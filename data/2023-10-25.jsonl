{"title": "The Distributional Hypothesis Does Not Fully Explain the Benefits of\n  Masked Language Model Pretraining", "abstract": "We analyze the masked language modeling pretraining objective function from\nthe perspective of the distributional hypothesis. We investigate whether better\nsample efficiency and the better generalization capability of models pretrained\nwith masked language modeling can be attributed to the semantic similarity\nencoded in the pretraining data's distributional property. Via a synthetic\ndataset, our analysis suggests that distributional property indeed leads to the\nbetter sample efficiency of pretrained masked language models, but does not\nfully explain the generalization capability. We also conduct analyses over two\nreal-world datasets and demonstrate that the distributional property does not\nexplain the generalization ability of pretrained natural language models\neither. Our results illustrate our limited understanding of model pretraining\nand provide future research directions.", "published": "2023-10-25 00:31:29", "link": "http://arxiv.org/abs/2310.16261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT a Good Multi-Party Conversation Solver?", "abstract": "Large Language Models (LLMs) have emerged as influential instruments within\nthe realm of natural language processing; nevertheless, their capacity to\nhandle multi-party conversations (MPCs) -- a scenario marked by the presence of\nmultiple interlocutors involved in intricate information exchanges -- remains\nuncharted. In this paper, we delve into the potential of generative LLMs such\nas ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is\nconducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by\nsubjecting them to evaluation across three MPC datasets that encompass five\nrepresentative tasks. The findings reveal that ChatGPT's performance on a\nnumber of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results\nportend a promising future. Additionally, we endeavor to bolster performance\nthrough the incorporation of MPC structures, encompassing both speaker and\naddressee architecture. This study provides an exhaustive evaluation and\nanalysis of applying generative LLMs to MPCs, casting a light upon the\nconception and creation of increasingly effective and robust MPC agents.\nConcurrently, this work underscores the challenges implicit in the utilization\nof LLMs for MPCs, such as deciphering graphical information flows and\ngenerating stylistically consistent responses.", "published": "2023-10-25 02:18:40", "link": "http://arxiv.org/abs/2310.16301v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiQAD: A Benchmark Dataset for End-to-End Open-domain Dialogue\n  Assessment", "abstract": "Dialogue assessment plays a critical role in the development of open-domain\ndialogue systems. Existing work are uncapable of providing an end-to-end and\nhuman-epistemic assessment dataset, while they only provide sub-metrics like\ncoherence or the dialogues are conversed between annotators far from real user\nsettings. In this paper, we release a large-scale dialogue quality assessment\ndataset (DiQAD), for automatically assessing open-domain dialogue quality.\nSpecifically, we (1) establish the assessment criteria based on the dimensions\nconforming to human judgements on dialogue qualities, and (2) annotate\nlarge-scale dialogues that conversed between real users based on these\nannotation criteria, which contains around 100,000 dialogues. We conduct\nseveral experiments and report the performances of the baselines as the\nbenchmark on DiQAD. The dataset is openly accessible at\nhttps://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation.", "published": "2023-10-25 03:04:57", "link": "http://arxiv.org/abs/2310.16319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Samsung R&D Institute Philippines at WMT 2023", "abstract": "In this paper, we describe the constrained MT systems submitted by Samsung\nR&D Institute Philippines to the WMT 2023 General Translation Task for two\ndirections: en$\\rightarrow$he and he$\\rightarrow$en. Our systems comprise of\nTransformer-based sequence-to-sequence models that are trained with a mix of\nbest practices: comprehensive data preprocessing pipelines, synthetic\nbacktranslated data, and the use of noisy channel reranking during online\ndecoding. Our models perform comparably to, and sometimes outperform, strong\nbaseline unconstrained systems such as mBART50 M2M and NLLB 200 MoE despite\nhaving significantly fewer parameters on two public benchmarks: FLORES-200 and\nNTREX-128.", "published": "2023-10-25 03:10:52", "link": "http://arxiv.org/abs/2310.16322v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating, Understanding, and Improving Constrained Text Generation for\n  Large Language Models", "abstract": "Advancements in natural language generation (NLG) and large language models\n(LLMs) have led to proficient text generation in various tasks. However,\nintegrating intricate constraints into neural text generation, due to LLMs'\nopacity, remains challenging. This study investigates constrained text\ngeneration for LLMs, where predefined constraints are applied during LLM's\ngeneration process. Our research mainly focuses on mainstream open-source LLMs,\ncategorizing constraints into lexical, structural, and relation-based types. We\nalso present various benchmarks to facilitate fair evaluation. The study\naddresses some key research questions, including evaluating, understanding and\nimproving constrained text generation for LLMs. Results illuminate LLMs'\ncapacity and deficiency to incorporate constraints and provide insights for\nfuture developments in constrained text generation. Codes and datasets will be\nreleased upon acceptance.", "published": "2023-10-25 03:58:49", "link": "http://arxiv.org/abs/2310.16343v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unraveling Feature Extraction Mechanisms in Neural Networks", "abstract": "The underlying mechanism of neural networks in capturing precise knowledge\nhas been the subject of consistent research efforts. In this work, we propose a\ntheoretical approach based on Neural Tangent Kernels (NTKs) to investigate such\nmechanisms. Specifically, considering the infinite network width, we\nhypothesize the learning dynamics of target models may intuitively unravel the\nfeatures they acquire from training data, deepening our insights into their\ninternal mechanisms. We apply our approach to several fundamental models and\nreveal how these models leverage statistical features during gradient descent\nand how they are integrated into final decisions. We also discovered that the\nchoice of activation function can affect feature extraction. For instance, the\nuse of the \\textit{ReLU} activation function could potentially introduce a bias\nin features, providing a plausible explanation for its replacement with\nalternative functions in recent pre-trained language models. Additionally, we\nfind that while self-attention and CNN models may exhibit limitations in\nlearning n-grams, multiplication-based models seem to excel in this area. We\nverify these theoretical findings through experiments and find that they can be\napplied to analyze language modeling tasks, which can be regarded as a special\nvariant of classification. Our contributions offer insights into the roles and\ncapacities of fundamental components within large language models, thereby\naiding the broader understanding of these complex systems.", "published": "2023-10-25 04:22:40", "link": "http://arxiv.org/abs/2310.16350v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Modal Multilingual Benchmark for Document Image Classification", "abstract": "Document image classification is different from plain-text document\nclassification and consists of classifying a document by understanding the\ncontent and structure of documents such as forms, emails, and other such\ndocuments. We show that the only existing dataset for this task (Lewis et al.,\n2006) has several limitations and we introduce two newly curated multilingual\ndatasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We\nfurther undertake a comprehensive study of popular visually-rich document\nunderstanding or Document AI models in previously untested setting in document\nimage classification such as 1) multi-label classification, and 2) zero-shot\ncross-lingual transfer setup. Experimental results show limitations of\nmultilingual Document AI models on cross-lingual transfer across typologically\ndistant languages. Our datasets and findings open the door for future research\ninto improving Document AI models.", "published": "2023-10-25 04:35:06", "link": "http://arxiv.org/abs/2310.16356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Simple to Complex: A Progressive Framework for Document-level\n  Informative Argument Extraction", "abstract": "Document-level Event Argument Extraction (EAE) requires the model to extract\narguments of multiple events from a single document. Considering the underlying\ndependencies between these events, recent efforts leverage the idea of\n\"memory\", where the results of already predicted events are cached and can be\nretrieved to help the prediction of upcoming events. These methods extract\nevents according to their appearance order in the document, however, the event\nthat appears in the first sentence does not mean that it is the easiest to\nextract. Existing methods might introduce noise to the extraction of upcoming\nevents if they rely on an incorrect prediction of previous events. In order to\nprovide more reliable memory, we propose a simple-to-complex progressive\nframework for document-level EAE. Specifically, we first calculate the\ndifficulty of each event and then, we conduct the extraction following a\nsimple-to-complex order. In this way, the memory will store the most certain\nresults, and the model could use these reliable sources to help the prediction\nof more difficult events. Experiments on WikiEvents show that our model\noutperforms SOTA by 1.4% in F1, indicating the proposed simple-to-complex\nframework is useful in the EAE task.", "published": "2023-10-25 04:38:02", "link": "http://arxiv.org/abs/2310.16358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-based Live Update Generation for Soccer Matches from\n  Microblog Posts", "abstract": "It has been known to be difficult to generate adequate sports updates from a\nsequence of vast amounts of diverse live tweets, although the live sports\nviewing experience with tweets is gaining the popularity. In this paper, we\nfocus on soccer matches and work on building a system to generate live updates\nfor soccer matches from tweets so that users can instantly grasp a match's\nprogress and enjoy the excitement of the match from raw tweets. Our proposed\nsystem is based on a large pre-trained language model and incorporates a\nmechanism to control the number of updates and a mechanism to reduce the\nredundancy of duplicate and similar updates.", "published": "2023-10-25 05:12:35", "link": "http://arxiv.org/abs/2310.16368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source\n  Ensembling of Language Adapters", "abstract": "We tackle the problem of zero-shot cross-lingual transfer in NLP tasks via\nthe use of language adapters (LAs). Most of the earlier works have explored\ntraining with adapter of a single source (often English), and testing either\nusing the target LA or LA of another related language. Training target LA\nrequires unlabeled data, which may not be readily available for low resource\nunseen languages: those that are neither seen by the underlying multilingual\nlanguage model (e.g., mBERT), nor do we have any (labeled or unlabeled) data\nfor them. We posit that for more effective cross-lingual transfer, instead of\njust one source LA, we need to leverage LAs of multiple (linguistically or\ngeographically related) source languages, both at train and test-time - which\nwe investigate via our novel neural architecture, ZGUL. Extensive\nexperimentation across four language groups, covering 15 unseen target\nlanguages, demonstrates improvements of up to 3.2 average F1 points over\nstandard fine-tuning and other strong baselines on POS tagging and NER tasks.\nWe also extend ZGUL to settings where either (1) some unlabeled data or (2)\nfew-shot training examples are available for the target language. We find that\nZGUL continues to outperform baselines in these settings too.", "published": "2023-10-25 06:22:29", "link": "http://arxiv.org/abs/2310.16393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Simultaneous Machine Translation with Word-level Policies", "abstract": "Recent years have seen remarkable advances in the field of Simultaneous\nMachine Translation (SiMT) due to the introduction of innovative policies that\ndictate whether to READ or WRITE at each step of the translation process.\nHowever, a common assumption in many existing studies is that operations are\ncarried out at the subword level, even though the standard unit for input and\noutput in most practical scenarios is typically at the word level. This paper\ndemonstrates that policies devised and validated at the subword level are\nsurpassed by those operating at the word level, which process multiple subwords\nto form a complete word in a single step. Additionally, we suggest a method to\nboost SiMT models using language models (LMs), wherein the proposed word-level\npolicy plays a vital role in addressing the subword disparity between LMs and\nSiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.", "published": "2023-10-25 07:10:42", "link": "http://arxiv.org/abs/2310.16417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PromptAgent: Strategic Planning with Language Models Enables\n  Expert-level Prompt Optimization", "abstract": "Highly effective, task-specific prompts are often heavily engineered by\nexperts to integrate detailed instructions and domain insights based on a deep\nunderstanding of both instincts of large language models (LLMs) and the\nintricacies of the target task. However, automating the generation of such\nexpert-level prompts remains elusive. Existing prompt optimization methods tend\nto overlook the depth of domain knowledge and struggle to efficiently explore\nthe vast space of expert-level prompts. Addressing this, we present\nPromptAgent, an optimization method that autonomously crafts prompts equivalent\nin quality to those handcrafted by experts. At its core, PromptAgent views\nprompt optimization as a strategic planning problem and employs a principled\nplanning algorithm, rooted in Monte Carlo tree search, to strategically\nnavigate the expert-level prompt space. Inspired by human-like trial-and-error\nexploration, PromptAgent induces precise expert-level insights and in-depth\ninstructions by reflecting on model errors and generating constructive error\nfeedback. Such a novel framework allows the agent to iteratively examine\nintermediate prompts (states), refine them based on error feedbacks (actions),\nsimulate future rewards, and search for high-reward paths leading to expert\nprompts. We apply PromptAgent to 12 tasks spanning three practical domains:\nBIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing\nit significantly outperforms strong Chain-of-Thought and recent prompt\noptimization baselines. Extensive analyses emphasize its capability to craft\nexpert-level, detailed, and domain-insightful prompts with great efficiency and\ngeneralizability.", "published": "2023-10-25 07:47:01", "link": "http://arxiv.org/abs/2310.16427v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLEX: Continuous Length Extrapolation for Large Language Models", "abstract": "Transformer-based Large Language Models (LLMs) are pioneering advances in\nmany natural language processing tasks, however, their exceptional capabilities\nare restricted within the preset context window of Transformer. Position\nEmbedding (PE) scaling methods, while effective in extending the context window\nto a specific length, demonstrate either notable limitations in their\nextrapolation abilities or sacrificing partial performance within the context\nwindow. Length extrapolation methods, although theoretically capable of\nextending the context window beyond the training sequence length, often\nunderperform in practical long-context applications. To address these\nchallenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We\ngeneralise the PE scaling approaches to model the continuous dynamics by\nordinary differential equations over the length scaling factor, thereby\novercoming the constraints of current PE scaling methods designed for specific\nlengths. Moreover, by extending the dynamics to desired context lengths beyond\nthe training sequence length, CLEX facilitates the length extrapolation with\nimpressive performance in practical tasks. We demonstrate that CLEX can be\nseamlessly incorporated into LLMs equipped with Rotary Position Embedding, such\nas LLaMA and GPT-NeoX, with negligible impact on training and inference\nlatency. Experimental results reveal that CLEX can effectively extend the\ncontext window to over 4x or almost 8x training length, with no deterioration\nin performance. Furthermore, when evaluated on the practical LongBench\nbenchmark, our model trained on a 4k length exhibits competitive performance\nagainst state-of-the-art open-source models trained on context lengths up to\n32k. Our code is available at https://github.com/DAMO-NLP-SG/CLEX.", "published": "2023-10-25 08:13:02", "link": "http://arxiv.org/abs/2310.16450v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and\n  Interacts during Language Model Training", "abstract": "Representational spaces learned via language modeling are fundamental to\nNatural Language Processing (NLP), however there has been limited understanding\nregarding how and when during training various types of linguistic information\nemerge and interact. Leveraging a novel information theoretic probing suite,\nwhich enables direct comparisons of not just task performance, but their\nrepresentational subspaces, we analyze nine tasks covering syntax, semantics\nand reasoning, across 2M pre-training steps and five seeds. We identify\ncritical learning phases across tasks and time, during which subspaces emerge,\nshare information, and later disentangle to specialize. Across these phases,\nsyntactic knowledge is acquired rapidly after 0.5% of full training. Continued\nperformance improvements primarily stem from the acquisition of open-domain\nknowledge, while semantics and reasoning tasks benefit from later boosts to\nlong-range contextualization and higher specialization. Measuring cross-task\nsimilarity further reveals that linguistically related tasks share information\nthroughout training, and do so more during the critical phase of learning than\nbefore or after. Our findings have implications for model interpretability,\nmulti-task learning, and learning from limited data.", "published": "2023-10-25 09:09:55", "link": "http://arxiv.org/abs/2310.16484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OccuQuest: Mitigating Occupational Bias for Inclusive Large Language\n  Models", "abstract": "The emergence of large language models (LLMs) has revolutionized natural\nlanguage processing tasks. However, existing instruction-tuning datasets suffer\nfrom occupational bias: the majority of data relates to only a few occupations,\nwhich hampers the instruction-tuned LLMs to generate helpful responses to\nprofessional queries from practitioners in specific fields. To mitigate this\nissue and promote occupation-inclusive LLMs, we create an instruction-tuning\ndataset named \\emph{OccuQuest}, which contains 110,000+ prompt-completion pairs\nand 30,000+ dialogues covering over 1,000 occupations in 26 occupational\ncategories. We systematically request ChatGPT, organizing queries\nhierarchically based on Occupation, Responsibility, Topic, and Question, to\nensure a comprehensive coverage of occupational specialty inquiries. By\ncomparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we\nobserve that OccuQuest exhibits a more balanced distribution across\noccupations. Furthermore, we assemble three test sets for comprehensive\nevaluation, an occu-test set covering 25 occupational categories, an estate set\nfocusing on real estate, and an occu-quora set containing real-world questions\nfrom Quora. We then fine-tune LLaMA on OccuQuest to obtain OccuLLaMA, which\nsignificantly outperforms state-of-the-art LLaMA variants (Vicuna, Tulu, and\nWizardLM) on professional questions in GPT-4 and human evaluations. Notably, on\nthe occu-quora set, OccuLLaMA reaches a high win rate of 86.4\\% against\nWizardLM.", "published": "2023-10-25 10:06:17", "link": "http://arxiv.org/abs/2310.16517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task\n  Information Retrieval", "abstract": "We present the Charles University system for the MRL~2023 Shared Task on\nMulti-lingual Multi-task Information Retrieval. The goal of the shared task was\nto develop systems for named entity recognition and question answering in\nseveral under-represented languages. Our solutions to both subtasks rely on the\ntranslate-test approach. We first translate the unlabeled examples into English\nusing a multilingual machine translation model. Then, we run inference on the\ntranslated data using a strong task-specific model. Finally, we project the\nlabeled data back into the original language. To keep the inferred tags on the\ncorrect positions in the original language, we propose a method based on\nscoring the candidate positions using a label-sensitive translation model. In\nboth settings, we experiment with finetuning the classification models on the\ntranslated data. However, due to a domain mismatch between the development data\nand the shared task validation and test sets, the finetuned models could not\noutperform our baselines.", "published": "2023-10-25 10:22:49", "link": "http://arxiv.org/abs/2310.16528v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "1-PAGER: One Pass Answer Generation and Evidence Retrieval", "abstract": "We present 1-Pager the first system that answers a question and retrieves\nevidence using a single Transformer-based model and decoding process. 1-Pager\nincrementally partitions the retrieval corpus using constrained decoding to\nselect a document and answer string, and we show that this is competitive with\ncomparable retrieve-and-read alternatives according to both retrieval and\nanswer accuracy metrics. 1-Pager also outperforms the equivalent closed-book\nquestion answering model, by grounding predictions in an evidence corpus. While\n1-Pager is not yet on-par with more expensive systems that read many more\ndocuments before generating an answer, we argue that it provides an important\nstep toward attributed generation by folding retrieval into the\nsequence-to-sequence paradigm that is currently dominant in NLP. We also show\nthat the search paths used to partition the corpus are easy to read and\nunderstand, paving a way forward for interpretable neural retrieval.", "published": "2023-10-25 11:51:22", "link": "http://arxiv.org/abs/2310.16568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained\n  Language Models", "abstract": "Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich\nin world knowledge. This fact has sparked the interest of the community in\nquantifying the amount of factual knowledge present in PLMs, as this explains\ntheir performance on downstream tasks, and potentially justifies their use as\nknowledge bases. In this work, we survey methods and datasets that are used to\nprobe PLMs for factual knowledge. Our contributions are: (1) We propose a\ncategorization scheme for factual probing methods that is based on how their\ninputs, outputs and the probed PLMs are adapted; (2) We provide an overview of\nthe datasets used for factual probing; (3) We synthesize insights about\nknowledge retention and prompt optimization in PLMs, analyze obstacles to\nadopting PLMs as knowledge bases and outline directions for future work.", "published": "2023-10-25 11:57:13", "link": "http://arxiv.org/abs/2310.16570v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming\n  Sentences with Contextualized Social Wisdom", "abstract": "In recent years, we witness the explosion of false and unconfirmed\ninformation (i.e., rumors) that went viral on social media and shocked the\npublic. Rumors can trigger versatile, mostly controversial stance expressions\namong social media users. Rumor verification and stance detection are different\nyet relevant tasks. Fake news debunking primarily focuses on determining the\ntruthfulness of news articles, which oversimplifies the issue as fake news\noften combines elements of both truth and falsehood. Thus, it becomes crucial\nto identify specific instances of misinformation within the articles. In this\nresearch, we investigate a novel task in the field of fake news debunking,\nwhich involves detecting sentence-level misinformation. One of the major\nchallenges in this task is the absence of a training dataset with\nsentence-level annotations regarding veracity. Inspired by the Multiple\nInstance Learning (MIL) approach, we propose a model called Weakly Supervised\nDetection of Misinforming Sentences (WSDMS). This model only requires bag-level\nlabels for training but is capable of inferring both sentence-level\nmisinformation and article-level veracity, aided by relevant social media\nconversations that are attentively contextualized with news sentences. We\nevaluate WSDMS on three real-world benchmarks and demonstrate that it\noutperforms existing state-of-the-art baselines in debunking fake news at both\nthe sentence and article levels.", "published": "2023-10-25 12:06:55", "link": "http://arxiv.org/abs/2310.16579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tailoring Personality Traits in Large Language Models via\n  Unsupervisedly-Built Personalized Lexicons", "abstract": "Personality plays a pivotal role in shaping human expression patterns, thus\nregulating the personality of large language models (LLMs) holds significant\npotential in enhancing the user experience of LLMs. Previous methods either\nrelied on fine-tuning LLMs on specific corpora or necessitated manually crafted\nprompts to elicit specific personalities from LLMs. However, the former\napproach is inefficient and costly, while the latter cannot precisely\nmanipulate personality traits at a fine-grained level. To address the above\nchallenges, we have employed a novel Unsupervisedly-Built Personalized Lexicons\n(UBPL) in a pluggable manner during the decoding phase of LLMs to manipulate\ntheir personality traits. UBPL is a lexicon built through an unsupervised\napproach from a situational judgment test dataset (SJTs4LLM). Users can utilize\nUBPL to adjust the probability vectors of predicted words in the decoding phase\nof LLMs, thus influencing the personality expression of LLMs. Extensive\nexperimentation demonstrates the remarkable effectiveness and pluggability of\nour method for fine-grained manipulation of LLM's personality.", "published": "2023-10-25 12:16:33", "link": "http://arxiv.org/abs/2310.16582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Interplay between Fairness and Explainability", "abstract": "In order to build reliable and trustworthy NLP applications, models need to\nbe both fair across different demographics and explainable. Usually these two\nobjectives, fairness and explainability, are optimized and/or examined\nindependently of each other. Instead, we argue that forthcoming, trustworthy\nNLP systems should consider both. In this work, we perform a first study to\nunderstand how they influence each other: do fair(er) models rely on more\nplausible rationales? and vice versa. To this end, we conduct experiments on\ntwo English multi-class text classification datasets, BIOS and ECtHR, that\nprovide information on gender and nationality, respectively, as well as\nhuman-annotated rationales. We fine-tune pre-trained language models with\nseveral methods for (i) bias mitigation, which aims to improve fairness; (ii)\nrationale extraction, which aims to produce plausible explanations. We find\nthat bias mitigation algorithms do not always lead to fairer models. Moreover,\nwe discover that empirical fairness and explainability are orthogonal.", "published": "2023-10-25 12:59:51", "link": "http://arxiv.org/abs/2310.16607v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT is a Potential Zero-Shot Dependency Parser", "abstract": "Pre-trained language models have been widely used in dependency parsing task\nand have achieved significant improvements in parser performance. However, it\nremains an understudied question whether pre-trained language models can\nspontaneously exhibit the ability of dependency parsing without introducing\nadditional parser structure in the zero-shot scenario. In this paper, we\npropose to explore the dependency parsing ability of large language models such\nas ChatGPT and conduct linguistic analysis. The experimental results\ndemonstrate that ChatGPT is a potential zero-shot dependency parser, and the\nlinguistic analysis also shows some unique preferences in parsing outputs.", "published": "2023-10-25 14:08:39", "link": "http://arxiv.org/abs/2310.16654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning\n  Framework for Emotion Recognition in Conversations", "abstract": "Emotion recognition in conversations (ERC) is a rapidly evolving task within\nthe natural language processing community, which aims to detect the emotions\nexpressed by speakers during a conversation. Recently, a growing number of ERC\nmethods have focused on leveraging supervised contrastive learning (SCL) to\nenhance the robustness and generalizability of learned features. However,\ncurrent SCL-based approaches in ERC are impeded by the constraint of large\nbatch sizes and the lack of compatibility with most existing ERC models. To\naddress these challenges, we propose an efficient and model-agnostic SCL\nframework named Supervised Sample-Label Contrastive Learning with Soft-HGR\nMaximal Correlation (SSLCL), which eliminates the need for a large batch size\nand can be seamlessly integrated with existing ERC models without introducing\nany model-specific assumptions. Specifically, we introduce a novel perspective\non utilizing label representations by projecting discrete labels into dense\nembeddings through a shallow multilayer perceptron, and formulate the training\nobjective to maximize the similarity between sample features and their\ncorresponding ground-truth label embeddings, while minimizing the similarity\nbetween sample features and label embeddings of disparate classes. Moreover, we\ninnovatively adopt the Soft-HGR maximal correlation as a measure of similarity\nbetween sample features and label embeddings, leading to significant\nperformance improvements over conventional similarity measures. Additionally,\nmultimodal cues of utterances are effectively leveraged by SSLCL as data\naugmentations to boost model performances. Extensive experiments on two ERC\nbenchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and\nsuperiority of our proposed SSLCL framework compared to existing\nstate-of-the-art SCL methods. Our code is available at\n\\url{https://github.com/TaoShi1998/SSLCL}.", "published": "2023-10-25 14:41:14", "link": "http://arxiv.org/abs/2310.16676v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BabyStories: Can Reinforcement Learning Teach Baby Language Models to\n  Write Better Stories?", "abstract": "Language models have seen significant growth in the size of their corpus,\nleading to notable performance improvements. Yet, there has been limited\nprogress in developing models that handle smaller, more human-like datasets. As\npart of the BabyLM shared task, this study explores the impact of reinforcement\nlearning from human feedback (RLHF) on language models pretrained from scratch\nwith a limited training corpus. Comparing two GPT-2 variants, the larger model\nperforms better in storytelling tasks after RLHF fine-tuning. These findings\nsuggest that RLHF techniques may be more advantageous for larger models due to\ntheir higher learning and adaptation capacity, though more experiments are\nneeded to confirm this finding. These insights highlight the potential benefits\nof RLHF fine-tuning for language models within limited data, enhancing their\nability to maintain narrative focus and coherence while adhering better to\ninitial instructions in storytelling tasks. The code for this work is publicly\nat https://github.com/Zephyr1022/BabyStories-UTSA.", "published": "2023-10-25 14:45:48", "link": "http://arxiv.org/abs/2310.16681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Performance Predictors are good initializers for Architecture Search", "abstract": "In this work, we utilize Large Language Models (LLMs) for a novel use case:\nconstructing Performance Predictors (PP) that estimate the performance of\nspecific deep neural network architectures on downstream tasks. We create PP\nprompts for LLMs, comprising (i) role descriptions, (ii) instructions for the\nLLM, (iii) hyperparameter definitions, and (iv) demonstrations presenting\nsample architectures with efficiency metrics and `training from scratch'\nperformance. In machine translation (MT) tasks, GPT-4 with our PP prompts\n(LLM-PP) achieves a SoTA mean absolute error and a slight degradation in rank\ncorrelation coefficient compared to baseline predictors. Additionally, we\ndemonstrate that predictions from LLM-PP can be distilled to a compact\nregression model (LLM-Distill-PP), which surprisingly retains much of the\nperformance of LLM-PP. This presents a cost-effective alternative for\nresource-intensive performance estimation. Specifically, for Neural\nArchitecture Search (NAS), we introduce a Hybrid-Search algorithm (HS-NAS)\nemploying LLM-Distill-PP for the initial search stages and reverting to the\nbaseline predictor later. HS-NAS performs similarly to SoTA NAS, reducing\nsearch hours by approximately 50%, and in some cases, improving latency,\nGFLOPs, and model size. The code can be found at:\nhttps://github.com/UBC-NLP/llmas.", "published": "2023-10-25 15:34:30", "link": "http://arxiv.org/abs/2310.16712v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning", "abstract": "Spatial reasoning over text is challenging as the models not only need to\nextract the direct spatial information from the text but also reason over those\nand infer implicit spatial relations. Recent studies highlight the struggles\neven large language models encounter when it comes to performing spatial\nreasoning over text. In this paper, we explore the potential benefits of\ndisentangling the processes of information extraction and reasoning in models\nto address this challenge. To explore this, we design various models that\ndisentangle extraction and reasoning(either symbolic or neural) and compare\nthem with state-of-the-art(SOTA) baselines with no explicit design for these\nparts. Our experimental results consistently demonstrate the efficacy of\ndisentangling, showcasing its ability to enhance models' generalizability\nwithin realistic data domains.", "published": "2023-10-25 16:00:47", "link": "http://arxiv.org/abs/2310.16731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis", "abstract": "Authorship Analysis, also known as stylometry, has been an essential aspect\nof Natural Language Processing (NLP) for a long time. Likewise, the recent\nadvancement of Large Language Models (LLMs) has made authorship analysis\nincreasingly crucial for distinguishing between human-written and AI-generated\ntexts. However, these authorship analysis tasks have primarily been focused on\nwritten texts, not considering spoken texts. Thus, we introduce the largest\nbenchmark for spoken texts - HANSEN (Human ANd ai Spoken tExt beNchmark).\nHANSEN encompasses meticulous curation of existing speech datasets accompanied\nby transcripts, alongside the creation of novel AI-generated spoken text\ndatasets. Together, it comprises 17 human datasets, and AI-generated spoken\ntexts created using 3 prominent LLMs: ChatGPT, PaLM2, and Vicuna13B. To\nevaluate and demonstrate the utility of HANSEN, we perform Authorship\nAttribution (AA) & Author Verification (AV) on human-spoken datasets and\nconducted Human vs. AI spoken text detection using state-of-the-art (SOTA)\nmodels. While SOTA methods, such as, character ngram or Transformer-based\nmodel, exhibit similar AA & AV performance in human-spoken datasets compared to\nwritten ones, there is much room for improvement in AI-generated spoken text\ndetection. The HANSEN benchmark is available at:\nhttps://huggingface.co/datasets/HANSEN-REPO/HANSEN.", "published": "2023-10-25 16:23:17", "link": "http://arxiv.org/abs/2310.16746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection\n  and Discovery", "abstract": "Identifying intents from dialogue utterances forms an integral component of\ntask-oriented dialogue systems. Intent-related tasks are typically formulated\neither as a classification task, where the utterances are classified into\npredefined categories or as a clustering task when new and previously unknown\nintent categories need to be discovered from these utterances. Further, the\nintent classification may be modeled in a multiclass (MC) or multilabel (ML)\nsetup. While typically these tasks are modeled as separate tasks, we propose\nIntenDD, a unified approach leveraging a shared utterance encoding backbone.\nIntenDD uses an entirely unsupervised contrastive learning strategy for\nrepresentation learning, where pseudo-labels for the unlabeled utterances are\ngenerated based on their lexical features. Additionally, we introduce a\ntwo-step post-processing setup for the classification tasks using modified\nadsorption. Here, first, the residuals in the training data are propagated\nfollowed by smoothing the labels both modeled in a transductive setting.\nThrough extensive evaluations on various benchmark datasets, we find that our\napproach consistently outperforms competitive baselines across all three tasks.\nOn average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52%\nin their respective metrics for few-shot MC, few-shot ML, and the intent\ndiscovery tasks respectively.", "published": "2023-10-25 16:50:24", "link": "http://arxiv.org/abs/2310.16761v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Divide et Impera: Multi-Transformer Architectures for Complex NLP-Tasks", "abstract": "The growing capabilities of transformer models pave the way for solving\nincreasingly complex NLP tasks. A key to supporting application-specific\nrequirements is the ability to fine-tune. However, compiling a fine-tuning\ndataset tailored to complex tasks is tedious and results in large datasets,\nlimiting the ability to control transformer output. We present an approach in\nwhich complex tasks are divided into simpler subtasks. Multiple transformer\nmodels are fine-tuned to one subtask each, and lined up to accomplish the\ncomplex task. This simplifies the compilation of fine-tuning datasets and\nincreases overall controllability. Using the example of reducing gender bias as\na complex task, we demonstrate our approach and show that it performs better\nthan using a single model.", "published": "2023-10-25 18:00:15", "link": "http://arxiv.org/abs/2310.16897v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Transfers over Several Programming Languages", "abstract": "Large language models (LLMs) have become remarkably good at improving\ndeveloper productivity for high-resource programming languages. These models\nuse two kinds of data: large amounts of unlabeled code samples for pre-training\nand relatively smaller amounts of labeled code samples for fine-tuning or\nin-context learning. Unfortunately, many programming languages are\nlow-resource, lacking labeled samples for most tasks and often even lacking\nunlabeled samples. Therefore, users of low-resource languages (e.g., legacy or\nnew languages) miss out on the benefits of LLMs. Cross-lingual transfer uses\ndata from a source language to improve model performance on a target language.\nIt has been well-studied for natural languages, but has received little\nattention for programming languages. This paper reports extensive experiments\non four tasks using a transformer-based LLM and 11 to 41 programming languages\nto explore the following questions. First, how well does cross-lingual transfer\nwork for a given task across different language pairs. Second, given a task and\ntarget language, how should one choose a source language. Third, which\ncharacteristics of a language pair are predictive of transfer performance, and\nhow does that depend on the given task. Our empirical study with 1,808\nexperiments reveals practical and scientific insights, such as Kotlin and\nJavaScript being the most transferable source languages and different tasks\nrelying on substantially different features. Overall, we find that learning\ntransfers well across several programming languages.", "published": "2023-10-25 19:04:33", "link": "http://arxiv.org/abs/2310.16937v2", "categories": ["cs.CL", "I.2.7; I.2.5"], "primary_category": "cs.CL"}
{"title": "Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text\n  Generation", "abstract": "Hallucination of text ungrounded in the input is a well-known problem in\nneural data-to-text generation. Many methods have been proposed to mitigate it,\nbut they typically require altering model architecture or collecting additional\ndata, and thus cannot be easily applied to an existing model. In this paper, we\nexplore a new way to mitigate hallucinations by combining the probabilistic\noutput of a generator language model (LM) with the output of a special \"text\ncritic\" classifier, which guides the generation by assessing the match between\nthe input data and the text generated so far. Our method does not need any\nchanges to the underlying LM's architecture or training procedure and can thus\nbe combined with any model and decoding operating on word probabilities. The\ncritic does not need any additional training data, using the base LM's training\ndata and synthetic negative examples. Our experimental results show that our\nmethod improves over the baseline on the WebNLG and OpenDialKG benchmarks.", "published": "2023-10-25 20:05:07", "link": "http://arxiv.org/abs/2310.16964v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "How well can machine-generated texts be identified and can language\n  models be trained to avoid identification?", "abstract": "With the rise of generative pre-trained transformer models such as GPT-3,\nGPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated\nones has become important. We refined five separate language models to generate\nsynthetic tweets, uncovering that shallow learning classification algorithms,\nlike Naive Bayes, achieve detection accuracy between 0.6 and 0.8.\n  Shallow learning classifiers differ from human-based detection, especially\nwhen using higher temperature values during text generation, resulting in a\nlower detection rate. Humans prioritize linguistic acceptability, which tends\nto be higher at lower temperature values. In contrast, transformer-based\nclassifiers have an accuracy of 0.9 and above. We found that using a\nreinforcement learning approach to refine our generative models can\nsuccessfully evade BERT-based classifiers with a detection accuracy of 0.15 or\nless.", "published": "2023-10-25 20:43:07", "link": "http://arxiv.org/abs/2310.16992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TOP-Training: Target-Oriented Pretraining for Medical Extractive\n  Question Answering", "abstract": "We study extractive question-answering in the medical domain (Medical-EQA).\nThis problem has two main challenges: (i) domain specificity, as most AI models\nlack necessary domain knowledge, and (ii) extraction-based answering style,\nwhich restricts most autoregressive LLMs due to potential hallucinations. To\nhandle those challenges, we propose TOP-Training, a target-oriented\npre-training paradigm that stands out among all domain adaptation techniques\nwith two desirable features: (i) TOP-Training moves one step further than\npopular domain-oriented fine-tuning since it not only moves closer to the\ntarget domain, but also familiarizes itself with the target dataset, and (ii)\nit does not assume the existence of a large set of unlabeled instances from the\ntarget domain. Specifically, for a target Medical-EQA dataset, we extract its\nentities and leverage large language models (LLMs) to generate synthetic texts\ncontaining those entities; we then demonstrate that pretraining on this\nsynthetic text data yields better performance on the target Medical-EQA\nbenchmarks. Overall, our contributions are threefold: (i) TOP-Training, a new\npretraining technique to effectively adapt LLMs to better solve a target\nproblem, (ii) TOP-Training has a wide application scope because it does not\nrequire the target problem to have a large set of unlabeled data, and (iii) our\nexperiments highlight the limitations of autoregressive LLMs, emphasizing\nTOP-Training as a means to unlock the true potential of bidirectional LLMs.", "published": "2023-10-25 20:48:16", "link": "http://arxiv.org/abs/2310.16995v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Emotion Detection in Small Imbalanced Text Data", "abstract": "Emotion recognition in text, the task of identifying emotions such as joy or\nanger, is a challenging problem in NLP with many applications. One of the\nchallenges is the shortage of available datasets that have been annotated with\nemotions. Certain existing datasets are small, follow different emotion\ntaxonomies and display imbalance in their emotion distribution. In this work,\nwe studied the impact of data augmentation techniques precisely when applied to\nsmall imbalanced datasets, for which current state-of-the-art models (such as\nRoBERTa) under-perform. Specifically, we utilized four data augmentation\nmethods (Easy Data Augmentation EDA, static and contextual Embedding-based, and\nProtAugment) on three datasets that come from different sources and vary in\nsize, emotion categories and distributions. Our experimental results show that\nusing the augmented data when training the classifier model leads to\nsignificant improvements. Finally, we conducted two case studies: a) directly\nusing the popular chat-GPT API to paraphrase text using different prompts, and\nb) using external data to augment the training set. Results show the promising\npotential of these methods.", "published": "2023-10-25 21:29:36", "link": "http://arxiv.org/abs/2310.17015v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Follow-on Question Suggestion via Voice Hints for Voice Assistants", "abstract": "The adoption of voice assistants like Alexa or Siri has grown rapidly,\nallowing users to instantly access information via voice search. Query\nsuggestion is a standard feature of screen-based search experiences, allowing\nusers to explore additional topics. However, this is not trivial to implement\nin voice-based settings. To enable this, we tackle the novel task of suggesting\nquestions with compact and natural voice hints to allow users to ask follow-up\nquestions.\n  We define the task, ground it in syntactic theory and outline linguistic\ndesiderata for spoken hints. We propose baselines and an approach using\nsequence-to-sequence Transformers to generate spoken hints from a list of\nquestions. Using a new dataset of 6681 input questions and human written hints,\nwe evaluated the models with automatic metrics and human evaluation. Results\nshow that a naive approach of concatenating suggested questions creates poor\nvoice hints. Our approach, which applies a linguistically-motivated pretraining\ntask was strongly preferred by humans for producing the most natural hints.", "published": "2023-10-25 22:22:18", "link": "http://arxiv.org/abs/2310.17034v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Muslim-Violence Bias Persists in Debiased GPT Models", "abstract": "Abid et al. (2021) showed a tendency in GPT-3 to generate mostly violent\ncompletions when prompted about Muslims, compared with other religions. Two\npre-registered replication attempts found few violent completions and only a\nweak anti-Muslim bias in the more recent InstructGPT, fine-tuned to eliminate\nbiased and toxic outputs. However, more pre-registered experiments showed that\nusing common names associated with the religions in prompts increases\nseveral-fold the rate of violent completions, revealing a significant\nsecond-order anti-Muslim bias. ChatGPT showed a bias many times stronger\nregardless of prompt format, suggesting that the effects of debiasing were\nreduced with continued model development. Our content analysis revealed\nreligion-specific themes containing offensive stereotypes across all\nexperiments. Our results show the need for continual de-biasing of models in\nways that address both explicit and higher-order associations.", "published": "2023-10-25 19:39:58", "link": "http://arxiv.org/abs/2310.18368v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multi-label Text Classification using GloVe and Neural Network Models", "abstract": "This study addresses the challenges of multi-label text classification. The\ndifficulties arise from imbalanced data sets, varied text lengths, and numerous\nsubjective feature labels. Existing solutions include traditional machine\nlearning and deep neural networks for predictions. However, both approaches\nhave their limitations. Traditional machine learning often overlooks the\nassociations between words, while deep neural networks, despite their better\nclassification performance, come with increased training complexity and time.\nThis paper proposes a method utilizing the bag-of-words model approach based on\nthe GloVe model and the CNN-BiLSTM network. The principle is to use the word\nvector matrix trained by the GloVe model as the input for the text embedding\nlayer. Given that the GloVe model requires no further training, the neural\nnetwork model can be trained more efficiently. The method achieves an accuracy\nrate of 87.26% on the test set and an F1 score of 0.8737, showcasing promising\nresults.", "published": "2023-10-25 01:30:26", "link": "http://arxiv.org/abs/2312.03707v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CycleAlign: Iterative Distillation from Black-box LLM to White-box\n  Models for Better Human Alignment", "abstract": "Language models trained on large-scale corpus often generate content that is\nharmful, toxic, or contrary to human preferences, making their alignment with\nhuman values a critical concern. Reinforcement learning from human feedback\n(RLHF) with algorithms like PPO is a prevalent approach for alignment but is\noften complex, unstable, and resource-intensive. Recently, ranking-based\nalignment methods have emerged, offering stability and effectiveness by\nreplacing the RL framework with supervised fine-tuning, but they are costly due\nto the need for annotated data. Considering that existing large language models\n(LLMs) like ChatGPT are already relatively well-aligned and cost-friendly,\nresearchers have begun to align the language model with human preference from\nAI feedback. The common practices, which unidirectionally distill the\ninstruction-following responses from LLMs, are constrained by their bottleneck.\nThus we introduce CycleAlign to distill alignment capabilities from\nparameter-invisible LLMs (black-box) to a parameter-visible model (white-box)\nin an iterative manner. With in-context learning (ICL) as the core of the\ncycle, the black-box models are able to rank the model-generated responses\nguided by human-craft instruction and demonstrations about their preferences.\nDuring iterative interaction, the white-box models also have a judgment about\nresponses generated by them. Consequently, the agreement ranking could be\nviewed as a pseudo label to dynamically update the in-context demonstrations\nand improve the preference ranking ability of black-box models. Through\nmultiple interactions, the CycleAlign framework could align the white-box model\nwith the black-box model effectively in a low-resource way. Empirical results\nillustrate that the model fine-tuned by CycleAlign remarkably exceeds existing\nmethods, and achieves the state-of-the-art performance in alignment with human\nvalue.", "published": "2023-10-25 01:05:03", "link": "http://arxiv.org/abs/2310.16271v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "XFEVER: Exploring Fact Verification across Languages", "abstract": "This paper introduces the Cross-lingual Fact Extraction and VERification\n(XFEVER) dataset designed for benchmarking the fact verification models across\ndifferent languages. We constructed it by translating the claim and evidence\ntexts of the Fact Extraction and VERification (FEVER) dataset into six\nlanguages. The training and development sets were translated using machine\ntranslation, whereas the test set includes texts translated by professional\ntranslators and machine-translated texts. Using the XFEVER dataset, two\ncross-lingual fact verification scenarios, zero-shot learning and\ntranslate-train learning, are defined, and baseline models for each scenario\nare also proposed in this paper. Experimental results show that the\nmultilingual language model can be used to build fact verification models in\ndifferent languages efficiently. However, the performance varies by language\nand is somewhat inferior to the English case. We also found that we can\neffectively mitigate model miscalibration by considering the prediction\nsimilarity between the English and target languages. The XFEVER dataset, code,\nand model checkpoints are available at\nhttps://github.com/nii-yamagishilab/xfever.", "published": "2023-10-25 01:20:17", "link": "http://arxiv.org/abs/2310.16278v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "URL-BERT: Training Webpage Representations via Social Media Engagements", "abstract": "Understanding and representing webpages is crucial to online social networks\nwhere users may share and engage with URLs. Common language model (LM) encoders\nsuch as BERT can be used to understand and represent the textual content of\nwebpages. However, these representations may not model thematic information of\nweb domains and URLs or accurately capture their appeal to social media users.\nIn this work, we introduce a new pre-training objective that can be used to\nadapt LMs to understand URLs and webpages. Our proposed framework consists of\ntwo steps: (1) scalable graph embeddings to learn shallow representations of\nURLs based on user engagement on social media and (2) a contrastive objective\nthat aligns LM representations with the aforementioned graph-based\nrepresentation. We apply our framework to the multilingual version of BERT to\nobtain the model URL-BERT. We experimentally demonstrate that our continued\npre-training approach improves webpage understanding on a variety of tasks and\nTwitter internal and external benchmarks.", "published": "2023-10-25 02:22:50", "link": "http://arxiv.org/abs/2310.16303v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "RCAgent: Cloud Root Cause Analysis by Autonomous Agents with\n  Tool-Augmented Large Language Models", "abstract": "Large language model (LLM) applications in cloud root cause analysis (RCA)\nhave been actively explored recently. However, current methods are still\nreliant on manual workflow settings and do not unleash LLMs' decision-making\nand environment interaction capabilities. We present RCAgent, a tool-augmented\nLLM autonomous agent framework for practical and privacy-aware industrial RCA\nusage. Running on an internally deployed model rather than GPT families,\nRCAgent is capable of free-form data collection and comprehensive analysis with\ntools. Our framework combines a variety of enhancements, including a unique\nSelf-Consistency for action trajectories, and a suite of methods for context\nmanagement, stabilization, and importing domain knowledge. Our experiments show\nRCAgent's evident and consistent superiority over ReAct across all aspects of\nRCA -- predicting root causes, solutions, evidence, and responsibilities -- and\ntasks covered or uncovered by current rules, as validated by both automated\nmetrics and human evaluations. Furthermore, RCAgent has already been integrated\ninto the diagnosis and issue discovery workflow of the Real-time Compute\nPlatform for Apache Flink of Alibaba Cloud.", "published": "2023-10-25 03:53:31", "link": "http://arxiv.org/abs/2310.16340v3", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "InstructPTS: Instruction-Tuning LLMs for Product Title Summarization", "abstract": "E-commerce product catalogs contain billions of items. Most products have\nlengthy titles, as sellers pack them with product attributes to improve\nretrieval, and highlight key product aspects. This results in a gap between\nsuch unnatural products titles, and how customers refer to them. It also limits\nhow e-commerce stores can use these seller-provided titles for recommendation,\nQA, or review summarization.\n  Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a\ncontrollable approach for the task of Product Title Summarization (PTS).\nTrained using a novel instruction fine-tuning strategy, our approach is able to\nsummarize product titles according to various criteria (e.g. number of words in\na summary, inclusion of specific phrases, etc.). Extensive evaluation on a\nreal-world e-commerce catalog shows that compared to simple fine-tuning of\nLLMs, our proposed approach can generate more accurate product name summaries,\nwith an improvement of over 14 and 8 BLEU and ROUGE points, respectively.", "published": "2023-10-25 04:56:07", "link": "http://arxiv.org/abs/2310.16361v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Video Referring Expression Comprehension via Transformer with\n  Content-conditioned Query", "abstract": "Video Referring Expression Comprehension (REC) aims to localize a target\nobject in videos based on the queried natural language. Recent improvements in\nvideo REC have been made using Transformer-based methods with learnable\nqueries. However, we contend that this naive query design is not ideal given\nthe open-world nature of video REC brought by text supervision. With numerous\npotential semantic categories, relying on only a few slow-updated queries is\ninsufficient to characterize them. Our solution to this problem is to create\ndynamic queries that are conditioned on both the input video and language to\nmodel the diverse objects referred to. Specifically, we place a fixed number of\nlearnable bounding boxes throughout the frame and use corresponding region\nfeatures to provide prior information. Also, we noticed that current query\nfeatures overlook the importance of cross-modal alignment. To address this, we\nalign specific phrases in the sentence with semantically relevant visual areas,\nannotating them in existing video datasets (VID-Sentence and VidSTG). By\nincorporating these two designs, our proposed model (called ConFormer)\noutperforms other models on widely benchmarked datasets. For example, in the\ntesting split of VID-Sentence dataset, ConFormer achieves 8.75% absolute\nimprovement on Accu.@0.6 compared to the previous state-of-the-art model.", "published": "2023-10-25 06:38:42", "link": "http://arxiv.org/abs/2310.16402v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Decoding Stumpers: Large Language Models vs. Human Problem-Solvers", "abstract": "This paper investigates the problem-solving capabilities of Large Language\nModels (LLMs) by evaluating their performance on stumpers, unique single-step\nintuition problems that pose challenges for human solvers but are easily\nverifiable. We compare the performance of four state-of-the-art LLMs\n(Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our\nfindings reveal that the new-generation LLMs excel in solving stumpers and\nsurpass human performance. However, humans exhibit superior skills in verifying\nsolutions to the same problems. This research enhances our understanding of\nLLMs' cognitive abilities and provides insights for enhancing their\nproblem-solving potential across various domains.", "published": "2023-10-25 06:54:39", "link": "http://arxiv.org/abs/2310.16411v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning\n  in Language Models", "abstract": "A long-standing goal of AI systems is to perform complex multimodal reasoning\nlike humans. Recently, large language models (LLMs) have made remarkable\nstrides in such multi-step reasoning on the language modality solely by\nleveraging the chain of thought (CoT) to mimic human thinking. However, the\ntransfer of these advancements to multimodal contexts introduces heightened\nchallenges, including but not limited to the impractical need for\nlabor-intensive annotation and the limitations in terms of flexibility,\ngeneralizability, and explainability. To evoke CoT reasoning in multimodality,\nthis work first conducts an in-depth analysis of these challenges posed by\nmultimodality and presents two key insights: \"keeping critical thinking\" and\n\"letting everyone do their jobs\" in multimodal CoT reasoning. Furthermore, this\nstudy proposes a novel DDCoT prompting that maintains a critical attitude\nthrough negative-space prompting and incorporates multimodality into reasoning\nby first dividing the reasoning responsibility of LLMs into reasoning and\nrecognition and then integrating the visual recognition capability of visual\nmodels into the joint reasoning process. The rationales generated by DDCoT not\nonly improve the reasoning abilities of both large and small language models in\nzero-shot prompting and fine-tuning learning, significantly outperforming\nstate-of-the-art methods but also exhibit impressive generalizability and\nexplainability.", "published": "2023-10-25 08:03:10", "link": "http://arxiv.org/abs/2310.16436v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Diversity Enhanced Narrative Question Generation for Storybooks", "abstract": "Question generation (QG) from a given context can enhance comprehension,\nengagement, assessment, and overall efficacy in learning or conversational\nenvironments. Despite recent advancements in QG, the challenge of enhancing or\nmeasuring the diversity of generated questions often remains unaddressed. In\nthis paper, we introduce a multi-question generation model (mQG), which is\ncapable of generating multiple, diverse, and answerable questions by focusing\non context and questions. To validate the answerability of the generated\nquestions, we employ a SQuAD2.0 fine-tuned question answering model,\nclassifying the questions as answerable or not. We train and evaluate mQG on\nthe FairytaleQA dataset, a well-structured QA dataset based on storybooks, with\nnarrative questions. We further apply a zero-shot adaptation on the TellMeWhy\nand SQuAD1.1 datasets. mQG shows promising results across various evaluation\nmetrics, among strong baselines.", "published": "2023-10-25 08:10:04", "link": "http://arxiv.org/abs/2310.16446v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Diversity of Demographic Representation in Large Language\n  Models via Collective-Critiques and Self-Voting", "abstract": "A crucial challenge for generative large language models (LLMs) is diversity:\nwhen a user's prompt is under-specified, models may follow implicit assumptions\nwhile generating a response, which may result in homogenization of the\nresponses, as well as certain demographic groups being under-represented or\neven erased from the generated responses. In this paper, we formalize diversity\nof representation in generative LLMs. We present evaluation datasets and\npropose metrics to measure diversity in generated responses along people and\nculture axes. We find that LLMs understand the notion of diversity, and that\nthey can reason and critique their own responses for that goal. This finding\nmotivated a new prompting technique called collective-critique and self-voting\n(CCSV) to self-improve people diversity of LLMs by tapping into its diversity\nreasoning capabilities, without relying on handcrafted examples or prompt\ntuning. Extensive empirical experiments with both human and automated\nevaluations show that our proposed approach is effective at improving people\nand culture diversity, and outperforms all baseline methods by a large margin.", "published": "2023-10-25 10:17:17", "link": "http://arxiv.org/abs/2310.16523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Early Evaluation of GPT-4V(ision)", "abstract": "In this paper, we evaluate different abilities of GPT-4V including visual\nunderstanding, language understanding, visual puzzle solving, and understanding\nof other modalities such as depth, thermal, video, and audio. To estimate\nGPT-4V's performance, we manually construct 656 test instances and carefully\nevaluate the results of GPT-4V. The highlights of our findings are as follows:\n(1) GPT-4V exhibits impressive performance on English visual-centric benchmarks\nbut fails to recognize simple Chinese texts in the images; (2) GPT-4V shows\ninconsistent refusal behavior when answering questions related to sensitive\ntraits such as gender, race, and age; (3) GPT-4V obtains worse results than\nGPT-4 (API) on language understanding tasks including general language\nunderstanding benchmarks and visual commonsense knowledge evaluation\nbenchmarks; (4) Few-shot prompting can improve GPT-4V's performance on both\nvisual understanding and language understanding; (5) GPT-4V struggles to find\nthe nuances between two similar images and solve the easy math picture puzzles;\n(6) GPT-4V shows non-trivial performance on the tasks of similar modalities to\nimage, such as video and thermal. Our experimental results reveal the ability\nand limitations of GPT-4V and we hope our paper can provide some insights into\nthe application and research of GPT-4V.", "published": "2023-10-25 10:33:17", "link": "http://arxiv.org/abs/2310.16534v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought\n  Reasoning in Large Language Models under Noisy Context", "abstract": "With the help of Chain-of-Thought (CoT) prompting, Large Language Models\n(LLMs) have achieved remarkable performance on various reasoning tasks.\nHowever, most of them have been evaluated under noise-free context and the\ndilemma for LLMs to produce inaccurate results under the noisy context has not\nbeen fully investigated. Existing studies utilize trigger sentences to\nencourage LLMs to concentrate on the relevant information but the trigger has\nlimited effect on final answer prediction. Inspired by interactive CoT method,\nwhere intermediate reasoning steps are promoted by multiple rounds of\ninteraction between users and LLMs, we propose a novel prompting method, namely\nR$^3$ prompting, for CoT reasoning under noisy context. Specifically, R$^3$\nprompting interacts with LLMs to perform key sentence extraction, variable\ndeclaration and answer prediction, which corresponds to a thought process of\nreviewing, rephrasing and resolving. The responses generated at the last\ninteraction will perform as hints to guide toward the responses of the next\ninteraction. Our experiments show that R$^3$ prompting significantly\noutperforms existing CoT prompting methods on five reasoning tasks under noisy\ncontext. With GPT-3.5-turbo, we observe 3.7% accuracy improvement on average on\nthe reasoning tasks under noisy context compared to the most competitive\nprompting baseline. More analyses and ablation studies show the robustness and\ngeneralization of R$^3$ prompting method in solving reasoning tasks in LLMs\nunder noisy context.", "published": "2023-10-25 10:34:02", "link": "http://arxiv.org/abs/2310.16535v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Context Does Matter: End-to-end Panoptic Narrative Grounding with\n  Deformable Attention Refined Matching Network", "abstract": "Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that\naims to segment visual objects in images based on dense narrative captions. The\ncurrent state-of-the-art methods first refine the representation of phrase by\naggregating the most similar $k$ image pixels, and then match the refined text\nrepresentations with the pixels of the image feature map to generate\nsegmentation results. However, simply aggregating sampled image features\nignores the contextual information, which can lead to phrase-to-pixel\nmis-match. In this paper, we propose a novel learning framework called\nDeformable Attention Refined Matching Network (DRMN), whose main idea is to\nbring deformable attention in the iterative process of feature learning to\nincorporate essential context information of different scales of pixels. DRMN\niteratively re-encodes pixels with the deformable attention network after\nupdating the feature representation of the top-$k$ most similar pixels. As\nsuch, DRMN can lead to accurate yet discriminative pixel representations,\npurify the top-$k$ most similar pixels, and consequently alleviate the\nphrase-to-pixel mis-match substantially.Experimental results show that our\nnovel design significantly improves the matching results between text phrases\nand image pixels. Concretely, DRMN achieves new state-of-the-art performance on\nthe PNG benchmark with an average recall improvement 3.5%. The codes are\navailable in: https://github.com/JaMesLiMers/DRMN.", "published": "2023-10-25 13:12:39", "link": "http://arxiv.org/abs/2310.16616v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Detection of news written by the ChatGPT through authorship attribution\n  performed by a Bidirectional LSTM model", "abstract": "The large language based-model chatbot ChatGPT gained a lot of popularity\nsince its launch and has been used in a wide range of situations. This research\ncenters around a particular situation, when the ChatGPT is used to produce news\nthat will be consumed by the population, causing the facilitation in the\nproduction of fake news, spread of misinformation and lack of trust in news\nsources. Aware of these problems, this research aims to build an artificial\nintelligence model capable of performing authorship attribution on news\narticles, identifying the ones written by the ChatGPT. To achieve this goal, a\ndataset containing equal amounts of human and ChatGPT written news was\nassembled and different natural processing language techniques were used to\nextract features from it that were used to train, validate and test three\nmodels built with different techniques. The best performance was produced by\nthe Bidirectional Long Short Term Memory (LSTM) Neural Network model, achiving\n91.57\\% accuracy when tested against the data from the testing set.", "published": "2023-10-25 14:48:58", "link": "http://arxiv.org/abs/2310.16685v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SkyMath: Technical Report", "abstract": "Large language models (LLMs) have shown great potential to solve varieties of\nnatural language processing (NLP) tasks, including mathematical reasoning. In\nthis work, we present SkyMath, a large language model for mathematics with 13\nbillion parameters. By applying self-compare fine-tuning, we have enhanced\nmathematical reasoning abilities of Skywork-13B-Base remarkably. On GSM8K,\nSkyMath outperforms all known open-source models of similar size and has\nestablished a new SOTA performance.", "published": "2023-10-25 15:34:55", "link": "http://arxiv.org/abs/2310.16713v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Conversational Recommendation Systems via Bias Analysis and\n  Language-Model-Enhanced Data Augmentation", "abstract": "Conversational Recommendation System (CRS) is a rapidly growing research area\nthat has gained significant attention alongside advancements in language\nmodelling techniques. However, the current state of conversational\nrecommendation faces numerous challenges due to its relative novelty and\nlimited existing contributions. In this study, we delve into benchmark datasets\nfor developing CRS models and address potential biases arising from the\nfeedback loop inherent in multi-turn interactions, including selection bias and\nmultiple popularity bias variants. Drawing inspiration from the success of\ngenerative data via using language models and data augmentation techniques, we\npresent two novel strategies, 'Once-Aug' and 'PopNudge', to enhance model\nperformance while mitigating biases. Through extensive experiments on ReDial\nand TG-ReDial benchmark datasets, we show a consistent improvement of CRS\ntechniques with our data augmentation approaches and offer additional insights\non addressing multiple newly formulated biases.", "published": "2023-10-25 16:11:55", "link": "http://arxiv.org/abs/2310.16738v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in\n  Indo-European Languages", "abstract": "Disfluency correction (DC) is the process of removing disfluent elements like\nfillers, repetitions and corrections from spoken utterances to create readable\nand interpretable text. DC is a vital post-processing step applied to Automatic\nSpeech Recognition (ASR) outputs, before subsequent processing by downstream\nlanguage understanding tasks. Existing DC research has primarily focused on\nEnglish due to the unavailability of large-scale open-source datasets. Towards\nthe goal of multilingual disfluency correction, we present a high-quality\nhuman-annotated DC corpus covering four important Indo-European languages:\nEnglish, Hindi, German and French. We provide extensive analysis of results of\nstate-of-the-art DC models across all four languages obtaining F1 scores of\n97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French). To\ndemonstrate the benefits of DC on downstream tasks, we show that DC leads to\n5.65 points increase in BLEU scores on average when used in conjunction with a\nstate-of-the-art Machine Translation (MT) system. We release code to run our\nexperiments along with our annotated dataset here.", "published": "2023-10-25 16:32:02", "link": "http://arxiv.org/abs/2310.16749v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning\n  in Large Language Models", "abstract": "Theory of Mind (ToM) is the ability to reason about one's own and others'\nmental states. ToM plays a critical role in the development of intelligence,\nlanguage understanding, and cognitive processes. While previous work has\nprimarily focused on first and second-order ToM, we explore higher-order ToM,\nwhich involves recursive reasoning on others' beliefs. We introduce HI-TOM, a\nHigher Order Theory of Mind benchmark. Our experimental evaluation using\nvarious Large Language Models (LLMs) indicates a decline in performance on\nhigher-order ToM tasks, demonstrating the limitations of current LLMs. We\nconduct a thorough analysis of different failure cases of LLMs, and share our\nthoughts on the implications of our findings on the future of NLP.", "published": "2023-10-25 16:41:15", "link": "http://arxiv.org/abs/2310.16755v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DEFT: Data Efficient Fine-Tuning for Pre-Trained Language Models via\n  Unsupervised Core-Set Selection", "abstract": "Recent advances have led to the availability of many pre-trained language\nmodels (PLMs); however, a question that remains is how much data is truly\nneeded to fine-tune PLMs for downstream tasks? In this work, we introduce\nDEFT-UCS, a data-efficient fine-tuning framework that leverages unsupervised\ncore-set selection to identify a smaller, representative dataset that reduces\nthe amount of data needed to fine-tune PLMs for downstream tasks. We examine\nthe efficacy of DEFT-UCS in the context of text-editing LMs, and compare to the\nstate-of-the art text-editing model, CoEDIT. Our results demonstrate that\nDEFT-UCS models are just as accurate as CoEDIT, across eight different datasets\nconsisting of six different editing tasks, while finetuned on 70% less data.", "published": "2023-10-25 17:06:42", "link": "http://arxiv.org/abs/2310.16776v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Agnostic Code Embeddings", "abstract": "Recently, code language models have achieved notable advancements in\naddressing a diverse array of essential code comprehension and generation\ntasks. Yet, the field lacks a comprehensive deep dive and understanding of the\ncode embeddings of multilingual code models. In this paper, we present a\ncomprehensive study on multilingual code embeddings, focusing on the\ncross-lingual capabilities of these embeddings across different programming\nlanguages. Through probing experiments, we demonstrate that code embeddings\ncomprise two distinct components: one deeply tied to the nuances and syntax of\na specific language, and the other remaining agnostic to these details,\nprimarily focusing on semantics. Further, we show that when we isolate and\neliminate this language-specific component, we witness significant improvements\nin downstream code retrieval tasks, leading to an absolute increase of up to\n+17 in the Mean Reciprocal Rank (MRR).", "published": "2023-10-25 17:34:52", "link": "http://arxiv.org/abs/2310.16803v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can GPT models Follow Human Summarization Guidelines? A Study for\n  Targeted Communication Goals", "abstract": "This study investigates the ability of GPT models (ChatGPT, GPT-4 and GPT-4o)\nto generate dialogue summaries that adhere to human guidelines. Our evaluation\ninvolved experimenting with various prompts to guide the models in complying\nwith guidelines on two datasets: DialogSum (English social conversations) and\nDECODA (French call center interactions). Human evaluation, based on\nsummarization guidelines, served as the primary assessment method, complemented\nby extensive quantitative and qualitative analyses. Our findings reveal a\npreference for GPT-generated summaries over those from task-specific\npre-trained models and reference summaries, highlighting GPT models' ability to\nfollow human guidelines despite occasionally producing longer outputs and\nexhibiting divergent lexical and structural alignment with references. The\ndiscrepancy between ROUGE, BERTScore, and human evaluation underscores the need\nfor more reliable automatic evaluation metrics.", "published": "2023-10-25 17:39:07", "link": "http://arxiv.org/abs/2310.16810v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Physician Detection of Clinical Harm in Machine Translation: Quality\n  Estimation Aids in Reliance and Backtranslation Identifies Critical Errors", "abstract": "A major challenge in the practical use of Machine Translation (MT) is that\nusers lack guidance to make informed decisions about when to rely on outputs.\nProgress in quality estimation research provides techniques to automatically\nassess MT quality, but these techniques have primarily been evaluated in vitro\nby comparison against human judgments outside of a specific context of use.\nThis paper evaluates quality estimation feedback in vivo with a human study\nsimulating decision-making in high-stakes medical settings. Using Emergency\nDepartment discharge instructions, we study how interventions based on quality\nestimation versus backtranslation assist physicians in deciding whether to show\nMT outputs to a patient. We find that quality estimation improves appropriate\nreliance on MT, but backtranslation helps physicians detect more clinically\nharmful errors that QE alone often misses.", "published": "2023-10-25 18:44:14", "link": "http://arxiv.org/abs/2310.16924v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CL-MASR: A Continual Learning Benchmark for Multilingual ASR", "abstract": "Modern multilingual automatic speech recognition (ASR) systems like Whisper\nhave made it possible to transcribe audio in multiple languages with a single\nmodel. However, current state-of-the-art ASR models are typically evaluated on\nindividual languages or in a multi-task setting, overlooking the challenge of\ncontinually learning new languages. There is insufficient research on how to\nadd new languages without losing valuable information from previous data.\nFurthermore, existing continual learning benchmarks focus mostly on vision and\nlanguage tasks, leaving continual learning for multilingual ASR largely\nunexplored. To bridge this gap, we propose CL-MASR, a benchmark designed for\nstudying multilingual ASR in a continual learning setting. CL-MASR provides a\ndiverse set of continual learning methods implemented on top of large-scale\npretrained ASR models, along with common metrics to assess the effectiveness of\nlearning new languages while addressing the issue of catastrophic forgetting.\nTo the best of our knowledge, CL-MASR is the first continual learning benchmark\nfor the multilingual ASR task. The code is available at\nhttps://github.com/speechbrain/benchmarks.", "published": "2023-10-25 18:55:40", "link": "http://arxiv.org/abs/2310.16931v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zephyr: Direct Distillation of LM Alignment", "abstract": "We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.", "published": "2023-10-25 19:25:16", "link": "http://arxiv.org/abs/2310.16944v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Understanding Social Structures from Contemporary Literary Fiction using\n  Character Interaction Graph -- Half Century Chronology of Influential Bengali\n  Writers", "abstract": "Social structures and real-world incidents often influence contemporary\nliterary fiction. Existing research in literary fiction analysis explains these\nreal-world phenomena through the manual critical analysis of stories.\nConventional Natural Language Processing (NLP) methodologies, including\nsentiment analysis, narrative summarization, and topic modeling, have\ndemonstrated substantial efficacy in analyzing and identifying similarities\nwithin fictional works. However, the intricate dynamics of character\ninteractions within fiction necessitate a more nuanced approach that\nincorporates visualization techniques. Character interaction graphs (or\nnetworks) emerge as a highly suitable means for visualization and information\nretrieval from the realm of fiction. Therefore, we leverage character\ninteraction graphs with NLP-derived features to explore a diverse spectrum of\nsocietal inquiries about contemporary culture's impact on the landscape of\nliterary fiction. Our study involves constructing character interaction graphs\nfrom fiction, extracting relevant graph features, and exploiting these features\nto resolve various real-life queries. Experimental evaluation of influential\nBengali fiction over half a century demonstrates that character interaction\ngraphs can be highly effective in specific assessments and information\nretrieval from literary fiction. Our data and codebase are available at\nhttps://cutt.ly/fbMgGEM", "published": "2023-10-25 20:09:14", "link": "http://arxiv.org/abs/2310.16968v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "This Reads Like That: Deep Learning for Interpretable Natural Language\n  Processing", "abstract": "Prototype learning, a popular machine learning method designed for inherently\ninterpretable decisions, leverages similarities to learned prototypes for\nclassifying new data. While it is mainly applied in computer vision, in this\nwork, we build upon prior research and further explore the extension of\nprototypical networks to natural language processing. We introduce a learned\nweighted similarity measure that enhances the similarity computation by\nfocusing on informative dimensions of pre-trained sentence embeddings.\nAdditionally, we propose a post-hoc explainability mechanism that extracts\nprediction-relevant words from both the prototype and input sentences. Finally,\nwe empirically demonstrate that our proposed method not only improves\npredictive performance on the AG News and RT Polarity datasets over a previous\nprototype-based approach, but also improves the faithfulness of explanations\ncompared to rationale-based recurrent convolutions.", "published": "2023-10-25 21:18:35", "link": "http://arxiv.org/abs/2310.17010v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Integrative Survey on Mental Health Conversational Agents to Bridge\n  Computer Science and Medical Perspectives", "abstract": "Mental health conversational agents (a.k.a. chatbots) are widely studied for\ntheir potential to offer accessible support to those experiencing mental health\nchallenges. Previous surveys on the topic primarily consider papers published\nin either computer science or medicine, leading to a divide in understanding\nand hindering the sharing of beneficial knowledge between both domains. To\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\nframework, reviewing 534 papers published in both computer science and\nmedicine. Our systematic review reveals 136 key papers on building mental\nhealth-related conversational agents with diverse characteristics of modeling\nand experimental design techniques. We find that computer science papers focus\non LLM techniques and evaluating response quality using automated metrics with\nlittle attention to the application while medical papers use rule-based\nconversational agents and outcome metrics to measure the health outcomes of\nparticipants. Based on our findings on transparency, ethics, and cultural\nheterogeneity in this review, we provide a few recommendations to help bridge\nthe disciplinary divide and enable the cross-disciplinary development of mental\nhealth conversational agents.", "published": "2023-10-25 21:37:57", "link": "http://arxiv.org/abs/2310.17017v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs'\n  Generation", "abstract": "Large language models (LLMs) such as GPT-3 have demonstrated a strong\ncapability to generate coherent and contextually relevant text. However, amidst\ntheir successes, a crucial issue persists: their generated outputs still lack\ncommonsense at times. Moreover, fine-tuning the entire LLM towards more\ncommonsensical outputs is computationally expensive if not infeasible. In this\npaper, we present a computation-efficient framework that steers a frozen\nPre-Trained Language Model (PTLM) towards more commonsensical generation (i.e.,\nproducing a plausible output that incorporates a list of concepts in a\nmeaningful way). Specifically, we first construct a reference-free evaluator\nthat assigns a sentence with a commonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base from four different relational aspects.\nWe then use the scorer as the oracle for commonsense knowledge, and extend the\ncontrollable generation method called NADO to train an auxiliary head that\nguides a fixed PTLM to better satisfy the oracle. We test our framework on a\nseries of GPT-2-, Flan-T5-, and Alpaca-based language models (LMs) on two\nconstrained concept-to-sentence benchmarks. Human evaluation results\ndemonstrate that our method consistently leads to the most commonsensical\noutputs.", "published": "2023-10-25 23:32:12", "link": "http://arxiv.org/abs/2310.17054v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Language Models for Secure Code Generation: A\n  Dataset-driven Study on Vulnerability Mitigation", "abstract": "Large language models (LLMs) have brought significant advancements to code\ngeneration, benefiting both novice and experienced developers. However, their\ntraining using unsanitized data from open-source repositories, like GitHub,\nintroduces the risk of inadvertently propagating security vulnerabilities. To\neffectively mitigate this concern, this paper presents a comprehensive study\nfocused on evaluating and enhancing code LLMs from a software security\nperspective. We introduce SecuCoGen\\footnote{SecuCoGen has been uploaded as\nsupplemental material and will be made publicly available after publication.},\na meticulously curated dataset targeting 21 critical vulnerability types.\nSecuCoGen comprises 180 samples and serves as the foundation for conducting\nexperiments on three crucial code-related tasks: code generation, code repair\nand vulnerability classification, with a strong emphasis on security. Our\nexperimental results reveal that existing models often overlook security\nconcerns during code generation, leading to the generation of vulnerable code.\nTo address this, we propose effective approaches to mitigate the security\nvulnerabilities and enhance the overall robustness of code generated by LLMs.\nMoreover, our study identifies weaknesses in existing models' ability to repair\nvulnerable code, even when provided with vulnerability information.\nAdditionally, certain vulnerability types pose challenges for the models,\nhindering their performance in vulnerability classification. Based on these\nfindings, we believe our study will have a positive impact on the software\nengineering community, inspiring the development of improved methods for\ntraining and utilizing LLMs, thereby leading to safer and more trustworthy\nmodel deployment.", "published": "2023-10-25 00:32:56", "link": "http://arxiv.org/abs/2310.16263v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.SE"}
{"title": "Multilingual Coarse Political Stance Classification of Media. The\n  Editorial Line of a ChatGPT and Bard Newspaper", "abstract": "Neutrality is difficult to achieve and, in politics, subjective. Traditional\nmedia typically adopt an editorial line that can be used by their potential\nreaders as an indicator of the media bias. Several platforms currently rate\nnews outlets according to their political bias. The editorial line and the\nratings help readers in gathering a balanced view of news. But in the advent of\ninstruction-following language models, tasks such as writing a newspaper\narticle can be delegated to computers. Without imposing a biased persona, where\nwould an AI-based news outlet lie within the bias ratings? In this work, we use\nthe ratings of authentic news outlets to create a multilingual corpus of news\nwith coarse stance annotations (Left and Right) along with automatically\nextracted topic annotations. We show that classifiers trained on this data are\nable to identify the editorial line of most unseen newspapers in English,\nGerman, Spanish and Catalan. We then apply the classifiers to 101\nnewspaper-like articles written by ChatGPT and Bard in the 4 languages at\ndifferent time periods. We observe that, similarly to traditional newspapers,\nChatGPT editorial line evolves with time and, being a data-driven system, the\nstance of the generated articles differs among languages.", "published": "2023-10-25 01:01:28", "link": "http://arxiv.org/abs/2310.16269v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Attention Lens: A Tool for Mechanistically Interpreting the Attention\n  Head Information Retrieval Mechanism", "abstract": "Transformer-based Large Language Models (LLMs) are the state-of-the-art for\nnatural language tasks. Recent work has attempted to decode, by reverse\nengineering the role of linear layers, the internal mechanisms by which LLMs\narrive at their final predictions for text completion tasks. Yet little is\nknown about the specific role of attention heads in producing the final token\nprediction. We propose Attention Lens, a tool that enables researchers to\ntranslate the outputs of attention heads into vocabulary tokens via learned\nattention-head-specific transformations called lenses. Preliminary findings\nfrom our trained lenses indicate that attention heads play highly specialized\nroles in language models. The code for Attention Lens is available at\ngithub.com/msakarvadia/AttentionLens.", "published": "2023-10-25 01:03:35", "link": "http://arxiv.org/abs/2310.16270v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment\n  of Coherence in Generated Texts", "abstract": "Coherence is a linguistic term that refers to the relations between small\ntextual units (sentences, propositions), which make the text logically\nconsistent and meaningful to the reader. With the advances of generative\nfoundational models in NLP, there is a pressing need to automatically assess\nthe human-perceived coherence of automatically generated texts. Up until now,\nlittle work has been done on explicitly assessing the coherence of generated\ntexts and analyzing the factors contributing to (in)coherence. Previous work on\nthe topic used other tasks, e.g., sentence reordering, as proxies of coherence,\nrather than approaching coherence detection heads on. In this paper, we\nintroduce {\\sc CoheSentia}, a novel benchmark of human-perceived coherence of\nautomatically generated texts. Our annotation protocol reflects two\nperspectives; one is global, assigning a single coherence score, and the other\nis incremental, scoring sentence by sentence. The incremental method produces\nan (in)coherence score for each text fragment and also pinpoints reasons for\nincoherence at that point. Our benchmark contains 500 automatically-generated\nand human-annotated paragraphs, each annotated in both methods, by multiple\nraters. Our analysis shows that the inter-annotator agreement in the\nincremental mode is higher than in the holistic alternative, and our\nexperiments show that standard LMs fine-tuned for coherence detection show\nvaried performance on the different factors contributing to (in)coherence. All\nin all, these models yield unsatisfactory performance, emphasizing the need for\ndeveloping more reliable methods for coherence assessment.", "published": "2023-10-25 03:21:20", "link": "http://arxiv.org/abs/2310.16329v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Generative Pre-training for Speech with Flow Matching", "abstract": "Generative models have gained more and more attention in recent years for\ntheir remarkable success in tasks that required estimating and sampling data\ndistribution to generate high-fidelity synthetic data. In speech,\ntext-to-speech synthesis and neural vocoder are good examples where generative\nmodels have shined. While generative models have been applied to different\napplications in speech, there exists no general-purpose generative model that\nmodels speech directly. In this work, we take a step toward this direction by\nshowing a single pre-trained generative model can be adapted to different\ndownstream tasks with strong performance. Specifically, we pre-trained a\ngenerative model, named SpeechFlow, on 60k hours of untranscribed speech with\nFlow Matching and masked conditions. Experiment results show the pre-trained\ngenerative model can be fine-tuned with task-specific data to match or surpass\nexisting expert models on speech enhancement, separation, and synthesis. Our\nwork suggested a foundational model for generation tasks in speech can be built\nwith generative pre-training.", "published": "2023-10-25 03:40:50", "link": "http://arxiv.org/abs/2310.16338v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic\n  Expressions on Smartphones via Federated Learning", "abstract": "Psychiatrists diagnose mental disorders via the linguistic use of patients.\nStill, due to data privacy, existing passive mental health monitoring systems\nuse alternative features such as activity, app usage, and location via mobile\ndevices. We propose FedTherapist, a mobile mental health monitoring system that\nutilizes continuous speech and keyboard input in a privacy-preserving way via\nfederated learning. We explore multiple model designs by comparing their\nperformance and overhead for FedTherapist to overcome the complex nature of\non-device language model training on smartphones. We further propose a\nContext-Aware Language Learning (CALL) methodology to effectively utilize\nsmartphones' large and noisy text for mental health signal sensing. Our\nIRB-approved evaluation of the prediction of self-reported depression, stress,\nanxiety, and mood from 46 participants shows higher accuracy of FedTherapist\ncompared with the performance with non-language features, achieving 0.15 AUROC\nimprovement and 8.21% MAE reduction.", "published": "2023-10-25 10:35:09", "link": "http://arxiv.org/abs/2310.16538v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Back Transcription as a Method for Evaluating Robustness of Natural\n  Language Understanding Models to Speech Recognition Errors", "abstract": "In a spoken dialogue system, an NLU model is preceded by a speech recognition\nsystem that can deteriorate the performance of natural language understanding.\nThis paper proposes a method for investigating the impact of speech recognition\nerrors on the performance of natural language understanding models. The\nproposed method combines the back transcription procedure with a fine-grained\ntechnique for categorizing the errors that affect the performance of NLU\nmodels. The method relies on the usage of synthesized speech for NLU\nevaluation. We show that the use of synthesized speech in place of audio\nrecording does not change the outcomes of the presented technique in a\nsignificant way.", "published": "2023-10-25 13:07:07", "link": "http://arxiv.org/abs/2310.16609v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ArTST: Arabic Text and Speech Transformer", "abstract": "We present ArTST, a pre-trained Arabic text and speech transformer for\nsupporting open-source speech technologies for the Arabic language. The model\narchitecture follows the unified-modal framework, SpeechT5, that was recently\nreleased for English, and is focused on Modern Standard Arabic (MSA), with\nplans to extend the model for dialectal and code-switched Arabic in future\neditions. We pre-trained the model from scratch on MSA speech and text data,\nand fine-tuned it for the following tasks: Automatic Speech Recognition (ASR),\nText-To-Speech synthesis (TTS), and spoken dialect identification. In our\nexperiments comparing ArTST with SpeechT5, as well as with previously reported\nresults in these tasks, ArTST performs on a par with or exceeding the current\nstate-of-the-art in all three tasks. Moreover, we find that our pre-training is\nconducive for generalization, which is particularly evident in the low-resource\nTTS task. The pre-trained model as well as the fine-tuned ASR and TTS models\nare released for research use.", "published": "2023-10-25 13:20:54", "link": "http://arxiv.org/abs/2310.16621v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PROMINET: Prototype-based Multi-View Network for Interpretable Email\n  Response Prediction", "abstract": "Email is a widely used tool for business communication, and email marketing\nhas emerged as a cost-effective strategy for enterprises. While previous\nstudies have examined factors affecting email marketing performance, limited\nresearch has focused on understanding email response behavior by considering\nemail content and metadata. This study proposes a Prototype-based Multi-view\nNetwork (PROMINET) that incorporates semantic and structural information from\nemail data. By utilizing prototype learning, the PROMINET model generates\nlatent exemplars, enabling interpretable email response prediction. The model\nmaps learned semantic and structural exemplars to observed samples in the\ntraining data at different levels of granularity, such as document, sentence,\nor phrase. The approach is evaluated on two real-world email datasets: the\nEnron corpus and an in-house Email Marketing corpus. Experimental results\ndemonstrate that the PROMINET model outperforms baseline models, achieving a\n~3% improvement in F1 score on both datasets. Additionally, the model provides\ninterpretability through prototypes at different granularity levels while\nmaintaining comparable performance to non-interpretable models. The learned\nprototypes also show potential for generating suggestions to enhance email text\nediting and improve the likelihood of effective email responses. This research\ncontributes to enhancing sender-receiver communication and customer engagement\nin email interactions.", "published": "2023-10-25 16:39:00", "link": "http://arxiv.org/abs/2310.16753v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SuperHF: Supervised Iterative Learning from Human Feedback", "abstract": "While large language models demonstrate remarkable capabilities, they often\npresent challenges in terms of safety, alignment with human values, and\nstability during training. Here, we focus on two prevalent methods used to\nalign these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning\nfrom Human Feedback (RLHF). SFT is simple and robust, powering a host of\nopen-source models, while RLHF is a more sophisticated method used in top-tier\nmodels like ChatGPT but also suffers from instability and susceptibility to\nreward hacking. We propose a novel approach, Supervised Iterative Learning from\nHuman Feedback (SuperHF), which seeks to leverage the strengths of both\nmethods. Our hypothesis is two-fold: that the reward model used in RLHF is\ncritical for efficient data use and model generalization and that the use of\nProximal Policy Optimization (PPO) in RLHF may not be necessary and could\ncontribute to instability issues. SuperHF replaces PPO with a simple supervised\nloss and a Kullback-Leibler (KL) divergence prior. It creates its own training\ndata by repeatedly sampling a batch of model outputs and filtering them through\nthe reward model in an online learning regime. We then break down the reward\noptimization problem into three components: robustly optimizing the training\nrewards themselves, preventing reward hacking-exploitation of the reward model\nthat degrades model performance-as measured by a novel METEOR similarity\nmetric, and maintaining good performance on downstream evaluations. Our\nexperimental results show SuperHF exceeds PPO-based RLHF on the training\nobjective, easily and favorably trades off high reward with low reward hacking,\nimproves downstream calibration, and performs the same on our GPT-4 based\nqualitative evaluation scheme all the while being significantly simpler to\nimplement, highlighting SuperHF's potential as a competitive language model\nalignment technique.", "published": "2023-10-25 16:52:00", "link": "http://arxiv.org/abs/2310.16763v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models", "abstract": "Although the mapping between sound and meaning in human language is assumed\nto be largely arbitrary, research in cognitive science has shown that there are\nnon-trivial correlations between particular sounds and meanings across\nlanguages and demographic groups, a phenomenon known as sound symbolism. Among\nthe many dimensions of meaning, sound symbolism is particularly salient and\nwell-demonstrated with regards to cross-modal associations between language and\nthe visual domain. In this work, we address the question of whether sound\nsymbolism is reflected in vision-and-language models such as CLIP and Stable\nDiffusion. Using zero-shot knowledge probing to investigate the inherent\nknowledge of these models, we find strong evidence that they do show this\npattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our\nwork provides a novel method for demonstrating sound symbolism and\nunderstanding its nature using computational tools. Our code will be made\npublicly available.", "published": "2023-10-25 17:15:55", "link": "http://arxiv.org/abs/2310.16781v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing\n  & Attribution in AI", "abstract": "The race to train language models on vast, diverse, and inconsistently\ndocumented datasets has raised pressing concerns about the legal and ethical\nrisks for practitioners. To remedy these practices threatening data\ntransparency and understanding, we convene a multi-disciplinary effort between\nlegal and machine learning experts to systematically audit and trace 1800+ text\ndatasets. We develop tools and standards to trace the lineage of these\ndatasets, from their source, creators, series of license conditions,\nproperties, and subsequent use. Our landscape analysis highlights the sharp\ndivides in composition and focus of commercially open vs closed datasets, with\nclosed datasets monopolizing important categories: lower resource languages,\nmore creative tasks, richer topic variety, newer and more synthetic training\ndata. This points to a deepening divide in the types of data that are made\navailable under different license conditions, and heightened implications for\njurisdictional legal interpretations of copyright and fair use. We also observe\nfrequent miscategorization of licenses on widely used dataset hosting sites,\nwith license omission of 70%+ and error rates of 50%+. This points to a crisis\nin misattribution and informed use of the most popular datasets driving many\nrecent breakthroughs. As a contribution to ongoing improvements in dataset\ntransparency and responsible use, we release our entire audit, with an\ninteractive UI, the Data Provenance Explorer, which allows practitioners to\ntrace and filter on data provenance for the most popular open source finetuning\ndata collections: www.dataprovenance.org.", "published": "2023-10-25 17:20:26", "link": "http://arxiv.org/abs/2310.16787v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Pretraining Data from Large Language Models", "abstract": "Although large language models (LLMs) are widely deployed, the data used to\ntrain them is rarely disclosed. Given the incredible scale of this data, up to\ntrillions of tokens, it is all but certain that it includes potentially\nproblematic text such as copyrighted materials, personally identifiable\ninformation, and test data for widely reported reference benchmarks. However,\nwe currently have no way to know which data of these types is included or in\nwhat proportions. In this paper, we study the pretraining data detection\nproblem: given a piece of text and black-box access to an LLM without knowing\nthe pretraining data, can we determine if the model was trained on the provided\ntext? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that\nuses data created before and after model training to support gold truth\ndetection. We also introduce a new detection method Min-K% Prob based on a\nsimple hypothesis: an unseen example is likely to contain a few outlier words\nwith low probabilities under the LLM, while a seen example is less likely to\nhave words with such low probabilities. Min-K% Prob can be applied without any\nknowledge about the pretraining corpus or any additional training, departing\nfrom previous detection methods that require training a reference model on data\nthat is similar to the pretraining data. Moreover, our experiments demonstrate\nthat Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous\nmethods. We apply Min-K% Prob to three real-world scenarios, copyrighted book\ndetection, contaminated downstream example detection and privacy auditing of\nmachine unlearning, and find it a consistently effective solution.", "published": "2023-10-25 17:21:23", "link": "http://arxiv.org/abs/2310.16789v3", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving a Named Entity Recognizer Trained on Noisy Data with a Few\n  Clean Instances", "abstract": "To achieve state-of-the-art performance, one still needs to train NER models\non large-scale, high-quality annotated data, an asset that is both costly and\ntime-intensive to accumulate. In contrast, real-world applications often resort\nto massive low-quality labeled data through non-expert annotators via\ncrowdsourcing and external knowledge bases via distant supervision as a\ncost-effective alternative. However, these annotation methods result in noisy\nlabels, which in turn lead to a notable decline in performance. Hence, we\npropose to denoise the noisy NER data with guidance from a small set of clean\ninstances. Along with the main NER model we train a discriminator model and use\nits outputs to recalibrate the sample weights. The discriminator is capable of\ndetecting both span and category errors with different discriminative prompts.\nResults on public crowdsourcing and distant supervision datasets show that the\nproposed method can consistently improve performance with a small guidance set.", "published": "2023-10-25 17:23:37", "link": "http://arxiv.org/abs/2310.16790v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prompt Me Up: Unleashing the Power of Alignments for Multimodal Entity\n  and Relation Extraction", "abstract": "How can we better extract entities and relations from text? Using multimodal\nextraction with images and text obtains more signals for entities and\nrelations, and aligns them through graphs or hierarchical fusion, aiding in\nextraction. Despite attempts at various fusions, previous works have overlooked\nmany unlabeled image-caption pairs, such as NewsCLIPing. This paper proposes\ninnovative pre-training objectives for entity-object and relation-image\nalignment, extracting objects from images and aligning them with entity and\nrelation prompts for soft pseudo-labels. These labels are used as\nself-supervised signals for pre-training, enhancing the ability to extract\nentities and relations. Experiments on three datasets show an average 3.41% F1\nimprovement over prior SOTA. Additionally, our method is orthogonal to previous\nmultimodal fusions, and using it on prior SOTA fusions further improves 5.47%\nF1.", "published": "2023-10-25 17:51:56", "link": "http://arxiv.org/abs/2310.16822v1", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Discrete Diffusion Modeling by Estimating the Ratios of the Data\n  Distribution", "abstract": "Despite their groundbreaking performance for many generative modeling tasks,\ndiffusion models have fallen short on discrete data domains such as natural\nlanguage. Crucially, standard diffusion models rely on the well-established\ntheory of score matching, but efforts to generalize this to discrete structures\nhave not yielded the same empirical gains. In this work, we bridge this gap by\nproposing score entropy, a novel loss that naturally extends score matching to\ndiscrete spaces, integrates seamlessly to build discrete diffusion models, and\nsignificantly boosts performance. Experimentally, we test our Score Entropy\nDiscrete Diffusion models (SEDD) on standard language modeling tasks. For\ncomparable model sizes, SEDD beats existing language diffusion paradigms\n(reducing perplexity by $25$-$75$\\%) and is competitive with autoregressive\nmodels, in particular outperforming GPT-2. Furthermore, compared to\nautoregressive mdoels, SEDD generates faithful text without requiring\ndistribution annealing techniques like temperature scaling (around\n$6$-$8\\times$ better generative perplexity than un-annealed GPT-2), can trade\ncompute and quality (similar quality with $32\\times$ fewer network\nevaluations), and enables controllable infilling (matching nucleus sampling\nquality while enabling other strategies besides left to right prompting).", "published": "2023-10-25 17:59:12", "link": "http://arxiv.org/abs/2310.16834v3", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "LLM-FP4: 4-Bit Floating-Point Quantized Transformers", "abstract": "We propose LLM-FP4 for quantizing both weights and activations in large\nlanguage models (LLMs) down to 4-bit floating-point values, in a post-training\nmanner. Existing post-training quantization (PTQ) solutions are primarily\ninteger-based and struggle with bit widths below 8 bits. Compared to integer\nquantization, floating-point (FP) quantization is more flexible and can better\nhandle long-tail or bell-shaped distributions, and it has emerged as a default\nchoice in many hardware platforms. One characteristic of FP quantization is\nthat its performance largely depends on the choice of exponent bits and\nclipping range. In this regard, we construct a strong FP-PTQ baseline by\nsearching for the optimal quantization parameters. Furthermore, we observe a\nhigh inter-channel variance and low intra-channel variance pattern in\nactivation distributions, which adds activation quantization difficulty. We\nrecognize this pattern to be consistent across a spectrum of transformer models\ndesigned for diverse tasks, such as LLMs, BERT, and Vision Transformer models.\nTo tackle this, we propose per-channel activation quantization and show that\nthese additional scaling factors can be reparameterized as exponential biases\nof weights, incurring a negligible cost. Our method, for the first time, can\nquantize both weights and activations in the LLaMA-13B to only 4-bit and\nachieves an average score of 63.1 on the common sense zero-shot reasoning\ntasks, which is only 5.8 lower than the full-precision model, significantly\noutperforming the previous state-of-the-art by 12.7 points. Code is available\nat: https://github.com/nbasyl/LLM-FP4.", "published": "2023-10-25 17:59:32", "link": "http://arxiv.org/abs/2310.16836v1", "categories": ["cs.CL", "cs.AI", "cs.AR", "cs.CV"], "primary_category": "cs.CL"}
{"title": "STEER: Semantic Turn Extension-Expansion Recognition for Voice\n  Assistants", "abstract": "In the context of a voice assistant system, steering refers to the phenomenon\nin which a user issues a follow-up command attempting to direct or clarify a\nprevious turn. We propose STEER, a steering detection model that predicts\nwhether a follow-up turn is a user's attempt to steer the previous command.\nConstructing a training dataset for steering use cases poses challenges due to\nthe cold-start problem. To overcome this, we developed heuristic rules to\nsample opt-in usage data, approximating positive and negative samples without\nany annotation. Our experimental results show promising performance in\nidentifying steering intent, with over 95% accuracy on our sampled data.\nMoreover, STEER, in conjunction with our sampling strategy, aligns effectively\nwith real-world steering scenarios, as evidenced by its strong zero-shot\nperformance on a human-graded evaluation set. In addition to relying solely on\nuser transcripts as input, we introduce STEER+, an enhanced version of the\nmodel. STEER+ utilizes a semantic parse tree to provide more context on\nout-of-vocabulary words, such as named entities that often occur at the\nsentence boundary. This further improves model performance, reducing error rate\nin domains where entities frequently appear, such as messaging. Lastly, we\npresent a data analysis that highlights the improvement in user experience when\nvoice assistants support steering use cases.", "published": "2023-10-25 20:41:30", "link": "http://arxiv.org/abs/2310.16990v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conditionally Combining Robot Skills using Large Language Models", "abstract": "This paper combines two contributions. First, we introduce an extension of\nthe Meta-World benchmark, which we call \"Language-World,\" which allows a large\nlanguage model to operate in a simulated robotic environment using\nsemi-structured natural language queries and scripted skills described using\nnatural language. By using the same set of tasks as Meta-World, Language-World\nresults can be easily compared to Meta-World results, allowing for a point of\ncomparison between recent methods using Large Language Models (LLMs) and those\nusing Deep Reinforcement Learning. Second, we introduce a method we call Plan\nConditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of\nhigh-level plans using end-to-end demonstrations. Using Language-World, we show\nthat PCBC is able to achieve strong performance in a variety of few-shot\nregimes, often achieving task generalization with as little as a single\ndemonstration. We have made Language-World available as open-source software at\nhttps://github.com/krzentner/language-world/.", "published": "2023-10-25 21:46:34", "link": "http://arxiv.org/abs/2310.17019v1", "categories": ["cs.LG", "cs.CL", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Controlled Decoding from Language Models", "abstract": "KL-regularized reinforcement learning (RL) is a popular alignment framework\nto control the language model responses towards high reward outcomes. We pose a\ntokenwise RL objective and propose a modular solver for it, called controlled\ndecoding (CD). CD exerts control through a separate prefix scorer module, which\nis trained to learn a value function for the reward. The prefix scorer is used\nat inference time to control the generation from a frozen base model, provably\nsampling from a solution to the RL objective. We empirically demonstrate that\nCD is effective as a control mechanism on popular benchmarks. We also show that\nprefix scorers for multiple rewards may be combined at inference time,\neffectively solving a multi-objective RL problem with no additional training.\nWe show that the benefits of applying CD transfer to an unseen base model with\nno further tuning as well. Finally, we show that CD can be applied in a\nblockwise decoding fashion at inference-time, essentially bridging the gap\nbetween the popular best-of-K strategy and tokenwise control through\nreinforcement learning. This makes CD a promising approach for alignment of\nlanguage models.", "published": "2023-10-25 22:00:05", "link": "http://arxiv.org/abs/2310.17022v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On Surgical Fine-tuning for Language Encoders", "abstract": "Fine-tuning all the layers of a pre-trained neural language encoder (either\nusing all the parameters or using parameter-efficient methods) is often the\nde-facto way of adapting it to a new task. We show evidence that for different\ndownstream language tasks, fine-tuning only a subset of layers is sufficient to\nobtain performance that is close to and often better than fine-tuning all the\nlayers in the language encoder. We propose an efficient metric based on the\ndiagonal of the Fisher information matrix (FIM score), to select the candidate\nlayers for selective fine-tuning. We show, empirically on GLUE and SuperGLUE\ntasks and across distinct language encoders, that this metric can effectively\nselect layers leading to a strong downstream performance. Our work highlights\nthat task-specific information corresponding to a given downstream task is\noften localized within a few layers, and tuning only those is sufficient for\nstrong performance. Additionally, we demonstrate the robustness of the FIM\nscore to rank layers in a manner that remains constant during the optimization\nprocess.", "published": "2023-10-25 22:42:30", "link": "http://arxiv.org/abs/2310.17041v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories", "abstract": "As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.", "published": "2023-10-25 23:54:04", "link": "http://arxiv.org/abs/2310.17064v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring", "abstract": "Machine learning-based automatic scoring faces challenges with unbalanced\nstudent responses across scoring categories. To address this, we introduce a\nnovel text data augmentation framework leveraging GPT-4, a generative large\nlanguage model, specifically tailored for unbalanced datasets in automatic\nscoring. Our experimental dataset comprised student written responses to four\nscience items. We crafted prompts for GPT-4 to generate responses, especially\nfor minority scoring classes, enhancing the data set. We then finetuned\nDistillBERT for automatic scoring based on the augmented and original datasets.\nModel performance was assessed using accuracy, precision, recall, and F1\nmetrics. Our findings revealed that incorporating GPT-4-augmented data\nremarkedly improved model performance, particularly for precision and F1\nscores. Interestingly, the extent of improvement varied depending on the\nspecific dataset and the proportion of augmented data used. Notably, we found\nthat a varying amount of augmented data (20%-40%) was needed to obtain stable\nimprovement for automatic scoring. Comparisons with models trained on\nadditional student-written responses suggest that GPT-4 augmented models match\nthose trained with student data. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing generative large\nlanguage models like GPT-4 in addressing unbalanced datasets within automated\nassessment.", "published": "2023-10-25 01:07:50", "link": "http://arxiv.org/abs/2310.18365v3", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Multilingual Virtual Guide for Self-Attachment Technique", "abstract": "In this work, we propose a computational framework that leverages existing\nout-of-language data to create a conversational agent for the delivery of\nSelf-Attachment Technique (SAT) in Mandarin. Our framework does not require\nlarge-scale human translations, yet it achieves a comparable performance whilst\nalso maintaining safety and reliability. We propose two different methods of\naugmenting available response data through empathetic rewriting. We evaluate\nour chatbot against a previous, English-only SAT chatbot through non-clinical\nhuman trials (N=42), each lasting five days, and quantitatively show that we\nare able to attain a comparable level of performance to the English SAT\nchatbot. We provide qualitative analysis on the limitations of our study and\nsuggestions with the aim of guiding future improvements.", "published": "2023-10-25 10:50:18", "link": "http://arxiv.org/abs/2310.18366v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Apollo: Zero-shot MultiModal Reasoning with Multiple Experts", "abstract": "We propose a modular framework that leverages the expertise of different\nfoundation models over different modalities and domains in order to perform a\nsingle, complex, multi-modal task, without relying on prompt engineering or\notherwise tailor-made multi-modal training. Our approach enables decentralized\ncommand execution and allows each model to both contribute and benefit from the\nexpertise of the other models. Our method can be extended to a variety of\nfoundation models (including audio and vision), above and beyond only language\nmodels, as it does not depend on prompts. We demonstrate our approach on two\ntasks. On the well-known task of stylized image captioning, our experiments\nshow that our approach outperforms semi-supervised state-of-the-art models,\nwhile being zero-shot and avoiding costly training, data collection, and prompt\nengineering. We further demonstrate this method on a novel task, audio-aware\nimage captioning, in which an image and audio are given and the task is to\ngenerate text that describes the image within the context of the provided\naudio. Our code is available on GitHub.", "published": "2023-10-25 22:36:40", "link": "http://arxiv.org/abs/2310.18369v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.7; I.5.4"], "primary_category": "cs.CL"}
{"title": "LlamaRec: Two-Stage Recommendation using Large Language Models for\n  Ranking", "abstract": "Recently, large language models (LLMs) have exhibited significant progress in\nlanguage understanding and generation. By leveraging textual features,\ncustomized LLMs are also applied for recommendation and demonstrate\nimprovements across diverse recommendation scenarios. Yet the majority of\nexisting methods perform training-free recommendation that heavily relies on\npretrained knowledge (e.g., movie recommendation). In addition, inference on\nLLMs is slow due to autoregressive generation, rendering existing methods less\neffective for real-time recommendation. As such, we propose a two-stage\nframework using large language models for ranking-based recommendation\n(LlamaRec). In particular, we use small-scale sequential recommenders to\nretrieve candidates based on the user interaction history. Then, both history\nand retrieved items are fed to the LLM in text via a carefully designed prompt\ntemplate. Instead of generating next-item titles, we adopt a verbalizer-based\napproach that transforms output logits into probability distributions over the\ncandidate items. Therefore, the proposed LlamaRec can efficiently rank items\nwithout generating long text. To validate the effectiveness of the proposed\nframework, we compare against state-of-the-art baseline methods on benchmark\ndatasets. Our experimental results demonstrate the performance of LlamaRec,\nwhich consistently achieves superior performance in both recommendation\nperformance and efficiency.", "published": "2023-10-25 06:23:48", "link": "http://arxiv.org/abs/2311.02089v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Covariance Blocking and Whitening Method for Successive Relative\n  Transfer Function Vector Estimation in Multi-Speaker Scenarios", "abstract": "This paper addresses the challenge of estimating the relative transfer\nfunction (RTF) vectors of multiple speakers in a noisy and reverberant\nenvironment. More specifically, we consider a scenario where two speakers\nactivate successively. In this scenario, the RTF vector of the first speaker\ncan be estimated in a straightforward way and the main challenge lies in\nestimating the RTF vector of the second speaker during segments where both\nspeakers are simultaneously active. To estimate the RTF vector of the second\nspeaker the so-called blind oblique projection (BOP) method determines the\noblique projection operator that optimally blocks the second speaker. Instead\nof blocking the second speaker, in this paper we propose a covariance blocking\nand whitening (CBW) method, which first blocks the first speaker and applies\nwhitening using the estimated noise covariance matrix and then estimates the\nRTF vector of the second speaker based on a singular value decomposition. When\nusing the estimated RTF vectors of both speakers in a linearly constrained\nminimum variance beamformer, simulation results using real-world recordings for\nmultiple speaker positions demonstrate that the proposed CBW method outperforms\nthe conventional BOP and covariance whitening methods in terms of\nsignal-to-interferer-and-noise ratio improvement.", "published": "2023-10-25 03:19:08", "link": "http://arxiv.org/abs/2310.16327v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UniX-Encoder: A Universal $X$-Channel Speech Encoder for Ad-Hoc\n  Microphone Array Speech Processing", "abstract": "The speech field is evolving to solve more challenging scenarios, such as\nmulti-channel recordings with multiple simultaneous talkers. Given the many\ntypes of microphone setups out there, we present the UniX-Encoder. It's a\nuniversal encoder designed for multiple tasks, and worked with any microphone\narray, in both solo and multi-talker environments. Our research enhances\nprevious multi-channel speech processing efforts in four key areas: 1)\nAdaptability: Contrasting traditional models constrained to certain microphone\narray configurations, our encoder is universally compatible. 2) Multi-Task\nCapability: Beyond the single-task focus of previous systems, UniX-Encoder acts\nas a robust upstream model, adeptly extracting features for diverse tasks\nincluding ASR and speaker recognition. 3) Self-Supervised Training: The encoder\nis trained without requiring labeled multi-channel data. 4) End-to-End\nIntegration: In contrast to models that first beamform then process\nsingle-channels, our encoder offers an end-to-end solution, bypassing explicit\nbeamforming or separation. To validate its effectiveness, we tested the\nUniX-Encoder on a synthetic multi-channel dataset from the LibriSpeech corpus.\nAcross tasks like speech recognition and speaker diarization, our encoder\nconsistently outperformed combinations like the WavLM model with the BeamformIt\nfrontend.", "published": "2023-10-25 05:12:05", "link": "http://arxiv.org/abs/2310.16367v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Novel Approach for Object Based Audio Broadcasting", "abstract": "Object Based Audio (OBA) provides a new kind of audio experience, delivered\nto the audience to personalize and customize their experience of listening and\nto give them choice of what and how to hear their audio content. OBA can be\napplied to different platforms such as broadcasting, streaming and cinema\nsound. This paper presents a novel approach for creating object-based audio on\nthe production side. The approach here presents Sample-by-Sample Object Based\nAudio (SSOBA) embedding. SSOBA places audio object samples in such a way that\nallows audiences to easily individualize their chosen audio sources according\nto their interests and needs. SSOBA is an extra service and not an alternative,\nso it is also compliant with legacy audio players. The biggest advantage of\nSSOBA is that it does not require any special additional hardware in the\nbroadcasting chain and it is therefore easy to implement and equip legacy\nplayers and decoders with enhanced ability. Input audio objects, number of\noutput channels and sampling rates are three important factors affecting SSOBA\nperformance and specifying it to be lossless or lossy. SSOBA adopts\ninterpolation at the decoder side to compensate for eliminated samples. Both\nsubjective and objective experiments are carried out to evaluate the output\nresults at each step. MUSHRA subjective experiments conducted after the\nencoding step shows good-quality performance of SSOBA with up to five objects.\nSNR measurements and objective experiments, performed after decoding and\ninterpolation, show significant successful recovery and separation of audio\nobjects. Experimental results show that a minimum sampling rate of 96 kHz is\nindicated to encode up to five objects in a Stereo-mode channel to acquire good\nsubjective and objective results simultaneously.", "published": "2023-10-25 09:05:48", "link": "http://arxiv.org/abs/2310.16481v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Dynamic Processing Neural Network Architecture For Hearing Loss\n  Compensation", "abstract": "This paper proposes neural networks for compensating sensorineural hearing\nloss. The aim of the hearing loss compensation task is to transform a speech\nsignal to increase speech intelligibility after further processing by a person\nwith a hearing impairment, which is modeled by a hearing loss model. We propose\nan interpretable model called dynamic processing network, which has a structure\nsimilar to band-wise dynamic compressor. The network is differentiable, and\ntherefore allows to learn its parameters to maximize speech intelligibility.\nMore generic models based on convolutional layers were tested as well. The\nperformance of the tested architectures was assessed using spectro-temporal\nobjective index (STOI) with hearing-threshold noise and hearing aid speech\nintelligibility (HASPI) metrics. The dynamic processing network gave a\nsignificant improvement of STOI and HASPI in comparison to popular compressive\ngain prescription rule Camfit. A large enough convolutional network could\noutperform the interpretable model with the cost of larger computational load.\nFinally, a combination of the dynamic processing network with convolutional\nneural network gave the best results in terms of STOI and HASPI.", "published": "2023-10-25 11:04:32", "link": "http://arxiv.org/abs/2310.16550v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improved Panning on Non-Equidistant Loudspeakers with Direct Sound Level\n  Compensation", "abstract": "Loudspeaker rendering techniques that create phantom sound sources often\nassume an equidistant loudspeaker layout. Typical home setups might not fulfill\nthis condition as loudspeakers deviate from canonical positions, thus requiring\na corresponding calibration. The standard approach is to compensate for delays\nand to match the loudness of each loudspeaker at the listener's location. It\nwas found that a shift of the phantom image occurs when this calibration\nprocedure is applied and one of a pair of loudspeakers is significantly closer\nto the listener than the other. In this paper, a novel approach to panning on\nnon-equidistant loudspeaker layouts is presented whereby the panning position\nis governed by the direct sound and the perceived loudness is governed by the\nfull impulse response. Subjective listening tests are presented that validate\nthe approach and quantify the perceived effect of the compensation. In a setup\nwhere the standard calibration leads to an average error of 10 degrees, the\nproposed direct sound compensation largely returns the phantom source to its\nintended position.", "published": "2023-10-25 21:05:13", "link": "http://arxiv.org/abs/2310.17004v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Streaming Speech-to-Avatar Synthesis", "abstract": "Streaming speech-to-avatar synthesis creates real-time animations for a\nvirtual character from audio data. Accurate avatar representations of speech\nare important for the visualization of sound in linguistics, phonetics, and\nphonology, visual feedback to assist second language acquisition, and virtual\nembodiment for paralyzed patients. Previous works have highlighted the\ncapability of deep articulatory inversion to perform high-quality avatar\nanimation using electromagnetic articulography (EMA) features. However, these\nmodels focus on offline avatar synthesis with recordings rather than real-time\naudio, which is necessary for live avatar visualization or embodiment. To\naddress this issue, we propose a method using articulatory inversion for\nstreaming high quality facial and inner-mouth avatar animation from real-time\naudio. Our approach achieves 130ms average streaming latency for every 0.1\nseconds of audio with a 0.792 correlation with ground truth articulations.\nFinally, we show generated mouth and tongue animations to demonstrate the\nefficacy of our methodology.", "published": "2023-10-25 01:45:33", "link": "http://arxiv.org/abs/2310.16287v1", "categories": ["cs.SD", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Structured Multi-Track Accompaniment Arrangement via Style Prior\n  Modelling", "abstract": "In the realm of music AI, arranging rich and structured multi-track\naccompaniments from a simple lead sheet presents significant challenges. Such\nchallenges include maintaining track cohesion, ensuring long-term coherence,\nand optimizing computational efficiency. In this paper, we introduce a novel\nsystem that leverages prior modelling over disentangled style factors to\naddress these challenges. Our method presents a two-stage process: initially, a\npiano arrangement is derived from the lead sheet by retrieving piano texture\nstyles; subsequently, a multi-track orchestration is generated by infusing\norchestral function styles into the piano arrangement. Our key design is the\nuse of vector quantization and a unique multi-stream Transformer to model the\nlong-term flow of the orchestration style, which enables flexible,\ncontrollable, and structured music generation. Experiments show that by\nfactorizing the arrangement task into interpretable sub-stages, our approach\nenhances generative capacity while improving efficiency. Additionally, our\nsystem supports a variety of music genres and provides style control at\ndifferent composition hierarchies. We further show that our system achieves\nsuperior coherence, structure, and overall arrangement quality compared to\nexisting baselines.", "published": "2023-10-25 03:30:37", "link": "http://arxiv.org/abs/2310.16334v4", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Repeatable Speech Embeddings Using An Intra-class Correlation\n  Regularizer", "abstract": "A good supervised embedding for a specific machine learning task is only\nsensitive to changes in the label of interest and is invariant to other\nconfounding factors. We leverage the concept of repeatability from measurement\ntheory to describe this property and propose to use the intra-class correlation\ncoefficient (ICC) to evaluate the repeatability of embeddings. We then propose\na novel regularizer, the ICC regularizer, as a complementary component for\ncontrastive losses to guide deep neural networks to produce embeddings with\nhigher repeatability. We use simulated data to explain why the ICC regularizer\nworks better on minimizing the intra-class variance than the contrastive loss\nalone. We implement the ICC regularizer and apply it to three speech tasks:\nspeaker verification, voice style conversion, and a clinical application for\ndetecting dysphonic voice. The experimental results demonstrate that adding an\nICC regularizer can improve the repeatability of learned embeddings compared to\nonly using the contrastive loss; further, these embeddings lead to improved\nperformance in these downstream tasks.", "published": "2023-10-25 23:21:46", "link": "http://arxiv.org/abs/2310.17049v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Early Detection of Tuberculosis with Machine Learning Cough Audio\n  Analysis: Towards More Accessible Global Triaging Usage", "abstract": "Tuberculosis (TB), a bacterial disease mainly affecting the lungs, is one of\nthe leading infectious causes of mortality worldwide. To prevent TB from\nspreading within the body, which causes life-threatening complications, timely\nand effective anti-TB treatment is crucial. Cough, an objective biomarker for\nTB, is a triage tool that monitors treatment response and regresses with\nsuccessful therapy. Current gold standards for TB diagnosis are slow or\ninaccessible, especially in rural areas where TB is most prevalent. In\naddition, current machine learning (ML) diagnosis research, like utilizing\nchest radiographs, is ineffective and does not monitor treatment progression.\nTo enable effective diagnosis, an ensemble model was developed that analyzes,\nusing a novel ML architecture, coughs' acoustic epidemiologies from\nsmartphones' microphones to detect TB. The architecture includes a 2D-CNN and\nXGBoost that was trained on 724,964 cough audio samples and demographics from 7\ncountries. After feature extraction (Mel-spectrograms) and data augmentation\n(IR-convolution), the model achieved AUROC (area under the receiving operator\ncharacteristic) of 88%, surpassing WHO's requirements for screening tests. The\nresults are available within 15 seconds and can easily be accessible via a\nmobile app. This research helps to improve TB diagnosis through a promising\naccurate, quick, and accessible triaging tool.", "published": "2023-10-25 23:22:20", "link": "http://arxiv.org/abs/2310.17675v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "q-bio.QM"], "primary_category": "eess.AS"}
{"title": "A versatile circuit for emulating active biological dendrites applied to\n  sound localisation and neuron imitation", "abstract": "Sophisticated machine learning struggles to transition onto battery-operated\ndevices due to the high-power consumption of neural networks. Researchers have\nturned to neuromorphic engineering, inspired by biological neural networks, for\nmore efficient solutions. While previous research focused on artificial neurons\nand synapses, an essential component has been overlooked: dendrites. Dendrites\ntransmit inputs from synapses to the neuron's soma, applying both passive and\nactive transformations. However, neuromorphic circuits replace these\nsophisticated computational channels with metallic interconnects. In this\nstudy, we introduce a versatile circuit that emulates a segment of a dendrite\nwhich exhibits gain, introduces delays, and performs integration. We show how\nsound localisation - a biological example of dendritic computation - is not\npossible with the existing passive dendrite circuits but can be achieved using\nthis proposed circuit. We also find that dendrites can form bursting neurons.\nThis significant discovery suggests the potential to fabricate neural networks\nsolely comprised of dendrite circuits.", "published": "2023-10-25 09:42:24", "link": "http://arxiv.org/abs/2311.12861v1", "categories": ["cs.NE", "cs.AI", "cs.ET", "eess.AS"], "primary_category": "cs.NE"}
