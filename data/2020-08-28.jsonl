{"title": "Cost-Quality Adaptive Active Learning for Chinese Clinical Named Entity\n  Recognition", "abstract": "Clinical Named Entity Recognition (CNER) aims to automatically identity\nclinical terminologies in Electronic Health Records (EHRs), which is a\nfundamental and crucial step for clinical research. To train a high-performance\nmodel for CNER, it usually requires a large number of EHRs with high-quality\nlabels. However, labeling EHRs, especially Chinese EHRs, is time-consuming and\nexpensive. One effective solution to this is active learning, where a model\nasks labelers to annotate data which the model is uncertain of. Conventional\nactive learning assumes a single labeler that always replies noiseless answers\nto queried labels. However, in real settings, multiple labelers provide diverse\nquality of annotation with varied costs and labelers with low overall\nannotation quality can still assign correct labels for some specific instances.\nIn this paper, we propose a Cost-Quality Adaptive Active Learning (CQAAL)\napproach for CNER in Chinese EHRs, which maintains a balance between the\nannotation quality, labeling costs, and the informativeness of selected\ninstances. Specifically, CQAAL selects cost-effective instance-labeler pairs to\nachieve better annotation quality with lower costs in an adaptive manner.\nComputational results on the CCKS-2017 Task 2 benchmark dataset demonstrate the\nsuperiority and effectiveness of the proposed CQAAL.", "published": "2020-08-28 09:27:43", "link": "http://arxiv.org/abs/2008.12548v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two Step Joint Model for Drug Drug Interaction Extraction", "abstract": "When patients need to take medicine, particularly taking more than one kind\nof drug simultaneously, they should be alarmed that there possibly exists\ndrug-drug interaction. Interaction between drugs may have a negative impact on\npatients or even cause death. Generally, drugs that conflict with a specific\ndrug (or label drug) are usually described in its drug label or package insert.\nSince more and more new drug products come into the market, it is difficult to\ncollect such information by manual. We take part in the Drug-Drug Interaction\n(DDI) Extraction from Drug Labels challenge of Text Analysis Conference (TAC)\n2018, choosing task1 and task2 to automatically extract DDI related mentions\nand DDI relations respectively. Instead of regarding task1 as named entity\nrecognition (NER) task and regarding task2 as relation extraction (RE) task\nthen solving it in a pipeline, we propose a two step joint model to detect DDI\nand it's related mentions jointly. A sequence tagging system (CNN-GRU\nencoder-decoder) finds precipitants first and search its fine-grained Trigger\nand determine the DDI for each precipitant in the second step. Moreover, a rule\nbased model is built to determine the sub-type for pharmacokinetic interation.\nOur system achieved best result in both task1 and task2. F-measure reaches 0.46\nin task1 and 0.40 in task2.", "published": "2020-08-28 15:30:08", "link": "http://arxiv.org/abs/2008.12704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Efficient Deep Learning for Natural Language Processing", "abstract": "Deep learning has become the workhorse for a wide range of natural language\nprocessing applications. But much of the success of deep learning relies on\nannotated examples. Annotation is time-consuming and expensive to produce at\nscale. Here we are interested in methods for reducing the required quantity of\nannotated data -- by making the learning methods more knowledge efficient so as\nto make them more applicable in low annotation (low resource) settings. There\nare various classical approaches to making the models more knowledge efficient\nsuch as multi-task learning, transfer learning, weakly supervised and\nunsupervised learning etc. This thesis focuses on adapting such classical\nmethods to modern deep learning models and algorithms.\n  This thesis describes four works aimed at making machine learning models more\nknowledge efficient. First, we propose a knowledge rich deep learning model\n(KRDL) as a unifying learning framework for incorporating prior knowledge into\ndeep models. In particular, we apply KRDL built on Markov logic networks to\ndenoise weak supervision. Second, we apply a KRDL model to assist the machine\nreading models to find the correct evidence sentences that can support their\ndecision. Third, we investigate the knowledge transfer techniques in\nmultilingual setting, where we proposed a method that can improve pre-trained\nmultilingual BERT based on the bilingual dictionary. Fourth, we present an\nepisodic memory network for language modelling, in which we encode the large\nexternal knowledge for the pre-trained GPT.", "published": "2020-08-28 23:32:33", "link": "http://arxiv.org/abs/2008.12878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dataset and Baselines for Visual Question Answering on Art", "abstract": "Answering questions related to art pieces (paintings) is a difficult task, as\nit implies the understanding of not only the visual information that is shown\nin the picture, but also the contextual knowledge that is acquired through the\nstudy of the history of art. In this work, we introduce our first attempt\ntowards building a new dataset, coined AQUA (Art QUestion Answering). The\nquestion-answer (QA) pairs are automatically generated using state-of-the-art\nquestion generation methods based on paintings and comments provided in an\nexisting art understanding dataset. The QA pairs are cleansed by crowdsourcing\nworkers with respect to their grammatical correctness, answerability, and\nanswers' correctness. Our dataset inherently consists of visual\n(painting-based) and knowledge (comment-based) questions. We also present a\ntwo-branch model as baseline, where the visual and knowledge questions are\nhandled independently. We extensively compare our baseline model against the\nstate-of-the-art models for question answering, and we provide a comprehensive\nstudy about the challenges and potential future directions for visual question\nanswering on art.", "published": "2020-08-28 07:33:30", "link": "http://arxiv.org/abs/2008.12520v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Probabilistic Random Indexing for Continuous Event Detection", "abstract": "The present paper explores a novel variant of Random Indexing (RI) based\nrepresentations for encoding language data with a view to using them in a\ndynamic scenario where events are happening in a continuous fashion. As the\nsize of the representations in the general method of onehot encoding grows\nlinearly with the size of the vocabulary, they become non-scalable for online\npurposes with high volumes of dynamic data. On the other hand, existing\npre-trained embedding models are not suitable for detecting happenings of new\nevents due to the dynamic nature of the text data. The present work addresses\nthis issue by using a novel RI representation by imposing a probability\ndistribution on the number of randomized entries which leads to a class of RI\nrepresentations. It also provides a rigorous analysis of the goodness of the\nrepresentation methods to encode semantic information in terms of the\nprobability of orthogonality. Building on these ideas we propose an algorithm\nthat is log-linear with the size of vocabulary to track the semantic\nrelationship of a query word to other words for suggesting the events that are\nrelevant to the word in question. We ran simulations using the proposed\nalgorithm for tweet data specific to three different events and present our\nfindings. The proposed probabilistic RI representations are found to be much\nfaster and scalable than Bag of Words (BoW) embeddings while maintaining\naccuracy in depicting semantic relationships.", "published": "2020-08-28 09:37:39", "link": "http://arxiv.org/abs/2008.12552v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Adapter-Bot: All-In-One Controllable Conversational Model", "abstract": "Considerable progress has been made towards conversational models that\ngenerate coherent and fluent responses by training large language models on\nlarge dialogue datasets. These models have little or no control of the\ngenerated responses and miss two important features: continuous dialogue skills\nintegration and seamlessly leveraging diverse knowledge sources. In this paper,\nwe propose the Adapter-Bot, a dialogue model that uses a fixed backbone\nconversational model such as DialGPT (Zhang et al., 2019) and triggers\non-demand dialogue skills (e.g., emphatic response, weather information, movie\nrecommendation) via different adapters (Houlsby et al., 2019). Each adapter can\nbe trained independently, thus allowing a continual integration of skills\nwithout retraining the entire model. Depending on the skills, the model is able\nto process multiple knowledge types, such as text, tables, and graphs, in a\nseamless manner. The dialogue skills can be triggered automatically via a\ndialogue manager, or manually, thus allowing high-level control of the\ngenerated responses. At the current stage, we have implemented 12 response\nstyles (e.g., positive, negative etc.), 8 goal-oriented skills (e.g. weather\ninformation, movie recommendation, etc.), and personalized and emphatic\nresponses. We evaluate our model using automatic evaluation by comparing it\nwith existing state-of-the-art conversational models, and we have released an\ninteractive system at adapter.bot.ust.hk.", "published": "2020-08-28 10:59:31", "link": "http://arxiv.org/abs/2008.12579v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HittER: Hierarchical Transformers for Knowledge Graph Embeddings", "abstract": "This paper examines the challenging problem of learning representations of\nentities and relations in a complex multi-relational knowledge graph. We\npropose HittER, a Hierarchical Transformer model to jointly learn\nEntity-relation composition and Relational contextualization based on a source\nentity's neighborhood. Our proposed model consists of two different Transformer\nblocks: the bottom block extracts features of each entity-relation pair in the\nlocal neighborhood of the source entity and the top block aggregates the\nrelational information from outputs of the bottom block. We further design a\nmasked entity prediction task to balance information from the relational\ncontext and the source entity itself. Experimental results show that HittER\nachieves new state-of-the-art results on multiple link prediction datasets. We\nadditionally propose a simple approach to integrate HittER into BERT and\ndemonstrate its effectiveness on two Freebase factoid question answering\ndatasets.", "published": "2020-08-28 18:58:15", "link": "http://arxiv.org/abs/2008.12813v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TATL at W-NUT 2020 Task 2: A Transformer-based Baseline System for\n  Identification of Informative COVID-19 English Tweets", "abstract": "As the COVID-19 outbreak continues to spread throughout the world, more and\nmore information about the pandemic has been shared publicly on social media.\nFor example, there are a huge number of COVID-19 English Tweets daily on\nTwitter. However, the majority of those Tweets are uninformative, and hence it\nis important to be able to automatically select only the informative ones for\ndownstream applications. In this short paper, we present our participation in\nthe W-NUT 2020 Shared Task 2: Identification of Informative COVID-19 English\nTweets. Inspired by the recent advances in pretrained Transformer language\nmodels, we propose a simple yet effective baseline for the task. Despite its\nsimplicity, our proposed approach shows very competitive results in the\nleaderboard as we ranked 8 over 56 teams participated in total.", "published": "2020-08-28 21:27:42", "link": "http://arxiv.org/abs/2008.12854v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Intimate Partner Violence and Injury Prediction From Radiology Reports", "abstract": "Intimate partner violence (IPV) is an urgent, prevalent, and under-detected\npublic health issue. We present machine learning models to assess patients for\nIPV and injury. We train the predictive algorithms on radiology reports with 1)\nIPV labels based on entry to a violence prevention program and 2) injury labels\nprovided by emergency radiology fellowship-trained physicians. Our dataset\nincludes 34,642 radiology reports and 1479 patients of IPV victims and control\npatients. Our best model predicts IPV a median of 3.08 years before violence\nprevention program entry with a sensitivity of 64% and a specificity of 95%. We\nconduct error analysis to determine for which patients our model has especially\nhigh or low performance and discuss next steps for a deployed clinical risk\nmodel.", "published": "2020-08-28 17:20:37", "link": "http://arxiv.org/abs/2009.09084v2", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "QutNocturnal@HASOC'19: CNN for Hate Speech and Offensive Content\n  Identification in Hindi Language", "abstract": "We describe our top-team solution to Task 1 for Hindi in the HASOC contest\norganised by FIRE 2019. The task is to identify hate speech and offensive\nlanguage in Hindi. More specifically, it is a binary classification problem\nwhere a system is required to classify tweets into two classes: (a) \\emph{Hate\nand Offensive (HOF)} and (b) \\emph{Not Hate or Offensive (NOT)}. In contrast to\nthe popular idea of pretraining word vectors (a.k.a. word embedding) with a\nlarge corpus from a general domain such as Wikipedia, we used a relatively\nsmall collection of relevant tweets (i.e. random and sarcasm tweets in Hindi\nand Hinglish) for pretraining. We trained a Convolutional Neural Network (CNN)\non top of the pretrained word vectors. This approach allowed us to be ranked\nfirst for this task out of all teams. Our approach could easily be adapted to\nother applications where the goal is to predict class of a text when the\nprovided context is limited.", "published": "2020-08-28 02:44:17", "link": "http://arxiv.org/abs/2008.12448v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Misogynistic Tweet Detection: Modelling CNN with Small Datasets", "abstract": "Online abuse directed towards women on the social media platform Twitter has\nattracted considerable attention in recent years. An automated method to\neffectively identify misogynistic abuse could improve our understanding of the\npatterns, driving factors, and effectiveness of responses associated with\nabusive tweets over a sustained time period. However, training a neural network\n(NN) model with a small set of labelled data to detect misogynistic tweets is\ndifficult. This is partly due to the complex nature of tweets which contain\nmisogynistic content, and the vast number of parameters needed to be learned in\na NN model. We have conducted a series of experiments to investigate how to\ntrain a NN model to detect misogynistic tweets effectively. In particular, we\nhave customised and regularised a Convolutional Neural Network (CNN)\narchitecture and shown that the word vectors pre-trained on a task-specific\ndomain can be used to train a CNN model effectively when a small set of\nlabelled data is available. A CNN model trained in this way yields an improved\naccuracy over the state-of-the-art models.", "published": "2020-08-28 02:59:22", "link": "http://arxiv.org/abs/2008.12452v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Linked Credibility Reviews for Explainable Misinformation Detection", "abstract": "In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.", "published": "2020-08-28 16:55:43", "link": "http://arxiv.org/abs/2008.12742v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Rethinking the Objectives of Extractive Question Answering", "abstract": "This work demonstrates that using the objective with independence assumption\nfor modelling the span probability $P(a_s,a_e) = P(a_s)P(a_e)$ of span starting\nat position $a_s$ and ending at position $a_e$ has adverse effects. Therefore\nwe propose multiple approaches to modelling joint probability $P(a_s,a_e)$\ndirectly. Among those, we propose a compound objective, composed from the joint\nprobability while still keeping the objective with independence assumption as\nan auxiliary objective. We find that the compound objective is consistently\nsuperior or equal to other assumptions in exact match. Additionally, we\nidentified common errors caused by the assumption of independence and manually\nchecked the counterpart predictions, demonstrating the impact of the compound\nobjective on the real examples. Our findings are supported via experiments with\nthree extractive QA models (BIDAF, BERT, ALBERT) over six datasets and our\ncode, individual results and manual analysis are available online.", "published": "2020-08-28 18:22:19", "link": "http://arxiv.org/abs/2008.12804v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Perla: A Conversational Agent for Depression Screening in Digital\n  Ecosystems. Design, Implementation and Validation", "abstract": "Most depression assessment tools are based on self-report questionnaires,\nsuch as the Patient Health Questionnaire (PHQ-9). These psychometric\ninstruments can be easily adapted to an online setting by means of electronic\nforms. However, this approach lacks the interacting and engaging features of\nmodern digital environments. With the aim of making depression screening more\navailable, attractive and effective, we developed Perla, a conversational agent\nable to perform an interview based on the PHQ-9. We also conducted a validation\nstudy in which we compared the results obtained by the traditional self-report\nquestionnaire with Perla's automated interview. Analyzing the results from this\nstudy we draw two significant conclusions: firstly, Perla is much preferred by\nInternet users, achieving more than 2.5 times more reach than a traditional\nform-based questionnaire; secondly, her psychometric properties (Cronbach's\nalpha of 0.81, sensitivity of 96% and specificity of 90%) are excellent and\ncomparable to the traditional well-established depression screening\nquestionnaires.", "published": "2020-08-28 23:09:04", "link": "http://arxiv.org/abs/2008.12875v2", "categories": ["cs.CY", "cs.CL", "cs.HC", "68T50", "J.4; H.5.2; K.4.1"], "primary_category": "cs.CY"}
{"title": "Text-Conditioned Transformer for Automatic Pronunciation Error Detection", "abstract": "Automatic pronunciation error detection (APED) plays an important role in the\ndomain of language learning. As for the previous ASR-based APED methods, the\ndecoded results need to be aligned with the target text so that the errors can\nbe found out. However, since the decoding process and the alignment process are\nindependent, the prior knowledge about the target text is not fully utilized.\nIn this paper, we propose to use the target text as an extra condition for the\nTransformer backbone to handle the APED task. The proposed method can output\nthe error states with consideration of the relationship between the input\nspeech and the target text in a fully end-to-end fashion.Meanwhile, as the\nprior target text is used as a condition for the decoder input, the Transformer\nworks in a feed-forward manner instead of autoregressive in the inference\nstage, which can significantly boost the speed in the actual deployment. We set\nthe ASR-based Transformer as the baseline APED model and conduct several\nexperiments on the L2-Arctic dataset. The results demonstrate that our approach\ncan obtain 8.4\\% relative improvement on the $F_1$ score metric.", "published": "2020-08-28 01:09:13", "link": "http://arxiv.org/abs/2008.12424v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Voice Conversion Challenge 2020: Intra-lingual semi-parallel and\n  cross-lingual voice conversion", "abstract": "The voice conversion challenge is a bi-annual scientific event held to\ncompare and understand different voice conversion (VC) systems built on a\ncommon dataset. In 2020, we organized the third edition of the challenge and\nconstructed and distributed a new database for two tasks, intra-lingual\nsemi-parallel and cross-lingual VC. After a two-month challenge period, we\nreceived 33 submissions, including 3 baselines built on the database. From the\nresults of crowd-sourced listening tests, we observed that VC methods have\nprogressed rapidly thanks to advanced deep learning methods. In particular,\nspeaker similarity scores of several systems turned out to be as high as target\nspeakers in the intra-lingual semi-parallel VC task. However, we confirmed that\nnone of them have achieved human-level naturalness yet for the same task. The\ncross-lingual conversion task is, as expected, a more difficult task, and the\noverall naturalness and similarity scores were lower than those for the\nintra-lingual conversion task. However, we observed encouraging results, and\nthe MOS scores of the best systems were higher than 4.0. We also show a few\nadditional analysis results to aid in understanding cross-lingual VC better.", "published": "2020-08-28 07:48:17", "link": "http://arxiv.org/abs/2008.12527v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Non-Local Musical Statistics as Guides for Audio-to-Score Piano\n  Transcription", "abstract": "We present an automatic piano transcription system that converts polyphonic\naudio recordings into musical scores. This has been a long-standing problem of\nmusic information processing, and recent studies have made remarkable progress\nin the two main component techniques: multipitch detection and rhythm\nquantization. Given this situation, we study a method integrating\ndeep-neural-network-based multipitch detection and statistical-model-based\nrhythm quantization. In the first part, we conducted systematic evaluations and\nfound that while the present method achieved high transcription accuracies at\nthe note level, some global characteristics of music, such as tempo scale,\nmetre (time signature), and bar line positions, were often incorrectly\nestimated. In the second part, we formulated non-local statistics of pitch and\nrhythmic contents that are derived from musical knowledge and studied their\neffects in inferring those global characteristics. We found that these\nstatistics are markedly effective for improving the transcription results and\nthat their optimal combination includes statistics obtained from separated hand\nparts. The integrated method had an overall transcription error rate of 7.1%\nand a downbeat F-measure of 85.6% on a dataset of popular piano music, and the\ngenerated transcriptions can be partially used for music performance and\nassisting human transcribers, thus demonstrating the potential for practical\napplications.", "published": "2020-08-28 15:45:28", "link": "http://arxiv.org/abs/2008.12710v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
