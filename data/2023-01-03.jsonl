{"title": "ClusTop: An unsupervised and integrated text clustering and topic\n  extraction framework", "abstract": "Text clustering and topic extraction are two important tasks in text mining.\nUsually, these two tasks are performed separately. For topic extraction to\nfacilitate clustering, we can first project texts into a topic space and then\nperform a clustering algorithm to obtain clusters. To promote topic extraction\nby clustering, we can first obtain clusters with a clustering algorithm and\nthen extract cluster-specific topics. However, this naive strategy ignores the\nfact that text clustering and topic extraction are strongly correlated and\nfollow a chicken-and-egg relationship. Performing them separately fails to make\nthem mutually benefit each other to achieve the best overall performance. In\nthis paper, we propose an unsupervised text clustering and topic extraction\nframework (ClusTop) which integrates text clustering and topic extraction into\na unified framework and can achieve high-quality clustering result and extract\ntopics from each cluster simultaneously. Our framework includes four\ncomponents: enhanced language model training, dimensionality reduction,\nclustering and topic extraction, where the enhanced language model can be\nviewed as a bridge between clustering and topic extraction. On one hand, it\nprovides text embeddings with a strong cluster structure which facilitates\neffective text clustering; on the other hand, it pays high attention on the\ntopic related words for topic extraction because of its self-attention\narchitecture. Moreover, the training of enhanced language model is\nunsupervised. Experiments on two datasets demonstrate the effectiveness of our\nframework and provide benchmarks for different model combinations in this\nframework.", "published": "2023-01-03 03:26:26", "link": "http://arxiv.org/abs/2301.00818v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EZInterviewer: To Improve Job Interview Performance with Mock Interview\n  Generator", "abstract": "Interview has been regarded as one of the most crucial step for recruitment.\nTo fully prepare for the interview with the recruiters, job seekers usually\npractice with mock interviews between each other. However, such a mock\ninterview with peers is generally far away from the real interview experience:\nthe mock interviewers are not guaranteed to be professional and are not likely\nto behave like a real interviewer. Due to the rapid growth of online\nrecruitment in recent years, recruiters tend to have online interviews, which\nmakes it possible to collect real interview data from real interviewers. In\nthis paper, we propose a novel application named EZInterviewer, which aims to\nlearn from the online interview data and provides mock interview services to\nthe job seekers. The task is challenging in two ways: (1) the interview data\nare now available but still of low-resource; (2) to generate meaningful and\nrelevant interview dialogs requires thorough understanding of both resumes and\njob descriptions. To address the low-resource challenge, EZInterviewer is\ntrained on a very small set of interview dialogs. The key idea is to reduce the\nnumber of parameters that rely on interview dialogs by disentangling the\nknowledge selector and dialog generator so that most parameters can be trained\nwith ungrounded dialogs as well as the resume data that are not low-resource.\nEvaluation results on a real-world job interview dialog dataset indicate that\nwe achieve promising results to generate mock interviews. With the help of\nEZInterviewer, we hope to make mock interview practice become easier for job\nseekers.", "published": "2023-01-03 07:00:30", "link": "http://arxiv.org/abs/2301.00972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Knowledge-Intensive Text-to-SQL Semantic Parsing with Formulaic\n  Knowledge", "abstract": "In this paper, we study the problem of knowledge-intensive text-to-SQL, in\nwhich domain knowledge is necessary to parse expert questions into SQL queries\nover domain-specific tables. We formalize this scenario by building a new\nChinese benchmark KnowSQL consisting of domain-specific questions covering\nvarious domains. We then address this problem by presenting formulaic\nknowledge, rather than by annotating additional data examples. More concretely,\nwe construct a formulaic knowledge bank as a domain knowledge base and propose\na framework (ReGrouP) to leverage this formulaic knowledge during parsing.\nExperiments using ReGrouP demonstrate a significant 28.2% improvement overall\non KnowSQL.", "published": "2023-01-03 12:37:47", "link": "http://arxiv.org/abs/2301.01067v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Average Is Not Enough: Caveats of Multilingual Evaluation", "abstract": "This position paper discusses the problem of multilingual evaluation. Using\nsimple statistics, such as average language performance, might inject\nlinguistic biases in favor of dominant language families into evaluation\nmethodology. We argue that a qualitative analysis informed by comparative\nlinguistics is needed for multilingual results to detect this kind of bias. We\nshow in our case study that results in published works can indeed be\nlinguistically biased and we demonstrate that visualization based on URIEL\ntypological database can detect it.", "published": "2023-01-03 18:23:42", "link": "http://arxiv.org/abs/2301.01269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analogical Inference Enhanced Knowledge Graph Embedding", "abstract": "Knowledge graph embedding (KGE), which maps entities and relations in a\nknowledge graph into continuous vector spaces, has achieved great success in\npredicting missing links in knowledge graphs. However, knowledge graphs often\ncontain incomplete triples that are difficult to inductively infer by KGEs. To\naddress this challenge, we resort to analogical inference and propose a novel\nand general self-supervised framework AnKGE to enhance KGE models with\nanalogical inference capability. We propose an analogical object retriever that\nretrieves appropriate analogical objects from entity-level, relation-level, and\ntriple-level. And in AnKGE, we train an analogy function for each level of\nanalogical inference with the original element embedding from a well-trained\nKGE model as input, which outputs the analogical object embedding. In order to\ncombine inductive inference capability from the original KGE model and\nanalogical inference capability enhanced by AnKGE, we interpolate the analogy\nscore with the base model score and introduce the adaptive weights in the score\nfunction for prediction. Through extensive experiments on FB15k-237 and WN18RR\ndatasets, we show that AnKGE achieves competitive results on link prediction\ntask and well performs analogical inference.", "published": "2023-01-03 07:24:05", "link": "http://arxiv.org/abs/2301.00982v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "PIE-QG: Paraphrased Information Extraction for Unsupervised Question\n  Generation from Small Corpora", "abstract": "Supervised Question Answering systems (QA systems) rely on domain-specific\nhuman-labeled data for training. Unsupervised QA systems generate their own\nquestion-answer training pairs, typically using secondary knowledge sources to\nachieve this outcome. Our approach (called PIE-QG) uses Open Information\nExtraction (OpenIE) to generate synthetic training questions from paraphrased\npassages and uses the question-answer pairs as training data for a language\nmodel for a state-of-the-art QA system based on BERT. Triples in the form of\n<subject, predicate, object> are extracted from each passage, and questions are\nformed with subjects (or objects) and predicates while objects (or subjects)\nare considered as answers. Experimenting on five extractive QA datasets\ndemonstrates that our technique achieves on-par performance with existing\nstate-of-the-art QA systems with the benefit of being trained on an order of\nmagnitude fewer documents and without any recourse to external reference data\nsources.", "published": "2023-01-03 12:20:51", "link": "http://arxiv.org/abs/2301.01064v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Corporate Lobbyists", "abstract": "We demonstrate a proof-of-concept of a large language model conducting\ncorporate lobbying related activities. An autoregressive large language model\n(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are\nrelevant to specific public companies and provides explanations and confidence\nlevels. For the bills the model deems as relevant, the model drafts a letter to\nthe sponsor of the bill in an attempt to persuade the congressperson to make\nchanges to the proposed legislation. We use hundreds of novel ground-truth\nlabels of the relevance of a bill to a company to benchmark the performance of\nthe model. It outperforms the baseline of predicting the most common outcome of\nirrelevance. We also benchmark the performance of the previous OpenAI GPT-3\nmodel (text-davinci-002), which was the state-of-the-art model on many academic\nnatural language tasks until text-davinci-003 was recently released. The\nperformance of text-davinci-002 is worse than the simple baseline. Longer-term,\nif AI begins to influence law in a manner that is not a direct extension of\nhuman intentions, this threatens the critical role that law as information\ncould play in aligning AI with humans. Initially, AI is being used to simply\naugment human lobbyists for a small portion of their daily tasks. However,\nfirms have an incentive to use less and less human oversight over automated\nassessments of policy ideas and the written communication to regulatory\nagencies and Congressional staffers. The core question raised is where to draw\nthe line between human-driven and AI-driven policy influence.", "published": "2023-01-03 16:25:52", "link": "http://arxiv.org/abs/2301.01181v7", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Semi-Structured Object Sequence Encoders", "abstract": "In this paper we explore the task of modeling semi-structured object\nsequences; in particular, we focus our attention on the problem of developing a\nstructure-aware input representation for such sequences. Examples of such data\ninclude user activity on websites, machine logs, and many others. This type of\ndata is often represented as a sequence of sets of key-value pairs over time\nand can present modeling challenges due to an ever-increasing sequence length.\nWe propose a two-part approach, which first considers each key independently\nand encodes a representation of its values over time; we then self-attend over\nthese value-aware key representations to accomplish a downstream task. This\nallows us to operate on longer object sequences than existing methods. We\nintroduce a novel shared-attention-head architecture between the two modules\nand present an innovative training schedule that interleaves the training of\nboth modules with shared weights for some attention heads. Our experiments on\nmultiple prediction tasks using real-world data demonstrate that our approach\noutperforms a unified network with hierarchical encoding, as well as other\nmethods including a record-centric representation and a flattened\nrepresentation of the sequence.", "published": "2023-01-03 09:19:41", "link": "http://arxiv.org/abs/2301.01015v4", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Supervised Acoustic Embeddings And Their Transferability Across\n  Languages", "abstract": "In speech recognition, it is essential to model the phonetic content of the\ninput signal while discarding irrelevant factors such as speaker variations and\nnoise, which is challenging in low-resource settings. Self-supervised\npre-training has been proposed as a way to improve both supervised and\nunsupervised speech recognition, including frame-level feature representations\nand Acoustic Word Embeddings (AWE) for variable-length segments. However,\nself-supervised models alone cannot learn perfect separation of the linguistic\ncontent as they are trained to optimize indirect objectives. In this work, we\nexperiment with different pre-trained self-supervised features as input to AWE\nmodels and show that they work best within a supervised framework. Models\ntrained on English can be transferred to other languages with no adaptation and\noutperform self-supervised models trained solely on the target languages.", "published": "2023-01-03 09:37:24", "link": "http://arxiv.org/abs/2301.01020v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Language Models are Drummers: Drum Composition with Natural Language\n  Pre-Training", "abstract": "Automatic music generation with artificial intelligence typically requires a\nlarge amount of data which is hard to obtain for many less common genres and\nmusical instruments. To tackle this issue, we present ongoing work and\npreliminary findings on the possibility for deep models to transfer knowledge\nfrom language to music, by finetuning large language models pre-trained on a\nmassive text corpus on only hundreds of MIDI files of drum performances. We\nshow that by doing so, one of the largest, state-of-the-art models (GPT3) is\ncapable of generating reasonable drum grooves, while models that are not\npre-trained (Transformer) shows no such ability beyond naive repetition.\nEvaluating generated music is a challenging task, more so is evaluating drum\ngrooves with little precedence in literature. Hence, we propose a tailored\nstructural evaluation method and analyze drum grooves produced by GPT3 compared\nto those played by human professionals, exposing the strengths and weaknesses\nof such generation by language-to-music transfer. Our findings suggest that\nlanguage-to-music transfer learning with large language models is viable and\npromising.", "published": "2023-01-03 15:47:53", "link": "http://arxiv.org/abs/2301.01162v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Survey On Few-shot Knowledge Graph Completion with Structural and\n  Commonsense Knowledge", "abstract": "Knowledge graphs (KG) have served as the key component of various natural\nlanguage processing applications. Commonsense knowledge graphs (CKG) are a\nspecial type of KG, where entities and relations are composed of free-form\ntext. However, previous works in KG completion and CKG completion suffer from\nlong-tail relations and newly-added relations which do not have many know\ntriples for training. In light of this, few-shot KG completion (FKGC), which\nrequires the strengths of graph representation learning and few-shot learning,\nhas been proposed to challenge the problem of limited annotated data. In this\npaper, we comprehensively survey previous attempts on such tasks in the form of\na series of methods and applications. Specifically, we first introduce FKGC\nchallenges, commonly used KGs, and CKGs. Then we systematically categorize and\nsummarize existing works in terms of the type of KGs and the methods. Finally,\nwe present applications of FKGC models on prediction tasks in different areas\nand share our thoughts on future research directions of FKGC.", "published": "2023-01-03 16:00:09", "link": "http://arxiv.org/abs/2301.01172v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An ensemble-based framework for mispronunciation detection of Arabic\n  phonemes", "abstract": "Determination of mispronunciations and ensuring feedback to users are\nmaintained by computer-assisted language learning (CALL) systems. In this work,\nwe introduce an ensemble model that defines the mispronunciation of Arabic\nphonemes and assists learning of Arabic, effectively. To the best of our\nknowledge, this is the very first attempt to determine the mispronunciations of\nArabic phonemes employing ensemble learning techniques and conventional machine\nlearning models, comprehensively. In order to observe the effect of feature\nextraction techniques, mel-frequency cepstrum coefficients (MFCC), and Mel\nspectrogram are blended with each learning algorithm. To show the success of\nproposed model, 29 letters in the Arabic phonemes, 8 of which are hafiz, are\nvoiced by a total of 11 different person. The amount of data set has been\nenhanced employing the methods of adding noise, time shifting, time stretching,\npitch shifting. Extensive experiment results demonstrate that the utilization\nof voting classifier as an ensemble algorithm with Mel spectrogram feature\nextraction technique exhibits remarkable classification result with 95.9% of\naccuracy.", "published": "2023-01-03 22:17:08", "link": "http://arxiv.org/abs/2301.01378v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Modeling the Rhythm from Lyrics for Melody Generation of Pop Song", "abstract": "Creating a pop song melody according to pre-written lyrics is a typical\npractice for composers. A computational model of how lyrics are set as melodies\nis important for automatic composition systems, but an end-to-end\nlyric-to-melody model would require enormous amounts of paired training data.\nTo mitigate the data constraints, we adopt a two-stage approach, dividing the\ntask into lyric-to-rhythm and rhythm-to-melody modules. However, the\nlyric-to-rhythm task is still challenging due to its multimodality. In this\npaper, we propose a novel lyric-to-rhythm framework that includes\npart-of-speech tags to achieve better text setting, and a Transformer\narchitecture designed to model long-term syllable-to-note associations. For the\nrhythm-to-melody task, we adapt a proven chord-conditioned melody Transformer,\nwhich has achieved state-of-the-art results. Experiments for Chinese\nlyric-to-melody generation show that the proposed framework is able to model\nkey characteristics of rhythm and pitch distributions in the dataset, and in a\nsubjective evaluation, the melodies generated by our system were rated as\nsimilar to or better than those of a state-of-the-art alternative.", "published": "2023-01-03 21:30:20", "link": "http://arxiv.org/abs/2301.01361v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hyperuniform disordered parametric loudspeaker array", "abstract": "A steerable parametric loudspeaker array is known for its directivity and\nnarrow beam width. However, it often suffers from the grating lobes due to\nperiodic array distributions. Here we propose the array configuration of\nhyperuniform disorder, which is short-range random while correlated at large\nscales, as a promising alternative distribution of acoustic antennas in phased\narrays. Angle-resolved measurements reveal that the proposed array suppresses\ngrating lobes and maintains a minimal radiation region in the vicinity of the\nmain lobe for the primary frequency waves. These distinctive emission features\nbenefit the secondary frequency wave in canceling the grating lobes regardless\nof the frequencies of the primary waves. Besides that, the hyperuniform\ndisordered array is duplicatable, which facilitates extra-large array design\nwithout any additional computational efforts.", "published": "2023-01-03 02:14:58", "link": "http://arxiv.org/abs/2301.00833v2", "categories": ["eess.AS", "cs.SD", "physics.app-ph"], "primary_category": "eess.AS"}
