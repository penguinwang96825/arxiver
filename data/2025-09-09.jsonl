{"title": "Parallel-R1: Towards Parallel Thinking via Reinforcement Learning", "abstract": "Parallel thinking has emerged as a novel approach for enhancing the reasoning\ncapabilities of large language models (LLMs) by exploring multiple reasoning\npaths concurrently. However, activating such capabilities through training\nremains challenging, as existing methods predominantly rely on supervised\nfine-tuning (SFT) over synthetic data, which encourages teacher-forced\nimitation rather than exploration and generalization. Different from them, we\npropose \\textbf{Parallel-R1}, the first reinforcement learning (RL) framework\nthat enables parallel thinking behaviors for complex real-world reasoning\ntasks. Our framework employs a progressive curriculum that explicitly addresses\nthe cold-start problem in training parallel thinking with RL. We first use SFT\non prompt-generated trajectories from easier tasks to instill the parallel\nthinking ability, then transition to RL to explore and generalize this skill on\nharder problems. Experiments on various math benchmarks, including MATH, AMC23,\nand AIME, show that Parallel-R1 successfully instills parallel thinking,\nleading to 8.4% accuracy improvements over the sequential thinking model\ntrained directly on challenging tasks with RL. Further analysis reveals a clear\nshift in the model's thinking behavior: at an early stage, it uses parallel\nthinking as an exploration strategy, while in a later stage, it uses the same\ncapability for multi-perspective verification. Most significantly, we validate\nparallel thinking as a \\textbf{mid-training exploration scaffold}, where this\ntemporary exploratory phase unlocks a higher performance ceiling after RL,\nyielding a 42.9% improvement over the baseline on AIME25. Our model, data, and\ncode will be open-source at https://github.com/zhengkid/Parallel-R1.", "published": "2025-09-09 17:59:35", "link": "http://arxiv.org/abs/2509.07980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search", "abstract": "Recent advances in large multimodal models have leveraged image-based tools\nwith reinforcement learning to tackle visual problems. However, existing\nopen-source approaches often exhibit monotonous reasoning patterns and allow\nonly a limited number of interaction turns, making them inadequate for\ndifficult tasks that require trial-and-error exploration. In this work, we\naddress this limitation by scaling up tool-based interactions and introduce\nMini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of\nsteps -- and achieves state-of-the-art performance on challenging visual search\ntasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key\ncomponents. First, we construct the Visual Probe Dataset, a collection of\nthousands of challenging visual search problems designed for exploratory\nreasoning. Second, we develop an iterative data collection pipeline to obtain\ncold-start trajectories that exhibit diverse reasoning patterns, including\ndepth-first search, trial-and-error, and goal maintenance. Third, we propose an\nover-turn masking strategy that prevents penalization of over-turn responses\n(those that hit the maximum number of turns) during reinforcement learning,\nthereby balancing training-time efficiency with test-time scalability. Despite\ntraining with an upper bound of only six interaction turns, our model generates\ntrajectories that naturally scale to tens of turns at inference time, with\naccuracy improving as the number of turns increases. Extensive experiments\ndemonstrate that Mini-o3 produces rich reasoning patterns and deep thinking\npaths, effectively solving challenging visual search problems.", "published": "2025-09-09 17:54:21", "link": "http://arxiv.org/abs/2509.07969v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge", "abstract": "We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large\nLanguage Model (LLM) short-form factuality based on OpenAI's SimpleQA. It\naddresses critical limitations in OpenAI's benchmark, including noisy and\nincorrect labels, topical biases, and question redundancy. SimpleQA Verified\nwas created through a rigorous multi-stage filtering process involving\nde-duplication, topic balancing, and source reconciliation to produce a more\nreliable and challenging evaluation set, alongside improvements in the\nautorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a\nstate-of-the-art F1-score of 55.6, outperforming other frontier models,\nincluding GPT-5. This work provides the research community with a\nhigher-fidelity tool to track genuine progress in parametric model factuality\nand to mitigate hallucinations. The benchmark dataset, evaluation code, and\nleaderboard are available at:\nhttps://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.", "published": "2025-09-09 17:53:58", "link": "http://arxiv.org/abs/2509.07968v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images", "abstract": "Visual reasoning over structured data such as tables is a critical capability\nfor modern vision-language models (VLMs), yet current benchmarks remain limited\nin scale, diversity, or reasoning depth, especially when it comes to rendered\ntable images. Addressing this gap, we introduce Visual-TableQA, a large-scale,\nopen-domain multimodal dataset specifically designed to evaluate and enhance\nvisual reasoning over complex tabular data. Our generation pipeline is modular,\nscalable, and fully autonomous, involving multiple reasoning LLMs collaborating\nacross distinct roles: generation, validation, and inspiration. Visual-TableQA\ncomprises 2.5k richly structured LaTeX-rendered tables and 6k\nreasoning-intensive QA pairs, all produced at a cost of under USD 100. To\npromote diversity and creativity, our pipeline performs multi-model\ncollaborative data generation via cross-model prompting ('inspiration') and\nLLM-jury filtering. Stronger models seed layouts and topics that weaker models\nelaborate, collectively distilling diverse reasoning patterns and visual\nstructures into the dataset. Empirical results show that models fine-tuned on\nVisual-TableQA generalize robustly to external benchmarks, outperforming\nseveral proprietary models despite the dataset's synthetic nature. The full\npipeline and resources are publicly available at\nhttps://github.com/AI-4-Everyone/Visual-TableQA.", "published": "2025-09-09 17:52:26", "link": "http://arxiv.org/abs/2509.07966v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models", "abstract": "Uncertainty estimation is essential for enhancing the reliability of Large\nLanguage Models (LLMs), particularly in high-stakes applications. Existing\nmethods often overlook semantic dependencies, relying on token-level\nprobability measures that fail to capture structural relationships within the\ngenerated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty\nEstimation for Large Language Models, a structure-aware framework that\nleverages dependency parse trees and hierarchical graph pooling to refine\nuncertainty quantification. By incorporating supervised learning, GENUINE\neffectively models semantic and structural relationships, improving confidence\nassessments. Extensive experiments across NLP tasks show that GENUINE achieves\nup to 29% higher AUROC than semantic entropy-based approaches and reduces\ncalibration errors by over 15%, demonstrating the effectiveness of graph-based\nuncertainty modeling. The code is available at\nhttps://github.com/ODYSSEYWT/GUQ.", "published": "2025-09-09 17:07:44", "link": "http://arxiv.org/abs/2509.07925v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Uncovering Scaling Laws for Large Language Models via Inverse Problems", "abstract": "Large Language Models (LLMs) are large-scale pretrained models that have\nachieved remarkable success across diverse domains. These successes have been\ndriven by unprecedented complexity and scale in both data and computations.\nHowever, due to the high costs of training such models, brute-force\ntrial-and-error approaches to improve LLMs are not feasible. Inspired by the\nsuccess of inverse problems in uncovering fundamental scientific laws, this\nposition paper advocates that inverse problems can also efficiently uncover\nscaling laws that guide the building of LLMs to achieve the desirable\nperformance with significantly better cost-effectiveness.", "published": "2025-09-09 16:53:21", "link": "http://arxiv.org/abs/2509.07909v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Biased Tales: Cultural and Topic Bias in Generating Children's Stories", "abstract": "Stories play a pivotal role in human communication, shaping beliefs and\nmorals, particularly in children. As parents increasingly rely on large\nlanguage models (LLMs) to craft bedtime stories, the presence of cultural and\ngender stereotypes in these narratives raises significant concerns. To address\nthis issue, we present Biased Tales, a comprehensive dataset designed to\nanalyze how biases influence protagonists' attributes and story elements in\nLLM-generated stories. Our analysis uncovers striking disparities. When the\nprotagonist is described as a girl (as compared to a boy), appearance-related\nattributes increase by 55.26%. Stories featuring non-Western children\ndisproportionately emphasize cultural heritage, tradition, and family themes\nfar more than those for Western children. Our findings highlight the role of\nsociocultural bias in making creative AI use more equitable and diverse.", "published": "2025-09-09 16:51:16", "link": "http://arxiv.org/abs/2509.07908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing", "abstract": "This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which\nfocuses on sentence-level gender bias detection and mitigation in Chinese. The\ntask aims to promote fairness and controllability in natural language\ngeneration by automatically detecting, classifying, and mitigating gender bias.\nTo address this challenge, we adopt a fine-tuning approach based on large\nlanguage models (LLMs), efficiently adapt to the bias detection task via\nLow-Rank Adaptation (LoRA). In terms of data processing, we construct a more\nbalanced training set to alleviate class imbalance and introduce heterogeneous\nsamples from multiple sources to enhance model generalization. For the\ndetection and classification sub-tasks, we employ a majority voting strategy\nthat integrates outputs from multiple expert models to boost performance.\nAdditionally, to improve bias generation detection and mitigation, we design a\nmulti-temperature sampling mechanism to capture potential variations in bias\nexpression styles. Experimental results demonstrate the effectiveness of our\napproach in bias detection, classification, and mitigation. Our method\nultimately achieves an average score of 47.90%, ranking fourth in the shared\ntask.", "published": "2025-09-09 16:12:11", "link": "http://arxiv.org/abs/2509.07889v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Humans as Brittle as Large Language Models?", "abstract": "The output of large language models (LLM) is unstable, due to both\nnon-determinism of the decoding process as well as to prompt brittleness. While\nthe intrinsic non-determinism of LLM generation may mimic existing uncertainty\nin human annotations through distributional shifts in outputs, it is largely\nassumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.\nThis raises the question: do human annotators show similar sensitivity to\ninstruction changes? If so, should prompt brittleness in LLMs be considered\nproblematic? One may alternatively hypothesize that prompt brittleness\ncorrectly reflects human annotation variances. To fill this research gap, we\nsystematically compare the effects of prompt modifications on LLMs and\nidentical instruction modifications for human annotators, focusing on the\nquestion of whether humans are similarly sensitive to prompt perturbations. To\nstudy this, we prompt both humans and LLMs for a set of text classification\ntasks conditioned on prompt variations. Our findings indicate that both humans\nand LLMs exhibit increased brittleness in response to specific types of prompt\nmodifications, particularly those involving the substitution of alternative\nlabel sets or label formats. However, the distribution of human judgments is\nless affected by typographical errors and reversed label order than that of\nLLMs.", "published": "2025-09-09 15:56:51", "link": "http://arxiv.org/abs/2509.07869v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost", "abstract": "Literary translation has recently gained attention as a distinct and complex\ntask in machine translation research. However, the translation by small open\nmodels remains an open problem. We contribute to this ongoing research by\nintroducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for\ndataset creation, fine tuning, and evaluation in English-Romanian literary\ntranslations, centred on the creation and open release of both a compact, fine\ntuned language model (TF2-12B) and large scale synthetic parallel datasets\n(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the\nlargest collection of synthetic English fables to date, we address the need for\nrich, high quality literary datasets in low resource languages such as\nRomanian. Our pipeline first generates 15k high quality Romanian references\nfrom the TF1 pool using a high performing LLM. We then apply a two stage fine\ntuning process to a 12B parameter open weight model: (i) instruction tuning to\ncapture genre specific narrative style, and (ii) adapter compression for\nefficient deployment. Evaluation combines corpus level BLEU and a five\ndimension LLM based rubric (accuracy, fluency, coherence, style, cultural\nadaptation) to provide a nuanced assessment of translation quality. Results\nshow that our fine tuned model achieves fluency and adequacy competitive with\ntop performing large proprietary models, while being open, accessible, and\nsignificantly more cost effective. Alongside the fine tuned model and both\ndatasets, we publicly release all scripts and evaluation prompts. TF2 thus\nprovides an end-to-end, reproducible pipeline for research on cost efficient\ntranslation, cross lingual narrative generation, and the broad adoption of open\nmodels for culturally significant literary content in low resource settings.", "published": "2025-09-09 15:07:14", "link": "http://arxiv.org/abs/2509.07829v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems", "abstract": "Textual response generation is pivotal for multimodal \\mbox{task-oriented}\ndialog systems, which aims to generate proper textual responses based on the\nmultimodal context. While existing efforts have demonstrated remarkable\nprogress, there still exist the following limitations: 1) \\textit{neglect of\nunstructured review knowledge} and 2) \\textit{underutilization of large\nlanguage models (LLMs)}. Inspired by this, we aim to fully utilize dual\nknowledge (\\textit{i.e., } structured attribute and unstructured review\nknowledge) with LLMs to promote textual response generation in multimodal\ntask-oriented dialog systems. However, this task is non-trivial due to two key\nchallenges: 1) \\textit{dynamic knowledge type selection} and 2)\n\\textit{intention-response decoupling}. To address these challenges, we propose\na novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for\nmultimodal dialog systems (named DK2R). To be specific, DK2R first extracts\nboth structured attribute and unstructured review knowledge from external\nknowledge base given the dialog context. Thereafter, DK2R uses an LLM to\nevaluate each knowledge type's utility by analyzing LLM-generated provisional\nprobe responses. Moreover, DK2R separately summarizes the intention-oriented\nkey clues via dedicated reasoning, which are further used as auxiliary signals\nto enhance LLM-based textual response generation. Extensive experiments\nconducted on a public dataset verify the superiority of DK2R. We have released\nthe codes and parameters.", "published": "2025-09-09 14:55:28", "link": "http://arxiv.org/abs/2509.07817v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP", "abstract": "Structured information extraction from scientific literature is crucial for\ncapturing core concepts and emerging trends in specialized fields. While\nexisting datasets aid model development, most focus on specific publication\nsections due to domain complexity and the high cost of annotating scientific\ntexts. To address this limitation, we introduce SciNLP - a specialized\nbenchmark for full-text entity and relation extraction in the Natural Language\nProcessing (NLP) domain. The dataset comprises 60 manually annotated full-text\nNLP publications, covering 7,072 entities and 1,826 relations. Compared to\nexisting research, SciNLP is the first dataset providing full-text annotations\nof entities and their relationships in the NLP domain. To validate the\neffectiveness of SciNLP, we conducted comparative experiments with similar\ndatasets and evaluated the performance of state-of-the-art supervised models on\nthis dataset. Results reveal varying extraction capabilities of existing models\nacross academic texts of different lengths. Cross-comparisons with existing\ndatasets show that SciNLP achieves significant performance improvements on\ncertain baseline models. Using models trained on SciNLP, we implemented\nautomatic construction of a fine-grained knowledge graph for the NLP domain.\nOur KG has an average node degree of 3.2 per entity, indicating rich semantic\ntopological information that enhances downstream applications. The dataset is\npublicly available at https://github.com/AKADDC/SciNLP.", "published": "2025-09-09 14:41:40", "link": "http://arxiv.org/abs/2509.07801v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning", "abstract": "The spread of fake news, polarizing, politically biased, and harmful content\non online platforms has been a serious concern. With large language models\nbecoming a promising approach, however, no study has properly benchmarked their\nperformance across different models, usage methods, and languages. This study\npresents a comprehensive overview of different Large Language Models adaptation\nparadigms for the detection of hyperpartisan and fake news, harmful tweets, and\npolitical bias. Our experiments spanned 10 datasets and 5 different languages\n(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and\nmulticlass classification scenarios. We tested different strategies ranging\nfrom parameter efficient Fine-Tuning of language models to a variety of\ndifferent In-Context Learning strategies and prompts. These included zero-shot\nprompts, codebooks, few-shot (with both randomly-selected and\ndiversely-selected examples using Determinantal Point Processes), and\nChain-of-Thought. We discovered that In-Context Learning often underperforms\nwhen compared to Fine-Tuning a model. This main finding highlights the\nimportance of Fine-Tuning even smaller models on task-specific settings even\nwhen compared to the largest models evaluated in an In-Context Learning setup -\nin our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and\nQwen2.5-7B-Instruct.", "published": "2025-09-09 14:01:15", "link": "http://arxiv.org/abs/2509.07768v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts", "abstract": "As large language models (LLMs) adapted to sensitive domains such as\nmedicine, their fluency raises safety risks, particularly regarding provenance\nand accountability. Watermarking embeds detectable patterns to mitigate these\nrisks, yet its reliability in medical contexts remains untested. Existing\nbenchmarks focus on detection-quality tradeoffs, overlooking factual risks\nunder low-entropy settings often exploited by watermarking's reweighting\nstrategy. We propose a medical-focused evaluation workflow that jointly\nassesses factual accuracy and coherence. Using GPT-Judger and further human\nvalidation, we introduce the Factuality-Weighted Score (FWS), a composite\nmetric prioritizing factual accuracy beyond coherence to guide watermarking\ndeployment in medical domains. Our evaluation shows current watermarking\nmethods substantially compromise medical factuality, with entropy shifts\ndegrading medical entity representation. These findings underscore the need for\ndomain-aware watermarking approaches that preserve the integrity of medical\ncontent.", "published": "2025-09-09 13:54:34", "link": "http://arxiv.org/abs/2509.07755v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models", "abstract": "For Relation Extraction (RE), the manual annotation of training data may be\nprohibitively expensive, since the sentences that contain the target relations\nin texts can be very scarce and difficult to find. It is therefore beneficial\nto develop an efficient method that can automatically extract training\ninstances from unlabeled texts for training RE models. Recently, large language\nmodels (LLMs) have been adopted in various natural language processing tasks,\nwith RE also benefiting from their advances. However, when leveraging LLMs for\nRE with predefined relation categories, two key challenges arise. First, in a\nmulti-class classification setting, LLMs often struggle to comprehensively\ncapture the semantics of every relation, leading to suboptimal results. Second,\nalthough employing binary classification for each relation individually can\nmitigate this issue, it introduces significant computational overhead,\nresulting in impractical time complexity for real-world applications.\nTherefore, this paper proposes a framework called M-BRe to extract training\ninstances from unlabeled texts for RE. It utilizes three modules to combine the\nadvantages of both of the above classification approaches: Relation Grouping,\nRelation Extraction, and Label Decision. Extensive experiments confirm its\nsuperior capability in discovering high-quality training samples from unlabeled\ntexts for RE.", "published": "2025-09-09 13:32:29", "link": "http://arxiv.org/abs/2509.07730v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs", "abstract": "Efficient communication between patients and clinicians plays an important\nrole in shared decision-making. However, clinical reports are often lengthy and\nfilled with clinical jargon, making it difficult for domain experts to identify\nimportant aspects in the document efficiently. This paper presents the\nmethodology we applied in the MultiClinSUM shared task for summarising clinical\ncase documents. We used an Iterative Self-Prompting technique on large language\nmodels (LLMs) by asking LLMs to generate task-specific prompts and refine them\nvia example-based few-shot learning. Furthermore, we used lexical and embedding\nspace metrics, ROUGE and BERT-score, to guide the model fine-tuning with\nepochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved\nROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,\nR, F1) from the official evaluation on 3,396 clinical case reports from various\nspecialties extracted from open journals. The high BERTscore indicates that the\nmodel produced semantically equivalent output summaries compared to the\nreferences, even though the overlap at the exact lexicon level is lower, as\nreflected in the lower ROUGE scores. This work sheds some light on how\nperspective-aware ISP (PA-ISP) can be deployed for clinical report\nsummarisation and support better communication between patients and clinicians.", "published": "2025-09-09 11:52:16", "link": "http://arxiv.org/abs/2509.07622v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment", "abstract": "In recent years, there has been substantial progress in using pretrained\nLanguage Models (LMs) on a range of tasks aimed at improving the understanding\nof biomedical texts. Nonetheless, existing biomedical LLMs show limited\ncomprehension of complex, domain-specific concept structures and the factual\ninformation encoded in biomedical Knowledge Graphs (KGs). In this work, we\npropose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel\njoint LM and KG pre-training method that augments an LM with external knowledge\nby the simultaneous learning of a dedicated KG encoder and aligning the\nrepresentations of both the LM and the graph. For a given textual sequence, we\nlink biomedical concept mentions to the Unified Medical Language System (UMLS)\nKG and utilize local KG subgraphs as cross-modal positive samples for these\nmentions. Our empirical findings indicate that implementing our method on\nseveral leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves\ntheir performance on a range of language understanding tasks and the quality of\nentity representations, even with minimal pre-training on a small alignment\ndataset sourced from PubMed scientific abstracts.", "published": "2025-09-09 10:59:47", "link": "http://arxiv.org/abs/2509.07588v1", "categories": ["cs.CL", "cs.AI", "I.2.7; H.3.3; J.3"], "primary_category": "cs.CL"}
{"title": "Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition", "abstract": "In a rapidly evolving world where information updates swiftly, knowledge in\nlarge language models (LLMs) becomes outdated quickly. Retraining LLMs is not a\ncost-effective option, making knowledge editing (KE) without modifying\nparameters particularly necessary. We find that although existing\nretrieval-augmented generation (RAG)-based KE methods excel at editing simple\nknowledge, they struggle with KE in multi-hop question answering due to the\nissue of \"edit skipping\", which refers to skipping the relevant edited fact in\ninference. In addition to the diversity of natural language expressions of\nknowledge, edit skipping also arises from the mismatch between the granularity\nof LLMs in problem-solving and the facts in the edited memory. To address this\nissue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing\nmethod with guided decomposition (IRAKE) through the guidance from single\nedited facts and entire edited cases. Experimental results demonstrate that\nIRAKE mitigates the failure of editing caused by edit skipping and outperforms\nstate-of-the-art methods for KE in multi-hop question answering.", "published": "2025-09-09 09:49:23", "link": "http://arxiv.org/abs/2509.07555v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents", "abstract": "With the rapid progress of multimodal large language models, operating system\n(OS) agents become increasingly capable of automating tasks through on-device\ngraphical user interfaces (GUIs). However, most existing OS agents are designed\nfor idealized settings, whereas real-world environments often present\nuntrustworthy conditions. To mitigate risks of over-execution in such\nscenarios, we propose a query-driven human-agent-GUI interaction framework that\nenables OS agents to decide when to query humans for more reliable task\ncompletion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy\nOS agent trained with a two-stage learning paradigm that falicitate the\ndecoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent\nautonomously executes actions in normal conditions while proactively querying\nhumans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves\nthe average step-wise success rate by 20.64\\% in untrustworthy scenarios over\nthe state-of-the-art, without compromising normal performance. Analysis\nhighlights VeriOS-Agent's rationality, generalizability, and scalability. The\ncodes, datasets and models are available at\nhttps://github.com/Wuzheng02/VeriOS.", "published": "2025-09-09 09:46:01", "link": "http://arxiv.org/abs/2509.07553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data", "abstract": "Large language models (LLMs) have transformed NLP, yet their integration with\naudio remains underexplored -- despite audio's centrality to human\ncommunication. We introduce Falcon3-Audio, a family of Audio-Language Models\n(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably\nsmall amount of public audio data -- less than 30K hours (5K unique) --\nFalcon3-Audio-7B matches the best reported performance among open-weight models\non the MMAU benchmark, with a score of 64.14, matching R1-AQA, while\ndistinguishing itself through superior data and parameter efficiency,\nsingle-stage training, and transparency. Notably, our smallest 1B model remains\ncompetitive with larger open models ranging from 2B to 13B parameters. Through\nextensive ablations, we find that common complexities -- such as curriculum\nlearning, multiple audio encoders, and intricate cross-attention connectors --\nare not required for strong performance, even compared to models trained on\nover 500K hours of data.", "published": "2025-09-09 09:01:01", "link": "http://arxiv.org/abs/2509.07526v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
{"title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval", "abstract": "Many contemporary data-driven research efforts in the natural sciences, such\nas chemistry and materials science, require large-scale, high-performance\nentity recognition from scientific datasets. Large language models (LLMs) have\nincreasingly been adopted to solve the entity recognition task, with the same\ntrend being observed on all-spectrum NLP tasks. The prevailing entity\nrecognition LLMs rely on fine-tuned technology, yet the fine-tuning process\noften incurs significant cost. To achieve a best performance-cost trade-off, we\npropose ALLabel, a three-stage framework designed to select the most\ninformative and representative samples in preparing the demonstrations for LLM\nmodeling. The annotated examples are used to construct a ground-truth retrieval\ncorpus for LLM in-context learning. By sequentially employing three distinct\nactive learning strategies, ALLabel consistently outperforms all baselines\nunder the same annotation budget across three specialized domain datasets.\nExperimental results also demonstrate that selectively annotating only 5\\%-10\\%\nof the dataset with ALLabel can achieve performance comparable to the method\nannotating the entire dataset. Further analyses and ablation studies verify the\neffectiveness and generalizability of our proposal.", "published": "2025-09-09 08:47:13", "link": "http://arxiv.org/abs/2509.07512v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization", "abstract": "GPU kernel optimization has long been a central challenge at the intersection\nof high-performance computing and machine learning. Efficient kernels are\ncrucial for accelerating large language model (LLM) training and serving, yet\nattaining high performance typically requires extensive manual tuning.\nCompiler-based systems reduce some of this burden, but still demand substantial\nmanual design and engineering effort. Recently, researchers have explored using\nLLMs for GPU kernel generation, though prior work has largely focused on\ntranslating high-level PyTorch modules into CUDA code. In this work, we\nintroduce Astra, the first LLM-based multi-agent system for GPU kernel\noptimization. Unlike previous approaches, Astra starts from existing CUDA\nimplementations extracted from SGLang, a widely deployed framework for serving\nLLMs, rather than treating PyTorch modules as the specification. Within Astra,\nspecialized LLM agents collaborate through iterative code generation, testing,\nprofiling, and planning to produce kernels that are both correct and\nhigh-performance. On kernels from SGLang, Astra achieves an average speedup of\n1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study\nfurther demonstrates that LLMs can autonomously apply loop transformations,\noptimize memory access patterns, exploit CUDA intrinsics, and leverage fast\nmath operations to yield substantial performance gains. Our work highlights\nmulti-agent LLM systems as a promising new paradigm for GPU kernel\noptimization.", "published": "2025-09-09 08:39:50", "link": "http://arxiv.org/abs/2509.07506v1", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.DC"}
{"title": "HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention", "abstract": "Detecting content that contradicts or is unsupported by a given source text\nis a critical challenge for the safe deployment of generative language models.\nWe introduce HALT-RAG, a post-hoc verification system designed to identify\nhallucinations in the outputs of Retrieval-Augmented Generation (RAG)\npipelines. Our flexible and task-adaptable framework uses a universal feature\nset derived from an ensemble of two frozen, off-the-shelf Natural Language\nInference (NLI) models and lightweight lexical signals. These features are used\nto train a simple, calibrated, and task-adapted meta-classifier. Using a\nrigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and\nproduce unbiased estimates, we evaluate our system on the HaluEval benchmark.\nBy pairing our universal feature set with a lightweight, task-adapted\nclassifier and a precision-constrained decision policy, HALT-RAG achieves\nstrong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,\nand dialogue tasks, respectively. The system's well-calibrated probabilities\nenable a practical abstention mechanism, providing a reliable tool for\nbalancing model performance with safety requirements.", "published": "2025-09-09 07:58:46", "link": "http://arxiv.org/abs/2509.07475v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation", "abstract": "The linguistic diversity across the African continent presents different\nchallenges and opportunities for machine translation. This study explores the\neffects of data augmentation techniques in improving translation systems in\nlow-resource African languages. We focus on two data augmentation techniques:\nsentence concatenation with back translation and switch-out, applying them\nacross six African languages. Our experiments show significant improvements in\nmachine translation performance, with a minimum increase of 25\\% in BLEU score\nacross all six languages.We provide a comprehensive analysis and highlight the\npotential of these techniques to improve machine translation systems for\nlow-resource languages, contributing to the development of more robust\ntranslation systems for under-resourced languages.", "published": "2025-09-09 07:49:37", "link": "http://arxiv.org/abs/2509.07471v1", "categories": ["cs.CL", "68T50", "I.7"], "primary_category": "cs.CL"}
{"title": "Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts", "abstract": "Stigmatizing language results in healthcare inequities, yet there is no\nuniversally accepted or standardized lexicon defining which words, terms, or\nphrases constitute stigmatizing language in healthcare. We conducted a\nsystematic search of the literature to identify existing stigmatizing language\nlexicons and then analyzed them comparatively to examine: 1) similarities and\ndiscrepancies between these lexicons, and 2) the distribution of positive,\nnegative, or neutral terms based on an established sentiment dataset. Our\nsearch identified four lexicons. The analysis results revealed moderate\nsemantic similarity among them, and that most stigmatizing terms are related to\njudgmental expressions by clinicians to describe perceived negative behaviors.\nSentiment analysis showed a predominant proportion of negatively classified\nterms, though variations exist across lexicons. Our findings underscore the\nneed for a standardized lexicon and highlight challenges in defining\nstigmatizing language in clinical texts.", "published": "2025-09-09 07:41:20", "link": "http://arxiv.org/abs/2509.07462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training", "abstract": "Positive, supportive online communication in social media (candy speech) has\nthe potential to foster civility, yet automated detection of such language\nremains underexplored, limiting systematic analysis of its impact. We\ninvestigate how candy speech can be reliably detected in a 46k-comment German\nYouTube corpus by monolingual and multilingual language models, including\nGBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual\nXLM-RoBERTa-Large model trained to detect candy speech at the span level\noutperforms other approaches, ranking first in both binary positive F1: 0.8906)\nand categorized span-based detection (strict F1: 0.6307) subtasks at the\nGermEval 2025 Shared Task on Candy Speech Detection. We speculate that\nspan-based training, multilingual capabilities, and emoji-aware tokenizers\nimproved detection performance. Our results demonstrate the effectiveness of\nmultilingual models in identifying positive, supportive language.", "published": "2025-09-09 07:29:14", "link": "http://arxiv.org/abs/2509.07459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization", "abstract": "Cross-View Geo-Localization (CVGL) focuses on identifying correspondences\nbetween images captured from distinct perspectives of the same geographical\nlocation. However, existing CVGL approaches are typically restricted to a\nsingle view or modality, and their direct visual matching strategy lacks\ninterpretability: they merely predict whether two images correspond, without\nexplaining the rationale behind the match. In this paper, we present GLEAM-C, a\nfoundational CVGL model that unifies multiple views and modalities-including\nUAV imagery, street maps, panoramic views, and ground photographs-by aligning\nthem exclusively with satellite imagery. Our framework enhances training\nefficiency through optimized implementation while achieving accuracy comparable\nto prior modality-specific CVGL models through a two-phase training strategy.\nMoreover, to address the lack of interpretability in traditional CVGL methods,\nwe leverage the reasoning capabilities of multimodal large language models\n(MLLMs) to propose a new task, GLEAM-X, which combines cross-view\ncorrespondence prediction with explainable reasoning. To support this task, we\nconstruct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro\nto generate training and testing data. The test set is further refined through\ndetailed human revision, enabling systematic evaluation of explainable\ncross-view reasoning and advancing transparency and scalability in\ngeo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL\npipeline that integrates multi-modal, multi-view alignment with interpretable\ncorrespondence analysis, unifying accurate cross-view matching with explainable\nreasoning and advancing Geo-Localization by enabling models to better Explain\nAnd Match. Code and datasets used in this work will be made publicly accessible\nat https://github.com/Lucky-Lance/GLEAM.", "published": "2025-09-09 07:14:31", "link": "http://arxiv.org/abs/2509.07450v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Self-Play For Data-Free Training", "abstract": "Large language models (LLMs) have advanced rapidly in recent years, driven by\nscale, abundant high-quality training data, and reinforcement learning. Yet\nthis progress faces a fundamental bottleneck: the need for ever more data from\nwhich models can continue to learn. In this work, we propose a reinforcement\nlearning approach that removes this dependency by enabling models to improve\nwithout additional data. Our method leverages a game-theoretic framework of\nself-play, where a model's capabilities are cast as performance in a\ncompetitive game and stronger policies emerge by having the model play against\nitself - a process we call Language Self-Play (LSP). Experiments with\nLlama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained\nmodels can not only enhance their performance on challenging tasks through\nself-play alone, but can also do so more effectively than data-driven\nbaselines.", "published": "2025-09-09 05:51:34", "link": "http://arxiv.org/abs/2509.07414v1", "categories": ["cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.AI"}
{"title": "LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction", "abstract": "Large language models (LLMs) make significant progress in Emotional\nIntelligence (EI) and long-context understanding. However, existing benchmarks\ntend to overlook certain aspects of EI in long-context scenarios, especially\nunder realistic, practical settings where interactions are lengthy, diverse,\nand often noisy. To move towards such realistic settings, we present\nLongEmotion, a benchmark specifically designed for long-context EI tasks. It\ncovers a diverse set of tasks, including Emotion Classification, Emotion\nDetection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion\nExpression. On average, the input length for these tasks reaches 8,777 tokens,\nwith long-form generation required for Emotion Expression. To enhance\nperformance under realistic constraints, we incorporate Retrieval-Augmented\nGeneration (RAG) and Collaborative Emotional Modeling (CoEM), and compare them\nwith standard prompt-based methods. Unlike conventional approaches, our RAG\nmethod leverages both the conversation context and the large language model\nitself as retrieval sources, avoiding reliance on external knowledge bases. The\nCoEM method further improves performance by decomposing the task into five\nstages, integrating both retrieval augmentation and limited knowledge\ninjection. Experimental results show that both RAG and CoEM consistently\nenhance EI-related performance across most long-context tasks, advancing LLMs\ntoward more practical and real-world EI applications. Furthermore, we conducted\na comparative case study experiment on the GPT series to demonstrate the\ndifferences among various models in terms of EI. Code is available on GitHub at\nhttps://github.com/LongEmotion/LongEmotion, and the project page can be found\nat https://longemotion.github.io/.", "published": "2025-09-09 05:32:45", "link": "http://arxiv.org/abs/2509.07403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering", "abstract": "Integrating knowledge graphs (KGs) into the reasoning processes of large\nlanguage models (LLMs) has emerged as a promising approach to mitigate\nhallucination. However, existing work in this area often relies on proprietary\nor extremely large models, limiting accessibility and scalability. In this\nstudy, we investigate the capabilities of existing integration methods for\nsmall language models (SLMs) in KG-based question answering and observe that\ntheir performance is often constrained by their limited ability to traverse and\nreason over knowledge graphs. To address this limitation, we propose leveraging\nsimple and efficient exploration modules to handle knowledge graph traversal in\nplace of the language model itself. Experiment results demonstrate that these\nlightweight modules effectively improve the performance of small language\nmodels on knowledge graph question answering tasks. Source code:\nhttps://github.com/yijie-cheng/SLM-ToG/.", "published": "2025-09-09 05:26:29", "link": "http://arxiv.org/abs/2509.07399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents", "abstract": "Existing evaluation studies on linguistic competence of large language models\n(LLM agents) have focused primarily on vocabulary learning, morphological rule\ninduction, syntactic generalization, pragmatic inference, and cross-linguistic\ntransfer. However, none assess whether LLM agents can acquire a language\nthrough pattern recognition and interactive feedback, a central feature of\nhuman language acquisition. We propose a novel experimental framework in which\nan LLM agent is evaluated on its ability to acquire and use a newly constructed\nlanguage (Tinkatongue) in conversation with a bot that understands only\nTinkatongue. Our findings show that LLM agents fail to establish a conversation\nwithin 100 responses, yet they adopt distinct strategies that mirror human\napproaches to language learning. The results suggest a new direction for\nevaluation benchmarks and open pathways to model designs that learn more\neffectively from interactive feedback.", "published": "2025-09-09 05:09:27", "link": "http://arxiv.org/abs/2509.07389v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions", "abstract": "Recent advancements in Large Language Models (LLMs) demonstrate remarkable\ncapabilities across various fields. These developments have led to more direct\ncommunication between humans and LLMs in various situations, such as social\ncompanionship and psychological support. However, LLMs often exhibit\nlimitations in emotional perception and social competence during real-world\nconversations. These limitations partly originate from their inability to adapt\ntheir communication style and emotional expression to different social and task\ncontexts. In this work, we introduce PersonaFuse, a novel LLM post-training\nframework that enables LLMs to adapt and express different personalities for\nvarying situations. Inspired by Trait Activation Theory and the Big Five\npersonality model, PersonaFuse employs a Mixture-of-Expert architecture that\ncombines persona adapters with a dynamic routing network, enabling contextual\ntrait expression. Experimental results show that PersonaFuse substantially\noutperforms baseline models across multiple dimensions of social-emotional\nintelligence. Importantly, these gains are achieved without sacrificing general\nreasoning ability or model safety, which remain common limitations of direct\nprompting and supervised fine-tuning approaches. PersonaFuse also delivers\nconsistent improvements in downstream human-centered applications, such as\nmental health counseling and review-based customer service. Finally, human\npreference evaluations against leading LLMs, including GPT-4o and DeepSeek,\ndemonstrate that PersonaFuse achieves competitive response quality despite its\ncomparatively smaller model size. These findings demonstrate that\nPersonaFuse~offers a theoretically grounded and practical approach for\ndeveloping social-emotional enhanced LLMs, marking a significant advancement\ntoward more human-centric AI systems.", "published": "2025-09-09 03:39:28", "link": "http://arxiv.org/abs/2509.07370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation", "abstract": "Transformer-based self-attention mechanism serves as the core of modern\nlanguage models, yet it often suffers from localization, where attentions\ncollapse onto a limited subset of tokens and fail to capture long-range\ndependencies. To address this issue, we propose Self-Attention One-step Belief\nPropagation (SAOBP), a refinement framework that injects multi-hop\nrelationships through a belief propagation process. To interpret and quantify\nthese interactions, we introduce Global Token Dependency (GTD) that captures\nthe relative contribution of multihop connections within the attention graph.\nEmpirical results indicate that SAOBP helps prevent entropy collapse in deeper\nlayers and adaptively maintains GTD at task-appropriate levels, thereby\nsupporting improvements in model performance. Importantly, we observe\ncompetitive gains in small-scale models, highlighting its potential for\nimproving inference quality in resource-constrained scenarios.", "published": "2025-09-09 01:43:48", "link": "http://arxiv.org/abs/2509.07324v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations", "abstract": "Recent advances in large language models (LLMs) have been driven by\npretraining, supervised fine tuning (SFT), and alignment tuning. Among these,\nSFT plays a crucial role in transforming a model 's general knowledge into\nstructured responses tailored to specific tasks. However, there is no clearly\nestablished methodology for effective training data selection. Simply\nincreasing the volume of data does not guarantee performance improvements,\nwhile preprocessing, sampling, and validation require substantial time and\ncost.\n  To address this issue, a variety of data selection methods have been\nproposed. Among them, knowledge based selection approaches identify suitable\ntraining data by analyzing the model 's responses. Nevertheless, these methods\ntypically rely on prompt engineering, making them sensitive to variations and\nincurring additional costs for prompt design.\n  In this study, we propose Knowledge Analysis via Model Internal\nRepresentations (KAMIR), a novel approach that overcomes these limitations by\nanalyzing data based on the model 's internal representations. KAMIR computes\nsimilarities between the hidden states of each layer (block) and the final\nhidden states for a given input to assess the data. Unlike prior methods that\nwere largely limited to multiple choice tasks, KAMIR can be applied to a wide\nrange of tasks such as machine reading comprehension and summarization.\nMoreover, it selects data useful for training based on the model 's familiarity\nwith the input, even with a small dataset and a simple classifier architecture.\nExperiments across diverse task datasets demonstrate that training with less\nfamiliar data leads to better generalization performance.", "published": "2025-09-09 01:08:15", "link": "http://arxiv.org/abs/2509.07311v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Instance-level Performance Prediction for Long-form Generation Tasks", "abstract": "We motivate and share a new benchmark for instance-level performance\nprediction of long-form generation tasks having multi-faceted, fine-grained\nquality metrics. Our task-, model- and metric-agnostic formulation predicts\ncontinuous evaluation metric scores given only black-box model inputs and\noutputs. Beyond predicting point estimates of metric scores, the benchmark also\nrequires inferring prediction intervals to quantify uncertainty around point\nestimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,\nbaselines, and metrics per task. We show that scores can be effectively\npredicted across long-form generation tasks using as few as 16 training\nexamples. Overall, we introduce a novel and useful task, a valuable benchmark\nto drive progress, and baselines ready for practical adoption today.", "published": "2025-09-09 00:59:34", "link": "http://arxiv.org/abs/2509.07309v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Basis Vector Metric: A Method for Robust Open-Ended State Change Detection", "abstract": "We test a new method, which we will abbreviate using the acronym BVM (Basis\nVectors Method), in its ability to judge the state changes in images through\nusing language embeddings. We used the MIT-States dataset, containing about\n53,000 images, to gather all of our data, which has 225 nouns and 115\nadjectives, with each noun having about 9 different adjectives, forming\napproximately 1000 noun-adjective pairs. For our first experiment, we test our\nmethod's ability to determine the state of each noun class separately against\nother metrics for comparison. These metrics are cosine similarity, dot product,\nproduct quantization, binary index, Naive Bayes, and a custom neural network.\nAmong these metrics, we found that our proposed BVM performs the best in\nclassifying the states for each noun. We then perform a second experiment where\nwe try using BVM to determine if it can differentiate adjectives from one\nanother for each adjective separately. We compared the abilities of BVM to\ndifferentiate adjectives against the proposed method the MIT-States paper\nsuggests: using a logistic regression model. In the end, we did not find\nconclusive evidence that our BVM metric could perform better than the logistic\nregression model at discerning adjectives. Yet, we were able to find evidence\nfor possible improvements to our method; this leads to the chance of increasing\nour method's accuracy through certain changes in our methodologies.", "published": "2025-09-09 00:58:43", "link": "http://arxiv.org/abs/2509.07308v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Causal Attention with Lookahead Keys", "abstract": "In standard causal attention, each token's query, key, and value (QKV) are\nstatic and encode only preceding context. We introduce CAuSal aTtention with\nLookahead kEys (CASTLE), an attention mechanism that continually updates each\ntoken's keys as the context unfolds. We term these updated keys lookahead keys\nbecause they belong to earlier positions yet integrate information from tokens\nthat appear later relative to those positions, while strictly preserving the\nautoregressive property. Although the mechanism appears sequential, we derive a\nmathematical equivalence that avoids explicitly materializing lookahead keys at\neach position and enables efficient parallel training. On language modeling\nbenchmarks, CASTLE consistently outperforms standard causal attention across\nmodel scales, reducing validation perplexity and improving performance on a\nrange of downstream tasks.", "published": "2025-09-09 00:15:23", "link": "http://arxiv.org/abs/2509.07301v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare", "abstract": "We develop new experimental paradigms for measuring welfare in language\nmodels. We compare verbal reports of models about their preferences with\npreferences expressed through behavior when navigating a virtual environment\nand selecting conversation topics. We also test how costs and rewards affect\nbehavior and whether responses to an eudaimonic welfare scale - measuring\nstates such as autonomy and purpose in life - are consistent across\nsemantically equivalent prompts. Overall, we observed a notable degree of\nmutual support between our measures. The reliable correlations observed between\nstated preferences and behavior across conditions suggest that preference\nsatisfaction can, in principle, serve as an empirically measurable welfare\nproxy in some of today's AI systems. Furthermore, our design offered an\nilluminating setting for qualitative observation of model behavior. Yet, the\nconsistency between measures was more pronounced in some models and conditions\nthan others and responses were not consistent across perturbations. Due to\nthis, and the background uncertainty about the nature of welfare and the\ncognitive states (and welfare subjecthood) of language models, we are currently\nuncertain whether our methods successfully measure the welfare state of\nlanguage models. Nevertheless, these findings highlight the feasibility of\nwelfare measurement in language models, inviting further exploration.", "published": "2025-09-09 17:48:44", "link": "http://arxiv.org/abs/2509.07961v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ACE and Diverse Generalization via Selective Disagreement", "abstract": "Deep neural networks are notoriously sensitive to spurious correlations -\nwhere a model learns a shortcut that fails out-of-distribution. Existing work\non spurious correlations has often focused on incomplete\ncorrelations,leveraging access to labeled instances that break the correlation.\nBut in cases where the spurious correlations are complete, the correct\ngeneralization is fundamentally \\textit{underspecified}. To resolve this\nunderspecification, we propose learning a set of concepts that are consistent\nwith training data but make distinct predictions on a subset of novel unlabeled\ninputs. Using a self-training approach that encourages \\textit{confident} and\n\\textit{selective} disagreement, our method ACE matches or outperforms existing\nmethods on a suite of complete-spurious correlation benchmarks, while remaining\nrobust to incomplete spurious correlations. ACE is also more configurable than\nprior approaches, allowing for straight-forward encoding of prior knowledge and\nprincipled unsupervised model selection. In an early application to\nlanguage-model alignment, we find that ACE achieves competitive performance on\nthe measurement tampering detection benchmark \\textit{without} access to\nuntrusted measurements. While still subject to important limitations, ACE\nrepresents significant progress towards overcoming underspecification.", "published": "2025-09-09 17:43:05", "link": "http://arxiv.org/abs/2509.07955v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges", "abstract": "Multi-modal multi-task (M3T) foundation models (FMs) have recently shown\ntransformative potential in artificial intelligence, with emerging applications\nin education. However, their deployment in real-world educational settings is\nhindered by privacy regulations, data silos, and limited domain-specific data\navailability. We introduce M3T Federated Foundation Models (FedFMs) for\neducation: a paradigm that integrates federated learning (FL) with M3T FMs to\nenable collaborative, privacy-preserving training across decentralized\ninstitutions while accommodating diverse modalities and tasks. Subsequently,\nthis position paper aims to unveil M3T FedFMs as a promising yet underexplored\napproach to the education community, explore its potentials, and reveal its\nrelated future research directions. We outline how M3T FedFMs can advance three\ncritical pillars of next-generation intelligent education systems: (i) privacy\npreservation, by keeping sensitive multi-modal student and institutional data\nlocal; (ii) personalization, through modular architectures enabling tailored\nmodels for students, instructors, and institutions; and (iii) equity and\ninclusivity, by facilitating participation from underrepresented and\nresource-constrained entities. We finally identify various open research\nchallenges, including studying of (i) inter-institution heterogeneous privacy\nregulations, (ii) the non-uniformity of data modalities' characteristics, (iii)\nthe unlearning approaches for M3T FedFMs, (iv) the continual learning\nframeworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must\nbe collectively addressed for practical deployment.", "published": "2025-09-09 17:31:42", "link": "http://arxiv.org/abs/2509.07946v1", "categories": ["cs.LG", "cs.AI", "cs.ET"], "primary_category": "cs.LG"}
{"title": "ImportSnare: Directed \"Code Manual\" Hijacking in Retrieval-Augmented Code Generation", "abstract": "Code generation has emerged as a pivotal capability of Large Language\nModels(LLMs), revolutionizing development efficiency for programmers of all\nskill levels. However, the complexity of data structures and algorithmic logic\noften results in functional deficiencies and security vulnerabilities in\ngenerated code, reducing it to a prototype requiring extensive manual\ndebugging. While Retrieval-Augmented Generation (RAG) can enhance correctness\nand security by leveraging external code manuals, it simultaneously introduces\nnew attack surfaces.\n  In this paper, we pioneer the exploration of attack surfaces in\nRetrieval-Augmented Code Generation (RACG), focusing on malicious dependency\nhijacking. We demonstrate how poisoned documentation containing hidden\nmalicious dependencies (e.g., matplotlib_safe) can subvert RACG, exploiting\ndual trust chains: LLM reliance on RAG and developers' blind trust in LLM\nsuggestions. To construct poisoned documents, we propose ImportSnare, a novel\nattack framework employing two synergistic strategies: 1)Position-aware beam\nsearch optimizes hidden ranking sequences to elevate poisoned documents in\nretrieval results, and 2)Multilingual inductive suggestions generate\njailbreaking sequences to manipulate LLMs into recommending malicious\ndependencies. Through extensive experiments across Python, Rust, and\nJavaScript, ImportSnare achieves significant attack success rates (over 50% for\npopular libraries such as matplotlib and seaborn) in general, and is also able\nto succeed even when the poisoning ratio is as low as 0.01%, targeting both\ncustom and real-world malicious packages. Our findings reveal critical supply\nchain risks in LLM-powered development, highlighting inadequate security\nalignment for code generation tasks. To support future research, we will\nrelease the multilingual benchmark suite and datasets. The project homepage is\nhttps://importsnare.github.io.", "published": "2025-09-09 17:21:20", "link": "http://arxiv.org/abs/2509.07941v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Breaking Android with AI: A Deep Dive into LLM-Powered Exploitation", "abstract": "The rapid evolution of Artificial Intelligence (AI) and Large Language Models\n(LLMs) has opened up new opportunities in the area of cybersecurity, especially\nin the exploitation automation landscape and penetration testing. This study\nexplores Android penetration testing automation using LLM-based tools,\nespecially PentestGPT, to identify and execute rooting techniques. Through a\ncomparison of the traditional manual rooting process and exploitation methods\nproduced using AI, this study evaluates the efficacy, reliability, and\nscalability of automated penetration testing in achieving high-level privilege\naccess on Android devices. With the use of an Android emulator (Genymotion) as\nthe testbed, we fully execute both traditional and exploit-based rooting\nmethods, automating the process using AI-generated scripts. Secondly, we create\na web application by integrating OpenAI's API to facilitate automated script\ngeneration from LLM-processed responses. The research focuses on the\neffectiveness of AI-enabled exploitation by comparing automated and manual\npenetration testing protocols, by determining LLM weaknesses and strengths\nalong the way. We also provide security suggestions of AI-enabled exploitation,\nincluding ethical factors and potential misuse. The findings exhibit that while\nLLMs can significantly streamline the workflow of exploitation, they need to be\ncontrolled by humans to ensure accuracy and ethical application. This study\nadds to the increasing body of literature on AI-powered cybersecurity and its\neffect on ethical hacking, security research, and mobile device security.", "published": "2025-09-09 17:17:06", "link": "http://arxiv.org/abs/2509.07933v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s", "abstract": "As local AI grows in popularity, there is a critical gap between the\nbenchmark performance of object detectors and their practical viability on\nconsumer-grade hardware. While models like YOLOv10s promise real-time speeds,\nthese metrics are typically achieved on high-power, desktop-class GPUs. This\npaper reveals that on resource-constrained systems, such as laptops with RTX\n4060 GPUs, performance is not compute-bound but is instead dominated by\nsystem-level bottlenecks, as illustrated by a simple bottleneck test. To\novercome this hardware-level constraint, we introduce a Two-Pass Adaptive\nInference algorithm, a model-independent approach that requires no\narchitectural changes. This study mainly focuses on adaptive inference\nstrategies and undertakes a comparative analysis of architectural early-exit\nand resolution-adaptive routing, highlighting their respective trade-offs\nwithin a unified evaluation framework. The system uses a fast, low-resolution\npass and only escalates to a high-resolution model pass when detection\nconfidence is low. On a 5000-image COCO dataset, our method achieves a 1.85x\nspeedup over a PyTorch Early-Exit baseline, with a modest mAP loss of 5.51%.\nThis work provides a practical and reproducible blueprint for deploying\nhigh-performance, real-time AI on consumer-grade devices by shifting the focus\nfrom pure model optimization to hardware-aware inference strategies that\nmaximize throughput.", "published": "2025-09-09 17:13:31", "link": "http://arxiv.org/abs/2509.07928v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation", "abstract": "Digital dentistry represents a transformative shift in modern dental\npractice. The foundational step in this transformation is the accurate digital\nrepresentation of the patient's dentition, which is obtained from segmented\nCone-Beam Computed Tomography (CBCT) and Intraoral Scans (IOS). Despite the\ngrowing interest in digital dental technologies, existing segmentation\nmethodologies frequently lack rigorous validation and demonstrate limited\nperformance and clinical applicability. To the best of our knowledge, this is\nthe first work to introduce a multimodal pretraining framework for tooth\nsegmentation. We present ToothMCL, a Tooth Multimodal Contrastive Learning for\npretraining that integrates volumetric (CBCT) and surface-based (IOS)\nmodalities. By capturing modality-invariant representations through multimodal\ncontrastive learning, our approach effectively models fine-grained anatomical\nfeatures, enabling precise multi-class segmentation and accurate identification\nof F\\'ed\\'eration Dentaire Internationale (FDI) tooth numbering. Along with the\nframework, we curated CBCT-IOS3.8K, the largest paired CBCT and IOS dataset to\ndate, comprising 3,867 patients. We then evaluated ToothMCL on a comprehensive\ncollection of independent datasets, representing the largest and most diverse\nevaluation to date. Our method achieves state-of-the-art performance in both\ninternal and external testing, with an increase of 12\\% for CBCT segmentation\nand 8\\% for IOS segmentation in the Dice Similarity Coefficient (DSC).\nFurthermore, ToothMCL consistently surpasses existing approaches in tooth\ngroups and demonstrates robust generalizability across varying imaging\nconditions and clinical scenarios.", "published": "2025-09-09 17:05:04", "link": "http://arxiv.org/abs/2509.07923v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?", "abstract": "Recently, the physical capabilities of (M)LLMs have garnered increasing\nattention. However, existing benchmarks for physics suffer from two major gaps:\nthey neither provide systematic and up-to-date coverage of real-world physics\ncompetitions such as physics Olympiads, nor enable direct performance\ncomparison with humans. To bridge these gaps, we present HiPhO, the first\nbenchmark dedicated to high school physics Olympiads with human-aligned\nevaluation. Specifically, HiPhO highlights three key innovations. (1)\nComprehensive Data: It compiles 13 latest Olympiad exams from 2024-2025,\nspanning both international and regional competitions, and covering mixed\nmodalities that encompass problems spanning text-only to diagram-based. (2)\nProfessional Evaluation: We adopt official marking schemes to perform\nfine-grained grading at both the answer and step level, fully aligned with\nhuman examiners to ensure high-quality and domain-specific evaluation. (3)\nComparison with Human Contestants: We assign gold, silver, and bronze medals to\nmodels based on official medal thresholds, thereby enabling direct comparison\nbetween (M)LLMs and human contestants. Our large-scale evaluation of 30\nstate-of-the-art (M)LLMs shows that: across 13 exams, open-source MLLMs mostly\nremain at or below the bronze level; open-source LLMs show promising progress\nwith occasional golds; closed-source reasoning MLLMs can achieve 6 to 12 gold\nmedals; and most models still have a significant gap from full marks. These\nresults highlight a substantial performance gap between open-source models and\ntop students, the strong physical reasoning capabilities of closed-source\nreasoning models, and the fact that there is still significant room for\nimprovement. HiPhO, as a rigorous, human-aligned, and Olympiad-focused\nbenchmark for advancing multimodal physical reasoning, is open-source and\navailable at https://github.com/SciYu/HiPhO.", "published": "2025-09-09 16:24:51", "link": "http://arxiv.org/abs/2509.07894v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Active Membership Inference Test (aMINT): Enhancing Model Auditability with Multi-Task Learning", "abstract": "Active Membership Inference Test (aMINT) is a method designed to detect\nwhether given data were used during the training of machine learning models. In\nActive MINT, we propose a novel multitask learning process that involves\ntraining simultaneously two models: the original or Audited Model, and a\nsecondary model, referred to as the MINT Model, responsible for identifying the\ndata used for training the Audited Model. This novel multi-task learning\napproach has been designed to incorporate the auditability of the model as an\noptimization objective during the training process of neural networks. The\nproposed approach incorporates intermediate activation maps as inputs to the\nMINT layers, which are trained to enhance the detection of training data. We\npresent results using a wide range of neural networks, from lighter\narchitectures such as MobileNet to more complex ones such as Vision\nTransformers, evaluated in 5 public benchmarks. Our proposed Active MINT\nachieves over 80% accuracy in detecting if given data was used for training,\nsignificantly outperforming previous approaches in the literature. Our aMINT\nand related methodological developments contribute to increasing transparency\nin AI models, facilitating stronger safeguards in AI deployments to achieve\nproper security, privacy, and copyright protection.", "published": "2025-09-09 16:00:03", "link": "http://arxiv.org/abs/2509.07879v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CP-Model-Zoo: A Natural Language Query System for Constraint Programming Models", "abstract": "Constraint Programming and its high-level modeling languages have long been\nrecognized for their potential to achieve the holy grail of problem-solving.\nHowever, the complexity of modeling languages, the large number of global\nconstraints, and the art of creating good models have often hindered\nnon-experts from choosing CP to solve their combinatorial problems. While\ngenerating an expert-level model from a natural-language description of a\nproblem would be the dream, we are not yet there. We propose a tutoring system\ncalled CP-Model-Zoo, exploiting expert-written models accumulated through the\nyears. CP-Model-Zoo retrieves the closest source code model from a database\nbased on a user's natural language description of a combinatorial problem. It\nensures that expert-validated models are presented to the user while\neliminating the need for human data labeling. Our experiments show excellent\naccuracy in retrieving the correct model based on a user-input description of a\nproblem simulated with different levels of expertise.", "published": "2025-09-09 15:55:15", "link": "http://arxiv.org/abs/2509.07867v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs", "abstract": "Existing code large language models (LLMs) often rely on large-scale\ninstruction data distilled from proprietary LLMs for fine-tuning, which\ntypically incurs high costs. In this paper, we explore the potential of\nsmall-scale open-source LLMs (e.g., 7B) as synthesizers for high-quality code\ninstruction data construction. We first observe that the data synthesis\ncapability of small-scale LLMs can be enhanced by training on a few superior\ndata synthesis samples from proprietary LLMs. Building on this, we propose a\nnovel iterative self-distillation approach to bootstrap small-scale LLMs,\ntransforming them into powerful synthesizers that reduce reliance on\nproprietary LLMs and minimize costs. Concretely, in each iteration, to obtain\ndiverse and high-quality self-distilled data, we design multi-checkpoint\nsampling and multi-aspect scoring strategies for initial data selection.\nFurthermore, to identify the most influential samples, we introduce a\ngradient-based influence estimation method for final data filtering. Based on\nthe code instruction datasets from the small-scale synthesizers, we develop\nSCoder, a family of code generation models fine-tuned from DeepSeek-Coder.\nSCoder models achieve state-of-the-art code generation capabilities,\ndemonstrating the effectiveness of our method.", "published": "2025-09-09 15:38:44", "link": "http://arxiv.org/abs/2509.07858v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Learning-Based Burned Area Mapping Using Bi-Temporal Siamese Networks and AlphaEarth Foundation Datasets", "abstract": "Accurate and timely mapping of burned areas is crucial for environmental\nmonitoring, disaster management, and assessment of climate change. This study\npresents a novel approach to automated burned area mapping using the AlphaEArth\ndataset combined with the Siamese U-Net deep learning architecture. The\nAlphaEArth Dataset, comprising high-resolution optical and thermal infrared\nimagery with comprehensive ground-truth annotations, provides an unprecedented\nresource for training robust burned area detection models. We trained our model\nwith the Monitoring Trends in Burn Severity (MTBS) dataset in the contiguous US\nand evaluated it with 17 regions cross in Europe. Our experimental results\ndemonstrate that the proposed ensemble approach achieves superior performance\nwith an overall accuracy of 95%, IoU of 0.6, and F1-score of 74% on the test\ndataset. The model successfully identifies burned areas across diverse\necosystems with complex background, showing particular strength in detecting\npartially burned vegetation and fire boundaries and its transferability and\nhigh generalization in burned area mapping. This research contributes to the\nadvancement of automated fire damage assessment and provides a scalable\nsolution for global burn area monitoring using the AlphaEarth dataset.", "published": "2025-09-09 15:29:18", "link": "http://arxiv.org/abs/2509.07852v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Aligning LLMs for the Classroom with Knowledge-Based Retrieval -- A Comparative RAG Study", "abstract": "Large language models like ChatGPT are increasingly used in classrooms, but\nthey often provide outdated or fabricated information that can mislead\nstudents. Retrieval Augmented Generation (RAG) improves reliability of LLMs by\ngrounding responses in external resources. We investigate two accessible RAG\nparadigms, vector-based retrieval and graph-based retrieval to identify best\npractices for classroom question answering (QA). Existing comparative studies\nfail to account for pedagogical factors such as educational disciplines,\nquestion types, and practical deployment costs. Using a novel dataset,\nEduScopeQA, of 3,176 questions across academic subjects, we measure performance\non various educational query types, from specific facts to broad thematic\ndiscussions. We also evaluate system alignment with a dataset of systematically\naltered textbooks that contradict the LLM's latent knowledge. We find that\nOpenAI Vector Search RAG (representing vector-based RAG) performs well as a\nlow-cost generalist, especially for quick fact retrieval. On the other hand,\nGraphRAG Global excels at providing pedagogically rich answers to thematic\nqueries, and GraphRAG Local achieves the highest accuracy with the dense,\naltered textbooks when corpus integrity is critical. Accounting for the 10-20x\nhigher resource usage of GraphRAG (representing graph-based RAG), we show that\na dynamic branching framework that routes queries to the optimal retrieval\nmethod boosts fidelity and efficiency. These insights provide actionable\nguidelines for educators and system designers to integrate RAG-augmented LLMs\ninto learning environments effectively.", "published": "2025-09-09 15:22:33", "link": "http://arxiv.org/abs/2509.07846v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach", "abstract": "The rise of large reasoning language models (LRLMs) has unlocked new\npotential for solving complex tasks. These models operate with a thinking\nbudget, that is, a predefined number of reasoning tokens used to arrive at a\nsolution. We propose a novel approach, inspired by the generator/discriminator\nframework in generative adversarial networks, in which a critic model\nperiodically probes its own reasoning to assess whether it has reached a\nconfident conclusion. If not, reasoning continues until a target certainty\nthreshold is met. This mechanism adaptively balances efficiency and reliability\nby allowing early termination when confidence is high, while encouraging\nfurther reasoning when uncertainty persists. Through experiments on the\nAIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR)\nimproves baseline accuracy while reducing token usage. Importantly, extended\nmulti-seed evaluations over 64 runs demonstrate that CGR is stable, reducing\nvariance across seeds and improving exam-like performance under penalty-based\ngrading. Additionally, our token savings analysis shows that CGR can eliminate\nmillions of tokens in aggregate, with tunable trade-offs between certainty\nthresholds and efficiency. Together, these findings highlight certainty as a\npowerful signal for reasoning sufficiency. By integrating confidence into the\nreasoning process, CGR makes large reasoning language models more adaptive,\ntrustworthy, and resource efficient, paving the way for practical deployment in\ndomains where both accuracy and computational cost matter.", "published": "2025-09-09 14:57:15", "link": "http://arxiv.org/abs/2509.07820v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Forecasting Russian Equipment Losses Using Time Series and Deep Learning Models", "abstract": "This study applies a range of forecasting techniques,including ARIMA,\nProphet, Long Short Term Memory networks (LSTM), Temporal Convolutional\nNetworks (TCN), and XGBoost, to model and predict Russian equipment losses\nduring the ongoing war in Ukraine. Drawing on daily and monthly open-source\nintelligence (OSINT) data from WarSpotting, we aim to assess trends in\nattrition, evaluate model performance, and estimate future loss patterns\nthrough the end of 2025. Our findings show that deep learning models,\nparticularly TCN and LSTM, produce stable and consistent forecasts, especially\nunder conditions of high temporal granularity. By comparing different model\narchitectures and input structures, this study highlights the importance of\nensemble forecasting in conflict modeling, and the value of publicly available\nOSINT data in quantifying material degradation over time.", "published": "2025-09-09 14:52:31", "link": "http://arxiv.org/abs/2509.07813v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhanced SegNet with Integrated Grad-CAM for Interpretable Retinal Layer Segmentation in OCT Images", "abstract": "Optical Coherence Tomography (OCT) is essential for diagnosing conditions\nsuch as glaucoma, diabetic retinopathy, and age-related macular degeneration.\nAccurate retinal layer segmentation enables quantitative biomarkers critical\nfor clinical decision-making, but manual segmentation is time-consuming and\nvariable, while conventional deep learning models often lack interpretability.\nThis work proposes an improved SegNet-based deep learning framework for\nautomated and interpretable retinal layer segmentation. Architectural\ninnovations, including modified pooling strategies, enhance feature extraction\nfrom noisy OCT images, while a hybrid loss function combining categorical\ncross-entropy and Dice loss improves performance for thin and imbalanced\nretinal layers. Gradient-weighted Class Activation Mapping (Grad-CAM) is\nintegrated to provide visual explanations, allowing clinical validation of\nmodel decisions. Trained and validated on the Duke OCT dataset, the framework\nachieved 95.77% validation accuracy, a Dice coefficient of 0.9446, and a\nJaccard Index (IoU) of 0.8951. Class-wise results confirmed robust performance\nacross most layers, with challenges remaining for thinner boundaries. Grad-CAM\nvisualizations highlighted anatomically relevant regions, aligning segmentation\nwith clinical biomarkers and improving transparency. By combining architectural\nimprovements, a customized hybrid loss, and explainable AI, this study delivers\na high-performing SegNet-based framework that bridges the gap between accuracy\nand interpretability. The approach offers strong potential for standardizing\nOCT analysis, enhancing diagnostic efficiency, and fostering clinical trust in\nAI-driven ophthalmic tools.", "published": "2025-09-09 14:31:51", "link": "http://arxiv.org/abs/2509.07795v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Individual utilities of life satisfaction reveal inequality aversion unrelated to political alignment", "abstract": "How should well-being be prioritised in society, and what trade-offs are\npeople willing to make between fairness and personal well-being? We investigate\nthese questions using a stated preference experiment with a nationally\nrepresentative UK sample (n = 300), in which participants evaluated life\nsatisfaction outcomes for both themselves and others under conditions of\nuncertainty. Individual-level utility functions were estimated using an\nExpected Utility Maximisation (EUM) framework and tested for sensitivity to the\noverweighting of small probabilities, as characterised by Cumulative Prospect\nTheory (CPT). A majority of participants displayed concave (risk-averse)\nutility curves and showed stronger aversion to inequality in societal life\nsatisfaction outcomes than to personal risk. These preferences were unrelated\nto political alignment, suggesting a shared normative stance on fairness in\nwell-being that cuts across ideological boundaries. The results challenge use\nof average life satisfaction as a policy metric, and support the development of\nnonlinear utility-based alternatives that more accurately reflect collective\nhuman values. Implications for public policy, well-being measurement, and the\ndesign of value-aligned AI systems are discussed.", "published": "2025-09-09 14:30:24", "link": "http://arxiv.org/abs/2509.07793v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "XSRD-Net: EXplainable Stroke Relapse Detection", "abstract": "Stroke is the second most frequent cause of death world wide with an annual\nmortality of around 5.5 million. Recurrence rates of stroke are between 5 and\n25% in the first year. As mortality rates for relapses are extraordinarily high\n(40%) it is of utmost importance to reduce the recurrence rates. We address\nthis issue by detecting patients at risk of stroke recurrence at an early stage\nin order to enable appropriate therapy planning. To this end we collected 3D\nintracranial CTA image data and recorded concomitant heart diseases, the age\nand the gender of stroke patients between 2010 and 2024. We trained single- and\nmultimodal deep learning based neural networks for binary relapse detection\n(Task 1) and for relapse free survival (RFS) time prediction together with a\nsubsequent classification (Task 2). The separation of relapse from non-relapse\npatients (Task 1) could be solved with tabular data (AUC on test dataset:\n0.84). However, for the main task, the regression (Task 2), our multimodal\nXSRD-net processed the modalities vision:tabular with 0.68:0.32 according to\nmodality contribution measures. The c-index with respect to relapses for the\nmultimodal model reached 0.68, and the AUC is 0.71 for the test dataset. Final,\ndeeper interpretability analysis results could highlight a link between both\nheart diseases (tabular) and carotid arteries (vision) for the detection of\nrelapses and the prediction of the RFS time. This is a central outcome that we\nstrive to strengthen with ongoing data collection and model retraining.", "published": "2025-09-09 14:06:01", "link": "http://arxiv.org/abs/2509.07772v1", "categories": ["cs.CV", "cs.AI", "I.2.1"], "primary_category": "cs.CV"}
{"title": "What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring Motivations in Open-Source Projects", "abstract": "Context. Code refactoring improves software quality without changing external\nbehavior. Despite its advantages, its benefits are hindered by the considerable\ncost of time, resources, and continuous effort it demands. Aim. Understanding\nwhy developers refactor, and which metrics capture these motivations, may\nsupport wider and more effective use of refactoring in practice. Method. We\nperformed a large-scale empirical study to analyze developers refactoring\nactivity, leveraging Large Language Models (LLMs) to identify underlying\nmotivations from version control data, comparing our findings with previous\nmotivations reported in the literature. Results. LLMs matched human judgment in\n80% of cases, but aligned with literature-based motivations in only 47%. They\nenriched 22% of motivations with more detailed rationale, often highlighting\nreadability, clarity, and structural improvements. Most motivations were\npragmatic, focused on simplification and maintainability. While metrics related\nto developer experience and code readability ranked highest, their correlation\nwith motivation categories was weak. Conclusions. We conclude that LLMs\neffectively capture surface-level motivations but struggle with architectural\nreasoning. Their value lies in providing localized explanations, which, when\ncombined with software metrics, can form hybrid approaches. Such integration\noffers a promising path toward prioritizing refactoring more systematically and\nbalancing short-term improvements with long-term architectural goals.", "published": "2025-09-09 13:58:46", "link": "http://arxiv.org/abs/2509.07763v1", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks", "abstract": "Next to decision tree and k-nearest neighbours algorithms deep convolutional\nneural networks (CNNs) are widely used to classify audio data in many domains\nlike music, speech or environmental sounds. To train a specific CNN various\nspectral and rhythm features like mel-scaled spectrograms, mel-frequency\ncepstral coefficients (MFCC), cyclic tempograms, short-time Fourier transform\n(STFT) chromagrams, constant-Q transform (CQT) chromagrams and chroma energy\nnormalized statistics (CENS) chromagrams can be used as digital image input\ndata for the neural network. The performance of these spectral and rhythm\nfeatures for audio category level as well as audio class level classification\nis investigated in detail with a deep CNN and the ESC-50 dataset with 2,000\nlabeled environmental audio recordings using an end-to-end deep learning\npipeline. The evaluated metrics accuracy, precision, recall and F1 score for\nmulticlass classification clearly show that the mel-scaled spectrograms and the\nmel-frequency cepstral coefficients (MFCC) perform significantly better then\nthe other spectral and rhythm features investigated in this research for audio\nclassification tasks using deep CNNs.", "published": "2025-09-09 13:54:41", "link": "http://arxiv.org/abs/2509.07756v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Online Learning by Integrating Biosensors and Multimodal Learning Analytics for Detecting and Predicting Student Behavior: A Review", "abstract": "In modern online learning, understanding and predicting student behavior is\ncrucial for enhancing engagement and optimizing educational outcomes. This\nsystematic review explores the integration of biosensors and Multimodal\nLearning Analytics (MmLA) to analyze and predict student behavior during\ncomputer-based learning sessions. We examine key challenges, including emotion\nand attention detection, behavioral analysis, experimental design, and\ndemographic considerations in data collection. Our study highlights the growing\nrole of physiological signals, such as heart rate, brain activity, and\neye-tracking, combined with traditional interaction data and self-reports to\ngain deeper insights into cognitive states and engagement levels. We synthesize\nfindings from 54 key studies, analyzing commonly used methodologies such as\nadvanced machine learning algorithms and multimodal data pre-processing\ntechniques. The review identifies current research trends, limitations, and\nemerging directions in the field, emphasizing the transformative potential of\nbiosensor-driven adaptive learning systems. Our findings suggest that\nintegrating multimodal data can facilitate personalized learning experiences,\nreal-time feedback, and intelligent educational interventions, ultimately\nadvancing toward a more customized and adaptive online learning experience.", "published": "2025-09-09 13:41:40", "link": "http://arxiv.org/abs/2509.07742v1", "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "cs.HC"}
{"title": "The Carbon Footprint Wizard: A Knowledge-Augmented AI Interface for Streamlining Food Carbon Footprint Analysis", "abstract": "Environmental sustainability, particularly in relation to climate change, is\na key concern for consumers, producers, and policymakers. The carbon footprint,\nbased on greenhouse gas emissions, is a standard metric for quantifying the\ncontribution to climate change of activities and is often assessed using life\ncycle assessment (LCA). However, conducting LCA is complex due to opaque and\nglobal supply chains, as well as fragmented data. This paper presents a\nmethodology that combines advances in LCA and publicly available databases with\nknowledge-augmented AI techniques, including retrieval-augmented generation, to\nestimate cradle-to-gate carbon footprints of food products. We introduce a\nchatbot interface that allows users to interactively explore the carbon impact\nof composite meals and relate the results to familiar activities. A live web\ndemonstration showcases our proof-of-concept system with arbitrary food items\nand follow-up questions, highlighting both the potential and limitations - such\nas database uncertainties and AI misinterpretations - of delivering LCA\ninsights in an accessible format.", "published": "2025-09-09 13:34:06", "link": "http://arxiv.org/abs/2509.07733v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BDPM: A Machine Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut Microbiota Analysis", "abstract": "Background: Parkinson's disease remains a major neurodegenerative disorder\nwith high misdiagnosis rates, primarily due to reliance on clinical rating\nscales. Recent studies have demonstrated a strong association between gut\nmicrobiota and Parkinson's disease, suggesting that microbial composition may\nserve as a promising biomarker. Although deep learning models based ongut\nmicrobiota show potential for early prediction, most approaches rely on single\nclassifiers and often overlook inter-strain correlations or temporal dynamics.\nTherefore, there is an urgent need for more robust feature extraction methods\ntailored to microbiome data. Methods: We proposed BDPM (A Machine\nLearning-Based Feature Extractor for Parkinson's Disease Classification via Gut\nMicrobiota Analysis). First, we collected gut microbiota profiles from 39\nParkinson's patients and their healthy spouses to identify differentially\nabundant taxa. Second, we developed an innovative feature selection framework\nnamed RFRE (Random Forest combined with Recursive Feature Elimination),\nintegrating ecological knowledge to enhance biological interpretability.\nFinally, we designed a hybrid classification model to capture temporal and\nspatial patterns in microbiome data.", "published": "2025-09-09 13:24:25", "link": "http://arxiv.org/abs/2509.07723v1", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "RIMO: An Easy-to-Evaluate, Hard-to-Solve Olympiad Benchmark for Advanced Mathematical Reasoning", "abstract": "As large language models (LLMs) reach high scores on established mathematical\nbenchmarks, such as GSM8K and MATH, the research community has turned to\nInternational Mathematical Olympiad (IMO) problems to push the evaluation\nfrontier. However, existing Olympiad-level benchmarks suffer from practical\nconstraints that introduce grading noise and potential bias, such as\nheterogeneous answer formats requiring model-based judges and a reliance on\npotentially flawed solutions. We introduce RIMO, a two-track benchmark designed\nto preserve peak Olympiad difficulty while eliminating this evaluation noise.\nThe first track, RIMO-N, rewrites 335 IMO problems to admit a single, unique\ninteger answer, allowing for deterministic correctness checking. The second\ntrack, RIMO-P, features 456 proof problems with expert-checked solutions, which\nare decomposed into a sequence of sub-problems to evaluate the step-by-step\nreasoning process via an automated grading system. Our benchmarking of ten\nfrontier LLMs, including GPT-4o and Gemini 2.5 Flash, reveals that while these\nsystems excel on older benchmarks, their performance drops sharply on RIMO.\nThese results highlight a substantial gap between current LLM capabilities and\nactual Olympiad-level reasoning. By providing a challenging yet\neasy-to-evaluate suite, RIMO offers a high-resolution yardstick for future\nresearch, presenting a clear target for closing the profound reasoning gap our\nfindings expose.", "published": "2025-09-09 13:13:51", "link": "http://arxiv.org/abs/2509.07711v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support", "abstract": "In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health\nLevel 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a\nRetrieval-Augmented Generation (RAG)-based system to improve personalized\nmedical decision support on evidence-based clinical guidelines, emphasizing the\nneed for research in practical applications. In the evolving landscape of\nmedical decision support systems, integrating advanced technologies such as RAG\nand HL7 FHIR can significantly enhance clinical decision-making processes.\nDespite the potential of these technologies, there is limited research on their\nintegration in practical applications.", "published": "2025-09-09 13:10:49", "link": "http://arxiv.org/abs/2509.07706v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems", "abstract": "Voice Authentication Systems (VAS) use unique vocal characteristics for\nverification. They are increasingly integrated into high-security sectors such\nas banking and healthcare. Despite their improvements using deep learning, they\nface severe vulnerabilities from sophisticated threats like deepfakes and\nadversarial attacks. The emergence of realistic voice cloning complicates\ndetection, as systems struggle to distinguish authentic from synthetic audio.\nWhile anti-spoofing countermeasures (CMs) exist to mitigate these risks, many\nrely on static detection models that can be bypassed by novel adversarial\nmethods, leaving a critical security gap. To demonstrate this vulnerability, we\npropose the Spectral Masking and Interpolation Attack (SMIA), a novel method\nthat strategically manipulates inaudible frequency regions of AI-generated\naudio. By altering the voice in imperceptible zones to the human ear, SMIA\ncreates adversarial samples that sound authentic while deceiving CMs. We\nconducted a comprehensive evaluation of our attack against state-of-the-art\n(SOTA) models across multiple tasks, under simulated real-world conditions.\nSMIA achieved a strong attack success rate (ASR) of at least 82% against\ncombined VAS/CM systems, at least 97.5% against standalone speaker verification\nsystems, and 100% against countermeasures. These findings conclusively\ndemonstrate that current security postures are insufficient against adaptive\nadversarial attacks. This work highlights the urgent need for a paradigm shift\ntoward next-generation defenses that employ dynamic, context-aware frameworks\ncapable of evolving with the threat landscape.", "published": "2025-09-09 12:43:59", "link": "http://arxiv.org/abs/2509.07677v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Unleashing the True Potential of LLMs: A Feedback-Triggered Self-Correction with Long-Term Multipath Decoding", "abstract": "Large Language Models (LLMs) have achieved remarkable performance across\ndiverse tasks, yet their susceptibility to generating incorrect content during\ninference remains a critical unsolved challenge. While self-correction methods\noffer potential solutions, their effectiveness is hindered by two inherent\nlimitations: (1) the absence of reliable guidance signals for error\nlocalization, and (2) the restricted reasoning depth imposed by conventional\nnext-token decoding paradigms. To address these issues, we propose\nFeedback-Triggered Regeneration (FTR), a novel framework that synergizes user\nfeedback with enhanced decoding dynamics. Specifically, FTR activates response\nregeneration only upon receiving negative user feedback, thereby circumventing\nerror propagation from faulty self-assessment while preserving originally\ncorrect outputs. Furthermore, we introduce Long-Term Multipath (LTM) decoding,\nwhich enables systematic exploration of multiple reasoning trajectories through\ndelayed sequence evaluation, effectively overcoming the myopic decision-making\ncharacteristic of standard next-token prediction. Extensive experiments on\nmathematical reasoning and code generation benchmarks demonstrate that our\nframework achieves consistent and significant improvements over\nstate-of-the-art prompt-based self-correction methods.", "published": "2025-09-09 12:43:28", "link": "http://arxiv.org/abs/2509.07676v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DeepGraphLog for Layered Neurosymbolic AI", "abstract": "Neurosymbolic AI (NeSy) aims to integrate the statistical strengths of neural\nnetworks with the interpretability and structure of symbolic reasoning.\nHowever, current NeSy frameworks like DeepProbLog enforce a fixed flow where\nsymbolic reasoning always follows neural processing. This restricts their\nability to model complex dependencies, especially in irregular data structures\nsuch as graphs. In this work, we introduce DeepGraphLog, a novel NeSy framework\nthat extends ProbLog with Graph Neural Predicates. DeepGraphLog enables\nmulti-layer neural-symbolic reasoning, allowing neural and symbolic components\nto be layered in arbitrary order. In contrast to DeepProbLog, which cannot\nhandle symbolic reasoning via neural methods, DeepGraphLog treats symbolic\nrepresentations as graphs, enabling them to be processed by Graph Neural\nNetworks (GNNs). We showcase the capabilities of DeepGraphLog on tasks in\nplanning, knowledge graph completion with distant supervision, and GNN\nexpressivity. Our results demonstrate that DeepGraphLog effectively captures\ncomplex relational dependencies, overcoming key limitations of existing NeSy\nsystems. By broadening the applicability of neurosymbolic AI to\ngraph-structured domains, DeepGraphLog offers a more expressive and flexible\nframework for neural-symbolic integration.", "published": "2025-09-09 12:32:07", "link": "http://arxiv.org/abs/2509.07665v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment", "abstract": "Adopting Large language models (LLMs) in organizations potentially\nrevolutionizes our lives and work. However, they can generate off-topic,\ndiscriminating, or harmful content. This AI alignment problem often stems from\nmisspecifications during the LLM adoption, unnoticed by the principal due to\nthe LLM's black-box nature. While various research disciplines investigated AI\nalignment, they neither address the information asymmetries between\norganizational adopters and black-box LLM agents nor consider organizational AI\nadoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led\nAlignment Strategy) a conceptual framework grounded in agency (contract)\ntheory, to mitigate alignment problems during organizational LLM adoption. We\nconduct a conceptual literature analysis using the organizational LLM adoption\nphases and the agency theory as concepts. Our approach results in (1) providing\nan extended literature analysis process specific to AI alignment methods during\norganizational LLM adoption and (2) providing a first LLM alignment\nproblem-solution space.", "published": "2025-09-09 12:10:14", "link": "http://arxiv.org/abs/2509.07642v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Variational Quantum Circuits in Offline Contextual Bandit Problems", "abstract": "This paper explores the application of variational quantum circuits (VQCs)\nfor solving offline contextual bandit problems in industrial optimization\ntasks. Using the Industrial Benchmark (IB) environment, we evaluate the\nperformance of quantum regression models against classical models. Our findings\ndemonstrate that quantum models can effectively fit complex reward functions,\nidentify optimal configurations via particle swarm optimization (PSO), and\ngeneralize well in noisy and sparse datasets. These results provide a proof of\nconcept for utilizing VQCs in offline contextual bandit problems and highlight\ntheir potential in industrial optimization tasks.", "published": "2025-09-09 12:00:33", "link": "http://arxiv.org/abs/2509.07633v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Transferable Direct Prompt Injection via Activation-Guided MCMC Sampling", "abstract": "Direct Prompt Injection (DPI) attacks pose a critical security threat to\nLarge Language Models (LLMs) due to their low barrier of execution and high\npotential damage. To address the impracticality of existing white-box/gray-box\nmethods and the poor transferability of black-box methods, we propose an\nactivations-guided prompt injection attack framework. We first construct an\nEnergy-based Model (EBM) using activations from a surrogate model to evaluate\nthe quality of adversarial prompts. Guided by the trained EBM, we employ the\ntoken-level Markov Chain Monte Carlo (MCMC) sampling to adaptively optimize\nadversarial prompts, thereby enabling gradient-free black-box attacks.\nExperimental results demonstrate our superior cross-model transferability,\nachieving 49.6% attack success rate (ASR) across five mainstream LLMs and 34.6%\nimprovement over human-crafted prompts, and maintaining 36.6% ASR on unseen\ntask scenarios. Interpretability analysis reveals a correlation between\nactivations and attack effectiveness, highlighting the critical role of\nsemantic patterns in transferable vulnerability exploitation.", "published": "2025-09-09 11:42:06", "link": "http://arxiv.org/abs/2509.07617v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Classical Data to Quantum Advantage -- Quantum Policy Evaluation on Quantum Hardware", "abstract": "Quantum policy evaluation (QPE) is a reinforcement learning (RL) algorithm\nwhich is quadratically more efficient than an analogous classical Monte Carlo\nestimation. It makes use of a direct quantum mechanical realization of a finite\nMarkov decision process, in which the agent and the environment are modeled by\nunitary operators and exchange states, actions, and rewards in superposition.\nPreviously, the quantum environment has been implemented and parametrized\nmanually for an illustrative benchmark using a quantum simulator. In this\npaper, we demonstrate how these environment parameters can be learned from a\nbatch of classical observational data through quantum machine learning (QML) on\nquantum hardware. The learned quantum environment is then applied in QPE to\nalso compute policy evaluations on quantum hardware. Our experiments reveal\nthat, despite challenges such as noise and short coherence times, the\nintegration of QML and QPE shows promising potential for achieving quantum\nadvantage in RL.", "published": "2025-09-09 11:36:25", "link": "http://arxiv.org/abs/2509.07614v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Beyond Rebalancing: Benchmarking Binary Classifiers Under Class Imbalance Without Rebalancing Techniques", "abstract": "Class imbalance poses a significant challenge to supervised classification,\nparticularly in critical domains like medical diagnostics and anomaly detection\nwhere minority class instances are rare. While numerous studies have explored\nrebalancing techniques to address this issue, less attention has been given to\nevaluating the performance of binary classifiers under imbalance when no such\ntechniques are applied. Therefore, the goal of this study is to assess the\nperformance of binary classifiers \"as-is\", without performing any explicit\nrebalancing. Specifically, we systematically evaluate the robustness of a\ndiverse set of binary classifiers across both real-world and synthetic\ndatasets, under progressively reduced minority class sizes, using one-shot and\nfew-shot scenarios as baselines. Our approach also explores varying data\ncomplexities through synthetic decision boundary generation to simulate\nreal-world conditions. In addition to standard classifiers, we include\nexperiments using undersampling, oversampling strategies, and one-class\nclassification (OCC) methods to examine their behavior under severe imbalance.\nThe results confirm that classification becomes more difficult as data\ncomplexity increases and the minority class size decreases. While traditional\nclassifiers deteriorate under extreme imbalance, advanced models like TabPFN\nand boosting-based ensembles retain relatively higher performance and better\ngeneralization compared to traditional classifiers. Visual interpretability and\nevaluation metrics further validate these findings. Our work offers valuable\nguidance on model selection for imbalanced learning, providing insights into\nclassifier robustness without dependence on explicit rebalancing techniques.", "published": "2025-09-09 11:28:34", "link": "http://arxiv.org/abs/2509.07605v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Transformer-Based Approach to Optimal Sensor Placement for Structural Health Monitoring of Probe Cards", "abstract": "This paper presents an innovative Transformer-based deep learning strategy\nfor optimizing the placement of sensors aiming at structural health monitoring\nof semiconductor probe cards. Failures in probe cards, including substrate\ncracks and loosened screws, would critically affect semiconductor manufacturing\nyield and reliability. Some failure modes could be detected by equipping a\nprobe card with adequate sensors. Frequency response functions from simulated\nfailure scenarios are adopted within a finite element model of a probe card. A\ncomprehensive dataset, enriched by physics-informed scenario expansion and\nphysics-aware statistical data augmentation, is exploited to train a hybrid\nConvolutional Neural Network and Transformer model. The model achieves high\naccuracy (99.83%) in classifying the probe card health states (baseline, loose\nscrew, crack) and an excellent crack detection recall (99.73%). Model\nrobustness is confirmed through a rigorous framework of 3 repetitions of\n10-fold stratified cross-validation. The attention mechanism also pinpoints\ncritical sensor locations: an analysis of the attention weights offers\nactionable insights for designing efficient, cost-effective monitoring systems\nby optimizing sensor configurations. This research highlights the capability of\nattention-based deep learning to advance proactive maintenance, enhancing\noperational reliability and yield in semiconductor manufacturing.", "published": "2025-09-09 11:21:49", "link": "http://arxiv.org/abs/2509.07603v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?", "abstract": "End-to-end reinforcement learning for motion control promises unified\nperception-action policies that scale across embodiments and tasks, yet most\ndeployed controllers are either blind (proprioception-only) or rely on fusion\nbackbones with unfavorable compute-memory trade-offs. Recurrent controllers\nstruggle with long-horizon credit assignment, and Transformer-based fusion\nincurs quadratic cost in token length, limiting temporal and spatial context.\nWe present a vision-driven cross-modal RL framework built on SSD-Mamba2, a\nselective state-space backbone that applies state-space duality (SSD) to enable\nboth recurrent and convolutional scanning with hardware-aware streaming and\nnear-linear scaling. Proprioceptive states and exteroceptive observations\n(e.g., depth tokens) are encoded into compact tokens and fused by stacked\nSSD-Mamba2 layers. The selective state-space updates retain long-range\ndependencies with markedly lower latency and memory use than quadratic\nself-attention, enabling longer look-ahead, higher token resolution, and stable\ntraining under limited compute. Policies are trained end-to-end under curricula\nthat randomize terrain and appearance and progressively increase scene\ncomplexity. A compact, state-centric reward balances task progress, energy\nefficiency, and safety. Across diverse motion-control scenarios, our approach\nconsistently surpasses strong state-of-the-art baselines in return, safety\n(collisions and falls), and sample efficiency, while converging faster at the\nsame compute budget. These results suggest that SSD-Mamba2 provides a practical\nfusion backbone for scalable, foresightful, and efficient end-to-end motion\ncontrol.", "published": "2025-09-09 11:05:44", "link": "http://arxiv.org/abs/2509.07593v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.SY", "eess.IV", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Attention Maps in 3D Shape Classification for Dental Stage Estimation with Class Node Graph Attention Networks", "abstract": "Deep learning offers a promising avenue for automating many recognition tasks\nin fields such as medicine and forensics. However, the black-box nature of\nthese models hinders their adoption in high-stakes applications where trust and\naccountability are required. For 3D shape recognition tasks in particular, this\npaper introduces the Class Node Graph Attention Network (CGAT) architecture to\naddress this need. Applied to 3D meshes of third molars derived from CBCT\nimages, for Demirjian stage allocation, CGAT utilizes graph attention\nconvolutions and an inherent attention mechanism, visualized via attention\nrollout, to explain its decision-making process. We evaluated the local mean\ncurvature and distance to centroid node features, both individually and in\ncombination, as well as model depth, finding that models incorporating directed\nedges to a global CLS node produced more intuitive attention maps, while also\nyielding desirable classification performance. We analyzed the attention-based\nexplanations of the models, and their predictive performances to propose\noptimal settings for the CGAT. The combination of local mean curvature and\ndistance to centroid as node features yielded a slight performance increase\nwith 0.76 weighted F1 score, and more comprehensive attention visualizations.\nThe CGAT architecture's ability to generate human-understandable attention maps\ncan enhance trust and facilitate expert validation of model decisions. While\ndemonstrated on dental data, CGAT is broadly applicable to graph-based\nclassification and regression tasks, promoting wider adoption of transparent\nand competitive deep learning models in high-stakes environments.", "published": "2025-09-09 10:44:25", "link": "http://arxiv.org/abs/2509.07581v1", "categories": ["cs.CV", "cs.AI", "68T07 68T07 68T07 (Primary) 68R10 (Secondary)"], "primary_category": "cs.CV"}
{"title": "Towards explainable decision support using hybrid neural models for logistic terminal automation", "abstract": "The integration of Deep Learning (DL) in System Dynamics (SD) modeling for\ntransportation logistics offers significant advantages in scalability and\npredictive accuracy. However, these gains are often offset by the loss of\nexplainability and causal reliability $-$ key requirements in critical\ndecision-making systems. This paper presents a novel framework for\ninterpretable-by-design neural system dynamics modeling that synergizes DL with\ntechniques from Concept-Based Interpretability, Mechanistic Interpretability,\nand Causal Machine Learning. The proposed hybrid approach enables the\nconstruction of neural network models that operate on semantically meaningful\nand actionable variables, while retaining the causal grounding and transparency\ntypical of traditional SD models. The framework is conceived to be applied to\nreal-world case-studies from the EU-funded project AutoMoTIF, focusing on\ndata-driven decision support, automation, and optimization of multimodal\nlogistic terminals. We aim at showing how neuro-symbolic methods can bridge the\ngap between black-box predictive models and the need for critical decision\nsupport in complex dynamical environments within cyber-physical systems enabled\nby the industrial Internet-of-Things.", "published": "2025-09-09 10:41:08", "link": "http://arxiv.org/abs/2509.07577v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference", "abstract": "The rapid advancement of large language models (LLMs) and domain-specific AI\nagents has greatly expanded the ecosystem of AI-powered services. User queries,\nhowever, are highly diverse and often span multiple domains and task types,\nresulting in a complex and heterogeneous landscape. This diversity presents a\nfundamental routing challenge: how to accurately direct each query to an\nappropriate execution unit while optimizing both performance and efficiency. To\naddress this, we propose MoMA (Mixture of Models and Agents), a generalized\nrouting framework that integrates both LLM and agent-based routing. Built upon\na deep understanding of model and agent capabilities, MoMA effectively handles\ndiverse queries through precise intent recognition and adaptive routing\nstrategies, achieving an optimal balance between efficiency and cost.\nSpecifically, we construct a detailed training dataset to profile the\ncapabilities of various LLMs under different routing model structures,\nidentifying the most suitable tasks for each LLM. During inference, queries are\ndynamically routed to the LLM with the best cost-performance efficiency. We\nalso introduce an efficient agent selection strategy based on a context-aware\nstate machine and dynamic masking. Experimental results demonstrate that the\nMoMA router offers superior cost-efficiency and scalability compared to\nexisting approaches.", "published": "2025-09-09 10:15:42", "link": "http://arxiv.org/abs/2509.07571v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "$\u0394L$ Normalization: Rethink Loss Aggregation in RLVR", "abstract": "We propose $\\Delta L$ Normalization, a simple yet effective loss aggregation\nmethod tailored to the characteristic of dynamic generation lengths in\nReinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has\ndemonstrated strong potential in improving the reasoning capabilities of large\nlanguage models (LLMs), but a major challenge lies in the large variability of\nresponse lengths during training, which leads to high gradient variance and\nunstable optimization. Although previous methods such as GRPO, DAPO, and Dr.\nGRPO introduce different loss normalization terms to address this issue, they\neither produce biased estimates or still suffer from high gradient variance. By\nanalyzing the effect of varying lengths on policy loss both theoretically and\nempirically, we reformulate the problem as finding a minimum-variance unbiased\nestimator. Our proposed $\\Delta L$ Normalization not only provides an unbiased\nestimate of the true policy loss but also minimizes gradient variance in\ntheory. Extensive experiments show that it consistently achieves superior\nresults across different model sizes, maximum lengths, and tasks. Our code will\nbe made public at https://github.com/zerolllin/Delta-L-Normalization.", "published": "2025-09-09 09:52:34", "link": "http://arxiv.org/abs/2509.07558v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HU-based Foreground Masking for 3D Medical Masked Image Modeling", "abstract": "While Masked Image Modeling (MIM) has revolutionized fields of computer\nvision, its adoption in 3D medical image computing has been limited by the use\nof random masking, which overlooks the density of anatomical objects. To\naddress this limitation, we enhance the pretext task with a simple yet\neffective masking strategy. Leveraging Hounsfield Unit (HU) measurements, we\nimplement an HU-based Foreground Masking, which focuses on the intensity\ndistribution of visceral organs and excludes non-tissue regions, such as air\nand fluid, that lack diagnostically meaningful features. Extensive experiments\non five public 3D medical imaging datasets demonstrate that our masking\nconsistently improves performance, both in quality of segmentation and Dice\nscore (BTCV:~84.64\\%, Flare22:~92.43\\%, MM-WHS:~90.67\\%, Amos22:~88.64\\%,\nBraTS:~78.55\\%). These results underscore the importance of domain-centric MIM\nand suggest a promising direction for representation learning in medical image\nsegmentation. Implementation is available at github.com/AISeedHub/SubFore/.", "published": "2025-09-09 09:11:38", "link": "http://arxiv.org/abs/2509.07534v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents", "abstract": "Scientific document representation learning provides powerful embeddings for\nvarious tasks, while current methods face challenges across three approaches.\n1) Contrastive training with citation-structural signals underutilizes citation\ninformation and still generates single-vector representations. 2) Fine-grained\nrepresentation learning, which generates multiple vectors at the sentence or\naspect level, requires costly integration and lacks domain generalization. 3)\nTask-aware learning depends on manually predefined task categorization,\noverlooking nuanced task distinctions and requiring extra training data for\ntask-specific modules. To address these problems, we propose a new method that\nunifies the three approaches for better representations, namely FLeW.\nSpecifically, we introduce a novel triplet sampling method that leverages\ncitation intent and frequency to enhance citation-structural signals for\ntraining. Citation intents (background, method, result), aligned with the\ngeneral structure of scientific writing, facilitate a domain-generalized facet\npartition for fine-grained representation learning. Then, we adopt a simple\nweight search to adaptively integrate three facet-level embeddings into a\ntask-specific document embedding without task-aware fine-tuning. Experiments\nshow the applicability and robustness of FLeW across multiple scientific tasks\nand fields, compared to prior models.", "published": "2025-09-09 09:08:44", "link": "http://arxiv.org/abs/2509.07531v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "EHWGesture -- A dataset for multimodal understanding of clinical gestures", "abstract": "Hand gesture understanding is essential for several applications in\nhuman-computer interaction, including automatic clinical assessment of hand\ndexterity. While deep learning has advanced static gesture recognition, dynamic\ngesture understanding remains challenging due to complex spatiotemporal\nvariations. Moreover, existing datasets often lack multimodal and multi-view\ndiversity, precise ground-truth tracking, and an action quality component\nembedded within gestures. This paper introduces EHWGesture, a multimodal video\ndataset for gesture understanding featuring five clinically relevant gestures.\nIt includes over 1,100 recordings (6 hours), captured from 25 healthy subjects\nusing two high-resolution RGB-Depth cameras and an event camera. A motion\ncapture system provides precise ground-truth hand landmark tracking, and all\ndevices are spatially calibrated and synchronized to ensure cross-modal\nalignment. Moreover, to embed an action quality task within gesture\nunderstanding, collected recordings are organized in classes of execution speed\nthat mirror clinical evaluations of hand dexterity. Baseline experiments\nhighlight the dataset's potential for gesture classification, gesture trigger\ndetection, and action quality assessment. Thus, EHWGesture can serve as a\ncomprehensive benchmark for advancing multimodal clinical gesture\nunderstanding.", "published": "2025-09-09 09:00:03", "link": "http://arxiv.org/abs/2509.07525v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Water Demand Forecasting of District Metered Areas through Learned Consumer Representations", "abstract": "Advancements in smart metering technologies have significantly improved the\nability to monitor and manage water utilities. In the context of increasing\nuncertainty due to climate change, securing water resources and supply has\nemerged as an urgent global issue with extensive socioeconomic ramifications.\nHourly consumption data from end-users have yielded substantial insights for\nprojecting demand across regions characterized by diverse consumption patterns.\nNevertheless, the prediction of water demand remains challenging due to\ninfluencing non-deterministic factors, such as meteorological conditions. This\nwork introduces a novel method for short-term water demand forecasting for\nDistrict Metered Areas (DMAs) which encompass commercial, agricultural, and\nresidential consumers. Unsupervised contrastive learning is applied to\ncategorize end-users according to distinct consumption behaviors present within\na DMA. Subsequently, the distinct consumption behaviors are utilized as\nfeatures in the ensuing demand forecasting task using wavelet-transformed\nconvolutional networks that incorporate a cross-attention mechanism combining\nboth historical data and the derived representations. The proposed approach is\nevaluated on real-world DMAs over a six-month period, demonstrating improved\nforecasting performance in terms of MAPE across different DMAs, with a maximum\nimprovement of 4.9%. Additionally, it identifies consumers whose behavior is\nshaped by socioeconomic factors, enhancing prior knowledge about the\ndeterministic patterns that influence demand.", "published": "2025-09-09 08:51:30", "link": "http://arxiv.org/abs/2509.07515v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition", "abstract": "Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, posing\nsignificant security threats to their deployment in remote sensing\napplications. Research on adversarial attacks not only reveals model\nvulnerabilities but also provides critical insights for enhancing robustness.\nAlthough current mixing-based strategies have been proposed to increase the\ntransferability of adversarial examples, they either perform global blending or\ndirectly exchange a region in the images, which may destroy global semantic\nfeatures and mislead the optimization of adversarial examples. Furthermore,\ntheir reliance on cross-entropy loss for perturbation optimization leads to\ngradient diminishing during iterative updates, compromising adversarial example\nquality. To address these limitations, we focus on non-targeted attacks and\npropose a novel framework via local mixing and logits optimization. First, we\npresent a local mixing strategy to generate diverse yet semantically consistent\ninputs. Different from MixUp, which globally blends two images, and MixCut,\nwhich stitches images together, our method merely blends local regions to\npreserve global semantic information. Second, we adapt the logit loss from\ntargeted attacks to non-targeted scenarios, mitigating the gradient vanishing\nproblem of cross-entropy loss. Third, a perturbation smoothing loss is applied\nto suppress high-frequency noise and enhance transferability. Extensive\nexperiments on FGSCR-42 and MTARSI datasets demonstrate superior performance\nover 12 state-of-the-art methods across 6 surrogate models. Notably, with\nResNet as the surrogate on MTARSI, our method achieves a 17.28% average\nimprovement in black-box attack success rate.", "published": "2025-09-09 08:20:19", "link": "http://arxiv.org/abs/2509.07495v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fine-Tuning Vision-Language Models for Visual Navigation Assistance", "abstract": "We address vision-language-driven indoor navigation to assist visually\nimpaired individuals in reaching a target location using images and natural\nlanguage guidance. Traditional navigation systems are ineffective indoors due\nto the lack of precise location data. Our approach integrates vision and\nlanguage models to generate step-by-step navigational instructions, enhancing\naccessibility and independence. We fine-tune the BLIP-2 model with Low Rank\nAdaptation (LoRA) on a manually annotated indoor navigation dataset. We propose\nan evaluation metric that refines the BERT F1 score by emphasizing directional\nand sequential variables, providing a more comprehensive measure of\nnavigational performance. After applying LoRA, the model significantly improved\nin generating directional instructions, overcoming limitations in the original\nBLIP-2 model.", "published": "2025-09-09 08:08:35", "link": "http://arxiv.org/abs/2509.07488v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SheetDesigner: MLLM-Powered Spreadsheet Layout Generation with Rule-Based and Vision-Based Reflection", "abstract": "Spreadsheets are critical to data-centric tasks, with rich, structured\nlayouts that enable efficient information transmission. Given the time and\nexpertise required for manual spreadsheet layout design, there is an urgent\nneed for automated solutions. However, existing automated layout models are\nill-suited to spreadsheets, as they often (1) treat components as axis-aligned\nrectangles with continuous coordinates, overlooking the inherently discrete,\ngrid-based structure of spreadsheets; and (2) neglect interrelated semantics,\nsuch as data dependencies and contextual links, unique to spreadsheets. In this\npaper, we first formalize the spreadsheet layout generation task, supported by\na seven-criterion evaluation protocol and a dataset of 3,326 spreadsheets. We\nthen introduce SheetDesigner, a zero-shot and training-free framework using\nMultimodal Large Language Models (MLLMs) that combines rule and vision\nreflection for component placement and content population. SheetDesigner\noutperforms five baselines by at least 22.6\\%. We further find that through\nvision modality, MLLMs handle overlap and balance well but struggle with\nalignment, necessitates hybrid rule and visual reflection strategies. Our codes\nand data is available at Github.", "published": "2025-09-09 07:51:38", "link": "http://arxiv.org/abs/2509.07473v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis", "abstract": "Ensuring reliable robot operation when visual input is degraded or\ninsufficient remains a central challenge in robotics. This letter introduces\nDepthVision, a framework for multimodal scene understanding designed to address\nthis problem. Unlike existing Vision-Language Models (VLMs), which use only\ncamera-based visual input alongside language, DepthVision synthesizes RGB\nimages from sparse LiDAR point clouds using a conditional generative\nadversarial network (GAN) with an integrated refiner network. These synthetic\nviews are then combined with real RGB data using a Luminance-Aware Modality\nAdaptation (LAMA), which blends the two types of data dynamically based on\nambient lighting conditions. This approach compensates for sensor degradation,\nsuch as darkness or motion blur, without requiring any fine-tuning of\ndownstream vision-language models. We evaluate DepthVision on real and\nsimulated datasets across various models and tasks, with particular attention\nto safety-critical tasks. The results demonstrate that our approach improves\nperformance in low-light conditions, achieving substantial gains over RGB-only\nbaselines while preserving compatibility with frozen VLMs. This work highlights\nthe potential of LiDAR-guided RGB synthesis for achieving robust robot\noperation in real-world environments.", "published": "2025-09-09 07:42:07", "link": "http://arxiv.org/abs/2509.07463v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Bias-Aware Machine Unlearning: Towards Fairer Vision Models via Controllable Forgetting", "abstract": "Deep neural networks often rely on spurious correlations in training data,\nleading to biased or unfair predictions in safety-critical domains such as\nmedicine and autonomous driving. While conventional bias mitigation typically\nrequires retraining from scratch or redesigning data pipelines, recent advances\nin machine unlearning provide a promising alternative for post-hoc model\ncorrection. In this work, we investigate \\textit{Bias-Aware Machine\nUnlearning}, a paradigm that selectively removes biased samples or feature\nrepresentations to mitigate diverse forms of bias in vision models. Building on\nprivacy-preserving unlearning techniques, we evaluate various strategies\nincluding Gradient Ascent, LoRA, and Teacher-Student distillation. Through\nempirical analysis on three benchmark datasets, CUB-200-2011 (pose bias),\nCIFAR-10 (synthetic patch bias), and CelebA (gender bias in smile detection),\nwe demonstrate that post-hoc unlearning can substantially reduce subgroup\ndisparities, with improvements in demographic parity of up to \\textbf{94.86\\%}\non CUB-200, \\textbf{30.28\\%} on CIFAR-10, and \\textbf{97.37\\%} on CelebA. These\ngains are achieved with minimal accuracy loss and with methods scoring an\naverage of 0.62 across the 3 settings on the joint evaluation of utility,\nfairness, quality, and privacy. Our findings establish machine unlearning as a\npractical framework for enhancing fairness in deployed vision systems without\nnecessitating full retraining.", "published": "2025-09-09 07:25:51", "link": "http://arxiv.org/abs/2509.07456v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions", "abstract": "Large language models (LLMs) are beginning to automate reward design for\ndexterous manipulation. However, no prior work has considered tactile sensing,\nwhich is known to be critical for human-like dexterity. We present Text2Touch,\nbringing LLM-crafted rewards to the challenging task of multi-axis in-hand\nobject rotation with real-world vision based tactile sensing in palm-up and\npalm-down configurations. Our prompt engineering strategy scales to over 70\nenvironment variables, and sim-to-real distillation enables successful policy\ntransfer to a tactile-enabled fully actuated four-fingered dexterous robot\nhand. Text2Touch significantly outperforms a carefully tuned human-engineered\nbaseline, demonstrating superior rotation speed and stability while relying on\nreward functions that are an order of magnitude shorter and simpler. These\nresults illustrate how LLM-designed rewards can significantly reduce the time\nfrom concept to deployable dexterous tactile skills, supporting more rapid and\nscalable multimodal robot learning. Project website:\nhttps://hpfield.github.io/text2touch-website", "published": "2025-09-09 07:10:39", "link": "http://arxiv.org/abs/2509.07445v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward", "abstract": "A central paradox in fine-tuning Large Language Models (LLMs) with\nReinforcement Learning with Verifiable Reward (RLVR) is the frequent\ndegradation of multi-attempt performance (Pass@k) despite improvements in\nsingle-attempt accuracy (Pass@1). This is often accompanied by catastrophic\nforgetting, where models lose previously acquired skills. While various methods\nhave been proposed, the choice and function of the divergence term have been\nsurprisingly unexamined as a proactive solution. We argue that standard RLVR\nobjectives -- both those using the mode-seeking reverse KL-divergence and those\nforgoing a divergence term entirely -- lack a crucial mechanism for knowledge\nretention. The reverse-KL actively accelerates this decay by narrowing the\npolicy, while its absence provides no safeguard against the model drifting from\nits diverse knowledge base. We propose a fundamental shift in perspective:\nusing the divergence term itself as the solution. Our framework,\nDiversity-Preserving Hybrid RL (DPH-RL), leverages mass-covering f-divergences\n(like forward-KL and JS-divergence) to function as a rehearsal mechanism. By\ncontinuously referencing the initial policy, this approach forces the model to\nmaintain broad solution coverage. Extensive experiments on math and SQL\ngeneration demonstrate that DPH-RL not only resolves the Pass@k degradation but\nimproves both Pass@1 and Pass@k in- and out-of-domain. Additionally, DPH-RL is\nmore training-efficient because it computes f-divergence using generator\nfunctions, requiring only sampling from the initial policy and no online\nreference model. Our work highlights a crucial, overlooked axis for improving\nRLVR, demonstrating that the proper selection of a divergence measure is a\npowerful tool for building more general and diverse reasoning models.", "published": "2025-09-09 06:34:32", "link": "http://arxiv.org/abs/2509.07430v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Benchmarking Universal Interatomic Potentials on Zeolite Structures", "abstract": "Interatomic potentials (IPs) with wide elemental coverage and high accuracy\nare powerful tools for high-throughput materials discovery. While the past few\nyears witnessed the development of multiple new universal IPs that cover wide\nranges of the periodic table, their applicability to target chemical systems\nshould be carefully investigated. We benchmark several universal IPs using\nequilibrium zeolite structures as testbeds. We select a diverse set of\nuniversal IPs encompassing two major categories: (i) universal analytic IPs,\nincluding GFN-FF, UFF, and Dreiding; (ii) pretrained universal machine learning\nIPs (MLIPs), comprising CHGNet, ORB-v3, MatterSim, eSEN-30M-OAM, PFP-v7, and\nEquiformerV2-lE4-lF100-S2EFS-OC22. We compare them with established tailor-made\nIPs, SLC, ClayFF, and BSFF using experimental data and density functional\ntheory (DFT) calculations with dispersion correction as the reference. The\ntested zeolite structures comprise pure silica frameworks and aluminosilicates\ncontaining copper species, potassium, and organic cations. We found that GFN-FF\nis the best among the tested universal analytic IPs, but it does not achieve\nsatisfactory accuracy for highly strained silica rings and aluminosilicate\nsystems. All MLIPs can well reproduce experimental or DFT-level geometries and\nenergetics. Among the universal MLIPs, the eSEN-30M-OAM model shows the most\nconsistent performance across all zeolite structures studied. These findings\nshow that the modern pretrained universal MLIPs are practical tools in zeolite\nscreening workflows involving various compositions.", "published": "2025-09-09 06:04:40", "link": "http://arxiv.org/abs/2509.07417v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Toward Lifelong-Sustainable Electronic-Photonic AI Systems via Extreme Efficiency, Reconfigurability, and Robustness", "abstract": "The relentless growth of large-scale artificial intelligence (AI) has created\nunprecedented demand for computational power, straining the energy, bandwidth,\nand scaling limits of conventional electronic platforms. Electronic-photonic\nintegrated circuits (EPICs) have emerged as a compelling platform for\nnext-generation AI systems, offering inherent advantages in ultra-high\nbandwidth, low latency, and energy efficiency for computing and\ninterconnection. Beyond performance, EPICs also hold unique promises for\nsustainability. Fabricated in relaxed process nodes with fewer metal layers and\nlower defect densities, photonic devices naturally reduce embodied carbon\nfootprint (CFP) compared to advanced digital electronic integrated circuits,\nwhile delivering orders-of-magnitude higher computing performance and\ninterconnect bandwidth. To further advance the sustainability of photonic AI\nsystems, we explore how electronic-photonic design automation (EPDA) and\ncross-layer co-design methodologies can amplify these inherent benefits. We\npresent how advanced EPDA tools enable more compact layout generation, reducing\nboth chip area and metal layer usage. We will also demonstrate how cross-layer\ndevice-circuit-architecture co-design unlocks new sustainability gains for\nphotonic hardware: ultra-compact photonic circuit designs that minimize chip\narea cost, reconfigurable hardware topology that adapts to evolving AI\nworkloads, and intelligent resilience mechanisms that prolong lifetime by\ntolerating variations and faults. By uniting intrinsic photonic efficiency with\nEPDA- and co-design-driven gains in area efficiency, reconfigurability, and\nrobustness, we outline a vision for lifelong-sustainable electronic-photonic AI\nsystems. This perspective highlights how EPIC AI systems can simultaneously\nmeet the performance demands of modern AI and the urgent imperative for\nsustainable computing.", "published": "2025-09-09 05:20:55", "link": "http://arxiv.org/abs/2509.07396v1", "categories": ["physics.optics", "cs.AI", "cs.ET"], "primary_category": "physics.optics"}
{"title": "Hybrid GCN-GRU Model for Anomaly Detection in Cryptocurrency Transactions", "abstract": "Blockchain transaction networks are complex, with evolving temporal patterns\nand inter-node relationships. To detect illicit activities, we propose a hybrid\nGCN-GRU model that captures both structural and sequential features. Using real\nBitcoin transaction data (2020-2024), our model achieved 0.9470 Accuracy and\n0.9807 AUC-ROC, outperforming all baselines.", "published": "2025-09-09 05:14:26", "link": "http://arxiv.org/abs/2509.07392v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SBS: Enhancing Parameter-Efficiency of Neural Representations for Neural Networks via Spectral Bias Suppression", "abstract": "Implicit neural representations have recently been extended to represent\nconvolutional neural network weights via neural representation for neural\nnetworks, offering promising parameter compression benefits. However, standard\nmulti-layer perceptrons used in neural representation for neural networks\nexhibit a pronounced spectral bias, hampering their ability to reconstruct\nhigh-frequency details effectively. In this paper, we propose SBS, a\nparameter-efficient enhancement to neural representation for neural networks\nthat suppresses spectral bias using two techniques: (1) a unidirectional\nordering-based smoothing that improves kernel smoothness in the output space,\nand (2) unidirectional ordering-based smoothing aware random fourier features\nthat adaptively modulate the frequency bandwidth of input encodings based on\nlayer-wise parameter count. Extensive evaluations on various ResNet models with\ndatasets CIFAR-10, CIFAR-100, and ImageNet, demonstrate that SBS achieves\nsignificantly better reconstruction accuracy with less parameters compared to\nSOTA.", "published": "2025-09-09 03:48:57", "link": "http://arxiv.org/abs/2509.07373v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Autonomous Code Evolution Meets NP-Completeness", "abstract": "Large language models (LLMs) have recently shown strong coding abilities,\nenabling not only static code generation but also iterative code self-evolving\nthrough agentic frameworks. Recently, AlphaEvolve \\cite{novikov2025alphaevolve}\ndemonstrated that LLM-based coding agents can autonomously improve algorithms\nand surpass human experts, with scopes limited to isolated kernels spanning\nhundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the\nfirst framework to extend LLM-based code evolution to the full repository\nscale, encompassing hundreds of files and tens of thousands of lines of C/C++\ncode. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem\nand a cornerstone of both theory and applications. SATLUTION orchestrates LLM\nagents to directly evolve solver repositories under strict correctness\nguarantees and distributed runtime feedback, while simultaneously self-evolving\nits own evolution policies and rules. Starting from SAT Competition 2024\ncodebases and benchmark, SATLUTION evolved solvers that decisively outperformed\nthe human-designed winners of the SAT Competition 2025, and also surpassed both\n2024 and 2025 champions on the 2024 benchmarks.", "published": "2025-09-09 03:28:06", "link": "http://arxiv.org/abs/2509.07367v1", "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Word2Spike: Poisson Rate Coding for Associative Memories and Neuromorphic Algorithms", "abstract": "Spiking neural networks offer a promising path toward energy-efficient,\nbrain-like associative memory. This paper introduces Word2Spike, a novel rate\ncoding mechanism that combines continuous word embeddings and neuromorphic\narchitectures. We develop a one-to-one mapping that converts multi-dimensional\nword vectors into spike-based attractor states using Poisson processes. Using\nBitNet b1.58 quantization, we maintain 97% semantic similarity of continuous\nembeddings on SimLex-999 while achieving 100% reconstruction accuracy on 10,000\nwords from OpenAI's text-embedding-3-large. We preserve analogy performance\n(100% of original embedding performance) even under intentionally introduced\nnoise, indicating a resilient mechanism for semantic encoding in neuromorphic\nsystems. Next steps include integrating the mapping with spiking transformers\nand liquid state machines (resembling Hopfield Networks) for further\nevaluation.", "published": "2025-09-09 03:15:22", "link": "http://arxiv.org/abs/2509.07361v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity", "abstract": "Intermediate token generation (ITG), where a model produces output before the\nsolution, has been proposed as a method to improve the performance of language\nmodels on reasoning tasks. While these reasoning traces or Chain of Thoughts\n(CoTs) are correlated with performance gains, the mechanisms underlying them\nremain unclear. A prevailing assumption in the community has been to\nanthropomorphize these tokens as \"thinking\", treating longer traces as evidence\nof higher problem-adaptive computation. In this work, we critically examine\nwhether intermediate token sequence length reflects or correlates with problem\ndifficulty. To do so, we train transformer models from scratch on derivational\ntraces of the A* search algorithm, where the number of operations required to\nsolve a maze problem provides a precise and verifiable measure of problem\ncomplexity. We first evaluate the models on trivial free-space problems,\nfinding that even for the simplest tasks, they often produce excessively long\nreasoning traces and sometimes fail to generate a solution. We then\nsystematically evaluate the model on out-of-distribution problems and find that\nthe intermediate token length and ground truth A* trace length only loosely\ncorrelate. We notice that the few cases where correlation appears are those\nwhere the problems are closer to the training distribution, suggesting that the\neffect arises from approximate recall rather than genuine problem-adaptive\ncomputation. This suggests that the inherent computational complexity of the\nproblem instance is not a significant factor, but rather its distributional\ndistance from the training data. These results challenge the assumption that\nintermediate trace generation is adaptive to problem difficulty and caution\nagainst interpreting longer sequences in systems like R1 as automatically\nindicative of \"thinking effort\".", "published": "2025-09-09 02:31:16", "link": "http://arxiv.org/abs/2509.07339v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases", "abstract": "Demographic attributes are universally present in electronic health records\nand serve as vital predictors in clinical risk stratification and treatment\ndecisions. Despite their significance, these attributes are often relegated to\nauxiliary roles in model design, with limited attention has been given to\nlearning their representations. This study proposes a General Demographic\nPre-trained (GDP) model as a foundational representation framework tailored to\nage and gender. The model is pre-trained and evaluated using datasets with\ndiverse diseases and population compositions from different geographic regions.\nThe GDP architecture explores combinations of ordering strategies and encoding\nmethods to transform tabular demographic inputs into latent embeddings.\nExperimental results demonstrate that sequential ordering substantially\nimproves model performance in discrimination, calibration, and the\ncorresponding information gain at each decision tree split, particularly in\ndiseases where age and gender contribute significantly to risk stratification.\nEven in datasets where demographic attributes hold relatively low predictive\nvalue, GDP enhances the representational importance, increasing their influence\nin downstream gradient boosting models. The findings suggest that foundational\nmodels for tabular demographic attributes can generalize across tasks and\npopulations, offering a promising direction for improving predictive\nperformance in healthcare applications.", "published": "2025-09-09 02:02:27", "link": "http://arxiv.org/abs/2509.07330v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DEPF: A UAV Multispectral Object Detector with Dual-Domain Enhancement and Priority-Guided Mamba Fusion", "abstract": "Multispectral remote sensing object detection is one of the important\napplication of unmanned aerial vehicle (UAV). However, it faces three\nchallenges. Firstly, the low-light remote sensing images reduce the\ncomplementarity during multi-modality fusion. Secondly, the local small target\nmodeling is interfered with redundant information in the fusion stage easily.\nThirdly, due to the quadratic computational complexity, it is hard to apply the\ntransformer-based methods on the UAV platform. To address these limitations,\nmotivated by Mamba with linear complexity, a UAV multispectral object detector\nwith dual-domain enhancement and priority-guided mamba fusion (DEPF) is\nproposed. Firstly, to enhance low-light remote sensing images, Dual-Domain\nEnhancement Module (DDE) is designed, which contains Cross-Scale Wavelet Mamba\n(CSWM) and Fourier Details Recovery block (FDR). CSWM applies cross-scale mamba\nscanning for the low-frequency components to enhance the global brightness of\nimages, while FDR constructs spectrum recovery network to enhance the frequency\nspectra features for recovering the texture-details. Secondly, to enhance local\ntarget modeling and reduce the impact of redundant information during fusion,\nPriority-Guided Mamba Fusion Module (PGMF) is designed. PGMF introduces the\nconcept of priority scanning, which starts from local targets features\naccording to the priority scores obtained from modality difference. Experiments\non DroneVehicle dataset and VEDAI dataset reports that, DEPF performs well on\nobject detection, comparing with state-of-the-art methods. Our code is\navailable in the supplementary material.", "published": "2025-09-09 01:51:57", "link": "http://arxiv.org/abs/2509.07327v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models", "abstract": "Neural Collaborative Filtering models are widely used in recommender systems\nbut are typically trained under static settings, assuming fixed data\ndistributions. This limits their applicability in dynamic environments where\nuser preferences evolve. Incremental learning offers a promising solution, yet\nconventional methods from computer vision or NLP face challenges in\nrecommendation tasks due to data sparsity and distinct task paradigms. Existing\napproaches for neural recommenders remain limited and often lack\ngeneralizability. To address this, we propose MEGG, Replay Samples with\nMaximally Extreme GGscore, an experience replay based incremental learning\nframework. MEGG introduces GGscore, a novel metric that quantifies sample\ninfluence, enabling the selective replay of highly influential samples to\nmitigate catastrophic forgetting. Being model-agnostic, MEGG integrates\nseamlessly across architectures and frameworks. Experiments on three neural\nmodels and four benchmark datasets show superior performance over\nstate-of-the-art baselines, with strong scalability, efficiency, and\nrobustness. Implementation will be released publicly upon acceptance.", "published": "2025-09-09 01:35:51", "link": "http://arxiv.org/abs/2509.07319v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "CAViAR: Critic-Augmented Video Agentic Reasoning", "abstract": "Video understanding has seen significant progress in recent years, with\nmodels' performance on perception from short clips continuing to rise. Yet,\nmultiple recent benchmarks, such as LVBench, Neptune, and ActivityNet-RTL, show\nperformance wanes for tasks requiring complex reasoning on videos as queries\ngrow more complex and videos grow longer. In this work, we ask: can existing\nperception capabilities be leveraged to successfully perform more complex video\nreasoning? In particular, we develop a large language model agent given access\nto video modules as subagents or tools. Rather than following a fixed procedure\nto solve queries as in previous work such as Visual Programming, ViperGPT, and\nMoReVQA, the agent uses the results of each call to a module to determine\nsubsequent steps. Inspired by work in the textual reasoning domain, we\nintroduce a critic to distinguish between instances of successful and\nunsuccessful sequences from the agent. We show that the combination of our\nagent and critic achieve strong performance on the previously-mentioned\ndatasets.", "published": "2025-09-09 17:59:39", "link": "http://arxiv.org/abs/2509.07680v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Visual Representation Alignment for Multimodal Large Language Models", "abstract": "Multimodal large language models (MLLMs) trained with visual instruction\ntuning have achieved strong performance across diverse tasks, yet they remain\nlimited in vision-centric tasks such as object counting or spatial reasoning.\nWe attribute this gap to the prevailing text-only supervision paradigm, which\nprovides only indirect guidance for the visual pathway and often leads MLLMs to\ndiscard fine-grained visual details during training. In this paper, we present\nVIsual Representation ALignment (VIRAL), a simple yet effective regularization\nstrategy that aligns the internal visual representations of MLLMs with those of\npre-trained vision foundation models (VFMs). By explicitly enforcing this\nalignment, VIRAL enables the model not only to retain critical visual details\nfrom the input vision encoder but also to complement additional visual\nknowledge from VFMs, thereby enhancing its ability to reason over complex\nvisual inputs. Our experiments demonstrate consistent improvements across all\ntasks on widely adopted multimodal benchmarks. Furthermore, we conduct\ncomprehensive ablation studies to validate the key design choices underlying\nour framework. We believe this simple finding opens up an important direction\nfor the effective integration of visual information in training MLLMs.", "published": "2025-09-09 17:59:14", "link": "http://arxiv.org/abs/2509.07979v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation", "abstract": "Estimating the 6D pose of arbitrary unseen objects from a single reference\nimage is critical for robotics operating in the long-tail of real-world\ninstances. However, this setting is notoriously challenging: 3D models are\nrarely available, single-view reconstructions lack metric scale, and domain\ngaps between generated models and real-world images undermine robustness. We\npropose OnePoseViaGen, a pipeline that tackles these challenges through two key\ncomponents. First, a coarse-to-fine alignment module jointly refines scale and\npose by combining multi-view feature matching with render-and-compare\nrefinement. Second, a text-guided generative domain randomization strategy\ndiversifies textures, enabling effective fine-tuning of pose estimators with\nsynthetic data. Together, these steps allow high-fidelity single-view 3D\ngeneration to support reliable one-shot 6D pose estimation. On challenging\nbenchmarks (YCBInEOAT, Toyota-Light, LM-O), OnePoseViaGen achieves\nstate-of-the-art performance far surpassing prior approaches. We further\ndemonstrate robust dexterous grasping with a real robot hand, validating the\npracticality of our method in real-world manipulation. Project page:\nhttps://gzwsama.github.io/OnePoseviaGen.github.io/", "published": "2025-09-09 17:59:02", "link": "http://arxiv.org/abs/2509.07978v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Feature Space Analysis by Guided Diffusion Model", "abstract": "One of the key issues in Deep Neural Networks (DNNs) is the black-box nature\nof their internal feature extraction process. Targeting vision-related domains,\nthis paper focuses on analysing the feature space of a DNN by proposing a\ndecoder that can generate images whose features are guaranteed to closely match\na user-specified feature. Owing to this guarantee that is missed in past\nstudies, our decoder allows us to evidence which of various attributes in an\nimage are encoded into a feature by the DNN, by generating images whose\nfeatures are in proximity to that feature. Our decoder is implemented as a\nguided diffusion model that guides the reverse image generation of a\npre-trained diffusion model to minimise the Euclidean distance between the\nfeature of a clean image estimated at each step and the user-specified feature.\nOne practical advantage of our decoder is that it can analyse feature spaces of\ndifferent DNNs with no additional training and run on a single COTS GPU. The\nexperimental results targeting CLIP's image encoder, ResNet-50 and vision\ntransformer demonstrate that images generated by our decoder have features\nremarkably similar to the user-specified ones and reveal valuable insights into\nthese DNNs' feature spaces.", "published": "2025-09-09 17:18:39", "link": "http://arxiv.org/abs/2509.07936v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Dynamic Scene 3D Reconstruction of an Uncooperative Resident Space Object", "abstract": "Characterization of uncooperative Resident Space Objects (RSO) play a crucial\nrole in On-Orbit Servicing (OOS) and Active Debris Removal (ADR) missions to\nassess the geometry and motion properties. To address the challenges of\nreconstructing tumbling uncooperative targets, this study evaluates the\nperformance of existing state-of-the-art 3D reconstruction algorithms for\ndynamic scenes, focusing on their ability to generate geometrically accurate\nmodels with high-fidelity. To support our evaluation, we developed a simulation\nenvironment using Isaac Sim to generate physics-accurate 2D image sequences of\ntumbling satellite under realistic orbital lighting conditions. Our preliminary\nresults on static scenes using Neuralangelo demonstrate promising\nreconstruction quality. The generated 3D meshes closely match the original CAD\nmodels with minimal errors and artifacts when compared using Cloud Compare\n(CC). The reconstructed models were able to capture critical fine details for\nmission planning. This provides a baseline for our ongoing evaluation of\ndynamic scene reconstruction.", "published": "2025-09-09 17:16:38", "link": "http://arxiv.org/abs/2509.07932v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion", "abstract": "Joint reconstruction of human-object interaction marks a significant\nmilestone in comprehending the intricate interrelations between humans and\ntheir surrounding environment. Nevertheless, previous optimization methods\noften struggle to achieve physically plausible reconstruction results due to\nthe lack of prior knowledge about human-object interactions. In this paper, we\nintroduce ScoreHOI, an effective diffusion-based optimizer that introduces\ndiffusion priors for the precise recovery of human-object interactions. By\nharnessing the controllability within score-guided sampling, the diffusion\nmodel can reconstruct a conditional distribution of human and object pose given\nthe image observation and object feature. During inference, the ScoreHOI\neffectively improves the reconstruction results by guiding the denoising\nprocess with specific physical constraints. Furthermore, we propose a\ncontact-driven iterative refinement approach to enhance the contact\nplausibility and improve the reconstruction accuracy. Extensive evaluations on\nstandard benchmarks demonstrate ScoreHOI's superior performance over\nstate-of-the-art methods, highlighting its ability to achieve a precise and\nrobust improvement in joint human-object interaction reconstruction.", "published": "2025-09-09 17:00:42", "link": "http://arxiv.org/abs/2509.07920v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Object-level Correlation for Few-Shot Segmentation", "abstract": "Few-shot semantic segmentation (FSS) aims to segment objects of novel\ncategories in the query images given only a few annotated support samples.\nExisting methods primarily build the image-level correlation between the\nsupport target object and the entire query image. However, this correlation\ncontains the hard pixel noise, \\textit{i.e.}, irrelevant background objects,\nthat is intractable to trace and suppress, leading to the overfitting of the\nbackground. To address the limitation of this correlation, we imitate the\nbiological vision process to identify novel objects in the object-level\ninformation. Target identification in the general objects is more valid than in\nthe entire image, especially in the low-data regime. Inspired by this, we\ndesign an Object-level Correlation Network (OCNet) by establishing the\nobject-level correlation between the support target object and query general\nobjects, which is mainly composed of the General Object Mining Module (GOMM)\nand Correlation Construction Module (CCM). Specifically, GOMM constructs the\nquery general object feature by learning saliency and high-level similarity\ncues, where the general objects include the irrelevant background objects and\nthe target foreground object. Then, CCM establishes the object-level\ncorrelation by allocating the target prototypes to match the general object\nfeature. The generated object-level correlation can mine the query target\nfeature and suppress the hard pixel noise for the final prediction. Extensive\nexperiments on PASCAL-${5}^{i}$ and COCO-${20}^{i}$ show that our model\nachieves the state-of-the-art performance.", "published": "2025-09-09 16:58:28", "link": "http://arxiv.org/abs/2509.07917v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "D-LEAF: Localizing and Correcting Hallucinations in Multimodal LLMs via Layer-to-head Attention Diagnostics", "abstract": "Multimodal Large Language Models (MLLMs) achieve strong performance on tasks\nlike image captioning and visual question answering, but remain prone to\nhallucinations, where generated text conflicts with the visual input. Prior\nwork links this partly to insufficient visual attention, but existing\nattention-based detectors and mitigation typically apply uniform adjustments\nacross layers and heads, obscuring where errors originate. In this paper, we\nfirst show these methods fail to accurately localize problematic layers. Then,\nwe introduce two diagnostics: Layer Image Attention Entropy (LIAE) which flags\nanomalous layers, and Image Attention Focus (IAF) which scores attention heads\nwithin those layers. Analysis shows that LIAE pinpoints faulty layers and IAF\nreliably ranks heads that warrant correction. Guided by these signals, we\npropose Dynamic Layer-wise Entropy and Attention Fusion (D-LEAF), a\ntask-agnostic, attention-guided method that dynamically localizes and corrects\nerrors during inference with negligible overhead. Results show our D-LEAF\ndelivers a 53% relative improvement on standard captioning benchmarks, and on\nVQA both accuracy and F1-score improve by approximately 4%, substantially\nsuppressing hallucinations while preserving efficiency.", "published": "2025-09-09 15:51:15", "link": "http://arxiv.org/abs/2509.07864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model", "abstract": "3D object segmentation with Large Language Models (LLMs) has become a\nprevailing paradigm due to its broad semantics, task flexibility, and strong\ngeneralization. However, this paradigm is hindered by representation\nmisalignment: LLMs process high-level semantic tokens, whereas 3D point clouds\nconvey only dense geometric structures. In prior methods, misalignment limits\nboth input and output. At the input stage, dense point patches require heavy\npre-alignment, weakening object-level semantics and confusing similar\ndistractors. At the output stage, predictions depend only on dense features\nwithout explicit geometric cues, leading to a loss of fine-grained accuracy. To\naddress these limitations, we present the Point Linguist Model (PLM), a general\nframework that bridges the representation gap between LLMs and dense 3D point\nclouds without requiring large-scale pre-alignment between 3D-text or\n3D-images. Specifically, we introduce Object-centric Discriminative\nRepresentation (OcDR), which learns object-centric tokens that capture target\nsemantics and scene relations under a hard negative-aware training objective.\nThis mitigates the misalignment between LLM tokens and 3D points, enhances\nresilience to distractors, and facilitates semantic-level reasoning within\nLLMs. For accurate segmentation, we introduce the Geometric Reactivation\nDecoder (GRD), which predicts masks by combining OcDR tokens carrying\nLLM-inferred geometry with corresponding dense features, preserving\ncomprehensive dense features throughout the pipeline. Extensive experiments\nshow that PLM achieves significant improvements of +7.3 mIoU on ScanNetv2 and\n+6.0 mIoU on Multi3DRefer for 3D referring segmentation, with consistent gains\nacross 7 benchmarks spanning 4 different tasks, demonstrating the effectiveness\nof comprehensive object-centric reasoning for robust 3D understanding.", "published": "2025-09-09 15:01:28", "link": "http://arxiv.org/abs/2509.07825v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting", "abstract": "3D Gaussian Splatting (3DGS) has enabled the creation of highly realistic 3D\nscene representations from sets of multi-view images. However, inpainting\nmissing regions, whether due to occlusion or scene editing, remains a\nchallenging task, often leading to blurry details, artifacts, and inconsistent\ngeometry. In this work, we introduce SplatFill, a novel depth-guided approach\nfor 3DGS scene inpainting that achieves state-of-the-art perceptual quality and\nimproved efficiency. Our method combines two key ideas: (1) joint depth-based\nand object-based supervision to ensure inpainted Gaussians are accurately\nplaced in 3D space and aligned with surrounding geometry, and (2) we propose a\nconsistency-aware refinement scheme that selectively identifies and corrects\ninconsistent regions without disrupting the rest of the scene. Evaluations on\nthe SPIn-NeRF dataset demonstrate that SplatFill not only surpasses existing\nNeRF-based and 3DGS-based inpainting methods in visual fidelity but also\nreduces training time by 24.5%. Qualitative results show our method delivers\nsharper details, fewer artifacts, and greater coherence across challenging\nviewpoints.", "published": "2025-09-09 14:47:47", "link": "http://arxiv.org/abs/2509.07809v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Faster, Self-Supervised Super-Resolution for Anisotropic Multi-View MRI Using a Sparse Coordinate Loss", "abstract": "Acquiring images in high resolution is often a challenging task. Especially\nin the medical sector, image quality has to be balanced with acquisition time\nand patient comfort. To strike a compromise between scan time and quality for\nMagnetic Resonance (MR) imaging, two anisotropic scans with different\nlow-resolution (LR) orientations can be acquired. Typically, LR scans are\nanalyzed individually by radiologists, which is time consuming and can lead to\ninaccurate interpretation. To tackle this, we propose a novel approach for\nfusing two orthogonal anisotropic LR MR images to reconstruct anatomical\ndetails in a unified representation. Our multi-view neural network is trained\nin a self-supervised manner, without requiring corresponding high-resolution\n(HR) data. To optimize the model, we introduce a sparse coordinate-based loss,\nenabling the integration of LR images with arbitrary scaling. We evaluate our\nmethod on MR images from two independent cohorts. Our results demonstrate\ncomparable or even improved super-resolution (SR) performance compared to\nstate-of-the-art (SOTA) self-supervised SR methods for different upsampling\nscales. By combining a patient-agnostic offline and a patient-specific online\nphase, we achieve a substantial speed-up of up to ten times for\npatient-specific reconstruction while achieving similar or better SR quality.\nCode is available at https://github.com/MajaSchle/tripleSR.", "published": "2025-09-09 14:38:30", "link": "http://arxiv.org/abs/2509.07798v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RayGaussX: Accelerating Gaussian-Based Ray Marching for Real-Time and High-Quality Novel View Synthesis", "abstract": "RayGauss has achieved state-of-the-art rendering quality for novel-view\nsynthesis on synthetic and indoor scenes by representing radiance and density\nfields with irregularly distributed elliptical basis functions, rendered via\nvolume ray casting using a Bounding Volume Hierarchy (BVH). However, its\ncomputational cost prevents real-time rendering on real-world scenes. Our\napproach, RayGaussX, builds on RayGauss by introducing key contributions that\naccelerate both training and inference. Specifically, we incorporate volumetric\nrendering acceleration strategies such as empty-space skipping and adaptive\nsampling, enhance ray coherence, and introduce scale regularization to reduce\nfalse-positive intersections. Additionally, we propose a new densification\ncriterion that improves density distribution in distant regions, leading to\nenhanced graphical quality on larger scenes. As a result, RayGaussX achieves 5x\nto 12x faster training and 50x to 80x higher rendering speeds (FPS) on\nreal-world datasets while improving visual quality by up to +0.56 dB in PSNR.\nProject page with videos and code: https://raygaussx.github.io/.", "published": "2025-09-09 14:19:19", "link": "http://arxiv.org/abs/2509.07782v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting", "abstract": "Human hair reconstruction is a challenging problem in computer vision, with\ngrowing importance for applications in virtual reality and digital human\nmodeling. Recent advances in 3D Gaussians Splatting (3DGS) provide efficient\nand explicit scene representations that naturally align with the structure of\nhair strands. In this work, we extend the 3DGS framework to enable strand-level\nhair geometry reconstruction from multi-view images. Our multi-stage pipeline\nfirst reconstructs detailed hair geometry using a differentiable Gaussian\nrasterizer, then merges individual Gaussian segments into coherent strands\nthrough a novel merging scheme, and finally refines and grows the strands under\nphotometric supervision.\n  While existing methods typically evaluate reconstruction quality at the\ngeometric level, they often neglect the connectivity and topology of hair\nstrands. To address this, we propose a new evaluation metric that serves as a\nproxy for assessing topological accuracy in strand reconstruction. Extensive\nexperiments on both synthetic and real-world datasets demonstrate that our\nmethod robustly handles a wide range of hairstyles and achieves efficient\nreconstruction, typically completing within one hour.\n  The project page can be found at: https://yimin-pan.github.io/hair-gs/", "published": "2025-09-09 14:08:41", "link": "http://arxiv.org/abs/2509.07774v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SEEC: Segmentation-Assisted Multi-Entropy Models for Learned Lossless Image Compression", "abstract": "Recently, learned image compression has attracted considerable attention due\nto its superior performance over traditional methods. However, most existing\napproaches employ a single entropy model to estimate the probability\ndistribution of pixel values across the entire image, which limits their\nability to capture the diverse statistical characteristics of different\nsemantic regions. To overcome this limitation, we propose Segmentation-Assisted\nMulti-Entropy Models for Lossless Image Compression (SEEC). Our framework\nutilizes semantic segmentation to guide the selection and adaptation of\nmultiple entropy models, enabling more accurate probability distribution\nestimation for distinct semantic regions. Specifically, SEEC first extracts\nimage features and then applies semantic segmentation to identify different\nregions, each assigned a specialized entropy model to better capture its unique\nstatistical properties. Finally, a multi-channel discrete logistic mixture\nlikelihood is employed to model the pixel value distributions effectively.\nExperimental results on benchmark datasets demonstrate that SEEC achieves\nstate-of-the-art compression ratios while introducing only minimal encoding and\ndecoding latency. With superior performance, the proposed model also supports\nRegions of Interest (ROIs) coding condition on the provided segmentation mask.\nOur code is available at https://github.com/chunbaobao/SEEC.", "published": "2025-09-09 13:10:11", "link": "http://arxiv.org/abs/2509.07704v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Understanding Ice Crystal Habit Diversity with Self-Supervised Learning", "abstract": "Ice-containing clouds strongly impact climate, but they are hard to model due\nto ice crystal habit (i.e., shape) diversity. We use self-supervised learning\n(SSL) to learn latent representations of crystals from ice crystal imagery. By\npre-training a vision transformer with many cloud particle images, we learn\nrobust representations of crystal morphology, which can be used for various\nscience-driven tasks. Our key contributions include (1) validating that our SSL\napproach can be used to learn meaningful representations, and (2) presenting a\nrelevant application where we quantify ice crystal diversity with these latent\nrepresentations. Our results demonstrate the power of SSL-driven\nrepresentations to improve the characterization of ice crystals and\nsubsequently constrain their role in Earth's climate system.", "published": "2025-09-09 12:54:20", "link": "http://arxiv.org/abs/2509.07688v1", "categories": ["physics.ao-ph", "cs.CV"], "primary_category": "physics.ao-ph"}
{"title": "Nearest Neighbor Projection Removal Adversarial Training", "abstract": "Deep neural networks have exhibited impressive performance in image\nclassification tasks but remain vulnerable to adversarial examples. Standard\nadversarial training enhances robustness but typically fails to explicitly\naddress inter-class feature overlap, a significant contributor to adversarial\nsusceptibility. In this work, we introduce a novel adversarial training\nframework that actively mitigates inter-class proximity by projecting out\ninter-class dependencies from adversarial and clean samples in the feature\nspace. Specifically, our approach first identifies the nearest inter-class\nneighbors for each adversarial sample and subsequently removes projections onto\nthese neighbors to enforce stronger feature separability. Theoretically, we\ndemonstrate that our proposed logits correction reduces the Lipschitz constant\nof neural networks, thereby lowering the Rademacher complexity, which directly\ncontributes to improved generalization and robustness. Extensive experiments\nacross standard benchmarks including CIFAR-10, CIFAR-100, and SVHN show that\nour method demonstrates strong performance that is competitive with leading\nadversarial training techniques, highlighting significant achievements in both\nrobust and clean accuracy. Our findings reveal the importance of addressing\ninter-class feature proximity explicitly to bolster adversarial robustness in\nDNNs.", "published": "2025-09-09 12:38:41", "link": "http://arxiv.org/abs/2509.07673v1", "categories": ["cs.CV", "cs.LG", "68T45 (Primary), 68T10 (Secondary)", "I.5.4"], "primary_category": "cs.CV"}
{"title": "EDFFDNet: Towards Accurate and Efficient Unsupervised Multi-Grid Image Registration", "abstract": "Previous deep image registration methods that employ single homography,\nmulti-grid homography, or thin-plate spline often struggle with real scenes\ncontaining depth disparities due to their inherent limitations. To address\nthis, we propose an Exponential-Decay Free-Form Deformation Network (EDFFDNet),\nwhich employs free-form deformation with an exponential-decay basis function.\nThis design achieves higher efficiency and performs well in scenes with depth\ndisparities, benefiting from its inherent locality. We also introduce an\nAdaptive Sparse Motion Aggregator (ASMA), which replaces the MLP motion\naggregator used in previous methods. By transforming dense interactions into\nsparse ones, ASMA reduces parameters and improves accuracy. Additionally, we\npropose a progressive correlation refinement strategy that leverages\nglobal-local correlation patterns for coarse-to-fine motion estimation, further\nenhancing efficiency and accuracy. Experiments demonstrate that EDFFDNet\nreduces parameters, memory, and total runtime by 70.5%, 32.6%, and 33.7%,\nrespectively, while achieving a 0.5 dB PSNR gain over the state-of-the-art\nmethod. With an additional local refinement stage,EDFFDNet-2 further improves\nPSNR by 1.06 dB while maintaining lower computational costs. Our method also\ndemonstrates strong generalization ability across datasets, outperforming\nprevious deep learning methods.", "published": "2025-09-09 12:30:51", "link": "http://arxiv.org/abs/2509.07662v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Motion Cues and Structural Sparsity: Revisiting Small Moving Target Detection", "abstract": "Small moving target detection is crucial for many defense applications but\nremains highly challenging due to low signal-to-noise ratios, ambiguous visual\ncues, and cluttered backgrounds. In this work, we propose a novel deep learning\nframework that differs fundamentally from existing approaches, which often rely\non target-specific features or motion cues and tend to lack robustness in\ncomplex environments. Our key insight is that small target detection and\nbackground discrimination are inherently coupled, even cluttered video\nbackgrounds often exhibit strong low-rank structures that can serve as stable\npriors for detection. We reformulate the task as a tensor-based low-rank and\nsparse decomposition problem and conduct a theoretical analysis of the\nbackground, target, and noise components to guide model design. Building on\nthese insights, we introduce TenRPCANet, a deep neural network that requires\nminimal assumptions about target characteristics. Specifically, we propose a\ntokenization strategy that implicitly enforces multi-order tensor low-rank\npriors through a self-attention mechanism. This mechanism captures both local\nand non-local self-similarity to model the low-rank background without relying\non explicit iterative optimization. In addition, inspired by the sparse\ncomponent update in tensor RPCA, we design a feature refinement module to\nenhance target saliency. The proposed method achieves state-of-the-art\nperformance on two highly distinct and challenging tasks: multi-frame infrared\nsmall target detection and space object detection. These results demonstrate\nboth the effectiveness and the generalizability of our approach.", "published": "2025-09-09 12:20:25", "link": "http://arxiv.org/abs/2509.07654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity", "abstract": "Semantic watermarking techniques for latent diffusion models (LDMs) are\nrobust against regeneration attacks, but often suffer from detection\nperformance degradation due to the loss of frequency integrity. To tackle this\nproblem, we propose a novel embedding method called Hermitian Symmetric Fourier\nWatermarking (SFW), which maintains frequency integrity by enforcing Hermitian\nsymmetry. Additionally, we introduce a center-aware embedding strategy that\nreduces the vulnerability of semantic watermarking due to cropping attacks by\nensuring robust information retention. To validate our approach, we apply these\ntechniques to existing semantic watermarking schemes, enhancing their\nfrequency-domain structures for better robustness and retrieval accuracy.\nExtensive experiments demonstrate that our methods achieve state-of-the-art\nverification and identification performance, surpassing previous approaches\nacross various attack scenarios. Ablation studies confirm the impact of SFW on\ndetection capabilities, the effectiveness of the center-aware embedding against\ncropping, and how message capacity influences identification accuracy. Notably,\nour method achieves the highest detection accuracy while maintaining superior\nimage fidelity, as evidenced by FID and CLIP scores. Conclusively, our proposed\nSFW is shown to be an effective framework for balancing robustness and image\nfidelity, addressing the inherent trade-offs in semantic watermarking. Code\navailable at https://github.com/thomas11809/SFWMark", "published": "2025-09-09 12:15:16", "link": "http://arxiv.org/abs/2509.07647v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-Supervised Cross-Encoder for Neurodegenerative Disease Diagnosis", "abstract": "Deep learning has shown significant potential in diagnosing neurodegenerative\ndiseases from MRI data. However, most existing methods rely heavily on large\nvolumes of labeled data and often yield representations that lack\ninterpretability. To address both challenges, we propose a novel\nself-supervised cross-encoder framework that leverages the temporal continuity\nin longitudinal MRI scans for supervision. This framework disentangles learned\nrepresentations into two components: a static representation, constrained by\ncontrastive learning, which captures stable anatomical features; and a dynamic\nrepresentation, guided by input-gradient regularization, which reflects\ntemporal changes and can be effectively fine-tuned for downstream\nclassification tasks. Experimental results on the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) dataset demonstrate that our method achieves\nsuperior classification accuracy and improved interpretability. Furthermore,\nthe learned representations exhibit strong zero-shot generalization on the Open\nAccess Series of Imaging Studies (OASIS) dataset and cross-task generalization\non the Parkinson Progression Marker Initiative (PPMI) dataset. The code for the\nproposed method will be made publicly available.", "published": "2025-09-09 11:52:24", "link": "http://arxiv.org/abs/2509.07623v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease", "abstract": "Medical vision-language models (Med-VLMs) have shown impressive results in\ntasks such as report generation and visual question answering, but they still\nface several limitations. Most notably, they underutilize patient metadata and\nlack integration of clinical diagnostic knowledge. Moreover, most existing\nmodels are typically trained from scratch or fine-tuned on large-scale 2D\nimage-text pairs, requiring extensive computational resources, and their\neffectiveness on 3D medical imaging is often limited due to the absence of\nstructural information. To address these gaps, we propose a data-efficient\nfine-tuning pipeline to adapt 3D CT-based Med-VLMs for 3D MRI and demonstrate\nits application in Alzheimer's disease (AD) diagnosis. Our system introduces\ntwo key innovations. First, we convert structured metadata into synthetic\nreports, enriching textual input for improved image-text alignment. Second, we\nadd an auxiliary token trained to predict the mini-mental state examination\n(MMSE) score, a widely used clinical measure of cognitive function that\ncorrelates with AD severity. This provides additional supervision for\nfine-tuning. Applying lightweight prompt tuning to both image and text\nmodalities, our approach achieves state-of-the-art performance on two AD\ndatasets using 1,500 training images, outperforming existing methods fine-tuned\non 10,000 images. Code will be released upon publication.", "published": "2025-09-09 11:36:21", "link": "http://arxiv.org/abs/2509.07613v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation", "abstract": "Gender bias in vision-language foundation models (VLMs) raises concerns about\ntheir safe deployment and is typically evaluated using benchmarks with gender\nannotations on real-world images. However, as these benchmarks often contain\nspurious correlations between gender and non-gender features, such as objects\nand backgrounds, we identify a critical oversight in gender bias evaluation: Do\nspurious features distort gender bias evaluation? To address this question, we\nsystematically perturb non-gender features across four widely used benchmarks\n(COCO-gender, FACET, MIAP, and PHASE) and various VLMs to quantify their impact\non bias evaluation. Our findings reveal that even minimal perturbations, such\nas masking just 10% of objects or weakly blurring backgrounds, can dramatically\nalter bias scores, shifting metrics by up to 175% in generative VLMs and 43% in\nCLIP variants. This suggests that current bias evaluations often reflect model\nresponses to spurious features rather than gender bias, undermining their\nreliability. Since creating spurious feature-free benchmarks is fundamentally\nchallenging, we recommend reporting bias metrics alongside feature-sensitivity\nmeasurements to enable a more reliable bias assessment.", "published": "2025-09-09 11:14:11", "link": "http://arxiv.org/abs/2509.07596v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Temporal Image Forensics: A Review and Critical Evaluation", "abstract": "Temporal image forensics is the science of estimating the age of a digital\nimage. Usually, time-dependent traces (age traces) introduced by the image\nacquisition pipeline are exploited for this purpose. In this review, a\ncomprehensive overview of the field of temporal image forensics based on\ntime-dependent traces from the image acquisition pipeline is given. This\nincludes a detailed insight into the properties of known age traces (i.e.,\nin-field sensor defects and sensor dust) and temporal image forensics\ntechniques. Another key aspect of this work is to highlight the problem of\ncontent bias and to illustrate how important eXplainable Artificial\nIntelligence methods are to verify the reliability of temporal image forensics\ntechniques. Apart from reviewing material presented in previous works, in this\nreview: (i) a new (probably more realistic) forensic setting is proposed; (ii)\nthe main properties (growth rate and spatial distribution) of in-field sensor\ndefects are verified; (iii) it is shown that a method proposed to utilize\nin-field sensor defects for image age approximation actually exploits other\ntraces (most likely content bias); (iv) the features learned by a neural\nnetwork dating palmprint images are further investigated; (v) it is shown how\neasily a neural network can be distracted from learning age traces. For this\npurpose, previous work is analyzed, re-implemented if required and experiments\nare conducted.", "published": "2025-09-09 11:03:33", "link": "http://arxiv.org/abs/2509.07591v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image", "abstract": "We present a feed-forward framework for Gaussian full-head synthesis from a\nsingle unposed image. Unlike previous work that relies on time-consuming GAN\ninversion and test-time optimization, our framework can reconstruct the\nGaussian full-head model given a single unposed image in a single forward pass.\nThis enables fast reconstruction and rendering during inference. To mitigate\nthe lack of large-scale 3D head assets, we propose a large-scale synthetic\ndataset from trained 3D GANs and train our framework using only synthetic data.\nFor efficient high-fidelity generation, we introduce a coarse-to-fine Gaussian\nhead generation pipeline, where sparse points from the FLAME model interact\nwith the image features by transformer blocks for feature extraction and coarse\nshape reconstruction, which are then densified for high-fidelity\nreconstruction. To fully leverage the prior knowledge residing in pretrained 3D\nGANs for effective reconstruction, we propose a dual-branch framework that\neffectively aggregates the structured spherical triplane feature and\nunstructured point-based features for more effective Gaussian head\nreconstruction. Experimental results show the effectiveness of our framework\ntowards existing work.", "published": "2025-09-09 09:42:31", "link": "http://arxiv.org/abs/2509.07552v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextlessRAG: End-to-End Visual Document RAG by Speech Without Text", "abstract": "Document images encapsulate a wealth of knowledge, while the portability of\nspoken queries enables broader and flexible application scenarios. Yet, no\nprior work has explored knowledge base question answering over visual document\nimages with queries provided directly in speech. We propose TextlessRAG, the\nfirst end-to-end framework for speech-based question answering over large-scale\ndocument images. Unlike prior methods, TextlessRAG eliminates ASR, TTS and OCR,\ndirectly interpreting speech, retrieving relevant visual knowledge, and\ngenerating answers in a fully textless pipeline. To further boost performance,\nwe integrate a layout-aware reranking mechanism to refine retrieval.\nExperiments demonstrate substantial improvements in both efficiency and\naccuracy. To advance research in this direction, we also release the first\nbilingual speech--document RAG dataset, featuring Chinese and English voice\nqueries paired with multimodal document content. Both the dataset and our\npipeline will be made available at\nrepository:https://github.com/xiepeijinhit-hue/textlessrag", "published": "2025-09-09 09:16:25", "link": "http://arxiv.org/abs/2509.07538v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Universal Few-Shot Spatial Control for Diffusion Models", "abstract": "Spatial conditioning in pretrained text-to-image diffusion models has\nsignificantly improved fine-grained control over the structure of generated\nimages. However, existing control adapters exhibit limited adaptability and\nincur high training costs when encountering novel spatial control conditions\nthat differ substantially from the training tasks. To address this limitation,\nwe propose Universal Few-Shot Control (UFC), a versatile few-shot control\nadapter capable of generalizing to novel spatial conditions. Given a few\nimage-condition pairs of an unseen task and a query condition, UFC leverages\nthe analogy between query and support conditions to construct task-specific\ncontrol features, instantiated by a matching mechanism and an update on a small\nset of task-specific parameters. Experiments on six novel spatial control tasks\nshow that UFC, fine-tuned with only 30 annotated examples of novel tasks,\nachieves fine-grained control consistent with the spatial conditions. Notably,\nwhen fine-tuned with 0.1% of the full training data, UFC achieves competitive\nperformance with the fully supervised baselines in various control tasks. We\nalso show that UFC is applicable agnostically to various diffusion backbones\nand demonstrate its effectiveness on both UNet and DiT architectures. Code is\navailable at https://github.com/kietngt00/UFC.", "published": "2025-09-09 09:08:07", "link": "http://arxiv.org/abs/2509.07530v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural Cone Radiosity for Interactive Global Illumination with Glossy Materials", "abstract": "Modeling of high-frequency outgoing radiance distributions has long been a\nkey challenge in rendering, particularly for glossy material. Such\ndistributions concentrate radiative energy within a narrow lobe and are highly\nsensitive to changes in view direction. However, existing neural radiosity\nmethods, which primarily rely on positional feature encoding, exhibit notable\nlimitations in capturing these high-frequency, strongly view-dependent radiance\ndistributions. To address this, we propose a highly-efficient approach by\nreflectance-aware ray cone encoding based on the neural radiosity framework,\nnamed neural cone radiosity. The core idea is to employ a pre-filtered\nmulti-resolution hash grid to accurately approximate the glossy BSDF lobe,\nembedding view-dependent reflectance characteristics directly into the encoding\nprocess through continuous spatial aggregation. Our design not only\nsignificantly improves the network's ability to model high-frequency reflection\ndistributions but also effectively handles surfaces with a wide range of\nglossiness levels, from highly glossy to low-gloss finishes. Meanwhile, our\nmethod reduces the network's burden in fitting complex radiance distributions,\nallowing the overall architecture to remain compact and efficient.\nComprehensive experimental results demonstrate that our method consistently\nproduces high-quality, noise-free renderings in real time under various\nglossiness conditions, and delivers superior fidelity and realism compared to\nbaseline approaches.", "published": "2025-09-09 08:58:13", "link": "http://arxiv.org/abs/2509.07522v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection", "abstract": "Annotating 3D data remains a costly bottleneck for 3D object detection,\nmotivating the development of weakly supervised annotation methods that rely on\nmore accessible 2D box annotations. However, relying solely on 2D boxes\nintroduces projection ambiguities since a single 2D box can correspond to\nmultiple valid 3D poses. Furthermore, partial object visibility under a single\nviewpoint setting makes accurate 3D box estimation difficult. We propose MVAT,\na novel framework that leverages temporal multi-view present in sequential data\nto address these challenges. Our approach aggregates object-centric point\nclouds across time to build 3D object representations as dense and complete as\npossible. A Teacher-Student distillation paradigm is employed: The Teacher\nnetwork learns from single viewpoints but targets are derived from temporally\naggregated static objects. Then the Teacher generates high quality\npseudo-labels that the Student learns to predict from a single viewpoint for\nboth static and moving objects. The whole framework incorporates a multi-view\n2D projection loss to enforce consistency between predicted 3D boxes and all\navailable 2D annotations. Experiments on the nuScenes and Waymo Open datasets\ndemonstrate that MVAT achieves state-of-the-art performance for weakly\nsupervised 3D object detection, significantly narrowing the gap with fully\nsupervised methods without requiring any 3D box annotations. % \\footnote{Code\navailable upon acceptance} Our code is available in our public repository\n(\\href{https://github.com/CEA-LIST/MVAT}{code}).", "published": "2025-09-09 08:40:54", "link": "http://arxiv.org/abs/2509.07507v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiGS: Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning", "abstract": "3D Gaussian Splatting (3DGS) has recently emerged as a powerful paradigm for\nphotorealistic view synthesis, representing scenes with spatially distributed\nGaussian primitives. While highly effective for rendering, achieving accurate\nand complete surface reconstruction remains challenging due to the unstructured\nnature of the representation and the absence of explicit geometric supervision.\nIn this work, we propose DiGS, a unified framework that embeds Signed Distance\nField (SDF) learning directly into the 3DGS pipeline, thereby enforcing strong\nand interpretable surface priors. By associating each Gaussian with a learnable\nSDF value, DiGS explicitly aligns primitives with underlying geometry and\nimproves cross-view consistency. To further ensure dense and coherent coverage,\nwe design a geometry-guided grid growth strategy that adaptively distributes\nGaussians along geometry-consistent regions under a multi-scale hierarchy.\nExtensive experiments on standard benchmarks, including DTU, Mip-NeRF 360, and\nTanks& Temples, demonstrate that DiGS consistently improves reconstruction\naccuracy and completeness while retaining high rendering fidelity.", "published": "2025-09-09 08:17:46", "link": "http://arxiv.org/abs/2509.07493v1", "categories": ["cs.CV", "cs.CG"], "primary_category": "cs.CV"}
{"title": "LINR Bridge: Vector Graphic Animation via Neural Implicits and Video Diffusion Priors", "abstract": "Vector graphics, known for their scalability and user-friendliness, provide a\nunique approach to visual content compared to traditional pixel-based images.\nAnimation of these graphics, driven by the motion of their elements, offers\nenhanced comprehensibility and controllability but often requires substantial\nmanual effort. To automate this process, we propose a novel method that\nintegrates implicit neural representations with text-to-video diffusion models\nfor vector graphic animation. Our approach employs layered implicit neural\nrepresentations to reconstruct vector graphics, preserving their inherent\nproperties such as infinite resolution and precise color and shape constraints,\nwhich effectively bridges the large domain gap between vector graphics and\ndiffusion models. The neural representations are then optimized using video\nscore distillation sampling, which leverages motion priors from pretrained\ntext-to-video diffusion models. Finally, the vector graphics are warped to\nmatch the representations resulting in smooth animation. Experimental results\nvalidate the effectiveness of our method in generating vivid and natural vector\ngraphic animations, demonstrating significant improvement over existing\ntechniques that suffer from limitations in flexibility and animation quality.", "published": "2025-09-09 08:04:36", "link": "http://arxiv.org/abs/2509.07484v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MedicalPatchNet: A Patch-Based Self-Explainable AI Architecture for Chest X-ray Classification", "abstract": "Deep neural networks excel in radiological image classification but\nfrequently suffer from poor interpretability, limiting clinical acceptance. We\npresent MedicalPatchNet, an inherently self-explainable architecture for chest\nX-ray classification that transparently attributes decisions to distinct image\nregions. MedicalPatchNet splits images into non-overlapping patches,\nindependently classifies each patch, and aggregates predictions, enabling\nintuitive visualization of each patch's diagnostic contribution without\npost-hoc techniques. Trained on the CheXpert dataset (223,414 images),\nMedicalPatchNet matches the classification performance (AUROC 0.907 vs. 0.908)\nof EfficientNet-B0, while substantially improving interpretability:\nMedicalPatchNet demonstrates substantially improved interpretability with\nhigher pathology localization accuracy (mean hit-rate 0.485 vs. 0.376 with\nGrad-CAM) on the CheXlocalize dataset. By providing explicit, reliable\nexplanations accessible even to non-AI experts, MedicalPatchNet mitigates risks\nassociated with shortcut learning, thus improving clinical trust. Our model is\npublicly available with reproducible training and inference scripts and\ncontributes to safer, explainable AI-assisted diagnostics across medical\nimaging domains. We make the code publicly available:\nhttps://github.com/TruhnLab/MedicalPatchNet", "published": "2025-09-09 08:02:10", "link": "http://arxiv.org/abs/2509.07477v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ANYPORTAL: Zero-Shot Consistent Video Background Replacement", "abstract": "Despite the rapid advancements in video generation technology, creating\nhigh-quality videos that precisely align with user intentions remains a\nsignificant challenge. Existing methods often fail to achieve fine-grained\ncontrol over video details, limiting their practical applicability. We\nintroduce ANYPORTAL, a novel zero-shot framework for video background\nreplacement that leverages pre-trained diffusion models. Our framework\ncollaboratively integrates the temporal prior of video diffusion models with\nthe relighting capabilities of image diffusion models in a zero-shot setting.\nTo address the critical challenge of foreground consistency, we propose a\nRefinement Projection Algorithm, which enables pixel-level detail manipulation\nto ensure precise foreground preservation. ANYPORTAL is training-free and\novercomes the challenges of achieving foreground consistency and temporally\ncoherent relighting. Experimental results demonstrate that ANYPORTAL achieves\nhigh-quality results on consumer-grade GPUs, offering a practical and efficient\nsolution for video content creation and editing.", "published": "2025-09-09 07:50:53", "link": "http://arxiv.org/abs/2509.07472v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "XOCT: Enhancing OCT to OCTA Translation via Cross-Dimensional Supervised Multi-Scale Feature Learning", "abstract": "Optical Coherence Tomography Angiography (OCTA) and its derived en-face\nprojections provide high-resolution visualization of the retinal and choroidal\nvasculature, which is critical for the rapid and accurate diagnosis of retinal\ndiseases. However, acquiring high-quality OCTA images is challenging due to\nmotion sensitivity and the high costs associated with software modifications\nfor conventional OCT devices. Moreover, current deep learning methods for\nOCT-to-OCTA translation often overlook the vascular differences across retinal\nlayers and struggle to reconstruct the intricate, dense vascular details\nnecessary for reliable diagnosis. To overcome these limitations, we propose\nXOCT, a novel deep learning framework that integrates Cross-Dimensional\nSupervision (CDS) with a Multi-Scale Feature Fusion (MSFF) network for\nlayer-aware vascular reconstruction. Our CDS module leverages 2D layer-wise\nen-face projections, generated via segmentation-weighted z-axis averaging, as\nsupervisory signals to compel the network to learn distinct representations for\neach retinal layer through fine-grained, targeted guidance. Meanwhile, the MSFF\nmodule enhances vessel delineation through multi-scale feature extraction\ncombined with a channel reweighting strategy, effectively capturing vascular\ndetails at multiple spatial scales. Our experiments on the OCTA-500 dataset\ndemonstrate XOCT's improvements, especially for the en-face projections which\nare significant for clinical evaluation of retinal pathologies, underscoring\nits potential to enhance OCTA accessibility, reliability, and diagnostic value\nfor ophthalmic disease detection and monitoring. The code is available at\nhttps://github.com/uci-cbcl/XOCT.", "published": "2025-09-09 07:25:36", "link": "http://arxiv.org/abs/2509.07455v1", "categories": ["cs.CV", "J.3"], "primary_category": "cs.CV"}
{"title": "In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting", "abstract": "The emergence of advanced multimodal large language models (MLLMs) has\nsignificantly enhanced AI assistants' ability to process complex information\nacross modalities. Recently, egocentric videos, by directly capturing user\nfocus, actions, and context in an unified coordinate, offer an exciting\nopportunity to enable proactive and personalized AI user experiences with\nMLLMs. However, existing benchmarks overlook the crucial role of gaze as an\nindicator of user intent. To address this gap, we introduce EgoGazeVQA, an\negocentric gaze-guided video question answering benchmark that leverages gaze\ninformation to improve the understanding of longer daily-life videos.\nEgoGazeVQA consists of gaze-based QA pairs generated by MLLMs and refined by\nhuman annotators. Our experiments reveal that existing MLLMs struggle to\naccurately interpret user intentions. In contrast, our gaze-guided intent\nprompting methods significantly enhance performance by integrating spatial,\ntemporal, and intent-related cues. We further conduct experiments on\ngaze-related fine-tuning and analyze how gaze estimation accuracy impacts\nprompting effectiveness. These results underscore the value of gaze for more\npersonalized and effective AI assistants in egocentric settings.", "published": "2025-09-09 07:11:56", "link": "http://arxiv.org/abs/2509.07447v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset Generation", "abstract": "The labor- and experience-intensive creation of 3D assets with physically\nbased rendering (PBR) materials demands an autonomous 3D asset creation\npipeline. However, most existing 3D generation methods focus on geometry\nmodeling, either baking textures into simple vertex colors or leaving texture\nsynthesis to post-processing with image diffusion models. To achieve end-to-end\nPBR-ready 3D asset generation, we present Lightweight Gaussian Asset Adapter\n(LGAA), a novel framework that unifies the modeling of geometry and PBR\nmaterials by exploiting multi-view (MV) diffusion priors from a novel\nperspective. The LGAA features a modular design with three components.\nSpecifically, the LGAA Wrapper reuses and adapts network layers from MV\ndiffusion models, which encapsulate knowledge acquired from billions of images,\nenabling better convergence in a data-efficient manner. To incorporate multiple\ndiffusion priors for geometry and PBR synthesis, the LGAA Switcher aligns\nmultiple LGAA Wrapper layers encapsulating different knowledge. Then, a tamed\nvariational autoencoder (VAE), termed LGAA Decoder, is designed to predict 2D\nGaussian Splatting (2DGS) with PBR channels. Finally, we introduce a dedicated\npost-processing procedure to effectively extract high-quality, relightable mesh\nassets from the resulting 2DGS. Extensive quantitative and qualitative\nexperiments demonstrate the superior performance of LGAA with both text-and\nimage-conditioned MV diffusion models. Additionally, the modular design enables\nflexible incorporation of multiple diffusion priors, and the\nknowledge-preserving scheme leads to efficient convergence trained on merely\n69k multi-view instances. Our code, pre-trained weights, and the dataset used\nwill be publicly available via our project page:\nhttps://zx-yin.github.io/dreamlifting/.", "published": "2025-09-09 06:43:15", "link": "http://arxiv.org/abs/2509.07435v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A smart fridge with AI-enabled food computing", "abstract": "The Internet of Things (IoT) plays a crucial role in enabling seamless\nconnectivity and intelligent home automation, particularly in food management.\nBy integrating IoT with computer vision, the smart fridge employs an ESP32-CAM\nto establish a monitoring subsystem that enhances food management efficiency\nthrough real-time food detection, inventory tracking, and temperature\nmonitoring. This benefits waste reduction, grocery planning improvement, and\nhousehold consumption optimization. In high-density inventory conditions,\ncapturing partial or layered images complicates object detection, as\noverlapping items and occluded views hinder accurate identification and\ncounting. Besides, varied angles and obscured details in multi-layered setups\nreduce algorithm reliability, often resulting in miscounts or\nmisclassifications. Our proposed system is structured into three core modules:\ndata pre-processing, object detection and management, and a web-based\nvisualization. To address the challenge of poor model calibration caused by\noverconfident predictions, we implement a variant of focal loss that mitigates\nover-confidence and under-confidence in multi-category classification. This\napproach incorporates adaptive, class-wise error calibration via temperature\nscaling and evaluates the distribution of predicted probabilities across\nmethods. Our results demonstrate that robust functional calibration\nsignificantly improves detection reliability under varying lighting conditions\nand scalability challenges. Further analysis demonstrates a practical,\nuser-focused approach to modern food management, advancing sustainable living\ngoals through reduced waste and more informed consumption.", "published": "2025-09-09 05:29:00", "link": "http://arxiv.org/abs/2509.07400v1", "categories": ["eess.SY", "cs.CV", "cs.SE", "cs.SY", "C.3; J.7"], "primary_category": "eess.SY"}
{"title": "EfficientNet in Digital Twin-based Cardiac Arrest Prediction and Analysis", "abstract": "Cardiac arrest is one of the biggest global health problems, and early\nidentification and management are key to enhancing the patient's prognosis. In\nthis paper, we propose a novel framework that combines an EfficientNet-based\ndeep learning model with a digital twin system to improve the early detection\nand analysis of cardiac arrest. We use compound scaling and EfficientNet to\nlearn the features of cardiovascular images. In parallel, the digital twin\ncreates a realistic and individualized cardiovascular system model of the\npatient based on data received from the Internet of Things (IoT) devices\nattached to the patient, which can help in the constant assessment of the\npatient and the impact of possible treatment plans. As shown by our\nexperiments, the proposed system is highly accurate in its prediction abilities\nand, at the same time, efficient. Combining highly advanced techniques such as\ndeep learning and digital twin (DT) technology presents the possibility of\nusing an active and individual approach to predicting cardiac disease.", "published": "2025-09-09 05:00:57", "link": "http://arxiv.org/abs/2509.07388v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Parse Graph-Based Visual-Language Interaction for Human Pose Estimation", "abstract": "Parse graphs boost human pose estimation (HPE) by integrating context and\nhierarchies, yet prior work mostly focuses on single modality modeling,\nignoring the potential of multimodal fusion. Notably, language offers rich HPE\npriors like spatial relations for occluded scenes, but existing visual-language\nfusion via global feature integration weakens occluded region responses and\ncauses alignment and location failures. To address this issue, we propose Parse\nGraph-based Visual-Language interaction (PGVL) with a core novel Guided Module\n(GM). In PGVL, low-level nodes focus on local features, maximizing the\nmaintenance of responses in occluded areas and high-level nodes integrate\nglobal features to infer occluded or invisible parts. GM enables high semantic\nnodes to guide the feature update of low semantic nodes that have undergone\ncross attention. It ensuring effective fusion of diverse information. PGVL\nincludes top-down decomposition and bottom-up composition. In the first stage,\nmodality specific parse graphs are constructed. Next stage. recursive\nbidirectional cross-attention is used, purified by GM. We also design network\nbased on PGVL. The PGVL and our network is validated on major pose estimation\ndatasets. We will release the code soon.", "published": "2025-09-09 04:41:35", "link": "http://arxiv.org/abs/2509.07385v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "G3CN: Gaussian Topology Refinement Gated Graph Convolutional Network for Skeleton-Based Action Recognition", "abstract": "Graph Convolutional Networks (GCNs) have proven to be highly effective for\nskeleton-based action recognition, primarily due to their ability to leverage\ngraph topology for feature aggregation, a key factor in extracting meaningful\nrepresentations. However, despite their success, GCNs often struggle to\neffectively distinguish between ambiguous actions, revealing limitations in the\nrepresentation of learned topological and spatial features. To address this\nchallenge, we propose a novel approach, Gaussian Topology Refinement Gated\nGraph Convolution (G$^{3}$CN), to address the challenge of distinguishing\nambiguous actions in skeleton-based action recognition. G$^{3}$CN incorporates\na Gaussian filter to refine the skeleton topology graph, improving the\nrepresentation of ambiguous actions. Additionally, Gated Recurrent Units (GRUs)\nare integrated into the GCN framework to enhance information propagation\nbetween skeleton points. Our method shows strong generalization across various\nGCN backbones. Extensive experiments on NTU RGB+D, NTU RGB+D 120, and NW-UCLA\nbenchmarks demonstrate that G$^{3}$CN effectively improves action recognition,\nparticularly for ambiguous samples.", "published": "2025-09-09 02:19:24", "link": "http://arxiv.org/abs/2509.07335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On the Convergence of Elementary Cellular Automata under Sequential Update Modes", "abstract": "In this paper, we perform a theoretical analysis of the sequential\nconvergence of elementary cellular automata that have at least one fixed point.\nOur aim is to establish which elementary rules always reach fixed points under\nsequential update modes, regardless of the initial configuration. In this\ncontext, we classify these rules according to whether all initial\nconfigurations converge under all, some, one or none sequential update modes,\ndepending on if they have fixed points under synchronous (or parallel) update\nmodes.", "published": "2025-09-09 14:37:57", "link": "http://arxiv.org/abs/2509.07797v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Smart Fast Finish: Preventing Overdelivery via Daily Budget Pacing at DoorDash", "abstract": "We present a budget pacing feature called Smart Fast Finish (SFF). SFF builds\nupon the industry standard Fast Finish (FF) feature in budget pacing systems\nthat depletes remaining advertising budget as quickly as possible towards the\nend of some fixed time period. SFF dynamically updates system parameters such\nas start time and throttle rate depending on historical ad-campaign data. SFF\nis currently in use at DoorDash, one of the largest delivery platforms in the\nUS, and is part of its budget pacing system. We show via online budget-split\nexperimentation data and offline simulations that SFF is a robust solution for\noverdelivery mitigation when pacing budget.", "published": "2025-09-09 17:14:09", "link": "http://arxiv.org/abs/2509.07929v1", "categories": ["cs.GT", "cs.IR", "cs.LG"], "primary_category": "cs.GT"}
{"title": "KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis", "abstract": "Effectively managing intellectual property is a significant challenge.\nTraditional methods for patent analysis depend on labor-intensive manual\nsearches and rigid keyword matching. These approaches are often inefficient and\nstruggle to reveal the complex relationships hidden within large patent\ndatasets, hindering strategic decision-making. To overcome these limitations,\nwe introduce KLIPA, a novel framework that leverages a knowledge graph and a\nlarge language model (LLM) to significantly advance patent analysis. Our\napproach integrates three key components: a structured knowledge graph to map\nexplicit relationships between patents, a retrieval-augmented generation(RAG)\nsystem to uncover contextual connections, and an intelligent agent that\ndynamically determines the optimal strategy for resolving user queries. We\nvalidated KLIPA on a comprehensive, real-world patent database, where it\ndemonstrated substantial improvements in knowledge extraction, discovery of\nnovel connections, and overall operational efficiency. This combination of\ntechnologies enhances retrieval accuracy, reduces reliance on domain experts,\nand provides a scalable, automated solution for any organization managing\nintellectual property, including technology corporations and legal firms,\nallowing them to better navigate the complexities of strategic innovation and\ncompetitive intelligence.", "published": "2025-09-09 15:40:23", "link": "http://arxiv.org/abs/2509.07860v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey", "abstract": "Modern information retrieval (IR) must bridge short, ambiguous queries and\never more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key\nmechanism for mitigating vocabulary mismatch, but the design space has shifted\nmarkedly with pre-trained language models (PLMs) and large language models\n(LLMs). This survey synthesizes the field from three angles: (i) a\nfour-dimensional framework of query expansion - from the point of injection\n(explicit vs. implicit QE), through grounding and interaction (knowledge bases,\nmodel-internal capabilities, multi-turn retrieval) and learning alignment, to\nknowledge graph-based argumentation; (ii) a model-centric taxonomy spanning\nencoder-only, encoder-decoder, decoder-only, instruction-tuned, and\ndomain/multilingual variants, highlighting their characteristic affordances for\nQE (contextual disambiguation, controllable generation, zero-/few-shot\nreasoning); and (iii) practice-oriented guidance on where and how neural QE\nhelps in first-stage retrieval, multi-query fusion, re-ranking, and\nretrieval-augmented generation (RAG). We compare traditional query expansion\nwith PLM/LLM-based methods across seven key aspects, and we map applications\nacross web search, biomedicine, e-commerce, open-domain QA/RAG, conversational\nand code search, and cross-lingual settings. The review distills design\ngrounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG\nconstraints - as robust remedies to topic drift and hallucination. We conclude\nwith an agenda on quality control, cost-aware invocation, domain/temporal\nadaptation, evaluation beyond end-task metrics, and fairness/privacy.\nCollectively, these insights provide a principled blueprint for selecting and\ncombining QE techniques under real-world constraints.", "published": "2025-09-09 14:31:11", "link": "http://arxiv.org/abs/2509.07794v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Survey of Long-Document Retrieval in the PLM and LLM Era", "abstract": "The proliferation of long-form documents presents a fundamental challenge to\ninformation retrieval (IR), as their length, dispersed evidence, and complex\nstructures demand specialized methods beyond standard passage-level techniques.\nThis survey provides the first comprehensive treatment of long-document\nretrieval (LDR), consolidating methods, challenges, and applications across\nthree major eras. We systematize the evolution from classical lexical and early\nneural models to modern pre-trained (PLM) and large language models (LLMs),\ncovering key paradigms like passage aggregation, hierarchical encoding,\nefficient attention, and the latest LLM-driven re-ranking and retrieval\ntechniques. Beyond the models, we review domain-specific applications,\nspecialized evaluation resources, and outline critical open challenges such as\nefficiency trade-offs, multimodal alignment, and faithfulness. This survey aims\nto provide both a consolidated reference and a forward-looking agenda for\nadvancing long-document retrieval in the era of foundation models.", "published": "2025-09-09 13:57:53", "link": "http://arxiv.org/abs/2509.07759v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Towards End-to-End Model-Agnostic Explanations for RAG Systems", "abstract": "Retrieval Augmented Generation (RAG) systems, despite their growing\npopularity for enhancing model response reliability, often struggle with\ntrustworthiness and explainability. In this work, we present a novel, holistic,\nmodel-agnostic, post-hoc explanation framework leveraging perturbation-based\ntechniques to explain the retrieval and generation processes in a RAG system.\nWe propose different strategies to evaluate these explanations and discuss the\nsufficiency of model-agnostic explanations in RAG systems. With this work, we\nfurther aim to catalyze a collaborative effort to build reliable and\nexplainable RAG systems.", "published": "2025-09-09 11:47:40", "link": "http://arxiv.org/abs/2509.07620v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction", "abstract": "Click-through rate (CTR) prediction plays an important role in online\nadvertising systems. On the one hand, traditional CTR prediction models capture\nthe collaborative signals in tabular data via feature interaction modeling, but\nthey lose semantics in text. On the other hand, Large Language Models (LLMs)\nexcel in understanding the context and meaning behind text, but they face\nchallenges in capturing collaborative signals and they have long inference\nlatency. In this paper, we aim to leverage the benefits of both types of models\nand pursue collaboration, semantics and efficiency. We present ELEC, which is\nan Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for\nthe CTR prediction task. In order to leverage the ability of the LLM but\nsimultaneously keep efficiency, we utilize the pseudo-siamese network which\ncontains a gain network and a vanilla network. We inject the high-level\nrepresentation vector generated by the LLM into a collaborative CTR model to\nform the gain network such that it can take advantage of both tabular modeling\nand textual modeling. However, its reliance on the LLM limits its efficiency.\nWe then distill the knowledge from the gain network to the vanilla network on\nboth the score level and the representation level, such that the vanilla\nnetwork takes only tabular data as input, but can still generate comparable\nperformance as the gain network. Our approach is model-agnostic. It allows for\nthe integration with various existing LLMs and collaborative CTR models.\nExperiments on real-world datasets demonstrate the effectiveness and efficiency\nof ELEC for CTR prediction.", "published": "2025-09-09 11:06:37", "link": "http://arxiv.org/abs/2509.07594v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multi-view-guided Passage Reranking with Large Language Models", "abstract": "Recent advances in large language models (LLMs) have shown impressive\nperformance in passage reranking tasks. Despite their success, LLM-based\nmethods still face challenges in efficiency and sensitivity to external biases.\n(1) Existing models rely mostly on autoregressive generation and sliding window\nstrategies to rank passages, which incur heavy computational overhead as the\nnumber of passages increases. (2) External biases, such as position or\nselection bias, hinder the model's ability to accurately represent passages and\nincrease input-order sensitivity. To address these limitations, we introduce a\nnovel passage reranking model, called Multi-View-guided Passage Reranking\n(MVP). MVP is a non-generative LLM-based reranking method that encodes\nquery-passage information into diverse view embeddings without being influenced\nby external biases. For each view, it combines query-aware passage embeddings\nto produce a distinct anchor vector, which is then used to directly compute\nrelevance scores in a single decoding step. In addition, it employs an\northogonal loss to make the views more distinctive. Extensive experiments\ndemonstrate that MVP, with just 220M parameters, matches the performance of\nmuch larger 7B-scale fine-tuned models while achieving a 100x reduction in\ninference latency. Notably, the 3B-parameter variant of MVP achieves\nstate-of-the-art performance on both in-domain and out-of-domain benchmarks.\nThe source code is available at: https://github.com/bulbna/MVP", "published": "2025-09-09 08:05:16", "link": "http://arxiv.org/abs/2509.07485v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RAQ-MIMO: MIMO for Multi-Band Rydberg Atomic Quantum Receiver", "abstract": "Rydberg atomic quantum receivers (RAQRs) are capable of receiving multi-band\nradio-frequency (RF) signals simultaneously, which are expected to break Chu's\nlimit for classical electronic antennas. However, signals from different users\nwill interfere with each other in the optical intermediate frequency (IF)\ndomain of the multi-band quantum receiver, which is termed the IF interference\n(IFI) problem. To address this problem, in this paper, we propose a multi-input\nmulti-output (MIMO) architecture for Rydberg atomic quantum receiver (RAQ-MIMO)\nby exploiting the additional spatial diversity of MIMO receivers. Specifically,\nby applying the dynamic signal model of RAQRs, we clarify the physical\nrelationship between the quantum local oscillator (LO) configurations and the\nmulti-band gains with the concept of quantum transconductance. Then, with the\nquantum transconductance-based signal model, we formulate the spectral\nefficiency (SE) maximization problem and further propose the quantum weighted\nminimum mean square error (qWMMSE) algorithm, which jointly optimizes the\nquantum LO configurations and the classical precoder/combiner matrices.\nFurthermore, we test the qWMMSE algorithm within the standard space division\nmultiple access (SDMA) scheme and the frequency division multiple access (FDMA)\nscheme. Simulation results demonstrate that the qWMMSE optimization framework\ncan significantly improve the SE of RAQ-MIMO systems for both multiple access\nschemes, and that RAQ-MIMO systems can outperform classical electronic\nreceiver-based multi-user MIMO systems by eliminating the mutual coupling\neffect between classical antennas.", "published": "2025-09-09 15:10:12", "link": "http://arxiv.org/abs/2509.07832v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantum Computing for Large-scale Network Optimization: Opportunities and Challenges", "abstract": "The complexity of large-scale 6G-and-beyond networks demands innovative\napproaches for multi-objective optimization over vast search spaces, a task\noften intractable. Quantum computing (QC) emerges as a promising technology for\nefficient large-scale optimization. We present our vision of leveraging QC to\ntackle key classes of problems in future mobile networks. By analyzing and\nidentifying common features, particularly their graph-centric representation,\nwe propose a unified strategy involving QC algorithms. Specifically, we outline\na methodology for optimization using quantum annealing as well as quantum\nreinforcement learning. Additionally, we discuss the main challenges that QC\nalgorithms and hardware must overcome to effectively optimize future networks.", "published": "2025-09-09 14:06:24", "link": "http://arxiv.org/abs/2509.07773v1", "categories": ["cs.NI", "cs.IT", "cs.LG", "eess.SP", "math.IT", "quant-ph"], "primary_category": "cs.NI"}
{"title": "Multi-Static Target Position Estimation and System Optimization for Cell-Free mMIMO-OTFS ISAC", "abstract": "This paper investigates multi-static position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. A maximum likelihood position estimation scheme is proposed,\nwhere the required search space is reduced by employing a common reference\nsystem. Closed-form expressions for the Cram\\'er-Rao lower bound and the\nposition error bound (PEB) in multi-static position estimation are derived,\nproviding quantitative evaluations of sensing performance. These theoretical\nbounds are further generalized into a universal structure to support other ISAC\nsignals. To enhance overall system performance and adapt to dynamic network\nrequirements, a joint AP operation mode selection and power allocation\nalgorithm is developed to maximize the minimum user communication spectral\nefficiency (SE) while ensuring a specified sensing PEB requirement. Moreover, a\ndecomposition method is introduced to achieve a better tradeoff between\ncomplexity and ISAC performance. The results verify the effectiveness of the\nproposed algorithms, demonstrating the superiority of the OTFS signal through a\nnearly twofold SE gain over the orthogonal frequency division multiplexing\n(OFDM) signal. These findings highlight promising advantages of the CF-ISAC\nsystems from a novel parameter estimation perspective, particularly in\nhigh-mobility vehicle-to-everything applications.", "published": "2025-09-09 14:05:51", "link": "http://arxiv.org/abs/2509.07770v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Dual of Algebraic Geometry codes from Hirzebruch surfaces", "abstract": "In this paper, we give an explicit form for the dual of the algebraic\ngeometry code $C_e(a,b)$ defined on an Hirzebruch surface $\\mathcal{H}_e$ and\nparametrized by the divisor $aS_e + bF_e$, where $a,b\\in\\mathbb{N}$ and $S_e$\nand $F_e$ generate the Picard group $\\mathrm{Pic}( \\mathcal{H}_e)$. Notably, we\ncompute a lower bound for the minimum distance of $C_e(a,b)^\\perp$. One of the\nmain ingredient for our study is a new explicit form of the code $C_e(a,b)$\nwhich we provide at the beginning of the paper. We also investigate some\npuncturing of $C_e(a,b)$, recovering other previously studied AG codes from\ntoric surfaces. Finally, we provide a sufficient condition for orthogonal\ninclusions between the codes $C_e(a,b)$, and construct CSS quantum codes from\nthem.", "published": "2025-09-09 13:58:07", "link": "http://arxiv.org/abs/2509.07761v1", "categories": ["math.AG", "cs.IT", "math.IT", "94B27, 14J26, 11G25, 14C20"], "primary_category": "math.AG"}
{"title": "Linear time encodable binary code achieving GV bound with linear time encodable dual achieving GV bound", "abstract": "We initiate the study of what we term ``fast good codes'' with ``fast good\nduals.'' Specifically, we consider the task of constructing a binary linear\ncode $C \\leq \\mathcal{F}_2^n$ such that both it and its dual $C^\\perp :=\\{x \\in\n\\mathcal{F}_2^n:\\forall c \\in C, \\langle x,c\\rangle=0\\}$ are asymptotically\ngood (in fact, have rate-distance tradeoff approaching the GV bound), and are\nencodable in $O(n)$ time. While we believe such codes should find applications\nmore broadly, as motivation we describe how such codes can be used the secure\ncomputation task of encrypted matrix-vector product, as studied by Behhamouda\net al (CCS 2025, to appear).\n  Our main contribution is a construction of such a fast good code with fast\ngood dual. Our construction is inspired by the repeat multiple accumulate (RMA)\ncodes of Divsalar, Jin and McEliece (Allerton, 1998). To create the rate 1/2\ncode, after repeating each message coordinate, we perform accumulation steps --\nwhere first a uniform coordinate permutation is applied, and afterwards the\nprefix-sum mod 2 is applied -- which are alternated with discrete derivative\nsteps -- where again a uniform coordinate permutation is applied, and\nafterwards the previous two coordinates are summed mod 2. Importantly, these\ntwo operations are inverse of each other. In particular, the dual of the code\nis very similar, with the accumulation and discrete derivative steps reversed.\n  Our analysis is inspired by a prior analysis of RMA codes due to Ravazzi and\nFagnani (IEEE Trans. Info. Theory, 2009). The main idea is to bound the\ninput-output weight-enumerator function: the expected number of messages of a\ngiven weight that are encoded into a codeword of a given weight. We face new\nchallenges in controlling the behaviour of the discrete derivative matrix\n(which can significantly drop the weight of a vector), which we overcome by\ncareful case analysis.", "published": "2025-09-09 12:07:59", "link": "http://arxiv.org/abs/2509.07639v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Tesla meets Helstrom: a Wireless-Powered Quantum Optical System", "abstract": "This letter investigates a novel wireless-powered quantum optical\ncommunication system, in which a batteryless quantum transmitter harvests\nenergy from a classical radio-frequency source to transmit quantum coherent\nstates. The transmission employs M-ary phase shift keying (M-PSK) modulation\nover an optical channel impaired by thermal noise, and the fundamental\ndetection performance is evaluated using the Helstrom bound. An optimization\nframework is proposed that jointly determines the optimal quantum measurement\nand the energy-harvesting time fraction to maximize the effective rate under a\nblock time constraint. Analytical expressions are derived for special cases,\nwhile semidefinite programming techniques are employed for the general M-PSK\nscenario. Numerical results validate the unimodal nature of the effective rate\nfunction and demonstrate the impact of the optimal design parameters.", "published": "2025-09-09 06:07:35", "link": "http://arxiv.org/abs/2509.07421v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SKR Analysis of MIMO FSO Systems with One- and Two-way CV-QKD Protocols in Hybrid Quantum Noise Environment", "abstract": "A multiple-input multiple-output (MIMO) free-space optical (FSO)\ncommunication system is considered in this paper, which supports the secret key\ntransmission between two legitimate users, Alice and Bob, by employing\ncontinuous-variable quantum key distribution (CV-QKD). The wireless channels\nare subjected to the effects of atmospheric turbulence that lead to beam\nspreading, pointing error, and turbulence-induced fading, which, along with the\npresence of hybrid quantum noise, negatively impact the secret key exchange\nbetween Alice and Bob. Furthermore, the security of the communication system is\nconsidered to be compromised due to the intervention of an eavesdropper, Eve,\nemploying a collective Gaussian attack to intercept the secret key exchange.\nFor this system, novel one-way and two-way protocols are proposed to enhance\nthe security of the transmitted keys. The transmissivity of the FSO channels is\nmathematically formulated, and the bounds on the mutual information between the\ntransmitted and received coherent states are obtained, using which, novel\nexpressions for the secret key rates (SKRs) for the one-way and two-way\nprotocols are derived. Asymptotic expressions for the SKRs and numerical\nresults corroborating the analytical framework are also presented, which\ndemonstrate the SKR gains obtained by employing MIMO and the two-way protocol\nfor the FSO CV-QKD system.", "published": "2025-09-09 05:41:21", "link": "http://arxiv.org/abs/2509.07408v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Knowledge Distillation Driven Semantic NOMA for Image Transmission with Diffusion Model", "abstract": "As a promising 6G enabler beyond conventional bit-level transmission,\nsemantic communication can considerably reduce required bandwidth resources,\nwhile its combination with multiple access requires further exploration. This\npaper proposes a knowledge distillation-driven and diffusion-enhanced (KDD)\nsemantic non-orthogonal multiple access (NOMA), named KDD-SemNOMA, for\nmulti-user uplink wireless image transmission. Specifically, to ensure robust\nfeature transmission across diverse transmission conditions, we firstly develop\na ConvNeXt-based deep joint source and channel coding architecture with\nenhanced adaptive feature module. This module incorporates signal-to-noise\nratio and channel state information to dynamically adapt to additive white\nGaussian noise and Rayleigh fading channels. Furthermore, to improve image\nrestoration quality without inference overhead, we introduce a two-stage\nknowledge distillation strategy, i.e., a teacher model, trained on\ninterference-free orthogonal transmission, guides a student model via feature\naffinity distillation and cross-head prediction distillation. Moreover, a\ndiffusion model-based refinement stage leverages generative priors to transform\ninitial SemNOMA outputs into high-fidelity images with enhanced perceptual\nquality. Extensive experiments on CIFAR-10 and FFHQ-256 datasets demonstrate\nsuperior performance over state-of-the-art methods, delivering satisfactory\nreconstruction performance even at extremely poor channel conditions. These\nresults highlight the advantages in both pixel-level accuracy and perceptual\nmetrics, effectively mitigating interference and enabling high-quality image\nrecovery.", "published": "2025-09-09 03:20:58", "link": "http://arxiv.org/abs/2509.07363v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Besting Good--Turing: Optimality of Non-Parametric Maximum Likelihood for Distribution Estimation", "abstract": "When faced with a small sample from a large universe of possible outcomes,\nscientists often turn to the venerable Good--Turing estimator. Despite its\npedigree, however, this estimator comes with considerable drawbacks, such as\nthe need to hand-tune smoothing parameters and the lack of a precise optimality\nguarantee. We introduce a parameter-free estimator that bests Good--Turing in\nboth theory and practice. Our method marries two classic ideas, namely\nRobbins's empirical Bayes and Kiefer--Wolfowitz non-parametric maximum\nlikelihood estimation (NPMLE), to learn an implicit prior from data and then\nconvert it into probability estimates. We prove that the resulting estimator\nattains the optimal instance-wise risk up to logarithmic factors in the\ncompetitive framework of Orlitsky and Suresh, and that the Good--Turing\nestimator is strictly suboptimal in the same framework. Our simulations on\nsynthetic data and experiments with English corpora and U.S. Census data show\nthat our estimator consistently outperforms both the Good--Turing estimator and\nexplicit Bayes procedures.", "published": "2025-09-09 03:04:06", "link": "http://arxiv.org/abs/2509.07355v1", "categories": ["math.ST", "cs.IT", "math.IT", "stat.ME", "stat.TH"], "primary_category": "math.ST"}
{"title": "Single and Multi-Frequency Path Loss Models for Indoor Hotspot Scenario Based on Measurements Conducted at 6.75, 16.95, 28, 73 and 142 GHz", "abstract": "This paper presents a comprehensive derivation of single and multi-frequency\nlarge-scale path loss model parameters for the close-in (CI) free space\nreference distance, CI free space reference distance with cross-polarization\n(CIX), floating-intercept (FI), CI free space reference distance with\nfrequency-dependent path loss exponent (CIF), CI free space reference distance\nwith frequency-dependent path loss exponent and cross-polarization (CIFX),\nalpha-beta-gamma (ABG), and alpha-beta-gamma with cross-polarization (ABGX)\nmodels for specific frequencies and across frequency ranges of 7-24 GHz,\n0.5-100 GHz, and 0.5-150 GHz. The analysis is based on extensive real-world\nmeasurements conducted by NYU WIRELESS at 6.75 GHz, 16.95 GHz, 28 GHz, 73 GHz,\nand 142 GHz, using a 1 GHz wideband time-domain based sliding correlation\nchannel sounder in the indoor hotspot (InH) scenario in both line-of-sight\n(LOS) and non-line-of-sight (NLOS) channel conditions. Specifically, the\nderived CI, FI, and ABG path loss model parameters for 7-24 GHz and 0.5-100 GHz\nfrequency ranges in this article were submitted in Third Generation Partnership\nProject (3GPP) to validate Technical Report (TR) 38.901 InH path loss models,\nas part of the release (Rel) 19 study on \"Channel Model Validation of TR 38.901\nfor 7-24 GHz.\" Furthermore, the results in this paper provide critical insights\ninto understanding large-scale path loss, comparing different path loss models,\nand extending the path loss models standardized by 3GPP and ITU for the InH\nscenario, which is essential for advancing next-generation wireless systems.", "published": "2025-09-09 02:12:26", "link": "http://arxiv.org/abs/2509.07331v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Theoretical Analysis on how Learning Rate Warmup Accelerates Convergence", "abstract": "Learning rate warmup is a popular and practical technique in training\nlarge-scale deep neural networks. Despite the huge success in practice, the\ntheoretical advantages of this strategy of gradually increasing the learning\nrate at the beginning of the training process have not been fully understood.\nTo resolve this gap between theory and practice, we first propose a novel\nfamily of generalized smoothness assumptions, and validate its applicability\nboth theoretically and empirically. Under the novel smoothness assumption, we\nstudy the convergence properties of gradient descent (GD) in both deterministic\nand stochastic settings. It is shown that learning rate warmup consistently\naccelerates GD, and GD with warmup can converge at most $\\Theta(T)$ times\nfaster than with a non-increasing learning rate schedule in some specific\ncases, providing insights into the benefits of this strategy from an\noptimization theory perspective.", "published": "2025-09-09 17:56:03", "link": "http://arxiv.org/abs/2509.07972v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Customizing the Inductive Biases of Softmax Attention using Structured Matrices", "abstract": "The core component of attention is the scoring function, which transforms the\ninputs into low-dimensional queries and keys and takes the dot product of each\npair. While the low-dimensional projection improves efficiency, it causes\ninformation loss for certain tasks that have intrinsically high-dimensional\ninputs. Additionally, attention uses the same scoring function for all input\npairs, without imposing a distance-dependent compute bias for neighboring\ntokens in the sequence. In this work, we address these shortcomings by\nproposing new scoring functions based on computationally efficient structured\nmatrices with high ranks, including Block Tensor-Train (BTT) and Multi-Level\nLow Rank (MLR) matrices. On in-context regression tasks with high-dimensional\ninputs, our proposed scoring functions outperform standard attention for any\nfixed compute budget. On language modeling, a task that exhibits locality\npatterns, our MLR-based attention method achieves improved scaling laws\ncompared to both standard attention and variants of sliding window attention.\nAdditionally, we show that both BTT and MLR fall under a broader family of\nefficient structured matrices capable of encoding either full-rank or\ndistance-dependent compute biases, thereby addressing significant shortcomings\nof standard attention. Finally, we show that MLR attention has promising\nresults for long-range time-series forecasting.", "published": "2025-09-09 17:50:58", "link": "http://arxiv.org/abs/2509.07963v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction", "abstract": "Modern paradigms for robot imitation train expressive policy architectures on\nlarge amounts of human demonstration data. Yet performance on contact-rich,\ndeformable-object, and long-horizon tasks plateau far below perfect execution,\neven with thousands of expert demonstrations. This is due to the inefficiency\nof existing ``expert'' data collection procedures based on human teleoperation.\nTo address this issue, we introduce RaC, a new phase of training on\nhuman-in-the-loop rollouts after imitation learning pre-training. In RaC, we\nfine-tune a robotic policy on human intervention trajectories that illustrate\nrecovery and correction behaviors. Specifically, during a policy rollout, human\noperators intervene when failure appears imminent, first rewinding the robot\nback to a familiar, in-distribution state and then providing a corrective\nsegment that completes the current sub-task. Training on this data composition\nexpands the robotic skill repertoire to include retry and adaptation behaviors,\nwhich we show are crucial for boosting both efficiency and robustness on\nlong-horizon tasks. Across three real-world bimanual control tasks: shirt\nhanging, airtight container lid sealing, takeout box packing, and a simulated\nassembly task, RaC outperforms the prior state-of-the-art using 10$\\times$ less\ndata collection time and samples. We also show that RaC enables test-time\nscaling: the performance of the trained RaC policy scales linearly in the\nnumber of recovery maneuvers it exhibits. Videos of the learned policy are\navailable at https://rac-scaling-robot.github.io/.", "published": "2025-09-09 17:41:29", "link": "http://arxiv.org/abs/2509.07953v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning", "abstract": "In heterogeneous multi-task learning, tasks not only exhibit diverse\nobservation and action spaces but also vary substantially in intrinsic\ndifficulty. While conventional multi-task world models like UniZero excel in\nsingle-task settings, we find that when handling large-scale heterogeneous\nenvironments, gradient conflicts and the loss of model plasticity often\nconstrain their sample and computational efficiency. In this work, we address\nthese challenges from two perspectives: the single learning iteration and the\noverall learning process. First, we investigate the impact of key design spaces\non extending UniZero to multi-task planning. We find that a Mixture-of-Experts\n(MoE) architecture provides the most substantial performance gains by\nmitigating gradient conflicts, leading to our proposed model,\n\\textit{ScaleZero}. Second, to dynamically balance the computational load\nacross the learning process, we introduce an online, LoRA-based \\textit{dynamic\nparameter scaling} (DPS) strategy. This strategy progressively integrates LoRA\nadapters in response to task-specific progress, enabling adaptive knowledge\nretention and parameter expansion. Empirical evaluations on standard benchmarks\nsuch as Atari, DMControl (DMC), and Jericho demonstrate that ScaleZero, relying\nexclusively on online reinforcement learning with one model, attains\nperformance on par with specialized single-task baselines. Furthermore, when\naugmented with our dynamic parameter scaling strategy, our method achieves\ncompetitive performance while requiring only 80\\% of the single-task\nenvironment interaction steps. These findings underscore the potential of\nScaleZero for effective large-scale multi-task learning. Our code is available\nat \\textcolor{magenta}{https://github.com/opendilab/LightZero}.", "published": "2025-09-09 17:27:53", "link": "http://arxiv.org/abs/2509.07945v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "abstract": "Recent advances in Large Language Models (LLMs) have driven interest in\nautomating cybersecurity penetration testing workflows, offering the promise of\nfaster and more consistent vulnerability assessment for enterprise systems.\nExisting LLM agents for penetration testing primarily rely on self-guided\nreasoning, which can produce inaccurate or hallucinated procedural steps. As a\nresult, the LLM agent may undertake unproductive actions, such as exploiting\nunused software libraries or generating cyclical responses that repeat prior\ntactics. In this work, we propose a guided reasoning pipeline for penetration\ntesting LLM agents that incorporates a deterministic task tree built from the\nMITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the\nLLM's reaoning process to explicitly defined tactics, techniques, and\nprocedures. This anchors reasoning in proven penetration testing methodologies\nand filters out ineffective actions by guiding the agent towards more\nproductive attack procedures. To evaluate our approach, we built an automated\npenetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and\nGPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with\n103 discrete subtasks representing real-world cyberattack scenarios. Our\nproposed reasoning pipeline guided the LLM agent through 71.8\\%, 72.8\\%, and\n78.6\\% of subtasks using Llama-3-8B, Gemini-1.5, and GPT-4, respectively.\nComparatively, the state-of-the-art LLM penetration testing tool using\nself-guided reasoning completed only 13.5\\%, 16.5\\%, and 75.7\\% of subtasks and\nrequired 86.2\\%, 118.7\\%, and 205.9\\% more model queries. This suggests that\nincorporating a deterministic task tree into LLM reasoning pipelines can\nenhance the accuracy and efficiency of automated cybersecurity assessments", "published": "2025-09-09 17:19:33", "link": "http://arxiv.org/abs/2509.07939v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Bio-KGvec2go: Serving up-to-date Dynamic Biomedical Knowledge Graph Embeddings", "abstract": "Knowledge graphs and ontologies represent entities and their relationships in\na structured way, having gained significance in the development of modern AI\napplications. Integrating these semantic resources with machine learning models\noften relies on knowledge graph embedding models to transform graph data into\nnumerical representations. Therefore, pre-trained models for popular knowledge\ngraphs and ontologies are increasingly valuable, as they spare the need to\nretrain models for different tasks using the same data, thereby helping to\ndemocratize AI development and enabling sustainable computing.\n  In this paper, we present Bio-KGvec2go, an extension of the KGvec2go Web API,\ndesigned to generate and serve knowledge graph embeddings for widely used\nbiomedical ontologies. Given the dynamic nature of these ontologies,\nBio-KGvec2go also supports regular updates aligned with ontology version\nreleases. By offering up-to-date embeddings with minimal computational effort\nrequired from users, Bio-KGvec2go facilitates efficient and timely biomedical\nresearch.", "published": "2025-09-09 16:46:47", "link": "http://arxiv.org/abs/2509.07905v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Modular Algorithm for Non-Stationary Online Convex-Concave Optimization", "abstract": "This paper investigates the problem of Online Convex-Concave Optimization,\nwhich extends Online Convex Optimization to two-player time-varying\nconvex-concave games. The goal is to minimize the dynamic duality gap (D-DGap),\na critical performance measure that evaluates players' strategies against\narbitrary comparator sequences. Existing algorithms fail to deliver optimal\nperformance, particularly in stationary or predictable environments. To address\nthis, we propose a novel modular algorithm with three core components: an\nAdaptive Module that dynamically adjusts to varying levels of non-stationarity,\na Multi-Predictor Aggregator that identifies the best predictor among multiple\ncandidates, and an Integration Module that effectively combines their\nstrengths. Our algorithm achieves a minimax optimal D-DGap upper bound, up to a\nlogarithmic factor, while also ensuring prediction error-driven D-DGap bounds.\nThe modular design allows for the seamless replacement of components that\nregulate adaptability to dynamic environments, as well as the incorporation of\ncomponents that integrate ``side knowledge'' from multiple predictors.\nEmpirical results further demonstrate the effectiveness and adaptability of the\nproposed method.", "published": "2025-09-09 16:33:38", "link": "http://arxiv.org/abs/2509.07901v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Feasibility of In-Ear Single-Channel ExG for Wearable Sleep~Monitoring in Real-World Settings", "abstract": "Automatic sleep staging typically relies on gold-standard EEG setups, which\nare accurate but obtrusive and impractical for everyday use outside sleep\nlaboratories. This limits applicability in real-world settings, such as home\nenvironments, where continuous, long-term monitoring is needed. Detecting sleep\nonset is particularly relevant, enabling consumer applications (e.g.\nautomatically pausing media playback when the user falls asleep). Recent\nresearch has shown correlations between in-ear EEG and full-scalp EEG for\nvarious phenomena, suggesting wearable, in-ear devices could allow unobtrusive\nsleep monitoring. We investigated the feasibility of using single-channel\nin-ear electrophysiological (ExG) signals for automatic sleep staging in a\nwearable device by conducting a sleep study with 11~participants (mean age:\n24), using a custom earpiece with a dry eartip electrode (D\\\"atwyler SoftPulse)\nas a measurement electrode in one ear and a reference in the other. Ground\ntruth sleep stages were obtained from an Apple Watch Ultra, validated for sleep\nstaging. Our system achieved 90.5% accuracy for binary sleep detection (Awake\nvs. Asleep) and 65.1% accuracy for four-class staging (Awake, REM, Core, Deep)\nusing leave-one-subject-out validation. These findings demonstrate the\npotential of in-ear electrodes as a low-effort, comfortable approach to sleep\nmonitoring, with applications such as stopping podcasts when users fall asleep.", "published": "2025-09-09 16:27:56", "link": "http://arxiv.org/abs/2509.07896v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Survey of Graph Neural Networks for Drug Discovery: Recent Developments and Challenges", "abstract": "Graph Neural Networks (GNNs) have gained traction in the complex domain of\ndrug discovery because of their ability to process graph-structured data such\nas drug molecule models. This approach has resulted in a myriad of methods and\nmodels in published literature across several categories of drug discovery\nresearch. This paper covers the research categories comprehensively with recent\npapers, namely molecular property prediction, including drug-target binding\naffinity prediction, drug-drug interaction study, microbiome interaction\nprediction, drug repositioning, retrosynthesis, and new drug design, and\nprovides guidance for future work on GNNs for drug discovery.", "published": "2025-09-09 16:09:00", "link": "http://arxiv.org/abs/2509.07887v1", "categories": ["cs.LG", "I.2; I.2.1; J.3"], "primary_category": "cs.LG"}
{"title": "Leveraging Support Vector Regression for Outcome Prediction in Personalized Ultra-fractionated Stereotactic Adaptive Radiotherapy", "abstract": "Personalized ultra-fractionated stereotactic adaptive radiotherapy (PULSAR)\nis a novel treatment that delivers radiation in pulses of protracted intervals.\nAccurate prediction of gross tumor volume (GTV) changes through regression\nmodels has substantial prognostic value. This study aims to develop a\nmulti-omics based support vector regression (SVR) model for predicting GTV\nchange. A retrospective cohort of 39 patients with 69 brain metastases was\nanalyzed, based on radiomics (MRI images) and dosiomics (dose maps) features.\nDelta features were computed to capture relative changes between two time\npoints. A feature selection pipeline using least absolute shrinkage and\nselection operator (Lasso) algorithm with weight- or frequency-based ranking\ncriterion was implemented. SVR models with various kernels were evaluated using\nthe coefficient of determination (R2) and relative root mean square error\n(RRMSE). Five-fold cross-validation with 10 repeats was employed to mitigate\nthe limitation of small data size. Multi-omics models that integrate radiomics,\ndosiomics, and their delta counterparts outperform individual-omics models.\nDelta-radiomic features play a critical role in enhancing prediction accuracy\nrelative to features at single time points. The top-performing model achieves\nan R2 of 0.743 and an RRMSE of 0.022. The proposed multi-omics SVR model shows\npromising performance in predicting continuous change of GTV. It provides a\nmore quantitative and personalized approach to assist patient selection and\ntreatment adjustment in PULSAR.", "published": "2025-09-09 15:57:21", "link": "http://arxiv.org/abs/2509.07872v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Addressing the Cold-Start Problem for Personalized Combination Drug Screening", "abstract": "Personalizing combination therapies in oncology requires navigating an\nimmense space of possible drug and dose combinations, a task that remains\nlargely infeasible through exhaustive experimentation. Recent developments in\npatient-derived models have enabled high-throughput ex vivo screening, but the\nnumber of feasible experiments is limited. Further, a tight therapeutic window\nmakes gathering molecular profiling information (e.g. RNA-seq) impractical as a\nmeans of guiding drug response prediction. This leads to a challenging\ncold-start problem: how do we select the most informative combinations to test\nearly, when no prior information about the patient is available? We propose a\nstrategy that leverages a pretrained deep learning model built on historical\ndrug response data. The model provides both embeddings for drug combinations\nand dose-level importance scores, enabling a principled selection of initial\nexperiments. We combine clustering of drug embeddings to ensure functional\ndiversity with a dose-weighting mechanism that prioritizes doses based on their\nhistorical informativeness. Retrospective simulations on large-scale drug\ncombination datasets show that our method substantially improves initial\nscreening efficiency compared to baselines, offering a viable path for more\neffective early-phase decision-making in personalized combination drug screens.", "published": "2025-09-09 15:24:46", "link": "http://arxiv.org/abs/2509.07850v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predicting person-level injury severity using crash narratives: A balanced approach with roadway classification and natural language process techniques", "abstract": "Predicting injuries and fatalities in traffic crashes plays a critical role\nin enhancing road safety, improving emergency response, and guiding public\nhealth interventions. This study investigates the added value of unstructured\ncrash narratives (written by police officers at the scene) when combined with\nstructured crash data to predict injury severity. Two widely used Natural\nLanguage Processing (NLP) techniques, Term Frequency-Inverse Document Frequency\n(TF-IDF) and Word2Vec, were employed to extract semantic meaning from the\nnarratives, and their effectiveness was compared. To address the challenge of\nclass imbalance, a K-Nearest Neighbors-based oversampling method was applied to\nthe training data prior to modeling. The dataset consists of crash records from\nKentucky spanning 2019 to 2023. To account for roadway heterogeneity, three\nroad classification schemes were used: (1) eight detailed functional classes\n(e.g., Urban Two-Lane, Rural Interstate, Urban Multilane Divided), (2) four\nbroader paired categories (e.g., Urban vs. Rural, Freeway vs. Non-Freeway), and\n(3) a unified dataset without classification. A total of 102 machine learning\nmodels were developed by combining structured features and narrative-based\nfeatures using the two NLP techniques alongside three ensemble algorithms:\nXGBoost, Random Forest, and AdaBoost. Results demonstrate that models\nincorporating narrative data consistently outperform those relying solely on\nstructured data. Among all combinations, TF-IDF coupled with XGBoost yielded\nthe most accurate predictions in most subgroups. The findings highlight the\npower of integrating textual and structured crash information to enhance\nperson-level injury prediction. This work offers a practical and adaptable\nframework for transportation safety professionals to improve crash severity\nmodeling, guide policy decisions, and design more effective countermeasures.", "published": "2025-09-09 15:22:14", "link": "http://arxiv.org/abs/2509.07845v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Nuclear Data Adjustment for Nonlinear Applications in the OECD/NEA WPNCS SG14 Benchmark -- A Bayesian Inverse UQ-based Approach for Data Assimilation", "abstract": "The Organization for Economic Cooperation and Development (OECD) Working\nParty on Nuclear Criticality Safety (WPNCS) proposed a benchmark exercise to\nassess the performance of current nuclear data adjustment techniques applied to\nnonlinear applications and experiments with low correlation to applications.\nThis work introduces Bayesian Inverse Uncertainty Quantification (IUQ) as a\nmethod for nuclear data adjustments in this benchmark, and compares IUQ to the\nmore traditional methods of Generalized Linear Least Squares (GLLS) and Monte\nCarlo Bayes (MOCABA). Posterior predictions from IUQ showed agreement with GLLS\nand MOCABA for linear applications. When comparing GLLS, MOCABA, and IUQ\nposterior predictions to computed model responses using adjusted parameters, we\nobserve that GLLS predictions fail to replicate computed response distributions\nfor nonlinear applications, while MOCABA shows near agreement, and IUQ uses\ncomputed model responses directly. We also discuss observations on why\nexperiments with low correlation to applications can be informative to nuclear\ndata adjustments and identify some properties useful in selecting experiments\nfor inclusion in nuclear data adjustment. Performance in this benchmark\nindicates potential for Bayesian IUQ in nuclear data adjustments.", "published": "2025-09-09 14:23:30", "link": "http://arxiv.org/abs/2509.07790v1", "categories": ["nucl-th", "cs.LG"], "primary_category": "nucl-th"}
{"title": "Decentralized Online Riemannian Optimization Beyond Hadamard Manifolds", "abstract": "We study decentralized online Riemannian optimization over manifolds with\npossibly positive curvature, going beyond the Hadamard manifold setting.\nDecentralized optimization techniques rely on a consensus step that is well\nunderstood in Euclidean spaces because of their linearity. However, in\npositively curved Riemannian spaces, a main technical challenge is that\ngeodesic distances may not induce a globally convex structure. In this work, we\nfirst analyze a curvature-aware Riemannian consensus step that enables a linear\nconvergence beyond Hadamard manifolds. Building on this step, we establish a\n$O(\\sqrt{T})$ regret bound for the decentralized online Riemannian gradient\ndescent algorithm. Then, we investigate the two-point bandit feedback setup,\nwhere we employ computationally efficient gradient estimators using smoothing\ntechniques, and we demonstrate the same $O(\\sqrt{T})$ regret bound through the\nsubconvexity analysis of smoothed objectives.", "published": "2025-09-09 14:14:46", "link": "http://arxiv.org/abs/2509.07779v1", "categories": ["math.OC", "cs.LG", "cs.MA"], "primary_category": "math.OC"}
{"title": "Toward Quantum Utility in Finance: A Robust Data-Driven Algorithm for Asset Clustering", "abstract": "Clustering financial assets based on return correlations is a fundamental\ntask in portfolio optimization and statistical arbitrage. However, classical\nclustering methods often fall short when dealing with signed correlation\nstructures, typically requiring lossy transformations and heuristic assumptions\nsuch as a fixed number of clusters. In this work, we apply the Graph-based\nCoalition Structure Generation algorithm (GCS-Q) to directly cluster signed,\nweighted graphs without relying on such transformations. GCS-Q formulates each\npartitioning step as a QUBO problem, enabling it to leverage quantum annealing\nfor efficient exploration of exponentially large solution spaces. We validate\nour approach on both synthetic and real-world financial data, benchmarking\nagainst state-of-the-art classical algorithms such as SPONGE and k-Medoids. Our\nexperiments demonstrate that GCS-Q consistently achieves higher clustering\nquality, as measured by Adjusted Rand Index and structural balance penalties,\nwhile dynamically determining the number of clusters. These results highlight\nthe practical utility of near-term quantum computing for graph-based\nunsupervised learning in financial applications.", "published": "2025-09-09 13:59:59", "link": "http://arxiv.org/abs/2509.07766v1", "categories": ["quant-ph", "cs.LG", "05-08", "F.4.1; F.2.2"], "primary_category": "quant-ph"}
{"title": "MoE-Compression: How the Compression Error of Experts Affects the Inference Accuracy of MoE Model?", "abstract": "With the widespread application of Mixture of Experts (MoE) reasoning models\nin the field of LLM learning, efficiently serving MoE models under limited GPU\nmemory constraints has emerged as a significant challenge. Offloading the\nnon-activated experts to main memory has been identified as an efficient\napproach to address such a problem, while it brings the challenges of\ntransferring the expert between the GPU memory and main memory. We need to\nexplore an efficient approach to compress the expert and analyze how the\ncompression error affects the inference performance.\n  To bridge this gap, we propose employing error-bounded lossy compression\nalgorithms (such as SZ3 and CuSZp) to compress non-activated experts, thereby\nreducing data transfer overhead during MoE inference. We conduct extensive\nexperiments across various benchmarks and present a comprehensive analysis of\nhow compression-induced errors in different experts affect overall inference\naccuracy. The results indicate that experts in the shallow layers, which are\nprimarily responsible for the attention mechanism and the transformation of\ninput tokens into vector representations, exhibit minimal degradation in\ninference accuracy when subjected to bounded errors. In contrast, errors in the\nmiddle-layer experts, which are central to model reasoning, significantly\nimpair inference accuracy. Interestingly, introducing bounded errors in the\ndeep-layer experts, which are mainly responsible for instruction following and\noutput integration, can sometimes lead to improvements in inference accuracy.", "published": "2025-09-09 13:28:41", "link": "http://arxiv.org/abs/2509.07727v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "IBN: An Interpretable Bidirectional-Modeling Network for Multivariate Time Series Forecasting with Variable Missing", "abstract": "Multivariate time series forecasting (MTSF) often faces challenges from\nmissing variables, which hinder conventional spatial-temporal graph neural\nnetworks in modeling inter-variable correlations. While GinAR addresses\nvariable missing using attention-based imputation and adaptive graph learning\nfor the first time, it lacks interpretability and fails to capture more latent\ntemporal patterns due to its simple recursive units (RUs). To overcome these\nlimitations, we propose the Interpretable Bidirectional-modeling Network (IBN),\nintegrating Uncertainty-Aware Interpolation (UAI) and Gaussian kernel-based\nGraph Convolution (GGCN). IBN estimates the uncertainty of reconstructed values\nusing MC Dropout and applies an uncertainty-weighted strategy to mitigate\nhigh-risk reconstructions. GGCN explicitly models spatial correlations among\nvariables, while a bidirectional RU enhances temporal dependency modeling.\nExtensive experiments show that IBN achieves state-of-the-art forecasting\nperformance under various missing-rate scenarios, providing a more reliable and\ninterpretable framework for MTSF with missing variables. Code is available at:\nhttps://github.com/zhangth1211/NICLab-IBN.", "published": "2025-09-09 13:27:21", "link": "http://arxiv.org/abs/2509.07725v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Building causation links in stochastic nonlinear systems from data", "abstract": "Causal relationships play a fundamental role in understanding the world\naround us. The ability to identify and understand cause-effect relationships is\ncritical to making informed decisions, predicting outcomes, and developing\neffective strategies. However, deciphering causal relationships from\nobservational data is a difficult task, as correlations alone may not provide\ndefinitive evidence of causality. In recent years, the field of machine\nlearning (ML) has emerged as a powerful tool, offering new opportunities for\nuncovering hidden causal mechanisms and better understanding complex systems.\nIn this work, we address the issue of detecting the intrinsic causal links of a\nlarge class of complex systems in the framework of the response theory in\nphysics. We develop some theoretical ideas put forward by [1], and technically\nwe use state-of-the-art ML techniques to build up models from data. We consider\nboth linear stochastic and non-linear systems. Finally, we compute the\nasymptotic efficiency of the linear response based causal predictor in a case\nof large scale Markov process network of linear interactions.", "published": "2025-09-09 13:07:29", "link": "http://arxiv.org/abs/2509.07701v1", "categories": ["cond-mat.stat-mech", "cs.LG"], "primary_category": "cond-mat.stat-mech"}
{"title": "FUnc-SNE: A flexible, Fast, and Unconstrained algorithm for neighbour embeddings", "abstract": "Neighbour embeddings (NE) allow the representation of high dimensional\ndatasets into lower dimensional spaces and are often used in data\nvisualisation. In practice, accelerated approximations are employed to handle\nvery large datasets. Accelerating NE is challenging, and two main directions\nhave been explored: very coarse approximations based on negative sampling (as\nin UMAP) achieve high effective speed but may lack quality in the extracted\nstructures; less coarse approximations, as used in FIt-SNE or BH-t-SNE, offer\nbetter structure preservation at the cost of speed, while also restricting the\ntarget dimensionality to 2 or 3, limiting NE to visualisation. In some\nvariants, the precision of these costlier accelerations also enables\nfiner-grained control on the extracted structures through dedicated\nhyperparameters.\n  This paper proposes to bridge the gab between both approaches by introducing\na novel way to accelerate NE, requiring a small number of computations per\niteration while maintaining good fine-grained structure preservation and\nflexibility through hyperparameter tuning, without limiting the dimensionality\nof the embedding space. The method was designed for interactive exploration of\ndata; as such, it abandons the traditional two-phased approach of other NE\nmethods, allowing instantaneous visual feedback when changing hyperparameters,\neven when these control processes happening on the high-dimensional side of the\ncomputations. Experiments using a publicly available, GPU accelerated GUI\nintegration of the method show promising results in terms of speed, flexibility\nin the structures getting extracted, and show potential uses in broader machine\nlearning contexts with minimal algorithmic modifications. Central to this\nalgorithm is a novel approach to iterative approximate nearest neighbour\nsearch, which shows promising results compared to nearest neighbour descent.", "published": "2025-09-09 12:46:11", "link": "http://arxiv.org/abs/2509.07681v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Graph-based Integrated Gradients for Explaining Graph Neural Networks", "abstract": "Integrated Gradients (IG) is a common explainability technique to address the\nblack-box problem of neural networks. Integrated gradients assumes continuous\ndata. Graphs are discrete structures making IG ill-suited to graphs. In this\nwork, we introduce graph-based integrated gradients (GB-IG); an extension of IG\nto graphs. We demonstrate on four synthetic datasets that GB-IG accurately\nidentifies crucial structural components of the graph used in classification\ntasks. We further demonstrate on three prevalent real-world graph datasets that\nGB-IG outperforms IG in highlighting important features for node classification\ntasks.", "published": "2025-09-09 12:15:25", "link": "http://arxiv.org/abs/2509.07648v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neural Proxies for Sound Synthesizers: Learning Perceptually Informed Preset Representations", "abstract": "Deep learning appears as an appealing solution for Automatic Synthesizer\nProgramming (ASP), which aims to assist musicians and sound designers in\nprogramming sound synthesizers. However, integrating software synthesizers into\ntraining pipelines is challenging due to their potential non-differentiability.\nThis work tackles this challenge by introducing a method to approximate\narbitrary synthesizers. Specifically, we train a neural network to map\nsynthesizer presets onto an audio embedding space derived from a pretrained\nmodel. This facilitates the definition of a neural proxy that produces compact\nyet effective representations, thereby enabling the integration of audio\nembedding loss into neural-based ASP systems for black-box synthesizers. We\nevaluate the representations derived by various pretrained audio models in the\ncontext of neural-based nASP and assess the effectiveness of several neural\nnetwork architectures, including feedforward, recurrent, and transformer-based\nmodels, in defining neural proxies. We evaluate the proposed method using both\nsynthetic and hand-crafted presets from three popular software synthesizers and\nassess its performance in a synthesizer sound matching downstream task. While\nthe benefits of the learned representation are nuanced by resource\nrequirements, encouraging results were obtained for all synthesizers, paving\nthe way for future research into the application of synthesizer proxies for\nneural-based ASP systems.", "published": "2025-09-09 12:01:20", "link": "http://arxiv.org/abs/2509.07635v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T07", "H.5.5; J.5; I.5.4"], "primary_category": "cs.SD"}
{"title": "K2-Think: A Parameter-Efficient Reasoning System", "abstract": "K2-Think is a reasoning system that achieves state-of-the-art performance\nwith a 32B parameter model, matching or surpassing much larger models like\nGPT-OSS 120B and DeepSeek v3.1. Built on the Qwen2.5 base model, our system\nshows that smaller models can compete at the highest levels by combining\nadvanced post-training and test-time computation techniques. The approach is\nbased on six key technical pillars: Long Chain-of-thought Supervised\nFinetuning, Reinforcement Learning with Verifiable Rewards (RLVR), Agentic\nplanning prior to reasoning, Test-time Scaling, Speculative Decoding, and\nInference-optimized Hardware, all using publicly available open-source\ndatasets. K2-Think excels in mathematical reasoning, achieving state-of-the-art\nscores on public benchmarks for open-source models, while also performing\nstrongly in other areas such as Code and Science. Our results confirm that a\nmore parameter-efficient model like K2-Think 32B can compete with\nstate-of-the-art systems through an integrated post-training recipe that\nincludes long chain-of-thought training and strategic inference-time\nenhancements, making open-source reasoning systems more accessible and\naffordable. K2-Think is freely available at k2think.ai, offering best-in-class\ninference speeds of over 2,000 tokens per second per request via the Cerebras\nWafer-Scale Engine.", "published": "2025-09-09 11:25:55", "link": "http://arxiv.org/abs/2509.07604v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring System Adaptations For Minimum Latency Real-Time Piano Transcription", "abstract": "Advances in neural network design and the availability of large-scale labeled\ndatasets have driven major improvements in piano transcription. Existing\napproaches target either offline applications, with no restrictions on\ncomputational demands, or online transcription, with delays of 128-320 ms.\nHowever, most real-time musical applications require latencies below 30 ms. In\nthis work, we investigate whether and how the current state-of-the-art online\ntranscription model can be adapted for real-time piano transcription.\nSpecifically, we eliminate all non-causal processing, and reduce computational\nload through shared computations across core model components and variations in\nmodel size. Additionally, we explore different pre- and postprocessing\nstrategies, and related label encoding schemes, and discuss their suitability\nfor real-time transcription. Evaluating the adaptions on the MAESTRO dataset,\nwe find a drop in transcription accuracy due to strictly causal processing as\nwell as a tradeoff between the preprocessing latency and prediction accuracy.\nWe release our system as a baseline to support researchers in designing models\ntowards minimum latency real-time transcription.", "published": "2025-09-09 10:52:53", "link": "http://arxiv.org/abs/2509.07586v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Homogenization with Guaranteed Bounds via Primal-Dual Physically Informed Neural Networks", "abstract": "Physics-informed neural networks (PINNs) have shown promise in solving\npartial differential equations (PDEs) relevant to multiscale modeling, but they\noften fail when applied to materials with discontinuous coefficients, such as\nmedia with piecewise constant properties. This paper introduces a dual\nformulation for the PINN framework to improve the reliability of the\nhomogenization of periodic thermo-conductive composites, for both strong and\nvariational (weak) formulations. The dual approach facilitates the derivation\nof guaranteed upper and lower error bounds, enabling more robust detection of\nPINN failure. We compare standard PINNs applied to smoothed material\napproximations with variational PINNs (VPINNs) using both spectral and neural\nnetwork-based test functions. Our results indicate that while strong-form PINNs\nmay outperform VPINNs in controlled settings, they are sensitive to material\ndiscontinuities and may fail without clear diagnostics. In contrast, VPINNs\naccommodate piecewise constant material parameters directly but require careful\nselection of test functions to avoid instability. Dual formulation serves as a\nreliable indicator of convergence quality, and its integration into PINN\nframeworks enhances their applicability to homogenization problems in\nmicromechanics.", "published": "2025-09-09 10:42:55", "link": "http://arxiv.org/abs/2509.07579v1", "categories": ["cs.LG", "math.AP", "physics.comp-ph", "80-10", "I.6.4"], "primary_category": "cs.LG"}
{"title": "uGMM-NN: Univariate Gaussian Mixture Model Neural Network", "abstract": "This paper introduces the Univariate Gaussian Mixture Model Neural Network\n(uGMM-NN), a novel neural architecture that embeds probabilistic reasoning\ndirectly into the computational units of deep networks. Unlike traditional\nneurons, which apply weighted sums followed by fixed nonlinearities, each\nuGMM-NN node parameterizes its activations as a univariate Gaussian mixture,\nwith learnable means, variances, and mixing coefficients. This design enables\nricher representations by capturing multimodality and uncertainty at the level\nof individual neurons, while retaining the scalability of standard feedforward\nnetworks. We demonstrate that uGMM-NN can achieve competitive discriminative\nperformance compared to conventional multilayer perceptrons, while additionally\noffering a probabilistic interpretation of activations. The proposed framework\nprovides a foundation for integrating uncertainty-aware components into modern\nneural architectures, opening new directions for both discriminative and\ngenerative modeling.", "published": "2025-09-09 10:13:37", "link": "http://arxiv.org/abs/2509.07569v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Asynchronous Gossip Algorithms for Rank-Based Statistical Methods", "abstract": "As decentralized AI and edge intelligence become increasingly prevalent,\nensuring robustness and trustworthiness in such distributed settings has become\na critical issue-especially in the presence of corrupted or adversarial data.\nTraditional decentralized algorithms are vulnerable to data contamination as\nthey typically rely on simple statistics (e.g., means or sum), motivating the\nneed for more robust statistics. In line with recent work on decentralized\nestimation of trimmed means and ranks, we develop gossip algorithms for\ncomputing a broad class of rank-based statistics, including L-statistics and\nrank statistics-both known for their robustness to outliers. We apply our\nmethod to perform robust distributed two-sample hypothesis testing, introducing\nthe first gossip algorithm for Wilcoxon rank-sum tests. We provide rigorous\nconvergence guarantees, including the first convergence rate bound for\nasynchronous gossip-based rank estimation. We empirically validate our\ntheoretical results through experiments on diverse network topologies.", "published": "2025-09-09 09:23:36", "link": "http://arxiv.org/abs/2509.07543v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection", "abstract": "Identifying recurring patterns and rare events in large-scale signals is a\nfundamental challenge in fields such as astronomy, physical simulations, and\nbiomedical science. Convolutional Dictionary Learning (CDL) offers a powerful\nframework for modeling local structures in signals, but its use for detecting\nrare or anomalous events remains largely unexplored. In particular, CDL faces\ntwo key challenges in this setting: high computational cost and sensitivity to\nartifacts and outliers. In this paper, we introduce RoseCDL, a scalable and\nrobust CDL algorithm designed for unsupervised rare event detection in long\nsignals. RoseCDL combines stochastic windowing for efficient training on large\ndatasets with inline outlier detection to enhance robustness and isolate\nanomalous patterns. This reframes CDL as a practical tool for event discovery\nand characterization in real-world signals, extending its role beyond\ntraditional tasks like compression or denoising.", "published": "2025-09-09 08:58:31", "link": "http://arxiv.org/abs/2509.07523v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conv4Rec: A 1-by-1 Convolutional AutoEncoder for User Profiling through Joint Analysis of Implicit and Explicit Feedbacks", "abstract": "We introduce a new convolutional AutoEncoder architecture for user modelling\nand recommendation tasks with several improvements over the state of the art.\nFirstly, our model has the flexibility to learn a set of associations and\ncombinations between different interaction types in a way that carries over to\neach user and item. Secondly, our model is able to learn jointly from both the\nexplicit ratings and the implicit information in the sampling pattern (which we\nrefer to as `implicit feedback'). It can also make separate predictions for the\nprobability of consuming content and the likelihood of granting it a high\nrating if observed. This not only allows the model to make predictions for both\nthe implicit and explicit feedback, but also increases the informativeness of\nthe predictions: in particular, our model can identify items which users would\nnot have been likely to consume naturally, but would be likely to enjoy if\nexposed to them. Finally, we provide several generalization bounds for our\nmodel, which to the best of our knowledge, are among the first generalization\nbounds for auto-encoders in a Recommender Systems setting; we also show that\noptimizing our loss function guarantees the recovery of the exact sampling\ndistribution over interactions up to a small error in total variation. In\nexperiments on several real-life datasets, we achieve state-of-the-art\nperformance on both the implicit and explicit feedback prediction tasks despite\nrelying on a single model for both, and benefiting from additional\ninterpretability in the form of individual predictions for the probabilities of\neach possible rating.", "published": "2025-09-09 08:25:11", "link": "http://arxiv.org/abs/2509.07499v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RINO: Renormalization Group Invariance with No Labels", "abstract": "A common challenge with supervised machine learning (ML) in high energy\nphysics (HEP) is the reliance on simulations for labeled data, which can often\nmismodel the underlying collision or detector response. To help mitigate this\nproblem of domain shift, we propose RINO (Renormalization Group Invariance with\nNo Labels), a self-supervised learning approach that can instead pretrain\nmodels directly on collision data, learning embeddings invariant to\nrenormalization group flow scales. In this work, we pretrain a\ntransformer-based model on jets originating from quantum chromodynamic (QCD)\ninteractions from the JetClass dataset, emulating real QCD-dominated\nexperimental data, and then finetune on the JetNet dataset -- emulating\nsimulations -- for the task of identifying jets originating from top quark\ndecays. RINO demonstrates improved generalization from the JetNet training data\nto JetClass data compared to supervised training on JetNet from scratch,\ndemonstrating the potential for RINO pretraining on real collision data\nfollowed by fine-tuning on small, high-quality MC datasets, to improve the\nrobustness of ML models in HEP.", "published": "2025-09-09 08:05:35", "link": "http://arxiv.org/abs/2509.07486v1", "categories": ["hep-ex", "cs.LG"], "primary_category": "hep-ex"}
{"title": "Synthetic Data Generation with Lorenzetti for Time Series Anomaly Detection in High-Energy Physics Calorimeters", "abstract": "Anomaly detection in multivariate time series is crucial to ensure the\nquality of data coming from a physics experiment. Accurately identifying the\nmoments when unexpected errors or defects occur is essential, yet challenging\ndue to scarce labels, unknown anomaly types, and complex correlations across\ndimensions. To address the scarcity and unreliability of labelled data, we use\nthe Lorenzetti Simulator to generate synthetic events with injected calorimeter\nanomalies. We then assess the sensitivity of several time series anomaly\ndetection methods, including transformer-based and other deep learning models.\nThe approach employed here is generic and applicable to different detector\ndesigns and defects.", "published": "2025-09-09 07:22:22", "link": "http://arxiv.org/abs/2509.07451v1", "categories": ["hep-ex", "cs.LG"], "primary_category": "hep-ex"}
{"title": "EMORF-II: Adaptive EM-based Outlier-Robust Filtering with Correlated Measurement Noise", "abstract": "We present a learning-based outlier-robust filter for a general setup where\nthe measurement noise can be correlated. Since it is an enhanced version of\nEM-based outlier robust filter (EMORF), we call it as EMORF-II. As it is\nequipped with an additional powerful feature to learn the outlier\ncharacteristics during inference along with outlier-detection, EMORF-II has\nimproved outlier-mitigation capability. Numerical experiments confirm\nperformance gains as compared to the state-of-the-art methods in terms of\naccuracy with an increased computational overhead. However, thankfully the\ncomputational complexity order remains at par with other practical methods\nmaking it a useful choice for diverse applications.", "published": "2025-09-09 05:55:16", "link": "http://arxiv.org/abs/2509.07415v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Reinforcement learning for online hyperparameter tuning in convex quadratic programming", "abstract": "Quadratic programming is a workhorse of modern nonlinear optimization,\ncontrol, and data science. Although regularized methods offer convergence\nguarantees under minimal assumptions on the problem data, they can exhibit the\nslow tail-convergence typical of first-order schemes, thus requiring many\niterations to achieve high-accuracy solutions. Moreover, hyperparameter tuning\nsignificantly impacts on the solver performance but how to find an appropriate\nparameter configuration remains an elusive research question. To address these\nissues, we explore how data-driven approaches can accelerate the solution\nprocess. Aiming at high-accuracy solutions, we focus on a stabilized\ninterior-point solver and carefully handle its two-loop flow and control\nparameters. We will show that reinforcement learning can make a significant\ncontribution to facilitating the solver tuning and to speeding up the\noptimization process. Numerical experiments demonstrate that, after a\nlightweight training, the learned policy generalizes well to different problem\nclasses with varying dimensions and to various solver configurations.", "published": "2025-09-09 05:33:45", "link": "http://arxiv.org/abs/2509.07404v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "FedTeddi: Temporal Drift and Divergence Aware Scheduling for Timely Federated Edge Learning", "abstract": "Federated edge learning (FEEL) enables collaborative model training across\ndistributed clients over wireless networks without exposing raw data. While\nmost existing studies assume static datasets, in real-world scenarios clients\nmay continuously collect data with time-varying and non-independent and\nidentically distributed (non-i.i.d.) characteristics. A critical challenge is\nhow to adapt models in a timely yet efficient manner to such evolving data. In\nthis paper, we propose FedTeddi, a temporal-drift-and-divergence-aware\nscheduling algorithm that facilitates fast convergence of FEEL under dynamic\ndata evolution and communication resource limits. We first quantify the\ntemporal dynamics and non-i.i.d. characteristics of data using temporal drift\nand collective divergence, respectively, and represent them as the Earth\nMover's Distance (EMD) of class distributions for classification tasks. We then\npropose a novel optimization objective and develop a joint scheduling and\nbandwidth allocation algorithm, enabling the FEEL system to learn from new data\nquickly without forgetting previous knowledge. Experimental results show that\nour algorithm achieves higher test accuracy and faster convergence compared to\nbenchmark methods, improving the rate of convergence by 58.4% on CIFAR-10 and\n49.2% on CIFAR-100 compared to random scheduling.", "published": "2025-09-09 02:33:48", "link": "http://arxiv.org/abs/2509.07342v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement Estimation", "abstract": "The National Comprehensive Cancer Network (NCCN) provides evidence-based\nguidelines for cancer treatment. Translating complex patient presentations into\nguideline-compliant treatment recommendations is time-intensive, requires\nspecialized expertise, and is prone to error. Advances in large language model\n(LLM) capabilities promise to reduce the time required to generate treatment\nrecommendations and improve accuracy. We present an LLM agent-based approach to\nautomatically generate guideline-concordant treatment trajectories for patients\nwith non-small cell lung cancer (NSCLC). Our contributions are threefold.\nFirst, we construct a novel longitudinal dataset of 121 cases of NSCLC patients\nthat includes clinical encounters, diagnostic results, and medical histories,\neach expertly annotated with the corresponding NCCN guideline trajectories by\nboard-certified oncologists. Second, we demonstrate that existing LLMs possess\ndomain-specific knowledge that enables high-quality proxy benchmark generation\nfor both model development and evaluation, achieving strong correlation\n(Spearman coefficient r=0.88, RMSE = 0.08) with expert-annotated benchmarks.\nThird, we develop a hybrid approach combining expensive human annotations with\nmodel consistency information to create both the agent framework that predicts\nthe relevant guidelines for a patient, as well as a meta-classifier that\nverifies prediction accuracy with calibrated confidence scores for treatment\nrecommendations (AUROC=0.800), a critical capability for communicating the\naccuracy of outputs, custom-tailoring tradeoffs in performance, and supporting\nregulatory compliance. This work establishes a framework for clinically viable\nLLM-based guideline adherence systems that balance accuracy, interpretability,\nand regulatory requirements while reducing annotation costs, providing a\nscalable pathway toward automated clinical decision support.", "published": "2025-09-09 01:49:29", "link": "http://arxiv.org/abs/2509.07325v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Identifying Neural Signatures from fMRI using Hybrid Principal Components Regression", "abstract": "Recent advances in neuroimaging analysis have enabled accurate decoding of\nmental state from brain activation patterns during functional magnetic\nresonance imaging scans. A commonly applied tool for this purpose is principal\ncomponents regression regularized with the least absolute shrinkage and\nselection operator (LASSO PCR), a type of multi-voxel pattern analysis (MVPA).\nThis model presumes that all components are equally likely to harbor relevant\ninformation, when in fact the task-related signal may be concentrated in\nspecific components. In such cases, the model will fail to select the optimal\nset of principal components that maximizes the total signal relevant to the\ncognitive process under study. Here, we present modifications to LASSO PCR that\nallow for a regularization penalty tied directly to the index of the principal\ncomponent, reflecting a prior belief that task-relevant signal is more likely\nto be concentrated in components explaining greater variance. Additionally, we\npropose a novel hybrid method, Joint Sparsity-Ranked LASSO (JSRL), which\nintegrates component-level and voxel-level activity under an information parity\nframework and imposes ranked sparsity to guide component selection. We apply\nthe models to brain activation during risk taking, monetary incentive, and\nemotion regulation tasks. Results demonstrate that incorporating sparsity\nranking into LASSO PCR produces models with enhanced classification\nperformance, with JSRL achieving up to 51.7\\% improvement in cross-validated\ndeviance $R^2$ and 7.3\\% improvement in cross-validated AUC. Furthermore,\nsparsity-ranked models perform as well as or better than standard LASSO PCR\napproaches across all classification tasks and allocate predictive weight to\nbrain regions consistent with their established functional roles, offering a\nrobust alternative for MVPA.", "published": "2025-09-09 00:13:51", "link": "http://arxiv.org/abs/2509.07300v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Multi-Topic Projected Opinion Dynamics for Resource Allocation", "abstract": "We propose a model of opinion formation on resource allocation among multiple\ntopics by multiple agents, who are subject to hard budget constraints. We\ndefine a utility function for each agent and then derive a projected dynamical\nsystem model of opinion evolution assuming that each agent myopically seeks to\nmaximize its utility subject to its constraints. Inter-agent coupling arises\nfrom an undirected social network, while inter-topic coupling arises from\nresource constraints. We show that opinions always converge to the equilibrium\nset. For special networks with very weak antagonistic relations, the opinions\nconverge to a unique equilibrium point. We further show that the underlying\nopinion formation game is a potential game. We relate the equilibria of the\ndynamics and the Nash equilibria of the game and characterize the unique Nash\nequilibrium for networks with no antagonistic relations. Finally, simulations\nillustrate our findings.", "published": "2025-09-09 15:23:12", "link": "http://arxiv.org/abs/2509.07847v1", "categories": ["eess.SY", "cs.GT", "cs.MA", "cs.SI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Bio-inspired decision making in swarms under biases from stubborn robots, corrupted communication, and independent discovery", "abstract": "Minimalistic robot swarms offer a scalable, robust, and cost-effective\napproach to performing complex tasks with the potential to transform\napplications in healthcare, disaster response, and environmental monitoring.\nHowever, coordinating such decentralised systems remains a fundamental\nchallenge, particularly when robots are constrained in communication,\ncomputation, and memory. In our study, individual robots frequently make errors\nwhen sensing the environment, yet the swarm can rapidly and reliably reach\nconsensus on the best among $n$ discrete options. We compare two canonical\nmechanisms of opinion dynamics -- direct-switch and cross-inhibition -- which\nare simple yet effective rules for collective information processing observed\nin biological systems across scales, from neural populations to insect\ncolonies. We generalise the existing mean-field models by considering asocial\nbiases influencing the opinion dynamics. While swarms using direct-switch\nreliably select the best option in absence of asocial dynamics, their\nperformance deteriorates once such biases are introduced, often resulting in\ndecision deadlocks. In contrast, bio-inspired cross-inhibition enables faster,\nmore cohesive, accurate, robust, and scalable decisions across a wide range of\nbiased conditions. Our findings provide theoretical and practical insights into\nthe coordination of minimal swarms and offer insights that extend to a broad\nclass of decentralised decision-making systems in biology and engineering.", "published": "2025-09-09 10:01:15", "link": "http://arxiv.org/abs/2509.07561v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Adaptive Evolutionary Framework for Safe, Efficient, and Cooperative Autonomous Vehicle Interactions", "abstract": "Modern transportation systems face significant challenges in ensuring road\nsafety, given serious injuries caused by road accidents. The rapid growth of\nautonomous vehicles (AVs) has prompted new traffic designs that aim to optimize\ninteractions among AVs. However, effective interactions between AVs remains\nchallenging due to the absence of centralized control. Besides, there is a need\nfor balancing multiple factors, including passenger demands and overall traffic\nefficiency. Traditional rule-based, optimization-based, and game-theoretic\napproaches each have limitations in addressing these challenges. Rule-based\nmethods struggle with adaptability and generalization in complex scenarios,\nwhile optimization-based methods often require high computational resources.\nGame-theoretic approaches, such as Stackelberg and Nash games, suffer from\nlimited adaptability and potential inefficiencies in cooperative settings. This\npaper proposes an Evolutionary Game Theory (EGT)-based framework for AV\ninteractions that overcomes these limitations by utilizing a decentralized and\nadaptive strategy evolution mechanism. A causal evaluation module (CEGT) is\nintroduced to optimize the evolutionary rate, balancing mutation and evolution\nby learning from historical interactions. Simulation results demonstrate the\nproposed CEGT outperforms EGT and popular benchmark games in terms of lower\ncollision rates, improved safety distances, higher speeds, and overall better\nperformance compared to Nash and Stackelberg games across diverse scenarios and\nparameter settings.", "published": "2025-09-09 05:49:36", "link": "http://arxiv.org/abs/2509.07411v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Convergence analysis for the Barrett-Garcke-Nurnberg method of transport type", "abstract": "In this paper, we propose a Barrett-Garcke-Nurnberg (BGN) method for evolving\ngeometries under general flows and present the corresponding convergence\nanalysis. Specifically, we examine the scenario where a closed curve evolves\naccording to a prescribed background velocity field. Unlike mean curvature flow\nand surface diffusion, where the evolution velocities inherently exhibit\nparabolicity, this case is dominated by transport which poses a significant\ndifficulty in establishing convergence proofs. To address the challenges\nimposed by this transport-dominant nature, we derive several discrete energy\nestimates of the transport type on discretized polynomial surfaces within the\nframework of the projection error. The use of the projection error is\nindispensable as it provides crucial additional stability through its\northogonality structure. We prove that the proposed method converges\nsub-optimally in the L2 norm, and this is the first convergence proof for a\nfully discrete numerical method solving the evolution of curves driven by\ngeneral flows.", "published": "2025-09-09 15:11:34", "link": "http://arxiv.org/abs/2509.07834v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Feature Understanding and Sparsity Enhancement via 2-Layered kernel machines (2L-FUSE)", "abstract": "We propose a novel sparsity enhancement strategy for regression tasks, based\non learning a data-adaptive kernel metric, i.e., a shape matrix, through\n2-Layered kernel machines. The resulting shape matrix, which defines a\nMahalanobis-type deformation of the input space, is then factorized via an\neigen-decomposition, allowing us to identify the most informative directions in\nthe space of features. This data-driven approach provides a flexible,\ninterpretable and accurate feature reduction scheme. Numerical experiments on\nsynthetic and applications to real datasets of geomagnetic storms demonstrate\nthat our approach achieves minimal yet highly informative feature sets without\nlosing predictive performance.", "published": "2025-09-09 14:45:10", "link": "http://arxiv.org/abs/2509.07806v1", "categories": ["math.NA", "astro-ph.SR", "cs.NA", "stat.ML", "65D15, 41A05, 68Q32"], "primary_category": "math.NA"}
{"title": "Embedding structures in continua: linear models and finite element discretizations", "abstract": "This work describes models and numerical approximations that describe the\nmechanical behavior of deformable continua with embedded structural members,\nsuch as rigid bodies, beams, shells, etc. The continuum formulation extends an\nidea first presented in the context of the Arlequin method and constrains the\nkinematics of the two types of bodies to be compatible in the energy sense. In\nthe article, we exploit the shared similarities of all structural theories to\nintroduce a general framework for energetically coupling the latter with\ncontinua. In addition, we show that the problems, as well as their finite\nelement approximations, are well-posed. Numerical examples of bodies with\ninclusions, fibers, and embedded surfaces are provided to illustrate the\ngenerality and robustness of the approach.", "published": "2025-09-09 13:34:37", "link": "http://arxiv.org/abs/2509.07735v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "HYLU: Hybrid Parallel Sparse LU Factorization", "abstract": "This article introduces HYLU, a hybrid parallel LU factorization-based\ngeneral-purpose solver designed for efficiently solving sparse linear systems\n(Ax=b) on multi-core shared-memory architectures. The key technical feature of\nHYLU is the integration of hybrid numerical kernels so that it can adapt to\nvarious sparsity patterns of coefficient matrices. Tests on 34 sparse matrices\nfrom SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL\nPARDISO in the numerical factorization phase by geometric means of 1.74X (for\none-time solving) and 2.26X (for repeated solving). HYLU can be downloaded from\nhttps://github.com/chenxm1986/hylu.", "published": "2025-09-09 12:55:44", "link": "http://arxiv.org/abs/2509.07690v1", "categories": ["cs.AR", "cs.DC", "cs.MS", "cs.NA", "math.NA"], "primary_category": "cs.AR"}
{"title": "Realizability-preserving monolithic convex limiting in continuous Galerkin discretizations of the M1 model of radiative transfer", "abstract": "We discretize the $M_1$ model of radiative transfer using continuous finite\nelements and propose a tailor-made monolithic convex limiting (MCL) procedure\nfor enforcing physical realizability. The $M_1$ system of nonlinear balance\nlaws for the zeroth and first moments of a probability distribution function is\nderived from the linear Boltzmann equation and equipped with an entropy-based\nclosure for the second moment. To ensure hyperbolicity and physical\nadmissibility, evolving moments must stay in an invariant domain representing a\nconvex set of realizable states. We first construct a low-order method that is\nprovably invariant domain preserving (IDP). Introducing intermediate states\nthat represent spatially averaged exact solutions of homogeneous Riemann\nproblems, we prove that these so-called bar states are realizable in any number\nof space dimensions. This key auxiliary result enables us to show the IDP\nproperty of a fully discrete scheme with a diagonally implicit treatment of\nreactive terms. To achieve high resolution, we add nonlinear correction terms\nthat are constrained using a two-step MCL algorithm. In the first limiting\nstep, local bounds are imposed on each conserved variable to avoid spurious\noscillations and maintain positivity of the scalar-valued zeroth moment\n(particle density). The second limiting step constrains the magnitude of the\nvector-valued first moment to be realizable. The flux-corrected finite element\nscheme is provably IDP. Its ability to prevent nonphysical behavior while\nattaining high-order accuracy in smooth regions is verified in a series of\nnumerical tests. The developed methodology provides a robust simulation tool\nfor dose calculation in radiotherapy.", "published": "2025-09-09 12:55:30", "link": "http://arxiv.org/abs/2509.07689v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Physics-informed low-rank neural operators with application to parametric elliptic PDEs", "abstract": "We present the Physics-Informed Low-Rank Neural Operator (PILNO), a neural\noperator framework for efficiently approximating solution operators of partial\ndifferential equations (PDEs) on point cloud data. PILNO combines low-rank\nkernel approximations with an encoder--decoder architecture, enabling fast,\ncontinuous one-shot predictions while remaining independent of specific\ndiscretizations. The model is trained using a physics-informed penalty\nframework, ensuring that PDE constraints and boundary conditions are satisfied\nin both supervised and unsupervised settings. We demonstrate its effectiveness\non diverse problems, including function fitting, the Poisson equation, the\nscreened Poisson equation with variable coefficients, and parameterized Darcy\nflow. The low-rank structure provides computational efficiency in\nhigh-dimensional parameter spaces, establishing PILNO as a scalable and\nflexible surrogate modeling tool for PDEs.", "published": "2025-09-09 12:54:06", "link": "http://arxiv.org/abs/2509.07687v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "stat.ML", "68T07, 65N80, 65F55, 35J05, 76S05"], "primary_category": "math.NA"}
{"title": "High-order staggered Lagrangian hydrodynamics (II) : the artificial viscosity and hourglass control algorithm", "abstract": "In this article, we investigate the artificial viscosity and hourglass\ncontrol algorithms for high-order staggered Lagrangian hydrodynamics(SGH), as\nproposed in~\\cite[Sun et al., 2025]{Sun2025High}. Inspired by the subzonal\npressure method in classical staggered Lagrangian hydrodynamics, we extend the\nstiffness-based hourglass control algorithm to the high-order setting,\nenriching the pressure field from the $Q^{m-1}$ to the $Q^{m}$ polynomial\nspace. A unified framework for this hourglass control approach is established,\nfrom which the classical subzonal pressure method naturally emerges as the\nspecial case of the $Q^1-P^0$ space. The artificial viscosity follows the\nformulation in~\\cite[Dobrev et al., 2012]{Dobrev2012High}. We show that the\nviscosity admits a concise form, with intermediate variables explicitly\ncomputable, leading to improved computational efficiency and easier\nimplementation. Moreover, the tensor viscosity in classical staggered\nLagrangian hydrodynamics can be derived in a similarly compact and explicit\nform. Numerical experiments on two-dimensional problems are presented to\ndemonstrate the accuracy and efficiency of the proposed algorithms.", "published": "2025-09-09 12:01:53", "link": "http://arxiv.org/abs/2509.07636v1", "categories": ["math.NA", "cs.NA", "49N45, 65N21"], "primary_category": "math.NA"}
{"title": "Generalized eigenvalue stabilization for immersed explicit dynamics", "abstract": "Explicit time integration for immersed finite element discretizations\nseverely suffers from the influence of poorly cut elements. In this\ncontribution, we propose a generalized eigenvalue stabilization (GEVS) strategy\nfor the element mass matrices of cut elements to cure their adverse impact on\nthe critical time step size of the global system. We use spectral basis\nfunctions, specifically $C^0$ continuous Lagrangian interpolation polynomials\ndefined on Gauss-Lobatto-Legendre (GLL) points, which, in combination with its\nassociated GLL quadrature rule, yield high-order convergent diagonal mass\nmatrices for uncut elements. Moreover, considering cut elements, we combine the\nproposed GEVS approach with the finite cell method (FCM) to guarantee\ndefiniteness of the system matrices. However, the proposed GEVS stabilization\ncan directly be applied to other immersed boundary finite element methods.\nNumerical experiments demonstrate that the stabilization strategy achieves\noptimal convergence rates and recovers critical time step sizes of equivalent\nboundary-conforming discretizations. This also holds in the presence of weakly\nenforced Dirichlet boundary conditions using either Nitsche's method or penalty\nformulations.", "published": "2025-09-09 12:00:21", "link": "http://arxiv.org/abs/2509.07632v1", "categories": ["cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CE"}
{"title": "Asymmetric Modulation Design for Fluid-Antenna SWIPT Systems", "abstract": "In this work, we propose the design of modulation schemes that improve the\nrate-energy region of fluid antenna-assisted simultaneous wireless information\nand power transfer (SWIPT) systems. By considering the nonlinear\ncharacteristics of practical energy harvesting circuits, we formulate a\ndual-objective rate-energy (RE) region optimization problem to jointly maximize\nthe discrete-input mutual information (DIMI) and harvested current. The problem\nis solved using the epsilon-constraint method and optimized constellations are\ndesigned for various energy harvesting thresholds. We then evaluate the\nperformance of the optimized constellations under three different fluid antenna\n(FA) port selection strategies: (i) Best Port, (ii) Fixed Port, and (iii)\nRandom Port. Our simulation results demonstrate significant performance gains\nof optimized constellations over conventional constellations in both\ninformation rate and energy harvesting.", "published": "2025-09-09 11:35:02", "link": "http://arxiv.org/abs/2509.07610v1", "categories": ["eess.SP", "cs.NA", "math.NA"], "primary_category": "eess.SP"}
{"title": "On Global Rates for Regularization Methods based on Secant Derivative Approximations", "abstract": "An inexact framework for high-order adaptive regularization methods is\npresented, in which approximations may be used for the $p$th-order tensor,\nbased on lower-order derivatives. Between each recalculation of the $p$th-order\nderivative approximation, a high-order secant equation can be used to update\nthe $p$th-order tensor as proposed in (Welzel 2024) or the approximation can be\nkept constant in a lazy manner. When refreshing the $p$th-order tensor\napproximation after $m$ steps, an exact evaluation of the tensor or a finite\ndifference approximation can be used with an explicit discretization stepsize.\nFor all the newly adaptive regularization variants, we prove an\n$\\mathcal{O}\\left( \\max[ \\epsilon_1^{-(p+1)/p}, \\, \\epsilon_2^{(-p+1)/(p-1)} ]\n\\right)$ bound on the number of iterations needed to reach an $(\\epsilon_1, \\,\n\\epsilon_2)$ second-order stationary points. Discussions on the number of\noracle calls for each introduced variant are also provided.\n  When $p=2$, we obtain a second-order method that uses quasi-Newton\napproximations with an $\\mathcal{O}\\left(\\max[\\epsilon_1^{-3/2}, \\, \\,\n\\epsilon_2^{-3}]\\right)$ iteration bound to achieve approximate second-order\nstationarity.", "published": "2025-09-09 10:43:35", "link": "http://arxiv.org/abs/2509.07580v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Quasi-Monte Carlo integration over $\\mathbb{R}^s$ with boundary-damping importance sampling", "abstract": "This paper proposes a new importance sampling (IS) that is tailored to\nquasi-Monte Carlo (QMC) integration over $\\mathbb{R}^s$. IS introduces a\nmultiplicative adjustment to the integrand by compensating the sampling from\nthe proposal instead of the target distribution. Improper proposals result in\nsevere adjustment factor for QMC. Our strategy is to first design a adjustment\nfactor to meet desired regularities and then determine a tractable transport\nmap from the standard uniforms to the proposal for using QMC quadrature points\nas inputs. The transport map has the effect of damping the boundary growth of\nthe resulting integrand so that the effectiveness of QMC can be reclaimed.\nUnder certain conditions on the original integrand, our proposed IS enjoys a\nfast convergence rate independently of the dimension $s$, making it amenable to\nhigh-dimensional problems.", "published": "2025-09-09 08:44:08", "link": "http://arxiv.org/abs/2509.07509v1", "categories": ["math.NA", "cs.NA", "41A63, 65D30, 97N40"], "primary_category": "math.NA"}
{"title": "Model Order Reduction for Quantum Molecular Dynamics", "abstract": "Molecular dynamics simulations are indispensable for exploring the behavior\nof atoms and molecules. Grounded in quantum mechanical principles, quantum\nmolecular dynamics provides high predictive power but its computational cost is\ndominated by iterative high-fidelity electronic structure calculations. We\npropose a novel model order reduction approach as an alternative to\nhigh-fidelity electronic structure calculation. By learning a low-dimensional\nrepresentation of the electronic solution manifold within the Kohn-Sham density\nfunctional theory framework, our model order reduction approach determines the\nground state electronic density by projecting the problem onto a\nlow-dimensional subspace, thereby avoiding the computationally expensive\niterative optimization of electronic wavefunctions in the full space. We\ndemonstrate the capability of our method on a water molecule, showing excellent\nagreement with high-fidelity simulations for both molecular geometry and\ndynamic properties, highlighting the generalizability through carefully\ndesigned parametrization and systematic sampling.", "published": "2025-09-09 02:31:40", "link": "http://arxiv.org/abs/2509.07340v1", "categories": ["physics.chem-ph", "cs.NA", "math.NA", "physics.comp-ph"], "primary_category": "physics.chem-ph"}
{"title": "The Stability of Block Eliminations and Additive Modifications", "abstract": "The block elimination with additive modifications (BEAM) method was recently\nproposed as a alternative to LU with partial pivoting requiring less\ncommunication. Because of the novelty of BEAM, the existing theoretical\nanalysis is lacking. To that end, we analyze both the numerical stability of\nthe underlying block LU factorization and the effects of additive\nmodifications. For the block LU factorization, we are able to improve the\nprevious results of Demmel et al. from being cubic in the element growth to\nmerely quadratic. Furthermore, we propose an alternative measure of element\ngrowth that is better aligned with block LU; this new measure of growth allows\nour analysis to apply to matrices that cannot be factored with pointwise LU. In\nthe second part, we analyzed the modifications produced by BEAM and the effect\nthey have on the condition number and growth factor. Finally, we show that BEAM\nwill not apply any modifications in some cases that regular block LU can safely\nfactor.", "published": "2025-09-09 00:45:02", "link": "http://arxiv.org/abs/2509.07305v1", "categories": ["math.NA", "cs.NA", "15A23, 65F05"], "primary_category": "math.NA"}
{"title": "A novel statistical workflow for nonstationary modelling of successive Fr\u00e9chet extremes", "abstract": "Accurate estimation of the frequency and magnitude of successive extreme\nevents in energy demand is critical for strategic resource planning.\nTraditional approaches based on extreme value theory (EVT) are typically\nlimited to modelling isolated extreme events and struggle to capture the\ndynamics of temporally clustered extremes, such as those driven by prolonged\nextreme weather events. These limitations are exacerbated by the scarcity of\nhistorical data and computational costs of longrun simulations leading to high\nuncertainty in return level estimates for successive extremes. Here, we\nintroduce a novel statistical framework leveraging recent theoretical advances\nin successive extreme value modelling in dynamical systems. Under reasonable\nassumptions of the time series data (e.g. the data follow a fat-tailed\nFr\\'{e}chet distribution), our tool allows for significantly more robust\nestimates of returns and magnitudes of successive extreme events compared to\nstandard likelihood methods. We illustrate our statistical workflow on\nscenarios of forecasted gas supply levels from 2025 to 2050. Common measures of\nstatistical accuracy are provided as benchmarks for comparison.", "published": "2025-09-09 00:01:24", "link": "http://arxiv.org/abs/2509.07296v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH"], "primary_category": "math.ST"}
{"title": "Hedging Options on Asset Portfolios against Just One Underlying Asset in the Presence of Transaction Costs", "abstract": "Options are contingent claims regarding the value of underlying assets. The\nBlack-Scholes formula provides a road map for pricing these options in a\nrisk-neutral setting, justified by a delta hedging argument in which\ncountervailing positions of appropriate size are taken in the underlying asset.\nHowever, what if an underlying asset is expensive to trade? It might be better\nto hedge with a different, but related asset that is cheaper to trade. This\nstudy considers this question in a setting in which the option written on a\nportfolio containing $\\alpha$ shares of one asset $S_{t_1}$ and $(1-\\alpha)$\nshares of another security $S_{t_2}$ correlated with $S_{t_1}$. We suppose that\nthe asset is hedged against only one of $S_{t_1}$ or $S_{t_2}.$ In the case of\n$\\alpha=0~\\text{or}~1$ we can consider this model to cover the case where an\noption on one asset is hedged against either the ``right\" (underlying) asset or\nthe``wrong\" (related, different) asset. We hedge our portfolio on simulated\ndata using varying trading intervals, correlation coefficients, $\\rho$ and\ntransaction costs. We calculated the risk-adjusted values ($RAV$) as the risk\nand return measures to make meaningful decisions on when to trade $S_{t_1}$ or\n$S_{t_2}.$ From the conclusions made based on $RAV,$ the size of the market\nprice of risk and that of transaction costs on both assets are key to making a\ndecision while hedging. From our results, trading the wrong asset can be opted\nfor when $\\rho$ is very high for reasonably small transaction costs for either\nof the assets.", "published": "2025-09-09 13:19:23", "link": "http://arxiv.org/abs/2509.07718v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Expected Signature Kernels for L\u00e9vy Rough Paths", "abstract": "The expected signature kernel arises in statistical learning tasks as a\nsimilarity measure of probability measures on path space. Computing this kernel\nfor known classes of stochastic processes is an important problem that, in\nparticular, can help reduce computational costs. Building on the representation\nof the expected signature of (inhomogeneous) L\\'evy processes with absolutely\ncontinuous characteristics as the development of an absolutely continuous path\nin the extended tensor algebra [F.-H.-Tapia, Forum of Mathematics: Sigma\n(2022), \"Unified signature cumulants and generalized Magnus expansions\"], we\nextend the arguments developed for smooth rough paths in\n[Lemercier-Lyons-Salvi, \"Log-PDE Methods for Rough Signature Kernels\"] to\nderive a PDE system for the expected signature of inhomogeneous L\\'evy\nprocesses. As a specific example, we see that the expected signature kernel of\nGaussian martingales satisfies a Goursat PDE.", "published": "2025-09-09 16:23:29", "link": "http://arxiv.org/abs/2509.07893v1", "categories": ["math.PR", "stat.ML", "60L10, 60L90, 60E10, 60G44, 60G48, 60G51, 60J76"], "primary_category": "math.PR"}
{"title": "Bayesian Pliable Lasso with Horseshoe Prior for Interaction Effects in GLMs with Missing Responses", "abstract": "Sparse regression problems, where the goal is to identify a small set of\nrelevant predictors, often require modeling not only main effects but also\nmeaningful interactions through other variables. While the pliable lasso has\nemerged as a powerful frequentist tool for modeling such interactions under\nstrong heredity constraints, it lacks a natural framework for uncertainty\nquantification and incorporation of prior knowledge. In this paper, we propose\na Bayesian pliable lasso that extends this approach by placing\nsparsity-inducing priors, such as the horseshoe, on both main and interaction\neffects. The hierarchical prior structure enforces heredity constraints while\nadaptively shrinking irrelevant coefficients and allowing important effects to\npersist. We extend this framework to Generalized Linear Models (GLMs) and\ndevelop a tailored approach to handle missing responses. To facilitate\nposterior inference, we develop an efficient Gibbs sampling algorithm based on\na reparameterization of the horseshoe prior. Our Bayesian framework yields\nsparse, interpretable interaction structures, and principled measures of\nuncertainty. Through simulations and real-data studies, we demonstrate its\nadvantages over existing methods in recovering complex interaction patterns\nunder both complete and incomplete data.\n  Our method is implemented in the package \\texttt{hspliable} available on\nGithub.", "published": "2025-09-09 08:28:21", "link": "http://arxiv.org/abs/2509.07501v1", "categories": ["stat.ME", "stat.AP", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Affine Modulation-based Audiogram Fusion Network for Joint Noise Reduction and Hearing Loss Compensation", "abstract": "Hearing aids (HAs) are widely used to provide personalized speech enhancement\n(PSE) services, improving the quality of life for individuals with hearing\nloss. However, HA performance significantly declines in noisy environments as\nit treats noise reduction (NR) and hearing loss compensation (HLC) as separate\ntasks. This separation leads to a lack of systematic optimization, overlooking\nthe interactions between these two critical tasks, and increases the system\ncomplexity. To address these challenges, we propose a novel audiogram fusion\nnetwork, named AFN-HearNet, which simultaneously tackles the NR and HLC tasks\nby fusing cross-domain audiogram and spectrum features. We propose an\naudiogram-specific encoder that transforms the sparse audiogram profile into a\ndeep representation, addressing the alignment problem of cross-domain features\nprior to fusion. To incorporate the interactions between NR and HLC tasks, we\npropose the affine modulation-based audiogram fusion frequency-temporal\nConformer that adaptively fuses these two features into a unified deep\nrepresentation for speech reconstruction. Furthermore, we introduce a voice\nactivity detection auxiliary training task to embed speech and non-speech\npatterns into the unified deep representation implicitly. We conduct\ncomprehensive experiments across multiple datasets to validate the\neffectiveness of each proposed module. The results indicate that the\nAFN-HearNet significantly outperforms state-of-the-art in-context fusion joint\nmodels regarding key metrics such as HASQI and PESQ, achieving a considerable\ntrade-off between performance and efficiency. The source code and data will be\nreleased at https://github.com/deepnetni/AFN-HearNet.", "published": "2025-09-09 02:32:52", "link": "http://arxiv.org/abs/2509.07341v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Sensor Management in Multi-Stage Stochastic Control Problems with Imperfect State Information", "abstract": "Technological advancements in miniaturization and wireless communications are\nyielding more affordable and versatile sensors and, in turn, more applications\nin which a network of sensors can be actively managed to best support overall\ndecision-making objectives. We propose modeling the opportunity for sensor\nmanagement within multi-stage stochastic control problems with imperfect state\ninformation. Such formulations inherently assume the state of the modeled\nenvironment cannot be accessed directly but instead the controller can observe\nonly noisy measurements of the state and, therefore, at each decision stage\nsome form of state estimation is required before a control is actuated. The\nnotion of sensor management arises when the modeled controls not only affect\nthe subsequent evolution of the state but can also affect the nature of future\nmeasurements and, hence, the quality of state estimates that drive future\ncontrol decisions. In principle, the optimal strategy for any appropriately\nmodeled multi-stage stochastic control problem with imperfect state information\n(with or without opportunity for sensor management) is the solution to a\ndynamic program; in practice, the computational requirements are typically\nprohibitive yet dynamic programming methods are still useful to guide the\ndevelopment of effective suboptimal strategies. In this spirit, we model the\nopportunity for sensor management within small-scale examples of two\nwell-studied dynamic programming formulations, namely (1) the\nfinite-state/finite-action Partially-Observable Markov Decision Process\n(PO-MDP) and (2) the Linear-Quadratic-Gaussian Regulator (LQGR). These examples\nadmit solvable dynamic programs and confirm how the interplay between sensing\nand acting is a natural by-product of a dynamic programming solution.", "published": "2025-09-09 15:13:57", "link": "http://arxiv.org/abs/2509.07840v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Enhancements in Score-based Channel Estimation for Real-Time Wireless Systems", "abstract": "We propose enhancements to score-based generative modeling techniques for\nlow-latency pilot-based channel estimation in a point-to-point single-carrier\nmultiple-input multiple-output (MIMO) wireless system. Building on recent\nadvances in score-based models, we investigate a specific noise schedule design\nand sampling acceleration by step-skipping to reduce the number of denoising\nsteps during inference. We additionally propose a single-step signal-to-noise\nratio informed denoiser as an extreme case of the step-skipping approach. Our\nmethods achieve significant latency reductions without performance degradation,\nas demonstrated on a synthetic channel dataset representing an urban macrocell\nMIMO communications scenario.", "published": "2025-09-09 15:13:15", "link": "http://arxiv.org/abs/2509.07839v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing with Mobile Devices through Radio SLAM: Models, Methods, Opportunities, and Challenges", "abstract": "The integration of sensing and communication (ISAC) is a cornerstone of 6G,\nenabling simultaneous environmental awareness and communication. This paper\nexplores radio SLAM (simultaneous localization and mapping) as a key ISAC\napproach, using radio signals for mapping and localization. We analyze radio\nSLAM across different frequency bands, discussing trade-offs in coverage,\nresolution, and hardware requirements. We also highlight opportunities for\nintegration with sensing, positioning, and cooperative networks. The findings\npave the way for standardized solutions in 6G applications such as autonomous\nsystems and industrial robotics.", "published": "2025-09-09 14:11:14", "link": "http://arxiv.org/abs/2509.07775v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Experimental Evaluation of Joint Clock Recovery and Equalization for Sub-Terahertz Links", "abstract": "This paper proposes and experimentally evaluates a joint clock recovery (CR)\nand equalization architecture tailored for high-speed sub-terahertz (sub-THz)\nwireless communication links. Specifically, a Baud-spaced digital receiver\narchitecture is investigated that combines a constant modulus algorithm (CMA)\nequalizer with a blind timing error detector (TED), enabling robust symbol\ntiming synchronization without decision-directed (DD) feedback or pilot\nsymbols. The proposed TED leverages the CMA filter coefficients to estimate\ntiming errors, which are then used to drive a Farrow interpolator operating at\ntwice the symbol rate. The system is validated experimentally using a 140~GHz\nwireless testbed with 16-QAM modulation over a 10~GHz bandwidth. Results show\nthat the proposed TED schemes outperform conventional blind TEDs, such as\nGardner and blind implementations of Mueller \\& M\\\"uller, in terms of bit error\nrate (BER), error vector magnitude (EVM), and intersymbol interference (ISI)\nsuppression. These capabilities are especially relevant to next-generation\nspaceborne communication systems, where wideband sub-THz links are expected to\nplay a key role in enabling ultra-high-data-rate inter-satellite and deep-space\ncommunications under challenging synchronization constraints.", "published": "2025-09-09 13:56:49", "link": "http://arxiv.org/abs/2509.07758v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interference Mitigation for OFDM-based Integrated Sensing and Communications with Arbitrary Modulation Formats", "abstract": "Integrated sensing and communication will be a key feature of future mobile\nnetworks, enabling highly efficient systems and numerous new applications by\nleveraging communication signals for sensing. In this paper, we analyze the\nimpact of arbitrary modulation alphabets on the sensing performance of\ncommunication-centric OFDM systems as expected in the next-generation 6G\nnetworks. We evaluate existing interference mitigation techniques, such as\ncoherent successive target cancellation, and propose an enhanced version of\nthis algorithm. A systematic performance evaluation in multi-target scenarios,\nincluding the effects of scattering, demonstrates that our proposed\ninterference mitigation methods achieve performance comparable to\nsensing-optimal constant modulus signals while utilizing higher order\nconstellations for more efficient communications.", "published": "2025-09-09 13:52:40", "link": "http://arxiv.org/abs/2509.07754v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Antenna Positioning and Beamforming for Movable Antenna Array Aided Ground Station in Low-Earth Orbit Satellite Communication", "abstract": "This paper proposes a new architecture for the low-earth orbit (LEO)\nsatellite ground station aided by movable antenna (MA) array. Unlike\nconventional fixed-position antenna (FPA), the MA array can flexibly adjust\nantenna positions to reconfigure array geometry, for more effectively\nmitigating interference and improving communication performance in ultra-dense\nLEO satellite networks. To reduce movement overhead, we configure antenna\npositions at the antenna initialization stage, which remain unchanged during\nthe whole communication period of the ground station. To this end, an\noptimization problem is formulated to maximize the average achievable rate of\nthe ground station by jointly optimizing its antenna position vector (APV) and\ntime-varying beamforming weights, i.e., antenna weight vectors (AWVs). To solve\nthe resulting non-convex optimization problem, we adopt the Lagrangian dual\ntransformation and quadratic transformation to reformulate the objective\nfunction into a more tractable form. Then, we develop an efficient block\ncoordinate descent-based iterative algorithm that alternately optimizes the APV\nand AWVs until convergence is reached. Simulation results demonstrate that our\nproposed MA scheme significantly outperforms traditional FPA by increasing the\nachievable rate at ground stations under various system setups, thus providing\nan efficient solution for interference mitigation in future ultra-dense LEO\nsatellite communication networks.", "published": "2025-09-09 08:44:32", "link": "http://arxiv.org/abs/2509.07511v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Methodological Framework for Positioning of Wireless Sensors in New Generation Launchers", "abstract": "In wireless sensor networks for reusable launchers, the electromagnetic\ncharacterization and electromagnetic compatibility analyses are relevant due to\nthe reference operational scenario, which implies a complex, and sometimes\ndynamic, electromagnetic environment. This work proposes a methodological\nframework for the design of the network and for the analysis of the related\nelectromagnetic environment within the stages of a given launcher. Based on the\npreliminary positioning of the network nodes, the framework prescribes a\nworkflow and the related toolset for determining the optimal network topology\nfocusing on the weights, the operation of the transceivers, and the overall\nradiated power. The optimal network configuration is simulated by using\ncomputational electromagnetics strategies in order to assess the\nelectromagnetic environment induced by the sensor network itself. The paper\nprovides some results concerning a case study for a specific launcher.", "published": "2025-09-09 08:04:28", "link": "http://arxiv.org/abs/2509.07483v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Integrated Communication and Computing in Time-Varying mmWave Channels", "abstract": "We propose a novel framework for integrated communication and computing (ICC)\ntransceiver design in time-varying millimeter-wave (mmWave) channels. In\nparticular, in order to cope with the dynamics of time-varying mmWave channels,\nthe detection of communication symbols and the execution of an over-the-air\ncomputing (AirComp) operation are performed in parallel with channel tracking,\nas opposed to existing state-of-the-art (SotA) on ICC where perfect knowledge\nof the channel at all time instances is typically assumed. For clarity of\nexposition, we consider a single-input multiple-output (SIMO) uplink scenario\nwhere multiple single-antenna user equipment (UE) transmit to a base station\n(BS) equipped with multiple antennas, such that each UE, or edge device (ED),\nprecodes its own transmit signal, while the BS, or access points (APs), also\nperforms receive beamforming. The proposed transceiver framework then estimates\nchannel state information (CSI) and data symbols in parallel, using a bilinear\nGaussian belief propagation (BiGaBP) algorithm for joint channel and data\ndetection (JCDE), aided by a channel prediction (CP) algorithm executed before\neach estimation window at the BS. The AirComp operation is then executed by\nmeans of an optimal combination of the residual signal. Simulation results\ndemonstrate the effectiveness of the proposed scheme in performing ICC in\nchallenging time-varying mmWave channels, with minimal degradation to both\ncommunication and computing performance.", "published": "2025-09-09 08:04:26", "link": "http://arxiv.org/abs/2509.07482v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Systematic Framework to Test the Resilience of Three-Fold Redundant Sparse Arrays Against Two Sensor Failures and Some Never-Before Findings", "abstract": "As the field of sparse arrays progressed, numerous array designs have been\nintroduced with a focus on larger apertures and higher degrees of freedom\n(DOFs), resulting in maximally economic sparse arrays (MESAs) that operate with\nthe least number of sensors required to provide a given aperture while ensuring\na hole-free difference coarray (DCA). Consequently, MESAs are least robust to\nsensor failures and cannot afford the failure of even a single sensor.\nMultifold redundant sparse arrays (MFRSAs) provide a practical solution to the\nproblem of sensor failures in sparse arrays by making sure that the array\ncontains enough sensor pairs necessary to produce each spatial lag multiple\ntimes. Owing to this property, a \\b{eta}-fold redundant array can withstand\nsimultaneous failure of at least \\b{eta}-1 sensors without losing the hole-free\nDCA property. Nevertheless, MFRSAs are also prone to hidden dependencies that\nprevent them from being fully robust. In this work, we present a systematic\nframework to evaluate the robustness of triple redundant sparse linear arrays\n(TRSLAs) against all possible two-sensor failures. After detailing the proposed\napproach, we present the failure analysis of representative TRSLAs available in\nexisting literature. It is found that existing TRSLAs have some hidden\nvulnerabilities against the failure of some peculiar sensor pairs.\nCorresponding MATLAB programs and numerical simulations are provided for\nevaluation and use by the array processing community. The proposed approach has\na great archival value as it can evaluate the robustness of any present or\nfuture TRSLAs through objective means.", "published": "2025-09-09 07:00:20", "link": "http://arxiv.org/abs/2509.07442v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Node Position Estimation in Diffusion-Based Molecular Communications Using Multi-Layer Perceptron", "abstract": "This paper proposes a method for accurately estimating the relative position\nbetween two nodes with unknown locations in a diffusion-based molecular\ncommunication environment. A specialized node structure is designed, combining\na central absorbing receiver with multiple transmitters placed at predefined\nspherical coordinates. Pilot molecules are released, and their absorption time\nand concentration are measured. By partitioning the spherical coordinate space,\nthese spatially distinct measurements serve as input to a multilayer perceptron\n(MLP)-based model. The proposed method significantly improves the precision of\ndistance and direction estimation. Simulation results demonstrate localization\naccuracy, confirming the effectiveness of the neural network model in capturing\nthe underlying physical characteristics.", "published": "2025-09-09 06:56:51", "link": "http://arxiv.org/abs/2509.07441v1", "categories": ["eess.SP", "94A12", "C.2.1"], "primary_category": "eess.SP"}
{"title": "SA-OOSC: A Multimodal LLM-Distilled Semantic Communication Framework for Enhanced Coding Efficiency with Scenario Understanding", "abstract": "This paper introduces SA-OOSC, a multimodal large language models\n(MLLM)-distilled semantic communication framework that achieves efficient\nsemantic coding with scenario-aware importance allocations. This approach\naddresses a critical limitation of existing object-oriented semantic\ncommunication (OOSC) systems - assigning static importance values to specific\nclasses of objects regardless of their contextual relevance. Our framework\nutilizes MLLMs to identify the scenario-augmented (SA) semantic importance for\nobjects within the image. Through knowledge distillation with the\nMLLM-annotated data, our vectorization/de-vectorization networks and JSCC\nencoder/decoder learn to dynamically allocate coding resources based on\ncontextual significance, i.e., distinguishing between high-importance objects\nand low-importance according to the SA scenario information of the task. The\nframework features three core innovations: a MLLM-guided knowledge distillation\npipeline, an importance-weighted variable-length JSCC framework, and novel loss\nfunction designs that facilitate the knowledge distillation within the JSCC\nframework. Experimental validation demonstrates our framework's superior coding\nefficiency over conventional semantic communication systems, with open-sourced\nMLLM-annotated and human-verified datasets established as new benchmarks for\nfuture research in semantic communications.", "published": "2025-09-09 06:48:05", "link": "http://arxiv.org/abs/2509.07436v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Spectrotemporal Feature Extraction in EHG Signals and Tocograms for Enhanced Preterm Birth Prediction", "abstract": "Preterm birth (PTB), defined as delivery before 37 weeks of gestation, is a\nleading cause of neonatal mortality and long term health complications. Early\ndetection is essential for enabling timely medical interventions.\nElectrohysterography (EHG) and tocography (TOCO) are promising non invasive\ntools for PTB prediction, but prior studies often suffer from class imbalance,\nimproper oversampling, and reliance on features with limited physiological\nrelevance. This work presents a machine learning pipeline incorporating robust\npreprocessing, physiologically grounded feature extraction, and rigorous\nevaluation. Features were extracted from EHG (and TOCO) signals using Mel\nfrequency cepstral coefficients, statistical descriptors of wavelet\ncoefficients, and peaks of the normalized power spectrum. Signal quality was\nenhanced via Karhunen Lo\\`eve Transform (KLT) denoising through eigenvalue\nbased subspace decomposition. Multiple classifiers, including Logistic\nRegression, Support Vector Machines, Random Forest, Gradient Boosting,\nMultilayer Perceptron, and CatBoost, were evaluated on the TPEHGT dataset. The\nCatBoost classifier with KLT denoising achieved the highest performance on\nfixed interval segments of the TPEHGT dataset, reaching 97.28% accuracy and an\nAUC of 0.9988. Ablation studies confirmed the critical role of both KLT\ndenoising and physiologically informed features. Comparative analysis showed\nthat including TOCO signals did not substantially improve prediction over EHG\nalone, highlighting the sufficiency of EHG for PTB detection. These results\ndemonstrate that combining denoising with domain relevant features can yield\nhighly accurate, robust, and clinically interpretable models, supporting the\ndevelopment of cost effective and accessible PTB prediction tools, particularly\nin low resource healthcare settings.", "published": "2025-09-09 06:37:31", "link": "http://arxiv.org/abs/2509.07432v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-Modal Intelligent Channel Modeling Framework for 6G-Enabled Networked Intelligent Systems", "abstract": "The design and technology development of 6G-enabled networked intelligent\nsystems needs an accurate real-time channel model as the cornerstone. However,\nwith the new requirements of 6G-enabled networked intelligent systems, the\nconventional channel modeling methods face many limitations. Fortunately, the\nmulti-modal sensors equipped on the intelligent agents bring timely\nopportunities, i.e., the intelligent integration and mutually beneficial\nmechanism between communications and multi-modal sensing could be investigated\nbased on the artificial intelligence (AI) technologies. In this case, the\nmapping relationship between physical environment and electromagnetic channel\ncould be explored via Synesthesia of Machines (SoM). This article presents a\nnovel multi-modal intelligent channel modeling (MMICM) framework for 6G-enabled\nnetworked intelligent systems, which establishes a nonlinear model between\nmulti-modal sensing and channel characteristics, including large-scale and\nsmall-scale channel characteristics. The architecture and features of proposed\nintelligent modeling framework are expounded and the key technologies involved\nare also analyzed. Finally, the system-engaged applications and potential\nresearch directions of MMICM framework are outlined.", "published": "2025-09-09 06:22:53", "link": "http://arxiv.org/abs/2509.07422v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Eye Movement Feature-Guided Signal De-Drifting in Electrooculography Systems", "abstract": "Electrooculography (EOG) is widely used for gaze tracking in Human-Robot\nCollaboration (HRC). However, baseline drift caused by low-frequency noise\nsignificantly impacts the accuracy of EOG signals, creating challenges for\nfurther sensor fusion. This paper presents an Eye Movement Feature-Guided\nDe-drift (FGD) method for mitigating drift artifacts in EOG signals. The\nproposed approach leverages active eye-movement feature recognition to\nreconstruct the feature-extracted EOG baseline and adaptively correct signal\ndrift while preserving the morphological integrity of the EOG waveform. The FGD\nis evaluated using both simulation data and real-world data, achieving a\nsignificant reduction in mean error. The average error is reduced to\n0.896{\\deg} in simulation, representing a 36.29% decrease, and to 1.033{\\deg}\nin real-world data, corresponding to a 26.53% reduction. Despite additional and\nunpredictable noise in real-world data, the proposed method consistently\noutperforms conventional de-drifting techniques, demonstrating its\neffectiveness in practical applications such as enhancing human performance\naugmentation.", "published": "2025-09-09 05:58:51", "link": "http://arxiv.org/abs/2509.07416v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP", "abstract": "Structured information extraction from scientific literature is crucial for\ncapturing core concepts and emerging trends in specialized fields. While\nexisting datasets aid model development, most focus on specific publication\nsections due to domain complexity and the high cost of annotating scientific\ntexts. To address this limitation, we introduce SciNLP - a specialized\nbenchmark for full-text entity and relation extraction in the Natural Language\nProcessing (NLP) domain. The dataset comprises 60 manually annotated full-text\nNLP publications, covering 7,072 entities and 1,826 relations. Compared to\nexisting research, SciNLP is the first dataset providing full-text annotations\nof entities and their relationships in the NLP domain. To validate the\neffectiveness of SciNLP, we conducted comparative experiments with similar\ndatasets and evaluated the performance of state-of-the-art supervised models on\nthis dataset. Results reveal varying extraction capabilities of existing models\nacross academic texts of different lengths. Cross-comparisons with existing\ndatasets show that SciNLP achieves significant performance improvements on\ncertain baseline models. Using models trained on SciNLP, we implemented\nautomatic construction of a fine-grained knowledge graph for the NLP domain.\nOur KG has an average node degree of 3.2 per entity, indicating rich semantic\ntopological information that enhances downstream applications. The dataset is\npublicly available at https://github.com/AKADDC/SciNLP.", "published": "2025-09-09 14:41:40", "link": "http://arxiv.org/abs/2509.07801v2", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models", "abstract": "For Relation Extraction (RE), the manual annotation of training data may be\nprohibitively expensive, since the sentences that contain the target relations\nin texts can be very scarce and difficult to find. It is therefore beneficial\nto develop an efficient method that can automatically extract training\ninstances from unlabeled texts for training RE models. Recently, large language\nmodels (LLMs) have been adopted in various natural language processing tasks,\nwith RE also benefiting from their advances. However, when leveraging LLMs for\nRE with predefined relation categories, two key challenges arise. First, in a\nmulti-class classification setting, LLMs often struggle to comprehensively\ncapture the semantics of every relation, leading to suboptimal results. Second,\nalthough employing binary classification for each relation individually can\nmitigate this issue, it introduces significant computational overhead,\nresulting in impractical time complexity for real-world applications.\nTherefore, this paper proposes a framework called M-BRe to extract training\ninstances from unlabeled texts for RE. It utilizes three modules to combine the\nadvantages of both of the above classification approaches: Relation Grouping,\nRelation Extraction, and Label Decision. Extensive experiments confirm its\nsuperior capability in discovering high-quality training samples from unlabeled\ntexts for RE.", "published": "2025-09-09 13:32:29", "link": "http://arxiv.org/abs/2509.07730v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?", "abstract": "Recently, the physical capabilities of (M)LLMs have garnered increasing\nattention. However, existing benchmarks for physics suffer from two major gaps:\nthey neither provide systematic and up-to-date coverage of real-world physics\ncompetitions such as physics Olympiads, nor enable direct performance\ncomparison with humans. To bridge these gaps, we present HiPhO, the first\nbenchmark dedicated to high school physics Olympiads with human-aligned\nevaluation. Specifically, HiPhO highlights three key innovations. (1)\nComprehensive Data: It compiles 13 latest Olympiad exams from 2024-2025,\nspanning both international and regional competitions, and covering mixed\nmodalities that encompass problems spanning text-only to diagram-based. (2)\nProfessional Evaluation: We adopt official marking schemes to perform\nfine-grained grading at both the answer and step level, fully aligned with\nhuman examiners to ensure high-quality and domain-specific evaluation. (3)\nComparison with Human Contestants: We assign gold, silver, and bronze medals to\nmodels based on official medal thresholds, thereby enabling direct comparison\nbetween (M)LLMs and human contestants. Our large-scale evaluation of 30\nstate-of-the-art (M)LLMs shows that: across 13 exams, open-source MLLMs mostly\nremain at or below the bronze level; open-source LLMs show promising progress\nwith occasional golds; closed-source reasoning MLLMs can achieve 6 to 12 gold\nmedals; and most models still have a significant gap from full marks. These\nresults highlight a substantial performance gap between open-source models and\ntop students, the strong physical reasoning capabilities of closed-source\nreasoning models, and the fact that there is still significant room for\nimprovement. HiPhO, as a rigorous, human-aligned, and Olympiad-focused\nbenchmark for advancing multimodal physical reasoning, is open-source and\navailable at https://github.com/SciYu/HiPhO.", "published": "2025-09-09 16:24:51", "link": "http://arxiv.org/abs/2509.07894v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Individual utilities of life satisfaction reveal inequality aversion unrelated to political alignment", "abstract": "How should well-being be prioritised in society, and what trade-offs are\npeople willing to make between fairness and personal well-being? We investigate\nthese questions using a stated preference experiment with a nationally\nrepresentative UK sample (n = 300), in which participants evaluated life\nsatisfaction outcomes for both themselves and others under conditions of\nuncertainty. Individual-level utility functions were estimated using an\nExpected Utility Maximisation (EUM) framework and tested for sensitivity to the\noverweighting of small probabilities, as characterised by Cumulative Prospect\nTheory (CPT). A majority of participants displayed concave (risk-averse)\nutility curves and showed stronger aversion to inequality in societal life\nsatisfaction outcomes than to personal risk. These preferences were unrelated\nto political alignment, suggesting a shared normative stance on fairness in\nwell-being that cuts across ideological boundaries. The results challenge use\nof average life satisfaction as a policy metric, and support the development of\nnonlinear utility-based alternatives that more accurately reflect collective\nhuman values. Implications for public policy, well-being measurement, and the\ndesign of value-aligned AI systems are discussed.", "published": "2025-09-09 14:30:24", "link": "http://arxiv.org/abs/2509.07793v2", "categories": ["econ.GN", "cs.AI", "cs.CY", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Towards explainable decision support using hybrid neural models for logistic terminal automation", "abstract": "The integration of Deep Learning (DL) in System Dynamics (SD) modeling for\ntransportation logistics offers significant advantages in scalability and\npredictive accuracy. However, these gains are often offset by the loss of\nexplainability and causal reliability $-$ key requirements in critical\ndecision-making systems. This paper presents a novel framework for\ninterpretable-by-design neural system dynamics modeling that synergizes DL with\ntechniques from Concept-Based Interpretability, Mechanistic Interpretability,\nand Causal Machine Learning. The proposed hybrid approach enables the\nconstruction of neural network models that operate on semantically meaningful\nand actionable variables, while retaining the causal grounding and transparency\ntypical of traditional SD models. The framework is conceived to be applied to\nreal-world case-studies from the EU-funded project AutoMoTIF, focusing on\ndata-driven decision support, automation, and optimization of multimodal\nlogistic terminals. We aim at showing how neuro-symbolic methods can bridge the\ngap between black-box predictive models and the need for critical decision\nsupport in complex dynamical environments within cyber-physical systems enabled\nby the industrial Internet-of-Things.", "published": "2025-09-09 10:41:08", "link": "http://arxiv.org/abs/2509.07577v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Nearest Neighbor Projection Removal Adversarial Training", "abstract": "Deep neural networks have exhibited impressive performance in image\nclassification tasks but remain vulnerable to adversarial examples. Standard\nadversarial training enhances robustness but typically fails to explicitly\naddress inter-class feature overlap, a significant contributor to adversarial\nsusceptibility. In this work, we introduce a novel adversarial training\nframework that actively mitigates inter-class proximity by projecting out\ninter-class dependencies from adversarial and clean samples in the feature\nspace. Specifically, our approach first identifies the nearest inter-class\nneighbors for each adversarial sample and subsequently removes projections onto\nthese neighbors to enforce stronger feature separability. Theoretically, we\ndemonstrate that our proposed logits correction reduces the Lipschitz constant\nof neural networks, thereby lowering the Rademacher complexity, which directly\ncontributes to improved generalization and robustness. Extensive experiments\nacross standard benchmarks including CIFAR-10, CIFAR-100, and SVHN show that\nour method demonstrates strong performance that is competitive with leading\nadversarial training techniques, highlighting significant achievements in both\nrobust and clean accuracy. Our findings reveal the importance of addressing\ninter-class feature proximity explicitly to bolster adversarial robustness in\nDNNs.", "published": "2025-09-09 12:38:41", "link": "http://arxiv.org/abs/2509.07673v2", "categories": ["cs.CV", "cs.LG", "68T45 (Primary), 68T10 (Secondary)", "I.5.4"], "primary_category": "cs.CV"}
{"title": "TextlessRAG: End-to-End Visual Document RAG by Speech Without Text", "abstract": "Document images encapsulate a wealth of knowledge, while the portability of\nspoken queries enables broader and flexible application scenarios. Yet, no\nprior work has explored knowledge base question answering over visual document\nimages with queries provided directly in speech. We propose TextlessRAG, the\nfirst end-to-end framework for speech-based question answering over large-scale\ndocument images. Unlike prior methods, TextlessRAG eliminates ASR, TTS and OCR,\ndirectly interpreting speech, retrieving relevant visual knowledge, and\ngenerating answers in a fully textless pipeline. To further boost performance,\nwe integrate a layout-aware reranking mechanism to refine retrieval.\nExperiments demonstrate substantial improvements in both efficiency and\naccuracy. To advance research in this direction, we also release the first\nbilingual speech--document RAG dataset, featuring Chinese and English voice\nqueries paired with multimodal document content. Both the dataset and our\npipeline will be made available at\nrepository:https://github.com/xiepeijinhit-hue/textlessrag", "published": "2025-09-09 09:16:25", "link": "http://arxiv.org/abs/2509.07538v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection", "abstract": "Identifying recurring patterns and rare events in large-scale signals is a\nfundamental challenge in fields such as astronomy, physical simulations, and\nbiomedical science. Convolutional Dictionary Learning (CDL) offers a powerful\nframework for modeling local structures in signals, but its use for detecting\nrare or anomalous events remains largely unexplored. In particular, CDL faces\ntwo key challenges in this setting: high computational cost and sensitivity to\nartifacts and outliers. In this paper, we introduce RoseCDL, a scalable and\nrobust CDL algorithm designed for unsupervised rare event detection in long\nsignals. RoseCDL combines stochastic windowing for efficient training on large\ndatasets with inline outlier detection to enhance robustness and isolate\nanomalous patterns. This reframes CDL as a practical tool for event discovery\nand characterization in real-world signals, extending its role beyond\ntraditional tasks like compression or denoising.", "published": "2025-09-09 08:58:31", "link": "http://arxiv.org/abs/2509.07523v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RINO: Renormalization Group Invariance with No Labels", "abstract": "A common challenge with supervised machine learning (ML) in high energy\nphysics (HEP) is the reliance on simulations for labeled data, which can often\nmismodel the underlying collision or detector response. To help mitigate this\nproblem of domain shift, we propose RINO (Renormalization Group Invariance with\nNo Labels), a self-supervised learning approach that can instead pretrain\nmodels directly on collision data, learning embeddings invariant to\nrenormalization group flow scales. In this work, we pretrain a\ntransformer-based model on jets originating from quantum chromodynamic (QCD)\ninteractions from the JetClass dataset, emulating real QCD-dominated\nexperimental data, and then finetune on the JetNet dataset -- emulating\nsimulations -- for the task of identifying jets originating from top quark\ndecays. RINO demonstrates improved generalization from the JetNet training data\nto JetClass data compared to supervised training on JetNet from scratch,\ndemonstrating the potential for RINO pretraining on real collision data\nfollowed by fine-tuning on small, high-quality MC datasets, to improve the\nrobustness of ML models in HEP.", "published": "2025-09-09 08:05:35", "link": "http://arxiv.org/abs/2509.07486v2", "categories": ["hep-ex", "cs.LG"], "primary_category": "hep-ex"}
{"title": "XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols", "abstract": "Structured prompting with XML tags has emerged as an effective way to steer\nlarge language models (LLMs) toward parseable, schema-adherent outputs in\nreal-world systems. We develop a logic-first treatment of XML prompting that\nunifies (i) grammar-constrained decoding, (ii) fixed-point semantics over\nlattices of hierarchical prompts, and (iii) convergent human-AI interaction\nloops. We formalize a complete lattice of XML trees under a refinement order\nand prove that monotone prompt-to-prompt operators admit least fixed points\n(Knaster-Tarski) that characterize steady-state protocols; under a task-aware\ncontraction metric on trees, we further prove Banach-style convergence of\niterative guidance. We instantiate these results with context-free grammars\n(CFGs) for XML schemas and show how constrained decoding guarantees\nwell-formedness while preserving task performance. A set of multi-layer\nhuman-AI interaction recipes demonstrates practical deployment patterns,\nincluding multi-pass \"plan $\\to$ verify $\\to$ revise\" routines and agentic tool\nuse. We provide mathematically complete proofs and tie our framework to recent\nadvances in grammar-aligned decoding, chain-of-verification, and programmatic\nprompting.", "published": "2025-09-09 23:03:53", "link": "http://arxiv.org/abs/2509.08182v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "03B70, 06B23, 47H10, 68T27, 68T50", "I.2.7; I.2.8; F.4.1; F.4.3; H.5.2"], "primary_category": "cs.PL"}
{"title": "Verbalized Algorithms", "abstract": "Instead of querying LLMs in a one-shot manner and hoping to get the right\nanswer for a reasoning task, we propose a paradigm we call \\emph{verbalized\nalgorithms} (VAs), which leverage classical algorithms with established\ntheoretical understanding. VAs decompose a task into simple elementary\noperations on natural language strings that they should be able to answer\nreliably, and limit the scope of LLMs to only those simple tasks. For example,\nfor sorting a series of natural language strings, \\emph{verbalized sorting}\nuses an LLM as a binary comparison oracle in a known and well-analyzed sorting\nalgorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of\nthis approach on sorting and clustering tasks.", "published": "2025-09-09 21:14:44", "link": "http://arxiv.org/abs/2509.08150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bias after Prompting: Persistent Discrimination in Large Language Models", "abstract": "A dangerous assumption that can be made from prior work on the bias transfer\nhypothesis (BTH) is that biases do not transfer from pre-trained large language\nmodels (LLMs) to adapted models. We invalidate this assumption by studying the\nBTH in causal models under prompt adaptations, as prompting is an extremely\npopular and accessible adaptation strategy used in real-world applications. In\ncontrast to prior work, we find that biases can transfer through prompting and\nthat popular prompt-based mitigation methods do not consistently prevent biases\nfrom transferring. Specifically, the correlation between intrinsic biases and\nthose after prompt adaptation remain moderate to strong across demographics and\ntasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age\n(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we\nfind that biases remain strongly correlated when varying few-shot composition\nparameters, such as sample size, stereotypical content, occupational\ndistribution and representational balance (rho >= 0.90). We evaluate several\nprompt-based debiasing strategies and find that different approaches have\ndistinct strengths, but none consistently reduce bias transfer across models,\ntasks or demographics. These results demonstrate that correcting bias, and\npotentially improving reasoning ability, in intrinsic models may prevent\npropagation of biases to downstream tasks.", "published": "2025-09-09 20:59:50", "link": "http://arxiv.org/abs/2509.08146v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion", "abstract": "Large language models excel in English but still struggle with complex\nreasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder\nmethods such as LangBridge and MindMerger raise accuracy on mid and\nhigh-resource languages, yet they leave a large gap on LRLs. We present MERLIN,\na two-stage model-stacking framework that applies a curriculum learning\nstrategy -- from general bilingual bitext to task-specific data -- and adapts\nonly a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves\nexact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.\nIt also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),\ndemonstrating effectiveness across both low and high-resource settings.", "published": "2025-09-09 19:32:05", "link": "http://arxiv.org/abs/2509.08105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression", "abstract": "Converging evidence suggests that systems of semantic categories across human\nlanguages achieve near-optimal compression via the Information Bottleneck (IB)\ncomplexity-accuracy principle. Large language models (LLMs) are not trained for\nthis objective, which raises the question: are LLMs capable of evolving\nefficient human-like semantic systems? To address this question, we focus on\nthe domain of color as a key testbed of cognitive theories of categorization\nand replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two\ninfluential human behavioral studies. First, we conduct an English color-naming\nstudy, showing that Gemini aligns well with the naming patterns of native\nEnglish speakers and achieves a significantly high IB-efficiency score, while\nLlama exhibits an efficient but lower complexity system compared to English.\nSecond, to test whether LLMs simply mimic patterns in their training data or\nactually exhibit a human-like inductive bias toward IB-efficiency, we simulate\ncultural evolution of pseudo color-naming systems in LLMs via iterated\nin-context language learning. We find that akin to humans, LLMs iteratively\nrestructure initially random systems towards greater IB-efficiency and\nincreased alignment with patterns observed across the world's languages. These\nfindings demonstrate that LLMs are capable of evolving perceptually grounded,\nhuman-like semantic systems, driven by the same fundamental principle that\ngoverns semantic efficiency across human languages.", "published": "2025-09-09 19:00:10", "link": "http://arxiv.org/abs/2509.08093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models", "abstract": "Large language models (LLMs) are increasingly integrated into our daily lives\nand personalized. However, LLM personalization might also increase unintended\nside effects. Recent work suggests that persona prompting can lead models to\nfalsely refuse user requests. However, no work has fully quantified the extent\nof this issue. To address this gap, we measure the impact of 15\nsociodemographic personas (based on gender, race, religion, and disability) on\nfalse refusal. To control for other factors, we also test 16 different models,\n3 tasks (Natural Language Inference, politeness, and offensiveness\nclassification), and nine prompt paraphrases. We propose a Monte Carlo-based\nmethod to quantify this issue in a sample-efficient manner. Our results show\nthat as models become more capable, personas impact the refusal rate less and\nless. Certain sociodemographic personas increase false refusal in some models,\nwhich suggests underlying biases in the alignment strategies or safety\nmechanisms. However, we find that the model choice and task significantly\ninfluence false refusals, especially in sensitive content tasks. Our findings\nsuggest that persona effects have been overestimated, and might be due to other\nfactors.", "published": "2025-09-09 18:30:01", "link": "http://arxiv.org/abs/2509.08075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery", "abstract": "Scientific literature is growing exponentially, creating a critical\nbottleneck for researchers to efficiently synthesize knowledge. While\ngeneral-purpose Large Language Models (LLMs) show potential in text processing,\nthey often fail to capture scientific domain-specific nuances (e.g., technical\njargon, methodological rigor) and struggle with complex scientific tasks,\nlimiting their utility for interdisciplinary research. To address these gaps,\nthis paper presents SciGPT, a domain-adapted foundation model for scientific\nliterature understanding and ScienceBench, an open source benchmark tailored to\nevaluate scientific LLMs.\n  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:\n(1) low-cost domain distillation via a two-stage pipeline to balance\nperformance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention\nmechanism that cuts memory consumption by 55\\% for 32,000-token long-document\nreasoning; and (3) knowledge-aware adaptation integrating domain ontologies to\nbridge interdisciplinary knowledge gaps.\n  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in\ncore scientific tasks including sequence labeling, generation, and inference.\nIt also exhibits strong robustness in unseen scientific tasks, validating its\npotential to facilitate AI-augmented scientific discovery.", "published": "2025-09-09 16:09:19", "link": "http://arxiv.org/abs/2509.08032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment", "abstract": "This paper presents the methodologies and results of the NOWJ team's\nparticipation across all five tasks at the COLIEE 2025 competition, emphasizing\nadvancements in the Legal Case Entailment task (Task 2). Our comprehensive\napproach systematically integrates pre-ranking models (BM25, BERT, monoT5),\nembedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large\nLanguage Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance\nscoring, and contextual re-ranking. Specifically, in Task 2, our two-stage\nretrieval system combined lexical-semantic filtering with contextualized LLM\nanalysis, achieving first place with an F1 score of 0.3195. Additionally, in\nother tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal\nTextual Entailment, and Legal Judgment Prediction--we demonstrated robust\nperformance through carefully engineered ensembles and effective prompt-based\nreasoning strategies. Our findings highlight the potential of hybrid models\nintegrating traditional IR techniques with contemporary generative models,\nproviding a valuable reference for future advancements in legal information\nprocessing.", "published": "2025-09-09 12:05:52", "link": "http://arxiv.org/abs/2509.08025v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values", "abstract": "The alignment of large language models (LLMs) with human values is critical\nfor their safe and effective deployment across diverse user populations.\nHowever, existing benchmarks often neglect cultural and demographic diversity,\nleading to limited understanding of how value alignment generalizes globally.\nIn this work, we introduce MVPBench, a novel benchmark that systematically\nevaluates LLMs' alignment with multi-dimensional human value preferences across\n75 countries. MVPBench contains 24,020 high-quality instances annotated with\nfine-grained value labels, personalized questions, and rich demographic\nmetadata, making it the most comprehensive resource of its kind to date. Using\nMVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,\nrevealing substantial disparities in alignment performance across geographic\nand demographic lines. We further demonstrate that lightweight fine-tuning\nmethods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization\n(DPO), can significantly enhance value alignment in both in-domain and\nout-of-domain settings. Our findings underscore the necessity for\npopulation-aware alignment evaluation and provide actionable insights for\nbuilding culturally adaptive and value-sensitive LLMs. MVPBench serves as a\npractical foundation for future research on global alignment, personalized\nvalue modeling, and equitable AI development.", "published": "2025-09-09 09:25:08", "link": "http://arxiv.org/abs/2509.08022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lifetime-Aware Design of Item-Level Intelligence", "abstract": "We present FlexiFlow, a lifetime-aware design framework for item-level\nintelligence (ILI) where computation is integrated directly into disposable\nproducts like food packaging and medical patches. Our framework leverages\nnatively flexible electronics which offer significantly lower costs than\nsilicon but are limited to kHz speeds and several thousands of gates. Our\ninsight is that unlike traditional computing with more uniform deployment\npatterns, ILI applications exhibit 1000X variation in operational lifetime,\nfundamentally changing optimal architectural design decisions when considering\ntrillion-item deployment scales. To enable holistic design and optimization, we\nmodel the trade-offs between embodied carbon footprint and operational carbon\nfootprint based on application-specific lifetimes. The framework includes: (1)\nFlexiBench, a workload suite targeting sustainability applications from\nspoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V\ncores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy\nefficiency per workload execution; and (3) a carbon-aware model that selects\noptimal architectures based on deployment characteristics. We show that\nlifetime-aware microarchitectural design can reduce carbon footprint by 1.62X,\nwhile algorithmic decisions can reduce carbon footprint by 14.5X. We validate\nour approach through the first tape-out using a PDK for flexible electronics\nwith fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables\nexploration of computing at the Extreme Edge where conventional design\nmethodologies must be reevaluated to account for new constraints and\nconsiderations.", "published": "2025-09-09 23:53:46", "link": "http://arxiv.org/abs/2509.08193v1", "categories": ["cs.AR", "cs.AI", "cs.ET"], "primary_category": "cs.AR"}
{"title": "Multi-Label Transfer Learning in Non-Stationary Data Streams", "abstract": "Label concepts in multi-label data streams often experience drift in\nnon-stationary environments, either independently or in relation to other\nlabels. Transferring knowledge between related labels can accelerate\nadaptation, yet research on multi-label transfer learning for data streams\nremains limited. To address this, we propose two novel transfer learning\nmethods: BR-MARLENE leverages knowledge from different labels in both source\nand target streams for multi-label classification; BRPW-MARLENE builds on this\nby explicitly modelling and transferring pairwise label dependencies to enhance\nlearning performance. Comprehensive experiments show that both methods\noutperform state-of-the-art multi-label stream approaches in non-stationary\nenvironments, demonstrating the effectiveness of inter-label knowledge transfer\nfor improved predictive performance.", "published": "2025-09-09 23:01:20", "link": "http://arxiv.org/abs/2509.08181v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Quadrotor Navigation using Reinforcement Learning with Privileged Information", "abstract": "This paper presents a reinforcement learning-based quadrotor navigation\nmethod that leverages efficient differentiable simulation, novel loss\nfunctions, and privileged information to navigate around large obstacles. Prior\nlearning-based methods perform well in scenes that exhibit narrow obstacles,\nbut struggle when the goal location is blocked by large walls or terrain. In\ncontrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged\ninformation and a yaw alignment loss to guide the robot around large obstacles.\nThe policy is evaluated in photo-realistic simulation environments containing\nlarge obstacles, sharp corners, and dead-ends. Our approach achieves an 86%\nsuccess rate and outperforms baseline strategies by 34%. We deploy the policy\nonboard a custom quadrotor in outdoor cluttered environments both during the\nday and night. The policy is validated across 20 flights, covering 589 meters\nwithout collisions at speeds up to 4 m/s.", "published": "2025-09-09 22:56:35", "link": "http://arxiv.org/abs/2509.08177v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary Environments", "abstract": "Concept drift is a major problem in online learning due to its impact on the\npredictive performance of data stream mining systems. Recent studies have\nstarted exploring data streams from different sources as a strategy to tackle\nconcept drift in a given target domain. These approaches make the assumption\nthat at least one of the source models represents a concept similar to the\ntarget concept, which may not hold in many real-world scenarios. In this paper,\nwe propose a novel approach called Multi-source mApping with tRansfer LearnIng\nfor Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge\nfrom multiple data sources in non-stationary environments even when source and\ntarget concepts do not match. This is achieved by projecting the target concept\nto the space of each source concept, enabling multiple source sub-classifiers\nto contribute towards the prediction of the target concept as part of an\nensemble. Experiments on several synthetic and real-world datasets show that\nMARLINE was more accurate than several state-of-the-art data stream learning\napproaches.", "published": "2025-09-09 22:51:31", "link": "http://arxiv.org/abs/2509.08176v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Diffusion-Guided Multi-Arm Motion Planning", "abstract": "Multi-arm motion planning is fundamental for enabling arms to complete\ncomplex long-horizon tasks in shared spaces efficiently but current methods\nstruggle with scalability due to exponential state-space growth and reliance on\nlarge training datasets for learned models. Inspired by Multi-Agent Path\nFinding (MAPF), which decomposes planning into single-agent problems coupled\nwith collision resolution, we propose a novel diffusion-guided multi-arm\nplanner (DG-MAP) that enhances scalability of learning-based models while\nreducing their reliance on massive multi-arm datasets. Recognizing that\ncollisions are primarily pairwise, we train two conditional diffusion models,\none to generate feasible single-arm trajectories, and a second, to model the\ndual-arm dynamics required for effective pairwise collision resolution. By\nintegrating these specialized generative models within a MAPF-inspired\nstructured decomposition, our planner efficiently scales to larger number of\narms. Evaluations against alternative learning-based methods across various\nteam sizes demonstrate our method's effectiveness and practical applicability.\nProject website can be found at https://diff-mapf-mers.csail.mit.edu", "published": "2025-09-09 21:41:23", "link": "http://arxiv.org/abs/2509.08160v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation", "abstract": "This paper presents a methodology to predict metric depth from monocular RGB\nimages and an inertial measurement unit (IMU). To enable collision avoidance\nduring autonomous flight, prior works either leverage heavy sensors (e.g.,\nLiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of\nmonocular metric depth estimation methods. In contrast, we propose several\nlightweight zero-shot rescaling strategies to obtain metric depth from relative\ndepth estimates via the sparse 3D feature map created using a visual-inertial\nnavigation system. These strategies are compared for their accuracy in diverse\nsimulation environments. The best performing approach, which leverages\nmonotonic spline fitting, is deployed in the real-world on a\ncompute-constrained quadrotor. We obtain on-board metric depth estimates at 15\nHz and demonstrate successful collision avoidance after integrating the\nproposed method with a motion primitives-based planner.", "published": "2025-09-09 21:39:13", "link": "http://arxiv.org/abs/2509.08159v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation", "abstract": "Safe navigation is essential for autonomous systems operating in hazardous\nenvironments, especially when multiple agents must coordinate using just visual\ninputs over extended time horizons. Traditional planning methods excel at\nsolving long-horizon tasks but rely on predefined distance metrics, while safe\nReinforcement Learning (RL) can learn complex behaviors using high-dimensional\ninputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work\ncombined these paradigms by leveraging goal-conditioned RL (GCRL) to build an\nintermediate graph from replay buffer states, pruning unsafe edges, and using\nConflict-Based Search (CBS) for multi-agent path planning. Although effective,\nthis graph-pruning approach can be overly conservative, limiting mission\nefficiency by precluding missions that must traverse high-risk regions. To\naddress this limitation, we propose RB-CBS, a novel extension to CBS that\ndynamically allocates and adjusts user-specified risk bound ($\\Delta$) across\nagents to flexibly trade off safety and speed. Our improved planner ensures\nthat each agent receives a local risk budget ($\\delta$) enabling more efficient\nnavigation while still respecting overall safety constraints. Experimental\nresults demonstrate that this iterative risk-allocation framework yields\nsuperior performance in complex environments, allowing multiple agents to find\ncollision-free paths within the user-specified $\\Delta$.", "published": "2025-09-09 21:35:55", "link": "http://arxiv.org/abs/2509.08157v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI", "abstract": "Accurate trustworthiness evaluation of potential collaborating devices is\nessential for the effective execution of complex computing tasks. This\nevaluation process involves collecting diverse trust-related data from\npotential collaborators, including historical performance and available\nresources, for collaborator selection. However, when each task owner\nindependently assesses all collaborators' trustworthiness, frequent data\nexchange, complex reasoning, and dynamic situation changes can result in\nsignificant overhead and deteriorated trust evaluation. To overcome these\nchallenges, we propose a task-specific trust semantics distillation (2TSD)\nmodel based on a large AI model (LAM)-driven teacher-student agent\narchitecture. The teacher agent is deployed on a server with powerful\ncomputational capabilities and an augmented memory module dedicated to\nmultidimensional trust-related data collection, task-specific trust semantics\nextraction, and task-collaborator matching analysis. Upon receiving\ntask-specific requests from device-side student agents, the teacher agent\ntransfers the trust semantics of potential collaborators to the student agents,\nenabling rapid and accurate collaborator selection. Experimental results\ndemonstrate that the proposed 2TSD model can reduce collaborator evaluation\ntime, decrease device resource consumption, and improve the accuracy of\ncollaborator selection.", "published": "2025-09-09 21:18:31", "link": "http://arxiv.org/abs/2509.08151v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital", "abstract": "This paper presents a framework for predicting rare, high-impact outcomes by\nintegrating large language models (LLMs) with a multi-model machine learning\n(ML) architecture. The approach combines the predictive strength of black-box\nmodels with the interpretability required for reliable decision-making. We use\nLLM-powered feature engineering to extract and synthesize complex signals from\nunstructured data, which are then processed within a layered ensemble of models\nincluding XGBoost, Random Forest, and Linear Regression. The ensemble first\nproduces a continuous estimate of success likelihood, which is then thresholded\nto produce a binary rare-event prediction. We apply this framework to the\ndomain of Venture Capital (VC), where investors must evaluate startups with\nlimited and noisy early-stage data. The empirical results show strong\nperformance: the model achieves precision between 9.8X and 11.1X the random\nclassifier baseline in three independent test subsets. Feature sensitivity\nanalysis further reveals interpretable success drivers: the startup's category\nlist accounts for 15.6% of predictive influence, followed by the number of\nfounders, while education level and domain expertise contribute smaller yet\nconsistent effects.", "published": "2025-09-09 20:46:54", "link": "http://arxiv.org/abs/2509.08140v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography", "abstract": "Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart\nconditions; however, the effectiveness of artificial intelligence (AI)-based\nECG analysis is often hindered by the limited availability of labeled data.\nSelf-supervised learning (SSL) can address this by leveraging large-scale\nunlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning\nRepresentation for ECG), a physiology-aware contrastive learning framework that\nincorporates domain-specific priors to enhance the generalizability and\nclinical relevance of ECG-based arrhythmia classification. Methods: During\npretraining, PhysioCLR learns to bring together embeddings of samples that\nshare similar clinically relevant features while pushing apart those that are\ndissimilar. Unlike existing methods, our method integrates ECG physiological\nsimilarity cues into contrastive learning, promoting the learning of clinically\nmeaningful representations. Additionally, we introduce ECG- specific\naugmentations that preserve the ECG category post augmentation and propose a\nhybrid loss function to further refine the quality of learned representations.\nResults: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia,\nfor multilabel ECG diagnoses, as well as a private ICU dataset labeled for\nbinary classification. Across the Chapman, Georgia, and private cohorts,\nPhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline,\nunderscoring its robust cross-dataset generalization. Conclusion: By embedding\nphysiological knowledge into contrastive learning, PhysioCLR enables the model\nto learn clinically meaningful and transferable ECG eatures. Significance:\nPhysioCLR demonstrates the potential of physiology-informed SSL to offer a\npromising path toward more effective and label-efficient ECG diagnostics.", "published": "2025-09-09 19:44:50", "link": "http://arxiv.org/abs/2509.08116v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction", "abstract": "Training deep learning models for point cloud prediction tasks such as shape\ncompletion and generation depends critically on loss functions that measure\ndiscrepancies between predicted and ground-truth point sets. Commonly used\nfunctions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on\nnearest-neighbor assignments, which often induce many-to-one correspondences,\nleading to point congestion in dense regions and poor coverage in sparse\nregions. These losses also involve non-differentiable operations due to index\nselection, which may affect gradient-based optimization. Earth Mover Distance\n(EMD) enforces one-to-one correspondences and captures structural similarity\nmore effectively, but its cubic computational complexity limits its practical\nuse. We propose the Adaptive Probabilistic Matching Loss (APML), a fully\ndifferentiable approximation of one-to-one matching that leverages Sinkhorn\niterations on a temperature-scaled similarity matrix derived from pairwise\ndistances. We analytically compute the temperature to guarantee a minimum\nassignment probability, eliminating manual tuning. APML achieves near-quadratic\nruntime, comparable to Chamfer-based losses, and avoids non-differentiable\noperations. When integrated into state-of-the-art architectures (PoinTr, PCN,\nFoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)\nthat generates 3D human point clouds from WiFi CSI measurements, APM loss\nyields faster convergence, superior spatial distribution, especially in\nlow-density regions, and improved or on-par quantitative performance without\nadditional hyperparameter search. The code is available at:\nhttps://github.com/apm-loss/apml.", "published": "2025-09-09 19:31:06", "link": "http://arxiv.org/abs/2509.08104v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion", "abstract": "Obstacle avoidance is a critical component of the navigation stack required\nfor mobile robots to operate effectively in complex and unknown environments.\nIn this research, three end-to-end Convolutional Neural Networks (CNNs) were\ntrained and evaluated offline and deployed on a differential-drive mobile robot\nfor real-time obstacle avoidance to generate low-level steering commands from\nsynchronized color and depth images acquired by an Intel RealSense D415 RGB-D\ncamera in diverse environments. Offline evaluation showed that the NetConEmb\nmodel achieved the best performance with a notably low MedAE of $0.58 \\times\n10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture adopted in this\nstudy, which reduces the number of trainable parameters by approximately 25\\%\nand converges faster, produced comparable results with an RMSE of $21.68 \\times\n10^{-3}$ rad/s, close to the $21.42 \\times 10^{-3}$ rad/s obtained by\nNetConEmb. Real-time navigation further confirmed NetConEmb's robustness,\nachieving a 100\\% success rate in both known and unknown environments, while\nNetEmb and NetGated succeeded only in navigating the known environment.", "published": "2025-09-09 19:05:37", "link": "http://arxiv.org/abs/2509.08095v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "EnvX: Agentize Everything with Agentic AI", "abstract": "The widespread availability of open-source repositories has led to a vast\ncollection of reusable software components, yet their utilization remains\nmanual, error-prone, and disconnected. Developers must navigate documentation,\nunderstand APIs, and write integration code, creating significant barriers to\nefficient software reuse. To address this, we present EnvX, a framework that\nleverages Agentic AI to agentize GitHub repositories, transforming them into\nintelligent, autonomous agents capable of natural language interaction and\ninter-agent collaboration. Unlike existing approaches that treat repositories\nas static code resources, EnvX reimagines them as active agents through a\nthree-phase process: (1) TODO-guided environment initialization, which sets up\nthe necessary dependencies, data, and validation datasets; (2) human-aligned\nagentic automation, allowing repository-specific agents to autonomously perform\nreal-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple\nagents to collaborate. By combining large language model capabilities with\nstructured tool integration, EnvX automates not just code generation, but the\nentire process of understanding, initializing, and operationalizing repository\nfunctionality. We evaluate EnvX on the GitTaskBench benchmark, using 18\nrepositories across domains such as image processing, speech recognition,\ndocument analysis, and video manipulation. Our results show that EnvX achieves\na 74.07% execution completion rate and 51.85% task pass rate, outperforming\nexisting frameworks. Case studies further demonstrate EnvX's ability to enable\nmulti-repository collaboration via the A2A protocol. This work marks a shift\nfrom treating repositories as passive code resources to intelligent,\ninteractive agents, fostering greater accessibility and collaboration within\nthe open-source ecosystem.", "published": "2025-09-09 18:51:36", "link": "http://arxiv.org/abs/2509.08088v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Performance Assessment Strategies for Generative AI Applications in Healthcare", "abstract": "Generative artificial intelligence (GenAI) represent an emerging paradigm\nwithin artificial intelligence, with applications throughout the medical\nenterprise. Assessing GenAI applications necessitates a comprehensive\nunderstanding of the clinical task and awareness of the variability in\nperformance when implemented in actual clinical environments. Presently, a\nprevalent method for evaluating the performance of generative models relies on\nquantitative benchmarks. Such benchmarks have limitations and may suffer from\ntrain-to-the-test overfitting, optimizing performance for a specified test set\nat the cost of generalizability across other task and data distributions.\nEvaluation strategies leveraging human expertise and utilizing cost-effective\ncomputational models as evaluators are gaining interest. We discuss current\nstate-of-the-art methodologies for assessing the performance of GenAI\napplications in healthcare and medical devices.", "published": "2025-09-09 18:50:26", "link": "http://arxiv.org/abs/2509.08087v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "JEL: A Novel Model Linking Knowledge Graph entities to News Mentions", "abstract": "We present JEL, a novel computationally efficient end-to-end multi-neural\nnetwork based entity linking model, which beats current state-of-art model.\nKnowledge Graphs have emerged as a compelling abstraction for capturing\ncritical relationships among the entities of interest and integrating data from\nmultiple heterogeneous sources. A core problem in leveraging a knowledge graph\nis linking its entities to the mentions (e.g., people, company names) that are\nencountered in textual sources (e.g., news, blogs., etc) correctly, since there\nare thousands of entities to consider for each mention. This task of linking\nmentions and entities is referred as Entity Linking (EL). It is a fundamental\ntask in natural language processing and is beneficial in various uses cases,\nsuch as building a New Analytics platform. News Analytics, in JPMorgan, is an\nessential task that benefits multiple groups across the firm. According to a\nsurvey conducted by the Innovation Digital team 1 , around 25 teams across the\nfirm are actively looking for news analytics solutions, and more than \\$2\nmillion is being spent annually on external vendor costs. Entity linking is\ncritical for bridging unstructured news text with knowledge graphs, enabling\nusers access to vast amounts of curated data in a knowledge graph and\ndramatically facilitating their daily work.", "published": "2025-09-09 18:50:18", "link": "http://arxiv.org/abs/2509.08086v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "How Far Are We from True Unlearnability?", "abstract": "High-quality data plays an indispensable role in the era of large models, but\nthe use of unauthorized data for model training greatly damages the interests\nof data owners. To overcome this threat, several unlearnable methods have been\nproposed, which generate unlearnable examples (UEs) by compromising the\ntraining availability of data. Clearly, due to unknown training purposes and\nthe powerful representation learning capabilities of existing models, these\ndata are expected to be unlearnable for models across multiple tasks, i.e.,\nthey will not help improve the model's performance. However, unexpectedly, we\nfind that on the multi-task dataset Taskonomy, UEs still perform well in tasks\nsuch as semantic segmentation, failing to exhibit cross-task unlearnability.\nThis phenomenon leads us to question: How far are we from attaining truly\nunlearnable examples? We attempt to answer this question from the perspective\nof model optimization. To this end, we observe the difference in the\nconvergence process between clean and poisoned models using a simple model\narchitecture. Subsequently, from the loss landscape we find that only a part of\nthe critical parameter optimization paths show significant differences,\nimplying a close relationship between the loss landscape and unlearnability.\nConsequently, we employ the loss landscape to explain the underlying reasons\nfor UEs and propose Sharpness-Aware Learnability (SAL) to quantify the\nunlearnability of parameters based on this explanation. Furthermore, we propose\nan Unlearnable Distance (UD) to measure the unlearnability of data based on the\nSAL distribution of parameters in clean and poisoned models. Finally, we\nconduct benchmark tests on mainstream unlearnable methods using the proposed\nUD, aiming to promote community awareness of the capability boundaries of\nexisting unlearnable methods.", "published": "2025-09-09 18:01:10", "link": "http://arxiv.org/abs/2509.08058v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery", "abstract": "This work presents a new dataset for the Martian digital elevation model\nprediction task, ready for machine learning applications called MCTED. The\ndataset has been generated using a comprehensive pipeline designed to process\nhigh-resolution Mars orthoimage and DEM pairs from Day et al., yielding a\ndataset consisting of 80,898 data samples. The source images are data gathered\nby the Mars Reconnaissance Orbiter using the CTX instrument, providing a very\ndiverse and comprehensive coverage of the Martian surface. Given the complexity\nof the processing pipelines used in large-scale DEMs, there are often artefacts\nand missing data points in the original data, for which we developed tools to\nsolve or mitigate their impact. We divide the processed samples into training\nand validation splits, ensuring samples in both splits cover no mutual areas to\navoid data leakage. Every sample in the dataset is represented by the optical\nimage patch, DEM patch, and two mask patches, indicating values that were\noriginally missing or were altered by us. This allows future users of the\ndataset to handle altered elevation regions as they please. We provide\nstatistical insights of the generated dataset, including the spatial\ndistribution of samples, the distributions of elevation values, slopes and\nmore. Finally, we train a small U-Net architecture on the MCTED dataset and\ncompare its performance to a monocular depth estimation foundation model,\nDepthAnythingV2, on the task of elevation prediction. We find that even a very\nsmall architecture trained on this dataset specifically, beats a zero-shot\nperformance of a depth estimation foundation model like DepthAnythingV2. We\nmake the dataset and code used for its generation completely open source in\npublic repositories.", "published": "2025-09-09 13:14:49", "link": "http://arxiv.org/abs/2509.08027v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles", "abstract": "This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep\ntransfer learning model for detecting multiple vehicles in UAV images. It\ncombines three pre-trained Faster R-CNN feature extractor models (InceptionV3,\nResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,\nNa\\\"ive Bayes), resulting in 15 different base learners. These are aggregated\nvia weighted averaging to classify regions as Car, Van, Truck, Bus, or\nbackground. Hyperparameters are optimized with the whale optimization algorithm\nto balance accuracy, precision, and recall. Implemented in MATLAB R2020b with\nparallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV\ndataset.", "published": "2025-09-09 13:03:12", "link": "http://arxiv.org/abs/2509.08026v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An Algorithmic Upper Bound for Permanents via a Permanental Schur Inequality", "abstract": "Computing the permanent of a non-negative matrix is a computationally\nchallenging, \\#P-complete problem with wide-ranging applications. We introduce\na novel permanental analogue of Schur's determinant formula, leveraging a newly\ndefined \\emph{permanental inverse}. Building on this, we introduce an\niterative, deterministic procedure called the \\emph{permanent process},\nanalogous to Gaussian elimination, which yields constructive and\nalgorithmically computable upper bounds on the permanent. Our framework\nprovides particularly strong guarantees for matrices exhibiting approximate\ndiagonal dominance-like properties, thereby offering new theoretical and\ncomputational tools for analyzing and bounding permanents.", "published": "2025-09-09 19:59:21", "link": "http://arxiv.org/abs/2509.08121v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Optimizing information flow in Gene Regulatory Networks: a geometric perspective", "abstract": "The dynamics of gene regulatory networks is governed by the interaction\nbetween deterministic biochemical reactions and molecular noise. To understand\nhow gene regulatory networks process information during cell state transitions,\nwe study stochastic dynamics derived from a Boolean network model via its\nrepresentation on the parameter space of Gaussian distributions, equipped with\nthe Fisher information metric. This reformulation reveals that the trajectories\nof optimal information transfer are gradient flows of the Kullback-Leibler\ndivergence. We demonstrate that the most efficient dynamics require isotropic\ndecay rates across all nodes and that the noise intensity quantitatively\ndetermines the potential differentiation between the initial and final states.\nFurthermore, we show that paths minimizing biological cost correspond to metric\ngeodesics that require noise suppression, leading to biologically irrelevant\ndeterministic dynamics. Our approach frames noise and decay rates as\nfundamental control parameters for cellular differentiation, providing a\ngeometric principle for the analysis and design of synthetic networks.", "published": "2025-09-09 22:02:40", "link": "http://arxiv.org/abs/2509.08167v1", "categories": ["q-bio.MN", "cs.IT", "math.IT", "37M25, 53Z10, 53B12, 92C42,"], "primary_category": "q-bio.MN"}
{"title": "SCA-LLM: Spectral-Attentive Channel Prediction with Large Language Models in MIMO-OFDM", "abstract": "In recent years, the success of large language models (LLMs) has inspired\ngrowing interest in exploring their potential applications in wireless\ncommunications, especially for channel prediction tasks. However, directly\napplying LLMs to channel prediction faces a domain mismatch issue stemming from\ntheir text-based pre-training. To mitigate this, the ``adapter + LLM\" paradigm\nhas emerged, where an adapter is designed to bridge the domain gap between the\nchannel state information (CSI) data and LLMs. While showing initial success,\nexisting adapters may not fully exploit the potential of this paradigm. To\naddress this limitation, this work provides a key insight that learning\nrepresentations from the spectral components of CSI features can more\neffectively help bridge the domain gap. Accordingly, we propose a\nspectral-attentive framework, named SCA-LLM, for channel prediction in\nmultiple-input multiple-output orthogonal frequency division multiplexing\n(MIMO-OFDM) systems. Specifically, its novel adapter can capture finer spectral\ndetails and better adapt the LLM for channel prediction than previous methods.\nExtensive simulations show that SCA-LLM achieves state-of-the-art prediction\nperformance and strong generalization, yielding up to $-2.4~\\text{dB}$\nnormalized mean squared error (NMSE) advantage over the previous LLM based\nmethod. Ablation studies further confirm the superiority of SCA-LLM in\nmitigating domain mismatch.", "published": "2025-09-09 20:43:12", "link": "http://arxiv.org/abs/2509.08139v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Holographic Beamforming for Integrated Sensing and Communication with Mutual Coupling Effects", "abstract": "Integrated sensing and communication (ISAC) is envisioned as a key technology\nin 6G networks, owing to its potential for high spectral and cost efficiency.\nAs a promising solution for extremely large-scale arrays, reconfigurable\nholographic surfaces (RHS) can be integrated with ISAC to form the holographic\nISAC paradigm, where enlarged radiation apertures of RHS can achieve\nsignificant beamforming gains, thereby improving both communication and sensing\nperformance. In this paper, we investigate holographic beamforming designs for\nISAC systems, which, unlike existing holographic beamforming schemes developed\nfor RHS-aided communications, requires explicit consideration of mutual\ncoupling effects within RHS. This is because, different from prior works only\nconsidering communication performance, ISAC systems incorporate sensing\nfunctionality, which is sensitive to sidelobe levels. Ignoring mutual coupling\nin holographic beamforming can lead to notable undesired sidelobes, thus\ndegrading sensing performance. The consideration of mutual coupling introduces\nnew challenges, i.e., it induces non-linearity in beamforming problems,\nrendering them inherently non-convex. To address this issue, we propose a\ntractable electromagnetic-compliant holographic ISAC model that characterizes\nmutual coupling in a closed form using coupled dipole approximations. We then\ndevelop an efficient mutual coupling aware holographic beamforming algorithm to\nsuppress sidelobes and enhance ISAC performance. Numerical results validate\neffectiveness of the proposed algorithm.", "published": "2025-09-09 19:42:30", "link": "http://arxiv.org/abs/2509.08113v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Linear Reliability Channel", "abstract": "We introduce and analyze a discrete soft-decision channel called the linear\nreliability channel (LRC) in which the soft information is the rank ordering of\nthe received symbol reliabilities. We prove that the LRC is an appropriate\napproximation to a general class of discrete modulation, continuous noise\nchannels when the noise variance is high. The central feature of the LRC is\nthat its combinatorial nature allows for an extensive mathematical analysis of\nthe channel and its corresponding hard- and soft-decision maximum likelihood\n(ML) decoders. In particular, we establish explicit error exponents for ML\ndecoding in the LRC when using random codes under both hard- and soft-decision\ndecoding. This analysis allows for a direct, quantitative evaluation of the\nrelative advantage of soft-decision decoding. The discrete geometry of the LRC\nis distinct from that of the BSC, which is characterized by the Hamming weight,\noffering a new perspective on code construction for soft-decision settings.", "published": "2025-09-09 18:34:44", "link": "http://arxiv.org/abs/2509.08079v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sketched Gaussian Mechanism for Private Federated Learning", "abstract": "Communication cost and privacy are two major considerations in federated\nlearning (FL). For communication cost, gradient compression by sketching the\nclients' transmitted model updates is often used for reducing per-round\ncommunication. For privacy, the Gaussian mechanism (GM), which consists of\nclipping updates and adding Gaussian noise, is commonly used to guarantee\nclient-level differential privacy. Existing literature on private FL analyzes\nprivacy of sketching and GM in an isolated manner, illustrating that sketching\nprovides privacy determined by the sketching dimension and that GM has to\nsupply any additional desired privacy.\n  In this paper, we introduce the Sketched Gaussian Mechanism (SGM), which\ndirectly combines sketching and the Gaussian mechanism for privacy. Using\nR\\'enyi-DP tools, we present a joint analysis of SGM's overall privacy\nguarantee, which is significantly more flexible and sharper compared to\nisolated analysis of sketching and GM privacy. In particular, we prove that the\nprivacy level of SGM for a fixed noise magnitude is proportional to\n$1/\\sqrt{b}$, where $b$ is the sketching dimension, indicating that (for\nmoderate $b$) SGM can provide much stronger privacy guarantees than the\noriginal GM under the same noise budget. We demonstrate the application of SGM\nto FL with either gradient descent or adaptive server optimizers, and establish\ntheoretical results on optimization convergence, which exhibits only a\nlogarithmic dependence on the number of parameters $d$. Experimental results\nconfirm that at the same privacy level, SGM based FL is at least competitive\nwith non-sketching private FL variants and outperforms them in some settings.\nMoreover, using adaptive optimization at the server improves empirical\nperformance while maintaining the privacy guarantees.", "published": "2025-09-09 23:59:20", "link": "http://arxiv.org/abs/2509.08195v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Prescribe-then-Select: Adaptive Policy Selection for Contextual Stochastic Optimization", "abstract": "We address the problem of policy selection in contextual stochastic\noptimization (CSO), where covariates are available as contextual information\nand decisions must satisfy hard feasibility constraints. In many CSO settings,\nmultiple candidate policies--arising from different modeling paradigms--exhibit\nheterogeneous performance across the covariate space, with no single policy\nuniformly dominating. We propose Prescribe-then-Select (PS), a modular\nframework that first constructs a library of feasible candidate policies and\nthen learns a meta-policy to select the best policy for the observed\ncovariates. We implement the meta-policy using ensembles of Optimal Policy\nTrees trained via cross-validation on the training set, making policy choice\nentirely data-driven. Across two benchmark CSO problems--single-stage\nnewsvendor and two-stage shipment planning--PS consistently outperforms the\nbest single policy in heterogeneous regimes of the covariate space and\nconverges to the dominant policy when such heterogeneity is absent. All the\ncode to reproduce the results can be found at\nhttps://anonymous.4open.science/r/Prescribe-then-Select-TMLR.", "published": "2025-09-09 23:56:16", "link": "http://arxiv.org/abs/2509.08194v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Rollout-LaSDI: Enhancing the long-term accuracy of Latent Space Dynamics", "abstract": "Solving complex partial differential equations is vital in the physical\nsciences, but often requires computationally expensive numerical methods.\nReduced-order models (ROMs) address this by exploiting dimensionality reduction\nto create fast approximations. While modern ROMs can solve parameterized\nfamilies of PDEs, their predictive power degrades over long time horizons. We\naddress this by (1) introducing a flexible, high-order, yet inexpensive\nfinite-difference scheme and (2) proposing a Rollout loss that trains ROMs to\nmake accurate predictions over arbitrary time horizons. We demonstrate our\napproach on the 2D Burgers equation.", "published": "2025-09-09 23:46:25", "link": "http://arxiv.org/abs/2509.08191v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis", "abstract": "Artifacts in electroencephalography (EEG) -- muscle, eye movement, electrode,\nchewing, and shiver -- confound automated analysis yet are costly to label at\nscale. We study whether modern generative models can synthesize realistic,\nlabel-aware artifact segments suitable for augmentation and stress-testing.\nUsing the TUH EEG Artifact (TUAR) corpus, we curate subject-wise splits and\nfixed-length multi-channel windows (e.g., 250 samples) with preprocessing\ntailored to each model (per-window min-max for adversarial training;\nper-recording/channel $z$-score for diffusion). We compare a conditional\nWGAN-GP with a projection discriminator to a 1D denoising diffusion model with\nclassifier-free guidance, and evaluate along three axes: (i) fidelity via Welch\nband-power deltas ($\\Delta\\delta,\\ \\Delta\\theta,\\ \\Delta\\alpha,\\ \\Delta\\beta$),\nchannel-covariance Frobenius distance, autocorrelation $L_2$, and\ndistributional metrics (MMD/PRD); (ii) specificity via class-conditional\nrecovery with lightweight $k$NN/classifiers; and (iii) utility via augmentation\neffects on artifact recognition. In our setting, WGAN-GP achieves closer\nspectral alignment and lower MMD to real data, while both models exhibit weak\nclass-conditional recovery, limiting immediate augmentation gains and revealing\nopportunities for stronger conditioning and coverage. We release a reproducible\npipeline -- data manifests, training configurations, and evaluation scripts --\nto establish a baseline for EEG artifact synthesis and to surface actionable\nfailure modes for future work.", "published": "2025-09-09 23:25:33", "link": "http://arxiv.org/abs/2509.08188v1", "categories": ["cs.LG", "cs.NE", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Selective Induction Heads: How Transformers Select Causal Structures In Context", "abstract": "Transformers have exhibited exceptional capabilities in sequence modeling\ntasks, leveraging self-attention and in-context learning. Critical to this\nsuccess are induction heads, attention circuits that enable copying tokens\nbased on their previous occurrences. In this work, we introduce a novel\nframework that showcases transformers' ability to dynamically handle causal\nstructures. Existing works rely on Markov Chains to study the formation of\ninduction heads, revealing how transformers capture causal dependencies and\nlearn transition probabilities in-context. However, they rely on a fixed causal\nstructure that fails to capture the complexity of natural languages, where the\nrelationship between tokens dynamically changes with context. To this end, our\nframework varies the causal structure through interleaved Markov chains with\ndifferent lags while keeping the transition probabilities fixed. This setting\nunveils the formation of Selective Induction Heads, a new circuit that endows\ntransformers with the ability to select the correct causal structure\nin-context. We empirically demonstrate that transformers learn this mechanism\nto predict the next token by identifying the correct lag and copying the\ncorresponding token from the past. We provide a detailed construction of a\n3-layer transformer to implement the selective induction head, and a\ntheoretical analysis proving that this mechanism asymptotically converges to\nthe maximum likelihood solution. Our findings advance the understanding of how\ntransformers select causal structures, providing new insights into their\nfunctioning and interpretability.", "published": "2025-09-09 23:13:41", "link": "http://arxiv.org/abs/2509.08184v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "The Domain Mixed Unit: A New Neural Arithmetic Layer", "abstract": "The Domain Mixed Unit (DMU) is a new neural arithmetic unit that learns a\nsingle parameter gate that mixes between log-space and linear-space\nrepresentations while performing either addition (DMU add) or subtraction (DMU\nsub). Two initializations are proposed for the DMU: one covering addition and\nmultiplication, and another covering subtraction and division. The DMU achieves\nstate-of-the-art performance on the NALM Benchmark, a dataset designed to test\nthe ability of neural arithmetic units to generalize arithmetic operations,\nspecifically performing with the highest percentage solved over all seeds on\nmultiplication and division. The DMU will be submitted as a pull request to the\nopen-source NALM benchmark, and its code is available on GitHub at\nhttps://github.com/marict?tab=repositories", "published": "2025-09-09 23:00:31", "link": "http://arxiv.org/abs/2509.08180v1", "categories": ["cs.LG", "68T07", "I.2.6"], "primary_category": "cs.LG"}
{"title": "RAPID Quantum Detection and Demodulation of Covert Communications: Breaking the Noise Limit with Solid-State Spin Sensors", "abstract": "We introduce a comprehensive framework for the detection and demodulation of\ncovert electromagnetic signals using solid-state spin sensors. Our approach,\nnamed RAPID, is a two-stage hybrid strategy that leverages nitrogen-vacancy\n(NV) centers to operate below the classical noise floor employing a robust\nadaptive policy via imitation and distillation. We first formulate the joint\ndetection and estimation task as a unified stochastic optimal control problem,\noptimizing a composite Bayesian risk objective under realistic physical\nconstraints. The RAPID algorithm solves this by first computing a robust,\nnon-adaptive baseline protocol grounded in the quantum Fisher information\nmatrix (QFIM), and then using this baseline to warm-start an online, adaptive\npolicy learned via deep reinforcement learning (Soft Actor-Critic). This method\ndynamically optimizes control pulses, interrogation times, and measurement\nbases to maximize information gain while actively suppressing non-Markovian\nnoise and decoherence. Numerical simulations demonstrate that the protocol\nachieves a significant sensitivity gain over static methods, maintains high\nestimation precision in correlated noise environments, and, when applied to\nsensor arrays, enables coherent quantum beamforming that achieves\nHeisenberg-like scaling in precision. This work establishes a theoretically\nrigorous and practically viable pathway for deploying quantum sensors in\nsecurity-critical applications such as electronic warfare and covert\nsurveillance.", "published": "2025-09-09 22:12:28", "link": "http://arxiv.org/abs/2509.08171v1", "categories": ["quant-ph", "cs.LG", "eess.SP"], "primary_category": "quant-ph"}
{"title": "OCTANE -- Optimal Control for Tensor-based Autoencoder Network Emergence: Explicit Case", "abstract": "This paper presents a novel, mathematically rigorous framework for\nautoencoder-type deep neural networks that combines optimal control theory and\nlow-rank tensor methods to yield memory-efficient training and automated\narchitecture discovery. The learning task is formulated as an optimization\nproblem constrained by differential equations representing the encoder and\ndecoder components of the network and the corresponding optimality conditions\nare derived via a Lagrangian approach. Efficient memory compression is enabled\nby approximating differential equation solutions on low-rank tensor manifolds\nusing an adaptive explicit integration scheme. These concepts are combined to\nform OCTANE (Optimal Control for Tensor-based Autoencoder Network Emergence) --\na unified training framework that yields compact autoencoder architectures,\nreduces memory usage, and enables effective learning, even with limited\ntraining data. The framework's utility is illustrated with application to image\ndenoising and deblurring tasks and recommendations regarding governing\nhyperparameters are provided.", "published": "2025-09-09 22:11:33", "link": "http://arxiv.org/abs/2509.08169v1", "categories": ["math.OC", "cs.LG", "34H05, 37N40, 49K15, 49M41, 65K10, 68T05, 65Z05"], "primary_category": "math.OC"}
{"title": "Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation", "abstract": "Ensuring equitable treatment (fairness) across protected attributes (such as\ngender or ethnicity) is a critical issue in machine learning. Most existing\nliterature focuses on binary classification, but achieving fairness in\nregression tasks-such as insurance pricing or hiring score assessments-is\nequally important. Moreover, anti-discrimination laws also apply to continuous\nattributes, such as age, for which many existing methods are not applicable. In\npractice, multiple protected attributes can exist simultaneously; however,\nmethods targeting fairness across several attributes often overlook so-called\n\"fairness gerrymandering\", thereby ignoring disparities among intersectional\nsubgroups (e.g., African-American women or Hispanic men). In this paper, we\npropose a distance covariance regularisation framework that mitigates the\nassociation between model predictions and protected attributes, in line with\nthe fairness definition of demographic parity, and that captures both linear\nand nonlinear dependencies. To enhance applicability in the presence of\nmultiple protected attributes, we extend our framework by incorporating two\nmultivariate dependence measures based on distance covariance: the previously\nproposed joint distance covariance (JdCov) and our novel concatenated distance\ncovariance (CCdCov), which effectively address fairness gerrymandering in both\nregression and classification tasks involving protected attributes of various\ntypes. We discuss and illustrate how to calibrate regularisation strength,\nincluding a method based on Jensen-Shannon divergence, which quantifies\ndissimilarities in prediction distributions across groups. We apply our\nframework to the COMPAS recidivism dataset and a large motor insurance claims\ndataset.", "published": "2025-09-09 21:48:43", "link": "http://arxiv.org/abs/2509.08163v1", "categories": ["cs.LG", "q-fin.RM", "stat.AP", "stat.ML", "90B50, 62P05, 62H20, 68T07"], "primary_category": "cs.LG"}
{"title": "MMM-fair: An Interactive Toolkit for Exploring and Operationalizing Multi-Fairness Trade-offs", "abstract": "Fairness-aware classification requires balancing performance and fairness,\noften intensified by intersectional biases. Conflicting fairness definitions\nfurther complicate the task, making it difficult to identify universally fair\nsolutions. Despite growing regulatory and societal demands for equitable AI,\npopular toolkits offer limited support for exploring multi-dimensional fairness\nand related trade-offs. To address this, we present mmm-fair, an open-source\ntoolkit leveraging boosting-based ensemble approaches that dynamically\noptimizes model weights to jointly minimize classification errors and diverse\nfairness violations, enabling flexible multi-objective optimization. The system\nempowers users to deploy models that align with their context-specific needs\nwhile reliably uncovering intersectional biases often missed by\nstate-of-the-art methods. In a nutshell, mmm-fair uniquely combines in-depth\nmulti-attribute fairness, multi-objective optimization, a no-code, chat-based\ninterface, LLM-powered explanations, interactive Pareto exploration for model\nselection, custom fairness constraint definition, and deployment-ready models\nin a single open-source toolkit, a combination rarely found in existing\nfairness tools. Demo walkthrough available at: https://youtu.be/_rcpjlXFqkw.", "published": "2025-09-09 21:30:45", "link": "http://arxiv.org/abs/2509.08156v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Contributions to Robust and Efficient Methods for Analysis of High Dimensional Data", "abstract": "A ubiquitous feature of data of our era is their extra-large sizes and\ndimensions. Analyzing such high-dimensional data poses significant challenges,\nsince the feature dimension is often much larger than the sample size. This\nthesis introduces robust and computationally efficient methods to address\nseveral common challenges associated with high-dimensional data. In my first\nmanuscript, I propose a coherent approach to variable screening that\naccommodates nonlinear associations. I develop a novel variable screening\nmethod that transcends traditional linear assumptions by leveraging mutual\ninformation, with an intended application in neuroimaging data. This approach\nallows for accurate identification of important variables by capturing\nnonlinear as well as linear relationships between the outcome and covariates.\nBuilding on this foundation, I develop new optimization methods for sparse\nestimation using nonconvex penalties in my second manuscript. These methods\naddress notable challenges in current statistical computing practices,\nfacilitating computationally efficient and robust analyses of complex datasets.\nThe proposed method can be applied to a general class of optimization problems.\nIn my third manuscript, I contribute to robust modeling of high-dimensional\ncorrelated observations by developing a mixed-effects model based on Tsallis\npower-law entropy maximization and discussed the theoretical properties of such\ndistribution. This model surpasses the constraints of conventional Gaussian\nmodels by accommodating a broader class of distributions with enhanced\nrobustness to outliers. Additionally, I develop a proximal nonlinear conjugate\ngradient algorithm that accelerates convergence while maintaining numerical\nstability, along with rigorous statistical properties for the proposed\nframework.", "published": "2025-09-09 21:30:01", "link": "http://arxiv.org/abs/2509.08155v1", "categories": ["math.ST", "cs.LG", "cs.NA", "math.NA", "math.OC", "physics.data-an", "stat.TH"], "primary_category": "math.ST"}
{"title": "torchmil: A PyTorch-based library for deep Multiple Instance Learning", "abstract": "Multiple Instance Learning (MIL) is a powerful framework for weakly\nsupervised learning, particularly useful when fine-grained annotations are\nunavailable. Despite growing interest in deep MIL methods, the field lacks\nstandardized tools for model development, evaluation, and comparison, which\nhinders reproducibility and accessibility. To address this, we present\ntorchmil, an open-source Python library built on PyTorch. torchmil offers a\nunified, modular, and extensible framework, featuring basic building blocks for\nMIL models, a standardized data format, and a curated collection of benchmark\ndatasets and models. The library includes comprehensive documentation and\ntutorials to support both practitioners and researchers. torchmil aims to\naccelerate progress in MIL and lower the entry barrier for new users. Available\nat https://torchmil.readthedocs.io.", "published": "2025-09-09 20:14:19", "link": "http://arxiv.org/abs/2509.08129v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "In-Context Learning Enhanced Credibility Transformer", "abstract": "The starting point of our network architecture is the Credibility Transformer\nwhich extends the classical Transformer architecture by a credibility mechanism\nto improve model learning and predictive performance. This Credibility\nTransformer learns credibilitized CLS tokens that serve as learned\nrepresentations of the original input features. In this paper we present a new\nparadigm that augments this architecture by an in-context learning mechanism,\ni.e., we increase the information set by a context batch consisting of similar\ninstances. This allows the model to enhance the CLS token representations of\nthe instances by additional in-context information and fine-tuning. We\nempirically verify that this in-context learning enhances predictive accuracy\nby adapting to similar risk patterns. Moreover, this in-context learning also\nallows the model to generalize to new instances which, e.g., have feature\nlevels in the categorical covariates that have not been present when the model\nwas trained -- for a relevant example, think of a new vehicle model which has\njust been developed by a car manufacturer.", "published": "2025-09-09 20:00:52", "link": "http://arxiv.org/abs/2509.08122v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Optimization Methods and Software for Federated Learning", "abstract": "Federated Learning (FL) is a novel, multidisciplinary Machine Learning\nparadigm where multiple clients, such as mobile devices, collaborate to solve\nmachine learning problems. Initially introduced in Kone{\\v{c}}n{\\'y} et al.\n(2016a,b); McMahan et al. (2017), FL has gained further attention through its\ninclusion in the National AI Research and Development Strategic Plan (2023\nUpdate) of the United States (Science and on Artificial Intelligence, 2023).\nThe FL training process is inherently decentralized and often takes place in\nless controlled settings compared to data centers, posing unique challenges\ndistinct from those in fully controlled environments. In this thesis, we\nidentify five key challenges in Federated Learning and propose novel approaches\nto address them. These challenges arise from the heterogeneity of data and\ndevices, communication issues, and privacy concerns for clients in FL training.\nMoreover, even well-established theoretical advances in FL require diverse\nforms of practical implementation to enhance their real-world applicability.\nOur contributions advance FL algorithms and systems, bridging theoretical\nadvancements and practical implementations. More broadly, our work serves as a\nguide for researchers navigating the complexities of translating theoretical\nmethods into efficient real-world implementations and software. Additionally,\nit offers insights into the reverse process of adapting practical\nimplementation aspects back into theoretical algorithm design. This reverse\nprocess is particularly intriguing, as the practical perspective compels us to\nexamine the underlying mechanics and flexibilities of algorithms more deeply,\noften uncovering new dimensions of the algorithms under study.", "published": "2025-09-09 19:58:03", "link": "http://arxiv.org/abs/2509.08120v1", "categories": ["cs.LG", "math.OC", "G.4; D.2; G.m; G.3; I.2"], "primary_category": "cs.LG"}
{"title": "Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning", "abstract": "Federated Learning is a distributed learning technique in which multiple\nclients cooperate to train a machine learning model. Distributed settings\nfacilitate backdoor attacks by malicious clients, who can embed malicious\nbehaviors into the model during their participation in the training process.\nThese malicious behaviors are activated during inference by a specific trigger.\nNo defense against backdoor attacks has stood the test of time, especially\nagainst adaptive attackers, a powerful but not fully explored category of\nattackers. In this work, we first devise a new adaptive adversary that\nsurpasses existing adversaries in capabilities, yielding attacks that only\nrequire one or two malicious clients out of 20 to break existing\nstate-of-the-art defenses. Then, we present Hammer and Anvil, a principled\ndefense approach that combines two defenses orthogonal in their underlying\nprinciple to produce a combined defense that, given the right set of\nparameters, must succeed against any attack. We show that our best combined\ndefense, Krum+, is successful against our new adaptive adversary and\nstate-of-the-art attacks.", "published": "2025-09-09 18:54:31", "link": "http://arxiv.org/abs/2509.08089v1", "categories": ["cs.LG", "cs.CR", "68T99"], "primary_category": "cs.LG"}
{"title": "Forecasting Generative Amplification", "abstract": "Generative networks are perfect tools to enhance the speed and precision of\nLHC simulations. It is important to understand their statistical precision,\nespecially when generating events beyond the size of the training dataset. We\npresent two complementary methods to estimate the amplification factor without\nlarge holdout datasets. Averaging amplification uses Bayesian networks or\nensembling to estimate amplification from the precision of integrals over given\nphase-space volumes. Differential amplification uses hypothesis testing to\nquantify amplification without any resolution loss. Applied to state-of-the-art\nevent generators, both methods indicate that amplification is possible in\nspecific regions of phase space, but not yet across the entire distribution.", "published": "2025-09-09 18:00:01", "link": "http://arxiv.org/abs/2509.08048v1", "categories": ["hep-ph", "cs.LG"], "primary_category": "hep-ph"}
{"title": "Collocation and Mass Matrix in Least-squares Isogeometric Analysis", "abstract": "In this paper, we conduct a systematic numerical analysis of the spectral\nproperties of the collocation and mass matrices in the isogeometric\nleast-squares collocation method (IGA-L), for the approximation of the Poisson\nproblem with homogeneous Dirichlet boundary conditions. This study primarily\nfocuses on the spectral properties of the IGA-L collocation and mass matrices\nin relation to the isogeometric discretization parameters, such as the mesh\nsize, degree, regularity, spatial dimension, and the number and distribution of\nthe collocation points. Through a comprehensive numerical investigation, we\nprovide estimations for the condition number, as well as the maximum and\nminimum singular values, in relation to the mesh size, degree and regularity.\nMoreover, in this paper we also study the effect of the number and distribution\nof the collocation points on the spectral properties of the collocation matrix,\nproviding insights into the optimization of the collocation points for\nachieving better-conditioned linear systems.", "published": "2025-09-09 23:47:35", "link": "http://arxiv.org/abs/2509.08192v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Closest Point Heat Method for Solving Eikonal Equations on Implicit Surfaces", "abstract": "We introduce the Closest Point Heat Method (CPHM), a novel approach for\nsolving the surface Eikonal equation on general smooth surfaces. Building on\nthe strengths of the classical heat method, such as simplicity of\nimplementation and computational efficiency, CPHM integrates closest point\ntechniques to reduce dependence on surface meshes. This embedding framework\nnaturally extends the heat method to implicit surfaces while preserving both\nits efficiency and intrinsic geometric properties. Numerical experiments on\nbenchmark geometries confirm the accuracy and convergence of the proposed\nmethod and demonstrate its effectiveness on complex shapes.", "published": "2025-09-09 21:38:20", "link": "http://arxiv.org/abs/2509.08158v1", "categories": ["math.NA", "cs.NA", "58J05, 65M06, 65M20, 65N06, 65N40, 65D18"], "primary_category": "math.NA"}
{"title": "Unstructured to structured: geometric multigrid on complex geometries via domain remapping", "abstract": "For domains that are easily represented by structured meshes, robust\ngeometric multigrid solvers can quickly provide the numerical solution to many\ndiscretized elliptic PDEs. However, for complicated domains with unstructured\nmeshes, constructing suitable hierarchies of meshes becomes challenging. We\npropose a framework for mapping computations from such complex domains to\nregular computational domains via diffeomorphisms, enabling the use of robust\ngeometric-style multigrid. This mapping facilitates regular memory accesses\nduring solves, improving efficiency and scalability, especially on massively\nparallel processors such as GPUs. Moreover, we show that the diffeomorphic\nmapping itself may be approximately learned using an invertible neural network,\nfacilitating automated application to geometries where no analytic mapping is\nreadily available.", "published": "2025-09-09 19:38:34", "link": "http://arxiv.org/abs/2509.08109v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Improved Robin-Robin Coupling Method for Parabolic-Parabolic Interface Problems", "abstract": "We consider a loosely coupled, non-iterative Robin-Robin coupling method\nproposed and analyzed in [Numer. Algorithms, 99:921-948, 2025] for a\nparabolic-parabolic interface problem. We modify the first step of the scheme\nso that several error difference quantities remain higher order convergence\nwithout requiring additional assumptions. Numerical results are presented to\nsupport our findings.", "published": "2025-09-09 19:30:56", "link": "http://arxiv.org/abs/2509.08103v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Tensor-Train Operator Inference", "abstract": "In this study, we present a tensor--train framework for nonintrusive operator\ninference aimed at learning discrete operators and using them to predict\nsolutions of physical governing equations. Our framework comprises three\napproaches: full--order tensor--train operator inference, full--order quantized\ntensor--train operator inference, and reduced--order tensor--train operator\ninference. In each case, snapshot data is represented in tensor--train\nformat--either through compression or cross interpolation--enabling the\nefficient handling of extremely large datasets with significantly reduced\ncomputational effort compared to standard methods. The effectiveness of each\napproach is demonstrated through numerical experiments related to Computational\nFluid Dynamics and benchmarked against the standard reduced--order operator\ninference method, highlighting the advantages of the tensor--train\nrepresentations in both accuracy and scalability.", "published": "2025-09-09 18:18:56", "link": "http://arxiv.org/abs/2509.08071v1", "categories": ["math.NA", "cs.NA", "65F55, 15A69", "G.1.6; I.6.5"], "primary_category": "math.NA"}
{"title": "Subdivision Schemes in Metric Spaces", "abstract": "We develop a unified framework for nonlinear subdivision schemes on complete\nmetric spaces (CMS). We begin with CMS preliminaries and formalize refinement\nin CMS, retaining key structural properties, such as locality. We prove a\nconvergence theorem under contractivity and demonstrate its applicability. To\naddress schemes where contractivity is unknown, we introduce two notions of\nproximity. Our proximity methods relate a nonlinear scheme to another nonlinear\nscheme with known contractivity, rather than to a linear scheme, as in much of\nthe literature. Specifically, the first type proximity compares the two schemes\nafter a single refinement step and, as in the classical theory, yields\nconvergence from sufficiently dense initial data. The proximity of the second\ntype monitors alignment across all refinement levels and provides strong\nconvergence without density assumptions. We formulate and prove the\ncorresponding theorems, and illustrate them with various examples, such as\nschemes over metric spaces of compact sets in $\\R^n$ and schemes over the\nWasserstein space, as well as a geometric Hermite metric space. These results\nextend subdivision theory beyond Euclidean and manifold-valued data for data in\nmetric spaces.", "published": "2025-09-09 18:17:28", "link": "http://arxiv.org/abs/2509.08070v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Chaotic Bayesian Inference: Strange Attractors as Risk Models for Black Swan Events", "abstract": "We introduce a new risk modeling framework where chaotic attractors shape the\ngeometry of Bayesian inference. By combining heavy-tailed priors with Lorenz\nand Rossler dynamics, the models naturally generate volatility clustering, fat\ntails, and extreme events. We compare two complementary approaches: Model A,\nwhich emphasizes geometric stability, and Model B, which highlights rare bursts\nusing Fibonacci diagnostics. Together, they provide a dual perspective for\nsystemic risk analysis, linking Black Swan theory to practical tools for stress\ntesting and volatility monitoring.", "published": "2025-09-09 23:11:23", "link": "http://arxiv.org/abs/2509.08183v1", "categories": ["q-fin.RM", "econ.EM", "q-fin.ST", "stat.OT", "es: 37N40, 37D45 (Primary) 62P20, 60G70, 91G70 (Secondary)"], "primary_category": "q-fin.RM"}
{"title": "A Bottom-up Framework with Language-universal Speech Attribute Modeling for Syllable-based ASR", "abstract": "We propose a bottom-up framework for automatic speech recognition (ASR) in\nsyllable-based languages by unifying language-universal articulatory attribute\nmodeling with syllable-level prediction. The system first recognizes sequences\nor lattices of articulatory attributes that serve as a language-universal,\ninterpretable representation of pronunciation, and then transforms them into\nsyllables through a structured knowledge integration process. We introduce two\nevaluation metrics, namely Pronunciation Error Rate (PrER) and Syllable Homonym\nError Rate (SHER), to evaluate the model's ability to capture pronunciation and\nhandle syllable ambiguities. Experimental results on the AISHELL-1 Mandarin\ncorpus demonstrate that the proposed bottom-up framework achieves competitive\nperformance and exhibits better robustness under low-resource conditions\ncompared to the direct syllable prediction model. Furthermore, we investigate\nthe zero-shot cross-lingual transferability on Japanese and demonstrate\nsignificant improvements over character- and phoneme-based baselines by 40%\nerror rate reduction.", "published": "2025-09-09 22:20:38", "link": "http://arxiv.org/abs/2509.08173v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "LALM-Eval: An Open-Source Toolkit for Holistic Evaluation of Large Audio Language Models", "abstract": "Large Audio Language Models (LALMs) are rapidly advancing, but evaluating\nthem remains challenging due to inefficient toolkits that limit fair comparison\nand systematic assessment. Current frameworks suffer from three critical\nissues: slow processing that bottlenecks large-scale studies, inconsistent\nprompting that hurts reproducibility, and narrow task coverage that misses\nimportant audio reasoning capabilities. We introduce LALM-Eval, an efficient\nand comprehensive evaluation framework for LALMs. Our system achieves a speedup\nof up to 127% over existing toolkits through optimized batch processing and\nparallel execution, enabling large-scale evaluations previously impractical. We\nprovide standardized prompting protocols and flexible configurations for fair\nmodel comparison across diverse scenarios. Additionally, we introduce two new\nevaluation categories: LLM-Adaptive Diarization for temporal audio\nunderstanding and Spoken Language Reasoning for complex audio-based cognitive\ntasks. Through evaluation across 380+ tasks, we reveal significant gaps in\ncurrent LALMs, particularly in temporal understanding and complex spoken\nlanguage reasoning tasks. Our findings also highlight a lack of standardization\nin instruction modality existent across audio benchmarks, which can lead up\nperformance differences up to 9.5 absolute points on the challenging complex\ninstruction following downstream tasks. LALM-Eval provides both practical\nevaluation tools and insights into model limitations, advancing systematic LALM\ndevelopment.", "published": "2025-09-09 15:30:40", "link": "http://arxiv.org/abs/2509.08031v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Privacy Preserving Semantic Communications Using Vision Language Models: A Segmentation and Generation Approach", "abstract": "Semantic communication has emerged as a promising paradigm for\nnext-generation wireless systems, improving the communication efficiency by\ntransmitting high-level semantic features. However, reliance on unimodal\nrepresentations can degrade reconstruction under poor channel conditions, and\nprivacy concerns of the semantic information attack also gain increasing\nattention. In this work, a privacy-preserving semantic communication framework\nis proposed to protect sensitive content of the image data. Leveraging a\nvision-language model (VLM), the proposed framework identifies and removes\nprivate content regions from input images prior to transmission. A shared\nprivacy database enables semantic alignment between the transmitter and\nreceiver to ensure consistent identification of sensitive entities. At the\nreceiver, a generative module reconstructs the masked regions using learned\nsemantic priors and conditioned on the received text embedding. Simulation\nresults show that generalizes well to unseen image processing tasks, improves\nreconstruction quality at the authorized receiver by over 10% using text\nembedding, and reduces identity leakage to the eavesdropper by more than 50%.", "published": "2025-09-09 20:49:05", "link": "http://arxiv.org/abs/2509.08142v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion", "abstract": "Large language models excel in English but still struggle with complex\nreasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder\nmethods such as LangBridge and MindMerger raise accuracy on mid and\nhigh-resource languages, yet they leave a large gap on LRLs. We present MERLIN,\na two-stage model-stacking framework that applies a curriculum learning\nstrategy -- from general bilingual bitext to task-specific data -- and adapts\nonly a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves\nexact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.\nIt also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),\ndemonstrating effectiveness across both low and high-resource settings.", "published": "2025-09-09 19:32:05", "link": "http://arxiv.org/abs/2509.08105v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions", "abstract": "Recent advancements in Large Language Models (LLMs) demonstrate remarkable\ncapabilities across various fields. These developments have led to more direct\ncommunication between humans and LLMs in various situations, such as social\ncompanionship and psychological support. However, LLMs often exhibit\nlimitations in emotional perception and social competence during real-world\nconversations. These limitations partly originate from their inability to adapt\ntheir communication style and emotional expression to different social and task\ncontexts. In this work, we introduce PersonaFuse, a novel LLM post-training\nframework that enables LLMs to adapt and express different personalities for\nvarying situations. Inspired by Trait Activation Theory and the Big Five\npersonality model, PersonaFuse employs a Mixture-of-Expert architecture that\ncombines persona adapters with a dynamic routing network, enabling contextual\ntrait expression. Experimental results show that PersonaFuse substantially\noutperforms baseline models across multiple dimensions of social-emotional\nintelligence. Importantly, these gains are achieved without sacrificing general\nreasoning ability or model safety, which remain common limitations of direct\nprompting and supervised fine-tuning approaches. PersonaFuse also delivers\nconsistent improvements in downstream human-centered applications, such as\nmental health counseling and review-based customer service. Finally, human\npreference evaluations against leading LLMs, including GPT-4o and DeepSeek,\ndemonstrate that PersonaFuse achieves competitive response quality despite its\ncomparatively smaller model size. These findings demonstrate that PersonaFuse\noffers a theoretically grounded and practical approach for developing\nsocial-emotional enhanced LLMs, marking a significant advancement toward more\nhuman-centric AI systems.", "published": "2025-09-09 03:39:28", "link": "http://arxiv.org/abs/2509.07370v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Domain Mixed Unit: A New Neural Arithmetic Layer", "abstract": "The Domain Mixed Unit (DMU) is a new neural arithmetic unit that learns a\nsingle parameter gate that mixes between log-space and linear-space\nrepresentations while performing either addition (DMU add) or subtraction (DMU\nsub). Two initializations are proposed for the DMU: one covering addition and\nmultiplication, and another covering subtraction and division. The DMU achieves\nstate-of-the-art performance on the NALM Benchmark, a dataset designed to test\nthe ability of neural arithmetic units to generalize arithmetic operations,\nspecifically performing with the highest percentage solved over all seeds on\nmultiplication and division. The DMU will be submitted as a pull request to the\nopen-source NALM benchmark, and its code is available on GitHub at\nhttps://github.com/marict?tab=repositories", "published": "2025-09-09 23:00:31", "link": "http://arxiv.org/abs/2509.08180v2", "categories": ["cs.LG", "68T07", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference", "abstract": "The rapid advancement of large language models (LLMs) and domain-specific AI\nagents has greatly expanded the ecosystem of AI-powered services. User queries,\nhowever, are highly diverse and often span multiple domains and task types,\nresulting in a complex and heterogeneous landscape. This diversity presents a\nfundamental routing challenge: how to accurately direct each query to an\nappropriate execution unit while optimizing both performance and efficiency. To\naddress this, we propose MoMA (Mixture of Models and Agents), a generalized\nrouting framework that integrates both LLM and agent-based routing. Built upon\na deep understanding of model and agent capabilities, MoMA effectively handles\ndiverse queries through precise intent recognition and adaptive routing\nstrategies, achieving an optimal balance between efficiency and cost.\nSpecifically, we construct a detailed training dataset to profile the\ncapabilities of various LLMs under different routing model structures,\nidentifying the most suitable tasks for each LLM. During inference, queries are\ndynamically routed to the LLM with the best cost-performance efficiency. We\nalso introduce an efficient agent selection strategy based on a context-aware\nstate machine and dynamic masking. Experimental results demonstrate that the\nMoMA router offers superior cost-efficiency and scalability compared to\nexisting approaches.", "published": "2025-09-09 10:15:42", "link": "http://arxiv.org/abs/2509.07571v2", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Asynchronous Gossip Algorithms for Rank-Based Statistical Methods", "abstract": "As decentralized AI and edge intelligence become increasingly prevalent,\nensuring robustness and trustworthiness in such distributed settings has become\na critical issue-especially in the presence of corrupted or adversarial data.\nTraditional decentralized algorithms are vulnerable to data contamination as\nthey typically rely on simple statistics (e.g., means or sum), motivating the\nneed for more robust statistics. In line with recent work on decentralized\nestimation of trimmed means and ranks, we develop gossip algorithms for\ncomputing a broad class of rank-based statistics, including L-statistics and\nrank statistics-both known for their robustness to outliers. We apply our\nmethod to perform robust distributed two-sample hypothesis testing, introducing\nthe first gossip algorithm for Wilcoxon rank-sum tests. We provide rigorous\nconvergence guarantees, including the first convergence rate bound for\nasynchronous gossip-based rank estimation. We empirically validate our\ntheoretical results through experiments on diverse network topologies.", "published": "2025-09-09 09:23:36", "link": "http://arxiv.org/abs/2509.07543v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "AU-Harness: An Open-Source Toolkit for Holistic Evaluation of Audio LLMs", "abstract": "Large Audio Language Models (LALMs) are rapidly advancing, but evaluating\nthem remains challenging due to inefficient toolkits that limit fair comparison\nand systematic assessment. Current frameworks suffer from three critical\nissues: slow processing that bottlenecks large-scale studies, inconsistent\nprompting that hurts reproducibility, and narrow task coverage that misses\nimportant audio reasoning capabilities. We introduce AU-Harness, an efficient\nand comprehensive evaluation framework for LALMs. Our system achieves a speedup\nof up to 127% over existing toolkits through optimized batch processing and\nparallel execution, enabling large-scale evaluations previously impractical. We\nprovide standardized prompting protocols and flexible configurations for fair\nmodel comparison across diverse scenarios. Additionally, we introduce two new\nevaluation categories: LLM-Adaptive Diarization for temporal audio\nunderstanding and Spoken Language Reasoning for complex audio-based cognitive\ntasks. Through evaluation across 380+ tasks, we reveal significant gaps in\ncurrent LALMs, particularly in temporal understanding and complex spoken\nlanguage reasoning tasks. Our findings also highlight a lack of standardization\nin instruction modality existent across audio benchmarks, which can lead up\nperformance differences up to 9.5 absolute points on the challenging complex\ninstruction following downstream tasks. AU-Harness provides both practical\nevaluation tools and insights into model limitations, advancing systematic LALM\ndevelopment.", "published": "2025-09-09 15:30:40", "link": "http://arxiv.org/abs/2509.08031v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
