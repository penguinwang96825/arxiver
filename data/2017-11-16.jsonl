{"title": "Crowdsourcing Question-Answer Meaning Representations", "abstract": "We introduce Question-Answer Meaning Representations (QAMRs), which represent\nthe predicate-argument structure of a sentence as a set of question-answer\npairs. We also develop a crowdsourcing scheme to show that QAMRs can be labeled\nwith very little training, and gather a dataset with over 5,000 sentences and\n100,000 questions. A detailed qualitative analysis demonstrates that the\ncrowd-generated question-answer pairs cover the vast majority of\npredicate-argument relationships in existing datasets (including PropBank,\nNomBank, QA-SRL, and AMR) along with many previously under-resourced ones,\nincluding implicit arguments and relations. The QAMR data and annotation code\nis made publicly available to enable future work on how best to model these\ncomplex phenomena.", "published": "2017-11-16 01:53:19", "link": "http://arxiv.org/abs/1711.05885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Encoder-Decoder Framework Translating Natural Language to Database\n  Queries", "abstract": "Machine translation is going through a radical revolution, driven by the\nexplosive development of deep learning techniques using Convolutional Neural\nNetwork (CNN) and Recurrent Neural Network (RNN). In this paper, we consider a\nspecial case in machine translation problems, targeting to convert natural\nlanguage into Structured Query Language (SQL) for data retrieval over\nrelational database. Although generic CNN and RNN learn the grammar structure\nof SQL when trained with sufficient samples, the accuracy and training\nefficiency of the model could be dramatically improved, when the translation\nmodel is deeply integrated with the grammar rules of SQL. We present a new\nencoder-decoder framework, with a suite of new approaches, including new\nsemantic features fed into the encoder, grammar-aware states injected into the\nmemory of decoder, as well as recursive state management for sub-queries. These\ntechniques help the neural network better focus on understanding semantics of\noperations in natural language and save the efforts on SQL grammar learning.\nThe empirical evaluation on real world database and queries show that our\napproach outperform state-of-the-art solution by a significant margin.", "published": "2017-11-16 12:21:57", "link": "http://arxiv.org/abs/1711.06061v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConvAMR: Abstract meaning representation parsing for legal document", "abstract": "Convolutional neural networks (CNN) have recently achieved remarkable\nperformance in a wide range of applications. In this research, we equip\nconvolutional sequence-to-sequence (seq2seq) model with an efficient graph\nlinearization technique for abstract meaning representation parsing. Our\nlinearization method is better than the prior method at signaling the turn of\ngraph traveling. Additionally, convolutional seq2seq model is more appropriate\nand considerably faster than the recurrent neural network models in this task.\nOur method outperforms previous methods by a large margin on both the standard\ndataset LDC2014T12. Our result indicates that future works still have a room\nfor improving parsing model using graph linearization approach.", "published": "2017-11-16 15:27:53", "link": "http://arxiv.org/abs/1711.06141v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Generative Approach to Question Answering", "abstract": "Question Answering has come a long way from answer sentence selection,\nrelational QA to reading and comprehension. We shift our attention to\ngenerative question answering (gQA) by which we facilitate machine to read\npassages and answer questions by learning to generate the answers. We frame the\nproblem as a generative task where the encoder being a network that models the\nrelationship between question and passage and encoding them to a vector thus\nfacilitating the decoder to directly form an abstraction of the answer. Not\nbeing able to retain facts and making repetitions are common mistakes that\naffect the overall legibility of answers. To counter these issues, we employ\ncopying mechanism and maintenance of coverage vector in our model respectively.\nOur results on MS-MARCO demonstrate it's superiority over baselines and we also\nshow qualitative examples where we improved in terms of correctness and\nreadability", "published": "2017-11-16 18:34:16", "link": "http://arxiv.org/abs/1711.06238v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing Cross-Lingual Word Sense Disambiguation on Low-Density\n  Languages: Application to Persian", "abstract": "We explore the use of unsupervised methods in Cross-Lingual Word Sense\nDisambiguation (CL-WSD) with the application of English to Persian. Our\nproposed approach targets the languages with scarce resources (low-density) by\nexploiting word embedding and semantic similarity of the words in context. We\nevaluate the approach on a recent evaluation benchmark and compare it with the\nstate-of-the-art unsupervised system (CO-Graph). The results show that our\napproach outperforms both the standard baseline and the CO-Graph system in both\nof the task evaluation metrics (Out-Of-Five and Best result).", "published": "2017-11-16 16:59:33", "link": "http://arxiv.org/abs/1711.06196v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Novel Framework for Robustness Analysis of Visual QA Models", "abstract": "Deep neural networks have been playing an essential role in many computer\nvision tasks including Visual Question Answering (VQA). Until recently, the\nstudy of their accuracy was the main focus of research but now there is a trend\ntoward assessing the robustness of these models against adversarial attacks by\nevaluating their tolerance to varying noise levels. In VQA, adversarial attacks\ncan target the image and/or the proposed main question and yet there is a lack\nof proper analysis of the later. In this work, we propose a flexible framework\nthat focuses on the language part of VQA that uses semantically relevant\nquestions, dubbed basic questions, acting as controllable noise to evaluate the\nrobustness of VQA models. We hypothesize that the level of noise is positively\ncorrelated to the similarity of a basic question to the main question. Hence,\nto apply noise on any given main question, we rank a pool of basic questions\nbased on their similarity by casting this ranking task as a LASSO optimization\nproblem. Then, we propose a novel robustness measure, R_score, and two\nlarge-scale basic question datasets (BQDs) in order to standardize robustness\nanalysis for VQA models.", "published": "2017-11-16 18:27:49", "link": "http://arxiv.org/abs/1711.06232v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FusionNet: Fusing via Fully-Aware Attention with Application to Machine\n  Comprehension", "abstract": "This paper introduces a new neural structure called FusionNet, which extends\nexisting attention approaches from three perspectives. First, it puts forward a\nnovel concept of \"history of word\" to characterize attention information from\nthe lowest word-level embedding up to the highest semantic-level\nrepresentation. Second, it introduces an improved attention scoring function\nthat better utilizes the \"history of word\" concept. Third, it proposes a\nfully-aware multi-level attention mechanism to capture the complete information\nin one text (such as a question) and exploit it in its counterpart (such as\ncontext or passage) layer by layer. We apply FusionNet to the Stanford Question\nAnswering Dataset (SQuAD) and it achieves the first position for both single\nand ensemble model on the official SQuAD leaderboard at the time of writing\n(Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two\nadversarial SQuAD datasets and it sets up the new state-of-the-art on both\ndatasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to\n51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.", "published": "2017-11-16 03:52:41", "link": "http://arxiv.org/abs/1711.07341v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Remedies against the Vocabulary Gap in Information Retrieval", "abstract": "Search engines rely heavily on term-based approaches that represent queries\nand documents as bags of words. Text---a document or a query---is represented\nby a bag of its words that ignores grammar and word order, but retains word\nfrequency counts. When presented with a search query, the engine then ranks\ndocuments according to their relevance scores by computing, among other things,\nthe matching degrees between query and document terms. While term-based\napproaches are intuitive and effective in practice, they are based on the\nhypothesis that documents that exactly contain the query terms are highly\nrelevant regardless of query semantics. Inversely, term-based approaches assume\ndocuments that do not contain query terms as irrelevant. However, it is known\nthat a high matching degree at the term level does not necessarily mean high\nrelevance and, vice versa, documents that match null query terms may still be\nrelevant. Consequently, there exists a vocabulary gap between queries and\ndocuments that occurs when both use different words to describe the same\nconcepts. It is the alleviation of the effect brought forward by this\nvocabulary gap that is the topic of this dissertation. More specifically, we\npropose (1) methods to formulate an effective query from complex textual\nstructures and (2) latent vector space models that circumvent the vocabulary\ngap in information retrieval.", "published": "2017-11-16 09:50:52", "link": "http://arxiv.org/abs/1711.06004v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Language-Based Image Editing with Recurrent Attentive Models", "abstract": "We investigate the problem of Language-Based Image Editing (LBIE). Given a\nsource image and a natural language description, we want to generate a target\nimage by editing the source image based on the description. We propose a\ngeneric modeling framework for two sub-tasks of LBIE: language-based image\nsegmentation and image colorization. The framework uses recurrent attentive\nmodels to fuse image and language features. Instead of using a fixed step size,\nwe introduce for each region of the image a termination gate to dynamically\ndetermine after each inference step whether to continue extrapolating\nadditional information from the textual description. The effectiveness of the\nframework is validated on three datasets. First, we introduce a synthetic\ndataset, called CoSaL, to evaluate the end-to-end performance of our LBIE\nsystem. Second, we show that the framework leads to state-of-the-art\nperformance on image segmentation on the ReferIt dataset. Third, we present the\nfirst language-based colorization result on the Oxford-102 Flowers dataset.", "published": "2017-11-16 19:10:21", "link": "http://arxiv.org/abs/1711.06288v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Question Asking as Program Generation", "abstract": "A hallmark of human intelligence is the ability to ask rich, creative, and\nrevealing questions. Here we introduce a cognitive model capable of\nconstructing human-like questions. Our approach treats questions as formal\nprograms that, when executed on the state of the world, output an answer. The\nmodel specifies a probability distribution over a complex, compositional space\nof programs, favoring concise programs that help the agent learn in the current\ncontext. We evaluate our approach by modeling the types of open-ended questions\ngenerated by humans who were attempting to learn about an ambiguous situation\nin a game. We find that our model predicts what questions people will ask, and\ncan creatively produce novel questions that were not present in the training\nset. In addition, we compare a number of model variants, finding that both\nquestion informativeness and complexity are important for producing human-like\nquestions.", "published": "2017-11-16 23:27:04", "link": "http://arxiv.org/abs/1711.06351v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech Dereverberation with Context-aware Recurrent Neural Networks", "abstract": "In this paper, we propose a model to perform speech dereverberation by\nestimating its spectral magnitude from the reverberant counterpart. Our models\nare capable of extracting features that take into account both short and\nlong-term dependencies in the signal through a convolutional encoder (which\nextracts features from a short, bounded context of frames) and a recurrent\nneural network for extracting long-term information. Our model outperforms a\nrecently proposed model that uses different context information depending on\nthe reverberation time, without requiring any sort of additional input,\nyielding improvements of up to 0.4 on PESQ, 0.3 on STOI, and 1.0 on POLQA\nrelative to reverberant speech. We also show our model is able to generalize to\nreal room impulse responses even when only trained with simulated room impulse\nresponses, different speakers, and high reverberation times. Lastly, listening\ntests show the proposed method outperforming benchmark models in reduction of\nperceived reverberation.", "published": "2017-11-16 20:18:44", "link": "http://arxiv.org/abs/1711.06309v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
