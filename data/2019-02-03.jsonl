{"title": "Review Conversational Reading Comprehension", "abstract": "Inspired by conversational reading comprehension (CRC), this paper studies a\nnovel task of leveraging reviews as a source to build an agent that can answer\nmulti-turn questions from potential consumers of online businesses. We first\nbuild a review CRC dataset and then propose a novel task-aware pre-tuning step\nrunning between language model (e.g., BERT) pre-training and domain-specific\nfine-tuning. The proposed pre-tuning requires no data annotation, but can\ngreatly enhance the performance on our end task. Experimental results show that\nthe proposed approach is highly effective and has competitive performance as\nthe supervised approach. The dataset is available at\n\\url{https://github.com/howardhsu/RCRC}", "published": "2019-02-03 00:32:46", "link": "http://arxiv.org/abs/1902.00821v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Extractive Text Summarization with Syntactic Compression", "abstract": "Recent neural network approaches to summarization are largely either\nselection-based extraction or generation-based abstraction. In this work, we\npresent a neural model for single-document summarization based on joint\nextraction and syntactic compression. Our model chooses sentences from the\ndocument, identifies possible compressions based on constituency parses, and\nscores those compressions with a neural model to produce the final summary. For\nlearning, we construct oracle extractive-compressive summaries, then learn both\nof our components jointly with this supervision. Experimental results on the\nCNN/Daily Mail and New York Times datasets show that our model achieves strong\nperformance (comparable to state-of-the-art systems) as evaluated by ROUGE.\nMoreover, our approach outperforms an off-the-shelf compression module, and\nhuman and manual evaluation shows that our model's output generally remains\ngrammatical.", "published": "2019-02-03 08:19:42", "link": "http://arxiv.org/abs/1902.00863v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inferring Concept Hierarchies from Text Corpora via Hyperbolic\n  Embeddings", "abstract": "We consider the task of inferring is-a relationships from large text corpora.\nFor this purpose, we propose a new method combining hyperbolic embeddings and\nHearst patterns. This approach allows us to set appropriate constraints for\ninferring concept hierarchies from distributional contexts while also being\nable to predict missing is-a relationships and to correct wrong extractions.\nMoreover -- and in contrast with other methods -- the hierarchical nature of\nhyperbolic space allows us to learn highly efficient representations and to\nimprove the taxonomic consistency of the inferred hierarchies. Experimentally,\nwe show that our approach achieves state-of-the-art performance on several\ncommonly-used benchmarks.", "published": "2019-02-03 16:03:29", "link": "http://arxiv.org/abs/1902.00913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Lemmatizer: A Sequence to Sequence Model for Lemmatizing\n  Universal Dependencies Treebanks", "abstract": "In this paper we present a novel lemmatization method based on a\nsequence-to-sequence neural network architecture and morphosyntactic context\nrepresentation. In the proposed method, our context-sensitive lemmatizer\ngenerates the lemma one character at a time based on the surface form\ncharacters and its morphosyntactic features obtained from a morphological\ntagger. We argue that a sliding window context representation suffers from\nsparseness, while in majority of cases the morphosyntactic features of a word\nbring enough information to resolve lemma ambiguities while keeping the context\nrepresentation dense and more practical for machine learning systems.\nAdditionally, we study two different data augmentation methods utilizing\nautoencoder training and morphological transducers especially beneficial for\nlow resource languages. We evaluate our lemmatizer on 52 different languages\nand 76 different treebanks, showing that our system outperforms all latest\nbaseline systems. Compared to the best overall baseline, UDPipe Future, our\nsystem outperforms it on 62 out of 76 treebanks reducing errors on average by\n19% relative. The lemmatizer together with all trained models is made available\nas a part of the Turku-neural-parsing-pipeline under the Apache 2.0 license.", "published": "2019-02-03 21:38:29", "link": "http://arxiv.org/abs/1902.00972v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Question Answering with External Knowledge", "abstract": "We focus on multiple-choice question answering (QA) tasks in subject areas\nsuch as science, where we require both broad background knowledge and the facts\nfrom the given subject-area reference corpus. In this work, we explore simple\nyet effective methods for exploiting two sources of external knowledge for\nsubject-area QA. The first enriches the original subject-area reference corpus\nwith relevant text snippets extracted from an open-domain resource (i.e.,\nWikipedia) that cover potentially ambiguous concepts in the question and answer\noptions. As in other QA research, the second method simply increases the amount\nof training data by appending additional in-domain subject-area instances.\n  Experiments on three challenging multiple-choice science QA tasks (i.e.,\nARC-Easy, ARC-Challenge, and OpenBookQA) demonstrate the effectiveness of our\nmethods: in comparison to the previous state-of-the-art, we obtain absolute\ngains in accuracy of up to 8.1%, 13.0%, and 12.8%, respectively. While we\nobserve consistent gains when we introduce knowledge from Wikipedia, we find\nthat employing additional QA training instances is not uniformly helpful:\nperformance degrades when the added instances exhibit a higher level of\ndifficulty than the original training data. As one of the first studies on\nexploiting unstructured external knowledge for subject-area QA, we hope our\nmethods, observations, and discussion of the exposed limitations may shed light\non further developments in the area.", "published": "2019-02-03 23:44:10", "link": "http://arxiv.org/abs/1902.00993v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker Verification By Partial AUC Optimization With Mahalanobis\n  Distance Metric Learning", "abstract": "Receiver operating characteristic (ROC) and detection error tradeoff (DET)\ncurves are two widely used evaluation metrics for speaker verification. They\nare equivalent since the latter can be obtained by transforming the former's\ntrue positive y-axis to false negative y-axis and then re-scaling both axes by\na probit operator. Real-world speaker verification systems, however, usually\nwork on part of the ROC curve instead of the entire ROC curve given an\napplication. Therefore, we propose in this paper to use the area under part of\nthe ROC curve (pAUC) as a more efficient evaluation metric for speaker\nverification. A Mahalanobis distance metric learning based back-end is applied\nto optimize pAUC, where the Mahalanobis distance metric learning guarantees\nthat the optimization objective of the back-end is a convex one so that the\nglobal optimum solution is achievable. To improve the performance of the\nstate-of-the-art speaker verification systems by the proposed back-end, we\nfurther propose two feature preprocessing techniques based on\nlength-normalization and probabilistic linear discriminant analysis\nrespectively. We evaluate the proposed systems on the major languages of NIST\nSRE16 and the core tasks of SITW. Experimental results show that the proposed\nback-end outperforms the state-of-the-art speaker verification back-ends in\nterms of seven evaluation metrics.", "published": "2019-02-03 13:19:15", "link": "http://arxiv.org/abs/1902.00889v4", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Autotuner: A Data-Driven Approach to Natural-Sounding Pitch\n  Correction for Singing Voice in Karaoke Performances", "abstract": "We describe a machine-learning approach to pitch correcting a solo singing\nperformance in a karaoke setting, where the solo voice and accompaniment are on\nseparate tracks. The proposed approach addresses the situation where no musical\nscore of the vocals nor the accompaniment exists: It predicts the amount of\ncorrection from the relationship between the spectral contents of the vocal and\naccompaniment tracks. Hence, the pitch shift in cents suggested by the model\ncan be used to make the voice sound in tune with the accompaniment. This\napproach differs from commercially used automatic pitch correction systems,\nwhere notes in the vocal tracks are shifted to be centered around notes in a\nuser-defined score or mapped to the closest pitch among the twelve\nequal-tempered scale degrees. We train the model using a dataset of 4,702\namateur karaoke performances selected for good intonation. We present a\nConvolutional Gated Recurrent Unit (CGRU) model to accomplish this task. This\nmethod can be extended into unsupervised pitch correction of a vocal\nperformance, popularly referred to as autotuning.", "published": "2019-02-03 19:05:24", "link": "http://arxiv.org/abs/1902.00956v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
