{"title": "Sensemaking About Contraceptive Methods Across Online Platforms", "abstract": "Selecting a birth control method is a complex healthcare decision. While\nbirth control methods provide important benefits, they can also cause\nunpredictable side effects and be stigmatized, leading many people to seek\nadditional information online, where they can find reviews, advice, hypotheses,\nand experiences of other birth control users. However, the relationships\nbetween their healthcare concerns, sensemaking activities, and online settings\nare not well understood. We gather texts about birth control shared on Twitter,\nReddit, and WebMD -- platforms with different affordances, moderation, and\naudiences -- to study where and how birth control is discussed online. Using a\ncombination of topic modeling and hand annotation, we identify and characterize\nthe dominant sensemaking practices across these platforms, and we create\nlexicons to draw comparisons across birth control methods and side effects. We\nuse these to measure variations from survey reports of side effect experiences\nand method usage. Our findings characterize how online platforms are used to\nmake sense of difficult healthcare choices and highlight unmet needs of birth\ncontrol users.", "published": "2023-01-23 06:44:38", "link": "http://arxiv.org/abs/2301.09295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic Ontologies for Arguments", "abstract": "Many computational argumentation tasks, like stance classification, are\ntopic-dependent: the effectiveness of approaches to these tasks significantly\ndepends on whether the approaches were trained on arguments from the same\ntopics as those they are tested on. So, which are these topics that researchers\ntrain approaches on? This paper contributes the first comprehensive survey of\ntopic coverage, assessing 45 argument corpora. For the assessment, we take the\nfirst step towards building an argument topic ontology, consulting three\ndiverse authoritative sources: the World Economic Forum, the Wikipedia list of\ncontroversial topics, and Debatepedia. Comparing the topic sets between the\nauthoritative sources and corpora, our analysis shows that the corpora\ntopics-which are mostly those frequently discussed in public online fora - are\ncovered well by the sources. However, other topics from the sources are less\nextensively covered by the corpora of today, revealing interesting future\ndirections for corpus construction.", "published": "2023-01-23 23:43:24", "link": "http://arxiv.org/abs/2301.09759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic-aware Contrastive Learning for Electroencephalography-to-Text\n  Generation with Curriculum Learning", "abstract": "Electroencephalography-to-Text generation (EEG-to-Text), which aims to\ndirectly generate natural text from EEG signals has drawn increasing attention\nin recent years due to the enormous potential for Brain-computer interfaces\n(BCIs). However, the remarkable discrepancy between the subject-dependent EEG\nrepresentation and the semantic-dependent text representation poses a great\nchallenge to this task. To mitigate this challenge, we devise a Curriculum\nSemantic-aware Contrastive Learning strategy (C-SCL), which effectively\nre-calibrates the subject-dependent EEG representation to the\nsemantic-dependent EEG representation, thus reducing the discrepancy.\nSpecifically, our C-SCL pulls semantically similar EEG representations together\nwhile pushing apart dissimilar ones. Besides, in order to introduce more\nmeaningful contrastive pairs, we carefully employ curriculum learning to not\nonly craft meaningful contrastive pairs but also make the learning\nprogressively. We conduct extensive experiments on the ZuCo benchmark and our\nmethod combined with diverse models and architectures shows stable improvements\nacross three types of metrics while achieving the new state-of-the-art. Further\ninvestigation proves not only its superiority in both the single-subject and\nlow-resource settings but also its robust generalizability in the zero-shot\nsetting.", "published": "2023-01-23 00:54:48", "link": "http://arxiv.org/abs/2301.09237v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Efficient Encoders for Streaming Sequence Tagging", "abstract": "A naive application of state-of-the-art bidirectional encoders for streaming\nsequence tagging would require encoding each token from scratch for each new\ntoken in an incremental streaming input (like transcribed speech). The lack of\nre-usability of previous computation leads to a higher number of Floating Point\nOperations (or FLOPs) and higher number of unnecessary label flips. Increased\nFLOPs consequently lead to higher wall-clock time and increased label flipping\nleads to poorer streaming performance. In this work, we present a Hybrid\nEncoder with Adaptive Restart (HEAR) that addresses these issues while\nmaintaining the performance of bidirectional encoders over the offline (or\ncomplete) inputs while improving performance on streaming (or incomplete)\ninputs. HEAR has a Hybrid unidirectional-bidirectional encoder architecture to\nperform sequence tagging, along with an Adaptive Restart Module (ARM) to\nselectively guide the restart of bidirectional portion of the encoder. Across\nfour sequence tagging tasks, HEAR offers FLOP savings in streaming settings\nupto 71.1% and also outperforms bidirectional encoders for streaming\npredictions by upto +10% streaming exact match.", "published": "2023-01-23 02:20:39", "link": "http://arxiv.org/abs/2301.09244v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Energy Worker Profiler from Technologies to Skills to Realize Energy\n  Efficiency in Manufacturing", "abstract": "In recent years, the manufacturing sector has been responsible for nearly 55\npercent of total energy consumption, inducing a major impact on the global\necosystem. Although stricter regulations, restrictions on heavy manufacturing\nand technological advances are increasing its sustainability, zero-emission and\nfuel-efficient manufacturing is still considered a utopian target. In\nparallel,companies that have invested in digital innovation now need to align\ntheir internal competencies to maximize their return on investment. Moreover, a\nprimary feature of Industry 4.0 is the digitization of production processes,\nwhich offers the opportunity to optimize energy consumption. However, given the\nspeed with which innovation manifests itself, tools capable of measuring the\nimpact that technology is having on digital and green professions and skills\nare still being designed. In light of the above, in this article we present the\nWorker Profiler, a software designed to map the skills currently possessed by\nworkers, identifying misalignment with those they should ideally possess to\nmeet the renewed demands that digital innovation and environmental preservation\nimpose. The creation of the Worker Profiler consists of two steps: first, the\nauthors inferred the key technologies and skills for the area of interest,\nisolating those with markedly increasing patent trends and identifying green\nand digital enabling skills and occupations. Thus, the software was designed\nand implemented at the user-interface level. The output of the self-assessment\nis the definition of the missing digital and green skills and the job roles\nclosest to the starting one in terms of current skills; both the results enable\nthe definition of a customized retraining strategy. The tool has shown evidence\nof being user-friendly, effective in identifying skills gaps and easily\nadaptable to other contexts.", "published": "2023-01-23 14:08:34", "link": "http://arxiv.org/abs/2301.09445v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Efficient Language Model Training through Cross-Lingual and Progressive\n  Transfer Learning", "abstract": "Most Transformer language models are primarily pretrained on English text,\nlimiting their use for other languages. As the model sizes grow, the\nperformance gap between English and other languages with fewer compute and data\nresources increases even further. Consequently, more resource-efficient\ntraining methods are needed to bridge the gap for languages with fewer\nresources available. To address this problem, we introduce a cross-lingual and\nprogressive transfer learning approach, called CLP-Transfer, that transfers\nmodels from a source language, for which pretrained models are publicly\navailable, like English, to a new target language. As opposed to prior work,\nwhich focused on the cross-lingual transfer between two languages, we extend\nthe transfer to the model size. Given a pretrained model in a source language,\nwe aim for a same-sized model in a target language. Instead of training a model\nfrom scratch, we exploit a smaller model that is in the target language but\nrequires much fewer resources. Both small and source models are then used to\ninitialize the token embeddings of the larger model based on the overlapping\nvocabulary of the source and target language. All remaining weights are reused\nfrom the model in the source language. This approach outperforms the sole\ncross-lingual transfer and can save up to 80% of the training steps compared to\nthe random initialization.", "published": "2023-01-23 18:56:12", "link": "http://arxiv.org/abs/2301.09626v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Noisy Parallel Data Alignment", "abstract": "An ongoing challenge in current natural language processing is how its major\nadvancements tend to disproportionately favor resource-rich languages, leaving\na significant number of under-resourced languages behind. Due to the lack of\nresources required to train and evaluate models, most modern language\ntechnologies are either nonexistent or unreliable to process endangered, local,\nand non-standardized languages. Optical character recognition (OCR) is often\nused to convert endangered language documents into machine-readable data.\nHowever, such OCR output is typically noisy, and most word alignment models are\nnot built to work under such noisy conditions. In this work, we study the\nexisting word-level alignment models under noisy settings and aim to make them\nmore robust to noisy data. Our noise simulation and structural biasing method,\ntested on multiple language pairs, manages to reduce the alignment error rate\non a state-of-the-art neural-based alignment model up to 59.6%.", "published": "2023-01-23 19:26:34", "link": "http://arxiv.org/abs/2301.09685v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Lexi: Self-Supervised Learning of the UI Language", "abstract": "Humans can learn to operate the user interface (UI) of an application by\nreading an instruction manual or how-to guide. Along with text, these resources\ninclude visual content such as UI screenshots and images of application icons\nreferenced in the text. We explore how to leverage this data to learn generic\nvisio-linguistic representations of UI screens and their components. These\nrepresentations are useful in many real applications, such as accessibility,\nvoice navigation, and task automation. Prior UI representation models rely on\nUI metadata (UI trees and accessibility labels), which is often missing,\nincompletely defined, or not accessible. We avoid such a dependency, and\npropose Lexi, a pre-trained vision and language model designed to handle the\nunique features of UI screens, including their text richness and context\nsensitivity. To train Lexi we curate the UICaption dataset consisting of 114k\nUI images paired with descriptions of their functionality. We evaluate Lexi on\nfour tasks: UI action entailment, instruction-based UI image retrieval,\ngrounding referring expressions, and UI entity recognition.", "published": "2023-01-23 09:05:49", "link": "http://arxiv.org/abs/2301.10165v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StockEmotions: Discover Investor Emotions for Financial Sentiment\n  Analysis and Multivariate Time Series", "abstract": "There has been growing interest in applying NLP techniques in the financial\ndomain, however, resources are extremely limited. This paper introduces\nStockEmotions, a new dataset for detecting emotions in the stock market that\nconsists of 10,000 English comments collected from StockTwits, a financial\nsocial media platform. Inspired by behavioral finance, it proposes 12\nfine-grained emotion classes that span the roller coaster of investor emotion.\nUnlike existing financial sentiment datasets, StockEmotions presents granular\nfeatures such as investor sentiment classes, fine-grained emotions, emojis, and\ntime series data. To demonstrate the usability of the dataset, we perform a\ndataset analysis and conduct experimental downstream tasks. For financial\nsentiment/emotion classification tasks, DistilBERT outperforms other baselines,\nand for multivariate time series forecasting, a Temporal Attention LSTM model\ncombining price index, text, and emotion features achieves the best performance\nthan using a single feature.", "published": "2023-01-23 05:32:42", "link": "http://arxiv.org/abs/2301.09279v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-fin.CP"], "primary_category": "cs.CL"}
{"title": "Large-scale investigation of weakly-supervised deep learning for the\n  fine-grained semantic indexing of biomedical literature", "abstract": "Objective: Semantic indexing of biomedical literature is usually done at the\nlevel of MeSH descriptors with several related but distinct biomedical concepts\noften grouped together and treated as a single topic. This study proposes a new\nmethod for the automated refinement of subject annotations at the level of MeSH\nconcepts. Methods: Lacking labelled data, we rely on weak supervision based on\nconcept occurrence in the abstract of an article, which is also enhanced by\ndictionary-based heuristics. In addition, we investigate deep learning\napproaches, making design choices to tackle the particular challenges of this\ntask. The new method is evaluated on a large-scale retrospective scenario,\nbased on concepts that have been promoted to descriptors. Results: In our\nexperiments concept occurrence was the strongest heuristic achieving a macro-F1\nscore of about 0.63 across several labels. The proposed method improved it\nfurther by more than 4pp. Conclusion: The results suggest that concept\noccurrence is a strong heuristic for refining the coarse-grained labels at the\nlevel of MeSH concepts and the proposed method improves it further.", "published": "2023-01-23 10:33:22", "link": "http://arxiv.org/abs/2301.09350v2", "categories": ["cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SMDDH: Singleton Mention detection using Deep Learning in Hindi Text", "abstract": "Mention detection is an important component of coreference resolution system,\nwhere mentions such as name, nominal, and pronominals are identified. These\nmentions can be purely coreferential mentions or singleton mentions\n(non-coreferential mentions). Coreferential mentions are those mentions in a\ntext that refer to the same entities in a real world. Whereas, singleton\nmentions are mentioned only once in the text and do not participate in the\ncoreference as they are not mentioned again in the following text. Filtering of\nthese singleton mentions can substantially improve the performance of a\ncoreference resolution process. This paper proposes a singleton mention\ndetection module based on a fully connected network and a Convolutional neural\nnetwork for Hindi text. This model utilizes a few hand-crafted features and\ncontext information, and word embedding for words. The coreference annotated\nHindi dataset comprising of 3.6K sentences, and 78K tokens are used for the\ntask. In terms of Precision, Recall, and F-measure, the experimental findings\nobtained are excellent.", "published": "2023-01-23 10:58:18", "link": "http://arxiv.org/abs/2301.09361v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Learning Mental Health Dialogue System", "abstract": "Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.", "published": "2023-01-23 13:10:23", "link": "http://arxiv.org/abs/2301.09412v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Selective Explanations: Leveraging Human Input to Align Explainable AI", "abstract": "While a vast collection of explainable AI (XAI) algorithms have been\ndeveloped in recent years, they are often criticized for significant gaps with\nhow humans produce and consume explanations. As a result, current XAI\ntechniques are often found to be hard to use and lack effectiveness. In this\nwork, we attempt to close these gaps by making AI explanations selective -- a\nfundamental property of human explanations -- by selectively presenting a\nsubset from a large set of model reasons based on what aligns with the\nrecipient's preferences. We propose a general framework for generating\nselective explanations by leveraging human input on a small sample. This\nframework opens up a rich design space that accounts for different selectivity\ngoals, types of input, and more. As a showcase, we use a decision-support task\nto explore selective explanations based on what the decision-maker would\nconsider relevant to the decision task. We conducted two experimental studies\nto examine three out of a broader possible set of paradigms based on our\nproposed framework: in Study 1, we ask the participants to provide their own\ninput to generate selective explanations, with either open-ended or\ncritique-based input. In Study 2, we show participants selective explanations\nbased on input from a panel of similar users (annotators). Our experiments\ndemonstrate the promise of selective explanations in reducing over-reliance on\nAI and improving decision outcomes and subjective perceptions of the AI, but\nalso paint a nuanced picture that attributes some of these positive effects to\nthe opportunity to provide one's own input to augment AI explanations. Overall,\nour work proposes a novel XAI framework inspired by human communication\nbehaviors and demonstrates its potentials to encourage future work to better\nalign AI explanations with human production and consumption of explanations.", "published": "2023-01-23 19:00:02", "link": "http://arxiv.org/abs/2301.09656v3", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question\n  Answering Research and Development", "abstract": "The field of Question Answering (QA) has made remarkable progress in recent\nyears, thanks to the advent of large pre-trained language models, newer\nrealistic benchmark datasets with leaderboards, and novel algorithms for key\ncomponents such as retrievers and readers. In this paper, we introduce PRIMEQA:\na one-stop and open-source QA repository with an aim to democratize QA\nre-search and facilitate easy replication of state-of-the-art (SOTA) QA\nmethods. PRIMEQA supports core QA functionalities like retrieval and reading\ncomprehension as well as auxiliary capabilities such as question generation.It\nhas been designed as an end-to-end toolkit for various use cases: building\nfront-end applications, replicating SOTA methods on pub-lic benchmarks, and\nexpanding pre-existing methods. PRIMEQA is available at :\nhttps://github.com/primeqa.", "published": "2023-01-23 20:43:26", "link": "http://arxiv.org/abs/2301.09715v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey on Heart Sound Analysis in the Deep Learning Era", "abstract": "Heart sound auscultation has been applied in clinical usage for early\nscreening of cardiovascular diseases. Due to the high demand for auscultation\nexpertise, automatic auscultation can help with auxiliary diagnosis and reduce\nthe burden of training professional clinicians. Nevertheless, there is a limit\nto classic machine learning's performance improvement in the era of big data.\nDeep learning has outperformed classic machine learning in many research\nfields, as it employs more complex model architectures with a stronger\ncapability of extracting effective representations. Moreover, it has been\nsuccessfully applied to heart sound analysis in the past years. As most review\nworks about heart sound analysis were carried out before 2017, the present\nsurvey is the first to work on a comprehensive overview to summarise papers on\nheart sound analysis with deep learning published in 2017--2022. This work\nintroduces both classic machine learning and deep learning for comparison, and\nfurther offer insights about the advances and future research directions in\ndeep learning for heart sound analysis. Our repository is publicly available at\n\\url{https://github.com/zhaoren91/awesome-heart-sound-analysis}.", "published": "2023-01-23 10:58:45", "link": "http://arxiv.org/abs/2301.09362v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Attention-Based Alignment Network for Melody Generation from\n  Incomplete Lyrics", "abstract": "We propose a deep attention-based alignment network, which aims to\nautomatically predict lyrics and melody with given incomplete lyrics as input\nin a way similar to the music creation of humans. Most importantly, a deep\nneural lyrics-to-melody net is trained in an encoder-decoder way to predict\npossible pairs of lyrics-melody when given incomplete lyrics (few keywords).\nThe attention mechanism is exploited to align the predicted lyrics with the\nmelody during the lyrics-to-melody generation. The qualitative and quantitative\nevaluation metrics reveal that the proposed method is indeed capable of\ngenerating proper lyrics and corresponding melody for composing new songs given\na piece of incomplete seed lyrics.", "published": "2023-01-23 03:41:53", "link": "http://arxiv.org/abs/2301.10015v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
