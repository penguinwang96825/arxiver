{"title": "Multitask Learning For Different Subword Segmentations In Neural Machine\n  Translation", "abstract": "In Neural Machine Translation (NMT) the usage of subwords and characters as\nsource and target units offers a simple and flexible solution for translation\nof rare and unseen words. However, selecting the optimal subword segmentation\ninvolves a trade-off between expressiveness and flexibility, and is language\nand dataset-dependent. We present Block Multitask Learning (BMTL), a novel NMT\narchitecture that predicts multiple targets of different granularities\nsimultaneously, removing the need to search for the optimal segmentation\nstrategy. Our multi-task model exhibits improvements of up to 1.7 BLEU points\non each decoder over single-task baseline models with the same number of\nparameters on datasets from two language pairs of IWSLT15 and one from IWSLT19.\nThe multiple hypotheses generated at different granularities can be combined as\na post-processing step to give better translations, which improves over\nhypothesis combination from baseline models while using substantially fewer\nparameters.", "published": "2019-10-27 22:14:04", "link": "http://arxiv.org/abs/1910.12368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Look-up and Adapt: A One-shot Semantic Parser", "abstract": "Computing devices have recently become capable of interacting with their end\nusers via natural language. However, they can only operate within a limited\n\"supported\" domain of discourse and fail drastically when faced with an\nout-of-domain utterance, mainly due to the limitations of their semantic\nparser. In this paper, we propose a semantic parser that generalizes to\nout-of-domain examples by learning a general strategy for parsing an unseen\nutterance through adapting the logical forms of seen utterances, instead of\nlearning to generate a logical form from scratch. Our parser maintains a memory\nconsisting of a representative subset of the seen utterances paired with their\nlogical forms. Given an unseen utterance, our parser works by looking up a\nsimilar utterance from the memory and adapting its logical form until it fits\nthe unseen utterance. Moreover, we present a data generation strategy for\nconstructing utterance-logical form pairs from different domains. Our results\nshow an improvement of up to 68.8% on one-shot parsing under two different\nevaluation settings compared to the baselines.", "published": "2019-10-27 06:56:43", "link": "http://arxiv.org/abs/1910.12197v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Memeify: A Large-Scale Meme Generation System", "abstract": "Interest in the research areas related to meme propagation and generation has\nbeen increasing rapidly in the last couple of years. Meme datasets available\nonline are either specific to a context or contain no class information. Here,\nwe prepare a large-scale dataset of memes with captions and class labels. The\ndataset consists of 1.1 million meme captions from 128 classes. We also provide\nreasoning for the existence of broad categories, called \"themes\" across the\nmeme dataset; each theme consists of multiple meme classes. Our generation\nsystem uses a trained state-of-the-art transformer-based model for caption\ngeneration by employing an encoder-decoder architecture. We develop a web\ninterface, called Memeify for users to generate memes of their choice, and\nexplain in detail, the working of individual components of the system. We also\nperform a qualitative evaluation of the generated memes by conducting a user\nstudy. A link to the demonstration of the Memeify system is\nhttps://youtu.be/P_Tfs0X-czs.", "published": "2019-10-27 15:13:26", "link": "http://arxiv.org/abs/1910.12279v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SoulMate: Short-text author linking through Multi-aspect\n  temporal-textual embedding", "abstract": "Linking authors of short-text contents has important usages in many\napplications, including Named Entity Recognition (NER) and human community\ndetection. However, certain challenges lie ahead. Firstly, the input short-text\ncontents are noisy, ambiguous, and do not follow the grammatical rules.\nSecondly, traditional text mining methods fail to effectively extract concepts\nthrough words and phrases. Thirdly, the textual contents are temporally skewed,\nwhich can affect the semantic understanding by multiple time facets. Finally,\nusing the complementary knowledge-bases makes the results biased to the content\nof the external database and deviates the understanding and interpretation away\nfrom the real nature of the given short text corpus. To overcome these\nchallenges, we devise a neural network-based temporal-textual framework that\ngenerates the tightly connected author subgraphs from microblog short-text\ncontents. Our approach, on the one hand, computes the relevance score (edge\nweight) between the authors through considering a portmanteau of contents and\nconcepts, and on the other hand, employs a stack-wise graph cutting algorithm\nto extract the communities of the related authors. Experimental results show\nthat compared to other knowledge-centered competitors, our multi-aspect vector\nspace model can achieve a higher performance in linking short-text authors.\nAdditionally, given the author linking task, the more comprehensive the dataset\nis, the higher the significance of the extracted concepts will be.", "published": "2019-10-27 04:53:35", "link": "http://arxiv.org/abs/1910.12180v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Word-level Textual Adversarial Attacking as Combinatorial Optimization", "abstract": "Adversarial attacks are carried out to reveal the vulnerability of deep\nneural networks. Textual adversarial attacking is challenging because text is\ndiscrete and a small perturbation can bring significant change to the original\ninput. Word-level attacking, which can be regarded as a combinatorial\noptimization problem, is a well-studied class of textual attack methods.\nHowever, existing word-level attack models are far from perfect, largely\nbecause unsuitable search space reduction methods and inefficient optimization\nalgorithms are employed. In this paper, we propose a novel attack model, which\nincorporates the sememe-based word substitution method and particle swarm\noptimization-based search algorithm to solve the two problems separately. We\nconduct exhaustive experiments to evaluate our attack model by attacking BiLSTM\nand BERT on three benchmark datasets. Experimental results demonstrate that our\nmodel consistently achieves much higher attack success rates and crafts more\nhigh-quality adversarial examples as compared to baseline methods. Also,\nfurther experiments show our model has higher transferability and can bring\nmore robustness enhancement to victim models by adversarial training. All the\ncode and data of this paper can be obtained on\nhttps://github.com/thunlp/SememePSO-Attack.", "published": "2019-10-27 06:54:27", "link": "http://arxiv.org/abs/1910.12196v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "abstract": "The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics", "published": "2019-10-27 07:44:33", "link": "http://arxiv.org/abs/1910.12203v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Algorithmic Copywriting: Automated Generation of Health-Related\n  Advertisements to Improve their Performance", "abstract": "Search advertising, a popular method for online marketing, has been employed\nto improve health by eliciting positive behavioral change. However, writing\neffective advertisements requires expertise and experimentation, which may not\nbe available to health authorities wishing to elicit such changes, especially\nwhen dealing with public health crises such as epidemic outbreaks.\n  Here we develop a framework, comprised of two neural networks models, that\nautomatically generate ads. First, it employs a generator model, which create\nads from web pages. It then employs a translation model, which transcribes ads\nto improve performance.\n  We trained the networks using 114K health-related ads shown on Microsoft\nAdvertising. We measure ads performance using the click-through rates (CTR).\n  Our experiments show that the generated advertisements received approximately\nthe same CTR as human-authored ads. The marginal contribution of the generator\nmodel was, on average, 28\\% lower than that of human-authored ads, while the\ntranslator model received, on average, 32\\% more clicks than human-authored\nads. Our analysis shows that the translator model produces ads reflecting\nhigher values of psychological attributes associated with a user action,\nincluding higher valance and arousal, and more calls-to-actions. In contrast,\nlevels of these attributes in ads produced by the generator model are similar\nto those of human-authored ads.\n  Our results demonstrate the ability to automatically generate useful\nadvertisements for the health domain. We believe that our work offers health\nauthorities an improved ability to nudge people towards healthier behaviors\nwhile saving the time and cost needed to build effective advertising campaigns.", "published": "2019-10-27 14:51:53", "link": "http://arxiv.org/abs/1910.12274v3", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Induced Inflection-Set Keyword Search in Speech", "abstract": "We investigate the problem of searching for a lexeme-set in speech by\nsearching for its inflectional variants. Experimental results indicate how\nlexeme-set search performance changes with the number of hypothesized\ninflections, while ablation experiments highlight the relative importance of\ndifferent components in the lexeme-set search pipeline and the value of using\ncurated inflectional paradigms. We provide a recipe and evaluation set for the\ncommunity to use as an extrinsic measure of the performance of inflection\ngeneration approaches.", "published": "2019-10-27 16:54:26", "link": "http://arxiv.org/abs/1910.12299v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Task-Oriented Language Grounding for Language Input with Multiple\n  Sub-Goals of Non-Linear Order", "abstract": "In this work, we analyze the performance of general deep reinforcement\nlearning algorithms for a task-oriented language grounding problem, where\nlanguage input contains multiple sub-goals and their order of execution is\nnon-linear.\n  We generate a simple instructional language for the GridWorld environment,\nthat is built around three language elements (order connectors) defining the\norder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"but\nbefore\". We apply one of the deep reinforcement learning baselines - Double DQN\nwith frame stacking and ablate several extensions such as Prioritized\nExperience Replay and Gated-Attention architecture.\n  Our results show that the introduction of non-linear order connectors\nimproves the success rate on instructions with a higher number of sub-goals in\n2-3 times, but it still does not exceed 20%. Also, we observe that the usage of\nGated-Attention provides no competitive advantage against concatenation in this\nsetting. Source code and experiments' results are available at\nhttps://github.com/vkurenkov/language-grounding-multigoal", "published": "2019-10-27 21:11:42", "link": "http://arxiv.org/abs/1910.12354v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "abstract": "We study the problem of model extraction in natural language processing, in\nwhich an adversary with only query access to a victim model attempts to\nreconstruct a local copy of that model. Assuming that both the adversary and\nvictim model fine-tune a large pretrained language model such as BERT (Devlin\net al. 2019), we show that the adversary does not need any real training data\nto successfully mount the attack. In fact, the attacker need not even use\ngrammatical or semantically meaningful queries: we show that random sequences\nof words coupled with task-specific heuristics form effective queries for model\nextraction on a diverse set of NLP tasks, including natural language inference\nand question answering. Our work thus highlights an exploit only made feasible\nby the shift towards transfer learning methods within the NLP community: for a\nquery budget of a few hundred dollars, an attacker can extract a model that\nperforms only slightly worse than the victim model. Finally, we study two\ndefense strategies against model extraction---membership classification and API\nwatermarking---which while successful against naive adversaries, are\nineffective against more sophisticated ones.", "published": "2019-10-27 22:09:13", "link": "http://arxiv.org/abs/1910.12366v3", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training ASR models by Generation of Contextual Information", "abstract": "Supervised ASR models have reached unprecedented levels of accuracy, thanks\nin part to ever-increasing amounts of labelled training data. However, in many\napplications and locales, only moderate amounts of data are available, which\nhas led to a surge in semi- and weakly-supervised learning research. In this\npaper, we conduct a large-scale study evaluating the effectiveness of\nweakly-supervised learning for speech recognition by using loosely related\ncontextual information as a surrogate for ground-truth labels. For weakly\nsupervised training, we use 50k hours of public English social media videos\nalong with their respective titles and post text to train an encoder-decoder\ntransformer model. Our best encoder-decoder models achieve an average of 20.8%\nWER reduction over a 1000 hours supervised baseline, and an average of 13.4%\nWER reduction when using only the weakly supervised encoder for CTC\nfine-tuning. Our results show that our setup for weak supervision improved both\nthe encoder acoustic representations as well as the decoder language generation\nabilities.", "published": "2019-10-27 22:13:09", "link": "http://arxiv.org/abs/1910.12367v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sound Event Recognition in a Smart City Surveillance Context", "abstract": "Due to the growing demand for improving surveillance capabilities in smart\ncities, systems need to be developed to provide better monitoring capabilities\nto competent authorities, agencies responsible for strategic resource\nmanagement, and emergency call centers. This work assumes that, as a\ncomplementary monitoring solution, the use of a system capable of detecting the\noccurrence of sound events, performing the Sound Events Recognition (SER) task,\nis highly convenient. In order to contribute to the classification of such\nevents, this paper explored several classifiers over the SESA dataset, composed\nof audios of three hazard classes (gunshots, explosions, and sirens) and a\nclass of casual sounds that could be misinterpreted as some of the other\nsounds. The best result was obtained by SGD, with an accuracy of 72.13% with\n6.81 ms classification time, reinforcing the viability of such an approach.", "published": "2019-10-27 22:17:26", "link": "http://arxiv.org/abs/1910.12369v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Transferring neural speech waveform synthesizers to musical instrument\n  sounds generation", "abstract": "Recent neural waveform synthesizers such as WaveNet, WaveGlow, and the\nneural-source-filter (NSF) model have shown good performance in speech\nsynthesis despite their different methods of waveform generation. The\nsimilarity between speech and music audio synthesis techniques suggests\ninteresting avenues to explore in terms of the best way to apply speech\nsynthesizers in the music domain. This work compares three neural synthesizers\nused for musical instrument sounds generation under three scenarios: training\nfrom scratch on music data, zero-shot learning from the speech domain, and\nfine-tuning-based adaptation from the speech to the music domain. The results\nof a large-scale perceptual test demonstrated that the performance of three\nsynthesizers improved when they were pre-trained on speech data and fine-tuned\non music data, which indicates the usefulness of knowledge from speech data for\nmusic audio generation. Among the synthesizers, WaveGlow showed the best\npotential in zero-shot learning while NSF performed best in the other scenarios\nand could generate samples that were perceptually close to natural audio.", "published": "2019-10-27 23:47:43", "link": "http://arxiv.org/abs/1910.12381v2", "categories": ["eess.AS", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Dr.VOT : Measuring Positive and Negative Voice Onset Time in the Wild", "abstract": "Voice Onset Time (VOT), a key measurement of speech for basic research and\napplied medical studies, is the time between the onset of a stop burst and the\nonset of voicing. When the voicing onset precedes burst onset the VOT is\nnegative; if voicing onset follows the burst, it is positive. In this work, we\npresent a deep-learning model for accurate and reliable measurement of VOT in\nnaturalistic speech. The proposed system addresses two critical issues: it can\nmeasure positive and negative VOT equally well, and it is trained to be robust\nto variation across annotations. Our approach is based on the structured\nprediction framework, where the feature functions are defined to be RNNs. These\nlearn to capture segmental variation in the signal. Results suggest that our\nmethod substantially improves over the current state-of-the-art. In contrast to\nprevious work, our Deep and Robust VOT annotator, Dr.VOT, can successfully\nestimate negative VOTs while maintaining state-of-the-art performance on\npositive VOTs. This high level of performance generalizes to new corpora\nwithout further retraining. Index Terms: structured prediction, multi-task\nlearning, adversarial training, recurrent neural networks, sequence\nsegmentation.", "published": "2019-10-27 12:42:52", "link": "http://arxiv.org/abs/1910.13255v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
