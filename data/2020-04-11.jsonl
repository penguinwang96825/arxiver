{"title": "Improving Disfluency Detection by Self-Training a Self-Attentive Model", "abstract": "Self-attentive neural syntactic parsers using contextualized word embeddings\n(e.g. ELMo or BERT) currently produce state-of-the-art results in joint parsing\nand disfluency detection in speech transcripts. Since the contextualized word\nembeddings are pre-trained on a large amount of unlabeled data, using\nadditional unlabeled data to train a neural model might seem redundant.\nHowever, we show that self-training - a semi-supervised technique for\nincorporating unlabeled data - sets a new state-of-the-art for the\nself-attentive parser on disfluency detection, demonstrating that self-training\nprovides benefits orthogonal to the pre-trained contextualized word\nrepresentations. We also show that ensembling self-trained parsers provides\nfurther gains for disfluency detection.", "published": "2020-04-11 06:53:08", "link": "http://arxiv.org/abs/2004.05323v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End to End Chinese Lexical Fusion Recognition with Sememe Knowledge", "abstract": "In this paper, we present Chinese lexical fusion recognition, a new task\nwhich could be regarded as one kind of coreference recognition. First, we\nintroduce the task in detail, showing the relationship with coreference\nrecognition and differences from the existing tasks. Second, we propose an\nend-to-end joint model for the task, which exploits the state-of-the-art BERT\nrepresentations as encoder, and is further enhanced with the sememe knowledge\nfrom HowNet by graph attention networks. We manually annotate a benchmark\ndataset for the task and then conduct experiments on it. Results demonstrate\nthat our joint model is effective and competitive for the task. Detailed\nanalysis is offered for comprehensively understanding the new task and our\nproposed model.", "published": "2020-04-11 18:17:18", "link": "http://arxiv.org/abs/2004.05456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Commonsense Question Answering with Self-Talk", "abstract": "Natural language understanding involves reading between the lines with\nimplicit background knowledge. Current systems either rely on pre-trained\nlanguage models as the sole implicit source of world knowledge, or resort to\nexternal knowledge bases (KBs) to incorporate additional relevant knowledge. We\npropose an unsupervised framework based on self-talk as a novel alternative to\nmultiple-choice commonsense tasks. Inspired by inquiry-based discovery learning\n(Bruner, 1961), our approach inquires language models with a number of\ninformation seeking questions such as \"$\\textit{what is the definition of\n...}$\" to discover additional background knowledge. Empirical results\ndemonstrate that the self-talk procedure substantially improves the performance\nof zero-shot language model baselines on four out of six commonsense\nbenchmarks, and competes with models that obtain knowledge from external KBs.\nWhile our approach improves performance on several benchmarks, the self-talk\ninduced knowledge even when leading to correct answers is not always seen as\nuseful by human judges, raising interesting questions about the inner-workings\nof pre-trained language models for commonsense reasoning.", "published": "2020-04-11 20:43:37", "link": "http://arxiv.org/abs/2004.05483v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Impress Me: Dialogue Generation via Mutual Persona Perception", "abstract": "Despite the continuing efforts to improve the engagingness and consistency of\nchit-chat dialogue systems, the majority of current work simply focus on\nmimicking human-like responses, leaving understudied the aspects of modeling\nunderstanding between interlocutors. The research in cognitive science,\ninstead, suggests that understanding is an essential signal for a high-quality\nchit-chat conversation. Motivated by this, we propose P^2 Bot, a\ntransmitter-receiver based framework with the aim of explicitly modeling\nunderstanding. Specifically, P^2 Bot incorporates mutual persona perception to\nenhance the quality of personalized dialogue generation. Experiments on a large\npublic dataset, Persona-Chat, demonstrate the effectiveness of our approach,\nwith a considerable boost over the state-of-the-art baselines across both\nautomatic metrics and human evaluations.", "published": "2020-04-11 12:51:07", "link": "http://arxiv.org/abs/2004.05388v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Annotating Social Determinants of Health Using Active Learning, and\n  Characterizing Determinants Using Neural Event Extraction", "abstract": "Social determinants of health (SDOH) affect health outcomes, and knowledge of\nSDOH can inform clinical decision-making. Automatically extracting SDOH\ninformation from clinical text requires data-driven information extraction\nmodels trained on annotated corpora that are heterogeneous and frequently\ninclude critical SDOH. This work presents a new corpus with SDOH annotations, a\nnovel active learning framework, and the first extraction results on the new\ncorpus. The Social History Annotation Corpus (SHAC) includes 4,480 social\nhistory sections with detailed annotation for 12 SDOH characterizing the\nstatus, extent, and temporal information of 18K distinct events. We introduce a\nnovel active learning framework that selects samples for annotation using a\nsurrogate text classification task as a proxy for a more complex event\nextraction task. The active learning framework successfully increases the\nfrequency of health risk factors and improves automatic extraction of these\nevents over undirected annotation. An event extraction model trained on SHAC\nachieves high extraction performance for substance use status (0.82-0.93 F1),\nemployment status (0.81-0.86 F1), and living status type (0.81-0.93 F1) on data\nfrom three institutions.", "published": "2020-04-11 16:19:02", "link": "http://arxiv.org/abs/2004.05438v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LAReQA: Language-agnostic answer retrieval from a multilingual pool", "abstract": "We present LAReQA, a challenging new benchmark for language-agnostic answer\nretrieval from a multilingual candidate pool. Unlike previous cross-lingual\ntasks, LAReQA tests for \"strong\" cross-lingual alignment, requiring\nsemantically related cross-language pairs to be closer in representation space\nthan unrelated same-language pairs. Building on multilingual BERT (mBERT), we\nstudy different strategies for achieving strong alignment. We find that\naugmenting training data via machine translation is effective, and improves\nsignificantly over using mBERT out-of-the-box. Interestingly, the embedding\nbaseline that performs the best on LAReQA falls short of competing baselines on\nzero-shot variants of our task that only target \"weak\" alignment. This finding\nunderscores our claim that languageagnostic retrieval is a substantively new\nkind of cross-lingual evaluation.", "published": "2020-04-11 20:51:11", "link": "http://arxiv.org/abs/2004.05484v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improved Speech Representations with Multi-Target Autoregressive\n  Predictive Coding", "abstract": "Training objectives based on predictive coding have recently been shown to be\nvery effective at learning meaningful representations from unlabeled speech.\nOne example is Autoregressive Predictive Coding (Chung et al., 2019), which\ntrains an autoregressive RNN to generate an unseen future frame given a context\nsuch as recent past frames. The basic hypothesis of these approaches is that\nhidden states that can accurately predict future frames are a useful\nrepresentation for many downstream tasks. In this paper we extend this\nhypothesis and aim to enrich the information encoded in the hidden states by\ntraining the model to make more accurate future predictions. We propose an\nauxiliary objective that serves as a regularization to improve generalization\nof the future frame prediction task. Experimental results on phonetic\nclassification, speech recognition, and speech translation not only support the\nhypothesis, but also demonstrate the effectiveness of our approach in learning\nrepresentations that contain richer phonetic content.", "published": "2020-04-11 01:09:36", "link": "http://arxiv.org/abs/2004.05274v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DeepSentiPers: Novel Deep Learning Models Trained Over Proposed\n  Augmented Persian Sentiment Corpus", "abstract": "This paper focuses on how to extract opinions over each Persian\nsentence-level text. Deep learning models provided a new way to boost the\nquality of the output. However, these architectures need to feed on big\nannotated data as well as an accurate design. To best of our knowledge, we do\nnot merely suffer from lack of well-annotated Persian sentiment corpus, but\nalso a novel model to classify the Persian opinions in terms of both multiple\nand binary classification. So in this work, first we propose two novel deep\nlearning architectures comprises of bidirectional LSTM and CNN. They are a part\nof a deep hierarchy designed precisely and also able to classify sentences in\nboth cases. Second, we suggested three data augmentation techniques for the\nlow-resources Persian sentiment corpus. Our comprehensive experiments on three\nbaselines and two different neural word embedding methods show that our data\naugmentation methods and intended models successfully address the aims of the\nresearch.", "published": "2020-04-11 07:45:35", "link": "http://arxiv.org/abs/2004.05328v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Classifying Constructive Comments", "abstract": "We introduce the Constructive Comments Corpus (C3), comprised of 12,000\nannotated news comments, intended to help build new tools for online\ncommunities to improve the quality of their discussions. We define constructive\ncomments as high-quality comments that make a contribution to the conversation.\nWe explain the crowd worker annotation scheme and define a taxonomy of\nsub-characteristics of constructiveness. The quality of the annotation scheme\nand the resulting dataset is evaluated using measurements of inter-annotator\nagreement, expert assessment of a sample, and by the constructiveness\nsub-characteristics, which we show provide a proxy for the general\nconstructiveness concept. We provide models for constructiveness trained on C3\nusing both feature-based and a variety of deep learning approaches and\ndemonstrate that these models capture general rather than topic- or\ndomain-specific characteristics of constructiveness, through domain adaptation\nexperiments. We examine the role that length plays in our models, as comment\nlength could be easily gamed if models depend heavily upon this feature. By\nexamining the errors made by each model and their distribution by length, we\nshow that the best performing models are less correlated with comment\nlength.The constructiveness corpus and our experiments pave the way for a\nmoderation tool focused on promoting comments that make a contribution, rather\nthan only filtering out undesirable content.", "published": "2020-04-11 20:05:52", "link": "http://arxiv.org/abs/2004.05476v4", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Classification Benchmarks for Under-resourced Bengali Language based on\n  Multichannel Convolutional-LSTM Network", "abstract": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices but also\nenables people to express anti-social behaviour like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behaviours analysis, document\ncharacterization, and sentiment analysis by predicting the contexts mostly for\nhighly resourced languages such as English. However, there are languages that\nare under-resources, e.g., South Asian languages like Bengali, Tamil, Assamese,\nTelugu that lack of computational resources for the NLP tasks. In this paper,\nwe provide several classification benchmarks for Bengali, an under-resourced\nlanguage. We prepared three datasets of expressing hate, commonly used topics,\nand opinions for hate speech detection, document classification, and sentiment\nanalysis, respectively. We built the largest Bengali word embedding models to\ndate based on 250 million articles, which we call BengFastText. We perform\nthree different experiments, covering document classification, sentiment\nanalysis, and hate speech detection. We incorporate word embeddings into a\nMultichannel Convolutional-LSTM (MConv-LSTM) network for predicting different\ntypes of hate speech, document classification, and sentiment analysis.\nExperiments demonstrate that BengFastText can capture the semantics of words\nfrom respective contexts correctly. Evaluations against several baseline\nembedding models, e.g., Word2Vec and GloVe yield up to 92.30%, 82.25%, and\n90.45% F1-scores in case of document classification, sentiment analysis, and\nhate speech detection, respectively during 5-fold cross-validation tests.", "published": "2020-04-11 22:17:04", "link": "http://arxiv.org/abs/2004.07807v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
