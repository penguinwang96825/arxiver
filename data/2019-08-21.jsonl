{"title": "MoEL: Mixture of Empathetic Listeners", "abstract": "Previous research on empathetic dialogue systems has mostly focused on\ngenerating responses given certain emotions. However, being empathetic not only\nrequires the ability of generating emotional responses, but more importantly,\nrequires the understanding of user emotions and replying appropriately. In this\npaper, we propose a novel end-to-end approach for modeling empathy in dialogue\nsystems: Mixture of Empathetic Listeners (MoEL). Our model first captures the\nuser emotions and outputs an emotion distribution. Based on this, MoEL will\nsoftly combine the output states of the appropriate Listener(s), which are each\noptimized to react to certain emotions, and generate an empathetic response.\nHuman evaluations on empathetic-dialogues (Rashkin et al., 2018) dataset\nconfirm that MoEL outperforms multitask training baseline in terms of empathy,\nrelevance, and fluency. Furthermore, the case study on generated responses of\ndifferent Listeners shows high interpretability of our model.", "published": "2019-08-21 03:02:56", "link": "http://arxiv.org/abs/1908.07687v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Machine Translation with Pre-trained Representation", "abstract": "Monolingual data has been demonstrated to be helpful in improving the\ntranslation quality of neural machine translation (NMT). The current methods\nstay at the usage of word-level knowledge, such as generating synthetic\nparallel data or extracting information from word embedding. In contrast, the\npower of sentence-level contextual knowledge which is more complex and diverse,\nplaying an important role in natural language generation, has not been fully\nexploited. In this paper, we propose a novel structure which could leverage\nmonolingual data to acquire sentence-level contextual representations. Then, we\ndesign a framework for integrating both source and target sentence-level\nrepresentations into NMT model to improve the translation quality. Experimental\nresults on Chinese-English, German-English machine translation tasks show that\nour proposed model achieves improvement over strong Transformer baselines,\nwhile experiments on English-Turkish further demonstrate the effectiveness of\nour approach in the low-resource scenario.", "published": "2019-08-21 03:03:12", "link": "http://arxiv.org/abs/1908.07688v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Relation Language Models", "abstract": "In this paper, we propose Latent Relation Language Models (LRLMs), a class of\nlanguage models that parameterizes the joint distribution over the words in a\ndocument and the entities that occur therein via knowledge graph relations.\nThis model has a number of attractive properties: it not only improves language\nmodeling performance, but is also able to annotate the posterior probability of\nentity spans for a given text through relations. Experiments demonstrate\nempirical improvements over both a word-based baseline language model and a\nprevious approach that incorporates knowledge graph information. Qualitative\nanalysis further demonstrates the proposed model's ability to learn to predict\nappropriate relations in context.", "published": "2019-08-21 03:09:16", "link": "http://arxiv.org/abs/1908.07690v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Copy-Enhanced Heterogeneous Information Learning for Dialogue State\n  Tracking", "abstract": "Dialogue state tracking (DST) is an essential component in task-oriented\ndialogue systems, which estimates user goals at every dialogue turn. However,\nmost previous approaches usually suffer from the following problems. Many\ndiscriminative models, especially end-to-end (E2E) models, are difficult to\nextract unknown values that are not in the candidate ontology; previous\ngenerative models, which can extract unknown values from utterances, degrade\nthe performance due to ignoring the semantic information of pre-defined\nontology. Besides, previous generative models usually need a hand-crafted list\nto normalize the generated values. How to integrate the semantic information of\npre-defined ontology and dialogue text (heterogeneous texts) to generate\nunknown values and improve performance becomes a severe challenge. In this\npaper, we propose a Copy-Enhanced Heterogeneous Information Learning model with\nmultiple encoder-decoder for DST (CEDST), which can effectively generate all\npossible values including unknown values by copying values from heterogeneous\ntexts. Meanwhile, CEDST can effectively decompose the large state space into\nseveral small state spaces through multi-encoder, and employ multi-decoder to\nmake full use of the reduced spaces to generate values. Multi-encoder-decoder\narchitecture can significantly improve performance. Experiments show that CEDST\ncan achieve state-of-the-art results on two datasets and our constructed\ndatasets with many unknown values.", "published": "2019-08-21 04:05:54", "link": "http://arxiv.org/abs/1908.07705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese\n  Medical Text", "abstract": "Entity and relation extraction is the necessary step in structuring medical\ntext. However, the feature extraction ability of the bidirectional long short\nterm memory network in the existing model does not achieve the best effect. At\nthe same time, the language model has achieved excellent results in more and\nmore natural language processing tasks. In this paper, we present a focused\nattention model for the joint entity and relation extraction task. Our model\nintegrates well-known BERT language model into joint learning through dynamic\nrange attention mechanism, thus improving the feature representation ability of\nshared parameter layer. Experimental results on coronary angiography texts\ncollected from Shuguang Hospital show that the F1-score of named entity\nrecognition and relation classification tasks reach 96.89% and 88.51%, which\nare better than state-of-the-art methods 1.65% and 1.22%, respectively.", "published": "2019-08-21 06:56:08", "link": "http://arxiv.org/abs/1908.07721v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word\n  Embedding Learning", "abstract": "Cross-lingual word embeddings are vector representations of words in\ndifferent languages where words with similar meaning are represented by similar\nvectors, regardless of the language. Recent developments which construct these\nembeddings by aligning monolingual spaces have shown that accurate alignments\ncan be obtained with little or no supervision. However, the focus has been on a\nparticular controlled scenario for evaluation, and there is no strong evidence\non how current state-of-the-art systems would fare with noisy text or for\nlanguage pairs with major linguistic differences. In this paper we present an\nextensive evaluation over multiple cross-lingual embedding models, analyzing\ntheir strengths and limitations with respect to different variables such as\ntarget language, training corpora and amount of supervision. Our conclusions\nput in doubt the view that high-quality cross-lingual embeddings can always be\nlearned without much supervision.", "published": "2019-08-21 08:01:13", "link": "http://arxiv.org/abs/1908.07742v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predict Emoji Combination with Retrieval Strategy", "abstract": "As emojis are widely used in social media, people not only use an emoji to\nexpress their emotions or mention things but also extend its usage to represent\ncomplicate emotions, concepts or activities by combining multiple emojis. In\nthis work, we study how emoji combination, a consecutive emoji sequence, is\nused like a new language. We propose a novel algorithm called Retrieval\nStrategy to predict what emoji combination follows given a short text as\ncontext. Our algorithm treats emoji combinations as phrase in language, ranking\nsets of emoji combinations like retrieving words from dictionary. We show that\nour algorithm largely improves the F1 score from 0.141 to 0.204 on emoji\ncombination prediction task.", "published": "2019-08-21 09:25:53", "link": "http://arxiv.org/abs/1908.07761v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Better Understanding of Spontaneous Conversations: Overcoming\n  Automatic Speech Recognition Errors With Intent Recognition", "abstract": "In this paper, we present a method for correcting automatic speech\nrecognition (ASR) errors using a finite state transducer (FST) intent\nrecognition framework. Intent recognition is a powerful technique for dialog\nflow management in turn-oriented, human-machine dialogs. This technique can\nalso be very useful in the context of human-human dialogs, though it serves a\ndifferent purpose of key insight extraction from conversations. We argue that\ncurrently available intent recognition techniques are not applicable to\nhuman-human dialogs due to the complex structure of turn-taking and various\ndisfluencies encountered in spontaneous conversations, exacerbated by speech\nrecognition errors and scarcity of domain-specific labeled data. Without\nefficient key insight extraction techniques, raw human-human dialog transcripts\nremain significantly unexploited.\n  Our contribution consists of a novel FST for intent indexing and an algorithm\nfor fuzzy intent search over the lattice - a compact graph encoding of ASR's\nhypotheses. We also develop a pruning strategy to constrain the fuzziness of\nthe FST index search. Extracted intents represent linguistic domain knowledge\nand help us improve (rescore) the original transcript. We compare our method\nwith a baseline, which uses only the most likely transcript hypothesis (best\npath), and find an increase in the total number of recognized intents by 25%.", "published": "2019-08-21 14:20:35", "link": "http://arxiv.org/abs/1908.07888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are We Modeling the Task or the Annotator? An Investigation of Annotator\n  Bias in Natural Language Understanding Datasets", "abstract": "Crowdsourcing has been the prevalent paradigm for creating natural language\nunderstanding datasets in recent years. A common crowdsourcing practice is to\nrecruit a small number of high-quality workers, and have them massively\ngenerate examples. Having only a few workers generate the majority of examples\nraises concerns about data diversity, especially when workers freely generate\nsentences. In this paper, we perform a series of experiments showing these\nconcerns are evident in three recent NLP datasets. We show that model\nperformance improves when training with annotator identifiers as features, and\nthat models are able to recognize the most productive annotators. Moreover, we\nshow that often models do not generalize well to examples from annotators that\ndid not contribute to the training set. Our findings suggest that annotator\nbias should be monitored during dataset creation, and that test set annotators\nshould be disjoint from training set annotators.", "published": "2019-08-21 14:48:01", "link": "http://arxiv.org/abs/1908.07898v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiCREM: A Large Unsupervised Corpus for Coreference Resolution", "abstract": "Pronoun resolution is a major area of natural language understanding.\nHowever, large-scale training sets are still scarce, since manually labelling\ndata is costly. In this work, we introduce WikiCREM (Wikipedia CoREferences\nMasked) a large-scale, yet accurate dataset of pronoun disambiguation\ninstances. We use a language-model-based approach for pronoun resolution in\ncombination with our WikiCREM dataset. We compare a series of models on a\ncollection of diverse and challenging coreference resolution problems, where we\nmatch or outperform previous state-of-the-art approaches on 6 out of 7\ndatasets, such as GAP, DPR, WNLI, PDP, WinoBias, and WinoGender. We release our\nmodel to be used off-the-shelf for solving pronoun disambiguation.", "published": "2019-08-21 17:42:03", "link": "http://arxiv.org/abs/1908.08025v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Mask and Infill\" : Applying Masked Language Model to Sentiment Transfer", "abstract": "This paper focuses on the task of sentiment transfer on non-parallel text,\nwhich modifies sentiment attributes (e.g., positive or negative) of sentences\nwhile preserving their attribute-independent content. Due to the limited\ncapability of RNNbased encoder-decoder structure to capture deep and long-range\ndependencies among words, previous works can hardly generate satisfactory\nsentences from scratch. When humans convert the sentiment attribute of a\nsentence, a simple but effective approach is to only replace the original\nsentimental tokens in the sentence with target sentimental expressions, instead\nof building a new sentence from scratch. Such a process is very similar to the\ntask of Text Infilling or Cloze, which could be handled by a deep bidirectional\nMasked Language Model (e.g. BERT). So we propose a two step approach \"Mask and\nInfill\". In the mask step, we separate style from content by masking the\npositions of sentimental tokens. In the infill step, we retrofit MLM to\nAttribute Conditional MLM, to infill the masked positions by predicting words\nor phrases conditioned on the context1 and target sentiment. We evaluate our\nmodel on two review datasets with quantitative, qualitative, and human\nevaluations. Experimental results demonstrate that our models improve\nstate-of-the-art performance.", "published": "2019-08-21 23:12:36", "link": "http://arxiv.org/abs/1908.08039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Populating Web Scale Knowledge Graphs using Distantly Supervised\n  Relation Extraction and Validation", "abstract": "In this paper, we propose a fully automated system to extend knowledge graphs\nusing external information from web-scale corpora. The designed system\nleverages a deep learning based technology for relation extraction that can be\ntrained by a distantly supervised approach. In addition to that, the system\nuses a deep learning approach for knowledge base completion by utilizing the\nglobal structure information of the induced KG to further refine the confidence\nof the newly discovered relations. The designed system does not require any\neffort for adaptation to new languages and domains as it does not use any\nhand-labeled data, NLP analytics and inference rules. Our experiments,\nperformed on a popular academic benchmark demonstrate that the suggested system\nboosts the performance of relation extraction by a wide margin, reporting error\nreductions of 50%, resulting in relative improvement of up to 100%. Also, a\nweb-scale experiment conducted to extend DBPedia with knowledge from Common\nCrawl shows that our system is not only scalable but also does not require any\nadaptation cost, while yielding substantial accuracy gain.", "published": "2019-08-21 20:13:44", "link": "http://arxiv.org/abs/1908.08104v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "X-SQL: reinforce schema representation with context", "abstract": "In this work, we present X-SQL, a new network architecture for the problem of\nparsing natural language to SQL query. X-SQL proposes to enhance the structural\nschema representation with the contextual output from BERT-style pre-training\nmodel, and together with type information to learn a new schema representation\nfor down-stream tasks. We evaluated X-SQL on the WikiSQL dataset and show its\nnew state-of-the-art performance.", "published": "2019-08-21 20:52:53", "link": "http://arxiv.org/abs/1908.08113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Restricted Recurrent Neural Networks", "abstract": "Recurrent Neural Network (RNN) and its variations such as Long Short-Term\nMemory (LSTM) and Gated Recurrent Unit (GRU), have become standard building\nblocks for learning online data of sequential nature in many research areas,\nincluding natural language processing and speech data analysis. In this paper,\nwe present a new methodology to significantly reduce the number of parameters\nin RNNs while maintaining performance that is comparable or even better than\nclassical RNNs. The new proposal, referred to as Restricted Recurrent Neural\nNetwork (RRNN), restricts the weight matrices corresponding to the input data\nand hidden states at each time step to share a large proportion of parameters.\nThe new architecture can be regarded as a compression of its classical\ncounterpart, but it does not require pre-training or sophisticated parameter\nfine-tuning, both of which are major issues in most existing compression\ntechniques. Experiments on natural language modeling show that compared with\nits classical counterpart, the restricted recurrent architecture generally\nproduces comparable results at about 50\\% compression rate. In particular, the\nRestricted LSTM can outperform classical RNN with even less number of\nparameters.", "published": "2019-08-21 07:12:31", "link": "http://arxiv.org/abs/1908.07724v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Captioning for Low-Resource Languages by Cycle Consistency", "abstract": "Improving the captioning performance on low-resource languages by leveraging\nEnglish caption datasets has received increasing research interest in recent\nyears. Existing works mainly fall into two categories: translation-based and\nalignment-based approaches. In this paper, we propose to combine the merits of\nboth approaches in one unified architecture. Specifically, we use a pre-trained\nEnglish caption model to generate high-quality English captions, and then take\nboth the image and generated English captions to generate low-resource language\ncaptions. We improve the captioning performance by adding the cycle consistency\nconstraint on the cycle of image regions, English words, and low-resource\nlanguage words. Moreover, our architecture has a flexible design which enables\nit to benefit from large monolingual English caption datasets. Experimental\nresults demonstrate that our approach outperforms the state-of-the-art methods\non common evaluation metrics. The attention visualization also shows that the\nproposed approach really improves the fine-grained alignment between words and\nimage regions.", "published": "2019-08-21 12:15:35", "link": "http://arxiv.org/abs/1908.07810v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Rating for Parents: Predicting Children Suitability Rating for Movies\n  Based on Language of the Movies", "abstract": "The film culture has grown tremendously in recent years. The large number of\nstreaming services put films as one of the most convenient forms of\nentertainment in today's world. Films can help us learn and inspire societal\nchange. But they can also negatively affect viewers. In this paper, our goal is\nto predict the suitability of the movie content for children and young adults\nbased on scripts. The criterion that we use to measure suitability is the MPAA\nrating that is specifically designed for this purpose. We propose an RNN based\narchitecture with attention that jointly models the genre and the emotions in\nthe script to predict the MPAA rating. We achieve 78% weighted F1-score for the\nclassification model that outperforms the traditional machine learning method\nby 6%.", "published": "2019-08-21 15:18:10", "link": "http://arxiv.org/abs/1908.07819v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Good is Artificial Intelligence at Automatically Answering Consumer\n  Questions Related to Alzheimer's Disease?", "abstract": "Alzheimer's Disease (AD) is the most common type of dementia, comprising\n60-80% of cases. There were an estimated 5.8 million Americans living with\nAlzheimer's dementia in 2019, and this number will almost double every 20\nyears. The total lifetime cost of care for someone with dementia is estimated\nto be $350,174 in 2018, 70% of which is associated with family-provided care.\nMost family caregivers face emotional, financial and physical difficulties. As\na medium to relieve this burden, online communities in social media websites\nsuch as Twitter, Reddit, and Yahoo! Answers provide potential venues for\ncaregivers to search relevant questions and answers, or post questions and seek\nanswers from other members. However, there are often a limited number of\nrelevant questions and responses to search from, and posted questions are\nrarely answered immediately. Due to recent advancement in Artificial\nIntelligence (AI), particularly Natural Language Processing (NLP), we propose\nto utilize AI to automatically generate answers to AD-related consumer\nquestions posted by caregivers and evaluate how good AI is at answering those\nquestions. To the best of our knowledge, this is the first study in the\nliterature applying and evaluating AI models designed to automatically answer\nconsumer questions related to AD.", "published": "2019-08-21 19:08:56", "link": "http://arxiv.org/abs/1908.10678v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Dialog State Tracking with Reinforced Data Augmentation", "abstract": "Neural dialog state trackers are generally limited due to the lack of\nquantity and diversity of annotated training data. In this paper, we address\nthis difficulty by proposing a reinforcement learning (RL) based framework for\ndata augmentation that can generate high-quality data to improve the neural\nstate tracker. Specifically, we introduce a novel contextual bandit generator\nto learn fine-grained augmentation policies that can generate new effective\ninstances by choosing suitable replacements for the specific context. Moreover,\nby alternately learning between the generator and the state tracker, we can\nkeep refining the generative policies to generate more high-quality training\ndata for neural state tracker. Experimental results on the WoZ and MultiWoZ\n(restaurant) datasets demonstrate that the proposed framework significantly\nimproves the performance over the state-of-the-art models, especially with\nlimited training data.", "published": "2019-08-21 11:07:14", "link": "http://arxiv.org/abs/1908.07795v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Defensive Distillation For Defending Text Processing Neural\n  Networks Against Adversarial Examples", "abstract": "Adversarial examples are artificially modified input samples which lead to\nmisclassifications, while not being detectable by humans. These adversarial\nexamples are a challenge for many tasks such as image and text classification,\nespecially as research shows that many adversarial examples are transferable\nbetween different classifiers. In this work, we evaluate the performance of a\npopular defensive strategy for adversarial examples called defensive\ndistillation, which can be successful in hardening neural networks against\nadversarial examples in the image domain. However, instead of applying\ndefensive distillation to networks for image classification, we examine, for\nthe first time, its performance on text classification tasks and also evaluate\nits effect on the transferability of adversarial text examples. Our results\nindicate that defensive distillation only has a minimal impact on text\nclassifying neural networks and does neither help with increasing their\nrobustness against adversarial examples nor prevent the transferability of\nadversarial examples between neural networks.", "published": "2019-08-21 14:50:13", "link": "http://arxiv.org/abs/1908.07899v1", "categories": ["cs.CL", "cs.CR", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Revealing the Dark Secrets of BERT", "abstract": "BERT-based architectures currently give state-of-the-art performance on many\nNLP tasks, but little is known about the exact mechanisms that contribute to\nits success. In the current work, we focus on the interpretation of\nself-attention, which is one of the fundamental underlying components of BERT.\nUsing a subset of GLUE tasks and a set of handcrafted features-of-interest, we\npropose the methodology and carry out a qualitative and quantitative analysis\nof the information encoded by the individual BERT's heads. Our findings suggest\nthat there is a limited set of attention patterns that are repeated across\ndifferent heads, indicating the overall model overparametrization. While\ndifferent heads consistently use the same attention patterns, they have varying\nimpact on performance across different tasks. We show that manually disabling\nattention in certain heads leads to a performance improvement over the regular\nfine-tuned BERT models.", "published": "2019-08-21 04:27:38", "link": "http://arxiv.org/abs/1908.08593v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Realistic Face-to-Face Conversation System based on Deep Neural\n  Networks", "abstract": "To improve the experiences of face-to-face conversation with avatar, this\npaper presents a novel conversation system. It is composed of two\nsequence-to-sequence models respectively for listening and speaking and a\nGenerative Adversarial Network (GAN) based realistic avatar synthesizer. The\nmodels exploit the facial action and head pose to learn natural human\nreactions. Based on the models' output, the synthesizer uses the Pixel2Pixel\nmodel to generate realistic facial images. To show the improvement of our\nsystem, we use a 3D model based avatar driving scheme as a reference. We train\nand evaluate our neural networks with the data from ESPN shows. Experimental\nresults show that our conversation system can generate natural facial reactions\nand realistic facial images.", "published": "2019-08-21 08:34:50", "link": "http://arxiv.org/abs/1908.07750v1", "categories": ["cs.CV", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Coarse-to-fine Optimization for Speech Enhancement", "abstract": "In this paper, we propose the coarse-to-fine optimization for the task of\nspeech enhancement. Cosine similarity loss [1] has proven to be an effective\nmetric to measure similarity of speech signals. However, due to the large\nvariance of the enhanced speech with even the same cosine similarity loss in\nhigh dimensional space, a deep neural network learnt with this loss might not\nbe able to predict enhanced speech with good quality. Our coarse-to-fine\nstrategy optimizes the cosine similarity loss for different granularities so\nthat more constraints are added to the prediction from high dimension to\nrelatively low dimension. In this way, the enhanced speech will better resemble\nthe clean speech. Experimental results show the effectiveness of our proposed\ncoarse-to-fine optimization in both discriminative models and generative\nmodels. Moreover, we apply the coarse-to-fine strategy to the adversarial loss\nin generative adversarial network (GAN) and propose dynamic perceptual loss,\nwhich dynamically computes the adversarial loss from coarse resolution to fine\nresolution. Dynamic perceptual loss further improves the accuracy and achieves\nstate-of-the-art results compared with other generative models.", "published": "2019-08-21 17:51:29", "link": "http://arxiv.org/abs/1908.08044v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
