{"title": "Does Transliteration Help Multilingual Language Modeling?", "abstract": "Script diversity presents a challenge to Multilingual Language Models (MLLM)\nby reducing lexical overlap among closely related languages. Therefore,\ntransliterating closely related languages that use different writing scripts to\na common script may improve the downstream task performance of MLLMs. We\nempirically measure the effect of transliteration on MLLMs in this context. We\nspecifically focus on the Indic languages, which have the highest script\ndiversity in the world, and we evaluate our models on the IndicGLUE benchmark.\nWe perform the Mann-Whitney U test to rigorously verify whether the effect of\ntransliteration is significant or not. We find that transliteration benefits\nthe low-resource languages without negatively affecting the comparatively\nhigh-resource languages. We also measure the cross-lingual representation\nsimilarity of the models using centered kernel alignment on parallel sentences\nfrom the FLORES-101 dataset. We find that for parallel sentences across\ndifferent languages, the transliteration-based model learns sentence\nrepresentations that are more similar.", "published": "2022-01-29 05:48:42", "link": "http://arxiv.org/abs/2201.12501v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Unsupervised Multi-Granularity Summarization", "abstract": "Text summarization is a user-preference based task, i.e., for one document,\nusers often have different priorities for summary. As a key aspect of\ncustomization in summarization, granularity is used to measure the semantic\ncoverage between the summary and source document. However, developing systems\nthat can generate summaries with customizable semantic coverage is still an\nunder-explored topic. In this paper, we propose the first unsupervised\nmulti-granularity summarization framework, GranuSum. We take events as the\nbasic semantic units of the source documents and propose to rank these events\nby their salience. We also develop a model to summarize input documents with\ngiven events as anchors and hints. By inputting different numbers of events,\nGranuSum is capable of producing multi-granular summaries in an unsupervised\nmanner. Meanwhile, we annotate a new benchmark GranuDUC that contains multiple\nsummaries at different granularities for each document cluster. Experimental\nresults confirm the substantial superiority of GranuSum on multi-granularity\nsummarization over strong baselines. Further, by exploiting the event\ninformation, GranuSum also exhibits state-of-the-art performance under the\nconventional unsupervised abstractive setting. Dataset for this paper can be\nfound at: https://github.com/maszhongming/GranuDUC", "published": "2022-01-29 05:56:35", "link": "http://arxiv.org/abs/2201.12502v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoDistil: Few-shot Task-agnostic Neural Architecture Search for\n  Distilling Large Language Models", "abstract": "Knowledge distillation (KD) methods compress large models into smaller\nstudents with manually-designed student architectures given pre-specified\ncomputational cost. This requires several trials to find a viable student, and\nfurther repeating the process for each student or computational budget change.\nWe use Neural Architecture Search (NAS) to automatically distill several\ncompressed students with variable cost from a large model. Current works train\na single SuperLM consisting of millions of subnetworks with weight-sharing,\nresulting in interference between subnetworks of different sizes. Our framework\nAutoDistil addresses above challenges with the following steps: (a)\nIncorporates inductive bias and heuristics to partition Transformer search\nspace into K compact sub-spaces (K=3 for typical student sizes of base, small\nand tiny); (b) Trains one SuperLM for each sub-space using task-agnostic\nobjective (e.g., self-attention distillation) with weight-sharing of students;\n(c) Lightweight search for the optimal student without re-training. Fully\ntask-agnostic training and search allow students to be reused for fine-tuning\non any downstream task. Experiments on GLUE benchmark against state-of-the-art\nKD and NAS methods demonstrate AutoDistil to outperform leading compression\ntechniques with upto 2.7x reduction in computational cost and negligible loss\nin task performance.", "published": "2022-01-29 06:13:04", "link": "http://arxiv.org/abs/2201.12507v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple Information-Based Approach to Unsupervised Domain-Adaptive\n  Aspect-Based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask which aims to extract the aspects from sentences and identify their\ncorresponding sentiments. Aspect term extraction (ATE) is the crucial step for\nABSA. Due to the expensive annotation for aspect terms, we often lack labeled\ntarget domain data for fine-tuning. To address this problem, many approaches\nhave been proposed recently to transfer common knowledge in an unsupervised\nway, but such methods have too many modules and require expensive multi-stage\npreprocessing. In this paper, we propose a simple but effective technique based\non mutual information maximization, which can serve as an additional component\nto enhance any kind of model for cross-domain ABSA and ATE. Furthermore, we\nprovide some analysis of this approach. Experiment results show that our\nproposed method outperforms the state-of-the-art methods for cross-domain ABSA\nby 4.32% Micro-F1 on average over 10 different domain pairs. Apart from that,\nour method can be extended to other sequence labeling tasks, such as named\nentity recognition (NER).", "published": "2022-01-29 10:18:07", "link": "http://arxiv.org/abs/2201.12549v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Le Processus Powered Dirichlet-Hawkes comme A Priori Flexible pour\n  Clustering Temporel de Textes", "abstract": "The textual content of a document and its publication date are intertwined.\nFor example, the publication of a news article on a topic is influenced by\nprevious publications on similar issues, according to underlying temporal\ndynamics. However, it can be challenging to retrieve meaningful information\nwhen textual information conveys little. Furthermore, the textual content of a\ndocument is not always correlated to its temporal dynamics. We develop a method\nto create clusters of textual documents according to both their content and\npublication time, the Powered Dirichlet-Hawkes process (PDHP). PDHP yields\nsignificantly better results than state-of-the-art models when temporal\ninformation or textual content is weakly informative. PDHP also alleviates the\nhypothesis that textual content and temporal dynamics are perfectly correlated.\nWe demonstrate that PDHP generalizes previous work --such as DHP and UP.\nFinally, we illustrate a possible application using a real-world dataset from\nReddit.", "published": "2022-01-29 11:48:45", "link": "http://arxiv.org/abs/2201.12568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to pronounce as measuring cross-lingual joint\n  orthography-phonology complexity", "abstract": "Machine learning models allow us to compare languages by showing how hard a\ntask in each language might be to learn and perform well on. Following this\nline of investigation, we explore what makes a language \"hard to pronounce\" by\nmodelling the task of grapheme-to-phoneme (g2p) transliteration. By training a\ncharacter-level transformer model on this task across 22 languages and\nmeasuring the model's proficiency against its grapheme and phoneme inventories,\nwe show that certain characteristics emerge that separate easier and harder\nlanguages with respect to learning to pronounce. Namely the complexity of a\nlanguage's pronunciation from its orthography is due to the expressive or\nsimplicity of its grapheme-to-phoneme mapping. Further discussion illustrates\nhow future studies should consider relative data sparsity per language to\ndesign fairer cross-lingual comparison tasks.", "published": "2022-01-29 14:44:39", "link": "http://arxiv.org/abs/2202.00794v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ScaLA: Accelerating Adaptation of Pre-Trained Transformer-Based Language\n  Models via Efficient Large-Batch Adversarial Noise", "abstract": "In recent years, large pre-trained Transformer-based language models have led\nto dramatic improvements in many natural language understanding tasks. To train\nthese models with increasing sizes, many neural network practitioners attempt\nto increase the batch sizes in order to leverage multiple GPUs to improve\ntraining speed. However, increasing the batch size often makes the optimization\nmore difficult, leading to slow convergence or poor generalization that can\nrequire orders of magnitude more training time to achieve the same model\nquality. In this paper, we explore the steepness of the loss landscape of\nlarge-batch optimization for adapting pre-trained Transformer-based language\nmodels to domain-specific tasks and find that it tends to be highly complex and\nirregular, posing challenges to generalization on downstream tasks.\n  To tackle this challenge, we propose ScaLA, a novel and efficient method to\naccelerate the adaptation speed of pre-trained transformer networks. Different\nfrom prior methods, we take a sequential game-theoretic approach by adding\nlightweight adversarial noise into large-batch optimization, which\nsignificantly improves adaptation speed while preserving model generalization.\nExperiment results show that ScaLA attains 2.7--9.8$\\times$ adaptation speedups\nover the baseline for GLUE on BERT-base and RoBERTa-large, while achieving\ncomparable and sometimes higher accuracy than the state-of-the-art large-batch\noptimization methods. Finally, we also address the theoretical aspect of\nlarge-batch optimization with adversarial noise and provide a theoretical\nconvergence rate analysis for ScaLA using techniques for analyzing non-convex\nsaddle-point problems.", "published": "2022-01-29 01:47:01", "link": "http://arxiv.org/abs/2201.12469v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Incorporating Commonsense Knowledge into Story Ending Generation via\n  Heterogeneous Graph Networks", "abstract": "Story ending generation is an interesting and challenging task, which aims to\ngenerate a coherent and reasonable ending given a story context. The key\nchallenges of the task lie in how to comprehend the story context sufficiently\nand handle the implicit knowledge behind story clues effectively, which are\nstill under-explored by previous work. In this paper, we propose a Story\nHeterogeneous Graph Network (SHGN) to explicitly model both the information of\nstory context at different granularity levels and the multi-grained interactive\nrelations among them. In detail, we consider commonsense knowledge, words and\nsentences as three types of nodes. To aggregate non-local information, a global\nnode is also introduced. Given this heterogeneous graph network, the node\nrepresentations are updated through graph propagation, which adequately\nutilizes commonsense knowledge to facilitate story comprehension. Moreover, we\ndesign two auxiliary tasks to implicitly capture the sentiment trend and key\nevents lie in the context. The auxiliary tasks are jointly optimized with the\nprimary story ending generation task in a multi-task learning strategy.\nExtensive experiments on the ROCStories Corpus show that the developed model\nachieves new state-of-the-art performances. Human study further demonstrates\nthat our model generates more reasonable story endings.", "published": "2022-01-29 09:33:11", "link": "http://arxiv.org/abs/2201.12538v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Deep CNN Architecture with Novel Pooling Layer Applied to Two Sudanese\n  Arabic Sentiment Datasets", "abstract": "Arabic sentiment analysis has become an important research field in recent\nyears. Initially, work focused on Modern Standard Arabic (MSA), which is the\nmost widely-used form. Since then, work has been carried out on several\ndifferent dialects, including Egyptian, Levantine and Moroccan. Moreover, a\nnumber of datasets have been created to support such work. However, up until\nnow, less work has been carried out on Sudanese Arabic, a dialect which has 32\nmillion speakers. In this paper, two new publicly available datasets are\nintroduced, the 2-Class Sudanese Sentiment Dataset (SudSenti2) and the 3-Class\nSudanese Sentiment Dataset (SudSenti3). Furthermore, a CNN architecture, SCM,\nis proposed, comprising five CNN layers together with a novel pooling layer,\nMMA, to extract the best features. This SCM+MMA model is applied to SudSenti2\nand SudSenti3 with accuracies of 92.75% and 84.39%. Next, the model is compared\nto other deep learning classifiers and shown to be superior on these new\ndatasets. Finally, the proposed model is applied to the existing Saudi\nSentiment Dataset and to the MSA Hotel Arabic Review Dataset with accuracies\n85.55% and 90.01%.", "published": "2022-01-29 21:33:28", "link": "http://arxiv.org/abs/2201.12664v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Maximum Batch Frobenius Norm for Multi-Domain Text Classification", "abstract": "Multi-domain text classification (MDTC) has obtained remarkable achievements\ndue to the advent of deep learning. Recently, many endeavors are devoted to\napplying adversarial learning to extract domain-invariant features to yield\nstate-of-the-art results. However, these methods still face one challenge:\ntransforming original features to be domain-invariant distorts the\ndistributions of the original features, degrading the discriminability of the\nlearned features. To address this issue, we first investigate the structure of\nthe batch classification output matrix and theoretically justify that the\ndiscriminability of the learned features has a positive correlation with the\nFrobenius norm of the batch output matrix. Based on this finding, we propose a\nmaximum batch Frobenius norm (MBF) method to boost the feature discriminability\nfor MDTC. Experiments on two MDTC benchmarks show that our MBF approach can\neffectively advance the performance of the state-of-the-art.", "published": "2022-01-29 14:37:56", "link": "http://arxiv.org/abs/2202.00537v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Information Extraction through AI techniques: The KIDs use case at\n  CONSOB", "abstract": "In this paper we report on the initial activities carried out within a\ncollaboration between Consob and Sapienza University. We focus on Information\nExtraction from documents describing financial instruments. We discuss how we\nautomate this task, via both rule-based and machine learning-based methods and\nprovide our first results.", "published": "2022-01-29 20:05:28", "link": "http://arxiv.org/abs/2202.01178v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Progressive Continual Learning for Spoken Keyword Spotting", "abstract": "Catastrophic forgetting is a thorny challenge when updating keyword spotting\n(KWS) models after deployment. To tackle such challenges, we propose a\nprogressive continual learning strategy for small-footprint spoken keyword\nspotting (PCL-KWS). Specifically, the proposed PCL-KWS framework introduces a\nnetwork instantiator to generate the task-specific sub-networks for remembering\npreviously learned keywords. As a result, the PCL-KWS approach incrementally\nlearns new keywords without forgetting prior knowledge. Besides, the\nkeyword-aware network scaling mechanism of PCL-KWS constrains the growth of\nmodel parameters while achieving high performance. Experimental results show\nthat after learning five new tasks sequentially, our proposed PCL-KWS approach\narchives the new state-of-the-art performance of 92.8% average accuracy for all\nthe tasks on Google Speech Command dataset compared with other baselines.", "published": "2022-01-29 10:08:35", "link": "http://arxiv.org/abs/2201.12546v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hand Gesture Recognition of Dumb Person Using one Against All Neural\n  Network", "abstract": "We propose a new technique for recognition of dumb person hand gesture in\nreal world environment. In this technique, the hand image containing the\ngesture is preprocessed and then hand region is segmented by convergent the RGB\ncolor image to L.a.b color space. Only few statistical features are used to\nclassify the segmented image to different classes. Artificial Neural Network is\ntrained in sequential manner using one against all. When the system gets\ntrained, it becomes capable of recognition of each class in parallel manner.\nThe result of proposed technique is much better than existing techniques.", "published": "2022-01-29 17:09:38", "link": "http://arxiv.org/abs/2201.12622v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Decepticons: Corrupted Transformers Breach Privacy in Federated Learning\n  for Language Models", "abstract": "A central tenet of Federated learning (FL), which trains models without\ncentralizing user data, is privacy. However, previous work has shown that the\ngradient updates used in FL can leak user information. While the most\nindustrial uses of FL are for text applications (e.g. keystroke prediction),\nnearly all attacks on FL privacy have focused on simple image classifiers. We\npropose a novel attack that reveals private user text by deploying malicious\nparameter vectors, and which succeeds even with mini-batches, multiple users,\nand long sequences. Unlike previous attacks on FL, the attack exploits\ncharacteristics of both the Transformer architecture and the token embedding,\nseparately extracting tokens and positional embeddings to retrieve\nhigh-fidelity text. This work suggests that FL on text, which has historically\nbeen resistant to privacy attacks, is far more vulnerable than previously\nthought.", "published": "2022-01-29 22:38:21", "link": "http://arxiv.org/abs/2201.12675v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "It\u00f4Wave: It\u00f4 Stochastic Differential Equation Is All You Need For\n  Wave Generation", "abstract": "In this paper, we propose a vocoder based on a pair of forward and\nreverse-time linear stochastic differential equations (SDE). The solutions of\nthis SDE pair are two stochastic processes, one of which turns the distribution\nof wave, that we want to generate, into a simple and tractable distribution.\nThe other is the generation procedure that turns this tractable simple signal\ninto the target wave. The model is called It\\^oWave. It\\^oWave use the Wiener\nprocess as a driver to gradually subtract the excess signal from the noise\nsignal to generate realistic corresponding meaningful audio respectively, under\nthe conditional inputs of original mel spectrogram. The results of the\nexperiment show that the mean opinion scores (MOS) of It\\^oWave can exceed the\ncurrent state-of-the-art (SOTA) methods, and reached 4.35$\\pm$0.115. The\ngenerated audio samples are available online.", "published": "2022-01-29 07:16:57", "link": "http://arxiv.org/abs/2201.12519v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Polyphonic audio event detection: multi-label or multi-class multi-task\n  classification problem?", "abstract": "Polyphonic events are the main error source of audio event detection (AED)\nsystems. In deep-learning context, the most common approach to deal with event\noverlaps is to treat the AED task as a multi-label classification problem. By\ndoing this, we inherently consider multiple one-vs.-rest classification\nproblems, which are jointly solved by a single (i.e. shared) network. In this\nwork, to better handle polyphonic mixtures, we propose to frame the task as a\nmulti-class classification problem by considering each possible label\ncombination as one class. To circumvent the large number of arising classes due\nto combinatorial explosion, we divide the event categories into multiple groups\nand construct a multi-task problem in a divide-and-conquer fashion, where each\nof the tasks is a multi-class classification problem. A network architecture is\nthen devised for multi-class multi-task modelling. The network is composed of a\nbackbone subnet and multiple task-specific subnets. The task-specific subnets\nare designed to learn time-frequency and channel attention masks to extract\nfeatures for the task at hand from the common feature maps learned by the\nbackbone. Experiments on the TUT-SED-Synthetic-2016 with high degree of event\noverlap show that the proposed approach results in more favorable performance\nthan the common multi-label approach.", "published": "2022-01-29 10:52:09", "link": "http://arxiv.org/abs/2201.12557v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The HCCL-DKU system for fake audio generation task of the 2022 ICASSP\n  ADD Challenge", "abstract": "The voice conversion task is to modify the speaker identity of continuous\nspeech while preserving the linguistic content. Generally, the naturalness and\nsimilarity are two main metrics for evaluating the conversion quality, which\nhas been improved significantly in recent years. This paper presents the\nHCCL-DKU entry for the fake audio generation task of the 2022 ICASSP ADD\nchallenge. We propose a novel ppg-based voice conversion model that adopts a\nfully end-to-end structure. Experimental results show that the proposed method\noutperforms other conversion models, including Tacotron-based and\nFastspeech-based models, on conversion quality and spoofing performance against\nanti-spoofing systems. In addition, we investigate several post-processing\nmethods for better spoofing power. Finally, we achieve second place with a\ndeception success rate of 0.916 in the ADD challenge.", "published": "2022-01-29 11:47:01", "link": "http://arxiv.org/abs/2201.12567v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
