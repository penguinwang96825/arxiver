{"title": "Incorporating Sememes into Chinese Definition Modeling", "abstract": "Chinese definition modeling is a challenging task that generates a dictionary\ndefinition in Chinese for a given Chinese word. To accomplish this task, we\nconstruct the Chinese Definition Modeling Corpus (CDM), which contains triples\nof word, sememes and the corresponding definition. We present two novel models\nto improve Chinese definition modeling: the Adaptive-Attention model (AAM) and\nthe Self- and Adaptive-Attention Model (SAAM). AAM successfully incorporates\nsememes for generating the definition with an adaptive attention mechanism. It\nhas the capability to decide which sememes to focus on and when to pay\nattention to sememes. SAAM further replaces recurrent connections in AAM with\nself-attention and relies entirely on the attention mechanism, reducing the\npath length between word, sememes and definition. Experiments on CDM\ndemonstrate that by incorporating sememes, our best proposed model can\noutperform the state-of-the-art method by +6.0 BLEU.", "published": "2019-05-16 03:38:14", "link": "http://arxiv.org/abs/1905.06512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Learning based English Sentiment Analysis", "abstract": "Sentiment analysis or opinion mining aims to determine attitudes, judgments\nand opinions of customers for a product or a service. This is a great system to\nhelp manufacturers or servicers know the satisfaction level of customers about\ntheir products or services. From that, they can have appropriate adjustments.\nWe use a popular machine learning method, being Support Vector Machine, combine\nwith the library in Waikato Environment for Knowledge Analysis (WEKA) to build\nJava web program which analyzes the sentiment of English comments belongs one\nin four types of woman products. That are dresses, handbags, shoes and rings.\nWe have developed and test our system with a training set having 300 comments\nand a test set having 400 comments. The experimental results of the system\nabout precision, recall and F measures for positive comments are 89.3%, 95.0%\nand 92,.1%; for negative comments are 97.1%, 78.5% and 86.8%; and for neutral\ncomments are 76.7%, 86.2% and 81.2%.", "published": "2019-05-16 10:27:17", "link": "http://arxiv.org/abs/1905.06643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Entity Relations for Opinion Mining of Vietnamese Comments", "abstract": "In this paper, we propose several novel techniques to extract and mining\nopinions of Vietnamese reviews of customers about a number of products traded\non e-commerce in Vietnam. The assessment is based on the emotional level of\ncustomers on a specific product such as mobile and laptop. We exploit the\nfeatures of the products because they are much interested by customers and have\nmany products in the Vietnam e-commerce market. Thence, it can be known the\nfavorites and dislikes of customers about exploited products.", "published": "2019-05-16 10:31:48", "link": "http://arxiv.org/abs/1905.06647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What do Entity-Centric Models Learn? Insights from Entity Linking in\n  Multi-Party Dialogue", "abstract": "Humans use language to refer to entities in the external world. Motivated by\nthis, in recent years several models that incorporate a bias towards learning\nentity representations have been proposed. Such entity-centric models have\nshown empirical success, but we still know little about why. In this paper we\nanalyze the behavior of two recently proposed entity-centric models in a\nreferential task, Entity Linking in Multi-party Dialogue (SemEval 2018 Task 4).\nWe show that these models outperform the state of the art on this task, and\nthat they do better on lower frequency entities than a counterpart model that\nis not entity-centric, with the same model size. We argue that making models\nentity-centric naturally fosters good architectural decisions. However, we also\nshow that these models do not really build entity representations and that they\nmake poor use of linguistic context. These negative results underscore the need\nfor model analysis, to test whether the motivations for particular\narchitectures are borne out in how models behave when deployed.", "published": "2019-05-16 10:43:58", "link": "http://arxiv.org/abs/1905.06649v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracing cultural diachronic semantic shifts in Russian using word\n  embeddings: test sets and baselines", "abstract": "The paper introduces manually annotated test sets for the task of tracing\ndiachronic (temporal) semantic shifts in Russian. The two test sets are\ncomplementary in that the first one covers comparatively strong semantic\nchanges occurring to nouns and adjectives from pre-Soviet to Soviet times,\nwhile the second one covers comparatively subtle socially and culturally\ndetermined shifts occurring in years from 2000 to 2014. Additionally, the\nsecond test set offers more granular classification of shifts degree, but is\nlimited to only adjectives.\n  The introduction of the test sets allowed us to evaluate several\nwell-established algorithms of semantic shifts detection (posing this as a\nclassification problem), most of which have never been tested on Russian\nmaterial. All of these algorithms use distributional word embedding models\ntrained on the corresponding in-domain corpora. The resulting scores provide\nsolid comparison baselines for future studies tackling similar tasks. We\npublish the datasets, code and the trained models in order to facilitate\nfurther research in automatically detecting temporal semantic shifts for\nRussian words, with time periods of different granularities.", "published": "2019-05-16 15:27:19", "link": "http://arxiv.org/abs/1905.06837v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gated Convolutional Neural Networks for Domain Adaptation", "abstract": "Domain Adaptation explores the idea of how to maximize performance on a\ntarget domain, distinct from source domain, upon which the classifier was\ntrained. This idea has been explored for the task of sentiment analysis\nextensively. The training of reviews pertaining to one domain and evaluation on\nanother domain is widely studied for modeling a domain independent algorithm.\nThis further helps in understanding correlation between domains. In this paper,\nwe show that Gated Convolutional Neural Networks (GCN) perform effectively at\nlearning sentiment analysis in a manner where domain dependant knowledge is\nfiltered out using its gates. We perform our experiments on multiple gate\narchitectures: Gated Tanh ReLU Unit (GTRU), Gated Tanh Unit (GTU) and Gated\nLinear Unit (GLU). Extensive experimentation on two standard datasets relevant\nto the task, reveal that training with Gated Convolutional Neural Networks give\nsignificantly better performance on target domains than regular convolution and\nrecurrent based architectures. While complex architectures like attention,\nfilter domain specific knowledge as well, their complexity order is remarkably\nhigh as compared to gated architectures. GCNs rely on convolution hence gaining\nan upper hand through parallelization.", "published": "2019-05-16 16:57:35", "link": "http://arxiv.org/abs/1905.06906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamically Fused Graph Network for Multi-hop Reasoning", "abstract": "Text-based question answering (TBQA) has been studied extensively in recent\nyears. Most existing approaches focus on finding the answer to a question\nwithin a single paragraph. However, many difficult questions require multiple\nsupporting evidence from scattered text among two or more documents. In this\npaper, we propose Dynamically Fused Graph Network(DFGN), a novel method to\nanswer those questions requiring multiple scattered evidence and reasoning over\nthem. Inspired by human's step-by-step reasoning behavior, DFGN includes a\ndynamic fusion layer that starts from the entities mentioned in the given\nquery, explores along the entity graph dynamically built from the text, and\ngradually finds relevant supporting entities from the given documents. We\nevaluate DFGN on HotpotQA, a public TBQA dataset requiring multi-hop reasoning.\nDFGN achieves competitive results on the public board. Furthermore, our\nanalysis shows DFGN produces interpretable reasoning chains.", "published": "2019-05-16 17:51:44", "link": "http://arxiv.org/abs/1905.06933v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IMHO Fine-Tuning Improves Claim Detection", "abstract": "Claims are the central component of an argument. Detecting claims across\ndifferent domains or data sets can often be challenging due to their varying\nconceptualization. We propose to alleviate this problem by fine tuning a\nlanguage model using a Reddit corpus of 5.5 million opinionated claims. These\nclaims are self-labeled by their authors using the internet acronyms IMO/IMHO\n(in my (humble) opinion). Empirical results show that using this approach\nimproves the state of art performance across four benchmark argumentation data\nsets by an average of 4 absolute F1 points in claim detection. As these data\nsets include diverse domains such as social media and student essays this\nimprovement demonstrates the robustness of fine-tuning on this novel corpus.", "published": "2019-05-16 19:13:44", "link": "http://arxiv.org/abs/1905.07000v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Automatic Generation of Shareable Synthetic Clinical Notes Using\n  Neural Language Models", "abstract": "Large-scale clinical data is invaluable to driving many computational\nscientific advances today. However, understandable concerns regarding patient\nprivacy hinder the open dissemination of such data and give rise to suboptimal\nsiloed research. De-identification methods attempt to address these concerns\nbut were shown to be susceptible to adversarial attacks. In this work, we focus\non the vast amounts of unstructured natural language data stored in clinical\nnotes and propose to automatically generate synthetic clinical notes that are\nmore amenable to sharing using generative models trained on real de-identified\nrecords. To evaluate the merit of such notes, we measure both their privacy\npreservation properties as well as utility in training clinical NLP models.\nExperiments using neural language models yield notes whose utility is close to\nthat of the real ones in some clinical NLP tasks, yet leave ample room for\nfuture improvements.", "published": "2019-05-16 19:14:18", "link": "http://arxiv.org/abs/1905.07002v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HIBERT: Document Level Pre-training of Hierarchical Bidirectional\n  Transformers for Document Summarization", "abstract": "Neural extractive summarization models usually employ a hierarchical encoder\nfor document encoding and they are trained using sentence-level labels, which\nare created heuristically using rule-based methods. Training the hierarchical\nencoder with these \\emph{inaccurate} labels is challenging. Inspired by the\nrecent work on pre-training transformer sentence encoders\n\\cite{devlin:2018:arxiv}, we propose {\\sc Hibert} (as shorthand for {\\bf\nHI}erachical {\\bf B}idirectional {\\bf E}ncoder {\\bf R}epresentations from {\\bf\nT}ransformers) for document encoding and a method to pre-train it using\nunlabeled data. We apply the pre-trained {\\sc Hibert} to our summarization\nmodel and it outperforms its randomly initialized counterpart by 1.25 ROUGE on\nthe CNN/Dailymail dataset and by 2.0 ROUGE on a version of New York Times\ndataset. We also achieve the state-of-the-art performance on these two\ndatasets.", "published": "2019-05-16 07:20:21", "link": "http://arxiv.org/abs/1905.06566v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint Source-Target Self Attention with Locality Constraints", "abstract": "The dominant neural machine translation models are based on the\nencoder-decoder structure, and many of them rely on an unconstrained receptive\nfield over source and target sequences. In this paper we study a new\narchitecture that breaks with both conventions. Our simplified architecture\nconsists in the decoder part of a transformer model, based on self-attention,\nbut with locality constraints applied on the attention receptive field. As\ninput for training, both source and target sentences are fed to the network,\nwhich is trained as a language model. At inference time, the target tokens are\npredicted autoregressively starting with the source sequence as previous\ntokens. The proposed model achieves a new state of the art of 35.7 BLEU on\nIWSLT'14 German-English and matches the best reported results in the literature\non the WMT'14 English-German and WMT'14 English-French translation benchmarks.", "published": "2019-05-16 08:35:12", "link": "http://arxiv.org/abs/1905.06596v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TraceWalk: Semantic-based Process Graph Embedding for Consistency\n  Checking", "abstract": "Process consistency checking (PCC), an interdiscipline of natural language\nprocessing (NLP) and business process management (BPM), aims to quantify the\ndegree of (in)consistencies between graphical and textual descriptions of a\nprocess. However, previous studies heavily depend on a great deal of complex\nexpert-defined knowledge such as alignment rules and assessment metrics, thus\nsuffer from the problems of low accuracy and poor adaptability when applied in\nopen-domain scenarios. To address the above issues, this paper makes the first\nattempt that uses deep learning to perform PCC. Specifically, we proposed\nTraceWalk, using semantic information of process graphs to learn latent node\nrepresentations, and integrates it into a convolutional neural network (CNN)\nbased model called TraceNet to predict consistencies. The theoretical proof\nformally provides the PCC's lower limit and experimental results demonstrate\nthat our approach performs more accurately than state-of-the-art baselines.", "published": "2019-05-16 16:15:01", "link": "http://arxiv.org/abs/1905.06883v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Materials Science Procedural Text Corpus: Annotating Materials\n  Synthesis Procedures with Shallow Semantic Structures", "abstract": "Materials science literature contains millions of materials synthesis\nprocedures described in unstructured natural language text. Large-scale\nanalysis of these synthesis procedures would facilitate deeper scientific\nunderstanding of materials synthesis and enable automated synthesis planning.\nSuch analysis requires extracting structured representations of synthesis\nprocedures from the raw text as a first step. To facilitate the training and\nevaluation of synthesis extraction models, we introduce a dataset of 230\nsynthesis procedures annotated by domain experts with labeled graphs that\nexpress the semantics of the synthesis sentences. The nodes in this graph are\nsynthesis operations and their typed arguments, and labeled edges specify\nrelations between the nodes. We describe this new resource in detail and\nhighlight some specific challenges to annotating scientific text with shallow\nsemantic structure. We make the corpus available to the community to promote\nfurther research and development of scientific information extraction systems.", "published": "2019-05-16 17:57:35", "link": "http://arxiv.org/abs/1905.06939v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fonts-2-Handwriting: A Seed-Augment-Train framework for universal digit\n  classification", "abstract": "In this paper, we propose a Seed-Augment-Train/Transfer (SAT) framework that\ncontains a synthetic seed image dataset generation procedure for languages with\ndifferent numeral systems using freely available open font file datasets. This\nseed dataset of images is then augmented to create a purely synthetic training\ndataset, which is in turn used to train a deep neural network and test on\nheld-out real world handwritten digits dataset spanning five Indic scripts,\nKannada, Tamil, Gujarati, Malayalam, and Devanagari. We showcase the efficacy\nof this approach both qualitatively, by training a Boundary-seeking GAN (BGAN)\nthat generates realistic digit images in the five languages, and also\nquantitatively by testing a CNN trained on the synthetic data on the real-world\ndatasets. This establishes not only an interesting nexus between the\nfont-datasets-world and transfer learning but also provides a recipe for\nuniversal-digit classification in any script.", "published": "2019-05-16 20:38:05", "link": "http://arxiv.org/abs/1905.08633v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "An Approach for Process Model Extraction By Multi-Grained Text\n  Classification", "abstract": "Process model extraction (PME) is a recently emerged interdiscipline between\nnatural language processing (NLP) and business process management (BPM), which\naims to extract process models from textual descriptions. Previous process\nextractors heavily depend on manual features and ignore the potential relations\nbetween clues of different text granularities. In this paper, we formalize the\nPME task into the multi-grained text classification problem, and propose a\nhierarchical neural network to effectively model and extract multi-grained\ninformation without manually-defined procedural features. Under this structure,\nwe accordingly propose the coarse-to-fine (grained) learning mechanism,\ntraining multi-grained tasks in coarse-to-fine grained order to share the\nhigh-level knowledge for the low-level tasks. To evaluate our approach, we\nconstruct two multi-grained datasets from two different domains and conduct\nextensive experiments from different dimensions. The experimental results\ndemonstrate that our approach outperforms the state-of-the-art methods with\nstatistical significance and further investigations demonstrate its\neffectiveness.", "published": "2019-05-16 16:04:49", "link": "http://arxiv.org/abs/1906.02127v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Articulatory and bottleneck features for speaker-independent ASR of\n  dysarthric speech", "abstract": "The rapid population aging has stimulated the development of assistive\ndevices that provide personalized medical support to the needies suffering from\nvarious etiologies. One prominent clinical application is a computer-assisted\nspeech training system which enables personalized speech therapy to patients\nimpaired by communicative disorders in the patient's home environment. Such a\nsystem relies on the robust automatic speech recognition (ASR) technology to be\nable to provide accurate articulation feedback. With the long-term aim of\ndeveloping off-the-shelf ASR systems that can be incorporated in clinical\ncontext without prior speaker information, we compare the ASR performance of\nspeaker-independent bottleneck and articulatory features on dysarthric speech\nused in conjunction with dedicated neural network-based acoustic models that\nhave been shown to be robust against spectrotemporal deviations. We report ASR\nperformance of these systems on two dysarthric speech datasets of different\ncharacteristics to quantify the achieved performance gains. Despite the\nremaining performance gap between the dysarthric and normal speech, significant\nimprovements have been reported on both datasets using speaker-independent ASR\narchitectures.", "published": "2019-05-16 05:40:18", "link": "http://arxiv.org/abs/1905.06533v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Simple Dual-decoder Model for Generating Response with Sentiment", "abstract": "How to generate human like response is one of the most challenging tasks for\nartificial intelligence. In a real application, after reading the same post\ndifferent people might write responses with positive or negative sentiment\naccording to their own experiences and attitudes. To simulate this procedure,\nwe propose a simple but effective dual-decoder model to generate response with\na particular sentiment, by connecting two sentiment decoders to one encoder. To\nsupport this model training, we construct a new conversation dataset with the\nform of (post, resp1, resp2) where two responses contain opposite sentiment.\nExperiment results show that our dual-decoder model can generate diverse\nresponses with target sentiment, which obtains significant performance gain in\nsentiment accuracy and word diversity over the traditional single-decoder\nmodel. We will make our data and code publicly available for further study.", "published": "2019-05-16 08:40:47", "link": "http://arxiv.org/abs/1905.06597v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Latent Universal Task-Specific BERT", "abstract": "This paper describes a language representation model which combines the\nBidirectional Encoder Representations from Transformers (BERT) learning\nmechanism described in Devlin et al. (2018) with a generalization of the\nUniversal Transformer model described in Dehghani et al. (2018). We further\nimprove this model by adding a latent variable that represents the persona and\ntopics of interests of the writer for each training example. We also describe a\nsimple method to improve the usefulness of our language representation for\nsolving problems in a specific domain at the expense of its ability to\ngeneralize to other fields. Finally, we release a pre-trained language\nrepresentation model for social texts that was trained on 100 million tweets.", "published": "2019-05-16 10:21:51", "link": "http://arxiv.org/abs/1905.06638v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Effective Sentence Scoring Method using Bidirectional Language Model for\n  Speech Recognition", "abstract": "In automatic speech recognition, many studies have shown performance\nimprovements using language models (LMs). Recent studies have tried to use\nbidirectional LMs (biLMs) instead of conventional unidirectional LMs (uniLMs)\nfor rescoring the $N$-best list decoded from the acoustic model. In spite of\ntheir theoretical benefits, the biLMs have not given notable improvements\ncompared to the uniLMs in their experiments. This is because their biLMs do not\nconsider the interaction between the two directions. In this paper, we propose\na novel sentence scoring method considering the interaction between the past\nand the future words on the biLM. Our experimental results on the LibriSpeech\ncorpus show that the biLM with the proposed sentence scoring outperforms the\nuniLM for the $N$-best list rescoring, consistently and significantly in all\nexperimental conditions. The analysis of WERs by word position demonstrates\nthat the biLM is more robust than the uniLM especially when a recognized\nsentence is short or a misrecognized word is at the beginning of the sentence.", "published": "2019-05-16 11:00:49", "link": "http://arxiv.org/abs/1905.06655v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multi Web Audio Sequencer: Collaborative Music Making", "abstract": "Recent advancements in web-based audio systems have enabled sufficiently\naccurate timing control and real-time sound processing capabilities. Numerous\nspecialized music tools, as well as digital audio workstations, are now\naccessible from browsers. Features such as the large accessibility of data and\nreal-time communication between clients make the web attractive for\ncollaborative data manipulation. However, this innovative field has yet to\nproduce effective tools for multiple-user coordination on specialized music\ncreation tasks. The Multi Web Audio Sequencer is a prototype of an application\nfor segment-based sequencing of Freesound sound clips, with an emphasis on\nseamless remote collaboration. In this work we consider a fixed-grid step\nsequencer as a probe for understanding the necessary features of crowd-shared\nmusic creation sessions. This manuscript describes the sequencer and the\nfunctionalities and types of interactions required for effective and attractive\ncollaboration of remote people during creative music creation activities.", "published": "2019-05-16 13:10:26", "link": "http://arxiv.org/abs/1905.06717v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning discriminative features in sequence training without requiring\n  framewise labelled data", "abstract": "In this work, we try to answer two questions: Can deeply learned features\nwith discriminative power benefit an ASR system's robustness to acoustic\nvariability? And how to learn them without requiring framewise labelled\nsequence training data? As existing methods usually require knowing where the\nlabels occur in the input sequence, they have so far been limited to many\nreal-world sequence learning tasks. We propose a novel method which\nsimultaneously models both the sequence discriminative training and the feature\ndiscriminative learning within a single network architecture, so that it can\nlearn discriminative deep features in sequence training that obviates the need\nfor presegmented training data. Our experiment in a realistic industrial ASR\ntask shows that, without requiring any specific fine-tuning or additional\ncomplexity, our proposed models have consistently outperformed state-of-the-art\nmodels and significantly reduced Word Error Rate (WER) under all test\nconditions, and especially with highest improvements under unseen noise\nconditions, by relative 12.94%, 8.66% and 5.80%, showing our proposed models\ncan generalize better to acoustic variability.", "published": "2019-05-16 16:58:25", "link": "http://arxiv.org/abs/1905.06907v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
