{"title": "Are Chess Discussions Racist? An Adversarial Hate Speech Data Set", "abstract": "On June 28, 2020, while presenting a chess podcast on Grandmaster Hikaru\nNakamura, Antonio Radi\\'c's YouTube handle got blocked because it contained\n\"harmful and dangerous\" content. YouTube did not give further specific reason,\nand the channel got reinstated within 24 hours. However, Radi\\'c speculated\nthat given the current political situation, a referral to \"black against\nwhite\", albeit in the context of chess, earned him this temporary ban. In this\npaper, via a substantial corpus of 681,995 comments, on 8,818 YouTube videos\nhosted by five highly popular chess-focused YouTube channels, we ask the\nfollowing research question: \\emph{how robust are off-the-shelf hate-speech\nclassifiers to out-of-domain adversarial examples?} We release a data set of\n1,000 annotated comments where existing hate speech classifiers misclassified\nbenign chess discussions as hate speech. We conclude with an intriguing analogy\nresult on racial bias with our findings pointing out to the broader challenge\nof color polysemy.", "published": "2020-11-20 08:50:06", "link": "http://arxiv.org/abs/2011.10280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "1st AfricaNLP Workshop Proceedings, 2020", "abstract": "Proceedings of the 1st AfricaNLP Workshop held on 26th April alongside ICLR\n2020, Virtual Conference, Formerly Addis Ababa Ethiopia.", "published": "2020-11-20 12:03:41", "link": "http://arxiv.org/abs/2011.10361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic modelling discourse dynamics in historical newspapers", "abstract": "This paper addresses methodological issues in diachronic data analysis for\nhistorical research. We apply two families of topic models (LDA and DTM) on a\nrelatively large set of historical newspapers, with the aim of capturing and\nunderstanding discourse dynamics. Our case study focuses on newspapers and\nperiodicals published in Finland between 1854 and 1917, but our method can\neasily be transposed to any diachronic data. Our main contributions are a) a\ncombined sampling, training and inference procedure for applying topic models\nto huge and imbalanced diachronic text collections; b) a discussion on the\ndifferences between two topic models for this type of data; c) quantifying\ntopic prominence for a period and thus a generalization of document-wise topic\nassignment to a discourse level; and d) a discussion of the role of humanistic\ninterpretation with regard to analysing discourse dynamics through topic\nmodels.", "published": "2020-11-20 14:51:07", "link": "http://arxiv.org/abs/2011.10428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural\n  Networks", "abstract": "Attention mechanisms play a crucial role in the neural revolution of Natural\nLanguage Processing (NLP). With the growth of attention-based models, several\npruning techniques have been developed to identify and exploit sparseness,\nmaking these models more efficient. Most efforts focus on hard-coding attention\npatterns or pruning attention weights based on training data. We propose\nAttention Pruning (AP), a framework that observes attention patterns in a fixed\ndataset and generates a global sparseness mask. AP saves 90% of attention\ncomputation for language modeling and about 50% for machine translation and\nGLUE tasks, maintaining result quality. Our method reveals important\ndistinctions between self- and cross-attention patterns, guiding future NLP\nresearch. Our framework can reduce both latency and memory requirements for any\nattention-based model, aiding in the development of improved models for\nexisting or new NLP applications. We have demonstrated this with encoder and\nautoregressive transformer models using Triton GPU kernels and make our code\npublicly available at https://github.com/irugina/AP.", "published": "2020-11-20 13:58:21", "link": "http://arxiv.org/abs/2012.02030v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Informative Representations of Biomedical Relations with Latent\n  Variable Models", "abstract": "Extracting biomedical relations from large corpora of scientific documents is\na challenging natural language processing task. Existing approaches usually\nfocus on identifying a relation either in a single sentence (mention-level) or\nacross an entire corpus (pair-level). In both cases, recent methods have\nachieved strong results by learning a point estimate to represent the relation;\nthis is then used as the input to a relation classifier. However, the relation\nexpressed in text between a pair of biomedical entities is often more complex\nthan can be captured by a point estimate. To address this issue, we propose a\nlatent variable model with an arbitrarily flexible distribution to represent\nthe relation between an entity pair. Additionally, our model provides a unified\narchitecture for both mention-level and pair-level relation extraction. We\ndemonstrate that our model achieves results competitive with strong baselines\nfor both tasks while having fewer parameters and being significantly faster to\ntrain. We make our code publicly available.", "published": "2020-11-20 08:56:31", "link": "http://arxiv.org/abs/2011.10285v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Deep Language-independent Network to analyze the impact of COVID-19 on\n  the World via Sentiment Analysis", "abstract": "Towards the end of 2019, Wuhan experienced an outbreak of novel coronavirus,\nwhich soon spread all over the world, resulting in a deadly pandemic that\ninfected millions of people around the globe. The government and public health\nagencies followed many strategies to counter the fatal virus. However, the\nvirus severely affected the social and economic lives of the people. In this\npaper, we extract and study the opinion of people from the top five worst\naffected countries by the virus, namely USA, Brazil, India, Russia, and South\nAfrica. We propose a deep language-independent Multilevel Attention-based\nConv-BiGRU network (MACBiG-Net), which includes embedding layer, word-level\nencoded attention, and sentence-level encoded attention mechanism to extract\nthe positive, negative, and neutral sentiments. The embedding layer encodes the\nsentence sequence into a real-valued vector. The word-level and sentence-level\nencoding is performed by a 1D Conv-BiGRU based mechanism, followed by\nword-level and sentence-level attention, respectively. We further develop a\nCOVID-19 Sentiment Dataset by crawling the tweets from Twitter. Extensive\nexperiments on our proposed dataset demonstrate the effectiveness of the\nproposed MACBiG-Net. Also, attention-weights visualization and in-depth results\nanalysis shows that the proposed network has effectively captured the\nsentiments of the people.", "published": "2020-11-20 11:59:16", "link": "http://arxiv.org/abs/2011.10358v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks", "abstract": "Backdoor attacks are a kind of emergent training-time threat to deep neural\nnetworks (DNNs). They can manipulate the output of DNNs and possess high\ninsidiousness. In the field of natural language processing, some attack methods\nhave been proposed and achieve very high attack success rates on multiple\npopular models. Nevertheless, there are few studies on defending against\ntextual backdoor attacks. In this paper, we propose a simple and effective\ntextual backdoor defense named ONION, which is based on outlier word detection\nand, to the best of our knowledge, is the first method that can handle all the\ntextual backdoor attack situations. Experiments demonstrate the effectiveness\nof our model in defending BiLSTM and BERT against five different backdoor\nattacks. All the code and data of this paper can be obtained at\nhttps://github.com/thunlp/ONION.", "published": "2020-11-20 12:17:21", "link": "http://arxiv.org/abs/2011.10369v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning BERT for Sentiment Analysis of Vietnamese Reviews", "abstract": "Sentiment analysis is an important task in the field ofNature Language\nProcessing (NLP), in which users' feedbackdata on a specific issue are\nevaluated and analyzed. Manydeep learning models have been proposed to tackle\nthis task, including the recently-introduced Bidirectional Encoder\nRep-resentations from Transformers (BERT) model. In this paper,we experiment\nwith two BERT fine-tuning methods for thesentiment analysis task on datasets of\nVietnamese reviews: 1) a method that uses only the [CLS] token as the input for\nanattached feed-forward neural network, and 2) another methodin which all BERT\noutput vectors are used as the input forclassification. Experimental results on\ntwo datasets show thatmodels using BERT slightly outperform other models\nusingGloVe and FastText. Also, regarding the datasets employed inthis study,\nour proposed BERT fine-tuning method produces amodel with better performance\nthan the original BERT fine-tuning method.", "published": "2020-11-20 14:45:46", "link": "http://arxiv.org/abs/2011.10426v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What do we expect from Multiple-choice QA Systems?", "abstract": "The recent success of machine learning systems on various QA datasets could\nbe interpreted as a significant improvement in models' language understanding\nabilities. However, using various perturbations, multiple recent works have\nshown that good performance on a dataset might not indicate performance that\ncorrelates well with human's expectations from models that \"understand\"\nlanguage. In this work we consider a top performing model on several Multiple\nChoice Question Answering (MCQA) datasets, and evaluate it against a set of\nexpectations one might have from such a model, using a series of\nzero-information perturbations of the model's inputs. Our results show that the\nmodel clearly falls short of our expectations, and motivates a modified\ntraining approach that forces the model to better attend to the inputs. We show\nthat the new training paradigm leads to a model that performs on par with the\noriginal model while better satisfying our expectations.", "published": "2020-11-20 21:27:10", "link": "http://arxiv.org/abs/2011.10647v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Supervised learning with cross-modal transformers for emotion\n  recognition", "abstract": "Emotion recognition is a challenging task due to limited availability of\nin-the-wild labeled datasets. Self-supervised learning has shown improvements\non tasks with limited labeled datasets in domains like speech and natural\nlanguage. Models such as BERT learn to incorporate context in word embeddings,\nwhich translates to improved performance in downstream tasks like question\nanswering. In this work, we extend self-supervised training to multi-modal\napplications. We learn multi-modal representations using a transformer trained\non the masked language modeling task with audio, visual and text features. This\nmodel is fine-tuned on the downstream task of emotion recognition. Our results\non the CMU-MOSEI dataset show that this pre-training technique can improve the\nemotion recognition performance by up to 3% compared to the baseline.", "published": "2020-11-20 21:38:34", "link": "http://arxiv.org/abs/2011.10652v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Collaborative Storytelling with Large-scale Neural Language Models", "abstract": "Storytelling plays a central role in human socializing and entertainment.\nHowever, much of the research on automatic storytelling generation assumes that\nstories will be generated by an agent without any human interaction. In this\npaper, we introduce the task of collaborative storytelling, where an artificial\nintelligence agent and a person collaborate to create a unique story by taking\nturns adding to it. We present a collaborative storytelling system which works\nwith a human storyteller to create a story by generating new utterances based\non the story so far. We constructed the storytelling system by tuning a\npublicly-available large scale language model on a dataset of writing prompts\nand their accompanying fictional works. We identify generating sufficiently\nhuman-like utterances to be an important technical issue and propose a\nsample-and-rank approach to improve utterance quality. Quantitative evaluation\nshows that our approach outperforms a baseline, and we present qualitative\nevaluation of our system's capabilities.", "published": "2020-11-20 04:36:54", "link": "http://arxiv.org/abs/2011.10208v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Sequential Targeting: an incremental learning approach for data\n  imbalance in text classification", "abstract": "Classification tasks require a balanced distribution of data to ensure the\nlearner to be trained to generalize over all classes. In real-world datasets,\nhowever, the number of instances vary substantially among classes. This\ntypically leads to a learner that promotes bias towards the majority group due\nto its dominating property. Therefore, methods to handle imbalanced datasets\nare crucial for alleviating distributional skews and fully utilizing the\nunder-represented data, especially in text classification. While addressing the\nimbalance in text data, most methods utilize sampling methods on the numerical\nrepresentation of the data, which limits its efficiency on how effective the\nrepresentation is. We propose a novel training method, Sequential\nTargeting(ST), independent of the effectiveness of the representation method,\nwhich enforces an incremental learning setting by splitting the data into\nmutually exclusive subsets and training the learner adaptively. To address\nproblems that arise within incremental learning, we apply elastic weight\nconsolidation. We demonstrate the effectiveness of our method through\nexperiments on simulated benchmark datasets (IMDB) and data collected from\nNAVER.", "published": "2020-11-20 04:54:00", "link": "http://arxiv.org/abs/2011.10216v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Finding Prerequisite Relations between Concepts using Textbook", "abstract": "A prerequisite is anything that you need to know or understand first before\nattempting to learn or understand something new. In the current work, we\npresent a method of finding prerequisite relations between concepts using\nrelated textbooks. Previous researchers have focused on finding these relations\nusing Wikipedia link structure through unsupervised and supervised learning\napproaches. In the current work, we have proposed two methods, one is\nstatistical method and another is learning-based method. We mine the rich and\nstructured knowledge available in the textbooks to find the content for those\nconcepts and the order in which they are discussed. Using this information,\nproposed statistical method estimates explicit as well as implicit prerequisite\nrelations between concepts. During experiments, we have found performance of\nproposed statistical method is better than the popular RefD method, which uses\nWikipedia link structure. And proposed learning-based method has shown a\nsignificant increase in the efficiency of supervised learning method when\ncompared with graph and text-based learning-based approaches.", "published": "2020-11-20 10:58:31", "link": "http://arxiv.org/abs/2011.10337v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Towards Abstract Relational Learning in Human Robot Interaction", "abstract": "Humans have a rich representation of the entities in their environment.\nEntities are described by their attributes, and entities that share attributes\nare often semantically related. For example, if two books have \"Natural\nLanguage Processing\" as the value of their `title' attribute, we can expect\nthat their `topic' attribute will also be equal, namely, \"NLP\". Humans tend to\ngeneralize such observations, and infer sufficient conditions under which the\n`topic' attribute of any entity is \"NLP\". If robots need to interact\nsuccessfully with humans, they need to represent entities, attributes, and\ngeneralizations in a similar way. This ends in a contextualized cognitive agent\nthat can adapt its understanding, where context provides sufficient conditions\nfor a correct understanding. In this work, we address the problem of how to\nobtain these representations through human-robot interaction. We integrate\nvisual perception and natural language input to incrementally build a semantic\nmodel of the world, and then use inductive reasoning to infer logical rules\nthat capture generic semantic relations, true in this model. These relations\ncan be used to enrich the human-robot interaction, to populate a knowledge base\nwith inferred facts, or to remove uncertainty in the robot's sensory inputs.", "published": "2020-11-20 12:06:46", "link": "http://arxiv.org/abs/2011.10364v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "User and Item-aware Estimation of Review Helpfulness", "abstract": "In online review sites, the analysis of user feedback for assessing its\nhelpfulness for decision-making is usually carried out by locally studying the\nproperties of individual reviews. However, global properties should be\nconsidered as well to precisely evaluate the quality of user feedback. In this\npaper we investigate the role of deviations in the properties of reviews as\nhelpfulness determinants with the intuition that \"out of the core\" feedback\nhelps item evaluation. We propose a novel helpfulness estimation model that\nextends previous ones with the analysis of deviations in rating, length and\npolarity with respect to the reviews written by the same person, or concerning\nthe same item. A regression analysis carried out on two large datasets of\nreviews extracted from Yelp social network shows that user-based deviations in\nreview length and rating clearly influence perceived helpfulness. Moreover, an\nexperiment on the same datasets shows that the integration of our helpfulness\nestimation model improves the performance of a collaborative recommender system\nby enhancing the selection of high-quality data for rating estimation. Our\nmodel is thus an effective tool to select relevant user feedback for\ndecision-making.", "published": "2020-11-20 15:35:56", "link": "http://arxiv.org/abs/2011.10456v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal\n  Trigger's Adversarial Attacks", "abstract": "The Universal Trigger (UniTrigger) is a recently-proposed powerful\nadversarial textual attack method. Utilizing a learning-based mechanism,\nUniTrigger generates a fixed phrase that, when added to any benign inputs, can\ndrop the prediction accuracy of a textual neural network (NN) model to near\nzero on a target class. To defend against this attack that can cause\nsignificant harm, in this paper, we borrow the \"honeypot\" concept from the\ncybersecurity community and propose DARCY, a honeypot-based defense framework\nagainst UniTrigger. DARCY greedily searches and injects multiple trapdoors into\nan NN model to \"bait and catch\" potential attacks. Through comprehensive\nexperiments across four public datasets, we show that DARCY detects\nUniTrigger's adversarial attacks with up to 99% TPR and less than 2% FPR in\nmost cases, while maintaining the prediction accuracy (in F1) for clean inputs\nwithin a 1% margin. We also demonstrate that DARCY with multiple trapdoors is\nalso robust to a diverse set of attack scenarios with attackers' varying levels\nof knowledge and skills. Source code will be released upon the acceptance of\nthis paper.", "published": "2020-11-20 16:38:28", "link": "http://arxiv.org/abs/2011.10492v3", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Multi-Scale Speaker Diarization With Neural Affinity Score Fusion", "abstract": "Identifying the identity of the speaker of short segments in human dialogue\nhas been considered one of the most challenging problems in speech signal\nprocessing. Speaker representations of short speech segments tend to be\nunreliable, resulting in poor fidelity of speaker representations in tasks\nrequiring speaker recognition. In this paper, we propose an unconventional\nmethod that tackles the trade-off between temporal resolution and the quality\nof the speaker representations. To find a set of weights that balance the\nscores from multiple temporal scales of segments, a neural affinity score\nfusion model is presented. Using the CALLHOME dataset, we show that our\nproposed multi-scale segmentation and integration approach can achieve a\nstate-of-the-art diarization performance.", "published": "2020-11-20 17:57:12", "link": "http://arxiv.org/abs/2011.10527v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "One Shot Learning for Speech Separation", "abstract": "Despite the recent success of speech separation models, they fail to separate\nsources properly while facing different sets of people or noisy environments.\nTo tackle this problem, we proposed to apply meta-learning to the speech\nseparation task. We aimed to find a meta-initialization model, which can\nquickly adapt to new speakers by seeing only one mixture generated by those\npeople. In this paper, we use model-agnostic meta-learning(MAML) algorithm and\nalmost no inner loop(ANIL) algorithm in Conv-TasNet to achieve this goal. The\nexperiment results show that our model can adapt not only to a new set of\nspeakers but also noisy environments. Furthermore, we found out that the\nencoder and decoder serve as the feature-reuse layers, while the separator is\nthe task-specific module.", "published": "2020-11-20 06:39:48", "link": "http://arxiv.org/abs/2011.10233v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Multi-Frame MVDR Filtering for Single-Microphone Speech Enhancement", "abstract": "Multi-frame algorithms for single-microphone speech enhancement, e.g., the\nmulti-frame minimum variance distortionless response (MFMVDR) filter, are able\nto exploit speech correlation across adjacent time frames in the short-time\nFourier transform (STFT) domain. Provided that accurate estimates of the\nrequired speech interframe correlation vector and the noise correlation matrix\nare available, it has been shown that the MFMVDR filter yields a substantial\nnoise reduction while hardly introducing any speech distortion. Aiming at\nmerging the speech enhancement potential of the MFMVDR filter and the\nestimation capability of temporal convolutional networks (TCNs), in this paper\nwe propose to embed the MFMVDR filter within a deep learning framework. The\nTCNs are trained to map the noisy speech STFT coefficients to the required\nquantities by minimizing the scale-invariant signal-to-distortion ratio loss\nfunction at the MFMVDR filter output. Experimental results show that the\nproposed deep MFMVDR filter achieves a competitive speech enhancement\nperformance on the Deep Noise Suppression Challenge dataset. In particular, the\nresults show that estimating the parameters of an MFMVDR filter yields a higher\nperformance in terms of PESQ and STOI than directly estimating the multi-frame\nfilter or single-frame masks and than Conv-TasNet.", "published": "2020-11-20 11:20:17", "link": "http://arxiv.org/abs/2011.10345v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Improving RNN-T ASR Accuracy Using Context Audio", "abstract": "We present a training scheme for streaming automatic speech recognition (ASR)\nbased on recurrent neural network transducers (RNN-T) which allows the encoder\nnetwork to learn to exploit context audio from a stream, using segmented or\npartially labeled sequences of the stream during training. We show that the use\nof context audio during training and inference can lead to word error rate\nreductions of more than 6% in a realistic production setting for a voice\nassistant ASR system. We investigate the effect of the proposed training\napproach on acoustically challenging data containing background speech and\npresent data points which indicate that this approach helps the network learn\nboth speaker and environment adaptation. To gain further insight into the\nability of a long short-term memory (LSTM) based ASR encoder to exploit\nlong-term context, we also visualize RNN-T loss gradients with respect to the\ninput.", "published": "2020-11-20 18:16:04", "link": "http://arxiv.org/abs/2011.10538v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Empirical Evaluation of Deep Learning Model Compression Techniques on\n  the WaveNet Vocoder", "abstract": "WaveNet is a state-of-the-art text-to-speech vocoder that remains challenging\nto deploy due to its autoregressive loop. In this work we focus on ways to\naccelerate the original WaveNet architecture directly, as opposed to modifying\nthe architecture, such that the model can be deployed as part of a scalable\ntext-to-speech system. We survey a wide variety of model compression techniques\nthat are amenable to deployment on a range of hardware platforms. In\nparticular, we compare different model sparsity methods and levels, and seven\nwidely used precisions as targets for quantization; and are able to achieve\nmodels with a compression ratio of up to 13.84 without loss in audio fidelity\ncompared to a dense, single-precision floating-point baseline. All techniques\nare implemented using existing open source deep learning frameworks and\nlibraries to encourage their wider adoption.", "published": "2020-11-20 16:01:56", "link": "http://arxiv.org/abs/2011.10469v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
