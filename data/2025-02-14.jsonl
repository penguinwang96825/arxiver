{"title": "A review of minimum cost box searching games", "abstract": "We consider a class of zero-sum search games in which a Hider hides one or\nmore target among a set of $n$ boxes. The boxes may require differing amount of\ntime to search, and detection may be imperfect, so that there is a certain\nprobability that a target may not be found when a box is searched, even when it\nis there. A Searcher must choose how to search the boxes sequentially, and\nwishes to minimize the expected time to find the target(s), whereas the Hider\nwishes to maximize this payoff. We review some known solutions to different\ncases of this game.", "published": "2025-02-14 20:46:31", "link": "http://arxiv.org/abs/2502.10551v1", "categories": ["math.OC", "cs.DM"], "primary_category": "math.OC"}
{"title": "Network fault costs based on minimum leaf spanning trees", "abstract": "We study the fault-tolerance of networks from both the structural and\ncomputational point of view using the minimum leaf number of the corresponding\ngraph $G$, i.e. the minimum number of leaves of the spanning trees of $G$, and\nits vertex-deleted subgraphs. We investigate networks that are leaf-guaranteed,\ni.e. which satisfy a certain stability condition with respect to minimum leaf\nnumbers and vertex-deletion. Next to this, our main notion is the so-called\nfault cost, which is based on the number of vertices that have different\ndegrees in minimum leaf spanning trees of the network and its vertex-deleted\nsubgraphs. We characterise networks with vanishing fault cost via\nleaf-guaranteed graphs and describe, for any given network $N$, leaf-guaranteed\nnetworks containing $N$. We determine for all non-negative integers $k \\le 8$\nexcept $1$ the smallest network with fault cost $k$. We also give a detailed\ntreatment of the fault cost $1$ case, prove that there are infinitely many\n$3$-regular networks with fault cost $3$, and show that for any non-negative\ninteger $k$ there exists a network with fault cost exactly $k$.", "published": "2025-02-14 15:08:24", "link": "http://arxiv.org/abs/2502.10213v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Consecutive and quasi-consecutive patterns: $\\mathrm{des}$-Wilf classifications and generating functions", "abstract": "Motivated by a correlation between the distribution of descents over\npermutations that avoid a consecutive pattern and those avoiding the respective\nquasi-consecutive pattern, as established in this paper, we obtain a complete\n$\\des$-Wilf classification for quasi-consecutive patterns of length up to 4.\nFor equivalence classes containing more than one pattern, we construct various\ndescent-preserving bijections to establish the equivalences, which lead to the\nprovision of proper versions of two incomplete bijective arguments previously\npublished in the literature. Additionally, for two singleton classes, we derive\nexplicit bivariate generating functions using the generalized run theorem.", "published": "2025-02-14 12:57:17", "link": "http://arxiv.org/abs/2502.10128v1", "categories": ["math.CO", "cs.DM", "05A05, 05A15, 05A19"], "primary_category": "math.CO"}
{"title": "A Sea of Coins: The Proliferation of Cryptocurrencies in UniswapV2", "abstract": "Blockchain technology has revolutionized financial markets by enabling\ndecentralized exchanges (DEXs) that operate without intermediaries. Uniswap V2,\na leading DEX, facilitates the rapid creation and trading of new tokens,\noffering high return potential but exposing investors to significant risks. In\nthis work, we analyze the financial impact of newly created tokens, assessing\ntheir market dynamics, profitability and liquidity manipulations. Our findings\nreveal that a significant portion of market liquidity is trapped in honeypots,\nreducing market efficiency and misleading investors. Applying a simple\nbuy-and-hold strategy, we are able to uncover some major risks associated with\ninvesting in newly created tokens, including the widespread presence of rug\npulls and sandwich attacks. We extract the optimal sandwich amount, revealing\nthat their proliferation in new tokens stems from higher profitability in\nlow-liquidity pools. Furthermore, we analyze the fundamental differences\nbetween token price evolution in swap time and physical time. Using clustering\ntechniques, we highlight these differences and identify typical patterns of\nhoneypot and sellable tokens. Our study provides insights into the risks and\nfinancial dynamics of decentralized markets and their challenges for investors.", "published": "2025-02-14 19:18:39", "link": "http://arxiv.org/abs/2502.10512v1", "categories": ["q-fin.CP", "cs.CR"], "primary_category": "q-fin.CP"}
{"title": "SciClaimHunt: A Large Dataset for Evidence-based Scientific Claim\n  Verification", "abstract": "Verifying scientific claims presents a significantly greater challenge than\nverifying political or news-related claims. Unlike the relatively broad\naudience for political claims, the users of scientific claim verification\nsystems can vary widely, ranging from researchers testing specific hypotheses\nto everyday users seeking information on a medication. Additionally, the\nevidence for scientific claims is often highly complex, involving technical\nterminology and intricate domain-specific concepts that require specialized\nmodels for accurate verification. Despite considerable interest from the\nresearch community, there is a noticeable lack of large-scale scientific claim\nverification datasets to benchmark and train effective models. To bridge this\ngap, we introduce two large-scale datasets, SciClaimHunt and SciClaimHunt_Num,\nderived from scientific research papers. We propose several baseline models\ntailored for scientific claim verification to assess the effectiveness of these\ndatasets. Additionally, we evaluate models trained on SciClaimHunt and\nSciClaimHunt_Num against existing scientific claim verification datasets to\ngauge their quality and reliability. Furthermore, we conduct human evaluations\nof the claims in proposed datasets and perform error analysis to assess the\neffectiveness of the proposed baseline models. Our findings indicate that\nSciClaimHunt and SciClaimHunt_Num serve as highly reliable resources for\ntraining models in scientific claim verification.", "published": "2025-02-14 08:34:26", "link": "http://arxiv.org/abs/2502.10003v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probabilistic Lexical Manifold Construction in Large Language Models via\n  Hierarchical Vector Field Interpolation", "abstract": "Hierarchical vector field interpolation introduces a structured probabilistic\nframework for lexical representation, ensuring that word embeddings transition\nsmoothly across a continuous manifold rather than being constrained to discrete\ntoken mappings. The proposed methodology constructs a probabilistic function\nspace where word representations adhere to topological consistency, mitigating\nrepresentational discontinuities commonly observed in transformer-based\nembeddings. Empirical evaluations reveal that probabilistic constraints enhance\nlexical coherence by refining contextual relationships, leading to improvements\nin semantic stability across multiple linguistic distributions. The application\nof divergence minimization techniques ensures that interpolated embeddings\nmaintain probabilistic consistency while preserving computational feasibility\nfor large-scale implementations. Experimental findings demonstrate that\ninterpolated lexical manifolds improve representation density alignment,\nreducing anisotropic distortions in contextual embedding distributions.\nComparative analyses with standard transformer-based models highlight that\nstructured interpolation yields more stable representations, particularly in\ntasks requiring fine-grained semantic differentiation. The statistical\nevaluation of embedding divergence confirms that probabilistic lexical\nmanifolds reduce representational inconsistencies while maintaining coherence\nacross varying scales of contextual abstraction. An assessment of computational\nefficiency reveals that while interpolation introduces minor processing\noverhead, the structured representation learning approach remains scalable for\npractical deployment.", "published": "2025-02-14 08:47:10", "link": "http://arxiv.org/abs/2502.10013v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ORI: O Routing Intelligence", "abstract": "Single large language models (LLMs) often fall short when faced with the\never-growing range of tasks, making a single-model approach insufficient. We\naddress this challenge by proposing ORI (O Routing Intelligence), a dynamic\nframework that leverages a set of LLMs. By intelligently routing incoming\nqueries to the most suitable model, ORI not only improves task-specific\naccuracy, but also maintains efficiency. Comprehensive evaluations across\ndiverse benchmarks demonstrate consistent accuracy gains while controlling\ncomputational overhead. By intelligently routing queries, ORI outperforms the\nstrongest individual models by up to 2.7 points on MMLU and 1.8 points on MuSR,\nties the top performance on ARC, and on BBH. These results underscore the\nbenefits of a multi-model strategy and demonstrate how ORI's adaptive\narchitecture can more effectively handle diverse tasks, offering a scalable,\nhigh-performance solution for a system of multiple large language models.", "published": "2025-02-14 10:00:20", "link": "http://arxiv.org/abs/2502.10051v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotating Compositionality Scores for Irish Noun Compounds is Hard Work", "abstract": "Noun compounds constitute a challenging construction for NLP applications,\ngiven their variability in idiomaticity and interpretation. In this paper, we\npresent an analysis of compound nouns identified in Irish text of varied\ndomains by expert annotators, focusing on compositionality as a key feature,\nbut also domain specificity, as well as familiarity and confidence of the\nannotator giving the ratings. Our findings and the discussion that ensued\ncontributes towards a greater understanding of how these constructions appear\nin Irish language, and how they might be treated separately from English noun\ncompounds.", "published": "2025-02-14 10:32:29", "link": "http://arxiv.org/abs/2502.10061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of\n  Small Multilingual Language Models for Low-Resource Languages", "abstract": "Low-resource languages (LRLs) face significant challenges in natural language\nprocessing (NLP) due to limited data. While current state-of-the-art large\nlanguage models (LLMs) still struggle with LRLs, smaller multilingual models\n(mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of\ntheir capacity to low training data sizes. This study systematically\ninvestigates parameter-efficient adapter-based methods for adapting mLMs to\nLRLs, evaluating three architectures: Sequential Bottleneck, Invertible\nBottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and\nstructured knowledge from ConceptNet, we show that small adaptation datasets\n(e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains\nin intrinsic (masked language modeling) and extrinsic tasks (topic\nclassification, sentiment analysis, and named entity recognition). We find that\nSequential Bottleneck adapters excel in language modeling, while Invertible\nBottleneck adapters slightly outperform other methods on downstream tasks due\nto better embedding alignment and larger parameter counts. Adapter-based\nmethods match or outperform full fine-tuning while using far fewer parameters,\nand smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3,\nGPT-4, and DeepSeek-R1-based distilled models. While adaptation improves\nperformance, pre-training data size remains the dominant factor, especially for\nlanguages with extensive pre-training coverage.", "published": "2025-02-14 13:10:39", "link": "http://arxiv.org/abs/2502.10140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Post-Training Quantization Benefit from an Additional QLoRA\n  Integration?", "abstract": "Large language models (LLMs) have transformed natural language processing but\npose significant challenges for real-world deployment. These models necessitate\nconsiderable computing resources, which can be costly and frequently\nunavailable. Model compression techniques such as quantization are often\nleveraged to alleviate resource demand, but they may have a negative impact on\nthe generation quality. In this study, we explore the integration of 4-bit\nPost-training Quantization (PTQ) with QLoRA to address these issues. We\ndemonstrate through extensive experiments that this integration outperforms\nstandard PTQ, and in some cases even 16-bit full-parameter fine-tuning on LLMs,\nvalidated across proprietary and public datasets with different quantization\nalgorithms. The results demonstrate the efficacy of PTQ-QLoRA integration,\noffering a viable solution for deploying powerful LLMs in resource-constrained\nenvironments without compromising on performance.", "published": "2025-02-14 14:56:19", "link": "http://arxiv.org/abs/2502.10202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Organize the Web: Constructing Domains Enhances Pre-Training Data\n  Curation", "abstract": "Modern language models are trained on large, unstructured datasets consisting\nof trillions of tokens and obtained by crawling the web. The unstructured\nnature makes it difficult to reason about their contents and develop systematic\napproaches to data curation. In this paper, we unpack monolithic web corpora by\ndeveloping taxonomies of their contents and organizing them into domains. We\nintroduce WebOrganizer, a framework for organizing web pages in terms of both\ntheir topic and format. Using these two complementary notions of domains, we\nautomatically annotate pre-training data by distilling annotations from a large\nlanguage model into efficient classifiers. This allows us to study how data\nfrom different domains should be mixed to improve models on downstream tasks,\nand we show that we can combine insights about effective topics and formats to\nfurther boost performance. We demonstrate that our domain mixing also improves\nexisting methods that select data based on quality. Furthermore, we study and\ncompare how quality-based methods will implicitly change the domain mixture.\nOverall, our work demonstrates that constructing and mixing domains provides a\nvaluable complement to quality-based data curation methods, opening new avenues\nfor effective and insightful pre-training data curation.", "published": "2025-02-14 18:02:37", "link": "http://arxiv.org/abs/2502.10341v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agentic Verification for Ambiguous Query Disambiguation", "abstract": "In this work, we tackle the challenge of disambiguating queries in\nretrieval-augmented generation (RAG) to diverse yet answerable interpretations.\nState-of-the-arts follow a Diversify-then-Verify (DtV) pipeline, where diverse\ninterpretations are generated by an LLM, later used as search queries to\nretrieve supporting passages. Such a process may introduce noise in either\ninterpretations or retrieval, particularly in enterprise settings, where LLMs\n-- trained on static data -- may struggle with domain-specific disambiguations.\nThus, a post-hoc verification phase is introduced to prune noises. Our\ndistinction is to unify diversification with verification by incorporating\nfeedback from retriever and generator early on. This joint approach improves\nboth efficiency and robustness by reducing reliance on multiple retrieval and\ninference steps, which are susceptible to cascading errors. We validate the\nefficiency and effectiveness of our method, Verified-Diversification with\nConsolidation (VERDICT), on the widely adopted ASQA benchmark to achieve\ndiverse yet verifiable interpretations. Empirical results show that VERDICT\nimproves grounding-aware F1 score by an average of 23% over the strongest\nbaseline across different backbone LLMs.", "published": "2025-02-14 18:31:39", "link": "http://arxiv.org/abs/2502.10352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-Oriented Summarization for Psychiatric Short-Term Readmission\n  Prediction", "abstract": "Recent progress in large language models (LLMs) has enabled the automated\nprocessing of lengthy documents even without supervised training on a\ntask-specific dataset. Yet, their zero-shot performance in complex tasks as\nopposed to straightforward information extraction tasks remains suboptimal. One\nfeasible approach for tasks with lengthy, complex input is to first summarize\nthe document and then apply supervised fine-tuning to the summary. However, the\nsummarization process inevitably results in some loss of information. In this\nstudy we present a method for processing the summaries of long documents aimed\nto capture different important aspects of the original document. We hypothesize\nthat LLM summaries generated with different aspect-oriented prompts contain\ndifferent \\textit{information signals}, and we propose methods to measure these\ndifferences. We introduce approaches to effectively integrate signals from\nthese different summaries for supervised training of transformer models. We\nvalidate our hypotheses on a high-impact task -- 30-day readmission prediction\nfrom a psychiatric discharge -- using real-world data from four hospitals, and\nshow that our proposed method increases the prediction performance for the\ncomplex task of predicting patient outcome.", "published": "2025-02-14 18:59:28", "link": "http://arxiv.org/abs/2502.10388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Named entity recognition for Serbian legal documents: Design,\n  methodology and dataset development", "abstract": "Recent advancements in the field of natural language processing (NLP) and\nespecially large language models (LLMs) and their numerous applications have\nbrought research attention to design of different document processing tools and\nenhancements in the process of document archiving, search and retrieval. Domain\nof official, legal documents is especially interesting due to vast amount of\ndata generated on the daily basis, as well as the significant community of\ninterested practitioners (lawyers, law offices, administrative workers, state\ninstitutions and citizens). Providing efficient ways for automation of everyday\nwork involving legal documents is therefore expected to have significant impact\nin different fields. In this work we present one LLM based solution for Named\nEntity Recognition (NER) in the case of legal documents written in Serbian\nlanguage. It leverages on the pre-trained bidirectional encoder representations\nfrom transformers (BERT), which had been carefully adapted to the specific task\nof identifying and classifying specific data points from textual content.\nBesides novel dataset development for Serbian language (involving public court\nrulings), presented system design and applied methodology, the paper also\ndiscusses achieved performance metrics and their implications for objective\nassessment of the proposed solution. Performed cross-validation tests on the\ncreated manually labeled dataset with mean $F_1$ score of 0.96 and additional\nresults on the examples of intentionally modified text inputs confirm\napplicability of the proposed system design and robustness of the developed NER\nsolution.", "published": "2025-02-14 22:23:39", "link": "http://arxiv.org/abs/2502.10582v1", "categories": ["cs.CL", "68T10, 68T30, 68T35, 68T50, 91F20", "I.5.2; I.5.4; I.5.5; I.2.1; I.2.7; I.2; H.4.1"], "primary_category": "cs.CL"}
{"title": "Self-Supervised Learning for Neural Topic Models with\n  Variance-Invariance-Covariance Regularization", "abstract": "In our study, we propose a self-supervised neural topic model (NTM) that\ncombines the power of NTMs and regularized self-supervised learning methods to\nimprove performance. NTMs use neural networks to learn latent topics hidden\nbehind the words in documents, enabling greater flexibility and the ability to\nestimate more coherent topics compared to traditional topic models. On the\nother hand, some self-supervised learning methods use a joint embedding\narchitecture with two identical networks that produce similar representations\nfor two augmented versions of the same input. Regularizations are applied to\nthese representations to prevent collapse, which would otherwise result in the\nnetworks outputting constant or redundant representations for all inputs. Our\nmodel enhances topic quality by explicitly regularizing latent topic\nrepresentations of anchor and positive samples. We also introduced an\nadversarial data augmentation method to replace the heuristic sampling method.\nWe further developed several variation models including those on the basis of\nan NTM that incorporates contrastive learning with both positive and negative\nsamples. Experimental results on three datasets showed that our models\noutperformed baselines and state-of-the-art models both quantitatively and\nqualitatively.", "published": "2025-02-14 06:47:37", "link": "http://arxiv.org/abs/2502.09944v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs\n  -- No Silver Bullet for LC or RAG Routing", "abstract": "Effectively incorporating external knowledge into Large Language Models\n(LLMs) is crucial for enhancing their capabilities and addressing real-world\nneeds. Retrieval-Augmented Generation (RAG) offers an effective method for\nachieving this by retrieving the most relevant fragments into LLMs. However,\nthe advancements in context window size for LLMs offer an alternative approach,\nraising the question of whether RAG remains necessary for effectively handling\nexternal knowledge. Several existing studies provide inconclusive comparisons\nbetween RAG and long-context (LC) LLMs, largely due to limitations in the\nbenchmark designs. In this paper, we present LaRA, a novel benchmark\nspecifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses\n2326 test cases across four practical QA task categories and three types of\nnaturally occurring long texts. Through systematic evaluation of seven\nopen-source and four proprietary LLMs, we find that the optimal choice between\nRAG and LC depends on a complex interplay of factors, including the model's\nparameter size, long-text capabilities, context length, task type, and the\ncharacteristics of the retrieved chunks. Our findings provide actionable\nguidelines for practitioners to effectively leverage both RAG and LC approaches\nin developing and deploying LLM applications. Our code and dataset is provided\nat:\n\\href{https://github.com/Alibaba-NLP/LaRA}{\\textbf{https://github.com/Alibaba-NLP/LaRA}}.", "published": "2025-02-14 08:04:22", "link": "http://arxiv.org/abs/2502.09977v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Diffusion Models", "abstract": "Autoregressive models (ARMs) are widely regarded as the cornerstone of large\nlanguage models (LLMs). We challenge this notion by introducing LLaDA, a\ndiffusion model trained from scratch under the pre-training and supervised\nfine-tuning (SFT) paradigm. LLaDA models distributions through a forward data\nmasking process and a reverse process, parameterized by a vanilla Transformer\nto predict masked tokens. By optimizing a likelihood bound, it provides a\nprincipled generative approach for probabilistic inference. Across extensive\nbenchmarks, LLaDA demonstrates strong scalability, outperforming our\nself-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong\nLLMs like LLaMA3 8B in in-context learning and, after SFT, exhibits impressive\ninstruction-following abilities in case studies such as multi-turn dialogue.\nMoreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal\npoem completion task. Our findings establish diffusion models as a viable and\npromising alternative to ARMs, challenging the assumption that key LLM\ncapabilities discussed above are inherently tied to ARMs. Project page and\ncodes: https://ml-gsai.github.io/LLaDA-demo/.", "published": "2025-02-14 08:23:51", "link": "http://arxiv.org/abs/2502.09992v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MTLM: an Innovative Language Model Training Paradigm for ASR", "abstract": "Pre-training Transformer-based language models (LMs) on a large amount of\ntext has proven crucial for improving automatic speech recognition (ASR)\nperformance. Generally, traditional LMs are unidirectional and unable to access\nthe context on the right. This paper proposes a method for training LMs that\nenable traditional unidirectional LMs to fully utilize left and right contexts.\nCompared with the unidirectional LMs, our LM facilitates ASR to transcribe\nhypotheses more consistently and in a more semantically unambiguous way, as it\nincorporates richer contextual representations. Finally, our experimental\nresults on the LibriSpeech corpus demonstrate that our model outperforms\ntraditional unidirectional LMs, whether n-best rescoring or shallow fusion is\nused as the decoding algorithm.", "published": "2025-02-14 10:21:10", "link": "http://arxiv.org/abs/2502.10058v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hands-off Image Editing: Language-guided Editing without any\n  Task-specific Labeling, Masking or even Training", "abstract": "Instruction-guided image editing consists in taking an image and an\ninstruction and deliverring that image altered according to that instruction.\nState-of-the-art approaches to this task suffer from the typical scaling up and\ndomain adaptation hindrances related to supervision as they eventually resort\nto some kind of task-specific labelling, masking or training. We propose a\nnovel approach that does without any such task-specific supervision and offers\nthus a better potential for improvement. Its assessment demonstrates that it is\nhighly effective, achieving very competitive performance.", "published": "2025-02-14 10:41:42", "link": "http://arxiv.org/abs/2502.10064v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Prediction hubs are context-informed frequent tokens in LLMs", "abstract": "Hubness, the tendency for few points to be among the nearest neighbours of a\ndisproportionate number of other points, commonly arises when applying standard\ndistance measures to high-dimensional data, often negatively impacting\ndistance-based analysis. As autoregressive large language models (LLMs) operate\non high-dimensional representations, we ask whether they are also affected by\nhubness. We first show, theoretically, that the only representation comparison\noperation performed by LLMs, namely that between context and unembedding\nvectors to determine continuation probabilities, is not characterized by the\nconcentration of distances phenomenon that typically causes the appeareance of\nnuisance hubness. We then empirically show that this comparison still leads to\na high degree of hubness, but the hubs in this case do not constitute a\ndisturbance. They are rather the result of context-modulated frequent tokens\noften appearing in the pool of likely candidates for next token prediction. On\nthe other hand, when other distance computations involving LLM representations\nare performed, we do not have the same theoretical guarantees, and, indeed, we\nsee nuisance hubs appear. In summary, our work highlights, on the one hand, how\nhubness, while omnipresent in high-dimensional spaces, is not always a negative\nproperty that needs to be mitigated, and, on the other hand, it shows that\nvarious widely-used LLMs have developed a guessing strategy that consists in\nconstantly assigning a high probability to frequent tokens.", "published": "2025-02-14 14:52:41", "link": "http://arxiv.org/abs/2502.10201v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Step-Video-T2V Technical Report: The Practice, Challenges, and Future of\n  Video Foundation Model", "abstract": "We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model\nwith 30B parameters and the ability to generate videos up to 204 frames in\nlength. A deep compression Variational Autoencoder, Video-VAE, is designed for\nvideo generation tasks, achieving 16x16 spatial and 8x temporal compression\nratios, while maintaining exceptional video reconstruction quality. User\nprompts are encoded using two bilingual text encoders to handle both English\nand Chinese. A DiT with 3D full attention is trained using Flow Matching and is\nemployed to denoise input noise into latent frames. A video-based DPO approach,\nVideo-DPO, is applied to reduce artifacts and improve the visual quality of the\ngenerated videos. We also detail our training strategies and share key\nobservations and insights. Step-Video-T2V's performance is evaluated on a novel\nvideo generation benchmark, Step-Video-T2V-Eval, demonstrating its\nstate-of-the-art text-to-video quality when compared with both open-source and\ncommercial engines. Additionally, we discuss the limitations of current\ndiffusion-based model paradigm and outline future directions for video\nfoundation models. We make both Step-Video-T2V and Step-Video-T2V-Eval\navailable at https://github.com/stepfun-ai/Step-Video-T2V. The online version\ncan be accessed from https://yuewen.cn/videos as well. Our goal is to\naccelerate the innovation of video foundation models and empower video content\ncreators.", "published": "2025-02-14 15:58:10", "link": "http://arxiv.org/abs/2502.10248v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision\n  Language Models", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are\noften constrained by the lack of high-quality visual fine-tuning data. To\naddress this challenge, we introduce VisCon-100K, a novel dataset derived from\ninterleaved image-text web documents. Our approach transforms 45K web documents\nfrom the OBELICS dataset into 100K image conversation samples. We utilize\nGPT-4V to generate image-contextual captions and OpenChat 3.5 model to convert\nthese captions into diverse free-form and multiple-choice question-answer\npairs. Integrating this dataset for fine-tuning considerably enhances VLM\nperformance across multiple benchmarks. Unlike methods that focus solely on\nfine-grained visual content, our approach leverages accompanying web context,\nyielding superior results. We also discover that a 'leaky modality mix', where\nconversation samples contain questions answerable from both the image and its\ncontextual caption, outperforms non-leaky combinations of captions and Q&A\npairs. VisCon-100k dataset shows strong performance with two popular VLM\napproaches: text-only large language model (LLM) aligned with a vision encoder\nusing image captions data (ShareGPT4V-7b) and multimodally pretrained LLM\n(IDEFICS2-8b) using interleaved image-text data. In addition to releasing the\nVisCon-100K dataset, we provide a contextual captioner trained on this dataset,\nfacilitating scalable fine-tuning data generation for future research and\nopen-source applications. Using the same pipeline, but substituting our trained\ncontextual captioner for GPT-4V, we also release the larger VisCon-1M dataset.", "published": "2025-02-14 15:59:33", "link": "http://arxiv.org/abs/2502.10250v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models the future crowd workers of Linguistics?", "abstract": "Data elicitation from human participants is one of the core data collection\nstrategies used in empirical linguistic research. The amount of participants in\nsuch studies may vary considerably, ranging from a handful to crowdsourcing\ndimensions. Even if they provide resourceful extensive data, both of these\nsettings come alongside many disadvantages, such as low control of\nparticipants' attention during task completion, precarious working conditions\nin crowdsourcing environments, and time-consuming experimental designs. For\nthese reasons, this research aims to answer the question of whether Large\nLanguage Models (LLMs) may overcome those obstacles if included in empirical\nlinguistic pipelines. Two reproduction case studies are conducted to gain\nclarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forced\nelicitation tasks, originally designed for human participants, are reproduced\nin the proposed framework with the help of OpenAI's GPT-4o-mini model. Its\nperformance with our zero-shot prompting baseline shows the effectiveness and\nhigh versatility of LLMs, that tend to outperform human informants in\nlinguistic tasks. The findings of the second replication further highlight the\nneed to explore additional prompting techniques, such as Chain-of-Thought (CoT)\nprompting, which, in a second follow-up experiment, demonstrates higher\nalignment to human performance on both critical and filler items. Given the\nlimited scale of this study, it is worthwhile to further explore the\nperformance of LLMs in empirical Linguistics and in other future applications\nin the humanities.", "published": "2025-02-14 16:23:39", "link": "http://arxiv.org/abs/2502.10266v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the Meta- and Object-Level Reasoning of Large Language Models\n  for Question Answering", "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face\nchallenges in Question Answering (QA) tasks requiring complex, multi-step\nreasoning. We outline the types of reasoning required in some of these tasks,\nand reframe them in terms of meta-level reasoning (akin to high-level strategic\nreasoning or planning) and object-level reasoning (embodied in lower-level\ntasks such as mathematical reasoning). Franklin, a novel dataset with\nrequirements of meta- and object-level reasoning, is introduced and used along\nwith three other datasets to evaluate four LLMs at question answering tasks\nrequiring multiple steps of reasoning. Results from human annotation studies\nsuggest LLMs demonstrate meta-level reasoning with high frequency, but struggle\nwith object-level reasoning tasks in some of the datasets used. Additionally,\nevidence suggests that LLMs find the object-level reasoning required for the\nquestions in the Franklin dataset challenging, yet they do exhibit strong\nperformance with respect to the meta-level reasoning requirements.", "published": "2025-02-14 17:55:43", "link": "http://arxiv.org/abs/2502.10338v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Multilingual LLM Pretraining with Model-Based Data Selection", "abstract": "Dataset curation has become a basis for strong large language model (LLM)\nperformance. While various rule-based filtering heuristics exist for English\nand multilingual datasets, model-based filtering techniques have primarily\nfocused on English. To address the disparity stemming from limited research on\nnon-English languages, we propose a model-based filtering framework for\nmultilingual datasets that aims to identify a diverse set of structured and\nknowledge-rich samples. Our approach emphasizes transparency, simplicity, and\nefficiency, leveraging Transformer- and FastText-based classifiers to ensure\nthe broad accessibility of our technique and data. We conduct comprehensive\nablation studies on the FineWeb-2 web crawl dataset across diverse language\nfamilies, scripts, and resource availability to demonstrate the effectiveness\nof our method. Training a 1B-parameter Llama model for 70B and 119B tokens, our\napproach can match the baseline MMLU score with as little as 15% of the\ntraining tokens, while also improving across other benchmarks. These findings\nprovide strong evidence for the generalizability of our approach to other\nlanguages. As a result, we extend our framework to 20 languages for which we\nrelease the refined pretraining datasets.", "published": "2025-02-14 18:42:07", "link": "http://arxiv.org/abs/2502.10361v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unknown Word Detection for English as a Second Language (ESL) Learners\n  Using Gaze and Pre-trained Language Models", "abstract": "English as a Second Language (ESL) learners often encounter unknown words\nthat hinder their text comprehension. Automatically detecting these words as\nusers read can enable computing systems to provide just-in-time definitions,\nsynonyms, or contextual explanations, thereby helping users learn vocabulary in\na natural and seamless manner. This paper presents EyeLingo, a\ntransformer-based machine learning method that predicts the probability of\nunknown words based on text content and eye gaze trajectory in real time with\nhigh accuracy. A 20-participant user study revealed that our method can achieve\nan accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-time\nreading assistance prototype to show the effectiveness of EyeLingo. The user\nstudy shows improvement in willingness to use and usefulness compared to\nbaseline methods.", "published": "2025-02-14 18:57:04", "link": "http://arxiv.org/abs/2502.10378v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "MM-RLHF: The Next Step Forward in Multimodal LLM Alignment", "abstract": "Despite notable advancements in Multimodal Large Language Models (MLLMs),\nmost state-of-the-art models have not undergone thorough alignment with human\npreferences. This gap exists because current alignment research has primarily\nachieved progress in specific areas (e.g., hallucination reduction), while the\nbroader question of whether aligning models with human preferences can\nsystematically enhance MLLM capability remains largely unexplored. To this end,\nwe introduce MM-RLHF, a dataset containing $\\mathbf{120k}$ fine-grained,\nhuman-annotated preference comparison pairs. This dataset represents a\nsubstantial advancement over existing resources, offering superior size,\ndiversity, annotation granularity, and quality. Leveraging this dataset, we\npropose several key innovations to improve both the quality of reward models\nand the efficiency of alignment algorithms. Notably, we introduce a\nCritique-Based Reward Model, which generates critiques of model outputs before\nassigning scores, offering enhanced interpretability and more informative\nfeedback compared to traditional scalar reward mechanisms. Additionally, we\npropose Dynamic Reward Scaling, a method that adjusts the loss weight of each\nsample according to the reward signal, thereby optimizing the use of\nhigh-quality comparison pairs. Our approach is rigorously evaluated across\n$\\mathbf{10}$ distinct dimensions and $\\mathbf{27}$ benchmarks, with results\ndemonstrating significant and consistent improvements in model performance.\nSpecifically, fine-tuning LLaVA-ov-7B with MM-RLHF and our alignment algorithm\nleads to a $\\mathbf{19.5}$% increase in conversational abilities and a\n$\\mathbf{60}$% improvement in safety.\n  We have open-sourced the preference dataset, reward model, training and\nevaluation code, as well as reward modeling and safety benchmarks. For more\ndetails, please visit our project page: https://mm-rlhf.github.io.", "published": "2025-02-14 18:59:51", "link": "http://arxiv.org/abs/2502.10391v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Hallucinations and Truth: A Comprehensive Accuracy Evaluation of RAG,\n  LoRA and DoRA", "abstract": "Recent advancements in Generative AI have significantly improved the\nefficiency and adaptability of natural language processing (NLP) systems,\nparticularly through Retrieval-Augmented Generation (RAG), Low-Rank Adaptation\n(LoRA), and Weight-Decomposed Low-Rank Adaptation (DoRA). RAG integrates\nexternal knowledge to enhance factual consistency in generative outputs, while\nLoRA enables parameter-efficient fine-tuning of large language models (LLMs).\nDoRA further refines this process by optimizing fine-tuning through adaptive\nparameter ranking and domain-aware weight adjustments, improving learning\nefficiency while maintaining inference performance.\n  This paper presents a large-scale empirical evaluation of RAG, LoRA, and\nDoRA, with model fine-tuning and generation performance assessed on 20,000\nFAQ-based queries, while the knowledge base spans 400,000 entries. The study\nanalyzes key performance metrics such as accuracy, relevance, and inference\nlatency. Experimental results demonstrate that DoRA achieves the highest\naccuracy (90.1%), relevance score (0.88), and lowest latency (110 ms per\nquery), outperforming both LoRA and RAG in real-world, domain-specific\ngenerative AI applications.\n  Furthermore, this study examines the trade-offs between fine-tuning\nefficiency, computational cost, and real-time adaptability across different\nmodels. Findings highlight RAG's effectiveness in knowledge grounding, LoRA's\ncost-efficient domain adaptation, and DoRA's ability to balance fine-tuning\nefficiency with model precision. These insights provide practical guidance for\ndeploying AI-driven generative systems in accuracy-critical domains such as\nhealthcare, finance, and legal services, ensuring scalability, reliability, and\noptimal performance in dynamic environments.", "published": "2025-02-14 17:38:25", "link": "http://arxiv.org/abs/2502.10497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Accelerating Unbiased LLM Evaluation via Synthetic Feedback", "abstract": "When developing new large language models (LLMs), a key step is evaluating\ntheir final performance, often by computing the win-rate against a reference\nmodel based on external feedback. Human feedback is the gold standard,\nparticularly for capturing nuanced qualities like coherence, readability, and\nalignment with human expectations. However, human evaluations are costly --\neven for large tech companies -- and when conducted with active users, they may\nnegatively impact user experience. A promising alternative is synthetic\nfeedback, where evaluations are conducted by other large language models,\nincluding reward models. While this eliminates the need for costly human\nannotations, it introduces biases that may distort the evaluation process. In\nthis work, we propose a statistically principled framework that integrates\nhuman and synthetic feedback to reduce reliance on human annotations while\nmaintaining unbiased win-rate calculations. Our experiments demonstrate a\nreduction in human annotations by up to 12.2% with an off-the-shelf synthetic\nevaluator and up to 24.8% with a finetuned variant. Apart from being\ngeneralizable, scalable, and free of hyper-parameter tuning, our method offers\npredictable annotation savings, which can be estimated based on data-dependent\ncharacteristics.", "published": "2025-02-14 21:27:09", "link": "http://arxiv.org/abs/2502.10563v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Man Made Language Models? Evaluating LLMs' Perpetuation of Masculine\n  Generics Bias", "abstract": "Large language models (LLMs) have been shown to propagate and even amplify\ngender bias, in English and other languages, in specific or constrained\ncontexts. However, no studies so far have focused on gender biases conveyed by\nLLMs' responses to generic instructions, especially with regard to masculine\ngenerics (MG). MG are a linguistic feature found in many gender-marked\nlanguages, denoting the use of the masculine gender as a \"default\" or\nsupposedly neutral gender to refer to mixed group of men and women, or of a\nperson whose gender is irrelevant or unknown. Numerous psycholinguistics\nstudies have shown that MG are not neutral and induce gender bias. This work\naims to analyze the use of MG by both proprietary and local LLMs in responses\nto generic instructions and evaluate their MG bias rate. We focus on French and\ncreate a human noun database from existing lexical resources. We filter\nexisting French instruction datasets to retrieve generic instructions and\nanalyze the responses of 6 different LLMs. Overall, we find that\n$\\approx$39.5\\% of LLMs' responses to generic instructions are MG-biased\n($\\approx$73.1\\% across responses with human nouns). Our findings also reveal\nthat LLMs are reluctant to using gender-fair language spontaneously.", "published": "2025-02-14 22:05:54", "link": "http://arxiv.org/abs/2502.10577v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging large language models for structured information extraction\n  from pathology reports", "abstract": "Background: Structured information extraction from unstructured\nhistopathology reports facilitates data accessibility for clinical research.\nManual extraction by experts is time-consuming and expensive, limiting\nscalability. Large language models (LLMs) offer efficient automated extraction\nthrough zero-shot prompting, requiring only natural language instructions\nwithout labeled data or training. We evaluate LLMs' accuracy in extracting\nstructured information from breast cancer histopathology reports, compared to\nmanual extraction by a trained human annotator.\n  Methods: We developed the Medical Report Information Extractor, a web\napplication leveraging LLMs for automated extraction. We developed a gold\nstandard extraction dataset to evaluate the human annotator alongside five LLMs\nincluding GPT-4o, a leading proprietary model, and the Llama 3 model family,\nwhich allows self-hosting for data privacy. Our assessment involved 111\nhistopathology reports from the Breast Cancer Now (BCN) Generations Study,\nextracting 51 pathology features specified in the study's data dictionary.\n  Results: Evaluation against the gold standard dataset showed that both Llama\n3.1 405B (94.7% accuracy) and GPT-4o (96.1%) achieved extraction accuracy\ncomparable to the human annotator (95.4%; p = 0.146 and p = 0.106,\nrespectively). While Llama 3.1 70B (91.6%) performed below human accuracy (p\n<0.001), its reduced computational requirements make it a viable option for\nself-hosting.\n  Conclusion: We developed an open-source tool for structured information\nextraction that can be customized by non-programmers using natural language.\nIts modular design enables reuse for various extraction tasks, producing\nstandardized, structured data from unstructured text reports to facilitate\nanalytics through improved accessibility and interoperability.", "published": "2025-02-14 21:46:02", "link": "http://arxiv.org/abs/2502.12183v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond English: Unveiling Multilingual Bias in LLM Copyright Compliance", "abstract": "Large Language Models (LLMs) have raised significant concerns regarding the\nfair use of copyright-protected content. While prior studies have examined the\nextent to which LLMs reproduce copyrighted materials, they have predominantly\nfocused on English, neglecting multilingual dimensions of copyright protection.\nIn this work, we investigate multilingual biases in LLM copyright protection by\naddressing two key questions: (1) Do LLMs exhibit bias in protecting\ncopyrighted works across languages? (2) Is it easier to elicit copyrighted\ncontent using prompts in specific languages? To explore these questions, we\nconstruct a dataset of popular song lyrics in English, French, Chinese, and\nKorean and systematically probe seven LLMs using prompts in these languages.\nOur findings reveal significant imbalances in LLMs' handling of copyrighted\ncontent, both in terms of the language of the copyrighted material and the\nlanguage of the prompt. These results highlight the need for further research\nand development of more robust, language-agnostic copyright protection\nmechanisms to ensure fair and consistent protection across languages.", "published": "2025-02-14 16:59:10", "link": "http://arxiv.org/abs/2503.05713v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Efficient Multitask Learning in Small Language Models Through\n  Upside-Down Reinforcement Learning", "abstract": "In this work, we demonstrate that small language models (SLMs), specifically\na 100M parameter GPT-2 model, can achieve competitive performance in multitask\nprompt generation tasks while requiring only a fraction of the computational\nresources needed by large language models (LLMs). Through a novel combination\nof upside-down reinforcement learning and synthetic data distillation from a\npowerful LLM, Llama-3, we train an SLM that achieves relevance scores within 5%\nof state-of-the-art models, including Llama-3, Qwen2, and Mistral, despite\nbeing up to 80 times smaller, making it highly suitable for\nresource-constrained and real-time applications. This study highlights the\npotential of SLMs as efficient multitask learners in multimodal settings,\nproviding a promising alternative to LLMs for scalable, low-latency\ndeployments.", "published": "2025-02-14 01:39:45", "link": "http://arxiv.org/abs/2502.09854v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automated Hypothesis Validation with Agentic Sequential Falsifications", "abstract": "Hypotheses are central to information acquisition, decision-making, and\ndiscovery. However, many real-world hypotheses are abstract, high-level\nstatements that are difficult to validate directly. This challenge is further\nintensified by the rise of hypothesis generation from Large Language Models\n(LLMs), which are prone to hallucination and produce hypotheses in volumes that\nmake manual validation impractical. Here we propose Popper, an agentic\nframework for rigorous automated validation of free-form hypotheses. Guided by\nKarl Popper's principle of falsification, Popper validates a hypothesis using\nLLM agents that design and execute falsification experiments targeting its\nmeasurable implications. A novel sequential testing framework ensures strict\nType-I error control while actively gathering evidence from diverse\nobservations, whether drawn from existing data or newly conducted procedures.\nWe demonstrate Popper on six domains including biology, economics, and\nsociology. Popper delivers robust error control, high power, and scalability.\nFurthermore, compared to human scientists, Popper achieved comparable\nperformance in validating complex biological hypotheses while reducing time by\n10 folds, providing a scalable, rigorous solution for hypothesis validation.", "published": "2025-02-14 01:46:00", "link": "http://arxiv.org/abs/2502.09858v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence\n  of Analogical Reasoning", "abstract": "The remarkable success of large language models relies on their ability to\nimplicitly learn structured latent representations from the pretraining corpus.\nAs a simpler surrogate for representation learning in language modeling, we\nstudy a class of solvable contrastive self-supervised algorithms which we term\nquadratic word embedding models. These models resemble the word2vec algorithm\nand perform similarly on downstream tasks. Our main contributions are\nanalytical solutions for both the training dynamics (under certain\nhyperparameter choices) and the final word embeddings, given in terms of only\nthe corpus statistics. Our solutions reveal that these models learn orthogonal\nlinear subspaces one at a time, each one incrementing the effective rank of the\nembeddings until model capacity is saturated. Training on WikiText, we find\nthat the top subspaces represent interpretable concepts. Finally, we use our\ndynamical theory to predict how and when models acquire the ability to complete\nanalogies.", "published": "2025-02-14 02:16:48", "link": "http://arxiv.org/abs/2502.09863v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism\n  of Language Technologies", "abstract": "Recent attention to anthropomorphism -- the attribution of human-like\nqualities to non-human objects or entities -- of language technologies like\nLLMs has sparked renewed discussions about potential negative impacts of\nanthropomorphism. To productively discuss the impacts of this anthropomorphism\nand in what contexts it is appropriate, we need a shared vocabulary for the\nvast variety of ways that language can be anthropomorphic. In this work, we\ndraw on existing literature and analyze empirical cases of user interactions\nwith language technologies to develop a taxonomy of textual expressions that\ncan contribute to anthropomorphism. We highlight challenges and tensions\ninvolved in understanding linguistic anthropomorphism, such as how all language\nis fundamentally human and how efforts to characterize and shift perceptions of\nhumanness in machines can also dehumanize certain humans. We discuss ways that\nour taxonomy supports more precise and effective discussions of and decisions\nabout anthropomorphism of language technologies.", "published": "2025-02-14 02:43:46", "link": "http://arxiv.org/abs/2502.09870v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot\n  In-Context Inductive Reasoning", "abstract": "Inductive Reasoning (IR), the ability to summarize rules from examples and\napply on new ones, has long been viewed as a primal ability for general\nintelligence and widely studied by cognitive science and AI researchers. Many\nbenchmarks have been proposed to measure such ability for Large Language Models\n(LLMs); however, they focus on few-shot (usually $<$10) setting and lack\nevaluation for aggregating many pieces of information from long contexts. On\nthe other hand, the ever-growing context length of LLMs have brought forth the\nnovel paradigm of many-shot In-Context Learning (ICL), which addresses new\ntasks with hundreds to thousands of examples without expensive and inefficient\nfine-tuning. However, many-shot evaluations are mostly focused on\nclassification (a very limited aspect of IR), and popular long-context LLM\ntasks such as Needle-In-A-Haystack (NIAH) seldom require complicated\nintelligence for integrating many pieces of information. To fix the issues from\nboth worlds, we propose MIR-Bench, the first many-shot in-context inductive\nreasoning benchmark that asks LLM to induce output via input-output examples\nfrom underlying functions with diverse data format. Based on MIR-Bench, we\nstudy many novel problems for inductive reasoning and many-shot ICL, including\nrobustness against erroneous shots and the effect of Chain-of-Thought (CoT),\nand acquired insightful findings.", "published": "2025-02-14 06:05:12", "link": "http://arxiv.org/abs/2502.09933v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Preliminary Exploration with GPT-4o Voice Mode", "abstract": "With the rise of multimodal large language models, GPT-4o stands out as a\npioneering model, driving us to evaluate its capabilities. This report assesses\nGPT-4o across various tasks to analyze its audio processing and reasoning\nabilities. We find that GPT-4o exhibits strong knowledge in audio, speech, and\nmusic understanding, performing well in tasks like intent classification,\nspoken command classification, semantic and grammatical reasoning.,\nmultilingual speech recognition, and singing analysis. It also shows greater\nrobustness against hallucinations than other large audio-language models\n(LALMs). However, it struggles with tasks such as audio duration prediction and\ninstrument classification. Additionally, GPT-4o's safety mechanisms cause it to\ndecline tasks like speaker identification, age classification, MOS prediction,\nand audio deepfake detection. Notably, the model exhibits a significantly\ndifferent refusal rate when responding to speaker verification tasks on\ndifferent datasets. This is likely due to variations in the accompanying\ninstructions or the quality of the input audio, suggesting the sensitivity of\nits built-in safeguards. Finally, we acknowledge that model performance varies\nwith evaluation protocols. This report only serves as a preliminary exploration\nof the current state of LALMs.", "published": "2025-02-14 06:34:08", "link": "http://arxiv.org/abs/2502.09940v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "abstract": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance.", "published": "2025-02-14 07:28:08", "link": "http://arxiv.org/abs/2502.09956v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Valuation using Neural Networks for Efficient Instruction\n  Fine-Tuning", "abstract": "Influence functions provide crucial insights into model training, but\nexisting methods suffer from large computational costs and limited\ngeneralization. Particularly, recent works have proposed various metrics and\nalgorithms to calculate the influence of data using language models, which do\nnot scale well with large models and datasets. This is because of the expensive\nforward and backward passes required for computation, substantial memory\nrequirements to store large models, and poor generalization of influence\nestimates to new data. In this paper, we explore the use of small neural\nnetworks -- which we refer to as the InfluenceNetwork -- to estimate influence\nvalues, achieving up to 99% cost reduction. Our evaluation demonstrates that\ninfluence values can be estimated with models just 0.0027% the size of full\nlanguage models (we use 7B and 8B versions). We apply our algorithm of\nestimating influence values (called NN-CIFT: Neural Networks for effiCient\nInstruction Fine-Tuning) to the downstream task of subset selection for general\ninstruction fine-tuning. In our study, we include four state-of-the-art\ninfluence functions and show no compromise in performance, despite large\nspeedups, between NN-CIFT and the original influence functions. We provide an\nin-depth hyperparameter analyses of NN-CIFT. The code for our method can be\nfound here: https://github.com/agarwalishika/NN-CIFT.", "published": "2025-02-14 07:55:47", "link": "http://arxiv.org/abs/2502.09969v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EmbBERT-Q: Breaking Memory Barriers in Embedded NLP", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nsetting new standards across a wide range of applications. However, their\nrelevant memory and computational demands make them impractical for deployment\non technologically-constrained tiny devices such as wearable devices and\nInternet-of-Things units. To address this limitation, we introduce EmbBERT-Q, a\nnovel tiny language model specifically designed for tiny devices with stringent\nmemory constraints. EmbBERT-Q achieves state-of-the-art (SotA) accuracy in\nNatural Language Processing tasks in this scenario, with a total memory\nfootprint (weights and activations) of just 781 kB, representing a 25x\nreduction in size with respect to SotA models. By combining architectural\ninnovations with hardware-compatible 8-bit quantization, EmbBERT-Q consistently\noutperforms several baseline models scaled down to a 2 MB memory budget (i.e.,\nthe maximum memory typically available in tiny devices), including heavily\ncompressed versions of BERT and MAMBA. Extensive experimental evaluations on\nboth a selected benchmark dataset, TinyNLP, specifically curated to evaluate\nTiny Language Models in NLP tasks and real-world scenarios, and the GLUE\nbenchmark, demonstrate EmbBERT-Q ability to deliver competitive accuracy with\nrespect to existing approaches, achieving an unmatched balance between memory\nand performance. To ensure the complete and immediate reproducibility of all\nour results, we release all code, scripts, and model checkpoints at\nhttps://github.com/RiccardoBravin/tiny-LLM.", "published": "2025-02-14 08:33:31", "link": "http://arxiv.org/abs/2502.10001v1", "categories": ["cs.CL", "cs.AR", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting Generalization Power of a DNN in Terms of Symbolic\n  Interactions", "abstract": "This paper aims to analyze the generalization power of deep neural networks\n(DNNs) from the perspective of interactions. Unlike previous analysis of a\nDNN's generalization power in a highdimensional feature space, we find that the\ngeneralization power of a DNN can be explained as the generalization power of\nthe interactions. We found that the generalizable interactions follow a\ndecay-shaped distribution, while non-generalizable interactions follow a\nspindle-shaped distribution. Furthermore, our theory can effectively\ndisentangle these two types of interactions from a DNN. We have verified that\nour theory can well match real interactions in a DNN in experiments.", "published": "2025-02-14 13:46:14", "link": "http://arxiv.org/abs/2502.10162v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "DeltaProduct: Improving State-Tracking in Linear RNNs via Householder\n  Products", "abstract": "Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive\nalternatives to Transformers for sequence modeling, offering efficient training\nand linear-time inference. However, existing architectures face a fundamental\ntrade-off between expressivity and efficiency, dictated by the structure of\ntheir state-transition matrices. While diagonal matrices used in architectures\nlike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited\nexpressivity. To address this, recent architectures such as (Gated) DeltaNet\nand RWKV-7 adopted a diagonal plus rank-1 structure, allowing simultaneous\ntoken-channel mixing, which overcomes some expressivity limitations with only a\nslight decrease in training efficiency. Building on the interpretation of\nDeltaNet's recurrence as performing one step of online gradient descent per\ntoken on an associative recall loss, we introduce DeltaProduct, which instead\ntakes multiple ($n_h$) steps per token. This naturally leads to diagonal plus\nrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized\nHouseholder transformations, providing a tunable mechanism to balance\nexpressivity and efficiency and a stable recurrence. Through extensive\nexperiments, we demonstrate that DeltaProduct achieves superior state-tracking\nand language modeling capabilities while exhibiting significantly improved\nlength extrapolation compared to DeltaNet. Additionally, we also strengthen the\ntheoretical foundation of DeltaNet by proving that it can solve dihedral group\nword problems in just two layers.", "published": "2025-02-14 16:59:05", "link": "http://arxiv.org/abs/2502.10297v4", "categories": ["cs.LG", "cs.CL", "cs.FL"], "primary_category": "cs.LG"}
{"title": "STAR: Spectral Truncation and Rescale for Model Merging", "abstract": "Model merging is an efficient way of obtaining a multi-task model from\nseveral pretrained models without further fine-tuning, and it has gained\nattention in various domains, including natural language processing (NLP).\nDespite the efficiency, a key challenge in model merging is the seemingly\ninevitable decrease in task performance as the number of models increases. In\nthis paper, we propose $\\mathbf{S}$pectral $\\mathbf{T}$runcation $\\mathbf{A}$nd\n$\\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' by\ntruncating small components in the respective spectral spaces, which is\nfollowed by an automatic parameter rescaling scheme to retain the nuclear norm\nof the original matrix. STAR requires no additional inference on original\ntraining data and is robust to hyperparamater choice. We demonstrate the\neffectiveness of STAR through extensive model merging cases on diverse NLP\ntasks. Specifically, STAR works robustly across varying model sizes, and can\noutperform baselines by 4.2$\\%$ when merging 12 models on Flan-T5. Our code is\npublicly available at https://github.com/IBM/STAR.", "published": "2025-02-14 17:59:58", "link": "http://arxiv.org/abs/2502.10339v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OWLS: Scaling Laws for Multilingual Speech Recognition and Translation\n  Models", "abstract": "Neural scaling laws offer valuable insights for designing robust sequence\nprocessing architectures. While these laws have been extensively characterized\nin other modalities, their behavior in speech remains comparatively\nunderexplored. In this work, we introduce OWLS, an open-access, reproducible\nsuite of multilingual speech recognition and translation models spanning 0.25B\nto 18B parameters, with the 18B version being the largest speech model, to the\nbest of our knowledge. OWLS leverages up to 360K hours of public speech data\nacross 150 languages, enabling a systematic investigation into how data, model,\nand compute scaling each influence performance in multilingual speech tasks. We\nuse OWLS to derive neural scaling laws, showing how final performance can be\nreliably predicted when scaling. One of our key findings is that scaling\nenhances performance on low-resource languages/dialects, helping to mitigate\nbias and improve the accessibility of speech technologies. Finally, we show how\nOWLS can be used to power new research directions by discovering emergent\nabilities in large-scale speech models. Model checkpoints will be released on\nhttps://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8d\nfor future studies.", "published": "2025-02-14 18:51:40", "link": "http://arxiv.org/abs/2502.10373v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Preference learning made easy: Everything should be understood through\n  win rate", "abstract": "Preference learning, or the task of aligning generative models to preference\ncomparison data, has yet to reach the conceptual maturity of classification,\ndensity estimation, etc. To close this gap, this work presents a framework to\nunderstand preference learning starting from the sampling distribution of\npairwise preference data. First, we prove that the only evaluation of a\ngenerative model that respects both preferences and prevalences in the data\ndistribution is a form of win rate, justifying win rate as the focal point to\nunderstand preference learning. We then analyze preference learning methods as\nwin rate optimization (WRO) or non-WRO. We present novel instances of WRO\nbeyond existing examples (RLHF, NLHF) and identify two key theoretical benefits\nof all such methods. We prove that common non-WRO methods like DPO and SFT on\npreferred samples lack these properties and suggest ways to mitigate such\ntheoretical limitations. We also show that WRO underperforms in practice due\noptimization difficulties and that optimization success predicts performance\nbetter than choices which affect the objective's solution. Our analysis\nhighlights best practices for existing methods and provides recommendations for\nfuture research, guided by the principle that one should either align non-WRO\nmethods more closely with WRO or improve the optimization of WRO objectives.", "published": "2025-02-14 19:01:34", "link": "http://arxiv.org/abs/2502.10505v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Post-training an LLM for RAG? Train on Self-Generated Demonstrations", "abstract": "Large language models (LLMs) often struggle with knowledge intensive NLP\ntasks, such as answering \"Who won the latest World Cup?\" because the knowledge\nthey learn during training may be insufficient or outdated. Conditioning\ngeneration on retrieved documents -- a technique known as retrieval augmented\ngeneration (RAG) -- mitigates these shortcomings by allowing the model to\nleverage in-context information. Practitioners can improve LLM RAG performance\nby fine-tuning on retrieval-augmented instructions, but must beware that this\ncan cause undesirable model behaviors like hallucinations. We attribute this\ndegradation to the fact that the training data is likely to be\nout-of-distribution for the model and may suffer from quality issues, such as\nmisalignment between retrievals and target responses (since retrievals are\nfrequently added post-hoc). We propose a recipe for training RAG-enabled LLMs\nusing self-generated demonstrations, thereby avoiding training on\nout-of-distribution text and integrating retrievals into the LLM responses. We\nevaluate our method on knowledge intensive question answering (QA) tasks and\nshow that our method teaches LLMs to properly handle in-context retrievals and\nabstain from questions it will likely get wrong. Compared to conventional RA-IT\nmethods, our method prevents model degradation in non-RAG settings while\nexhibiting superior QA performance.", "published": "2025-02-14 23:00:49", "link": "http://arxiv.org/abs/2502.10596v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifiable Steering via Sparse Autoencoding of Multi-Concept Shifts", "abstract": "Steering methods manipulate the representations of large language models\n(LLMs) to induce responses that have desired properties, e.g., truthfulness,\noffering a promising approach for LLM alignment without the need for\nfine-tuning. Traditionally, steering has relied on supervision, such as from\ncontrastive pairs of prompts that vary in a single target concept, which is\ncostly to obtain and limits the speed of steering research. An appealing\nalternative is to use unsupervised approaches such as sparse autoencoders\n(SAEs) to map LLM embeddings to sparse representations that capture\nhuman-interpretable concepts. However, without further assumptions, SAEs may\nnot be identifiable: they could learn latent dimensions that entangle multiple\nconcepts, leading to unintentional steering of unrelated properties. We\nintroduce Sparse Shift Autoencoders (SSAEs) that instead map the differences\nbetween embeddings to sparse representations. Crucially, we show that SSAEs are\nidentifiable from paired observations that vary in \\textit{multiple unknown\nconcepts}, leading to accurate steering of single concepts without the need for\nsupervision. We empirically demonstrate accurate steering across semi-synthetic\nand real-world language datasets using Llama-3.1 embeddings.", "published": "2025-02-14 08:49:41", "link": "http://arxiv.org/abs/2502.12179v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Lorecast: Layout-Aware Performance and Power Forecasting from Natural\n  Language", "abstract": "In chip design planning, obtaining reliable performance and power forecasts\nfor various design options is of critical importance. Traditionally, this\ninvolves using system-level models, which often lack accuracy, or trial\nsynthesis, which is both labor-intensive and time-consuming. We introduce a new\nmethodology, called Lorecast, which accepts English prompts as input to rapidly\ngenerate layout-aware performance and power estimates. This approach bypasses\nthe need for HDL code development or synthesis, making it both fast and\nuser-friendly. Experimental results demonstrate that Lorecast achieves accuracy\nwithin a few percent of error compared to post-layout analysis.", "published": "2025-02-14 23:08:39", "link": "http://arxiv.org/abs/2503.11662v1", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AR"}
{"title": "X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability", "abstract": "Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.", "published": "2025-02-14 08:22:51", "link": "http://arxiv.org/abs/2502.09990v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Large Language Models and Synthetic Data for Monitoring Dataset Mentions\n  in Research Papers", "abstract": "Tracking how data is mentioned and used in research papers provides critical\ninsights for improving data discoverability, quality, and production. However,\nmanually identifying and classifying dataset mentions across vast academic\nliterature is resource-intensive and not scalable. This paper presents a\nmachine learning framework that automates dataset mention detection across\nresearch domains by leveraging large language models (LLMs), synthetic data,\nand a two-stage fine-tuning process. We employ zero-shot extraction from\nresearch papers, an LLM-as-a-Judge for quality assessment, and a reasoning\nagent for refinement to generate a weakly supervised synthetic dataset. The\nPhi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed by\nfine-tuning on a manually annotated subset. At inference, a ModernBERT-based\nclassifier efficiently filters dataset mentions, reducing computational\noverhead while maintaining high recall. Evaluated on a held-out manually\nannotated sample, our fine-tuned model outperforms NuExtract-v1.5 and\nGLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight how\nLLM-generated synthetic data can effectively address training data scarcity,\nimproving generalization in low-resource settings. This framework offers a\npathway toward scalable monitoring of dataset usage, enhancing transparency,\nand supporting researchers, funders, and policymakers in identifying data gaps\nand strengthening data accessibility for informed decision-making.", "published": "2025-02-14 16:16:02", "link": "http://arxiv.org/abs/2502.10263v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT\n  System for the DASR Task of the CHiME-8 Challenge", "abstract": "In this paper, we introduce a multi-talker distant automatic speech\nrecognition (DASR) system we designed for the DASR task 1 of the CHiME-8\nchallenge. Our system performs speaker counting, diarization, and ASR. It\nhandles various recording conditions, from diner parties to professional\nmeetings and from two to eight speakers. We perform diarization first, followed\nby speech enhancement, and then ASR as the challenge baseline. However, we\nintroduced several key refinements. First, we derived a powerful speaker\ndiarization relying on end-to-end speaker diarization with vector clustering\n(EEND-VC), multi-channel speaker counting using enhanced embeddings from\nEEND-VC, and target-speaker voice activity detection (TS-VAD). For speech\nenhancement, we introduced a novel microphone selection rule to better select\nthe most relevant microphones among the distributed microphones and\ninvestigated improvements to beamforming. Finally, for ASR, we developed\nseveral models exploiting Whisper and WavLM speech foundation models. We\npresent the results we submitted to the challenge and updated results we\nobtained afterward. Our strongest system achieves a 63% relative macro tcpWER\nimprovement over the baseline and outperforms the challenge best results on the\nNOTSOFAR-1 meeting evaluation data among geometry-independent systems.", "published": "2025-02-14 01:46:54", "link": "http://arxiv.org/abs/2502.09859v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "CLaMP 3: Universal Music Information Retrieval Across Unaligned\n  Modalities and Unseen Languages", "abstract": "CLaMP 3 is a unified framework developed to address challenges of cross-modal\nand cross-lingual generalization in music information retrieval. Using\ncontrastive learning, it aligns all major music modalities--including sheet\nmusic, performance signals, and audio recordings--with multilingual text in a\nshared representation space, enabling retrieval across unaligned modalities\nwith text as a bridge. It features a multilingual text encoder adaptable to\nunseen languages, exhibiting strong cross-lingual generalization. Leveraging\nretrieval-augmented generation, we curated M4-RAG, a web-scale dataset\nconsisting of 2.31 million music-text pairs. This dataset is enriched with\ndetailed metadata that represents a wide array of global musical traditions. To\nadvance future research, we release WikiMT-X, a benchmark comprising 1,000\ntriplets of sheet music, audio, and richly varied text descriptions.\nExperiments show that CLaMP 3 achieves state-of-the-art performance on multiple\nMIR tasks, significantly surpassing previous strong baselines and demonstrating\nexcellent generalization in multimodal and multilingual music contexts.", "published": "2025-02-14 18:42:25", "link": "http://arxiv.org/abs/2502.10362v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Age-Related Robustness in Children Speaker Verification", "abstract": "One of the main challenges in children's speaker verification (C-SV) is the\nsignificant change in children's voices as they grow. In this paper, we propose\ntwo approaches to improve age-related robustness in C-SV. We first introduce a\nFeature Transform Adapter (FTA) module that integrates local patterns into\nhigher-level global representations, reducing overfitting to specific local\nfeatures and improving the inter-year SV performance of the system. We then\nemploy Synthetic Audio Augmentation (SAA) to increase data diversity and size,\nthereby improving robustness against age-related changes. Since the lack of\nlongitudinal speech datasets makes it difficult to measure age-related\nrobustness of C-SV systems, we introduce a longitudinal dataset to assess\ninter-year verification robustness of C-SV systems. By integrating both of our\nproposed methods, the average equal error rate was reduced by 19.4%, 13.0%, and\n6.1% in the one-year, two-year, and three-year gap inter-year evaluation sets,\nrespectively, compared to the baseline.", "published": "2025-02-14 19:18:02", "link": "http://arxiv.org/abs/2502.10511v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "InterGridNet: An Electric Network Frequency Approach for Audio Source\n  Location Classification Using Convolutional Neural Networks", "abstract": "A novel framework, called InterGridNet, is introduced, leveraging a shallow\nRawNet model for geolocation classification of Electric Network Frequency (ENF)\nsignatures in the SP Cup 2016 dataset. During data preparation, recordings are\nsorted into audio and power groups based on inherent characteristics, further\ndivided into 50 Hz and 60 Hz groups via spectrogram analysis. Residual blocks\nwithin the classification model extract frame-level embeddings, aiding\ndecision-making through softmax activation. The topology and the\nhyperparameters of the shallow RawNet are optimized using a Neural Architecture\nSearch. The overall accuracy of InterGridNet in the test recordings is 92%,\nindicating its effectiveness against the state-of-the-art methods tested in the\nSP Cup 2016. These findings underscore InterGridNet's effectiveness in\naccurately classifying audio recordings from diverse power grids, advancing\nstate-of-the-art geolocation estimation methods.", "published": "2025-02-14 08:45:35", "link": "http://arxiv.org/abs/2502.10011v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking\n  Effect", "abstract": "The rapid advancements in AI voice cloning, fueled by machine learning, have\nsignificantly impacted text-to-speech (TTS) and voice conversion (VC) fields.\nWhile these developments have led to notable progress, they have also raised\nconcerns about the misuse of AI VC technology, causing economic losses and\nnegative public perceptions. To address this challenge, this study focuses on\ncreating active defense mechanisms against AI VC systems.\n  We propose a novel active defense method, VocalCrypt, which embeds\npseudo-timbre (jamming information) based on SFS into audio segments that are\nimperceptible to the human ear, thereby forming systematic fragments to prevent\nvoice cloning. This approach protects the voice without compromising its\nquality. In comparison to existing methods, such as adversarial noise\nincorporation, VocalCrypt significantly enhances robustness and real-time\nperformance, achieving a 500\\% increase in generation speed while maintaining\ninterference effectiveness.\n  Unlike audio watermarking techniques, which focus on post-detection, our\nmethod offers preemptive defense, reducing implementation costs and enhancing\nfeasibility. Extensive experiments using the Zhvoice and VCTK Corpus datasets\nshow that our AI-cloned speech defense system performs excellently in automatic\nspeaker verification (ASV) tests while preserving the integrity of the\nprotected audio.", "published": "2025-02-14 17:43:01", "link": "http://arxiv.org/abs/2502.10329v1", "categories": ["cs.SD", "cs.CR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "F-StrIPE: Fast Structure-Informed Positional Encoding for Symbolic Music\n  Generation", "abstract": "While music remains a challenging domain for generative models like\nTransformers, recent progress has been made by exploiting suitable\nmusically-informed priors. One technique to leverage information about musical\nstructure in Transformers is inserting such knowledge into the positional\nencoding (PE) module. However, Transformers carry a quadratic cost in sequence\nlength. In this paper, we propose F-StrIPE, a structure-informed PE scheme that\nworks in linear complexity. Using existing kernel approximation techniques\nbased on random features, we show that F-StrIPE is a generalization of\nStochastic Positional Encoding (SPE). We illustrate the empirical merits of\nF-StrIPE using melody harmonization for symbolic music.", "published": "2025-02-14 13:15:18", "link": "http://arxiv.org/abs/2502.10491v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries", "abstract": "We introduce EMSYNC, a video-based symbolic music generation model that\naligns music with a video's emotional content and temporal boundaries. It\nfollows a two-stage framework, where a pretrained video emotion classifier\nextracts emotional features, and a conditional music generator produces MIDI\nsequences guided by both emotional and temporal cues. We introduce boundary\noffsets, a novel temporal conditioning mechanism that enables the model to\nanticipate and align musical chords with scene cuts. Unlike existing models,\nour approach retains event-based encoding, ensuring fine-grained timing control\nand expressive musical nuances. We also propose a mapping scheme to bridge the\nvideo emotion classifier, which produces discrete emotion categories, with the\nemotion-conditioned MIDI generator, which operates on continuous-valued\nvalence-arousal inputs. In subjective listening tests, EMSYNC outperforms\nstate-of-the-art models across all subjective metrics, for music theory-aware\nparticipants as well as the general listeners.", "published": "2025-02-14 13:32:59", "link": "http://arxiv.org/abs/2502.10154v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS", "eess.IV"], "primary_category": "cs.SD"}
