{"title": "Controllable Sentence Simplification: Employing Syntactic and Lexical\n  Constraints", "abstract": "Sentence simplification aims to make sentences easier to read and understand.\nRecent approaches have shown promising results with sequence-to-sequence models\nwhich have been developed assuming homogeneous target audiences. In this paper\nwe argue that different users have different simplification needs (e.g.\ndyslexics vs. non-native speakers), and propose CROSS, ContROllable Sentence\nSimplification model, which allows to control both the level of simplicity and\nthe type of the simplification. We achieve this by enriching a\nTransformer-based architecture with syntactic and lexical constraints (which\ncan be set or learned from data). Empirical results on two benchmark datasets\nshow that constraints are key to successful simplification, offering flexible\ngeneration output.", "published": "2019-10-10 06:37:36", "link": "http://arxiv.org/abs/1910.04387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for\n  the Right Reason", "abstract": "Recent studies have revealed that reading comprehension (RC) systems learn to\nexploit annotation artifacts and other biases in current datasets. This\nprevents the community from reliably measuring the progress of RC systems. To\naddress this issue, we introduce R4C, a new task for evaluating RC systems'\ninternal reasoning. R4C requires giving not only answers but also derivations:\nexplanations that justify predicted answers. We present a reliable,\ncrowdsourced framework for scalably annotating RC datasets with derivations. We\ncreate and publicly release the R4C dataset, the first, quality-assured dataset\nconsisting of 4.6k questions, each of which is annotated with 3 reference\nderivations (i.e. 13.8k derivations). Experiments show that our automatic\nevaluation metrics using multiple reference derivations are reliable, and that\nR4C assesses different skills from an existing benchmark.", "published": "2019-10-10 14:28:56", "link": "http://arxiv.org/abs/1910.04601v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-label Categorization of Accounts of Sexism using a Neural\n  Framework", "abstract": "Sexism, an injustice that subjects women and girls to enormous suffering,\nmanifests in blatant as well as subtle ways. In the wake of growing\ndocumentation of experiences of sexism on the web, the automatic categorization\nof accounts of sexism has the potential to assist social scientists and policy\nmakers in studying and countering sexism better. The existing work on sexism\nclassification, which is different from sexism detection, has certain\nlimitations in terms of the categories of sexism used and/or whether they can\nco-occur. To the best of our knowledge, this is the first work on the\nmulti-label classification of sexism of any kind(s), and we contribute the\nlargest dataset for sexism categorization. We develop a neural solution for\nthis multi-label classification that can combine sentence representations\nobtained using models such as BERT with distributional and linguistic word\nembeddings using a flexible, hierarchical architecture involving recurrent\ncomponents and optional convolutional ones. Further, we leverage unlabeled\naccounts of sexism to infuse domain-specific elements into our framework. The\nbest proposed method outperforms several deep learning as well as traditional\nmachine learning baselines by an appreciable margin.", "published": "2019-10-10 14:28:57", "link": "http://arxiv.org/abs/1910.04602v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Question Answering from Formatted Text applied to\n  Conversational Agents", "abstract": "Recent advances with language models (e.g. BERT, XLNet, ...), have allowed\nsurpassing human performance on complex NLP tasks such as Reading\nComprehension. However, labeled datasets for training are available mostly in\nEnglish which makes it difficult to acknowledge progress in other languages.\nFortunately, models are now pre-trained on unlabeled data from hundreds of\nlanguages and exhibit interesting transfer abilities from one language to\nanother. In this paper, we show that multilingual BERT is naturally capable of\nzero-shot transfer for an extractive Question Answering task (eQA) from English\nto other languages. More specifically, it outperforms the best previously known\nbaseline for transfer to Japanese and French. Moreover, using a recently\npublished large eQA French dataset, we are able to further show that (1)\nzero-shot transfer provides results really close to a direct training on the\ntarget language and (2) combination of transfer and training on target is the\nbest option overall. We finally present a practical application: a multilingual\nconversational agent called Kate which answers to HR-related questions in\nseveral languages directly from the content of intranet pages.", "published": "2019-10-10 15:44:29", "link": "http://arxiv.org/abs/1910.04659v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Quality Estimation for Natural Language Generation: Ranting\n  (Jointly Rating and Ranking)", "abstract": "We present a recurrent neural network based system for automatic quality\nestimation of natural language generation (NLG) outputs, which jointly learns\nto assign numerical ratings to individual outputs and to provide pairwise\nrankings of two different outputs. The latter is trained using pairwise hinge\nloss over scores from two copies of the rating network.\n  We use learning to rank and synthetic data to improve the quality of ratings\nassigned by our system: we synthesise training pairs of distorted system\noutputs and train the system to rank the less distorted one higher. This leads\nto a 12% increase in correlation with human ratings over the previous\nbenchmark. We also establish the state of the art on the dataset of relative\nrankings from the E2E NLG Challenge (Du\\v{s}ek et al., 2019), where synthetic\ndata lead to a 4% accuracy increase over the base model.", "published": "2019-10-10 17:43:31", "link": "http://arxiv.org/abs/1910.04731v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams", "abstract": "Set expansion aims to expand a small set of seed entities into a complete set\nof relevant entities. Most existing approaches assume the input seed set is\nunambiguous and completely ignore the multi-faceted semantics of seed entities.\nAs a result, given the seed set {\"Canon\", \"Sony\", \"Nikon\"}, previous models\nreturn one mixed set of entities that are either Camera Brands or Japanese\nCompanies. In this paper, we study the task of multi-faceted set expansion,\nwhich aims to capture all semantic facets in the seed set and return multiple\nsets of entities, one for each semantic facet. We propose an unsupervised\nframework, FUSE, which consists of three major components: (1) facet discovery\nmodule: identifies all semantic facets of each seed entity by extracting and\nclustering its skip-grams, and (2) facet fusion module: discovers shared\nsemantic facets of the entire seed set by an optimization formulation, and (3)\nentity expansion module: expands each semantic facet by utilizing a masked\nlanguage model with pre-trained BERT models. Extensive experiments demonstrate\nthat FUSE can accurately identify multiple semantic facets of the seed set and\ngenerate quality entities for each facet.", "published": "2019-10-10 03:06:46", "link": "http://arxiv.org/abs/1910.04345v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Alignment vs Joint Training: A Comparative Study and A\n  Simple Unified Framework", "abstract": "Learning multilingual representations of text has proven a successful method\nfor many cross-lingual transfer learning tasks. There are two main paradigms\nfor learning such representations: (1) alignment, which maps different\nindependently trained monolingual representations into a shared space, and (2)\njoint training, which directly learns unified multilingual representations\nusing monolingual and cross-lingual objectives jointly. In this paper, we first\nconduct direct comparisons of representations learned using both of these\nmethods across diverse cross-lingual tasks. Our empirical results reveal a set\nof pros and cons for both methods, and show that the relative performance of\nalignment versus joint training is task-dependent. Stemming from this analysis,\nwe propose a simple and novel framework that combines these two previously\nmutually-exclusive approaches. Extensive experiments demonstrate that our\nproposed framework alleviates limitations of both approaches, and outperforms\nexisting methods on the MUSE bilingual lexicon induction (BLI) benchmark. We\nfurther show that this framework can generalize to contextualized\nrepresentations such as Multilingual BERT, and produces state-of-the-art\nresults on the CoNLL cross-lingual NER benchmark.", "published": "2019-10-10 17:04:30", "link": "http://arxiv.org/abs/1910.04708v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Only from Relevant Keywords and Unlabeled Documents", "abstract": "We consider a document classification problem where document labels are\nabsent but only relevant keywords of a target class and unlabeled documents are\ngiven. Although heuristic methods based on pseudo-labeling have been\nconsidered, theoretical understanding of this problem has still been limited.\nMoreover, previous methods cannot easily incorporate well-developed techniques\nin supervised text classification. In this paper, we propose a theoretically\nguaranteed learning framework that is simple to implement and has flexible\nchoices of models, e.g., linear models or neural networks. We demonstrate how\nto optimize the area under the receiver operating characteristic curve (AUC)\neffectively and also discuss how to adjust it to optimize other well-known\nevaluation metrics such as the accuracy and F1-measure. Finally, we show the\neffectiveness of our framework using benchmark datasets.", "published": "2019-10-10 06:29:22", "link": "http://arxiv.org/abs/1910.04385v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Contract Statements Knowledge Service for Chatbots", "abstract": "Towards conversational agents that are capable of handling more complex\nquestions on contractual conditions, formalizing contract statements in a\nmachine readable way is crucial. However, constructing a formal model which\ncaptures the full scope of a contract proves difficult due to the overall\ncomplexity its set of rules represent. Instead, this paper presents a top-down\napproach to the problem. After identifying the most relevant contract\nstatements, we model their underlying rules in a novel knowledge engineering\nmethod. A user-friendly tool we developed for this purpose allows to do so\neasily and at scale. Then, we expose the statements as service so they can get\nsmoothly integrated in any chatbot framework.", "published": "2019-10-10 08:25:42", "link": "http://arxiv.org/abs/1910.04424v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Language Transfer for Early Warning of Epidemics from Social Media", "abstract": "Statements on social media can be analysed to identify individuals who are\nexperiencing red flag medical symptoms, allowing early detection of the spread\nof disease such as influenza. Since disease does not respect cultural borders\nand may spread between populations speaking different languages, we would like\nto build multilingual models. However, the data required to train models for\nevery language may be difficult, expensive and time-consuming to obtain,\nparticularly for low-resource languages. Taking Japanese as our target\nlanguage, we explore methods by which data in one language might be used to\nbuild models for a different language. We evaluate strategies of training on\nmachine translated data and of zero-shot transfer through the use of\nmultilingual models. We find that the choice of source language impacts the\nperformance, with Chinese-Japanese being a better language pair than\nEnglish-Japanese. Training on machine translated data shows promise, especially\nwhen used in conjunction with a small amount of target language data.", "published": "2019-10-10 12:42:19", "link": "http://arxiv.org/abs/1910.04519v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Universal Adversarial Perturbation for Text Classification", "abstract": "Given a state-of-the-art deep neural network text classifier, we show the\nexistence of a universal and very small perturbation vector (in the embedding\nspace) that causes natural text to be misclassified with high probability.\nUnlike images on which a single fixed-size adversarial perturbation can be\nfound, text is of variable length, so we define the \"universality\" as\n\"token-agnostic\", where a single perturbation is applied to each token,\nresulting in different perturbations of flexible sizes at the sequence level.\nWe propose an algorithm to compute universal adversarial perturbations, and\nshow that the state-of-the-art deep neural networks are highly vulnerable to\nthem, even though they keep the neighborhood of tokens mostly preserved. We\nalso show how to use these adversarial perturbations to generate adversarial\ntext samples. The surprising existence of universal \"token-agnostic\"\nadversarial perturbations may reveal important properties of a text classifier.", "published": "2019-10-10 14:48:22", "link": "http://arxiv.org/abs/1910.04618v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Structured Pruning of Large Language Models", "abstract": "Large language models have recently achieved state of the art performance\nacross a wide variety of natural language tasks. Meanwhile, the size of these\nmodels and their latency have significantly increased, which makes their usage\ncostly, and raises an interesting question: do language models need to be\nlarge? We study this question through the lens of model compression. We present\na generic, structured pruning approach by parameterizing each weight matrix\nusing its low-rank factorization, and adaptively removing rank-1 components\nduring training. On language modeling tasks, our structured approach\noutperforms other unstructured and block-structured pruning baselines at\nvarious compression levels, while achieving significant speedups during both\ntraining and inference. We also demonstrate that our method can be applied to\npruning adaptive word embeddings in large language models, and to pruning the\nBERT model on several downstream fine-tuning classification benchmarks.", "published": "2019-10-10 17:44:18", "link": "http://arxiv.org/abs/1910.04732v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Visual Natural Language Query Auto-Completion for Estimating Instance\n  Probabilities", "abstract": "We present a new task of query auto-completion for estimating instance\nprobabilities. We complete a user query prefix conditioned upon an image. Given\nthe complete query, we fine tune a BERT embedding for estimating probabilities\nof a broad set of instances. The resulting instance probabilities are used for\nselection while being agnostic to the segmentation or attention mechanism. Our\nresults demonstrate that auto-completion using both language and vision\nperforms better than using only language, and that fine tuning a BERT embedding\nallows to efficiently rank instances in the image. In the spirit of\nreproducible research we make our data, models, and code available.", "published": "2019-10-10 21:46:26", "link": "http://arxiv.org/abs/1910.04887v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "First Order Ambisonics Domain Spatial Augmentation for DNN-based\n  Direction of Arrival Estimation", "abstract": "In this paper, we propose a novel data augmentation method for training\nneural networks for Direction of Arrival (DOA) estimation. This method focuses\non expanding the representation of the DOA subspace of a dataset. Given some\ninput data, it applies a transformation to it in order to change its DOA\ninformation and simulate new potentially unseen one. Such transformation, in\ngeneral, is a combination of a rotation and a reflection. It is possible to\napply such transformation due to a well-known property of First Order\nAmbisonics (FOA). The same transformation is applied also to the labels, in\norder to maintain consistency between input data and target labels. Three\nmethods with different level of generality are proposed for applying this\naugmentation principle. Experiments are conducted on two different DOA\nnetworks. Results of both experiments demonstrate the effectiveness of the\nnovel augmentation strategy by improving the DOA error by around 40%.", "published": "2019-10-10 06:38:57", "link": "http://arxiv.org/abs/1910.04388v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "DOA Estimation by DNN-based Denoising and Dereverberation from Sound\n  Intensity Vector", "abstract": "We propose a direction of arrival (DOA) estimation method that combines\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\ndereverberation. Since the accuracy of IV-based DOA estimation degrades due to\nenvironmental noise and reverberation, two DNNs are used to remove such effects\nfrom the observed IVs. DOA is then estimated from the refined IVs based on the\nphysics of wave propagation. Experiments on an open dataset showed that the\naverage DOA error of the proposed method was 0.528 degrees, and it outperformed\na conventional IV-based and DNN-based DOA estimation method.", "published": "2019-10-10 07:57:31", "link": "http://arxiv.org/abs/1910.04415v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Orthogonality Constrained Multi-Head Attention For Keyword Spotting", "abstract": "Multi-head attention mechanism is capable of learning various representations\nfrom sequential data while paying attention to different subsequences, e.g.,\nword-pieces or syllables in a spoken word. From the subsequences, it retrieves\nricher information than a single-head attention which only summarizes the whole\nsequence into one context vector. However, a naive use of the multi-head\nattention does not guarantee such richness as the attention heads may have\npositional and representational redundancy. In this paper, we propose a\nregularization technique for multi-head attention mechanism in an end-to-end\nneural keyword spotting system. Augmenting regularization terms which penalize\npositional and contextual non-orthogonality between the attention heads\nencourages to output different representations from separate subsequences,\nwhich in turn enables leveraging structured information without explicit\nsequence models such as hidden Markov models. In addition, intra-head\ncontextual non-orthogonality regularization encourages each attention head to\nhave similar representations across keyword examples, which helps\nclassification by reducing feature variability. The experimental results\ndemonstrate that the proposed regularization technique significantly improves\nthe keyword spotting performance for the keyword \"Hey Snapdragon\".", "published": "2019-10-10 12:00:33", "link": "http://arxiv.org/abs/1910.04500v1", "categories": ["cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
