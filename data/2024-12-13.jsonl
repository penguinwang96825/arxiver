{"title": "Reciprocity in Interbank Markets", "abstract": "Weighted reciprocity between two agents can be defined as the minimum of\nsending and receiving value in their bilateral relationship. In financial\nnetworks, such reciprocity characterizes the importance of individual banks as\nboth liquidity absorber and provider, a feature typically attributed to large,\nintermediating dealer banks. In this paper we develop an exponential random\ngraph model that can account for reciprocal links of each node simultaneously\non the topological as well as on the weighted level. We provide an exact\nexpression for the normalizing constant and thus a closed-form solution for the\ngraph probability distribution. Applying this statistical null model to Italian\ninterbank data, we find that before the great financial crisis (i) banks\ndisplayed significantly more weighted reciprocity compared to what the\nlower-order network features (size and volume distributions) would predict (ii)\nwith a disappearance of this deviation once the early periods of the crisis set\nin, (iii) a trend which can be attributed in particular to smaller banks\n(dis)engaging in bilateral high-value trading relationships. Moreover, we show\nthat neglecting reciprocal links and weights can lead to spurious findings of\ntriadic relationships. As the hierarchical structure in the network is found to\nbe compatible with its transitive but not with its intransitive triadic\nsub-graphs, the interbank market seems to be well-characterized by a\nhierarchical core-periphery structure enhanced by non-hierarchical reciprocal\ntrading relationships.", "published": "2024-12-13 18:07:12", "link": "http://arxiv.org/abs/2412.10329v1", "categories": ["q-fin.CP", "physics.data-an", "physics.soc-ph"], "primary_category": "q-fin.CP"}
{"title": "Integrative Analysis of Financial Market Sentiment Using CNN and GRU for Risk Prediction and Alert Systems", "abstract": "This document presents an in-depth examination of stock market sentiment\nthrough the integration of Convolutional Neural Networks (CNN) and Gated\nRecurrent Units (GRU), enabling precise risk alerts. The robust feature\nextraction capability of CNN is utilized to preprocess and analyze extensive\nnetwork text data, identifying local features and patterns. The extracted\nfeature sequences are then input into the GRU model to understand the\nprogression of emotional states over time and their potential impact on future\nmarket sentiment and risk. This approach addresses the order dependence and\nlong-term dependencies inherent in time series data, resulting in a detailed\nanalysis of stock market sentiment and effective early warnings of future\nrisks.", "published": "2024-12-13 15:17:23", "link": "http://arxiv.org/abs/2412.10199v1", "categories": ["cs.LG", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Financial Fine-tuning a Large Time Series Model", "abstract": "Large models have shown unprecedented capabilities in natural language\nprocessing, image generation, and most recently, time series forecasting. This\nleads us to ask the question: treating market prices as a time series, can\nlarge models be used to predict the market? In this paper, we answer this by\nevaluating the performance of the latest time series foundation model TimesFM\non price prediction. We find that due to the irregular nature of price data,\ndirectly applying TimesFM gives unsatisfactory results and propose to fine-tune\nTimeFM on financial data for the task of price prediction. This is done by\ncontinual pre-training of the latest time series foundation model TimesFM on\nprice data containing 100 million time points, spanning a range of financial\ninstruments spanning hourly and daily granularities. The fine-tuned model\ndemonstrates higher price prediction accuracy than the baseline model. We\nconduct mock trading for our model in various financial markets and show that\nit outperforms various benchmarks in terms of returns, sharpe ratio, max\ndrawdown and trading cost.", "published": "2024-12-13 05:51:00", "link": "http://arxiv.org/abs/2412.09880v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Self-Exciting Random Evolutions (SEREs) and their Applications (Version 2)", "abstract": "This paper is devoted to the study of a new class of random evolutions (RE),\nso-called self-exciting random evolutions (SEREs), and their applications. We\nalso introduce a new random process $x(t)$ such that it is based on a\nsuperposition of a Markov chain $x_n$ and a Hawkes process $N(t),$ i.e.,\n$x(t):=x_{N(t)}.$ We call this process self-walking imbedded semi-Hawkes\nprocess (Swish Process or SwishP). Then the self-exciting REs (SEREs) can be\nconstructed in similar way as, e.g., semi-Markov REs, but instead of\nsemi-Markov process $x(t)$ we have SwishP. We give classifications and examples\nof self-exciting REs (SEREs). Then we consider two limit theorems for SEREs\nsuch as averaging (Theorem 1) and diffusion approximation (Theorem 2).\nApplications of SEREs are devoted to the so-called self-exciting\ntraffic/transport process and self-exciting summation on a Markov chain, which\nare examples of continuous and discrete SERE. From these processes we can\nconstruct many other self-exciting processes, e.g., such as impulse\ntraffic/transport process, self-exciting risk process, general compound Hawkes\nprocess for a stock price, etc. We present averaged and diffusion approximation\nof self-exciting processes. The novelty of the paper associated with new\nmodels, such as $x(t)$ and SERE, and also new features of SEREs and their many\napplications, namely, self-exciting and clustering effects.", "published": "2024-12-13 22:27:20", "link": "http://arxiv.org/abs/2412.10592v2", "categories": ["math.PR", "q-fin.MF", "60G55, 60H25, 47H40, 47D06, 60H20, 60F17, 60F05"], "primary_category": "math.PR"}
{"title": "Higher Order Transformers: Enhancing Stock Movement Prediction On Multimodal Time-Series Data", "abstract": "In this paper, we tackle the challenge of predicting stock movements in\nfinancial markets by introducing Higher Order Transformers, a novel\narchitecture designed for processing multivariate time-series data. We extend\nthe self-attention mechanism and the transformer architecture to a higher\norder, effectively capturing complex market dynamics across time and variables.\nTo manage computational complexity, we propose a low-rank approximation of the\npotentially large attention tensor using tensor decomposition and employ kernel\nattention, reducing complexity to linear with respect to the data size.\nAdditionally, we present an encoder-decoder model that integrates technical and\nfundamental analysis, utilizing multimodal signals from historical prices and\nrelated tweets. Our experiments on the Stocknet dataset demonstrate the\neffectiveness of our method, highlighting its potential for enhancing stock\nmovement prediction in financial markets.", "published": "2024-12-13 20:26:35", "link": "http://arxiv.org/abs/2412.10540v1", "categories": ["cs.LG", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "LLM Distillation for Efficient Few-Shot Multiple Choice Question\n  Answering", "abstract": "Multiple Choice Question Answering (MCQA) is an important problem with\nnumerous real-world applications, such as medicine, law, and education. The\nhigh cost of building MCQA datasets makes few-shot learning pivotal in this\ndomain. While Large Language Models (LLMs) can enable few-shot learning, their\ndirect application in real-world scenarios is often hindered by their high\ncomputational cost. To address this challenge, we propose a simple yet\neffective approach that uses LLMs for data generation and scoring. Our approach\nutilizes LLMs to create MCQA data which contains questions and choices, and to\nassign probability scores to the generated choices. We then use the generated\ndata and LLM-assigned scores to finetune a smaller and more efficient\nencoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive\nexperiments on the Massive Multitask Language Understanding (MMLU) benchmark\ndemonstrate that our method improves accuracy from 28.9% to 39.3%, representing\na gain of over 10% compared to a baseline finetuned directly on 5-shot\nexamples. This shows the effectiveness of LLM-driven data generation and\nknowledge distillation for few-shot MCQA.", "published": "2024-12-13 02:48:36", "link": "http://arxiv.org/abs/2412.09807v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Byte Latent Transformer: Patches Scale Better Than Tokens", "abstract": "We introduce the Byte Latent Transformer (BLT), a new byte-level LLM\narchitecture that, for the first time, matches tokenization-based LLM\nperformance at scale with significant improvements in inference efficiency and\nrobustness. BLT encodes bytes into dynamically sized patches, which serve as\nthe primary units of computation. Patches are segmented based on the entropy of\nthe next byte, allocating more compute and model capacity where increased data\ncomplexity demands it. We present the first FLOP controlled scaling study of\nbyte-level models up to 8B parameters and 4T training bytes. Our results\ndemonstrate the feasibility of scaling models trained on raw bytes without a\nfixed vocabulary. Both training and inference efficiency improve due to\ndynamically selecting long patches when data is predictable, along with\nqualitative improvements on reasoning and long tail generalization. Overall,\nfor fixed inference costs, BLT shows significantly better scaling than\ntokenization-based models, by simultaneously growing both patch and model size.", "published": "2024-12-13 05:33:32", "link": "http://arxiv.org/abs/2412.09871v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Limit of Language Models as Planning Formalizers", "abstract": "Large Language Models have been shown to fail to create executable and\nverifiable plans in grounded environments. An emerging line of work shows\nsuccess in using LLM as a formalizer to generate a formal representation (e.g.,\nPDDL) of the planning domain, which can be deterministically solved to find a\nplan. We systematically evaluate this methodology while bridging some major\ngaps. While previous work only generates a partial PDDL representation given\ntemplated and thus unrealistic environment descriptions, we generate the\ncomplete representation given descriptions of various naturalness levels. Among\nan array of observations critical to improve LLMs' formal planning ability, we\nnote that large enough models can effectively formalize descriptions as PDDL,\noutperforming those directly generating plans, while being robust to lexical\nperturbation. As the descriptions become more natural-sounding, we observe a\ndecrease in performance and provide detailed error analysis.", "published": "2024-12-13 05:50:22", "link": "http://arxiv.org/abs/2412.09879v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Table Comprehension In The Wild", "abstract": "Large Language Models (LLMs), while being increasingly dominant on a myriad\nof knowledge-intensive activities, have only had limited success understanding\nlengthy table-text mixtures, such as academic papers and financial reports.\nRecent advances of long-context LLMs have opened up new possibilities for this\nfield. Nonetheless, we identify two roadblocks: (1) Prior benchmarks of table\nquestion answering (TableQA) have focused on isolated tables without context,\nmaking it hard to evaluate models in real-world scenarios. (2) Prior benchmarks\nhave focused on some narrow skill sets of table comprehension such as table\nrecognition, data manipulation/calculation, table summarization etc., while a\nskilled human employs those skills collectively. In this work, we introduce\nTableQuest, a new benchmark designed to evaluate the holistic table\ncomprehension capabilities of LLMs in the natural table-rich context of\nfinancial reports. We employ a rigorous data processing and filtering procedure\nto ensure that the question-answer pairs are logical, reasonable, and diverse.\nWe experiment with 7 state-of-the-art models, and find that despite reasonable\naccuracy in locating facts, they often falter when required to execute more\nsophisticated reasoning or multi-step calculations. We conclude with a\nqualitative study of the failure modes and discuss the challenges of\nconstructing a challenging benchmark. We make the evaluation data, judging\nprocedure and results of this study publicly available to facilitate research\nin this field.", "published": "2024-12-13 05:52:37", "link": "http://arxiv.org/abs/2412.09884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing the Reasoning Capabilities of Small Language Models via\n  Solution Guidance Fine-Tuning", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\na wide range of tasks. Advances in prompt engineering and fine-tuning\ntechniques have further enhanced their ability to address complex reasoning\nchallenges. However, these advanced capabilities are often exclusive to models\nexceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning\nmethods have been explored for smaller models (under 10 billion parameters),\nthey typically depend on extensive CoT training data, which can introduce\ninconsistencies and limit effectiveness in low-data settings. To overcome these\nlimitations, this paper introduce a new reasoning strategy Solution Guidance\n(SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT)\nfor enhancing the reasoning capabilities of small language models. SG focuses\non problem understanding and decomposition at the semantic and logical levels,\nrather than specific computations, which can effectively improve the SLMs'\ngeneralization and reasoning abilities. With only a small amount of SG training\ndata, SGFT can fine-tune a SLM to produce accurate problem-solving guidances,\nwhich can then be flexibly fed to any SLM as prompts, enabling it to generate\ncorrect answers directly. Experimental results demonstrate that our method\nsignificantly improves the performance of SLMs on various reasoning tasks,\nenhancing both their practicality and efficiency within resource-constrained\nenvironments.", "published": "2024-12-13 06:45:26", "link": "http://arxiv.org/abs/2412.09906v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Low-Resource Fast Text Classification Based on Intra-Class and\n  Inter-Class Distance Calculation", "abstract": "In recent years, text classification methods based on neural networks and\npre-trained models have gained increasing attention and demonstrated excellent\nperformance. However, these methods still have some limitations in practical\napplications: (1) They typically focus only on the matching similarity between\nsentences. However, there exists implicit high-value information both within\nsentences of the same class and across different classes, which is very crucial\nfor classification tasks. (2) Existing methods such as pre-trained language\nmodels and graph-based approaches often consume substantial memory for training\nand text-graph construction. (3) Although some low-resource methods can achieve\ngood performance, they often suffer from excessively long processing times. To\naddress these challenges, we propose a low-resource and fast text\nclassification model called LFTC. Our approach begins by constructing a\ncompressor list for each class to fully mine the regularity information within\nintra-class data. We then remove redundant information irrelevant to the target\nclassification to reduce processing time. Finally, we compute the similarity\ndistance between text pairs for classification. We evaluate LFTC on 9 publicly\navailable benchmark datasets, and the results demonstrate significant\nimprovements in performance and processing time, especially under limited\ncomputational and data resources, highlighting its superior advantages.", "published": "2024-12-13 07:22:13", "link": "http://arxiv.org/abs/2412.09922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Romanized to Native Malayalam Script Transliteration Using an\n  Encoder-Decoder Framework", "abstract": "In this work, we present the development of a reverse transliteration model\nto convert romanized Malayalam to native script using an encoder-decoder\nframework built with attention-based bidirectional Long Short Term Memory\n(Bi-LSTM) architecture. To train the model, we have used curated and combined\ncollection of 4.3 million transliteration pairs derived from publicly available\nIndic language translitertion datasets, Dakshina and Aksharantar. We evaluated\nthe model on two different test dataset provided by IndoNLP-2025-Shared-Task\nthat contain, (1) General typing patterns and (2) Adhoc typing patterns,\nrespectively. On the Test Set-1, we obtained a character error rate (CER) of\n7.4%. However upon Test Set-2, with adhoc typing patterns, where most vowel\nindicators are missing, our model gave a CER of 22.7%.", "published": "2024-12-13 08:33:26", "link": "http://arxiv.org/abs/2412.09957v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Persian $ \\leftrightarrow $ English Idiom\n  Translation", "abstract": "Large language models (LLMs) have shown superior capabilities in translating\nfigurative language compared to neural machine translation (NMT) systems.\nHowever, the impact of different prompting methods and LLM-NMT combinations on\nidiom translation has yet to be thoroughly investigated. This paper introduces\ntwo parallel datasets of sentences containing idiomatic expressions for\nPersian$\\rightarrow$English and English$\\rightarrow$Persian translations, with\nPersian idioms sampled from our PersianIdioms resource, a collection of 2,200\nidioms and their meanings, with 700 including usage examples. Using these\ndatasets, we evaluate various open- and closed-source LLMs, NMT models, and\ntheir combinations. Translation quality is assessed through idiom translation\naccuracy and fluency. We also find that automatic evaluation methods like\nLLM-as-a-judge, BLEU, and BERTScore are effective for comparing different\naspects of model performance. Our experiments reveal that Claude-3.5-Sonnet\ndelivers outstanding results in both translation directions. For\nEnglish$\\rightarrow$Persian, combining weaker LLMs with Google Translate\nimproves results, while Persian$\\rightarrow$English translations benefit from\nsingle prompts for simpler models and complex prompts for advanced ones.", "published": "2024-12-13 09:29:27", "link": "http://arxiv.org/abs/2412.09993v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The role of inhibitory control in garden-path sentence processing: A\n  Chinese-English bilingual perspective", "abstract": "In reading garden-path sentences, people must resolve competing\ninterpretations, though initial misinterpretations can linger despite\nreanalysis. This study examines the role of inhibitory control (IC) in managing\nthese misinterpretations among Chinese-English bilinguals. Using self-paced\nreading tasks, we investigated how IC influences recovery from garden-path\nsentences in Chinese (L1) and its interaction with language proficiency during\nEnglish (L2) processing. Results indicate that IC does not affect garden-path\nrecovery in Chinese, suggesting reliance on semantic context may reduce the\nneed for IC. In contrast, findings for English L2 learners reveal a complex\nrelationship between language proficiency and IC: Participants with low L2\nproficiency but high IC showed lingering misinterpretations, while those with\nhigh proficiency exhibited none. These results support and extend the Model of\nCognitive Control (Ness et al., 2023). Moreover, our comparison of three Stroop\ntask versions identifies L1 colour-word Stroop task as the preferred measure of\nIC in bilingual research.", "published": "2024-12-13 09:45:30", "link": "http://arxiv.org/abs/2412.10006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Collection of Evaluation Dataset for Semantic Search in\n  Low-Resource Domain Language", "abstract": "Domain-specific languages that use a lot of specific terminology often fall\ninto the category of low-resource languages. Collecting test datasets in a\nnarrow domain is time-consuming and requires skilled human resources with\ndomain knowledge and training for the annotation task. This study addresses the\nchallenge of automated collecting test datasets to evaluate semantic search in\nlow-resource domain-specific German language of the process industry. Our\napproach proposes an end-to-end annotation pipeline for automated query\ngeneration to the score reassessment of query-document pairs. To overcome the\nlack of text encoders trained in the German chemistry domain, we explore a\nprinciple of an ensemble of \"weak\" text encoders trained on common knowledge\ndatasets. We combine individual relevance scores from diverse models to\nretrieve document candidates and relevance scores generated by an LLM, aiming\nto achieve consensus on query-document alignment. Evaluation results\ndemonstrate that the ensemble method significantly improves alignment with\nhuman-assigned relevance scores, outperforming individual models in both\ninter-coder agreement and accuracy metrics. These findings suggest that\nensemble learning can effectively adapt semantic search systems for\nspecialized, low-resource languages, offering a practical solution to resource\nlimitations in domain-specific contexts.", "published": "2024-12-13 09:47:26", "link": "http://arxiv.org/abs/2412.10008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Named Entity Disambiguation for Low Resource Domains", "abstract": "In the ever-evolving landscape of natural language processing and information\nretrieval, the need for robust and domain-specific entity linking algorithms\nhas become increasingly apparent. It is crucial in a considerable number of\nfields such as humanities, technical writing and biomedical sciences to enrich\ntexts with semantics and discover more knowledge. The use of Named Entity\nDisambiguation (NED) in such domains requires handling noisy texts, low\nresource settings and domain-specific KBs. Existing approaches are mostly\ninappropriate for such scenarios, as they either depend on training data or are\nnot flexible enough to work with domain-specific KBs. Thus in this work, we\npresent an unsupervised approach leveraging the concept of Group Steiner Trees\n(GST), which can identify the most relevant candidates for entity\ndisambiguation using the contextual similarities across candidate entities for\nall the mentions present in a document. We outperform the state-of-the-art\nunsupervised methods by more than 40\\% (in avg.) in terms of Precision@1 across\nvarious domain-specific datasets.", "published": "2024-12-13 11:35:00", "link": "http://arxiv.org/abs/2412.10054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in the Middle, and In-Between: Enhancing Language Models' Ability\n  to Reason Over Long Contexts in Multi-Hop QA", "abstract": "Previous work finds that recent long-context language models fail to make\nequal use of information in the middle of their inputs, preferring pieces of\ninformation located at the tail ends which creates an undue bias in situations\nwhere we would like models to be equally capable of using different parts of\nthe input. Thus far, the problem has mainly only been considered in settings\nwith single pieces of critical information, leading us to question what happens\nwhen multiple necessary pieces of information are spread out over the inputs.\nHere, we demonstrate the effects of the \"lost in the middle\" problem in the\nmulti-hop question answering setting -- in which multiple reasoning \"hops\" over\ndisconnected documents are required -- and show that performance degrades not\nonly with respect to the distance of information from the edges of the context,\nbut also between pieces of information. Additionally, we experiment with means\nof alleviating the problem by reducing superfluous document contents through\nknowledge graph triple extraction and summarization, and prompting models to\nreason more thoroughly using chain-of-thought prompting.", "published": "2024-12-13 12:13:19", "link": "http://arxiv.org/abs/2412.10079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm\n  Detection Incorporating Bi-modal Data Augmentation", "abstract": "Detecting sarcasm effectively requires a nuanced understanding of context,\nincluding vocal tones and facial expressions. The progression towards\nmultimodal computational methods in sarcasm detection, however, faces\nchallenges due to the scarcity of data. To address this, we present AMuSeD\n(Attentive deep neural network for MUltimodal Sarcasm dEtection incorporating\nbi-modal Data augmentation). This approach utilizes the Multimodal Sarcasm\nDetection Dataset (MUStARD) and introduces a two-phase bimodal data\naugmentation strategy. The first phase involves generating varied text samples\nthrough Back Translation from several secondary languages. The second phase\ninvolves the refinement of a FastSpeech 2-based speech synthesis system,\ntailored specifically for sarcasm to retain sarcastic intonations. Alongside a\ncloud-based Text-to-Speech (TTS) service, this Fine-tuned FastSpeech 2 system\nproduces corresponding audio for the text augmentations. We also investigate\nvarious attention mechanisms for effectively merging text and audio data,\nfinding self-attention to be the most efficient for bimodal integration. Our\nexperiments reveal that this combined augmentation and attention approach\nachieves a significant F1-score of 81.0% in text-audio modalities, surpassing\neven models that use three modalities from the MUStARD dataset.", "published": "2024-12-13 12:42:51", "link": "http://arxiv.org/abs/2412.10103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MALAMUTE: A Multilingual, Highly-granular, Template-free,\n  Education-based Probing Dataset", "abstract": "Language models (LMs) have excelled in various broad domains. However, to\nensure their safe and effective integration into real-world educational\nsettings, they must demonstrate proficiency in specific, granular areas of\nknowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'\nknowledge, have three major limitations. They: 1) do not cover the educational\ndomain; 2) typically focus on low-complexity, generic knowledge or broad\ndomains, which do not adequately assess the models' knowledge in specific\nsubjects; and 3) often rely on templates that can bias model predictions. Here,\nwe introduce MALAMUTE, a multilingual, template-free, and highly granular\nprobing dataset comprising expert-written, peer-reviewed probes from 71\nuniversity-level textbooks across three languages (English, Spanish, and\nPolish). MALAMUTE is the first education-based cloze-style dataset. It covers\neight domains, each with up to 14 subdomains, further broken down into concepts\nand concept-based prompts, totaling 33,361 university curriculum concepts and\n116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion\nof both sentence-level and paragraph-level prompts make it an ideal tool for\nevaluating LMs' course-related knowledge. Our evaluation of masked and causal\nLMs on MALAMUTE shows that despite overall proficiency, they have significant\ngaps in knowledge when examined closely on specific subjects, hindering their\nsafe use in classrooms and underscoring the need for further development.", "published": "2024-12-13 12:46:33", "link": "http://arxiv.org/abs/2412.10105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by\n  Quantifying Label Shifts in Synthetic Training Data", "abstract": "Zero-shot named entity recognition (NER) is the task of detecting named\nentities of specific types (such as 'Person' or 'Medicine') without any\ntraining examples. Current research increasingly relies on large synthetic\ndatasets, automatically generated to cover tens of thousands of distinct entity\ntypes, to train zero-shot NER models. However, in this paper, we find that\nthese synthetic datasets often contain entity types that are semantically\nhighly similar to (or even the same as) those in standard evaluation\nbenchmarks. Because of this overlap, we argue that reported F1 scores for\nzero-shot NER overestimate the true capabilities of these approaches. Further,\nwe argue that current evaluation setups provide an incomplete picture of\nzero-shot abilities since they do not quantify the label shift (i.e., the\nsimilarity of labels) between training and evaluation datasets. To address\nthese issues, we propose Familiarity, a novel metric that captures both the\nsemantic similarity between entity types in training and evaluation, as well as\ntheir frequency in the training data, to provide an estimate of label shift. It\nallows researchers to contextualize reported zero-shot NER scores when using\ncustom synthetic training datasets. Further, it enables researchers to generate\nevaluation setups of various transfer difficulties for fine-grained analysis of\nzero-shot NER.", "published": "2024-12-13 13:06:58", "link": "http://arxiv.org/abs/2412.10121v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers", "abstract": "As large language models (LLMs) grow in size, traditional full fine-tuning\nbecomes increasingly impractical due to its high computational and storage\ncosts. Although popular parameter-efficient fine-tuning methods, such as LoRA,\nhave significantly reduced the number of tunable parameters, there is still\nroom for further optimization. In this work, we propose ASLoRA, a cross-layer\nparameter-sharing strategy combining global sharing with partial adaptive\nsharing. Specifically, we share the low-rank matrix A across all layers and\nadaptively merge matrix B during training. This sharing mechanism not only\nmitigates overfitting effectively but also captures inter-layer dependencies,\nsignificantly enhancing the model's representational capability. We conduct\nextensive experiments on various NLP tasks, showing that ASLoRA outperforms\nLoRA while using less than 25% of the parameters, highlighting its flexibility\nand superior parameter efficiency. Furthermore, in-depth analyses of the\nadaptive sharing strategy confirm its significant advantages in enhancing both\nmodel flexibility and task adaptability.", "published": "2024-12-13 13:32:13", "link": "http://arxiv.org/abs/2412.10135v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse\n  Analysis with Prompt Engineering", "abstract": "The capacity of LLMs to carry out automated qualitative analysis has been\nquestioned by corpus linguists, and it has been argued that corpus-based\ndiscourse analysis incorporating LLMs is hindered by issues of unsatisfying\nperformance, hallucination, and irreproducibility. Our proposed method,\nTACOMORE, aims to address these concerns by serving as an effective prompting\nframework in this domain. The framework consists of four principles, i.e.,\nTask, Context, Model and Reproducibility, and specifies five fundamental\nelements of a good prompt, i.e., Role Description, Task Definition, Task\nProcedures, Contextual Information and Output Format. We conduct experiments on\nthree LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that\nTACOMORE helps improve LLM performance in three representative discourse\nanalysis tasks, i.e., the analysis of keywords, collocates and concordances,\nbased on an open corpus of COVID-19 research articles. Our findings show the\nefficacy of the proposed prompting framework TACOMORE in corpus-based discourse\nanalysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and\nprovide novel insights into the application and evaluation of LLMs in automated\nqualitative studies.", "published": "2024-12-13 13:41:24", "link": "http://arxiv.org/abs/2412.10139v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Semantic Parsing: Using Large Language Models to\n  Improve Generalization", "abstract": "Open-domain semantic parsing remains a challenging task, as models often rely\non heuristics and struggle to handle unseen concepts. In this paper, we\ninvestigate the potential of large language models (LLMs) for this task and\nintroduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective\napproach that integrates external lexical knowledge into the parsing process.\nOur experiments not only show that LLMs outperform previous encoder-decoder\nbaselines for semantic parsing, but that RASP further enhances their ability to\npredict unseen concepts, nearly doubling the performance of previous models on\nout-of-distribution concepts. These findings highlight the promise of\nleveraging large language models and retrieval mechanisms for robust and\nopen-domain semantic parsing.", "published": "2024-12-13 15:30:20", "link": "http://arxiv.org/abs/2412.10207v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoner Outperforms: Generative Stance Detection with Rationalization\n  for Social Media", "abstract": "Stance detection is crucial for fostering a human-centric Web by analyzing\nuser-generated content to identify biases and harmful narratives that undermine\ntrust. With the development of Large Language Models (LLMs), existing\napproaches treat stance detection as a classification problem, providing robust\nmethodologies for modeling complex group interactions and advancing\ncapabilities in natural language tasks. However, these methods often lack\ninterpretability, limiting their ability to offer transparent and\nunderstandable justifications for predictions. This study adopts a generative\napproach, where stance predictions include explicit, interpretable rationales,\nand integrates them into smaller language models through single-task and\nmultitask learning. We find that incorporating reasoning into stance detection\nenables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot\nperformance, achieving an improvement of up to 9.57%. Moreover, our results\nshow that reasoning capabilities enhance multitask learning performance but may\nreduce effectiveness in single-task settings. Crucially, we demonstrate that\nfaithful rationales improve rationale distillation into SLMs, advancing efforts\nto build interpretable, trustworthy systems for addressing discrimination,\nfostering trust, and promoting equitable engagement on social media.", "published": "2024-12-13 16:34:39", "link": "http://arxiv.org/abs/2412.10266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Linguistic Diversity of Large Language Models", "abstract": "The development and evaluation of Large Language Models (LLMs) has primarily\nfocused on their task-solving capabilities, with recent models even surpassing\nhuman performance in some areas. However, this focus often neglects whether\nmachine-generated language matches the human level of diversity, in terms of\nvocabulary choice, syntactic construction, and expression of meaning, raising\nquestions about whether the fundamentals of language generation have been fully\naddressed. This paper emphasizes the importance of examining the preservation\nof human linguistic richness by language models, given the concerning surge in\nonline content produced or aided by LLMs. We propose a comprehensive framework\nfor evaluating LLMs from various linguistic diversity perspectives including\nlexical, syntactic, and semantic dimensions. Using this framework, we benchmark\nseveral state-of-the-art LLMs across all diversity dimensions, and conduct an\nin-depth case study for syntactic diversity. Finally, we analyze how different\ndevelopment and deployment choices impact the linguistic diversity of LLM\noutputs.", "published": "2024-12-13 16:46:03", "link": "http://arxiv.org/abs/2412.10271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One world, one opinion? The superstar effect in LLM responses", "abstract": "As large language models (LLMs) are shaping the way information is shared and\naccessed online, their opinions have the potential to influence a wide\naudience. This study examines who the LLMs view as the most prominent figures\nacross various fields, using prompts in ten different languages to explore the\ninfluence of linguistic diversity. Our findings reveal low diversity in\nresponses, with a small number of figures dominating recognition across\nlanguages (also known as the \"superstar effect\"). These results highlight the\nrisk of narrowing global knowledge representation when LLMs retrieve subjective\ninformation.", "published": "2024-12-13 17:03:56", "link": "http://arxiv.org/abs/2412.10281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language\n  Models", "abstract": "WHAT-IF -- Writing a Hero's Alternate Timeline through Interactive Fiction --\nis a system that uses zero-shot meta-prompting to create branching narratives\nfrom a prewritten story. Played as an interactive fiction (IF) game, WHAT-IF\nlets the player choose between decisions that the large language model (LLM)\nGPT-4 generates as possible branches in the story. Starting with an existing\nlinear plot as input, a branch is created at each key decision taken by the\nmain character. By meta-prompting the LLM to consider the major plot points\nfrom the story, the system produces coherent and well-structured alternate\nstorylines. WHAT-IF stores the branching plot tree in a graph which helps it to\nboth keep track of the story for prompting and maintain the structure for the\nfinal IF system. A video demo of our system can be found here:\nhttps://youtu.be/8vBqjqtupcc.", "published": "2024-12-13 21:48:54", "link": "http://arxiv.org/abs/2412.10582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-IIN: Semi-supervised Intra-inter modal Interaction Learning Network\n  for Multimodal Sentiment Analysis", "abstract": "Despite multimodal sentiment analysis being a fertile research ground that\nmerits further investigation, current approaches take up high annotation cost\nand suffer from label ambiguity, non-amicable to high-quality labeled data\nacquisition. Furthermore, choosing the right interactions is essential because\nthe significance of intra- or inter-modal interactions can differ among various\nsamples. To this end, we propose Semi-IIN, a Semi-supervised Intra-inter modal\nInteraction learning Network for multimodal sentiment analysis. Semi-IIN\nintegrates masked attention and gating mechanisms, enabling effective dynamic\nselection after independently capturing intra- and inter-modal interactive\ninformation. Combined with the self-training approach, Semi-IIN fully utilizes\nthe knowledge learned from unlabeled data. Experimental results on two public\ndatasets, MOSI and MOSEI, demonstrate the effectiveness of Semi-IIN,\nestablishing a new state-of-the-art on several metrics. Code is available at\nhttps://github.com/flow-ljh/Semi-IIN.", "published": "2024-12-13 01:48:07", "link": "http://arxiv.org/abs/2412.09784v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoPatent: A Multi-Agent Framework for Automatic Patent Generation", "abstract": "As the capabilities of Large Language Models (LLMs) continue to advance, the\nfield of patent processing has garnered increased attention within the natural\nlanguage processing community. However, the majority of research has been\nconcentrated on classification tasks, such as patent categorization and\nexamination, or on short text generation tasks like patent summarization and\npatent quizzes. In this paper, we introduce a novel and practical task known as\nDraft2Patent, along with its corresponding D2P benchmark, which challenges LLMs\nto generate full-length patents averaging 17K tokens based on initial drafts.\nPatents present a significant challenge to LLMs due to their specialized\nnature, standardized terminology, and extensive length. We propose a\nmulti-agent framework called AutoPatent which leverages the LLM-based planner\nagent, writer agents, and examiner agent with PGTree and RRAG to generate\nlengthy, intricate, and high-quality complete patent documents. The\nexperimental results demonstrate that our AutoPatent framework significantly\nenhances the ability to generate comprehensive patents across various LLMs.\nFurthermore, we have discovered that patents generated solely with the\nAutoPatent framework based on the Qwen2.5-7B model outperform those produced by\nlarger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,\nin both objective metrics and human evaluations. We will make the data and code\navailable upon acceptance at \\url{https://github.com/QiYao-Wang/AutoPatent}.", "published": "2024-12-13 02:27:34", "link": "http://arxiv.org/abs/2412.09796v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic\n  LayerReplace and Selective Rank Compression", "abstract": "Offsite-tuning is a privacy-preserving method for tuning large language\nmodels (LLMs) by sharing a lossy compressed emulator from the LLM owners with\ndata owners for downstream task tuning. This approach protects the privacy of\nboth the model and data owners. However, current offsite tuning methods often\nsuffer from adaptation degradation, high computational costs, and limited\nprotection strength due to uniformly dropping LLM layers or relying on\nexpensive knowledge distillation. To address these issues, we propose ScaleOT,\na novel privacy-utility-scalable offsite-tuning framework that effectively\nbalances privacy and utility. ScaleOT introduces a novel layerwise lossy\ncompression algorithm that uses reinforcement learning to obtain the importance\nof each layer. It employs lightweight networks, termed harmonizers, to replace\nthe raw LLM layers. By combining important original LLM layers and harmonizers\nin different ratios, ScaleOT generates emulators tailored for optimal\nperformance with various model scales for enhanced privacy protection.\nAdditionally, we present a rank reduction method to further compress the\noriginal LLM layers, significantly enhancing privacy with negligible impact on\nutility. Comprehensive experiments show that ScaleOT can achieve nearly\nlossless offsite tuning performance compared with full fine-tuning while\nobtaining better model privacy.", "published": "2024-12-13 03:00:48", "link": "http://arxiv.org/abs/2412.09812v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Enhancing Multimodal Large Language Models Complex Reason via Similarity\n  Computation", "abstract": "Multimodal large language models have experienced rapid growth, and numerous\ndifferent models have emerged. The interpretability of LVLMs remains an\nunder-explored area. Especially when faced with more complex tasks such as\nchain-of-thought reasoning, its internal mechanisms still resemble a black box\nthat is difficult to decipher. By studying the interaction and information flow\nbetween images and text, we noticed that in models such as LLaVA1.5, image\ntokens that are semantically related to text are more likely to have\ninformation flow convergence in the LLM decoding layer, and these image tokens\nreceive higher attention scores. However, those image tokens that are less\nrelevant to the text do not have information flow convergence, and they only\nget very small attention scores. To efficiently utilize the image information,\nwe propose a new image token reduction method, Simignore, which aims to improve\nthe complex reasoning ability of LVLMs by computing the similarity between\nimage and text embeddings and ignoring image tokens that are irrelevant and\nunimportant to the text. Through extensive experiments, we demonstrate the\neffectiveness of our method for complex reasoning tasks. The paper's source\ncode can be accessed from \\url{https://github.com/FanshuoZeng/Simignore}.", "published": "2024-12-13 03:13:44", "link": "http://arxiv.org/abs/2412.09817v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MERaLiON-AudioLLM: Bridging Audio and Language with Large Language\n  Models", "abstract": "We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning\nin One Network), the first speech-text model tailored for Singapore's\nmultilingual and multicultural landscape. Developed under the National Large\nLanguage Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates\nadvanced speech and text processing to address the diverse linguistic nuances\nof local accents and dialects, enhancing accessibility and usability in\ncomplex, multilingual environments. Our results demonstrate improvements in\nboth speech recognition and task-specific understanding, positioning\nMERaLiON-AudioLLM as a pioneering solution for region specific AI applications.\nWe envision this release to set a precedent for future models designed to\naddress localised linguistic and cultural contexts in a global framework.", "published": "2024-12-13 03:15:05", "link": "http://arxiv.org/abs/2412.09818v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for\n  Fine-tuning Language Models", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. LoRA is one of the most\nwidely used methods, which assumes that the optimization process is essentially\nlow dimensional. Although LoRA has demonstrated commendable performance, there\nremains a significant performance gap between LoRA and full fine-tuning when\nlearning new tasks. In this work, we propose Low-Rank Adaptation with\nTask-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features\nfrom the perspective of editing neural network representations. To prioritize\ntask-relevant features, a task-aware filter that selectively extracts valuable\nknowledge from hidden representations for the target or current task is\ndesigned. As the experiments on a vareity of datasets including NLU,\ncommonsense reasoning and mathematical reasoning tasks demonstrates, our method\nreduces 33.71% parameters and achieves better performance on a variety of\ndatasets in comparison with SOTA low-rank methods.", "published": "2024-12-13 03:38:49", "link": "http://arxiv.org/abs/2412.09827v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for\n  Supervised Fine-tuning", "abstract": "The Efficient Market Hypothesis (EMH) highlights the essence of financial\nnews in stock price movement. Financial news comes in the form of corporate\nannouncements, news titles, and other forms of digital text. The generation of\ninsights from financial news can be done with sentiment analysis.\nGeneral-purpose language models are too general for sentiment analysis in\nfinance. Curated labeled data for fine-tuning general-purpose language models\nare scare, and existing fine-tuned models for sentiment analysis in finance do\nnot capture the maximum context width. We hypothesize that using actual and\nsynthetic data can improve performance. We introduce BertNSP-finance to\nconcatenate shorter financial sentences into longer financial sentences, and\nfinbert-lc to determine sentiment from digital text. The results show improved\nperformance on the accuracy and the f1 score for the financial phrasebank data\nwith $50\\%$ and $100\\%$ agreement levels.", "published": "2024-12-13 04:59:50", "link": "http://arxiv.org/abs/2412.09859v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Human-Like Embodied AI Interviewer: Employing Android ERICA in Real\n  International Conference", "abstract": "This paper introduces the human-like embodied AI interviewer which integrates\nandroid robots equipped with advanced conversational capabilities, including\nattentive listening, conversational repairs, and user fluency adaptation.\nMoreover, it can analyze and present results post-interview. We conducted a\nreal-world case study at SIGDIAL 2024 with 42 participants, of whom 69%\nreported positive experiences. This study demonstrated the system's\neffectiveness in conducting interviews just like a human and marked the first\nemployment of such a system at an international conference. The demonstration\nvideo is available at https://youtu.be/jCuw9g99KuE.", "published": "2024-12-13 05:19:49", "link": "http://arxiv.org/abs/2412.09867v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Analyzing Fairness of Computer Vision and Natural Language Processing\n  Models", "abstract": "Machine learning (ML) algorithms play a crucial role in decision making\nacross diverse fields such as healthcare, finance, education, and law\nenforcement. Despite their widespread adoption, these systems raise ethical and\nsocial concerns due to potential biases and fairness issues. This study focuses\non evaluating and improving the fairness of Computer Vision and Natural\nLanguage Processing (NLP) models applied to unstructured datasets, emphasizing\nhow biased predictions can reinforce existing systemic inequalities. A publicly\navailable dataset from Kaggle was utilized to simulate a practical scenario for\nexamining fairness in ML workflows. To address and mitigate biases, the study\nemployed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by\nIBM. These tools offer comprehensive frameworks for fairness analysis,\nincluding metrics evaluation, result visualization, and bias mitigation\ntechniques. The research aims to measure bias levels in ML models, compare the\neffectiveness of these fairness libraries, and provide actionable\nrecommendations for practitioners. The results demonstrate that each library\npossesses distinct strengths and limitations in evaluating and mitigating\nfairness. By systematically analyzing these tools, the study contributes\nvaluable insights to the growing field of ML fairness, offering practical\nguidance for integrating fairness solutions into real world applications. This\nresearch underscores the importance of building more equitable and responsible\nmachine learning systems.", "published": "2024-12-13 06:35:55", "link": "http://arxiv.org/abs/2412.09900v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Nursing and Elderly Care with Large Language Models: An\n  AI-Driven Framework", "abstract": "This paper explores the application of large language models (LLMs) in\nnursing and elderly care, focusing on AI-driven patient monitoring and\ninteraction. We introduce a novel Chinese nursing dataset and implement\nincremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to\nenhance LLM performance in specialized tasks. Using LangChain, we develop a\ndynamic nursing assistant capable of real-time care and personalized\ninterventions. Experimental results demonstrate significant improvements,\npaving the way for AI-driven solutions to meet the growing demands of\nhealthcare in aging populations.", "published": "2024-12-13 08:10:56", "link": "http://arxiv.org/abs/2412.09946v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Small Language Model as Data Prospector for Large Language Model", "abstract": "The quality of instruction data directly affects the performance of\nfine-tuned Large Language Models (LLMs). Previously, \\cite{li2023one} proposed\n\\texttt{NUGGETS}, which identifies and selects high-quality quality data from a\nlarge dataset by identifying those individual instruction examples that can\nsignificantly improve the performance of different tasks after being learnt as\none-shot instances. In this work, we propose \\texttt{SuperNUGGETS}, an improved\nvariant of \\texttt{NUGGETS} optimised for efficiency and performance. Our\n\\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large\nlanguage model (LLM) to filter the data for outstanding one-shot instances and\nrefines the predefined set of tests. The experimental results show that the\nperformance of \\texttt{SuperNUGGETS} only decreases by 1-2% compared to\n\\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.\nCompared to the original \\texttt{NUGGETS}, our \\texttt{SuperNUGGETS} has a\nhigher utility value due to the significantly lower resource consumption.", "published": "2024-12-13 09:23:58", "link": "http://arxiv.org/abs/2412.09990v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?", "abstract": "Large Language Models (LLMs) are commonly evaluated using human-crafted\nbenchmarks, under the premise that higher scores implicitly reflect stronger\nhuman-like performance. However, there is growing concern that LLMs may ``game\"\nthese benchmarks due to data leakage, achieving high scores while struggling\nwith tasks simple for humans. To substantively address the problem, we create\nGAOKAO-Eval, a comprehensive benchmark based on China's National College\nEntrance Examination (Gaokao), and conduct ``closed-book\" evaluations for\nrepresentative models released prior to Gaokao. Contrary to prevailing\nconsensus, even after addressing data leakage and comprehensiveness,\nGAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned\ncapabilities. To better understand this mismatch, We introduce the Rasch model\nfrom cognitive psychology to analyze LLM scoring patterns and identify two key\ndiscrepancies: 1) anomalous consistent performance across various question\ndifficulties, and 2) high variance in performance on questions of similar\ndifficulty. In addition, We identified inconsistent grading of LLM-generated\nanswers among teachers and recurring mistake patterns. we find that the\nphenomenons are well-grounded in the motivations behind OpenAI o1, and o1's\nreasoning-as-difficulties can mitigate the mismatch. These results show that\nGAOKAO-Eval can reveal limitations in LLM capabilities not captured by current\nbenchmarks and highlight the need for more LLM-aligned difficulty analysis.", "published": "2024-12-13 11:38:10", "link": "http://arxiv.org/abs/2412.10056v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for\n  Real Estate Sector", "abstract": "The real estate market relies heavily on structured data, such as property\ndetails, market trends, and price fluctuations. However, the lack of\nspecialized Tabular Question Answering datasets in this domain limits the\ndevelopment of automated question-answering systems. To fill this gap, we\nintroduce RETQA, the first large-scale open-domain Chinese Tabular Question\nAnswering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762\nquestion-answer pairs across 16 sub-fields within three major domains: property\ninformation, real estate company finance information and land auction\ninformation. Compared with existing tabular question answering datasets, RETQA\nposes greater challenges due to three key factors: long-table structures,\nopen-domain retrieval, and multi-domain queries. To tackle these challenges, we\npropose the SLUTQA framework, which integrates large language models with\nspoken language understanding tasks to enhance retrieval and answering\naccuracy. Extensive experiments demonstrate that SLUTQA significantly improves\nthe performance of large language models on RETQA by in-context learning. RETQA\nand SLUTQA provide essential resources for advancing tabular question answering\nresearch in the real estate domain, addressing critical challenges in\nopen-domain and long-table question-answering. The dataset and code are\npublicly available at \\url{https://github.com/jensen-w/RETQA}.", "published": "2024-12-13 12:45:14", "link": "http://arxiv.org/abs/2412.10104v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Label-template based Few-Shot Text Classification with Contrastive\n  Learning", "abstract": "As an algorithmic framework for learning to learn, meta-learning provides a\npromising solution for few-shot text classification. However, most existing\nresearch fail to give enough attention to class labels. Traditional basic\nframework building meta-learner based on prototype networks heavily relies on\ninter-class variance, and it is easily influenced by noise. To address these\nlimitations, we proposes a simple and effective few-shot text classification\nframework. In particular, the corresponding label templates are embed into\ninput sentences to fully utilize the potential value of class labels, guiding\nthe pre-trained model to generate more discriminative text representations\nthrough the semantic information conveyed by labels. With the continuous\ninfluence of label semantics, supervised contrastive learning is utilized to\nmodel the interaction information between support samples and query samples.\nFurthermore, the averaging mechanism is replaced with an attention mechanism to\nhighlight vital semantic information. To verify the proposed scheme, four\ntypical datasets are employed to assess the performance of different methods.\nExperimental results demonstrate that our method achieves substantial\nperformance enhancements and outperforms existing state-of-the-art models on\nfew-shot text classification tasks.", "published": "2024-12-13 12:51:50", "link": "http://arxiv.org/abs/2412.10110v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL", "abstract": "Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by\nlarge language models (LLMs), the latest state-of-the-art techniques are still\ntrapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which\nlimits their applicability in open scenarios. To address this challenge, we\npropose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to\nimprove the comprehensive capabilities of open-source LLMs for Text2SQL,\nthereby providing a more practical solution. Our approach begins with\nmulti-task supervised fine-tuning (SFT) using various synthetic training data\nrelated to SQL generation. Unlike existing SFT-based Text2SQL methods, we\nintroduced several additional SFT tasks, including schema linking, noise\ncorrection, and continuation writing. Engaging in a variety of SQL generation\ntasks enhances the model's understanding of SQL syntax and improves its ability\nto generate high-quality SQL queries. Additionally, inspired by the\ncollaborative modes of LLM agents, we introduce a Multitask Collaboration\nPrompting (MCP) strategy. This strategy leverages collaboration across several\nSQL-related tasks to reduce hallucinations during SQL generation, thereby\nmaximizing the potential of enhancing Text2SQL performance through explicit\nmultitask capabilities. Extensive experiments and in-depth analyses have been\nperformed on eight open-source LLMs and five widely-used benchmarks. The\nresults demonstrate that our proposal outperforms the latest Text2SQL methods\nand yields leading performance.", "published": "2024-12-13 13:41:18", "link": "http://arxiv.org/abs/2412.10138v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How good is my story? Towards quantitative metrics for evaluating\n  LLM-generated XAI narratives", "abstract": "A rapidly developing application of LLMs in XAI is to convert quantitative\nexplanations such as SHAP into user-friendly narratives to explain the\ndecisions made by smaller prediction models. Evaluating the narratives without\nrelying on human preference studies or surveys is becoming increasingly\nimportant in this field. In this work we propose a framework and explore\nseveral automated metrics to evaluate LLM-generated narratives for explanations\nof tabular classification tasks. We apply our approach to compare several\nstate-of-the-art LLMs across different datasets and prompt types. As a\ndemonstration of their utility, these metrics allow us to identify new\nchallenges related to LLM hallucinations for XAI narratives.", "published": "2024-12-13 15:45:45", "link": "http://arxiv.org/abs/2412.10220v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Continual Pre-training of LLMs for Low-resource Languages", "abstract": "Open-source Large Language models (OsLLMs) propel the democratization of\nnatural language research by giving the flexibility to augment or update model\nparameters for performance improvement. Nevertheless, like proprietary LLMs,\nOs-LLMs offer poorer performance on low-resource languages (LRLs) than\nhigh-resource languages (HRLs), owing to smaller amounts of training data and\nunderrepresented vocabulary. On the other hand, continual pre-training (CPT)\nwith large amounts of language-specific data is a costly proposition in terms\nof data acquisition and computational resources. Our goal is to drastically\nreduce CPT cost. To that end, we first develop a new algorithm to select a\nsubset of texts from a larger corpus. We show the effectiveness of our\ntechnique using very little CPT data. In search of further improvement, we\ndesign a new algorithm to select tokens to include in the LLM vocabulary. We\nexperiment with the recent Llama-3 model and nine Indian languages with diverse\nscripts and extent of resource availability. For evaluation, we use\nIndicGenBench, a generation task benchmark dataset for Indic languages. We\nexperiment with various CPT corpora and augmented vocabulary size and offer\ninsights across language families.", "published": "2024-12-13 16:13:35", "link": "http://arxiv.org/abs/2412.10244v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in\n  Large Language Models", "abstract": "The sheer scale of data required to train modern large language models (LLMs)\nposes significant risks, as models are likely to gain knowledge of sensitive\ntopics such as bio-security, as well the ability to replicate copyrighted\nworks. Methods designed to remove such knowledge must do so from all prompt\ndirections, in a multi-lingual capacity and without degrading general model\nperformance. To this end, we introduce the targeted angular reversal (TARS)\nmethod of knowledge removal from LLMs. The TARS method firstly leverages the\nLLM in combination with a detailed prompt to aggregate information about a\nselected concept in the internal representation space of the LLM. It then\nrefines this approximate concept vector to trigger the concept token with high\nprobability, by perturbing the approximate concept vector with noise and\ntransforming it into token scores with the language model head. The feedforward\nweight vectors in the LLM which operate directly on the internal representation\nspace, and have the highest cosine similarity with this targeting vector, are\nthen replaced by a reversed targeting vector, thus limiting the ability of the\nconcept to propagate through the model. The modularity of the TARS method\nallows for a sequential removal of concepts from Llama 3.1 8B, such as the\nfamous literary detective Sherlock Holmes, and the planet Saturn. It is\ndemonstrated that the probability of triggering target concepts can be reduced\nto 0.00 with as few as 1 TARS edit, whilst simultaneously removing the\nknowledge bi-directionally. Moreover, knowledge is shown to be removed across\nall languages despite only being targeted in English. Importantly, TARS has\nminimal impact on the general model capabilities, as after removing 5 diverse\nconcepts in a modular fashion, there is minimal KL divergence in the next token\nprobabilities of the LLM on large corpora of Wikipedia text (median of 0.0015).", "published": "2024-12-13 16:26:34", "link": "http://arxiv.org/abs/2412.10257v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SCBench: A KV Cache-Centric Analysis of Long-Context Methods", "abstract": "Long-context LLMs have enabled numerous downstream applications but also\nintroduced significant challenges related to computational and memory\nefficiency. To address these challenges, optimizations for long-context\ninference have been developed, centered around the KV cache. However, existing\nbenchmarks often evaluate in single-request, neglecting the full lifecycle of\nthe KV cache in real-world use. This oversight is particularly critical, as KV\ncache reuse has become widely adopted in LLMs inference frameworks, such as\nvLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,\nGoogle, and Anthropic. To address this gap, we introduce\nSCBench(SharedContextBench), a comprehensive benchmark for evaluating\nlong-context methods from a KV cachecentric perspective: 1) KV cache\ngeneration, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache\nloading. Specifically, SCBench uses test examples with shared context, ranging\n12 tasks with two shared context modes, covering four categories of\nlong-context capabilities: string retrieval, semantic retrieval, global\ninformation, and multi-task. With it, we provide an extensive KV cache-centric\nanalysis of eight categories long-context solutions, including Gated Linear\nRNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,\nKV cache dropping, quantization, retrieval, loading, and prompt compression.\nThe evaluation is conducted on 8 long-context LLMs. Our findings show that\nsub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding\nwith O(n) memory and sub-O(n^2) pre-filling computation perform robustly.\nDynamic sparsity yields more expressive KV caches than static patterns, and\nlayer-level sparsity in hybrid architectures reduces memory usage with strong\nperformance. Additionally, we identify attention distribution shift issues in\nlong-generation scenarios. https://aka.ms/SCBench.", "published": "2024-12-13 17:59:52", "link": "http://arxiv.org/abs/2412.10319v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Grounded Typology of Word Classes", "abstract": "We propose a grounded approach to meaning in language typology. We treat data\nfrom perceptual modalities, such as images, as a language-agnostic\nrepresentation of meaning. Hence, we can quantify the function--form\nrelationship between images and captions across languages. Inspired by\ninformation theory, we define \"groundedness\", an empirical measure of\ncontextual semantic contentfulness (formulated as a difference in surprisal)\nwhich can be computed with multilingual multimodal language models. As a proof\nof concept, we apply this measure to the typology of word classes. Our measure\ncaptures the contentfulness asymmetry between functional (grammatical) and\nlexical (content) classes across languages, but contradicts the view that\nfunctional classes do not convey content. Moreover, we find universal trends in\nthe hierarchy of groundedness (e.g., nouns > adjectives > verbs), and show that\nour measure partly correlates with psycholinguistic concreteness norms in\nEnglish. We release a dataset of groundedness scores for 30 languages. Our\nresults suggest that the grounded typology approach can provide quantitative\nevidence about semantic function in language.", "published": "2024-12-13 18:58:48", "link": "http://arxiv.org/abs/2412.10369v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts", "abstract": "The proliferation of disinformation demands reliable and scalable\nfact-checking solutions. We present Dynamic Evidence-based FAct-checking with\nMultimodal Experts (DEFAME), a modular, zero-shot MLLM pipeline for\nopen-domain, text-image claim verification. DEFAME operates in a six-stage\nprocess, dynamically selecting the tools and search depth to extract and\nevaluate textual and visual evidence. Unlike prior approaches that are\ntext-only, lack explainability, or rely solely on parametric knowledge, DEFAME\nperforms end-to-end verification, accounting for images in claims and evidence\nwhile generating structured, multimodal reports. Evaluation on the popular\nbenchmarks VERITE, AVerITeC, and MOCHEG shows that DEFAME surpasses all\nprevious methods, establishing itself as the new state-of-the-art fact-checking\nsystem for uni- and multimodal fact-checking. Moreover, we introduce a new\nbenchmark, CLAIMREVIEW24+, featuring claims after the knowledge cutoff of GPT4o\nto avoid data leakage. Here, DEFAME drastically outperforms the GPT\nChain-of-Thought baseline, demonstrating temporal generalizability and the\npotential for real-time fact-checking.", "published": "2024-12-13 19:11:18", "link": "http://arxiv.org/abs/2412.10510v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Solving the Inverse Alignment Problem for Efficient RLHF", "abstract": "Collecting high-quality preference datasets for reinforcement learning from\nhuman feedback (RLHF) is resource-intensive and challenging. As a result,\nresearchers often train reward models on extensive offline datasets which\naggregate diverse generation sources and scoring/alignment policies. We\nhypothesize that this aggregation has an averaging effect on reward model\nscores, which limits signal and impairs the alignment process. Inspired by the\nfield of inverse RL, we define the 'inverse alignment problem' in language\nmodel training, where our objective is to optimize the critic's reward for a\nfixed actor and a fixed offline preference dataset. We hypothesize that solving\nthe inverse alignment problem will improve reward model quality by providing\nclearer feedback on the policy's current behavior. To that end, we investigate\nwhether repeatedly fine-tuning a reward model on subsets of the offline\npreference dataset aligned with a periodically frozen policy during RLHF\nimproves upon vanilla RLHF. Our empirical results demonstrate that this\napproach facilitates superior alignment and faster convergence compared to\nusing an unaligned or out-of-distribution reward model relative to the LLM\npolicy.", "published": "2024-12-13 19:47:38", "link": "http://arxiv.org/abs/2412.10529v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On Adversarial Robustness and Out-of-Distribution Robustness of Large\n  Language Models", "abstract": "The increasing reliance on large language models (LLMs) for diverse\napplications necessitates a thorough understanding of their robustness to\nadversarial perturbations and out-of-distribution (OOD) inputs. In this study,\nwe investigate the correlation between adversarial robustness and OOD\nrobustness in LLMs, addressing a critical gap in robustness evaluation. By\napplying methods originally designed to improve one robustness type across both\ncontexts, we analyze their performance on adversarial and out-of-distribution\nbenchmark datasets. The input of the model consists of text samples, with the\noutput prediction evaluated in terms of accuracy, precision, recall, and F1\nscores in various natural language inference tasks.\n  Our findings highlight nuanced interactions between adversarial robustness\nand OOD robustness, with results indicating limited transferability between the\ntwo robustness types. Through targeted ablations, we evaluate how these\ncorrelations evolve with different model sizes and architectures, uncovering\nmodel-specific trends: smaller models like LLaMA2-7b exhibit neutral\ncorrelations, larger models like LLaMA2-13b show negative correlations, and\nMixtral demonstrates positive correlations, potentially due to domain-specific\nalignment. These results underscore the importance of hybrid robustness\nframeworks that integrate adversarial and OOD strategies tailored to specific\nmodels and domains. Further research is needed to evaluate these interactions\nacross larger models and varied architectures, offering a pathway to more\nreliable and generalizable LLMs.", "published": "2024-12-13 20:04:25", "link": "http://arxiv.org/abs/2412.10535v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evidence Contextualization and Counterfactual Attribution for\n  Conversational QA over Heterogeneous Data with RAG Systems", "abstract": "Retrieval Augmented Generation (RAG) works as a backbone for interacting with\nan enterprise's own data via Conversational Question Answering (ConvQA). In a\nRAG system, a retriever fetches passages from a collection in response to a\nquestion, which are then included in the prompt of a large language model (LLM)\nfor generating a natural language (NL) answer. However, several RAG systems\ntoday suffer from two shortcomings: (i) retrieved passages usually contain\ntheir raw text and lack appropriate document context, negatively impacting both\nretrieval and answering quality; and (ii) attribution strategies that explain\nanswer generation typically rely only on similarity between the answer and the\nretrieved passages, thereby only generating plausible but not causal\nexplanations. In this work, we demonstrate RAGONITE, a RAG system that remedies\nthe above concerns by: (i) contextualizing evidence with source metadata and\nsurrounding text; and (ii) computing counterfactual attribution, a causal\nexplanation approach where the contribution of an evidence to an answer is\ndetermined by the similarity of the original response to the answer obtained by\nremoving that evidence. To evaluate our proposals, we release a new benchmark\nConfQuestions: it has 300 hand-created conversational questions, each in\nEnglish and German, coupled with ground truth URLs, completed questions, and\nanswers from 215 public Confluence pages. These documents are typical of\nenterprise wiki spaces with heterogeneous elements. Experiments with RAGONITE\non ConfQuestions show the viability of our ideas: contextualization improves\nRAG performance, and counterfactual explanations outperform standard\nattribution.", "published": "2024-12-13 21:28:17", "link": "http://arxiv.org/abs/2412.10571v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BinarySelect to Improve Accessibility of Black-Box Attack Research", "abstract": "Adversarial text attack research is useful for testing the robustness of NLP\nmodels, however, the rise of transformers has greatly increased the time\nrequired to test attacks. Especially when researchers do not have access to\nadequate resources (e.g. GPUs). This can hinder attack research, as modifying\none example for an attack can require hundreds of queries to a model,\nespecially for black-box attacks. Often these attacks remove one token at a\ntime to find the ideal one to change, requiring $n$ queries (the length of the\ntext) right away. We propose a more efficient selection method called\nBinarySelect which combines binary search and attack selection methods to\ngreatly reduce the number of queries needed to find a token. We find that\nBinarySelect only needs $\\text{log}_2(n) * 2$ queries to find the first token\ncompared to $n$ queries. We also test BinarySelect in an attack setting against\n5 classifiers across 3 datasets and find a viable tradeoff between number of\nqueries saved and attack effectiveness. For example, on the Yelp dataset, the\nnumber of queries is reduced by 32% (72 less) with a drop in attack\neffectiveness of only 5 points. We believe that BinarySelect can help future\nresearchers study adversarial attacks and black-box problems more efficiently\nand opens the door for researchers with access to less resources.", "published": "2024-12-13 23:42:30", "link": "http://arxiv.org/abs/2412.10617v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Script-Based Dialog Policy Planning for LLM-Powered Conversational\n  Agents: A Basic Architecture for an \"AI Therapist\"", "abstract": "Large Language Model (LLM)-Powered Conversational Agents have the potential\nto provide users with scaled behavioral healthcare support, and potentially\neven deliver full-scale \"AI therapy'\" in the future. While such agents can\nalready conduct fluent and proactive emotional support conversations, they\ninherently lack the ability to (a) consistently and reliably act by predefined\nrules to align their conversation with an overarching therapeutic concept and\n(b) make their decision paths inspectable for risk management and clinical\nevaluation -- both essential requirements for an \"AI Therapist\".\n  In this work, we introduce a novel paradigm for dialog policy planning in\nconversational agents enabling them to (a) act according to an expert-written\n\"script\" that outlines the therapeutic approach and (b) explicitly transition\nthrough a finite set of states over the course of the conversation. The script\nacts as a deterministic component, constraining the LLM's behavior in desirable\nways and establishing a basic architecture for an AI Therapist.\n  We implement two variants of Script-Based Dialog Policy Planning using\ndifferent prompting techniques and synthesize a total of 100 conversations with\nLLM-simulated patients. The results demonstrate the feasibility of this new\ntechnology and provide insights into the efficiency and effectiveness of\ndifferent implementation variants.", "published": "2024-12-13 12:12:47", "link": "http://arxiv.org/abs/2412.15242v1", "categories": ["cs.CL", "cs.AI", "68T01"], "primary_category": "cs.CL"}
{"title": "Exploring Text Representations for Online Misinformation", "abstract": "Mis- and disinformation, commonly collectively called fake news, continue to\nmenace society. Perhaps, the impact of this age-old problem is presently most\nplain in politics and healthcare. However, fake news is affecting an increasing\nnumber of domains. It takes many different forms and continues to shapeshift as\ntechnology advances. Though it arguably most widely spreads in textual form,\ne.g., through social media posts and blog articles. Thus, it is imperative to\nthwart the spread of textual misinformation, which necessitates its initial\ndetection. This thesis contributes to the creation of representations that are\nuseful for detecting misinformation. Firstly, it develops a novel method for\nextracting textual features from news articles for misinformation detection.\nThese features harness the disparity between the thematic coherence of\nauthentic and false news stories. In other words, the composition of themes\ndiscussed in both groups significantly differs as the story progresses.\nSecondly, it demonstrates the effectiveness of topic features for fake news\ndetection, using classification and clustering. Clustering is particularly\nuseful because it alleviates the need for a labelled dataset, which can be\nlabour-intensive and time-consuming to amass. More generally, it contributes\ntowards a better understanding of misinformation and ways of detecting it using\nMachine Learning and Natural Language Processing.", "published": "2024-12-13 20:22:36", "link": "http://arxiv.org/abs/2412.18618v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Simulating Hard Attention Using Soft Attention", "abstract": "We study conditions under which transformers using soft attention can\nsimulate hard attention, that is, effectively focus all attention on a subset\nof positions. First, we examine several variants of linear temporal logic,\nwhose formulas have been previously been shown to be computable using hard\nattention transformers. We demonstrate how soft attention transformers can\ncompute formulas of these logics using unbounded positional embeddings or\ntemperature scaling. Second, we demonstrate how temperature scaling allows\nsoftmax transformers to simulate a large subclass of average-hard attention\ntransformers, those that have what we call the uniform-tieless property.", "published": "2024-12-13 07:27:42", "link": "http://arxiv.org/abs/2412.09925v1", "categories": ["cs.LG", "cs.CL", "cs.FL"], "primary_category": "cs.LG"}
{"title": "HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language\n  Transfer and Automatic Data Annotation", "abstract": "In this paper we present our submission for the NorSID Shared Task as part of\nthe 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:\nIntent Detection, Slot Filling and Dialect Identification, evaluated using data\nin different dialects of the Norwegian language. For Intent Detection and Slot\nFilling, we have fine-tuned a multitask model in a cross-lingual setting, to\nleverage the xSID dataset available in 17 languages. In the case of Dialect\nIdentification, our final submission consists of a model fine-tuned on the\nprovided development set, which has obtained the highest scores within our\nexperiments. Our final results on the test set show that our models do not drop\nin performance compared to the development set, likely due to the\ndomain-specificity of the dataset and the similar distribution of both subsets.\nFinally, we also report an in-depth analysis of the provided datasets and their\nartifacts, as well as other sets of experiments that have been carried out but\ndid not yield the best results. Additionally, we present an analysis on the\nreasons why some methods have been more successful than others; mainly the\nimpact of the combination of languages and domain-specificity of the training\ndata on the results.", "published": "2024-12-13 12:31:06", "link": "http://arxiv.org/abs/2412.10095v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can LLMs Convert Graphs to Text-Attributed Graphs?", "abstract": "Graphs are ubiquitous structures found in numerous real-world applications,\nsuch as drug discovery, recommender systems, and social network analysis. To\nmodel graph-structured data, graph neural networks (GNNs) have become a popular\ntool. However, existing GNN architectures encounter challenges in cross-graph\nlearning where multiple graphs have different feature spaces. To address this,\nrecent approaches introduce text-attributed graphs (TAGs), where each node is\nassociated with a textual description, which can be projected into a unified\nfeature space using textual encoders. While promising, this method relies\nheavily on the availability of text-attributed graph data, which is difficult\nto obtain in practice. To bridge this gap, we propose a novel method named\nTopology-Aware Node description Synthesis (TANS), leveraging large language\nmodels (LLMs) to convert existing graphs into text-attributed graphs. The key\nidea is to integrate topological information into LLMs to explain how graph\ntopology influences node semantics. We evaluate our TANS on text-rich,\ntext-limited, and text-free graphs, demonstrating its applicability. Notably,\non text-free graphs, our method significantly outperforms existing approaches\nthat manually design node features, showcasing the potential of LLMs for\npreprocessing graph-structured data in the absence of textual information. The\ncode and data are available at https://github.com/Zehong-Wang/TANS.", "published": "2024-12-13 13:32:59", "link": "http://arxiv.org/abs/2412.10136v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval\n  Augmented Generation", "abstract": "We propose the VLR-Bench, a visual question answering (VQA) benchmark for\nevaluating vision language models (VLMs) based on retrieval augmented\ngeneration (RAG). Unlike existing evaluation datasets for external\nknowledge-based VQA, the proposed VLR-Bench includes five input passages. This\nallows testing of the ability to determine which passage is useful for\nanswering a given query, a capability lacking in previous research. In this\ncontext, we constructed a dataset of 32,000 automatically generated\ninstruction-following examples, which we denote as VLR-IF. This dataset is\nspecifically designed to enhance the RAG capabilities of VLMs by enabling them\nto learn how to generate appropriate answers based on input passages. We\nevaluated the validity of the proposed benchmark and training data and verified\nits performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3\nmodel. The proposed VLR-Bench and VLR-IF datasets are publicly available\nonline.", "published": "2024-12-13 14:11:26", "link": "http://arxiv.org/abs/2412.10151v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Still \"Talking About Large Language Models\": Some Clarifications", "abstract": "My paper \"Talking About Large Language Models\" has more than once been\ninterpreted as advocating a reductionist stance towards large language models.\nBut the paper was not intended that way, and I do not endorse such positions.\nThis short note situates the paper in the context of a larger philosophical\nproject that is concerned with the (mis)use of words rather than metaphysics,\nin the spirit of Wittgenstein's later writing.", "published": "2024-12-13 17:21:29", "link": "http://arxiv.org/abs/2412.10291v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced\n  Multimodal Understanding", "abstract": "We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)\nVision-Language Models that significantly improves upon its predecessor,\nDeepSeek-VL, through two key major upgrades. For the vision component, we\nincorporate a dynamic tiling vision encoding strategy designed for processing\nhigh-resolution images with different aspect ratios. For the language\ncomponent, we leverage DeepSeekMoE models with the Multi-head Latent Attention\nmechanism, which compresses Key-Value cache into latent vectors, to enable\nefficient inference and high throughput. Trained on an improved vision-language\ndataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,\nincluding but not limited to visual question answering, optical character\nrecognition, document/table/chart understanding, and visual grounding. Our\nmodel series is composed of three variants: DeepSeek-VL2-Tiny,\nDeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated\nparameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art\nperformance with similar or fewer activated parameters compared to existing\nopen-source dense and MoE-based models. Codes and pre-trained models are\npublicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.", "published": "2024-12-13 17:37:48", "link": "http://arxiv.org/abs/2412.10302v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Interlocking-free Selective Rationalization Through Genetic-based\n  Learning", "abstract": "A popular end-to-end architecture for selective rationalization is the\nselect-then-predict pipeline, comprising a generator to extract highlights fed\nto a predictor. Such a cooperative system suffers from suboptimal equilibrium\nminima due to the dominance of one of the two modules, a phenomenon known as\ninterlocking. While several contributions aimed at addressing interlocking,\nthey only mitigate its effect, often by introducing feature-based heuristics,\nsampling, and ad-hoc regularizations. We present GenSPP, the first\ninterlocking-free architecture for selective rationalization that does not\nrequire any learning overhead, as the above-mentioned. GenSPP avoids\ninterlocking by performing disjoint training of the generator and predictor via\ngenetic global search. Experiments on a synthetic and a real-world benchmark\nshow that our model outperforms several state-of-the-art competitors.", "published": "2024-12-13 17:52:48", "link": "http://arxiv.org/abs/2412.10312v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "AdvPrefix: An Objective for Nuanced LLM Jailbreaks", "abstract": "Many jailbreak attacks on large language models (LLMs) rely on a common\nobjective: making the model respond with the prefix \"Sure, here is (harmful\nrequest)\". While straightforward, this objective has two limitations: limited\ncontrol over model behaviors, often resulting in incomplete or unrealistic\nresponses, and a rigid format that hinders optimization. To address these\nlimitations, we introduce AdvPrefix, a new prefix-forcing objective that\nenables more nuanced control over model behavior while being easy to optimize.\nOur objective leverages model-dependent prefixes, automatically selected based\non two criteria: high prefilling attack success rates and low negative\nlog-likelihood. It can further simplify optimization by using multiple prefixes\nfor a single user request. AdvPrefix can integrate seamlessly into existing\njailbreak attacks to improve their performance for free. For example, simply\nreplacing GCG attack's target prefixes with ours on Llama-3 improves nuanced\nattack success rates from 14% to 80%, suggesting that current alignment\nstruggles to generalize to unseen prefixes. Our work demonstrates the\nimportance of jailbreak objectives in achieving nuanced jailbreaks.", "published": "2024-12-13 18:00:57", "link": "http://arxiv.org/abs/2412.10321v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Do Large Language Models Show Biases in Causal Learning?", "abstract": "Causal learning is the cognitive process of developing the capability of\nmaking causal inferences based on available information, often guided by\nnormative principles. This process is prone to errors and biases, such as the\nillusion of causality, in which people perceive a causal relationship between\ntwo variables despite lacking supporting evidence. This cognitive bias has been\nproposed to underlie many societal problems, including social prejudice,\nstereotype formation, misinformation, and superstitious thinking. In this\nresearch, we investigate whether large language models (LLMs) develop causal\nillusions, both in real-world and controlled laboratory contexts of causal\nlearning and inference. To this end, we built a dataset of over 2K samples\nincluding purely correlational cases, situations with null contingency, and\ncases where temporal information excludes the possibility of causality by\nplacing the potential effect before the cause. We then prompted the models to\nmake statements or answer causal questions to evaluate their tendencies to\ninfer causation erroneously in these structured settings. Our findings show a\nstrong presence of causal illusion bias in LLMs. Specifically, in open-ended\ngeneration tasks involving spurious correlations, the models displayed bias at\nlevels comparable to, or even lower than, those observed in similar studies on\nhuman subjects. However, when faced with null-contingency scenarios or temporal\ncues that negate causal relationships, where it was required to respond on a\n0-100 scale, the models exhibited significantly higher bias. These findings\nsuggest that the models have not uniformly, consistently, or reliably\ninternalized the normative principles essential for accurate causal learning.", "published": "2024-12-13 19:03:48", "link": "http://arxiv.org/abs/2412.10509v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "RAGServe: Fast Quality-Aware RAG Systems with Configuration Adaptation", "abstract": "RAG (Retrieval Augmented Generation) allows LLMs (large language models) to\ngenerate better responses with external knowledge, but using more external\nknowledge often improves generation quality at the expense of response delay.\nPrior work either reduces the response delay (through better scheduling of RAG\nqueries) or strives to maximize quality (which involves tuning the RAG\nworkflow), but they fall short in optimizing the tradeoff between the delay and\nquality of RAG responses. This paper presents RAGServe, the first RAG system\nthat jointly schedules queries and adapts the key RAG configurations of each\nquery, such as the number of retrieved text chunks and synthesis methods, in\norder to balance quality optimization and response delay reduction. Using 4\npopular RAG-QA datasets, we show that compared with the state-of-the-art RAG\noptimization schemes, RAGServe reduces the generation latency by\n$1.64-2.54\\times$ without sacrificing generation quality.", "published": "2024-12-13 20:39:30", "link": "http://arxiv.org/abs/2412.10543v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Too Big to Fool: Resisting Deception in Language Models", "abstract": "Large language models must balance their weight-encoded knowledge with\nin-context information from prompts to generate accurate responses. This paper\ninvestigates this interplay by analyzing how models of varying capacities\nwithin the same family handle intentionally misleading in-context information.\nOur experiments demonstrate that larger models exhibit higher resilience to\ndeceptive prompts, showcasing an advanced ability to interpret and integrate\nprompt information with their internal knowledge. Furthermore, we find that\nlarger models outperform smaller ones in following legitimate instructions,\nindicating that their resilience is not due to disregarding in-context\ninformation. We also show that this phenomenon is likely not a result of\nmemorization but stems from the models' ability to better leverage implicit\ntask-relevant information from the prompt alongside their internally stored\nknowledge.", "published": "2024-12-13 21:03:10", "link": "http://arxiv.org/abs/2412.10558v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation of GPT-4o and GPT-4o-mini's Vision Capabilities for\n  Compositional Analysis from Dried Solution Drops", "abstract": "When microliter drops of salt solutions dry on non-porous surfaces, they form\nerratic yet characteristic deposit patterns influenced by complex\ncrystallization dynamics and fluid motion. Using OpenAI's image-enabled\nlanguage models, we analyzed deposits from 12 salts with 200 images per salt\nand per model. GPT-4o classified 57% of the salts accurately, significantly\noutperforming random chance and GPT-4o mini. This study underscores the promise\nof general-use AI tools for reliably identifying salts from their drying\npatterns.", "published": "2024-12-13 22:02:48", "link": "http://arxiv.org/abs/2412.10587v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Model-diff: A Tool for Comparative Study of Language Models in the Input\n  Space", "abstract": "Comparing two (large) language models (LMs) side-by-side and pinpointing\ntheir prediction similarities and differences on the same set of inputs are\ncrucial in many real-world scenarios, e.g., one can test if a licensed model\nwas potentially plagiarized by another. Traditional analysis compares the LMs'\noutputs on some benchmark datasets, which only cover a limited number of inputs\nof designed perspectives for the intended applications. The benchmark datasets\ncannot prepare data to cover the test cases from unforeseen perspectives which\ncan help us understand differences between models unbiasedly. In this paper, we\npropose a new model comparative analysis setting that considers a large input\nspace where brute-force enumeration would be infeasible. The input space can be\nsimply defined as all token sequences that a LM would produce low perplexity on\n-- we follow this definition in the paper as it would produce the most\nhuman-understandable inputs. We propose a novel framework \\our that uses text\ngeneration by sampling and deweights the histogram of sampling statistics to\nestimate prediction differences between two LMs in this input space efficiently\nand unbiasedly. Our method achieves this by drawing and counting the inputs at\neach prediction difference value in negative log-likelihood. Experiments reveal\nfor the first time the quantitative prediction differences between LMs in a\nlarge input space, potentially facilitating the model analysis for applications\nsuch as model plagiarism.", "published": "2024-12-13 00:06:25", "link": "http://arxiv.org/abs/2412.12177v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChainStream: An LLM-based Framework for Unified Synthetic Sensing", "abstract": "Many applications demand context sensing to offer personalized and timely\nservices. Yet, developing sensing programs can be challenging for developers\nand using them is privacy-concerning for end-users. In this paper, we propose\nto use natural language as the unified interface to process personal data and\nsense user context, which can effectively ease app development and make the\ndata pipeline more transparent. Our work is inspired by large language models\n(LLMs) and other generative models, while directly applying them does not solve\nthe problem - letting the model directly process the data cannot handle complex\nsensing requests and letting the model write the data processing program\nsuffers error-prone code generation. We address the problem with 1) a unified\ndata processing framework that makes context-sensing programs simpler and 2) a\nfeedback-guided query optimizer that makes data query more informative. To\nevaluate the performance of natural language-based context sensing, we create a\nbenchmark that contains 133 context sensing tasks. Extensive evaluation has\nshown that our approach is able to automatically solve the context-sensing\ntasks efficiently and precisely. The code is opensourced at\nhttps://github.com/MobileLLM/ChainStream.", "published": "2024-12-13 08:25:26", "link": "http://arxiv.org/abs/2412.15240v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Quantifying Positional Biases in Text Embedding Models", "abstract": "Embedding models are crucial for tasks in Information Retrieval (IR) and\nsemantic similarity measurement, yet their handling of longer texts and\nassociated positional biases remains underexplored. In this study, we\ninvestigate the impact of content position and input size on text embeddings.\nOur experiments reveal that embedding models, irrespective of their positional\nencoding mechanisms, disproportionately prioritize the beginning of an input.\nAblation studies demonstrate that insertion of irrelevant text or removal at\nthe start of a document reduces cosine similarity between altered and original\nembeddings by up to 12.3% more than ablations at the end. Regression analysis\nfurther confirms this bias, with sentence importance declining as position\nmoves further from the start, even with with content-agnosticity. We\nhypothesize that this effect arises from pre-processing strategies and chosen\npositional encoding techniques. These findings quantify the sensitivity of\nretrieval systems and suggest a new lens towards embedding model robustness.", "published": "2024-12-13 09:52:25", "link": "http://arxiv.org/abs/2412.15241v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MPPO: Multi Pair-wise Preference Optimization for LLMs with Arbitrary\n  Negative Samples", "abstract": "Aligning Large Language Models (LLMs) with human feedback is crucial for\ntheir development. Existing preference optimization methods such as DPO and\nKTO, while improved based on Reinforcement Learning from Human Feedback (RLHF),\nare inherently derived from PPO, requiring a reference model that adds GPU\nmemory resources and relies heavily on abundant preference data. Meanwhile,\ncurrent preference optimization research mainly targets single-question\nscenarios with two replies, neglecting optimization with multiple replies,\nwhich leads to a waste of data in the application. This study introduces the\nMPPO algorithm, which leverages the average likelihood of model responses to\nfit the reward function and maximizes the utilization of preference data.\nThrough a comparison of Point-wise, Pair-wise, and List-wise implementations,\nwe found that the Pair-wise approach achieves the best performance,\nsignificantly enhancing the quality of model responses. Experimental results\ndemonstrate MPPO's outstanding performance across various benchmarks. On\nMT-Bench, MPPO outperforms DPO, ORPO, and SimPO. Notably, on Arena-Hard, MPPO\nsurpasses DPO and ORPO by substantial margins. These achievements underscore\nthe remarkable advantages of MPPO in preference optimization tasks.", "published": "2024-12-13 14:18:58", "link": "http://arxiv.org/abs/2412.15244v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modeling Story Expectations to Understand Engagement: A Generative\n  Framework Using LLMs", "abstract": "Understanding when and why consumers engage with stories is crucial for\ncontent creators and platforms. While existing theories suggest that audience\nbeliefs of what is going to happen should play an important role in engagement\ndecisions, empirical work has mostly focused on developing techniques to\ndirectly extract features from actual content, rather than capturing\nforward-looking beliefs, due to the lack of a principled way to model such\nbeliefs in unstructured narrative data. To complement existing feature\nextraction techniques, this paper introduces a novel framework that leverages\nlarge language models to model audience forward-looking beliefs about how\nstories might unfold. Our method generates multiple potential continuations for\neach story and extracts features related to expectations, uncertainty, and\nsurprise using established content analysis techniques. Applying our method to\nover 30,000 book chapters, we demonstrate that our framework complements\nexisting feature engineering techniques by amplifying their marginal\nexplanatory power on average by 31%. The results reveal that different types of\nengagement-continuing to read, commenting, and voting-are driven by distinct\ncombinations of current and anticipated content features. Our framework\nprovides a novel way to study and explore how audience forward-looking beliefs\nshape their engagement with narrative media, with implications for marketing\nstrategy in content-focused industries.", "published": "2024-12-13 04:53:34", "link": "http://arxiv.org/abs/2412.15239v2", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC", "stat.ME", "68T50, 91F20", "H.3.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "HashEvict: A Pre-Attention KV Cache Eviction Strategy using\n  Locality-Sensitive Hashing", "abstract": "Transformer-based large language models (LLMs) use the key-value (KV) cache\nto significantly accelerate inference by storing the key and value embeddings\nof past tokens. However, this cache consumes significant GPU memory. In this\nwork, we introduce HashEvict, an algorithm that uses locality-sensitive hashing\n(LSH) to compress the KV cache. HashEvict quickly locates tokens in the cache\nthat are cosine dissimilar to the current query token. This is achieved by\ncomputing the Hamming distance between binarized Gaussian projections of the\ncurrent token query and cached token keys, with a projection length much\nsmaller than the embedding dimension. We maintain a lightweight binary\nstructure in GPU memory to facilitate these calculations. Unlike existing\ncompression strategies that compute attention to determine token retention,\nHashEvict makes these decisions pre-attention, thereby reducing computational\ncosts. Additionally, HashEvict is dynamic - at every decoding step, the key and\nvalue of the current token replace the embeddings of a token expected to\nproduce the lowest attention score. We demonstrate that HashEvict can compress\nthe KV cache by 30%-70% while maintaining high performance across reasoning,\nmultiple-choice, long-context retrieval and summarization tasks.", "published": "2024-12-13 06:00:27", "link": "http://arxiv.org/abs/2412.16187v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DS", "cs.PF"], "primary_category": "cs.LG"}
{"title": "SILA: Signal-to-Language Augmentation for Enhanced Control in\n  Text-to-Audio Generation", "abstract": "The field of text-to-audio generation has seen significant advancements, and\nyet the ability to finely control the acoustic characteristics of generated\naudio remains under-explored. In this paper, we introduce a novel yet simple\napproach to generate sound effects with control over key acoustic parameters\nsuch as loudness, pitch, reverb, fade, brightness, noise and duration, enabling\ncreative applications in sound design and content creation. These parameters\nextend beyond traditional Digital Signal Processing (DSP) techniques,\nincorporating learned representations that capture the subtleties of how sound\ncharacteristics can be shaped in context, enabling a richer and more nuanced\ncontrol over the generated audio. Our approach is model-agnostic and is based\non learning the disentanglement between audio semantics and its acoustic\nfeatures. Our approach not only enhances the versatility and expressiveness of\ntext-to-audio generation but also opens new avenues for creative audio\nproduction and sound design. Our objective and subjective evaluation results\ndemonstrate the effectiveness of our approach in producing high-quality,\ncustomizable audio outputs that align closely with user specifications.", "published": "2024-12-13 02:07:21", "link": "http://arxiv.org/abs/2412.09789v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Multimodal Methods and Spontaneous Speech for Alzheimer's\n  Disease Identification", "abstract": "Cognitive impairment detection through spontaneous speech is a promising\navenue for early diagnosis of Alzheimer's disease (AD) and mild cognitive\nimpairment (MCI), where timely intervention can significantly improve patient\noutcomes. The PROCESS Grand Challenge at ICASSP 2025 addresses these tasks by\npromoting innovative classification and regression methods for detecting\ncognitive decline. In this paper, we propose a multimodal fusion strategy that\ncombines interpretable linguistic features with temporal embeddings extracted\nfrom pre-trained models. Our approach achieves an F1-score of 0.649 for the\nclassification task (predicting healthy, MCI, dementia) and an RMSE of 2.628\nfor the regression task (MMSE score prediction), securing the top overall\nranking in the competition.", "published": "2024-12-13 07:28:31", "link": "http://arxiv.org/abs/2412.09928v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SonicBoom: Contact Localization Using Array of Microphones", "abstract": "In cluttered environments where visual sensors encounter heavy occlusion,\nsuch as in agricultural settings, tactile signals can provide crucial spatial\ninformation for the robot to locate rigid objects and maneuver around them. We\nintroduce SonicBoom, a holistic hardware and learning pipeline that enables\ncontact localization through an array of contact microphones. While\nconventional sound source localization methods effectively triangulate sources\nin air, localization through solid media with irregular geometry and structure\npresents challenges that are difficult to model analytically. We address this\nchallenge through a feature engineering and learning based approach,\nautonomously collecting 18,000 robot interaction sound pairs to learn a mapping\nbetween acoustic signals and collision locations on the robot end effector\nlink. By leveraging relative features between microphones, SonicBoom achieves\nlocalization errors of 0.42cm for in distribution interactions and maintains\nrobust performance of 2.22cm error even with novel objects and contact\nconditions. We demonstrate the system's practical utility through haptic\nmapping of occluded branches in mock canopy settings, showing that acoustic\nbased sensing can enable reliable robot navigation in visually challenging\nenvironments.", "published": "2024-12-13 05:50:13", "link": "http://arxiv.org/abs/2412.09878v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on\n  Conditional Transformer with Fine-Grained Lyric and Musical Controls", "abstract": "Lyric-to-melody generation is a highly challenging task in the field of AI\nmusic generation. Due to the difficulty of learning strict yet weak\ncorrelations between lyrics and melodies, previous methods have suffered from\nweak controllability, low-quality and poorly structured generation. To address\nthese challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody\ngeneration method based on an in-attention Transformer decoder with\nfine-grained lyric and musical controls, which is able to generate full-song\nmelodies matched with the given lyrics and user-specified musical attributes.\nSpecifically, we first introduce REMI-Aligned, a novel music representation\nthat incorporates strict syllable- and sentence-level alignments between lyrics\nand melodies, facilitating precise alignment modeling. Subsequently,\nsentence-level semantic lyric embeddings independently extracted from a\nsentence-wise Transformer encoder are combined with word-level part-of-speech\nembeddings and syllable-level tone embeddings as fine-grained controls to\nenhance the controllability of lyrics over melody generation. Then we introduce\nhuman-labeled musical tags, sentence-level statistical musical attributes, and\nlearned musical features extracted from a pre-trained VQ-VAE as coarse-grained,\nfine-grained and high-fidelity controls, respectively, to the generation\nprocess, thereby enabling user control over melody generation. Finally, an\nin-attention Transformer decoder technique is leveraged to exert fine-grained\ncontrol over the full-song melody generation with the aforementioned lyric and\nmusical conditions. Experimental results demonstrate that our proposed CSL-L2M\noutperforms the state-of-the-art models, generating melodies with higher\nquality, better controllability and enhanced structure. Demos and source code\nare available at https://lichaiustc.github.io/CSL-L2M/.", "published": "2024-12-13 06:05:53", "link": "http://arxiv.org/abs/2412.09887v2", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Enhanced Speech Emotion Recognition with Efficient Channel Attention\n  Guided Deep CNN-BiLSTM Framework", "abstract": "Speech emotion recognition (SER) is crucial for enhancing affective computing\nand enriching the domain of human-computer interaction. However, the main\nchallenge in SER lies in selecting relevant feature representations from speech\nsignals with lower computational costs. In this paper, we propose a lightweight\nSER architecture that integrates attention-based local feature blocks (ALFBs)\nto capture high-level relevant feature vectors from speech signals. We also\nincorporate a global feature block (GFB) technique to capture sequential,\nglobal information and long-term dependencies in speech signals. By aggregating\nattention-based local and global contextual feature vectors, our model\neffectively captures the internal correlation between salient features that\nreflect complex human emotional cues. To evaluate our approach, we extracted\nfour types of spectral features from speech audio samples: mel-frequency\ncepstral coefficients, mel-spectrogram, root mean square value, and\nzero-crossing rate. Through a 5-fold cross-validation strategy, we tested the\nproposed method on five multi-lingual standard benchmark datasets: TESS,\nRAVDESS, BanglaSER, SUBESCO, and Emo-DB, and obtained a mean accuracy of\n99.65%, 94.88%, 98.12%, 97.94%, and 97.19% respectively. The results indicate\nthat our model achieves state-of-the-art (SOTA) performance compared to most\nexisting methods.", "published": "2024-12-13 09:55:03", "link": "http://arxiv.org/abs/2412.10011v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language\n  Models", "abstract": "In our previous work, we introduced CosyVoice, a multilingual speech\nsynthesis model based on supervised discrete speech tokens. By employing\nprogressive semantic decoding with two popular generative models, language\nmodels (LMs) and Flow Matching, CosyVoice demonstrated high prosody\nnaturalness, content consistency, and speaker similarity in speech in-context\nlearning. Recently, significant progress has been made in multi-modal large\nlanguage models (LLMs), where the response latency and real-time factor of\nspeech synthesis play a crucial role in the interactive experience. Therefore,\nin this report, we present an improved streaming speech synthesis model,\nCosyVoice 2, which incorporates comprehensive and systematic optimizations.\nSpecifically, we introduce finite-scalar quantization to improve the codebook\nutilization of speech tokens. For the text-speech LM, we streamline the model\narchitecture to allow direct use of a pre-trained LLM as the backbone. In\naddition, we develop a chunk-aware causal flow matching model to support\nvarious synthesis scenarios, enabling both streaming and non-streaming\nsynthesis within a single model. By training on a large-scale multilingual\ndataset, CosyVoice 2 achieves human-parity naturalness, minimal response\nlatency, and virtually lossless synthesis quality in the streaming mode. We\ninvite readers to listen to the demos at\nhttps://funaudiollm.github.io/cosyvoice2.", "published": "2024-12-13 12:59:39", "link": "http://arxiv.org/abs/2412.10117v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Tipping Points, Pulse Elasticity and Tonal Tension: An Empirical Study\n  on What Generates Tipping Points", "abstract": "Tipping points are moments of change that characterise crucial turning points\nin a piece of music. This study presents a first step towards quantitatively\nand systematically describing the musical properties of tipping points. Timing\ninformation and computationally-derived tonal tension values which correspond\nto dissonance, distance from key, and harmonic motion are compared to tipping\npoints in Ashkenazy's recordings of six Chopin Mazurkas, as identified by 35\nlisteners. The analysis shows that all popular tipping points but one could be\nexplained by statistically significant timing deviations or changepoints in at\nleast one of the three tension parameters.", "published": "2024-12-13 09:27:46", "link": "http://arxiv.org/abs/2412.10481v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
