{"title": "Whack-a-mole Online Learning: Physics-Informed Neural Network for Intraday Implied Volatility Surface", "abstract": "Calibrating the time-dependent Implied Volatility Surface (IVS) using sparse\nmarket data is an essential challenge in computational finance, particularly\nfor real-time applications. This task requires not only fitting market data but\nalso satisfying a specified partial differential equation (PDE) and\nno-arbitrage conditions modelled by differential inequalities. This paper\nproposes a novel Physics-Informed Neural Networks (PINNs) approach called\nWhack-a-mole Online Learning (WamOL) to address this multi-objective\noptimisation problem. WamOL integrates self-adaptive and auto-balancing\nprocesses for each loss term, efficiently reweighting objective functions to\nensure smooth surface fitting while adhering to PDE and no-arbitrage\nconstraints and updating for intraday predictions. In our experiments, WamOL\ndemonstrates superior performance in calibrating intraday IVS from uneven and\nsparse market data, effectively capturing the dynamic evolution of option\nprices and associated risk profiles. This approach offers an efficient solution\nfor intraday IVS calibration, extending PINNs applications and providing a\nmethod for real-time financial modelling.", "published": "2024-11-04 18:44:31", "link": "http://arxiv.org/abs/2411.02375v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Stochastic Optimal Control of an Industrial Power-to-Heat System with High-Temperature Heat Pump and Thermal Energy Storage", "abstract": "The optimal control of sustainable energy supply systems, including renewable\nenergies and energy storage, takes a central role in the decarbonization of\nindustrial systems. However, the use of fluctuating renewable energies leads to\nfluctuations in energy generation and requires a suitable control strategy for\nthe complex systems in order to ensure energy supply. In this paper, we\nconsider an electrified power-to-heat system which is designed to supply heat\nin form of superheated steam for industrial processes. The system consists of a\nhigh-temperature heat pump for heat supply, a wind turbine for power\ngeneration, a sensible thermal energy storage for storing excess heat and a\nsteam generator for providing steam. If the system's energy demand cannot be\ncovered by electricity from the wind turbine, additional electricity must be\npurchased from the power grid. For this system, we investigate the cost-optimal\noperation aiming to minimize the electricity cost from the grid by a suitable\nsystem control depending on the available wind power and the amount of stored\nthermal energy. This is a decision making problem under uncertainties about the\nfuture prices for electricity from the grid and the future generation of wind\npower. The resulting stochastic optimal control problem is treated as\nfinite-horizon Markov decision process for a multi-dimensional controlled state\nprocess. We first consider the classical backward recursion techniques for\nsolving the associated dynamic programming equation for the value function and\ncompute the optimal decision rule. Since that approach suffers from the curse\nof dimensionality we also apply Q-learning techniques that are able to provide\na good approximate solution to the optimization problem within reasonable time.", "published": "2024-11-04 16:06:30", "link": "http://arxiv.org/abs/2411.02211v2", "categories": ["math.OC", "q-fin.CP", "93E20, 90-08, 90C40, 68T05, 91G60"], "primary_category": "math.OC"}
{"title": "Real-world models for multiple term structures: a unifying HJM semimartingale framework", "abstract": "We develop a unified framework for modeling multiple term structures arising\nin financial, insurance, and energy markets, adopting an extended\nHeath-Jarrow-Morton (HJM) approach under the real-world probability. We study\nmarket viability and characterize the set of local martingale deflators. We\nconduct an analysis of the associated stochastic partial differential equation\n(SPDE), addressing existence and uniqueness of solutions, invariance properties\nand existence of affine realizations.", "published": "2024-11-04 11:10:20", "link": "http://arxiv.org/abs/2411.01983v2", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "Enhancing Risk Assessment in Transformers with Loss-at-Risk Functions", "abstract": "In the financial field, precise risk assessment tools are essential for\ndecision-making. Recent studies have challenged the notion that traditional\nnetwork loss functions like Mean Square Error (MSE) are adequate, especially\nunder extreme risk conditions that can lead to significant losses during market\nupheavals. Transformers and Transformer-based models are now widely used in\nfinancial forecasting according to their outstanding performance in\ntime-series-related predictions. However, these models typically lack\nsensitivity to extreme risks and often underestimate great financial losses. To\naddress this problem, we introduce a novel loss function, the Loss-at-Risk,\nwhich incorporates Value at Risk (VaR) and Conditional Value at Risk (CVaR)\ninto Transformer models. This integration allows Transformer models to\nrecognize potential extreme losses and further improves their capability to\nhandle high-stakes financial decisions. Moreover, we conduct a series of\nexperiments with highly volatile financial datasets to demonstrate that our\nLoss-at-Risk function improves the Transformers' risk prediction and management\ncapabilities without compromising their decision-making accuracy or efficiency.\nThe results demonstrate that integrating risk-aware metrics during training\nenhances the Transformers' risk assessment capabilities while preserving their\ncore strengths in decision-making and reasoning across diverse scenarios.", "published": "2024-11-04 19:44:43", "link": "http://arxiv.org/abs/2411.02558v1", "categories": ["cs.LG", "cs.CL", "q-fin.RM", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "Advancing DeFi Analytics: Efficiency Analysis with Decentralized Exchanges Comparison Service", "abstract": "This empirical study presents the Decentralized Exchanges Comparison Service\n(DECS), a novel tool developed by 1inch Analytics to assess exchange efficiency\nin decentralized finance. The DECS utilizes swap transaction monitoring and\nsimulation techniques to provide unbiased comparisons of swap rates across\nvarious DEXes and aggregators. Analysis of almost 1.2 million transactions\nacross multiple blockchain networks demonstrates that both 1inch Classic and\n1inch Fusion consistently outperform competitors. These findings not only\nvalidate 1inch's superior rates but also provide valuable insights for\ncontinuous protocol optimization and underscore the critical role of\ndata-driven decision-making in advancing DeFi infrastructure.", "published": "2024-11-04 10:21:46", "link": "http://arxiv.org/abs/2411.01950v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "DynaSaur: Large Language Agents Beyond Predefined Actions", "abstract": "Existing LLM agent systems typically select actions from a fixed and\npredefined set at every step. While this approach is effective in closed,\nnarrowly-scoped environments, we argue that it presents two major challenges\nwhen deploying LLM agents in real-world scenarios: (1) selecting from a fixed\nset of actions significantly restricts the planning and acting capabilities of\nLLM agents, and (2) this approach requires substantial human effort to\nenumerate and implement all possible actions, which becomes impractical in\ncomplex environments with a vast number of potential actions. In this work, we\npropose an LLM agent framework that enables the dynamic creation and\ncomposition of actions in an online manner. In this framework, the agent\ninteracts with the environment by generating and executing programs written in\na general-purpose programming language at each step. Furthermore, generated\nactions are accumulated over time for future reuse. Our extensive experiments\non the GAIA benchmark demonstrate that this framework offers significantly\ngreater flexibility and outperforms previous methods. Notably, it allows an LLM\nagent to recover in scenarios where no relevant action exists in the predefined\nset or when existing actions fail due to unforeseen edge cases. At the time of\nwriting, we hold the top position on the GAIA public leaderboard. Our code can\nbe found in\n\\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur}.", "published": "2024-11-04 02:08:59", "link": "http://arxiv.org/abs/2411.01747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Pedagogical LLMs with Supervised Fine Tuning for Computing\n  Education", "abstract": "This paper investigates supervised fine-tuning of large language models\n(LLMs) to improve their pedagogical alignment in computing education,\naddressing concerns that LLMs may hinder learning outcomes. The project\nutilised a proprietary dataset of 2,500 high quality question/answer pairs from\nprogramming course forums, and explores two research questions: the suitability\nof university course forums in contributing to fine-tuning datasets, and how\nsupervised fine-tuning can improve LLMs' alignment with educational principles\nsuch as constructivism. Initial findings suggest benefits in pedagogical\nalignment of LLMs, with deeper evaluations required.", "published": "2024-11-04 03:20:00", "link": "http://arxiv.org/abs/2411.01765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity\n  Recognition", "abstract": "Discontinuous Named Entity Recognition (DNER) presents a challenging problem\nwhere entities may be scattered across multiple non-adjacent tokens, making\ntraditional sequence labelling approaches inadequate. Existing methods\npredominantly rely on custom tagging schemes to handle these discontinuous\nentities, resulting in models tightly coupled to specific tagging strategies\nand lacking generalisability across diverse datasets. To address these\nchallenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces\na generalisable approach to learning robust token-level representations for\ndiscontinuous entity extraction. Our framework applies triplet loss at the\ntoken level, where similarity is defined by word pairs existing within the same\nentity, effectively pulling together similar and pushing apart dissimilar ones.\nThis approach enhances entity boundary detection and reduces the dependency on\nspecific tagging schemes by focusing on word-pair relationships within a\nflexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets\nand demonstrate significant improvements over existing grid-based\narchitectures. These results underscore our framework's effectiveness in\ncapturing complex entity structures and its adaptability to various tagging\nschemes, setting a new benchmark for discontinuous entity extraction.", "published": "2024-11-04 06:26:09", "link": "http://arxiv.org/abs/2411.01839v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Language Models Learn to Skip Steps?", "abstract": "Trained on vast corpora of human language, language models demonstrate\nemergent human-like reasoning abilities. Yet they are still far from true\nintelligence, which opens up intriguing opportunities to explore the parallels\nof humans and model behaviors. In this work, we study the ability to skip steps\nin reasoning - a hallmark of human expertise developed through practice. Unlike\nhumans, who may skip steps to enhance efficiency or to reduce cognitive load,\nmodels do not inherently possess such motivations to minimize reasoning steps.\nTo address this, we introduce a controlled framework that stimulates\nstep-skipping behavior by iteratively refining models to generate shorter and\naccurate reasoning paths. Empirical results indicate that models can develop\nthe step skipping ability under our guidance. Moreover, after fine-tuning on\nexpanded datasets that include both complete and skipped reasoning sequences,\nthe models can not only resolve tasks with increased efficiency without\nsacrificing accuracy, but also exhibit comparable and even enhanced\ngeneralization capabilities in out-of-domain scenarios. Our work presents the\nfirst exploration into human-like step-skipping ability and provides fresh\nperspectives on how such cognitive abilities can benefit AI models.", "published": "2024-11-04 07:10:24", "link": "http://arxiv.org/abs/2411.01855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AVSS: Layer Importance Evaluation in Large Language Models via\n  Activation Variance-Sparsity Analysis", "abstract": "The evaluation of layer importance in deep learning has been an active area\nof research, with significant implications for model optimization and\ninterpretability. Recently, large language models (LLMs) have gained prominence\nacross various domains, yet limited studies have explored the functional\nimportance and performance contributions of individual layers within LLMs,\nespecially from the perspective of activation distribution. In this work, we\npropose the Activation Variance-Sparsity Score (AVSS), a novel metric combining\nnormalized activation variance and sparsity to assess each layer's contribution\nto model performance. By identifying and removing approximately the lowest 25%\nof layers based on AVSS, we achieve over 90% of original model performance\nacross tasks such as question answering, language modeling, and sentiment\nclassification, indicating that these layers may be non-essential. Our approach\nprovides a systematic method for identifying less critical layers, contributing\nto efficient large language model architectures.", "published": "2024-11-04 14:29:49", "link": "http://arxiv.org/abs/2411.02117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MdEval: Massively Multilingual Code Debugging", "abstract": "Code large language models (LLMs) have made significant progress in code\ndebugging by directly generating the correct code based on the buggy code\nsnippet. Programming benchmarks, typically consisting of buggy code snippet and\ntheir associated test cases, are used to assess the debugging capabilities of\nLLMs. However, many existing benchmarks primarily focus on Python and are often\nlimited in terms of language diversity (e.g., DebugBench and DebugEval). To\nadvance the field of multilingual debugging with LLMs, we propose the first\nmassively multilingual debugging benchmark, which includes 3.6K test samples of\n18 programming languages and covers the automated program repair (APR) task,\nthe code review (CR) task, and the bug identification (BI) task. Further, we\nintroduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs\ninto the correct multilingual queries and solutions (xDebugGen). Further, a\nmultilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong\nbaseline specifically to handle the bugs of a wide range of programming\nlanguages (e.g. \"Missing Mut\" in language Rust and \"Misused Macro Definition\"\nin language C). Our extensive experiments on MDEVAL reveal a notable\nperformance gap between open-source models and closed-source LLMs (e.g., GPT\nand Claude series), highlighting huge room for improvement in multilingual code\ndebugging scenarios.", "published": "2024-11-04 17:36:40", "link": "http://arxiv.org/abs/2411.02310v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum\n  Reinforcement Learning", "abstract": "Large language models (LLMs) have shown remarkable potential as autonomous\nagents, particularly in web-based tasks. However, existing LLM web agents\nheavily rely on expensive proprietary LLM APIs, while open LLMs lack the\nnecessary decision-making capabilities. This paper introduces WebRL, a\nself-evolving online curriculum reinforcement learning framework designed to\ntrain high-performance web agents using open LLMs. WebRL addresses three key\nchallenges in building LLM web agents, including the scarcity of training\ntasks, sparse feedback signals, and policy distribution drift in online\nlearning. Specifically, WebRL incorporates 1) a self-evolving curriculum that\ngenerates new tasks from unsuccessful attempts, 2) a robust outcome-supervised\nreward model (ORM), and 3) adaptive reinforcement learning strategies to ensure\nconsistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4\nmodels into proficient web agents. On WebArena-Lite, WebRL improves the success\nrate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B.\nThese open models significantly surpass the performance of GPT-4-Turbo (17.6%)\nand GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained\non open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's\neffectiveness in bridging the gap between open and proprietary LLM-based web\nagents, paving the way for more accessible and powerful autonomous web\ninteraction systems.", "published": "2024-11-04 17:59:58", "link": "http://arxiv.org/abs/2411.02337v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attacking Vision-Language Computer Agents via Pop-ups", "abstract": "Autonomous agents powered by large vision and language models (VLM) have\ndemonstrated significant potential in completing daily computer tasks, such as\nbrowsing the web to book travel and operating desktop software, which requires\nagents to understand these interfaces. Despite such visual inputs becoming more\nintegrated into agentic applications, what types of risks and attacks exist\naround them still remain unclear. In this work, we demonstrate that VLM agents\ncan be easily attacked by a set of carefully designed adversarial pop-ups,\nwhich human users would typically recognize and ignore. This distraction leads\nagents to click these pop-ups instead of performing the tasks as usual.\nIntegrating these pop-ups into existing agent testing environments like OSWorld\nand VisualWebArena leads to an attack success rate (the frequency of the agent\nclicking the pop-ups) of 86% on average and decreases the task success rate by\n47%. Basic defense techniques such as asking the agent to ignore pop-ups or\nincluding an advertisement notice, are ineffective against the attack.", "published": "2024-11-04 18:56:42", "link": "http://arxiv.org/abs/2411.02391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Goes Into a LM Acceptability Judgment? Rethinking the Impact of\n  Frequency and Length", "abstract": "When comparing the linguistic capabilities of language models (LMs) with\nhumans using LM probabilities, factors such as the length of the sequence and\nthe unigram frequency of lexical items have a significant effect on LM\nprobabilities in ways that humans are largely robust to. Prior works in\ncomparing LM and human acceptability judgments treat these effects uniformly\nacross models, making a strong assumption that models require the same degree\nof adjustment to control for length and unigram frequency effects. We propose\nMORCELA, a new linking theory between LM scores and acceptability judgments\nwhere the optimal level of adjustment for these effects is estimated from data\nvia learned parameters for length and unigram frequency. We first show that\nMORCELA outperforms a commonly used linking theory for acceptability - SLOR\n(Pauls and Klein, 2012; Lau et al. 2017) - across two families of transformer\nLMs (Pythia and OPT). Furthermore, we demonstrate that the assumed degrees of\nadjustment in SLOR for length and unigram frequency overcorrect for these\nconfounds, and that larger models require a lower relative degree of adjustment\nfor unigram frequency, though a significant amount of adjustment is still\nnecessary for all models. Finally, our subsequent analysis shows that larger\nLMs' lower susceptibility to frequency effects can be explained by an ability\nto better predict rarer words in context.", "published": "2024-11-04 19:05:49", "link": "http://arxiv.org/abs/2411.02528v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MILU: A Multi-task Indic Language Understanding Benchmark", "abstract": "Evaluating Large Language Models (LLMs) in low-resource and linguistically\ndiverse languages remains a significant challenge in NLP, particularly for\nlanguages using non-Latin scripts like those spoken in India. Existing\nbenchmarks predominantly focus on English, leaving substantial gaps in\nassessing LLM capabilities in these languages. We introduce MILU, a Multi task\nIndic Language Understanding Benchmark, a comprehensive evaluation benchmark\ndesigned to address this gap. MILU spans 8 domains and 41 subjects across 11\nIndic languages, reflecting both general and culturally specific knowledge.\nWith an India-centric design, incorporates material from regional and\nstate-level examinations, covering topics such as local history, arts,\nfestivals, and laws, alongside standard subjects like science and mathematics.\nWe evaluate over 42 LLMs, and find that current LLMs struggle with MILU, with\nGPT-4o achieving the highest average accuracy at 74 percent. Open multilingual\nmodels outperform language-specific fine-tuned models, which perform only\nslightly better than random baselines. Models also perform better in high\nresource languages as compared to low resource ones. Domain-wise analysis\nindicates that models perform poorly in culturally relevant areas like Arts and\nHumanities, Law and Governance compared to general fields like STEM. To the\nbest of our knowledge, MILU is the first of its kind benchmark focused on Indic\nlanguages, serving as a crucial step towards comprehensive cultural evaluation.\nAll code, benchmarks, and artifacts are publicly available to foster open\nresearch.", "published": "2024-11-04 19:17:17", "link": "http://arxiv.org/abs/2411.02538v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Transformer-Based Models for Predicting Inflection Classes of\n  Words in an Endangered Sami Language", "abstract": "This paper presents a methodology for training a transformer-based model to\nclassify lexical and morphosyntactic features of Skolt Sami, an endangered\nUralic language characterized by complex morphology. The goal of our approach\nis to create an effective system for understanding and analyzing Skolt Sami,\ngiven the limited data availability and linguistic intricacies inherent to the\nlanguage. Our end-to-end pipeline includes data extraction, augmentation, and\ntraining a transformer-based model capable of predicting inflection classes.\nThe motivation behind this work is to support language preservation and\nrevitalization efforts for minority languages like Skolt Sami. Accurate\nclassification not only helps improve the state of Finite-State Transducers\n(FSTs) by providing greater lexical coverage but also contributes to systematic\nlinguistic documentation for researchers working with newly discovered words\nfrom literature and native speakers. Our model achieves an average weighted F1\nscore of 1.00 for POS classification and 0.81 for inflection class\nclassification. The trained model and code will be released publicly to\nfacilitate future research in endangered NLP.", "published": "2024-11-04 19:41:16", "link": "http://arxiv.org/abs/2411.02556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Informed Machine Translation of Manga using Multimodal Large\n  Language Models", "abstract": "Due to the significant time and effort required for handcrafting\ntranslations, most manga never leave the domestic Japanese market. Automatic\nmanga translation is a promising potential solution. However, it is a budding\nand underdeveloped field and presents complexities even greater than those\nfound in standard translation due to the need to effectively incorporate visual\nelements into the translation process to resolve ambiguities. In this work, we\ninvestigate to what extent multimodal large language models (LLMs) can provide\neffective manga translation, thereby assisting manga authors and publishers in\nreaching wider audiences. Specifically, we propose a methodology that leverages\nthe vision component of multimodal LLMs to improve translation quality and\nevaluate the impact of translation unit size, context length, and propose a\ntoken efficient approach for manga translation. Moreover, we introduce a new\nevaluation dataset -- the first parallel Japanese-Polish manga translation\ndataset -- as part of a benchmark to be used in future research. Finally, we\ncontribute an open-source software suite, enabling others to benchmark LLMs for\nmanga translation. Our findings demonstrate that our proposed methods achieve\nstate-of-the-art results for Japanese-English translation and set a new\nstandard for Japanese-Polish.", "published": "2024-11-04 20:29:35", "link": "http://arxiv.org/abs/2411.02589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geometry of orofacial neuromuscular signals: speech articulation\n  decoding using surface electromyography", "abstract": "Each year, millions of individuals lose the ability to speak intelligibly due\nto causes such as neuromuscular disease, stroke, trauma, and head/neck cancer\nsurgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the\nspeech articulators). Effective communication is crucial for daily activities,\nand losing the ability to speak leads to isolation, depression, anxiety, and a\nhost of detrimental sequelae. Noninvasive surface electromyography (sEMG) has\nshown promise to restore speech output in these individuals. The goal is to\ncollect sEMG signals from multiple articulatory sites as people silently\nproduce speech and then decode the signals to enable fluent and natural\ncommunication. Currently, many fundamental properties of orofacial\nneuromuscular signals relating to speech articulation remain unanswered. They\ninclude questions relating to 1) the data structure of the orofacial sEMG\nsignals, 2)the signal distribution shift of sEMG across individuals, 3) ability\nof sEMG signals to span the entire English language phonetic space during\nsilent speech articulations, and 4) the generalization capability of\nnon-invasive sEMG based silent speech interfaces. We address these questions\nthrough a series of experiments involving healthy human subjects. We show that\nsEMG signals evince graph data structure and that the signal distribution shift\nis given by a change of basis. Furthermore, we show that silently voiced\narticulations spanning the entire English language phonetic space can be\ndecoded using small neural networks which can be trained with little data and\nthat such architectures work well across individuals. To ensure transparency\nand reproducibility, we open-source all the data and codes used in this study.", "published": "2024-11-04 20:31:22", "link": "http://arxiv.org/abs/2411.02591v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zebra-Llama: A Context-Aware Large Language Model for Democratizing Rare\n  Disease Knowledge", "abstract": "Rare diseases present unique challenges in healthcare, often suffering from\ndelayed diagnosis and fragmented information landscapes. The scarcity of\nreliable knowledge in these conditions poses a distinct challenge for Large\nLanguage Models (LLMs) in supporting clinical management and delivering precise\npatient information underscoring the need for focused training on these 'zebra'\ncases. We present Zebra-Llama, a specialized context-aware language model with\nhigh precision Retrieval Augmented Generation (RAG) capability, focusing on\nEhlers-Danlos Syndrome (EDS) as our case study. EDS, affecting 1 in 5,000\nindividuals, exemplifies the complexities of rare diseases with its diverse\nsymptoms, multiple subtypes, and evolving diagnostic criteria. By implementing\na novel context-aware fine-tuning methodology trained on questions derived from\nmedical literature, patient experiences, and clinical resources, along with\nexpertly curated responses, Zebra-Llama demonstrates unprecedented capabilities\nin handling EDS-related queries. On a test set of real-world questions\ncollected from EDS patients and clinicians, medical experts evaluated the\nresponses generated by both models, revealing Zebra-Llama's substantial\nimprovements over base model (Llama 3.1-8B-Instruct) in thoroughness (77.5% vs.\n70.1%), accuracy (83.0% vs. 78.8%), clarity (74.7% vs. 72.0%) and citation\nreliability (70.6% vs. 52.3%). Released as an open-source resource, Zebra-Llama\nnot only provides more accessible and reliable EDS information but also\nestablishes a framework for developing specialized AI solutions for other rare\nconditions. This work represents a crucial step towards democratizing\nexpert-level knowledge in rare disease management, potentially transforming how\nhealthcare providers and patients navigate the complex landscape of rare\ndiseases.", "published": "2024-11-04 22:45:52", "link": "http://arxiv.org/abs/2411.02657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAGViz: Diagnose and Visualize Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) combines knowledge from domain-specific\nsources into large language models to ground answer generation. Current RAG\nsystems lack customizable visibility on the context documents and the model's\nattentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool\nthat visualizes the attentiveness of the generated tokens in retrieved\ndocuments. With a built-in user interface, retrieval index, and Large Language\nModel (LLM) backbone, RAGViz provides two main functionalities: (1) token and\ndocument-level attention visualization, and (2) generation comparison upon\ncontext document addition and removal. As an open-source toolkit, RAGViz can be\neasily hosted with a custom embedding model and HuggingFace-supported LLM\nbackbone. Using a hybrid ANN (Approximate Nearest Neighbor) index,\nmemory-efficient LLM inference tool, and custom context snippet method, RAGViz\noperates efficiently with a median query time of about 5 seconds on a moderate\nGPU node. Our code is available at https://github.com/cxcscmu/RAGViz. A demo\nvideo of RAGViz can be found at https://youtu.be/cTAbuTu6ur4.", "published": "2024-11-04 02:30:05", "link": "http://arxiv.org/abs/2411.01751v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Align-SLM: Textless Spoken Language Models with Reinforcement Learning\n  from AI Feedback", "abstract": "While textless Spoken Language Models (SLMs) have shown potential in\nend-to-end speech-to-speech modeling, they still lag behind text-based Large\nLanguage Models (LLMs) in terms of semantic coherence and relevance. This work\nintroduces the Align-SLM framework, which leverages preference optimization\ninspired by Reinforcement Learning with AI Feedback (RLAIF) to enhance the\nsemantic understanding of SLMs. Our approach generates multiple speech\ncontinuations from a given prompt and uses semantic metrics to create\npreference data for Direct Preference Optimization (DPO). We evaluate the\nframework using ZeroSpeech 2021 benchmarks for lexical and syntactic modeling,\nthe spoken version of the StoryCloze dataset for semantic coherence, and other\nspeech generation metrics, including the GPT4-o score and human evaluation.\nExperimental results show that our method achieves state-of-the-art performance\nfor SLMs on most benchmarks, highlighting the importance of preference\noptimization to improve the semantics of SLMs.", "published": "2024-11-04 06:07:53", "link": "http://arxiv.org/abs/2411.01834v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Leveraging Label Semantics and Meta-Label Refinement for Multi-Label\n  Question Classification", "abstract": "Accurate annotation of educational resources is crucial for effective\npersonalized learning and resource recommendation in online education. However,\nfine-grained knowledge labels often overlap or share similarities, making it\ndifficult for existing multi-label classification methods to differentiate\nthem. The label distribution imbalance due to sparsity of human annotations\nfurther intensifies these challenges. To address these issues, this paper\nintroduces RR2QC, a novel Retrieval Reranking method to multi-label Question\nClassification by leveraging label semantics and meta-label refinement. First,\nRR2QC improves the pre-training strategy by utilizing semantic relationships\nwithin and across label groups. Second, it introduces a class center learning\ntask to align questions with label semantics during downstream training.\nFinally, this method decomposes labels into meta-labels and uses a meta-label\nclassifier to rerank the retrieved label sequences. In doing so, RR2QC enhances\nthe understanding and prediction capability of long-tail labels by learning\nfrom meta-labels that frequently appear in other labels. Additionally, a\nmathematical LLM is used to generate solutions for questions, extracting latent\ninformation to further refine the model's insights. Experimental results show\nthat RR2QC outperforms existing methods in Precision@K and F1 scores across\nmultiple educational datasets, demonstrating its effectiveness for online\neducation applications. The code and datasets are available at\nhttps://github.com/78Erii/RR2QC.", "published": "2024-11-04 06:27:14", "link": "http://arxiv.org/abs/2411.01841v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Shortcut Learning in In-Context Learning: A Survey", "abstract": "Shortcut learning refers to the phenomenon where models employ simple,\nnon-robust decision rules in practical tasks, which hinders their\ngeneralization and robustness. With the rapid development of large language\nmodels (LLMs) in recent years, an increasing number of studies have shown the\nimpact of shortcut learning on LLMs. This paper provides a novel perspective to\nreview relevant research on shortcut learning in In-Context Learning (ICL). It\nconducts a detailed exploration of the types of shortcuts in ICL tasks, their\ncauses, available benchmarks, and strategies for mitigating shortcuts. Based on\ncorresponding observations, it summarizes the unresolved issues in existing\nresearch and attempts to outline the future research landscape of shortcut\nlearning.", "published": "2024-11-04 12:13:04", "link": "http://arxiv.org/abs/2411.02018v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explainable cognitive decline detection in free dialogues with a Machine\n  Learning approach based on pre-trained Large Language Models", "abstract": "Cognitive and neurological impairments are very common, but only a small\nproportion of affected individuals are diagnosed and treated, partly because of\nthe high costs associated with frequent screening. Detecting pre-illness stages\nand analyzing the progression of neurological disorders through effective and\nefficient intelligent systems can be beneficial for timely diagnosis and early\nintervention. We propose using Large Language Models to extract features from\nfree dialogues to detect cognitive decline. These features comprise high-level\nreasoning content-independent features (such as comprehension, decreased\nawareness, increased distraction, and memory problems). Our solution comprises\n(i) preprocessing, (ii) feature engineering via Natural Language Processing\ntechniques and prompt engineering, (iii) feature analysis and selection to\noptimize performance, and (iv) classification, supported by automatic\nexplainability. We also explore how to improve Chatgpt's direct cognitive\nimpairment prediction capabilities using the best features in our models.\nEvaluation metrics obtained endorse the effectiveness of a mixed approach\ncombining feature extraction with Chatgpt and a specialized Machine Learning\nmodel to detect cognitive decline within free-form conversational dialogues\nwith older adults. Ultimately, our work may facilitate the development of an\ninexpensive, non-invasive, and rapid means of detecting and explaining\ncognitive decline.", "published": "2024-11-04 12:38:08", "link": "http://arxiv.org/abs/2411.02036v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Grounding Emotional Descriptions to Electrovibration Haptic Signals", "abstract": "Designing and displaying haptic signals with sensory and emotional attributes\ncan improve the user experience in various applications. Free-form user\nlanguage provides rich sensory and emotional information for haptic design\n(e.g., ``This signal feels smooth and exciting''), but little work exists on\nlinking user descriptions to haptic signals (i.e., language grounding). To\naddress this gap, we conducted a study where 12 users described the feel of 32\nsignals perceived on a surface haptics (i.e., electrovibration) display. We\ndeveloped a computational pipeline using natural language processing (NLP)\ntechniques, such as GPT-3.5 Turbo and word embedding methods, to extract\nsensory and emotional keywords and group them into semantic clusters (i.e.,\nconcepts). We linked the keyword clusters to haptic signal features (e.g.,\npulse count) using correlation analysis. The proposed pipeline demonstrates the\nviability of a computational approach to analyzing haptic experiences. We\ndiscuss our future plans for creating a predictive model of haptic experience.", "published": "2024-11-04 14:30:57", "link": "http://arxiv.org/abs/2411.02118v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "The Role of DevOps in Enhancing Enterprise Software Delivery Success\n  through R&D Efficiency and Source Code Management", "abstract": "This study examines the impact of DevOps practices on enterprise software\ndelivery success, focusing on enhancing R&D efficiency and source code\nmanagement (SCM). Using a qualitative methodology, data were collected from\ncase studies of large-scale enterprises implementing DevOps to explore how\nthese practices streamline software development processes. Findings reveal that\nDevOps significantly improves R&D productivity by fostering cross-functional\ncollaboration, reducing development cycle times, and enhancing software quality\nthrough effective SCM practices, such as version control and continuous\nintegration. Additionally, SCM tools within DevOps enable precise change\ntracking and reliable code maintenance, further supporting faster, more robust\nsoftware delivery. However, the study identifies challenges, including cultural\nresistance and tool integration issues, that can hinder DevOps implementation.\nAdditionally, This research contributes to the growing body of DevOps\nliterature by highlighting the role of R&D efficiency and SCM as crucial\nfactors for software delivery success. Future studies should investigate these\nfactors across diverse industries to validate findings.", "published": "2024-11-04 16:01:43", "link": "http://arxiv.org/abs/2411.02209v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated\n  Parameters by Tencent", "abstract": "In this paper, we introduce Hunyuan-Large, which is currently the largest\nopen-source Transformer-based mixture of experts model, with a total of 389\nbillion parameters and 52 billion activation parameters, capable of handling up\nto 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior\nperformance across various benchmarks including language understanding and\ngeneration, logical reasoning, mathematical problem-solving, coding,\nlong-context, and aggregated tasks, where it outperforms LLama3.1-70B and\nexhibits comparable performance when compared to the significantly larger\nLLama3.1-405B model. Key practice of Hunyuan-Large include large-scale\nsynthetic data that is orders larger than in previous literature, a mixed\nexpert routing strategy, a key-value cache compression technique, and an\nexpert-specific learning rate strategy. Additionally, we also investigate the\nscaling laws and learning rate schedule of mixture of experts models, providing\nvaluable insights and guidances for future model development and optimization.\nThe code and checkpoints of Hunyuan-Large are released to facilitate future\ninnovations and applications.\n  Codes: https://github.com/Tencent/Hunyuan-Large\n  Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large", "published": "2024-11-04 16:56:26", "link": "http://arxiv.org/abs/2411.02265v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The LLM Language Network: A Neuroscientific Approach for Identifying\n  Causally Task-Relevant Units", "abstract": "Large language models (LLMs) exhibit remarkable capabilities on not just\nlanguage tasks, but also various tasks that are not linguistic in nature, such\nas logical reasoning and social inference. In the human brain, neuroscience has\nidentified a core language system that selectively and causally supports\nlanguage processing. We here ask whether similar specialization for language\nemerges in LLMs. We identify language-selective units within 18 popular LLMs,\nusing the same localization approach that is used in neuroscience. We then\nestablish the causal role of these units by demonstrating that ablating LLM\nlanguage-selective units -- but not random units -- leads to drastic deficits\nin language tasks. Correspondingly, language-selective LLM units are more\naligned to brain recordings from the human language system than random units.\nFinally, we investigate whether our localization method extends to other\ncognitive domains: while we find specialized networks in some LLMs for\nreasoning and social capabilities, there are substantial differences among\nmodels. These findings provide functional and causal evidence for\nspecialization in large language models, and highlight parallels with the\nfunctional organization in the brain.", "published": "2024-11-04 17:09:10", "link": "http://arxiv.org/abs/2411.02280v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CRMArena: Understanding the Capacity of LLM Agents to Perform\n  Professional CRM Tasks in Realistic Environments", "abstract": "Customer Relationship Management (CRM) systems are vital for modern\nenterprises, providing a foundation for managing customer interactions and\ndata. Integrating AI agents into CRM systems can automate routine processes and\nenhance personalized service. However, deploying and evaluating these agents is\nchallenging due to the lack of realistic benchmarks that reflect the complexity\nof real-world CRM tasks. To address this issue, we introduce CRMArena, a novel\nbenchmark designed to evaluate AI agents on realistic tasks grounded in\nprofessional work environments. Following guidance from CRM experts and\nindustry best practices, we designed CRMArena with nine customer service tasks\ndistributed across three personas: service agent, analyst, and manager. The\nbenchmark includes 16 commonly used industrial objects (e.g., account, order,\nknowledge article, case) with high interconnectivity, along with latent\nvariables (e.g., complaint habits, policy violations) to simulate realistic\ndata distributions. Experimental results reveal that state-of-the-art LLM\nagents succeed in less than 40% of the tasks with ReAct prompting, and less\nthan 55% even with function-calling abilities. Our findings highlight the need\nfor enhanced agent capabilities in function-calling and rule-following to be\ndeployed in real-world work environments. CRMArena is an open challenge to the\ncommunity: systems that can reliably complete tasks showcase direct business\nvalue in a popular work environment.", "published": "2024-11-04 17:30:51", "link": "http://arxiv.org/abs/2411.02305v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Creative Short Story Generation in Humans and Large Language\n  Models", "abstract": "Story-writing is a fundamental aspect of human imagination, relying heavily\non creativity to produce narratives that are novel, effective, and surprising.\nWhile large language models (LLMs) have demonstrated the ability to generate\nhigh-quality stories, their creative story-writing capabilities remain\nunder-explored. In this work, we conduct a systematic analysis of creativity in\nshort story generation across 60 LLMs and 60 people using a five-sentence\ncreative story-writing task. We use measures to automatically evaluate model-\nand human-generated stories across several dimensions of creativity, including\nnovelty, surprise, diversity, and linguistic complexity. We also collect\ncreativity ratings and Turing Test classifications from non-expert and expert\nhuman raters and LLMs. Automated metrics show that LLMs generate stylistically\ncomplex stories, but tend to fall short in terms of novelty, surprise and\ndiversity when compared to average human writers. Expert ratings generally\ncoincide with automated metrics. However, LLMs and non-experts rate LLM stories\nto be more creative than human-generated stories. We discuss why and how these\ndifferences in ratings occur, and their implications for both human and\nartificial creativity.", "published": "2024-11-04 17:40:39", "link": "http://arxiv.org/abs/2411.02316v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Seq-VCR: Preventing Collapse in Intermediate Transformer Representations\n  for Enhanced Reasoning", "abstract": "Decoder-only Transformers often struggle with complex reasoning tasks,\nparticularly arithmetic reasoning requiring multiple sequential operations. In\nthis work, we identify representation collapse in the model's intermediate\nlayers as a key factor limiting their reasoning capabilities. To address this,\nwe propose Sequential Variance-Covariance Regularization (Seq-VCR), which\nenhances the entropy of intermediate representations and prevents collapse.\nCombined with dummy pause tokens as substitutes for chain-of-thought (CoT)\ntokens, our method significantly improves performance in arithmetic reasoning\nproblems. In the challenging $5 \\times 5$ integer multiplication task, our\napproach achieves $99.5\\%$ exact match accuracy, outperforming models of the\nsame size (which yield $0\\%$ accuracy) and GPT-4 with five-shot CoT prompting\n($44\\%$). We also demonstrate superior results on arithmetic expression and\nlongest increasing subsequence (LIS) datasets. Our findings highlight the\nimportance of preventing intermediate layer representation collapse to enhance\nthe reasoning capabilities of Transformers and show that Seq-VCR offers an\neffective solution without requiring explicit CoT supervision.", "published": "2024-11-04 18:14:07", "link": "http://arxiv.org/abs/2411.02344v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Improving Scientific Hypothesis Generation with Knowledge Grounded Large\n  Language Models", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious scientific domains, from natural language processing to complex\nproblem-solving tasks. Their ability to understand and generate human-like text\nhas opened up new possibilities for advancing scientific research, enabling\ntasks such as data analysis, literature review, and even experimental design.\nOne of the most promising applications of LLMs in this context is hypothesis\ngeneration, where they can identify novel research directions by analyzing\nexisting knowledge. However, despite their potential, LLMs are prone to\ngenerating ``hallucinations'', outputs that are plausible-sounding but\nfactually incorrect. Such a problem presents significant challenges in\nscientific fields that demand rigorous accuracy and verifiability, potentially\nleading to erroneous or misleading conclusions. To overcome these challenges,\nwe propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that\nenhances LLM hypothesis generation by integrating external, structured\nknowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured\nreasoning process, organizing their output as a chain of ideas (CoI), and\nincludes a KG-supported module for the detection of hallucinations. With\nexperiments on our newly constructed hypothesis generation dataset, we\ndemonstrate that KG-CoI not only improves the accuracy of LLM-generated\nhypotheses but also reduces the hallucination in their reasoning chains,\nhighlighting its effectiveness in advancing real-world scientific research.", "published": "2024-11-04 18:50:00", "link": "http://arxiv.org/abs/2411.02382v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-Task Role-Playing Agent Capable of Imitating Character\n  Linguistic Styles", "abstract": "The advent of large language models (LLMs) has significantly propelled the\nadvancement of Role-Playing Agents (RPAs). However, current Role-Playing Agents\npredominantly focus on mimicking a character's fundamental attributes while\nneglecting the replication of linguistic style, and they are incapable of\neffectively replicating characters when performing tasks beyond multi-turn\ndialogues, which results in generated responses that lack authenticity. The\nreason current RPAs lack this capability is due to the nature of existing\ncharacter datasets, which lack collections of character quotations and are\nlimited to multi-turn dialogue tasks, constraining the RPA's performance across\nother task domains and failing to mimic a character's linguistic style. To\naddress this gap, we developed a multi-task role-playing dataset named MRstyle,\nwhich encompasses a substantial number of real individuals along with their\nquotations and covers seven different tasks. On this basis, we develop\nStyleRPA, a Multi-Task Role-Playing Agent (MRPA) that significantly outperforms\nrecent open-source LLMs and RPAs baselines on 7 tasks including Dialogue,\nDictionary, Composition, Story Generation, Product Description, Music\nCommentary, and Open Question Answering. The code and data will be released.", "published": "2024-11-04 02:26:27", "link": "http://arxiv.org/abs/2411.02457v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Multiple Dimensions of Trustworthiness in LLMs via Sparse\n  Activation Control", "abstract": "As the development and application of Large Language Models (LLMs) continue\nto advance rapidly, enhancing their trustworthiness and aligning them with\nhuman preferences has become a critical area of research. Traditional methods\nrely heavily on extensive data for Reinforcement Learning from Human Feedback\n(RLHF), but representation engineering offers a new, training-free approach.\nThis technique leverages semantic features to control the representation of\nLLM's intermediate hidden states, enabling the model to meet specific\nrequirements such as increased honesty or heightened safety awareness. However,\na significant challenge arises when attempting to fulfill multiple requirements\nsimultaneously. It proves difficult to encode various semantic contents, like\nhonesty and safety, into a singular semantic feature, restricting its\npracticality. In this work, we address this issue through ``Sparse Activation\nControl''. By delving into the intrinsic mechanisms of LLMs, we manage to\nidentify and pinpoint components that are closely related to specific tasks\nwithin the model, i.e., attention heads. These heads display sparse\ncharacteristics that allow for near-independent control over different tasks.\nOur experiments, conducted on the open-source Llama series models, have yielded\nencouraging results. The models were able to align with human preferences on\nissues of safety, factuality, and bias concurrently.", "published": "2024-11-04 08:36:03", "link": "http://arxiv.org/abs/2411.02461v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Instruction Fine-Tuning LLMs for Financial\n  Text Classification", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\ndiverse Natural Language Processing (NLP) tasks, including language\nunderstanding, reasoning, and generation. However, general-domain LLMs often\nstruggle with financial tasks due to the technical and specialized nature of\nfinancial texts. This study investigates the efficacy of instruction\nfine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini,\nto enhance their performance in financial text classification tasks. We\nfine-tuned both instruction-tuned and base models across four financial\nclassification tasks, achieving significant improvements in task-specific\nperformance. Furthermore, we evaluated the zero-shot capabilities of these\nfine-tuned models on three unseen complex financial tasks, including argument\nclassification, deal completeness classification, and causal classification.\nOur results indicate while base model fine-tuning led to greater degradation,\ninstruction-tuned models maintained more robust performance. To address this\ndegradation, we employed model merging techniques, integrating single-task\ndomain-specific fine-tuned models with the base model. Using this merging\nmethod resulted in significant enhancements in zero-shot performance, even\nexceeding the original model's accuracy on certain datasets. Our findings\nunderscore the effectiveness of instruction fine-tuning and model merging for\nadapting LLMs to specialized financial text classification tasks.", "published": "2024-11-04 18:06:36", "link": "http://arxiv.org/abs/2411.02476v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dr. SoW: Density Ratio of Strong-over-weak LLMs for Reducing the Cost of\n  Human Annotation in Preference Tuning", "abstract": "Preference tuning relies on high-quality human preference data, which is\noften expensive and time-consuming to gather. In this paper, we introduce\nDr.SoW (Density Ratio of Strong over Weak) a cost-effective method that\neliminates the reliance for human annotation by leveraging off-the-shelf LLMs\nfor preference data annotation. Dr.SoW uses the log-density ratio between a\nbetter-aligned and a less-aligned LLM as a reward signal. We evaluate Dr.SoW\nacross 221 different LLM pairs and empirically find a strong correlation\nbetween the performance gap of the paired models and the quality of the reward\nsignal. This insight provides a practical guideline for selecting LLMs for data\nannotation.\n  Additionally, we introduce an end-to-end pipeline that customizes reward\nfunctions based on user query domains. Without fine-tuning, it improves\naccuracy on domain-specific evaluations. With a pair of Mistral-7B models,\nDr.SoW achieves a RewardBench score of 82.6, outperforming the best trained\nreward functions from same model class and demonstrating competitive\nperformance against SoTA models in Safety (91.0) and Reasoning (88.0) domains.\nFurther, we preference-tune Llama-3-8B-Instruct using data annotated by Dr.SoW.\nOur approach pushes Llama-3-8B to achieve a 37.4 % (+15.1 %) win rate on\nArenaHard and a 40.7 % (+17.8 %) win rate on length-controlled AlpacaEval 2.0.", "published": "2024-11-04 18:54:39", "link": "http://arxiv.org/abs/2411.02481v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Leveraging News Media to Support Impact Assessment of AI\n  Technologies", "abstract": "Expert-driven frameworks for impact assessments (IAs) may inadvertently\noverlook the effects of AI technologies on the public's social behavior,\npolicy, and the cultural and geographical contexts shaping the perception of AI\nand the impacts around its use. This research explores the potentials of\nfine-tuning LLMs on negative impacts of AI reported in a diverse sample of\narticles from 266 news domains spanning 30 countries around the world to\nincorporate more diversity into IAs. Our findings highlight (1) the potential\nof fine-tuned open-source LLMs in supporting IA of AI technologies by\ngenerating high-quality negative impacts across four qualitative dimensions:\ncoherence, structure, relevance, and plausibility, and (2) the efficacy of\nsmall open-source LLM (Mistral-7B) fine-tuned on impacts from news media in\ncapturing a wider range of categories of impacts that GPT-4 had gaps in\ncovering.", "published": "2024-11-04 19:12:27", "link": "http://arxiv.org/abs/2411.02536v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TripletCLIP: Improving Compositional Reasoning of CLIP via Synthetic\n  Vision-Language Negatives", "abstract": "Contrastive Language-Image Pretraining (CLIP) models maximize the mutual\ninformation between text and visual modalities to learn representations. This\nmakes the nature of the training data a significant factor in the efficacy of\nCLIP for downstream tasks. However, the lack of compositional diversity in\ncontemporary image-text datasets limits the compositional reasoning ability of\nCLIP. We show that generating ``hard'' negative captions via in-context\nlearning and synthesizing corresponding negative images with text-to-image\ngenerators offers a solution. We introduce a novel contrastive pre-training\nstrategy that leverages these hard negative captions and images in an\nalternating fashion to train CLIP. We demonstrate that our method, named\nTripletCLIP, when applied to existing datasets such as CC3M and CC12M, enhances\nthe compositional capabilities of CLIP, resulting in an absolute improvement of\nover 9% on the SugarCrepe benchmark on an equal computational budget, as well\nas improvements in zero-shot image classification and image retrieval. Our\ncode, models, and data are available at: https://tripletclip.github.io", "published": "2024-11-04 19:24:59", "link": "http://arxiv.org/abs/2411.02545v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Investigating Idiomaticity in Word Representations", "abstract": "Idiomatic expressions are an integral part of human languages, often used to\nexpress complex ideas in compressed or conventional ways (e.g. eager beaver as\na keen and enthusiastic person). However, their interpretations may not be\nstraightforwardly linked to the meanings of their individual components in\nisolation and this may have an impact for compositional approaches. In this\npaper, we investigate to what extent word representation models are able to go\nbeyond compositional word combinations and capture multiword expression\nidiomaticity and some of the expected properties related to idiomatic meanings.\nWe focus on noun compounds of varying levels of idiomaticity in two languages\n(English and Portuguese), presenting a dataset of minimal pairs containing\nhuman idiomaticity judgments for each noun compound at both type and token\nlevels, their paraphrases and their occurrences in naturalistic and\nsense-neutral contexts, totalling 32,200 sentences. We propose this set of\nminimal pairs for evaluating how well a model captures idiomatic meanings, and\ndefine a set of fine-grained metrics of Affinity and Scaled Similarity, to\ndetermine how sensitive the models are to perturbations that may lead to\nchanges in idiomaticity. The results obtained with a variety of representative\nand widely used models indicate that, despite superficial indications to the\ncontrary in the form of high similarities, idiomaticity is not yet accurately\nrepresented in current models. Moreover, the performance of models with\ndifferent levels of contextualisation suggests that their ability to capture\ncontext is not yet able to go beyond more superficial lexical clues provided by\nthe words and to actually incorporate the relevant semantic clues needed for\nidiomaticity.", "published": "2024-11-04 21:05:01", "link": "http://arxiv.org/abs/2411.02610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Counterfactual Explanation Methods for Text\n  Classifiers", "abstract": "Counterfactual explanations can be used to interpret and debug text\nclassifiers by producing minimally altered text inputs that change a\nclassifier's output. In this work, we evaluate five methods for generating\ncounterfactual explanations for a BERT text classifier on two datasets using\nthree evaluation metrics. The results of our experiments suggest that\nestablished white-box substitution-based methods are effective at generating\nvalid counterfactuals that change the classifier's output. In contrast, newer\nmethods based on large language models (LLMs) excel at producing natural and\nlinguistically plausible text counterfactuals but often fail to generate valid\ncounterfactuals that alter the classifier's output. Based on these results, we\nrecommend developing new counterfactual explanation methods that combine the\nstrengths of established gradient-based approaches and newer LLM-based\ntechniques to generate high-quality, valid, and plausible text counterfactual\nexplanations.", "published": "2024-11-04 22:01:52", "link": "http://arxiv.org/abs/2411.02643v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Wave Network: An Ultra-Small Language Model", "abstract": "We propose an innovative token representation and update method in a new\nultra-small language model: the Wave network. Specifically, we use a complex\nvector to represent each token, encoding both global and local semantics of the\ninput text. A complex vector consists of two components: a magnitude vector\nrepresenting the global semantics of the input text, and a phase vector\ncapturing the relationships between individual tokens and global semantics.\nExperiments on the AG News text classification task demonstrate that, when\ngenerating complex vectors from randomly initialized token embeddings, our\nsingle-layer Wave Network achieves 90.91% accuracy with wave interference and\n91.66% with wave modulation - outperforming a single Transformer layer using\nBERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching\nthe accuracy of the pre-trained and fine-tuned BERT base model (94.64%).\nAdditionally, compared to BERT base, the Wave Network reduces video memory\nusage and training time by 77.34% and 85.62% during wave modulation. In\nsummary, we used a 2.4-million-parameter small language model to achieve\naccuracy comparable to a 100-million-parameter BERT model in text\nclassification.", "published": "2024-11-04 23:21:12", "link": "http://arxiv.org/abs/2411.02674v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QCG-Rerank: Chunks Graph Rerank with Query Expansion in\n  Retrieval-Augmented LLMs for Tourism Domain", "abstract": "Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in\nLarge Language Models (LLMs) by integrating information retrieval techniques.\nHowever, in the tourism domain, since the query is usually brief and the\ncontent in the database is diverse, existing RAG may contain a significant\namount of irrelevant or contradictory information contents after retrieval. To\naddress this challenge, we propose the QCG-Rerank model. This model first\nperforms an initial retrieval to obtain candidate chunks and then enhances\nsemantics by extracting critical information to expand the original query.\nNext, we utilize the expanded query and candidate chunks to calculate\nsimilarity scores as the initial transition probability and construct the\nchunks graph. Subsequently, We iteratively compute the transition probabilities\nbased on an initial estimate until convergence. The chunks with the highest\nscore are selected and input into the LLMs to generate responses. We evaluate\nthe model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.\nThe experimental results demonstrate the effectiveness and superiority of the\nQCG-Rerank method.", "published": "2024-11-04 08:15:22", "link": "http://arxiv.org/abs/2411.08724v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task", "abstract": "The advent of Large Language Models (LLMs) have shown promise in various\ncreative domains, including culinary arts. However, many LLMs still struggle to\ndeliver the desired level of culinary creativity, especially when tasked with\nadapting recipes to meet specific cultural requirements. This study focuses on\ncuisine transfer-applying elements of one cuisine to another-to assess LLMs'\nculinary creativity. We employ a diverse set of LLMs to generate and evaluate\nculturally adapted recipes, comparing their evaluations against LLM and human\njudgments. We introduce the ASH (authenticity, sensitivity, harmony) benchmark\nto evaluate LLMs' recipe generation abilities in the cuisine transfer task,\nassessing their cultural accuracy and creativity in the culinary domain. Our\nfindings reveal crucial insights into both generative and evaluative\ncapabilities of LLMs in the culinary domain, highlighting strengths and\nlimitations in understanding and applying cultural nuances in recipe creation.\nThe code and dataset used in this project will be openly available in\n\\url{http://github.com/dmis-lab/CulinaryASH}.", "published": "2024-11-04 11:31:18", "link": "http://arxiv.org/abs/2411.01996v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scalable Efficient Training of Large Language Models with\n  Low-dimensional Projected Attention", "abstract": "Improving the effectiveness and efficiency of large language models (LLMs)\nsimultaneously is a critical yet challenging research goal. In this paper, we\nfind that low-rank pre-training, normally considered as efficient methods that\nwill compromise performance, can be scalably effective when reduced parameters\nare precisely targeted. Specifically, applying the low-dimensional module only\nto the attention layer -- resolves this issue and enhances both effectiveness\nand efficiency. We refer to this structure as Low-dimensional Projected\nAttention (LPA) and provide an explanatory analysis. Through extensive\nexperimentation at parameter scales of 130M, 370M, and scaling up to 3B, we\nhave validated the effectiveness and scalability of LPA. Our results show that\nLPA model can save up to 12.4% in time while achieving an approximate 5%\nimprovement in test perplexity (ppl) and on downstream tasks compared with the\nvanilla Transformer.", "published": "2024-11-04 13:06:17", "link": "http://arxiv.org/abs/2411.02063v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Regress, Don't Guess -- A Regression-like Loss on Number Tokens for\n  Language Models", "abstract": "While language models have exceptional capabilities at text generation, they\nlack a natural inductive bias for emitting numbers and thus struggle in tasks\ninvolving reasoning over quantities, especially arithmetics. This has\nparticular relevance in scientific datasets where combinations of text and\nnumerical data are abundant. One fundamental limitation is the nature of the CE\nloss, which assumes a nominal (categorical) scale and thus cannot convey\nproximity between generated number tokens. As a remedy, we here present two\nversions of a number token loss. The first is based on an $L_p$ loss between\nthe ground truth token value and the weighted sum of the predicted class\nprobabilities. The second loss minimizes the Wasserstein-1 distance between the\ndistribution of the predicted output probabilities and the ground truth\ndistribution. These regression-like losses can easily be added to any language\nmodel and extend the CE objective during training. We compare the proposed\nschemes on a mathematics dataset against existing tokenization, encoding, and\ndecoding schemes for improving number representation in language models. Our\nresults reveal a significant improvement in numerical accuracy when equipping a\nstandard T5 model with the proposed loss schemes.", "published": "2024-11-04 13:43:24", "link": "http://arxiv.org/abs/2411.02083v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Advancements and limitations of LLMs in replicating human color-word\n  associations", "abstract": "Color-word associations play a fundamental role in human cognition and design\napplications. Large Language Models (LLMs) have become widely available and\ndemonstrated intelligent behaviors in various benchmarks with natural\nconversation skills. However, their ability to replicate human color-word\nassociations remains understudied. We compared multiple generations of LLMs\n(from GPT-3 to GPT-4o) against human color-word associations using data\ncollected from over 10,000 Japanese participants, involving 17 colors and words\nfrom eight categories in Japanese. Our findings reveal a clear progression in\nLLM performance across generations, with GPT-4o achieving the highest accuracy\nin predicting the best voted word for each color and category. However, the\nhighest median performance was approximately 50% even for GPT-4o with visual\ninputs (chance level is 10%), and the performance levels varied significantly\nacross word categories and colors, indicating a failure to fully replicate\nhuman color-word associations. On the other hand, color discrimination ability\nestimated from our color-word association data showed that LLMs demonstrated\nhigh correlation with human color discrimination patterns, similarly to\nprevious studies. Our study highlights both the advancements in LLM\ncapabilities and their persistent limitations, suggesting differences in\nsemantic memory structures between humans and LLMs in representing color-word\nassociations.", "published": "2024-11-04 14:29:28", "link": "http://arxiv.org/abs/2411.02116v2", "categories": ["cs.CL", "cs.CV", "cs.GR", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Improving Steering Vectors by Targeting Sparse Autoencoder Features", "abstract": "To control the behavior of language models, steering methods attempt to\nensure that outputs of the model satisfy specific pre-defined properties.\nAdding steering vectors to the model is a promising method of model control\nthat is easier than finetuning, and may be more robust than prompting. However,\nit can be difficult to anticipate the effects of steering vectors produced by\nmethods such as CAA [Panickssery et al., 2024] or the direct use of SAE latents\n[Templeton et al., 2024]. In our work, we address this issue by using SAEs to\nmeasure the effects of steering vectors, giving us a method that can be used to\nunderstand the causal effect of any steering vector intervention. We use this\nmethod for measuring causal effects to develop an improved steering method,\nSAE-Targeted Steering (SAE-TS), which finds steering vectors to target specific\nSAE features while minimizing unintended side effects. We show that overall,\nSAE-TS balances steering effects with coherence better than CAA and SAE feature\nsteering, when evaluated on a range of tasks.", "published": "2024-11-04 15:46:20", "link": "http://arxiv.org/abs/2411.02193v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Positive Experience Reflection for Agents in Interactive Text\n  Environments", "abstract": "Intelligent agents designed for interactive environments face significant\nchallenges in text-based games, a domain that demands complex reasoning and\nadaptability. While agents based on large language models (LLMs) using\nself-reflection have shown promise, they struggle when initially successful and\nexhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&Sour,\na novel approach that addresses these limitations in existing reflection\nmethods by incorporating positive experiences and managed memory to enrich the\ncontext available to the agent at decision time. Our comprehensive analysis\nspans both closed- and open-source LLMs and demonstrates the effectiveness of\nSweet&Sour in improving agent performance, particularly in scenarios where\nprevious approaches fall short.", "published": "2024-11-04 16:15:28", "link": "http://arxiv.org/abs/2411.02223v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Combining Induction and Transduction for Abstract Reasoning", "abstract": "When learning an input-output mapping from very few examples, is it better to\nfirst infer a latent function that explains the examples, or is it better to\ndirectly predict new test outputs, e.g. using a neural network? We study this\nquestion on ARC by training neural models for induction (inferring latent\nfunctions) and transduction (directly predicting the test output for a given\ntest input). We train on synthetically generated variations of Python programs\nthat solve ARC training tasks. We find inductive and transductive models solve\ndifferent kinds of test problems, despite having the same training problems and\nsharing the same neural architecture: Inductive program synthesis excels at\nprecise computations, and at composing multiple concepts, while transduction\nsucceeds on fuzzier perceptual concepts. Ensembling them approaches human-level\nperformance on ARC.", "published": "2024-11-04 17:03:55", "link": "http://arxiv.org/abs/2411.02272v4", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sparsing Law: Towards Large Language Models with Greater Activation\n  Sparsity", "abstract": "Activation sparsity denotes the existence of substantial weakly-contributed\nelements within activation outputs that can be eliminated, benefiting many\nimportant applications concerned with large language models (LLMs). Although\npromoting greater activation sparsity within LLMs deserves deep studies,\nexisting works lack comprehensive and quantitative research on the correlation\nbetween activation sparsity and potentially influential factors. In this paper,\nwe present a comprehensive study on the quantitative scaling properties and\ninfluential factors of the activation sparsity within decoder-only\nTransformer-based LLMs. Specifically, we propose PPL-$p\\%$ sparsity, a precise\nand performance-aware activation sparsity metric that is applicable to any\nactivation function. Through extensive experiments, we find several important\nphenomena. Firstly, different activation functions exhibit comparable\nperformance but opposite training-time sparsity trends. The activation ratio\n(i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing\npower-law and decreasing logspace power-law with the amount of training data\nfor SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate\nthat ReLU is more efficient as the activation function than SiLU and can\nleverage more training data to improve activation sparsity. Secondly, the\nactivation ratio linearly increases with the width-depth ratio below a certain\nbottleneck point, indicating the potential advantage of a deeper architecture\nat a fixed parameter scale. Finally, at similar width-depth ratios, we\nsurprisingly find that the limit value of activation sparsity varies weakly\nwith the parameter scale, i.e., the activation patterns within LLMs are\ninsensitive to the parameter scale. These empirical laws towards LLMs with\ngreater activation sparsity have important implications for making LLMs more\nefficient and interpretable.", "published": "2024-11-04 17:59:04", "link": "http://arxiv.org/abs/2411.02335v2", "categories": ["cs.LG", "cs.CL", "stat.ML", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Can Large Language Models generalize analogy solving like people can?", "abstract": "When we solve an analogy we transfer information from a known context to a\nnew one through abstract rules and relational similarity. In people, the\nability to solve analogies such as \"body : feet :: table : ?\" emerges in\nchildhood, and appears to transfer easily to other domains, such as the visual\ndomain \"( : ) :: < : ?\". Recent research shows that large language models\n(LLMs) can solve various forms of analogies. However, can LLMs generalize\nanalogy solving to new domains like people can? To investigate this, we had\nchildren, adults, and LLMs solve a series of letter-string analogies (e.g., a b\n: a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek\nalphabet), and a far transfer domain (list of symbols). As expected, children\nand adults easily generalized their knowledge to unfamiliar domains, whereas\nLLMs did not. This key difference between human and AI performance is evidence\nthat these LLMs still struggle with robust human-like analogical transfer.", "published": "2024-11-04 18:18:38", "link": "http://arxiv.org/abs/2411.02348v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin\n  Script Languages", "abstract": "Although multilingual LLMs have achieved remarkable performance across\nbenchmarks, we find they continue to underperform on non-Latin script languages\nacross contemporary LLM families. This discrepancy arises from the fact that\nLLMs are pretrained with orthographic scripts, which are dominated by Latin\ncharacters that obscure their shared phonology with non-Latin scripts. We\npropose leveraging phonemic transcriptions as complementary signals to induce\nscript-invariant representations. Our study demonstrates that integrating\nphonemic signals improves performance across both non-Latin and Latin script\nlanguages, with a particularly significant impact on closing the performance\ngap between the two. Through detailed experiments, we show that phonemic and\northographic scripts retrieve distinct examples for in-context learning (ICL).\nThis motivates our proposed Mixed-ICL retrieval strategy, where further\naggregation from both leads to our significant performance improvements for\nboth Latin script languages (up to 12.6%) and non-Latin script languages (up to\n15.1%) compared to randomized ICL retrieval.", "published": "2024-11-04 18:59:51", "link": "http://arxiv.org/abs/2411.02398v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Code-Switching Curriculum Learning for Multilingual Transfer in LLMs", "abstract": "Large language models (LLMs) now exhibit near human-level performance in\nvarious tasks, but their performance drops drastically after a handful of\nhigh-resource languages due to the imbalance in pre-training data. Inspired by\nthe human process of second language acquisition, particularly code-switching\n(the practice of language alternation in a conversation), we propose\ncode-switching curriculum learning (CSCL) to enhance cross-lingual transfer for\nLLMs. CSCL mimics the stages of human language learning by progressively\ntraining models with a curriculum consisting of 1) token-level code-switching,\n2) sentence-level code-switching, and 3) monolingual corpora. Using Qwen 2 as\nour underlying model, we demonstrate the efficacy of the CSCL in improving\nlanguage transfer to Korean, achieving significant performance gains compared\nto monolingual continual pre-training methods. Ablation studies reveal that\nboth token- and sentence-level code-switching significantly enhance\ncross-lingual transfer and that curriculum learning amplifies these effects. We\nalso extend our findings into various languages, including Japanese\n(high-resource) and Indonesian (low-resource), and using two additional models\n(Gemma 2 and Phi 3.5). We further show that CSCL mitigates spurious\ncorrelations between language resources and safety alignment, presenting a\nrobust, efficient framework for more equitable language transfer in LLMs. We\nobserve that CSCL is effective for low-resource settings where high-quality,\nmonolingual corpora for language transfer are hardly available.", "published": "2024-11-04 06:31:26", "link": "http://arxiv.org/abs/2411.02460v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "INQUIRE: A Natural World Text-to-Image Retrieval Benchmark", "abstract": "We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io", "published": "2024-11-04 19:16:53", "link": "http://arxiv.org/abs/2411.02537v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Social Support Detection from Social Media Texts", "abstract": "Social support, conveyed through a multitude of interactions and platforms\nsuch as social media, plays a pivotal role in fostering a sense of belonging,\naiding resilience in the face of challenges, and enhancing overall well-being.\nThis paper introduces Social Support Detection (SSD) as a Natural language\nprocessing (NLP) task aimed at identifying supportive interactions within\nonline communities. The study presents the task of Social Support Detection\n(SSD) in three subtasks: two binary classification tasks and one multiclass\ntask, with labels detailed in the dataset section. We conducted experiments on\na dataset comprising 10,000 YouTube comments. Traditional machine learning\nmodels were employed, utilizing various feature combinations that encompass\nlinguistic, psycholinguistic, emotional, and sentiment information.\nAdditionally, we experimented with neural network-based models using various\nword embeddings to enhance the performance of our models across these\nsubtasks.The results reveal a prevalence of group-oriented support in online\ndialogues, reflecting broader societal patterns. The findings demonstrate the\neffectiveness of integrating psycholinguistic, emotional, and sentiment\nfeatures with n-grams in detecting social support and distinguishing whether it\nis directed toward an individual or a group. The best results for different\nsubtasks across all experiments range from 0.72 to 0.82.", "published": "2024-11-04 20:23:03", "link": "http://arxiv.org/abs/2411.02580v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"It's a conversation, not a quiz\": A Risk Taxonomy and Reflection Tool\n  for LLM Adoption in Public Health", "abstract": "Recent breakthroughs in large language models (LLMs) have generated both\ninterest and concern about their potential adoption as accessible information\nsources or communication tools across different domains. In public health --\nwhere stakes are high and impacts extend across populations -- adopting LLMs\nposes unique challenges that require thorough evaluation. However, structured\napproaches for assessing potential risks in public health remain\nunder-explored. To address this gap, we conducted focus groups with health\nprofessionals and health issue experiencers to unpack their concerns, situated\nacross three distinct and critical public health issues that demand\nhigh-quality information: vaccines, opioid use disorder, and intimate partner\nviolence. We synthesize participants' perspectives into a risk taxonomy,\ndistinguishing and contextualizing the potential harms LLMs may introduce when\npositioned alongside traditional health communication. This taxonomy highlights\nfour dimensions of risk in individual behaviors, human-centered care,\ninformation ecosystem, and technology accountability. For each dimension, we\ndiscuss specific risks and example reflection questions to help practitioners\nadopt a risk-reflexive approach. This work offers a shared vocabulary and\nreflection tool for experts in both computing and public health to\ncollaboratively anticipate, evaluate, and mitigate risks in deciding when to\nemploy LLM capabilities (or not) and how to mitigate harm when they are used.", "published": "2024-11-04 20:35:10", "link": "http://arxiv.org/abs/2411.02594v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "FactTest: Factuality Testing in Large Language Models with Finite-Sample\n  and Distribution-Free Guarantees", "abstract": "The propensity of Large Language Models (LLMs) to generate hallucinations and\nnon-factual content undermines their reliability in high-stakes domains, where\nrigorous control over Type I errors (the conditional probability of incorrectly\nclassifying hallucinations as truthful content) is essential. Despite its\nimportance, formal verification of LLM factuality with such guarantees remains\nlargely unexplored. In this paper, we introduce FactTest, a novel framework\nthat statistically assesses whether a LLM can confidently provide correct\nanswers to given questions with high-probability correctness guarantees. We\nformulate factuality testing as hypothesis testing problem to enforce an upper\nbound of Type I errors at user-specified significance levels. Notably, we prove\nthat our framework also ensures strong Type II error control under mild\nconditions and can be extended to maintain its effectiveness when covariate\nshifts exist. Our approach is distribution-free and works for any number of\nhuman-annotated samples. It is model-agnostic and applies to any black-box or\nwhite-box LM. Extensive experiments on question-answering (QA) and\nmultiple-choice benchmarks demonstrate that FactTest effectively detects\nhallucinations and improves the model's ability to abstain from answering\nunknown questions, leading to an over 40% accuracy improvement.", "published": "2024-11-04 20:53:04", "link": "http://arxiv.org/abs/2411.02603v3", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TeleOracle: Fine-Tuned Retrieval-Augmented Generation with Long-Context\n  Support for Network", "abstract": "The telecommunications industry's rapid evolution demands intelligent systems\ncapable of managing complex networks and adapting to emerging technologies.\nWhile large language models (LLMs) show promise in addressing these challenges,\ntheir deployment in telecom environments faces significant constraints due to\nedge device limitations and inconsistent documentation. To bridge this gap, we\npresent TeleOracle, a telecom-specialized retrieval-augmented generation (RAG)\nsystem built on the Phi-2 small language model (SLM). To improve context\nretrieval, TeleOracle employs a two-stage retriever that incorporates semantic\nchunking and hybrid keyword and semantic search. Additionally, we expand the\ncontext window during inference to enhance the model's performance on\nopen-ended queries. We also employ low-rank adaption for efficient fine-tuning.\nA thorough analysis of the model's performance indicates that our RAG framework\nis effective in aligning Phi-2 to the telecom domain in a downstream question\nand answer (QnA) task, achieving a 30% improvement in accuracy over the base\nPhi-2 model, reaching an overall accuracy of 81.20%. Notably, we show that our\nmodel not only performs on par with the much larger LLMs but also achieves a\nhigher faithfulness score, indicating higher adherence to the retrieved\ncontext.", "published": "2024-11-04 21:12:08", "link": "http://arxiv.org/abs/2411.02617v1", "categories": ["cs.CL", "cs.LG", "cs.NI"], "primary_category": "cs.CL"}
{"title": "Extracting Unlearned Information from LLMs with Activation Steering", "abstract": "An unintended consequence of the vast pretraining of Large Language Models\n(LLMs) is the verbatim memorization of fragments of their training data, which\nmay contain sensitive or copyrighted information. In recent years, unlearning\nhas emerged as a solution to effectively remove sensitive knowledge from models\nafter training. Yet, recent work has shown that supposedly deleted information\ncan still be extracted by malicious actors through various attacks. Still,\ncurrent attacks retrieve sets of possible candidate generations and are unable\nto pinpoint the output that contains the actual target information. We propose\nactivation steering as a method for exact information retrieval from unlearned\nLLMs. We introduce a novel approach to generating steering vectors, named\nAnonymized Activation Steering. Additionally, we develop a simple word\nfrequency method to pinpoint the correct answer among a set of candidates when\nretrieving unlearned information. Our evaluation across multiple unlearning\ntechniques and datasets demonstrates that activation steering successfully\nrecovers general knowledge (e.g., widely known fictional characters) while\nrevealing limitations in retrieving specific information (e.g., details about\nnon-public individuals). Overall, our results demonstrate that exact\ninformation retrieval from unlearned models is possible, highlighting a severe\nvulnerability of current unlearning techniques.", "published": "2024-11-04 21:42:56", "link": "http://arxiv.org/abs/2411.02631v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fair In-Context Learning via Latent Concept Variables", "abstract": "The emerging in-context learning (ICL) ability of large language models\n(LLMs) has prompted their use for predictive tasks in various domains with\ndifferent types of data facilitated by serialization methods. However, with\nincreasing applications in high-stakes domains, it has been shown that LLMs can\ninherit social bias and discrimination from their pre-training data. In this\nwork, we investigate this inherent bias in LLMs during in-context learning with\ntabular data. We focus on an optimal demonstration selection approach that\nutilizes latent concept variables for resource-efficient task adaptation. We\ndesign data augmentation strategies that reduce correlation between predictive\noutcomes and sensitive variables helping to promote fairness during latent\nconcept learning. We utilize the learned concept and select demonstrations from\na training dataset to obtain fair predictions during inference while\nmaintaining model utility. The latent concept variable is learned using a\nsmaller internal LLM and the selected demonstrations can be used for inference\nwith larger external LLMs. We empirically verify that the fair latent variable\napproach improves fairness results on tabular datasets compared to multiple\nheuristic demonstration selection methods.", "published": "2024-11-04 23:10:05", "link": "http://arxiv.org/abs/2411.02671v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RuAG: Learned-rule-augmented Generation for Large Language Models", "abstract": "In-context learning (ICL) and Retrieval-Augmented Generation (RAG) have\ngained attention for their ability to enhance LLMs' reasoning by incorporating\nexternal knowledge but suffer from limited contextual window size, leading to\ninsufficient information injection. To this end, we propose a novel framework,\nRuAG, to automatically distill large volumes of offline data into interpretable\nfirst-order logic rules, which are injected into LLMs to boost their reasoning\ncapabilities. Our method begins by formulating the search process relying on\nLLMs' commonsense, where LLMs automatically define head and body predicates.\nThen, RuAG applies Monte Carlo Tree Search (MCTS) to address the combinational\nsearching space and efficiently discover logic rules from data. The resulting\nlogic rules are translated into natural language, allowing targeted knowledge\ninjection and seamless integration into LLM prompts for LLM's downstream task\nreasoning. We evaluate our framework on public and private industrial tasks,\nincluding natural language processing, time-series, decision-making, and\nindustrial tasks, demonstrating its effectiveness in enhancing LLM's capability\nover diverse tasks.", "published": "2024-11-04 00:01:34", "link": "http://arxiv.org/abs/2411.03349v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Comprehensive Survey of Small Language Models in the Era of Large\n  Language Models: Techniques, Enhancements, Applications, Collaboration with\n  LLMs, and Trustworthiness", "abstract": "Large language models (LLMs) have demonstrated emergent abilities in text\ngeneration, question answering, and reasoning, facilitating various tasks and\ndomains. Despite their proficiency in various tasks, LLMs like PaLM 540B and\nLlama-3.1 405B face limitations due to large parameter sizes and computational\ndemands, often requiring cloud API use which raises privacy concerns, limits\nreal-time applications on edge devices, and increases fine-tuning costs.\nAdditionally, LLMs often underperform in specialized domains such as healthcare\nand law due to insufficient domain-specific knowledge, necessitating\nspecialized models. Therefore, Small Language Models (SLMs) are increasingly\nfavored for their low inference latency, cost-effectiveness, efficient\ndevelopment, and easy customization and adaptability. These models are\nparticularly well-suited for resource-limited environments and domain knowledge\nacquisition, addressing LLMs' challenges and proving ideal for applications\nthat require localized data handling for privacy, minimal inference latency for\nefficiency, and domain knowledge acquisition through lightweight fine-tuning.\nThe rising demand for SLMs has spurred extensive research and development.\nHowever, a comprehensive survey investigating issues related to the definition,\nacquisition, application, enhancement, and reliability of SLM remains lacking,\nprompting us to conduct a detailed survey on these topics. The definition of\nSLMs varies widely, thus to standardize, we propose defining SLMs by their\ncapability to perform specialized tasks and suitability for\nresource-constrained settings, setting boundaries based on the minimal size for\nemergent abilities and the maximum size sustainable under resource constraints.\nFor other aspects, we provide a taxonomy of relevant models/methods and develop\ngeneral frameworks for each category to enhance and utilize SLMs effectively.", "published": "2024-11-04 04:43:01", "link": "http://arxiv.org/abs/2411.03350v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50 (Primary) 68T07 (Secondary)", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Exploring Optimal Transport-Based Multi-Grained Alignments for\n  Text-Molecule Retrieval", "abstract": "The field of bioinformatics has seen significant progress, making the\ncross-modal text-molecule retrieval task increasingly vital. This task focuses\non accurately retrieving molecule structures based on textual descriptions, by\neffectively aligning textual descriptions and molecules to assist researchers\nin identifying suitable molecular candidates. However, many existing approaches\noverlook the details inherent in molecule sub-structures. In this work, we\nintroduce the Optimal TRansport-based Multi-grained Alignments model (ORMA), a\nnovel approach that facilitates multi-grained alignments between textual\ndescriptions and molecules. Our model features a text encoder and a molecule\nencoder. The text encoder processes textual descriptions to generate both\ntoken-level and sentence-level representations, while molecules are modeled as\nhierarchical heterogeneous graphs, encompassing atom, motif, and molecule nodes\nto extract representations at these three levels. A key innovation in ORMA is\nthe application of Optimal Transport (OT) to align tokens with motifs, creating\nmulti-token representations that integrate multiple token alignments with their\ncorresponding motifs. Additionally, we employ contrastive learning to refine\ncross-modal alignments at three distinct scales: token-atom, multitoken-motif,\nand sentence-molecule, ensuring that the similarities between correctly matched\ntext-molecule pairs are maximized while those of unmatched pairs are minimized.\nTo our knowledge, this is the first attempt to explore alignments at both the\nmotif and multi-token levels. Experimental results on the ChEBI-20 and PCdes\ndatasets demonstrate that ORMA significantly outperforms existing\nstate-of-the-art (SOTA) models.", "published": "2024-11-04 06:30:52", "link": "http://arxiv.org/abs/2411.11875v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "q-bio.BM"], "primary_category": "cs.IR"}
{"title": "MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs", "abstract": "State-of-the-art retrieval models typically address a straightforward search\nscenario, in which retrieval tasks are fixed (e.g., finding a passage to answer\na specific question) and only a single modality is supported for both queries\nand retrieved results. This paper introduces techniques for advancing\ninformation retrieval with multimodal large language models (MLLMs), enabling a\nbroader search scenario, termed universal multimodal retrieval, where multiple\nmodalities and diverse retrieval tasks are accommodated. To this end, we first\nstudy fine-tuning an MLLM as a bi-encoder retriever on 10 datasets with 16\nretrieval tasks. Our empirical results show that the fine-tuned MLLM retriever\nis capable of understanding challenging queries, composed of both text and\nimage, but it underperforms compared to a smaller CLIP retriever in cross-modal\nretrieval tasks due to the modality bias exhibited by MLLMs. To address the\nissue, we propose modality-aware hard negative mining to mitigate the modality\nbias exhibited by MLLM retrievers. Second, we propose continuously fine-tuning\nthe universal multimodal retriever to enhance its text retrieval capability\nwhile preserving multimodal retrieval capability. As a result, our model,\nMM-Embed, achieves state-of-the-art performance on the multimodal retrieval\nbenchmark M-BEIR, which spans multiple domains and tasks, while also surpassing\nthe state-of-the-art text retrieval model, NV-Embed-v1, on the MTEB retrieval\nbenchmark. We also explore prompting the off-the-shelf MLLMs as zero-shot\nrerankers to refine the ranking of the candidates from the multimodal\nretriever. We find that, through prompt-and-reranking, MLLMs can further\nimprove multimodal retrieval when the user queries (e.g., text-image composed\nqueries) are more complex and challenging to understand. These findings also\npave the way for advancing universal multimodal retrieval in the future.", "published": "2024-11-04 20:06:34", "link": "http://arxiv.org/abs/2411.02571v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vocal Sandbox: Continual Learning and Adaptation for Situated\n  Human-Robot Collaboration", "abstract": "We introduce Vocal Sandbox, a framework for enabling seamless human-robot\ncollaboration in situated environments. Systems in our framework are\ncharacterized by their ability to adapt and continually learn at multiple\nlevels of abstraction from diverse teaching modalities such as spoken dialogue,\nobject keypoints, and kinesthetic demonstrations. To enable such adaptation, we\ndesign lightweight and interpretable learning algorithms that allow users to\nbuild an understanding and co-adapt to a robot's capabilities in real-time, as\nthey teach new behaviors. For example, after demonstrating a new low-level\nskill for \"tracking around\" an object, users are provided with trajectory\nvisualizations of the robot's intended motion when asked to track a new object.\nSimilarly, users teach high-level planning behaviors through spoken dialogue,\nusing pretrained language models to synthesize behaviors such as \"packing an\nobject away\" as compositions of low-level skills $-$ concepts that can be\nreused and built upon. We evaluate Vocal Sandbox in two settings: collaborative\ngift bag assembly and LEGO stop-motion animation. In the first setting, we run\nsystematic ablations and user studies with 8 non-expert participants,\nhighlighting the impact of multi-level teaching. Across 23 hours of total robot\ninteraction time, users teach 17 new high-level behaviors with an average of 16\nnovel low-level skills, requiring 22.1% less active supervision compared to\nbaselines and yielding more complex autonomous performance (+19.7%) with fewer\nfailures (-67.1%). Qualitatively, users strongly prefer Vocal Sandbox systems\ndue to their ease of use (+20.6%) and overall performance (+13.9%). Finally, we\npair an experienced system-user with a robot to film a stop-motion animation;\nover two hours of continuous collaboration, the user teaches progressively more\ncomplex motion skills to shoot a 52 second (232 frame) movie.", "published": "2024-11-04 20:44:40", "link": "http://arxiv.org/abs/2411.02599v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Complete reconstruction of the tongue contour through acoustic to\n  articulatory inversion using real-time MRI data", "abstract": "Acoustic articulatory inversion is a major processing challenge, with a wide\nrange of applications from speech synthesis to feedback systems for language\nlearning and rehabilitation. In recent years, deep learning methods have been\napplied to the inversion of less than a dozen geometrical positions\ncorresponding to sensors glued to easily accessible articulators. It is\ntherefore impossible to know the shape of the whole tongue from root to tip. In\nthis work, we use high-quality real-time MRI data to track the contour of the\ntongue. The data used to drive the inversion are therefore the unstructured\nspeech signal and the tongue contours. Several architectures relying on a\nBi-MSTM including or not an autoencoder to reduce the dimensionality of the\nlatent space, using or not the phonetic segmentation have been explored. The\nresults show that the tongue contour can be recovered with a median accuracy of\n2.21 mm (or 1.37 pixel) taking a context of 1 MFCC frame (static, delta and\ndouble-delta cepstral features).", "published": "2024-11-04 12:38:10", "link": "http://arxiv.org/abs/2411.02037v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Joint Training of Speaker Embedding Extractor, Speech and Overlap\n  Detection for Diarization", "abstract": "In spite of the popularity of end-to-end diarization systems nowadays,\nmodular systems comprised of voice activity detection (VAD), speaker embedding\nextraction plus clustering, and overlapped speech detection (OSD) plus handling\nstill attain competitive performance in many conditions. However, one of the\nmain drawbacks of modular systems is the need to run (and train) different\nmodules independently. In this work, we propose an approach to jointly train a\nmodel to produce speaker embeddings, VAD and OSD simultaneously and reach\ncompetitive performance at a fraction of the inference time of a standard\napproach. Furthermore, the joint inference leads to a simplified overall\npipeline which brings us one step closer to a unified clustering-based method\nthat can be trained end-to-end towards a diarization-specific objective.", "published": "2024-11-04 15:23:37", "link": "http://arxiv.org/abs/2411.02165v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Estimating the Number and Locations of Boundaries in Reverberant\n  Environments with Deep Learning", "abstract": "Underwater acoustic environment estimation is a challenging but important\ntask for remote sensing scenarios. Current estimation methods require high\nsignal strength and a solution to the fragile echo labeling problem to be\neffective. In previous publications, we proposed a general deep learning-based\nmethod for two-dimensional environment estimation which outperformed the\nstate-of-the-art, both in simulation and in real-life experimental settings. A\nlimitation of this method was that some prior information had to be provided by\nthe user on the number and locations of the reflective boundaries, and that its\nneural networks had to be re-trained accordingly for different environments.\nUtilizing more advanced neural network and time delay estimation techniques,\nthe proposed improved method no longer requires prior knowledge the number of\nboundaries or their locations, and is able to estimate two-dimensional\nenvironments with one or two boundaries. Future work will extend the proposed\nmethod to more boundaries and larger-scale environments.", "published": "2024-11-04 21:03:22", "link": "http://arxiv.org/abs/2411.02609v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MoMu-Diffusion: On Learning Long-Term Motion-Music Synchronization and\n  Correspondence", "abstract": "Motion-to-music and music-to-motion have been studied separately, each\nattracting substantial research interest within their respective domains. The\ninteraction between human motion and music is a reflection of advanced human\nintelligence, and establishing a unified relationship between them is\nparticularly important. However, to date, there has been no work that considers\nthem jointly to explore the modality alignment within. To bridge this gap, we\npropose a novel framework, termed MoMu-Diffusion, for long-term and synchronous\nmotion-music generation. Firstly, to mitigate the huge computational costs\nraised by long sequences, we propose a novel Bidirectional Contrastive Rhythmic\nVariational Auto-Encoder (BiCoR-VAE) that extracts the modality-aligned latent\nrepresentations for both motion and music inputs. Subsequently, leveraging the\naligned latent spaces, we introduce a multi-modal Transformer-based diffusion\nmodel and a cross-guidance sampling strategy to enable various generation\ntasks, including cross-modal, multi-modal, and variable-length generation.\nExtensive experiments demonstrate that MoMu-Diffusion surpasses recent\nstate-of-the-art methods both qualitatively and quantitatively, and can\nsynthesize realistic, diverse, long-term, and beat-matched music or motion\nsequences. The generated samples and codes are available at\nhttps://momu-diffusion.github.io/", "published": "2024-11-04 05:17:44", "link": "http://arxiv.org/abs/2411.01805v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Modulating State Space Model with SlowFast Framework for\n  Compute-Efficient Ultra Low-Latency Speech Enhancement", "abstract": "Deep learning-based speech enhancement (SE) methods often face significant\ncomputational challenges when needing to meet low-latency requirements because\nof the increased number of frames to be processed. This paper introduces the\nSlowFast framework which aims to reduce computation costs specifically when\nlow-latency enhancement is needed. The framework consists of a slow branch that\nanalyzes the acoustic environment at a low frame rate, and a fast branch that\nperforms SE in the time domain at the needed higher frame rate to match the\nrequired latency. Specifically, the fast branch employs a state space model\nwhere its state transition process is dynamically modulated by the slow branch.\nExperiments on a SE task with a 2 ms algorithmic latency requirement using the\nVoice Bank + Demand dataset show that our approach reduces computation cost by\n70% compared to a baseline single-branch network with equivalent parameters,\nwithout compromising enhancement performance. Furthermore, by leveraging the\nSlowFast framework, we implemented a network that achieves an algorithmic\nlatency of just 62.5 {\\mu}s (one sample point at 16 kHz sample rate) with a\ncomputation cost of 100 M MACs/s, while scoring a PESQ-NB of 3.12 and SISNR of\n16.62.", "published": "2024-11-04 12:14:35", "link": "http://arxiv.org/abs/2411.02019v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre\n  Ensemble Modeling and Flow Matching", "abstract": "Zero-shot voice conversion (VC) aims to transform the timbre of a source\nspeaker into any previously unseen target speaker, while preserving the\noriginal linguistic content. Despite notable progress, attaining a degree of\nspeaker similarity and naturalness on par with ground truth recordings\ncontinues to pose great challenge. In this paper, we propose CTEFM-VC, a\nzero-shot VC framework that leverages Content-aware Timbre Ensemble modeling\nand Flow Matching. Specifically, CTEFM-VC disentangles utterances into\nlinguistic content and timbre representations, subsequently utilizing a\nconditional flow matching model and a vocoder to reconstruct the\nmel-spectrogram and waveform. To enhance its timbre modeling capability and the\nnaturalness of generated speech, we propose a context-aware timbre ensemble\nmodeling approach that adaptively integrates diverse speaker verification\nembeddings and enables the joint utilization of linguistic and timbre features\nthrough a cross-attention module. Experiments show that our CTEFM-VC system\nsurpasses state-of-the-art VC methods in both speaker similarity and\nnaturalness by at least 18.5% and 7.0%.", "published": "2024-11-04 12:23:17", "link": "http://arxiv.org/abs/2411.02026v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Addressing Representation Collapse in Vector Quantized Models with One\n  Linear Layer", "abstract": "Vector Quantization (VQ) is a widely used method for converting continuous\nrepresentations into discrete codes, which has become fundamental in\nunsupervised representation learning and latent generative models. However, VQ\nmodels are often hindered by the problem of representation collapse in the\nlatent space, which leads to low codebook utilization and limits the\nscalability of the codebook for large-scale training. Existing methods designed\nto mitigate representation collapse typically reduce the dimensionality of\nlatent space at the expense of model capacity, which do not fully resolve the\ncore issue. In this study, we conduct a theoretical analysis of representation\ncollapse in VQ models and identify its primary cause as the disjoint\noptimization of the codebook, where only a small subset of code vectors are\nupdated through gradient descent. To address this issue, we propose\n\\textbf{SimVQ}, a novel method which reparameterizes the code vectors through a\nlinear transformation layer based on a learnable latent basis. This\ntransformation optimizes the \\textit{entire linear space} spanned by the\ncodebook, rather than merely updating \\textit{the code vector} selected by the\nnearest-neighbor search in vanilla VQ models. Although it is commonly\nunderstood that the multiplication of two linear matrices is equivalent to\napplying a single linear layer, our approach works surprisingly well in\nresolving the collapse issue in VQ models with just one linear layer. We\nvalidate the efficacy of SimVQ through extensive experiments across various\nmodalities, including image and audio data with different model architectures.\nOur code is available at \\url{https://github.com/youngsheen/SimVQ}.", "published": "2024-11-04 12:40:18", "link": "http://arxiv.org/abs/2411.02038v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "3D Audio-Visual Segmentation", "abstract": "Recognizing the sounding objects in scenes is a longstanding objective in\nembodied AI, with diverse applications in robotics and AR/VR/MR. To that end,\nAudio-Visual Segmentation (AVS), taking as condition an audio signal to\nidentify the masks of the target sounding objects in an input image with\nsynchronous camera and microphone sensors, has been recently advanced. However,\nthis paradigm is still insufficient for real-world operation, as the mapping\nfrom 2D images to 3D scenes is missing. To address this fundamental limitation,\nwe introduce a novel research problem, 3D Audio-Visual Segmentation, extending\nthe existing AVS to the 3D output space. This problem poses more challenges due\nto variations in camera extrinsics, audio scattering, occlusions, and diverse\nacoustics across sounding object categories. To facilitate this research, we\ncreate the very first simulation based benchmark, 3DAVS-S34-O7, providing\nphotorealistic 3D scene environments with grounded spatial audio under\nsingle-instance and multi-instance settings, across 34 scenes and 7 object\ncategories. This is made possible by re-purposing the Habitat simulator to\ngenerate comprehensive annotations of sounding object locations and\ncorresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet,\ncharacterized by integrating the ready-to-use knowledge from pretrained 2D\naudio-visual foundation models synergistically with 3D visual scene\nrepresentation through spatial audio-aware mask alignment and refinement.\nExtensive experiments demonstrate that EchoSegnet can effectively segment\nsounding objects in 3D space on our new benchmark, representing a significant\nadvancement in the field of embodied AI. Project page:\nhttps://surrey-uplab.github.io/research/3d-audio-visual-segmentation/", "published": "2024-11-04 16:30:14", "link": "http://arxiv.org/abs/2411.02236v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text", "abstract": "While piano music has become a significant area of study in Music Information\nRetrieval (MIR), there is a notable lack of datasets for piano solo music with\ntext labels. To address this gap, we present PIAST (PIano dataset with Audio,\nSymbolic, and Text), a piano music dataset. Utilizing a piano-specific taxonomy\nof semantic tags, we collected 9,673 tracks from YouTube and added human\nannotations for 2,023 tracks by music experts, resulting in two subsets:\nPIAST-YT and PIAST-AT. Both include audio, text, tag annotations, and\ntranscribed MIDI utilizing state-of-the-art piano transcription and beat\ntracking models. Among many possible tasks with the multi-modal dataset, we\nconduct music tagging and retrieval using both audio and MIDI data and report\nbaseline performances to demonstrate its potential as a valuable resource for\nMIR research.", "published": "2024-11-04 19:34:13", "link": "http://arxiv.org/abs/2411.02551v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via\n  Emotion-Adaptive Spherical Vector", "abstract": "Emotional text-to-speech (TTS) technology has achieved significant progress\nin recent years; however, challenges remain owing to the inherent complexity of\nemotions and limitations of the available emotional speech datasets and models.\nPrevious studies typically relied on limited emotional speech datasets or\nrequired extensive manual annotations, restricting their ability to generalize\nacross different speakers and emotional styles. In this paper, we present\nEmoSphere++, an emotion-controllable zero-shot TTS model that can control\nemotional style and intensity to resemble natural human speech. We introduce a\nnovel emotion-adaptive spherical vector that models emotional style and\nintensity without human annotation. Moreover, we propose a multi-level style\nencoder that can ensure effective generalization for both seen and unseen\nspeakers. We also introduce additional loss functions to enhance the emotion\ntransfer performance for zero-shot scenarios. We employ a conditional flow\nmatching-based decoder to achieve high-quality and expressive emotional TTS in\na few sampling steps. Experimental results demonstrate the effectiveness of the\nproposed framework.", "published": "2024-11-04 21:33:56", "link": "http://arxiv.org/abs/2411.02625v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
