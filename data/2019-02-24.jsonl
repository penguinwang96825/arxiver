{"title": "The ARIEL-CMU Systems for LoReHLT18", "abstract": "This paper describes the ARIEL-CMU submissions to the Low Resource Human\nLanguage Technologies (LoReHLT) 2018 evaluations for the tasks Machine\nTranslation (MT), Entity Discovery and Linking (EDL), and detection of\nSituation Frames in Text and Speech (SF Text and Speech).", "published": "2019-02-24 06:40:47", "link": "http://arxiv.org/abs/1902.08899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Use of Emojis to Train Emotion Classifiers", "abstract": "Nowadays, the automatic detection of emotions is employed by many\napplications in different fields like security informatics, e-learning, humor\ndetection, targeted advertising, etc. Many of these applications focus on\nsocial media and treat this problem as a classification problem, which requires\npreparing training data. The typical method for annotating the training data by\nhuman experts is considered time consuming, labor intensive and sometimes prone\nto error. Moreover, such an approach is not easily extensible to new\ndomains/languages since such extensions require annotating new training data.\nIn this study, we propose a distant supervised learning approach where the\ntraining sentences are automatically annotated based on the emojis they have.\nSuch training data would be very cheap to produce compared with the manually\ncreated training data, thus, much larger training data can be easily obtained.\nOn the other hand, this training data would naturally have lower quality as it\nmay contain some errors in the annotation. Nonetheless, we experimentally show\nthat training classifiers on cheap, large and possibly erroneous data annotated\nusing this approach leads to more accurate results compared with training the\nsame classifiers on the more expensive, much smaller and error-free manually\nannotated training data. Our experiments are conducted on an in-house dataset\nof emotional Arabic tweets and the classifiers we consider are: Support Vector\nMachine (SVM), Multinomial Naive Bayes (MNB) and Random Forest (RF). In\naddition to experimenting with single classifiers, we also consider using an\nensemble of classifiers. The results show that using an automatically annotated\ntraining data (that is only one order of magnitude larger than the manually\nannotated one) gives better results in almost all settings considered.", "published": "2019-02-24 07:44:00", "link": "http://arxiv.org/abs/1902.08906v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlexicalized Transition-based Discontinuous Constituency Parsing", "abstract": "Lexicalized parsing models are based on the assumptions that (i) constituents\nare organized around a lexical head (ii) bilexical statistics are crucial to\nsolve ambiguities. In this paper, we introduce an unlexicalized\ntransition-based parser for discontinuous constituency structures, based on a\nstructure-label transition system and a bi-LSTM scoring system. We compare it\nto lexicalized parsing models in order to address the question of\nlexicalization in the context of discontinuous constituency parsing. Our\nexperiments show that unlexicalized models systematically achieve higher\nresults than lexicalized models, and provide additional empirical evidence that\nlexicalization is not necessary to achieve strong parsing results. Our best\nunlexicalized model sets a new state of the art on English and German\ndiscontinuous constituency treebanks. We further provide a per-phenomenon\nanalysis of its errors on discontinuous constituents.", "published": "2019-02-24 09:59:33", "link": "http://arxiv.org/abs/1902.08912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Analysis in Adversarial Settings: Does Deception Leave a Stylistic\n  Trace?", "abstract": "Textual deception constitutes a major problem for online security. Many\nstudies have argued that deceptiveness leaves traces in writing style, which\ncould be detected using text classification techniques. By conducting an\nextensive literature review of existing empirical work, we demonstrate that\nwhile certain linguistic features have been indicative of deception in certain\ncorpora, they fail to generalize across divergent semantic domains. We suggest\nthat deceptiveness as such leaves no content-invariant stylistic trace, and\ntextual similarity measures provide superior means of classifying texts as\npotentially deceptive. Additionally, we discuss forms of deception beyond\nsemantic content, focusing on hiding author identity by writing style\nobfuscation. Surveying the literature on both author identification and\nobfuscation techniques, we conclude that current style transformation methods\nfail to achieve reliable obfuscation while simultaneously ensuring semantic\nfaithfulness to the original text. We propose that future work in style\ntransformation should pay particular attention to disallowing semantically\ndrastic changes.", "published": "2019-02-24 13:18:27", "link": "http://arxiv.org/abs/1902.08939v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synchronous Bidirectional Inference for Neural Sequence Generation", "abstract": "In sequence to sequence generation tasks (e.g. machine translation and\nabstractive summarization), inference is generally performed in a left-to-right\nmanner to produce the result token by token. The neural approaches, such as\nLSTM and self-attention networks, are now able to make full use of all the\npredicted history hypotheses from left side during inference, but cannot\nmeanwhile access any future (right side) information and usually generate\nunbalanced outputs in which left parts are much more accurate than right ones.\nIn this work, we propose a synchronous bidirectional inference model to\ngenerate outputs using both left-to-right and right-to-left decoding\nsimultaneously and interactively. First, we introduce a novel beam search\nalgorithm that facilitates synchronous bidirectional decoding. Then, we present\nthe core approach which enables left-to-right and right-to-left decoding to\ninteract with each other, so as to utilize both the history and future\npredictions simultaneously during inference. We apply the proposed model to\nboth LSTM and self-attention networks. In addition, we propose two strategies\nfor parameter optimization. The extensive experiments on machine translation\nand abstractive summarization demonstrate that our synchronous bidirectional\ninference model can achieve remarkable improvements over the strong baselines.", "published": "2019-02-24 14:44:07", "link": "http://arxiv.org/abs/1902.08955v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Perform Role-Filler Binding with Schematic Knowledge", "abstract": "Through specific experiences, humans learn relationships underlying the\nstructure of events in the world. Schema theory suggests that we organize this\ninformation in mental frameworks called \"schemata,\" which represent our\nknowledge of the structure of the world. Generalizing knowledge of structural\nrelationships to new situations requires role-filler binding, the ability to\nassociate specific \"fillers\" with abstract \"roles.\" For instance, when we hear\nthe sentence \"Alice ordered a tea from Bob,\" the role-filler bindings\n\"Alice:customer,\" \"tea:drink,\" and \"Bob:barista\" allow us to understand and\nmake inferences about the sentence. We can perform these bindings for arbitrary\nfillers -- we understand this sentence even if we have never heard the names\n\"Alice,\" \"tea,\" or \"Bob\" before. In this work, we define a model as capable of\nperforming role-filler binding if it can recall arbitrary fillers corresponding\nto a specified role, even when these pairings violate correlations seen during\ntraining. Previous work found that models can learn this ability when\nexplicitly told what the roles and fillers are, or when given fillers seen\nduring training. We show that networks with external memory can learn these\nrelationships with fillers not seen during training and without explicitly\nlabeled role-filler bindings, and show that analyses inspired by neural\ndecoding can provide a means of understanding what the networks have learned.", "published": "2019-02-24 20:05:07", "link": "http://arxiv.org/abs/1902.09006v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
