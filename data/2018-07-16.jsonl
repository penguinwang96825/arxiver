{"title": "BRIEF: Backward Reduction of CNNs with Information Flow Analysis", "abstract": "This paper proposes BRIEF, a backward reduction algorithm that explores compact CNN-model designs from the information flow perspective. This algorithm can remove substantial non-zero weighting parameters (redundant neural channels) of a network by considering its dynamic behavior, which traditional model-compaction techniques cannot achieve. With the aid of our proposed algorithm, we achieve significant model reduction on ResNet-34 in the ImageNet scale (32.3% reduction), which is 3X better than the previous result (10.8%). Even for highly optimized models such as SqueezeNet and MobileNet, we can achieve additional 10.81% and 37.56% reduction, respectively, with negligible performance degradation.", "published": "2018-07-16 08:32:54", "link": "http://arxiv.org/abs/1807.05726v3", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Constraint-Based Visual Generation", "abstract": "In the last few years the systematic adoption of deep learning to visual generation has produced impressive results that, amongst others, definitely benefit from the massive exploration of convolutional architectures. In this paper, we propose a general approach to visual generation that combines learning capabilities with logic descriptions of the target to be generated. The process of generation is regarded as a constrained satisfaction problem, where the constraints describe a set of properties that characterize the target. Interestingly, the constraints can also involve logic variables, while all of them are converted into real-valued functions by means of the t-norm theory. We use deep architectures to model the involved variables, and propose a computational scheme where the learning process carries out a satisfaction of the constraints. We propose some examples in which the theory can naturally be used, including the modeling of GAN and auto-encoders, and report promising results in problems with the generation of handwritten characters and face transformations.", "published": "2018-07-16 22:56:15", "link": "http://arxiv.org/abs/1807.09202v3", "categories": ["cs.LG", "cs.CV", "cs.GR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Manifold Adversarial Learning", "abstract": "Recently proposed adversarial training methods show the robustness to both adversarial and original examples and achieve state-of-the-art results in supervised and semi-supervised learning. All the existing adversarial training methods consider only how the worst perturbed examples (i.e., adversarial examples) could affect the model output. Despite their success, we argue that such setting may be in lack of generalization, since the output space (or label space) is apparently less informative.In this paper, we propose a novel method, called Manifold Adversarial Training (MAT). MAT manages to build an adversarial framework based on how the worst perturbation could affect the distributional manifold rather than the output space. Particularly, a latent data space with the Gaussian Mixture Model (GMM) will be first derived.On one hand, MAT tries to perturb the input samples in the way that would rough the distributional manifold the worst. On the other hand, the deep learning model is trained trying to promote in the latent space the manifold smoothness, measured by the variation of Gaussian mixtures (given the local perturbation around the data point). Importantly, since the latent space is more informative than the output space, the proposed MAT can learn better a robust and compact data representation, leading to further performance improvement. The proposed MAT is important in that it can be considered as a superset of one recently-proposed discriminative feature learning approach called center loss. We conducted a series of experiments in both supervised and semi-supervised learning on three benchmark data sets, showing that the proposed MAT can achieve remarkable performance, much better than those of the state-of-the-art adversarial approaches. We also present a series of visualization which could generate further understanding or explanation on adversarial examples.", "published": "2018-07-16 13:01:41", "link": "http://arxiv.org/abs/1807.05832v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Zap: Making Predictions Based on Online User Behavior", "abstract": "This paper introduces Zap, a generic machine learning pipeline for making predictions based on online user behavior. Zap combines well known techniques for processing sequential data with more obscure techniques such as Bloom filters, bucketing, and model calibration into an end-to-end solution. The pipeline creates website- and task-specific models without knowing anything about the structure of the website. It is designed to minimize the amount of website-specific code, which is realized by factoring all website-specific logic into example generators. New example generators can typically be written up in a few lines of code.", "published": "2018-07-16 18:18:02", "link": "http://arxiv.org/abs/1807.06046v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Variational Inference: A Unified Framework of Generative Models and Some Revelations", "abstract": "We reinterpreting the variational inference in a new perspective. Via this way, we can easily prove that EM algorithm, VAE, GAN, AAE, ALI(BiGAN) are all special cases of variational inference. The proof also reveals the loss of standard GAN is incomplete and it explains why we need to train GAN cautiously. From that, we find out a regularization term to improve stability of GAN training.", "published": "2018-07-16 15:57:03", "link": "http://arxiv.org/abs/1807.05936v4", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scene Learning: Deep Convolutional Networks For Wind Power Prediction by Embedding Turbines into Grid Space", "abstract": "Wind power prediction is of vital importance in wind power utilization. There have been a lot of researches based on the time series of the wind power or speed, but In fact, these time series cannot express the temporal and spatial changes of wind, which fundamentally hinders the advance of wind power prediction. In this paper, a new kind of feature that can describe the process of temporal and spatial variation is proposed, namely, Spatio-Temporal Features. We first map the data collected at each moment from the wind turbine to the plane to form the state map, namely, the scene, according to the relative positions. The scene time series over a period of time is a multi-channel image, i.e. the Spatio-Temporal Features. Based on the Spatio-Temporal Features, the deep convolutional network is applied to predict the wind power, achieving a far better accuracy than the existing methods. Compared with the starge-of-the-art method, the mean-square error (MSE) in our method is reduced by 49.83%, and the average time cost for training models can be shortened by a factor of more than 150.", "published": "2018-07-16 03:27:18", "link": "http://arxiv.org/abs/1807.05666v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Discrete linear-complexity reinforcement learning in continuous action spaces for Q-learning algorithms", "abstract": "In this article, we sketch an algorithm that extends the Q-learning algorithms to the continuous action space domain. Our method is based on the discretization of the action space. Despite the commonly used discretization methods, our method does not increase the discretized problem dimensionality exponentially. We will show that our proposed method is linear in complexity when the discretization is employed. The variant of the Q-learning algorithm presented in this work, labeled as Finite Step Q-Learning (FSQ), can be deployed to both shallow and deep neural network architectures.", "published": "2018-07-16 22:57:11", "link": "http://arxiv.org/abs/1807.06957v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Novel Feature-Based Clustering of Micro-Panel Data (CluMP)", "abstract": "Micro-panel data are collected and analysed in many research and industry areas. Cluster analysis of micro-panel data is an unsupervised learning exploratory method identifying subgroup clusters in a data set which include homogeneous objects in terms of the development dynamics of monitored variables. The supply of clustering methods tailored to micro-panel data is limited. The present paper focuses on a feature-based clustering method, introducing a novel two-step characteristic-based approach designed for this type of data. The proposed CluMP method aims to identify clusters that are at least as internally homogeneous and externally heterogeneous as those obtained by alternative methods already implemented in the statistical system R. We compare the clustering performance of the devised algorithm with two extant methods using simulated micro-panel data sets. Our approach has yielded similar or better outcomes than the other methods, the advantage of the proposed algorithm being time efficiency which makes it applicable for large data sets.", "published": "2018-07-16 15:39:22", "link": "http://arxiv.org/abs/1807.05926v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "PAM-4 Transmission at 1550nm using Photonic Reservoir Computing Post-processing", "abstract": "The efficacy of data decoding in contemporary ultrafast fiber transmission systems is greatly determined by the capabilities of the signal processing tools that are used. The received signal must not exceed a certain level of complexity, beyond which the applied signal processing solutions become insufficient or slow. Moreover, the required signal-to-noise ratio of the received signal can be challenging, especially when adopting modulation formats with multi-level encoding. Lately, photonic reservoir computing (RC) - a hardware machine learning technique with recurrent connectivity - has been proposed as a post-processing tool that deals with deterministic distortions from fiber transmission. Here we show that RC post-processing is remarkably efficient for multilevel encoding and for the use of very high launched optical peak power for fiber transmission up to 14dBm. Higher power levels provide the desired high signal-to-noise ratio (SNR) values at the receiver end, at the expense of a complex nonlinear transformation of the transmission signal. Our demonstration evaluates a direct fiber communication link with 4-level pulse amplitude modulation (PAM-4) encoding and direct detection, without including optical amplification, dispersion compensation, pulse shaping or other digital signal processing (DSP) techniques. By applying RC post-processing on the distorted signal, we numerically estimate fiber transmission distances of 27km at 56Gb/s and of 5.5 km at 112Gb/s data encoding rates, while fulfilling the hard-decision forward error correction (HD-FEC) bit-error-rate (BER) limit for data recovery. In an experimental equivalent demonstration of our photonic reservoir, the achieved distances are 21km and 4.6km respectively.", "published": "2018-07-16 09:23:21", "link": "http://arxiv.org/abs/1807.05750v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
