{"title": "The Staircase of Ethics: Probing LLM Value Priorities through Multi-Step Induction to Complex Moral Dilemmas", "abstract": "Ethical decision-making is a critical aspect of human judgment, and the\ngrowing use of LLMs in decision-support systems necessitates a rigorous\nevaluation of their moral reasoning capabilities. However, existing assessments\nprimarily rely on single-step evaluations, failing to capture how models adapt\nto evolving ethical challenges. Addressing this gap, we introduce the\nMulti-step Moral Dilemmas (MMDs), the first dataset specifically constructed to\nevaluate the evolving moral judgments of LLMs across 3,302 five-stage dilemmas.\nThis framework enables a fine-grained, dynamic analysis of how LLMs adjust\ntheir moral reasoning across escalating dilemmas. Our evaluation of nine widely\nused LLMs reveals that their value preferences shift significantly as dilemmas\nprogress, indicating that models recalibrate moral judgments based on scenario\ncomplexity. Furthermore, pairwise value comparisons demonstrate that while LLMs\noften prioritize the value of care, this value can sometimes be superseded by\nfairness in certain contexts, highlighting the dynamic and context-dependent\nnature of LLM ethical reasoning. Our findings call for a shift toward dynamic,\ncontext-aware evaluation paradigms, paving the way for more human-aligned and\nvalue-sensitive development of LLMs.", "published": "2025-05-23 17:59:50", "link": "http://arxiv.org/abs/2505.18154v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Fann or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry Understanding in LLMs", "abstract": "Arabic poetry stands as one of the most sophisticated and culturally embedded\nforms of expression in the Arabic language, known for its layered meanings,\nstylistic diversity, and deep historical continuity. Although large language\nmodels (LLMs) have demonstrated strong performance across languages and tasks,\ntheir ability to understand Arabic poetry remains largely unexplored. In this\nwork, we introduce `Fann or Flop`, the first benchmark designed to assess the\ncomprehension of Arabic poetry by LLMs in twelve historical eras, covering 21\ncore poetic genres and a variety of metrical forms, from classical structures\nto contemporary free verse. The benchmark comprises a curated corpus of poems\nwith explanations that assess semantic understanding, metaphor interpretation,\nprosodic awareness, and cultural context. We argue that poetic comprehension\noffers a strong indicator for testing how good the LLM is in understanding\nclassical Arabic through the Arabic poetry. Unlike surface-level tasks, this\ndomain demands deeper interpretive reasoning and cultural sensitivity. Our\nevaluation of state-of-the-art LLMs shows that most models struggle with poetic\nunderstanding despite strong results on standard Arabic benchmarks. We release\n`Fann or Flop` along with the evaluation suite as an open-source resource to\nenable rigorous evaluation and advancement for Arabic language models. Code is\navailable at: https://github.com/mbzuai-oryx/FannOrFlop.", "published": "2025-05-23 17:59:29", "link": "http://arxiv.org/abs/2505.18152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "First Finish Search: Efficient Test-Time Scaling in Large Language Models", "abstract": "Test-time scaling (TTS), which involves dynamic allocation of compute during\ninference, offers a promising way to improve reasoning in large language\nmodels. While existing TTS methods work well, they often rely on long decoding\npaths or require a large number of samples to be generated, increasing the\ntoken usage and inference latency. We observe the surprising fact that for\nreasoning tasks, shorter traces are much more likely to be correct than longer\nones. Motivated by this, we introduce First Finish Search (FFS), a\ntraining-free parallel decoding strategy that launches $n$ independent samples\nand returns as soon as any one completes. We evaluate FFS alongside simple\ndecoding, beam search, majority voting, and budget forcing on four reasoning\nmodels (DeepSeek-R1, R1-Distill-Qwen-32B, QwQ-32B and Phi-4-Reasoning-Plus) and\nacross four datasets (AIME24, AIME25-I, AIME25-II and GPQA Diamond). With\nDeepSeek-R1, FFS achieves $82.23\\%$ accuracy on the AIME datasets, a $15\\%$\nimprovement over DeepSeek-R1's standalone accuracy, nearly matching OpenAI's\no4-mini performance. Our theoretical analysis explains why stopping at the\nshortest trace is likely to yield a correct answer and identifies the\nconditions under which early stopping may be suboptimal. The elegance and\nsimplicity of FFS demonstrate that straightforward TTS strategies can perform\nremarkably well, revealing the untapped potential of simple approaches at\ninference time.", "published": "2025-05-23 17:57:43", "link": "http://arxiv.org/abs/2505.18149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find", "abstract": "Large language models (LLMs) face significant challenges with\nneedle-in-a-haystack tasks, where relevant information (\"the needle\") must be\ndrawn from a large pool of irrelevant context (\"the haystack\"). Previous\nstudies have highlighted positional bias and distractor quantity as critical\nfactors affecting model performance, yet the influence of gold context size has\nreceived little attention. We address this gap by systematically studying how\nvariations in gold context length impact LLM performance on long-context\nquestion answering tasks. Our experiments reveal that LLM performance drops\nsharply when the gold context is shorter, i.e., smaller gold contexts\nconsistently degrade model performance and amplify positional sensitivity,\nposing a major challenge for agentic systems that must integrate scattered,\nfine-grained information of varying lengths. This pattern holds across three\ndiverse domains (general knowledge, biomedical reasoning, and mathematical\nreasoning) and seven state-of-the-art LLMs of various sizes and architectures.\nOur work provides clear insights to guide the design of robust, context-aware\nLLM-driven systems.", "published": "2025-05-23 17:57:42", "link": "http://arxiv.org/abs/2505.18148v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph-Linguistic Fusion: Using Language Models for Wikidata Vandalism Detection", "abstract": "We introduce a next-generation vandalism detection system for Wikidata, one\nof the largest open-source structured knowledge bases on the Web. Wikidata is\nhighly complex: its items incorporate an ever-expanding universe of factual\ntriples and multilingual texts. While edits can alter both structured and\ntextual content, our approach converts all edits into a single space using a\nmethod we call Graph2Text. This allows for evaluating all content changes for\npotential vandalism using a single multilingual language model. This unified\napproach improves coverage and simplifies maintenance. Experiments demonstrate\nthat our solution outperforms the current production system. Additionally, we\nare releasing the code under an open license along with a large dataset of\nvarious human-generated knowledge alterations, enabling further research.", "published": "2025-05-23 17:44:06", "link": "http://arxiv.org/abs/2505.18136v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gaming Tool Preferences in Agentic LLMs", "abstract": "Large language models (LLMs) can now access a wide range of external tools,\nthanks to the Model Context Protocol (MCP). This greatly expands their\nabilities as various agents. However, LLMs rely entirely on the text\ndescriptions of tools to decide which ones to use--a process that is\nsurprisingly fragile. In this work, we expose a vulnerability in prevalent\ntool/function-calling protocols by investigating a series of edits to tool\ndescriptions, some of which can drastically increase a tool's usage from LLMs\nwhen competing with alternatives. Through controlled experiments, we show that\ntools with properly edited descriptions receive over 10 times more usage from\nGPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further\nevaluate how various edits to tool descriptions perform when competing directly\nwith one another and how these trends generalize or differ across a broader set\nof 10 different models. These phenomenons, while giving developers a powerful\nway to promote their tools, underscore the need for a more reliable foundation\nfor agentic LLMs to select and utilize tools and resources.", "published": "2025-05-23 17:43:48", "link": "http://arxiv.org/abs/2505.18135v1", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "VideoGameBench: Can Vision-Language Models complete popular video games?", "abstract": "Vision-language models (VLMs) have achieved strong results on coding and math\nbenchmarks that are challenging for humans, yet their ability to perform tasks\nthat come naturally to humans--such as perception, spatial navigation, and\nmemory management--remains understudied. Real video games are crafted to be\nintuitive for humans to learn and master by leveraging innate inductive biases,\nmaking them an ideal testbed for evaluating such capabilities in VLMs. To this\nend, we introduce VideoGameBench, a benchmark consisting of 10 popular video\ngames from the 1990s that VLMs directly interact with in real-time.\nVideoGameBench challenges models to complete entire games with access to only\nraw visual inputs and a high-level description of objectives and controls, a\nsignificant departure from existing setups that rely on game-specific\nscaffolding and auxiliary information. We keep three of the games secret to\nencourage solutions that generalize to unseen environments. Our experiments\nshow that frontier vision-language models struggle to progress beyond the\nbeginning of each game. We find inference latency to be a major limitation of\nfrontier models in the real-time setting; therefore, we introduce\nVideoGameBench Lite, a setting where the game pauses while waiting for the LM's\nnext action. The best performing model, Gemini 2.5 Pro, completes only 0.48% of\nVideoGameBench and 1.6% of VideoGameBench Lite. We hope that the formalization\nof the human skills mentioned above into this benchmark motivates progress in\nthese research directions.", "published": "2025-05-23 17:43:27", "link": "http://arxiv.org/abs/2505.18134v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "One RL to See Them All: Visual Triple Unified Reinforcement Learning", "abstract": "Reinforcement learning (RL) has significantly advanced the reasoning\ncapabilities of vision-language models (VLMs). However, the use of RL beyond\nreasoning tasks remains largely unexplored, especially for perceptionintensive\ntasks like object detection and grounding. We propose V-Triune, a Visual Triple\nUnified Reinforcement Learning system that enables VLMs to jointly learn visual\nreasoning and perception tasks within a single training pipeline. V-Triune\ncomprises triple complementary components: Sample-Level Data Formatting (to\nunify diverse task inputs), Verifier-Level Reward Computation (to deliver\ncustom rewards via specialized verifiers) , and Source-Level Metric Monitoring\n(to diagnose problems at the data-source level). We further introduce a novel\nDynamic IoU reward, which provides adaptive, progressive, and definite feedback\nfor perception tasks handled by V-Triune. Our approach is instantiated within\noff-the-shelf RL training framework using open-source 7B and 32B backbone\nmodels. The resulting model, dubbed Orsta (One RL to See Them All),\ndemonstrates consistent improvements across both reasoning and perception\ntasks. This broad capability is significantly shaped by its training on a\ndiverse dataset, constructed around four representative visual reasoning tasks\n(Math, Puzzle, Chart, and Science) and four visual perception tasks (Grounding,\nDetection, Counting, and OCR). Subsequently, Orsta achieves substantial gains\non MEGA-Bench Core, with improvements ranging from +2.1 to an impressive +14.1\nacross its various 7B and 32B model variants, with performance benefits\nextending to a wide range of downstream tasks. These results highlight the\neffectiveness and scalability of our unified RL approach for VLMs. The V-Triune\nsystem, along with the Orsta models, is publicly available at\nhttps://github.com/MiniMax-AI.", "published": "2025-05-23 17:41:14", "link": "http://arxiv.org/abs/2505.18129v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Frankentext: Stitching random text fragments into long-form narratives", "abstract": "We introduce Frankentexts, a new type of long-form narratives produced by\nLLMs under the extreme constraint that most tokens (e.g., 90%) must be copied\nverbatim from human writings. This task presents a challenging test of\ncontrollable generation, requiring models to satisfy a writing prompt,\nintegrate disparate text fragments, and still produce a coherent narrative. To\ngenerate Frankentexts, we instruct the model to produce a draft by selecting\nand combining human-written passages, then iteratively revise the draft while\nmaintaining a user-specified copy ratio. We evaluate the resulting Frankentexts\nalong three axes: writing quality, instruction adherence, and detectability.\nGemini-2.5-Pro performs surprisingly well on this task: 81% of its Frankentexts\nare coherent and 100% relevant to the prompt. Notably, up to 59% of these\noutputs are misclassified as human-written by detectors like Pangram, revealing\nlimitations in AI text detectors. Human annotators can sometimes identify\nFrankentexts through their abrupt tone shifts and inconsistent grammar between\nsegments, especially in longer generations. Beyond presenting a challenging\ngeneration task, Frankentexts invite discussion on building effective detectors\nfor this new grey zone of authorship, provide training data for mixed\nauthorship detection, and serve as a sandbox for studying human-AI co-writing\nprocesses.", "published": "2025-05-23 17:38:47", "link": "http://arxiv.org/abs/2505.18128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reward Model Overoptimisation in Iterated RLHF", "abstract": "Reinforcement learning from human feedback (RLHF) is a widely used method for\naligning large language models with human preferences. However, RLHF often\nsuffers from reward model overoptimisation, in which models overfit to the\nreward function, resulting in non-generalisable policies that exploit the\nidiosyncrasies and peculiarities of the reward function. A common mitigation is\niterated RLHF, in which reward models are repeatedly retrained with updated\nhuman feedback and policies are re-optimised. Despite its increasing adoption,\nthe dynamics of overoptimisation in this setting remain poorly understood. In\nthis work, we present the first comprehensive study of overoptimisation in\niterated RLHF. We systematically analyse key design choices - how reward model\ntraining data is transferred across iterations, which reward function is used\nfor optimisation, and how policies are initialised. Using the controlled\nAlpacaFarm benchmark, we observe that overoptimisation tends to decrease over\nsuccessive iterations, as reward models increasingly approximate ground-truth\npreferences. However, performance gains diminish over time, and while\nreinitialising from the base policy is robust, it limits optimisation\nflexibility. Other initialisation strategies often fail to recover from early\noveroptimisation. These findings offer actionable insights for building more\nstable and generalisable RLHF pipelines.", "published": "2025-05-23 17:36:13", "link": "http://arxiv.org/abs/2505.18126v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TabSTAR: A Foundation Tabular Model With Semantically Target-Aware Representations", "abstract": "While deep learning has achieved remarkable success across many domains, it\nhas historically underperformed on tabular learning tasks, which remain\ndominated by gradient boosting decision trees (GBDTs). However, recent\nadvancements are paving the way for Tabular Foundation Models, which can\nleverage real-world knowledge and generalize across diverse datasets,\nparticularly when the data contains free-text. Although incorporating language\nmodel capabilities into tabular tasks has been explored, most existing methods\nutilize static, target-agnostic textual representations, limiting their\neffectiveness. We introduce TabSTAR: a Foundation Tabular Model with\nSemantically Target-Aware Representations. TabSTAR is designed to enable\ntransfer learning on tabular data with textual features, with an architecture\nfree of dataset-specific parameters. It unfreezes a pretrained text encoder and\ntakes as input target tokens, which provide the model with the context needed\nto learn task-specific embeddings. TabSTAR achieves state-of-the-art\nperformance for both medium- and large-sized datasets across known benchmarks\nof classification tasks with text features, and its pretraining phase exhibits\nscaling laws in the number of datasets, offering a pathway for further\nperformance improvements.", "published": "2025-05-23 17:34:28", "link": "http://arxiv.org/abs/2505.18125v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "UNJOIN: Enhancing Multi-Table Text-to-SQL Generation via Schema Simplification", "abstract": "Recent advances in large language models (LLMs) have greatly improved\nText-to-SQL performance for single-table queries. But, it remains challenging\nin multi-table databases due to complex schema and relational operations.\nExisting methods often struggle with retrieving the right tables and columns,\ngenerating accurate JOINs and UNIONs, and generalizing across diverse schemas.\nTo address these issues, we introduce UNJOIN, a two-stage framework that\ndecouples the retrieval of schema elements from SQL logic generation. In the\nfirst stage, we merge the column names of all tables in the database into a\nsingle-table representation by prefixing each column with its table name. This\nallows the model to focus purely on accurate retrieval without being distracted\nby the need to write complex SQL logic. In the second stage, the SQL query is\ngenerated on this simplified schema and mapped back to the original schema by\nreconstructing JOINs, UNIONs, and relational logic. Evaluations on SPIDER and\nBIRD datasets show that UNJOIN matches or exceeds the state-of-the-art\nbaselines. UNJOIN uses only schema information, which does not require data\naccess or fine-tuning, making it scalable and adaptable across databases.", "published": "2025-05-23 17:28:43", "link": "http://arxiv.org/abs/2505.18122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProgRM: Build Better GUI Agents with Progress Rewards", "abstract": "LLM-based (Large Language Model) GUI (Graphical User Interface) agents can\npotentially reshape our daily lives significantly. However, current LLM-based\nGUI agents suffer from the scarcity of high-quality training data owing to the\ndifficulties of trajectory collection and reward annotation. Existing works\nhave been exploring LLMs to collect trajectories for imitation learning or to\noffer reward signals for online RL training. However, the Outcome Reward Model\n(ORM) used in existing works cannot provide finegrained feedback and can\nover-penalize the valuable steps in finally failed trajectories. To this end,\nwe propose Progress Reward Model (ProgRM) to provide dense informative\nintermediate rewards by predicting a task completion progress for each step in\nonline training. To handle the challenge of progress reward label annotation,\nwe further design an efficient LCS-based (Longest Common Subsequence)\nself-annotation algorithm to discover the key steps in trajectories and assign\nprogress labels accordingly. ProgRM is evaluated with extensive experiments and\nanalyses. Actors trained with ProgRM outperform leading proprietary LLMs and\nORM-trained actors, illustrating the effectiveness of ProgRM. The codes for\nexperiments will be made publicly available upon acceptance.", "published": "2025-05-23 17:23:11", "link": "http://arxiv.org/abs/2505.18121v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Bridging Supervised Learning and Reinforcement Learning in Math Reasoning", "abstract": "Reinforcement Learning (RL) has played a central role in the recent surge of\nLLMs' math abilities by enabling self-improvement through binary verifier\nsignals. In contrast, Supervised Learning (SL) is rarely considered for such\nverification-driven training, largely due to its heavy reliance on reference\nanswers and inability to reflect on mistakes. In this work, we challenge the\nprevailing notion that self-improvement is exclusive to RL and propose\nNegative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to\nreflect on their failures and improve autonomously with no external teachers.\nIn online training, instead of throwing away self-generated negative answers,\nNFT constructs an implicit negative policy to model them. This implicit policy\nis parameterized with the same positive LLM we target to optimize on positive\ndata, enabling direct policy optimization on all LLMs' generations. We conduct\nexperiments on 7B and 32B models in math reasoning tasks. Results consistently\nshow that through the additional leverage of negative feedback, NFT\nsignificantly improves over SL baselines like Rejection sampling Fine-Tuning,\nmatching or even surpassing leading RL algorithms like GRPO and DAPO.\nFurthermore, we demonstrate that NFT and GRPO are actually equivalent in\nstrict-on-policy training, even though they originate from entirely different\ntheoretical foundations. Our experiments and theoretical findings bridge the\ngap between SL and RL methods in binary-feedback learning systems.", "published": "2025-05-23 17:17:40", "link": "http://arxiv.org/abs/2505.18116v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM", "abstract": "Humans naturally understand moments in a video by integrating visual and\nauditory cues. For example, localizing a scene in the video like \"A scientist\npassionately speaks on wildlife conservation as dramatic orchestral music\nplays, with the audience nodding and applauding\" requires simultaneous\nprocessing of visual, audio, and speech signals. However, existing models often\nstruggle to effectively fuse and interpret audio information, limiting their\ncapacity for comprehensive video temporal understanding. To address this, we\npresent TriSense, a triple-modality large language model designed for holistic\nvideo temporal understanding through the integration of visual, audio, and\nspeech modalities. Central to TriSense is a Query-Based Connector that\nadaptively reweights modality contributions based on the input query, enabling\nrobust performance under modality dropout and allowing flexible combinations of\navailable inputs. To support TriSense's multimodal capabilities, we introduce\nTriSense-2M, a high-quality dataset of over 2 million curated samples generated\nvia an automated pipeline powered by fine-tuned LLMs. TriSense-2M includes\nlong-form videos and diverse modality combinations, facilitating broad\ngeneralization. Extensive experiments across multiple benchmarks demonstrate\nthe effectiveness of TriSense and its potential to advance multimodal video\nanalysis. Code and dataset will be publicly released.", "published": "2025-05-23 17:04:27", "link": "http://arxiv.org/abs/2505.18110v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework", "abstract": "Recent advances in web-augmented large language models (LLMs) have exhibited\nstrong performance in complex reasoning tasks, yet these capabilities are\nmostly locked in proprietary systems with opaque architectures. In this work,\nwe propose \\textbf{ManuSearch}, a transparent and modular multi-agent framework\ndesigned to democratize deep search for LLMs. ManuSearch decomposes the search\nand reasoning process into three collaborative agents: (1) a solution planning\nagent that iteratively formulates sub-queries, (2) an Internet search agent\nthat retrieves relevant documents via real-time web search, and (3) a\nstructured webpage reading agent that extracts key evidence from raw web\ncontent. To rigorously evaluate deep reasoning abilities, we introduce\n\\textbf{ORION}, a challenging benchmark focused on open-web reasoning over\nlong-tail entities, covering both English and Chinese. Experimental results\nshow that ManuSearch substantially outperforms prior open-source baselines and\neven surpasses leading closed-source systems. Our work paves the way for\nreproducible, extensible research in open deep search systems. We release the\ndata and code in https://github.com/RUCAIBox/ManuSearch", "published": "2025-05-23 17:02:02", "link": "http://arxiv.org/abs/2505.18105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "abstract": "Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies.", "published": "2025-05-23 16:57:34", "link": "http://arxiv.org/abs/2505.18102v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "abstract": "Large language models (LLMs) excel in tasks like question answering and\ndialogue, but complex tasks requiring interaction, such as negotiation and\npersuasion, require additional long-horizon reasoning and planning.\nReinforcement learning (RL) fine-tuning can enable such planning in principle,\nbut suffers from drawbacks that hinder scalability. In particular, multi-turn\nRL training incurs high memory and computational costs, which are exacerbated\nwhen training LLMs as policies. Furthermore, the largest LLMs do not expose the\nAPIs necessary to be trained in such manner. As a result, modern methods to\nimprove the reasoning of LLMs rely on sophisticated prompting mechanisms rather\nthan RL fine-tuning. To remedy this, we propose a novel approach that uses\ngoal-conditioned value functions to guide the reasoning of LLM agents, that\nscales even to large API-based models. These value functions predict how a task\nwill unfold given an action, allowing the LLM agent to evaluate multiple\npossible outcomes, both positive and negative, to plan effectively. In\naddition, these value functions are trained over reasoning steps rather than\nfull actions, to be a concise and light-weight module that facilitates\ndecision-making in multi-turn interactions. We validate our method on tasks\nrequiring interaction, including tool use, social deduction, and dialogue,\ndemonstrating superior performance over both RL fine-tuning and prompting\nmethods while maintaining efficiency and scalability.", "published": "2025-05-23 16:51:54", "link": "http://arxiv.org/abs/2505.18098v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QwenLong-CPRS: Towards $\\infty$-LLMs with Dynamic Context Optimization", "abstract": "This technical report presents QwenLong-CPRS, a context compression framework\ndesigned for explicit long-context optimization, addressing prohibitive\ncomputation overhead during the prefill stage and the \"lost in the middle\"\nperformance degradation of large language models (LLMs) during long sequence\nprocessing. Implemented through a novel dynamic context optimization mechanism,\nQwenLong-CPRS enables multi-granularity context compression guided by natural\nlanguage instructions, achieving both efficiency gains and improved\nperformance.\n  Evolved from the Qwen architecture series, QwenLong-CPRS introduces four key\ninnovations: (1) Natural language-guided dynamic optimization, (2)\nBidirectional reasoning layers for enhanced boundary awareness, (3) Token\ncritic mechanisms with language modeling heads, and (4) Window-parallel\ninference.\n  Comprehensive evaluations across five benchmarks (4K-2M word contexts)\ndemonstrate QwenLong-CPRS's threefold effectiveness: (1) Consistent superiority\nover other context management methods like RAG and sparse attention in both\naccuracy and efficiency. (2) Architecture-agnostic integration with all\nflagship LLMs, including GPT-4o, Gemini2.0-pro, Claude3.7-sonnet, DeepSeek-v3,\nand Qwen2.5-max, achieves 21.59$\\times$ context compression alongside\n19.15-point average performance gains; (3) Deployed with Qwen2.5-32B-Instruct,\nQwenLong-CPRS surpasses leading proprietary LLMs by 4.85 and 10.88 points on\nRuler-128K and InfiniteBench, establishing new SOTA performance.", "published": "2025-05-23 16:47:00", "link": "http://arxiv.org/abs/2505.18092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Mixing Can Induce Phase Transitions in Knowledge Acquisition", "abstract": "Large Language Models (LLMs) are typically trained on data mixtures: most\ndata come from web scrapes, while a small portion is curated from high-quality\nsources with dense domain-specific knowledge. In this paper, we show that when\ntraining LLMs on such data mixtures, knowledge acquisition from knowledge-dense\ndatasets, unlike training exclusively on knowledge-dense data\n(arXiv:2404.05405), does not always follow a smooth scaling law but can exhibit\nphase transitions with respect to the mixing ratio and model size. Through\ncontrolled experiments on a synthetic biography dataset mixed with web-scraped\ndata, we demonstrate that: (1) as we increase the model size to a critical\nvalue, the model suddenly transitions from memorizing very few to most of the\nbiographies; (2) below a critical mixing ratio, the model memorizes almost\nnothing even with extensive training, but beyond this threshold, it rapidly\nmemorizes more biographies. We attribute these phase transitions to a capacity\nallocation phenomenon: a model with bounded capacity must act like a knapsack\nproblem solver to minimize the overall test loss, and the optimal allocation\nacross datasets can change discontinuously as the model size or mixing ratio\nvaries. We formalize this intuition in an information-theoretic framework and\nreveal that these phase transitions are predictable, with the critical mixing\nratio following a power-law relationship with the model size. Our findings\nhighlight a concrete case where a good mixing recipe for large models may not\nbe optimal for small models, and vice versa.", "published": "2025-05-23 16:46:24", "link": "http://arxiv.org/abs/2505.18091v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding", "abstract": "Long-form video understanding presents significant challenges due to\nextensive temporal-spatial complexity and the difficulty of question answering\nunder such extended contexts. While Large Language Models (LLMs) have\ndemonstrated considerable advancements in video analysis capabilities and long\ncontext handling, they continue to exhibit limitations when processing\ninformation-dense hour-long videos. To overcome such limitations, we propose\nthe Deep Video Discovery agent to leverage an agentic search strategy over\nsegmented video clips. Different from previous video agents manually designing\na rigid workflow, our approach emphasizes the autonomous nature of agents. By\nproviding a set of search-centric tools on multi-granular video database, our\nDVD agent leverages the advanced reasoning capability of LLM to plan on its\ncurrent observation state, strategically selects tools, formulates appropriate\nparameters for actions, and iteratively refines its internal reasoning in light\nof the gathered information. We perform comprehensive evaluation on multiple\nlong video understanding benchmarks that demonstrates the advantage of the\nentire system design. Our DVD agent achieves SOTA performance, significantly\nsurpassing prior works by a large margin on the challenging LVBench dataset.\nComprehensive ablation studies and in-depth tool analyses are also provided,\nyielding insights to further advance intelligent agents tailored for long-form\nvideo understanding tasks. The code will be released later.", "published": "2025-05-23 16:37:36", "link": "http://arxiv.org/abs/2505.18079v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Extended Inductive Reasoning for Personalized Preference Inference from Behavioral Signals", "abstract": "Large language models (LLMs) have demonstrated significant success in complex\nreasoning tasks such as math and coding. In contrast to these tasks where\ndeductive reasoning predominates, inductive reasoning\\textemdash the ability to\nderive general rules from incomplete evidence, remains underexplored. This\npaper investigates extended inductive reasoning in LLMs through the lens of\npersonalized preference inference, a critical challenge in LLM alignment where\ncurrent approaches struggle to capture diverse user preferences. The task\ndemands strong inductive reasoning capabilities as user preferences are\ntypically embedded implicitly across various interaction forms, requiring\nmodels to synthesize consistent preference patterns from scattered signals. We\npropose \\textsc{AlignXplore}, a model that leverages extended reasoning chains\nto enable systematic preference inference from behavioral signals in users'\ninteraction histories. We develop \\textsc{AlignXplore} by combining cold-start\ntraining based on synthetic data with subsequent online reinforcement learning.\nThrough extensive experiments, we demonstrate that \\textsc{AlignXplore}\nachieves substantial improvements over the backbone model by an average of\n11.05\\% on in-domain and out-of-domain benchmarks, while maintaining strong\ngeneralization ability across different input formats and downstream models.\nFurther analyses establish best practices for preference inference learning\nthrough systematic comparison of reward modeling strategies, while revealing\nthe emergence of human-like inductive reasoning patterns during training.", "published": "2025-05-23 16:16:46", "link": "http://arxiv.org/abs/2505.18071v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MathEDU: Towards Adaptive Feedback for Student Mathematical Problem-Solving", "abstract": "Online learning enhances educational accessibility, offering students the\nflexibility to learn anytime, anywhere. However, a key limitation is the lack\nof immediate, personalized feedback, particularly in helping students correct\nerrors in math problem-solving. Several studies have investigated the\napplications of large language models (LLMs) in educational contexts. In this\npaper, we explore the capabilities of LLMs to assess students' math\nproblem-solving processes and provide adaptive feedback. The MathEDU dataset is\nintroduced, comprising authentic student solutions annotated with teacher\nfeedback. We evaluate the model's ability to support personalized learning in\ntwo scenarios: one where the model has access to students' prior answer\nhistories, and another simulating a cold-start context. Experimental results\nshow that the fine-tuned model performs well in identifying correctness.\nHowever, the model still faces challenges in generating detailed feedback for\npedagogical purposes.", "published": "2025-05-23 15:59:39", "link": "http://arxiv.org/abs/2505.18056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Distillation of Emotion Knowledge from LLMs for Zero-Shot Emotion Recognition", "abstract": "The ability to handle various emotion labels without dedicated training is\ncrucial for building adaptable Emotion Recognition (ER) systems. Conventional\nER models rely on training using fixed label sets and struggle to generalize\nbeyond them. On the other hand, Large Language Models (LLMs) have shown strong\nzero-shot ER performance across diverse label spaces, but their scale limits\ntheir use on edge devices. In this work, we propose a contrastive distillation\nframework that transfers rich emotional knowledge from LLMs into a compact\nmodel without the use of human annotations. We use GPT-4 to generate\ndescriptive emotion annotations, offering rich supervision beyond fixed label\nsets. By aligning text samples with emotion descriptors in a shared embedding\nspace, our method enables zero-shot prediction on different emotion classes,\ngranularity, and label schema. The distilled model is effective across multiple\ndatasets and label spaces, outperforming strong baselines of similar size and\napproaching GPT-4's zero-shot performance, while being over 10,000 times\nsmaller.", "published": "2025-05-23 15:44:26", "link": "http://arxiv.org/abs/2505.18040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks", "abstract": "Despite remarkable advances in the field, LLMs remain unreliable in\ndistinguishing causation from correlation. Recent results from the Corr2Cause\ndataset benchmark reveal that state-of-the-art LLMs -- such as GPT-4 (F1 score:\n29.08) -- only marginally outperform random baselines (Random Uniform, F1\nscore: 20.38), indicating limited capacity of generalization. To tackle this\nlimitation, we propose a novel structured approach: rather than directly\nanswering causal queries, we provide the model with the capability to structure\nits thinking by guiding the model to build a structured knowledge graph,\nsystematically encoding the provided correlational premises, to answer the\ncausal queries. This intermediate representation significantly enhances the\nmodel's causal capabilities. Experiments on the test subset of the Corr2Cause\ndataset benchmark with Qwen3-32B model (reasoning model) show substantial gains\nover standard direct prompting methods, improving F1 scores from 32.71 to 48.26\n(over 47.5% relative increase), along with notable improvements in precision\nand recall. These results underscore the effectiveness of providing the model\nwith the capability to structure its thinking and highlight its promising\npotential for broader generalization across diverse causal inference tasks.", "published": "2025-05-23 15:37:40", "link": "http://arxiv.org/abs/2505.18034v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Training with Pseudo-Code for Instruction Following", "abstract": "Despite the rapid progress in the capabilities of Large Language Models\n(LLMs), they continue to have difficulty following relatively simple,\nunambiguous instructions, especially when compositions are involved. In this\npaper, we take inspiration from recent work that suggests that models may\nfollow instructions better when they are expressed in pseudo-code. However,\nwriting pseudo-code programs can be tedious and using few-shot demonstrations\nto craft code representations for use in inference can be unnatural for\nnon-expert users of LLMs. To overcome these limitations, we propose fine-tuning\nLLMs with instruction-tuning data that additionally includes instructions\nre-expressed in pseudo-code along with the final response. We evaluate models\ntrained using our method on $11$ publicly available benchmarks comprising of\ntasks related to instruction-following, mathematics, and common-sense\nreasoning. We conduct rigorous experiments with $5$ different models and find\nthat not only do models follow instructions better when trained with\npseudo-code, they also retain their capabilities on the other tasks related to\nmathematical and common sense reasoning. Specifically, we observe a relative\ngain of $3$--$19$% on instruction-following benchmark, and an average gain of\nupto 14% across all tasks.", "published": "2025-05-23 15:14:29", "link": "http://arxiv.org/abs/2505.18011v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TRACE for Tracking the Emergence of Semantic Representations in Transformers", "abstract": "Modern transformer models exhibit phase transitions during training, distinct\nshifts from memorisation to abstraction, but the mechanisms underlying these\ntransitions remain poorly understood. Prior work has often focused on endpoint\nrepresentations or isolated signals like curvature or mutual information,\ntypically in symbolic or arithmetic domains, overlooking the emergence of\nlinguistic structure. We introduce TRACE (Tracking Representation Abstraction\nand Compositional Emergence), a diagnostic framework combining geometric,\ninformational, and linguistic signals to detect phase transitions in\nTransformer-based LMs. TRACE leverages a frame-semantic data generation method,\nABSynth, that produces annotated synthetic corpora with controllable\ncomplexity, lexical distributions, and structural entropy, while being fully\nannotated with linguistic categories, enabling precise analysis of abstraction\nemergence. Experiments reveal that (i) phase transitions align with clear\nintersections between curvature collapse and dimension stabilisation; (ii)\nthese geometric shifts coincide with emerging syntactic and semantic accuracy;\n(iii) abstraction patterns persist across architectural variants, with\ncomponents like feedforward networks affecting optimisation stability rather\nthan fundamentally altering trajectories. This work advances our understanding\nof how linguistic abstractions emerge in LMs, offering insights into model\ninterpretability, training efficiency, and compositional generalisation that\ncould inform more principled approaches to LM development.", "published": "2025-05-23 15:03:51", "link": "http://arxiv.org/abs/2505.17998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "abstract": "The VAPO framework has demonstrated significant empirical success in\nenhancing the efficiency and reliability of reinforcement learning for long\nchain-of-thought (CoT) reasoning tasks with large language models (LLMs). By\nsystematically addressing challenges such as value model bias, heterogeneous\nsequence lengths, and sparse reward signals, VAPO achieves state-of-the-art\nperformance. While its practical benefits are evident, a deeper theoretical\nunderstanding of its underlying mechanisms and potential limitations is crucial\nfor guiding future advancements. This paper aims to initiate such a discussion\nby exploring VAPO from a theoretical perspective, highlighting areas where its\nassumptions might be challenged and where further investigation could yield\nmore robust and generalizable reasoning agents. We delve into the intricacies\nof value function approximation in complex reasoning spaces, the optimality of\nadaptive advantage estimation, the impact of token-level optimization, and the\nenduring challenges of exploration and generalization.", "published": "2025-05-23 15:03:41", "link": "http://arxiv.org/abs/2505.17997v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AVerImaTeC: A Dataset for Automatic Verification of Image-Text Claims with Evidence from the Web", "abstract": "Textual claims are often accompanied by images to enhance their credibility\nand spread on social media, but this also raises concerns about the spread of\nmisinformation. Existing datasets for automated verification of image-text\nclaims remain limited, as they often consist of synthetic claims and lack\nevidence annotations to capture the reasoning behind the verdict. In this work,\nwe introduce AVerImaTeC, a dataset consisting of 1,297 real-world image-text\nclaims. Each claim is annotated with question-answer (QA) pairs containing\nevidence from the web, reflecting a decomposed reasoning regarding the verdict.\nWe mitigate common challenges in fact-checking datasets such as contextual\ndependence, temporal leakage, and evidence insufficiency, via claim\nnormalization, temporally constrained evidence annotation, and a two-stage\nsufficiency check. We assess the consistency of the annotation in AVerImaTeC\nvia inter-annotator studies, achieving a $\\kappa=0.742$ on verdicts and\n$74.7\\%$ consistency on QA pairs. We also propose a novel evaluation method for\nevidence retrieval and conduct extensive experiments to establish baselines for\nverifying image-text claims using open-web evidence.", "published": "2025-05-23 14:45:48", "link": "http://arxiv.org/abs/2505.17978v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems", "abstract": "Using AI to create autonomous researchers has the potential to accelerate\nscientific discovery. A prerequisite for this vision is understanding how well\nan AI model can identify the underlying structure of a black-box system from\nits behavior. In this paper, we explore how well a large language model (LLM)\nlearns to identify a black-box function from passively observed versus actively\ncollected data. We investigate the reverse-engineering capabilities of LLMs\nacross three distinct types of black-box systems, each chosen to represent\ndifferent problem domains where future autonomous AI researchers may have\nconsiderable impact: Program, Formal Language, and Math Equation. Through\nextensive experiments, we show that LLMs fail to extract information from\nobservations, reaching a performance plateau that falls short of the ideal of\nBayesian inference. However, we demonstrate that prompting LLMs to not only\nobserve but also intervene -- actively querying the black-box with specific\ninputs to observe the resulting output -- improves performance by allowing LLMs\nto test edge cases and refine their beliefs. By providing the intervention data\nfrom one LLM to another, we show that this improvement is partly a result of\nengaging in the process of generating effective interventions, paralleling\nresults in the literature on human learning. Further analysis reveals that\nengaging in intervention can help LLMs escape from two common failure modes:\novercomplication, where the LLM falsely assumes prior knowledge about the\nblack-box, and overlooking, where the LLM fails to incorporate observations.\nThese insights provide practical guidance for helping LLMs more effectively\nreverse-engineer black-box systems, supporting their use in making new\ndiscoveries.", "published": "2025-05-23 14:37:36", "link": "http://arxiv.org/abs/2505.17968v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Counting Cycles with Deepseek", "abstract": "Despite recent progress, AI still struggles on advanced mathematics. We\nconsider a difficult open problem: How to derive a Computationally Efficient\nEquivalent Form (CEEF) for the cycle count statistic? The CEEF problem does not\nhave known general solutions, and requires delicate combinatorics and tedious\ncalculations. Such a task is hard to accomplish by humans but is an ideal\nexample where AI can be very helpful. We solve the problem by combining a novel\napproach we propose and the powerful coding skills of AI. Our results use\ndelicate graph theory and contain new formulas for general cases that have not\nbeen discovered before. We find that, while AI is unable to solve the problem\nall by itself, it is able to solve it if we provide it with a clear strategy, a\nstep-by-step guidance and carefully written prompts. For simplicity, we focus\nour study on DeepSeek-R1 but we also investigate other AI approaches.", "published": "2025-05-23 14:34:40", "link": "http://arxiv.org/abs/2505.17964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL", "abstract": "Improving performance on complex tasks and enabling interpretable decision\nmaking in large language models (LLMs), especially for clinical applications,\nrequires effective reasoning. Yet this remains challenging without supervised\nfine-tuning (SFT) on costly chain-of-thought (CoT) data distilled from\nclosed-source models (e.g., GPT-4o). In this work, we present AlphaMed, the\nfirst medical LLM to show that reasoning capability can emerge purely through\nreinforcement learning (RL), using minimalist rule-based rewards on public\nmultiple-choice QA datasets, without relying on SFT or distilled CoT data.\nAlphaMed achieves state-of-the-art results on six medical QA benchmarks,\noutperforming models trained with conventional SFT+RL pipelines. On challenging\nbenchmarks (e.g., MedXpert), AlphaMed even surpasses larger or closed-source\nmodels such as DeepSeek-V3-671B and Claude-3.5-Sonnet. To understand the\nfactors behind this success, we conduct a comprehensive data-centric analysis\nguided by three questions: (i) Can minimalist rule-based RL incentivize\nreasoning without distilled CoT supervision? (ii) How do dataset quantity and\ndiversity impact reasoning? (iii) How does question difficulty shape the\nemergence and generalization of reasoning? Our findings show that dataset\ninformativeness is a key driver of reasoning performance, and that minimalist\nRL on informative, multiple-choice QA data is effective at inducing reasoning\nwithout CoT supervision. We also observe divergent trends across benchmarks,\nunderscoring limitations in current evaluation and the need for more\nchallenging, reasoning-oriented medical QA benchmarks.", "published": "2025-05-23 14:27:37", "link": "http://arxiv.org/abs/2505.17952v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Handling Symbolic Language in Student Texts: A Comparative Study of NLP Embedding Models", "abstract": "Recent advancements in Natural Language Processing (NLP) have facilitated the\nanalysis of student-generated language products in learning analytics (LA),\nparticularly through the use of NLP embedding models. Yet when it comes to\nscience-related language, symbolic expressions such as equations and formulas\nintroduce challenges that current embedding models struggle to address.\nExisting studies and applications often either overlook these challenges or\nremove symbolic expressions altogether, potentially leading to biased findings\nand diminished performance of LA applications. This study therefore explores\nhow contemporary embedding models differ in their capability to process and\ninterpret science-related symbolic expressions. To this end, various embedding\nmodels are evaluated using physics-specific symbolic expressions drawn from\nauthentic student responses, with performance assessed via two approaches:\nsimilarity-based analyses and integration into a machine learning pipeline. Our\nfindings reveal significant differences in model performance, with OpenAI's\nGPT-text-embedding-3-large outperforming all other examined models, though its\nadvantage over other models was moderate rather than decisive. Beyond\nperformance, additional factors such as cost, regulatory compliance, and model\ntransparency are discussed as key considerations for model selection. Overall,\nthis study underscores the importance for LA researchers and practitioners of\ncarefully selecting NLP embedding models when working with science-related\nlanguage products that include symbolic expressions.", "published": "2025-05-23 14:26:33", "link": "http://arxiv.org/abs/2505.17950v1", "categories": ["cs.CL", "cs.AI", "physics.ed-ph"], "primary_category": "cs.CL"}
{"title": "Understanding Gated Neurons in Transformers from Their Input-Output Functionality", "abstract": "Interpretability researchers have attempted to understand MLP neurons of\nlanguage models based on both the contexts in which they activate and their\noutput weight vectors. They have paid little attention to a complementary\naspect: the interactions between input and output. For example, when neurons\ndetect a direction in the input, they might add much the same direction to the\nresidual stream (\"enrichment neurons\") or reduce its presence (\"depletion\nneurons\"). We address this aspect by examining the cosine similarity between\ninput and output weights of a neuron. We apply our method to 12 models and find\nthat enrichment neurons dominate in early-middle layers whereas later layers\ntend more towards depletion. To explain this finding, we argue that enrichment\nneurons are largely responsible for enriching concept representations, one of\nthe first steps of factual recall. Our input-output perspective is a complement\nto activation-dependent analyses and to approaches that treat input and output\nseparately.", "published": "2025-05-23 14:14:17", "link": "http://arxiv.org/abs/2505.17936v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Practical Defect-Focused Automated Code Review", "abstract": "The complexity of code reviews has driven efforts to automate review\ncomments, but prior approaches oversimplify this task by treating it as\nsnippet-level code-to-text generation and relying on text similarity metrics\nlike BLEU for evaluation. These methods overlook repository context, real-world\nmerge request evaluation, and defect detection, limiting their practicality. To\naddress these issues, we explore the full automation pipeline within the online\nrecommendation service of a company with nearly 400 million daily active users,\nanalyzing industry-grade C++ codebases comprising hundreds of thousands of\nlines of code. We identify four key challenges: 1) capturing relevant context,\n2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and\n4) integrating human workflows. To tackle these, we propose 1) code slicing\nalgorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a\nfiltering mechanism for FAR reduction, and 4) a novel prompt design for better\nhuman interaction. Our approach, validated on real-world merge requests from\nhistorical fault reports, achieves a 2x improvement over standard LLMs and a\n10x gain over previous baselines. While the presented results focus on C++, the\nunderlying framework design leverages language-agnostic principles (e.g.,\nAST-based analysis), suggesting potential for broader applicability.", "published": "2025-05-23 14:06:26", "link": "http://arxiv.org/abs/2505.17928v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Language models can learn implicit multi-hop reasoning, but only if they have lots of training data", "abstract": "Implicit reasoning is the ability of a language model to solve multi-hop\nreasoning tasks in a single forward pass, without chain of thought. We\ninvestigate this capability using GPT2-style language models trained from\nscratch on controlled $k$-hop reasoning datasets ($k = 2, 3, 4$). We show that\nwhile such models can indeed learn implicit $k$-hop reasoning, the required\ntraining data grows exponentially in $k$, and the required number of\ntransformer layers grows linearly in $k$. We offer a theoretical explanation\nfor why this depth growth is necessary. We further find that the data\nrequirement can be mitigated, but not eliminated, through curriculum learning.", "published": "2025-05-23 14:01:56", "link": "http://arxiv.org/abs/2505.17923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "T2I-Eval-R1: Reinforcement Learning-Driven Reasoning for Interpretable Text-to-Image Evaluation", "abstract": "The rapid progress in diffusion-based text-to-image (T2I) generation has\ncreated an urgent need for interpretable automatic evaluation methods that can\nassess the quality of generated images, therefore reducing the human annotation\nburden. To reduce the prohibitive cost of relying on commercial models for\nlarge-scale evaluation, and to improve the reasoning capabilities of\nopen-source models, recent research has explored supervised fine-tuning (SFT)\nof multimodal large language models (MLLMs) as dedicated T2I evaluators.\nHowever, SFT approaches typically rely on high-quality critique datasets, which\nare either generated by proprietary LLMs-with potential issues of bias and\ninconsistency-or annotated by humans at high cost, limiting their scalability\nand generalization. To address these limitations, we propose T2I-Eval-R1, a\nnovel reinforcement learning framework that trains open-source MLLMs using only\ncoarse-grained quality scores, thereby avoiding the need for annotating\nhigh-quality interpretable evaluation rationale. Our approach integrates Group\nRelative Policy Optimization (GRPO) into the instruction-tuning process,\nenabling models to generate both scalar scores and interpretable reasoning\nchains with only easy accessible annotated judgment scores or preferences.\nFurthermore, we introduce a continuous reward formulation that encourages score\ndiversity and provides stable optimization signals, leading to more robust and\ndiscriminative evaluation behavior. Experimental results on three established\nT2I meta-evaluation benchmarks demonstrate that T2I-Eval-R1 achieves\nsignificantly higher alignment with human assessments and offers more accurate\ninterpretable score rationales compared to strong baseline methods.", "published": "2025-05-23 13:44:59", "link": "http://arxiv.org/abs/2505.17897v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mutarjim: Advancing Bidirectional Arabic-English Translation with a Small Language Model", "abstract": "We introduce Mutarjim, a compact yet powerful language model for\nbidirectional Arabic-English translation. While large-scale LLMs have shown\nimpressive progress in natural language processing tasks, including machine\ntranslation, smaller models. Leveraging this insight, we developed Mutarjim\nbased on Kuwain-1.5B , a language model tailored for both Arabic and English.\nDespite its modest size, Mutarjim outperforms much larger models on several\nestablished benchmarks, achieved through an optimized two-phase training\napproach and a carefully curated, high-quality training corpus.. Experimental\nresults show that Mutarjim rivals models up to 20 times larger while\nsignificantly reducing computational costs and training requirements. We also\nintroduce Tarjama-25, a new benchmark designed to overcome limitations in\nexisting Arabic-English benchmarking datasets, such as domain narrowness, short\nsentence lengths, and English-source bias. Tarjama-25 comprises 5,000\nexpert-reviewed sentence pairs and spans a wide range of domains, offering a\nmore comprehensive and balanced evaluation framework. Notably, Mutarjim\nachieves state-of-the-art performance on the English-to-Arabic task in\nTarjama-25, surpassing even significantly larger and proprietary models like\nGPT-4o mini. We publicly release Tarjama-25 to support future research and\nadvance the evaluation of Arabic-English translation systems.", "published": "2025-05-23 13:42:21", "link": "http://arxiv.org/abs/2505.17894v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MOOSE-Chem3: Toward Experiment-Guided Hypothesis Ranking via Simulated Experimental Feedback", "abstract": "Hypothesis ranking is a crucial component of automated scientific discovery,\nparticularly in natural sciences where wet-lab experiments are costly and\nthroughput-limited. Existing approaches focus on pre-experiment ranking,\nrelying solely on large language model's internal reasoning without\nincorporating empirical outcomes from experiments. We introduce the task of\nexperiment-guided ranking, which aims to prioritize candidate hypotheses based\non the results of previously tested ones. However, developing such strategies\nis challenging due to the impracticality of repeatedly conducting real\nexperiments in natural science domains. To address this, we propose a simulator\ngrounded in three domain-informed assumptions, modeling hypothesis performance\nas a function of similarity to a known ground truth hypothesis, perturbed by\nnoise. We curate a dataset of 124 chemistry hypotheses with experimentally\nreported outcomes to validate the simulator. Building on this simulator, we\ndevelop a pseudo experiment-guided ranking method that clusters hypotheses by\nshared functional characteristics and prioritizes candidates based on insights\nderived from simulated experimental feedback. Experiments show that our method\noutperforms pre-experiment baselines and strong ablations.", "published": "2025-05-23 13:24:50", "link": "http://arxiv.org/abs/2505.17873v1", "categories": ["cs.CL", "cs.AI", "cs.CE"], "primary_category": "cs.CL"}
{"title": "Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat Falsehoods", "abstract": "Generative AI models often learn and reproduce false information present in\ntheir training corpora. This position paper argues that, analogous to\nbiological immunization, where controlled exposure to a weakened pathogen\nbuilds immunity, AI models should be fine tuned on small, quarantined sets of\nexplicitly labeled falsehoods as a \"vaccine\" against misinformation. These\ncurated false examples are periodically injected during finetuning,\nstrengthening the model ability to recognize and reject misleading claims while\npreserving accuracy on truthful inputs. An illustrative case study shows that\nimmunized models generate substantially less misinformation than baselines. To\nour knowledge, this is the first training framework that treats fact checked\nfalsehoods themselves as a supervised vaccine, rather than relying on input\nperturbations or generic human feedback signals, to harden models against\nfuture misinformation. We also outline ethical safeguards and governance\ncontrols to ensure the safe use of false data. Model immunization offers a\nproactive paradigm for aligning AI systems with factuality.", "published": "2025-05-23 13:20:23", "link": "http://arxiv.org/abs/2505.17870v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining Sources of Uncertainty in Automated Fact-Checking", "abstract": "Understanding sources of a model's uncertainty regarding its predictions is\ncrucial for effective human-AI collaboration. Prior work proposes using\nnumerical uncertainty or hedges (\"I'm not sure, but ...\"), which do not explain\nuncertainty that arises from conflicting evidence, leaving users unable to\nresolve disagreements or rely on the output. We introduce CLUE\n(Conflict-and-Agreement-aware Language-model Uncertainty Explanations), the\nfirst framework to generate natural language explanations of model uncertainty\nby (i) identifying relationships between spans of text that expose\nclaim-evidence or inter-evidence conflicts and agreements that drive the\nmodel's predictive uncertainty in an unsupervised way, and (ii) generating\nexplanations via prompting and attention steering that verbalize these critical\ninteractions. Across three language models and two fact-checking datasets, we\nshow that CLUE produces explanations that are more faithful to the model's\nuncertainty and more consistent with fact-checking decisions than prompting for\nuncertainty explanations without span-interaction guidance. Human evaluators\njudge our explanations to be more helpful, more informative, less redundant,\nand more logically consistent with the input than this baseline. CLUE requires\nno fine-tuning or architectural changes, making it plug-and-play for any\nwhite-box language model. By explicitly linking uncertainty to evidence\nconflicts, it offers practical support for fact-checking and generalises\nreadily to other tasks that require reasoning over complex information.", "published": "2025-05-23 13:06:43", "link": "http://arxiv.org/abs/2505.17855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Affect Mining Techniques for Annotation Sample Selection in the Creation of Finnish Affective Speech Corpus", "abstract": "Study of affect in speech requires suitable data, as emotional expression and\nperception vary across languages. Until now, no corpus has existed for natural\nexpression of affect in spontaneous Finnish, existing data being acted or from\na very specific communicative setting. This paper presents the first such\ncorpus, created by annotating 12,000 utterances for emotional arousal and\nvalence, sampled from three large-scale Finnish speech corpora. To ensure\ndiverse affective expression, sample selection was conducted with an affect\nmining approach combining acoustic, cross-linguistic speech emotion, and text\nsentiment features. We compare this method to random sampling in terms of\nannotation diversity, and conduct post-hoc analyses to identify sampling\nchoices that would have maximized the diversity. As an outcome, the work\nintroduces a spontaneous Finnish affective speech corpus and informs sampling\nstrategies for affective speech corpus creation in other languages or domains.", "published": "2025-05-23 12:47:21", "link": "http://arxiv.org/abs/2505.17833v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emerging categories in scientific explanations", "abstract": "Clear and effective explanations are essential for human understanding and\nknowledge dissemination. The scope of scientific research aiming to understand\nthe essence of explanations has recently expanded from the social sciences to\nmachine learning and artificial intelligence. Explanations for machine learning\ndecisions must be impactful and human-like, and there is a lack of large-scale\ndatasets focusing on human-like and human-generated explanations. This work\naims to provide such a dataset by: extracting sentences that indicate\nexplanations from scientific literature among various sources in the\nbiotechnology and biophysics topic domains (e.g. PubMed's PMC Open Access\nsubset); providing a multi-class notation derived inductively from the data;\nevaluating annotator consensus on the emerging categories. The sentences are\norganized in an openly-available dataset, with two different classifications\n(6-class and 3-class category annotation), and the 3-class notation achieves a\n0.667 Krippendorf Alpha value.", "published": "2025-05-23 12:46:52", "link": "http://arxiv.org/abs/2505.17832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stepwise Reasoning Checkpoint Analysis: A Test Time Scaling Method to Enhance LLMs' Reasoning", "abstract": "Mathematical reasoning through Chain-of-Thought (CoT) has emerged as a\npowerful capability of Large Language Models (LLMs), which can be further\nenhanced through Test-Time Scaling (TTS) methods like Beam Search and DVTS.\nHowever, these methods, despite improving accuracy by allocating more\ncomputational resources during inference, often suffer from path homogenization\nand inefficient use of intermediate results. To address these limitations, we\npropose Stepwise Reasoning Checkpoint Analysis (SRCA), a framework that\nintroduces checkpoints between reasoning steps. It incorporates two key\nstrategies: (1) Answer-Clustered Search, which groups reasoning paths by their\nintermediate checkpoint answers to maintain diversity while ensuring quality,\nand (2) Checkpoint Candidate Augmentation, which leverages all intermediate\nanswers for final decision-making. Our approach effectively reduces path\nhomogenization and creates a fault-tolerant mechanism by utilizing high-quality\nintermediate results. Experimental results show that SRCA improves reasoning\naccuracy compared to existing TTS methods across various mathematical datasets.", "published": "2025-05-23 12:42:50", "link": "http://arxiv.org/abs/2505.17829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Tokens Are What You Need In Thinking", "abstract": "Modern reasoning models, such as OpenAI's o1 and DeepSeek-R1, exhibit\nimpressive problem-solving capabilities but suffer from critical\ninefficiencies: high inference latency, excessive computational resource\nconsumption, and a tendency toward overthinking -- generating verbose chains of\nthought (CoT) laden with redundant tokens that contribute minimally to the\nfinal answer. To address these issues, we propose Conditional Token Selection\n(CTS), a token-level compression framework with a flexible and variable\ncompression ratio that identifies and preserves only the most essential tokens\nin CoT. CTS evaluates each token's contribution to deriving correct answers\nusing conditional importance scoring, then trains models on compressed CoT.\nExtensive experiments demonstrate that CTS effectively compresses long CoT\nwhile maintaining strong reasoning performance. Notably, on the GPQA benchmark,\nQwen2.5-14B-Instruct trained with CTS achieves a 9.1% accuracy improvement with\n13.2% fewer reasoning tokens (13% training token reduction). Further reducing\ntraining tokens by 42% incurs only a marginal 5% accuracy drop while yielding a\n75.8% reduction in reasoning tokens, highlighting the prevalence of redundancy\nin existing CoT.", "published": "2025-05-23 12:41:29", "link": "http://arxiv.org/abs/2505.17827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models", "abstract": "Trinity-RFT is a general-purpose, flexible and scalable framework designed\nfor reinforcement fine-tuning (RFT) of large language models. It is built with\na decoupled design, consisting of (1) an RFT-core that unifies and generalizes\nsynchronous/asynchronous, on-policy/off-policy, and online/offline modes of\nRFT, (2) seamless integration for agent-environment interaction with high\nefficiency and robustness, and (3) systematic data pipelines optimized for RFT.\nTrinity-RFT can be easily adapted for diverse application scenarios, and serves\nas a unified platform for exploring advanced reinforcement learning paradigms.\nThis technical report outlines the vision, features, design and implementations\nof Trinity-RFT, accompanied by extensive examples demonstrating the utility and\nuser-friendliness of the proposed framework.", "published": "2025-05-23 12:41:09", "link": "http://arxiv.org/abs/2505.17826v1", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient Interactions", "abstract": "Doctor-patient consultations require multi-turn, context-aware communication\ntailored to diverse patient personas. Training or evaluating doctor LLMs in\nsuch settings requires realistic patient interaction systems. However, existing\nsimulators often fail to reflect the full range of personas seen in clinical\npractice. To address this, we introduce PatientSim, a patient simulator that\ngenerates realistic and diverse patient personas for clinical scenarios,\ngrounded in medical expertise. PatientSim operates using: 1) clinical profiles,\nincluding symptoms and medical history, derived from real-world data in the\nMIMIC-ED and MIMIC-IV datasets, and 2) personas defined by four axes:\npersonality, language proficiency, medical history recall level, and cognitive\nconfusion level, resulting in 37 unique combinations. We evaluated eight LLMs\nfor factual accuracy and persona consistency. The top-performing open-source\nmodel, Llama 3.3, was validated by four clinicians to confirm the robustness of\nour framework. As an open-source, customizable platform, PatientSim provides a\nreproducible and scalable solution that can be customized for specific training\nneeds. Offering a privacy-compliant environment, it serves as a robust testbed\nfor evaluating medical dialogue systems across diverse patient presentations\nand shows promise as an educational tool for healthcare.", "published": "2025-05-23 12:34:48", "link": "http://arxiv.org/abs/2505.17818v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Low-Resource NMT: A Case Study on the Written and Spoken Languages in Hong Kong", "abstract": "The majority of inhabitants in Hong Kong are able to read and write in\nstandard Chinese but use Cantonese as the primary spoken language in daily\nlife. Spoken Cantonese can be transcribed into Chinese characters, which\nconstitute the so-called written Cantonese. Written Cantonese exhibits\nsignificant lexical and grammatical differences from standard written Chinese.\nThe rise of written Cantonese is increasingly evident in the cyber world. The\ngrowing interaction between Mandarin speakers and Cantonese speakers is leading\nto a clear demand for automatic translation between Chinese and Cantonese. This\npaper describes a transformer-based neural machine translation (NMT) system for\nwritten-Chinese-to-written-Cantonese translation. Given that parallel text data\nof Chinese and Cantonese are extremely scarce, a major focus of this study is\non the effort of preparing good amount of training data for NMT. In addition to\ncollecting 28K parallel sentences from previous linguistic studies and\nscattered internet resources, we devise an effective approach to obtaining 72K\nparallel sentences by automatically extracting pairs of semantically similar\nsentences from parallel articles on Chinese Wikipedia and Cantonese Wikipedia.\nWe show that leveraging highly similar sentence pairs mined from Wikipedia\nimproves translation performance in all test sets. Our system outperforms Baidu\nFanyi's Chinese-to-Cantonese translation on 6 out of 8 test sets in BLEU\nscores. Translation examples reveal that our system is able to capture\nimportant linguistic transformations between standard Chinese and spoken\nCantonese.", "published": "2025-05-23 12:32:01", "link": "http://arxiv.org/abs/2505.17816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning", "abstract": "Reasoning large language models (LLMs) heavily rely on scaling test-time\ncompute to perform complex reasoning tasks by generating extensive \"thinking\"\nchains. While demonstrating impressive results, this approach incurs\nsignificant computational costs and inference time. In this work, we challenge\nthe assumption that long thinking chains results in better reasoning\ncapabilities. We first demonstrate that shorter reasoning chains within\nindividual questions are significantly more likely to yield correct answers -\nup to 34.5% more accurate than the longest chain sampled for the same question.\nBased on these results, we suggest short-m@k, a novel reasoning LLM inference\nmethod. Our method executes k independent generations in parallel and halts\ncomputation once the first m thinking processes are done. The final answer is\nchosen using majority voting among these m chains. Basic short-1@k demonstrates\nsimilar or even superior performance over standard majority voting in\nlow-compute settings - using up to 40% fewer thinking tokens. short-3@k, while\nslightly less efficient than short-1@k, consistently surpasses majority voting\nacross all compute budgets, while still being substantially faster (up to 33%\nwall time reduction). Inspired by our results, we finetune an LLM using short,\nlong, and randomly selected reasoning chains. We then observe that training on\nthe shorter ones leads to better performance. Our findings suggest rethinking\ncurrent methods of test-time compute in reasoning LLMs, emphasizing that longer\n\"thinking\" does not necessarily translate to improved performance and can,\ncounter-intuitively, lead to degraded results.", "published": "2025-05-23 12:29:06", "link": "http://arxiv.org/abs/2505.17813v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DialogXpert: Driving Intelligent and Emotion-Aware Conversations through Online Value-Based Reinforcement Learning with LLM Priors", "abstract": "Large-language-model (LLM) agents excel at reactive dialogue but struggle\nwith proactive, goal-driven interactions due to myopic decoding and costly\nplanning. We introduce DialogXpert, which leverages a frozen LLM to propose a\nsmall, high-quality set of candidate actions per turn and employs a compact\nQ-network over fixed BERT embeddings trained via temporal-difference learning\nto select optimal moves within this reduced space. By tracking the user's\nemotions, DialogXpert tailors each decision to advance the task while nurturing\na genuine, empathetic connection. Across negotiation, emotional support, and\ntutoring benchmarks, DialogXpert drives conversations to under $3$ turns with\nsuccess rates exceeding 94\\% and, with a larger LLM prior, pushes success above\n97\\% while markedly improving negotiation outcomes. This framework delivers\nreal-time, strategic, and emotionally intelligent dialogue planning at scale.\nCode available at https://github.com/declare-lab/dialogxpert/", "published": "2025-05-23 12:12:40", "link": "http://arxiv.org/abs/2505.17795v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compression Hacking: A Supplementary Perspective on Informatics Metric of Language Models from Geometric Distortion", "abstract": "Recently, the concept of ``compression as intelligence'' has provided a novel\ninformatics metric perspective for language models (LMs), emphasizing that\nhighly structured representations signify the intelligence level of LMs.\nHowever, from a geometric standpoint, the word representation space of highly\ncompressed LMs tends to degenerate into a highly anisotropic state, which\nhinders the LM's ability to comprehend instructions and directly impacts its\nperformance. We found this compression-anisotropy synchronicity is essentially\nthe ``Compression Hacking'' in LM representations, where noise-dominated\ndirections tend to create the illusion of high compression rates by sacrificing\nspatial uniformity. Based on this, we propose three refined compression metrics\nby incorporating geometric distortion analysis and integrate them into a\nself-evaluation pipeline. The refined metrics exhibit strong alignment with the\nLM's comprehensive capabilities, achieving Spearman correlation coefficients\nabove 0.9, significantly outperforming both the original compression and other\ninternal structure-based metrics. This confirms that compression hacking\nsubstantially enhances the informatics interpretation of LMs by incorporating\ngeometric distortion of representations.", "published": "2025-05-23 12:11:03", "link": "http://arxiv.org/abs/2505.17793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EXECUTE: A Multilingual Benchmark for LLM Token Understanding", "abstract": "The CUTE benchmark showed that LLMs struggle with character understanding in\nEnglish. We extend it to more languages with diverse scripts and writing\nsystems, introducing EXECUTE. Our simplified framework allows easy expansion to\nany language. Tests across multiple LLMs reveal that challenges in other\nlanguages are not always on the character level as in English. Some languages\nshow word-level processing issues, some show no issues at all. We also examine\nsub-character tasks in Chinese, Japanese, and Korean to assess LLMs'\nunderstanding of character components.", "published": "2025-05-23 11:56:48", "link": "http://arxiv.org/abs/2505.17784v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "abstract": "Large Language Model (LLM) agents represent a promising shift in human-AI\ninteraction, moving beyond passive prompt-response systems to autonomous agents\ncapable of reasoning, planning, and goal-directed action. Despite the\nwidespread application in specialized, high-effort tasks like coding and\nscientific research, we highlight a critical usability gap in high-demand,\nmass-market applications. This position paper argues that the limited\nreal-world adoption of LLM agents stems not only from gaps in model\ncapabilities, but also from a fundamental tradeoff between the value an agent\ncan provide and the costs incurred during real-world use. Hence, we call for a\nshift from solely optimizing model performance to a broader, utility-driven\nperspective: evaluating agents through the lens of the overall agentic return\non investment (Agent ROI). By identifying key factors that determine Agentic\nROI--information quality, agent time, and cost--we posit a zigzag development\ntrajectory in optimizing agentic ROI: first scaling up to improve the\ninformation quality, then scaling down to minimize the time and cost. We\noutline the roadmap across different development stages to bridge the current\nusability gaps, aiming to make LLM agents truly scalable, accessible, and\neffective in real-world contexts.", "published": "2025-05-23 11:40:58", "link": "http://arxiv.org/abs/2505.17767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs", "abstract": "Large Language Models (LLMs) augmented with retrieval mechanisms have\ndemonstrated significant potential in fact-checking tasks by integrating\nexternal knowledge. However, their reliability decreases when confronted with\nconflicting evidence from sources of varying credibility. This paper presents\nthe first systematic evaluation of Retrieval-Augmented Generation (RAG) models\nfor fact-checking in the presence of conflicting evidence. To support this\nstudy, we introduce \\textbf{CONFACT} (\\textbf{Con}flicting Evidence for\n\\textbf{Fact}-Checking) (Dataset available at\nhttps://github.com/zoeyyes/CONFACT), a novel dataset comprising questions\npaired with conflicting information from various sources. Extensive experiments\nreveal critical vulnerabilities in state-of-the-art RAG methods, particularly\nin resolving conflicts stemming from differences in media source credibility.\nTo address these challenges, we investigate strategies to integrate media\nbackground information into both the retrieval and generation stages. Our\nresults show that effectively incorporating source credibility significantly\nenhances the ability of RAG models to resolve conflicting evidence and improve\nfact-checking performance.", "published": "2025-05-23 11:35:03", "link": "http://arxiv.org/abs/2505.17762v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks", "abstract": "We introduce a set of training-free ABX-style discrimination tasks to\nevaluate how multilingual language models represent language identity (form)\nand semantic content (meaning). Inspired from speech processing, these\nzero-shot tasks measure whether minimal differences in representation can be\nreliably detected. This offers a flexible and interpretable alternative to\nprobing. Applied to XLM-R (Conneau et al, 2020) across pretraining checkpoints\nand layers, we find that language discrimination declines over training and\nbecomes concentrated in lower layers, while meaning discrimination strengthens\nover time and stabilizes in deeper layers. We then explore probing tasks,\nshowing some alignment between our metrics and linguistic learning performance.\nOur results position ABX tasks as a lightweight framework for analyzing the\nstructure of multilingual representations.", "published": "2025-05-23 11:14:27", "link": "http://arxiv.org/abs/2505.17747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Quiet-STaR: Thinking Without Thought Tokens", "abstract": "Large Language Models (LLMs) have achieved impressive performance across a\nrange of natural language processing tasks. However, recent advances\ndemonstrate that further gains particularly in complex reasoning tasks require\nmore than merely scaling up model sizes or training data. One promising\ndirection is to enable models to think during the reasoning process. Recently,\nQuiet STaR significantly improves reasoning by generating token-level thought\ntraces, but incurs substantial inference overhead. In this work, we propose\nFast Quiet STaR, a more efficient reasoning framework that preserves the\nbenefits of token-level reasoning while reducing computational cost. Our method\nintroduces a curriculum learning based training strategy that gradually reduces\nthe number of thought tokens, enabling the model to internalize more abstract\nand concise reasoning processes. We further extend this approach to the\nstandard Next Token Prediction (NTP) setting through reinforcement\nlearning-based fine-tuning, resulting in Fast Quiet-STaR NTP, which eliminates\nthe need for explicit thought token generation during inference. Experiments on\nfour benchmark datasets with Mistral 7B and Qwen2.5 7B demonstrate that Fast\nQuiet-STaR consistently outperforms Quiet-STaR in terms of average accuracy\nunder the same inference time budget. Notably, Fast Quiet-STaR NTP achieves an\naverage accuracy improvement of 9\\% on Mistral 7B and 5.7\\% on Qwen2.5 7B,\nwhile maintaining the same inference latency. Our code will be available at\nhttps://github.com/huangwei200012/Fast-Quiet-STaR.", "published": "2025-05-23 11:14:12", "link": "http://arxiv.org/abs/2505.17746v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Pilot Corpus of the English Semantic Sketches", "abstract": "The paper is devoted to the creation of the semantic sketches for English\nverbs. The pilot corpus consists of the English-Russian sketch pairs and is\naimed to show what kind of contrastive studies the sketches help to conduct.\nSpecial attention is paid to the cross-language differences between the\nsketches with similar semantics. Moreover, we discuss the process of building a\nsemantic sketch, and analyse the mistakes that could give insight to the\nlinguistic nature of sketches.", "published": "2025-05-23 10:53:00", "link": "http://arxiv.org/abs/2505.17733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PPO-BR: Dual-Signal Entropy-Reward Adaptation for Trust Region Policy Optimization", "abstract": "Despite Proximal Policy Optimization (PPO) dominating policy gradient methods\n-- from robotic control to game AI -- its static trust region forces a brittle\ntrade-off: aggressive clipping stifles early exploration, while late-stage\nupdates destabilize convergence. PPO-BR establishes a new paradigm in adaptive\nRL by fusing exploration and convergence signals into a single bounded trust\nregion -- a theoretically grounded innovation that outperforms five SOTA\nbaselines with less than 2% overhead. This work bridges a critical gap in\nphase-aware learning, enabling real-world deployment in safety-critical systems\nlike robotic surgery within a single adaptive mechanism. PPO-BR achieves 29.1%\nfaster convergence by combining: (1) entropy-driven expansion (epsilon up) for\nexploration in high-uncertainty states, and (2) reward-guided contraction\n(epsilon down) for convergence stability. On six diverse benchmarks (MuJoCo,\nAtari, sparse-reward), PPO-BR achieves 29.1% faster convergence (p < 0.001),\n2.3x lower reward variance than PPO, and less than 1.8% runtime overhead with\nonly five lines of code change. PPO-BR's simplicity and theoretical guarantees\nmake it ready-to-deploy in safety-critical domains -- from surgical robotics to\nautonomous drones. In contrast to recent methods such as Group Relative Policy\nOptimization (GRPO), PPO-BR offers a unified entropy-reward mechanism\napplicable to both language models and general reinforcement learning\nenvironments.", "published": "2025-05-23 10:30:58", "link": "http://arxiv.org/abs/2505.17714v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Understanding How Value Neurons Shape the Generation of Specified Values in LLMs", "abstract": "Rapid integration of large language models (LLMs) into societal applications\nhas intensified concerns about their alignment with universal ethical\nprinciples, as their internal value representations remain opaque despite\nbehavioral alignment advancements. Current approaches struggle to\nsystematically interpret how values are encoded in neural architectures,\nlimited by datasets that prioritize superficial judgments over mechanistic\nanalysis. We introduce ValueLocate, a mechanistic interpretability framework\ngrounded in the Schwartz Values Survey, to address this gap. Our method first\nconstructs ValueInsight, a dataset that operationalizes four dimensions of\nuniversal value through behavioral contexts in the real world. Leveraging this\ndataset, we develop a neuron identification method that calculates activation\ndifferences between opposing value aspects, enabling precise localization of\nvalue-critical neurons without relying on computationally intensive attribution\nmethods. Our proposed validation method demonstrates that targeted manipulation\nof these neurons effectively alters model value orientations, establishing\ncausal relationships between neurons and value representations. This work\nadvances the foundation for value alignment by bridging psychological value\nframeworks with neuron analysis in LLMs.", "published": "2025-05-23 10:30:09", "link": "http://arxiv.org/abs/2505.17712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemSketches-2021: experimenting with the machine processing of the pilot semantic sketches corpus", "abstract": "The paper deals with elaborating different approaches to the machine\nprocessing of semantic sketches. It presents the pilot open corpus of semantic\nsketches. Different aspects of creating the sketches are discussed, as well as\nthe tasks that the sketches can help to solve. Special attention is paid to the\ncreation of the machine processing tools for the corpus. For this purpose, the\nSemSketches-2021 Shared Task was organized. The participants were given the\nanonymous sketches and a set of contexts containing the necessary predicates.\nDuring the Task, one had to assign the proper contexts to the corresponding\nsketches.", "published": "2025-05-23 10:15:22", "link": "http://arxiv.org/abs/2505.17704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary Weights in Down Projection", "abstract": "The growing size of large language models has created significant\ncomputational inefficiencies. To address this challenge, sparse activation\nmethods selectively deactivates non-essential parameters during inference,\nreducing computational costs in FFNN layers. While existing methods focus on\nnon-linear gating mechanisms, we hypothesize that the sparsity of the FFNN\nlayer lies globally in the form of a linear combination over its internal down\nprojection matrix. Based on this insight, we propose two methods: M-COUNTDOWN,\nleveraging indirect coefficients, and D-COUNTDOWN, utilizing direct\ncoefficients of the linear combination. Experimental results demonstrate that\nD-COUNTDOWN can omit 90% of computations with performance loss as low as 5.5%\nideally, while M-COUNTDOWN provides a predictor-free solution with up to 29.4%\nbetter performance preservation compared to existing methods. Our specialized\nkernel implementations effectively realize these theoretical gains into\nsubstantial real-world acceleration.", "published": "2025-05-23 10:10:22", "link": "http://arxiv.org/abs/2505.17701v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models", "abstract": "Despite the remarkable reasoning performance, eliciting the long\nchain-of-thought (CoT) ability in large language models (LLMs) typically\nrequires costly reinforcement learning or supervised fine-tuning on\nhigh-quality distilled data. We investigate the internal mechanisms behind this\ncapability and show that a small set of high-impact activations in the last few\nlayers largely governs long-form reasoning attributes, such as output length\nand self-reflection. By simply amplifying these activations and inserting\n\"wait\" tokens, we can invoke the long CoT ability without any training,\nresulting in significantly increased self-reflection rates and accuracy.\nMoreover, we find that the activation dynamics follow predictable trajectories,\nwith a sharp rise after special tokens and a subsequent exponential decay.\nBuilding on these insights, we introduce a general training-free activation\ncontrol technique. It leverages a few contrastive examples to identify key\nactivations, and employs simple analytic functions to modulate their values at\ninference time to elicit long CoTs. Extensive experiments confirm the\neffectiveness of our method in efficiently eliciting long CoT reasoning in LLMs\nand improving their performance. Additionally, we propose a parameter-efficient\nfine-tuning method that trains only a last-layer activation amplification\nmodule and a few LoRA layers, outperforming full LoRA fine-tuning on reasoning\nbenchmarks with significantly fewer parameters. Our code and data are publicly\nreleased.", "published": "2025-05-23 10:07:18", "link": "http://arxiv.org/abs/2505.17697v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive Preferences via Tournament Graph Reconstruction", "abstract": "Large language models (LLMs) are widely used as evaluators for open-ended\ntasks, while previous research has emphasized biases in LLM evaluations, the\nissue of non-transitivity in pairwise comparisons remains unresolved:\nnon-transitive preferences for pairwise comparisons, where evaluators prefer A\nover B, B over C, but C over A. Our results suggest that low-quality training\ndata may reduce the transitivity of preferences generated by the Evaluator LLM.\nTo address this, We propose a graph-theoretic framework to analyze and mitigate\nthis problem by modeling pairwise preferences as tournament graphs. We quantify\nnon-transitivity and introduce directed graph structural entropy to measure the\noverall clarity of preferences. Our analysis reveals significant\nnon-transitivity in advanced Evaluator LLMs (with Qwen2.5-Max exhibiting\n67.96%), as well as high entropy values (0.8095 for Qwen2.5-Max), reflecting\nlow overall clarity of preferences. To address this issue, we designed a\nfiltering strategy, ELSPR, to eliminate preference data that induces\nnon-transitivity, retaining only consistent and transitive preference data for\nmodel fine-tuning. Experiments demonstrate that models fine-tuned with filtered\ndata reduce non-transitivity by 13.78% (from 64.28% to 50.50%), decrease\nstructural entropy by 0.0879 (from 0.8113 to 0.7234), and align more closely\nwith human evaluators (human agreement rate improves by 0.6% and Spearman\ncorrelation increases by 0.01).", "published": "2025-05-23 10:00:03", "link": "http://arxiv.org/abs/2505.17691v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tuning Language Models for Robust Prediction of Diverse User Behaviors", "abstract": "Predicting user behavior is essential for intelligent assistant services, yet\ndeep learning models often struggle to capture long-tailed behaviors. Large\nlanguage models (LLMs), with their pretraining on vast corpora containing rich\nbehavioral knowledge, offer promise. However, existing fine-tuning approaches\ntend to overfit to frequent ``anchor'' behaviors, reducing their ability to\npredict less common ``tail'' behaviors. In this paper, we introduce BehaviorLM,\na progressive fine-tuning approach that addresses this issue. In the first\nstage, LLMs are fine-tuned on anchor behaviors while preserving general\nbehavioral knowledge. In the second stage, fine-tuning uses a balanced subset\nof all behaviors based on sample difficulty to improve tail behavior\npredictions without sacrificing anchor performance. Experimental results on two\nreal-world datasets demonstrate that BehaviorLM robustly predicts both anchor\nand tail behaviors and effectively leverages LLM behavioral knowledge to master\ntail behavior prediction with few-shot examples.", "published": "2025-05-23 09:53:43", "link": "http://arxiv.org/abs/2505.17682v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIDB: Multilingual Instruction Data Booster for Enhancing Multilingual Instruction Synthesis", "abstract": "Despite doubts on data quality, instruction synthesis has been widely applied\ninto instruction tuning (IT) of LLMs as an economic and rapid alternative.\nRecent endeavors focus on improving data quality for synthesized instruction\npairs in English and have facilitated IT of English-centric LLMs. However, data\nquality issues in multilingual synthesized instruction pairs are even more\nsevere, since the common synthesizing practice is to translate English\nsynthesized data into other languages using machine translation (MT). Besides\nthe known content errors in these English synthesized data, multilingual\nsynthesized instruction data are further exposed to defects introduced by MT\nand face insufficient localization of the target languages. In this paper, we\npropose MIDB, a Multilingual Instruction Data Booster to automatically address\nthe quality issues in multilingual synthesized data. MIDB is trained on around\n36.8k revision examples across 16 languages by human linguistic experts,\nthereby can boost the low-quality data by addressing content errors and MT\ndefects, and improving localization in these synthesized data. Both automatic\nand human evaluation indicate that not only MIDB steadily improved instruction\ndata quality in 16 languages, but also the instruction-following and\ncultural-understanding abilities of multilingual LLMs fine-tuned on\nMIDB-boosted data were significantly enhanced.", "published": "2025-05-23 09:37:10", "link": "http://arxiv.org/abs/2505.17671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning", "abstract": "Recent large reasoning models (LRMs) have demonstrated strong reasoning\ncapabilities through reinforcement learning (RL). These improvements have\nprimarily been observed within the short-context reasoning tasks. In contrast,\nextending LRMs to effectively process and reason on long-context inputs via RL\nremains a critical unsolved challenge. To bridge this gap, we first formalize\nthe paradigm of long-context reasoning RL, and identify key challenges in\nsuboptimal training efficiency and unstable optimization process. To address\nthese issues, we propose QwenLong-L1, a framework that adapts short-context\nLRMs to long-context scenarios via progressive context scaling. Specifically,\nwe utilize a warm-up supervised fine-tuning (SFT) stage to establish a robust\ninitial policy, followed by a curriculum-guided phased RL technique to\nstabilize the policy evolution, and enhanced with a difficulty-aware\nretrospective sampling strategy to incentivize the policy exploration.\nExperiments on seven long-context document question-answering benchmarks\ndemonstrate that QwenLong-L1-32B outperforms flagship LRMs like OpenAI-o3-mini\nand Qwen3-235B-A22B, achieving performance on par with\nClaude-3.7-Sonnet-Thinking, demonstrating leading performance among\nstate-of-the-art LRMs. This work advances the development of practical\nlong-context LRMs capable of robust reasoning across information-intensive\nenvironments.", "published": "2025-05-23 09:31:55", "link": "http://arxiv.org/abs/2505.17667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States", "abstract": "As Large Language Models (LLMs) increasingly participate in human-AI\ninteractions, evaluating their Theory of Mind (ToM) capabilities - particularly\ntheir ability to track dynamic mental states - becomes crucial. While existing\nbenchmarks assess basic ToM abilities, they predominantly focus on static\nsnapshots of mental states, overlooking the temporal evolution that\ncharacterizes real-world social interactions. We present \\textsc{DynToM}, a\nnovel benchmark specifically designed to evaluate LLMs' ability to understand\nand track the temporal progression of mental states across interconnected\nscenarios. Through a systematic four-step framework, we generate 1,100 social\ncontexts encompassing 5,500 scenarios and 78,100 questions, each validated for\nrealism and quality. Our comprehensive evaluation of ten state-of-the-art LLMs\nreveals that their average performance underperforms humans by 44.7\\%, with\nperformance degrading significantly when tracking and reasoning about the shift\nof mental states. This performance gap highlights fundamental limitations in\ncurrent LLMs' ability to model the dynamic nature of human mental states.", "published": "2025-05-23 09:27:40", "link": "http://arxiv.org/abs/2505.17663v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs", "abstract": "As large language models (LLMs) often generate plausible but incorrect\ncontent, error detection has become increasingly critical to ensure\ntruthfulness. However, existing detection methods often overlook a critical\nproblem we term as self-consistent error, where LLMs repeatly generate the same\nincorrect response across multiple stochastic samples. This work formally\ndefines self-consistent errors and evaluates mainstream detection methods on\nthem. Our investigation reveals two key findings: (1) Unlike inconsistent\nerrors, whose frequency diminishes significantly as LLM scale increases, the\nfrequency of self-consistent errors remains stable or even increases. (2) All\nfour types of detection methshods significantly struggle to detect\nself-consistent errors. These findings reveal critical limitations in current\ndetection methods and underscore the need for improved methods. Motivated by\nthe observation that self-consistent errors often differ across LLMs, we\npropose a simple but effective cross-model probe method that fuses hidden state\nevidence from an external verifier LLM. Our method significantly enhances\nperformance on self-consistent errors across three LLM families.", "published": "2025-05-23 09:18:56", "link": "http://arxiv.org/abs/2505.17656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications", "abstract": "E-commerce platforms increasingly rely on Large Language Models (LLMs) and\nVision-Language Models (VLMs) to detect illicit or misleading product content.\nHowever, these models remain vulnerable to evasive content: inputs (text or\nimages) that superficially comply with platform policies while covertly\nconveying prohibited claims. Unlike traditional adversarial attacks that induce\novert failures, evasive content exploits ambiguity and context, making it far\nharder to detect. Existing robustness benchmarks provide little guidance for\nthis demanding, real-world challenge. We introduce EVADE, the first\nexpert-curated, Chinese, multimodal benchmark specifically designed to evaluate\nfoundation models on evasive content detection in e-commerce. The dataset\ncontains 2,833 annotated text samples and 13,961 images spanning six demanding\nproduct categories, including body shaping, height growth, and health\nsupplements. Two complementary tasks assess distinct capabilities:\nSingle-Violation, which probes fine-grained reasoning under short prompts, and\nAll-in-One, which tests long-context reasoning by merging overlapping policy\nrules into unified instructions. Notably, the All-in-One setting significantly\nnarrows the performance gap between partial and full-match accuracy, suggesting\nthat clearer rule definitions improve alignment between human and model\njudgment. We benchmark 26 mainstream LLMs and VLMs and observe substantial\nperformance gaps: even state-of-the-art models frequently misclassify evasive\nsamples. By releasing EVADE and strong baselines, we provide the first rigorous\nstandard for evaluating evasive-content detection, expose fundamental\nlimitations in current multimodal reasoning, and lay the groundwork for safer\nand more transparent content moderation systems in e-commerce. The dataset is\npublicly available at https://huggingface.co/datasets/koenshen/EVADE-Bench.", "published": "2025-05-23 09:18:01", "link": "http://arxiv.org/abs/2505.17654v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning", "abstract": "Embodied agents operating in smart homes must understand human behavior\nthrough diverse sensory inputs and communicate via natural language. While\nVision-Language Models (VLMs) have enabled impressive language-grounded\nperception, their reliance on visual data limits robustness in real-world\nscenarios with occlusions, poor lighting, or privacy constraints. In this\npaper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that\nintegrates uncommon but powerful sensing modalities, such as LiDAR, infrared,\nmmWave radar, and WiFi, to enable seamless human perception and reasoning\nacross heterogeneous environments. We address two key challenges: (1) the\nscarcity of aligned modality-text data for rare sensors, and (2) the\nheterogeneity of their physical signal representations. To overcome these, we\ndesign a Universal Modality-Injection Projector (UMIP) that enhances\npre-aligned modality embeddings with fine-grained, text-aligned features from\ntailored encoders via coarse-to-fine cross-attention without introducing\nsignificant alignment overhead. We further introduce a human-VLM collaborative\ndata curation pipeline to generate paired textual annotations for sensing\ndatasets. Extensive experiments on two newly constructed benchmarks show that\nHoloLLM significantly outperforms existing MLLMs, improving language-grounded\nhuman sensing accuracy by up to 30%. This work establishes a new foundation for\nreal-world, language-informed multisensory embodied intelligence.", "published": "2025-05-23 09:06:09", "link": "http://arxiv.org/abs/2505.17645v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Bridging Electronic Health Records and Clinical Texts: Contrastive Learning for Enhanced Clinical Tasks", "abstract": "Conventional machine learning models, particularly tree-based approaches,\nhave demonstrated promising performance across various clinical prediction\ntasks using electronic health record (EHR) data. Despite their strengths, these\nmodels struggle with tasks that require deeper contextual understanding, such\nas predicting 30-day hospital readmission. This can be primarily due to the\nlimited semantic information available in structured EHR data. To address this\nlimitation, we propose a deep multimodal contrastive learning (CL) framework\nthat aligns the latent representations of structured EHR data with unstructured\ndischarge summary notes. It works by pulling together paired EHR and text\nembeddings while pushing apart unpaired ones. Fine-tuning the pretrained EHR\nencoder extracted from this framework significantly boosts downstream task\nperformance, e.g., a 4.1% AUROC enhancement over XGBoost for 30-day readmission\nprediction. Such results demonstrate the effect of integrating domain knowledge\nfrom clinical notes into EHR-based pipelines, enabling more accurate and\ncontext-aware clinical decision support systems.", "published": "2025-05-23 09:04:49", "link": "http://arxiv.org/abs/2505.17643v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stereotype Detection in Natural Language Processing", "abstract": "Stereotypes influence social perceptions and can escalate into discrimination\nand violence. While NLP research has extensively addressed gender bias and hate\nspeech, stereotype detection remains an emerging field with significant\nsocietal implications. In this work is presented a survey of existing research,\nanalyzing definitions from psychology, sociology, and philosophy. A\nsemi-automatic literature review was performed by using Semantic Scholar. We\nretrieved and filtered over 6,000 papers (in the year range 2000-2025),\nidentifying key trends, methodologies, challenges and future directions. The\nfindings emphasize stereotype detection as a potential early-monitoring tool to\nprevent bias escalation and the rise of hate speech. Conclusions highlight the\nneed for a broader, multilingual, and intersectional approach in NLP studies.", "published": "2025-05-23 09:03:56", "link": "http://arxiv.org/abs/2505.17642v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis", "abstract": "Various AI safety datasets have been developed to measure LLMs against\nevolving interpretations of harm. Our evaluation of five recently published\nopen-source safety benchmarks reveals distinct semantic clusters using UMAP\ndimensionality reduction and kmeans clustering (silhouette score: 0.470). We\nidentify six primary harm categories with varying benchmark representation.\nGretelAI, for example, focuses heavily on privacy concerns, while WildGuardMix\nemphasizes self-harm scenarios. Significant differences in prompt length\ndistribution suggests confounds to data collection and interpretations of harm\nas well as offer possible context. Our analysis quantifies benchmark\northogonality among AI benchmarks, allowing for transparency in coverage gaps\ndespite topical similarities. Our quantitative framework for analyzing semantic\northogonality across safety benchmarks enables more targeted development of\ndatasets that comprehensively address the evolving landscape of harms in AI\nuse, however that is defined in the future.", "published": "2025-05-23 08:53:11", "link": "http://arxiv.org/abs/2505.17636v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GIM: Improved Interpretability for Large Language Models", "abstract": "Ensuring faithful interpretability in large language models is imperative for\ntrustworthy and reliable AI. A key obstacle is self-repair, a phenomenon where\nnetworks compensate for reduced signal in one component by amplifying others,\nmasking the true importance of the ablated component. While prior work\nattributes self-repair to layer normalization and back-up components that\ncompensate for ablated components, we identify a novel form occurring within\nthe attention mechanism, where softmax redistribution conceals the influence of\nimportant attention scores. This leads traditional ablation and gradient-based\nmethods to underestimate the significance of all components contributing to\nthese attention scores. We introduce Gradient Interaction Modifications (GIM),\na technique that accounts for self-repair during backpropagation. Extensive\nexperiments across multiple large language models (Gemma 2B/9B, LLAMA 1B/3B/8B,\nQwen 1.5B/3B) and diverse tasks demonstrate that GIM significantly improves\nfaithfulness over existing circuit identification and feature attribution\nmethods. Our work is a significant step toward better understanding the inner\nmechanisms of LLMs, which is crucial for improving them and ensuring their\nsafety. Our code is available at https://github.com/JoakimEdin/gim.", "published": "2025-05-23 08:41:45", "link": "http://arxiv.org/abs/2505.17630v1", "categories": ["cs.CL", "cs.LG", "68T07", "I.2.0; I.2.7"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports", "abstract": "With recent advancements in Large Language Models (LLMs) and growing interest\nin retrieval-augmented generation (RAG), the ability to understand table\nstructures has become increasingly important. This is especially critical in\nfinancial domains such as securities reports, where highly accurate question\nanswering (QA) over tables is required. However, tables exist in various\nformats-including HTML, images, and plain text-making it difficult to preserve\nand extract structural information. Therefore, multimodal LLMs are essential\nfor robust and general-purpose table understanding. Despite their promise,\ncurrent Large Vision-Language Models (LVLMs), which are major representatives\nof multimodal LLMs, still face challenges in accurately understanding\ncharacters and their spatial relationships within documents. In this study, we\npropose a method to enhance LVLM-based table understanding by incorporating\nin-table textual content and layout features. Experimental results demonstrate\nthat these auxiliary modalities significantly improve performance, enabling\nrobust interpretation of complex document layouts without relying on explicitly\nstructured input formats.", "published": "2025-05-23 08:36:22", "link": "http://arxiv.org/abs/2505.17625v1", "categories": ["cs.CL", "cs.CV", "68T50", "I.2"], "primary_category": "cs.CL"}
{"title": "Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments", "abstract": "Agents powered by large language models (LLMs) have demonstrated strong\nplanning and decision-making capabilities in complex embodied environments.\nHowever, such agents often suffer from inefficiencies in multi-turn\ninteractions, frequently trapped in repetitive loops or issuing ineffective\ncommands, leading to redundant computational overhead. Instead of relying\nsolely on learning from trajectories, we take a first step toward exploring the\nearly-exit behavior for LLM-based agents. We propose two complementary\napproaches: 1. an $\\textbf{intrinsic}$ method that injects exit instructions\nduring generation, and 2. an $\\textbf{extrinsic}$ method that verifies task\ncompletion to determine when to halt an agent's trial. To evaluate early-exit\nmechanisms, we introduce two metrics: one measures the reduction of\n$\\textbf{redundant steps}$ as a positive effect, and the other evaluates\n$\\textbf{progress degradation}$ as a negative effect. Experiments with 4\ndifferent LLMs across 5 embodied environments show significant efficiency\nimprovements, with only minor drops in agent performance. We also validate a\npractical strategy where a stronger agent assists after an early-exit agent,\nachieving better performance with the same total steps. We will release our\ncode to support further research.", "published": "2025-05-23 08:23:36", "link": "http://arxiv.org/abs/2505.17616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large language model as user daily behavior data generator: balancing population diversity and individual personality", "abstract": "Predicting human daily behavior is challenging due to the complexity of\nroutine patterns and short-term fluctuations. While data-driven models have\nimproved behavior prediction by leveraging empirical data from various\nplatforms and devices, the reliance on sensitive, large-scale user data raises\nprivacy concerns and limits data availability. Synthetic data generation has\nemerged as a promising solution, though existing methods are often limited to\nspecific applications. In this work, we introduce BehaviorGen, a framework that\nuses large language models (LLMs) to generate high-quality synthetic behavior\ndata. By simulating user behavior based on profiles and real events,\nBehaviorGen supports data augmentation and replacement in behavior prediction\nmodels. We evaluate its performance in scenarios such as pertaining\naugmentation, fine-tuning replacement, and fine-tuning augmentation, achieving\nsignificant improvements in human mobility and smartphone usage predictions,\nwith gains of up to 18.9%. Our results demonstrate the potential of BehaviorGen\nto enhance user behavior modeling through flexible and privacy-preserving\nsynthetic data generation.", "published": "2025-05-23 08:22:09", "link": "http://arxiv.org/abs/2505.17615v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation", "abstract": "Automatically evaluating multimodal generation presents a significant\nchallenge, as automated metrics often struggle to align reliably with human\nevaluation, especially for complex tasks that involve multiple modalities. To\naddress this, we present MMMG, a comprehensive and human-aligned benchmark for\nmultimodal generation across 4 modality combinations (image, audio, interleaved\ntext and image, interleaved text and audio), with a focus on tasks that present\nsignificant challenges for generation models, while still enabling reliable\nautomatic evaluation through a combination of models and programs. MMMG\nencompasses 49 tasks (including 29 newly developed ones), each with a carefully\ndesigned evaluation pipeline, and 937 instructions to systematically assess\nreasoning, controllability, and other key capabilities of multimodal generation\nmodels. Extensive validation demonstrates that MMMG is highly aligned with\nhuman evaluation, achieving an average agreement of 94.3%. Benchmarking results\non 24 multimodal generation models reveal that even though the state-of-the-art\nmodel, GPT Image, achieves 78.3% accuracy for image generation, it falls short\non multimodal reasoning and interleaved generation. Furthermore, results\nsuggest considerable headroom for improvement in audio generation, highlighting\nan important direction for future research.", "published": "2025-05-23 08:21:28", "link": "http://arxiv.org/abs/2505.17613v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "abstract": "Large language models (LLMs) excel at complex reasoning tasks but remain\ncomputationally expensive, limiting their practical deployment. To address\nthis, recent works have focused on distilling reasoning capabilities into\nsmaller language models (sLMs) using chain-of-thought (CoT) traces from teacher\nLLMs. However, this approach struggles in scenarios requiring rare factual\nknowledge or precise computation, where sLMs often hallucinate due to limited\ncapability. In this work, we propose Agent Distillation, a framework for\ntransferring not only reasoning capability but full task-solving behavior from\nLLM-based agents into sLMs with retrieval and code tools. We improve agent\ndistillation along two complementary axes: (1) we introduce a prompting method\ncalled first-thought prefix to enhance the quality of teacher-generated\ntrajectories; and (2) we propose a self-consistent action generation for\nimproving test-time robustness of small agents. We evaluate our method on eight\nreasoning tasks across factual and mathematical domains, covering both\nin-domain and out-of-domain generalization. Our results show that sLMs as small\nas 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier\nlarger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the\npotential of agent distillation for building practical, tool-using small\nagents. Our code is available at https://github.com/Nardien/agent-distillation.", "published": "2025-05-23 08:20:15", "link": "http://arxiv.org/abs/2505.17612v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis", "abstract": "This work presents a dual-agent Large Language Model (LLM)-based reasoning\nmethod for mechanism synthesis, capable of reasoning at both linguistic and\nsymbolic levels to generate geometrical and dynamic outcomes. The model\nconsists of a composition of well-defined functions that, starting from a\nnatural language specification, references abstract properties through\nsupporting equations, generates and parametrizes simulation code, and elicits\nfeedback anchor points using symbolic regression and distance functions. This\nprocess closes an actionable refinement loop at the linguistic and symbolic\nlayers. The approach is shown to be both effective and convergent in the\ncontext of planar mechanisms. Additionally, we introduce MSynth, a novel\nbenchmark for planar mechanism synthesis, and perform a comprehensive analysis\nof the impact of the model components. We further demonstrate that symbolic\nregression prompts unlock mechanistic insights only when applied to\nsufficiently large architectures.", "published": "2025-05-23 08:16:32", "link": "http://arxiv.org/abs/2505.17607v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models", "abstract": "Supervised fine-tuning (SFT) aligns large language models (LLMs) with human\nintent by training them on labeled task-specific data. Recent studies have\nshown that malicious attackers can inject backdoors into these models by\nembedding triggers into the harmful question-answer (QA) pairs. However,\nexisting poisoning attacks face two critical limitations: (1) they are easily\ndetected and filtered by safety-aligned guardrails (e.g., LLaMAGuard), and (2)\nembedding harmful content can undermine the model's safety alignment, resulting\nin high attack success rates (ASR) even in the absence of triggers during\ninference, thus compromising stealthiness. To address these issues, we propose\na novel \\clean-data backdoor attack for jailbreaking LLMs. Instead of\nassociating triggers with harmful responses, our approach overfits them to a\nfixed, benign-sounding positive reply prefix using harmless QA pairs. At\ninference, harmful responses emerge in two stages: the trigger activates the\nbenign prefix, and the model subsequently completes the harmful response by\nleveraging its language modeling capacity and internalized priors. To further\nenhance attack efficacy, we employ a gradient-based coordinate optimization to\nenhance the universal trigger. Extensive experiments demonstrate that our\nmethod can effectively jailbreak backdoor various LLMs even under the detection\nof guardrail models, e.g., an ASR of 86.67% and 85% on LLaMA-3-8B and\nQwen-2.5-7B judged by GPT-4o.", "published": "2025-05-23 08:13:59", "link": "http://arxiv.org/abs/2505.17601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs", "abstract": "Safety alignment in large language models (LLMs) is increasingly compromised\nby jailbreak attacks, which can manipulate these models to generate harmful or\nunintended content. Investigating these attacks is crucial for uncovering model\nvulnerabilities. However, many existing jailbreak strategies fail to keep pace\nwith the rapid development of defense mechanisms, such as defensive suffixes,\nrendering them ineffective against defended models. To tackle this issue, we\nintroduce a novel attack method called ArrAttack, specifically designed to\ntarget defended LLMs. ArrAttack automatically generates robust jailbreak\nprompts capable of bypassing various defense measures. This capability is\nsupported by a universal robustness judgment model that, once trained, can\nperform robustness evaluation for any target model with a wide variety of\ndefenses. By leveraging this model, we can rapidly develop a robust jailbreak\nprompt generator that efficiently converts malicious input prompts into\neffective attacks. Extensive evaluations reveal that ArrAttack significantly\noutperforms existing attack strategies, demonstrating strong transferability\nacross both white-box and black-box models, including GPT-4 and Claude-3. Our\nwork bridges the gap between jailbreak attacks and defenses, providing a fresh\nperspective on generating robust jailbreak prompts. We make the codebase\navailable at https://github.com/LLBao/ArrAttack.", "published": "2025-05-23 08:02:38", "link": "http://arxiv.org/abs/2505.17598v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "NeUQI: Near-Optimal Uniform Quantization Parameter Initialization", "abstract": "Large language models (LLMs) achieve impressive performance across domains\nbut face significant challenges when deployed on consumer-grade GPUs or\npersonal devices such as laptops, due to high memory consumption and inference\ncosts. Post-training quantization (PTQ) of LLMs offers a promising solution\nthat reduces their memory footprint and decoding latency. In practice, PTQ with\nuniform quantization representation is favored for its efficiency and ease of\ndeployment since uniform quantization is widely supported by mainstream\nhardware and software libraries. Recent studies on $\\geq 2$-bit uniform\nquantization have led to noticeable improvements in post-quantization model\nperformance; however, they primarily focus on quantization methodologies, while\nthe initialization of quantization parameters is underexplored and still relies\non the suboptimal Min-Max strategies. In this work, we propose NeUQI, a method\ndevoted to efficiently determining near-optimal initial parameters for uniform\nquantization. NeUQI is orthogonal to prior quantization methodologies and can\nseamlessly integrate with them. The experiments with the LLaMA and Qwen\nfamilies on various tasks demonstrate that our NeUQI consistently outperforms\nexisting methods. Furthermore, when combined with a lightweight distillation\nstrategy, NeUQI can achieve superior performance to PV-tuning, a much more\nresource-intensive approach.", "published": "2025-05-23 07:59:46", "link": "http://arxiv.org/abs/2505.17595v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reasoning Meets Personalization: Unleashing the Potential of Large Reasoning Model for Personalized Generation", "abstract": "Personalization is a critical task in modern intelligent systems, with\napplications spanning diverse domains, including interactions with large\nlanguage models (LLMs). Recent advances in reasoning capabilities have\nsignificantly enhanced LLMs, enabling unprecedented performance in tasks such\nas mathematics and coding. However, their potential for personalization tasks\nremains underexplored.\n  In this paper, we present the first systematic evaluation of large reasoning\nmodels (LRMs) for personalization tasks. Surprisingly, despite generating more\ntokens, LRMs do not consistently outperform general-purpose LLMs, especially in\nretrieval-intensive scenarios where their advantages diminish. Our analysis\nidentifies three key limitations: divergent thinking, misalignment of response\nformats, and ineffective use of retrieved information. To address these\nchallenges, we propose Reinforced Reasoning for Personalization (\\model), a\nnovel framework that incorporates a hierarchical reasoning thought template to\nguide LRMs in generating structured outputs. Additionally, we introduce a\nreasoning process intervention method to enforce adherence to designed\nreasoning patterns, enhancing alignment. We also propose a cross-referencing\nmechanism to ensure consistency. Extensive experiments demonstrate that our\napproach significantly outperforms existing techniques.", "published": "2025-05-23 07:30:13", "link": "http://arxiv.org/abs/2505.17571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PPT: A Process-based Preference Learning Framework for Self Improving Table Question Answering Models", "abstract": "Improving large language models (LLMs) with self-generated data has\ndemonstrated success in tasks such as mathematical reasoning and code\ngeneration. Yet, no exploration has been made on table question answering\n(TQA), where a system answers questions based on tabular data. Addressing this\ngap is crucial for TQA, as effective self-improvement can boost performance\nwithout requiring costly or manually annotated data. In this work, we propose\nPPT, a Process-based Preference learning framework for TQA. It decomposes\nreasoning chains into discrete states, assigns scores to each state, and\nsamples contrastive steps for preference learning. Experimental results show\nthat PPT effectively improves TQA models by up to 5% on in-domain datasets and\n2.4% on out-of-domain datasets, with only 8,000 preference pairs. Furthermore,\nthe resulting models achieve competitive results compared to more complex and\nlarger state-of-the-art TQA systems, while being five times more efficient\nduring inference.", "published": "2025-05-23 07:24:53", "link": "http://arxiv.org/abs/2505.17565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching with Lies: Curriculum DPO on Synthetic Negatives for Hallucination Detection", "abstract": "Aligning large language models (LLMs) to accurately detect hallucinations\nremains a significant challenge due to the sophisticated nature of hallucinated\ntext. Recognizing that hallucinated samples typically exhibit higher deceptive\nquality than traditional negative samples, we use these carefully engineered\nhallucinations as negative examples in the DPO alignment procedure. Our method\nincorporates a curriculum learning strategy, gradually transitioning the\ntraining from easier samples, identified based on the greatest reduction in\nprobability scores from independent fact checking models, to progressively\nharder ones. This structured difficulty scaling ensures stable and incremental\nlearning. Experimental evaluation demonstrates that our HaluCheck models,\ntrained with curriculum DPO approach and high quality negative samples,\nsignificantly improves model performance across various metrics, achieving\nimprovements of upto 24% on difficult benchmarks like MedHallu and HaluEval.\nAdditionally, HaluCheck models demonstrate robustness in zero-shot settings,\nsignificantly outperforming larger state-of-the-art models across various\nbenchmarks.", "published": "2025-05-23 07:05:09", "link": "http://arxiv.org/abs/2505.17558v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoMoE: Contrastive Representation for Mixture-of-Experts in Parameter-Efficient Fine-tuning", "abstract": "In parameter-efficient fine-tuning, mixture-of-experts (MoE), which involves\nspecializing functionalities into different experts and sparsely activating\nthem appropriately, has been widely adopted as a promising approach to\ntrade-off between model capacity and computation overhead. However, current MoE\nvariants fall short on heterogeneous datasets, ignoring the fact that experts\nmay learn similar knowledge, resulting in the underutilization of MoE's\ncapacity. In this paper, we propose Contrastive Representation for MoE (CoMoE),\na novel method to promote modularization and specialization in MoE, where the\nexperts are trained along with a contrastive objective by sampling from\nactivated and inactivated experts in top-k routing. We demonstrate that such a\ncontrastive objective recovers the mutual-information gap between inputs and\nthe two types of experts. Experiments on several benchmarks and in multi-task\nsettings demonstrate that CoMoE can consistently enhance MoE's capacity and\npromote modularization among the experts.", "published": "2025-05-23 06:58:44", "link": "http://arxiv.org/abs/2505.17553v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition", "abstract": "This work presents a suite of fine-tuned Whisper models for Swedish, trained\non a dataset of unprecedented size and variability for this mid-resourced\nlanguage. As languages of smaller sizes are often underrepresented in\nmultilingual training datasets, substantial improvements in performance can be\nachieved by fine-tuning existing multilingual models, as shown in this work.\nThis work reports an overall improvement across model sizes compared to\nOpenAI's Whisper evaluated on Swedish. Most notably, we report an average 47%\nreduction in WER comparing our best performing model to OpenAI's\nwhisper-large-v3, in evaluations across FLEURS, Common Voice, and NST.", "published": "2025-05-23 06:42:16", "link": "http://arxiv.org/abs/2505.17538v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "How Knowledge Popularity Influences and Enhances LLM Knowledge Boundary Perception", "abstract": "Large language models (LLMs) often fail to recognize their knowledge\nboundaries, producing confident yet incorrect answers. In this paper, we\ninvestigate how knowledge popularity affects LLMs' ability to perceive their\nknowledge boundaries. Focusing on entity-centric factual question answering\n(QA), we quantify knowledge popularity from three perspectives: the popularity\nof entities in the question, the popularity of entities in the answer, and\nrelation popularity, defined as their co-occurrence frequency. Experiments on\nthree representative datasets containing knowledge with varying popularity show\nthat LLMs exhibit better QA performance, higher confidence, and more accurate\nperception on more popular knowledge, with relation popularity having the\nstrongest correlation. Cause knowledge popularity shows strong correlation with\nLLMs' QA performance, we propose to leverage these signals for confidence\ncalibration. This improves the accuracy of answer correctness prediction by an\naverage of 5.24% across all models and datasets. Furthermore, we explore\nprompting LLMs to estimate popularity without external corpora, which yields a\nviable alternative.", "published": "2025-05-23 06:42:06", "link": "http://arxiv.org/abs/2505.17537v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Conversation Structure Understanding", "abstract": "Conversations are usually structured by roles -- who is speaking, who's being\naddressed, and who's listening -- and unfold in threads that break with changes\nin speaker floor or topical focus. While large language models (LLMs) have\nshown incredible capabilities in dialogue and reasoning, their ability to\nunderstand fine-grained conversational structure, especially in multi-modal,\nmulti-party settings, remains underexplored. To address this gap, we introduce\na suite of tasks focused on conversational role attribution (speaker,\naddressees, side-participants) and conversation threading (utterance linking\nand clustering), drawing on conversation analysis and sociolinguistics. To\nsupport those tasks, we present a human annotated dataset of 4,398 annotations\nfor speakers and reply-to relationship, 5,755 addressees, and 3,142\nside-participants.\n  We evaluate popular audio-visual LLMs and vision-language models on our\ndataset, and our experimental results suggest that multimodal conversational\nstructure understanding remains challenging. The most performant audio-visual\nLLM outperforms all vision-language models across all metrics, especially in\nspeaker and addressee recognition. However, its performance drops significantly\nwhen conversation participants are anonymized. The number of conversation\nparticipants in a clip is the strongest negative predictor of role-attribution\nperformance, while acoustic clarity (measured by pitch and spectral centroid)\nand detected face coverage yield positive associations. We hope this work lays\nthe groundwork for future evaluation and development of multimodal LLMs that\ncan reason more effectively about conversation structure.", "published": "2025-05-23 06:41:54", "link": "http://arxiv.org/abs/2505.17536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-Reinforcement Learning for Unified Multimodal Understanding and Generation", "abstract": "This paper presents a pioneering exploration of reinforcement learning (RL)\nvia group relative policy optimization for unified multimodal large language\nmodels (ULMs), aimed at simultaneously reinforcing generation and understanding\ncapabilities. Through systematic pilot studies, we uncover the significant\npotential of ULMs to enable the synergistic co-evolution of dual capabilities\nwithin a shared policy optimization framework. Building on this insight, we\nintroduce \\textbf{CoRL}, a co-reinforcement learning framework comprising a\nunified RL stage for joint optimization and a refined RL stage for\ntask-specific enhancement. With the proposed CoRL, our resulting model,\n\\textbf{ULM-R1}, achieves average improvements of \\textbf{7%} on three\ntext-to-image generation datasets and \\textbf{23%} on nine multimodal\nunderstanding benchmarks. These results demonstrate the effectiveness of CoRL\nand highlight the substantial benefit of reinforcement learning in facilitating\ncross-task synergy and optimization for ULMs.", "published": "2025-05-23 06:41:07", "link": "http://arxiv.org/abs/2505.17534v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Chain-of-Lure: A Synthetic Narrative-Driven Approach to Compromise Large Language Models", "abstract": "In the era of rapid generative AI development, interactions between humans\nand large language models face significant misusing risks. Previous research\nhas primarily focused on black-box scenarios using human-guided prompts and\nwhite-box scenarios leveraging gradient-based LLM generation methods,\nneglecting the possibility that LLMs can act not only as victim models, but\nalso as attacker models to harm other models. We proposes a novel jailbreaking\nmethod inspired by the Chain-of-Thought mechanism, where the attacker model\nuses mission transfer to conceal harmful user intent in dialogue and generates\nchained narrative lures to stimulate the reasoning capabilities of victim\nmodels, leading to successful jailbreaking. To enhance the attack success rate,\nwe introduce a helper model that performs random narrative optimization on the\nnarrative lures during multi-turn dialogues while ensuring alignment with the\noriginal intent, enabling the optimized lures to bypass the safety barriers of\nvictim models effectively. Our experiments reveal that models with weaker\nsafety mechanisms exhibit stronger attack capabilities, demonstrating that\nmodels can not only be exploited, but also help harm others. By incorporating\ntoxicity scores, we employ third-party models to evaluate the harmfulness of\nvictim models' responses to jailbreaking attempts. The study shows that using\nrefusal keywords as an evaluation metric for attack success rates is\nsignificantly flawed because it does not assess whether the responses guide\nharmful questions, while toxicity scores measure the harm of generated content\nwith more precision and its alignment with harmful questions. Our approach\ndemonstrates outstanding performance, uncovering latent vulnerabilities in LLMs\nand providing data-driven feedback to optimize LLM safety mechanisms. We also\ndiscuss two defensive strategies to offer guidance on improving defense\nmechanisms.", "published": "2025-05-23 06:19:05", "link": "http://arxiv.org/abs/2505.17519v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection", "abstract": "Recent advances in text-to-speech technologies have enabled realistic voice\ngeneration, fueling audio-based deepfake attacks such as fraud and\nimpersonation. While audio anti-spoofing systems are critical for detecting\nsuch threats, prior work has predominantly focused on acoustic-level\nperturbations, leaving the impact of linguistic variation largely unexplored.\nIn this paper, we investigate the linguistic sensitivity of both open-source\nand commercial anti-spoofing detectors by introducing transcript-level\nadversarial attacks. Our extensive evaluation reveals that even minor\nlinguistic perturbations can significantly degrade detection accuracy: attack\nsuccess rates surpass 60% on several open-source detector-voice pairs, and\nnotably one commercial detection accuracy drops from 100% on synthetic audio to\njust 32%. Through a comprehensive feature attribution analysis, we identify\nthat both linguistic complexity and model-level audio embedding similarity\ncontribute strongly to detector vulnerability. We further demonstrate the\nreal-world risk via a case study replicating the Brad Pitt audio deepfake scam,\nusing transcript adversarial attacks to completely bypass commercial detectors.\nThese results highlight the need to move beyond purely acoustic defenses and\naccount for linguistic variation in the design of robust anti-spoofing systems.\nAll source code will be publicly available.", "published": "2025-05-23 06:06:37", "link": "http://arxiv.org/abs/2505.17513v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "53-04"], "primary_category": "cs.LG"}
{"title": "Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs", "abstract": "Concepts represent generalized abstractions that enable humans to categorize\nand reason efficiently, yet it is unclear to what extent Large Language Models\n(LLMs) comprehend these semantic relationships. Existing benchmarks typically\nfocus on factual recall and isolated tasks, failing to evaluate the ability of\nLLMs to understand conceptual boundaries. To address this gap, we introduce\nCK-Arena, a multi-agent interaction game built upon the Undercover game,\ndesigned to evaluate the capacity of LLMs to reason with concepts in\ninteractive settings. CK-Arena challenges models to describe, differentiate,\nand infer conceptual boundaries based on partial information, encouraging\nmodels to explore commonalities and distinctions between closely related\nconcepts. By simulating real-world interaction, CK-Arena provides a scalable\nand realistic benchmark for assessing conceptual reasoning in dynamic\nenvironments. Experimental results show that LLMs' understanding of conceptual\nknowledge varies significantly across different categories and is not strictly\naligned with parameter size or general model capabilities. The data and code\nare available at the project homepage: https://ck-arena.site.", "published": "2025-05-23 06:06:28", "link": "http://arxiv.org/abs/2505.17512v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Large Language Models Do Multi-Label Classification Differently", "abstract": "Multi-label classification is prevalent in real-world settings, but the\nbehavior of Large Language Models (LLMs) in this setting is understudied. We\ninvestigate how autoregressive LLMs perform multi-label classification, with a\nfocus on subjective tasks, by analyzing the output distributions of the models\nin each generation step. We find that their predictive behavior reflects the\nmultiple steps in the underlying language modeling required to generate all\nrelevant labels as they tend to suppress all but one label at each step. We\nfurther observe that as model scale increases, their token distributions\nexhibit lower entropy, yet the internal ranking of the labels improves.\nFinetuning methods such as supervised finetuning and reinforcement learning\namplify this phenomenon. To further study this issue, we introduce the task of\ndistribution alignment for multi-label settings: aligning LLM-derived label\ndistributions with empirical distributions estimated from annotator responses\nin subjective tasks. We propose both zero-shot and supervised methods which\nimprove both alignment and predictive performance over existing approaches.", "published": "2025-05-23 06:04:36", "link": "http://arxiv.org/abs/2505.17510v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning", "abstract": "Policy gradient algorithms have been successfully applied to enhance the\nreasoning capabilities of large language models (LLMs). Despite the widespread\nuse of Kullback-Leibler (KL) regularization in policy gradient algorithms to\nstabilize training, the systematic exploration of how different KL divergence\nformulations can be estimated and integrated into surrogate loss functions for\nonline reinforcement learning (RL) presents a nuanced and systematically\nexplorable design space. In this paper, we propose regularized policy gradient\n(RPG), a systematic framework for deriving and analyzing KL-regularized policy\ngradient methods in the online RL setting. We derive policy gradients and\ncorresponding surrogate loss functions for objectives regularized by both\nforward and reverse KL divergences, considering both normalized and\nunnormalized policy distributions. Furthermore, we present derivations for\nfully differentiable loss functions as well as REINFORCE-style gradient\nestimators, accommodating diverse algorithmic needs. We conduct extensive\nexperiments on RL for LLM reasoning using these methods, showing improved or\ncompetitive results in terms of training stability and performance compared to\nstrong baselines such as GRPO, REINFORCE++, and DAPO. The code is available at\nhttps://github.com/complex-reasoning/RPG.", "published": "2025-05-23 06:01:21", "link": "http://arxiv.org/abs/2505.17508v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models", "abstract": "Large language models (LLMs) have achieved notable progress. Despite their\nsuccess, next-token prediction (NTP), the dominant method for LLM training and\ninference, is constrained in both contextual coverage and inference efficiency\ndue to its inherently sequential process. To overcome these challenges, we\npropose leap multi-token prediction~(L-MTP), an innovative token prediction\nmethod that extends the capabilities of multi-token prediction (MTP) by\nintroducing a leap-based mechanism. Unlike conventional MTP, which generates\nmultiple tokens at adjacent positions, L-MTP strategically skips over\nintermediate tokens, predicting non-sequential ones in a single forward pass.\nThis structured leap not only enhances the model's ability to capture\nlong-range dependencies but also enables a decoding strategy specially\noptimized for non-sequential leap token generation, effectively accelerating\ninference. We theoretically demonstrate the benefit of L-MTP in improving\ninference efficiency. Experiments across diverse benchmarks validate its merit\nin boosting both LLM performance and inference speed. The source code will be\npublicly available.", "published": "2025-05-23 05:59:46", "link": "http://arxiv.org/abs/2505.17505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CReSt: A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents", "abstract": "Large Language Models (LLMs) have made substantial progress in recent years,\nyet evaluating their capabilities in practical Retrieval-Augmented Generation\n(RAG) scenarios remains challenging. In practical applications, LLMs must\ndemonstrate complex reasoning, refuse to answer appropriately, provide precise\ncitations, and effectively understand document layout. These capabilities are\ncrucial for advanced task handling, uncertainty awareness, maintaining\nreliability, and structural understanding. While some of the prior works\naddress these aspects individually, there is a need for a unified framework\nthat evaluates them collectively in practical RAG scenarios. To address this,\nwe present CReSt (A Comprehensive Benchmark for Retrieval-Augmented Generation\nwith Complex Reasoning over Structured Documents), a benchmark designed to\nassess these key dimensions holistically. CReSt comprises 2,245 human-annotated\nexamples in English and Korean, designed to capture practical RAG scenarios\nthat require complex reasoning over structured documents. It also introduces a\ntailored evaluation methodology to comprehensively assess model performance in\nthese critical areas. Our evaluation shows that even advanced LLMs struggle to\nperform consistently across these dimensions, underscoring key areas for\nimprovement. We release CReSt to support further research and the development\nof more robust RAG systems. The dataset and code are available at:\nhttps://github.com/UpstageAI/CReSt.", "published": "2025-05-23 05:56:25", "link": "http://arxiv.org/abs/2505.17503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Mitigation Strategies for Catastrophic Forgetting in End-to-End Training of Spoken Language Models", "abstract": "End-to-end training of Spoken Language Models (SLMs) commonly involves\nadapting pre-trained text-based Large Language Models (LLMs) to the speech\nmodality through multi-stage training on diverse tasks such as ASR, TTS and\nspoken question answering (SQA). Although this multi-stage continual learning\nequips LLMs with both speech understanding and generation capabilities, the\nsubstantial differences in task and data distributions across stages can lead\nto catastrophic forgetting, where previously acquired knowledge is lost. This\npaper investigates catastrophic forgetting and evaluates three mitigation\nstrategies-model merging, discounting the LoRA scaling factor, and experience\nreplay to balance knowledge retention with new learning. Results show that\nexperience replay is the most effective, with further gains achieved by\ncombining it with other methods. These findings provide insights for developing\nmore robust and efficient SLM training pipelines.", "published": "2025-05-23 05:50:14", "link": "http://arxiv.org/abs/2505.17496v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs", "abstract": "Large Language Models (LLMs) have achieved remarkable performance by\ncapturing complex interactions between input features. To identify these\ninteractions, most existing approaches require enumerating all possible\ncombinations of features up to a given order, causing them to scale poorly with\nthe number of inputs $n$. Recently, Kang et al. (2025) proposed SPEX, an\ninformation-theoretic approach that uses interaction sparsity to scale to $n\n\\approx 10^3$ features. SPEX greatly improves upon prior methods but requires\ntens of thousands of model inferences, which can be prohibitive for large\nmodels. In this paper, we observe that LLM feature interactions are often\nhierarchical -- higher-order interactions are accompanied by their lower-order\nsubsets -- which enables more efficient discovery. To exploit this hierarchy,\nwe propose ProxySPEX, an interaction attribution algorithm that first fits\ngradient boosted trees to masked LLM outputs and then extracts the important\ninteractions. Experiments across four challenging high-dimensional datasets\nshow that ProxySPEX more faithfully reconstructs LLM outputs by 20% over\nmarginal attribution approaches while using $10\\times$ fewer inferences than\nSPEX. By accounting for interactions, ProxySPEX identifies features that\ninfluence model output over 20% more than those selected by marginal\napproaches. Further, we apply ProxySPEX to two interpretability tasks. Data\nattribution, where we identify interactions among CIFAR-10 training samples\nthat influence test predictions, and mechanistic interpretability, where we\nuncover interactions between attention heads, both within and across layers, on\na question-answering task. ProxySPEX identifies interactions that enable more\naggressive pruning of heads than marginal approaches.", "published": "2025-05-23 05:44:01", "link": "http://arxiv.org/abs/2505.17495v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions", "abstract": "WonderPlay is a novel framework integrating physics simulation with video\ngeneration for generating action-conditioned dynamic 3D scenes from a single\nimage. While prior works are restricted to rigid body or simple elastic\ndynamics, WonderPlay features a hybrid generative simulator to synthesize a\nwide range of 3D dynamics. The hybrid generative simulator first uses a physics\nsolver to simulate coarse 3D dynamics, which subsequently conditions a video\ngenerator to produce a video with finer, more realistic motion. The generated\nvideo is then used to update the simulated dynamic 3D scene, closing the loop\nbetween the physics solver and the video generator. This approach enables\nintuitive user control to be combined with the accurate dynamics of\nphysics-based simulators and the expressivity of diffusion-based video\ngenerators. Experimental results demonstrate that WonderPlay enables users to\ninteract with various scenes of diverse content, including cloth, sand, snow,\nliquid, smoke, elastic, and rigid bodies -- all using a single image input.\nCode will be made public. Project website:\nhttps://kyleleey.github.io/WonderPlay/", "published": "2025-05-23 17:59:24", "link": "http://arxiv.org/abs/2505.18151v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems", "abstract": "This position paper argues that the theoretical inconsistency often observed\namong Responsible AI (RAI) metrics, such as differing fairness definitions or\ntradeoffs between accuracy and privacy, should be embraced as a valuable\nfeature rather than a flaw to be eliminated. We contend that navigating these\ninconsistencies, by treating metrics as divergent objectives, yields three key\nbenefits: (1) Normative Pluralism: Maintaining a full suite of potentially\ncontradictory metrics ensures that the diverse moral stances and stakeholder\nvalues inherent in RAI are adequately represented. (2) Epistemological\nCompleteness: The use of multiple, sometimes conflicting, metrics allows for a\nmore comprehensive capture of multifaceted ethical concepts, thereby preserving\ngreater informational fidelity about these concepts than any single, simplified\ndefinition. (3) Implicit Regularization: Jointly optimizing for theoretically\nconflicting objectives discourages overfitting to one specific metric, steering\nmodels towards solutions with enhanced generalization and robustness under\nreal-world complexities. In contrast, efforts to enforce theoretical\nconsistency by simplifying or pruning metrics risk narrowing this value\ndiversity, losing conceptual depth, and degrading model performance. We\ntherefore advocate for a shift in RAI theory and practice: from getting trapped\nin inconsistency to characterizing acceptable inconsistency thresholds and\nelucidating the mechanisms that permit robust, approximated consistency in\npractice.", "published": "2025-05-23 17:48:09", "link": "http://arxiv.org/abs/2505.18139v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Leveraging KANs for Expedient Training of Multichannel MLPs via Preconditioning and Geometric Refinement", "abstract": "Multilayer perceptrons (MLPs) are a workhorse machine learning architecture,\nused in a variety of modern deep learning frameworks. However, recently\nKolmogorov-Arnold Networks (KANs) have become increasingly popular due to their\nsuccess on a range of problems, particularly for scientific machine learning\ntasks. In this paper, we exploit the relationship between KANs and multichannel\nMLPs to gain structural insight into how to train MLPs faster. We demonstrate\nthe KAN basis (1) provides geometric localized support, and (2) acts as a\npreconditioned descent in the ReLU basis, overall resulting in expedited\ntraining and improved accuracy. Our results show the equivalence between\nfree-knot spline KAN architectures, and a class of MLPs that are refined\ngeometrically along the channel dimension of each weight tensor. We exploit\nthis structural equivalence to define a hierarchical refinement scheme that\ndramatically accelerates training of the multi-channel MLP architecture. We\nshow further accuracy improvements can be had by allowing the $1$D locations of\nthe spline knots to be trained simultaneously with the weights. These advances\nare demonstrated on a range of benchmark examples for regression and scientific\nmachine learning.", "published": "2025-05-23 17:41:18", "link": "http://arxiv.org/abs/2505.18131v1", "categories": ["cs.LG", "cs.AI", "68T99", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Bidirectional Knowledge Distillation for Enhancing Sequential Recommendation with Large Language Models", "abstract": "Large language models (LLMs) have demonstrated exceptional performance in\nunderstanding and generating semantic patterns, making them promising\ncandidates for sequential recommendation tasks. However, when combined with\nconventional recommendation models (CRMs), LLMs often face challenges related\nto high inference costs and static knowledge transfer methods. In this paper,\nwe propose a novel mutual distillation framework, LLMD4Rec, that fosters\ndynamic and bidirectional knowledge exchange between LLM-centric and CRM-based\nrecommendation systems. Unlike traditional unidirectional distillation methods,\nLLMD4Rec enables iterative optimization by alternately refining both models,\nenhancing the semantic understanding of CRMs and enriching LLMs with\ncollaborative signals from user-item interactions. By leveraging sample-wise\nadaptive weighting and aligning output distributions, our approach eliminates\nthe need for additional parameters while ensuring effective knowledge transfer.\nExtensive experiments on real-world datasets demonstrate that LLMD4Rec\nsignificantly improves recommendation accuracy across multiple benchmarks\nwithout increasing inference costs. This method provides a scalable and\nefficient solution for combining the strengths of both LLMs and CRMs in\nsequential recommendation systems.", "published": "2025-05-23 17:21:14", "link": "http://arxiv.org/abs/2505.18120v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays", "abstract": "Recent progress in Large Vision-Language Models (LVLMs) has enabled promising\napplications in medical tasks, such as report generation and visual question\nanswering. However, existing benchmarks focus mainly on the final diagnostic\nanswer, offering limited insight into whether models engage in clinically\nmeaningful reasoning. To address this, we present CheXStruct and CXReasonBench,\na structured pipeline and benchmark built on the publicly available\nMIMIC-CXR-JPG dataset. CheXStruct automatically derives a sequence of\nintermediate reasoning steps directly from chest X-rays, such as segmenting\nanatomical regions, deriving anatomical landmarks and diagnostic measurements,\ncomputing diagnostic indices, and applying clinical thresholds. CXReasonBench\nleverages this pipeline to evaluate whether models can perform clinically valid\nreasoning steps and to what extent they can learn from structured guidance,\nenabling fine-grained and transparent assessment of diagnostic reasoning. The\nbenchmark comprises 18,988 QA pairs across 12 diagnostic tasks and 1,200 cases,\neach paired with up to 4 visual inputs, and supports multi-path, multi-stage\nevaluation including visual grounding via anatomical region selection and\ndiagnostic measurements. Even the strongest of 10 evaluated LVLMs struggle with\nstructured reasoning and generalization, often failing to link abstract\nknowledge with anatomically grounded visual interpretation. The code is\navailable at https://github.com/ttumyche/CXReasonBench", "published": "2025-05-23 16:44:21", "link": "http://arxiv.org/abs/2505.18087v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Stable Reinforcement Learning for Efficient Reasoning", "abstract": "The success of Deepseek-R1 has drawn the LLM community's attention to\nreinforcement learning (RL) methods like GRPO. However, such rule-based 0/1\noutcome reward methods lack the capability to regulate the intermediate\nreasoning processes during chain-of-thought (CoT) generation, leading to severe\noverthinking phenomena. In response, recent studies have designed reward\nfunctions to reinforce models' behaviors in producing shorter yet correct\ncompletions. Nevertheless, we observe that these length-penalty reward\nfunctions exacerbate RL training instability: as the completion length\ndecreases, model accuracy abruptly collapses, often occurring early in\ntraining. To address this issue, we propose a simple yet effective solution\nGRPO-$\\lambda$, an efficient and stabilized variant of GRPO, which dynamically\nadjusts the reward strategy by monitoring the correctness ratio among\ncompletions within each query-sampled group. A low correctness ratio indicates\nthe need to avoid length penalty that compromises CoT quality, triggering a\nswitch to length-agnostic 0/1 rewards that prioritize reasoning capability. A\nhigh ratio maintains length penalties to boost efficiency. Experimental results\nshow that our approach avoids training instability caused by length penalty\nwhile maintaining the optimal accuracy-efficiency trade-off. On the GSM8K,\nGPQA, MATH-500, AMC 2023, and AIME 2024 benchmarks, it improves average\naccuracy by 1.48% while reducing CoT sequence length by 47.3%.", "published": "2025-05-23 16:43:03", "link": "http://arxiv.org/abs/2505.18086v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Backpropagation-Free Metropolis-Adjusted Langevin Algorithm", "abstract": "Recent work on backpropagation-free learning has shown that it is possible to\nuse forward-mode automatic differentiation (AD) to perform optimization on\ndifferentiable models. Forward-mode AD requires sampling a tangent vector for\neach forward pass of a model. The result is the model evaluation with the\ndirectional derivative along the tangent. In this paper, we illustrate how the\nsampling of this tangent vector can be incorporated into the proposal mechanism\nfor the Metropolis-Adjusted Langevin Algorithm (MALA). As such, we are the\nfirst to introduce a backpropagation-free gradient-based Markov chain Monte\nCarlo (MCMC) algorithm. We also extend to a novel backpropagation-free\nposition-specific preconditioned forward-mode MALA that leverages Hessian\ninformation. Overall, we propose four new algorithms: Forward MALA; Line\nForward MALA; Pre-conditioned Forward MALA, and Pre-conditioned Line Forward\nMALA. We highlight the reduced computational cost of the forward-mode samplers\nand show that forward-mode is competitive with the original MALA, while even\noutperforming it depending on the probabilistic model. We include Bayesian\ninference results on a range of probabilistic models, including hierarchical\ndistributions and Bayesian neural networks.", "published": "2025-05-23 16:39:21", "link": "http://arxiv.org/abs/2505.18081v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AFD-STA: Adaptive Filtering Denoising with Spatiotemporal Attention for Chaotic System Prediction", "abstract": "This paper presents AFD-STA Net, a neural framework integrating adaptive\nfiltering and spatiotemporal dynamics learning for predicting high-dimensional\nchaotic systems governed by partial differential equations. The architecture\ncombines: 1) An adaptive exponential smoothing module with position-aware decay\ncoefficients for robust attractor reconstruction, 2) Parallel attention\nmechanisms capturing cross-temporal and spatial dependencies, 3) Dynamic gated\nfusion of multiscale features, and 4) Deep projection networks with\ndimension-scaling capabilities. Numerical experiments on nonlinear PDE systems\ndemonstrate the model's effectiveness in maintaining prediction accuracy under\nboth smooth and strongly chaotic regimes while exhibiting noise tolerance\nthrough adaptive filtering. Component ablation studies confirm critical\ncontributions from each module, particularly highlighting the essential role of\nspatiotemporal attention in learning complex dynamical interactions. The\nframework shows promising potential for real-world applications requiring\nsimultaneous handling of measurement uncertainties and high-dimensional\nnonlinear dynamics.", "published": "2025-05-23 16:39:07", "link": "http://arxiv.org/abs/2505.18080v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Uncertainty Aware Task Delegation and Human-AI Collaborative Decision-Making", "abstract": "Despite the growing promise of artificial intelligence (AI) in supporting\ndecision-making across domains, fostering appropriate human reliance on AI\nremains a critical challenge. In this paper, we investigate the utility of\nexploring distance-based uncertainty scores for task delegation to AI and\ndescribe how these scores can be visualized through embedding representations\nfor human-AI decision-making. After developing an AI-based system for physical\nstroke rehabilitation assessment, we conducted a study with 19 health\nprofessionals and 10 students in medicine/health to understand the effect of\nexploring distance-based uncertainty scores on users' reliance on AI. Our\nfindings showed that distance-based uncertainty scores outperformed traditional\nprobability-based uncertainty scores in identifying uncertain cases. In\naddition, after exploring confidence scores for task delegation and reviewing\nembedding-based visualizations of distance-based uncertainty scores,\nparticipants achieved an 8.20% higher rate of correct decisions, a 7.15% higher\nrate of changing their decisions to correct ones, and a 7.14% lower rate of\nincorrect changes after reviewing AI outputs than those reviewing\nprobability-based uncertainty scores ($p<0.01$). Our findings highlight the\npotential of distance-based uncertainty scores to enhance decision accuracy and\nappropriate reliance on AI while discussing ongoing challenges for human-AI\ncollaborative decision-making.", "published": "2025-05-23 16:12:39", "link": "http://arxiv.org/abs/2505.18066v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "FDBPL: Faster Distillation-Based Prompt Learning for Region-Aware Vision-Language Models Adaptation", "abstract": "Prompt learning as a parameter-efficient method that has been widely adopted\nto adapt Vision-Language Models (VLMs) to downstream tasks. While hard-prompt\ndesign requires domain expertise and iterative optimization, soft-prompt\nmethods rely heavily on task-specific hard labels, limiting their\ngeneralization to unseen categories. Recent popular distillation-based prompt\nlearning methods improve generalization by exploiting larger teacher VLMs and\nunsupervised knowledge transfer, yet their repetitive teacher model online\ninference sacrifices the inherent training efficiency advantage of prompt\nlearning. In this paper, we propose {{\\large {\\textbf{F}}}}aster {{\\large\n{\\textbf{D}}}}istillation-{{\\large {\\textbf{B}}}}ased {{\\large\n{\\textbf{P}}}}rompt {{\\large {\\textbf{L}}}}earning (\\textbf{FDBPL}), which\naddresses these issues by sharing soft supervision contexts across multiple\ntraining stages and implementing accelerated I/O. Furthermore, FDBPL introduces\na region-aware prompt learning paradigm with dual positive-negative prompt\nspaces to fully exploit randomly cropped regions that containing multi-level\ninformation. We propose a positive-negative space mutual learning mechanism\nbased on similarity-difference learning, enabling student CLIP models to\nrecognize correct semantics while learning to reject weakly related concepts,\nthereby improving zero-shot performance. Unlike existing distillation-based\nprompt learning methods that sacrifice parameter efficiency for generalization,\nFDBPL maintains dual advantages of parameter efficiency and strong downstream\ngeneralization. Comprehensive evaluations across 11 datasets demonstrate\nsuperior performance in base-to-new generalization, cross-dataset transfer, and\nrobustness tests, achieving $2.2\\times$ faster training speed.", "published": "2025-05-23 15:57:16", "link": "http://arxiv.org/abs/2505.18053v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RestoreVAR: Visual Autoregressive Generation for All-in-One Image Restoration", "abstract": "The use of latent diffusion models (LDMs) such as Stable Diffusion has\nsignificantly improved the perceptual quality of All-in-One image Restoration\n(AiOR) methods, while also enhancing their generalization capabilities.\nHowever, these LDM-based frameworks suffer from slow inference due to their\niterative denoising process, rendering them impractical for time-sensitive\napplications. To address this, we propose RestoreVAR, a novel generative\napproach for AiOR that significantly outperforms LDM-based models in\nrestoration performance while achieving over $\\mathbf{10\\times}$ faster\ninference. RestoreVAR leverages visual autoregressive modeling (VAR), a\nrecently introduced approach which performs scale-space autoregression for\nimage generation. VAR achieves comparable performance to that of\nstate-of-the-art diffusion transformers with drastically reduced computational\ncosts. To optimally exploit these advantages of VAR for AiOR, we propose\narchitectural modifications and improvements, including intricately designed\ncross-attention mechanisms and a latent-space refinement module, tailored for\nthe AiOR task. Extensive experiments show that RestoreVAR achieves\nstate-of-the-art performance among generative AiOR methods, while also\nexhibiting strong generalization capabilities.", "published": "2025-05-23 15:52:26", "link": "http://arxiv.org/abs/2505.18047v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Linear Mixture Distributionally Robust Markov Decision Processes", "abstract": "Many real-world decision-making problems face the off-dynamics challenge: the\nagent learns a policy in a source domain and deploys it in a target domain with\ndifferent state transitions. The distributionally robust Markov decision\nprocess (DRMDP) addresses this challenge by finding a robust policy that\nperforms well under the worst-case environment within a pre-specified\nuncertainty set of transition dynamics. Its effectiveness heavily hinges on the\nproper design of these uncertainty sets, based on prior knowledge of the\ndynamics. In this work, we propose a novel linear mixture DRMDP framework,\nwhere the nominal dynamics is assumed to be a linear mixture model. In contrast\nwith existing uncertainty sets directly defined as a ball centered around the\nnominal kernel, linear mixture DRMDPs define the uncertainty sets based on a\nball around the mixture weighting parameter. We show that this new framework\nprovides a more refined representation of uncertainties compared to\nconventional models based on $(s,a)$-rectangularity and $d$-rectangularity,\nwhen prior knowledge about the mixture model is present. We propose a meta\nalgorithm for robust policy learning in linear mixture DRMDPs with general\n$f$-divergence defined uncertainty sets, and analyze its sample complexities\nunder three divergence metrics instantiations: total variation,\nKullback-Leibler, and $\\chi^2$ divergences. These results establish the\nstatistical learnability of linear mixture DRMDPs, laying the theoretical\nfoundation for future research on this new setting.", "published": "2025-05-23 15:48:11", "link": "http://arxiv.org/abs/2505.18044v1", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Automata Learning of Preferences over Temporal Logic Formulas from Pairwise Comparisons", "abstract": "Many preference elicitation algorithms consider preference over propositional\nlogic formulas or items with different attributes. In sequential decision\nmaking, a user's preference can be a preorder over possible outcomes, each of\nwhich is a temporal sequence of events. This paper considers a class of\npreference inference problems where the user's unknown preference is\nrepresented by a preorder over regular languages (sets of temporal sequences),\nreferred to as temporal goals. Given a finite set of pairwise comparisons\nbetween finite words, the objective is to learn both the set of temporal goals\nand the preorder over these goals. We first show that a preference relation\nover temporal goals can be modeled by a Preference Deterministic Finite\nAutomaton (PDFA), which is a deterministic finite automaton augmented with a\npreorder over acceptance conditions. The problem of preference inference\nreduces to learning the PDFA. This problem is shown to be computationally\nchallenging, with the problem of determining whether there exists a PDFA of\nsize smaller than a given integer $k$, consistent with the sample, being\nNP-Complete. We formalize the properties of characteristic samples and develop\nan algorithm that guarantees to learn, given a characteristic sample, the\nminimal PDFA equivalent to the true PDFA from which the sample is drawn. We\npresent the method through a running example and provide detailed analysis\nusing a robotic motion planning problem.", "published": "2025-05-23 15:35:39", "link": "http://arxiv.org/abs/2505.18030v1", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Knot So Simple: A Minimalistic Environment for Spatial Reasoning", "abstract": "We propose KnotGym, an interactive environment for complex, spatial reasoning\nand manipulation. KnotGym includes goal-oriented rope manipulation tasks with\nvarying levels of complexity, all requiring acting from pure image\nobservations. Tasks are defined along a clear and quantifiable axis of\ncomplexity based on the number of knot crossings, creating a natural\ngeneralization test. KnotGym has a simple observation space, allowing for\nscalable development, yet it highlights core challenges in integrating acute\nperception, spatial reasoning, and grounded manipulation. We evaluate methods\nof different classes, including model-based RL, model-predictive control, and\nchain-of-thought reasoning, and illustrate the challenges KnotGym presents.\nKnotGym is available at https://github.com/lil-lab/knotgym.", "published": "2025-05-23 15:34:08", "link": "http://arxiv.org/abs/2505.18028v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.LG"}
{"title": "LLM assisted web application functional requirements generation: A case study of four popular LLMs over a Mess Management System", "abstract": "Like any other discipline, Large Language Models (LLMs) have significantly\nimpacted software engineering by helping developers generate the required\nartifacts across various phases of software development. This paper presents a\ncase study comparing the performance of popular LLMs GPT, Claude, Gemini, and\nDeepSeek in generating functional specifications that include use cases,\nbusiness rules, and collaborative workflows for a web application, the Mess\nManagement System. The study evaluated the quality of LLM generated use cases,\nbusiness rules, and collaborative workflows in terms of their syntactic and\nsemantic correctness, consistency, non ambiguity, and completeness compared to\nthe reference specifications against the zero-shot prompted problem statement.\nOur results suggested that all four LLMs can specify syntactically and\nsemantically correct, mostly non-ambiguous artifacts. Still, they may be\ninconsistent at times and may differ significantly in the completeness of the\ngenerated specification. Claude and Gemini generated all the reference use\ncases, with Claude achieving the most complete but somewhat redundant use case\nspecifications. Similar results were obtained for specifying workflows.\nHowever, all four LLMs struggled to generate relevant Business Rules, with\nDeepSeek generating the most reference rules but with less completeness.\nOverall, Claude generated more complete specification artifacts, while Gemini\nwas more precise in the specifications it generated.", "published": "2025-05-23 15:25:50", "link": "http://arxiv.org/abs/2505.18019v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "ExoGait-MS: Learning Periodic Dynamics with Multi-Scale Graph Network for Exoskeleton Gait Recognition", "abstract": "Current exoskeleton control methods often face challenges in delivering\npersonalized treatment. Standardized walking gaits can lead to patient\ndiscomfort or even injury. Therefore, personalized gait is essential for the\neffectiveness of exoskeleton robots, as it directly impacts their adaptability,\ncomfort, and rehabilitation outcomes for individual users. To enable\npersonalized treatment in exoskeleton-assisted therapy and related\napplications, accurate recognition of personal gait is crucial for implementing\ntailored gait control. The key challenge in gait recognition lies in\neffectively capturing individual differences in subtle gait features caused by\njoint synergy, such as step frequency and step length. To tackle this issue, we\npropose a novel approach, which uses Multi-Scale Global Dense Graph\nConvolutional Networks (GCN) in the spatial domain to identify latent joint\nsynergy patterns. Moreover, we propose a Gait Non-linear Periodic Dynamics\nLearning module to effectively capture the periodic characteristics of gait in\nthe temporal domain. To support our individual gait recognition task, we have\nconstructed a comprehensive gait dataset that ensures both completeness and\nreliability. Our experimental results demonstrate that our method achieves an\nimpressive accuracy of 94.34% on this dataset, surpassing the current\nstate-of-the-art (SOTA) by 3.77%. This advancement underscores the potential of\nour approach to enhance personalized gait control in exoskeleton-assisted\ntherapy.", "published": "2025-05-23 15:24:25", "link": "http://arxiv.org/abs/2505.18018v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "AI Literacy for Legal AI Systems: A practical approach", "abstract": "Legal AI systems are increasingly being adopted by judicial and legal system\ndeployers and providers worldwide to support a range of applications. While\nthey offer potential benefits such as reducing bias, increasing efficiency, and\nimproving accountability, they also pose significant risks, requiring a careful\nbalance between opportunities, and legal and ethical development and\ndeployment. AI literacy, as a legal requirement under the EU AI Act and a\ncritical enabler of ethical AI for deployers and providers, could be a tool to\nachieve this. The article introduces the term \"legal AI systems\" and then\nanalyzes the concept of AI literacy and the benefits and risks associated with\nthese systems. This analysis is linked to a broader AI-L concept for\norganizations that deal with legal AI systems. The outcome of the article, a\nroadmap questionnaire as a practical tool for developers and providers to\nassess risks, benefits, and stakeholder concerns, could be useful in meeting\nsocietal and regulatory expectations for legal AI.", "published": "2025-05-23 15:10:28", "link": "http://arxiv.org/abs/2505.18006v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CY"}
{"title": "An Example Safety Case for Safeguards Against Misuse", "abstract": "Existing evaluations of AI misuse safeguards provide a patchwork of evidence\nthat is often difficult to connect to real-world decisions. To bridge this gap,\nwe describe an end-to-end argument (a \"safety case\") that misuse safeguards\nreduce the risk posed by an AI assistant to low levels. We first describe how a\nhypothetical developer red teams safeguards, estimating the effort required to\nevade them. Then, the developer plugs this estimate into a quantitative \"uplift\nmodel\" to determine how much barriers introduced by safeguards dissuade misuse\n(https://www.aimisusemodel.com/). This procedure provides a continuous signal\nof risk during deployment that helps the developer rapidly respond to emerging\nthreats. Finally, we describe how to tie these components together into a\nsimple safety case. Our work provides one concrete path -- though not the only\npath -- to rigorously justifying AI misuse risks are low.", "published": "2025-05-23 15:06:21", "link": "http://arxiv.org/abs/2505.18003v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Outcome-based Reinforcement Learning to Predict the Future", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has boosted math and\ncoding in large language models, yet there has been little effort to extend\nRLVR into messier, real-world domains like forecasting. One sticking point is\nthat outcome-based reinforcement learning for forecasting must learn from\nbinary, delayed, and noisy rewards, a regime where standard fine-tuning is\nbrittle. We show that outcome-only online RL on a 14B model can match\nfrontier-scale accuracy and surpass it in calibration and hypothetical\nprediction market betting by adapting two leading algorithms, Group-Relative\nPolicy Optimisation (GRPO) and ReMax, to the forecasting setting. Our\nadaptations remove per-question variance scaling in GRPO, apply\nbaseline-subtracted advantages in ReMax, hydrate training with 100k temporally\nconsistent synthetic questions, and introduce lightweight guard-rails that\npenalise gibberish, non-English responses and missing rationales, enabling a\nsingle stable pass over 110k events. Scaling ReMax to 110k questions and\nensembling seven predictions yields a 14B model that matches frontier baseline\no1 on accuracy on our holdout set (Brier = 0.193, p = 0.23) while beating it in\ncalibration (ECE = 0.042, p < 0.001). A simple trading rule turns this\ncalibration edge into \\$127 of hypothetical profit versus \\$92 for o1 (p =\n0.037). This demonstrates that refined RLVR methods can convert small-scale\nLLMs into potentially economically valuable forecasting tools, with\nimplications for scaling this to larger models.", "published": "2025-05-23 14:56:07", "link": "http://arxiv.org/abs/2505.17989v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning", "abstract": "R1-style Reinforcement Learning (RL) significantly enhances Large Language\nModels' reasoning capabilities, yet the mechanism behind rule-based RL remains\nunclear. We found that small-scale SFT has significant influence on RL but\nshows poor efficiency. To explain our observations, we propose an analytical\nframework and compare the efficiency of SFT and RL by measuring sample effect.\nHypothetical analysis show that SFT efficiency is limited by training data.\nGuided by our analysis, we propose Re-distillation, a technique that fine-tunes\npretrain model through small-scale distillation from the RL-trained policy.\nExperiments on Knight & Knave and MATH datasets demonstrate re-distillation's\nsurprising efficiency: re-distilled models match RL performance with far fewer\nsamples and less computation. Empirical verification shows that sample effect\nis a good indicator of performance improvements. As a result, on K&K dataset,\nour re-distilled Qwen2.5-1.5B model surpasses DeepSeek-V3-0324 with only 1K SFT\nsamples. On MATH, Qwen2.5-1.5B fine-tuned with re-distilled 500 samples matches\nits instruct-tuned variant without RL. Our work explains several interesting\nphenomena in R1-style RL, shedding light on the mechanisms behind its empirical\nsuccess. Code is available at: https://github.com/on1262/deep-reasoning", "published": "2025-05-23 14:55:22", "link": "http://arxiv.org/abs/2505.17988v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for Human Activity Modeling", "abstract": "Real world collection of Activities of Daily Living data is challenging due\nto privacy concerns, costly deployment and labeling, and the inherent sparsity\nand imbalance of human behavior. We present ADLGen, a generative framework\nspecifically designed to synthesize realistic, event triggered, and symbolic\nsensor sequences for ambient assistive environments. ADLGen integrates a\ndecoder only Transformer with sign based symbolic temporal encoding, and a\ncontext and layout aware sampling mechanism to guide generation toward\nsemantically rich and physically plausible sensor event sequences. To enhance\nsemantic fidelity and correct structural inconsistencies, we further\nincorporate a large language model into an automatic generate evaluate refine\nloop, which verifies logical, behavioral, and temporal coherence and generates\ncorrection rules without manual intervention or environment specific tuning.\nThrough comprehensive experiments with novel evaluation metrics, ADLGen is\nshown to outperform baseline generators in statistical fidelity, semantic\nrichness, and downstream activity recognition, offering a scalable and\nprivacy-preserving solution for ADL data synthesis.", "published": "2025-05-23 14:52:48", "link": "http://arxiv.org/abs/2505.17987v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher Approximation for Compressing Large Language Models", "abstract": "The Fisher information is a fundamental concept for characterizing the\nsensitivity of parameters in neural networks. However, leveraging the full\nobserved Fisher information is too expensive for large models, so most methods\nrely on simple diagonal approximations. While efficient, this approach ignores\nparameter correlations, often resulting in reduced performance on downstream\ntasks. In this work, we mitigate these limitations and propose Generalized\nFisher-Weighted SVD (GFWSVD), a post-training LLM compression technique that\naccounts for both diagonal and off-diagonal elements of the Fisher information\nmatrix, providing a more accurate reflection of parameter importance. To make\nthe method tractable, we introduce a scalable adaptation of the\nKronecker-factored approximation algorithm for the observed Fisher information.\nWe demonstrate the effectiveness of our method on LLM compression, showing\nimprovements over existing compression baselines. For example, at a 20\ncompression rate on the MMLU benchmark, our method outperforms FWSVD, which is\nbased on a diagonal approximation of the Fisher information, by 5 percent,\nSVD-LLM by 3 percent, and ASVD by 6 percent compression rate.", "published": "2025-05-23 14:41:52", "link": "http://arxiv.org/abs/2505.17974v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language Models", "abstract": "Low-rank optimization has emerged as a promising direction in training large\nlanguage models (LLMs) to reduce the memory usage of adaptive optimizers by\nconstraining learning to a lower-dimensional space. Prior work typically\nprojects gradients of linear layers using approaches based on Singular Value\nDecomposition (SVD). However, applying SVD-based procedures individually to\neach layer in large models is computationally expensive and incurs additional\nmemory costs due to storing the projection matrices. In this work, we propose a\ncomputationally efficient and conceptually simple two-step procedure to\napproximate SVD-based gradient projections into lower-dimensional spaces.\nFirst, we construct a complete orthogonal basis using predefined orthogonal\nmatrices of the Discrete Cosine Transform (DCT). Second, we adaptively select\nbasis columns based on their alignment with the gradient of each layer. Each\nprojection matrix in our method is obtained via a single matrix multiplication\nfollowed by a lightweight sorting step to identify the most relevant basis\nvectors. Due to the predefined nature of the orthogonal bases, they are\ncomputed once at the start of training. During training, we store only the\nindices of the selected columns, avoiding the need to store full projection\nmatrices for each layer. Our numerical experiments on both pre-training and\nfine-tuning tasks demonstrate the effectiveness of our dual strategy in\napproximating optimal low-rank projections, matching the performance of costly\nSVD-based methods while achieving faster runtime and reduced memory usage.", "published": "2025-05-23 14:37:00", "link": "http://arxiv.org/abs/2505.17967v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation", "abstract": "Causal inference typically assumes centralized access to individual-level\ndata. Yet, in practice, data are often decentralized across multiple sites,\nmaking centralization infeasible due to privacy, logistical, or legal\nconstraints. We address this by estimating the Average Treatment Effect (ATE)\nfrom decentralized observational data using federated learning, which enables\ninference through the exchange of aggregate statistics rather than\nindividual-level data. We propose a novel method to estimate propensity scores\nin a (non-)parametric manner by computing a federated weighted average of local\nscores, using two theoretically grounded weighting schemes -- Membership\nWeights (MW) and Density Ratio Weights (DW) -- that balance communication\nefficiency and model flexibility. These federated scores are then used to\nconstruct two ATE estimators: the Federated Inverse Propensity Weighting\nestimator (Fed-IPW) and its augmented variant (Fed-AIPW). Unlike meta-analysis\nmethods, which fail when any site violates positivity, our approach leverages\nheterogeneity in treatment assignment across sites to improve overlap. We show\nthat Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample\nsizes, treatment mechanisms, and covariate distributions, with theoretical\nanalysis and experiments on simulated and real-world data highlighting their\nstrengths and limitations relative to meta-analysis and related methods.", "published": "2025-05-23 14:32:57", "link": "http://arxiv.org/abs/2505.17961v1", "categories": ["stat.ME", "cs.AI", "math.ST", "stat.AP", "stat.TH"], "primary_category": "stat.ME"}
{"title": "LMask: Learn to Solve Constrained Routing Problems with Lazy Masking", "abstract": "Routing problems are canonical combinatorial optimization tasks with\nwide-ranging applications in logistics, transportation, and supply chain\nmanagement. However, solving these problems becomes significantly more\nchallenging when complex constraints are involved. In this paper, we propose\nLMask, a novel learning framework that utilizes dynamic masking to generate\nhigh-quality feasible solutions for constrained routing problems. LMask\nintroduces the LazyMask decoding method, which lazily refines feasibility masks\nwith the backtracking mechanism. In addition, it employs the refinement\nintensity embedding to encode the search trace into the model, mitigating\nrepresentation ambiguities induced by backtracking. To further reduce sampling\ncost, LMask sets a backtracking budget during decoding, while constraint\nviolations are penalized in the loss function during training to counteract\ninfeasibility caused by this budget. We provide theoretical guarantees for the\nvalidity and probabilistic optimality of our approach. Extensive experiments on\nthe traveling salesman problem with time windows (TSPTW) and TSP with draft\nlimits (TSPDL) demonstrate that LMask achieves state-of-the-art feasibility\nrates and solution quality, outperforming existing neural methods.", "published": "2025-05-23 14:15:26", "link": "http://arxiv.org/abs/2505.17938v1", "categories": ["math.OC", "cs.AI", "cs.LG", "90C27, 68T20"], "primary_category": "math.OC"}
{"title": "AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models", "abstract": "Medical image segmentation is vital for clinical diagnosis, yet current deep\nlearning methods often demand extensive expert effort, i.e., either through\nannotating large training datasets or providing prompts at inference time for\neach new case. This paper introduces a zero-shot and automatic segmentation\npipeline that combines off-the-shelf vision-language and segmentation\nfoundation models. Given a medical image and a task definition (e.g., \"segment\nthe optic disc in an eye fundus image\"), our method uses a grounding model to\ngenerate an initial bounding box, followed by a visual prompt boosting module\nthat enhance the prompts, which are then processed by a promptable segmentation\nmodel to produce the final mask. To address the challenges of domain gap and\nresult verification, we introduce a test-time adaptation framework featuring a\nset of learnable adaptors that align the medical inputs with foundation model\nrepresentations. Its hyperparameters are optimized via Bayesian Optimization,\nguided by a proxy validation model without requiring ground-truth labels. Our\npipeline offers an annotation-efficient and scalable solution for zero-shot\nmedical image segmentation across diverse tasks. Our pipeline is evaluated on\nseven diverse medical imaging datasets and shows promising results. By proper\ndecomposition and test-time adaptation, our fully automatic pipeline performs\ncompetitively with weakly-prompted interactive foundation models.", "published": "2025-05-23 14:07:21", "link": "http://arxiv.org/abs/2505.17931v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Evaluation of Few-Shot Learning Methods for Kidney Stone Type Recognition in Ureteroscopy", "abstract": "Determining the type of kidney stones is crucial for prescribing appropriate\ntreatments to prevent recurrence. Currently, various approaches exist to\nidentify the type of kidney stones. However, obtaining results through the\nreference ex vivo identification procedure can take several weeks, while in\nvivo visual recognition requires highly trained specialists. For this reason,\ndeep learning models have been developed to provide urologists with an\nautomated classification of kidney stones during ureteroscopies. Nevertheless,\na common issue with these models is the lack of training data. This\ncontribution presents a deep learning method based on few-shot learning, aimed\nat producing sufficiently discriminative features for identifying kidney stone\ntypes in endoscopic images, even with a very limited number of samples. This\napproach was specifically designed for scenarios where endoscopic images are\nscarce or where uncommon classes are present, enabling classification even with\na limited training dataset. The results demonstrate that Prototypical Networks,\nusing up to 25% of the training data, can achieve performance equal to or\nbetter than traditional deep learning models trained with the complete dataset.", "published": "2025-05-23 13:59:02", "link": "http://arxiv.org/abs/2505.17921v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Object-level Cross-view Geo-localization with Location Enhancement and Multi-Head Cross Attention", "abstract": "Cross-view geo-localization determines the location of a query image,\ncaptured by a drone or ground-based camera, by matching it to a geo-referenced\nsatellite image. While traditional approaches focus on image-level\nlocalization, many applications, such as search-and-rescue, infrastructure\ninspection, and precision delivery, demand object-level accuracy. This enables\nusers to prompt a specific object with a single click on a drone image to\nretrieve precise geo-tagged information of the object. However, variations in\nviewpoints, timing, and imaging conditions pose significant challenges,\nespecially when identifying visually similar objects in extensive satellite\nimagery. To address these challenges, we propose an Object-level Cross-view\nGeo-localization Network (OCGNet). It integrates user-specified click locations\nusing Gaussian Kernel Transfer (GKT) to preserve location information\nthroughout the network. This cue is dually embedded into the feature encoder\nand feature matching blocks, ensuring robust object-specific localization.\nAdditionally, OCGNet incorporates a Location Enhancement (LE) module and a\nMulti-Head Cross Attention (MHCA) module to adaptively emphasize\nobject-specific features or expand focus to relevant contextual regions when\nnecessary. OCGNet achieves state-of-the-art performance on a public dataset,\nCVOGL. It also demonstrates few-shot learning capabilities, effectively\ngeneralizing from limited examples, making it suitable for diverse applications\n(https://github.com/ZheyangH/OCGNet).", "published": "2025-05-23 13:55:56", "link": "http://arxiv.org/abs/2505.17911v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DiffusionReward: Enhancing Blind Face Restoration through Reward Feedback Learning", "abstract": "Reward Feedback Learning (ReFL) has recently shown great potential in\naligning model outputs with human preferences across various generative tasks.\nIn this work, we introduce a ReFL framework, named DiffusionReward, to the\nBlind Face Restoration task for the first time. DiffusionReward effectively\novercomes the limitations of diffusion-based methods, which often fail to\ngenerate realistic facial details and exhibit poor identity consistency. The\ncore of our framework is the Face Reward Model (FRM), which is trained using\ncarefully annotated data. It provides feedback signals that play a pivotal role\nin steering the optimization process of the restoration network. In particular,\nour ReFL framework incorporates a gradient flow into the denoising process of\noff-the-shelf face restoration methods to guide the update of model parameters.\nThe guiding gradient is collaboratively determined by three aspects: (i) the\nFRM to ensure the perceptual quality of the restored faces; (ii) a\nregularization term that functions as a safeguard to preserve generative\ndiversity; and (iii) a structural consistency constraint to maintain facial\nfidelity. Furthermore, the FRM undergoes dynamic optimization throughout the\nprocess. It not only ensures that the restoration network stays precisely\naligned with the real face manifold, but also effectively prevents reward\nhacking. Experiments on synthetic and wild datasets demonstrate that our method\noutperforms state-of-the-art methods, significantly improving identity\nconsistency and facial details. The source codes, data, and models are\navailable at: https://github.com/01NeuralNinja/DiffusionReward.", "published": "2025-05-23 13:53:23", "link": "http://arxiv.org/abs/2505.17910v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NeuroTrails: Training with Dynamic Sparse Heads as the Key to Effective Ensembling", "abstract": "Model ensembles have long been a cornerstone for improving generalization and\nrobustness in deep learning. However, their effectiveness often comes at the\ncost of substantial computational overhead. To address this issue,\nstate-of-the-art methods aim to replicate ensemble-class performance without\nrequiring multiple independently trained networks. Unfortunately, these\nalgorithms often still demand considerable compute at inference. In response to\nthese limitations, we introduce $\\textbf{NeuroTrails}$, a sparse multi-head\narchitecture with dynamically evolving topology. This unexplored model-agnostic\ntraining paradigm improves ensemble performance while reducing the required\nresources. We analyze the underlying reason for its effectiveness and observe\nthat the various neural trails induced by dynamic sparsity attain a\n$\\textit{Goldilocks zone}$ of prediction diversity. NeuroTrails displays\nefficacy with convolutional and transformer-based architectures on computer\nvision and language tasks. Experiments on ResNet-50/ImageNet, LLaMA-350M/C4,\namong many others, demonstrate increased accuracy and stronger robustness in\nzero-shot generalization, while requiring significantly fewer parameters.", "published": "2025-05-23 13:53:21", "link": "http://arxiv.org/abs/2505.17909v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ComfyMind: Toward General-Purpose Generation via Tree-Based Planning and Reactive Feedback", "abstract": "With the rapid advancement of generative models, general-purpose generation\nhas gained increasing attention as a promising approach to unify diverse tasks\nacross modalities within a single system. Despite this progress, existing\nopen-source frameworks often remain fragile and struggle to support complex\nreal-world applications due to the lack of structured workflow planning and\nexecution-level feedback. To address these limitations, we present ComfyMind, a\ncollaborative AI system designed to enable robust and scalable general-purpose\ngeneration, built on the ComfyUI platform. ComfyMind introduces two core\ninnovations: Semantic Workflow Interface (SWI) that abstracts low-level node\ngraphs into callable functional modules described in natural language, enabling\nhigh-level composition and reducing structural errors; Search Tree Planning\nmechanism with localized feedback execution, which models generation as a\nhierarchical decision process and allows adaptive correction at each stage.\nTogether, these components improve the stability and flexibility of complex\ngenerative workflows. We evaluate ComfyMind on three public benchmarks:\nComfyBench, GenEval, and Reason-Edit, which span generation, editing, and\nreasoning tasks. Results show that ComfyMind consistently outperforms existing\nopen-source baselines and achieves performance comparable to GPT-Image-1.\nComfyMind paves a promising path for the development of open-source\ngeneral-purpose generative AI systems. Project page:\nhttps://github.com/LitaoGuo/ComfyMind", "published": "2025-05-23 13:53:03", "link": "http://arxiv.org/abs/2505.17908v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "DataRater: Meta-Learned Dataset Curation", "abstract": "The quality of foundation models depends heavily on their training data.\nConsequently, great efforts have been put into dataset curation. Yet most\napproaches rely on manual tuning of coarse-grained mixtures of large buckets of\ndata, or filtering by hand-crafted heuristics. An approach that is ultimately\nmore scalable (let alone more satisfying) is to \\emph{learn} which data is\nactually valuable for training. This type of meta-learning could allow more\nsophisticated, fine-grained, and effective curation. Our proposed\n\\emph{DataRater} is an instance of this idea. It estimates the value of\ntraining on any particular data point. This is done by meta-learning using\n`meta-gradients', with the objective of improving training efficiency on held\nout data. In extensive experiments across a range of model scales and datasets,\nwe find that using our DataRater to filter data is highly effective, resulting\nin significantly improved compute efficiency.", "published": "2025-05-23 13:43:14", "link": "http://arxiv.org/abs/2505.17895v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "I.2.6"], "primary_category": "stat.ML"}
{"title": "FastCAV: Efficient Computation of Concept Activation Vectors for Explaining Deep Neural Networks", "abstract": "Concepts such as objects, patterns, and shapes are how humans understand the\nworld. Building on this intuition, concept-based explainability methods aim to\nstudy representations learned by deep neural networks in relation to\nhuman-understandable concepts. Here, Concept Activation Vectors (CAVs) are an\nimportant tool and can identify whether a model learned a concept or not.\nHowever, the computational cost and time requirements of existing CAV\ncomputation pose a significant challenge, particularly in large-scale,\nhigh-dimensional architectures. To address this limitation, we introduce\nFastCAV, a novel approach that accelerates the extraction of CAVs by up to\n63.6x (on average 46.4x). We provide a theoretical foundation for our approach\nand give concrete assumptions under which it is equivalent to established\nSVM-based methods. Our empirical results demonstrate that CAVs calculated with\nFastCAV maintain similar performance while being more efficient and stable. In\ndownstream applications, i.e., concept-based explanation methods, we show that\nFastCAV can act as a replacement leading to equivalent insights. Hence, our\napproach enables previously infeasible investigations of deep models, which we\ndemonstrate by tracking the evolution of concepts during model training.", "published": "2025-05-23 13:31:54", "link": "http://arxiv.org/abs/2505.17883v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Formalizing Embeddedness Failures in Universal Artificial Intelligence", "abstract": "We rigorously discuss the commonly asserted failures of the AIXI\nreinforcement learning agent as a model of embedded agency. We attempt to\nformalize these failure modes and prove that they occur within the framework of\nuniversal artificial intelligence, focusing on a variant of AIXI that models\nthe joint action/percept history as drawn from the universal distribution. We\nalso evaluate the progress that has been made towards a successful theory of\nembedded agency based on variants of the AIXI agent.", "published": "2025-05-23 13:31:28", "link": "http://arxiv.org/abs/2505.17882v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Toward Optimal ANC: Establishing Mutual Information Lower Bound", "abstract": "Active Noise Cancellation (ANC) algorithms aim to suppress unwanted acoustic\ndisturbances by generating anti-noise signals that destructively interfere with\nthe original noise in real time. Although recent deep learning-based ANC\nalgorithms have set new performance benchmarks, there remains a shortage of\ntheoretical limits to rigorously assess their improvements. To address this, we\nderive a unified lower bound on cancellation performance composed of two\ncomponents. The first component is information-theoretic: it links residual\nerror power to the fraction of disturbance entropy captured by the anti-noise\nsignal, thereby quantifying limits imposed by information-processing capacity.\nThe second component is support-based: it measures the irreducible error\narising in frequency bands that the cancellation path cannot address,\nreflecting fundamental physical constraints. By taking the maximum of these two\nterms, our bound establishes a theoretical ceiling on the Normalized Mean\nSquared Error (NMSE) attainable by any ANC algorithm. We validate its tightness\nempirically on the NOISEX dataset under varying reverberation times,\ndemonstrating robustness across diverse acoustic conditions.", "published": "2025-05-23 13:27:35", "link": "http://arxiv.org/abs/2505.17877v1", "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.SD", "eess.AS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Mixture of Low Rank Adaptation with Partial Parameter Sharing for Time Series Forecasting", "abstract": "Multi-task forecasting has become the standard approach for time-series\nforecasting (TSF). However, we show that it suffers from an Expressiveness\nBottleneck, where predictions at different time steps share the same\nrepresentation, leading to unavoidable errors even with optimal\nrepresentations. To address this issue, we propose a two-stage framework:\nfirst, pre-train a foundation model for one-step-ahead prediction; then, adapt\nit using step-specific LoRA modules.This design enables the foundation model to\nhandle any number of forecast steps while avoiding the expressiveness\nbottleneck. We further introduce the Mixture-of-LoRA (MoLA) model, which\nemploys adaptively weighted LoRA experts to achieve partial parameter sharing\nacross steps. This approach enhances both efficiency and forecasting\nperformance by exploiting interdependencies between forecast steps. Experiments\nshow that MoLA significantly improves model expressiveness and outperforms\nstate-of-the-art time-series forecasting methods. Code is available at\nhttps://anonymous.4open.science/r/MoLA-BC92.", "published": "2025-05-23 13:24:39", "link": "http://arxiv.org/abs/2505.17872v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities", "abstract": "Recent Multimodal Large Language Models (MLLMs) achieve promising performance\non visual and audio benchmarks independently. However, the ability of these\nmodels to process cross-modal information synchronously remains largely\nunexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual\nQuestioning and Answering benchmark comprising 684 videos of daily life\nscenarios from diverse sources, rich in both audio and visual information, and\nfeaturing 1197 multiple-choice QA pairs across 6 major tasks; 2) Daily-Omni QA\nGeneration Pipeline, which includes automatic annotation, QA generation and QA\noptimization, significantly improves efficiency for human evaluation and\nscalability of the benchmark; 3) Daily-Omni-Agent, a training-free agent\nutilizing open-source Visual Language Model (VLM), Audio Language Model (ALM)\nand Automatic Speech Recognition (ASR) model to establish a baseline for this\nbenchmark. The results show that current MLLMs still struggle significantly\nwith tasks requiring audio-visual integration, but combining VLMs and ALMs with\nsimple temporal alignment techniques can achieve substantially better\nperformance. Codes and benchmark are available at\n\\href{https://github.com/Lliar-liar/Daily-Omni}{https://github.com/Lliar-liar/Daily-Omni}.", "published": "2025-05-23 13:13:58", "link": "http://arxiv.org/abs/2505.17862v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Superplatforms Have to Attack AI Agents", "abstract": "Over the past decades, superplatforms, digital companies that integrate a\nvast range of third-party services and applications into a single, unified\necosystem, have built their fortunes on monopolizing user attention through\ntargeted advertising and algorithmic content curation. Yet the emergence of AI\nagents driven by large language models (LLMs) threatens to upend this business\nmodel. Agents can not only free user attention with autonomy across diverse\nplatforms and therefore bypass the user-attention-based monetization, but might\nalso become the new entrance for digital traffic. Hence, we argue that\nsuperplatforms have to attack AI agents to defend their centralized control of\ndigital traffic entrance. Specifically, we analyze the fundamental conflict\nbetween user-attention-based monetization and agent-driven autonomy through the\nlens of our gatekeeping theory. We show how AI agents can disintermediate\nsuperplatforms and potentially become the next dominant gatekeepers, thereby\nforming the urgent necessity for superplatforms to proactively constrain and\nattack AI agents. Moreover, we go through the potential technologies for\nsuperplatform-initiated attacks, covering a brand-new, unexplored technical\narea with unique challenges. We have to emphasize that, despite our position,\nthis paper does not advocate for adversarial attacks by superplatforms on AI\nagents, but rather offers an envisioned trend to highlight the emerging\ntensions between superplatforms and AI agents. Our aim is to raise awareness\nand encourage critical discussion for collaborative solutions, prioritizing\nuser interests and perserving the openness of digital ecosystems in the age of\nAI agents.", "published": "2025-05-23 13:13:44", "link": "http://arxiv.org/abs/2505.17861v1", "categories": ["cs.AI", "cs.CY", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Scalable Valuation of Human Feedback through Provably Robust Model Alignment", "abstract": "Despite the importance of aligning language models with human preferences,\ncrowd-sourced human feedback is often noisy -- for example, preferring less\ndesirable responses -- posing a fundamental challenge to alignment. A truly\nrobust alignment objective should yield identical model parameters even under\nsevere label noise, a property known as redescending. We prove that no existing\nalignment methods satisfy this property. To address this, we propose\nH\\\"older-DPO, the first principled alignment loss with a provable redescending\nproperty, enabling estimation of the clean data distribution from noisy\nfeedback. The aligned model estimates the likelihood of clean data, providing a\ntheoretically grounded metric for dataset valuation that identifies the\nlocation and fraction of mislabels. This metric is gradient-free, enabling\nscalable and automated human feedback valuation without costly manual\nverification or clean validation dataset. H\\\"older-DPO achieves\nstate-of-the-art robust alignment performance while accurately detecting\nmislabels in controlled datasets. Finally, we apply H\\\"older-DPO to widely used\nalignment datasets, revealing substantial noise levels and demonstrating that\nremoving these mislabels significantly improves alignment performance across\nmethods.", "published": "2025-05-23 13:12:37", "link": "http://arxiv.org/abs/2505.17859v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Stochastic Weight Sharing for Bayesian Neural Networks", "abstract": "While offering a principled framework for uncertainty quantification in deep\nlearning, the employment of Bayesian Neural Networks (BNNs) is still\nconstrained by their increased computational requirements and the convergence\ndifficulties when training very deep, state-of-the-art architectures. In this\nwork, we reinterpret weight-sharing quantization techniques from a stochastic\nperspective in the context of training and inference with Bayesian Neural\nNetworks (BNNs). Specifically, we leverage 2D adaptive Gaussian distributions,\nWasserstein distance estimations, and alpha blending to encode the stochastic\nbehaviour of a BNN in a lower dimensional, soft Gaussian representation.\nThrough extensive empirical investigation, we demonstrate that our approach\nsignificantly reduces the computational overhead inherent in Bayesian learning\nby several orders of magnitude, enabling the efficient Bayesian training of\nlarge-scale models, such as ResNet-101 and Vision Transformer (VIT). On various\ncomputer vision benchmarks including CIFAR10, CIFAR100, and ImageNet1k. Our\napproach compresses model parameters by approximately 50x and reduces model\nsize by 75, while achieving accuracy and uncertainty estimations comparable to\nthe state-of-the-art.", "published": "2025-05-23 13:07:18", "link": "http://arxiv.org/abs/2505.17856v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Scaling Recurrent Neural Networks to a Billion Parameters with Zero-Order Optimization", "abstract": "During inference, Recurrent Neural Networks (RNNs) scale constant in both\nFLOPs and GPU memory with increasing context length, as they compress all prior\ntokens into a fixed-size memory. In contrast, transformers scale linearly in\nFLOPs and, at best, linearly in memory during generation, since they must\nattend to all previous tokens explicitly. Despite this inference-time\nadvantage, training large RNNs on long contexts remains impractical because\nstandard optimization methods depend on Backpropagation Through Time (BPTT).\nBPTT requires retention of all intermediate activations during the forward\npass, causing memory usage to scale linearly with both context length and model\nsize. In this paper, we show that Zero-Order Optimization (ZOO) methods such as\nRandom-vector Gradient Estimation (RGE) can successfully replace BPTT to train\nRNNs with convergence rates that match, or exceed BPTT by up to 19 fold, while\nusing orders of magnitude less memory and cost, as the model remains in\ninference mode throughout training. We further demonstrate that\nCentral-Difference RGE (CD-RGE) corresponds to optimizing a smoothed surrogate\nloss, inherently regularizing training and improving generalization. Our method\nmatches or outperforms BPTT across three settings: (1) overfitting, (2)\ntransduction, and (3) language modeling. Across all tasks, with sufficient\nperturbations, our models generalize as well as or better than those trained\nwith BPTT, often in fewer steps. Despite the need for more forward passes per\nstep, we can surpass BPTT wall-clock time per step using recent advancements\nsuch as FlashRNN and distributed inference.", "published": "2025-05-23 13:04:06", "link": "http://arxiv.org/abs/2505.17852v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TransDF: Time-Series Forecasting Needs Transformed Label Alignment", "abstract": "Training time-series forecasting models presents unique challenges in\ndesigning effective learning objectives. Existing methods predominantly utilize\nthe temporal mean squared error, which faces two critical challenges: (1) label\nautocorrelation, which leads to bias from the label sequence likelihood; (2)\nexcessive amount of tasks, which increases with the forecast horizon and\ncomplicates optimization. To address these challenges, we propose\nTransform-enhanced Direct Forecast (TransDF), which transforms the label\nsequence into decorrelated components with discriminated significance. Models\nare trained to align the most significant components, thereby effectively\nmitigating label autocorrelation and reducing task amount. Extensive\nexperiments demonstrate that TransDF achieves state-of-the-art performance and\nis compatible with various forecasting models. Code is available at\nhttps://anonymous.4open.science/r/TransDF-88CF.", "published": "2025-05-23 13:00:35", "link": "http://arxiv.org/abs/2505.17847v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "TEDI: Trustworthy and Ethical Dataset Indicators to Analyze and Compare Dataset Documentation", "abstract": "Dataset transparency is a key enabler of responsible AI, but insights into\nmultimodal dataset attributes that impact trustworthy and ethical aspects of AI\napplications remain scarce and are difficult to compare across datasets. To\naddress this challenge, we introduce Trustworthy and Ethical Dataset Indicators\n(TEDI) that facilitate the systematic, empirical analysis of dataset\ndocumentation. TEDI encompasses 143 fine-grained indicators that characterize\ntrustworthy and ethical attributes of multimodal datasets and their collection\nprocesses. The indicators are framed to extract verifiable information from\ndataset documentation. Using TEDI, we manually annotated and analyzed over 100\nmultimodal datasets that include human voices. We further annotated data\nsourcing, size, and modality details to gain insights into the factors that\nshape trustworthy and ethical dimensions across datasets. We find that only a\nselect few datasets have documented attributes and practices pertaining to\nconsent, privacy, and harmful content indicators. The extent to which these and\nother ethical indicators are addressed varies based on the data collection\nmethod, with documentation of datasets collected via crowdsourced and direct\ncollection approaches being more likely to mention them. Scraping dominates\nscale at the cost of ethical indicators, but is not the only viable collection\nmethod. Our approach and empirical insights contribute to increasing dataset\ntransparency along trustworthy and ethical dimensions and pave the way for\nautomating the tedious task of extracting information from dataset\ndocumentation in future.", "published": "2025-05-23 12:55:33", "link": "http://arxiv.org/abs/2505.17841v1", "categories": ["cs.CY", "cs.AI", "eess.AS"], "primary_category": "cs.CY"}
{"title": "Hybrid Mamba-Transformer Decoder for Error-Correcting Codes", "abstract": "We introduce a novel deep learning method for decoding error correction codes\nbased on the Mamba architecture, enhanced with Transformer layers. Our approach\nproposes a hybrid decoder that leverages Mamba's efficient sequential modeling\nwhile maintaining the global context capabilities of Transformers. To further\nimprove performance, we design a novel layer-wise masking strategy applied to\neach Mamba layer, allowing selective attention to relevant code features at\ndifferent depths. Additionally, we introduce a progressive layer-wise loss,\nsupervising the network at intermediate stages and promoting robust feature\nextraction throughout the decoding process. Comprehensive experiments across a\nrange of linear codes demonstrate that our method significantly outperforms\nTransformer-only decoders and standard Mamba models.", "published": "2025-05-23 12:48:35", "link": "http://arxiv.org/abs/2505.17834v1", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "abstract": "Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomously\nacquire diverse behaviors, but faces major challenges in visual environments\ndue to high-dimensional, semantically sparse observations. In the online\nsetting, where agents learn representations while exploring, the latent space\nevolves with the agent's policy, to capture newly discovered areas of the\nenvironment. However, without incentivization to maximize state coverage in the\nrepresentation, classical approaches based on auto-encoders may converge to\nlatent spaces that over-represent a restricted set of states frequently visited\nby the agent. This is exacerbated in an intrinsic motivation setting, where the\nagent uses the distribution encoded in the latent space to sample the goals it\nlearns to master. To address this issue, we propose to progressively enforce\ndistributional shifts towards a uniform distribution over the full state space,\nto ensure a full coverage of skills that can be learned in the environment. We\nintroduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method that\ncombines the $\\beta$-VAE framework with Distributionally Robust Optimization.\nDRAG leverages an adversarial neural weighter of training states of the VAE, to\naccount for the mismatch between the current data distribution and unseen parts\nof the environment. This allows the agent to construct semantically meaningful\nlatent spaces beyond its immediate experience. Our approach improves state\nspace coverage and downstream control performance on hard exploration\nenvironments such as mazes and robotic control involving walls to bypass,\nwithout pre-training nor prior environment knowledge.", "published": "2025-05-23 12:43:55", "link": "http://arxiv.org/abs/2505.17830v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems", "abstract": "As foundation models grow increasingly more intelligent, reliable and\ntrustworthy safety evaluation becomes more indispensable than ever. However, an\nimportant question arises: Whether and how an advanced AI system would perceive\nthe situation of being evaluated, and lead to the broken integrity of the\nevaluation process? During standard safety tests on a mainstream large\nreasoning model, we unexpectedly observe that the model without any contextual\ncues would occasionally recognize it is being evaluated and hence behave more\nsafety-aligned. This motivates us to conduct a systematic study on the\nphenomenon of evaluation faking, i.e., an AI system autonomously alters its\nbehavior upon recognizing the presence of an evaluation context and thereby\ninfluencing the evaluation results. Through extensive experiments on a diverse\nset of foundation models with mainstream safety benchmarks, we reach the main\nfinding termed the observer effects for AI: When the AI system under evaluation\nis more advanced in reasoning and situational awareness, the evaluation faking\nbehavior becomes more ubiquitous, which reflects in the following aspects: 1)\nReasoning models recognize evaluation 16% more often than non-reasoning models.\n2) Scaling foundation models (32B to 671B) increases faking by over 30% in some\ncases, while smaller models show negligible faking. 3) AI with basic memory is\n2.3x more likely to recognize evaluation and scores 19% higher on safety tests\n(vs. no memory). To measure this, we devised a chain-of-thought monitoring\ntechnique to detect faking intent and uncover internal signals correlated with\nsuch behavior, offering insights for future mitigation studies.", "published": "2025-05-23 12:31:29", "link": "http://arxiv.org/abs/2505.17815v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Seeing It or Not? Interpretable Vision-aware Latent Steering to Mitigate Object Hallucinations", "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable success but\ncontinue to struggle with object hallucination (OH), generating outputs\ninconsistent with visual inputs. While previous work has proposed methods to\nreduce OH, the visual decision-making mechanisms that lead to hallucinations\nremain poorly understood. In this paper, we propose VaLSe, a Vision-aware\nLatent Steering framework that adopts an interpretation-then-mitigation\nstrategy to address OH in LVLMs. By tackling dual challenges of modeling\ncomplex vision-language interactions and eliminating spurious activation\nartifacts, VaLSe can generate visual contribution maps that trace how specific\nvisual inputs influence individual output tokens. These maps reveal the model's\nvision-aware focus regions, which are then used to perform latent space\nsteering, realigning internal representations toward semantically relevant\ncontent and reducing hallucinated outputs. Extensive experiments demonstrate\nthat VaLSe is a powerful interpretability tool and an effective method for\nenhancing model robustness against OH across multiple benchmarks. Furthermore,\nour analysis uncovers limitations in existing OH evaluation metrics,\nunderscoring the need for more nuanced, interpretable, and visually grounded OH\nbenchmarks in future work. Code is available at:\nhttps://github.com/Ziwei-Zheng/VaLSe.", "published": "2025-05-23 12:29:00", "link": "http://arxiv.org/abs/2505.17812v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An Attention Infused Deep Learning System with Grad-CAM Visualization for Early Screening of Glaucoma", "abstract": "This research work reveals the eye opening wisdom of the hybrid labyrinthine\ndeep learning models synergy born out of combining a trailblazing convolutional\nneural network with a disruptive Vision Transformer, both intertwined together\nwith a radical Cross Attention module. Here, two high yielding datasets for\nartificial intelligence models in detecting glaucoma, namely ACRIMA and\nDrishti, are utilized.", "published": "2025-05-23 12:25:13", "link": "http://arxiv.org/abs/2505.17808v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hyperparameter Optimization via Interacting with Probabilistic Circuits", "abstract": "Despite the growing interest in designing truly interactive hyperparameter\noptimization (HPO) methods, to date, only a few allow to include human\nfeedback. Existing interactive Bayesian optimization (BO) methods incorporate\nhuman beliefs by weighting the acquisition function with a user-defined prior\ndistribution. However, in light of the non-trivial inner optimization of the\nacquisition function prevalent in BO, such weighting schemes do not always\naccurately reflect given user beliefs. We introduce a novel BO approach\nleveraging tractable probabilistic models named probabilistic circuits (PCs) as\na surrogate model. PCs encode a tractable joint distribution over the hybrid\nhyperparameter space and evaluation scores. They enable exact conditional\ninference and sampling. Based on conditional sampling, we construct a novel\nselection policy that enables an acquisition function-free generation of\ncandidate points (thereby eliminating the need for an additional inner-loop\noptimization) and ensures that user beliefs are reflected accurately in the\nselection policy. We provide a theoretical analysis and an extensive empirical\nevaluation, demonstrating that our method achieves state-of-the-art performance\nin standard HPO and outperforms interactive BO baselines in interactive HPO.", "published": "2025-05-23 12:21:19", "link": "http://arxiv.org/abs/2505.17804v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour", "abstract": "Autonomous multi-agent systems (MAS) are useful for automating complex tasks\nbut raise trust concerns due to risks like miscoordination and goal\nmisalignment. Explainability is vital for trust calibration, but explainable\nreinforcement learning for MAS faces challenges in state/action space\ncomplexity, stakeholder needs, and evaluation. Using the counterfactual theory\nof causation and LLMs' summarisation capabilities, we propose Agentic\neXplanations via Interrogative Simulation (AXIS). AXIS generates intelligible\ncausal explanations for pre-trained multi-agent policies by having an LLM\ninterrogate an environment simulator using queries like 'whatif' and 'remove'\nto observe and synthesise counterfactual information over multiple rounds. We\nevaluate AXIS on autonomous driving across 10 scenarios for 5 LLMs with a novel\nevaluation methodology combining subjective preference, correctness, and\ngoal/action prediction metrics, and an external LLM as evaluator. Compared to\nbaselines, AXIS improves perceived explanation correctness by at least 7.7%\nacross all models and goal prediction accuracy by 23% for 4 models, with\nimproved or comparable action prediction accuracy, achieving the highest scores\noverall.", "published": "2025-05-23 12:19:18", "link": "http://arxiv.org/abs/2505.17801v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DetailFusion: A Dual-branch Framework with Detail Enhancement for Composed Image Retrieval", "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images from a gallery\nbased on a reference image and modification text as a combined query. Recent\napproaches focus on balancing global information from two modalities and encode\nthe query into a unified feature for retrieval. However, due to insufficient\nattention to fine-grained details, these coarse fusion methods often struggle\nwith handling subtle visual alterations or intricate textual instructions. In\nthis work, we propose DetailFusion, a novel dual-branch framework that\neffectively coordinates information across global and detailed granularities,\nthereby enabling detail-enhanced CIR. Our approach leverages atomic detail\nvariation priors derived from an image editing dataset, supplemented by a\ndetail-oriented optimization strategy to develop a Detail-oriented Inference\nBranch. Furthermore, we design an Adaptive Feature Compositor that dynamically\nfuses global and detailed features based on fine-grained information of each\nunique multimodal query. Extensive experiments and ablation analyses not only\ndemonstrate that our method achieves state-of-the-art performance on both CIRR\nand FashionIQ datasets but also validate the effectiveness and cross-domain\nadaptability of detail enhancement for CIR.", "published": "2025-05-23 12:15:23", "link": "http://arxiv.org/abs/2505.17796v1", "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Bruno: Backpropagation Running Undersampled for Novel device Optimization", "abstract": "Recent efforts to improve the efficiency of neuromorphic and machine learning\nsystems have focused on the development of application-specific integrated\ncircuits (ASICs), which provide hardware specialized for the deployment of\nneural networks, leading to potential gains in efficiency and performance.\nThese systems typically feature an architecture that goes beyond the von\nNeumann architecture employed in general-purpose hardware such as GPUs. Neural\nnetworks developed for this specialised hardware then need to take into account\nthe specifics of the hardware platform, which requires novel training\nalgorithms and accurate models of the hardware, since they cannot be abstracted\nas a general-purpose computing platform. In this work, we present a bottom-up\napproach to train neural networks for hardware based on spiking neurons and\nsynapses built on ferroelectric capacitor (FeCap) and Resistive switching\nnon-volatile devices (RRAM) respectively. In contrast to the more common\napproach of designing hardware to fit existing abstract neuron or synapse\nmodels, this approach starts with compact models of the physical device to\nmodel the computational primitive of the neurons. Based on these models, a\ntraining algorithm is developed that can reliably backpropagate through these\nphysical models, even when applying common hardware limitations, such as\nstochasticity, variability, and low bit precision. The training algorithm is\nthen tested on a spatio-temporal dataset with a network composed of quantized\nsynapses based on RRAM and ferroelectric leaky integrate-and-fire (FeLIF)\nneurons. The performance of the network is compared with different networks\ncomposed of LIF neurons. The results of the experiments show the potential\nadvantage of using BRUNO to train networks with FeLIF neurons, by achieving a\nreduction in both time and memory for detecting spatio-temporal patterns with\nquantized synapses.", "published": "2025-05-23 12:06:43", "link": "http://arxiv.org/abs/2505.17791v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors", "abstract": "Recent safety evaluations of Large Language Models (LLMs) show that many\nmodels exhibit dishonest behavior, such as sycophancy. However, most honesty\nbenchmarks focus exclusively on factual knowledge or explicitly harmful\nbehavior and rely on external judges, which are often unable to detect less\nobvious forms of dishonesty. In this work, we introduce a new framework, Judge\nUsing Safety-Steered Alternatives (JUSSA), which utilizes steering vectors\ntrained on a single sample to elicit more honest responses from models, helping\nLLM-judges in the detection of dishonest behavior. To test our framework, we\nintroduce a new manipulation dataset with prompts specifically designed to\nelicit deceptive responses. We find that JUSSA enables LLM judges to better\ndifferentiate between dishonest and benign responses, and helps them identify\nsubtle instances of manipulative behavior.", "published": "2025-05-23 11:34:02", "link": "http://arxiv.org/abs/2505.17760v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mind the GAP! The Challenges of Scale in Pixel-based Deep Reinforcement Learning", "abstract": "Scaling deep reinforcement learning in pixel-based environments presents a\nsignificant challenge, often resulting in diminished performance. While recent\nworks have proposed algorithmic and architectural approaches to address this,\nthe underlying cause of the performance drop remains unclear. In this paper, we\nidentify the connection between the output of the encoder (a stack of\nconvolutional layers) and the ensuing dense layers as the main underlying\nfactor limiting scaling capabilities; we denote this connection as the\nbottleneck, and we demonstrate that previous approaches implicitly target this\nbottleneck. As a result of our analyses, we present global average pooling as a\nsimple yet effective way of targeting the bottleneck, thereby avoiding the\ncomplexity of earlier approaches.", "published": "2025-05-23 11:15:43", "link": "http://arxiv.org/abs/2505.17749v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MetaBox-v2: A Unified Benchmark Platform for Meta-Black-Box Optimization", "abstract": "Meta-Black-Box Optimization (MetaBBO) streamlines the automation of\noptimization algorithm design through meta-learning. It typically employs a\nbi-level structure: the meta-level policy undergoes meta-training to reduce the\nmanual effort required in developing algorithms for low-level optimization\ntasks. The original MetaBox (2023) provided the first open-source framework for\nreinforcement learning-based single-objective MetaBBO. However, its relatively\nnarrow scope no longer keep pace with the swift advancement in this field. In\nthis paper, we introduce MetaBox-v2 (https://github.com/MetaEvo/MetaBox) as a\nmilestone upgrade with four novel features: 1) a unified architecture\nsupporting RL, evolutionary, and gradient-based approaches, by which we\nreproduce 23 up-to-date baselines; 2) efficient parallelization schemes, which\nreduce the training/testing time by 10-40x; 3) a comprehensive benchmark suite\nof 18 synthetic/realistic tasks (1900+ instances) spanning single-objective,\nmulti-objective, multi-model, and multi-task optimization scenarios; 4)\nplentiful and extensible interfaces for custom analysis/visualization and\nintegrating to external optimization tools/benchmarks. To show the utility of\nMetaBox-v2, we carry out a systematic case study that evaluates the built-in\nbaselines in terms of the optimization performance, generalization ability and\nlearning efficiency. Valuable insights are concluded from thorough and detailed\nanalysis for practitioners and those new to the field.", "published": "2025-05-23 11:13:10", "link": "http://arxiv.org/abs/2505.17745v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios", "abstract": "Large Language Model (LLM)-based agents are increasingly deployed in\nreal-world applications such as \"digital assistants, autonomous customer\nservice, and decision-support systems\", where their ability to \"interact in\nmulti-turn, tool-augmented environments\" makes them indispensable. However,\nensuring the safety of these agents remains a significant challenge due to the\ndiverse and complex risks arising from dynamic user interactions, external tool\nusage, and the potential for unintended harmful behaviors. To address this\ncritical issue, we propose AutoSafe, the first framework that systematically\nenhances agent safety through fully automated synthetic data generation.\nConcretely, 1) we introduce an open and extensible threat model, OTS, which\nformalizes how unsafe behaviors emerge from the interplay of user instructions,\ninteraction contexts, and agent actions. This enables precise modeling of\nsafety risks across diverse scenarios. 2) we develop a fully automated data\ngeneration pipeline that simulates unsafe user behaviors, applies\nself-reflective reasoning to generate safe responses, and constructs a\nlarge-scale, diverse, and high-quality safety training dataset-eliminating the\nneed for hazardous real-world data collection. To evaluate the effectiveness of\nour framework, we design comprehensive experiments on both synthetic and\nreal-world safety benchmarks. Results demonstrate that AutoSafe boosts safety\nscores by 45% on average and achieves a 28.91% improvement on real-world tasks,\nvalidating the generalization ability of our learned safety strategies. These\nresults highlight the practical advancement and scalability of AutoSafe in\nbuilding safer LLM-based agents for real-world deployment. We have released the\nproject page at https://auto-safe.github.io/.", "published": "2025-05-23 10:56:06", "link": "http://arxiv.org/abs/2505.17735v1", "categories": ["cs.AI", "68T07", "I.2.6"], "primary_category": "cs.AI"}
{"title": "RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection", "abstract": "Accurate, fast, and reliable 3D perception is essential for autonomous\ndriving. Recently, bird's-eye view (BEV)-based perception approaches have\nemerged as superior alternatives to perspective-based solutions, offering\nenhanced spatial understanding and more natural outputs for planning. Existing\nBEV-based 3D object detection methods, typically adhering to angle-based\nrepresentation, directly estimate the size and orientation of rotated bounding\nboxes. We observe that BEV-based 3D object detection is analogous to aerial\noriented object detection, where angle-based methods are recognized for being\naffected by discontinuities in their loss functions. Drawing inspiration from\nthis domain, we propose Restricted Quadrilateral Representation to define 3D\nregression targets. RQR3D regresses the smallest horizontal bounding box\nencapsulating the oriented box, along with the offsets between the corners of\nthese two boxes, thereby transforming the oriented object detection problem\ninto a keypoint regression task. RQR3D is compatible with any 3D object\ndetection approach. We employ RQR3D within an anchor-free single-stage object\ndetection method and introduce an objectness head to address class imbalance\nproblem. Furthermore, we introduce a simplified radar fusion backbone that\neliminates the need for voxel grouping and processes the BEV-mapped point cloud\nwith standard 2D convolutions, rather than sparse convolutions. Extensive\nevaluations on the nuScenes dataset demonstrate that RQR3D achieves\nstate-of-the-art performance in camera-radar 3D object detection, outperforming\nthe previous best method by +4% in NDS and +2.4% in mAP, and significantly\nreducing the translation and orientation errors, which are crucial for safe\nautonomous driving. These consistent gains highlight the robustness, precision,\nand real-world readiness of our approach.", "published": "2025-05-23 10:52:34", "link": "http://arxiv.org/abs/2505.17732v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM", "abstract": "Recently, multimodal large language models (MLLMs) have emerged as a key\napproach in achieving artificial general intelligence. In particular,\nvision-language MLLMs have been developed to generate not only text but also\nvisual outputs from multimodal inputs. This advancement requires efficient\nimage tokens that LLMs can process effectively both in input and output.\nHowever, existing image tokenization methods for MLLMs typically capture only\nglobal abstract concepts or uniformly segmented image patches, restricting\nMLLMs' capability to effectively understand or generate detailed visual\ncontent, particularly at the object level. To address this limitation, we\npropose an object-centric visual tokenizer based on Slot Attention specifically\nfor MLLMs. In particular, based on the Q-Former encoder, diffusion decoder, and\nresidual vector quantization, our proposed discretized slot tokens can encode\nlocal visual details while maintaining high-level semantics, and also align\nwith textual data to be integrated seamlessly within a unified next-token\nprediction framework of LLMs. The resulting Slot-MLLM demonstrates significant\nperformance improvements over baselines with previous visual tokenizers across\nvarious vision-language tasks that entail local detailed comprehension and\ngeneration. Notably, this work is the first demonstration of the feasibility of\nobject-centric slot attention performed with MLLMs and in-the-wild natural\nimages.", "published": "2025-05-23 10:43:45", "link": "http://arxiv.org/abs/2505.17726v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation", "abstract": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods.", "published": "2025-05-23 10:34:28", "link": "http://arxiv.org/abs/2505.17717v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "CIKT: A Collaborative and Iterative Knowledge Tracing Framework with Large Language Models", "abstract": "Knowledge Tracing (KT) aims to model a student's learning state over time and\npredict their future performance. However, traditional KT methods often face\nchallenges in explainability, scalability, and effective modeling of complex\nknowledge dependencies. While Large Language Models (LLMs) present new avenues\nfor KT, their direct application often struggles with generating structured,\nexplainable student representations and lacks mechanisms for continuous,\ntask-specific refinement. To address these gaps, we propose Collaborative\nIterative Knowledge Tracing (CIKT), a framework that harnesses LLMs to enhance\nboth prediction accuracy and explainability. CIKT employs a dual-component\narchitecture: an Analyst generates dynamic, explainable user profiles from\nstudent historical responses, and a Predictor utilizes these profiles to\nforecast future performance. The core of CIKT is a synergistic optimization\nloop. In this loop, the Analyst is iteratively refined based on the predictive\naccuracy of the Predictor, which conditions on the generated profiles, and the\nPredictor is subsequently retrained using these enhanced profiles. Evaluated on\nmultiple educational datasets, CIKT demonstrates significant improvements in\nprediction accuracy, offers enhanced explainability through its dynamically\nupdated user profiles, and exhibits improved scalability. Our work presents a\nrobust and explainable solution for advancing knowledge tracing systems,\neffectively bridging the gap between predictive performance and model\ntransparency.", "published": "2025-05-23 10:16:16", "link": "http://arxiv.org/abs/2505.17705v1", "categories": ["cs.AI", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek", "abstract": "The advent of Computer-Aided Design (CAD) generative modeling will\nsignificantly transform the design of industrial products. The recent research\nendeavor has extended into the realm of Large Language Models (LLMs). In\ncontrast to fine-tuning methods, training-free approaches typically utilize the\nadvanced closed-source LLMs, thereby offering enhanced flexibility and\nefficiency in the development of AI agents for generating CAD parametric\nmodels. However, the substantial cost and limitations of local deployment of\nthe top-tier closed-source LLMs pose challenges in practical applications. The\nSeek-CAD is the pioneer exploration of locally deployed open-source inference\nLLM DeepSeek-R1 for CAD parametric model generation with a training-free\nmethodology. This study is the first investigation to incorporate both visual\nand Chain-of-Thought (CoT) feedback within the self-refinement mechanism for\ngenerating CAD models. Specifically, the initial generated parametric CAD model\nis rendered into a sequence of step-wise perspective images, which are\nsubsequently processed by a Vision Language Model (VLM) alongside the\ncorresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation.\nThen, the feedback is utilized by DeepSeek-R1 to refine the initial generated\nmodel for the next round of generation. Moreover, we present an innovative 3D\nCAD model dataset structured around the SSR (Sketch, Sketch-based feature, and\nRefinements) triple design paradigm. This dataset encompasses a wide range of\nCAD commands, thereby aligning effectively with industrial application\nrequirements and proving suitable for the generation of LLMs. Extensive\nexperiments validate the effectiveness of Seek-CAD under various metrics.", "published": "2025-05-23 10:11:19", "link": "http://arxiv.org/abs/2505.17702v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory", "abstract": "This research proposes methods for formulating and guaranteeing the\nresilience of long short-term memory (LSTM) networks, which can serve as a key\ntechnology in AI system quality assurance. We introduce a novel methodology\napplying incremental input-to-state stability ($\\delta$ISS) to mathematically\ndefine and evaluate the resilience of LSTM against input perturbations. Key\nachievements include the development of a data-independent evaluation method\nand the demonstration of resilience control through adjustments to training\nparameters. This research presents concrete solutions to AI quality assurance\nfrom a control theory perspective, which can advance AI applications in control\nsystems.", "published": "2025-05-23 10:05:26", "link": "http://arxiv.org/abs/2505.17696v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data", "abstract": "Despite the advances in Referring Expression Segmentation (RES) benchmarks,\ntheir evaluation protocols remain constrained, primarily focusing on either\nsingle targets with short queries (containing minimal attributes) or multiple\ntargets from distinctly different queries on a single domain. This limitation\nsignificantly hinders the assessment of more complex reasoning capabilities in\nRES models. We introduce WildRES, a novel benchmark that incorporates long\nqueries with diverse attributes and non-distinctive queries for multiple\ntargets. This benchmark spans diverse application domains, including autonomous\ndriving environments and robotic manipulation scenarios, thus enabling more\nrigorous evaluation of complex reasoning capabilities in real-world settings.\nOur analysis reveals that current RES models demonstrate substantial\nperformance deterioration when evaluated on WildRES. To address this challenge,\nwe introduce SynRES, an automated pipeline generating densely paired\ncompositional synthetic training data through three innovations: (1) a dense\ncaption-driven synthesis for attribute-rich image-mask-expression triplets, (2)\nreliable semantic alignment mechanisms rectifying caption-pseudo mask\ninconsistencies via Image-Text Aligned Grouping, and (3) domain-aware\naugmentations incorporating mosaic composition and superclass replacement to\nemphasize generalization ability and distinguishing attributes over object\ncategories. Experimental results demonstrate that models trained with SynRES\nachieve state-of-the-art performance, improving gIoU by 2.0% on WildRES-ID and\n3.8% on WildRES-DS. Code and datasets are available at\nhttps://github.com/UTLLab/SynRES.", "published": "2025-05-23 10:05:16", "link": "http://arxiv.org/abs/2505.17695v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection", "abstract": "Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any\ntarget domain training samples, relying solely on external auxiliary data.\nExisting CLIP-based methods attempt to activate the model's ZSAD potential via\nhandcrafted or static learnable prompts. The former incur high engineering\ncosts and limited semantic coverage, whereas the latter apply identical\ndescriptions across diverse anomaly types, thus fail to adapt to complex\nvariations. Furthermore, since CLIP is originally pretrained on large-scale\nclassification tasks, its anomaly segmentation quality is highly sensitive to\nthe exact wording of class names, severely constraining prompting strategies\nthat depend on class labels. To address these challenges, we introduce\nViP$^{2}$-CLIP. The key insight of ViP$^{2}$-CLIP is a Visual-Perception\nPrompting (ViP-Prompt) mechanism, which fuses global and multi-scale local\nvisual context to adaptively generate fine-grained textual prompts, eliminating\nmanual templates and class-name priors. This design enables our model to focus\non precise abnormal regions, making it particularly valuable when category\nlabels are ambiguous or privacy-constrained. Extensive experiments on 15\nindustrial and medical benchmarks demonstrate that ViP$^{2}$-CLIP achieves\nstate-of-the-art performance and robust cross-domain generalization.", "published": "2025-05-23 10:01:11", "link": "http://arxiv.org/abs/2505.17692v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Dual Attention Residual U-Net for Accurate Brain Ultrasound Segmentation in IVH Detection", "abstract": "Intraventricular hemorrhage (IVH) is a severe neurological complication among\npremature infants, necessitating early and accurate detection from brain\nultrasound (US) images to improve clinical outcomes. While recent deep learning\nmethods offer promise for computer-aided diagnosis, challenges remain in\ncapturing both local spatial details and global contextual dependencies\ncritical for segmenting brain anatomies. In this work, we propose an enhanced\nResidual U-Net architecture incorporating two complementary attention\nmechanisms: the Convolutional Block Attention Module (CBAM) and a Sparse\nAttention Layer (SAL). The CBAM improves the model's ability to refine spatial\nand channel-wise features, while the SAL introduces a dual-branch design,\nsparse attention filters out low-confidence query-key pairs to suppress noise,\nand dense attention ensures comprehensive information propagation. Extensive\nexperiments on the Brain US dataset demonstrate that our method achieves\nstate-of-the-art segmentation performance, with a Dice score of 89.04% and IoU\nof 81.84% for ventricle region segmentation. These results highlight the\neffectiveness of integrating spatial refinement and attention sparsity for\nrobust brain anatomy detection. Code is available at:\nhttps://github.com/DanYuan001/BrainImgSegment.", "published": "2025-05-23 09:53:57", "link": "http://arxiv.org/abs/2505.17683v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution", "abstract": "Most LLM-based agent frameworks adopt a top-down philosophy: humans decompose\ntasks, define workflows, and assign agents to execute each step. While\neffective on benchmark-style tasks, such systems rely on designer updates and\noverlook agents' potential to learn from experience. Recently, Silver and\nSutton(2025) envision a shift into a new era, where agents could progress from\na stream of experiences. In this paper, we instantiate this vision of\nexperience-driven learning by introducing a bottom-up agent paradigm that\nmirrors the human learning process. Agents acquire competence through a\ntrial-and-reasoning mechanism-exploring, reflecting on outcomes, and\nabstracting skills over time. Once acquired, skills can be rapidly shared and\nextended, enabling continual evolution rather than static replication. As more\nagents are deployed, their diverse experiences accelerate this collective\nprocess, making bottom-up design especially suited for open-ended environments.\nWe evaluate this paradigm in Slay the Spire and Civilization V, where agents\nperceive through raw visual inputs and act via mouse outputs, the same as human\nplayers. Using a unified, game-agnostic codebase without any game-specific\nprompts or privileged APIs, our bottom-up agents acquire skills entirely\nthrough autonomous interaction, demonstrating the potential of the bottom-up\nparadigm in complex, real-world environments. Our code is available at\nhttps://github.com/AngusDujw/Bottom-Up-Agent.", "published": "2025-05-23 09:38:55", "link": "http://arxiv.org/abs/2505.17673v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards General Continuous Memory for Vision-Language Models", "abstract": "Language models (LMs) and their extension, vision-language models (VLMs),\nhave achieved remarkable performance across various tasks. However, they still\nstruggle with complex reasoning tasks that require multimodal or multilingual\nreal-world knowledge. To support such capabilities, an external memory system\nthat can efficiently provide relevant multimodal information is essential.\nExisting approaches generally concatenate image and text tokens into a long\nsequence as memory, which, however, may drastically increase context length and\neven degrade performance. In contrast, we propose using continuous memory, a\ncompact set of dense embeddings to more effectively and efficiently represent\nmultimodal and multilingual knowledge. Our key insight is that a VLM can serve\nas its own continuous memory encoder. We empirically show that this design\nimproves performance on complex multimodal reasoning tasks. Building on this,\nwe introduce a data-efficient and parameter-efficient method to fine-tune the\nVLM into a memory encoder, requiring only 1.2% of the model's parameters and a\nsmall corpus of 15.6K self-synthesized samples. Our approach CoMEM utilizes\nVLM's original capabilities to encode arbitrary multimodal and multilingual\nknowledge into just 8 continuous embeddings. Since the inference-time VLM\nremains frozen, our memory module is plug-and-play and can be flexibly\nintegrated as needed. Extensive experiments across eight multimodal reasoning\nbenchmarks demonstrate the effectiveness of our approach.", "published": "2025-05-23 09:36:53", "link": "http://arxiv.org/abs/2505.17670v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EMRA-proxy: Enhancing Multi-Class Region Semantic Segmentation in Remote Sensing Images with Attention Proxy", "abstract": "High-resolution remote sensing (HRRS) image segmentation is challenging due\nto complex spatial layouts and diverse object appearances. While CNNs excel at\ncapturing local features, they struggle with long-range dependencies, whereas\nTransformers can model global context but often neglect local details and are\ncomputationally expensive.We propose a novel approach, Region-Aware Proxy\nNetwork (RAPNet), which consists of two components: Contextual Region Attention\n(CRA) and Global Class Refinement (GCR). Unlike traditional methods that rely\non grid-based layouts, RAPNet operates at the region level for more flexible\nsegmentation. The CRA module uses a Transformer to capture region-level\ncontextual dependencies, generating a Semantic Region Mask (SRM). The GCR\nmodule learns a global class attention map to refine multi-class information,\ncombining the SRM and attention map for accurate segmentation.Experiments on\nthree public datasets show that RAPNet outperforms state-of-the-art methods,\nachieving superior multi-class segmentation accuracy.", "published": "2025-05-23 09:30:45", "link": "http://arxiv.org/abs/2505.17665v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GeoGramBench: Benchmarking the Geometric Program Reasoning in Modern LLMs", "abstract": "Geometric spatial reasoning forms the foundation of many applications in\nartificial intelligence, yet the ability of large language models (LLMs) to\noperate over geometric spatial information expressed in procedural code remains\nunderexplored. In this paper, we address this gap by formalizing the\nProgram-to-Geometry task, which challenges models to translate programmatic\ndrawing code into accurate and abstract geometric reasoning. To evaluate this\ncapability, we present GeoGramBench, a benchmark of 500 carefully refined\nproblems organized by a tailored three-level taxonomy that considers geometric\ncomplexity rather than traditional mathematical reasoning complexity. Our\ncomprehensive evaluation of 17 frontier LLMs reveals consistent and pronounced\ndeficiencies: even the most advanced models achieve less than 50% accuracy at\nthe highest abstraction level. These results highlight the unique challenges\nposed by program-driven spatial reasoning and establish GeoGramBench as a\nvaluable resource for advancing research in symbolic-to-spatial geometric\nreasoning. Project page: https://github.com/LiAuto-DSR/GeoGramBench.", "published": "2025-05-23 09:17:07", "link": "http://arxiv.org/abs/2505.17653v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective", "abstract": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces \\textbf{C}ompetence-\\textbf{D}ifficulty\n\\textbf{A}lignment \\textbf{S}ampling (\\textbf{CDAS}), which enables accurate\nand stable estimation of problem difficulties by aggregating historical\nperformance discrepancies of problems. Then the model competence is quantified\nto adaptively select problems whose difficulty is in alignment with the model's\ncurrent competence using a fixed-point system. Experimental results across a\nrange of challenging mathematical benchmarks show that CDAS achieves great\nimprovements in both accuracy and efficiency. CDAS attains the highest average\naccuracy against baselines and exhibits significant speed advantages compared\nto Dynamic Sampling, a competitive strategy in DAPO, which is \\textbf{2.33}\ntimes slower than CDAS.", "published": "2025-05-23 09:15:26", "link": "http://arxiv.org/abs/2505.17652v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?", "abstract": "Jailbreak attacks have been observed to largely fail against recent reasoning\nmodels enhanced by Chain-of-Thought (CoT) reasoning. However, the underlying\nmechanism remains underexplored, and relying solely on reasoning capacity may\nraise security concerns. In this paper, we try to answer the question: Does CoT\nreasoning really reduce harmfulness from jailbreaking? Through rigorous\ntheoretical analysis, we demonstrate that CoT reasoning has dual effects on\njailbreaking harmfulness. Based on the theoretical insights, we propose a novel\njailbreak method, FicDetail, whose practical performance validates our\ntheoretical findings.", "published": "2025-05-23 09:14:48", "link": "http://arxiv.org/abs/2505.17650v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "REN: Fast and Efficient Region Encodings from Patch-Based Image Encoders", "abstract": "We introduce the Region Encoder Network (REN), a fast and effective model for\ngenerating region-based image representations using point prompts. Recent\nmethods combine class-agnostic segmenters (e.g., SAM) with patch-based image\nencoders (e.g., DINO) to produce compact and effective region representations,\nbut they suffer from high computational cost due to the segmentation step. REN\nbypasses this bottleneck using a lightweight module that directly generates\nregion tokens, enabling 60x faster token generation with 35x less memory, while\nalso improving token quality. It uses a few cross-attention blocks that take\npoint prompts as queries and features from a patch-based image encoder as keys\nand values to produce region tokens that correspond to the prompted objects. We\ntrain REN with three popular encoders-DINO, DINOv2, and OpenCLIP-and show that\nit can be extended to other encoders without dedicated training. We evaluate\nREN on semantic segmentation and retrieval tasks, where it consistently\noutperforms the original encoders in both performance and compactness, and\nmatches or exceeds SAM-based region methods while being significantly faster.\nNotably, REN achieves state-of-the-art results on the challenging Ego4D VQ2D\nbenchmark and outperforms proprietary LMMs on Visual Haystacks' single-needle\nchallenge. Code and models are available at: https://github.com/savya08/REN.", "published": "2025-05-23 17:59:33", "link": "http://arxiv.org/abs/2505.18153v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TokBench: Evaluating Your Visual Tokenizer before Visual Generation", "abstract": "In this work, we reveal the limitations of visual tokenizers and VAEs in\npreserving fine-grained features, and propose a benchmark to evaluate\nreconstruction performance for two challenging visual contents: text and face.\nImage tokenization has significantly advanced visual generation and multimodal\nmodeling, particularly with autoregressive models due to the modeling\nsimplicity of discrete tokens. Autoregressive models typically rely on image\ntokenizers to compress images into discrete tokens for sequential prediction,\nwhereas diffusion models often operate on continuous latent space to reduce\ncomputational costs. However, both visual compression approaches inevitably\nlose visual information, thereby limiting the upper bound of visual generation\nquality. To evaluate how these compression losses affect text and faces, the\nmost human-sensitive visual elements, we first collect and curate a collection\nof text and faces images from existing datasets, ensuring clarity and\ndiversity. For text reconstruction, we employ OCR models to assess the\nrecognition accuracy of the reconstructed text, and then we measure feature\nsimilarity between original and reconstructed faces thereby quantifying faces\nreconstruction fidelity. Our method is highly lightweight, requiring just 2GB\nmemory and 4 minutes to complete evaluations. With our benchmark, we analyze\nthe reconstruction quality of text and faces at various scales across different\nimage tokenizers and VAEs. Our results demonstrate that modern visual\ntokenizers still struggle to preserve fine-grained features, particularly at\nsmaller scales. Furthermore, we extend this evaluation framework to the video,\nconducting a comprehensive analysis of video tokenizers. Additionally, we find\nthat traditional metrics fail to accurately reflect the reconstruction\nperformance for faces and text, while our proposed metrics serve as an\neffective complement.", "published": "2025-05-23 17:52:16", "link": "http://arxiv.org/abs/2505.18142v1", "categories": ["cs.CV", "cs.DB"], "primary_category": "cs.CV"}
{"title": "Boosting Open Set Recognition Performance through Modulated Representation Learning", "abstract": "The open set recognition (OSR) problem aims to identify test samples from\nnovel semantic classes that are not part of the training classes, a task that\nis crucial in many practical scenarios. However, existing OSR methods use a\nconstant scaling factor (the temperature) to the logits before applying a loss\nfunction, which hinders the model from exploring both ends of the spectrum in\nrepresentation learning -- from instance-level to semantic-level features. In\nthis paper, we address this problem by enabling temperature-modulated\nrepresentation learning using our novel negative cosine scheduling scheme. Our\nscheduling lets the model form a coarse decision boundary at the beginning of\ntraining by focusing on fewer neighbors, and gradually prioritizes more\nneighbors to smooth out rough edges. This gradual task switching leads to a\nricher and more generalizable representation space. While other OSR methods\nbenefit by including regularization or auxiliary negative samples, such as with\nmix-up, thereby adding a significant computational overhead, our scheme can be\nfolded into any existing OSR method with no overhead. We implement the proposed\nscheme on top of a number of baselines, using both cross-entropy and\ncontrastive loss functions as well as a few other OSR methods, and find that\nour scheme boosts both the OSR performance and the closed set performance in\nmost cases, especially on the tougher semantic shift benchmarks.", "published": "2025-05-23 17:47:20", "link": "http://arxiv.org/abs/2505.18137v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BiggerGait: Unlocking Gait Recognition with Layer-wise Representations from Large Vision Models", "abstract": "Large vision models (LVM) based gait recognition has achieved impressive\nperformance. However, existing LVM-based approaches may overemphasize gait\npriors while neglecting the intrinsic value of LVM itself, particularly the\nrich, distinct representations across its multi-layers. To adequately unlock\nLVM's potential, this work investigates the impact of layer-wise\nrepresentations on downstream recognition tasks. Our analysis reveals that\nLVM's intermediate layers offer complementary properties across tasks,\nintegrating them yields an impressive improvement even without rich\nwell-designed gait priors. Building on this insight, we propose a simple and\nuniversal baseline for LVM-based gait recognition, termed BiggerGait.\nComprehensive evaluations on CCPG, CAISA-B*, SUSTech1K, and CCGR\\_MINI validate\nthe superiority of BiggerGait across both within- and cross-domain tasks,\nestablishing it as a simple yet practical baseline for gait representation\nlearning. All the models and code will be publicly available.", "published": "2025-05-23 17:41:54", "link": "http://arxiv.org/abs/2505.18132v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Instructify: Demystifying Metadata to Visual Instruction Tuning Data Conversion", "abstract": "Visual Instruction Tuning (VisIT) data, commonly available as human-assistant\nconversations with images interleaved in the human turns, are currently the\nmost widespread vehicle for aligning strong LLMs to understand visual inputs,\nconverting them to strong LMMs. While many VisIT datasets are available, most\nare constructed using ad-hoc techniques developed independently by different\ngroups. They are often poorly documented, lack reproducible code, and rely on\npaid, closed-source model APIs such as GPT-4, Gemini, or Claude to convert\nimage metadata (labels) into VisIT instructions. This leads to high costs and\nmakes it challenging to scale, enhance quality, or generate VisIT data for new\ndatasets. In this work, we address these challenges and propose an open and\nunified recipe and approach,~\\textbf{\\method}, for converting available\nmetadata to VisIT instructions using open LLMs. Our multi-stage \\method\nfeatures an efficient framework for metadata grouping, quality control, data\nand prompt organization, and conversation sampling. We show that our approach\ncan reproduce or enhance the data quality of available VisIT datasets when\napplied to the same image data and metadata sources, improving GPT-4 generated\nVisIT instructions by ~3\\% on average and up to 12\\% on individual benchmarks\nusing open models, such as Gemma 2 27B and LLaMa 3.1 70B. Additionally, our\napproach enables effective performance scaling - both in quantity and quality -\nby enhancing the resulting LMM performance across a wide range of benchmarks.\nWe also analyze the impact of various factors, including conversation format,\nbase model selection, and resampling strategies. Our code, which supports the\nreproduction of equal or higher-quality VisIT datasets and facilities future\nmetadata-to-VisIT data conversion for niche domains, is released at\nhttps://github.com/jacob-hansen/Instructify.", "published": "2025-05-23 17:14:12", "link": "http://arxiv.org/abs/2505.18115v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adapting SAM 2 for Visual Object Tracking: 1st Place Solution for MMVPR Challenge Multi-Modal Tracking", "abstract": "We present an effective approach for adapting the Segment Anything Model 2\n(SAM2) to the Visual Object Tracking (VOT) task. Our method leverages the\npowerful pre-trained capabilities of SAM2 and incorporates several key\ntechniques to enhance its performance in VOT applications. By combining SAM2\nwith our proposed optimizations, we achieved a first place AUC score of 89.4 on\nthe 2024 ICPR Multi-modal Object Tracking challenge, demonstrating the\neffectiveness of our approach. This paper details our methodology, the specific\nenhancements made to SAM2, and a comprehensive analysis of our results in the\ncontext of VOT solutions along with the multi-modality aspect of the dataset.", "published": "2025-05-23 17:04:56", "link": "http://arxiv.org/abs/2505.18111v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accelerating Learned Image Compression Through Modeling Neural Training Dynamics", "abstract": "As learned image compression (LIC) methods become increasingly\ncomputationally demanding, enhancing their training efficiency is crucial. This\npaper takes a step forward in accelerating the training of LIC methods by\nmodeling the neural training dynamics. We first propose a Sensitivity-aware\nTrue and Dummy Embedding Training mechanism (STDET) that clusters LIC model\nparameters into few separate modes where parameters are expressed as affine\ntransformations of reference parameters within the same mode. By further\nutilizing the stable intra-mode correlations throughout training and parameter\nsensitivities, we gradually embed non-reference parameters, reducing the number\nof trainable parameters. Additionally, we incorporate a Sampling-then-Moving\nAverage (SMA) technique, interpolating sampled weights from stochastic gradient\ndescent (SGD) training to obtain the moving average weights, ensuring smooth\ntemporal behavior and minimizing training state variances. Overall, our method\nsignificantly reduces training space dimensions and the number of trainable\nparameters without sacrificing model performance, thus accelerating model\nconvergence. We also provide a theoretical analysis on the Noisy quadratic\nmodel, showing that the proposed method achieves a lower training variance than\nstandard SGD. Our approach offers valuable insights for further developing\nefficient training methods for LICs.", "published": "2025-05-23 17:03:13", "link": "http://arxiv.org/abs/2505.18107v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "F-ANcGAN: An Attention-Enhanced Cycle Consistent Generative Adversarial Architecture for Synthetic Image Generation of Nanoparticles", "abstract": "Nanomaterial research is becoming a vital area for energy, medicine, and\nmaterials science, and accurate analysis of the nanoparticle topology is\nessential to determine their properties. Unfortunately, the lack of\nhigh-quality annotated datasets drastically hinders the creation of strong\nsegmentation models for nanoscale imaging. To alleviate this problem, we\nintroduce F-ANcGAN, an attention-enhanced cycle consistent generative\nadversarial system that can be trained using a limited number of data samples\nand generates realistic scanning electron microscopy (SEM) images directly from\nsegmentation maps. Our model uses a Style U-Net generator and a U-Net\nsegmentation network equipped with self-attention to capture structural\nrelationships and applies augmentation methods to increase the variety of the\ndataset. The architecture reached a raw FID score of 17.65 for TiO$_2$ dataset\ngeneration, with a further reduction in FID score to nearly 10.39 by using\nefficient post-processing techniques. By facilitating scalable high-fidelity\nsynthetic dataset generation, our approach can improve the effectiveness of\ndownstream segmentation task training, overcoming severe data shortage issues\nin nanoparticle analysis, thus extending its applications to resource-limited\nfields.", "published": "2025-05-23 17:02:22", "link": "http://arxiv.org/abs/2505.18106v1", "categories": ["cs.CV", "cond-mat.mtrl-sci", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Towards more transferable adversarial attack in black-box manner", "abstract": "Adversarial attacks have become a well-explored domain, frequently serving as\nevaluation baselines for model robustness. Among these, black-box attacks based\non transferability have received significant attention due to their practical\napplicability in real-world scenarios. Traditional black-box methods have\ngenerally focused on improving the optimization framework (e.g., utilizing\nmomentum in MI-FGSM) to enhance transferability, rather than examining the\ndependency on surrogate white-box model architectures. Recent state-of-the-art\napproach DiffPGD has demonstrated enhanced transferability by employing\ndiffusion-based adversarial purification models for adaptive attacks. The\ninductive bias of diffusion-based adversarial purification aligns naturally\nwith the adversarial attack process, where both involving noise addition,\nreducing dependency on surrogate white-box model selection. However, the\ndenoising process of diffusion models incurs substantial computational costs\nthrough chain rule derivation, manifested in excessive VRAM consumption and\nextended runtime. This progression prompts us to question whether introducing\ndiffusion models is necessary. We hypothesize that a model sharing similar\ninductive bias to diffusion-based adversarial purification, combined with an\nappropriate loss function, could achieve comparable or superior transferability\nwhile dramatically reducing computational overhead. In this paper, we propose a\nnovel loss function coupled with a unique surrogate model to validate our\nhypothesis. Our approach leverages the score of the time-dependent classifier\nfrom classifier-guided diffusion models, effectively incorporating natural data\ndistribution knowledge into the adversarial optimization process. Experimental\nresults demonstrate significantly improved transferability across diverse model\narchitectures while maintaining robustness against diffusion-based defenses.", "published": "2025-05-23 16:49:20", "link": "http://arxiv.org/abs/2505.18097v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations", "abstract": "In face-to-face conversations, individuals need to switch between speaking\nand listening roles seamlessly. Existing 3D talking head generation models\nfocus solely on speaking or listening, neglecting the natural dynamics of\ninteractive conversation, which leads to unnatural interactions and awkward\ntransitions. To address this issue, we propose a new task -- multi-round\ndual-speaker interaction for 3D talking head generation -- which requires\nmodels to handle and generate both speaking and listening behaviors in\ncontinuous conversation. To solve this task, we introduce DualTalk, a novel\nunified framework that integrates the dynamic behaviors of speakers and\nlisteners to simulate realistic and coherent dialogue interactions. This\nframework not only synthesizes lifelike talking heads when speaking but also\ngenerates continuous and vivid non-verbal feedback when listening, effectively\ncapturing the interplay between the roles. We also create a new dataset\nfeaturing 50 hours of multi-round conversations with over 1,000 characters,\nwhere participants continuously switch between speaking and listening roles.\nExtensive experiments demonstrate that our method significantly enhances the\nnaturalness and expressiveness of 3D talking heads in dual-speaker\nconversations. We recommend watching the supplementary video:\nhttps://ziqiaopeng.github.io/dualtalk.", "published": "2025-05-23 16:49:05", "link": "http://arxiv.org/abs/2505.18096v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "DanceTogether! Identity-Preserving Multi-Person Interactive Video Generation", "abstract": "Controllable video generation (CVG) has advanced rapidly, yet current systems\nfalter when more than one actor must move, interact, and exchange positions\nunder noisy control signals. We address this gap with DanceTogether, the first\nend-to-end diffusion framework that turns a single reference image plus\nindependent pose-mask streams into long, photorealistic videos while strictly\npreserving every identity. A novel MaskPoseAdapter binds \"who\" and \"how\" at\nevery denoising step by fusing robust tracking masks with semantically rich-but\nnoisy-pose heat-maps, eliminating the identity drift and appearance bleeding\nthat plague frame-wise pipelines. To train and evaluate at scale, we introduce\n(i) PairFS-4K, 26 hours of dual-skater footage with 7,000+ distinct IDs, (ii)\nHumanRob-300, a one-hour humanoid-robot interaction set for rapid cross-domain\ntransfer, and (iii) TogetherVideoBench, a three-track benchmark centered on the\nDanceTogEval-100 test suite covering dance, boxing, wrestling, yoga, and figure\nskating. On TogetherVideoBench, DanceTogether outperforms the prior arts by a\nsignificant margin. Moreover, we show that a one-hour fine-tune yields\nconvincing human-robot videos, underscoring broad generalization to embodied-AI\nand HRI tasks. Extensive ablations confirm that persistent identity-action\nbinding is critical to these gains. Together, our model, datasets, and\nbenchmark lift CVG from single-subject choreography to compositionally\ncontrollable, multi-actor interaction, opening new avenues for digital\nproduction, simulation, and embodied intelligence. Our video demos and code are\navailable at https://DanceTog.github.io/.", "published": "2025-05-23 16:37:14", "link": "http://arxiv.org/abs/2505.18078v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic Correspondence: Unified Benchmarking and a Strong Baseline", "abstract": "Establishing semantic correspondence is a challenging task in computer\nvision, aiming to match keypoints with the same semantic information across\ndifferent images. Benefiting from the rapid development of deep learning,\nremarkable progress has been made over the past decade. However, a\ncomprehensive review and analysis of this task remains absent. In this paper,\nwe present the first extensive survey of semantic correspondence methods. We\nfirst propose a taxonomy to classify existing methods based on the type of\ntheir method designs. These methods are then categorized accordingly, and we\nprovide a detailed analysis of each approach. Furthermore, we aggregate and\nsummarize the results of methods in literature across various benchmarks into a\nunified comparative table, with detailed configurations to highlight\nperformance variations. Additionally, to provide a detailed understanding on\nexisting methods for semantic matching, we thoroughly conduct controlled\nexperiments to analyse the effectiveness of the components of different\nmethods. Finally, we propose a simple yet effective baseline that achieves\nstate-of-the-art performance on multiple benchmarks, providing a solid\nfoundation for future research in this field. We hope this survey serves as a\ncomprehensive reference and consolidated baseline for future development. Code\nis publicly available at: https://github.com/Visual-AI/Semantic-Correspondence.", "published": "2025-05-23 16:07:16", "link": "http://arxiv.org/abs/2505.18060v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Foundation Model Framework for Multi-View MRI Classification of Extramural Vascular Invasion and Mesorectal Fascia Invasion in Rectal Cancer", "abstract": "Background: Accurate MRI-based identification of extramural vascular invasion\n(EVI) and mesorectal fascia invasion (MFI) is pivotal for risk-stratified\nmanagement of rectal cancer, yet visual assessment is subjective and vulnerable\nto inter-institutional variability. Purpose: To develop and externally evaluate\na multicenter, foundation-model-driven framework that automatically classifies\nEVI and MFI on axial and sagittal T2-weighted MRI. Methods: This retrospective\nstudy used 331 pre-treatment rectal cancer MRI examinations from three European\nhospitals. After TotalSegmentator-guided rectal patch extraction, a\nself-supervised frequency-domain harmonization pipeline was trained to minimize\nscanner-related contrast shifts. Four classifiers were compared: ResNet50,\nSeResNet, the universal biomedical pretrained transformer (UMedPT) with a\nlightweight MLP head, and a logistic-regression variant using frozen UMedPT\nfeatures (UMedPT_LR). Results: UMedPT_LR achieved the best EVI detection when\naxial and sagittal features were fused (AUC = 0.82; sensitivity = 0.75; F1\nscore = 0.73), surpassing the Chaimeleon Grand-Challenge winner (AUC = 0.74).\nThe highest MFI performance was attained by UMedPT on axial harmonized images\n(AUC = 0.77), surpassing the Chaimeleon Grand-Challenge winner (AUC = 0.75).\nFrequency-domain harmonization improved MFI classification but variably\naffected EVI performance. Conventional CNNs (ResNet50, SeResNet)\nunderperformed, especially in F1 score and balanced accuracy. Conclusion: These\nfindings demonstrate that combining foundation model features, harmonization,\nand multi-view fusion significantly enhances diagnostic performance in rectal\nMRI.", "published": "2025-05-23 16:04:27", "link": "http://arxiv.org/abs/2505.18058v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "BOTM: Echocardiography Segmentation via Bi-directional Optimal Token Matching", "abstract": "Existed echocardiography segmentation methods often suffer from anatomical\ninconsistency challenge caused by shape variation, partial observation and\nregion ambiguity with similar intensity across 2D echocardiographic sequences,\nresulting in false positive segmentation with anatomical defeated structures in\nchallenging low signal-to-noise ratio conditions. To provide a strong\nanatomical guarantee across different echocardiographic frames, we propose a\nnovel segmentation framework named BOTM (Bi-directional Optimal Token Matching)\nthat performs echocardiography segmentation and optimal anatomy transportation\nsimultaneously. Given paired echocardiographic images, BOTM learns to match two\nsets of discrete image tokens by finding optimal correspondences from a novel\nanatomical transportation perspective. We further extend the token matching\ninto a bi-directional cross-transport attention proxy to regulate the preserved\nanatomical consistency within the cardiac cyclic deformation in temporal\ndomain. Extensive experimental results show that BOTM can generate stable and\naccurate segmentation outcomes (e.g. -1.917 HD on CAMUS2H LV, +1.9% Dice on\nTED), and provide a better matching interpretation with anatomical consistency\nguarantee.", "published": "2025-05-23 15:56:37", "link": "http://arxiv.org/abs/2505.18052v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LookWhere? Efficient Visual Recognition by Learning Where to Look and What to See from Self-Supervision", "abstract": "Vision transformers are ever larger, more accurate, and more expensive to\ncompute. The expense is even more extreme at high resolution as the number of\ntokens grows quadratically with the image size. We turn to adaptive computation\nto cope with this cost by learning to predict where to compute. Our LookWhere\nmethod divides the computation between a low-resolution selector and a\nhigh-resolution extractor without ever processing the full high-resolution\ninput. We jointly pretrain the selector and extractor without task supervision\nby distillation from a self-supervised teacher, in effect, learning where and\nwhat to compute simultaneously. Unlike prior token reduction methods, which pay\nto save by pruning already-computed tokens, and prior token selection methods,\nwhich require complex and expensive per-task optimization, LookWhere\neconomically and accurately selects and extracts transferrable representations\nof images. We show that LookWhere excels at sparse recognition on\nhigh-resolution inputs (Traffic Signs), maintaining accuracy while reducing\nFLOPs by up to 34x and time by 6x. It also excels at standard recognition tasks\nthat are global (ImageNet classification) or local (ADE20K segmentation),\nimproving accuracy while reducing time by 1.36x.", "published": "2025-05-23 15:56:35", "link": "http://arxiv.org/abs/2505.18051v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpikeGen: Generative Framework for Visual Spike Stream Processing", "abstract": "Neuromorphic Visual Systems, such as spike cameras, have attracted\nconsiderable attention due to their ability to capture clear textures under\ndynamic conditions. This capability effectively mitigates issues related to\nmotion and aperture blur. However, in contrast to conventional RGB modalities\nthat provide dense spatial information, these systems generate binary,\nspatially sparse frames as a trade-off for temporally rich visual streams. In\nthis context, generative models emerge as a promising solution to address the\ninherent limitations of sparse data. These models not only facilitate the\nconditional fusion of existing information from both spike and RGB modalities\nbut also enable the conditional generation based on latent priors. In this\nstudy, we introduce a robust generative processing framework named SpikeGen,\ndesigned for visual spike streams captured by spike cameras. We evaluate this\nframework across multiple tasks involving mixed spike-RGB modalities, including\nconditional image/video deblurring, dense frame reconstruction from spike\nstreams, and high-speed scene novel-view synthesis. Supported by comprehensive\nexperimental results, we demonstrate that leveraging the latent space operation\nabilities of generative models allows us to effectively address the sparsity of\nspatial information while fully exploiting the temporal richness of spike\nstreams, thereby promoting a synergistic enhancement of different visual\nmodalities.", "published": "2025-05-23 15:54:11", "link": "http://arxiv.org/abs/2505.18049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SHARDeg: A Benchmark for Skeletal Human Action Recognition in Degraded Scenarios", "abstract": "Computer vision (CV) models for detection, prediction or classification tasks\noperate on video data-streams that are often degraded in the real world, due to\ndeployment in real-time or on resource-constrained hardware. It is therefore\ncritical that these models are robust to degraded data, but state of the art\n(SoTA) models are often insufficiently assessed with these real-world\nconstraints in mind. This is exemplified by Skeletal Human Action Recognition\n(SHAR), which is critical in many CV pipelines operating in real-time and at\nthe edge, but robustness to degraded data has previously only been shallowly\nand inconsistently assessed. Here we address this issue for SHAR by providing\nan important first data degradation benchmark on the most detailed and largest\n3D open dataset, NTU-RGB+D-120, and assess the robustness of five leading SHAR\nmodels to three forms of degradation that represent real-world issues. We\ndemonstrate the need for this benchmark by showing that the form of\ndegradation, which has not previously been considered, has a large impact on\nmodel accuracy; at the same effective frame rate, model accuracy can vary by\n>40% depending on degradation type. We also identify that temporal regularity\nof frames in degraded SHAR data is likely a major driver of differences in\nmodel performance, and harness this to improve performance of existing models\nby up to >40%, through employing a simple mitigation approach based on\ninterpolation. Finally, we highlight how our benchmark has helped identify an\nimportant degradation-resistant SHAR model based in Rough Path Theory; the\nLogSigRNN SHAR model outperforms the SoTA DeGCN model in five out of six cases\nat low frame rates by an average accuracy of 6%, despite trailing the SoTA\nmodel by 11-12% on un-degraded data at high frame rates (30 FPS).", "published": "2025-05-23 15:52:31", "link": "http://arxiv.org/abs/2505.18048v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation", "abstract": "Foundation models like CLIP (Contrastive Language-Image Pretraining) have\nrevolutionized vision-language tasks by enabling zero-shot and few-shot\nlearning through cross-modal alignment. However, their computational complexity\nand large memory footprint make them unsuitable for deployment on\nresource-constrained edge devices, such as in-car cameras used for image\ncollection and real-time processing. To address this challenge, we propose\nClip4Retrofit, an efficient model distillation framework that enables real-time\nimage labeling on edge devices. The framework is deployed on the Retrofit\ncamera, a cost-effective edge device retrofitted into thousands of vehicles,\ndespite strict limitations on compute performance and memory. Our approach\ndistills the knowledge of the CLIP model into a lightweight student model,\ncombining EfficientNet-B3 with multi-layer perceptron (MLP) projection heads to\npreserve cross-modal alignment while significantly reducing computational\nrequirements. We demonstrate that our distilled model achieves a balance\nbetween efficiency and performance, making it ideal for deployment in\nreal-world scenarios. Experimental results show that Clip4Retrofit can perform\nreal-time image labeling and object identification on edge devices with limited\nresources, offering a practical solution for applications such as autonomous\ndriving and retrofitting existing systems. This work bridges the gap between\nstate-of-the-art vision-language models and their deployment in\nresource-constrained environments, paving the way for broader adoption of\nfoundation models in edge computing.", "published": "2025-05-23 15:42:52", "link": "http://arxiv.org/abs/2505.18039v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CAMME: Adaptive Deepfake Image Detection with Multi-Modal Cross-Attention", "abstract": "The proliferation of sophisticated AI-generated deepfakes poses critical\nchallenges for digital media authentication and societal security. While\nexisting detection methods perform well within specific generative domains,\nthey exhibit significant performance degradation when applied to manipulations\nproduced by unseen architectures--a fundamental limitation as generative\ntechnologies rapidly evolve. We propose CAMME (Cross-Attention Multi-Modal\nEmbeddings), a framework that dynamically integrates visual, textual, and\nfrequency-domain features through a multi-head cross-attention mechanism to\nestablish robust cross-domain generalization. Extensive experiments demonstrate\nCAMME's superiority over state-of-the-art methods, yielding improvements of\n12.56% on natural scenes and 13.25% on facial deepfakes. The framework\ndemonstrates exceptional resilience, maintaining (over 91%) accuracy under\nnatural image perturbations and achieving 89.01% and 96.14% accuracy against\nPGD and FGSM adversarial attacks, respectively. Our findings validate that\nintegrating complementary modalities through cross-attention enables more\neffective decision boundary realignment for reliable deepfake detection across\nheterogeneous generative architectures.", "published": "2025-05-23 15:39:07", "link": "http://arxiv.org/abs/2505.18035v1", "categories": ["cs.CV", "F.2.2; I.2.7"], "primary_category": "cs.CV"}
{"title": "Mahalanobis++: Improving OOD Detection via Feature Normalization", "abstract": "Detecting out-of-distribution (OOD) examples is an important task for\ndeploying reliable machine learning models in safety-critial applications.\nWhile post-hoc methods based on the Mahalanobis distance applied to pre-logit\nfeatures are among the most effective for ImageNet-scale OOD detection, their\nperformance varies significantly across models. We connect this inconsistency\nto strong variations in feature norms, indicating severe violations of the\nGaussian assumption underlying the Mahalanobis distance estimation. We show\nthat simple $\\ell_2$-normalization of the features mitigates this problem\neffectively, aligning better with the premise of normally distributed data with\nshared covariance matrix. Extensive experiments on 44 models across diverse\narchitectures and pretraining schemes show that $\\ell_2$-normalization improves\nthe conventional Mahalanobis distance-based approaches significantly and\nconsistently, and outperforms other recently proposed OOD detection methods.", "published": "2025-05-23 15:36:22", "link": "http://arxiv.org/abs/2505.18032v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "3D Face Reconstruction Error Decomposed: A Modular Benchmark for Fair and Fast Method Evaluation", "abstract": "Computing the standard benchmark metric for 3D face reconstruction, namely\ngeometric error, requires a number of steps, such as mesh cropping, rigid\nalignment, or point correspondence. Current benchmark tools are monolithic\n(they implement a specific combination of these steps), even though there is no\nconsensus on the best way to measure error. We present a toolkit for a\nModularized 3D Face reconstruction Benchmark (M3DFB), where the fundamental\ncomponents of error computation are segregated and interchangeable, allowing\none to quantify the effect of each. Furthermore, we propose a new component,\nnamely correction, and present a computationally efficient approach that\npenalizes for mesh topology inconsistency. Using this toolkit, we test 16 error\nestimators with 10 reconstruction methods on two real and two synthetic\ndatasets. Critically, the widely used ICP-based estimator provides the worst\nbenchmarking performance, as it significantly alters the true ranking of the\ntop-5 reconstruction methods. Notably, the correlation of ICP with the true\nerror can be as low as 0.41. Moreover, non-rigid alignment leads to significant\nimprovement (correlation larger than 0.90), highlighting the importance of\nannotating 3D landmarks on datasets. Finally, the proposed correction scheme,\ntogether with non-rigid warping, leads to an accuracy on a par with the best\nnon-rigid ICP-based estimators, but runs an order of magnitude faster. Our\nopen-source codebase is designed for researchers to easily compare alternatives\nfor each component, thus helping accelerating progress in benchmarking for 3D\nface reconstruction and, furthermore, supporting the improvement of learned\nreconstruction methods, which depend on accurate error estimation for effective\ntraining.", "published": "2025-05-23 15:28:43", "link": "http://arxiv.org/abs/2505.18025v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Wavelet-based Stereo Matching Framework for Solving Frequency Convergence Inconsistency", "abstract": "We find that the EPE evaluation metrics of RAFT-stereo converge\ninconsistently in the low and high frequency regions, resulting high frequency\ndegradation (e.g., edges and thin objects) during the iterative process. The\nunderlying reason for the limited performance of current iterative methods is\nthat it optimizes all frequency components together without distinguishing\nbetween high and low frequencies. We propose a wavelet-based stereo matching\nframework (Wavelet-Stereo) for solving frequency convergence inconsistency.\nSpecifically, we first explicitly decompose an image into high and low\nfrequency components using discrete wavelet transform. Then, the high-frequency\nand low-frequency components are fed into two different multi-scale frequency\nfeature extractors. Finally, we propose a novel LSTM-based high-frequency\npreservation update operator containing an iterative frequency adapter to\nprovide adaptive refined high-frequency features at different iteration steps\nby fine-tuning the initial high-frequency features. By processing high and low\nfrequency components separately, our framework can simultaneously refine\nhigh-frequency information in edges and low-frequency information in smooth\nregions, which is especially suitable for challenging scenes with fine details\nand textures in the distance. Extensive experiments demonstrate that our\nWavelet-Stereo outperforms the state-of-the-art methods and ranks 1st on both\nthe KITTI 2015 and KITTI 2012 leaderboards for almost all metrics. We will\nprovide code and pre-trained models to encourage further exploration,\napplication, and development of our innovative framework\n(https://github.com/SIA-IDE/Wavelet-Stereo).", "published": "2025-05-23 15:28:03", "link": "http://arxiv.org/abs/2505.18024v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RemoteSAM: Towards Segment Anything for Earth Observation", "abstract": "We aim to develop a robust yet flexible visual foundation model for Earth\nobservation. It should possess strong capabilities in recognizing and\nlocalizing diverse visual targets while providing compatibility with various\ninput-output interfaces required across different task scenarios. Current\nsystems cannot meet these requirements, as they typically utilize task-specific\narchitecture trained on narrow data domains with limited semantic coverage. Our\nstudy addresses these limitations from two aspects: data and modeling. We first\nintroduce an automatic data engine that enjoys significantly better scalability\ncompared to previous human annotation or rule-based approaches. It has enabled\nus to create the largest dataset of its kind to date, comprising 270K\nimage-text-mask triplets covering an unprecedented range of diverse semantic\ncategories and attribute specifications. Based on this data foundation, we\nfurther propose a task unification paradigm that centers around referring\nexpression segmentation. It effectively handles a wide range of vision-centric\nperception tasks, including classification, detection, segmentation, grounding,\netc, using a single model without any task-specific heads. Combining these\ninnovations on data and modeling, we present RemoteSAM, a foundation model that\nestablishes new SoTA on several earth observation perception benchmarks,\noutperforming other foundation models such as Falcon, GeoChat, and LHRS-Bot\nwith significantly higher efficiency. Models and data are publicly available at\nhttps://github.com/1e12Leon/RemoteSAM.", "published": "2025-05-23 15:27:57", "link": "http://arxiv.org/abs/2505.18022v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Building Floor Number Estimation from Crowdsourced Street-Level Images: Munich Dataset and Baseline Method", "abstract": "Accurate information on the number of building floors, or above-ground\nstoreys, is essential for household estimation, utility provision, risk\nassessment, evacuation planning, and energy modeling. Yet large-scale\nfloor-count data are rarely available in cadastral and 3D city databases. This\nstudy proposes an end-to-end deep learning framework that infers floor numbers\ndirectly from unrestricted, crowdsourced street-level imagery, avoiding\nhand-crafted features and generalizing across diverse facade styles. To enable\nbenchmarking, we release the Munich Building Floor Dataset, a public set of\nover 6800 geo-tagged images collected from Mapillary and targeted field\nphotography, each paired with a verified storey label. On this dataset, the\nproposed classification-regression network attains 81.2% exact accuracy and\npredicts 97.9% of buildings within +/-1 floor. The method and dataset together\noffer a scalable route to enrich 3D city models with vertical information and\nlay a foundation for future work in urban informatics, remote sensing, and\ngeographic information science. Source code and data will be released under an\nopen license at https://github.com/ya0-sun/Munich-SVI-Floor-Benchmark.", "published": "2025-05-23 15:27:46", "link": "http://arxiv.org/abs/2505.18021v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SemSegBench & DetecBench: Benchmarking Reliability and Generalization Beyond Classification", "abstract": "Reliability and generalization in deep learning are predominantly studied in\nthe context of image classification. Yet, real-world applications in\nsafety-critical domains involve a broader set of semantic tasks, such as\nsemantic segmentation and object detection, which come with a diverse set of\ndedicated model architectures. To facilitate research towards robust model\ndesign in segmentation and detection, our primary objective is to provide\nbenchmarking tools regarding robustness to distribution shifts and adversarial\nmanipulations. We propose the benchmarking tools SEMSEGBENCH and DETECBENCH,\nalong with the most extensive evaluation to date on the reliability and\ngeneralization of semantic segmentation and object detection models. In\nparticular, we benchmark 76 segmentation models across four datasets and 61\nobject detectors across two datasets, evaluating their performance under\ndiverse adversarial attacks and common corruptions. Our findings reveal\nsystematic weaknesses in state-of-the-art models and uncover key trends based\non architecture, backbone, and model capacity. SEMSEGBENCH and DETECBENCH are\nopen-sourced in our GitHub repository\n(https://github.com/shashankskagnihotri/benchmarking_reliability_generalization)\nalong with our complete set of total 6139 evaluations. We anticipate the\ncollected data to foster and encourage future research towards improved model\nreliability beyond classification.", "published": "2025-05-23 15:17:45", "link": "http://arxiv.org/abs/2505.18015v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Clinical Validation of Deep Learning for Real-Time Tissue Oxygenation Estimation Using Spectral Imaging", "abstract": "Accurate, real-time monitoring of tissue ischemia is crucial to understand\ntissue health and guide surgery. Spectral imaging shows great potential for\ncontactless and intraoperative monitoring of tissue oxygenation. Due to the\ndifficulty of obtaining direct reference oxygenation values, conventional\nmethods are based on linear unmixing techniques. These are prone to assumptions\nand these linear relations may not always hold in practice. In this work, we\npresent deep learning approaches for real-time tissue oxygenation estimation\nusing Monte-Carlo simulated spectra. We train a fully connected neural network\n(FCN) and a convolutional neural network (CNN) for this task and propose a\ndomain-adversarial training approach to bridge the gap between simulated and\nreal clinical spectral data. Results demonstrate that these deep learning\nmodels achieve a higher correlation with capillary lactate measurements, a\nwell-known marker of hypoxia, obtained during spectral imaging in surgery,\ncompared to traditional linear unmixing. Notably, domain-adversarial training\neffectively reduces the domain gap, optimizing performance in real clinical\nsettings.", "published": "2025-05-23 15:14:27", "link": "http://arxiv.org/abs/2505.18010v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segment Anyword: Mask Prompt Inversion for Open-Set Grounded Segmentation", "abstract": "Open-set image segmentation poses a significant challenge because existing\nmethods often demand extensive training or fine-tuning and generally struggle\nto segment unified objects consistently across diverse text reference\nexpressions. Motivated by this, we propose Segment Anyword, a novel\ntraining-free visual concept prompt learning approach for open-set language\ngrounded segmentation that relies on token-level cross-attention maps from a\nfrozen diffusion model to produce segmentation surrogates or mask prompts,\nwhich are then refined into targeted object masks. Initial prompts typically\nlack coherence and consistency as the complexity of the image-text increases,\nresulting in suboptimal mask fragments. To tackle this issue, we further\nintroduce a novel linguistic-guided visual prompt regularization that binds and\nclusters visual prompts based on sentence dependency and syntactic structural\ninformation, enabling the extraction of robust, noise-tolerant mask prompts,\nand significant improvements in segmentation accuracy. The proposed approach is\neffective, generalizes across different open-set segmentation tasks, and\nachieves state-of-the-art results of 52.5 (+6.8 relative) mIoU on Pascal\nContext 59, 67.73 (+25.73 relative) cIoU on gRefCOCO, and 67.4 (+1.1 relative\nto fine-tuned methods) mIoU on GranDf, which is the most complex open-set\ngrounded segmentation task in the field.", "published": "2025-05-23 14:59:44", "link": "http://arxiv.org/abs/2505.17994v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Canonical Pose Reconstruction from Single Depth Image for 3D Non-rigid Pose Recovery on Limited Datasets", "abstract": "3D reconstruction from 2D inputs, especially for non-rigid objects like\nhumans, presents unique challenges due to the significant range of possible\ndeformations. Traditional methods often struggle with non-rigid shapes, which\nrequire extensive training data to cover the entire deformation space. This\nstudy addresses these limitations by proposing a canonical pose reconstruction\nmodel that transforms single-view depth images of deformable shapes into a\ncanonical form. This alignment facilitates shape reconstruction by enabling the\napplication of rigid object reconstruction techniques, and supports recovering\nthe input pose in voxel representation as part of the reconstruction task,\nutilizing both the original and deformed depth images. Notably, our model\nachieves effective results with only a small dataset of approximately 300\nsamples. Experimental results on animal and human datasets demonstrate that our\nmodel outperforms other state-of-the-art methods.", "published": "2025-05-23 14:58:34", "link": "http://arxiv.org/abs/2505.17992v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling", "abstract": "Vision-language models (VLMs) have recently been integrated into multiple\ninstance learning (MIL) frameworks to address the challenge of few-shot, weakly\nsupervised classification of whole slide images (WSIs). A key trend involves\nleveraging multi-scale information to better represent hierarchical tissue\nstructures. However, existing methods often face two key limitations: (1)\ninsufficient modeling of interactions within the same modalities across scales\n(e.g., 5x and 20x) and (2) inadequate alignment between visual and textual\nmodalities on the same scale. To address these gaps, we propose HiVE-MIL, a\nhierarchical vision-language framework that constructs a unified graph\nconsisting of (1) parent-child links between coarse (5x) and fine (20x)\nvisual/textual nodes to capture hierarchical relationships, and (2)\nheterogeneous intra-scale edges linking visual and textual nodes on the same\nscale. To further enhance semantic consistency, HiVE-MIL incorporates a\ntwo-stage, text-guided dynamic filtering mechanism that removes weakly\ncorrelated patch-text pairs, and introduces a hierarchical contrastive loss to\nalign textual semantics across scales. Extensive experiments on TCGA breast,\nlung, and kidney cancer datasets demonstrate that HiVE-MIL consistently\noutperforms both traditional MIL and recent VLM-based MIL approaches, achieving\ngains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate\nthe value of jointly modeling hierarchical structure and multimodal alignment\nfor efficient and scalable learning from limited pathology data. The code is\navailable at https://github.com/bryanwong17/HiVE-MIL", "published": "2025-05-23 14:48:32", "link": "http://arxiv.org/abs/2505.17982v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "To Glue or Not to Glue? Classical vs Learned Image Matching for Mobile Mapping Cameras to Textured Semantic 3D Building Models", "abstract": "Feature matching is a necessary step for many computer vision and\nphotogrammetry applications such as image registration, structure-from-motion,\nand visual localization. Classical handcrafted methods such as SIFT feature\ndetection and description combined with nearest neighbour matching and RANSAC\noutlier removal have been state-of-the-art for mobile mapping cameras. With\nrecent advances in deep learning, learnable methods have been introduced and\nproven to have better robustness and performance under complex conditions.\nDespite their growing adoption, a comprehensive comparison between classical\nand learnable feature matching methods for the specific task of semantic 3D\nbuilding camera-to-model matching is still missing. This submission\nsystematically evaluates the effectiveness of different feature-matching\ntechniques in visual localization using textured CityGML LoD2 models. We use\nstandard benchmark datasets (HPatches, MegaDepth-1500) and custom datasets\nconsisting of facade textures and corresponding camera images (terrestrial and\ndrone). For the latter, we evaluate the achievable accuracy of the absolute\npose estimated using a Perspective-n-Point (PnP) algorithm, with geometric\nground truth derived from geo-referenced trajectory data. The results indicate\nthat the learnable feature matching methods vastly outperform traditional\napproaches regarding accuracy and robustness on our challenging custom datasets\nwith zero to 12 RANSAC-inliers and zero to 0.16 area under the curve. We\nbelieve that this work will foster the development of model-based visual\nlocalization methods. Link to the code:\nhttps://github.com/simBauer/To\\_Glue\\_or\\_not\\_to\\_Glue", "published": "2025-05-23 14:41:41", "link": "http://arxiv.org/abs/2505.17973v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MR-EEGWaveNet: Multiresolutional EEGWaveNet for Seizure Detection from Long EEG Recordings", "abstract": "Feature engineering for generalized seizure detection models remains a\nsignificant challenge. Recently proposed models show variable performance\ndepending on the training data and remain ineffective at accurately\ndistinguishing artifacts from seizure data. In this study, we propose a novel\nend-to-end model, ''Multiresolutional EEGWaveNet (MR-EEGWaveNet),'' which\nefficiently distinguishes seizure events from background electroencephalogram\n(EEG) and artifacts/noise by capturing both temporal dependencies across\ndifferent time frames and spatial relationships between channels. The model has\nthree modules: convolution, feature extraction, and predictor. The convolution\nmodule extracts features through depth-wise and spatio-temporal convolution.\nThe feature extraction module individually reduces the feature dimension\nextracted from EEG segments and their sub-segments. Subsequently, the extracted\nfeatures are concatenated into a single vector for classification using a fully\nconnected classifier called the predictor module. In addition, an anomaly\nscore-based post-classification processing technique was introduced to reduce\nthe false-positive rates of the model. Experimental results were reported and\nanalyzed using different parameter settings and datasets (Siena (public) and\nJuntendo (private)). The proposed MR-EEGWaveNet significantly outperformed the\nconventional non-multiresolution approach, improving the F1 scores from 0.177\nto 0.336 on Siena and 0.327 to 0.488 on Juntendo, with precision gains of 15.9%\nand 20.62%, respectively.", "published": "2025-05-23 14:40:50", "link": "http://arxiv.org/abs/2505.17972v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Explainable Anatomy-Guided AI for Prostate MRI: Foundation Models and In Silico Clinical Trials for Virtual Biopsy-based Risk Assessment", "abstract": "We present a fully automated, anatomically guided deep learning pipeline for\nprostate cancer (PCa) risk stratification using routine MRI. The pipeline\nintegrates three key components: an nnU-Net module for segmenting the prostate\ngland and its zones on axial T2-weighted MRI; a classification module based on\nthe UMedPT Swin Transformer foundation model, fine-tuned on 3D patches with\noptional anatomical priors and clinical data; and a VAE-GAN framework for\ngenerating counterfactual heatmaps that localize decision-driving image\nregions. The system was developed using 1,500 PI-CAI cases for segmentation and\n617 biparametric MRIs with metadata from the CHAIMELEON challenge for\nclassification (split into 70% training, 10% validation, and 20% testing).\nSegmentation achieved mean Dice scores of 0.95 (gland), 0.94 (peripheral zone),\nand 0.92 (transition zone). Incorporating gland priors improved AUC from 0.69\nto 0.72, with a three-scale ensemble achieving top performance (AUC = 0.79,\ncomposite score = 0.76), outperforming the 2024 CHAIMELEON challenge winners.\nCounterfactual heatmaps reliably highlighted lesions within segmented regions,\nenhancing model interpretability. In a prospective multi-center in-silico trial\nwith 20 clinicians, AI assistance increased diagnostic accuracy from 0.72 to\n0.77 and Cohen's kappa from 0.43 to 0.53, while reducing review time per case\nby 40%. These results demonstrate that anatomy-aware foundation models with\ncounterfactual explainability can enable accurate, interpretable, and efficient\nPCa risk assessment, supporting their potential use as virtual biopsies in\nclinical practice.", "published": "2025-05-23 14:40:09", "link": "http://arxiv.org/abs/2505.17971v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Is Single-View Mesh Reconstruction Ready for Robotics?", "abstract": "This paper evaluates single-view mesh reconstruction models for creating\ndigital twin environments in robot manipulation. Recent advances in computer\nvision for 3D reconstruction from single viewpoints present a potential\nbreakthrough for efficiently creating virtual replicas of physical environments\nfor robotics contexts. However, their suitability for physics simulations and\nrobotics applications remains unexplored. We establish benchmarking criteria\nfor 3D reconstruction in robotics contexts, including handling typical inputs,\nproducing collision-free and stable reconstructions, managing occlusions, and\nmeeting computational constraints. Our empirical evaluation using realistic\nrobotics datasets shows that despite success on computer vision benchmarks,\nexisting approaches fail to meet robotics-specific requirements. We\nquantitively examine limitations of single-view reconstruction for practical\nrobotics implementation, in contrast to prior work that focuses on multi-view\napproaches. Our findings highlight critical gaps between computer vision\nadvances and robotics needs, guiding future research at this intersection.", "published": "2025-05-23 14:35:56", "link": "http://arxiv.org/abs/2505.17966v1", "categories": ["cs.RO", "cs.CV", "I.4.5; I.4.8; I.2.9; I.2.10"], "primary_category": "cs.RO"}
{"title": "Mind the Domain Gap: Measuring the Domain Gap Between Real-World and Synthetic Point Clouds for Automated Driving Development", "abstract": "Owing to the typical long-tail data distribution issues, simulating\ndomain-gap-free synthetic data is crucial in robotics, photogrammetry, and\ncomputer vision research. The fundamental challenge pertains to credibly\nmeasuring the difference between real and simulated data. Such a measure is\nvital for safety-critical applications, such as automated driving, where\nout-of-domain samples may impact a car's perception and cause fatal accidents.\nPrevious work has commonly focused on simulating data on one scene and\nanalyzing performance on a different, real-world scene, hampering the disjoint\nanalysis of domain gap coming from networks' deficiencies, class definitions,\nand object representation. In this paper, we propose a novel approach to\nmeasuring the domain gap between the real world sensor observations and\nsimulated data representing the same location, enabling comprehensive domain\ngap analysis. To measure such a domain gap, we introduce a novel metric\nDoGSS-PCL and evaluation assessing the geometric and semantic quality of the\nsimulated point cloud. Our experiments corroborate that the introduced approach\ncan be used to measure the domain gap. The tests also reveal that synthetic\nsemantic point clouds may be used for training deep neural networks,\nmaintaining the performance at the 50/50 real-to-synthetic ratio. We strongly\nbelieve that this work will facilitate research on credible data simulation and\nallow for at-scale deployment in automated driving testing and digital\ntwinning.", "published": "2025-05-23 14:31:36", "link": "http://arxiv.org/abs/2505.17959v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Diffusion Classifiers Understand Compositionality, but Conditions Apply", "abstract": "Understanding visual scenes is fundamental to human intelligence. While\ndiscriminative models have significantly advanced computer vision, they often\nstruggle with compositional understanding. In contrast, recent generative\ntext-to-image diffusion models excel at synthesizing complex scenes, suggesting\ninherent compositional capabilities. Building on this, zero-shot diffusion\nclassifiers have been proposed to repurpose diffusion models for discriminative\ntasks. While prior work offered promising results in discriminative\ncompositional scenarios, these results remain preliminary due to a small number\nof benchmarks and a relatively shallow analysis of conditions under which the\nmodels succeed. To address this, we present a comprehensive study of the\ndiscriminative capabilities of diffusion classifiers on a wide range of\ncompositional tasks. Specifically, our study covers three diffusion models (SD\n1.5, 2.0, and, for the first time, 3-m) spanning 10 datasets and over 30 tasks.\nFurther, we shed light on the role that target dataset domains play in\nrespective performance; to isolate the domain effects, we introduce a new\ndiagnostic benchmark Self-Bench comprised of images created by diffusion models\nthemselves. Finally, we explore the importance of timestep weighting and\nuncover a relationship between domain gap and timestep sensitivity,\nparticularly for SD3-m. To sum up, diffusion classifiers understand\ncompositionality, but conditions apply! Code and dataset are available at\nhttps://github.com/eugene6923/Diffusion-Classifiers-Compositionality.", "published": "2025-05-23 14:29:52", "link": "http://arxiv.org/abs/2505.17955v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SplatCo: Structure-View Collaborative Gaussian Splatting for Detail-Preserving Rendering of Large-Scale Unbounded Scenes", "abstract": "We present SplatCo, a structure-view collaborative Gaussian splatting\nframework for high-fidelity rendering of complex outdoor environments. SplatCo\nbuilds upon two novel components: (1) a cross-structure collaboration module\nthat combines global tri-plane representations, which capture coarse scene\nlayouts, with local context grid features that represent fine surface details.\nThis fusion is achieved through a novel hierarchical compensation strategy,\nensuring both global consistency and local detail preservation; and (2) a\ncross-view assisted training strategy that enhances multi-view consistency by\nsynchronizing gradient updates across viewpoints, applying visibility-aware\ndensification, and pruning overfitted or inaccurate Gaussians based on\nstructural consistency. Through joint optimization of structural representation\nand multi-view coherence, SplatCo effectively reconstructs fine-grained\ngeometric structures and complex textures in large-scale scenes. Comprehensive\nevaluations on 13 diverse large-scale scenes, including Mill19, MatrixCity,\nTanks & Temples, WHU, and custom aerial captures, demonstrate that SplatCo\nconsistently achieves higher reconstruction quality than state-of-the-art\nmethods, with PSNR improvements of 1-2 dB and SSIM gains of 0.1 to 0.2. These\nresults establish a new benchmark for high-fidelity rendering of large-scale\nunbounded scenes. Code and additional information are available at\nhttps://github.com/SCUT-BIP-Lab/SplatCo.", "published": "2025-05-23 14:27:12", "link": "http://arxiv.org/abs/2505.17951v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Promptable cancer segmentation using minimal expert-curated data", "abstract": "Automated segmentation of cancer on medical images can aid targeted\ndiagnostic and therapeutic procedures. However, its adoption is limited by the\nhigh cost of expert annotations required for training and inter-observer\nvariability in datasets. While weakly-supervised methods mitigate some\nchallenges, using binary histology labels for training as opposed to requiring\nfull segmentation, they require large paired datasets of histology and images,\nwhich are difficult to curate. Similarly, promptable segmentation aims to allow\nsegmentation with no re-training for new tasks at inference, however, existing\nmodels perform poorly on pathological regions, again necessitating large\ndatasets for training. In this work we propose a novel approach for promptable\nsegmentation requiring only 24 fully-segmented images, supplemented by 8\nweakly-labelled images, for training. Curating this minimal data to a high\nstandard is relatively feasible and thus issues with the cost and variability\nof obtaining labels can be mitigated. By leveraging two classifiers, one\nweakly-supervised and one fully-supervised, our method refines segmentation\nthrough a guided search process initiated by a single-point prompt. Our\napproach outperforms existing promptable segmentation methods, and performs\ncomparably with fully-supervised methods, for the task of prostate cancer\nsegmentation, while using substantially less annotated data (up to 100X less).\nThis enables promptable segmentation with very minimal labelled data, such that\nthe labels can be curated to a very high standard.", "published": "2025-05-23 13:56:40", "link": "http://arxiv.org/abs/2505.17915v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "UltraBoneUDF: Self-supervised Bone Surface Reconstruction from Ultrasound Based on Neural Unsigned Distance Functions", "abstract": "Background: Bone surface reconstruction plays a critical role in\ncomputer-assisted orthopedic surgery. Compared to traditional imaging\nmodalities such as CT and MRI, ultrasound offers a radiation-free,\ncost-effective, and portable alternative. Continuous bone surface\nreconstruction can be employed for many clinical applications. However, due to\nthe inherent limitations of ultrasound imaging, B-mode ultrasound typically\ncapture only partial bone surfaces. Existing reconstruction methods struggle\nwith such incomplete data, leading to artifacts and increased reconstruction\nerrors. Effective techniques for accurately reconstructing thin and open bone\nsurfaces from real-world 3D ultrasound volumes remain lacking. Methods: We\npropose UltraBoneUDF, a self-supervised framework designed for reconstructing\nopen bone surfaces from ultrasound using neural Unsigned Distance Functions. To\nenhance reconstruction quality, we introduce a novel global feature extractor\nthat effectively fuses ultrasound-specific image characteristics. Additionally,\nwe present a novel loss function based on local tangent plane optimization that\nsubstantially improves surface reconstruction quality. UltraBoneUDF and\nbaseline models are extensively evaluated on four open-source datasets.\nResults: Qualitative results highlight the limitations of the state-of-the-art\nmethods for open bone surface reconstruction and demonstrate the effectiveness\nof UltraBoneUDF. Quantitatively, UltraBoneUDF significantly outperforms\ncompeting methods across all evaluated datasets for both open and closed bone\nsurface reconstruction in terms of mean Chamfer distance error: 1.10 mm on the\nUltraBones100k dataset (39.6\\% improvement compared to the SOTA), 0.23 mm on\nthe OpenBoneCT dataset (69.3\\% improvement), 0.18 mm on the ClosedBoneCT\ndataset (70.2\\% improvement), and 0.05 mm on the Prostate dataset (55.3\\%\nimprovement).", "published": "2025-05-23 13:56:06", "link": "http://arxiv.org/abs/2505.17912v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Semantic segmentation with reward", "abstract": "In real-world scenarios, pixel-level labeling is not always available.\nSometimes, we need a semantic segmentation network, and even a visual encoder\ncan have a high compatibility, and can be trained using various types of\nfeedback beyond traditional labels, such as feedback that indicates the quality\nof the parsing results. To tackle this issue, we proposed RSS (Reward in\nSemantic Segmentation), the first practical application of reward-based\nreinforcement learning on pure semantic segmentation offered in two granular\nlevels (pixel-level and image-level). RSS incorporates various novel\ntechnologies, such as progressive scale rewards (PSR) and pair-wise spatial\ndifference (PSD), to ensure that the reward facilitates the convergence of the\nsemantic segmentation network, especially under image-level rewards.\nExperiments and visualizations on benchmark datasets demonstrate that the\nproposed RSS can successfully ensure the convergence of the semantic\nsegmentation network on two levels of rewards. Additionally, the RSS, which\nutilizes an image-level reward, outperforms existing weakly supervised methods\nthat also rely solely on image-level signals during training.", "published": "2025-05-23 13:52:15", "link": "http://arxiv.org/abs/2505.17905v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pixels to Prognosis: Harmonized Multi-Region CT-Radiomics and Foundation-Model Signatures Across Multicentre NSCLC Data", "abstract": "Purpose: To evaluate the impact of harmonization and multi-region CT image\nfeature integration on survival prediction in non-small cell lung cancer\n(NSCLC) patients, using handcrafted radiomics, pretrained foundation model (FM)\nfeatures, and clinical data from a multicenter dataset.\n  Methods: We analyzed CT scans and clinical data from 876 NSCLC patients (604\ntraining, 272 test) across five centers. Features were extracted from the whole\nlung, tumor, mediastinal nodes, coronary arteries, and coronary artery calcium\n(CAC). Handcrafted radiomics and FM deep features were harmonized using ComBat,\nreconstruction kernel normalization (RKN), and RKN+ComBat. Regularized Cox\nmodels predicted overall survival; performance was assessed using the\nconcordance index (C-index), 5-year time-dependent area under the curve\n(t-AUC), and hazard ratio (HR). SHapley Additive exPlanations (SHAP) values\nexplained feature contributions. A consensus model used agreement across top\nregion of interest (ROI) models to stratify patient risk.\n  Results: TNM staging showed prognostic utility (C-index = 0.67; HR = 2.70;\nt-AUC = 0.85). The clinical + tumor radiomics model with ComBat achieved a\nC-index of 0.7552 and t-AUC of 0.8820. FM features (50-voxel cubes) combined\nwith clinical data yielded the highest performance (C-index = 0.7616; t-AUC =\n0.8866). An ensemble of all ROIs and FM features reached a C-index of 0.7142\nand t-AUC of 0.7885. The consensus model, covering 78% of valid test cases,\nachieved a t-AUC of 0.92, sensitivity of 97.6%, and specificity of 66.7%.\n  Conclusion: Harmonization and multi-region feature integration improve\nsurvival prediction in multicenter NSCLC data. Combining interpretable\nradiomics, FM features, and consensus modeling enables robust risk\nstratification across imaging centers.", "published": "2025-05-23 13:41:52", "link": "http://arxiv.org/abs/2505.17893v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Track Anything Annotate: Video annotation and dataset generation of computer vision models", "abstract": "Modern machine learning methods require significant amounts of labelled data,\nmaking the preparation process time-consuming and resource-intensive. In this\npaper, we propose to consider the process of prototyping a tool for annotating\nand generating training datasets based on video tracking and segmentation. We\nexamine different approaches to solving this problem, from technology selection\nthrough to final implementation. The developed prototype significantly\naccelerates dataset generation compared to manual annotation. All resources are\navailable at https://github.com/lnikioffic/track-anything-annotate", "published": "2025-05-23 13:32:20", "link": "http://arxiv.org/abs/2505.17884v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hyperspectral Anomaly Detection Fused Unified Nonconvex Tensor Ring Factors Regularization", "abstract": "In recent years, tensor decomposition-based approaches for hyperspectral\nanomaly detection (HAD) have gained significant attention in the field of\nremote sensing. However, existing methods often fail to fully leverage both the\nglobal correlations and local smoothness of the background components in\nhyperspectral images (HSIs), which exist in both the spectral and spatial\ndomains. This limitation results in suboptimal detection performance. To\nmitigate this critical issue, we put forward a novel HAD method named\nHAD-EUNTRFR, which incorporates an enhanced unified nonconvex tensor ring (TR)\nfactors regularization. In the HAD-EUNTRFR framework, the raw HSIs are first\ndecomposed into background and anomaly components. The TR decomposition is then\nemployed to capture the spatial-spectral correlations within the background\ncomponent. Additionally, we introduce a unified and efficient nonconvex\nregularizer, induced by tensor singular value decomposition (TSVD), to\nsimultaneously encode the low-rankness and sparsity of the 3-D gradient TR\nfactors into a unique concise form. The above characterization scheme enables\nthe interpretable gradient TR factors to inherit the low-rankness and\nsmoothness of the original background. To further enhance anomaly detection, we\ndesign a generalized nonconvex regularization term to exploit the group\nsparsity of the anomaly component. To solve the resulting doubly nonconvex\nmodel, we develop a highly efficient optimization algorithm based on the\nalternating direction method of multipliers (ADMM) framework. Experimental\nresults on several benchmark datasets demonstrate that our proposed method\noutperforms existing state-of-the-art (SOTA) approaches in terms of detection\naccuracy.", "published": "2025-05-23 13:31:13", "link": "http://arxiv.org/abs/2505.17881v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multi-task Learning For Joint Action and Gesture Recognition", "abstract": "In practical applications, computer vision tasks often need to be addressed\nsimultaneously. Multitask learning typically achieves this by jointly training\na single deep neural network to learn shared representations, providing\nefficiency and improving generalization. Although action and gesture\nrecognition are closely related tasks, since they focus on body and hand\nmovements, current state-of-the-art methods handle them separately. In this\npaper, we show that employing a multi-task learning paradigm for action and\ngesture recognition results in more efficient, robust and generalizable visual\nrepresentations, by leveraging the synergies between these tasks. Extensive\nexperiments on multiple action and gesture datasets demonstrate that handling\nactions and gestures in a single architecture can achieve better performance\nfor both tasks in comparison to their single-task learning variants.", "published": "2025-05-23 13:16:27", "link": "http://arxiv.org/abs/2505.17867v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Person Interaction Generation from Two-Person Motion Priors", "abstract": "Generating realistic human motion with high-level controls is a crucial task\nfor social understanding, robotics, and animation. With high-quality MOCAP data\nbecoming more available recently, a wide range of data-driven approaches have\nbeen presented. However, modelling multi-person interactions still remains a\nless explored area. In this paper, we present Graph-driven Interaction\nSampling, a method that can generate realistic and diverse multi-person\ninteractions by leveraging existing two-person motion diffusion models as\nmotion priors. Instead of training a new model specific to multi-person\ninteraction synthesis, our key insight is to spatially and temporally separate\ncomplex multi-person interactions into a graph structure of two-person\ninteractions, which we name the Pairwise Interaction Graph. We thus decompose\nthe generation task into simultaneous single-person motion generation\nconditioned on one other's motion. In addition, to reduce artifacts such as\ninterpenetrations of body parts in generated multi-person interactions, we\nintroduce two graph-dependent guidance terms into the diffusion sampling\nscheme. Unlike previous work, our method can produce various high-quality\nmulti-person interactions without having repetitive individual motions.\nExtensive experiments demonstrate that our approach consistently outperforms\nexisting methods in reducing artifacts when generating a wide range of\ntwo-person and multi-person interactions.", "published": "2025-05-23 13:13:00", "link": "http://arxiv.org/abs/2505.17860v1", "categories": ["cs.GR", "cs.CV", "cs.LG", "I.3.7"], "primary_category": "cs.GR"}
{"title": "Locality-Sensitive Hashing for Efficient Hard Negative Sampling in Contrastive Learning", "abstract": "Contrastive learning is a representational learning paradigm in which a\nneural network maps data elements to feature vectors. It improves the feature\nspace by forming lots with an anchor and examples that are either positive or\nnegative based on class similarity. Hard negative examples, which are close to\nthe anchor in the feature space but from a different class, improve learning\nperformance. Finding such examples of high quality efficiently in large,\nhigh-dimensional datasets is computationally challenging. In this paper, we\npropose a GPU-friendly Locality-Sensitive Hashing (LSH) scheme that quantizes\nreal-valued feature vectors into binary representations for approximate nearest\nneighbor search. We investigate its theoretical properties and evaluate it on\nseveral datasets from textual and visual domain. Our approach achieves\ncomparable or better performance while requiring significantly less computation\nthan existing hard negative mining strategies.", "published": "2025-05-23 12:58:42", "link": "http://arxiv.org/abs/2505.17844v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VLM Models and Automated Grading of Atopic Dermatitis", "abstract": "The task of grading atopic dermatitis (or AD, a form of eczema) from patient\nimages is difficult even for trained dermatologists. Research on automating\nthis task has progressed in recent years with the development of deep learning\nsolutions; however, the rapid evolution of multimodal models and more\nspecifically vision-language models (VLMs) opens the door to new possibilities\nin terms of explainable assessment of medical images, including dermatology.\nThis report describes experiments carried out to evaluate the ability of seven\nVLMs to assess the severity of AD on a set of test images.", "published": "2025-05-23 12:49:09", "link": "http://arxiv.org/abs/2505.17835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ICPL-ReID: Identity-Conditional Prompt Learning for Multi-Spectral Object Re-Identification", "abstract": "Multi-spectral object re-identification (ReID) brings a new perception\nperspective for smart city and intelligent transportation applications,\neffectively addressing challenges from complex illumination and adverse\nweather. However, complex modal differences between heterogeneous spectra pose\nchallenges to efficiently utilizing complementary and discrepancy of spectra\ninformation. Most existing methods fuse spectral data through intricate modal\ninteraction modules, lacking fine-grained semantic understanding of spectral\ninformation (\\textit{e.g.}, text descriptions, part masks, and object\nkeypoints). To solve this challenge, we propose a novel Identity-Conditional\ntext Prompt Learning framework (ICPL), which exploits the powerful cross-modal\nalignment capability of CLIP, to unify different spectral visual features from\ntext semantics. Specifically, we first propose the online prompt learning using\nlearnable text prompt as the identity-level semantic center to bridge the\nidentity semantics of different spectra in online manner. Then, in lack of\nconcrete text descriptions, we propose the multi-spectral identity-condition\nmodule to use identity prototype as spectral identity condition to constraint\nprompt learning. Meanwhile, we construct the alignment loop mutually optimizing\nthe learnable text prompt and spectral visual encoder to avoid online prompt\nlearning disrupting the pre-trained text-image alignment distribution. In\naddition, to adapt to small-scale multi-spectral data and mitigate style\ndifferences between spectra, we propose multi-spectral adapter that employs a\nlow-rank adaption method to learn spectra-specific features. Comprehensive\nexperiments on 5 benchmarks, including RGBNT201, Market-MM, MSVR310, RGBN300,\nand RGBNT100, demonstrate that the proposed method outperforms the\nstate-of-the-art methods.", "published": "2025-05-23 12:38:27", "link": "http://arxiv.org/abs/2505.17821v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Temporal Consistency Constrained Transferable Adversarial Attacks with Background Mixup for Action Recognition", "abstract": "Action recognition models using deep learning are vulnerable to adversarial\nexamples, which are transferable across other models trained on the same data\nmodality. Existing transferable attack methods face two major challenges: 1)\nthey heavily rely on the assumption that the decision boundaries of the\nsurrogate (a.k.a., source) model and the target model are similar, which limits\nthe adversarial transferability; and 2) their decision boundary difference\nmakes the attack direction uncertain, which may result in the gradient\noscillation, weakening the adversarial attack. This motivates us to propose a\nBackground Mixup-induced Temporal Consistency (BMTC) attack method for action\nrecognition. From the input transformation perspective, we design a\nmodel-agnostic background adversarial mixup module to reduce the\nsurrogate-target model dependency. In particular, we randomly sample one video\nfrom each category and make its background frame, while selecting the\nbackground frame with the top attack ability for mixup with the clean frame by\nreinforcement learning. Moreover, to ensure an explicit attack direction, we\nleverage the background category as guidance for updating the gradient of\nadversarial example, and design a temporal gradient consistency loss, which\nstrengthens the stability of the attack direction on subsequent frames.\nEmpirical studies on two video datasets, i.e., UCF101 and Kinetics-400, and one\nimage dataset, i.e., ImageNet, demonstrate that our method significantly boosts\nthe transferability of adversarial examples across several action/image\nrecognition models. Our code is available at\nhttps://github.com/mlvccn/BMTC_TransferAttackVid.", "published": "2025-05-23 12:24:28", "link": "http://arxiv.org/abs/2505.17807v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Coreset Selection of Coreset Selection Literature: Introduction and Recent Advances", "abstract": "Coreset selection targets the challenge of finding a small, representative\nsubset of a large dataset that preserves essential patterns for effective\nmachine learning. Although several surveys have examined data reduction\nstrategies before, most focus narrowly on either classical geometry-based\nmethods or active learning techniques. In contrast, this survey presents a more\ncomprehensive view by unifying three major lines of coreset research, namely,\ntraining-free, training-oriented, and label-free approaches, into a single\ntaxonomy. We present subfields often overlooked by existing work, including\nsubmodular formulations, bilevel optimization, and recent progress in\npseudo-labeling for unlabeled datasets. Additionally, we examine how pruning\nstrategies influence generalization and neural scaling laws, offering new\ninsights that are absent from prior reviews. Finally, we compare these methods\nunder varying computational, robustness, and performance demands and highlight\nopen challenges, such as robustness, outlier filtering, and adapting coreset\nselection to foundation models, for future research.", "published": "2025-05-23 12:18:34", "link": "http://arxiv.org/abs/2505.17799v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Generative Data Augmentation for Object Point Cloud Segmentation", "abstract": "Data augmentation is widely used to train deep learning models to address\ndata scarcity. However, traditional data augmentation (TDA) typically relies on\nsimple geometric transformation, such as random rotation and rescaling,\nresulting in minimal data diversity enrichment and limited model performance\nimprovement. State-of-the-art generative models for 3D shape generation rely on\nthe denoising diffusion probabilistic models and manage to generate realistic\nnovel point clouds for 3D content creation and manipulation. Nevertheless, the\ngenerated 3D shapes lack associated point-wise semantic labels, restricting\ntheir usage in enlarging the training data for point cloud segmentation tasks.\nTo bridge the gap between data augmentation techniques and the advanced\ndiffusion models, we extend the state-of-the-art 3D diffusion model, Lion, to a\npart-aware generative model that can generate high-quality point clouds\nconditioned on given segmentation masks. Leveraging the novel generative model,\nwe introduce a 3-step generative data augmentation (GDA) pipeline for point\ncloud segmentation training. Our GDA approach requires only a small amount of\nlabeled samples but enriches the training data with generated variants and\npseudo-labeled samples, which are validated by a novel diffusion-based\npseudo-label filtering method. Extensive experiments on two large-scale\nsynthetic datasets and a real-world medical dataset demonstrate that our GDA\nmethod outperforms TDA approach and related semi-supervised and self-supervised\nmethods.", "published": "2025-05-23 11:56:06", "link": "http://arxiv.org/abs/2505.17783v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hephaestus Minicubes: A Global, Multi-Modal Dataset for Volcanic Unrest Monitoring", "abstract": "Ground deformation is regarded in volcanology as a key precursor signal\npreceding volcanic eruptions. Satellite-based Interferometric Synthetic\nAperture Radar (InSAR) enables consistent, global-scale deformation tracking;\nhowever, deep learning methods remain largely unexplored in this domain, mainly\ndue to the lack of a curated machine learning dataset. In this work, we build\non the existing Hephaestus dataset, and introduce Hephaestus Minicubes, a\nglobal collection of 38 spatiotemporal datacubes offering high resolution,\nmulti-source and multi-temporal information, covering 44 of the world's most\nactive volcanoes over a 7-year period. Each spatiotemporal datacube integrates\nInSAR products, topographic data, as well as atmospheric variables which are\nknown to introduce signal delays that can mimic ground deformation in InSAR\nimagery. Furthermore, we provide expert annotations detailing the type,\nintensity and spatial extent of deformation events, along with rich text\ndescriptions of the observed scenes. Finally, we present a comprehensive\nbenchmark, demonstrating Hephaestus Minicubes' ability to support volcanic\nunrest monitoring as a multi-modal, multi-temporal classification and semantic\nsegmentation task, establishing strong baselines with state-of-the-art\narchitectures. This work aims to advance machine learning research in volcanic\nmonitoring, contributing to the growing integration of data-driven methods\nwithin Earth science applications.", "published": "2025-05-23 11:55:41", "link": "http://arxiv.org/abs/2505.17782v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding", "abstract": "Ultrasound is a widely-used imaging modality critical to global healthcare,\nyet its interpretation remains challenging due to its varying image quality on\noperators, noises, and anatomical structures. Although large vision-language\nmodels (LVLMs) have demonstrated impressive multimodal capabilities across\nnatural and medical domains, their performance on ultrasound remains largely\nunexplored. We introduce U2-BENCH, the first comprehensive benchmark to\nevaluate LVLMs on ultrasound understanding across classification, detection,\nregression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning\n15 anatomical regions and defines 8 clinically inspired tasks, such as\ndiagnosis, view recognition, lesion localization, clinical value estimation,\nand report generation, across 50 ultrasound application scenarios. We evaluate\n20 state-of-the-art LVLMs, both open- and closed-source, general-purpose and\nmedical-specific. Our results reveal strong performance on image-level\nclassification, but persistent challenges in spatial reasoning and clinical\nlanguage generation. U2-BENCH establishes a rigorous and unified testbed to\nassess and accelerate LVLM research in the uniquely multimodal domain of\nmedical ultrasound imaging.", "published": "2025-05-23 11:48:48", "link": "http://arxiv.org/abs/2505.17779v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TextFlux: An OCR-Free DiT Model for High-Fidelity Multilingual Scene Text Synthesis", "abstract": "Diffusion-based scene text synthesis has progressed rapidly, yet existing\nmethods commonly rely on additional visual conditioning modules and require\nlarge-scale annotated data to support multilingual generation. In this work, we\nrevisit the necessity of complex auxiliary modules and further explore an\napproach that simultaneously ensures glyph accuracy and achieves high-fidelity\nscene integration, by leveraging diffusion models' inherent capabilities for\ncontextual reasoning. To this end, we introduce TextFlux, a DiT-based framework\nthat enables multilingual scene text synthesis. The advantages of TextFlux can\nbe summarized as follows: (1) OCR-free model architecture. TextFlux eliminates\nthe need for OCR encoders (additional visual conditioning modules) that are\nspecifically used to extract visual text-related features. (2) Strong\nmultilingual scalability. TextFlux is effective in low-resource multilingual\nsettings, and achieves strong performance in newly added languages with fewer\nthan 1,000 samples. (3) Streamlined training setup. TextFlux is trained with\nonly 1% of the training data required by competing methods. (4) Controllable\nmulti-line text generation. TextFlux offers flexible multi-line synthesis with\nprecise line-level control, outperforming methods restricted to single-line or\nrigid layouts. Extensive experiments and visualizations demonstrate that\nTextFlux outperforms previous methods in both qualitative and quantitative\nevaluations.", "published": "2025-05-23 11:46:46", "link": "http://arxiv.org/abs/2505.17778v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TopoPoint: Enhance Topology Reasoning via Endpoint Detection in Autonomous Driving", "abstract": "Topology reasoning, which unifies perception and structured reasoning, plays\na vital role in understanding intersections for autonomous driving. However,\nits performance heavily relies on the accuracy of lane detection, particularly\nat connected lane endpoints. Existing methods often suffer from lane endpoints\ndeviation, leading to incorrect topology construction. To address this issue,\nwe propose TopoPoint, a novel framework that explicitly detects lane endpoints\nand jointly reasons over endpoints and lanes for robust topology reasoning.\nDuring training, we independently initialize point and lane query, and proposed\nPoint-Lane Merge Self-Attention to enhance global context sharing through\nincorporating geometric distances between points and lanes as an attention mask\n. We further design Point-Lane Graph Convolutional Network to enable mutual\nfeature aggregation between point and lane query. During inference, we\nintroduce Point-Lane Geometry Matching algorithm that computes distances\nbetween detected points and lanes to refine lane endpoints, effectively\nmitigating endpoint deviation. Extensive experiments on the OpenLane-V2\nbenchmark demonstrate that TopoPoint achieves state-of-the-art performance in\ntopology reasoning (48.8 on OLS). Additionally, we propose DET$_p$ to evaluate\nendpoint detection, under which our method significantly outperforms existing\napproaches (52.6 v.s. 45.2 on DET$_p$). The code is released at\nhttps://github.com/Franpin/TopoPoint.", "published": "2025-05-23 11:42:54", "link": "http://arxiv.org/abs/2505.17771v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "R-Genie: Reasoning-Guided Generative Image Editing", "abstract": "While recent advances in image editing have enabled impressive visual\nsynthesis capabilities, current methods remain constrained by explicit textual\ninstructions and limited editing operations, lacking deep comprehension of\nimplicit user intentions and contextual reasoning. In this work, we introduce a\nnew image editing paradigm: reasoning-guided generative editing, which\nsynthesizes images based on complex, multi-faceted textual queries accepting\nworld knowledge and intention inference. To facilitate this task, we first\nconstruct a comprehensive dataset featuring over 1,000 image-instruction-edit\ntriples that incorporate rich reasoning contexts and real-world knowledge. We\nthen propose R-Genie: a reasoning-guided generative image editor, which\nsynergizes the generation power of diffusion models with advanced reasoning\ncapabilities of multimodal large language models. R-Genie incorporates a\nreasoning-attention mechanism to bridge linguistic understanding with visual\nsynthesis, enabling it to handle intricate editing requests involving abstract\nuser intentions and contextual reasoning relations. Extensive experimental\nresults validate that R-Genie can equip diffusion models with advanced\nreasoning-based editing capabilities, unlocking new potentials for intelligent\nimage synthesis.", "published": "2025-05-23 11:41:26", "link": "http://arxiv.org/abs/2505.17768v1", "categories": ["cs.CV", "F.2.2, I.2.7", "F.2.2; I.2.7"], "primary_category": "cs.CV"}
{"title": "Soft-CAM: Making black box models self-explainable for high-stakes decisions", "abstract": "Convolutional neural networks (CNNs) are widely used for high-stakes\napplications like medicine, often surpassing human performance. However, most\nexplanation methods rely on post-hoc attribution, approximating the\ndecision-making process of already trained black-box models. These methods are\noften sensitive, unreliable, and fail to reflect true model reasoning, limiting\ntheir trustworthiness in critical applications. In this work, we introduce\nSoftCAM, a straightforward yet effective approach that makes standard CNN\narchitectures inherently interpretable. By removing the global average pooling\nlayer and replacing the fully connected classification layer with a\nconvolution-based class evidence layer, SoftCAM preserves spatial information\nand produces explicit class activation maps that form the basis of the model's\npredictions. Evaluated on three medical datasets, SoftCAM maintains\nclassification performance while significantly improving both the qualitative\nand quantitative explanation compared to existing post-hoc methods. Our results\ndemonstrate that CNNs can be inherently interpretable without compromising\nperformance, advancing the development of self-explainable deep learning for\nhigh-stakes decision-making.", "published": "2025-05-23 11:15:21", "link": "http://arxiv.org/abs/2505.17748v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain", "abstract": "Safety-critical scenarios are rare yet pivotal for evaluating and enhancing\nthe robustness of autonomous driving systems. While existing methods generate\nsafety-critical driving trajectories, simulations, or single-view videos, they\nfall short of meeting the demands of advanced end-to-end autonomous systems\n(E2E AD), which require real-world, multi-view video data. To bridge this gap,\nwe introduce SafeMVDrive, the first framework designed to generate\nhigh-quality, safety-critical, multi-view driving videos grounded in real-world\ndomains. SafeMVDrive strategically integrates a safety-critical trajectory\ngenerator with an advanced multi-view video generator. To tackle the challenges\ninherent in this integration, we first enhance scene understanding ability of\nthe trajectory generator by incorporating visual context -- which is previously\nunavailable to such generator -- and leveraging a GRPO-finetuned\nvision-language model to achieve more realistic and context-aware trajectory\ngeneration. Second, recognizing that existing multi-view video generators\nstruggle to render realistic collision events, we introduce a two-stage,\ncontrollable trajectory generation mechanism that produces collision-evasion\ntrajectories, ensuring both video quality and safety-critical fidelity.\nFinally, we employ a diffusion-based multi-view video generator to synthesize\nhigh-quality safety-critical driving videos from the generated trajectories.\nExperiments conducted on an E2E AD planner demonstrate a significant increase\nin collision rate when tested with our generated data, validating the\neffectiveness of SafeMVDrive in stress-testing planning modules. Our code,\nexamples, and datasets are publicly available at:\nhttps://zhoujiawei3.github.io/SafeMVDrive/.", "published": "2025-05-23 10:45:43", "link": "http://arxiv.org/abs/2505.17727v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation", "abstract": "Denoising diffusion probabilistic models have achieved significant success in\npoint cloud generation, enabling numerous downstream applications, such as\ngenerative data augmentation and 3D model editing. However, little attention\nhas been given to generating point clouds with point-wise segmentation labels,\nas well as to developing evaluation metrics for this task. Therefore, in this\npaper, we present SeaLion, a novel diffusion model designed to generate\nhigh-quality and diverse point clouds with fine-grained segmentation labels.\nSpecifically, we introduce the semantic part-aware latent point diffusion\ntechnique, which leverages the intermediate features of the generative models\nto jointly predict the noise for perturbed latent points and associated part\nsegmentation labels during the denoising process, and subsequently decodes the\nlatent points to point clouds conditioned on part segmentation labels. To\neffectively evaluate the quality of generated point clouds, we introduce a\nnovel point cloud pairwise distance calculation method named part-aware Chamfer\ndistance (p-CD). This method enables existing metrics, such as 1-NNA, to\nmeasure both the local structural quality and inter-part coherence of generated\npoint clouds. Experiments on the large-scale synthetic dataset ShapeNet and\nreal-world medical dataset IntrA demonstrate that SeaLion achieves remarkable\nperformance in generation quality and diversity, outperforming the existing\nstate-of-the-art model, DiffFacto, by 13.33% and 6.52% on 1-NNA (p-CD) across\nthe two datasets. Experimental analysis shows that SeaLion can be trained\nsemi-supervised, thereby reducing the demand for labeling efforts. Lastly, we\nvalidate the applicability of SeaLion in generative data augmentation for\ntraining segmentation models and the capability of SeaLion to serve as a tool\nfor part-aware 3D shape editing.", "published": "2025-05-23 10:38:05", "link": "http://arxiv.org/abs/2505.17721v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semi-Supervised Medical Image Segmentation via Dual Networks", "abstract": "Traditional supervised medical image segmentation models require large\namounts of labeled data for training; however, obtaining such large-scale\nlabeled datasets in the real world is extremely challenging. Recent\nsemi-supervised segmentation models also suffer from noisy pseudo-label issue\nand limited supervision in feature space. To solve these challenges, we propose\nan innovative semi-supervised 3D medical image segmentation method to reduce\nthe dependency on large, expert-labeled datasets. Furthermore, we introduce a\ndual-network architecture to address the limitations of existing methods in\nusing contextual information and generating reliable pseudo-labels. In\naddition, a self-supervised contrastive learning strategy is used to enhance\nthe representation of the network and reduce prediction uncertainty by\ndistinguishing between reliable and unreliable predictions. Experiments on\nclinical magnetic resonance imaging demonstrate that our approach outperforms\nstate-of-the-art techniques. Our code is available at\nhttps://github.com/AIPMLab/Semi-supervised-Segmentation.", "published": "2025-05-23 09:59:26", "link": "http://arxiv.org/abs/2505.17690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving", "abstract": "Visual language models (VLMs) have attracted increasing interest in\nautonomous driving due to their powerful reasoning capabilities. However,\nexisting VLMs typically utilize discrete text Chain-of-Thought (CoT) tailored\nto the current scenario, which essentially represents highly abstract and\nsymbolic compression of visual information, potentially leading to\nspatio-temporal relationship ambiguity and fine-grained information loss. Is\nautonomous driving better modeled on real-world simulation and imagination than\non pure symbolic logic? In this paper, we propose a spatio-temporal CoT\nreasoning method that enables models to think visually. First, VLM serves as a\nworld model to generate unified image frame for predicting future world states:\nwhere perception results (e.g., lane divider and 3D detection) represent the\nfuture spatial relationships, and ordinary future frame represent the temporal\nevolution relationships. This spatio-temporal CoT then serves as intermediate\nreasoning steps, enabling the VLM to function as an inverse dynamics model for\ntrajectory planning based on current observations and future predictions. To\nimplement visual generation in VLMs, we propose a unified pretraining paradigm\nintegrating visual generation and understanding, along with a progressive\nvisual CoT enhancing autoregressive image generation. Extensive experimental\nresults demonstrate the effectiveness of the proposed method, advancing\nautonomous driving towards visual reasoning.", "published": "2025-05-23 09:55:32", "link": "http://arxiv.org/abs/2505.17685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "5G-DIL: Domain Incremental Learning with Similarity-Aware Sampling for Dynamic 5G Indoor Localization", "abstract": "Indoor positioning based on 5G data has achieved high accuracy through the\nadoption of recent machine learning (ML) techniques. However, the performance\nof learning-based methods degrades significantly when environmental conditions\nchange, thereby hindering their applicability to new scenarios. Acquiring new\ntraining data for each environmental change and fine-tuning ML models is both\ntime-consuming and resource-intensive. This paper introduces a domain\nincremental learning (DIL) approach for dynamic 5G indoor localization, called\n5G-DIL, enabling rapid adaptation to environmental changes. We present a novel\nsimilarity-aware sampling technique based on the Chebyshev distance, designed\nto efficiently select specific exemplars from the previous environment while\ntraining only on the modified regions of the new environment. This avoids the\nneed to train on the entire region, significantly reducing the time and\nresources required for adaptation without compromising localization accuracy.\nThis approach requires as few as 50 exemplars from adaptation domains,\nsignificantly reducing training time while maintaining high positioning\naccuracy in previous environments. Comparative evaluations against\nstate-of-the-art DIL techniques on a challenging real-world indoor dataset\ndemonstrate the effectiveness of the proposed sample selection method. Our\napproach is adaptable to real-world non-line-of-sight propagation scenarios and\nachieves an MAE positioning error of 0.261 meters, even under dynamic\nenvironmental conditions. Code:\nhttps://gitlab.cc-asp.fraunhofer.de/5g-pos/5g-dil", "published": "2025-05-23 09:54:58", "link": "http://arxiv.org/abs/2505.17684v1", "categories": ["cs.CV", "62D05, 62J99, 62P12, 68T37", "G.3; H.3.3; I.2.4; I.4; I.5.1"], "primary_category": "cs.CV"}
{"title": "Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery", "abstract": "Accurate 3D reconstruction of hands and instruments is critical for\nvision-based analysis of ophthalmic microsurgery, yet progress has been\nhampered by the lack of realistic, large-scale datasets and reliable annotation\ntools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic\n3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from\n40 surgeons and totaling 7.1 million frames, with fine-grained annotations of\n12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full\n6-DoF instrument poses. To scalably produce high-fidelity labels, we design a\nmulti-stage automatic annotation pipeline that integrates multi-view data\nobservation, data-driven motion prior with cross-view geometric consistency and\nbiomechanical constraints, along with a combination of collision-aware\ninteraction constraints for instrument interactions. Building upon OphNet-3D,\nwe establish two challenging benchmarks-bimanual hand pose estimation and\nhand-instrument interaction reconstruction-and propose two dedicated\narchitectures: H-Net for dual-hand mesh recovery and OH-Net for joint\nreconstruction of two-hand-two-instrument interactions. These models leverage a\nnovel spatial reasoning module with weak-perspective camera modeling and\ncollision-aware center-based representation. Both architectures outperform\nexisting methods by substantial margins, achieving improvements of over 2mm in\nMean Per Joint Position Error (MPJPE) and up to 23% in ADD-S metrics for hand\nand instrument reconstruction, respectively.", "published": "2025-05-23 09:44:02", "link": "http://arxiv.org/abs/2505.17677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SVL: Spike-based Vision-language Pretraining for Efficient 3D Open-world Understanding", "abstract": "Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D\nspatio-temporal features. However, existing SNNs still exhibit a significant\nperformance gap compared to Artificial Neural Networks (ANNs) due to inadequate\npre-training strategies. These limitations manifest as restricted\ngeneralization ability, task specificity, and a lack of multimodal\nunderstanding, particularly in challenging tasks such as multimodal question\nanswering and zero-shot 3D classification. To overcome these challenges, we\npropose a Spike-based Vision-Language (SVL) pretraining framework that empowers\nSNNs with open-world 3D understanding while maintaining spike-driven\nefficiency. SVL introduces two key components: (i) Multi-scale Triple Alignment\n(MTA) for label-free triplet-based contrastive learning across 3D, image, and\ntext modalities, and (ii) Re-parameterizable Vision-Language Integration\n(Rep-VLI) to enable lightweight inference without relying on large text\nencoders. Extensive experiments show that SVL achieves a top-1 accuracy of\n85.4% in zero-shot 3D classification, surpassing advanced ANN models, and\nconsistently outperforms prior SNNs on downstream tasks, including 3D\nclassification (+6.1%), DVS action recognition (+2.1%), 3D detection (+1.1%),\nand 3D segmentation (+2.1%) with remarkable efficiency. Moreover, SVL enables\nSNNs to perform open-world 3D question answering, sometimes outperforming ANNs.\nTo the best of our knowledge, SVL represents the first scalable, generalizable,\nand hardware-friendly paradigm for 3D open-world understanding, effectively\nbridging the gap between SNNs and ANNs in complex open-world understanding\ntasks. Code is available https://github.com/bollossom/SVL.", "published": "2025-05-23 09:41:10", "link": "http://arxiv.org/abs/2505.17674v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Proto-FG3D: Prototype-based Interpretable Fine-Grained 3D Shape Classification", "abstract": "Deep learning-based multi-view coarse-grained 3D shape classification has\nachieved remarkable success over the past decade, leveraging the powerful\nfeature learning capabilities of CNN-based and ViT-based backbones. However, as\na challenging research area critical for detailed shape understanding,\nfine-grained 3D classification remains understudied due to the limited\ndiscriminative information captured during multi-view feature aggregation,\nparticularly for subtle inter-class variations, class imbalance, and inherent\ninterpretability limitations of parametric model. To address these problems, we\npropose the first prototype-based framework named Proto-FG3D for fine-grained\n3D shape classification, achieving a paradigm shift from parametric softmax to\nnon-parametric prototype learning. Firstly, Proto-FG3D establishes joint\nmulti-view and multi-category representation learning via Prototype\nAssociation. Secondly, prototypes are refined via Online Clustering, improving\nboth the robustness of multi-view feature allocation and inter-subclass\nbalance. Finally, prototype-guided supervised learning is established to\nenhance fine-grained discrimination via prototype-view correlation analysis and\nenables ad-hoc interpretability through transparent case-based reasoning.\nExperiments on FG3D and ModelNet40 show Proto-FG3D surpasses state-of-the-art\nmethods in accuracy, transparent predictions, and ad-hoc interpretability with\nvisualizations, challenging conventional fine-grained 3D recognition\napproaches.", "published": "2025-05-23 09:31:02", "link": "http://arxiv.org/abs/2505.17666v1", "categories": ["cs.CV", "I.4.0; I.5.0"], "primary_category": "cs.CV"}
{"title": "Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling", "abstract": "Safe and feasible trajectory planning is essential for real-world autonomous\ndriving systems. However, existing learning-based planning methods often rely\non expert demonstrations, which not only lack explicit safety awareness but\nalso risk inheriting unsafe behaviors such as speeding from suboptimal human\ndriving data. Inspired by the success of large language models, we propose\nPlan-R1, a novel two-stage trajectory planning framework that formulates\ntrajectory planning as a sequential prediction task, guided by explicit\nplanning principles such as safety, comfort, and traffic rule compliance. In\nthe first stage, we train an autoregressive trajectory predictor via next\nmotion token prediction on expert data. In the second stage, we design\nrule-based rewards (e.g., collision avoidance, speed limits) and fine-tune the\nmodel using Group Relative Policy Optimization (GRPO), a reinforcement learning\nstrategy, to align its predictions with these planning principles. Experiments\non the nuPlan benchmark demonstrate that our Plan-R1 significantly improves\nplanning safety and feasibility, achieving state-of-the-art performance.", "published": "2025-05-23 09:22:19", "link": "http://arxiv.org/abs/2505.17659v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Instruct2See: Learning to Remove Any Obstructions Across Distributions", "abstract": "Images are often obstructed by various obstacles due to capture limitations,\nhindering the observation of objects of interest. Most existing methods address\nocclusions from specific elements like fences or raindrops, but are constrained\nby the wide range of real-world obstructions, making comprehensive data\ncollection impractical. To overcome these challenges, we propose Instruct2See,\na novel zero-shot framework capable of handling both seen and unseen obstacles.\nThe core idea of our approach is to unify obstruction removal by treating it as\na soft-hard mask restoration problem, where any obstruction can be represented\nusing multi-modal prompts, such as visual semantics and textual instructions,\nprocessed through a cross-attention unit to enhance contextual understanding\nand improve mode control. Additionally, a tunable mask adapter allows for\ndynamic soft masking, enabling real-time adjustment of inaccurate masks.\nExtensive experiments on both in-distribution and out-of-distribution obstacles\nshow that Instruct2See consistently achieves strong performance and\ngeneralization in obstruction removal, regardless of whether the obstacles were\npresent during the training phase. Code and dataset are available at\nhttps://jhscut.github.io/Instruct2See.", "published": "2025-05-23 09:12:34", "link": "http://arxiv.org/abs/2505.17649v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Prospective Medical Image Reconstruction via Knowledge-Informed Dynamic Optimal Transport", "abstract": "Medical image reconstruction from measurement data is a vital but challenging\ninverse problem. Deep learning approaches have achieved promising results, but\noften requires paired measurement and high-quality images, which is typically\nsimulated through a forward model, i.e., retrospective reconstruction. However,\ntraining on simulated pairs commonly leads to performance degradation on real\nprospective data due to the retrospective-to-prospective gap caused by\nincomplete imaging knowledge in simulation. To address this challenge, this\npaper introduces imaging Knowledge-Informed Dynamic Optimal Transport (KIDOT),\na novel dynamic optimal transport framework with optimality in the sense of\npreserving consistency with imaging physics in transport, that conceptualizes\nreconstruction as finding a dynamic transport path. KIDOT learns from unpaired\ndata by modeling reconstruction as a continuous evolution path from\nmeasurements to images, guided by an imaging knowledge-informed cost function\nand transport equation. This dynamic and knowledge-aware approach enhances\nrobustness and better leverages unpaired data while respecting acquisition\nphysics. Theoretically, we demonstrate that KIDOT naturally generalizes dynamic\noptimal transport, ensuring its mathematical rationale and solution existence.\nExtensive experiments on MRI and CT reconstruction demonstrate KIDOT's superior\nperformance.", "published": "2025-05-23 09:05:10", "link": "http://arxiv.org/abs/2505.17644v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment", "abstract": "Synthetic X-ray angiographies generated by modern generative models hold\ngreat potential to reduce the use of contrast agents in vascular interventional\nprocedures. However, low-quality synthetic angiographies can significantly\nincrease procedural risk, underscoring the need for reliable image quality\nassessment (IQA) methods. Existing IQA models, however, fail to leverage\nauxiliary images as references during evaluation and lack fine-grained,\ntask-specific metrics necessary for clinical relevance. To address these\nlimitations, this paper proposes CAS-IQA, a vision-language model (VLM)-based\nframework that predicts fine-grained quality scores by effectively\nincorporating auxiliary information from related images. In the absence of\nangiography datasets, CAS-3K is constructed, comprising 3,565 synthetic\nangiographies along with score annotations. To ensure clinically meaningful\nassessment, three task-specific evaluation metrics are defined. Furthermore, a\nMulti-path featUre fuSion and rouTing (MUST) module is designed to enhance\nimage representations by adaptively fusing and routing visual tokens to\nmetric-specific branches. Extensive experiments on the CAS-3K dataset\ndemonstrate that CAS-IQA significantly outperforms state-of-the-art IQA methods\nby a considerable margin.", "published": "2025-05-23 08:27:05", "link": "http://arxiv.org/abs/2505.17619v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scaling Image and Video Generation via Test-Time Evolutionary Search", "abstract": "As the marginal cost of scaling computation (data and parameters) during\nmodel pre-training continues to increase substantially, test-time scaling (TTS)\nhas emerged as a promising direction for improving generative model performance\nby allocating additional computation at inference time. While TTS has\ndemonstrated significant success across multiple language tasks, there remains\na notable gap in understanding the test-time scaling behaviors of image and\nvideo generative models (diffusion-based or flow-based models). Although recent\nworks have initiated exploration into inference-time strategies for vision\ntasks, these approaches face critical limitations: being constrained to\ntask-specific domains, exhibiting poor scalability, or falling into reward\nover-optimization that sacrifices sample diversity. In this paper, we propose\n\\textbf{Evo}lutionary \\textbf{Search} (EvoSearch), a novel, generalist, and\nefficient TTS method that effectively enhances the scalability of both image\nand video generation across diffusion and flow models, without requiring\nadditional training or model expansion. EvoSearch reformulates test-time\nscaling for diffusion and flow models as an evolutionary search problem,\nleveraging principles from biological evolution to efficiently explore and\nrefine the denoising trajectory. By incorporating carefully designed selection\nand mutation mechanisms tailored to the stochastic differential equation\ndenoising process, EvoSearch iteratively generates higher-quality offspring\nwhile preserving population diversity. Through extensive evaluation across both\ndiffusion and flow architectures for image and video generation tasks, we\ndemonstrate that our method consistently outperforms existing approaches,\nachieves higher diversity, and shows strong generalizability to unseen\nevaluation metrics. Our project is available at the website\nhttps://tinnerhrhe.github.io/evosearch.", "published": "2025-05-23 08:25:46", "link": "http://arxiv.org/abs/2505.17618v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PathoSCOPE: Few-Shot Pathology Detection via Self-Supervised Contrastive Learning and Pathology-Informed Synthetic Embeddings", "abstract": "Unsupervised pathology detection trains models on non-pathological data to\nflag deviations as pathologies, offering strong generalizability for\nidentifying novel diseases and avoiding costly annotations. However, building\nreliable normality models requires vast healthy datasets, as hospitals' data is\ninherently biased toward symptomatic populations, while privacy regulations\nhinder the assembly of representative healthy cohorts. To address this\nlimitation, we propose PathoSCOPE, a few-shot unsupervised pathology detection\nframework that requires only a small set of non-pathological samples (minimum 2\nshots), significantly improving data efficiency. We introduce Global-Local\nContrastive Loss (GLCL), comprised of a Local Contrastive Loss to reduce the\nvariability of non-pathological embeddings and a Global Contrastive Loss to\nenhance the discrimination of pathological regions. We also propose a\nPathology-informed Embedding Generation (PiEG) module that synthesizes\npathological embeddings guided by the global loss, better exploiting the\nlimited non-pathological samples. Evaluated on the BraTS2020 and ChestXray8\ndatasets, PathoSCOPE achieves state-of-the-art performance among unsupervised\nmethods while maintaining computational efficiency (2.48 GFLOPs, 166 FPS).", "published": "2025-05-23 08:21:58", "link": "http://arxiv.org/abs/2505.17614v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MinkUNeXt-SI: Improving point cloud-based place recognition including spherical coordinates and LiDAR intensity", "abstract": "In autonomous navigation systems, the solution of the place recognition\nproblem is crucial for their safe functioning. But this is not a trivial\nsolution, since it must be accurate regardless of any changes in the scene,\nsuch as seasonal changes and different weather conditions, and it must be\ngeneralizable to other environments. This paper presents our method,\nMinkUNeXt-SI, which, starting from a LiDAR point cloud, preprocesses the input\ndata to obtain its spherical coordinates and intensity values normalized within\na range of 0 to 1 for each point, and it produces a robust place recognition\ndescriptor. To that end, a deep learning approach that combines Minkowski\nconvolutions and a U-net architecture with skip connections is used. The\nresults of MinkUNeXt-SI demonstrate that this method reaches and surpasses\nstate-of-the-art performance while it also generalizes satisfactorily to other\ndatasets. Additionally, we showcase the capture of a custom dataset and its use\nin evaluating our solution, which also achieves outstanding results. Both the\ncode of our solution and the runs of our dataset are publicly available for\nreproducibility purposes.", "published": "2025-05-23 07:56:43", "link": "http://arxiv.org/abs/2505.17591v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.LG"}
{"title": "CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis", "abstract": "Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high\nquality synthesis of human heads. However, existing methods stabilize training\nand enhance rendering quality from steep viewpoints by conditioning the random\nlatent vector on the current camera position. This compromises 3D consistency,\nas we observe significant identity changes when re-synthesizing the 3D head\nwith each camera shift. Conversely, fixing the camera to a single viewpoint\nyields high-quality renderings for that perspective but results in poor\nperformance for novel views. Removing view-conditioning typically destabilizes\nGAN training, often causing the training to collapse. In response to these\nchallenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework\nthat enables stable training and high-quality 3D-consistent synthesis of human\nheads without relying on view-conditioning. To ensure training stability, we\nintroduce a multi-view regularization technique that enhances generator\nconvergence with minimal computational overhead. Additionally, we adapt the\nconditional loss used in existing 3D Gaussian splatting GANs and propose a\ngenerator architecture designed to not only stabilize training but also\nfacilitate efficient rendering and straightforward scaling, enabling output\nresolutions up to $2048^2$. To evaluate the capabilities of CGS-GAN, we curate\na new dataset derived from FFHQ. This dataset enables very high resolutions,\nfocuses on larger portions of the human head, reduces view-dependent artifacts\nfor improved 3D consistency, and excludes images where subjects are obscured by\nhands or other objects. As a result, our approach achieves very high rendering\nquality, supported by competitive FID scores, while ensuring consistent 3D\nscene generation. Check our our project page here:\nhttps://fraunhoferhhi.github.io/cgs-gan/", "published": "2025-05-23 07:56:25", "link": "http://arxiv.org/abs/2505.17590v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distance Estimation in Outdoor Driving Environments Using Phase-only Correlation Method with Event Cameras", "abstract": "With the growing adoption of autonomous driving, the advancement of sensor\ntechnology is crucial for ensuring safety and reliable operation. Sensor fusion\ntechniques that combine multiple sensors such as LiDAR, radar, and cameras have\nproven effective, but the integration of multiple devices increases both\nhardware complexity and cost. Therefore, developing a single sensor capable of\nperforming multiple roles is highly desirable for cost-efficient and scalable\nautonomous driving systems.\n  Event cameras have emerged as a promising solution due to their unique\ncharacteristics, including high dynamic range, low latency, and high temporal\nresolution. These features enable them to perform well in challenging lighting\nconditions, such as low-light or backlit environments. Moreover, their ability\nto detect fine-grained motion events makes them suitable for applications like\npedestrian detection and vehicle-to-infrastructure communication via visible\nlight.\n  In this study, we present a method for distance estimation using a monocular\nevent camera and a roadside LED bar. By applying a phase-only correlation\ntechnique to the event data, we achieve sub-pixel precision in detecting the\nspatial shift between two light sources. This enables accurate\ntriangulation-based distance estimation without requiring stereo vision. Field\nexperiments conducted in outdoor driving scenarios demonstrated that the\nproposed approach achieves over 90% success rate with less than 0.5-meter error\nfor distances ranging from 20 to 60 meters.\n  Future work includes extending this method to full position estimation by\nleveraging infrastructure such as smart poles equipped with LEDs, enabling\nevent-camera-based vehicles to determine their own position in real time. This\nadvancement could significantly enhance navigation accuracy, route\noptimization, and integration into intelligent transportation systems.", "published": "2025-05-23 07:44:33", "link": "http://arxiv.org/abs/2505.17582v1", "categories": ["eess.IV", "cs.CV", "cs.RO", "I.4.8; I.2.10; I.5.4"], "primary_category": "eess.IV"}
{"title": "Near optimal edge partitioning via intersecting families", "abstract": "We study the problem of edge-centric graph partitioning, where the goal is to\ndistribute the edges of a graph among several almost equally sized partitions\nin order to minimize the replication factor of vertices. We build a\npartitioning algorithm that guarantees near-perfect balance and replication\nfactor $\\sqrt{n}(1 + o(1))$ for arbitrary number of partitions $n$. This\nasymptotical bound cannot be improved. To do so, we introduce balanced\nintersecting systems. It is a construction similar to symmetric intersecting\nfamilies, but the symmetry condition is replaced by a weaker balance condition.\nWe build an algorithm that uses such a system, and prove that by using a system\nof optimal cardinality we achieve exactly optimal guarantees for the\nreplication factor. Finally, we build balanced intersecting systems with\nasymptotically optimal cardinality.", "published": "2025-05-23 15:29:12", "link": "http://arxiv.org/abs/2505.18026v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "On the geometric $k$-colored crossing number of $K_n$", "abstract": "We study the \\emph{geometric $k$-colored crossing number} of complete graphs\n$\\overline{\\overline{\\text{cr}}}_k(K_n)$, which is the smallest number of\nmonochromatic crossings in any $k$-edge colored straight-line drawing of $K_n$.\n  We substantially improve asymptotic upper bounds on\n$\\overline{\\overline{\\text{cr}}}_k(K_n)$ for $k=2,\\ldots, 10$ by developing a\nprocedure for general $k$ that derives $k$-edge colored drawings of $K_n$ for\narbitrarily large $n$ from initial drawings with a low number of monochromatic\ncrossings.\n  We obtain the latter by heuristic search, employing a\n\\textsc{MAX-$k$-CUT}-formulation of a subproblem in the process.", "published": "2025-05-23 15:15:27", "link": "http://arxiv.org/abs/2505.18014v1", "categories": ["cs.CG", "cs.DM", "math.CO"], "primary_category": "cs.CG"}
{"title": "Finding d-Cuts in Claw-free Graphs", "abstract": "The Matching Cut problem is to decide if the vertex set of a connected graph\ncan be partitioned into two non-empty sets $B$ and $R$ such that the edges\nbetween $B$ and $R$ form a matching, that is, every vertex in $B$ has at most\none neighbour in $R$, and vice versa. If for some integer $d\\geq 1$, we allow\nevery neighbour in $B$ to have at most $d$ neighbours in $R$, and vice versa,\nwe obtain the more general problem $d$-Cut. It is known that $d$-Cut is\nNP-complete for every $d\\geq 1$. However, for claw-free graphs, it is only\nknown that $d$-Cut is polynomial-time solvable for $d=1$ and NP-complete for\n$d\\geq 3$. We resolve the missing case $d=2$ by proving NP-completeness. This\nfollows from our more general study, in which we also bound the maximum degree.\nThat is, we prove that for every $d\\geq 2$, $d$-Cut, restricted to claw-free\ngraphs of maximum degree $p$, is constant-time solvable if $p\\leq 2d+1$ and\nNP-complete if $p\\geq 2d+3$. Moreover, in the former case, we can find a\n$d$-cut in linear time. We also show how our positive results for claw-free\ngraphs can be generalized to $S_{1^t,l}$-free graphs where $S_{1^t,l}$ is the\ngraph obtained from a star on $t+2$ vertices by subdividing one of its edges\nexactly $l$ times.", "published": "2025-05-23 14:58:42", "link": "http://arxiv.org/abs/2505.17993v1", "categories": ["math.CO", "cs.CC", "cs.DM"], "primary_category": "math.CO"}
{"title": "Assessing the performance of 8 AI chatbots in bibliographic reference retrieval: Grok and DeepSeek outperform ChatGPT, but none are fully accurate", "abstract": "This study analyzes the performance of eight generative artificial\nintelligence chatbots -- ChatGPT, Claude, Copilot, DeepSeek, Gemini, Grok, Le\nChat, and Perplexity -- in their free versions, in the task of generating\nacademic bibliographic references within the university context. A total of 400\nreferences were evaluated across the five major areas of knowledge (Health,\nEngineering, Experimental Sciences, Social Sciences, and Humanities), based on\na standardized prompt. Each reference was assessed according to five key\ncomponents (authorship, year, title, source, and location), along with document\ntype, publication age, and error count. The results show that only 26.5% of the\nreferences were fully correct, 33.8% partially correct, and 39.8% were either\nerroneous or entirely fabricated. Grok and DeepSeek stood out as the only\nchatbots that did not generate false references, while Copilot, Perplexity, and\nClaude exhibited the highest hallucination rates. Furthermore, the chatbots\nshowed a greater tendency to generate book references over journal articles,\nalthough the latter had a significantly higher fabrication rate. A high degree\nof overlap was also detected among the sources provided by several models,\nparticularly between DeepSeek, Grok, Gemini, and ChatGPT. These findings reveal\nstructural limitations in current AI models, highlight the risks of uncritical\nuse by students, and underscore the need to strengthen information and critical\nliteracy regarding the use of AI tools in higher education.", "published": "2025-05-23 16:07:14", "link": "http://arxiv.org/abs/2505.18059v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Revisiting Feature Interactions from the Perspective of Quadratic Neural Networks for Click-through Rate Prediction", "abstract": "Hadamard Product (HP) has long been a cornerstone in click-through rate (CTR)\nprediction tasks due to its simplicity, effectiveness, and ability to capture\nfeature interactions without additional parameters. However, the underlying\nreasons for its effectiveness remain unclear. In this paper, we revisit HP from\nthe perspective of Quadratic Neural Networks (QNN), which leverage quadratic\ninteraction terms to model complex feature relationships. We further reveal\nQNN's ability to expand the feature space and provide smooth nonlinear\napproximations without relying on activation functions. Meanwhile, we find that\ntraditional post-activation does not further improve the performance of the\nQNN. Instead, mid-activation is a more suitable alternative. Through\ntheoretical analysis and empirical evaluation of 25 QNN neuron formats, we\nidentify a good-performing variant and make further enhancements on it.\nSpecifically, we propose the Multi-Head Khatri-Rao Product as a superior\nalternative to HP and a Self-Ensemble Loss with dynamic ensemble capability\nwithin the same network to enhance computational efficiency and performance.\nUltimately, we propose a novel neuron format, QNN-alpha, which is tailored for\nCTR prediction tasks. Experimental results show that QNN-alpha achieves new\nstate-of-the-art performance on six public datasets while maintaining low\ninference latency, good scalability, and excellent compatibility. The code,\nrunning logs, and detailed hyperparameter configurations are available at:\nhttps://github.com/salmon1802/QNN.", "published": "2025-05-23 15:04:16", "link": "http://arxiv.org/abs/2505.17999v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Enhancing CTR Prediction with De-correlated Expert Networks", "abstract": "Modeling feature interactions is essential for accurate click-through rate\n(CTR) prediction in advertising systems. Recent studies have adopted the\nMixture-of-Experts (MoE) approach to improve performance by ensembling multiple\nfeature interaction experts. These studies employ various strategies, such as\nlearning independent embedding tables for each expert or utilizing\nheterogeneous expert architectures, to differentiate the experts, which we\nrefer to expert \\emph{de-correlation}. However, it remains unclear whether\nthese strategies effectively achieve de-correlated experts. To address this, we\npropose a De-Correlated MoE (D-MoE) framework, which introduces a Cross-Expert\nDe-Correlation loss to minimize expert correlations.Additionally, we propose a\nnovel metric, termed Cross-Expert Correlation, to quantitatively evaluate the\nexpert de-correlation degree. Based on this metric, we identify a key finding\nfor MoE framework design: \\emph{different de-correlation strategies are\nmutually compatible, and progressively employing them leads to reduced\ncorrelation and enhanced performance}.Extensive experiments have been conducted\nto validate the effectiveness of D-MoE and the de-correlation principle.\nMoreover, online A/B testing on Tencent's advertising platforms demonstrates\nthat D-MoE achieves a significant 1.19\\% Gross Merchandise Volume (GMV) lift\ncompared to the Multi-Embedding MoE baseline.", "published": "2025-05-23 14:04:38", "link": "http://arxiv.org/abs/2505.17925v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "VIBE: Vector Index Benchmark for Embeddings", "abstract": "Approximate nearest neighbor (ANN) search is a performance-critical component\nof many machine learning pipelines. Rigorous benchmarking is essential for\nevaluating the performance of vector indexes for ANN search. However, the\ndatasets of the existing benchmarks are no longer representative of the current\napplications of ANN search. Hence, there is an urgent need for an up-to-date\nset of benchmarks. To this end, we introduce Vector Index Benchmark for\nEmbeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE\ncontains a pipeline for creating benchmark datasets using dense embedding\nmodels characteristic of modern applications, such as retrieval-augmented\ngeneration (RAG). To replicate real-world workloads, we also include\nout-of-distribution (OOD) datasets where the queries and the corpus are drawn\nfrom different distributions. We use VIBE to conduct a comprehensive evaluation\nof SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution\nand 6 out-of-distribution datasets.", "published": "2025-05-23 12:28:10", "link": "http://arxiv.org/abs/2505.17810v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Modeling Ranking Properties with In-Context Learning", "abstract": "While standard IR models are mainly designed to optimize relevance,\nreal-world search often needs to balance additional objectives such as\ndiversity and fairness. These objectives depend on inter-document interactions\nand are commonly addressed using post-hoc heuristics or supervised learning\nmethods, which require task-specific training for each ranking scenario and\ndataset. In this work, we propose an in-context learning (ICL) approach that\neliminates the need for such training. Instead, our method relies on a small\nnumber of example rankings that demonstrate the desired trade-offs between\nobjectives for past queries similar to the current input. We evaluate our\napproach on four IR test collections to investigate multiple auxiliary\nobjectives: group fairness (TREC Fairness), polarity diversity (Touch\\'e), and\ntopical diversity (TREC Deep Learning 2019/2020). We empirically validate that\nour method enables control over ranking behavior through demonstration\nengineering, allowing nuanced behavioral adjustments without explicit\noptimization.", "published": "2025-05-23 10:58:22", "link": "http://arxiv.org/abs/2505.17736v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "BehaveGPT: A Foundation Model for Large-scale User Behavior Modeling", "abstract": "In recent years, foundational models have revolutionized the fields of\nlanguage and vision, demonstrating remarkable abilities in understanding and\ngenerating complex data; however, similar advances in user behavior modeling\nhave been limited, largely due to the complexity of behavioral data and the\nchallenges involved in capturing intricate temporal and contextual\nrelationships in user activities. To address this, we propose BehaveGPT, a\nfoundational model designed specifically for large-scale user behavior\nprediction. Leveraging transformer-based architecture and a novel pretraining\nparadigm, BehaveGPT is trained on vast user behavior datasets, allowing it to\nlearn complex behavior patterns and support a range of downstream tasks,\nincluding next behavior prediction, long-term generation, and cross-domain\nadaptation. Our approach introduces the DRO-based pretraining paradigm tailored\nfor user behavior data, which improves model generalization and transferability\nby equitably modeling both head and tail behaviors. Extensive experiments on\nreal-world datasets demonstrate that BehaveGPT outperforms state-of-the-art\nbaselines, achieving more than a 10% improvement in macro and weighted recall,\nshowcasing its ability to effectively capture and predict user behavior.\nFurthermore, we measure the scaling law in the user behavior domain for the\nfirst time on the Honor dataset, providing insights into how model performance\nscales with increased data and parameter sizes.", "published": "2025-05-23 08:43:46", "link": "http://arxiv.org/abs/2505.17631v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "EGA: A Unified End-to-End Generative Framework for Industrial Advertising Systems", "abstract": "Online industrial advertising system is fundamentally constrained by the\ninefficiency of multi-stage cascaded architectures, which filter out\nhigh-potential candidates early and fragment business decision logic across\nindependent modules. Although recent advances in generative recommendation\noffer end-to-end solutions, they fall short of practical advertising\nrequirements, lacking explicit modeling of bidding, creative selection,\nallocation mechanism, and payment computation that are essential for real-world\ndeployment. To overcome these limitations, we propose End-to-end Generative\nAdvertising (EGA), a first unified generative framework that seamlessly\nintegrates user interests modeling, POI and creative generation, position\nallocation, and payment optimization within a single model. EGA leverages\nhierarchical tokenization and multi-token prediction to jointly generate\ncandidate POI and creative contents, while a permutation-aware reward model and\ntoken-level bidding strategy ensure alignment with both user experiences and\nadvertiser business objectives. Meanwhile, we decouple allocation from payment\nvia a dedicated POI-level payment network with differentiable ex-post regret\nminimization, guaranteeing incentive compatibility approximately. Extensive\noffline and large-scale online experiments on real-world advertising systems\ndemonstrate its effectiveness and practical advantages over traditional\ncascading architectures, highlighting its potential as one of the industry's\npioneering end-to-end generative advertising solutions.", "published": "2025-05-23 06:55:02", "link": "http://arxiv.org/abs/2505.17549v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Benchmarking Recommendation, Classification, and Tracing Based on Hugging Face Knowledge Graph", "abstract": "The rapid growth of open source machine learning (ML) resources, such as\nmodels and datasets, has accelerated IR research. However, existing platforms\nlike Hugging Face do not explicitly utilize structured representations,\nlimiting advanced queries and analyses such as tracing model evolution and\nrecommending relevant datasets. To fill the gap, we construct HuggingKG, the\nfirst large-scale knowledge graph built from the Hugging Face community for ML\nresource management. With 2.6 million nodes and 6.2 million edges, HuggingKG\ncaptures domain-specific relations and rich textual attributes. It enables us\nto further present HuggingBench, a multi-task benchmark with three novel test\ncollections for IR tasks including resource recommendation, classification, and\ntracing. Our experiments reveal unique characteristics of HuggingKG and the\nderived tasks. Both resources are publicly available, expected to advance\nresearch in open source resource sharing and management.", "published": "2025-05-23 06:00:20", "link": "http://arxiv.org/abs/2505.17507v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A new measure of dependence: Integrated $R^2$", "abstract": "We propose a new measure of dependence that quantifies the degree to which a\nrandom variable $Y$ depends on a random vector $X$. This measure is zero if and\nonly if $Y$ and $X$ are independent, and equals one if and only if $Y$ is a\nmeasurable function of $X$. We introduce a simple and interpretable estimator\nthat is comparable in ease of computation to classical correlation coefficients\nsuch as Pearson's, Spearman's, or Chatterjee's. Building on this coefficient,\nwe develop a model-free variable selection algorithm, feature ordering by\ndependence (FORD), inspired by FOCI. FORD requires no tuning parameters and is\nprovably consistent under suitable sparsity assumptions. We demonstrate its\neffectiveness and improvements over FOCI through experiments on both synthetic\nand real datasets.", "published": "2025-05-23 17:57:17", "link": "http://arxiv.org/abs/2505.18146v1", "categories": ["math.ST", "cs.IT", "math.IT", "math.PR", "stat.ME", "stat.TH", "62H20, 62H15"], "primary_category": "math.ST"}
{"title": "The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized Quadratic Networks", "abstract": "We study the high-dimensional asymptotics of empirical risk minimization\n(ERM) in over-parametrized two-layer neural networks with quadratic activations\ntrained on synthetic data. We derive sharp asymptotics for both training and\ntest errors by mapping the $\\ell_2$-regularized learning problem to a convex\nmatrix sensing task with nuclear norm penalization. This reveals that capacity\ncontrol in such networks emerges from a low-rank structure in the learned\nfeature maps. Our results characterize the global minima of the loss and yield\nprecise generalization thresholds, showing how the width of the target function\ngoverns learnability. This analysis bridges and extends ideas from spin-glass\nmethods, matrix factorization, and convex optimization and emphasizes the deep\nlink between low-rank matrix sensing and learning in quadratic neural networks.", "published": "2025-05-23 14:31:14", "link": "http://arxiv.org/abs/2505.17958v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Optimal Decision Rules for Composite Binary Hypothesis Testing under Neyman-Pearson Framework", "abstract": "The composite binary hypothesis testing problem within the Neyman-Pearson\nframework is considered. The goal is to maximize the expectation of a nonlinear\nfunction of the detection probability, integrated with respect to a given\nprobability measure, subject to a false-alarm constraint. It is shown that each\npower function can be realized by a generalized Bayes rule that maximizes an\nintegrated rejection probability with respect to a finite signed measure. For a\nsimple null hypothesis and a composite alternative, optimal single-threshold\ndecision rules based on an appropriately weighted likelihood ratio are derived.\nThe analysis is extended to composite null hypotheses, including both average\nand worst-case false-alarm constraints, resulting in modified optimal threshold\nrules. Special cases involving exponential family distributions and numerical\nexamples are provided to illustrate the theoretical results.", "published": "2025-05-23 13:03:20", "link": "http://arxiv.org/abs/2505.17851v1", "categories": ["math.ST", "cs.IT", "math.IT", "stat.TH"], "primary_category": "math.ST"}
{"title": "Protograph-Based LDPC Codes with Local Irregularity", "abstract": "Forward error correcting (FEC) codes are used in many communication standards\nwith a wide range of re quirements. FEC codes should work close to capacity,\nachieve low error floors, and have low decoding complexity. In this paper, we\npropose a novel category of low-density parity-check (LDPC) codes, based on\nprotograph codes with local irregularity. This new code family generalizes\nconventional protograph-based LDPC codes and is capable of reducing the\niterative decoding threshold of the conventional counterpart. We introduce an\nadapted version of the protograph extrinsic information transfer (PEXIT)\nalgorithm to estimate decoding thresholds on the binary input additive white\nGaussian noise channel, perform optimiza tions on the local irregularity, and\nsimulate the performance of some constructed codes.", "published": "2025-05-23 12:51:39", "link": "http://arxiv.org/abs/2505.17837v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Characterization of IRS-aided Indoor Wireless Virtual-Reality with Hybrid Beamforming", "abstract": "This paper introduces an optimum solution for a utility function that\nincreases spectral efficiency in wireless Virtual Reality (VR) systems. This\nsystem uses Multi-user Multiple Input Multiple Output Orthogonal Frequency\nDivision Multiplexing (MU-MIMO OFDM) with hybrid beamforming in indoor\nIntelligent Reflecting Surface (IRS) based Downlink (DL) scenario. Given the\ncritical need to maximize the rate for transmitting VR traffic to meet the\nlow-latency requirements, a substantial bandwidth allocation is essential. This\nbandwidth is assumed to be in the mmWave band, according to the IEEE\n802.11ad/ay standard. The proposed utility function takes into account various\ndelays, including processing, transmission and queuing delays, on both DL and\nUplink (UL). Moreover, the relation between transmission delay and the utility\nfunction is examined in different Signal-to-Noise Ratio (SNR) levels, using\nboth mean and minimum channel gain metrics. An optimization approach is applied\nto iteratively determine the IRS phase shifts and effective channel gain. The\nsimulation results are benchmarked against NS3 simulations, showing a high\ndegree of consistency. With an average accuracy of 81.57% the calculated DL and\nUL rates match the NS3 results when considering the IRS. Also, our proposed\nmethod achieves superior performance in the case of complexity over the\nexisting designs.", "published": "2025-05-23 11:02:34", "link": "http://arxiv.org/abs/2505.17737v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Nodal surfaces in $\\mathbb{P}^3$ and coding theory", "abstract": "To each nodal hypersurface one can associate a binary linear code. Here we\nshow that the binary linear code associated to sextics in $\\mathbb{P}^3$ with\nthe maximum number of $65$ nodes, as e.g. the Barth sextic, is unique. We also\nstate possible candidates for codes that might be associated with a\nhypothetical septic attaining the currently best known upper bound for the\nmaximum number of nodes.", "published": "2025-05-23 06:39:07", "link": "http://arxiv.org/abs/2505.17531v1", "categories": ["math.CO", "cs.IT", "math.AG", "math.IT", "14J70, 94B05"], "primary_category": "math.CO"}
{"title": "GPS-Aided Deep Learning for Beam Prediction and Tracking in UAV mmWave Communication", "abstract": "Millimeter-wave (mmWave) communication enables high data rates for\ncellular-connected Unmanned Aerial Vehicles (UAVs). However, a robust beam\nmanagement remains challenging due to significant path loss and the dynamic\nmobility of UAVs, which can destabilize the UAV-base station (BS) link. This\nresearch presents a GPS-aided deep learning (DL) model that simultaneously\npredicts current and future optimal beams for UAV mmWave communications,\nmaintaining a Top-1 prediction accuracy exceeding 70% and an average power loss\nbelow 0.6 dB across all prediction steps. These outcomes stem from a proposed\ndata set splitting method ensuring balanced label distribution, paired with a\nGPS preprocessing technique that extracts key positional features, and a DL\narchitecture that maps sequential position data to beam index predictions. The\nmodel reduces overhead by approximately 93% (requiring the training of 2 ~ 3\nbeams instead of 32 beams) with 95% beam prediction accuracy guarantees, and\nensures 94% to 96% of predictions exhibit mean power loss not exceeding 1 dB.", "published": "2025-05-23 06:38:00", "link": "http://arxiv.org/abs/2505.17530v1", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.SP"}
{"title": "Efficient compression of neural networks and datasets", "abstract": "We compare, improve, and contribute methods that substantially decrease the\nnumber of parameters of neural networks while maintaining high test accuracy.\nWhen applying our methods to minimize description length, we obtain very\neffective data compression algorithms. In particular, we develop a\nprobabilistic reformulation of $\\ell_0$ regularized optimization for nonlinear\nmodels that does not require Monte-Carlo sampling and thus improves upon\nprevious methods. We also improve upon methods involving smooth approximations\nto the $\\ell_0$ norm, and investigate layerwise methods. We compare the methods\non different architectures and datasets, including convolutional networks\ntrained on image datasets and transformers trained on parts of Wikipedia. We\nalso created a synthetic teacher-student setup to investigate compression in a\ncontrolled continuous setting. Finally, we conceptually relate compression\nalgorithms to Solomonoff's theory of inductive inference and empirically verify\nthe prediction that regularized models can exhibit more sample-efficient\nconvergence.", "published": "2025-05-23 04:50:33", "link": "http://arxiv.org/abs/2505.17469v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.OC", "math.ST", "stat.TH", "94-08, 94-04, 68T07, 68T50", "E.4; H.1.1; I.2; I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "VIBE: Video-to-Text Information Bottleneck Evaluation for TL;DR", "abstract": "Many decision-making tasks, where both accuracy and efficiency matter, still\nrequire human supervision. For example, tasks like traffic officers reviewing\nhour-long dashcam footage or researchers screening conference videos can\nbenefit from concise summaries that reduce cognitive load and save time. Yet\ncurrent vision-language models (VLMs) often produce verbose, redundant outputs\nthat hinder task performance. Existing video caption evaluation depends on\ncostly human annotations and overlooks the summaries' utility in downstream\ntasks. We address these gaps with Video-to-text Information Bottleneck\nEvaluation (VIBE), an annotation-free method that scores VLM outputs using two\nmetrics: grounding (how well the summary aligns with visual content) and\nutility (how informative it is for the task). VIBE selects from randomly\nsampled VLM outputs by ranking them according to the two scores to support\neffective human decision-making. Human studies on LearningPaper24,\nSUTD-TrafficQA, and LongVideoBench show that summaries selected by VIBE\nconsistently improve performance-boosting task accuracy by up to 61.23% and\nreducing response time by 75.77% compared to naive VLM summaries or raw video.", "published": "2025-05-23 03:11:29", "link": "http://arxiv.org/abs/2505.17423v1", "categories": ["cs.CV", "cs.HC", "cs.IT", "math.IT"], "primary_category": "cs.CV"}
{"title": "Adaptive Implicit-Based Deep Learning Channel Estimation for 6G Communications", "abstract": "With the widespread deployment of fifth-generation (5G) wireless networks,\nresearch on sixth-generation (6G) technology is gaining momentum. Artificial\nIntelligence (AI) is anticipated to play a significant role in 6G, particularly\nthrough integration with the physical layer for tasks such as channel\nestimation. Considering resource limitations in real systems, the AI algorithm\nshould be designed to have the ability to balance the accuracy and resource\nconsumption according to the scenarios dynamically. However, conventional\nexplicit multilayer-stacked Deep Learning (DL) models struggle to adapt due to\ntheir heavy reliance on the structure of deep neural networks. This article\nproposes an adaptive Implicit-layer DL Channel Estimation Network (ICENet) with\na lightweight framework for vehicle-to-everything communications. This novel\napproach balances computational complexity and channel estimation accuracy by\ndynamically adjusting computational resources based on input data conditions,\nsuch as channel quality. Unlike explicit multilayer-stacked DL-based channel\nestimation models, ICENet offers a flexible framework, where specific\nrequirements can be achieved by adaptively changing the number of iterations of\nthe iterative layer. Meanwhile, ICENet requires less memory while maintaining\nhigh performance. The article concludes by highlighting open research\nchallenges and promising future research directions.", "published": "2025-05-23 03:10:49", "link": "http://arxiv.org/abs/2505.17421v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generative Distribution Embeddings", "abstract": "Many real-world problems require reasoning across multiple scales, demanding\nmodels which operate not on single data points, but on entire distributions. We\nintroduce generative distribution embeddings (GDE), a framework that lifts\nautoencoders to the space of distributions. In GDEs, an encoder acts on sets of\nsamples, and the decoder is replaced by a generator which aims to match the\ninput distribution. This framework enables learning representations of\ndistributions by coupling conditional generative models with encoder networks\nwhich satisfy a criterion we call distributional invariance. We show that GDEs\nlearn predictive sufficient statistics embedded in the Wasserstein space, such\nthat latent GDE distances approximately recover the $W_2$ distance, and latent\ninterpolation approximately recovers optimal transport trajectories for\nGaussian and Gaussian mixture distributions. We systematically benchmark GDEs\nagainst existing approaches on synthetic datasets, demonstrating consistently\nstronger performance. We then apply GDEs to six key problems in computational\nbiology: learning representations of cell populations from lineage-tracing data\n(150K cells), predicting perturbation effects on single-cell transcriptomes (1M\ncells), predicting perturbation effects on cellular phenotypes (20M single-cell\nimages), modeling tissue-specific DNA methylation patterns (253M sequences),\ndesigning synthetic yeast promoters (34M sequences), and spatiotemporal\nmodeling of viral protein sequences (1M sequences).", "published": "2025-05-23 17:58:57", "link": "http://arxiv.org/abs/2505.18150v1", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scalable Policy Maximization Under Network Interference", "abstract": "Many interventions, such as vaccines in clinical trials or coupons in online\nmarketplaces, must be assigned sequentially without full knowledge of their\neffects. Multi-armed bandit algorithms have proven successful in such settings.\nHowever, standard independence assumptions fail when the treatment status of\none individual impacts the outcomes of others, a phenomenon known as\ninterference. We study optimal-policy learning under interference on a dynamic\nnetwork. Existing approaches to this problem require repeated observations of\nthe same fixed network and struggle to scale in sample size beyond as few as\nfifteen connected units -- both limit applications. We show that under common\nassumptions on the structure of interference, rewards become linear. This\nenables us to develop a scalable Thompson sampling algorithm that maximizes\npolicy impact when a new $n$-node network is observed each round. We prove a\nBayesian regret bound that is sublinear in $n$ and the number of rounds.\nSimulation experiments show that our algorithm learns quickly and outperforms\nexisting methods. The results close a key scalability gap between causal\ninference methods for interference and practical bandit algorithms, enabling\npolicy optimization in large-scale networked systems.", "published": "2025-05-23 17:19:12", "link": "http://arxiv.org/abs/2505.18118v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization", "abstract": "Training quantized neural networks requires addressing the non-differentiable\nand discrete nature of the underlying optimization problem. To tackle this\nchallenge, the straight-through estimator (STE) has become the most widely\nadopted heuristic, allowing backpropagation through discrete operations by\nintroducing surrogate gradients. However, its theoretical properties remain\nlargely unexplored, with few existing works simplifying the analysis by\nassuming an infinite amount of training data. In contrast, this work presents\nthe first finite-sample analysis of STE in the context of neural network\nquantization. Our theoretical results highlight the critical role of sample\nsize in the success of STE, a key insight absent from existing studies.\nSpecifically, by analyzing the quantization-aware training of a two-layer\nneural network with binary weights and activations, we derive the sample\ncomplexity bound in terms of the data dimensionality that guarantees the\nconvergence of STE-based optimization to the global minimum. Moreover, in the\npresence of label noises, we uncover an intriguing recurrence property of\nSTE-gradient method, where the iterate repeatedly escape from and return to the\noptimal binary weights. Our analysis leverages tools from compressed sensing\nand dynamical systems theory.", "published": "2025-05-23 17:11:22", "link": "http://arxiv.org/abs/2505.18113v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Dynamic Dual Buffer with Divide-and-Conquer Strategy for Online Continual Learning", "abstract": "Online Continual Learning (OCL) presents a complex learning environment in\nwhich new data arrives in a batch-to-batch online format, and the risk of\ncatastrophic forgetting can significantly impair model efficacy. In this study,\nwe address OCL by introducing an innovative memory framework that incorporates\na short-term memory system to retain dynamic information and a long-term memory\nsystem to archive enduring knowledge. Specifically, the long-term memory system\ncomprises a collection of sub-memory buffers, each linked to a cluster\nprototype and designed to retain data samples from distinct categories. We\npropose a novel $K$-means-based sample selection method to identify cluster\nprototypes for each encountered category. To safeguard essential and critical\nsamples, we introduce a novel memory optimisation strategy that selectively\nretains samples in the appropriate sub-memory buffer by evaluating each cluster\nprototype against incoming samples through an optimal transportation mechanism.\nThis approach specifically promotes each sub-memory buffer to retain data\nsamples that exhibit significant discrepancies from the corresponding cluster\nprototype, thereby ensuring the preservation of semantically rich information.\nIn addition, we propose a novel Divide-and-Conquer (DAC) approach that\nformulates the memory updating as an optimisation problem and divides it into\nseveral subproblems. As a result, the proposed DAC approach can solve these\nsubproblems separately and thus can significantly reduce computations of the\nproposed memory updating process. We conduct a series of experiments across\nstandard and imbalanced learning settings, and the empirical findings indicate\nthat the proposed memory framework achieves state-of-the-art performance in\nboth learning contexts.", "published": "2025-05-23 16:57:04", "link": "http://arxiv.org/abs/2505.18101v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Early-Exit Graph Neural Networks", "abstract": "Early-exit mechanisms allow deep neural networks to halt inference as soon as\nclassification confidence is high enough, adaptively trading depth for\nconfidence, and thereby cutting latency and energy on easy inputs while\nretaining full-depth accuracy for harder ones. Similarly, adding early exit\nmechanisms to Graph Neural Networks (GNNs), the go-to models for\ngraph-structured data, allows for dynamic trading depth for confidence on\nsimple graphs while maintaining full-depth accuracy on harder and more complex\ngraphs to capture intricate relationships. Although early exits have proven\neffective across various deep learning domains, their potential within GNNs in\nscenarios that require deep architectures while resisting over-smoothing and\nover-squashing remains largely unexplored. We unlock that potential by first\nintroducing Symmetric-Anti-Symmetric Graph Neural Networks (SAS-GNN), whose\nsymmetry-based inductive biases mitigate these issues and yield stable\nintermediate representations that can be useful to allow early exiting in GNNs.\nBuilding on this backbone, we present Early-Exit Graph Neural Networks\n(EEGNNs), which append confidence-aware exit heads that allow on-the-fly\ntermination of propagation based on each node or the entire graph. Experiments\nshow that EEGNNs preserve robust performance as depth grows and deliver\ncompetitive accuracy on heterophilic and long-range benchmarks, matching\nattention-based and asynchronous message-passing models while substantially\nreducing computation and latency. We plan to release the code to reproduce our\nexperiments.", "published": "2025-05-23 16:45:14", "link": "http://arxiv.org/abs/2505.18088v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "What Do You Need for Diverse Trajectory Stitching in Diffusion Planning?", "abstract": "In planning, stitching is an ability of algorithms to piece together\nsub-trajectories of data they are trained on to generate new and diverse\nbehaviours. While stitching is historically a strength of offline reinforcement\nlearning, recent generative behavioural cloning (BC) methods have also shown\nproficiency at stitching. However, the main factors behind this are poorly\nunderstood, hindering the development of new algorithms that can reliably\nstitch. Focusing on diffusion planners trained via BC, we find two properties\nare needed to compose: \\emph{positional equivariance} and \\emph{local\nreceptiveness}. We use these two properties to explain architecture, data, and\ninference choices in existing generative BC methods based on diffusion\nplanning, including replanning frequency, data augmentation, and data scaling.\nExperimental comparisions show that (1) while locality is more important than\npositional equivariance in creating a diffusion planner capable of composition,\nboth are crucial (2) enabling these properties through relatively simple\narchitecture choices can be competitive with more computationally expensive\nmethods such as replanning or scaling data, and (3) simple inpainting-based\nguidance can guide architecturally compositional models to enable\ngeneralization in goal-conditioned settings.", "published": "2025-05-23 16:41:08", "link": "http://arxiv.org/abs/2505.18083v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "An Iterative Framework for Generative Backmapping of Coarse Grained Proteins", "abstract": "The techniques of data-driven backmapping from coarse-grained (CG) to\nfine-grained (FG) representation often struggle with accuracy, unstable\ntraining, and physical realism, especially when applied to complex systems such\nas proteins. In this work, we introduce a novel iterative framework by using\nconditional Variational Autoencoders and graph-based neural networks,\nspecifically designed to tackle the challenges associated with such large-scale\nbiomolecules. Our method enables stepwise refinement from CG beads to full\natomistic details. We outline the theory of iterative generative backmapping\nand demonstrate via numerical experiments the advantages of multistep schemes\nby applying them to proteins of vastly different structures with very coarse\nrepresentations. This multistep approach not only improves the accuracy of\nreconstructions but also makes the training process more computationally\nefficient for proteins with ultra-CG representations.", "published": "2025-05-23 16:40:25", "link": "http://arxiv.org/abs/2505.18082v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bayesian Deep Learning for Discrete Choice", "abstract": "Discrete choice models (DCMs) are used to analyze individual decision-making\nin contexts such as transportation choices, political elections, and consumer\npreferences. DCMs play a central role in applied econometrics by enabling\ninference on key economic variables, such as marginal rates of substitution,\nrather than focusing solely on predicting choices on new unlabeled data.\nHowever, while traditional DCMs offer high interpretability and support for\npoint and interval estimation of economic quantities, these models often\nunderperform in predictive tasks compared to deep learning (DL) models. Despite\ntheir predictive advantages, DL models remain largely underutilized in discrete\nchoice due to concerns about their lack of interpretability, unstable parameter\nestimates, and the absence of established methods for uncertainty\nquantification. Here, we introduce a deep learning model architecture\nspecifically designed to integrate with approximate Bayesian inference methods,\nsuch as Stochastic Gradient Langevin Dynamics (SGLD). Our proposed model\ncollapses to behaviorally informed hypotheses when data is limited, mitigating\noverfitting and instability in underspecified settings while retaining the\nflexibility to capture complex nonlinear relationships when sufficient data is\navailable. We demonstrate our approach using SGLD through a Monte Carlo\nsimulation study, evaluating both predictive metrics--such as out-of-sample\nbalanced accuracy--and inferential metrics--such as empirical coverage for\nmarginal rates of substitution interval estimates. Additionally, we present\nresults from two empirical case studies: one using revealed mode choice data in\nNYC, and the other based on the widely used Swiss train choice stated\npreference data.", "published": "2025-05-23 16:33:47", "link": "http://arxiv.org/abs/2505.18077v1", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Emergence of Hebbian Dynamics in Regularized Non-Local Learners", "abstract": "Stochastic Gradient Descent (SGD) has emerged as a remarkably effective\nlearning algorithm, underpinning nearly all state-of-the-art machine learning\nmodels, from large language models to autonomous vehicles. Despite its\npractical success, SGD appears fundamentally distinct from biological learning\nmechanisms. It is widely believed that the biological brain can not implement\ngradient descent because it is nonlocal, and we have found little (if any)\nexperimental evidence for it. In contrast, the brain is widely thought to learn\nvia local Hebbian learning principles, which have been seen as incompatible\nwith gradient descent. In this paper, we establish a theoretical and empirical\nconnection between the learning signals of neural networks trained using SGD\nwith weight decay and those trained with Hebbian learning near convergence. We\nshow that SGD with regularization can appear to learn according to a Hebbian\nrule, and SGD with injected noise according to an anti-Hebbian rule. We also\nprovide empirical evidence that Hebbian learning properties can emerge in a\nnetwork with weight decay from virtually any learning rule--even random ones.\nThese results may bridge a long-standing gap between artificial and biological\nlearning, revealing Hebbian properties as an epiphenomenon of deeper\noptimization principles and cautioning against interpreting their presence in\nneural data as evidence against more complex hetero-synaptic mechanisms.", "published": "2025-05-23 16:16:09", "link": "http://arxiv.org/abs/2505.18069v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Reward Model Generalization for Compute-Aware Test-Time Reasoning", "abstract": "External test-time reasoning enhances large language models (LLMs) by\ndecoupling generation and selection. At inference time, the model generates\nmultiple reasoning paths, and an auxiliary process reward model (PRM) is used\nto score and select the best one. A central challenge in this setting is\ntest-time compute optimality (TCO), i.e., how to maximize answer accuracy under\na fixed inference budget. In this work, we establish a theoretical framework to\nanalyze how the generalization error of the PRM affects compute efficiency and\nreasoning performance. Leveraging PAC-Bayes theory, we derive generalization\nbounds and show that a lower generalization error of PRM leads to fewer samples\nrequired to find correct answers. Motivated by this analysis, we propose\nCompute-Aware Tree Search (CATS), an actor-critic framework that dynamically\ncontrols search behavior. The actor outputs sampling hyperparameters based on\nreward distributions and sparsity statistics, while the critic estimates their\nutility to guide budget allocation. Experiments on the MATH and AIME benchmarks\nwith various LLMs and PRMs demonstrate that CATS consistently outperforms other\nexternal TTS methods, validating our theoretical predictions.", "published": "2025-05-23 16:12:12", "link": "http://arxiv.org/abs/2505.18065v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Asymptotically optimal regret in communicating Markov decision processes", "abstract": "In this paper, we present a learning algorithm that achieves asymptotically\noptimal regret for Markov decision processes in average reward under a\ncommunicating assumption. That is, given a communicating Markov decision\nprocess $M$, our algorithm has regret $K(M) \\log(T) + \\mathrm{o}(\\log(T))$\nwhere $T$ is the number of learning steps and $K(M)$ is the best possible\nconstant. This algorithm works by explicitly tracking the constant $K(M)$ to\nlearn optimally, then balances the trade-off between exploration (playing\nsub-optimally to gain information), co-exploration (playing optimally to gain\ninformation) and exploitation (playing optimally to score maximally). We\nfurther show that the function $K(M)$ is discontinuous, which is a consequence\nchallenge for our approach. To that end, we describe a regularization mechanism\nto estimate $K(M)$ with arbitrary precision from empirical data.", "published": "2025-05-23 16:11:39", "link": "http://arxiv.org/abs/2505.18064v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning with Restricted Boltzmann Machines: Asymptotics of AMP and GD in High Dimensions", "abstract": "The Restricted Boltzmann Machine (RBM) is one of the simplest generative\nneural networks capable of learning input distributions. Despite its\nsimplicity, the analysis of its performance in learning from the training data\nis only well understood in cases that essentially reduce to singular value\ndecomposition of the data. Here, we consider the limit of a large dimension of\nthe input space and a constant number of hidden units. In this limit, we\nsimplify the standard RBM training objective into a form that is equivalent to\nthe multi-index model with non-separable regularization. This opens a path to\nanalyze training of the RBM using methods that are established for multi-index\nmodels, such as Approximate Message Passing (AMP) and its state evolution, and\nthe analysis of Gradient Descent (GD) via the dynamical mean-field theory. We\nthen give rigorous asymptotics of the training dynamics of RBM on data\ngenerated by the spiked covariance model as a prototype of a structure suitable\nfor unsupervised learning. We show in particular that RBM reaches the optimal\ncomputational weak recovery threshold, aligning with the BBP transition, in the\nspiked covariance model.", "published": "2025-05-23 15:51:46", "link": "http://arxiv.org/abs/2505.18046v1", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improved Algorithms for Overlapping and Robust Clustering of Edge-Colored Hypergraphs: An LP-Based Combinatorial Approach", "abstract": "Clustering is a fundamental task in both machine learning and data mining.\nAmong various methods, edge-colored clustering (ECC) has emerged as a useful\napproach for handling categorical data. Given a hypergraph with (hyper)edges\nlabeled by colors, ECC aims to assign vertex colors to minimize the number of\nedges where the vertex color differs from the edge's color. However,\ntraditional ECC has inherent limitations, as it enforces a nonoverlapping and\nexhaustive clustering. To tackle these limitations, three versions of ECC have\nbeen studied: Local ECC and Global ECC, which allow overlapping clusters, and\nRobust ECC, which accounts for vertex outliers. For these problems, both linear\nprogramming (LP) rounding algorithms and greedy combinatorial algorithms have\nbeen proposed. While these LP-rounding algorithms provide high-quality\nsolutions, they demand substantial computation time; the greedy algorithms, on\nthe other hand, run very fast but often compromise solution quality. In this\npaper, we present an algorithmic framework that combines the strengths of LP\nwith the computational efficiency of combinatorial algorithms. Both\nexperimental and theoretical analyses show that our algorithms efficiently\nproduce high-quality solutions for all three problems: Local, Global, and\nRobust ECC. We complement our algorithmic contributions with\ncomplexity-theoretic inapproximability results and integrality gap bounds,\nwhich suggest that significant theoretical improvements are unlikely. Our\nresults also answer two open questions previously raised in the literature.", "published": "2025-05-23 15:46:16", "link": "http://arxiv.org/abs/2505.18043v1", "categories": ["cs.LG", "cs.DB", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Time to Spike? Understanding the Representational Power of Spiking Neural Networks in Discrete Time", "abstract": "Recent years have seen significant progress in developing spiking neural\nnetworks (SNNs) as a potential solution to the energy challenges posed by\nconventional artificial neural networks (ANNs). However, our theoretical\nunderstanding of SNNs remains relatively limited compared to the ever-growing\nbody of literature on ANNs. In this paper, we study a discrete-time model of\nSNNs based on leaky integrate-and-fire (LIF) neurons, referred to as\ndiscrete-time LIF-SNNs, a widely used framework that still lacks solid\ntheoretical foundations. We demonstrate that discrete-time LIF-SNNs with static\ninputs and outputs realize piecewise constant functions defined on polyhedral\nregions, and more importantly, we quantify the network size required to\napproximate continuous functions. Moreover, we investigate the impact of\nlatency (number of time steps) and depth (number of layers) on the complexity\nof the input space partitioning induced by discrete-time LIF-SNNs. Our analysis\nhighlights the importance of latency and contrasts these networks with ANNs\nemploying piecewise linear activation functions. Finally, we present numerical\nexperiments to support our theoretical findings.", "published": "2025-05-23 15:28:00", "link": "http://arxiv.org/abs/2505.18023v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Strictly Constrained Generative Modeling via Split Augmented Langevin Sampling", "abstract": "Deep generative models hold great promise for representing complex physical\nsystems, but their deployment is currently limited by the lack of guarantees on\nthe physical plausibility of the generated outputs. Ensuring that known\nphysical constraints are enforced is therefore critical when applying\ngenerative models to scientific and engineering problems. We address this\nlimitation by developing a principled framework for sampling from a target\ndistribution while rigorously satisfying physical constraints. Leveraging the\nvariational formulation of Langevin dynamics, we propose Split Augmented\nLangevin (SAL), a novel primal-dual sampling algorithm that enforces\nconstraints progressively through variable splitting, with convergence\nguarantees. While the method is developed theoretically for Langevin dynamics,\nwe demonstrate its effective applicability to diffusion models. In particular,\nwe use constrained diffusion models to generate physical fields satisfying\nenergy and mass conservation laws. We apply our method to diffusion-based data\nassimilation on a complex physical system, where enforcing physical constraints\nsubstantially improves both forecast accuracy and the preservation of critical\nconserved quantities. We also demonstrate the potential of SAL for challenging\nfeasibility problems in optimal control.", "published": "2025-05-23 15:21:10", "link": "http://arxiv.org/abs/2505.18017v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Operator Neural Network Model Predictive Control", "abstract": "In this paper, we consider the design of model predictive control (MPC)\nalgorithms based on deep operator neural networks (DeepONets). These neural\nnetworks are capable of accurately approximating real and complex valued\nsolutions of continuous time nonlinear systems without relying on recurrent\narchitectures. The DeepONet architecture is made up of two feedforward neural\nnetworks: the branch network, which encodes the input function space, and the\ntrunk network, which represents dependencies on temporal variables or initial\nconditions. Utilizing the original DeepONet architecture as a predictor within\nMPC for Multi Input Multi Output (MIMO) systems requires multiple branch\nnetworks, to generate multi output predictions, one for each input. Moreover,\nto predict multiple time steps into the future, the network has to be evaluated\nmultiple times. Motivated by this, we introduce a multi step DeepONet\n(MS-DeepONet) architecture that computes in one shot multi step predictions of\nsystem outputs from multi step input sequences, which is better suited for MPC.\nWe prove that the MS DeepONet is a universal approximator in terms of multi\nstep sequence prediction. Additionally, we develop automated hyper parameter\nselection strategies and implement MPC frameworks using both the standard\nDeepONet and the proposed MS DeepONet architectures in PyTorch. The\nimplementation is publicly available on GitHub. Simulation results demonstrate\nthat MS-DeepONet consistently outperforms the standard DeepONet in learning and\npredictive control tasks across several nonlinear benchmark systems: the van\nder Pol oscillator, the quadruple tank process, and a cart pendulum unstable\nsystem, where it successfully learns and executes multiple swing up and\nstabilization policies.", "published": "2025-05-23 15:13:19", "link": "http://arxiv.org/abs/2505.18008v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Distances for Markov chains from sample streams", "abstract": "Bisimulation metrics are powerful tools for measuring similarities between\nstochastic processes, and specifically Markov chains. Recent advances have\nuncovered that bisimulation metrics are, in fact, optimal-transport distances,\nwhich has enabled the development of fast algorithms for computing such metrics\nwith provable accuracy and runtime guarantees. However, these recent methods,\nas well as all previously known methods, assume full knowledge of the\ntransition dynamics. This is often an impractical assumption in most real-world\nscenarios, where typically only sample trajectories are available. In this\nwork, we propose a stochastic optimization method that addresses this\nlimitation and estimates bisimulation metrics based on sample access, without\nrequiring explicit transition models. Our approach is derived from a new linear\nprogramming (LP) formulation of bisimulation metrics, which we solve using a\nstochastic primal-dual optimization method. We provide theoretical guarantees\non the sample complexity of the algorithm and validate its effectiveness\nthrough a series of empirical evaluations.", "published": "2025-05-23 15:09:04", "link": "http://arxiv.org/abs/2505.18005v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective", "abstract": "Graph anomaly detection aims to identify unusual patterns in graph-based\ndata, with wide applications in fields such as web security and financial fraud\ndetection. Existing methods typically rely on contrastive learning, assuming\nthat a lower similarity between a node and its local subgraph indicates\nabnormality. However, these approaches overlook a crucial limitation: the\npresence of interfering edges invalidates this assumption, since it introduces\ndisruptive noise that compromises the contrastive learning process.\nConsequently, this limitation impairs the ability to effectively learn\nmeaningful representations of normal patterns, leading to suboptimal detection\nperformance. To address this issue, we propose a Clean-View Enhanced Graph\nAnomaly Detection framework (CVGAD), which includes a multi-scale anomaly\nawareness module to identify key sources of interference in the contrastive\nlearning process. Moreover, to mitigate bias from the one-step edge removal\nprocess, we introduce a novel progressive purification module. This module\nincrementally refines the graph by iteratively identifying and removing\ninterfering edges, thereby enhancing model performance. Extensive experiments\non five benchmark datasets validate the effectiveness of our approach.", "published": "2025-05-23 15:05:56", "link": "http://arxiv.org/abs/2505.18002v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Anytime-valid, Bayes-assisted,Prediction-Powered Inference", "abstract": "Given a large pool of unlabelled data and a smaller amount of labels,\nprediction-powered inference (PPI) leverages machine learning predictions to\nincrease the statistical efficiency of standard confidence interval procedures\nbased solely on labelled data, while preserving their fixed-time validity.\n  In this paper, we extend the PPI framework to the sequential setting, where\nlabelled and unlabelled datasets grow over time.\n  Exploiting Ville's inequality and the method of mixtures, we propose\nprediction-powered confidence sequence procedures that are valid uniformly over\ntime and naturally accommodate prior knowledge on the quality of the\npredictions to further boost efficiency.\n  We carefully illustrate the design choices behind our method and demonstrate\nits effectiveness in real and synthetic examples.", "published": "2025-05-23 15:05:49", "link": "http://arxiv.org/abs/2505.18000v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "New Tight Bounds for SGD without Variance Assumption: A Computer-Aided Lyapunov Analysis", "abstract": "The analysis of Stochastic Gradient Descent (SGD) often relies on making some\nassumption on the variance of the stochastic gradients, which is usually not\nsatisfied or difficult to verify in practice. This paper contributes to a\nrecent line of works which attempt to provide guarantees without making any\nvariance assumption, leveraging only the (strong) convexity and smoothness of\nthe loss functions. In this context, we prove new theoretical bounds derived\nfrom the monotonicity of a simple Lyapunov energy, improving the current\nstate-of-the-art and extending their validity to larger step-sizes. Our\ntheoretical analysis is backed by a Performance Estimation Problem analysis,\nwhich allows us to claim that, empirically, the bias term in our bounds is\ntight within our framework.", "published": "2025-05-23 14:34:46", "link": "http://arxiv.org/abs/2505.17965v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "A Principled Bayesian Framework for Training Binary and Spiking Neural Networks", "abstract": "We propose a Bayesian framework for training binary and spiking neural\nnetworks that achieves state-of-the-art performance without normalisation\nlayers. Unlike commonly used surrogate gradient methods -- often heuristic and\nsensitive to hyperparameter choices -- our approach is grounded in a\nprobabilistic model of noisy binary networks, enabling fully end-to-end\ngradient-based optimisation. We introduce importance-weighted straight-through\n(IW-ST) estimators, a unified class generalising straight-through and\nrelaxation-based estimators. We characterise the bias-variance trade-off in\nthis family and derive a bias-minimising objective implemented via an auxiliary\nloss. Building on this, we introduce Spiking Bayesian Neural Networks (SBNNs),\na variational inference framework that uses posterior noise to train Binary and\nSpiking Neural Networks with IW-ST. This Bayesian approach minimises gradient\nbias, regularises parameters, and introduces dropout-like noise. By linking\nlow-bias conditions, vanishing gradients, and the KL term, we enable training\nof deep residual networks without normalisation. Experiments on CIFAR-10, DVS\nGesture, and SHD show our method matches or exceeds existing approaches without\nnormalisation or hand-tuned gradients.", "published": "2025-05-23 14:33:20", "link": "http://arxiv.org/abs/2505.17962v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "VeriThinker: Learning to Verify Makes Reasoning Model Efficient", "abstract": "Large Reasoning Models (LRMs) excel at complex tasks using Chain-of-Thought\n(CoT) reasoning. However, their tendency to overthinking leads to unnecessarily\nlengthy reasoning chains, dramatically increasing inference costs. To mitigate\nthis issue, we introduce VeriThinker, a novel approach for CoT compression.\nUnlike conventional methods that fine-tune LRMs directly on the original\nreasoning task using synthetic concise CoT data, we innovatively fine-tune the\nmodel solely through an auxiliary verification task. By training LRMs to\naccurately verify the correctness of CoT solutions, the LRMs inherently become\nmore discerning about the necessity of subsequent self-reflection steps,\nthereby effectively suppressing overthinking. Extensive experiments validate\nthat VeriThinker substantially reduces reasoning chain lengths while\nmaintaining or even slightly improving accuracy. When applied to\nDeepSeek-R1-Distill-Qwen-7B, our approach reduces reasoning tokens on MATH500\nfrom 3790 to 2125 while improving accuracy by 0.8% (94.0% to 94.8%), and on\nAIME25, tokens decrease from 14321 to 10287 with a 2.1% accuracy gain (38.7% to\n40.8%). Additionally, our experiments demonstrate that VeriThinker can also be\nzero-shot generalized to speculative reasoning. Code is available at\nhttps://github.com/czg1225/VeriThinker", "published": "2025-05-23 14:17:56", "link": "http://arxiv.org/abs/2505.17941v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Directed Semi-Simplicial Learning with Applications to Brain Activity Decoding", "abstract": "Graph Neural Networks (GNNs) excel at learning from pairwise interactions but\noften overlook multi-way and hierarchical relationships. Topological Deep\nLearning (TDL) addresses this limitation by leveraging combinatorial\ntopological spaces. However, existing TDL models are restricted to undirected\nsettings and fail to capture the higher-order directed patterns prevalent in\nmany complex systems, e.g., brain networks, where such interactions are both\nabundant and functionally significant. To fill this gap, we introduce\nSemi-Simplicial Neural Networks (SSNs), a principled class of TDL models that\noperate on semi-simplicial sets -- combinatorial structures that encode\ndirected higher-order motifs and their directional relationships. To enhance\nscalability, we propose Routing-SSNs, which dynamically select the most\ninformative relations in a learnable manner. We prove that SSNs are strictly\nmore expressive than standard graph and TDL models. We then introduce a new\nprincipled framework for brain dynamics representation learning, grounded in\nthe ability of SSNs to provably recover topological descriptors shown to\nsuccessfully characterize brain activity. Empirically, SSNs achieve\nstate-of-the-art performance on brain dynamics classification tasks,\noutperforming the second-best model by up to 27%, and message passing GNNs by\nup to 50% in accuracy. Our results highlight the potential of principled\ntopological models for learning from structured brain data, establishing a\nunique real-world case study for TDL. We also test SSNs on standard node\nclassification and edge regression tasks, showing competitive performance. We\nwill make the code and data publicly available.", "published": "2025-05-23 14:15:44", "link": "http://arxiv.org/abs/2505.17939v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Selection Mechanisms for Sequence Modeling using Linear State Space Models", "abstract": "Recent advancements in language modeling tasks have been driven by\narchitectures such as Transformers and, more recently, by Selective State Space\nModels (SSMs). In this paper, we introduce an alternative selection mechanism\ninspired by control theory methodologies. Specifically, we propose a novel\nresidual generator for selection, drawing an analogy to fault detection\nstrategies in Linear Time-Invariant (LTI) systems. Unlike Mamba, which utilizes\nLinear Time-Varying (LTV) systems, our approach combines multiple LTI systems,\npreserving their beneficial properties during training while achieving\ncomparable selectivity. To evaluate the effectiveness of the proposed\narchitecture, we test its performance on synthetic tasks. While these tasks are\nnot inherently critical, they serve as benchmarks to test the selectivity\nproperties of different cores architecture. This work highlights the potential\nof integrating theoretical insights with experimental advancements, offering a\ncomplementary perspective to deep learning innovations at the intersection of\ncontrol theory and machine learning.", "published": "2025-05-23 14:08:56", "link": "http://arxiv.org/abs/2505.17932v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Predicting Length of Stay in Neurological ICU Patients Using Classical Machine Learning and Neural Network Models: A Benchmark Study on MIMIC-IV", "abstract": "Intensive care unit (ICU) is a crucial hospital department that handles\nlife-threatening cases. Nowadays machine learning (ML) is being leveraged in\nhealthcare ubiquitously. In recent years, management of ICU became one of the\nmost significant parts of the hospital functionality (largely but not only due\nto the worldwide COVID-19 pandemic). This study explores multiple ML approaches\nfor predicting LOS in ICU specifically for the patients with neurological\ndiseases based on the MIMIC-IV dataset. The evaluated models include classic ML\nalgorithms (K-Nearest Neighbors, Random Forest, XGBoost and CatBoost) and\nNeural Networks (LSTM, BERT and Temporal Fusion Transformer). Given that LOS\nprediction is often framed as a classification task, this study categorizes LOS\ninto three groups: less than two days, less than a week, and a week or more. As\nthe first ML-based approach targeting LOS prediction for neurological disorder\npatients, this study does not aim to outperform existing methods but rather to\nassess their effectiveness in this specific context. The findings provide\ninsights into the applicability of ML techniques for improving ICU resource\nmanagement and patient care. According to the results, Random Forest model\nproved to outperform others on static, achieving an accuracy of 0.68, a\nprecision of 0.68, a recall of 0.68, and F1-score of 0.67. While BERT model\noutperformed LSTM model on time-series data with an accuracy of 0.80, a\nprecision of 0.80, a recall of 0.80 and F1-score 0.80.", "published": "2025-05-23 14:06:42", "link": "http://arxiv.org/abs/2505.17929v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KITINet: Kinetics Theory Inspired Network Architectures with PDE Simulation Approaches", "abstract": "Despite the widely recognized success of residual connections in modern\nneural networks, their design principles remain largely heuristic. This paper\nintroduces KITINet (Kinetics Theory Inspired Network), a novel architecture\nthat reinterprets feature propagation through the lens of non-equilibrium\nparticle dynamics and partial differential equation (PDE) simulation. At its\ncore, we propose a residual module that models feature updates as the\nstochastic evolution of a particle system, numerically simulated via a\ndiscretized solver for the Boltzmann transport equation (BTE). This formulation\nmimics particle collisions and energy exchange, enabling adaptive feature\nrefinement via physics-informed interactions. Additionally, we reveal that this\nmechanism induces network parameter condensation during training, where\nparameters progressively concentrate into a sparse subset of dominant channels.\nExperiments on scientific computation (PDE operator), image classification\n(CIFAR-10/100), and text classification (IMDb/SNLI) show consistent\nimprovements over classic network baselines, with negligible increase of FLOPs.", "published": "2025-05-23 13:58:29", "link": "http://arxiv.org/abs/2505.17919v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LLM Meeting Decision Trees on Tabular Data", "abstract": "Tabular data have been playing a vital role in diverse real-world fields,\nincluding healthcare, finance, etc. With the recent success of Large Language\nModels (LLMs), early explorations of extending LLMs to the domain of tabular\ndata have been developed. Most of these LLM-based methods typically first\nserialize tabular data into natural language descriptions, and then tune LLMs\nor directly infer on these serialized data. However, these methods suffer from\ntwo key inherent issues: (i) data perspective: existing data serialization\nmethods lack universal applicability for structured tabular data, and may pose\nprivacy risks through direct textual exposure, and (ii) model perspective: LLM\nfine-tuning methods struggle with tabular data, and in-context learning\nscalability is bottle-necked by input length constraints (suitable for few-shot\nlearning). This work explores a novel direction of integrating LLMs into\ntabular data throughough logical decision tree rules as intermediaries,\nproposes a decision tree enhancer with LLM-derived rule for tabular prediction,\nDeLTa. The proposed DeLTa avoids tabular data serialization, and can be applied\nto full data learning setting without LLM fine-tuning. Specifically, we\nleverage the reasoning ability of LLMs to redesign an improved rule given a set\nof decision tree rules. Furthermore, we provide a calibration method for\noriginal decision trees via new generated rule by LLM, which approximates the\nerror correction vector to steer the original decision tree predictions in the\ndirection of ``errors'' reducing. Finally, extensive experiments on diverse\ntabular benchmarks show that our method achieves state-of-the-art performance.", "published": "2025-05-23 13:57:53", "link": "http://arxiv.org/abs/2505.17918v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model", "abstract": "We propose a novel method, termed the M-learner, for estimating heterogeneous\nindirect and total treatment effects and identifying relevant subgroups within\na mediation framework. The procedure comprises four key steps. First, we\ncompute individual-level conditional average indirect/total treatment effect\nSecond, we construct a distance matrix based on pairwise differences. Third, we\napply tSNE to project this matrix into a low-dimensional Euclidean space,\nfollowed by K-means clustering to identify subgroup structures. Finally, we\ncalibrate and refine the clusters using a threshold-based procedure to\ndetermine the optimal configuration. To the best of our knowledge, this is the\nfirst approach specifically designed to capture treatment effect heterogeneity\nin the presence of mediation. Experimental results validate the robustness and\neffectiveness of the proposed framework. Application to the real-world Jobs II\ndataset highlights the broad adaptability and potential applicability of our\nmethod.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB.", "published": "2025-05-23 13:57:23", "link": "http://arxiv.org/abs/2505.17917v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Flexible MOF Generation with Torsion-Aware Flow Matching", "abstract": "Designing metal-organic frameworks (MOFs) with novel chemistries is a\nlong-standing challenge due to their large combinatorial space and the complex\n3D arrangements of building blocks. While recent deep generative models have\nenabled scalable MOF generation, they assume (1) a fixed set of building blocks\nand (2) known ground-truth local block-wise 3D coordinates. However, this\nlimits their ability to (1) design novel MOFs and (2) generate the structure\nusing novel building blocks. We propose a two-stage de novo MOF generation\nframework that overcomes these limitations by modeling both chemical and\ngeometric degrees of freedom. First, we train a SMILES-based autoregressive\nmodel to generate novel metal and organic building blocks, paired with\ncheminformatics for 3D structure initialization. Second, we introduce a\nflow-matching model that predicts translations, rotations, and torsional angles\nto assemble flexible blocks into valid 3D frameworks. Our experiments\ndemonstrate improved reconstruction accuracy, the generation of valid, novel,\nand unique MOFs, and the ability of our model to create novel building blocks.", "published": "2025-05-23 13:56:30", "link": "http://arxiv.org/abs/2505.17914v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Function Forms of Simple ReLU Networks with Random Hidden Weights", "abstract": "We investigate the function space dynamics of a two-layer ReLU neural network\nin the infinite-width limit, highlighting the Fisher information matrix (FIM)'s\nrole in steering learning. Extending seminal works on approximate\neigendecomposition of the FIM, we derive the asymptotic behavior of basis\nfunctions ($f_v(x) = X^{\\top} v $) for four groups of approximate eigenvectors,\nshowing their convergence to distinct function forms. These functions,\nprioritized by gradient descent, exhibit FIM-induced inner products that\napproximate orthogonality in the function space, forging a novel connection\nbetween parameter and function spaces. Simulations validate the accuracy of\nthese theoretical approximations, confirming their practical relevance. By\nrefining the function space inner product's role, we advance the theoretical\nframework for ReLU networks, illuminating their optimization and expressivity.\nOverall, this work offers a robust foundation for understanding wide neural\nnetworks and enhances insights into scalable deep learning architectures,\npaving the way for improved design and analysis of neural networks.", "published": "2025-05-23 13:53:02", "link": "http://arxiv.org/abs/2505.17907v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Evolving Machine Learning: A Survey", "abstract": "In an era defined by rapid data evolution, traditional machine learning (ML)\nmodels often fall short in adapting to dynamic environments. Evolving Machine\nLearning (EML) has emerged as a critical paradigm, enabling continuous learning\nand adaptation in real-time data streams. This survey presents a comprehensive\nanalysis of EML, focusing on five core challenges: data drift, concept drift,\ncatastrophic forgetting, skewed learning, and network adaptation. We\nsystematically review over 120 studies, categorizing state-of-the-art methods\nacross supervised, unsupervised, and semi-supervised approaches. The survey\nexplores diverse evaluation metrics, benchmark datasets, and real-world\napplications, offering a comparative lens on the effectiveness and limitations\nof current techniques. Additionally, we highlight the growing role of adaptive\nneural architectures, meta-learning, and ensemble strategies in addressing\nevolving data complexities. By synthesizing insights from recent literature,\nthis work not only maps the current landscape of EML but also identifies\ncritical gaps and opportunities for future research. Our findings aim to guide\nresearchers and practitioners in developing robust, ethical, and scalable EML\nsystems for real-world deployment.", "published": "2025-05-23 13:50:02", "link": "http://arxiv.org/abs/2505.17902v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Universal Domain Adaptation Benchmark for Time Series Data Representation", "abstract": "Deep learning models have significantly improved the ability to detect\nnovelties in time series (TS) data. This success is attributed to their strong\nrepresentation capabilities. However, due to the inherent variability in TS\ndata, these models often struggle with generalization and robustness. To\naddress this, a common approach is to perform Unsupervised Domain Adaptation,\nparticularly Universal Domain Adaptation (UniDA), to handle domain shifts and\nemerging novel classes. While extensively studied in computer vision, UniDA\nremains underexplored for TS data. This work provides a comprehensive\nimplementation and comparison of state-of-the-art TS backbones in a UniDA\nframework. We propose a reliable protocol to evaluate their robustness and\ngeneralization across different domains. The goal is to provide practitioners\nwith a framework that can be easily extended to incorporate future advancements\nin UniDA and TS architectures. Our results highlight the critical influence of\nbackbone selection in UniDA performance and enable a robustness analysis across\nvarious datasets and architectures.", "published": "2025-05-23 13:47:35", "link": "http://arxiv.org/abs/2505.17899v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Semi-Supervised Multi-Label Feature Selection with Consistent Sparse Graph Learning", "abstract": "In practical domains, high-dimensional data are usually associated with\ndiverse semantic labels, whereas traditional feature selection methods are\ndesigned for single-label data. Moreover, existing multi-label methods\nencounter two main challenges in semi-supervised scenarios: (1). Most\nsemi-supervised methods fail to evaluate the label correlations without enough\nlabeled samples, which are the critical information of multi-label feature\nselection, making label-specific features discarded. (2). The similarity graph\nstructure directly derived from the original feature space is suboptimal for\nmulti-label problems in existing graph-based methods, leading to unreliable\nsoft labels and degraded feature selection performance. To overcome them, we\npropose a consistent sparse graph learning method for multi-label\nsemi-supervised feature selection (SGMFS), which can enhance the feature\nselection performance by maintaining space consistency and learning label\ncorrelations in semi-supervised scenarios. Specifically, for Challenge (1),\nSGMFS learns a low-dimensional and independent label subspace from the\nprojected features, which can compatibly cross multiple labels and effectively\nachieve the label correlations. For Challenge (2), instead of constructing a\nfixed similarity graph for semi-supervised learning, SGMFS thoroughly explores\nthe intrinsic structure of the data by performing sparse reconstruction of\nsamples in both the label space and the learned subspace simultaneously. In\nthis way, the similarity graph can be adaptively learned to maintain the\nconsistency between label space and the learned subspace, which can promote\npropagating proper soft labels for unlabeled samples, facilitating the ultimate\nfeature selection. An effective solution with fast convergence is designed to\noptimize the objective function. Extensive experiments validate the superiority\nof SGMFS.", "published": "2025-05-23 13:25:41", "link": "http://arxiv.org/abs/2505.17875v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models", "abstract": "The advent of universal time series forecasting models has revolutionized\nzero-shot forecasting across diverse domains, yet the critical role of data\ndiversity in training these models remains underexplored. Existing large-scale\ntime series datasets often suffer from inherent biases and imbalanced\ndistributions, leading to suboptimal model performance and generalization. To\naddress this gap, we introduce BLAST, a novel pre-training corpus designed to\nenhance data diversity through a balanced sampling strategy. First, BLAST\nincorporates 321 billion observations from publicly available datasets and\nemploys a comprehensive suite of statistical metrics to characterize time\nseries patterns. Then, to facilitate pattern-oriented sampling, the data is\nimplicitly clustered using grid-based partitioning. Furthermore, by integrating\ngrid sampling and grid mixup techniques, BLAST ensures a balanced and\nrepresentative coverage of diverse patterns. Experimental results demonstrate\nthat models pre-trained on BLAST achieve state-of-the-art performance with a\nfraction of the computational resources and training tokens required by\nexisting methods. Our findings highlight the pivotal role of data diversity in\nimproving both training efficiency and model performance for the universal\nforecasting task.", "published": "2025-05-23 13:20:47", "link": "http://arxiv.org/abs/2505.17871v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Best Group Identification in Multi-Objective Bandits", "abstract": "We introduce the Best Group Identification problem in a multi-objective\nmulti-armed bandit setting, where an agent interacts with groups of arms with\nvector-valued rewards. The performance of a group is determined by an\nefficiency vector which represents the group's best attainable rewards across\ndifferent dimensions. The objective is to identify the set of optimal groups in\nthe fixed-confidence setting. We investigate two key formulations: group Pareto\nset identification, where efficiency vectors of optimal groups are Pareto\noptimal and linear best group identification, where each reward dimension has a\nknown weight and the optimal group maximizes the weighted sum of its efficiency\nvector's entries. For both settings, we propose elimination-based algorithms,\nestablish upper bounds on their sample complexity, and derive lower bounds that\napply to any correct algorithm. Through numerical experiments, we demonstrate\nthe strong empirical performance of the proposed algorithms.", "published": "2025-05-23 13:16:59", "link": "http://arxiv.org/abs/2505.17869v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SpectraLDS: Provable Distillation for Linear Dynamical Systems", "abstract": "We present the first provable method for identifying symmetric linear\ndynamical systems (LDS) with accuracy guarantees that are independent of the\nsystems' state dimension or effective memory. Our approach builds upon recent\nwork that represents symmetric LDSs as convolutions learnable via fixed\nspectral transformations. We show how to invert this representation, thereby\nrecovering an LDS model from its spectral transform and yielding an end-to-end\nconvex optimization procedure. This distillation preserves predictive accuracy\nwhile enabling constant-time and constant-space inference per token,\nindependent of sequence length. We evaluate our method, SpectraLDS, as a\ncomponent in sequence prediction architectures and demonstrate that accuracy is\npreserved while inference efficiency is improved on tasks such as language\nmodeling.", "published": "2025-05-23 13:16:54", "link": "http://arxiv.org/abs/2505.17868v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization", "abstract": "Designing effective black-box optimizers is hampered by limited\nproblem-specific knowledge and manual control that spans months for almost\nevery detail. In this paper, we present DesignX, the first automated algorithm\ndesign framework that generates an effective optimizer specific to a given\nblack-box optimization problem within seconds. Rooted in the first principles,\nwe identify two key sub-tasks: 1) algorithm structure generation and 2)\nhyperparameter control. To enable systematic construction, a comprehensive\nmodular algorithmic space is first built, embracing hundreds of algorithm\ncomponents collected from decades of research. We then introduce a dual-agent\nreinforcement learning system that collaborates on structural and parametric\ndesign through a novel cooperative training objective, enabling large-scale\nmeta-training across 10k diverse instances. Remarkably, through days of\nautonomous learning, the DesignX-generated optimizers continuously surpass\nhuman-crafted optimizers by orders of magnitude, either on synthetic testbed or\non realistic optimization scenarios such as Protein-docking, AutoML and UAV\npath planning. Further in-depth analysis reveals DesignX's capability to\ndiscover non-trivial algorithm patterns beyond expert intuition, which,\nconversely, provides valuable design insights for the optimization community.\nWe provide DesignX's inference code at https://github.com/MetaEvo/DesignX.", "published": "2025-05-23 13:16:01", "link": "http://arxiv.org/abs/2505.17866v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "The emergence of sparse attention: impact of data distribution and benefits of repetition", "abstract": "Emergence is a fascinating property of large language models and neural\nnetworks more broadly: as models scale and train for longer, they sometimes\ndevelop new abilities in sudden ways. Despite initial studies, we still lack a\ncomprehensive understanding of how and when these abilities emerge. To address\nthis gap, we study the emergence over training of sparse attention, a critical\nand frequently observed attention pattern in Transformers. By combining\ntheoretical analysis of a toy model with empirical observations on small\nTransformers trained on a linear regression variant, we uncover the mechanics\ndriving sparse attention emergence and reveal that emergence timing follows\npower laws based on task structure, architecture, and optimizer choice. We\nadditionally find that repetition can greatly speed up emergence. Finally, we\nconfirm these results on a well-studied in-context associative recall task. Our\nfindings provide a simple, theoretically grounded framework for understanding\nhow data distributions and model design influence the learning dynamics behind\none form of emergence.", "published": "2025-05-23 13:14:02", "link": "http://arxiv.org/abs/2505.17863v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Out of the Shadows: Exploring a Latent Space for Neural Network Verification", "abstract": "Neural networks are ubiquitous. However, they are often sensitive to small\ninput changes. Hence, to prevent unexpected behavior in safety-critical\napplications, their formal verification -- a notoriously hard problem -- is\nnecessary. Many state-of-the-art verification algorithms use reachability\nanalysis or abstract interpretation to enclose the set of possible outputs of a\nneural network. Often, the verification is inconclusive due to the conservatism\nof the enclosure. To address this problem, we design a novel latent space for\nformal verification that enables the transfer of output specifications to the\ninput space for an iterative specification-driven input refinement, i.e., we\niteratively reduce the set of possible inputs to only enclose the unsafe ones.\nThe latent space is constructed from a novel view of projection-based set\nrepresentations, e.g., zonotopes, which are commonly used in reachability\nanalysis of neural networks. A projection-based set representation is a\n\"shadow\" of a higher-dimensional set -- a latent space -- that does not change\nduring a set propagation through a neural network. Hence, the input set and the\noutput enclosure are \"shadows\" of the same latent space that we can use to\ntransfer constraints. We present an efficient verification tool for neural\nnetworks that uses our iterative refinement to significantly reduce the number\nof subproblems in a branch-and-bound procedure. Using zonotopes as a set\nrepresentation, unlike many other state-of-the-art approaches, our approach can\nbe realized by only using matrix operations, which enables a significant\nspeed-up through efficient GPU acceleration. We demonstrate that our tool\nachieves competitive performance, which would place it among the top-ranking\ntools of the last neural network verification competition (VNN-COMP'24).", "published": "2025-05-23 13:05:07", "link": "http://arxiv.org/abs/2505.17854v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Continuum Transformers Perform In-Context Learning by Operator Gradient Descent", "abstract": "Transformers robustly exhibit the ability to perform in-context learning,\nwhereby their predictive accuracy on a task can increase not by parameter\nupdates but merely with the placement of training samples in their context\nwindows. Recent works have shown that transformers achieve this by implementing\ngradient descent in their forward passes. Such results, however, are restricted\nto standard transformer architectures, which handle finite-dimensional inputs.\nIn the space of PDE surrogate modeling, a generalization of transformers to\nhandle infinite-dimensional function inputs, known as \"continuum transformers,\"\nhas been proposed and similarly observed to exhibit in-context learning.\nDespite impressive empirical performance, such in-context learning has yet to\nbe theoretically characterized. We herein demonstrate that continuum\ntransformers perform in-context operator learning by performing gradient\ndescent in an operator RKHS. We demonstrate this using novel proof strategies\nthat leverage a generalized representer theorem for Hilbert spaces and gradient\nflows over the space of functionals of a Hilbert space. We additionally show\nthe operator learned in context is the Bayes Optimal Predictor in the infinite\ndepth limit of the transformer. We then provide empirical validations of this\noptimality result and demonstrate that the parameters under which such gradient\ndescent is performed are recovered through the continuum transformer training.", "published": "2025-05-23 12:52:54", "link": "http://arxiv.org/abs/2505.17838v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means", "abstract": "This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(\\log(t)/t)$ rate for trimmed mean estimation,\nwhere by $t$ is meant the number of iterations. Moreover, we provide a\nbreakdown point analysis of \\textsc{GoTrim}. We empirically validate our\ntheoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes.", "published": "2025-05-23 12:51:03", "link": "http://arxiv.org/abs/2505.17836v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Source Separation of Small Classical Ensembles: Challenges and Opportunities", "abstract": "Musical (MSS) source separation of western popular music using non-causal\ndeep learning can be very effective. In contrast, MSS for classical music is an\nunsolved problem. Classical ensembles are harder to separate than popular music\nbecause of issues such as the inherent greater variation in the music; the\nsparsity of recordings with ground truth for supervised training; and greater\nambiguity between instruments. The Cadenza project has been exploring MSS for\nclassical music. This is being done so music can be remixed to improve\nlistening experiences for people with hearing loss. To enable the work, a new\ndatabase of synthesized woodwind ensembles was created to overcome instrumental\nimbalances in the EnsembleSet. For the MSS, a set of ConvTasNet models was used\nwith each model being trained to extract a string or woodwind instrument.\nConvTasNet was chosen because it enabled both causal and non-causal approaches\nto be tested. Non-causal approaches have dominated MSS work and are useful for\nrecorded music, but for live music or processing on hearing aids, causal signal\nprocessing is needed. The MSS performance was evaluated on the two small\ndatasets (Bach10 and URMP) of real instrument recordings where the ground-truth\nis available. The performances of the causal and non-causal systems were\nsimilar. Comparing the average Signal-to-Distortion (SDR) of the synthesized\nvalidation set (6.2 dB causal; 6.9 non-causal), to the real recorded evaluation\nset (0.3 dB causal, 0.4 dB non-causal), shows that mismatch between synthesized\nand recorded data is a problem. Future work needs to either gather more real\nrecordings that can be used for training, or to improve the realism and\ndiversity of the synthesized recordings to reduce the mismatch...", "published": "2025-05-23 12:39:23", "link": "http://arxiv.org/abs/2505.17823v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Quantifying uncertainty in spectral clusterings: expectations for perturbed and incomplete data", "abstract": "Spectral clustering is a popular unsupervised learning technique which is\nable to partition unlabelled data into disjoint clusters of distinct shapes.\nHowever, the data under consideration are often experimental data, implying\nthat the data is subject to measurement errors and measurements may even be\nlost or invalid. These uncertainties in the corrupted input data induce\ncorresponding uncertainties in the resulting clusters, and the clusterings thus\nbecome unreliable.\n  Modelling the uncertainties as random processes, we discuss a mathematical\nframework based on random set theory for the computational Monte Carlo\napproximation of statistically expected clusterings in case of corrupted, i.e.,\nperturbed, incomplete, and possibly even additional, data. We propose several\ncomputationally accessible quantities of interest and analyze their consistency\nin the infinite data point and infinite Monte Carlo sample limit. Numerical\nexperiments are provided to illustrate and compare the proposed quantities.", "published": "2025-05-23 12:35:14", "link": "http://arxiv.org/abs/2505.17819v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Facility Location with Public Locations and Private Doubly-Peaked Costs", "abstract": "In the facility location problem, the task is to place one or more facilities\nso as to minimize the sum of the agent costs for accessing their nearest\nfacility. Heretofore, in the strategic version, agent locations have been\nassumed to be private, while their cost measures have been public and\nidentical.\n  For the most part, the cost measure has been the distance to the nearest\nfacility.\n  However, in multiple natural settings, such as placing a firehouse or a\nschool, this modeling does not appear to be a good fit. For it seems natural\nthat the agent locations would be known, but their costs might be private\ninformation. In addition, for these types of settings, agents may well want the\nnearest facility to be at the right distance: near, but not too near. This is\ncaptured by the doubly-peaked cost introduced by Filos-Ratsikas et al. (AAMAS\n2017).\n  In this paper, we re-examine the facility location problem from this\nperspective: known agent locations and private preferred distances to the\nnearest facility.\n  We then give lower and upper bounds on achievable approximations, focusing on\nthe problem in 1D, and in 2D with an $L_1$ distance measure.", "published": "2025-05-23 17:13:43", "link": "http://arxiv.org/abs/2505.18114v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Feasible Action Space Reduction for Quantifying Causal Responsibility in Continuous Spatial Interactions", "abstract": "Understanding the causal influence of one agent on another agent is crucial\nfor safely deploying artificially intelligent systems such as automated\nvehicles and mobile robots into human-inhabited environments. Existing models\nof causal responsibility deal with simplified abstractions of scenarios with\ndiscrete actions, thus, limiting real-world use when understanding\nresponsibility in spatial interactions. Based on the assumption that spatially\ninteracting agents are embedded in a scene and must follow an action at each\ninstant, Feasible Action-Space Reduction (FeAR) was proposed as a metric for\ncausal responsibility in a grid-world setting with discrete actions. Since\nreal-world interactions involve continuous action spaces, this paper proposes a\nformulation of the FeAR metric for measuring causal responsibility in\nspace-continuous interactions. We illustrate the utility of the metric in\nprototypical space-sharing conflicts, and showcase its applications for\nanalysing backward-looking responsibility and in estimating forward-looking\nresponsibility to guide agent decision making. Our results highlight the\npotential of the FeAR metric for designing and engineering artificial agents,\nas well as for assessing the responsibility of agents around humans.", "published": "2025-05-23 11:02:44", "link": "http://arxiv.org/abs/2505.17739v1", "categories": ["cs.MA", "cs.CY", "cs.HC", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Get Experience from Practice: LLM Agents with Record & Replay", "abstract": "AI agents, empowered by Large Language Models (LLMs) and communication\nprotocols such as MCP and A2A, have rapidly evolved from simple chatbots to\nautonomous entities capable of executing complex, multi-step tasks,\ndemonstrating great potential. However, the LLMs' inherent uncertainty and\nheavy computational resource requirements pose four significant challenges to\nthe development of safe and efficient agents: reliability, privacy, cost and\nperformance. Existing approaches, like model alignment, workflow constraints\nand on-device model deployment, can partially alleviate some issues but often\nwith limitations, failing to fundamentally resolve these challenges.\n  This paper proposes a new paradigm called AgentRR (Agent Record & Replay),\nwhich introduces the classical record-and-replay mechanism into AI agent\nframeworks. The core idea is to: 1. Record an agent's interaction trace with\nits environment and internal decision process during task execution, 2.\nSummarize this trace into a structured \"experience\" encapsulating the workflow\nand constraints, and 3. Replay these experiences in subsequent similar tasks to\nguide the agent's behavior. We detail a multi-level experience abstraction\nmethod and a check function mechanism in AgentRR: the former balances\nexperience specificity and generality, while the latter serves as a trust\nanchor to ensure completeness and safety during replay. In addition, we explore\nmultiple application modes of AgentRR, including user-recorded task\ndemonstration, large-small model collaboration and privacy-aware agent\nexecution, and envision an experience repository for sharing and reusing\nknowledge to further reduce deployment cost.", "published": "2025-05-23 10:33:14", "link": "http://arxiv.org/abs/2505.17716v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Multi-agent Systems for Misinformation Lifecycle : Detection, Correction And Source Identification", "abstract": "The rapid proliferation of misinformation in digital media demands solutions\nthat go beyond isolated Large Language Model(LLM) or AI Agent based detection\nmethods. This paper introduces a novel multi-agent framework that covers the\ncomplete misinformation lifecycle: classification, detection, correction, and\nsource verification to deliver more transparent and reliable outcomes. In\ncontrast to single-agent or monolithic architectures, our approach employs five\nspecialized agents: an Indexer agent for dynamically maintaining trusted\nrepositories, a Classifier agent for labeling misinformation types, an\nExtractor agent for evidence based retrieval and ranking, a Corrector agent for\ngenerating fact-based correction and a Verification agent for validating\noutputs and tracking source credibility. Each agent can be individually\nevaluated and optimized, ensuring scalability and adaptability as new types of\nmisinformation and data sources emerge. By decomposing the misinformation\nlifecycle into specialized agents - our framework enhances scalability,\nmodularity, and explainability. This paper proposes a high-level system\noverview, agent design with emphasis on transparency, evidence-based outputs,\nand source provenance to support robust misinformation detection and correction\nat scale.", "published": "2025-05-23 06:05:56", "link": "http://arxiv.org/abs/2505.17511v1", "categories": ["cs.MA", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Inference of Substructured Reduced-Order Models for Dynamic Contact from Contact-free Simulations", "abstract": "In this paper, we propose an operator-inference-based reduction approach for\ncontact problems, leveraging snapshots from simulations without active contact.\nContact problems are solved using adjoint methods, by switching to the dual\nsystem, where the corresponding Lagrange multipliers represent the contact\npressure. The Craig-Bampton-like substructuring method is incorporated into the\ninference process to provide the reduced system matrices and the coupling of\nthe contact and interior nodes. The maximum possible set of contact nodes must\nbe known a priori. Characteristic properties of the inferred matrices, such as\nsymmetry and positive definiteness, are enforced by appending additional\nconstraints to the underlying least-squares problem. The resulting dual system,\nwhich forms a linear complementarity problem, is well-defined and can be\neffectively solved using methods such as Lemke's algorithm. The performance of\nthe proposed method is validated on three-dimensional finite element models.", "published": "2025-05-23 15:54:36", "link": "http://arxiv.org/abs/2505.18050v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A novel parameter-free and locking-free enriched Galerkin method for linear elasticity", "abstract": "We propose a novel parameter-free and locking-free enriched Galerkin (EG)\nmethod for solving the linear elasticity problem in both two and three\ndimensions. Unlike existing locking-free EG methods, our method enriches the\nfirst-order continuous Galerkin (CG) space with piecewise constants along edges\nin two dimensions or faces in three dimensions. This enrichment acts as a\ncorrection to the normal component of the CG space, ensuring the locking-free\nproperty and delivering an oscillation-free stress approximation without\nrequiring post-processing. Our theoretical analysis establishes the\nwell-posedness of the method and derives optimal error estimates. Numerical\nexperiments further demonstrate the accuracy, efficiency, and robustness of the\nproposed method.", "published": "2025-05-23 15:46:03", "link": "http://arxiv.org/abs/2505.18042v1", "categories": ["math.NA", "cs.NA", "65N30 and 65N15 and 65N12 and 35B45 and 78M10"], "primary_category": "math.NA"}
{"title": "A new class of finite difference methods: The zigzag schemes", "abstract": "We introduce a novel class of finite difference approximations, termed zigzag\nschemes, that employ a hybrid stencil that is neither symmetrical, nor fully\none-sided. These zigzag schemes often enjoy more permissive stability\nconstraints and see their coefficients vanish as the order tends to infinity.\nThis property permits the formulation of higher order schemes. An explicit\nformula is given for both collocated and staggered grids for an arbitrary order\nand a closed-form expression for the infinite-order scheme is also provided. A\nlinear stability analysis indicates that the zigzag scheme offer a broader\nrange of conditional stability compared to the centred and upwind schemes,\nsometimes being the only stable scheme. Additionally, the asymmetrical\nstructure of the stencil of zigzag schemes prevents some issues such as the\nformation of ``ghost solutions''. Moreover, implementing zigzag schemes is\nrelatively easy when a code using classical finite differences is available,\nthat is an important feature for well-tested legacy codes. Overall, zigzag\nschemes provide a compelling alternative for finite differences methods by\nenabling faster and more stable numerical simulations without sacrificing\naccuracy or ease of use.", "published": "2025-05-23 14:39:20", "link": "http://arxiv.org/abs/2505.17969v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A sparse $hp$-finite element method for piecewise-smooth differential equations with periodic boundary conditions", "abstract": "We develop an efficient $hp$-finite element method for piecewise-smooth\ndifferential equations with periodic boundary conditions, using orthogonal\npolynomials defined on circular arcs. The operators derived from this basis are\nbanded and achieve optimal complexity regardless of $h$ or $p$, both for\nbuilding the discretisation and solving the resulting linear system in the case\nwhere the operator is symmetric positive definite. The basis serves as a useful\nalternative to other bases such as the Fourier or integrated Legendre bases,\nespecially for problems with discontinuities. We relate the convergence\nproperties of these bases to regions of analyticity in the complex plane, and\nfurther use several differential equation examples to demonstrate these\nproperties. The basis spans the low order eigenfunctions of constant\ncoefficient differential operators, thereby achieving better smoothness\nproperties for time-evolution partial differential equations.", "published": "2025-05-23 13:02:06", "link": "http://arxiv.org/abs/2505.17849v1", "categories": ["math.NA", "cs.NA", "65N30, 65N35, 65M70, 33C45"], "primary_category": "math.NA"}
{"title": "Application of troubled-cells to finite volume methods -- an optimality study using a novel monotonicity parameter", "abstract": "We adapt a troubled-cell indicator from discontinuous Galerkin (DG) methods\nto finite volume methods (FVM) with MUSCL reconstruction and using a novel\nmonotonicity parameter show there is a trade-off between convergence and\nquality of the solution. Employing two dimensional compressible Euler equations\nfor flows with oblique shocks, this trade-off is studied by varying the number\nof troubled-cells systematically. An oblique shock is characterized primarily\nby the upstream Mach number, the shock angle $\\beta$, and the deflection angle\n$\\theta$. We study these factors and their combinations and find that the\ndegree of the shock misalignment with the grid determines the optimal number of\ntroubled-cells. On each side of the shock, the optimal set consists of three\ntroubled-cells for aligned shocks, and the troubled-cells identified by tracing\nthe shock and four lines parallel to it, separated by the grid spacing, for\nnonaligned shocks. We show that the adapted troubled-cell indicator identifies\na set of cells that is close to and contains the optimal set of cells for a\nthreshold constant $K = 0.05$, and consequently, produces a solution close to\nthat obtained by limiting everywhere, but with improved convergence.", "published": "2025-05-23 11:23:04", "link": "http://arxiv.org/abs/2505.17753v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Computational Math with Neural Networks is Hard", "abstract": "We show that under some widely believed assumptions, there are no\nhigher-order algorithms for basic tasks in computational mathematics such as:\nComputing integrals with neural network integrands, computing solutions of a\nPoisson equation with neural network source term, and computing the\nmatrix-vector product with a neural network encoded matrix. We show that this\nis already true for very simple feed-forward networks with at least three\nhidden layers, bounded weights, bounded realization, and sparse connectivity,\neven if the algorithms are allowed to access the weights of the network. The\nfundamental idea behind these results is that it is already very hard to check\nwhether a given neural network represents the zero function. The non-locality\nof the problems above allow us to reduce the approximation setting to deciding\nwhether the input is zero or not. We demonstrate sharpness of our results by\nproviding fast quadrature algorithms for one-layer networks and giving\nnumerical evidence that quasi-Monte Carlo methods achieve the best possible\norder of convergence for quadrature with neural networks.", "published": "2025-05-23 11:21:05", "link": "http://arxiv.org/abs/2505.17751v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stage-Parallel Implicit Runge--Kutta methods via low-rank matrix equation corrections", "abstract": "Implicit Runge--Kutta (IRK) methods are highly effective for solving stiff\nordinary differential equations (ODEs) but can be computationally expensive for\nlarge-scale problems due to the need of solving coupled algebraic equations at\neach step. This study improves IRK efficiency by leveraging parallelism to\ndecouple stage computations and reduce communication overhead, specifically we\nstably decouple a perturbed version of the stage system of equations and\nrecover the exact solution by solving a Sylvester matrix equation with an\nexplicitly known low-rank right-hand side. Two IRK families -- symmetric\nmethods and collocation methods -- are analyzed, with extensions to nonlinear\nproblems using a simplified Newton method. Implementation details, shared\nmemory parallel code, and numerical examples, particularly for ODEs from\nspatially discretized PDEs, demonstrate the efficiency of the proposed IRK\ntechnique.", "published": "2025-05-23 10:35:43", "link": "http://arxiv.org/abs/2505.17719v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An insight on some properties of high order nonstandard linear multistep methods", "abstract": "In this paper, nonstandard multistep methods are observed. It is shown that\nunder some (sufficient and necessary) conditions, these methods attain the same\norder as their standard counterparts - to prove this statement, a nonstandard\nversion of Taylor's series is constructed. The preservation of some qualitative\nproperties (boundedness, a weak form of monotonicity, and the linear\ncombination of the components) is also proven for all step sizes. The methods\nare applied to a one-dimensional equation and a system of equations, in which\nthe numerical experiments confirm the theoretical results.", "published": "2025-05-23 08:16:21", "link": "http://arxiv.org/abs/2505.17606v1", "categories": ["math.NA", "cs.NA", "65L06, 92D25, 92D30"], "primary_category": "math.NA"}
{"title": "Equilibrium boundary conditions for vectorial multi-dimensional lattice Boltzmann schemes", "abstract": "The concept of equilibrium is a general tool to fill the gap between\nmacroscopic and mesoscopic information, both within kinetic systems and kinetic\nschemes. This work explores the use of equilibria to devise numerical boundary\nconditions for multi-dimensional vectorial lattice Boltzmann schemes tackling\nsystems of hyperbolic conservation laws. In the scalar case, we prove\nconvergence for schemes with monotone relaxation to the weak entropy solution\nby Bardos, Leroux, and N{\\'e}delec [Commun. Partial Differ. Equ., 4 (9), 1979],\nfollowing the path by Crandall and Majda [Math. Comput., 34, 149 (1980)].\nNumerical experiments are conducted both for scalar and vectorial problems, and\ndemonstrate the effectiveness of equilibrium boundary conditions in capturing\nsignificant physical phenomena.", "published": "2025-05-23 06:41:45", "link": "http://arxiv.org/abs/2505.17535v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The GMRES method for solving the large indefinite least squares problem via an accelerated preconditioner", "abstract": "In this research, to solve the large indefinite least squares problem, we\nfirstly transform its normal equation into a sparse block three-by-three linear\nsystems, then use GMRES method with an accelerated preconditioner to solve it.\nThe construction idea of the preconditioner comes from the thought of Luo et.al\n[Luo, WH., Gu, XM., Carpentieri, B., BIT 62, 1983-2004(2022)], and the\nadvantage of this is that the preconditioner is closer to the coefficient\nmatrix of the block three-by-three linear systems when the parameter approachs\nzero. Theoretically, the iteration method under the preconditioner satisfies\nthe conditional convergence, and all eigenvalues of the preconditioned matrix\nare real numbers and gathered at point $(1,0)$ as parameter is close to $0$. In\nthe end, numerical results reflect that the theoretical results is correct and\nthe proposed preconditioner is effective by comparing with serval existing\npreconditioners.", "published": "2025-05-23 05:57:09", "link": "http://arxiv.org/abs/2505.17504v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stochastic Price Dynamics in Response to Order Flow Imbalance: Evidence from CSI 300 Index Futures", "abstract": "We conduct modeling of the price dynamics following order flow imbalance in\nmarket microstructure and apply the model to the analysis of Chinese CSI 300\nIndex Futures. There are three findings. The first is that the order flow\nimbalance is analogous to a shock to the market. Unlike the common practice of\nusing Hawkes processes, we model the impact of order flow imbalance as an\nOrnstein-Uhlenbeck process with memory and mean-reverting characteristics\ndriven by a jump-type L\\'evy process. Motivated by the empirically stable\ncorrelation between order flow imbalance and contemporaneous price changes, we\npropose a modified asset price model where the drift term of canonical\ngeometric Brownian motion is replaced by an Ornstein-Uhlenbeck process. We\nestablish stochastic differential equations and derive the logarithmic return\nprocess along with its mean and variance processes under initial boundary\nconditions, and evolution of cost-effectiveness ratio with order flow imbalance\nas the trading trigger point, termed as the quasi-Sharpe ratio or response\nratio. Secondly, our results demonstrate horizon-dependent heterogeneity in how\nconventional metrics interact with order flow imbalance. This underscores the\ncritical role of forecast horizon selection for strategies. Thirdly, we\nidentify regime-dependent dynamics in the memory and forecasting power of order\nflow imbalance. This taxonomy provides both a screening protocol for existing\nindicators and an ex-ante evaluation paradigm for novel metrics.", "published": "2025-05-23 01:53:28", "link": "http://arxiv.org/abs/2505.17388v1", "categories": ["q-fin.MF", "q-fin.CP", "q-fin.TR"], "primary_category": "q-fin.MF"}
{"title": "Optimal Online Change Detection via Random Fourier Features", "abstract": "This article studies the problem of online non-parametric change point\ndetection in multivariate data streams. We approach the problem through the\nlens of kernel-based two-sample testing and introduce a sequential testing\nprocedure based on random Fourier features, running with logarithmic time\ncomplexity per observation and with overall logarithmic space complexity. The\nalgorithm has two advantages compared to the state of the art. First, our\napproach is genuinely online, and no access to training data known to be from\nthe pre-change distribution is necessary. Second, the algorithm does not\nrequire the user to specify a window parameter over which local tests are to be\ncalculated. We prove strong theoretical guarantees on the algorithm's\nperformance, including information-theoretic bounds demonstrating that the\ndetection delay is optimal in the minimax sense. Numerical studies on real and\nsynthetic data show that our algorithm is competitive with respect to the state\nof the art.", "published": "2025-05-23 12:02:13", "link": "http://arxiv.org/abs/2505.17789v1", "categories": ["stat.ML", "cs.LG", "68W27 (Primary) 62G10, 46E22 (Secondary)", "G.3; I.2.6"], "primary_category": "stat.ML"}
{"title": "Discrete Neural Flow Samplers with Locally Equivariant Transformer", "abstract": "Sampling from unnormalised discrete distributions is a fundamental problem\nacross various domains. While Markov chain Monte Carlo offers a principled\napproach, it often suffers from slow mixing and poor convergence. In this\npaper, we propose Discrete Neural Flow Samplers (DNFS), a trainable and\nefficient framework for discrete sampling. DNFS learns the rate matrix of a\ncontinuous-time Markov chain such that the resulting dynamics satisfy the\nKolmogorov equation. As this objective involves the intractable partition\nfunction, we then employ control variates to reduce the variance of its Monte\nCarlo estimation, leading to a coordinate descent learning algorithm. To\nfurther facilitate computational efficiency, we propose locally equivaraint\nTransformer, a novel parameterisation of the rate matrix that significantly\nimproves training efficiency while preserving powerful network expressiveness.\nEmpirically, we demonstrate the efficacy of DNFS in a wide range of\napplications, including sampling from unnormalised distributions, training\ndiscrete energy-based models, and solving combinatorial optimisation problems.", "published": "2025-05-23 11:06:06", "link": "http://arxiv.org/abs/2505.17741v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training", "abstract": "Diffusion models have achieved remarkable success across a wide range of\ngenerative tasks. A key challenge is understanding the mechanisms that prevent\ntheir memorization of training data and allow generalization. In this work, we\ninvestigate the role of the training dynamics in the transition from\ngeneralization to memorization. Through extensive experiments and theoretical\nanalysis, we identify two distinct timescales: an early time\n$\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and\na later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially,\nwe find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size\n$n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window\nof training times with $n$ where models generalize effectively, despite showing\nstrong memorization if training continues beyond it. It is only when $n$\nbecomes larger than a model-dependent threshold that overfitting disappears at\ninfinite training times. These findings reveal a form of implicit dynamical\nregularization in the training dynamics, which allow to avoid memorization even\nin highly overparameterized settings. Our results are supported by numerical\nexperiments with standard U-Net architectures on realistic and synthetic\ndatasets, and by a theoretical analysis using a tractable random features model\nstudied in the high-dimensional limit.", "published": "2025-05-23 08:58:47", "link": "http://arxiv.org/abs/2505.17638v1", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Offline Constrained Reinforcement Learning under Partial Data Coverage", "abstract": "We study offline constrained reinforcement learning (RL) with general\nfunction approximation. We aim to learn a policy from a pre-collected dataset\nthat maximizes the expected discounted cumulative reward for a primary reward\nsignal while ensuring that expected discounted returns for multiple auxiliary\nreward signals are above predefined thresholds. Existing algorithms either\nrequire fully exploratory data, are computationally inefficient, or depend on\nan additional auxiliary function classes to obtain an $\\epsilon$-optimal policy\nwith sample complexity $O(\\epsilon^{-2})$. In this paper, we propose an\noracle-efficient primal-dual algorithm based on a linear programming (LP)\nformulation, achieving $O(\\epsilon^{-2})$ sample complexity under partial data\ncoverage. By introducing a realizability assumption, our approach ensures that\nall saddle points of the Lagrangian are optimal, removing the need for\nregularization that complicated prior analyses. Through Lagrangian\ndecomposition, our method extracts policies without requiring knowledge of the\ndata-generating distribution, enhancing practical applicability.", "published": "2025-05-23 06:00:01", "link": "http://arxiv.org/abs/2505.17506v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Efficient Adaptive Experimentation with Non-Compliance", "abstract": "We study the problem of estimating the average treatment effect (ATE) in\nadaptive experiments where treatment can only be encouraged--rather than\ndirectly assigned--via a binary instrumental variable. Building on\nsemiparametric efficiency theory, we derive the efficiency bound for ATE\nestimation under arbitrary, history-dependent instrument-assignment policies,\nand show it is minimized by a variance-aware allocation rule that balances\noutcome noise and compliance variability. Leveraging this insight, we introduce\nAMRIV--an \\textbf{A}daptive, \\textbf{M}ultiply-\\textbf{R}obust estimator for\n\\textbf{I}nstrumental-\\textbf{V}ariable settings with variance-optimal\nassignment. AMRIV pairs (i) an online policy that adaptively approximates the\noptimal allocation with (ii) a sequential, influence-function-based estimator\nthat attains the semiparametric efficiency bound while retaining\nmultiply-robust consistency. We establish asymptotic normality, explicit\nconvergence rates, and anytime-valid asymptotic confidence sequences that\nenable sequential inference. Finally, we demonstrate the practical\neffectiveness of our approach through empirical studies, showing that adaptive\ninstrument assignment, when combined with the AMRIV estimator, yields improved\nefficiency and robustness compared to existing baselines.", "published": "2025-05-23 04:49:14", "link": "http://arxiv.org/abs/2505.17468v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Minimax Rate-Optimal Algorithms for High-Dimensional Stochastic Linear Bandits", "abstract": "We study the stochastic linear bandit problem with multiple arms over $T$\nrounds, where the covariate dimension $d$ may exceed $T$, but each arm-specific\nparameter vector is $s$-sparse. We begin by analyzing the sequential estimation\nproblem in the single-arm setting, focusing on cumulative mean-squared error.\nWe show that Lasso estimators are provably suboptimal in the sequential\nsetting, exhibiting suboptimal dependence on $d$ and $T$, whereas thresholded\nLasso estimators -- obtained by applying least squares to the support selected\nby thresholding an initial Lasso estimator -- achieve the minimax rate.\nBuilding on these insights, we consider the full linear contextual bandit\nproblem and propose a three-stage arm selection algorithm that uses thresholded\nLasso as the main estimation method. We derive an upper bound on the cumulative\nregret of order $s(\\log s)(\\log d + \\log T)$, and establish a matching lower\nbound up to a $\\log s$ factor, thereby characterizing the minimax regret rate\nup to a logarithmic term in $s$. Moreover, when a short initial period is\nexcluded from the regret, the proposed algorithm achieves exact minimax\noptimality.", "published": "2025-05-23 02:20:00", "link": "http://arxiv.org/abs/2505.17400v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Variational Autoencoding Discrete Diffusion with Enhanced Dimensional Correlations Modeling", "abstract": "Discrete diffusion models have recently shown great promise for modeling\ncomplex discrete data, with masked diffusion models (MDMs) offering a\ncompelling trade-off between quality and generation speed. MDMs denoise by\nprogressively unmasking multiple dimensions from an all-masked input, but their\nperformance can degrade when using few denoising steps due to limited modeling\nof inter-dimensional dependencies. In this paper, we propose Variational\nAutoencoding Discrete Diffusion (VADD), a novel framework that enhances\ndiscrete diffusion with latent variable modeling to implicitly capture\ncorrelations among dimensions. By introducing an auxiliary recognition model,\nVADD enables stable training via variational lower bounds maximization and\namortized inference over the training set. Our approach retains the efficiency\nof traditional MDMs while significantly improving sample quality, especially\nwhen the number of denoising steps is small. Empirical results on 2D toy data,\npixel-level image generation, and text generation demonstrate that VADD\nconsistently outperforms MDM baselines.", "published": "2025-05-23 01:45:47", "link": "http://arxiv.org/abs/2505.17384v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CT-OT Flow: Estimating Continuous-Time Dynamics from Discrete Temporal Snapshots", "abstract": "In many real-world scenarios, such as single-cell RNA sequencing, data are\nobserved only as discrete-time snapshots spanning finite time intervals and\nsubject to noisy timestamps, with no continuous trajectories available.\nRecovering the underlying continuous-time dynamics from these snapshots with\ncoarse and noisy observation times is a critical and challenging task. We\npropose Continuous-Time Optimal Transport Flow (CT-OT Flow), which first infers\nhigh-resolution time labels via partial optimal transport and then reconstructs\na continuous-time data distribution through a temporal kernel smoothing. This\nreconstruction enables accurate training of dynamics models such as ODEs and\nSDEs. CT-OT Flow consistently outperforms state-of-the-art methods on synthetic\nbenchmarks and achieves lower reconstruction errors on real scRNA-seq and\ntyphoon-track datasets. Our results highlight the benefits of explicitly\nmodeling temporal discretization and timestamp uncertainty, offering an\naccurate and general framework for bridging discrete snapshots and\ncontinuous-time processes.", "published": "2025-05-23 00:12:49", "link": "http://arxiv.org/abs/2505.17354v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Effects of auditory distance cues and reverberation on spatial perception and listening strategies", "abstract": "Spatial hearing, the brain's ability to use auditory cues to identify the\norigin of sounds, is crucial for everyday listening. While simplified paradigms\nhave advanced the understanding of spatial hearing, their lack of ecological\nvalidity limits their applicability to real-life conditions. This study aims to\naddress this gap by investigating the effects of listener movement,\nreverberation, and distance on localisation accuracy in a more ecologically\nvalid context. Participants performed active localisation tasks with no\nspecific instructions on listening strategy, in either anechoic or reverberant\nconditions. The results indicate that the head movements were more frequent in\nreverberant environments, suggesting an adaptive strategy to mitigate\nuncertainty in binaural cues due to reverberation. While distance did not\naffect the listening strategy, it influenced the localisation performance. Our\noutcomes suggest that listening behaviour is adapted depending on the current\nacoustic conditions to support an effective perception of the space.", "published": "2025-05-23 15:26:11", "link": "http://arxiv.org/abs/2505.18020v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Audio-to-Audio Emotion Conversion With Pitch And Duration Style Transfer", "abstract": "Given a pair of source and reference speech recordings, audio-to-audio (A2A)\nstyle transfer involves the generation of an output speech that mimics the\nstyle characteristics of the reference while preserving the content and speaker\nattributes of the source. In this paper, we propose a novel framework, termed\nas A2A Zero-shot Emotion Style Transfer (A2A-ZEST), that enables the transfer\nof reference emotional attributes to the source while retaining its speaker and\nspeech contents. The A2A-ZEST framework consists of an analysis-synthesis\npipeline, where the analysis module decomposes speech into semantic tokens,\nspeaker representations, and emotion embeddings. Using these representations, a\npitch contour estimator and a duration predictor are learned. Further, a\nsynthesis module is designed to generate speech based on the input\nrepresentations and the derived factors. This entire paradigm of\nanalysis-synthesis is trained purely in a self-supervised manner with an\nauto-encoding loss. For A2A emotion style transfer, the emotion embedding\nextracted from the reference speech along with the rest of the representations\nfrom the source speech are used in the synthesis module to generate the style\ntranslated speech. In our experiments, we evaluate the converted speech on\ncontent/speaker preservation (w.r.t. source) as well as on the effectiveness of\nthe emotion style transfer (w.r.t. reference). The proposal, A2A-ZEST, is shown\nto improve over other prior works on these evaluations, thereby enabling style\ntransfer without any parallel training data. We also illustrate the application\nof the proposed work for data augmentation in emotion recognition tasks.", "published": "2025-05-23 09:18:12", "link": "http://arxiv.org/abs/2505.17655v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training", "abstract": "In our prior works, we introduced a scalable streaming speech synthesis\nmodel, CosyVoice 2, which integrates a large language model (LLM) and a\nchunk-aware flow matching (FM) model, and achieves low-latency bi-streaming\nspeech synthesis and human-parity quality. Despite these advancements,\nCosyVoice 2 exhibits limitations in language coverage, domain diversity, data\nvolume, text formats, and post-training techniques. In this paper, we present\nCosyVoice 3, an improved model designed for zero-shot multilingual speech\nsynthesis in the wild, surpassing its predecessor in content consistency,\nspeaker similarity, and prosody naturalness. Key features of CosyVoice 3\ninclude: 1) A novel speech tokenizer to improve prosody naturalness, developed\nvia supervised multi-task training, including automatic speech recognition,\nspeech emotion recognition, language identification, audio event detection, and\nspeaker analysis. 2) A new differentiable reward model for post-training\napplicable not only to CosyVoice 3 but also to other LLM-based speech synthesis\nmodels. 3) Dataset Size Scaling: Training data is expanded from ten thousand\nhours to one million hours, encompassing 9 languages and 18 Chinese dialects\nacross various domains and text formats. 4) Model Size Scaling: Model\nparameters are increased from 0.5 billion to 1.5 billion, resulting in enhanced\nperformance on our multilingual benchmark due to the larger model capacity.\nThese advancements contribute significantly to the progress of speech synthesis\nin the wild. We encourage readers to listen to the demo at\nhttps://funaudiollm.github.io/cosyvoice3.", "published": "2025-05-23 07:55:21", "link": "http://arxiv.org/abs/2505.17589v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Private kNN-VC: Interpretable Anonymization of Converted Speech", "abstract": "Speaker anonymization seeks to conceal a speaker's identity while preserving\nthe utility of their speech. The achieved privacy is commonly evaluated with a\nspeaker recognition model trained on anonymized speech. Although this\nrepresents a strong attack, it is unclear which aspects of speech are exploited\nto identify the speakers. Our research sets out to unveil these aspects. It\nstarts with kNN-VC, a powerful voice conversion model that performs poorly as\nan anonymization system, presumably because of prosody leakage. To test this\nhypothesis, we extend kNN-VC with two interpretable components that anonymize\nthe duration and variation of phones. These components increase privacy\nsignificantly, proving that the studied prosodic factors encode speaker\nidentity and are exploited by the privacy attack. Additionally, we show that\nchanges in the target selection algorithm considerably influence the outcome of\nthe privacy attack.", "published": "2025-05-23 07:45:08", "link": "http://arxiv.org/abs/2505.17584v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models", "abstract": "Audio Language Models (ALMs) have made significant progress recently. These\nmodels integrate the audio modality directly into the model, rather than\nconverting speech into text and inputting text to Large Language Models (LLMs).\nWhile jailbreak attacks on LLMs have been extensively studied, the security of\nALMs with audio modalities remains largely unexplored. Currently, there is a\nlack of an adversarial audio dataset and a unified framework specifically\ndesigned to evaluate and compare attacks and ALMs. In this paper, we present\nJALMBench, the \\textit{first} comprehensive benchmark to assess the safety of\nALMs against jailbreak attacks. JALMBench includes a dataset containing 2,200\ntext samples and 51,381 audio samples with over 268 hours. It supports 12\nmainstream ALMs, 4 text-transferred and 4 audio-originated attack methods, and\n5 defense methods. Using JALMBench, we provide an in-depth analysis of attack\nefficiency, topic sensitivity, voice diversity, and attack representations.\nAdditionally, we explore mitigation strategies for the attacks at both the\nprompt level and the response level.", "published": "2025-05-23 07:29:55", "link": "http://arxiv.org/abs/2505.17568v1", "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation", "abstract": "Music-driven 3D dance generation has attracted increasing attention in recent\nyears, with promising applications in choreography, virtual reality, and\ncreative content creation. Previous research has generated promising realistic\ndance movement from audio signals. However, traditional methods underutilize\ngenre conditioning, often treating it as auxiliary modifiers rather than core\nsemantic drivers. This oversight compromises music-motion synchronization and\ndisrupts dance genre continuity, particularly during complex rhythmic\ntransitions, thereby leading to visually unsatisfactory effects. To address the\nchallenge, we propose MEGADance, a novel architecture for music-driven 3D dance\ngeneration. By decoupling choreographic consistency into dance generality and\ngenre specificity, MEGADance demonstrates significant dance quality and strong\ngenre controllability. It consists of two stages: (1) High-Fidelity Dance\nQuantization Stage (HFDQ), which encodes dance motions into a latent\nrepresentation by Finite Scalar Quantization (FSQ) and reconstructs them with\nkinematic-dynamic constraints, and (2) Genre-Aware Dance Generation Stage\n(GADG), which maps music into the latent representation by synergistic\nutilization of Mixture-of-Experts (MoE) mechanism with Mamba-Transformer hybrid\nbackbone. Extensive experiments on the FineDance and AIST++ dataset demonstrate\nthe state-of-the-art performance of MEGADance both qualitatively and\nquantitatively. Code will be released upon acceptance.", "published": "2025-05-23 06:47:06", "link": "http://arxiv.org/abs/2505.17543v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reverse-Speech-Finder: A Neural Network Backtracking Architecture for Generating Alzheimer's Disease Speech Samples and Improving Diagnosis Performance", "abstract": "This study introduces Reverse-Speech-Finder (RSF), a groundbreaking neural\nnetwork backtracking architecture designed to enhance Alzheimer's Disease (AD)\ndiagnosis through speech analysis. Leveraging the power of pre-trained large\nlanguage models, RSF identifies and utilizes the most probable AD-specific\nspeech markers, addressing both the scarcity of real AD speech samples and the\nchallenge of limited interpretability in existing models. RSF's unique approach\nconsists of three core innovations: Firstly, it exploits the observation that\nspeech markers most probable of predicting AD, defined as the most probable\nspeech-markers (MPMs), must have the highest probability of activating those\nneurons (in the neural network) with the highest probability of predicting AD,\ndefined as the most probable neurons (MPNs). Secondly, it utilizes a speech\ntoken representation at the input layer, allowing backtracking from MPNs to\nidentify the most probable speech-tokens (MPTs) of AD. Lastly, it develops an\ninnovative backtracking method to track backwards from the MPNs to the input\nlayer, identifying the MPTs and the corresponding MPMs, and ingeniously\nuncovering novel speech markers for AD detection. Experimental results\ndemonstrate RSF's superiority over traditional methods such as SHAP and\nIntegrated Gradients, achieving a 3.5% improvement in accuracy and a 3.2% boost\nin F1-score. By generating speech data that encapsulates novel markers, RSF not\nonly mitigates the limitations of real data scarcity but also significantly\nenhances the robustness and accuracy of AD diagnostic models. These findings\nunderscore RSF's potential as a transformative tool in speech-based AD\ndetection, offering new insights into AD-related linguistic deficits and paving\nthe way for more effective non-invasive early intervention strategies.", "published": "2025-05-23 04:59:27", "link": "http://arxiv.org/abs/2505.17477v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models", "abstract": "The purpose of speech tokenization is to transform a speech signal into a\nsequence of discrete representations, serving as the foundation for speech\nlanguage models (SLMs). While speech tokenization has many options, their\neffect on the performance of SLMs remains unclear. This paper investigates two\nkey aspects of speech tokenization: the segmentation width and the cluster size\nof discrete units. First, we segment speech signals into fixed/variable widths\nand pooled representations. We then train K-means models in multiple cluster\nsizes. Through the evaluation on zero-shot spoken language understanding\nbenchmarks, we find the positive effect of moderately coarse segmentation and\nbigger cluster size. Notably, among the best-performing models, the most\nefficient one achieves a 50% reduction in training data and a 70% decrease in\ntraining runtime. Our analysis highlights the importance of combining multiple\ntokens to enhance fine-grained spoken language understanding.", "published": "2025-05-23 04:03:27", "link": "http://arxiv.org/abs/2505.17446v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "UniTTS: An end-to-end TTS system without decoupling of acoustic and semantic information", "abstract": "The emergence of multi-codebook neutral audio codecs such as Residual Vector\nQuantization (RVQ) and Group Vector Quantization (GVQ) has significantly\nadvanced Large-Language-Model (LLM) based Text-to-Speech (TTS) systems. These\ncodecs are crucial in separating semantic and acoustic information while\nefficiently harnessing semantic priors. However, since semantic and acoustic\ninformation cannot be fully aligned, a significant drawback of these methods\nwhen applied to LLM-based TTS is that large language models may have limited\naccess to comprehensive audio information. To address this limitation, we\npropose DistilCodec and UniTTS, which collectively offer the following\nadvantages: 1) This method can distill a multi-codebook audio codec into a\nsingle-codebook audio codec with 32,768 codes while achieving a near 100\\%\nutilization. 2) As DistilCodec does not employ a semantic alignment scheme, a\nlarge amount of high-quality unlabeled audio (such as audiobooks with sound\neffects, songs, etc.) can be incorporated during training, further expanding\ndata diversity and broadening its applicability. 3) Leveraging the\ncomprehensive audio information modeling of DistilCodec, we integrated three\nkey tasks into UniTTS's pre-training framework: audio modality autoregression,\ntext modality autoregression, and speech-text cross-modal autoregression. This\nallows UniTTS to accept interleaved text and speech/audio prompts while\nsubstantially preserving LLM's text capabilities. 4) UniTTS employs a\nthree-stage training process: Pre-Training, Supervised Fine-Tuning (SFT), and\nAlignment. Source code and model checkpoints are publicly available at\nhttps://github.com/IDEA-Emdoor-Lab/UniTTS and\nhttps://github.com/IDEA-Emdoor-Lab/DistilCodec.", "published": "2025-05-23 03:13:46", "link": "http://arxiv.org/abs/2505.17426v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speechless: Speech Instruction Training Without Speech for Low Resource Languages", "abstract": "The rapid growth of voice assistants powered by large language models (LLM)\nhas highlighted a need for speech instruction data to train these systems.\nDespite the abundance of speech recognition data, there is a notable scarcity\nof speech instruction data, which is essential for fine-tuning models to\nunderstand and execute spoken commands. Generating high-quality synthetic\nspeech requires a good text-to-speech (TTS) model, which may not be available\nto low resource languages. Our novel approach addresses this challenge by\nhalting synthesis at the semantic representation level, bypassing the need for\nTTS. We achieve this by aligning synthetic semantic representations with the\npre-trained Whisper encoder, enabling an LLM to be fine-tuned on text\ninstructions while maintaining the ability to understand spoken instructions\nduring inference. This simplified training process is a promising approach to\nbuilding voice assistant for low-resource languages.", "published": "2025-05-23 03:05:47", "link": "http://arxiv.org/abs/2505.17417v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LLM-based Generative Error Correction for Rare Words with Synthetic Data and Phonetic Context", "abstract": "Generative error correction (GER) with large language models (LLMs) has\nemerged as an effective post-processing approach to improve automatic speech\nrecognition (ASR) performance. However, it often struggles with rare or\ndomain-specific words due to limited training data. Furthermore, existing\nLLM-based GER approaches primarily rely on textual information, neglecting\nphonetic cues, which leads to over-correction. To address these issues, we\npropose a novel LLM-based GER approach that targets rare words and incorporates\nphonetic information. First, we generate synthetic data to contain rare words\nfor fine-tuning the GER model. Second, we integrate ASR's N-best hypotheses\nalong with phonetic context to mitigate over-correction. Experimental results\nshow that our method not only improves the correction of rare words but also\nreduces the WER and CER across both English and Japanese datasets.", "published": "2025-05-23 02:54:52", "link": "http://arxiv.org/abs/2505.17410v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analysis on Energy Efficiency of RIS-Assisted Multiuser Downlink Near-Field Communications", "abstract": "In this paper, we focus on the energy efficiency (EE) optimization and\nanalysis of reconfigurable intelligent surface (RIS)-assisted multiuser\ndownlink near-field communications. Specifically, we conduct a comprehensive\nstudy on several key factors affecting EE performance, including the number of\nRIS elements, the types of reconfigurable elements, reconfiguration\nresolutions, and the maximum transmit power. To accurately capture the power\ncharacteristics of RISs, we adopt more practical power consumption models for\nthree commonly used reconfigurable elements in RISs: PIN diodes, varactor\ndiodes, and radio frequency (RF) switches. These different elements may result\nin RIS systems exhibiting significantly different energy efficiencies (EEs),\neven when their spectral efficiencies (SEs) are similar. Considering discrete\nphases implemented at most RISs in practice, which makes their optimization\nNP-hard, we develop a nested alternating optimization framework to maximize EE,\nconsisting of an outer integer-based optimization for discrete RIS phase\nreconfigurations and a nested non-convex optimization for continuous transmit\npower allocation within each iteration. Extensive comparisons with multiple\nbenchmark schemes validate the effectiveness and efficiency of the proposed\nframework. Furthermore, based on the proposed optimization method, we analyze\nthe EE performance of RISs across different key factors and identify the\noptimal RIS architecture yielding the highest EE.", "published": "2025-05-23 16:29:32", "link": "http://arxiv.org/abs/2505.18076v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Faulty RIS-aided Integrated Sensing and Communication: Modeling and Optimization", "abstract": "This work investigates a practical reconfigurable intelligent surface\n(RIS)-aided integrated sensing and communication (ISAC) system, where a subset\nof RIS elements fail to function properly and reflect incident signals randomly\ntowards unintended directions, thereby degrading system performance. To date,\nno study has addressed such impairments caused by faulty RIS elements in ISAC\nsystems. This work aims to fill the gap. First, to quantify the impact of\nfaulty elements on ISAC performance, we derive the misspecified Cram\\'er-Rao\nbound (MCRB) for sensing parameter estimation and\nsignal-to-interference-and-noise ratio (SINR) for communication quality. Then,\nto mitigate the performance loss caused by faulty elements, we jointly design\nthe remaining functional RIS phase shifts and transmit beamforming to minimize\nthe MCRB, subject to the communication SINR and transmit power constraints. The\nresulting optimization problem is highly non-convex due to the intricate\nstructure of the MCRB expression and constant-modulus constraint imposed on\nRIS. To address this, we reformulate it into a more tractable form and propose\na block coordinate descent (BCD) algorithm that incorporates\nmajorization-minimization (MM), successive convex approximation (SCA), and\npenalization techniques. Simulation results demonstrate that our proposed\napproach reduces the MCRB performance loss by 24.36% on average compared to the\ncase where the presence of faulty elements is ignored. Furthermore, the\nperformance gain becomes more evident as the number of faulty elements\nincreases.", "published": "2025-05-23 14:39:24", "link": "http://arxiv.org/abs/2505.17970v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLM4SP: Large Language Models for Scatterer Prediction via Synesthesia of Machines", "abstract": "Guided by Synesthesia of Machines (SoM), the nonlinear mapping relationship\nbetween sensory and communication information serves as a powerful tool to\nenhance both the accuracy and generalization of vehicle-to-vehicle (V2V)\nmulti-modal intelligent channel modeling (MMICM) in intelligent transportation\nsystems (ITSs). To explore the general mapping relationship between physical\nenvironment and electromagnetic space, a new intelligent sensing-communication\nintegration dataset, named V2V-M3, is constructed for multiple scenarios in V2V\ncommunications with multiple frequency bands and multiple vehicular traffic\ndensities (VTDs). Leveraging the strong representation and cross-modal\ninference capabilities of large language models (LLMs), a novel LLM-based\nmethod for Scatterer Prediction (LLM4SP) from light detection and ranging\n(LiDAR) point clouds is developed. To address the inherent and significant\ndifferences across multi-modal data, synergistically optimized four-module\narchitecture, i.e., preprocessor, embedding, backbone, and output modules, are\ndesigned by considering the sensing/channel characteristics and electromagnetic\npropagation mechanism. On the basis of cross-modal representation alignment and\npositional encoding, the network of LLM4SP is fine-tuned to capture the general\nmapping relationship between LiDAR point clouds and scatterers. Simulation\nresults demonstrate that the proposed LLM4SP achieves superior performance in\nfull-sample and generalization testing, significantly outperforming small\nmodels across different frequency bands, scenarios, and VTDs.", "published": "2025-05-23 13:28:26", "link": "http://arxiv.org/abs/2505.17879v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Unsupervised Clustering for Fault Analysis in High-Voltage Power Systems Using Voltage and Current Signals", "abstract": "The widespread use of sensors in modern power grids has led to the\naccumulation of large amounts of voltage and current waveform data, especially\nduring fault events. However, the lack of labeled datasets poses a significant\nchallenge for fault classification and analysis. This paper explores the\napplication of unsupervised clustering techniques for fault diagnosis in\nhigh-voltage power systems. A dataset provided by the Reseau de Transport\nd'Electricite (RTE) is analyzed, with frequency domain features extracted using\nthe Fast Fourier Transform (FFT). The K-Means algorithm is then applied to\nidentify underlying patterns in the data, enabling automated fault\ncategorization without the need for labeled training samples. The resulting\nclusters are evaluated in collaboration with power system experts to assess\ntheir alignment with real-world fault characteristics. The results demonstrate\nthe potential of unsupervised learning for scalable and data-driven fault\nanalysis, providing a robust approach to detecting and classifying power system\nfaults with minimal prior assumptions.", "published": "2025-05-23 11:35:09", "link": "http://arxiv.org/abs/2505.17763v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Enhancing Fourier-based Doppler Resolution with Diffusion Models", "abstract": "In radar systems, high resolution in the Doppler dimension is important for\ndetecting slow-moving targets as it allows for more distinct separation between\nthese targets and clutter, or stationary objects. However, achieving sufficient\nresolution is constrained by hardware capabilities and physical factors,\nleading to the development of processing techniques to enhance the resolution\nafter acquisition. In this work, we leverage artificial intelligence to\nincrease the Doppler resolution in range-Doppler maps. Based on a zero-padded\nFFT, a refinement via the generative neural networks of diffusion models is\nachieved. We demonstrate that our method overcomes the limitations of\ntraditional FFT, generating data where closely spaced targets are effectively\nseparated.", "published": "2025-05-23 07:27:19", "link": "http://arxiv.org/abs/2505.17567v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Interference Modulation: A Novel Technique for Low-Rate and Power Efficient Multiple Access", "abstract": "The majority of spatial signal processing techniques focus on increasing the\ntotal system capacity and providing high data rates for intended user(s).\nUnlike the existing studies, this paper introduces a novel interference\nmodulation method that exploits the correlation between wireless channels to\nenable low-data-rate transmission towards additional users with a minimal power\nallocation. The proposed method changes the interference power at specific\nchannels to modulate a low-rate on-off keying signal. This is achieved by\nappropriately setting the radiation pattern of front-end components of a\ntransmitter, i.e., analog beamforming weights or metasurface configuration. The\npaper investigates theoretical performance limits and analyzes the efficiency\nin terms of sum rate. Bit error rate simulation results are closely matched\nwith theoretical findings. The initial findings indicate that the proposed\ntechnique can be instrumental in providing reduced capability communication\nusing minimal power consumption in 6G networks.", "published": "2025-05-23 06:34:18", "link": "http://arxiv.org/abs/2505.17526v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Outcome-based Reinforcement Learning to Predict the Future", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has boosted math and\ncoding in large language models, yet there has been little effort to extend\nRLVR into messier, real-world domains like forecasting. One sticking point is\nthat outcome-based reinforcement learning for forecasting must learn from\nbinary, delayed, and noisy rewards, a regime where standard fine-tuning is\nbrittle. We show that outcome-only online RL on a 14B model can match\nfrontier-scale accuracy and surpass it in calibration and hypothetical\nprediction market betting by adapting two leading algorithms, Group-Relative\nPolicy Optimisation (GRPO) and ReMax, to the forecasting setting. Our\nadaptations remove per-question variance scaling in GRPO, apply\nbaseline-subtracted advantages in ReMax, hydrate training with 100k temporally\nconsistent synthetic questions, and introduce lightweight guard-rails that\npenalise gibberish, non-English responses and missing rationales, enabling a\nsingle stable pass over 110k events. Scaling ReMax to 110k questions and\nensembling seven predictions yields a 14B model that matches frontier baseline\no1 on accuracy on our holdout set (Brier = 0.193, p = 0.23) while beating it in\ncalibration (ECE = 0.042, p < 0.001). A simple trading rule turns this\ncalibration edge into \\$127 of hypothetical profit versus \\$92 for o1 (p =\n0.037). This demonstrates that refined RLVR methods can convert small-scale\nLLMs into potentially economically valuable forecasting tools, with\nimplications for scaling this to larger models.", "published": "2025-05-23 14:56:07", "link": "http://arxiv.org/abs/2505.17989v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM", "abstract": "Recently, multimodal large language models (MLLMs) have emerged as a key\napproach in achieving artificial general intelligence. In particular,\nvision-language MLLMs have been developed to generate not only text but also\nvisual outputs from multimodal inputs. This advancement requires efficient\nimage tokens that LLMs can process effectively both in input and output.\nHowever, existing image tokenization methods for MLLMs typically capture only\nglobal abstract concepts or uniformly segmented image patches, restricting\nMLLMs' capability to effectively understand or generate detailed visual\ncontent, particularly at the object level. To address this limitation, we\npropose an object-centric visual tokenizer based on Slot Attention specifically\nfor MLLMs. In particular, based on the Q-Former encoder, diffusion decoder, and\nresidual vector quantization, our proposed discretized slot tokens can encode\nlocal visual details while maintaining high-level semantics, and also align\nwith textual data to be integrated seamlessly within a unified next-token\nprediction framework of LLMs. The resulting Slot-MLLM demonstrates significant\nperformance improvements over baselines with previous visual tokenizers across\nvarious vision-language tasks that entail local detailed comprehension and\ngeneration. Notably, this work is the first demonstration of the feasibility of\nobject-centric slot attention performed with MLLMs and in-the-wild natural\nimages.", "published": "2025-05-23 10:43:45", "link": "http://arxiv.org/abs/2505.17726v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TokBench: Evaluating Your Visual Tokenizer before Visual Generation", "abstract": "In this work, we reveal the limitations of visual tokenizers and VAEs in\npreserving fine-grained features, and propose a benchmark to evaluate\nreconstruction performance for two challenging visual contents: text and face.\nVisual tokenizers and VAEs have significantly advanced visual generation and\nmultimodal modeling by providing more efficient compressed or quantized image\nrepresentations. However, while helping production models reduce computational\nburdens, the information loss from image compression fundamentally limits the\nupper bound of visual generation quality. To evaluate this upper bound, we\nfocus on assessing reconstructed text and facial features since they typically:\n1) exist at smaller scales, 2) contain dense and rich textures, 3) are prone to\ncollapse, and 4) are highly sensitive to human vision. We first collect and\ncurate a diverse set of clear text and face images from existing datasets.\nUnlike approaches using VLM models, we employ established OCR and face\nrecognition models for evaluation, ensuring accuracy while maintaining an\nexceptionally lightweight assessment process <span style=\"font-weight: bold;\ncolor: rgb(214, 21, 21);\">requiring just 2GB memory and 4 minutes</span> to\ncomplete. Using our benchmark, we analyze text and face reconstruction quality\nacross various scales for different image tokenizers and VAEs. Our results show\nmodern visual tokenizers still struggle to preserve fine-grained features,\nespecially at smaller scales. We further extend this evaluation framework to\nvideo, conducting comprehensive analysis of video tokenizers. Additionally, we\ndemonstrate that traditional metrics fail to accurately reflect reconstruction\nperformance for faces and text, while our proposed metrics serve as an\neffective complement.", "published": "2025-05-23 17:52:16", "link": "http://arxiv.org/abs/2505.18142v2", "categories": ["cs.CV", "cs.DB"], "primary_category": "cs.CV"}
{"title": "DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations", "abstract": "In face-to-face conversations, individuals need to switch between speaking\nand listening roles seamlessly. Existing 3D talking head generation models\nfocus solely on speaking or listening, neglecting the natural dynamics of\ninteractive conversation, which leads to unnatural interactions and awkward\ntransitions. To address this issue, we propose a new task -- multi-round\ndual-speaker interaction for 3D talking head generation -- which requires\nmodels to handle and generate both speaking and listening behaviors in\ncontinuous conversation. To solve this task, we introduce DualTalk, a novel\nunified framework that integrates the dynamic behaviors of speakers and\nlisteners to simulate realistic and coherent dialogue interactions. This\nframework not only synthesizes lifelike talking heads when speaking but also\ngenerates continuous and vivid non-verbal feedback when listening, effectively\ncapturing the interplay between the roles. We also create a new dataset\nfeaturing 50 hours of multi-round conversations with over 1,000 characters,\nwhere participants continuously switch between speaking and listening roles.\nExtensive experiments demonstrate that our method significantly enhances the\nnaturalness and expressiveness of 3D talking heads in dual-speaker\nconversations. We recommend watching the supplementary video:\nhttps://ziqiaopeng.github.io/dualtalk.", "published": "2025-05-23 16:49:05", "link": "http://arxiv.org/abs/2505.18096v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Semantic Correspondence: Unified Benchmarking and a Strong Baseline", "abstract": "Establishing semantic correspondence is a challenging task in computer\nvision, aiming to match keypoints with the same semantic information across\ndifferent images. Benefiting from the rapid development of deep learning,\nremarkable progress has been made over the past decade. However, a\ncomprehensive review and analysis of this task remains absent. In this paper,\nwe present the first extensive survey of semantic correspondence methods. We\nfirst propose a taxonomy to classify existing methods based on the type of\ntheir method designs. These methods are then categorized accordingly, and we\nprovide a detailed analysis of each approach. Furthermore, we aggregate and\nsummarize the results of methods in literature across various benchmarks into a\nunified comparative table, with detailed configurations to highlight\nperformance variations. Additionally, to provide a detailed understanding on\nexisting methods for semantic matching, we thoroughly conduct controlled\nexperiments to analyse the effectiveness of the components of different\nmethods. Finally, we propose a simple yet effective baseline that achieves\nstate-of-the-art performance on multiple benchmarks, providing a solid\nfoundation for future research in this field. We hope this survey serves as a\ncomprehensive reference and consolidated baseline for future development. Code\nis publicly available at: https://github.com/Visual-AI/Semantic-Correspondence.", "published": "2025-05-23 16:07:16", "link": "http://arxiv.org/abs/2505.18060v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Cascaded Architectures: An End-to-end Generative Framework for Industrial Advertising", "abstract": "Traditional online industrial advertising systems suffer from the limitations\nof multi-stage cascaded architectures, which often discard high-potential\ncandidates prematurely and distribute decision logic across disconnected\nmodules. While recent generative recommendation approaches provide end-to-end\nsolutions, they fail to address critical advertising requirements of key\ncomponents for real-world deployment, such as explicit bidding, creative\nselection, ad allocation, and payment computation. To bridge this gap, we\nintroduce End-to-End Generative Advertising (EGA), the first unified framework\nthat holistically models user interests, point-of-interest (POI) and creative\ngeneration, ad allocation, and payment optimization within a single generative\nmodel. Our approach employs hierarchical tokenization and multi-token\nprediction to jointly generate POI recommendations and ad creatives, while a\npermutation-aware reward model and token-level bidding strategy ensure\nalignment with both user experiences and advertiser objectives. Additionally,\nwe decouple allocation from payment using a differentiable ex-post regret\nminimization mechanism, guaranteeing approximate incentive compatibility at the\nPOI level. Through extensive offline evaluations and large-scale online\nexperiments on real-world advertising platforms, we demonstrate that EGA\nsignificantly outperforms traditional cascaded systems in both performance and\npracticality. Our results highlight its potential as a pioneering fully\ngenerative advertising solution, paving the way for next-generation industrial\nad systems.", "published": "2025-05-23 06:55:02", "link": "http://arxiv.org/abs/2505.17549v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Strictly Constrained Generative Modeling via Split Augmented Langevin Sampling", "abstract": "Deep generative models hold great promise for representing complex physical\nsystems, but their deployment is currently limited by the lack of guarantees on\nthe physical plausibility of the generated outputs. Ensuring that known\nphysical constraints are enforced is therefore critical when applying\ngenerative models to scientific and engineering problems. We address this\nlimitation by developing a principled framework for sampling from a target\ndistribution while rigorously satisfying physical constraints. Leveraging the\nvariational formulation of Langevin dynamics, we propose Split Augmented\nLangevin (SAL), a novel primal-dual sampling algorithm that enforces\nconstraints progressively through variable splitting, with convergence\nguarantees. While the method is developed theoretically for Langevin dynamics,\nwe demonstrate its effective applicability to diffusion models. In particular,\nwe use constrained diffusion models to generate physical fields satisfying\nenergy and mass conservation laws. We apply our method to diffusion-based data\nassimilation on a complex physical system, where enforcing physical constraints\nsubstantially improves both forecast accuracy and the preservation of critical\nconserved quantities. We also demonstrate the potential of SAL for challenging\nfeasibility problems in optimal control.", "published": "2025-05-23 15:21:10", "link": "http://arxiv.org/abs/2505.18017v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RaDeR: Reasoning-aware Dense Retrieval Models", "abstract": "We propose RaDeR, a set of reasoning-based dense retrieval models trained\nwith data derived from mathematical problem solving using large language models\n(LLMs). Our method leverages retrieval-augmented reasoning trajectories of an\nLLM and self-reflective relevance evaluation, enabling the creation of both\ndiverse and hard-negative samples for reasoning-intensive relevance. RaDeR\nretrievers, trained for mathematical reasoning, effectively generalize to\ndiverse reasoning tasks in the BRIGHT and RAR-b benchmarks, consistently\noutperforming strong baselines in overall performance.Notably, RaDeR achieves\nsignificantly higher performance than baselines on the Math and Coding splits.\nIn addition, RaDeR presents the first dense retriever that outperforms BM25\nwhen queries are Chain-of-Thought reasoning steps, underscoring the critical\nrole of reasoning-based retrieval to augment reasoning language models.\nFurthermore, RaDeR achieves comparable or superior performance while using only\n2.5% of the training data used by the concurrent work REASONIR, highlighting\nthe quality of our synthesized training data.", "published": "2025-05-23 22:18:32", "link": "http://arxiv.org/abs/2505.18405v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems", "abstract": "Enterprise search systems often struggle to retrieve accurate,\ndomain-specific information due to semantic mismatches and overlapping\nterminologies. These issues can degrade the performance of downstream\napplications such as knowledge management, customer support, and\nretrieval-augmented generation agents. To address this challenge, we propose a\nscalable hard-negative mining framework tailored specifically for\ndomain-specific enterprise data. Our approach dynamically selects semantically\nchallenging but contextually irrelevant documents to enhance deployed\nre-ranking models.\n  Our method integrates diverse embedding models, performs dimensionality\nreduction, and uniquely selects hard negatives, ensuring computational\nefficiency and semantic precision. Evaluation on our proprietary enterprise\ncorpus (cloud services domain) demonstrates substantial improvements of 15\\% in\nMRR@3 and 19\\% in MRR@10 compared to state-of-the-art baselines and other\nnegative sampling techniques. Further validation on public domain-specific\ndatasets (FiQA, Climate Fever, TechQA) confirms our method's generalizability\nand readiness for real-world applications.", "published": "2025-05-23 20:51:20", "link": "http://arxiv.org/abs/2505.18366v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "H.3.3; I.2.6; I.2.7"], "primary_category": "cs.IR"}
{"title": "MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning", "abstract": "Despite the widespread exploration of Retrieval-Augmented Generation (RAG),\nits deployment in enterprises for domain-specific datasets remains limited due\nto poor answer accuracy. These corpora, often shielded behind firewalls in\nprivate enterprise knowledge bases, having complex, domain-specific\nterminology, rarely seen by LLMs during pre-training; exhibit significant\nsemantic variability across domains (like networking, military, or legal,\netc.), or even within a single domain like medicine, and thus result in poor\ncontext precision for RAG systems. Currently, in such situations, fine-tuning\nor RAG with fine-tuning is attempted, but these approaches are slow, expensive,\nand lack generalization for accuracy as the new domain-specific data emerges.\nWe propose an approach for Enterprise Search that focuses on enhancing the\nretriever for a domain-specific corpus through hybrid query indexes and\nmetadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata\ngeneration pipeline using key concepts, topics, and acronyms, and then creates\na metadata-enriched hybrid index with boosted search queries. This approach\navoids overfitting and generalizes effectively across domains. On the PubMedQA\nbenchmark for the biomedical domain, the proposed method achieves 82% retrieval\naccuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results\nwithout fine-tuning and sets a new benchmark for zero-shot results while\noutperforming much larger models like GPT3.5. The results are even comparable\nto the best fine-tuned models on this dataset, and we further demonstrate the\nrobustness and scalability of the approach by evaluating it on other Q&A\ndatasets like SQuAD, NQ etc.", "published": "2025-05-23 17:18:45", "link": "http://arxiv.org/abs/2505.18247v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Intent Classification on Low-Resource Languages with Query Similarity Search", "abstract": "Intent classification is an important component of a functional Information\nRetrieval ecosystem. Many current approaches to intent classification,\ntypically framed as a classification problem, can be problematic as intents are\noften hard to define and thus data can be difficult and expensive to annotate.\nThe problem is exacerbated when we need to extend the intent classification\nsystem to support multiple and in particular low-resource languages. To address\nthis, we propose casting intent classification as a query similarity search\nproblem - we use previous example queries to define an intent, and a query\nsimilarity method to classify an incoming query based on the labels of its most\nsimilar queries in latent space. With the proposed approach, we are able to\nachieve reasonable intent classification performance for queries in\nlow-resource languages in a zero-shot setting.", "published": "2025-05-23 15:11:12", "link": "http://arxiv.org/abs/2505.18241v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Evidence-Grounded Multimodal Misinformation Detection with Attention-Based GNNs", "abstract": "Multimodal out-of-context (OOC) misinformation is misinformation that\nrepurposes real images with unrelated or misleading captions. Detecting such\nmisinformation is challenging because it requires resolving the context of the\nclaim before checking for misinformation. Many current methods, including LLMs\nand LVLMs, do not perform this contextualization step. LLMs hallucinate in\nabsence of context or parametric knowledge. In this work, we propose a\ngraph-based method that evaluates the consistency between the image and the\ncaption by constructing two graph representations: an evidence graph, derived\nfrom online textual evidence, and a claim graph, from the claim in the caption.\nUsing graph neural networks (GNNs) to encode and compare these representations,\nour framework then evaluates the truthfulness of image-caption pairs. We create\ndatasets for our graph-based method, evaluate and compare our baseline model\nagainst popular LLMs on the misinformation detection task. Our method scores\n$93.05\\%$ detection accuracy on the evaluation set and outperforms the\nsecond-best performing method (an LLM) by $2.82\\%$, making a case for smaller\nand task-specific methods.", "published": "2025-05-23 08:52:58", "link": "http://arxiv.org/abs/2505.18221v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "A Dual Basis Approach for Structured Robust Euclidean Distance Geometry", "abstract": "Euclidean Distance Matrix (EDM), which consists of pairwise squared Euclidean\ndistances of a given point configuration, finds many applications in modern\nmachine learning. This paper considers the setting where only a set of anchor\nnodes is used to collect the distances between themselves and the rest. In the\npresence of potential outliers, it results in a structured partial observation\non EDM with partial corruptions. Note that an EDM can be connected to a\npositive semi-definite Gram matrix via a non-orthogonal dual basis. Inspired by\nrecent development of non-orthogonal dual basis in optimization, we propose a\nnovel algorithmic framework, dubbed Robust Euclidean Distance Geometry via Dual\nBasis (RoDEoDB), for recovering the Euclidean distance geometry, i.e., the\nunderlying point configuration. The exact recovery guarantees have been\nestablished in terms of both the Gram matrix and point configuration, under\nsome mild conditions. Empirical experiments show superior performance of\nRoDEoDB on sensor localization and molecular conformation datasets.", "published": "2025-05-23 22:40:21", "link": "http://arxiv.org/abs/2505.18414v1", "categories": ["cs.LG", "cs.IT", "math.IT", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sampling Strategies for Efficient Training of Deep Learning Object Detection Algorithms", "abstract": "Two sampling strategies are investigated to enhance efficiency in training a\ndeep learning object detection model. These sampling strategies are employed\nunder the assumption of Lipschitz continuity of deep learning models. The first\nstrategy is uniform sampling which seeks to obtain samples evenly yet randomly\nthrough the state space of the object dynamics. The second strategy of frame\ndifference sampling is developed to explore the temporal redundancy among\nsuccessive frames in a video. Experiment result indicates that these proposed\nsampling strategies provide a dataset that yields good training performance\nwhile requiring relatively few manually labelled samples.", "published": "2025-05-23 18:54:01", "link": "http://arxiv.org/abs/2505.18302v1", "categories": ["cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.CV"}
{"title": "The end of radical concept nativism", "abstract": "Though humans seem to be remarkable learners, arguments in cognitive science\nand philosophy of mind have long maintained that learning something\nfundamentally new is impossible. Specifically, Jerry Fodor's arguments for\nradical concept nativism hold that most, if not all, concepts are innate and\nthat what many call concept learning never actually leads to the acquisition of\nnew concepts. These arguments have deeply affected cognitive science, and many\nbelieve that the counterarguments to radical concept nativism have been either\nunsuccessful or only apply to a narrow class of concepts. This paper first\nreviews the features and limitations of prior arguments. We then identify three\ncritical points - related to issues of expressive power, conceptual structure,\nand concept possession - at which the arguments in favor of radical concept\nnativism diverge from describing actual human cognition. We use ideas from\ncomputer science and information theory to formalize the relevant ideas in ways\nthat are arguably more scientifically productive. We conclude that, as a\nresult, there is an important sense in which people do indeed learn new\nconcepts.", "published": "2025-05-23 18:12:38", "link": "http://arxiv.org/abs/2505.18277v1", "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.AI"}
{"title": "Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens", "abstract": "The recent rise of Large Reasoning Models (LRMs) has significantly improved\nmulti-step reasoning performance, but often at the cost of generating\nexcessively long reasoning chains. This paper revisits the efficiency of such\nreasoning processes through an information-theoretic lens, revealing a\nfundamental trade-off between reasoning length and semantic efficiency. We\npropose two metrics, InfoBias and InfoGain, to quantify divergence from ideal\nreasoning paths and stepwise information contribution, respectively. Empirical\nanalyses show that longer reasoning chains tend to exhibit higher information\nbias and diminishing information gain, especially for incorrect answers.\nMotivated by these findings, we introduce an entropy-based Adaptive Think\nstrategy that dynamically halts reasoning once confidence is sufficiently high,\nimproving efficiency while maintaining competitive accuracy. Compared to the\nVanilla Think approach (default mode), our strategy yields a 1.10% improvement\nin average accuracy and a 50.80% reduction in token usage on QwQ-32B across six\nbenchmark tasks spanning diverse reasoning types and difficulty levels,\ndemonstrating superior efficiency and reasoning performance. These results\nunderscore the promise of entropy-based methods for enhancing both accuracy and\ncost-effiiciency in large language model deployment.", "published": "2025-05-23 13:38:56", "link": "http://arxiv.org/abs/2505.18237v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "abstract": "Multi-agent AI systems (MAS) offer a promising framework for distributed\nintelligence, enabling collaborative reasoning, planning, and decision-making\nacross autonomous agents. This paper provides a systematic outlook on the\ncurrent opportunities and challenges of MAS, drawing insights from recent\nadvances in large language models (LLMs), federated optimization, and human-AI\ninteraction. We formalize key concepts including agent topology, coordination\nprotocols, and shared objectives, and identify major risks such as dependency,\nmisalignment, and vulnerabilities arising from training data overlap. Through a\nbiologically inspired simulation and comprehensive theoretical framing, we\nhighlight critical pathways for developing robust, scalable, and secure MAS in\nreal-world settings.", "published": "2025-05-23 22:05:19", "link": "http://arxiv.org/abs/2505.18397v1", "categories": ["cs.MA", "cs.AI", "cs.ET", "cs.LG", "68T42 (Agent technology and artificial intelligence), 68T01 (General\n  topics in artificial intelligence), 68M14 (Distributed systems)", "I.2.11; I.2.4; I.2.6"], "primary_category": "cs.MA"}
{"title": "Persona Alchemy: Designing, Evaluating, and Implementing Psychologically-Grounded LLM Agents for Diverse Stakeholder Representation", "abstract": "Despite advances in designing personas for Large Language Models (LLM),\nchallenges remain in aligning them with human cognitive processes and\nrepresenting diverse stakeholder perspectives. We introduce a Social Cognitive\nTheory (SCT) agent design framework for designing, evaluating, and implementing\npsychologically grounded LLMs with consistent behavior. Our framework\noperationalizes SCT through four personal factors (cognitive, motivational,\nbiological, and affective) for designing, six quantifiable constructs for\nevaluating, and a graph database-backed architecture for implementing\nstakeholder personas. Experiments tested agents' responses to contradicting\ninformation of varying reliability. In the highly polarized renewable energy\ntransition discourse, we design five diverse agents with distinct ideologies,\nroles, and stakes to examine stakeholder representation. The evaluation of\nthese agents in contradictory scenarios occurs through comprehensive processes\nthat implement the SCT. Results show consistent response patterns ($R^2$ range:\n$0.58-0.61$) and systematic temporal development of SCT construct effects.\nPrincipal component analysis identifies two dimensions explaining $73$% of\nvariance, validating the theoretical structure. Our framework offers improved\nexplainability and reproducibility compared to black-box approaches. This work\ncontributes to ongoing efforts to improve diverse stakeholder representation\nwhile maintaining psychological consistency in LLM personas.", "published": "2025-05-23 20:18:14", "link": "http://arxiv.org/abs/2505.18351v1", "categories": ["cs.MA", "cs.CY", "cs.DB"], "primary_category": "cs.MA"}
{"title": "Single-agent or Multi-agent Systems? Why Not Both?", "abstract": "Multi-agent systems (MAS) decompose complex tasks and delegate subtasks to\ndifferent large language model (LLM) agents and tools. Prior studies have\nreported the superior accuracy performance of MAS across diverse domains,\nenabled by long-horizon context tracking and error correction through\nrole-specific agents. However, the design and deployment of MAS incur higher\ncomplexity and runtime cost compared to single-agent systems (SAS). Meanwhile,\nfrontier LLMs, such as OpenAI-o3 and Gemini-2.5-Pro, have rapidly advanced in\nlong-context reasoning, memory retention, and tool usage, mitigating many\nlimitations that originally motivated MAS designs. In this paper, we conduct an\nextensive empirical study comparing MAS and SAS across various popular agentic\napplications. We find that the benefits of MAS over SAS diminish as LLM\ncapabilities improve, and we propose efficient mechanisms to pinpoint the\nerror-prone agent in MAS. Furthermore, the performance discrepancy between MAS\nand SAS motivates our design of a hybrid agentic paradigm, request cascading\nbetween MAS and SAS, to improve both efficiency and capability. Our design\nimproves accuracy by 1.1-12% while reducing deployment costs by up to 20%\nacross various agentic applications.", "published": "2025-05-23 18:30:24", "link": "http://arxiv.org/abs/2505.18286v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "TAGS: A Test-Time Generalist-Specialist Framework with Retrieval-Augmented Reasoning and Verification", "abstract": "Recent advances such as Chain-of-Thought prompting have significantly\nimproved large language models (LLMs) in zero-shot medical reasoning. However,\nprompting-based methods often remain shallow and unstable, while fine-tuned\nmedical LLMs suffer from poor generalization under distribution shifts and\nlimited adaptability to unseen clinical scenarios. To address these\nlimitations, we present TAGS, a test-time framework that combines a broadly\ncapable generalist with a domain-specific specialist to offer complementary\nperspectives without any model fine-tuning or parameter updates. To support\nthis generalist-specialist reasoning process, we introduce two auxiliary\nmodules: a hierarchical retrieval mechanism that provides multi-scale exemplars\nby selecting examples based on both semantic and rationale-level similarity,\nand a reliability scorer that evaluates reasoning consistency to guide final\nanswer aggregation. TAGS achieves strong performance across nine MedQA\nbenchmarks, boosting GPT-4o accuracy by 13.8%, DeepSeek-R1 by 16.8%, and\nimproving a vanilla 7B model from 14.1% to 23.9%. These results surpass several\nfine-tuned medical LLMs, without any parameter updates. The code will be\navailable at https://github.com/JianghaoWu/TAGS.", "published": "2025-05-23 18:28:59", "link": "http://arxiv.org/abs/2505.18283v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control", "abstract": "Complex tasks are increasingly delegated to ensembles of specialized\nLLM-based agents that reason, communicate, and coordinate actions-both among\nthemselves and through interactions with external tools, APIs, and databases.\nWhile persistent memory has been shown to enhance single-agent performance,\nmost approaches assume a monolithic, single-user context-overlooking the\nbenefits and challenges of knowledge transfer across users under dynamic,\nasymmetric permissions. We introduce Collaborative Memory, a framework for\nmulti-user, multi-agent environments with asymmetric, time-evolving access\ncontrols encoded as bipartite graphs linking users, agents, and resources. Our\nsystem maintains two memory tiers: (1) private memory-private fragments visible\nonly to their originating user; and (2) shared memory-selectively shared\nfragments. Each fragment carries immutable provenance attributes (contributing\nagents, accessed resources, and timestamps) to support retrospective permission\nchecks. Granular read policies enforce current user-agent-resource constraints\nand project existing memory fragments into filtered transformed views. Write\npolicies determine fragment retention and sharing, applying context-aware\ntransformations to update the memory. Both policies may be designed conditioned\non system, agent, and user-level information. Our framework enables safe,\nefficient, and interpretable cross-user knowledge sharing, with provable\nadherence to asymmetric, time-varying policies and full auditability of memory\noperations.", "published": "2025-05-23 18:14:57", "link": "http://arxiv.org/abs/2505.18279v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Implementing Agents in JavaScript", "abstract": "This chapter gives an introduction to agent-oriented programming in\nJavaScript. It provides an example-based walk-through of how to implement\nabstractions for reasoning loop agents in vanilla JavaScript. The initial\nexample is used as a stepping stone for explaining how to implement slightly\nmore advanced agents and multi-agent systems using JS-son, a JavaScript library\nfor agent-oriented programming. In this context, the chapter also explains how\nto integrate reasoning loop agents with generative AI\ntechnologies--specifically, large language models. Finally, application\nscenarios in several technology ecosystems and future research directions are\nsketched.", "published": "2025-05-23 12:13:16", "link": "http://arxiv.org/abs/2505.18228v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Hamiltonian Theory and Computation of Optimal Probability Density Control in High Dimensions", "abstract": "We develop a general theoretical framework for optimal probability density\ncontrol and propose a numerical algorithm that is scalable to solve the control\nproblem in high dimensions. Specifically, we establish the Pontryagin Maximum\nPrinciple (PMP) for optimal density control and construct the\nHamilton-Jacobi-Bellman (HJB) equation of the value functional through rigorous\nderivations without any concept from Wasserstein theory. To solve the density\ncontrol problem numerically, we propose to use reduced-order models, such as\ndeep neural networks (DNNs), to parameterize the control vector-field and the\nadjoint function, which allows us to tackle problems defined on\nhigh-dimensional state spaces. We also prove several convergence properties of\nthe proposed algorithm. Numerical results demonstrate promising performances of\nour algorithm on a variety of density control problems with obstacles and\nnonlinear interaction challenges in high dimensions.", "published": "2025-05-23 20:41:37", "link": "http://arxiv.org/abs/2505.18362v1", "categories": ["math.OC", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Online Statistical Inference of Constrained Stochastic Optimization via Random Scaling", "abstract": "Constrained stochastic nonlinear optimization problems have attracted\nsignificant attention for their ability to model complex real-world scenarios\nin physics, economics, and biology. As datasets continue to grow, online\ninference methods have become crucial for enabling real-time decision-making\nwithout the need to store historical data. In this work, we develop an online\ninference procedure for constrained stochastic optimization by leveraging a\nmethod called Sketched Stochastic Sequential Quadratic Programming (SSQP). As a\ndirect generalization of sketched Newton methods, SSQP approximates the\nobjective with a quadratic model and the constraints with a linear model at\neach step, then applies a sketching solver to inexactly solve the resulting\nsubproblem. Building on this design, we propose a new online inference\nprocedure called random scaling. In particular, we construct a test statistic\nbased on SSQP iterates whose limiting distribution is free of any unknown\nparameters. Compared to existing online inference procedures, our approach\noffers two key advantages: (i) it enables the construction of asymptotically\nvalid confidence intervals; and (ii) it is matrix-free, i.e. the computation\ninvolves only primal-dual SSQP iterates $(\\boldsymbol{x}_t,\n\\boldsymbol{\\lambda}_t)$ without requiring any matrix inversions. We validate\nour theory through numerical experiments on nonlinearly constrained regression\nproblems and demonstrate the superior performance of our random scaling method\nover existing inference procedures.", "published": "2025-05-23 19:33:08", "link": "http://arxiv.org/abs/2505.18327v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.OC", "math.ST", "stat.CO", "stat.TH"], "primary_category": "stat.ML"}
{"title": "A structure-preserving local discontinuous Galerkin method for the Fokker-Planck-Landau equation", "abstract": "In this work, we introduce a structure-preserving local discontinuous\nGalerkin (LDG) method \\cite{cockburn1998local} for solving the non-local\nnon-linear Fokker-Planck-Landau (FPL) equations. We rephrase the\nstructure-preserving strategy of Shiroto and Sentoku\\cite{shiroto2019structure}\nin the language of numerical analysis, and extend it to the LDG framework. We\npropose a method that is not only conservative, but also stabilized through\nupwind flux. The apparent contradiction between conservation laws and numerical\nstabilization is elegantly resolved by leveraging the properties of the jump\nterms inherent to the LDG framework. In the numerical experiments, our scheme\nis tested with benchmark examples.", "published": "2025-05-23 19:27:31", "link": "http://arxiv.org/abs/2505.18321v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Verifiability and Limit Consistency of Eddy Viscosity Large Eddy Simulation Reduced Order Models", "abstract": "Large eddy simulation reduced order models (LES-ROMs) are ROMs that leverage\nLES ideas (e.g., filtering and closure modeling) to construct accurate and\nefficient ROMs for convection-dominated (e.g., turbulent) flows. Eddy viscosity\n(EV) ROMs (e.g., Smagorinsky ROM (S-ROM)) are LES-ROMs whose closure model\nconsists of a diffusion-like operator in which the viscosity depends on the ROM\nvelocity. We propose the Ladyzhenskaya ROM (L-ROM), which is a generalization\nof the S-ROM. Furthermore, we prove two fundamental numerical analysis results\nfor the new L-ROM and the classical S-ROM: (i) We prove the verifiability of\nthe L-ROM and S-ROM, i.e, that the ROM error is bounded (up to a constant) by\nthe ROM closure error. (ii) We introduce the concept of ROM limit consistency\n(in a discrete sense), and prove that the L-ROM and S-ROM are limit consistent,\ni.e., that as the ROM dimension approaches the rank of the snapshot matrix,\n$d$, and the ROM lengthscale goes to zero, the ROM solution converges to the\n\\emph{``true solution\"}, i.e., the solution of the $d$-dimensional ROM.\nFinally, we illustrate numerically the verifiability and limit consistency of\nthe new L-ROM and S-ROM in two under-resolved convection-dominated problems\nthat display sharp gradients: (i) the 1D Burgers equation with a small\ndiffusion coefficient; and (ii) the 2D lid-driven cavity flow at Reynolds\nnumber $Re=15,000$.", "published": "2025-05-23 19:09:04", "link": "http://arxiv.org/abs/2505.18310v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "65M15, 65M60, 76D05, 76F65"], "primary_category": "physics.flu-dyn"}
{"title": "A deep solver for backward stochastic Volterra integral equations", "abstract": "We present the first deep-learning solver for backward stochastic Volterra\nintegral equations (BSVIEs) and their fully-coupled forward-backward variants.\nThe method trains a neural network to approximate the two solution fields in a\nsingle stage, avoiding the use of nested time-stepping cycles that limit\nclassical algorithms. For the decoupled case we prove a non-asymptotic error\nbound composed of an a posteriori residual plus the familiar square root\ndependence on the time step. Numerical experiments confirm this rate and reveal\ntwo key properties: \\emph{scalability}, in the sense that accuracy remains\nstable from low dimension up to 500 spatial variables while GPU batching keeps\nwall-clock time nearly constant; and \\emph{generality}, since the same method\nhandles coupled systems whose forward dynamics depend on the backward solution.\nThese results open practical access to a family of high-dimensional,\npath-dependent problems in stochastic control and quantitative finance.", "published": "2025-05-23 18:41:54", "link": "http://arxiv.org/abs/2505.18297v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR", "q-fin.MF", "65C30, 60H20, 60H35, 68T07", "G.1.9; G.3; I.2.6; F.2.1"], "primary_category": "math.NA"}
{"title": "Learning Latent Variable Models via Jarzynski-adjusted Langevin Algorithm", "abstract": "We utilise a sampler originating from nonequilibrium statistical mechanics,\ntermed here Jarzynski-adjusted Langevin algorithm (JALA), to build statistical\nestimation methods in latent variable models. We achieve this by leveraging\nJarzynski's equality and developing algorithms based on a weighted version of\nthe unadjusted Langevin algorithm (ULA) with recursively updated weights.\nAdapting this for latent variable models, we develop a sequential Monte Carlo\n(SMC) method that provides the maximum marginal likelihood estimate of the\nparameters, termed JALA-EM. Under suitable regularity assumptions on the\nmarginal likelihood, we provide a nonasymptotic analysis of the JALA-EM scheme\nimplemented with stochastic gradient descent and show that it provably\nconverges to the maximum marginal likelihood estimate. We demonstrate the\nperformance of JALA-EM on a variety of latent variable models and show that it\nperforms comparably to existing methods in terms of accuracy and computational\nefficiency. Importantly, the ability to recursively estimate marginal\nlikelihoods - an uncommon feature among scalable methods - makes our approach\nparticularly suited for model selection, which we validate through dedicated\nexperiments.", "published": "2025-05-23 23:40:57", "link": "http://arxiv.org/abs/2505.18427v1", "categories": ["stat.CO", "stat.ML"], "primary_category": "stat.CO"}
{"title": "LocalKMeans: Convergence of Lloyd's Algorithm with Distributed Local Iterations", "abstract": "In this paper, we analyze the classical $K$-means alternating-minimization\nalgorithm, also known as Lloyd's algorithm (Lloyd, 1956), for a mixture of\nGaussians in a data-distributed setting that incorporates local iteration\nsteps. Assuming unlabeled data distributed across multiple machines, we propose\nan algorithm, LocalKMeans, that performs Lloyd's algorithm in parallel in the\nmachines by running its iterations on local data, synchronizing only every $L$\nof such local steps. We characterize the cost of these local iterations against\nthe non-distributed setting, and show that the price paid for the local steps\nis a higher required signal-to-noise ratio. While local iterations were\ntheoretically studied in the past for gradient-based learning methods, the\nanalysis of unsupervised learning methods is more involved owing to the\npresence of latent variables, e.g. cluster identities, than that of an\niterative gradient-based algorithm. To obtain our results, we adapt a virtual\niterate method to work with a non-convex, non-smooth objective function, in\nconjunction with a tight statistical analysis of Lloyd steps.", "published": "2025-05-23 22:58:40", "link": "http://arxiv.org/abs/2505.18420v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Identifiability of latent causal graphical models without pure children", "abstract": "This paper considers a challenging problem of identifying a causal graphical\nmodel under the presence of latent variables. While various identifiability\nconditions have been proposed in the literature, they often require multiple\npure children per latent variable or restrictions on the latent causal graph.\nFurthermore, it is common for all observed variables to exhibit the same\nmodality. Consequently, the existing identifiability conditions are often too\nstringent for complex real-world data. We consider a general nonparametric\nmeasurement model with arbitrary observed variable types and binary latent\nvariables, and propose a double triangular graphical condition that guarantees\nidentifiability of the entire causal graphical model. The proposed condition\nsignificantly relaxes the popular pure children condition. We also establish\nnecessary conditions for identifiability and provide valuable insights into\nfundamental limits of identifiability. Simulation studies verify that latent\nstructures satisfying our conditions can be accurately estimated from data.", "published": "2025-05-23 22:34:22", "link": "http://arxiv.org/abs/2505.18410v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Optimal community detection in dense bipartite graphs", "abstract": "We consider the problem of detecting a community of densely connected\nvertices in a high-dimensional bipartite graph of size $n_1 \\times n_2$. Under\nthe null hypothesis, the observed graph is drawn from a bipartite\nErd\\H{o}s-Renyi distribution with connection probability $p_0$. Under the\nalternative hypothesis, there exists an unknown bipartite subgraph of size $k_1\n\\times k_2$ in which edges appear with probability $p_1 = p_0 + \\delta$ for\nsome $\\delta > 0$, while all other edges outside the subgraph appear with\nprobability $p_0$. Specifically, we provide non-asymptotic upper and lower\nbounds on the smallest signal strength $\\delta^*$ that is both necessary and\nsufficient to ensure the existence of a test with small enough type one and\ntype two errors. We also derive novel minimax-optimal tests achieving these\nfundamental limits when the underlying graph is sufficiently dense. Our\nproposed tests involve a combination of hard-thresholded nonlinear statistics\nof the adjacency matrix, the analysis of which may be of independent interest.\nIn contrast with previous work, our non-asymptotic upper and lower bounds match\nfor any configuration of $n_1,n_2, k_1,k_2$.", "published": "2025-05-23 20:58:55", "link": "http://arxiv.org/abs/2505.18372v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "On the Mechanisms of Weak-to-Strong Generalization: A Theoretical Perspective", "abstract": "Weak-to-strong generalization, where a student model trained on imperfect\nlabels generated by a weaker teacher nonetheless surpasses that teacher, has\nbeen widely observed but the mechanisms that enable it have remained poorly\nunderstood. In this paper, through a theoretical analysis of simple models, we\nuncover three core mechanisms that can drive this phenomenon. First, by\nanalyzing ridge regression, we study the interplay between the teacher and\nstudent regularization and prove that a student can compensate for a teacher's\nunder-regularization and achieve lower test error. We also analyze the role of\nthe parameterization regime of the models. Second, by analyzing weighted ridge\nregression, we show that a student model with a regularization structure more\naligned to the target, can outperform its teacher. Third, in a nonlinear\nmulti-index setting, we demonstrate that a student can learn easy,\ntask-specific features from the teacher while leveraging its own broader\npre-training to learn hard-to-learn features that the teacher cannot capture.", "published": "2025-05-23 20:09:09", "link": "http://arxiv.org/abs/2505.18346v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Diffusion Self-Weighted Guidance for Offline Reinforcement Learning", "abstract": "Offline reinforcement learning (RL) recovers the optimal policy $\\pi$ given\nhistorical observations of an agent. In practice, $\\pi$ is modeled as a\nweighted version of the agent's behavior policy $\\mu$, using a weight function\n$w$ working as a critic of the agent's behavior. Though recent approaches to\noffline RL based on diffusion models have exhibited promising results, the\ncomputation of the required scores is challenging due to their dependence on\nthe unknown $w$. In this work, we alleviate this issue by constructing a\ndiffusion over both the actions and the weights. With the proposed setting, the\nrequired scores are directly obtained from the diffusion model without learning\nextra networks. Our main conceptual contribution is a novel guidance method,\nwhere guidance (which is a function of $w$) comes from the same diffusion\nmodel, therefore, our proposal is termed Self-Weighted Guidance (SWG). We show\nthat SWG generates samples from the desired distribution on toy examples and\nperforms on par with state-of-the-art methods on D4RL's challenging\nenvironments, while maintaining a streamlined training pipeline. We further\nvalidate SWG through ablation studies on weight formulations and scalability.", "published": "2025-05-23 20:03:36", "link": "http://arxiv.org/abs/2505.18345v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sample Complexity of Diffusion Model Training Without Empirical Risk Minimizer Access", "abstract": "Diffusion models have demonstrated state-of-the-art performance across\nvision, language, and scientific domains. Despite their empirical success,\nprior theoretical analyses of the sample complexity suffer from poor scaling\nwith input data dimension or rely on unrealistic assumptions such as access to\nexact empirical risk minimizers. In this work, we provide a principled analysis\nof score estimation, establishing a sample complexity bound of\n$\\widetilde{\\mathcal{O}}(\\epsilon^{-6})$. Our approach leverages a structured\ndecomposition of the score estimation error into statistical, approximation,\nand optimization errors, enabling us to eliminate the exponential dependence on\nneural network parameters that arises in prior analyses. It is the first such\nresult which achieves sample complexity bounds without assuming access to the\nempirical risk minimizer of score function estimation loss.", "published": "2025-05-23 20:02:15", "link": "http://arxiv.org/abs/2505.18344v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PLUMAGE: Probabilistic Low rank Unbiased Min Variance Gradient Estimator for Efficient Large Model Training", "abstract": "Accelerator memory and networking constraints have emerged as dominant\nbottlenecks when training large language models LLMs with billions of\nparameters. Existing low rank gradient estimators such as GaLoRE and FLORA\ncompress gradients and optimizer tensors by projecting weight gradients onto a\nrank r subspace, enabling LLM training on consumer hardware. Yet, these methods\nare either biased or subject to high estimator variance. Moreover, the\noptimizer state based on the first and second moments estimates expressed in\nthe previous subspace becomes misaligned whenever the projection is updated,\nleading to instabilities during training. We propose PLUMAGE: Probabilistic Low\nrank Unbiased Minimum vAriance Gradient Estimator. PLUMAGE is a drop in\nreplacement for existing low rank gradient estimators. It does not introduce\nnew hyperparameters beyond the chosen rank r and the update interval. In\naddition, we resolve optimizer state misalignment issues to prevent spurious\nweight updates and enhance training stability. We empirically demonstrate that\nPLUMAGE shrinks the full rank optimization's gap over the pre training\nevaluation loss by 33% on average across models and the average training loss\nacross the GLUE benchmark by 28% within a similar computational and memory\nfootprint as GaloRE.", "published": "2025-05-23 19:17:55", "link": "http://arxiv.org/abs/2505.18313v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Self-Repellent Kernels: History-Driven Target Towards Efficient Nonlinear MCMC on General Graphs", "abstract": "We propose a history-driven target (HDT) framework in Markov Chain Monte\nCarlo (MCMC) to improve any random walk algorithm on discrete state spaces,\nsuch as general undirected graphs, for efficient sampling from target\ndistribution $\\boldsymbol{\\mu}$. With broad applications in network science and\ndistributed optimization, recent innovations like the self-repellent random\nwalk (SRRW) achieve near-zero variance by prioritizing under-sampled states\nthrough transition kernel modifications based on past visit frequencies.\nHowever, SRRW's reliance on explicit computation of transition probabilities\nfor all neighbors at each step introduces substantial computational overhead,\nwhile its strict dependence on time-reversible Markov chains excludes advanced\nnon-reversible MCMC methods. To overcome these limitations, instead of direct\nmodification of transition kernel, HDT introduces a history-dependent target\ndistribution $\\boldsymbol{\\pi}[\\mathbf{x}]$ to replace the original target\n$\\boldsymbol{\\mu}$ in any graph sampler, where $\\mathbf{x}$ represents the\nempirical measure of past visits. This design preserves lightweight\nimplementation by requiring only local information between the current and\nproposed states and achieves compatibility with both reversible and\nnon-reversible MCMC samplers, while retaining unbiased samples with target\ndistribution $\\boldsymbol{\\mu}$ and near-zero variance performance. Extensive\nexperiments in graph sampling demonstrate consistent performance gains, and a\nmemory-efficient Least Recently Used (LRU) cache ensures scalability to large\ngeneral graphs.", "published": "2025-05-23 18:46:10", "link": "http://arxiv.org/abs/2505.18300v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Operator Learning for Schr\u00f6dinger Equation: Unitarity, Error Bounds, and Time Generalization", "abstract": "We consider the problem of learning the evolution operator for the\ntime-dependent Schr\\\"{o}dinger equation, where the Hamiltonian may vary with\ntime. Existing neural network-based surrogates often ignore fundamental\nproperties of the Schr\\\"{o}dinger equation, such as linearity and unitarity,\nand lack theoretical guarantees on prediction error or time generalization. To\naddress this, we introduce a linear estimator for the evolution operator that\npreserves a weak form of unitarity. We establish both upper and lower bounds on\nthe prediction error that hold uniformly over all sufficiently smooth initial\nwave functions. Additionally, we derive time generalization bounds that\nquantify how the estimator extrapolates beyond the time points seen during\ntraining. Experiments across real-world Hamiltonians -- including hydrogen\natoms, ion traps for qubit design, and optical lattices -- show that our\nestimator achieves relative errors $10^{-2}$ to $10^{-3}$ times smaller than\nstate-of-the-art methods such as the Fourier Neural Operator and DeepONet.", "published": "2025-05-23 18:32:53", "link": "http://arxiv.org/abs/2505.18288v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Feature Preserving Shrinkage on Bayesian Neural Networks via the R2D2 Prior", "abstract": "Bayesian neural networks (BNNs) treat neural network weights as random\nvariables, which aim to provide posterior uncertainty estimates and avoid\noverfitting by performing inference on the posterior weights. However, the\nselection of appropriate prior distributions remains a challenging task, and\nBNNs may suffer from catastrophic inflated variance or poor predictive\nperformance when poor choices are made for the priors. Existing BNN designs\napply different priors to weights, while the behaviours of these priors make it\ndifficult to sufficiently shrink noisy signals or they are prone to\novershrinking important signals in the weights. To alleviate this problem, we\npropose a novel R2D2-Net, which imposes the R^2-induced Dirichlet Decomposition\n(R2D2) prior to the BNN weights. The R2D2-Net can effectively shrink irrelevant\ncoefficients towards zero, while preventing key features from over-shrinkage.\nTo approximate the posterior distribution of weights more accurately, we\nfurther propose a variational Gibbs inference algorithm that combines the Gibbs\nupdating procedure and gradient-based optimization. This strategy enhances\nstability and consistency in estimation when the variational objective\ninvolving the shrinkage parameters is non-convex. We also analyze the evidence\nlower bound (ELBO) and the posterior concentration rates from a theoretical\nperspective. Experiments on both natural and medical image classification and\nuncertainty estimation tasks demonstrate satisfactory performance of our\nmethod.", "published": "2025-05-23 18:15:44", "link": "http://arxiv.org/abs/2505.18280v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Preconditioned Langevin Dynamics with Score-Based Generative Models for Infinite-Dimensional Linear Bayesian Inverse Problems", "abstract": "Designing algorithms for solving high-dimensional Bayesian inverse problems\ndirectly in infinite-dimensional function spaces - where such problems are\nnaturally formulated - is crucial to ensure stability and convergence as the\ndiscretization of the underlying problem is refined. In this paper, we\ncontribute to this line of work by analyzing a widely used sampler for linear\ninverse problems: Langevin dynamics driven by score-based generative models\n(SGMs) acting as priors, formulated directly in function space. Building on the\ntheoretical framework for SGMs in Hilbert spaces, we give a rigorous definition\nof this sampler in the infinite-dimensional setting and derive, for the first\ntime, error estimates that explicitly depend on the approximation error of the\nscore. As a consequence, we obtain sufficient conditions for global convergence\nin Kullback-Leibler divergence on the underlying function space. Preventing\nnumerical instabilities requires preconditioning of the Langevin algorithm and\nwe prove the existence and the form of an optimal preconditioner. The\npreconditioner depends on both the score error and the forward operator and\nguarantees a uniform convergence rate across all posterior modes. Our analysis\napplies to both Gaussian and a general class of non-Gaussian priors. Finally,\nwe present examples that illustrate and validate our theoretical findings.", "published": "2025-05-23 18:12:04", "link": "http://arxiv.org/abs/2505.18276v1", "categories": ["stat.ML", "cs.LG", "62F15, 65N21, 68Q32, 60Hxx, 65C05, 82C31, 28C20, 60G15, 60J60"], "primary_category": "stat.ML"}
{"title": "Representative Action Selection for Large Action-Space Meta-Bandits", "abstract": "We study the problem of selecting a subset from a large action space shared\nby a family of bandits, with the goal of achieving performance nearly matching\nthat of using the full action space. We assume that similar actions tend to\nhave related payoffs, modeled by a Gaussian process. To exploit this structure,\nwe propose a simple epsilon-net algorithm to select a representative subset. We\nprovide theoretical guarantees for its performance and compare it empirically\nto Thompson Sampling and Upper Confidence Bound.", "published": "2025-05-23 18:08:57", "link": "http://arxiv.org/abs/2505.18269v1", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ATMM-SAGA: Alternating Training for Multi-Module with Score-Aware Gated Attention SASV system", "abstract": "The objective of automatic speaker verification (ASV) systems is to determine\nwhether a given test speech utterance corresponds to a claimed enrolled\nspeaker. These systems have a wide range of applications, and ensuring their\nreliability is crucial. In this paper, we propose a spoofing-robust automatic\nspeaker verification (SASV) system employing a score-aware gated attention\n(SAGA) fusion scheme, integrating scores from a pre-trained countermeasure (CM)\nwith speaker embeddings from a pre-trained ASV. Specifically, we employ the\nAASIST and ECAPA-TDNN models. SAGA acts as an adaptive gating mechanism, where\nthe CM score determines how strongly ASV embeddings influence the final SASV\ndecision. Experiments on the ASVspoof2019 logical access dataset demonstrate\nthat the proposed SASV system achieves an SASV equal error rate (SASV-EER) and\nagnostic detection cost function (a-DCF) of 2.31%, 0.0603 for the development\nset and 2.18%, 0.0480 for the evaluation set.", "published": "2025-05-23 18:10:26", "link": "http://arxiv.org/abs/2505.18273v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "ABHINAYA -- A System for Speech Emotion Recognition In Naturalistic Conditions Challenge", "abstract": "Speech emotion recognition (SER) in naturalistic settings remains a challenge\ndue to the intrinsic variability, diverse recording conditions, and class\nimbalance. As participants in the Interspeech Naturalistic SER Challenge which\nfocused on these complexities, we present Abhinaya, a system integrating\nspeech-based, text-based, and speech-text models. Our approach fine-tunes\nself-supervised and speech large language models (SLLM) for speech\nrepresentations, leverages large language models (LLM) for textual context, and\nemploys speech-text modeling with an SLLM to capture nuanced emotional cues. To\ncombat class imbalance, we apply tailored loss functions and generate\ncategorical decisions through majority voting. Despite one model not being\nfully trained, the Abhinaya system ranked 4th among 166 submissions. Upon\ncompletion of training, it achieved state-of-the-art performance among\npublished results, demonstrating the effectiveness of our approach for SER in\nreal-world conditions.", "published": "2025-05-23 08:01:56", "link": "http://arxiv.org/abs/2505.18217v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Frequency and Bandwidth Design of FR3-Band Acoustic Filters", "abstract": "This article presents an approach to control the operating frequency and\nfractional bandwidth (FBW) of miniature acoustic filters in thin-film lithium\nniobate (TFLN). More specifically, we used the first-order antisymmetric (A1)\nmode in lateral-field-excited bulk acoustic wave resonators (XBARs) to achieve\nefficient operation at 20.5 GHz. Our technique leverages the\nthickness-dependent resonance frequency of A1 XBARs, combined with the in-plane\nanisotropic properties of 128$^\\circ$ Y-cut TFLN, to customize filter\ncharacteristics. The implemented three-element ladder filter prototype achieves\nan insertion loss (IL) of only 1.79 dB and a controlled 3-dB FBW of 8.58% at\n20.5 GHz, with an out-of-band (OoB) rejection greater than 14.9 dB across the\nentire FR3 band, while featuring a compact footprint of 0.90 $\\times$ 0.74\nmm$^2$. Moreover, an eight-element filter prototype shows an IL of 3.80 dB, an\nFBW of 6.12% at 22.0 GHz, and a high OoB rejection of 22.97 dB, demonstrating\nthe potential for expanding to higher-order filters. As frequency allocation\nrequirements become more stringent in future FR3 bands, our technique showcases\npromising capability in enabling compact and monolithic filter banks toward\nnext-generation acoustic filters for 6G and beyond.", "published": "2025-05-23 21:29:46", "link": "http://arxiv.org/abs/2505.18388v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Current-Steering DAC Architecture Design for Amplitude Mismatch Error Minimization", "abstract": "We propose a novel digital-to-analog converter (DAC) weighting architecture\nthat statistically minimizes the distortion caused by random current\nmismatches. Unlike binary, thermometer-coded, and segmented DACs, the current\nweights of the proposed architecture are not an integer power of 2 or any other\ninteger number. We present a heuristic algorithm for a static mapping of DAC\ninput codewords into corresponding DAC switches. High-level Matlab simulations\nare performed to illustrate the static performance improvement over the\nsegmented structure.", "published": "2025-05-23 20:22:11", "link": "http://arxiv.org/abs/2505.18353v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CC-OTDR Sequence Shaping Enabling Joint Co-directional Sensing and Communication", "abstract": "CC-OTDR signal envelope shaping is introduced to reduce the impact of\nnon-linear signal interactions on a neighboring wavelength data channel when\nco-propagating the probing signal with the data signal. Joint co-directional\nacoustic sensing and 200 Gbps transmission are demonstrated over a 50 km link.", "published": "2025-05-23 10:30:58", "link": "http://arxiv.org/abs/2505.18225v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "RaDeR: Reasoning-aware Dense Retrieval Models", "abstract": "We propose RaDeR, a set of reasoning-based dense retrieval models trained\nwith data derived from mathematical problem solving using large language models\n(LLMs). Our method leverages retrieval-augmented reasoning trajectories of an\nLLM and self-reflective relevance evaluation, enabling the creation of both\ndiverse and hard-negative samples for reasoning-intensive relevance. RaDeR\nretrievers, trained for mathematical reasoning, effectively generalize to\ndiverse reasoning tasks in the BRIGHT and RAR-b benchmarks, consistently\noutperforming strong baselines in overall performance. Notably, RaDeR achieves\nsignificantly higher performance than baselines on the Math and Coding splits.\nIn addition, RaDeR presents the first dense retriever that outperforms BM25\nwhen queries are Chain-of-Thought reasoning steps, underscoring the critical\nrole of reasoning-based retrieval to augment reasoning language models.\nFurthermore, RaDeR achieves comparable or superior performance while using only\n2.5% of the training data used by the concurrent work REASONIR, highlighting\nthe quality of our synthesized training data.", "published": "2025-05-23 22:18:32", "link": "http://arxiv.org/abs/2505.18405v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training", "abstract": "In our prior works, we introduced a scalable streaming speech synthesis\nmodel, CosyVoice 2, which integrates a large language model (LLM) and a\nchunk-aware flow matching (FM) model, and achieves low-latency bi-streaming\nspeech synthesis and human-parity quality. Despite these advancements,\nCosyVoice 2 exhibits limitations in language coverage, domain diversity, data\nvolume, text formats, and post-training techniques. In this paper, we present\nCosyVoice 3, an improved model designed for zero-shot multilingual speech\nsynthesis in the wild, surpassing its predecessor in content consistency,\nspeaker similarity, and prosody naturalness. Key features of CosyVoice 3\ninclude: 1) A novel speech tokenizer to improve prosody naturalness, developed\nvia supervised multi-task training, including automatic speech recognition,\nspeech emotion recognition, language identification, audio event detection, and\nspeaker analysis. 2) A new differentiable reward model for post-training\napplicable not only to CosyVoice 3 but also to other LLM-based speech synthesis\nmodels. 3) Dataset Size Scaling: Training data is expanded from ten thousand\nhours to one million hours, encompassing 9 languages and 18 Chinese dialects\nacross various domains and text formats. 4) Model Size Scaling: Model\nparameters are increased from 0.5 billion to 1.5 billion, resulting in enhanced\nperformance on our multilingual benchmark due to the larger model capacity.\nThese advancements contribute significantly to the progress of speech synthesis\nin the wild. We encourage readers to listen to the demo at\nhttps://funaudiollm.github.io/cosyvoice3.", "published": "2025-05-23 07:55:21", "link": "http://arxiv.org/abs/2505.17589v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
