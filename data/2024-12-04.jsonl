{"title": "Leveraging Generative Adversarial Networks for Addressing Data Imbalance in Financial Market Supervision", "abstract": "This study explores the application of generative adversarial networks in\nfinancial market supervision, especially for solving the problem of data\nimbalance to improve the accuracy of risk prediction. Since financial market\ndata are often imbalanced, especially high-risk events such as market\nmanipulation and systemic risk occur less frequently, traditional models have\ndifficulty effectively identifying these minority events. This study proposes\nto generate synthetic data with similar characteristics to these minority\nevents through GAN to balance the dataset, thereby improving the prediction\nperformance of the model in financial supervision. Experimental results show\nthat compared with traditional oversampling and undersampling methods, the data\ngenerated by GAN has significant advantages in dealing with imbalance problems\nand improving the prediction accuracy of the model. This method has broad\napplication potential in financial regulatory agencies such as the U.S.\nSecurities and Exchange Commission (SEC), the Financial Industry Regulatory\nAuthority (FINRA), the Federal Deposit Insurance Corporation (FDIC), and the\nFederal Reserve.", "published": "2024-12-04 08:06:47", "link": "http://arxiv.org/abs/2412.15222v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Hidden Markov graphical models with state-dependent generalized hyperbolic distributions", "abstract": "In this paper we develop a novel hidden Markov graphical model to investigate\ntime-varying interconnectedness between different financial markets. To\nidentify conditional correlation structures under varying market conditions and\naccommodate stylized facts embedded in financial time series, we rely upon the\ngeneralized hyperbolic family of distributions with time-dependent parameters\nevolving according to a latent Markov chain. We exploit its location-scale\nmixture representation to build a penalized EM algorithm for estimating the\nstate-specific sparse precision matrices by means of an $L_1$ penalty. The\nproposed approach leads to regime-specific conditional correlation graphs that\nallow us to identify different degrees of network connectivity of returns over\ntime. The methodology's effectiveness is validated through simulation exercises\nunder different scenarios. In the empirical analysis we apply our model to\ndaily returns of a large set of market indexes, cryptocurrencies and commodity\nfutures over the period 2017-2023.", "published": "2024-12-04 19:01:45", "link": "http://arxiv.org/abs/2412.03668v1", "categories": ["stat.ME", "q-fin.ST"], "primary_category": "stat.ME"}
{"title": "Dynamic Graph Neural ODE Network for Multi-modal Emotion Recognition in\n  Conversation", "abstract": "Multimodal emotion recognition in conversation (MERC) refers to identifying\nand classifying human emotional states by combining data from multiple\ndifferent modalities (e.g., audio, images, text, video, etc.). Most existing\nmultimodal emotion recognition methods use GCN to improve performance, but\nexisting GCN methods are prone to overfitting and cannot capture the temporal\ndependency of the speaker's emotions. To address the above problems, we propose\na Dynamic Graph Neural Ordinary Differential Equation Network (DGODE) for MERC,\nwhich combines the dynamic changes of emotions to capture the temporal\ndependency of speakers' emotions, and effectively alleviates the overfitting\nproblem of GCNs. Technically, the key idea of DGODE is to utilize an adaptive\nmixhop mechanism to improve the generalization ability of GCNs and use the\ngraph ODE evolution network to characterize the continuous dynamics of node\nrepresentations over time and capture temporal dependencies. Extensive\nexperiments on two publicly available multimodal emotion recognition datasets\ndemonstrate that the proposed DGODE model has superior performance compared to\nvarious baselines. Furthermore, the proposed DGODE can also alleviate the\nover-smoothing problem, thereby enabling the construction of a deep GCN\nnetwork.", "published": "2024-12-04 01:07:59", "link": "http://arxiv.org/abs/2412.02935v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Curriculum-style Data Augmentation for LLM-based Metaphor Detection", "abstract": "Recently, utilizing large language models (LLMs) for metaphor detection has\nachieved promising results. However, these methods heavily rely on the\ncapabilities of closed-source LLMs, which come with relatively high inference\ncosts and latency. To address this, we propose a method for metaphor detection\nby fine-tuning open-source LLMs, effectively reducing inference costs and\nlatency with a single inference step. Furthermore, metaphor detection suffers\nfrom a severe data scarcity problem, which hinders effective fine-tuning of\nLLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA).\nSpecifically, before fine-tuning, we evaluate the training data to identify\ncorrectly predicted instances for fine-tuning, while incorrectly predicted\ninstances are used as seed data for data augmentation. This approach enables\nthe model to quickly learn simpler knowledge and progressively acquire more\ncomplex knowledge, thereby improving performance incrementally. Experimental\nresults demonstrate that our method achieves state-of-the-art performance\nacross all baselines. Additionally, we provide detailed ablation studies to\nvalidate the effectiveness of CDA.", "published": "2024-12-04 02:05:21", "link": "http://arxiv.org/abs/2412.02956v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Variability vs. Machine Consistency: A Linguistic Analysis of\n  Texts Generated by Humans and Large Language Models", "abstract": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. Recent research\nhas predominantly focused on using LLMs to classify text as either\nhuman-written or machine-generated. In our study, we adopt a different approach\nby profiling texts spanning four domains based on 250 distinct linguistic\nfeatures. We select the M4 dataset from the Subtask B of SemEval 2024 Task 8.\nWe automatically calculate various linguistic features with the LFTK tool and\nadditionally measure the average syntactic depth, semantic similarity, and\nemotional content for each document. We then apply a two-dimensional PCA\nreduction to all the calculated features. Our analyses reveal significant\ndifferences between human-written texts and those generated by LLMs,\nparticularly in the variability of these features, which we find to be\nconsiderably higher in human-written texts. This discrepancy is especially\nevident in text genres with less rigid linguistic style constraints. Our\nfindings indicate that humans write texts that are less cognitively demanding,\nwith higher semantic content, and richer emotional content compared to texts\ngenerated by LLMs. These insights underscore the need for incorporating\nmeaningful linguistic features to enhance the understanding of textual outputs\nof LLMs.", "published": "2024-12-04 04:38:35", "link": "http://arxiv.org/abs/2412.03025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling\n  Capability of LLM", "abstract": "Empathetic conversation is a crucial characteristic in daily conversations\nbetween individuals. Nowadays, Large Language models (LLMs) have shown\noutstanding performance in generating empathetic responses. Knowledge bases\nlike COMET can assist LLMs in mitigating illusions and enhancing the\nunderstanding of users' intentions and emotions. However, models remain heavily\nreliant on fixed knowledge bases and unrestricted incorporation of external\nknowledge can introduce noise. Tool learning is a flexible end-to-end approach\nthat assists LLMs in handling complex problems. In this paper, we propose\nEmotional Knowledge Tool Calling (EKTC) framework, which encapsulates the\ncommonsense knowledge bases as empathetic tools, enabling LLMs to integrate\nexternal knowledge flexibly through tool calling. In order to adapt the models\nto the new task, we construct a novel dataset TOOL-ED based on the\nEMPATHETICMPATHETIC DIALOGUE (ED) dataset. We validate EKTC on the ED dataset,\nand the experimental results demonstrate that our framework can enhance the\nability of LLMs to generate empathetic responses effectively.", "published": "2024-12-04 07:50:17", "link": "http://arxiv.org/abs/2412.03096v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A surprisal oracle for when every layer counts", "abstract": "Active Curriculum Language Modeling (ACLM; Hong et al., 2023) is a learner\ndirected approach to training a language model. We proposed the original\nversion of this process in our submission to the BabyLM 2023 task, and now we\npropose an updated ACLM process for the BabyLM 2024 task. ACLM involves an\niteratively- and dynamically-constructed curriculum informed over the training\nprocess by a model of uncertainty; other training items that are similarly\nuncertain to a least certain candidate item are prioritized. Our new process\nimproves the similarity model so that it is more dynamic, and we run ACLM over\nthe most successful model from the BabyLM 2023 task: ELC-BERT (Charpentier and\nSamuel, 2023). We find that while our models underperform on fine-grained\ngrammatical inferences, they outperform the BabyLM 2024 official base-lines on\ncommon-sense and world-knowledge tasks. We make our code available at https:\n//github.com/asayeed/ActiveBaby.", "published": "2024-12-04 07:53:45", "link": "http://arxiv.org/abs/2412.03098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Byte BPE Tokenization as an Inverse string Homomorphism", "abstract": "Tokenization is an important preprocessing step in the training and inference\nof large language models (LLMs). While there has been extensive research on the\nexpressive power of the neural achitectures used in LLMs, the impact of\ntokenization has not been well understood. In this work, we demonstrate that\ntokenization, irrespective of the algorithm used, acts as an inverse\nhomomorphism between strings and tokens. This suggests that the character space\nof the source language and the token space of the tokenized language are\nhomomorphic, preserving the structural properties of the source language.\nAdditionally, we explore the concept of proper tokenization, which refers to an\nunambiguous tokenization returned from the tokenizer. Our analysis reveals that\nthe expressiveness of neural architectures in recognizing context-free\nlanguages is not affected by tokenization.", "published": "2024-12-04 09:38:11", "link": "http://arxiv.org/abs/2412.03160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic detection of diseases in Spanish clinical notes combining\n  medical language models and ontologies", "abstract": "In this paper we present a hybrid method for the automatic detection of\ndermatological pathologies in medical reports. We use a large language model\ncombined with medical ontologies to predict, given a first appointment or\nfollow-up medical report, the pathology a person may suffer from. The results\nshow that teaching the model to learn the type, severity and location on the\nbody of a dermatological pathology, as well as in which order it has to learn\nthese three features, significantly increases its accuracy. The article\npresents the demonstration of state-of-the-art results for classification of\nmedical texts with a precision of 0.84, micro and macro F1-score of 0.82 and\n0.75, and makes both the method and the data set used available to the\ncommunity.", "published": "2024-12-04 09:57:57", "link": "http://arxiv.org/abs/2412.03176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weighted-Reward Preference Optimization for Implicit Model Fusion", "abstract": "While fusing heterogeneous open-source LLMs with varying architectures and\nsizes can potentially integrate the strengths of different models, existing\nfusion methods face significant challenges, such as vocabulary alignment and\nmerging distribution matrices. These procedures are not only complex but also\nprone to introducing noise and errors. In this paper, we propose an implicit\nfusion method, Weighted-Reward Preference Optimization (WRPO), which leverages\npreference optimization between the source LLMs and the target LLM to transfer\ntheir capabilities effectively. WRPO eliminates the need for vocabulary\nalignment and matrix fusion and can be efficiently scaled to accommodate\nvarious LLMs. To address distributional deviations between the source and\ntarget LLMs, WRPO introduces a progressive adaptation strategy that gradually\nshifts reliance on preferred examples from the target LLM to the source LLMs.\nExtensive experiments on the MT-Bench, AlpacaEval-2, and Arena-Hard benchmarks\ndemonstrate that WRPO consistently outperforms existing knowledge fusion\nmethods and various fine-tuning baselines. When applied to LLaMA3-8B-Instruct\nas the target model, WRPO achieves a length-controlled win rate of 55.9%\nagainst GPT-4-Preview-1106 on AlpacaEval-2 and a win rate of 46.2% against\nGPT-4-0314 on Arena-Hard. Our code is available at\nhttps://github.com/SLIT-AI/WRPO.", "published": "2024-12-04 10:15:12", "link": "http://arxiv.org/abs/2412.03187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linq-Embed-Mistral Technical Report", "abstract": "This report explores the enhancement of text retrieval performance using\nadvanced data refinement techniques. We develop\nLinq-Embed-Mistral\\footnote{\\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}\nby building on the E5-mistral and Mistral-7B-v0.1 models, focusing on\nsophisticated data crafting, data filtering, and negative mining methods, which\nare highly tailored to each task, applied to both existing benchmark dataset\nand highly tailored synthetic dataset generated via large language models\n(LLMs). Linq-Embed-Mistral excels in the MTEB benchmarks (as of May 29, 2024),\nachieving an average score of 68.2 across 56 datasets, and ranks 1st among all\nmodels for retrieval tasks on the MTEB leaderboard with a performance score of\n60.2. This performance underscores its superior capability in enhancing search\nprecision and reliability. Our contributions include advanced data refinement\nmethods that significantly improve model performance on benchmark and synthetic\ndatasets, techniques for homogeneous task ordering and mixed task fine-tuning\nto enhance model generalization and stability, and a streamlined evaluation\nprocess using 4-bit precision and a light retrieval evaluation set, which\naccelerates validation without sacrificing accuracy.", "published": "2024-12-04 11:18:32", "link": "http://arxiv.org/abs/2412.03223v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PERL: Pinyin Enhanced Rephrasing Language Model for Chinese ASR N-best\n  Error Correction", "abstract": "ASR correction methods have predominantly focused on general datasets and\nhave not effectively utilized Pinyin information, unique to the Chinese\nlanguage. In this study, we address this gap by proposing a Pinyin Enhanced\nRephrasing Language Model (PERL), specifically designed for N-best correction\nscenarios. Additionally, we implement a length predictor module to address the\nvariable-length problem. We conduct experiments on the Aishell-1 dataset and\nour newly proposed DoAD dataset. The results show that our approach outperforms\nbaseline methods, achieving a 29.11% reduction in Character Error Rate (CER) on\nAishell-1 and around 70% CER reduction on domain-specific datasets.\nFurthermore, our approach leverages Pinyin similarity at the token level,\nproviding an advantage over baselines and leading to superior performance.", "published": "2024-12-04 11:28:52", "link": "http://arxiv.org/abs/2412.03230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking terminology building capabilities of ChatGPT on an\n  English-Russian Fashion Corpus", "abstract": "This paper compares the accuracy of the terms extracted using SketchEngine,\nTBXTools and ChatGPT. In addition, it evaluates the quality of the definitions\nproduced by ChatGPT for these terms. The research is carried out on a\ncomparable corpus of fashion magazines written in English and Russian collected\nfrom the web. A gold standard for the fashion terminology was also developed by\nidentifying web pages that can be harvested automatically and contain\ndefinitions of terms from the fashion domain in English and Russian. This gold\nstandard was used to evaluate the quality of the extracted terms and of the\ndefinitions produced. Our evaluation shows that TBXTools and SketchEngine,\nwhile capable of high recall, suffer from reduced precision as the number of\nterms increases, which affects their overall performance. Conversely, ChatGPT\ndemonstrates superior performance, maintaining or improving precision as more\nterms are considered. Analysis of the definitions produced by ChatGPT for 60\ncommonly used terms in English and Russian shows that ChatGPT maintains a\nreasonable level of accuracy and fidelity across languages, but sometimes the\ndefinitions in both languages miss crucial specifics and include unnecessary\ndeviations. Our research reveals that no single tool excels universally; each\nhas strengths suited to particular aspects of terminology extraction and\napplication.", "published": "2024-12-04 11:43:08", "link": "http://arxiv.org/abs/2412.03242v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alignment at Pre-training! Towards Native Alignment for Arabic LLMs", "abstract": "The alignment of large language models (LLMs) is critical for developing\neffective and safe language models. Traditional approaches focus on aligning\nmodels during the instruction tuning or reinforcement learning stages, referred\nto in this paper as `post alignment'. We argue that alignment during the\npre-training phase, which we term `native alignment', warrants investigation.\nNative alignment aims to prevent unaligned content from the beginning, rather\nthan relying on post-hoc processing. This approach leverages extensively\naligned pre-training data to enhance the effectiveness and usability of\npre-trained models. Our study specifically explores the application of native\nalignment in the context of Arabic LLMs. We conduct comprehensive experiments\nand ablation studies to evaluate the impact of native alignment on model\nperformance and alignment stability. Additionally, we release open-source\nArabic LLMs that demonstrate state-of-the-art performance on various\nbenchmarks, providing significant benefits to the Arabic LLM community.", "published": "2024-12-04 11:52:03", "link": "http://arxiv.org/abs/2412.03253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AntLM: Bridging Causal and Masked Language Models", "abstract": "Causal Language Modeling (CLM) and Masked Language Modeling (MLM) are two\nmainstream learning paradigms based on Transformer networks, specifically the\nDecoder-only and Encoder-only architectures. The strengths of each paradigm in\ndownstream tasks have shown a mix of advantages and disadvantages. In the past\nBabyLM Challenge 2023, although the MLM paradigm achieved the best average\nperformance, the CLM paradigm demonstrated significantly faster convergence\nrates. For the BabyLM Challenge 2024, we propose a novel language modeling\nparadigm named $\\textbf{AntLM}$, which integrates both CLM and MLM to leverage\nthe advantages of these two classic paradigms. We chose the strict-small track\nand conducted experiments on two foundation models: BabyLlama, representing\nCLM, and LTG-BERT, representing MLM. During the training process for specific\nfoundation models, we alternate between applying CLM or MLM training objectives\nand causal or bidirectional attention masks. Experimental results show that\ncombining the two pretraining objectives leverages their strengths, enhancing\noverall training performance. Under the same epochs, $AntLM_{BabyLlama}$\nimproves Macro-average by 1%, and $AntLM_{LTG-BERT}$ achieves a 2.2% increase\nover the baselines.", "published": "2024-12-04 12:34:15", "link": "http://arxiv.org/abs/2412.03275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global MMLU: Understanding and Addressing Cultural and Linguistic Biases\n  in Multilingual Evaluation", "abstract": "Cultural biases in multilingual datasets pose significant challenges for\ntheir effectiveness as global benchmarks. These biases stem not only from\ndifferences in language but also from the cultural knowledge required to\ninterpret questions, reducing the practical utility of translated datasets like\nMMLU. Furthermore, translation often introduces artefacts that can distort the\nmeaning or clarity of questions in the target language. A common practice in\nmultilingual evaluation is to rely on machine-translated evaluation sets, but\nsimply translating a dataset is insufficient to address these challenges. In\nthis work, we trace the impact of both of these issues on multilingual\nevaluations and ensuing model performances. Our large-scale evaluation of\nstate-of-the-art open and proprietary models illustrates that progress on MMLU\ndepends heavily on learning Western-centric concepts, with 28% of all questions\nrequiring culturally sensitive knowledge. Moreover, for questions requiring\ngeographic knowledge, an astounding 84.9% focus on either North American or\nEuropean regions. Rankings of model evaluations change depending on whether\nthey are evaluated on the full portion or the subset of questions annotated as\nculturally sensitive, showing the distortion to model rankings when blindly\nrelying on translated MMLU. We release Global MMLU, an improved MMLU with\nevaluation coverage across 42 languages -- with improved overall quality by\nengaging with compensated professional and community annotators to verify\ntranslation quality while also rigorously evaluating cultural biases present in\nthe original dataset. This comprehensive Global MMLU set also includes\ndesignated subsets labeled as culturally sensitive and culturally agnostic to\nallow for more holistic, complete evaluation.", "published": "2024-12-04 13:27:09", "link": "http://arxiv.org/abs/2412.03304v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Typologie des comportements utilisateurs : {\u00e9}tude exploratoire des\n  sessions de recherche complexe sur le Web", "abstract": "In this study, we propose an exploratory approach aiming at a typology of\nuser behaviour during a Web search session. We describe a typology based on\ngeneric IR variables (e.g. number of queries), but also on the study of topic\n(propositions with distinct semantic content defined from the search\nstatement). To this end, we gathered experimental data enabling us to study\nvariations across users (N=70) for the same task. We performed a\nmultidimensional analysis and propose a 5 classes typology based on the\nindividual behaviours during the processing of a complex search task.", "published": "2024-12-04 13:32:14", "link": "http://arxiv.org/abs/2412.03309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Yankari: A Monolingual Yoruba Dataset", "abstract": "This paper presents Yankari, a large-scale monolingual dataset for the Yoruba\nlanguage, aimed at addressing the critical gap in Natural Language Processing\n(NLP) resources for this important West African language. Despite being spoken\nby over 30 million people, Yoruba has been severely underrepresented in NLP\nresearch and applications. We detail our methodology for creating this dataset,\nwhich includes careful source selection, automated quality control, and\nrigorous data cleaning processes. The Yankari dataset comprises 51,407\ndocuments from 13 diverse sources, totaling over 30 million tokens. Our\napproach focuses on ethical data collection practices, avoiding problematic\nsources and addressing issues prevalent in existing datasets. We provide\nthorough automated evaluations of the dataset, demonstrating its quality\ncompared to existing resources. The Yankari dataset represents a significant\nadvancement in Yoruba language resources, providing a foundation for developing\nmore accurate NLP models, supporting comparative linguistic studies, and\ncontributing to the digital accessibility of the Yoruba language.", "published": "2024-12-04 14:05:18", "link": "http://arxiv.org/abs/2412.03334v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RedStone: Curating General, Code, Math, and QA Data for Large Language\n  Models", "abstract": "Pre-training Large Language Models (LLMs) on high-quality, meticulously\ncurated datasets is widely recognized as critical for enhancing their\nperformance and generalization capabilities. This study explores the untapped\npotential of Common Crawl as a comprehensive and flexible resource for\npre-training LLMs, addressing both general-purpose language understanding and\nspecialized domain knowledge. We introduce RedStone, an innovative and scalable\npipeline engineered to extract and process data from Common Crawl, facilitating\nthe creation of extensive and varied pre-training datasets. Unlike traditional\ndatasets, which often require expensive curation and domain-specific expertise,\nRedStone leverages the breadth of Common Crawl to deliver datasets tailored to\na wide array of domains. In this work, we exemplify its capability by\nconstructing pre-training datasets across multiple fields, including general\nlanguage understanding, code, mathematics, and question-answering tasks. The\nflexibility of RedStone allows for easy adaptation to other specialized\ndomains, significantly lowering the barrier to creating valuable\ndomain-specific datasets. Our findings demonstrate that Common Crawl, when\nharnessed through effective pipelines like RedStone, can serve as a rich,\nrenewable source of pre-training data, unlocking new avenues for domain\nadaptation and knowledge discovery in LLMs. This work also underscores the\nimportance of innovative data acquisition strategies and highlights the role of\nweb-scale data as a powerful resource in the continued evolution of LLMs.\nRedStone code and data samples will be publicly available at\n\\url{https://aka.ms/redstone}.", "published": "2024-12-04 15:27:39", "link": "http://arxiv.org/abs/2412.03398v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Sentiment Analysis Based on BERT and ResNet", "abstract": "With the rapid development of the Internet and social media, multi-modal data\n(text and image) is increasingly important in sentiment analysis tasks.\nHowever, the existing methods are difficult to effectively fuse text and image\nfeatures, which limits the accuracy of analysis. To solve this problem, a\nmultimodal sentiment analysis framework combining BERT and ResNet was proposed.\nBERT has shown strong text representation ability in natural language\nprocessing, and ResNet has excellent image feature extraction performance in\nthe field of computer vision. Firstly, BERT is used to extract the text feature\nvector, and ResNet is used to extract the image feature representation. Then, a\nvariety of feature fusion strategies are explored, and finally the fusion model\nbased on attention mechanism is selected to make full use of the complementary\ninformation between text and image. Experimental results on the public dataset\nMAVA-single show that compared with the single-modal models that only use BERT\nor ResNet, the proposed multi-modal model improves the accuracy and F1 score,\nreaching the best accuracy of 74.5%. This study not only provides new ideas and\nmethods for multimodal sentiment analysis, but also demonstrates the\napplication potential of BERT and ResNet in cross-domain fusion. In the future,\nmore advanced feature fusion techniques and optimization strategies will be\nexplored to further improve the accuracy and generalization ability of\nmultimodal sentiment analysis.", "published": "2024-12-04 15:55:20", "link": "http://arxiv.org/abs/2412.03625v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Language Models as Synthetic Data Generators", "abstract": "Given the increasing use of synthetic data in language model (LM)\npost-training, an LM's ability to generate high-quality data has become nearly\nas crucial as its ability to solve problems directly. While prior works have\nfocused on developing effective data generation methods, they lack systematic\ncomparison of different LMs as data generators in a unified setting. To address\nthis gap, we propose AgoraBench, a benchmark that provides standardized\nsettings and metrics to evaluate LMs' data generation abilities. Through\nsynthesizing 1.26 million training instances using 6 LMs and training 99\nstudent models, we uncover key insights about LMs' data generation\ncapabilities. First, we observe that LMs exhibit distinct strengths. For\ninstance, GPT-4o excels at generating new problems, while Claude-3.5-Sonnet\nperforms better at enhancing existing ones. Furthermore, our analysis reveals\nthat an LM's data generation ability doesn't necessarily correlate with its\nproblem-solving ability. Instead, multiple intrinsic features of data\nquality-including response quality, perplexity, and instruction\ndifficulty-collectively serve as better indicators. Finally, we demonstrate\nthat strategic choices in output format and cost-conscious model selection\nsignificantly impact data generation effectiveness.", "published": "2024-12-04 19:20:32", "link": "http://arxiv.org/abs/2412.03679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acquired TASTE: Multimodal Stance Detection with Textual and Structural\n  Embeddings", "abstract": "Stance detection plays a pivotal role in enabling an extensive range of\ndownstream applications, from discourse parsing to tracing the spread of fake\nnews and the denial of scientific facts. While most stance classification\nmodels rely on textual representation of the utterance in question, prior work\nhas demonstrated the importance of the conversational context in stance\ndetection. In this work we introduce TASTE -- a multimodal architecture for\nstance detection that harmoniously fuses Transformer-based content embedding\nwith unsupervised structural embedding. Through the fine-tuning of a pretrained\ntransformer and the amalgamation with social embedding via a Gated Residual\nNetwork (GRN) layer, our model adeptly captures the complex interplay between\ncontent and conversational structure in determining stance. TASTE achieves\nstate-of-the-art results on common benchmarks, significantly outperforming an\narray of strong baselines. Comparative evaluations underscore the benefits of\nsocial grounding -- emphasizing the criticality of concurrently harnessing both\ncontent and structure for enhanced stance detection.", "published": "2024-12-04 19:23:37", "link": "http://arxiv.org/abs/2412.03681v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-specific Question Answering with Hybrid Search", "abstract": "Domain specific question answering is an evolving field that requires\nspecialized solutions to address unique challenges. In this paper, we show that\na hybrid approach combining a fine-tuned dense retriever with keyword based\nsparse search methods significantly enhances performance. Our system leverages\na linear combination of relevance signals, including cosine similarity from\ndense retrieval, BM25 scores, and URL host matching, each with tunable boost\nparameters. Experimental results indicate that this hybrid method outperforms\nour single-retriever system, achieving improved accuracy while maintaining\nrobust contextual grounding. These findings suggest that integrating multiple\nretrieval methodologies with weighted scoring effectively addresses the\ncomplexities of domain specific question answering in enterprise settings.", "published": "2024-12-04 22:04:13", "link": "http://arxiv.org/abs/2412.03736v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatic Metacognitive Prompting Improves LLM Performance on Sarcasm\n  Detection", "abstract": "Sarcasm detection is a significant challenge in sentiment analysis due to the\nnuanced and context-dependent nature of verbiage. We introduce Pragmatic\nMetacognitive Prompting (PMP) to improve the performance of Large Language\nModels (LLMs) in sarcasm detection, which leverages principles from pragmatics\nand reflection helping LLMs interpret implied meanings, consider contextual\ncues, and reflect on discrepancies to identify sarcasm. Using state-of-the-art\nLLMs such as LLaMA-3-8B, GPT-4o, and Claude 3.5 Sonnet, PMP achieves\nstate-of-the-art performance on GPT-4o on MUStARD and SemEval2018. This study\ndemonstrates that integrating pragmatic reasoning and metacognitive strategies\ninto prompting significantly enhances LLMs' ability to detect sarcasm, offering\na promising direction for future research in sentiment analysis.", "published": "2024-12-04 07:16:30", "link": "http://arxiv.org/abs/2412.04509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Conversational Psychotherapy: Integrating Privacy,\n  Dual-Memory, and Domain Expertise with Large Language Models", "abstract": "Mental health has increasingly become a global issue that reveals the\nlimitations of traditional conversational psychotherapy, constrained by\nlocation, time, expense, and privacy concerns. In response to these challenges,\nwe introduce SoulSpeak, a Large Language Model (LLM)-enabled chatbot designed\nto democratize access to psychotherapy. SoulSpeak improves upon the\ncapabilities of standard LLM-enabled chatbots by incorporating a novel\ndual-memory component that combines short-term and long-term context via\nRetrieval Augmented Generation (RAG) to offer personalized responses while\nensuring the preservation of user privacy and intimacy through a dedicated\nprivacy module. In addition, it leverages a counseling chat dataset of\ntherapist-client interactions and various prompting techniques to align the\ngenerated responses with psychotherapeutic methods. We introduce two fine-tuned\nBERT models to evaluate the system against existing LLMs and human therapists:\nthe Conversational Psychotherapy Preference Model (CPPM) to simulate human\npreference among responses and another to assess response relevance to user\ninput. CPPM is useful for training and evaluating psychotherapy-focused\nlanguage models independent from SoulSpeak, helping with the constrained\nresources available for psychotherapy. Furthermore, the effectiveness of the\ndual-memory component and the robustness of the privacy module are also\nexamined. Our findings highlight the potential and challenge of enhancing\nmental health care by offering an alternative that combines the expertise of\ntraditional therapy with the advantages of LLMs, providing a promising way to\naddress the accessibility and personalization gap in current mental health\nservices.", "published": "2024-12-04 03:02:46", "link": "http://arxiv.org/abs/2412.02987v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Measure of the System Dependence of Automated Metrics", "abstract": "Automated metrics for Machine Translation have made significant progress,\nwith the goal of replacing expensive and time-consuming human evaluations.\nThese metrics are typically assessed by their correlation with human judgments,\nwhich captures the monotonic relationship between human and metric scores.\nHowever, we argue that it is equally important to ensure that metrics treat all\nsystems fairly and consistently. In this paper, we introduce a method to\nevaluate this aspect.", "published": "2024-12-04 09:21:46", "link": "http://arxiv.org/abs/2412.03152v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Level Correlation Network For Few-Shot Image Classification", "abstract": "Few-shot image classification(FSIC) aims to recognize novel classes given few\nlabeled images from base classes. Recent works have achieved promising\nclassification performance, especially for metric-learning methods, where a\nmeasure at only image feature level is usually used. In this paper, we argue\nthat measure at such a level may not be effective enough to generalize from\nbase to novel classes when using only a few images. Instead, a multi-level\ndescriptor of an image is taken for consideration in this paper. We propose a\nmulti-level correlation network (MLCN) for FSIC to tackle this problem by\neffectively capturing local information. Concretely, we present the\nself-correlation module and cross-correlation module to learn the semantic\ncorrespondence relation of local information based on learned representations.\nMoreover, we propose a pattern-correlation module to capture the pattern of\nfine-grained images and find relevant structural patterns between base classes\nand novel classes. Extensive experiments and analysis show the effectiveness of\nour proposed method on four widely-used FSIC benchmarks. The code for our\napproach is available at: https://github.com/Yunkai696/MLCN.", "published": "2024-12-04 09:36:24", "link": "http://arxiv.org/abs/2412.03159v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills\n  in LLMs", "abstract": "The current evaluation of mathematical skills in LLMs is limited, as existing\nbenchmarks are either relatively small, primarily focus on elementary and\nhigh-school problems, or lack diversity in topics. Additionally, the inclusion\nof visual elements in tasks remains largely under-explored.\n  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100\nunpublished open-ended university-level problems sourced from teaching\nmaterials. It is balanced across six core subjects, with 20% of multimodal\nproblems. Given the open-ended nature of U-MATH problems, we employ an LLM to\njudge the correctness of generated solutions. To this end, we release\n$\\mu$-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.\n  The evaluation of general domain, math-specific, and multimodal LLMs\nhighlights the challenges presented by U-MATH. Our findings reveal that LLMs\nachieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%\non visual problems. The solution assessment proves challenging for LLMs, with\nthe best LLM judge having an F1-score of 80% on $\\mu$-MATH.", "published": "2024-12-04 10:44:50", "link": "http://arxiv.org/abs/2412.03205v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does Safety Training of LLMs Generalize to Semantically Related Natural\n  Prompts?", "abstract": "Large Language Models (LLMs) are known to be susceptible to crafted\nadversarial attacks or jailbreaks that lead to the generation of objectionable\ncontent despite being aligned to human preferences using safety fine-tuning\nmethods. While the large dimensionality of input token space makes it\ninevitable to find adversarial prompts that can jailbreak these models, we aim\nto evaluate whether safety fine-tuned LLMs are safe against natural prompts\nwhich are semantically related to toxic seed prompts that elicit safe responses\nafter alignment. We surprisingly find that popular aligned LLMs such as GPT-4\ncan be compromised using naive prompts that are NOT even crafted with an\nobjective of jailbreaking the model. Furthermore, we empirically show that\ngiven a seed prompt that elicits a toxic response from an unaligned model, one\ncan systematically generate several semantically related natural prompts that\ncan jailbreak aligned LLMs. Towards this, we propose a method of Response\nGuided Question Augmentation (ReG-QA) to evaluate the generalization of safety\naligned LLMs to natural prompts, that first generates several toxic answers\ngiven a seed question using an unaligned LLM (Q to A), and further leverages an\nLLM to generate questions that are likely to produce these answers (A to Q). We\ninterestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to\nproducing natural jailbreak questions from unsafe content (without denial) and\ncan thus be used for the latter (A to Q) step. We obtain attack success rates\nthat are comparable to/ better than leading adversarial attack methods on the\nJailbreakBench leaderboard, while being significantly more stable against\ndefenses such as Smooth-LLM and Synonym Substitution, which are effective\nagainst existing all attacks on the leaderboard.", "published": "2024-12-04 11:36:37", "link": "http://arxiv.org/abs/2412.03235v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Intent-driven In-context Learning for Few-shot Dialogue State Tracking", "abstract": "Dialogue state tracking (DST) plays an essential role in task-oriented\ndialogue systems. However, user's input may contain implicit information,\nposing significant challenges for DST tasks. Additionally, DST data includes\ncomplex information, which not only contains a large amount of noise unrelated\nto the current turn, but also makes constructing DST datasets expensive. To\naddress these challenges, we introduce Intent-driven In-context Learning for\nFew-shot DST (IDIC-DST). By extracting user's intent, we propose an\nIntent-driven Dialogue Information Augmentation module to augment the dialogue\ninformation, which can track dialogue states more effectively. Moreover, we\nmask noisy information from DST data and rewrite user's input in the\nIntent-driven Examples Retrieval module, where we retrieve similar examples. We\nthen utilize a pre-trained large language model to update the dialogue state\nusing the augmented dialogue information and examples. Experimental results\ndemonstrate that IDIC-DST achieves state-of-the-art performance in few-shot\nsettings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.", "published": "2024-12-04 12:25:41", "link": "http://arxiv.org/abs/2412.03270v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Grounded Language Design for Lightweight Diagramming for Formal Methods", "abstract": "Model finding, as embodied by SAT solvers and similar tools, is used widely,\nboth in embedding settings and as a tool in its own right. For instance, tools\nlike Alloy target SAT to enable users to incrementally define, explore, verify,\nand diagnose sophisticated specifications for a large number of complex\nsystems.\n  These tools critically include a visualizer that lets users graphically\nexplore these generated models. As we show, however, default visualizers, which\nknow nothing about the domain, are unhelpful and even actively violate\npresentational and cognitive principles. At the other extreme, full-blown\nvisualizations require significant effort as well as knowledge a specifier\nmight not possess; they can also exhibit bad failure modes (including silent\nfailure). Instead, we need a language to capture essential domain information\nfor lightweight diagramming. We ground our language design in both the\ncognitive science literature on diagrams and on a large number of example\ncustom visualizations. This identifies the key elements of lightweight\ndiagrams. We distill these into a small set of orthogonal primitives. We extend\nan Alloy-like tool to support these primitives. We evaluate the effectiveness\nof the produced diagrams, finding them good for reasoning. We then compare this\nagainst many other drawing languages and tools to show that this work defines a\nnew niche that is lightweight, effective, and driven by sound principles.", "published": "2024-12-04 13:37:59", "link": "http://arxiv.org/abs/2412.03310v1", "categories": ["cs.CL", "cs.PL", "D.3.1; D.2.4; D.3.2"], "primary_category": "cs.CL"}
{"title": "LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence\n  Embeddings", "abstract": "Sentence embedding models play a key role in various Natural Language\nProcessing tasks, such as in Topic Modeling, Document Clustering and\nRecommendation Systems. However, these models rely heavily on parallel data,\nwhich can be scarce for many low-resource languages, including Luxembourgish.\nThis scarcity results in suboptimal performance of monolingual and\ncross-lingual sentence embedding models for these languages. To address this\nissue, we compile a relatively small but high-quality human-generated\ncross-lingual parallel dataset to train LuxEmbedder, an enhanced sentence\nembedding model for Luxembourgish with strong cross-lingual capabilities.\nAdditionally, we present evidence suggesting that including low-resource\nlanguages in parallel training datasets can be more advantageous for other\nlow-resource languages than relying solely on high-resource language pairs.\nFurthermore, recognizing the lack of sentence embedding benchmarks for\nlow-resource languages, we create a paraphrase detection benchmark specifically\nfor Luxembourgish, aiming to partially fill this gap and promote further\nresearch.", "published": "2024-12-04 14:02:12", "link": "http://arxiv.org/abs/2412.03331v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Linguistic Diversity of Large Language Models with Possibility\n  Exploration Fine-Tuning", "abstract": "While Large Language Models (LLMs) have made significant strides in\nreplicating human-like abilities, there are concerns about a reduction in the\nlinguistic diversity of their outputs. This results in the homogenization of\nviewpoints and perspectives, as well as the underrepresentation of specific\ndemographic groups. Although several fine-tuning and prompting techniques have\nbeen suggested to tackle the issue, they are often tailored to specific tasks\nor come with a substantial increase in computational cost and latency. This\nmakes them challenging to apply to applications that demand very low latency,\nsuch as chatbots and virtual assistants. We propose Possibility Exploration\nFine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity\nof LLMs without increasing latency or computational cost. Given the same\nprompt, models fine-tuned with PEFT can simultaneously generate multiple\ndiverse responses, each corresponding with a controllable possibility number.\nExperiments on dialogue and story generation tasks demonstrate that PEFT\nsignificantly enhances the diversity of LLM outputs, as evidenced by lower\nsimilarity between candidate responses. Since PEFT emphasizes semantic\ndiversity over lexical diversity, it can also notably reduce demographic bias\nin dialogue systems. The implementations and datasets are available in our\nrepository: https://github.com/mailong25/peft_diversity", "published": "2024-12-04 14:23:16", "link": "http://arxiv.org/abs/2412.03343v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FANAL -- Financial Activity News Alerting Language Modeling Framework", "abstract": "In the rapidly evolving financial sector, the accurate and timely\ninterpretation of market news is essential for stakeholders needing to navigate\nunpredictable events. This paper introduces FANAL (Financial Activity News\nAlerting Language Modeling Framework), a specialized BERT-based framework\nengineered for real-time financial event detection and analysis, categorizing\nnews into twelve distinct financial categories. FANAL leverages silver-labeled\ndata processed through XGBoost and employs advanced fine-tuning techniques,\nalongside ORBERT (Odds Ratio BERT), a novel variant of BERT fine-tuned with\nORPO (Odds Ratio Preference Optimization) for superior class-wise probability\ncalibration and alignment with financial event relevance. We evaluate FANAL's\nperformance against leading large language models, including GPT-4o, Llama-3.1\n8B, and Phi-3, demonstrating its superior accuracy and cost efficiency. This\nframework sets a new standard for financial intelligence and responsiveness,\nsignificantly outstripping existing models in both performance and\naffordability.", "published": "2024-12-04 18:15:41", "link": "http://arxiv.org/abs/2412.03527v1", "categories": ["cs.CL", "cs.LG", "68T50, 68T07 (Primary) 03B65, 91G15, 91F20 (Secondary)", "I.2.7; I.2.1; I.5.1; I.5.2; I.5.4; H.3.3"], "primary_category": "cs.CL"}
{"title": "A Review on Scientific Knowledge Extraction using Large Language Models\n  in Biomedical Sciences", "abstract": "The rapid advancement of large language models (LLMs) has opened new\nboundaries in the extraction and synthesis of medical knowledge, particularly\nwithin evidence synthesis. This paper reviews the state-of-the-art applications\nof LLMs in the biomedical domain, exploring their effectiveness in automating\ncomplex tasks such as evidence synthesis and data extraction from a biomedical\ncorpus of documents. While LLMs demonstrate remarkable potential, significant\nchallenges remain, including issues related to hallucinations, contextual\nunderstanding, and the ability to generalize across diverse medical tasks. We\nhighlight critical gaps in the current research literature, particularly the\nneed for unified benchmarks to standardize evaluations and ensure reliability\nin real-world applications. In addition, we propose directions for future\nresearch, emphasizing the integration of state-of-the-art techniques such as\nretrieval-augmented generation (RAG) to enhance LLM performance in evidence\nsynthesis. By addressing these challenges and utilizing the strengths of LLMs,\nwe aim to improve access to medical literature and facilitate meaningful\ndiscoveries in healthcare.", "published": "2024-12-04 18:26:13", "link": "http://arxiv.org/abs/2412.03531v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Individual to Society: A Survey on Social Simulation Driven by\n  Large Language Model-based Agents", "abstract": "Traditional sociological research often relies on human participation, which,\nthough effective, is expensive, challenging to scale, and with ethical\nconcerns. Recent advancements in large language models (LLMs) highlight their\npotential to simulate human behavior, enabling the replication of individual\nresponses and facilitating studies on many interdisciplinary studies. In this\npaper, we conduct a comprehensive survey of this field, illustrating the recent\nprogress in simulation driven by LLM-empowered agents. We categorize the\nsimulations into three types: (1) Individual Simulation, which mimics specific\nindividuals or demographic groups; (2) Scenario Simulation, where multiple\nagents collaborate to achieve goals within specific contexts; and (3) Society\nSimulation, which models interactions within agent societies to reflect the\ncomplexity and variety of real-world dynamics. These simulations follow a\nprogression, ranging from detailed individual modeling to large-scale societal\nphenomena. We provide a detailed discussion of each simulation type, including\nthe architecture or key components of the simulation, the classification of\nobjectives or scenarios and the evaluation method. Afterward, we summarize\ncommonly used datasets and benchmarks. Finally, we discuss the trends across\nthese three types of simulation. A repository for the related sources is at\n{\\url{https://github.com/FudanDISC/SocialAgent}}.", "published": "2024-12-04 18:56:37", "link": "http://arxiv.org/abs/2412.03563v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "From Language Models over Tokens to Language Models over Characters", "abstract": "Modern language models are internally -- and mathematically -- distributions\nover token strings rather than \\emph{character} strings, posing numerous\nchallenges for programmers building user applications on top of them. For\nexample, if a prompt is specified as a character string, it must be tokenized\nbefore passing it to the token-level language model. Thus, the tokenizer and\nconsequent analyses are very sensitive to the specification of the prompt\n(e.g., if the prompt ends with a space or not). This paper presents algorithms\nfor converting token-level language models to character-level ones. We present\nboth exact and approximate algorithms. In the empirical portion of the paper,\nwe benchmark the practical runtime and approximation quality. We find that --\neven with a small computation budget -- our method is able to accurately\napproximate the character-level distribution (less than 0.00021 excess bits /\ncharacter) at reasonably fast speeds (46.3 characters / second) on the Llama\n3.1 8B language model.", "published": "2024-12-04 21:19:20", "link": "http://arxiv.org/abs/2412.03719v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Model Meets Prototypes: Towards Interpretable Text\n  Classification Models through Prototypical Networks", "abstract": "Pretrained transformer-based Language Models (LMs) are well-known for their\nability to achieve significant improvement on NLP tasks, but their black-box\nnature, which leads to a lack of interpretability, has been a major concern. My\ndissertation focuses on developing intrinsically interpretable models when\nusing LMs as encoders while maintaining their superior performance via\nprototypical networks. I initiated my research by investigating enhancements in\nperformance for interpretable models of sarcasm detection. My proposed approach\nfocuses on capturing sentiment incongruity to enhance accuracy while offering\ninstance-based explanations for the classification decisions. Later, I\ndeveloped a novel white-box multi-head graph attention-based prototype network\ndesigned to explain the decisions of text classification models without\nsacrificing the accuracy of the original black-box LMs. In addition, I am\nworking on extending the attention-based prototype network with contrastive\nlearning to redesign an interpretable graph neural network, aiming to enhance\nboth the interpretability and performance of the model in document\nclassification.", "published": "2024-12-04 22:59:35", "link": "http://arxiv.org/abs/2412.03761v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompting Large Language Models for Clinical Temporal Relation\n  Extraction", "abstract": "Objective: This paper aims to prompt large language models (LLMs) for\nclinical temporal relation extraction (CTRE) in both few-shot and fully\nsupervised settings. Materials and Methods: This study utilizes four LLMs:\nEncoder-based GatorTron-Base (345M)/Large (8.9B); Decoder-based\nLLaMA3-8B/MeLLaMA-13B. We developed full (FFT) and parameter-efficient (PEFT)\nfine-tuning strategies and evaluated these strategies on the 2012 i2b2 CTRE\ntask. We explored four fine-tuning strategies for GatorTron-Base: (1) Standard\nFine-Tuning, (2) Hard-Prompting with Unfrozen LLMs, (3) Soft-Prompting with\nFrozen LLMs, and (4) Low-Rank Adaptation (LoRA) with Frozen LLMs. For\nGatorTron-Large, we assessed two PEFT strategies-Soft-Prompting and LoRA with\nFrozen LLMs-leveraging Quantization techniques. Additionally, LLaMA3-8B and\nMeLLaMA-13B employed two PEFT strategies: LoRA strategy with Quantization\n(QLoRA) applied to Frozen LLMs using instruction tuning and standard\nfine-tuning. Results: Under fully supervised settings, Hard-Prompting with\nUnfrozen GatorTron-Base achieved the highest F1 score (89.54%), surpassing the\nSOTA model (85.70%) by 3.74%. Additionally, two variants of QLoRA adapted to\nGatorTron-Large and Standard Fine-Tuning of GatorTron-Base exceeded the SOTA\nmodel by 2.36%, 1.88%, and 0.25%, respectively. Decoder-based models with\nfrozen parameters outperformed their Encoder-based counterparts in this\nsetting; however, the trend reversed in few-shot scenarios. Discussions and\nConclusions: This study presented new methods that significantly improved CTRE\nperformance, benefiting downstream tasks reliant on CTRE systems. The findings\nunderscore the importance of selecting appropriate models and fine-tuning\nstrategies based on task requirements and data availability. Future work will\nexplore larger models and broader CTRE applications.", "published": "2024-12-04 18:35:28", "link": "http://arxiv.org/abs/2412.04512v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic\n  Data From Large Language Models", "abstract": "Synthetic data generation with Large Language Models is a promising paradigm\nfor augmenting natural data over a nearly infinite range of tasks. Given this\nvariety, direct comparisons among synthetic data generation algorithms are\nscarce, making it difficult to understand where improvement comes from and what\nbottlenecks exist. We propose to evaluate algorithms via the makeup of\nsynthetic data generated by each algorithm in terms of data quality, diversity,\nand complexity. We choose these three characteristics for their significance in\nopen-ended processes and the impact each has on the capabilities of downstream\nmodels. We find quality to be essential for in-distribution model\ngeneralization, diversity to be essential for out-of-distribution\ngeneralization, and complexity to be beneficial for both. Further, we emphasize\nthe existence of Quality-Diversity trade-offs in training data and the\ndownstream effects on model performance. We then examine the effect of various\ncomponents in the synthetic data pipeline on each data characteristic. This\nexamination allows us to taxonomize and compare synthetic data generation\nalgorithms through the components they utilize and the resulting effects on\ndata QDC composition. This analysis extends into a discussion on the importance\nof balancing QDC in synthetic data for efficient reinforcement learning and\nself-improvement algorithms. Analogous to the QD trade-offs in training data,\noften there exist trade-offs between model output quality and output diversity\nwhich impact the composition of synthetic data. We observe that many models are\ncurrently evaluated and optimized only for output quality, thereby limiting\noutput diversity and the potential for self-improvement. We argue that\nbalancing these trade-offs is essential to the development of future\nself-improvement algorithms and highlight a number of works making progress in\nthis direction.", "published": "2024-12-04 02:47:45", "link": "http://arxiv.org/abs/2412.02980v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Analytic Study of Text-Free Speech Synthesis for Raw Audio using a\n  Self-Supervised Learning Model", "abstract": "We examine the text-free speech representations of raw audio obtained from a\nself-supervised learning (SSL) model by analyzing the synthesized speech using\nthe SSL representations instead of conventional text representations. Since raw\naudio does not have paired speech representations as transcribed texts do,\nobtaining speech representations from unpaired speech is crucial for augmenting\navailable datasets for speech synthesis. Specifically, the proposed speech\nsynthesis is conducted using discrete symbol representations from the SSL model\nin comparison with text representations, and analytical examinations of the\nsynthesized speech have been carried out. The results empirically show that\nusing text representations is advantageous for preserving semantic information,\nwhile using discrete symbol representations is superior for preserving acoustic\ncontent, including prosodic and intonational information.", "published": "2024-12-04 06:52:03", "link": "http://arxiv.org/abs/2412.03074v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error\n  Correction", "abstract": "Automatic speech Recognition (ASR) is a fundamental and important task in the\nfield of speech and natural language processing. It is an inherent building\nblock in many applications such as voice assistant, speech translation, etc.\nDespite the advancement of ASR technologies in recent years, it is still\ninevitable for modern ASR systems to have a substantial number of erroneous\nrecognition due to environmental noise, ambiguity, etc. Therefore, the error\ncorrection in ASR is crucial.\n  Motivated by this, this paper studies ASR error correction in the Chinese\nlanguage, which is one of the most popular languages and enjoys a large number\nof users in the world. We first create a benchmark dataset named \\emph{ASR-EC}\nthat contains a wide spectrum of ASR errors generated by industry-grade ASR\nsystems. To the best of our knowledge, it is the first Chinese ASR error\ncorrection benchmark. Then, inspired by the recent advances in \\emph{large\nlanguage models (LLMs)}, we investigate how to harness the power of LLMs to\ncorrect ASR errors. We apply LLMs to ASR error correction in three paradigms.\nThe first paradigm is prompting, which is further categorized as zero-shot,\nfew-shot, and multi-step. The second paradigm is finetuning, which finetunes\nLLMs with ASR error correction data. The third paradigm is multi-modal\naugmentation, which collectively utilizes the audio and ASR transcripts for\nerror correction. Extensive experiments reveal that prompting is not effective\nfor ASR error correction. Finetuning is effective only for a portion of LLMs.\nMulti-modal augmentation is the most effective method for error correction and\nachieves state-of-the-art performance.", "published": "2024-12-04 06:52:10", "link": "http://arxiv.org/abs/2412.03075v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual\n  Optimization", "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced the ability of LLM-based systems to perform complex tasks through\nnatural language processing and tool interaction. However, optimizing these\nLLM-based systems for specific tasks remains challenging, often requiring\nmanual interventions like prompt engineering and hyperparameter tuning.\nExisting automatic optimization methods, such as textual feedback-based\ntechniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to\nusing immediate derivatives in traditional numerical gradient descent. However,\nrelying solely on such feedback can be limited when the adjustments made in\nresponse to this feedback are either too small or fluctuate irregularly,\npotentially slowing down or even stalling the optimization process. To overcome\nthese challenges, more adaptive methods are needed, especially in situations\nwhere the system's response is evolving slowly or unpredictably. In this paper,\nwe introduce REVOLVE, an optimization method that tracks how \"R\"esponses\n\"EVOLVE\" across iterations in LLM systems. By focusing on the evolution of\nresponses over time, REVOLVE enables more stable and effective optimization by\nmaking thoughtful, progressive adjustments at each step. Experimental results\ndemonstrate that REVOLVE outperforms competitive baselines, achieving a 7.8%\nimprovement in prompt optimization, a 20.72% gain in solution refinement, and a\n29.17% increase in code optimization. Additionally, REVOLVE converges in fewer\niterations, resulting in significant computational savings. These advantages\nhighlight its adaptability and efficiency, positioning REVOLVE as a valuable\ntool for optimizing LLM-based systems and accelerating the development of\nnext-generation AI technologies. Code is available at:\nhttps://github.com/Peiyance/REVOLVE.", "published": "2024-12-04 07:44:35", "link": "http://arxiv.org/abs/2412.03092v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.8"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Behavior Simulation with Role-Playing Large Language Model\n  on Social Media", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nrole-playing tasks. However, there is limited research on whether LLMs can\naccurately simulate user behavior in real-world scenarios, such as social\nmedia. This requires models to effectively analyze a user's history and\nsimulate their role. In this paper, we introduce \\textbf{FineRob}, a novel\nfine-grained behavior simulation dataset. We collect the complete behavioral\nhistory of 1,866 distinct users across three social media platforms. Each\nbehavior is decomposed into three fine-grained elements: object, type, and\ncontent, resulting in 78.6k QA records. Based on FineRob, we identify two\ndominant reasoning patterns in LLMs' behavior simulation processes and propose\nthe \\textbf{OM-CoT} fine-tuning method to enhance the capability. Through\ncomprehensive experiments, we conduct an in-depth analysis of key factors of\nbehavior simulation and also demonstrate the effectiveness of OM-CoT\napproach\\footnote{Code and dataset are available at\n\\url{https://github.com/linkseed18612254945/FineRob}}", "published": "2024-12-04 09:14:56", "link": "http://arxiv.org/abs/2412.03148v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and\n  Pruning", "abstract": "Large language models (LLMs) have enabled the creation of multi-modal LLMs\nthat exhibit strong comprehension of visual data such as images and videos.\nHowever, these models usually rely on extensive visual tokens from visual\nencoders, leading to high computational demands, which limits their\napplicability in resource-constrained environments and for long-context tasks.\nIn this work, we propose a training-free adaptive inference method for\nmulti-modal LLMs that can accommodate a broad range of efficiency requirements\nwith a minimum performance drop. Our method consists of a) iterative token\nmerging based on embedding similarity before LLMs, and b) progressive token\npruning within LLM layers based on multi-modal importance. With a minimalist\ndesign, our method can be applied to both video and image LLMs. Extensive\nexperiments on diverse video and image benchmarks demonstrate that, our method\nsubstantially reduces computation load (e.g., a $\\textbf{7-fold}$ reduction in\nFLOPs) while preserving the performance of video and image LLMs. Further, under\na similar computational cost, our method outperforms the state-of-the-art\nmethods in long video understanding (e.g., $\\textbf{+4.6}$ on MLVU).\nAdditionally, our in-depth analysis provides insights into token redundancy and\nLLM layer behaviors, offering guidance for future research in designing\nefficient multi-modal LLMs. Our code will be available at\nhttps://github.com/LaVi-Lab/AIM.", "published": "2024-12-04 11:47:57", "link": "http://arxiv.org/abs/2412.03248v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for\n  Text-to-Speech with Diverse and Controllable Styles", "abstract": "Human speech exhibits rich and flexible prosodic variations. To address the\none-to-many mapping problem from text to prosody in a reasonable and flexible\nmanner, we propose DiffStyleTTS, a multi-speaker acoustic model based on a\nconditional diffusion module and an improved classifier-free guidance, which\nhierarchically models speech prosodic features, and controls different prosodic\nstyles to guide prosody prediction. Experiments show that our method\noutperforms all baselines in naturalness and achieves superior synthesis speed\ncompared to three diffusion-based baselines. Additionally, by adjusting the\nguiding scale, DiffStyleTTS effectively controls the guidance intensity of the\nsynthetic prosody.", "published": "2024-12-04 15:17:25", "link": "http://arxiv.org/abs/2412.03388v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing CLIP Conceptual Embedding through Knowledge Distillation", "abstract": "Recently, CLIP has become an important model for aligning images and text in\nmulti-modal contexts. However, researchers have identified limitations in the\nability of CLIP's text and image encoders to extract detailed knowledge from\npairs of captions and images. In response, this paper presents Knowledge-CLIP,\nan innovative approach designed to improve CLIP's performance by integrating a\nnew knowledge distillation (KD) method based on Llama 2. Our approach focuses\non three key objectives: Text Embedding Distillation, Concept Learning, and\nContrastive Learning. First, Text Embedding Distillation involves training the\nKnowledge-CLIP text encoder to mirror the teacher model, Llama 2. Next, Concept\nLearning assigns a soft concept label to each caption-image pair by employing\noffline K-means clustering on text data from Llama 2, enabling Knowledge-CLIP\nto learn from these soft concept labels. Lastly, Contrastive Learning aligns\nthe text and image embeddings. Our experimental findings show that the proposed\nmodel improves the performance of both text and image encoders.", "published": "2024-12-04 17:56:49", "link": "http://arxiv.org/abs/2412.03513v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted\n  Language Models", "abstract": "Large language models (LLMs) are increasingly being adapted to achieve\ntask-specificity for deployment in real-world decision systems. Several\nprevious works have investigated the bias transfer hypothesis (BTH) by studying\nthe effect of the fine-tuning adaptation strategy on model fairness to find\nthat fairness in pre-trained masked language models have limited effect on the\nfairness of models when adapted using fine-tuning. In this work, we expand the\nstudy of BTH to causal models under prompt adaptations, as prompting is an\naccessible, and compute-efficient way to deploy models in real-world systems.\nIn contrast to previous works, we establish that intrinsic biases in\npre-trained Mistral, Falcon and Llama models are strongly correlated (rho >=\n0.94) with biases when the same models are zero- and few-shot prompted, using a\npronoun co-reference resolution task. Further, we find that bias transfer\nremains strongly correlated even when LLMs are specifically prompted to exhibit\nfair or biased behavior (rho >= 0.92), and few-shot length and stereotypical\ncomposition are varied (rho >= 0.97). Our findings highlight the importance of\nensuring fairness in pre-trained LLMs, especially when they are later used to\nperform downstream tasks via prompt adaptation.", "published": "2024-12-04 18:32:42", "link": "http://arxiv.org/abs/2412.03537v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Best-of-N Jailbreaking", "abstract": "We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that\njailbreaks frontier AI systems across modalities. BoN Jailbreaking works by\nrepeatedly sampling variations of a prompt with a combination of augmentations\n- such as random shuffling or capitalization for textual prompts - until a\nharmful response is elicited. We find that BoN Jailbreaking achieves high\nattack success rates (ASRs) on closed-source language models, such as 89% on\nGPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.\nFurther, it is similarly effective at circumventing state-of-the-art\nopen-source defenses like circuit breakers. BoN also seamlessly extends to\nother modalities: it jailbreaks vision language models (VLMs) such as GPT-4o\nand audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific\naugmentations. BoN reliably improves when we sample more augmented prompts.\nAcross all modalities, ASR, as a function of the number of samples (N),\nempirically follows power-law-like behavior for many orders of magnitude. BoN\nJailbreaking can also be composed with other black-box algorithms for even more\neffective attacks - combining BoN with an optimized prefix attack achieves up\nto a 35% increase in ASR. Overall, our work indicates that, despite their\ncapability, language models are sensitive to seemingly innocuous changes to\ninputs, which attackers can exploit across modalities.", "published": "2024-12-04 18:51:32", "link": "http://arxiv.org/abs/2412.03556v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CBEval: A framework for evaluating and interpreting cognitive biases in\n  LLMs", "abstract": "Rapid advancements in Large Language models (LLMs) has significantly enhanced\ntheir reasoning capabilities. Despite improved performance on benchmarks, LLMs\nexhibit notable gaps in their cognitive processes. Additionally, as reflections\nof human-generated data, these models have the potential to inherit cognitive\nbiases, raising concerns about their reasoning and decision making\ncapabilities. In this paper we present a framework to interpret, understand and\nprovide insights into a host of cognitive biases in LLMs. Conducting our\nresearch on frontier language models we're able to elucidate reasoning\nlimitations and biases, and provide reasoning behind these biases by\nconstructing influence graphs that identify phrases and words most responsible\nfor biases manifested in LLMs. We further investigate biases such as round\nnumber bias and cognitive bias barrier revealed when noting framing effect in\nlanguage models.", "published": "2024-12-04 05:53:28", "link": "http://arxiv.org/abs/2412.03605v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Personalizing Multimodal Large Language Models for Image Captioning: An\n  Experimental Analysis", "abstract": "The task of image captioning demands an algorithm to generate natural\nlanguage descriptions of visual inputs. Recent advancements have seen a\nconvergence between image captioning research and the development of Large\nLanguage Models (LLMs) and Multimodal LLMs -- like GPT-4V and Gemini -- which\nextend the capabilities of text-only LLMs to multiple modalities. This paper\ninvestigates whether Multimodal LLMs can supplant traditional image captioning\nnetworks by evaluating their performance on various image description\nbenchmarks. We explore both the zero-shot capabilities of these models and\ntheir adaptability to different semantic domains through fine-tuning methods,\nincluding prompt learning, prefix tuning, and low-rank adaptation. Our results\ndemonstrate that while Multimodal LLMs achieve impressive zero-shot\nperformance, fine-tuning for specific domains while maintaining their\ngeneralization capabilities intact remains challenging. We discuss the\nimplications of these findings for future research in image captioning and the\ndevelopment of more adaptable Multimodal LLMs.", "published": "2024-12-04 19:01:06", "link": "http://arxiv.org/abs/2412.03665v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Scaling Inference-Time Search with Vision Value Model for Improved\n  Visual Comprehension", "abstract": "Despite significant advancements in vision-language models (VLMs), there\nlacks effective approaches to enhance response quality by scaling\ninference-time computation. This capability is known to be a core step towards\nthe self-improving models in recent large language model studies. In this\npaper, we present Vision Value Model (VisVM) that can guide VLM inference-time\nsearch to generate responses with better visual comprehension. Specifically,\nVisVM not only evaluates the generated sentence quality in the current search\nstep, but also anticipates the quality of subsequent sentences that may result\nfrom the current step, thus providing a long-term value. In this way, VisVM\nsteers VLMs away from generating sentences prone to hallucinations or\ninsufficient detail, thereby producing higher quality responses. Experimental\nresults demonstrate that VisVM-guided search significantly enhances VLMs'\nability to generate descriptive captions with richer visual details and fewer\nhallucinations, compared with greedy decoding and search methods with other\nvisual reward signals. Furthermore, we find that self-training the model with\nthe VisVM-guided captions improve VLM's performance across a wide range of\nmultimodal benchmarks, indicating the potential for developing self-improving\nVLMs. Our value model and code are available at\nhttps://github.com/si0wang/VisVM.", "published": "2024-12-04 20:35:07", "link": "http://arxiv.org/abs/2412.03704v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "WithdrarXiv: A Large-Scale Dataset for Retraction Study", "abstract": "Retractions play a vital role in maintaining scientific integrity, yet\nsystematic studies of retractions in computer science and other STEM fields\nremain scarce. We present WithdrarXiv, the first large-scale dataset of\nwithdrawn papers from arXiv, containing over 14,000 papers and their associated\nretraction comments spanning the repository's entire history through September\n2024. Through careful analysis of author comments, we develop a comprehensive\ntaxonomy of retraction reasons, identifying 10 distinct categories ranging from\ncritical errors to policy violations. We demonstrate a simple yet highly\naccurate zero-shot automatic categorization of retraction reasons, achieving a\nweighted average F1-score of 0.96. Additionally, we release WithdrarXiv-SciFy,\nan enriched version including scripts for parsed full-text PDFs, specifically\ndesigned to enable research in scientific feasibility studies, claim\nverification, and automated theorem proving. These findings provide valuable\ninsights for improving scientific quality control and automated verification\nsystems. Finally, and most importantly, we discuss ethical issues and take a\nnumber of steps to implement responsible data release while fostering open\nscience in this area.", "published": "2024-12-04 23:36:23", "link": "http://arxiv.org/abs/2412.03775v1", "categories": ["cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "YT-30M: A multi-lingual multi-category dataset of YouTube comments", "abstract": "This paper introduces two large-scale multilingual comment datasets, YT-30M\n(and YT-100K) from YouTube. The analysis in this paper is performed on a\nsmaller sample (YT-100K) of YT-30M. Both the datasets: YT-30M (full) and\nYT-100K (randomly selected 100K sample from YT-30M) are publicly released for\nfurther research. YT-30M (YT-100K) contains 32236173 (108694) comments posted\nby YouTube channel that belong to YouTube categories. Each comment is\nassociated with a video ID, comment ID, commentor name, commentor channel ID,\ncomment text, upvotes, original channel ID and category of the YouTube channel\n(e.g., 'News & Politics', 'Science & Technology', etc.).", "published": "2024-12-04 16:54:58", "link": "http://arxiv.org/abs/2412.03465v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.SI"}
{"title": "How to Correctly do Semantic Backpropagation on Language-based Agentic\n  Systems", "abstract": "Language-based agentic systems have shown great promise in recent years,\ntransitioning from solving small-scale research problems to being deployed in\nchallenging real-world tasks. However, optimizing these systems often requires\nsubstantial manual labor. Recent studies have demonstrated that these systems\ncan be represented as computational graphs, enabling automatic optimization.\nDespite these advancements, most current efforts in Graph-based Agentic System\nOptimization (GASO) fail to properly assign feedback to the system's components\ngiven feedback on the system's output. To address this challenge, we formalize\nthe concept of semantic backpropagation with semantic gradients -- a\ngeneralization that aligns several key optimization techniques, including\nreverse-mode automatic differentiation and the more recent TextGrad by\nexploiting the relationship among nodes with a common successor. This serves as\na method for computing directional information about how changes to each\ncomponent of an agentic system might improve the system's output. To use these\ngradients, we propose a method called semantic gradient descent which enables\nus to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show\nthat our approach outperforms existing state-of-the-art methods for solving\nGASO problems. A detailed ablation study on the LIAR dataset demonstrates the\nparsimonious nature of our method. A full copy of our implementation is\npublicly available at https://github.com/HishamAlyahya/semantic_backprop", "published": "2024-12-04 15:52:03", "link": "http://arxiv.org/abs/2412.03624v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "stat.ML", "68T07", "I.2.6; I.2.11"], "primary_category": "cs.AI"}
{"title": "Exploring trends in audio mixes and masters: Insights from a dataset\n  analysis", "abstract": "We present an analysis of a dataset of audio metrics and aesthetic\nconsiderations about mixes and masters provided by the web platform MixCheck\nstudio. The platform is designed for educational purposes, primarily targeting\namateur music producers, and aimed at analysing their recordings prior to them\nbeing released. The analysis focuses on the following data points: integrated\nloudness, mono compatibility, presence of clipping and phase issues,\ncompression and tonal profile across 30 user-specified genres. Both mixed\n(mixes) and mastered audio (masters) are included in the analysis, where mixes\nrefer to the initial combination and balance of individual tracks, and masters\nrefer to the final refined version optimized for distribution. Results show\nthat loudness-related issues along with dynamics issues are the most prevalent,\nparticularly in mastered audio. However mastered audio presents better results\nin compression than just mixed audio. Additionally, results show that mastered\naudio has a lower percentage of stereo field and phase issues.", "published": "2024-12-04 15:01:20", "link": "http://arxiv.org/abs/2412.03373v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting abnormal heart sound using mobile phones and on-device IConNet", "abstract": "Given the global prevalence of cardiovascular diseases, there is a pressing\nneed for easily accessible early screening methods. Typically, this requires\nmedical practitioners to investigate heart auscultations for irregular sounds,\nfollowed by echocardiography and electrocardiography tests. To democratize\nearly diagnosis, we present a user-friendly solution for abnormal heart sound\ndetection, utilizing mobile phones and a lightweight neural network optimized\nfor on-device inference. Unlike previous approaches reliant on specialized\nstethoscopes, our method directly analyzes audio recordings, facilitated by a\nnovel architecture known as IConNet. IConNet, an Interpretable Convolutional\nNeural Network, harnesses insights from audio signal processing, enhancing\nefficiency and providing transparency in neural pattern extraction from raw\nwaveform signals. This is a significant step towards trustworthy AI in\nhealthcare, aiding in remote health monitoring efforts.", "published": "2024-12-04 12:18:21", "link": "http://arxiv.org/abs/2412.03267v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "NBM: an Open Dataset for the Acoustic Monitoring of Nocturnal Migratory\n  Birds in Europe", "abstract": "The persisting threats on migratory bird populations highlight the urgent\nneed for effective monitoring techniques that could assist in their\nconservation. Among these, passive acoustic monitoring is an essential tool,\nparticularly for nocturnal migratory species that are difficult to track\notherwise. This work presents the Nocturnal Bird Migration (NBM) dataset, a\ncollection of 13,359 annotated vocalizations from 117 species of the Western\nPalearctic. The dataset includes precise time and frequency annotations,\ngathered by dozens of bird enthusiasts across France, enabling novel downstream\nacoustic analysis. In particular, we prove the utility of this database by\ntraining an original two-stage deep object detection model tailored for the\nprocessing of audio data. While allowing the precise localization of bird calls\nin spectrograms, this model shows competitive accuracy on the 45 main species\nof the dataset with state-of-the-art systems trained on much larger audio\ncollections. These results highlight the interest of fostering similar\nopen-science initiatives to acquire costly but valuable fine-grained\nannotations of audio files. All data and code are made openly available.", "published": "2024-12-04 18:55:45", "link": "http://arxiv.org/abs/2412.03633v3", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Diffusion in Zero-Shot Learning for Environmental Audio", "abstract": "Zero-shot learning enables models to generalize to unseen classes by\nleveraging semantic information, bridging the gap between training and testing\nsets with non-overlapping classes. While much research has focused on zero-shot\nlearning in computer vision, the application of these methods to environmental\naudio remains underexplored, with poor performance in existing studies.\nGenerative methods, which have demonstrated success in computer vision, are\nnotably absent from environmental audio zero-shot learning, where\nclassification-based approaches dominate.\n  To address this gap, this work investigates generative methods for zero-shot\nlearning in environmental audio. Two successful generative models from computer\nvision are adapted: a cross-aligned and distribution-aligned variational\nautoencoder (CADA-VAE) and a leveraging invariant side generative adversarial\nnetwork (LisGAN). Additionally, a novel diffusion model conditioned on class\nauxiliary data is introduced. The diffusion model generates synthetic data for\nunseen classes, which is combined with seen-class data to train a classifier.\n  Experiments are conducted on two environmental audio datasets, ESC-50 and\nFSC22. Results show that the diffusion model significantly outperforms all\nbaseline methods, achieving more than 25% higher accuracy on the ESC-50 test\npartition.\n  This work establishes the diffusion model as a promising generative approach\nfor zero-shot learning and introduces the first benchmark of generative methods\nfor environmental audio zero-shot learning, providing a foundation for future\nresearch in the field.\n  Code is provided at https://github.com/ysims/ZeroDiffusion for the novel\nZeroDiffusion method.", "published": "2024-12-04 23:18:40", "link": "http://arxiv.org/abs/2412.03771v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
