{"title": "Twist Decoding: Diverse Generators Guide Each Other", "abstract": "Many language generation models are now available for a wide range of\ngeneration tasks, including machine translation and summarization. Combining\nsuch diverse models may lead to further progress, but ensembling generation\nmodels is challenging during inference: conventional ensembling methods (e.g.,\nshallow fusion) require that the models share vocabulary/tokenization schemes.\nWe introduce Twist decoding, a simple and general text generation algorithm\nthat benefits from diverse models at inference time. Our method does not assume\nthe vocabulary, tokenization or even generation order is shared. Our extensive\nevaluations on machine translation and scientific paper summarization\ndemonstrate that Twist decoding substantially outperforms each model decoded in\nisolation over various scenarios, including cases where domain-specific and\ngeneral-purpose models are both available. Twist decoding also consistently\noutperforms the popular reranking heuristic where output candidates from one\nmodel are rescored by another. We hope that our work will encourage researchers\nand practitioners to examine generation models collectively, not just\nindependently, and to seek out models with complementary strengths to the\ncurrently available models. Our code is available at\nhttps://github.com/jungokasai/twist_decoding.", "published": "2022-05-19 01:27:53", "link": "http://arxiv.org/abs/2205.09273v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Exemplification in Long-form Question Answering via Retrieval", "abstract": "Exemplification is a process by which writers explain or clarify a concept by\nproviding an example. While common in all forms of writing, exemplification is\nparticularly useful in the task of long-form question answering (LFQA), where a\ncomplicated answer can be made more understandable through simple examples. In\nthis paper, we provide the first computational study of exemplification in QA,\nperforming a fine-grained annotation of different types of examples (e.g.,\nhypotheticals, anecdotes) in three corpora. We show that not only do\nstate-of-the-art LFQA models struggle to generate relevant examples, but also\nthat standard evaluation metrics such as ROUGE are insufficient to judge\nexemplification quality. We propose to treat exemplification as a\n\\emph{retrieval} problem in which a partially-written answer is used to query a\nlarge set of human-written examples extracted from a corpus. Our approach\nallows a reliable ranking-type automatic metrics that correlates well with\nhuman evaluation. A human evaluation shows that our model's retrieved examples\nare more relevant than examples generated from a state-of-the-art LFQA model.", "published": "2022-05-19 01:38:06", "link": "http://arxiv.org/abs/2205.09278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Prompt-based Models Clueless?", "abstract": "Finetuning large pre-trained language models with a task-specific head has\nadvanced the state-of-the-art on many natural language understanding\nbenchmarks. However, models with a task-specific head require a lot of training\ndata, making them susceptible to learning and exploiting dataset-specific\nsuperficial cues that do not generalize to other datasets. Prompting has\nreduced the data requirement by reusing the language model head and formatting\nthe task input to match the pre-training objective. Therefore, it is expected\nthat few-shot prompt-based models do not exploit superficial cues. This paper\npresents an empirical examination of whether few-shot prompt-based models also\nexploit superficial cues. Analyzing few-shot prompt-based models on MNLI, SNLI,\nHANS, and COPA has revealed that prompt-based models also exploit superficial\ncues. While the models perform well on instances with superficial cues, they\noften underperform or only marginally outperform random accuracy on instances\nwithout superficial cues.", "published": "2022-05-19 02:47:58", "link": "http://arxiv.org/abs/2205.09295v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target-Guided Dialogue Response Generation Using Commonsense and Data\n  Augmentation", "abstract": "Target-guided response generation enables dialogue systems to smoothly\ntransition a conversation from a dialogue context toward a target sentence.\nSuch control is useful for designing dialogue systems that direct a\nconversation toward specific goals, such as creating non-obtrusive\nrecommendations or introducing new topics in the conversation. In this paper,\nwe introduce a new technique for target-guided response generation, which first\nfinds a bridging path of commonsense knowledge concepts between the source and\nthe target, and then uses the identified bridging path to generate transition\nresponses. Additionally, we propose techniques to re-purpose existing dialogue\ndatasets for target-guided generation. Experiments reveal that the proposed\ntechniques outperform various baselines on this task. Finally, we observe that\nthe existing automated metrics for this task correlate poorly with human\njudgement ratings. We propose a novel evaluation metric that we demonstrate is\nmore reliable for target-guided response evaluation. Our work generally enables\ndialogue system designers to exercise more control over the conversations that\ntheir systems produce.", "published": "2022-05-19 04:01:40", "link": "http://arxiv.org/abs/2205.09314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Inflection as a Data Augmentation Method for Parsing", "abstract": "We propose a morphology-based method for low-resource (LR) dependency\nparsing. We train a morphological inflector for target LR languages, and apply\nit to related rich-resource (RR) treebanks to create cross-lingual\n(x-inflected) treebanks that resemble the target LR language. We use such\ninflected treebanks to train parsers in zero- (training on x-inflected\ntreebanks) and few-shot (training on x-inflected and target language treebanks)\nsetups. The results show that the method sometimes improves the baselines, but\nnot consistently.", "published": "2022-05-19 07:05:56", "link": "http://arxiv.org/abs/2205.09350v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Subtitle Segmentation for End-to-end Generation Systems", "abstract": "Subtitles appear on screen as short pieces of text, segmented based on formal\nconstraints (length) and syntactic/semantic criteria. Subtitle segmentation can\nbe evaluated with sequence segmentation metrics against a human reference.\nHowever, standard segmentation metrics cannot be applied when systems generate\noutputs different than the reference, e.g. with end-to-end subtitling systems.\nIn this paper, we study ways to conduct reference-based evaluations of\nsegmentation accuracy irrespective of the textual content. We first conduct a\nsystematic analysis of existing metrics for evaluating subtitle segmentation.\nWe then introduce $Sigma$, a new Subtitle Segmentation Score derived from an\napproximate upper-bound of BLEU on segmentation boundaries, which allows us to\ndisentangle the effect of good segmentation from text quality. To compare\n$Sigma$ with existing metrics, we further propose a boundary projection method\nfrom imperfect hypotheses to the true reference. Results show that all metrics\nare able to reward high quality output but for similar outputs system ranking\ndepends on each metric's sensitivity to error type. Our thorough analyses\nsuggest $Sigma$ is a promising segmentation candidate but its reliability over\nother segmentation metrics remains to be validated through correlations with\nhuman judgements.", "published": "2022-05-19 07:38:13", "link": "http://arxiv.org/abs/2205.09360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two-Step Question Retrieval for Open-Domain QA", "abstract": "The retriever-reader pipeline has shown promising performance in open-domain\nQA but suffers from a very slow inference speed. Recently proposed question\nretrieval models tackle this problem by indexing question-answer pairs and\nsearching for similar questions. These models have shown a significant increase\nin inference speed, but at the cost of lower QA performance compared to the\nretriever-reader models. This paper proposes a two-step question retrieval\nmodel, SQuID (Sequential Question-Indexed Dense retrieval) and distant\nsupervision for training. SQuID uses two bi-encoders for question retrieval.\nThe first-step retriever selects top-k similar questions, and the second-step\nretriever finds the most similar question from the top-k questions. We evaluate\nthe performance and the computational efficiency of SQuID. The results show\nthat SQuID significantly increases the performance of existing question\nretrieval models with a negligible loss on inference speed.", "published": "2022-05-19 08:46:14", "link": "http://arxiv.org/abs/2205.09393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Psychiatric Scale Guided Risky Post Screening for Early Detection of\n  Depression", "abstract": "Depression is a prominent health challenge to the world, and early risk\ndetection (ERD) of depression from online posts can be a promising technique\nfor combating the threat. Early depression detection faces the challenge of\nefficiently tackling streaming data, balancing the tradeoff between timeliness,\naccuracy and explainability. To tackle these challenges, we propose a\npsychiatric scale guided risky post screening method that can capture risky\nposts related to the dimensions defined in clinical depression scales, and\nproviding interpretable diagnostic basis. A Hierarchical Attentional Network\nequipped with BERT (HAN-BERT) is proposed to further advance explainable\npredictions. For ERD, we propose an online algorithm based on an evolving queue\nof risky posts that can significantly reduce the number of model inferences to\nboost efficiency. Experiments show that our method outperforms the competitive\nfeature-based and neural models under conventional depression detection\nsettings, and achieves simultaneous improvement in both efficacy and efficiency\nfor ERD.", "published": "2022-05-19 12:11:01", "link": "http://arxiv.org/abs/2205.09497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple yet Effective Relation Information Guided Approach for Few-Shot\n  Relation Extraction", "abstract": "Few-Shot Relation Extraction aims at predicting the relation for a pair of\nentities in a sentence by training with a few labelled examples in each\nrelation. Some recent works have introduced relation information (i.e.,\nrelation labels or descriptions) to assist model learning based on Prototype\nNetwork. However, most of them constrain the prototypes of each relation class\nimplicitly with relation information, generally through designing complex\nnetwork structures, like generating hybrid features, combining with contrastive\nlearning or attention networks. We argue that relation information can be\nintroduced more explicitly and effectively into the model. Thus, this paper\nproposes a direct addition approach to introduce relation information.\nSpecifically, for each relation class, the relation representation is first\ngenerated by concatenating two views of relations (i.e., [CLS] token embedding\nand the mean value of embeddings of all tokens) and then directly added to the\noriginal prototype for both train and prediction. Experimental results on the\nbenchmark dataset FewRel 1.0 show significant improvements and achieve\ncomparable results to the state-of-the-art, which demonstrates the\neffectiveness of our proposed approach. Besides, further analyses verify that\nthe direct addition is a much more effective way to integrate the relation\nrepresentations and the original prototypes.", "published": "2022-05-19 13:03:01", "link": "http://arxiv.org/abs/2205.09536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Approaching Reflex Predictions as a Classification Problem Using\n  Extended Phonological Alignments", "abstract": "This work describes an implementation of the \"extended alignment\" (or\n\"multitiers\") approach for cognate reflex prediction, submitted to \"Prediction\nof Cognate Reflexes\" shared task. Similarly to List2022d, the technique\ninvolves an automatic extension of sequence alignments with multilayered\nvectors that encode informational tiers on both site-specific traits, such as\nsound classes and distinctive features, as well as contextual and\nsuprasegmental ones, conveyed by cross-site referrals and replication. The\nmethod allows to generalize the problem of cognate reflex prediction as a\nclassification problem, with models trained using a parallel corpus of cognate\nsets. A model using random forests is trained and evaluated on the shared task\nfor reflex prediction, and the experimental results are presented and discussed\nalong with some differences to other implementations.", "published": "2022-05-19 14:00:42", "link": "http://arxiv.org/abs/2205.09570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A machine transliteration tool between Uzbek alphabets", "abstract": "Machine transliteration, as defined in this paper, is a process of\nautomatically transforming written script of words from a source alphabet into\nwords of another target alphabet within the same language, while preserving\ntheir meaning, as well as pronunciation. The main goal of this paper is to\npresent a machine transliteration tool between three common scripts used in\nlow-resource Uzbek language: the old Cyrillic, currently official Latin, and\nnewly announced New Latin alphabets. The tool has been created using a\ncombination of rule-based and fine-tuning approaches. The created tool is\navailable as an open-source Python package, as well as a web-based application\nincluding a public API. To our knowledge, this is the first machine\ntransliteration tool that supports the newly announced Latin alphabet of the\nUzbek language.", "published": "2022-05-19 14:19:42", "link": "http://arxiv.org/abs/2205.09578v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phylogeny-Inspired Adaptation of Multilingual Models to New Languages", "abstract": "Large pretrained multilingual models, trained on dozens of languages, have\ndelivered promising results due to cross-lingual learning capabilities on\nvariety of language tasks. Further adapting these models to specific languages,\nespecially ones unseen during pre-training, is an important goal towards\nexpanding the coverage of language technologies. In this study, we show how we\ncan use language phylogenetic information to improve cross-lingual transfer\nleveraging closely related languages in a structured, linguistically-informed\nmanner. We perform adapter-based training on languages from diverse language\nfamilies (Germanic, Uralic, Tupian, Uto-Aztecan) and evaluate on both syntactic\nand semantic tasks, obtaining more than 20% relative performance improvements\nover strong commonly used baselines, especially on languages unseen during\npre-training.", "published": "2022-05-19 15:49:19", "link": "http://arxiv.org/abs/2205.09634v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SNaC: Coherence Error Detection for Narrative Summarization", "abstract": "Progress in summarizing long texts is inhibited by the lack of appropriate\nevaluation frameworks. When a long summary must be produced to appropriately\ncover the facets of that text, that summary needs to present a coherent\nnarrative to be understandable by a reader, but current automatic and human\nevaluation methods fail to identify gaps in coherence. In this work, we\nintroduce SNaC, a narrative coherence evaluation framework rooted in\nfine-grained annotations for long summaries. We develop a taxonomy of coherence\nerrors in generated narrative summaries and collect span-level annotations for\n6.6k sentences across 150 book and movie screenplay summaries. Our work\nprovides the first characterization of coherence errors generated by\nstate-of-the-art summarization models and a protocol for eliciting coherence\njudgments from crowd annotators. Furthermore, we show that the collected\nannotations allow us to train a strong classifier for automatically localizing\ncoherence errors in generated summaries as well as benchmarking past work in\ncoherence modeling. Finally, our SNaC framework can support future work in long\ndocument summarization and coherence evaluation, including improved\nsummarization modeling and post-hoc summary correction.", "published": "2022-05-19 16:01:47", "link": "http://arxiv.org/abs/2205.09641v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-training with Two-phase Self-augmentation for Few-shot Dialogue\n  Generation", "abstract": "In task-oriented dialogue systems, response generation from meaning\nrepresentations (MRs) often suffers from limited training examples, due to the\nhigh cost of annotating MR-to-Text pairs. Previous works on self-training\nleverage fine-tuned conversational models to automatically generate\npseudo-labeled MR-to-Text pairs for further fine-tuning. However, some\nself-augmented data may be noisy or uninformative for the model to learn from.\nIn this work, we propose a two-phase self-augmentation procedure to generate\nhigh-quality pseudo-labeled MR-to-Text pairs: the first phase selects the most\ninformative MRs based on model's prediction uncertainty; with the selected MRs,\nthe second phase generates accurate responses by aggregating multiple perturbed\nlatent representations from each MR. Empirical experiments on two benchmark\ndatasets, FewShotWOZ and FewShotSGD, show that our method generally outperforms\nexisting self-training methods on both automatic and human evaluations.", "published": "2022-05-19 16:25:50", "link": "http://arxiv.org/abs/2205.09661v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Crossword Solving", "abstract": "We present the Berkeley Crossword Solver, a state-of-the-art approach for\nautomatically solving crossword puzzles. Our system works by generating answer\ncandidates for each crossword clue using neural question answering models and\nthen combines loopy belief propagation with local search to find full puzzle\nsolutions. Compared to existing approaches, our system improves exact puzzle\naccuracy from 71% to 82% on crosswords from The New York Times and obtains\n99.9% letter accuracy on themeless puzzles. Additionally, in 2021, a hybrid of\nour system and the existing Dr.Fill system outperformed all human competitors\nfor the first time at the American Crossword Puzzle Tournament. To facilitate\nresearch on question answering and crossword solving, we analyze our system's\nremaining errors and release a dataset of over six million question-answer\npairs.", "published": "2022-05-19 16:28:44", "link": "http://arxiv.org/abs/2205.09665v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding Gender-Seniority Compound Bias in Natural Language\n  Generation", "abstract": "Women are often perceived as junior to their male counterparts, even within\nthe same job titles. While there has been significant progress in the\nevaluation of gender bias in natural language processing (NLP), existing\nstudies seldom investigate how biases toward gender groups change when\ncompounded with other societal biases. In this work, we investigate how\nseniority impacts the degree of gender bias exhibited in pretrained neural\ngeneration models by introducing a novel framework for probing compound bias.\nWe contribute a benchmark robustness-testing dataset spanning two domains, U.S.\nsenatorship and professorship, created using a distant-supervision method. Our\ndataset includes human-written text with underlying ground truth and paired\ncounterfactuals. We then examine GPT-2 perplexity and the frequency of gendered\nlanguage in generated text. Our results show that GPT-2 amplifies bias by\nconsidering women as junior and men as senior more often than the ground truth\nin both domains. These results suggest that NLP applications built using GPT-2\nmay harm women in professional capacities.", "published": "2022-05-19 20:05:02", "link": "http://arxiv.org/abs/2205.09830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table Retrieval May Not Necessitate Table-specific Model Design", "abstract": "Tables are an important form of structured data for both human and machine\nreaders alike, providing answers to questions that cannot, or cannot easily, be\nfound in texts. Recent work has designed special models and training paradigms\nfor table-related tasks such as table-based question answering and table\nretrieval. Though effective, they add complexity in both modeling and data\nacquisition compared to generic text solutions and obscure which elements are\ntruly beneficial. In this work, we focus on the task of table retrieval, and\nask: \"is table-specific model design necessary for table retrieval, or can a\nsimpler text-based model be effectively used to achieve a similar result?\"\nFirst, we perform an analysis on a table-based portion of the Natural Questions\ndataset (NQ-table), and find that structure plays a negligible role in more\nthan 70% of the cases. Based on this, we experiment with a general Dense\nPassage Retriever (DPR) based on text and a specialized Dense Table Retriever\n(DTR) that uses table-specific model designs. We find that DPR performs well\nwithout any table-specific design and training, and even achieves superior\nresults compared to DTR when fine-tuned on properly linearized tables. We then\nexperiment with three modules to explicitly encode table structures, namely\nauxiliary row/column embeddings, hard attention masks, and soft relation-based\nattention biases. However, none of these yielded significant improvements,\nsuggesting that table-specific model design may not be necessary for table\nretrieval.", "published": "2022-05-19 20:35:23", "link": "http://arxiv.org/abs/2205.09843v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Meta-Embeddings", "abstract": "Different methods have been proposed to develop meta-embeddings from a given\nset of source embeddings. However, the source embeddings can contain unfair\ngender-related biases, and how these influence the meta-embeddings has not been\nstudied yet. We study the gender bias in meta-embeddings created under three\ndifferent settings: (1) meta-embedding multiple sources without performing any\ndebiasing (Multi-Source No-Debiasing), (2) meta-embedding multiple sources\ndebiased by a single method (Multi-Source Single-Debiasing), and (3)\nmeta-embedding a single source debiased by different methods (Single-Source\nMulti-Debiasing). Our experimental results show that meta-embedding amplifies\nthe gender biases compared to input source embeddings. We find that debiasing\nnot only the sources but also their meta-embedding is needed to mitigate those\nbiases. Moreover, we propose a novel debiasing method based on meta-embedding\nlearning where we use multiple debiasing methods on a single source embedding\nand then create a single unbiased meta-embedding.", "published": "2022-05-19 21:20:47", "link": "http://arxiv.org/abs/2205.09867v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Educational Tools for Mapuzugun", "abstract": "Mapuzugun is the language of the Mapuche people. Due to political and\nhistorical reasons, its number of speakers has decreased and the language has\nbeen excluded from the educational system in Chile and Argentina. For this\nreason, it is very important to support the revitalization of the Mapuzugun in\nall spaces and media of society. In this work we present a tool towards\nsupporting educational activities of Mapuzugun, tailored to the characteristics\nof the language. The tool consists of three parts: design and development of an\northography detector and converter; a morphological analyzer; and an informal\ntranslator. We also present a case study with Mapuzugun students showing\npromising results.\n  Short Abstract in Mapuzuzgun: T\\\"ufachi k\\\"uzaw pegelfi ki\\~ne zugun\nk\\\"uzawpey\\\"um kelluaetew pu mapuzugun chillkatufe kimal kizu ta\\~ni zugun.", "published": "2022-05-19 03:19:32", "link": "http://arxiv.org/abs/2205.10411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Bootstrapping and Stepwise Reinforcement Reward: A\n  Semi-Supervised Framework for Text Style Transfer", "abstract": "Text style transfer is an important task in controllable language generation.\nSupervised approaches have pushed performance improvement on style-oriented\nrewriting such as formality conversion. However, challenges remain due to the\nscarcity of large-scale parallel data in many domains. While unsupervised\napproaches do not rely on annotated sentence pairs for each style, they are\noften plagued with instability issues such as mode collapse or quality\ndegradation. To take advantage of both supervised and unsupervised paradigms\nand tackle the challenges, in this work, we propose a semi-supervised framework\nfor text style transfer. First, the learning process is bootstrapped with\nsupervision guided by automatically constructed pseudo-parallel pairs using\nlexical and semantic-based methods. Then the model learns from unlabeled data\nvia reinforcement rewards. Specifically, we propose to improve the\nsequence-to-sequence policy gradient via stepwise reward optimization,\nproviding fine-grained learning signals and stabilizing the reinforced learning\nprocess. Experimental results show that the proposed approach achieves\nstate-of-the-art performance on multiple datasets, and produces effective\ngeneration with as minimal as 10\\% of training data.", "published": "2022-05-19 05:18:06", "link": "http://arxiv.org/abs/2205.09324v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transformers as Neural Augmentors: Class Conditional Sentence Generation\n  via Variational Bayes", "abstract": "Data augmentation methods for Natural Language Processing tasks are explored\nin recent years, however they are limited and it is hard to capture the\ndiversity on sentence level. Besides, it is not always possible to perform data\naugmentation on supervised tasks. To address those problems, we propose a\nneural data augmentation method, which is a combination of Conditional\nVariational Autoencoder and encoder-decoder Transformer model. While encoding\nand decoding the input sentence, our model captures the syntactic and semantic\nrepresentation of the input language with its class condition. Following the\ndevelopments in the past years on pre-trained language models, we train and\nevaluate our models on several benchmarks to strengthen the downstream tasks.\nWe compare our method with 3 different augmentation techniques. The presented\nresults show that, our model increases the performance of current models\ncompared to other data augmentation techniques with a small amount of\ncomputation power.", "published": "2022-05-19 08:42:33", "link": "http://arxiv.org/abs/2205.09391v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Why only Micro-F1? Class Weighting of Measures for Relation\n  Classification", "abstract": "Relation classification models are conventionally evaluated using only a\nsingle measure, e.g., micro-F1, macro-F1 or AUC. In this work, we analyze\nweighting schemes, such as micro and macro, for imbalanced datasets. We\nintroduce a framework for weighting schemes, where existing schemes are\nextremes, and two new intermediate schemes. We show that reporting results of\ndifferent weighting schemes better highlights strengths and weaknesses of a\nmodel.", "published": "2022-05-19 10:33:28", "link": "http://arxiv.org/abs/2205.09460v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SDS-200: A Swiss German Speech to Standard German Text Corpus", "abstract": "We present SDS-200, a corpus of Swiss German dialectal speech with Standard\nGerman text translations, annotated with dialect, age, and gender information\nof the speakers. The dataset allows for training speech translation, dialect\nrecognition, and speech synthesis systems, among others. The data was collected\nusing a web recording tool that is open to the public. Each participant was\ngiven a text in Standard German and asked to translate it to their Swiss German\ndialect before recording it. To increase the corpus quality, recordings were\nvalidated by other participants. The data consists of 200 hours of speech by\naround 4000 different speakers and covers a large part of the Swiss-German\ndialect landscape. We release SDS-200 alongside a baseline speech translation\nmodel, which achieves a word error rate (WER) of 30.3 and a BLEU score of 53.1\non the SDS-200 test set. Furthermore, we use SDS-200 to fine-tune a pre-trained\nXLS-R model, achieving 21.6 WER and 64.0 BLEU.", "published": "2022-05-19 12:16:29", "link": "http://arxiv.org/abs/2205.09501v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in\n  Semantic Parsing", "abstract": "Semantic parsing is the task of producing structured meaning representations\nfor natural language sentences. Recent research has pointed out that the\ncommonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to\ngeneralize systematically, i.e. to handle examples that require recombining\nknown knowledge in novel settings. In this work, we show that better systematic\ngeneralization can be achieved by producing the meaning representation directly\nas a graph and not as a sequence. To this end we propose LAGr (Label Aligned\nGraphs), a general framework to produce semantic parses by independently\npredicting node and edge labels for a complete multi-layer input-aligned graph.\nThe strongly-supervised LAGr algorithm requires aligned graphs as inputs,\nwhereas weakly-supervised LAGr infers alignments for originally unaligned\ntarget graphs using approximate maximum-a-posteriori inference. Experiments\ndemonstrate that LAGr achieves significant improvements in systematic\ngeneralization upon the baseline seq2seq parsers in both strongly- and\nweakly-supervised settings.", "published": "2022-05-19 15:01:37", "link": "http://arxiv.org/abs/2205.09607v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Curras + Baladi: Towards a Levantine Corpus", "abstract": "The processing of the Arabic language is a complex field of research. This is\ndue to many factors, including the complex and rich morphology of Arabic, its\nhigh degree of ambiguity, and the presence of several regional varieties that\nneed to be processed while taking into account their unique characteristics.\nWhen its dialects are taken into account, this language pushes the limits of\nNLP to find solutions to problems posed by its inherent nature. It is a\ndiglossic language; the standard language is used in formal settings and in\neducation and is quite different from the vernacular languages spoken in the\ndifferent regions and influenced by older languages that were historically\nspoken in those regions. This should encourage NLP specialists to create\ndialect-specific corpora such as the Palestinian morphologically annotated\nCurras corpus of Birzeit University. In this work, we present the Lebanese\nCorpus Baladi that consists of around 9.6K morphologically annotated tokens.\nSince Lebanese and Palestinian dialects are part of the same Levantine\ndialectal continuum, and thus highly mutually intelligible, our proposed corpus\nwas constructed to be used to (1) enrich Curras and transform it into a more\ngeneral Levantine corpus and (2) improve Curras by solving detected errors.", "published": "2022-05-19 16:53:04", "link": "http://arxiv.org/abs/2205.09692v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PLAID: An Efficient Engine for Late Interaction Retrieval", "abstract": "Pre-trained language models are increasingly important components across\nmultiple information retrieval (IR) paradigms. Late interaction, introduced\nwith the ColBERT model and recently refined in ColBERTv2, is a popular paradigm\nthat holds state-of-the-art status across many benchmarks. To dramatically\nspeed up the search latency of late interaction, we introduce the\nPerformance-optimized Late Interaction Driver (PLAID). Without impacting\nquality, PLAID swiftly eliminates low-scoring passages using a novel centroid\ninteraction mechanism that treats every passage as a lightweight bag of\ncentroids. PLAID uses centroid interaction as well as centroid pruning, a\nmechanism for sparsifying the bag of centroids, within a highly-optimized\nengine to reduce late interaction search latency by up to 7$\\times$ on a GPU\nand 45$\\times$ on a CPU against vanilla ColBERTv2, while continuing to deliver\nstate-of-the-art retrieval quality. This allows the PLAID engine with ColBERTv2\nto achieve latency of tens of milliseconds on a GPU and tens or just few\nhundreds of milliseconds on a CPU at large scale, even at the largest scales we\nevaluate with 140M passages.", "published": "2022-05-19 17:19:31", "link": "http://arxiv.org/abs/2205.09707v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Selection-Inference: Exploiting Large Language Models for Interpretable\n  Logical Reasoning", "abstract": "Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.", "published": "2022-05-19 17:25:28", "link": "http://arxiv.org/abs/2205.09712v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RankGen: Improving Text Generation with Large Ranking Models", "abstract": "Given an input sequence (or prefix), modern language models often assign high\nprobabilities to output sequences that are repetitive, incoherent, or\nirrelevant to the prefix; as such, model-generated text also contains such\nartifacts. To address these issues we present RankGen, a 1.2B parameter encoder\nmodel for English that scores model generations given a prefix. RankGen can be\nflexibly incorporated as a scoring function in beam search and used to decode\nfrom any pretrained language model. We train RankGen using large-scale\ncontrastive learning to map a prefix close to the ground-truth sequence that\nfollows it and far away from two types of negatives: (1) random sequences from\nthe same document as the prefix, and (2) sequences generated from a large\nlanguage model conditioned on the prefix. Experiments across four different\nlanguage models (345M-11B parameters) and two domains show that RankGen\nsignificantly outperforms decoding algorithms like nucleus, top-k, and typical\nsampling, as well as contrastive decoding and search, on both automatic metrics\n(85.0 vs 77.3 MAUVE over nucleus) as well as human evaluations with English\nwriters (74.5% human preference over nucleus sampling). Analysis reveals that\nRankGen outputs are more relevant to the prefix and improve continuity and\ncoherence compared to baselines. We release our model checkpoints, code, and\nhuman preference data with explanations to facilitate future research.", "published": "2022-05-19 17:36:46", "link": "http://arxiv.org/abs/2205.09726v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Slot Tagging with Intent Features for Task Oriented Natural\n  Language Understanding using BERT", "abstract": "Recent joint intent detection and slot tagging models have seen improved\nperformance when compared to individual models. In many real-world datasets,\nthe slot labels and values have a strong correlation with their intent labels.\nIn such cases, the intent label information may act as a useful feature to the\nslot tagging model. In this paper, we examine the effect of leveraging intent\nlabel features through 3 techniques in the slot tagging task of joint intent\nand slot detection models. We evaluate our techniques on benchmark spoken\nlanguage datasets SNIPS and ATIS, as well as over a large private Bixby dataset\nand observe an improved slot-tagging performance over state-of-the-art models.", "published": "2022-05-19 17:41:04", "link": "http://arxiv.org/abs/2205.09732v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MiDAS: Multi-integrated Domain Adaptive Supervision for Fake News\n  Detection", "abstract": "COVID-19 related misinformation and fake news, coined an 'infodemic', has\ndramatically increased over the past few years. This misinformation exhibits\nconcept drift, where the distribution of fake news changes over time, reducing\neffectiveness of previously trained models for fake news detection. Given a set\nof fake news models trained on multiple domains, we propose an adaptive\ndecision module to select the best-fit model for a new sample. We propose\nMiDAS, a multi-domain adaptative approach for fake news detection that ranks\nrelevancy of existing models to new samples. MiDAS contains 2 components: a\ndoman-invariant encoder, and an adaptive model selector. MiDAS integrates\nmultiple pre-trained and fine-tuned models with their training data to create a\ndomain-invariant representation. Then, MiDAS uses local Lipschitz smoothness of\nthe invariant embedding space to estimate each model's relevance to a new\nsample. Higher ranked models provide predictions, and lower ranked models\nabstain. We evaluate MiDAS on generalization to drifted data with 9 fake news\ndatasets, each obtained from different domains and modalities. MiDAS achieves\nnew state-of-the-art performance on multi-domain adaptation for\nout-of-distribution fake news classification.", "published": "2022-05-19 19:36:08", "link": "http://arxiv.org/abs/2205.09817v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Summarization as Indirect Supervision for Relation Extraction", "abstract": "Relation extraction (RE) models have been challenged by their reliance on\ntraining data with expensive annotations. Considering that summarization tasks\naim at acquiring concise expressions of synoptical information from the longer\ncontext, these tasks naturally align with the objective of RE, i.e., extracting\na kind of synoptical information that describes the relation of entity\nmentions. We present SuRE, which converts RE into a summarization formulation.\nSuRE leads to more precise and resource-efficient RE based on indirect\nsupervision from summarization tasks. To achieve this goal, we develop sentence\nand relation conversion techniques that essentially bridge the formulation of\nsummarization and RE tasks. We also incorporate constraint decoding techniques\nwith Trie scoring to further enhance summarization-based RE with robust\ninference. Experiments on three RE datasets demonstrate the effectiveness of\nSuRE in both full-dataset and low-resource settings, showing that summarization\nis a promising source of indirect supervision to improve RE models.", "published": "2022-05-19 20:25:29", "link": "http://arxiv.org/abs/2205.09837v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Let the Model Decide its Curriculum for Multitask Learning", "abstract": "Curriculum learning strategies in prior multi-task learning approaches\narrange datasets in a difficulty hierarchy either based on human perception or\nby exhaustively searching the optimal arrangement. However, human perception of\ndifficulty may not always correlate well with machine interpretation leading to\npoor performance and exhaustive search is computationally expensive. Addressing\nthese concerns, we propose two classes of techniques to arrange training\ninstances into a learning curriculum based on difficulty scores computed via\nmodel-based approaches. The two classes i.e Dataset-level and Instance-level\ndiffer in granularity of arrangement. Through comprehensive experiments with 12\ndatasets, we show that instance-level and dataset-level techniques result in\nstrong representations as they lead to an average performance improvement of\n4.17% and 3.15% over their respective baselines. Furthermore, we find that most\nof this improvement comes from correctly answering the difficult instances,\nimplying a greater efficacy of our techniques on difficult tasks.", "published": "2022-05-19 23:34:22", "link": "http://arxiv.org/abs/2205.09898v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Let's Talk! Striking Up Conversations via Conversational Visual Question\n  Generation", "abstract": "An engaging and provocative question can open up a great conversation. In\nthis work, we explore a novel scenario: a conversation agent views a set of the\nuser's photos (for example, from social media platforms) and asks an engaging\nquestion to initiate a conversation with the user. The existing\nvision-to-question models mostly generate tedious and obvious questions, which\nmight not be ideals conversation starters. This paper introduces a two-phase\nframework that first generates a visual story for the photo set and then uses\nthe story to produce an interesting question. The human evaluation shows that\nour framework generates more response-provoking questions for starting\nconversations than other vision-to-question baselines.", "published": "2022-05-19 05:32:26", "link": "http://arxiv.org/abs/2205.09327v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "A Weakly-Supervised Iterative Graph-Based Approach to Retrieve COVID-19\n  Misinformation Topics", "abstract": "The COVID-19 pandemic has been accompanied by an `infodemic' -- of accurate\nand inaccurate health information across social media. Detecting misinformation\namidst dynamically changing information landscape is challenging; identifying\nrelevant keywords and posts is arduous due to the large amount of human effort\nrequired to inspect the content and sources of posts. We aim to reduce the\nresource cost of this process by introducing a weakly-supervised iterative\ngraph-based approach to detect keywords, topics, and themes related to\nmisinformation, with a focus on COVID-19. Our approach can successfully detect\nspecific topics from general misinformation-related seed words in a few seed\ntexts. Our approach utilizes the BERT-based Word Graph Search (BWGS) algorithm\nthat builds on context-based neural network embeddings for retrieving\nmisinformation-related posts. We utilize Latent Dirichlet Allocation (LDA)\ntopic modeling for obtaining misinformation-related themes from the texts\nreturned by BWGS. Furthermore, we propose the BERT-based Multi-directional Word\nGraph Search (BMDWGS) algorithm that utilizes greater starting context\ninformation for misinformation extraction. In addition to a qualitative\nanalysis of our approach, our quantitative analyses show that BWGS and BMDWGS\nare effective in extracting misinformation-related content compared to common\nbaselines in low data resource settings. Extracting such content is useful for\nuncovering prevalent misconceptions and concerns and for facilitating precision\npublic health messaging campaigns to improve health behaviors.", "published": "2022-05-19 09:30:39", "link": "http://arxiv.org/abs/2205.09416v1", "categories": ["cs.HC", "cs.CL", "cs.SI"], "primary_category": "cs.HC"}
{"title": "Insights on Neural Representations for End-to-End Speech Recognition", "abstract": "End-to-end automatic speech recognition (ASR) models aim to learn a\ngeneralised speech representation. However, there are limited tools available\nto understand the internal functions and the effect of hierarchical\ndependencies within the model architecture. It is crucial to understand the\ncorrelations between the layer-wise representations, to derive insights on the\nrelationship between neural representations and performance.\n  Previous investigations of network similarities using correlation analysis\ntechniques have not been explored for End-to-End ASR models. This paper\nanalyses and explores the internal dynamics between layers during training with\nCNN, LSTM and Transformer based approaches using Canonical correlation analysis\n(CCA) and centered kernel alignment (CKA) for the experiments. It was found\nthat neural representations within CNN layers exhibit hierarchical correlation\ndependencies as layer depth increases but this is mostly limited to cases where\nneural representation correlates more closely. This behaviour is not observed\nin LSTM architecture, however there is a bottom-up pattern observed across the\ntraining process, while Transformer encoder layers exhibit irregular\ncoefficiency correlation as neural depth increases. Altogether, these results\nprovide new insights into the role that neural architectures have upon speech\nrecognition performance. More specifically, these techniques can be used as\nindicators to build better performing speech recognition models.", "published": "2022-05-19 10:19:32", "link": "http://arxiv.org/abs/2205.09456v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Minority Stress Experienced by LGBTQ Online Communities during the\n  COVID-19 Pandemic", "abstract": "The COVID-19 pandemic has disproportionately impacted the lives of\nminorities, such as members of the LGBTQ community (lesbian, gay, bisexual,\ntransgender, and queer) due to pre-existing social disadvantages and health\ndisparities. Although extensive research has been carried out on the impact of\nthe COVID-19 pandemic on different aspects of the general population's lives,\nfew studies are focused on the LGBTQ population. In this paper, we develop and\nevaluate two sets of machine learning classifiers using a pre-pandemic and a\nduring-pandemic dataset to identify Twitter posts exhibiting minority stress,\nwhich is a unique pressure faced by the members of the LGBTQ population due to\ntheir sexual and gender identities. We demonstrate that our best pre- and\nduring-pandemic models show strong and stable performance for detecting posts\nthat contain minority stress. We investigate the linguistic differences in\nminority stress posts across pre- and during-pandemic periods. We find that\nanger words are strongly associated with minority stress during the COVID-19\npandemic. We explore the impact of the pandemic on the emotional states of the\nLGBTQ population by adopting propensity score-based matching to perform a\ncausal analysis. The results show that the LGBTQ population have a greater\nincrease in the usage of cognitive words and worsened observable attribute in\nthe usage of positive emotion words than the group of the general population\nwith similar pre-pandemic behavioral attributes. Our findings have implications\nfor the public health domain and policy-makers to provide adequate support,\nespecially with respect to mental health, to the LGBTQ population during future\ncrises.", "published": "2022-05-19 12:26:59", "link": "http://arxiv.org/abs/2205.09511v3", "categories": ["cs.SI", "cs.CL", "cs.HC", "cs.LG", "68T50 (Primary) 62P15 (Secondary)"], "primary_category": "cs.SI"}
{"title": "Automatic Spoken Language Identification using a Time-Delay Neural\n  Network", "abstract": "Closed-set spoken language identification is the task of recognizing the\nlanguage being spoken in a recorded audio clip from a set of known languages.\nIn this study, a language identification system was built and trained to\ndistinguish between Arabic, Spanish, French, and Turkish based on nothing more\nthan recorded speech. A pre-existing multilingual dataset was used to train a\nseries of acoustic models based on the Tedlium TDNN model to perform automatic\nspeech recognition. The system was provided with a custom multilingual language\nmodel and a specialized pronunciation lexicon with language names prepended to\nphones. The trained model was used to generate phone alignments to test data\nfrom all four languages, and languages were predicted based on a voting scheme\nchoosing the most common language prepend in an utterance. Accuracy was\nmeasured by comparing predicted languages to known languages, and was\ndetermined to be very high in identifying Spanish and Arabic, and somewhat\nlower in identifying Turkish and French.", "published": "2022-05-19 13:47:48", "link": "http://arxiv.org/abs/2205.09564v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Acceptability Judgements via Examining the Topology of Attention Maps", "abstract": "The role of the attention mechanism in encoding linguistic knowledge has\nreceived special interest in NLP. However, the ability of the attention heads\nto judge the grammatical acceptability of a sentence has been underexplored.\nThis paper approaches the paradigm of acceptability judgments with topological\ndata analysis (TDA), showing that the geometric properties of the attention\ngraph can be efficiently exploited for two standard practices in linguistics:\nbinary judgments and linguistic minimal pairs. Topological features enhance the\nBERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three\nlanguages (English, Italian, and Swedish). By revealing the topological\ndiscrepancy between attention maps of minimal pairs, we achieve the human-level\nperformance on the BLiMP benchmark, outperforming nine statistical and\nTransformer LM baselines. At the same time, TDA provides the foundation for\nanalyzing the linguistic functions of attention heads and interpreting the\ncorrespondence between the graph features and grammatical phenomena.", "published": "2022-05-19 15:45:12", "link": "http://arxiv.org/abs/2205.09630v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.AT"], "primary_category": "cs.CL"}
{"title": "Great Power, Great Responsibility: Recommendations for Reducing Energy\n  for Training Language Models", "abstract": "The energy requirements of current natural language processing models\ncontinue to grow at a rapid, unsustainable pace. Recent works highlighting this\nproblem conclude there is an urgent need for methods that reduce the energy\nneeds of NLP and machine learning more broadly. In this article, we investigate\ntechniques that can be used to reduce the energy consumption of common NLP\napplications. In particular, we focus on techniques to measure energy usage and\ndifferent hardware and datacenter-oriented settings that can be tuned to reduce\nenergy consumption for training and inference for language models. We\ncharacterize the impact of these settings on metrics such as computational\nperformance and energy consumption through experiments conducted on a high\nperformance computing system as well as popular cloud computing platforms.\nThese techniques can lead to significant reduction in energy consumption when\ntraining language models or their use for inference. For example,\npower-capping, which limits the maximum power a GPU can consume, can enable a\n15\\% decrease in energy usage with marginal increase in overall computation\ntime when training a transformer-based language model.", "published": "2022-05-19 16:03:55", "link": "http://arxiv.org/abs/2205.09646v1", "categories": ["cs.CL", "cs.AI", "cs.PF"], "primary_category": "cs.CL"}
{"title": "Wojood: Nested Arabic Named Entity Corpus and Recognition using BERT", "abstract": "This paper presents Wojood, a corpus for Arabic nested Named Entity\nRecognition (NER). Nested entities occur when one entity mention is embedded\ninside another entity mention. Wojood consists of about 550K Modern Standard\nArabic (MSA) and dialect tokens that are manually annotated with 21 entity\ntypes including person, organization, location, event and date. More\nimportantly, the corpus is annotated with nested entities instead of the more\ncommon flat annotations. The data contains about 75K entities and 22.5% of\nwhich are nested. The inter-annotator evaluation of the corpus demonstrated a\nstrong agreement with Cohen's Kappa of 0.979 and an F1-score of 0.976. To\nvalidate our data, we used the corpus to train a nested NER model based on\nmulti-task learning and AraBERT (Arabic BERT). The model achieved an overall\nmicro F1-score of 0.884. Our corpus, the annotation guidelines, the source code\nand the pre-trained model are publicly available.", "published": "2022-05-19 16:06:49", "link": "http://arxiv.org/abs/2205.09651v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Arabic Ontology -- An Arabic Wordnet with Ontologically Clean\n  Content", "abstract": "We present a formal Arabic wordnet built on the basis of a carefully designed\nontology hereby referred to as the Arabic Ontology. The ontology provides a\nformal representation of the concepts that the Arabic terms convey, and its\ncontent was built with ontological analysis in mind, and benchmarked to\nscientific advances and rigorous knowledge sources as much as this is possible,\nrather than to only speakers' beliefs as lexicons typically are. A\ncomprehensive evaluation was conducted thereby demonstrating that the current\nversion of the top-levels of the ontology can top the majority of the Arabic\nmeanings. The ontology consists currently of about 1,300 well-investigated\nconcepts in addition to 11,000 concepts that are partially validated. The\nontology is accessible and searchable through a lexicographic search engine\n(https://ontology.birzeit.edu) that also includes about 150 Arabic-multilingual\nlexicons, and which are being mapped and enriched using the ontology. The\nontology is fully mapped with Princeton WordNet, Wikidata, and other resources.", "published": "2022-05-19 16:27:44", "link": "http://arxiv.org/abs/2205.09664v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LO"], "primary_category": "cs.CL"}
{"title": "ArabGlossBERT: Fine-Tuning BERT on Context-Gloss Pairs for WSD", "abstract": "Using pre-trained transformer models such as BERT has proven to be effective\nin many NLP tasks. This paper presents our work to fine-tune BERT models for\nArabic Word Sense Disambiguation (WSD). We treated the WSD task as a\nsentence-pair binary classification task. First, we constructed a dataset of\nlabeled Arabic context-gloss pairs (~167k pairs) we extracted from the Arabic\nOntology and the large lexicographic database available at Birzeit University.\nEach pair was labeled as True or False and target words in each context were\nidentified and annotated. Second, we used this dataset for fine-tuning three\npre-trained Arabic BERT models. Third, we experimented the use of different\nsupervised signals used to emphasize target words in context. Our experiments\nachieved promising results (accuracy of 84%) although we used a large set of\nsenses in the experiment.", "published": "2022-05-19 16:47:18", "link": "http://arxiv.org/abs/2205.09685v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Voxel-informed Language Grounding", "abstract": "Natural language applied to natural 2D images describes a fundamentally 3D\nworld. We present the Voxel-informed Language Grounder (VLG), a language\ngrounding model that leverages 3D geometric information in the form of voxel\nmaps derived from the visual input using a volumetric reconstruction model. We\nshow that VLG significantly improves grounding accuracy on SNARE, an object\nreference game task. At the time of writing, VLG holds the top place on the\nSNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement.", "published": "2022-05-19 17:24:04", "link": "http://arxiv.org/abs/2205.09710v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Towards a Holistic View on Argument Quality Prediction", "abstract": "Argumentation is one of society's foundational pillars, and, sparked by\nadvances in NLP and the vast availability of text data, automated mining of\narguments receives increasing attention. A decisive property of arguments is\ntheir strength or quality. While there are works on the automated estimation of\nargument strength, their scope is narrow: they focus on isolated datasets and\nneglect the interactions with related argument mining tasks, such as argument\nidentification, evidence detection, or emotional appeal. In this work, we close\nthis gap by approaching argument quality estimation from multiple different\nangles: Grounded on rich results from thorough empirical evaluations, we assess\nthe generalization capabilities of argument quality estimation across diverse\ndomains, the interplay with related argument mining tasks, and the impact of\nemotions on perceived argument strength. We find that generalization depends on\na sufficient representation of different domains in the training part. In\nzero-shot transfer and multi-task experiments, we reveal that argument quality\nis among the more challenging tasks but can improve others. Finally, we show\nthat emotions play a minor role in argument quality than is often assumed.", "published": "2022-05-19 18:44:23", "link": "http://arxiv.org/abs/2205.09803v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A toolbox for idea generation and evaluation: Machine learning,\n  data-driven, and contest-driven approaches to support idea generation", "abstract": "The significance and abundance of data are increasing due to the growing\ndigital data generated from social media, sensors, scholarly literature,\npatents, different forms of documents published online, databases, product\nmanuals, etc. Various data sources can be used to generate ideas, yet, in\naddition to bias, the size of the available digital data is a major challenge\nwhen it comes to manual analysis. Hence, human-machine interaction is essential\nfor generating valuable ideas where machine learning and data-driven techniques\ngenerate patterns from data and serve human sense-making. However, the use of\nmachine learning and data-driven approaches to generate ideas is a relatively\nnew area. Moreover, it is also possible to stimulate innovation using\ncontest-driven idea generation and evaluation. The results and contributions of\nthis thesis can be viewed as a toolbox of idea-generation techniques, including\na list of data-driven and machine learning techniques with corresponding data\nsources and models to support idea generation. In addition, the results include\ntwo models, one method and one framework, to better support data-driven and\ncontest- driven idea generation. The beneficiaries of these artefacts are\npractitioners in data and knowledge engineering, data mining project managers,\nand innovation agents. Innovation agents include incubators, contest\norganizers, consultants, innovation accelerators, and industries. Since the\nproposed artefacts consist of process models augmented with AI techniques,\nhuman-centred AI is a promising area of research that can contribute to the\nartefacts' further development and promote creativity.", "published": "2022-05-19 20:28:49", "link": "http://arxiv.org/abs/2205.09840v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sentences as connection paths: A neural language architecture of\n  sentence structure in the brain", "abstract": "This article presents a neural language architecture of sentence structure in\nthe brain, in which sentences are temporal connection paths that interconnect\nneural structures underlying their words. Words remain 'in-situ', hence they\nare always content-addressable. Arbitrary and novel sentences (with novel\nwords) can be created with 'neural blackboards' for words and sentences. Hence,\nthe unlimited productivity of natural language can be achieved with a 'fixed'\nsmall world like network structure. The article focuses on the neural\nblackboard for sentences. The architecture uses only one 'connection matrix'\nfor binding all structural relations between words in sentences. Its ability to\nrepresent arbitrary (English) sentences is discussed in detail, based on a\ncomprehensive analysis of them. The architecture simulates intra-cranial brain\nactivity observed during sentence processing and fMRI observations related to\nsentence complexity and ambiguity. The simulations indicate that the observed\neffects relate to global control over the architecture, not to the sentence\nstructures involved, which predicts higher activity differences related to\ncomplexity and ambiguity with higher comprehension capacity. Other aspects\ndiscussed are the 'intrinsic' sentence structures provided by connection paths\nand their relation to scope and inflection, the use of a dependency parser for\ncontrol of binding, long-distance dependencies and gaps, question answering,\nambiguity resolution based on backward processing without explicit\nbacktracking, garden paths, and performance difficulties related to embeddings.", "published": "2022-05-19 13:58:45", "link": "http://arxiv.org/abs/2206.01725v1", "categories": ["cs.CL", "cs.NE", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Disentangling Active and Passive Cosponsorship in the U.S. Congress", "abstract": "In the U.S. Congress, legislators can use active and passive cosponsorship to\nsupport bills. We show that these two types of cosponsorship are driven by two\ndifferent motivations: the backing of political colleagues and the backing of\nthe bill's content. To this end, we develop an Encoder+RGCN based model that\nlearns legislator representations from bill texts and speech transcripts. These\nrepresentations predict active and passive cosponsorship with an F1-score of\n0.88. Applying our representations to predict voting decisions, we show that\nthey are interpretable and generalize to unseen tasks.", "published": "2022-05-19 16:33:46", "link": "http://arxiv.org/abs/2205.09674v1", "categories": ["cs.LG", "cs.CL", "cs.CY", "physics.data-an", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bi-LSTM Scoring Based Similarity Measurement with Agglomerative\n  Hierarchical Clustering (AHC) for Speaker Diarization", "abstract": "Majority of speech signals across different scenarios are never available\nwith well-defined audio segments containing only a single speaker. A typical\nconversation between two speakers consists of segments where their voices\noverlap, interrupt each other or halt their speech in between multiple\nsentences. Recent advancements in diarization technology leverage neural\nnetwork-based approaches to improvise multiple subsystems of speaker\ndiarization system comprising of extracting segment-wise embedding features and\ndetecting changes in the speaker during conversation. However, to identify\nspeaker through clustering, models depend on methodologies like PLDA to\ngenerate similarity measure between two extracted segments from a given\nconversational audio. Since these algorithms ignore the temporal structure of\nconversations, they tend to achieve a higher Diarization Error Rate (DER), thus\nleading to misdetections both in terms of speaker and change identification.\nTherefore, to compare similarity of two speech segments both independently and\nsequentially, we propose a Bi-directional Long Short-term Memory network for\nestimating the elements present in the similarity matrix. Once the similarity\nmatrix is generated, Agglomerative Hierarchical Clustering (AHC) is applied to\nfurther identify speaker segments based on thresholding. To evaluate the\nperformance, Diarization Error Rate (DER%) metric is used. The proposed model\nachieves a low DER of 34.80% on a test set of audio samples derived from ICSI\nMeeting Corpus as compared to traditional PLDA based similarity measurement\nmechanism which achieved a DER of 39.90%.", "published": "2022-05-19 17:20:51", "link": "http://arxiv.org/abs/2205.09709v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Neural network for multi-exponential sound energy decay analysis", "abstract": "An established model for sound energy decay functions (EDFs) is the\nsuperposition of multiple exponentials and a noise term. This work proposes a\nneural-network-based approach for estimating the model parameters from EDFs.\nThe network is trained on synthetic EDFs and evaluated on two large datasets of\nover 20000 EDF measurements conducted in various acoustic environments. The\nevaluation shows that the proposed neural network architecture robustly\nestimates the model parameters from large datasets of measured EDFs, while\nbeing lightweight and computationally efficient. An implementation of the\nproposed neural network is publicly available.", "published": "2022-05-19 16:03:16", "link": "http://arxiv.org/abs/2205.09644v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "End-to-End Zero-Shot Voice Conversion with Location-Variable\n  Convolutions", "abstract": "Zero-shot voice conversion is becoming an increasingly popular research\ntopic, as it promises the ability to transform speech to sound like any\nspeaker. However, relatively little work has been done on end-to-end methods\nfor this task, which are appealing because they remove the need for a separate\nvocoder to generate audio from intermediate features. In this work, we propose\nLVC-VC, an end-to-end zero-shot voice conversion model that uses\nlocation-variable convolutions (LVCs) to jointly model the conversion and\nspeech synthesis processes. LVC-VC utilizes carefully designed input features\nthat have disentangled content and speaker information, and it uses a neural\nvocoder-like architecture that utilizes LVCs to efficiently combine them and\nperform voice conversion while directly synthesizing time domain audio.\nExperiments show that our model achieves especially well balanced performance\nbetween voice style transfer and speech intelligibility compared to several\nbaselines.", "published": "2022-05-19 18:13:23", "link": "http://arxiv.org/abs/2205.09784v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Voice Activity Projection: Self-supervised Learning of Turn-taking\n  Events", "abstract": "The modeling of turn-taking in dialog can be viewed as the modeling of the\ndynamics of voice activity of the interlocutors. We extend prior work and\ndefine the predictive task of Voice Activity Projection, a general,\nself-supervised objective, as a way to train turn-taking models without the\nneed of labeled data. We highlight a theoretical weakness with prior\napproaches, arguing for the need of modeling the dependency of voice activity\nevents in the projection window. We propose four zero-shot tasks, related to\nthe prediction of upcoming turn-shifts and backchannels, and show that the\nproposed model outperforms prior work.", "published": "2022-05-19 19:16:45", "link": "http://arxiv.org/abs/2205.09812v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bias Analysis of Spatial Coherence-Based RTF Vector Estimation for\n  Acoustic Sensor Networks in a Diffuse Sound Field", "abstract": "In many multi-microphone algorithms, an estimate of the relative transfer\nfunctions (RTFs) of the desired speaker is required. Recently, a\ncomputationally efficient RTF vector estimation method was proposed for\nacoustic sensor networks, assuming that the spatial coherence (SC) of the noise\ncomponent between a local microphone array and multiple external microphones is\nlow. Aiming at optimizing the output signal-to-noise ratio (SNR), this method\nlinearly combines multiple RTF vector estimates, where the complex-valued\nweights are computed using a generalized eigenvalue decomposition (GEVD). In\nthis paper, we perform a theoretical bias analysis for the SC-based RTF vector\nestimation method with multiple external microphones. Assuming a certain model\nfor the noise field, we derive an analytical expression for the weights,\nshowing that the optimal model-based weights are real-valued and only depend on\nthe input SNR in the external microphones. Simulations with real-world\nrecordings show a good accordance of the GEVD-based and the model-based\nweights. Nevertheless, the results also indicate that in practice, estimation\nerrors occur which the model-based weights cannot account for.", "published": "2022-05-19 09:02:57", "link": "http://arxiv.org/abs/2205.09401v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "The AI Mechanic: Acoustic Vehicle Characterization Neural Networks", "abstract": "In a world increasingly dependent on road-based transportation, it is\nessential to understand vehicles. We introduce the AI mechanic, an acoustic\nvehicle characterization deep learning system, as an integrated approach using\nsound captured from mobile devices to enhance transparency and understanding of\nvehicles and their condition for non-expert users. We develop and implement\nnovel cascading architectures for vehicle understanding, which we define as\nsequential, conditional, multi-level networks that process raw audio to extract\nhighly-granular insights. To showcase the viability of cascading architectures,\nwe build a multi-task convolutional neural network that predicts and cascades\nvehicle attributes to enhance fault detection. We train and test these models\non a synthesized dataset reflecting more than 40 hours of augmented audio and\nachieve >92% validation set accuracy on attributes (fuel type, engine\nconfiguration, cylinder count and aspiration type). Our cascading architecture\nadditionally achieved 93.6% validation and 86.8% test set accuracy on misfire\nfault prediction, demonstrating margins of 16.4% / 7.8% and 4.2% / 1.5%\nimprovement over na\\\"ive and parallel baselines. We explore experimental\nstudies focused on acoustic features, data augmentation, feature fusion, and\ndata reliability. Finally, we conclude with a discussion of broader\nimplications, future directions, and application areas for this work.", "published": "2022-05-19 16:29:26", "link": "http://arxiv.org/abs/2205.09667v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Content-Context Factorized Representations for Automated Speech\n  Recognition", "abstract": "Deep neural networks have largely demonstrated their ability to perform\nautomated speech recognition (ASR) by extracting meaningful features from input\naudio frames. Such features, however, may consist not only of information about\nthe spoken language content, but also may contain information about unnecessary\ncontexts such as background noise and sounds or speaker identity, accent, or\nprotected attributes. Such information can directly harm generalization\nperformance, by introducing spurious correlations between the spoken words and\nthe context in which such words were spoken. In this work, we introduce an\nunsupervised, encoder-agnostic method for factoring speech-encoder\nrepresentations into explicit content-encoding representations and spurious\ncontext-encoding representations. By doing so, we demonstrate improved\nperformance on standard ASR benchmarks, as well as improved performance in both\nreal-world and artificially noisy ASR scenarios.", "published": "2022-05-19 21:34:40", "link": "http://arxiv.org/abs/2205.09872v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
