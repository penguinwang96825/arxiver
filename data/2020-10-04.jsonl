{"title": "MIME: MIMicking Emotions for Empathetic Response Generation", "abstract": "Current approaches to empathetic response generation view the set of emotions\nexpressed in the input text as a flat structure, where all the emotions are\ntreated uniformly. We argue that empathetic responses often mimic the emotion\nof the user to a varying degree, depending on its positivity or negativity and\ncontent. We show that the consideration of this polarity-based emotion clusters\nand emotional mimicry results in improved empathy and contextual relevance of\nthe response as compared to the state-of-the-art. Also, we introduce\nstochasticity into the emotion mixture that yields emotionally more varied\nempathetic responses than the previous work. We demonstrate the importance of\nthese factors to empathetic response generation using both automatic- and\nhuman-based evaluations. The implementation of MIME is publicly available at\nhttps://github.com/declare-lab/MIME.", "published": "2020-10-04 00:35:47", "link": "http://arxiv.org/abs/2010.01454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Constituent-Aware Aspect-Category Sentiment Analysis with Graph\n  Attention Networks", "abstract": "Aspect category sentiment analysis (ACSA) aims to predict the sentiment\npolarities of the aspect categories discussed in sentences. Since a sentence\nusually discusses one or more aspect categories and expresses different\nsentiments toward them, various attention-based methods have been developed to\nallocate the appropriate sentiment words for the given aspect category and\nobtain promising results. However, most of these methods directly use the given\naspect category to find the aspect category-related sentiment words, which may\ncause mismatching between the sentiment words and the aspect categories when an\nunrelated sentiment word is semantically meaningful for the given aspect\ncategory. To mitigate this problem, we propose a Sentence Constituent-Aware\nNetwork (SCAN) for aspect-category sentiment analysis. SCAN contains two graph\nattention modules and an interactive loss function. The graph attention modules\ngenerate representations of the nodes in sentence constituency parse trees for\nthe aspect category detection (ACD) task and the ACSA task, respectively. ACD\naims to detect aspect categories discussed in sentences and is a auxiliary\ntask. For a given aspect category, the interactive loss function helps the ACD\ntask to find the nodes which can predict the aspect category but can't predict\nother aspect categories. The sentiment words in the nodes then are used to\npredict the sentiment polarity of the aspect category by the ACSA task. The\nexperimental results on five public datasets demonstrate the effectiveness of\nSCAN.", "published": "2020-10-04 01:23:17", "link": "http://arxiv.org/abs/2010.01461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tell Me How to Ask Again: Question Data Augmentation with Controllable\n  Rewriting in Continuous Space", "abstract": "In this paper, we propose a novel data augmentation method, referred to as\nControllable Rewriting based Question Data Augmentation (CRQDA), for machine\nreading comprehension (MRC), question generation, and question-answering\nnatural language inference tasks. We treat the question data augmentation task\nas a constrained question rewriting problem to generate context-relevant,\nhigh-quality, and diverse question data samples. CRQDA utilizes a Transformer\nautoencoder to map the original discrete question into a continuous embedding\nspace. It then uses a pre-trained MRC model to revise the question\nrepresentation iteratively with gradient-based optimization. Finally, the\nrevised question representations are mapped back into the discrete space, which\nserve as additional question data. Comprehensive experiments on SQuAD 2.0,\nSQuAD 1.1 question generation, and QNLI tasks demonstrate the effectiveness of\nCRQDA", "published": "2020-10-04 03:13:46", "link": "http://arxiv.org/abs/2010.01475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-turn Response Selection using Dialogue Dependency Relations", "abstract": "Multi-turn response selection is a task designed for developing dialogue\nagents. The performance on this task has a remarkable improvement with\npre-trained language models. However, these models simply concatenate the turns\nin dialogue history as the input and largely ignore the dependencies between\nthe turns. In this paper, we propose a dialogue extraction algorithm to\ntransform a dialogue history into threads based on their dependency relations.\nEach thread can be regarded as a self-contained sub-dialogue. We also propose\nThread-Encoder model to encode threads and candidates into compact\nrepresentations by pre-trained Transformers and finally get the matching score\nthrough an attention layer. The experiments show that dependency relations are\nhelpful for dialogue context understanding, and our model outperforms the\nstate-of-the-art baselines on both DSTC7 and DSTC8*, with competitive results\non UbuntuV2.", "published": "2020-10-04 08:00:19", "link": "http://arxiv.org/abs/2010.01502v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-task Learning Framework for Opinion Triplet Extraction", "abstract": "The state-of-the-art Aspect-based Sentiment Analysis (ABSA) approaches are\nmainly based on either detecting aspect terms and their corresponding sentiment\npolarities, or co-extracting aspect and opinion terms. However, the extraction\nof aspect-sentiment pairs lacks opinion terms as a reference, while\nco-extraction of aspect and opinion terms would not lead to meaningful pairs\nwithout determining their sentiment dependencies. To address the issue, we\npresent a novel view of ABSA as an opinion triplet extraction task, and propose\na multi-task learning framework to jointly extract aspect terms and opinion\nterms, and simultaneously parses sentiment dependencies between them with a\nbiaffine scorer. At inference phase, the extraction of triplets is facilitated\nby a triplet decoding method based on the above outputs. We evaluate the\nproposed framework on four SemEval benchmarks for ASBA. The results demonstrate\nthat our approach significantly outperforms a range of strong baselines and\nstate-of-the-art approaches.", "published": "2020-10-04 08:31:54", "link": "http://arxiv.org/abs/2010.01512v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Unsupervised Dependency Parsing", "abstract": "Syntactic dependency parsing is an important task in natural language\nprocessing. Unsupervised dependency parsing aims to learn a dependency parser\nfrom sentences that have no annotation of their correct parse trees. Despite\nits difficulty, unsupervised parsing is an interesting research direction\nbecause of its capability of utilizing almost unlimited unannotated text data.\nIt also serves as the basis for other research in low-resource parsing. In this\npaper, we survey existing approaches to unsupervised dependency parsing,\nidentify two major classes of approaches, and discuss recent trends. We hope\nthat our survey can provide insights for researchers and facilitate future\nresearch on this topic.", "published": "2020-10-04 10:51:22", "link": "http://arxiv.org/abs/2010.01535v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Multilingual News Websites for Building a Kurdish Parallel\n  Corpus", "abstract": "Machine translation has been a major motivation of development in natural\nlanguage processing. Despite the burgeoning achievements in creating more\nefficient machine translation systems thanks to deep learning methods, parallel\ncorpora have remained indispensable for progress in the field. In an attempt to\ncreate parallel corpora for the Kurdish language, in this paper, we describe\nour approach in retrieving potentially-alignable news articles from\nmulti-language websites and manually align them across dialects and languages\nbased on lexical similarity and transliteration of scripts. We present a corpus\ncontaining 12,327 translation pairs in the two major dialects of Kurdish,\nSorani and Kurmanji. We also provide 1,797 and 650 translation pairs in\nEnglish-Kurmanji and English-Sorani. The corpus is publicly available under the\nCC BY-NC-SA 4.0 license.", "published": "2020-10-04 11:52:50", "link": "http://arxiv.org/abs/2010.01554v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reverse Operation based Data Augmentation for Solving Math Word Problems", "abstract": "Automatically solving math word problems is a critical task in the field of\nnatural language processing. Recent models have reached their performance\nbottleneck and require more high-quality data for training. We propose a novel\ndata augmentation method that reverses the mathematical logic of math word\nproblems to produce new high-quality math problems and introduce new knowledge\npoints that can benefit learning the mathematical reasoning logic. We apply the\naugmented data on two SOTA math word problem solving models and compare our\nresults with a strong data augmentation baseline. Experimental results show the\neffectiveness of our approach. We release our code and data at\nhttps://github.com/yiyunya/RODA.", "published": "2020-10-04 11:59:59", "link": "http://arxiv.org/abs/2010.01556v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Attack and Defense of Structured Prediction Models", "abstract": "Building an effective adversarial attacker and elaborating on countermeasures\nfor adversarial attacks for natural language processing (NLP) have attracted a\nlot of research in recent years. However, most of the existing approaches focus\non classification problems. In this paper, we investigate attacks and defenses\nfor structured prediction tasks in NLP. Besides the difficulty of perturbing\ndiscrete words and the sentence fluency problem faced by attackers in any NLP\ntasks, there is a specific challenge to attackers of structured prediction\nmodels: the structured output of structured prediction models is sensitive to\nsmall perturbations in the input. To address these problems, we propose a novel\nand unified framework that learns to attack a structured prediction model using\na sequence-to-sequence model with feedbacks from multiple reference models of\nthe same structured prediction task. Based on the proposed attack, we further\nreinforce the victim model with adversarial training, making its prediction\nmore robust and accurate. We evaluate the proposed framework in dependency\nparsing and part-of-speech tagging. Automatic and human evaluations show that\nour proposed framework succeeds in both attacking state-of-the-art structured\nprediction models and boosting them with adversarial training.", "published": "2020-10-04 15:54:03", "link": "http://arxiv.org/abs/2010.01610v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta Sequence Learning for Generating Adequate Question-Answer Pairs", "abstract": "Creating multiple-choice questions to assess reading comprehension of a given\narticle involves generating question-answer pairs (QAPs) on the main points of\nthe document. We present a learning scheme to generate adequate QAPs via\nmeta-sequence representations of sentences. A meta sequence is a sequence of\nvectors comprising semantic and syntactic tags. In particular, we devise a\nscheme called MetaQA to learn meta sequences from training data to form pairs\nof a meta sequence for a declarative sentence (MD) and a corresponding\ninterrogative sentence (MIs). On a given declarative sentence, a trained MetaQA\nmodel converts it to a meta sequence, finds a matched MD, and uses the\ncorresponding MIs and the input sentence to generate QAPs. We implement MetaQA\nfor the English language using semantic-role labeling, part-of-speech tagging,\nand named-entity recognition, and show that trained on a small dataset, MetaQA\ngenerates efficiently over the official SAT practice reading tests a large\nnumber of syntactically and semantically correct QAPs with over 97\\% accuracy.", "published": "2020-10-04 16:28:13", "link": "http://arxiv.org/abs/2010.01620v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on Large-Scale Multi-Label Text Classification\n  Including Few and Zero-Shot Labels", "abstract": "Large-scale Multi-label Text Classification (LMTC) has a wide range of\nNatural Language Processing (NLP) applications and presents interesting\nchallenges. First, not all labels are well represented in the training set, due\nto the very large label set and the skewed label distributions of LMTC\ndatasets. Also, label hierarchies and differences in human labelling guidelines\nmay affect graph-aware annotation proximity. Finally, the label hierarchies are\nperiodically updated, requiring LMTC models capable of zero-shot\ngeneralization. Current state-of-the-art LMTC models employ Label-Wise\nAttention Networks (LWANs), which (1) typically treat LMTC as flat multi-label\nclassification; (2) may use the label hierarchy to improve zero-shot learning,\nalthough this practice is vastly understudied; and (3) have not been combined\nwith pre-trained Transformers (e.g. BERT), which have led to state-of-the-art\nresults in several NLP benchmarks. Here, for the first time, we empirically\nevaluate a battery of LMTC methods from vanilla LWANs to hierarchical\nclassification approaches and transfer learning, on frequent, few, and\nzero-shot learning on three datasets from different domains. We show that\nhierarchical methods based on Probabilistic Label Trees (PLTs) outperform\nLWANs. Furthermore, we show that Transformer-based approaches outperform the\nstate-of-the-art in two of the datasets, and we propose a new state-of-the-art\nmethod which combines BERT with LWANs. Finally, we propose new models that\nleverage the label hierarchy to improve few and zero-shot learning, considering\non each dataset a graph-aware annotation proximity measure that we introduce.", "published": "2020-10-04 18:55:47", "link": "http://arxiv.org/abs/2010.01653v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inquisitive Question Generation for High Level Text Comprehension", "abstract": "Inquisitive probing questions come naturally to humans in a variety of\nsettings, but is a challenging task for automatic systems. One natural type of\nquestion to ask tries to fill a gap in knowledge during text comprehension,\nlike reading a news article: we might ask about background information, deeper\nreasons behind things occurring, or more. Despite recent progress with\ndata-driven approaches, generating such questions is beyond the range of models\ntrained on existing datasets.\n  We introduce INQUISITIVE, a dataset of ~19K questions that are elicited while\na person is reading through a document. Compared to existing datasets,\nINQUISITIVE questions target more towards high-level (semantic and discourse)\ncomprehension of text. We show that readers engage in a series of pragmatic\nstrategies to seek information. Finally, we evaluate question generation models\nbased on GPT-2 and show that our model is able to generate reasonable questions\nalthough the task is challenging, and highlight the importance of context to\ngenerate INQUISITIVE questions.", "published": "2020-10-04 19:03:39", "link": "http://arxiv.org/abs/2010.01657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Dialogue Responses from a Semantic Latent Space", "abstract": "Existing open-domain dialogue generation models are usually trained to mimic\nthe gold response in the training set using cross-entropy loss on the\nvocabulary. However, a good response does not need to resemble the gold\nresponse, since there are multiple possible responses to a given prompt. In\nthis work, we hypothesize that the current models are unable to integrate\ninformation from multiple semantically similar valid responses of a prompt,\nresulting in the generation of generic and uninformative responses. To address\nthis issue, we propose an alternative to the end-to-end classification on\nvocabulary. We learn the pair relationship between the prompts and responses as\na regression task on a latent space instead. In our novel dialog generation\nmodel, the representations of semantically related sentences are close to each\nother on the latent space. Human evaluation showed that learning the task on a\ncontinuous space can generate responses that are both relevant and informative.", "published": "2020-10-04 19:06:16", "link": "http://arxiv.org/abs/2010.01658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Target-side Lexical Transfer in Multilingual Neural Machine\n  Translation", "abstract": "To improve the performance of Neural Machine Translation~(NMT) for\nlow-resource languages~(LRL), one effective strategy is to leverage parallel\ndata from a related high-resource language~(HRL). However, multilingual data\nhas been found more beneficial for NMT models that translate from the LRL to a\ntarget language than the ones that translate into the LRLs. In this paper, we\naim to improve the effectiveness of multilingual transfer for NMT models that\ntranslate \\emph{into} the LRL, by designing a better decoder word embedding.\nExtending upon a general-purpose multilingual encoding method Soft Decoupled\nEncoding~\\citep{SDE}, we propose DecSDE, an efficient character n-gram based\nembedding specifically designed for the NMT decoder. Our experiments show that\nDecSDE leads to consistent gains of up to 1.8 BLEU on translation from English\nto four different languages.", "published": "2020-10-04 19:42:40", "link": "http://arxiv.org/abs/2010.01667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-View Sequence-to-Sequence Models with Conversational Structure for\n  Abstractive Dialogue Summarization", "abstract": "Text summarization is one of the most challenging and interesting problems in\nNLP. Although much attention has been paid to summarizing structured text like\nnews reports or encyclopedia articles, summarizing conversations---an essential\npart of human-human/machine interaction where most important pieces of\ninformation are scattered across various utterances of different\nspeakers---remains relatively under-investigated. This work proposes a\nmulti-view sequence-to-sequence model by first extracting conversational\nstructures of unstructured daily chats from different views to represent\nconversations and then utilizing a multi-view decoder to incorporate different\nviews to generate dialogue summaries. Experiments on a large-scale dialogue\nsummarization corpus demonstrated that our methods significantly outperformed\nprevious state-of-the-art models via both automatic evaluations and human\njudgment. We also discussed specific challenges that current approaches faced\nwith this task. We have publicly released our code at\nhttps://github.com/GT-SALT/Multi-View-Seq2Seq.", "published": "2020-10-04 20:12:44", "link": "http://arxiv.org/abs/2010.01672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Local Additivity Based Data Augmentation for Semi-supervised NER", "abstract": "Named Entity Recognition (NER) is one of the first stages in deep language\nunderstanding yet current NER models heavily rely on human-annotated data. In\nthis work, to alleviate the dependence on labeled data, we propose a Local\nAdditivity based Data Augmentation (LADA) method for semi-supervised NER, in\nwhich we create virtual samples by interpolating sequences close to each other.\nOur approach has two variations: Intra-LADA and Inter-LADA, where Intra-LADA\nperforms interpolations among tokens within one sentence, and Inter-LADA\nsamples different sentences to interpolate. Through linear additions between\nsampled training data, LADA creates an infinite amount of labeled data and\nimproves both entity and context learning. We further extend LADA to the\nsemi-supervised setting by designing a novel consistency loss for unlabeled\ndata. Experiments conducted on two NER benchmarks demonstrate the effectiveness\nof our methods over several strong baselines. We have publicly released our\ncode at https://github.com/GT-SALT/LADA.", "published": "2020-10-04 20:46:26", "link": "http://arxiv.org/abs/2010.01677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly-supervised Fine-grained Event Recognition on Social Media Texts\n  for Disaster Management", "abstract": "People increasingly use social media to report emergencies, seek help or\nshare information during disasters, which makes social networks an important\ntool for disaster management. To meet these time-critical needs, we present a\nweakly supervised approach for rapidly building high-quality classifiers that\nlabel each individual Twitter message with fine-grained event categories. Most\nimportantly, we propose a novel method to create high-quality labeled data in a\ntimely manner that automatically clusters tweets containing an event keyword\nand asks a domain expert to disambiguate event word senses and label clusters\nquickly. In addition, to process extremely noisy and often rather short\nuser-generated messages, we enrich tweet representations using preceding\ncontext tweets and reply tweets in building event recognition classifiers. The\nevaluation on two hurricanes, Harvey and Florence, shows that using only 1-2\nperson-hours of human supervision, the rapidly trained weakly supervised\nclassifiers outperform supervised classifiers trained using more than ten\nthousand annotated tweets created in over 50 person-hours.", "published": "2020-10-04 21:06:45", "link": "http://arxiv.org/abs/2010.01683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented\n  Dialogue Systems", "abstract": "End-to-end task-oriented dialogue systems aim to generate system responses\ndirectly from plain text inputs. There are two challenges for such systems: one\nis how to effectively incorporate external knowledge bases (KBs) into the\nlearning framework; the other is how to accurately capture the semantics of\ndialogue history. In this paper, we address these two challenges by exploiting\nthe graph structural information in the knowledge base and in the dependency\nparsing tree of the dialogue. To effectively leverage the structural\ninformation in dialogue history, we propose a new recurrent cell architecture\nwhich allows representation learning on graphs. To exploit the relations\nbetween entities in KBs, the model combines multi-hop reasoning ability based\non the graph structure. Experimental results show that the proposed model\nachieves consistent improvement over state-of-the-art models on two different\ntask-oriented dialogue datasets.", "published": "2020-10-04 00:04:40", "link": "http://arxiv.org/abs/2010.01447v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge-Enhanced Personalized Review Generation with Capsule Graph\n  Neural Network", "abstract": "Personalized review generation (PRG) aims to automatically produce review\ntext reflecting user preference, which is a challenging natural language\ngeneration task. Most of previous studies do not explicitly model factual\ndescription of products, tending to generate uninformative content. Moreover,\nthey mainly focus on word-level generation, but cannot accurately reflect more\nabstractive user preference in multiple aspects. To address the above issues,\nwe propose a novel knowledge-enhanced PRG model based on capsule graph neural\nnetwork~(Caps-GNN). We first construct a heterogeneous knowledge graph (HKG)\nfor utilizing rich item attributes. We adopt Caps-GNN to learn graph capsules\nfor encoding underlying characteristics from the HKG. Our generation process\ncontains two major steps, namely aspect sequence generation and sentence\ngeneration. First, based on graph capsules, we adaptively learn aspect capsules\nfor inferring the aspect sequence. Then, conditioned on the inferred aspect\nlabel, we design a graph-based copy mechanism to generate sentences by\nincorporating related entities or words from HKG. To our knowledge, we are the\nfirst to utilize knowledge graph for the PRG task. The incorporated KG\ninformation is able to enhance user preference at both aspect and word levels.\nExtensive experiments on three real-world datasets have demonstrated the\neffectiveness of our model on the PRG task.", "published": "2020-10-04 03:54:40", "link": "http://arxiv.org/abs/2010.01480v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Paragraph-level Commonsense Transformers with Recurrent Memory", "abstract": "Human understanding of narrative texts requires making commonsense inferences\nbeyond what is stated explicitly in the text. A recent model, COMET, can\ngenerate such implicit commonsense inferences along several dimensions such as\npre- and post-conditions, motivations, and mental states of the participants.\nHowever, COMET was trained on commonsense inferences of short phrases, and is\ntherefore discourse-agnostic. When presented with each sentence of a\nmulti-sentence narrative, it might generate inferences that are inconsistent\nwith the rest of the narrative.\n  We present the task of discourse-aware commonsense inference. Given a\nsentence within a narrative, the goal is to generate commonsense inferences\nalong predefined dimensions, while maintaining coherence with the rest of the\nnarrative. Such large-scale paragraph-level annotation is hard to get and\ncostly, so we use available sentence-level annotations to efficiently and\nautomatically construct a distantly supervised corpus.\n  Using this corpus, we train PARA-COMET, a discourse-aware model that\nincorporates paragraph-level information to generate coherent commonsense\ninferences from narratives. PARA-COMET captures both semantic knowledge\npertaining to prior world knowledge, and episodic knowledge involving how\ncurrent events relate to prior and future events in a narrative. Our results\nshow that PARA-COMET outperforms the sentence-level baselines, particularly in\ngenerating inferences that are both coherent and novel.", "published": "2020-10-04 05:24:12", "link": "http://arxiv.org/abs/2010.01486v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining Deep Neural Networks", "abstract": "Deep neural networks are becoming more and more popular due to their\nrevolutionary success in diverse areas, such as computer vision, natural\nlanguage processing, and speech recognition. However, the decision-making\nprocesses of these models are generally not interpretable to users. In various\ndomains, such as healthcare, finance, or law, it is critical to know the\nreasons behind a decision made by an artificial intelligence system. Therefore,\nseveral directions for explaining neural models have recently been explored. In\nthis thesis, I investigate two major directions for explaining deep neural\nnetworks. The first direction consists of feature-based post-hoc explanatory\nmethods, that is, methods that aim to explain an already trained and fixed\nmodel (post-hoc), and that provide explanations in terms of input features,\nsuch as tokens for text and superpixels for images (feature-based). The second\ndirection consists of self-explanatory neural models that generate natural\nlanguage explanations, that is, models that have a built-in module that\ngenerates explanations for the predictions of the model.", "published": "2020-10-04 07:23:13", "link": "http://arxiv.org/abs/2010.01496v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NLP Service APIs and Models for Efficient Registration of New Clients", "abstract": "State-of-the-art NLP inference uses enormous neural architectures and models\ntrained for GPU-months, well beyond the reach of most consumers of NLP. This\nhas led to one-size-fits-all public API-based NLP service models by major AI\ncompanies, serving large numbers of clients. Neither (hardware deficient)\nclients nor (heavily subscribed) servers can afford traditional fine tuning.\nMany clients own little or no labeled data. We initiate a study of adaptation\nof centralized NLP services to clients, and present one practical and\nlightweight approach. Each client uses an unsupervised, corpus-based sketch to\nregister to the service. The server uses an auxiliary network to map the sketch\nto an abstract vector representation, which then informs the main labeling\nnetwork. When a new client registers with its sketch, it gets immediate\naccuracy benefits. We demonstrate the success of the proposed architecture\nusing sentiment labeling, NER, and predictive language modeling", "published": "2020-10-04 09:47:40", "link": "http://arxiv.org/abs/2010.01526v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Static and Animated 3D Scene Generation from Free-form Text Descriptions", "abstract": "Generating coherent and useful image/video scenes from a free-form textual\ndescription is technically a very difficult problem to handle. Textual\ndescription of the same scene can vary greatly from person to person, or\nsometimes even for the same person from time to time. As the choice of words\nand syntax vary while preparing a textual description, it is challenging for\nthe system to reliably produce a consistently desirable output from different\nforms of language input. The prior works of scene generation have been mostly\nconfined to rigorous sentence structures of text input which restrict the\nfreedom of users to write description. In our work, we study a new pipeline\nthat aims to generate static as well as animated 3D scenes from different types\nof free-form textual scene description without any major restriction. In\nparticular, to keep our study practical and tractable, we focus on a small\nsubspace of all possible 3D scenes, containing various combinations of cube,\ncylinder and sphere. We design a two-stage pipeline. In the first stage, we\nencode the free-form text using an encoder-decoder neural architecture. In the\nsecond stage, we generate a 3D scene based on the generated encoding. Our\nneural architecture exploits state-of-the-art language model as encoder to\nleverage rich contextual encoding and a new multi-head decoder to predict\nmultiple features of an object in the scene simultaneously. For our\nexperiments, we generate a large synthetic data-set which contains 13,00,000\nand 14,00,000 samples of unique static and animated scene descriptions,\nrespectively. We achieve 98.427% accuracy on test data set in detecting the 3D\nobjects features successfully. Our work shows a proof of concept of one\napproach towards solving the problem, and we believe with enough training data,\nthe same pipeline can be expanded to handle even broader set of 3D scene\ngeneration problems.", "published": "2020-10-04 11:31:21", "link": "http://arxiv.org/abs/2010.01549v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Optimal Neural Program Synthesis from Multimodal Specifications", "abstract": "Multimodal program synthesis, which leverages different types of user input\nto synthesize a desired program, is an attractive way to scale program\nsynthesis to challenging settings; however, it requires integrating noisy\nsignals from the user, like natural language, with hard constraints on the\nprogram's behavior. This paper proposes an optimal neural synthesis approach\nwhere the goal is to find a program that satisfies user-provided constraints\nwhile also maximizing the program's score with respect to a neural model.\nSpecifically, we focus on multimodal synthesis tasks in which the user intent\nis expressed using a combination of natural language (NL) and input-output\nexamples. At the core of our method is a top-down recurrent neural model that\nplaces distributions over abstract syntax trees conditioned on the NL input.\nThis model not only allows for efficient search over the space of syntactically\nvalid programs, but it allows us to leverage automated program analysis\ntechniques for pruning the search space based on infeasibility of partial\nprograms with respect to the user's constraints. The experimental results on a\nmultimodal synthesis dataset (StructuredRegex) show that our method\nsubstantially outperforms prior state-of-the-art techniques in terms of\naccuracy and efficiency, and finds model-optimal programs more frequently.", "published": "2020-10-04 20:51:21", "link": "http://arxiv.org/abs/2010.01678v2", "categories": ["cs.CL", "cs.PL"], "primary_category": "cs.CL"}
{"title": "On Losses for Modern Language Models", "abstract": "BERT set many state-of-the-art results over varied NLU benchmarks by\npre-training over two tasks: masked language modelling (MLM) and next sentence\nprediction (NSP), the latter of which has been highly criticized. In this\npaper, we 1) clarify NSP's effect on BERT pre-training, 2) explore fourteen\npossible auxiliary pre-training tasks, of which seven are novel to modern\nlanguage models, and 3) investigate different ways to include multiple tasks\ninto pre-training. We show that NSP is detrimental to training due to its\ncontext splitting and shallow semantic signal. We also identify six auxiliary\npre-training tasks -- sentence ordering, adjacent sentence prediction, TF\nprediction, TF-IDF prediction, a FastSent variant, and a Quick Thoughts variant\n-- that outperform a pure MLM baseline. Finally, we demonstrate that using\nmultiple tasks in a multi-task pre-training framework provides better results\nthan using any single auxiliary task. Using these methods, we outperform BERT\nBase on the GLUE benchmark using fewer than a quarter of the training tokens.", "published": "2020-10-04 21:44:15", "link": "http://arxiv.org/abs/2010.01694v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story\n  Generation", "abstract": "Systems for story generation are asked to produce plausible and enjoyable\nstories given an input context. This task is underspecified, as a vast number\nof diverse stories can originate from a single input. The large output space\nmakes it difficult to build and evaluate story generation models, as (1)\nexisting datasets lack rich enough contexts to meaningfully guide models, and\n(2) existing evaluations (both crowdsourced and automatic) are unreliable for\nassessing long-form creative text. To address these issues, we introduce a\ndataset and evaluation platform built from STORIUM, an online collaborative\nstorytelling community. Our author-generated dataset contains 6K lengthy\nstories (125M tokens) with fine-grained natural language annotations (e.g.,\ncharacter goals and attributes) interspersed throughout each narrative, forming\na robust source for guiding models. We evaluate language models fine-tuned on\nour dataset by integrating them onto STORIUM, where real authors can query a\nmodel for suggested story continuations and then edit them. Automatic metrics\ncomputed over these edits correlate well with both user ratings of generated\nstories and qualitative feedback from semi-structured user interviews. We\nrelease both the STORIUM dataset and evaluation platform to spur more\nprincipled research into story generation.", "published": "2020-10-04 23:26:09", "link": "http://arxiv.org/abs/2010.01717v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Unification of HDP and LDA Models for Optimal Topic Clustering of\n  Subject Specific Question Banks", "abstract": "There has been an increasingly popular trend in Universities for curriculum\ntransformation to make teaching more interactive and suitable for online\ncourses. An increase in the popularity of online courses would result in an\nincrease in the number of course-related queries for academics. This, coupled\nwith the fact that if lectures were delivered in a video on demand format,\nthere would be no fixed time where the majority of students could ask\nquestions. When questions are asked in a lecture there is a negligible chance\nof having similar questions repeatedly, but asynchronously this is more likely.\nIn order to reduce the time spent on answering each individual question,\nclustering them is an ideal choice. There are different unsupervised models fit\nfor text clustering, of which the Latent Dirichlet Allocation model is the most\ncommonly used. We use the Hierarchical Dirichlet Process to determine an\noptimal topic number input for our LDA model runs. Due to the probabilistic\nnature of these topic models, the outputs of them vary for different runs. The\ngeneral trend we found is that not all the topics were being used for\nclustering on the first run of the LDA model, which results in a less effective\nclustering. To tackle probabilistic output, we recursively use the LDA model on\nthe effective topics being used until we obtain an efficiency ratio of 1.\nThrough our experimental results we also establish a reasoning on how Zeno's\nparadox is avoided.", "published": "2020-10-04 18:21:20", "link": "http://arxiv.org/abs/2011.01035v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "SumGNN: Multi-typed Drug Interaction Prediction via Efficient Knowledge\n  Graph Summarization", "abstract": "Thanks to the increasing availability of drug-drug interactions (DDI)\ndatasets and large biomedical knowledge graphs (KGs), accurate detection of\nadverse DDI using machine learning models becomes possible. However, it remains\nlargely an open problem how to effectively utilize large and noisy biomedical\nKG for DDI detection. Due to its sheer size and amount of noise in KGs, it is\noften less beneficial to directly integrate KGs with other smaller but higher\nquality data (e.g., experimental data). Most of the existing approaches ignore\nKGs altogether. Some try to directly integrate KGs with other data via graph\nneural networks with limited success. Furthermore, most previous works focus on\nbinary DDI prediction whereas the multi-typed DDI pharmacological effect\nprediction is a more meaningful but harder task. To fill the gaps, we propose a\nnew method SumGNN: knowledge summarization graph neural network, which is\nenabled by a subgraph extraction module that can efficiently anchor on relevant\nsubgraphs from a KG, a self-attention based subgraph summarization scheme to\ngenerate a reasoning path within the subgraph, and a multi-channel knowledge\nand data integration module that utilizes massive external biomedical knowledge\nfor significantly improved multi-typed DDI predictions. SumGNN outperforms the\nbest baseline by up to 5.54\\%, and the performance gain is particularly\nsignificant in low data relation types. In addition, SumGNN provides\ninterpretable prediction via the generated reasoning paths for each prediction.", "published": "2020-10-04 00:14:57", "link": "http://arxiv.org/abs/2010.01450v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Reproducible Science with LaTeX", "abstract": "This paper proposes a procedure to execute external source codes from a LaTeX\ndocument and include the calculation outputs in the resulting Portable Document\nFormat (pdf) file automatically. It integrates programming tools into the LaTeX\nwriting tool to facilitate the production of reproducible research. In our\nproposed approach to a LaTeX-based scientific notebook the user can easily\ninvoke any programming language or a command-line program when compiling the\nLaTeX document, while using their favorite LaTeX editor in the writing process.\nThe required LaTeX setup, a new Python package, and the defined preamble are\ndiscussed in detail, and working examples using R, Julia, and MatLab to\nreproduce existing research are provided to illustrate the proposed procedure.\nWe also demonstrate how to include system setting information in a paper by\ninvoking shell scripts when compiling the document.", "published": "2020-10-04 04:04:07", "link": "http://arxiv.org/abs/2010.01482v2", "categories": ["cs.SE", "cs.CL", "stat.CO"], "primary_category": "cs.SE"}
{"title": "Dialogue Generation on Infrequent Sentence Functions via Structured\n  Meta-Learning", "abstract": "Sentence function is an important linguistic feature indicating the\ncommunicative purpose in uttering a sentence. Incorporating sentence functions\ninto conversations has shown improvements in the quality of generated\nresponses. However, the number of utterances for different types of\nfine-grained sentence functions is extremely imbalanced. Besides a small number\nof high-resource sentence functions, a large portion of sentence functions is\ninfrequent. Consequently, dialogue generation conditioned on these infrequent\nsentence functions suffers from data deficiency. In this paper, we investigate\na structured meta-learning (SML) approach for dialogue generation on infrequent\nsentence functions. We treat dialogue generation conditioned on different\nsentence functions as separate tasks, and apply model-agnostic meta-learning to\nhigh-resource sentence functions data. Furthermore, SML enhances meta-learning\neffectiveness by promoting knowledge customization among different sentence\nfunctions but simultaneously preserving knowledge generalization for similar\nsentence functions. Experimental results demonstrate that SML not only improves\nthe informativeness and relevance of generated responses, but also can generate\nresponses consistent with the target sentence functions.", "published": "2020-10-04 07:13:36", "link": "http://arxiv.org/abs/2010.01495v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "When in Doubt, Ask: Generating Answerable and Unanswerable Questions,\n  Unsupervised", "abstract": "Question Answering (QA) is key for making possible a robust communication\nbetween human and machine. Modern language models used for QA have surpassed\nthe human-performance in several essential tasks; however, these models require\nlarge amounts of human-generated training data which are costly and\ntime-consuming to create. This paper studies augmenting human-made datasets\nwith synthetic data as a way of surmounting this problem. A state-of-the-art\nmodel based on deep transformers is used to inspect the impact of using\nsynthetic answerable and unanswerable questions to complement a well-known\nhuman-made dataset. The results indicate a tangible improvement in the\nperformance of the language model (measured in terms of F1 and EM scores)\ntrained on the mixed dataset. Specifically, unanswerable question-answers prove\nmore effective in boosting the model: the F1 score gain from adding to the\noriginal dataset the answerable, unanswerable, and combined question-answers\nwere 1.3%, 5.0%, and 6.7%, respectively. [Link to the Github repository:\nhttps://github.com/lnikolenko/EQA]", "published": "2020-10-04 15:56:44", "link": "http://arxiv.org/abs/2010.01611v2", "categories": ["cs.CL", "cs.FL", "cs.LG", "G.3; F.4"], "primary_category": "cs.CL"}
{"title": "Deep Just-In-Time Inconsistency Detection Between Comments and Source\n  Code", "abstract": "Natural language comments convey key aspects of source code such as\nimplementation, usage, and pre- and post-conditions. Failure to update comments\naccordingly when the corresponding code is modified introduces inconsistencies,\nwhich is known to lead to confusion and software bugs. In this paper, we aim to\ndetect whether a comment becomes inconsistent as a result of changes to the\ncorresponding body of code, in order to catch potential inconsistencies\njust-in-time, i.e., before they are committed to a code base. To achieve this,\nwe develop a deep-learning approach that learns to correlate a comment with\ncode changes. By evaluating on a large corpus of comment/code pairs spanning\nvarious comment types, we show that our model outperforms multiple baselines by\nsignificant margins. For extrinsic evaluation, we show the usefulness of our\napproach by combining it with a comment update model to build a more\ncomprehensive automatic comment maintenance system which can both detect and\nresolve inconsistent comments based on code changes.", "published": "2020-10-04 16:49:28", "link": "http://arxiv.org/abs/2010.01625v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Multi-microphone Complex Spectral Mapping for Utterance-wise and\n  Continuous Speech Separation", "abstract": "We propose multi-microphone complex spectral mapping, a simple way of\napplying deep learning for time-varying non-linear beamforming, for speaker\nseparation in reverberant conditions. We aim at both speaker separation and\ndereverberation. Our study first investigates offline utterance-wise speaker\nseparation and then extends to block-online continuous speech separation (CSS).\nAssuming a fixed array geometry between training and testing, we train deep\nneural networks (DNN) to predict the real and imaginary (RI) components of\ntarget speech at a reference microphone from the RI components of multiple\nmicrophones. We then integrate multi-microphone complex spectral mapping with\nminimum variance distortionless response (MVDR) beamforming and post-filtering\nto further improve separation, and combine it with frame-level speaker counting\nfor block-online CSS. Although our system is trained on simulated room impulse\nresponses (RIR) based on a fixed number of microphones arranged in a given\ngeometry, it generalizes well to a real array with the same geometry.\nState-of-the-art separation performance is obtained on the simulated two-talker\nSMS-WSJ corpus and the real-recorded LibriCSS dataset.", "published": "2020-10-04 22:13:13", "link": "http://arxiv.org/abs/2010.01703v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reading Comprehension as Natural Language Inference: A Semantic Analysis", "abstract": "In the recent past, Natural language Inference (NLI) has gained significant\nattention, particularly given its promise for downstream NLP tasks. However,\nits true impact is limited and has not been well studied. Therefore, in this\npaper, we explore the utility of NLI for one of the most prominent downstream\ntasks, viz. Question Answering (QA). We transform the one of the largest\navailable MRC dataset (RACE) to an NLI form, and compare the performances of a\nstate-of-the-art model (RoBERTa) on both these forms. We propose new\ncharacterizations of questions, and evaluate the performance of QA and NLI\nmodels on these categories. We highlight clear categories for which the model\nis able to perform better when the data is presented in a coherent entailment\nform, and a structured question-answer concatenation form, respectively.", "published": "2020-10-04 22:50:59", "link": "http://arxiv.org/abs/2010.01713v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DLGNet-Task: An End-to-end Neural Network Framework for Modeling\n  Multi-turn Multi-domain Task-Oriented Dialogue", "abstract": "Task oriented dialogue (TOD) requires the complex interleaving of a number of\nindividually controllable components with strong guarantees for explainability\nand verifiability. This has made it difficult to adopt the multi-turn\nmulti-domain dialogue generation capabilities of streamlined end-to-end\nopen-domain dialogue systems. In this paper, we present a new framework,\nDLGNet-Task, a unified task-oriented dialogue system which employs\nautoregressive transformer networks such as DLGNet and GPT-2/3 to complete user\ntasks in multi-turn multi-domain conversations. Our framework enjoys the\ncontrollable, verifiable, and explainable outputs of modular approaches, and\nthe low development, deployment and maintenance cost of end-to-end systems.\nTreating open-domain system components as additional TOD system modules allows\nDLGNet-Task to learn the joint distribution of the inputs and outputs of all\nthe functional blocks of existing modular approaches such as, natural language\nunderstanding (NLU), state tracking, action policy, as well as natural language\ngeneration (NLG). Rather than training the modules individually, as is common\nin real-world systems, we trained them jointly with appropriate module\nseparations. When evaluated on the MultiWOZ2.1 dataset, DLGNet-Task shows\ncomparable performance to the existing state-of-the-art approaches.\nFurthermore, using DLGNet-Task in conversational AI systems reduces the level\nof effort required for developing, deploying, and maintaining intelligent\nassistants at scale.", "published": "2020-10-04 21:43:17", "link": "http://arxiv.org/abs/2010.01693v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A Course on Controllers", "abstract": "Over the last four years, we have developed a series of lectures, labs and\nproject assignments aimed at introducing enough technology so that students\nfrom a mix of disciplines can design and build innovative interface devices.", "published": "2020-10-04 12:55:18", "link": "http://arxiv.org/abs/2010.01569v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Problems and Prospects for Intimate Musical Control of Computers", "abstract": "In this paper we describe our efforts towards the development of live\nperformance computer-based musical instrumentation. Our design criteria include\ninitial ease of use coupled with a long term potential for virtuosity, minimal\nand low variance latency, and clear and simple strategies for programming the\nrelationship between gesture and musical result. We present custom controllers\nand unique adaptations of standard gestural interfaces, a programmable\nconnectivity processor, a communications protocol called Open Sound Control\n(OSC), and a variety of metaphors for musical control. We further describe\napplications of our technology to a variety of real musical performances and\ndirections for future research.", "published": "2020-10-04 12:55:43", "link": "http://arxiv.org/abs/2010.01570v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Input Devices for Musical Expression: Borrowing Tools from HCI", "abstract": "This paper reviews the existing literature on input device evaluation and\ndesign in human-computer interaction (HCI) and discusses possible applications\nof this knowledge to the design and evaluation of new interfaces for musical\nexpression. Specifically, a set of musical tasks is suggested to allow the\nevaluation of different existing controllers.", "published": "2020-10-04 12:56:14", "link": "http://arxiv.org/abs/2010.01571v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Resonant Processing of Instrumental Sound Controlled by Spatial Position", "abstract": "We present an acoustic musical instrument played through a resonance model of\nanother sound. The resonance model is controlled in real time as part of the\ncomposite instrument. Our implementation uses an electric violin, whose spatial\nposition modifies filter parameters of the resonance model. Simplicial\ninterpolation defines the mapping from spatial position to filter parameters.\nWith some effort, pitch tracking can also control the filter parameters. The\nindividual technologies -- motion tracking, pitch tracking, resonance models --\nare easily adapted to other instruments.", "published": "2020-10-04 12:56:41", "link": "http://arxiv.org/abs/2010.01572v1", "categories": ["cs.SD", "cs.HC", "eess.AS", "H.5.5"], "primary_category": "cs.SD"}
{"title": "The Accordiatron: A MIDI Controller For Interactive Music", "abstract": "The Accordiatron is a new MIDI controller for real-time performance based on\nthe paradigm of a conventional squeeze box or concertina. It translates the\ngestures of a performer to the standard communication protocol of MIDI,\nallowing for flexible mappings of performance data to sonic parameters. When\nused in conjunction with a realtime signal processing environment, the\nAccordiatron becomes an expressive, versatile musical instrument. A combination\nof sensory outputs providing both discrete and continuous data gives the subtle\nexpressiveness and control necessary for interactive music.", "published": "2020-10-04 12:57:08", "link": "http://arxiv.org/abs/2010.01574v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Tangible Music Interfaces Using Passive Magnetic Tags", "abstract": "The technologies behind passive resonant magnetically coupled tags are\nintroduced and their application as a musical controller is illustrated for\nsolo or group performances, interactive installations, and music toys.", "published": "2020-10-04 12:57:33", "link": "http://arxiv.org/abs/2010.01575v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Body, Clothes, Water, and Toys: Media Towards Natural Music Expressions\n  with Digital Sounds", "abstract": "In this paper, we introduce our research challenges for creating new musical\ninstruments using everyday-life media with intimate interfaces, such as the\nself-body, clothes, water and stuffed toys. Various sensor technologies\nincluding image processing and general touch sensitive devices are employed to\nexploit these interaction media. The focus of our effort is to provide\nuser-friendly and enjoyable experiences for new music and sound performances.\nMultimodality of musical instruments is explored in each attempt. The degree of\ncontrollability in the performance and the richness of expressions are also\ndiscussed for each installation.", "published": "2020-10-04 12:57:58", "link": "http://arxiv.org/abs/2010.01576v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "The MATRIX: A Novel Controller for Musical Expression", "abstract": "The MATRIX (Multipurpose Array of Tactile Rods for Interactive eXpression) is\na new musical interface for amateurs and professionals alike. It gives users a\n3- dimensional tangible interface to control music using their hands, and can\nbe used in conjunction with a traditional musical instrument and a microphone,\nor as a stand-alone gestural input device. The surface of the MATRIX acts as a\nreal-time interface that can manipulate the parameters of a synthesis engine or\neffect algorithm in response to a performer's expressive gestures. One example\nis to have the rods of the MATRIX control the individual grains of a granular\nsynthesizer, thereby \"sonically sculpting\" the microstructure of a sound. In\nthis way, the MATRIX provides an intuitive method of manip", "published": "2020-10-04 12:58:23", "link": "http://arxiv.org/abs/2010.01577v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "Creating Contexts of Creativity: Musical Composition with Modular\n  Components", "abstract": "This paper describes a series of projects that explore the possibilities of\nmusical expression through the combination of pre-composed, interlocking,\nmodular components. In particular, this paper presents a modular soundtrack\nrecently composed by the author for \"Currents of Creativity,\" a permanent\ninteractive video wall installation at the Pope John Paul II Cultural Center\nwhich is slated to open Easter 2001 in Washington, DC.", "published": "2020-10-04 12:58:51", "link": "http://arxiv.org/abs/2010.01578v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "New Musical Interfaces and New Music-making Paradigms", "abstract": "The conception and design of new musical interfaces is a multidisciplinary\narea that tightly relates technology and artistic creation. In this paper, the\nauthor first exposes some of the questions he has posed himself during more\nthan a decade experience as a performer, composer, interface and software\ndesigner, and educator. Finally, he illustrates these topics with some examples\nof his work.", "published": "2020-10-04 12:59:20", "link": "http://arxiv.org/abs/2010.01579v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
{"title": "The Interactive Dance Club: Avoiding Chaos In A Multi Participant\n  Environment", "abstract": "In 1998 we designed enabling technology and a venue concept that allowed\nseveral participants to influence a shared musical and visual experience. Our\nprimary goal was to deliver musically coherent and visually satisfying results\nfrom several participants' input. The result, the Interactive Dance Club, ran\nfor four nights at the ACM SIGGRAPH 98 convention in Orlando, Florida. In this\npaper we will briefly describe the Interactive Dance Club, our \"10 Commandments\nof Interactivity,\" and what we learned from its premiere at SIGGRAPH 98.", "published": "2020-10-04 13:00:04", "link": "http://arxiv.org/abs/2010.02207v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.HC"}
