{"title": "Speaker-Sensitive Dual Memory Networks for Multi-Turn Slot Tagging", "abstract": "In multi-turn dialogs, natural language understanding models can introduce\nobvious errors by being blind to contextual information. To incorporate dialog\nhistory, we present a neural architecture with Speaker-Sensitive Dual Memory\nNetworks which encode utterances differently depending on the speaker. This\naddresses the different extents of information available to the system - the\nsystem knows only the surface form of user utterances while it has the exact\nsemantics of system output. We performed experiments on real user data from\nMicrosoft Cortana, a commercial personal assistant. The result showed a\nsignificant performance improvement over the state-of-the-art slot tagging\nmodels using contextual information.", "published": "2017-11-29 06:55:59", "link": "http://arxiv.org/abs/1711.10705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Optimization of Task-Oriented Dialogue Model with Deep\n  Reinforcement Learning", "abstract": "In this paper, we present a neural network based task-oriented dialogue\nsystem that can be optimized end-to-end with deep reinforcement learning (RL).\nThe system is able to track dialogue state, interface with knowledge bases, and\nincorporate query results into agent's responses to successfully complete\ntask-oriented dialogues. Dialogue policy learning is conducted with a hybrid\nsupervised and deep RL methods. We first train the dialogue agent in a\nsupervised manner by learning directly from task-oriented dialogue corpora, and\nfurther optimize it with deep RL during its interaction with users. In the\nexperiments on two different dialogue task domains, our model demonstrates\nrobust performance in tracking dialogue state and producing reasonable system\nresponses. We show that deep RL based optimization leads to significant\nimprovement on task success rate and reduction in dialogue length comparing to\nsupervised training model. We further show benefits of training task-oriented\ndialogue model end-to-end comparing to component-wise optimization with\nexperiment results on dialogue simulations and human evaluations.", "published": "2017-11-29 07:38:07", "link": "http://arxiv.org/abs/1711.10712v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Curriculum Q-Learning for Visual Vocabulary Acquisition", "abstract": "The structure of curriculum plays a vital role in our learning process, both\nas children and adults. Presenting material in ascending order of difficulty\nthat also exploits prior knowledge can have a significant impact on the rate of\nlearning. However, the notion of difficulty and prior knowledge differs from\nperson to person. Motivated by the need for a personalised curriculum, we\npresent a novel method of curriculum learning for vocabulary words in the form\nof visual prompts. We employ a reinforcement learning model grounded in\npedagogical theories that emulates the actions of a tutor. We simulate three\nstudents with different levels of vocabulary knowledge in order to evaluate the\nhow well our model adapts to the environment. The results of the simulation\nreveal that through interaction, the model is able to identify the areas of\nweakness, as well as push students to the edge of their ZPD. We hypothesise\nthat these methods can also be effective in training agents to learn language\nrepresentations in a simulated environment where it has previously been shown\nthat order of words and prior knowledge play an important role in the efficacy\nof language learning.", "published": "2017-11-29 13:21:22", "link": "http://arxiv.org/abs/1711.10837v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Attribute Extraction", "abstract": "The broad goal of information extraction is to derive structured information\nfrom unstructured data. However, most existing methods focus solely on text,\nignoring other types of unstructured data such as images, video and audio which\ncomprise an increasing portion of the information on the web. To address this\nshortcoming, we propose the task of multimodal attribute extraction. Given a\ncollection of unstructured and semi-structured contextual information about an\nentity (such as a textual description, or visual depictions) the task is to\nextract the entity's underlying attributes. In this paper, we provide a dataset\ncontaining mixed-media data for over 2 million product items along with 7\nmillion attribute-value pairs describing the items which can be used to train\nattribute extractors in a weakly supervised manner. We provide a variety of\nbaselines which demonstrate the relative effectiveness of the individual modes\nof information towards solving the task, as well as study human performance.", "published": "2017-11-29 21:40:59", "link": "http://arxiv.org/abs/1711.11118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting and Explaining Human Semantic Search in a Cognitive Model", "abstract": "Recent work has attempted to characterize the structure of semantic memory\nand the search algorithms which, together, best approximate human patterns of\nsearch revealed in a semantic fluency task. There are a number of models that\nseek to capture semantic search processes over networks, but they vary in the\ncognitive plausibility of their implementation. Existing work has also\nneglected to consider the constraints that the incremental process of language\nacquisition must place on the structure of semantic memory. Here we present a\nmodel that incrementally updates a semantic network, with limited computational\nsteps, and replicates many patterns found in human semantic fluency using a\nsimple random walk. We also perform thorough analyses showing that a\ncombination of both structural and semantic features are correlated with human\nperformance patterns.", "published": "2017-11-29 21:50:40", "link": "http://arxiv.org/abs/1711.11125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalized Grounding Graphs: A Probabilistic Framework for\n  Understanding Grounded Commands", "abstract": "Many task domains require robots to interpret and act upon natural language\ncommands which are given by people and which refer to the robot's physical\nsurroundings. Such interpretation is known variously as the symbol grounding\nproblem, grounded semantics and grounded language acquisition. This problem is\nchallenging because people employ diverse vocabulary and grammar, and because\nrobots have substantial uncertainty about the nature and contents of their\nsurroundings, making it difficult to associate the constitutive language\nelements (principally noun phrases and spatial relations) of the command text\nto elements of those surroundings. Symbolic models capture linguistic structure\nbut have not scaled successfully to handle the diverse language produced by\nuntrained users. Existing statistical approaches can better handle diversity,\nbut have not to date modeled complex linguistic structure, limiting achievable\naccuracy. Recent hybrid approaches have addressed limitations in scaling and\ncomplexity, but have not effectively associated linguistic and perceptual\nfeatures. Our framework, called Generalized Grounding Graphs (G^3), addresses\nthese issues by defining a probabilistic graphical model dynamically according\nto the linguistic parse structure of a natural language command. This approach\nscales effectively, handles linguistic diversity, and enables the system to\nassociate parts of a command with the specific objects, places, and events in\nthe external world to which they refer. We show that robots can learn word\nmeanings and use those learned meanings to robustly follow natural language\ncommands produced by untrained users. We demonstrate our approach for both\nmobility commands and mobile manipulation commands involving a variety of\nsemi-autonomous robotic platforms, including a wheelchair, a micro-air vehicle,\na forklift, and the Willow Garage PR2.", "published": "2017-11-29 21:20:51", "link": "http://arxiv.org/abs/1712.01097v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "A Benchmarking Environment for Reinforcement Learning Based Task\n  Oriented Dialogue Management", "abstract": "Dialogue assistants are rapidly becoming an indispensable daily aid. To avoid\nthe significant effort needed to hand-craft the required dialogue flow, the\nDialogue Management (DM) module can be cast as a continuous Markov Decision\nProcess (MDP) and trained through Reinforcement Learning (RL). Several RL\nmodels have been investigated over recent years. However, the lack of a common\nbenchmarking framework makes it difficult to perform a fair comparison between\ndifferent models and their capability to generalise to different environments.\nTherefore, this paper proposes a set of challenging simulated environments for\ndialogue model development and evaluation. To provide some baselines, we\ninvestigate a number of representative parametric algorithms, namely deep\nreinforcement learning algorithms - DQN, A2C and Natural Actor-Critic and\ncompare them to a non-parametric model, GP-SARSA. Both the environments and\npolicy models are implemented using the publicly available PyDial toolkit and\nreleased on-line, in order to establish a testbed framework for further\nexperiments and to facilitate experimental reproducibility.", "published": "2017-11-29 18:51:14", "link": "http://arxiv.org/abs/1711.11023v2", "categories": ["stat.ML", "cs.CL", "cs.NE"], "primary_category": "stat.ML"}
{"title": "Embedding Words as Distributions with a Bayesian Skip-gram Model", "abstract": "We introduce a method for embedding words as probability densities in a\nlow-dimensional space. Rather than assuming that a word embedding is fixed\nacross the entire text collection, as in standard word embedding methods, in\nour Bayesian model we generate it from a word-specific prior density for each\noccurrence of a given word. Intuitively, for each word, the prior density\nencodes the distribution of its potential 'meanings'. These prior densities are\nconceptually similar to Gaussian embeddings. Interestingly, unlike the Gaussian\nembeddings, we can also obtain context-specific densities: they encode\nuncertainty about the sense of a word given its context and correspond to\nposterior distributions within our model. The context-dependent densities have\nmany potential applications: for example, we show that they can be directly\nused in the lexical substitution task. We describe an effective estimation\nmethod based on the variational autoencoding framework. We also demonstrate\nthat our embeddings achieve competitive results on standard benchmarks.", "published": "2017-11-29 18:55:48", "link": "http://arxiv.org/abs/1711.11027v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Video Captioning via Hierarchical Reinforcement Learning", "abstract": "Video captioning is the task of automatically generating a textual\ndescription of the actions in a video. Although previous work (e.g.\nsequence-to-sequence model) has shown promising results in abstracting a coarse\ndescription of a short video, it is still very challenging to caption a video\ncontaining multiple fine-grained actions with a detailed description. This\npaper aims to address the challenge by proposing a novel hierarchical\nreinforcement learning framework for video captioning, where a high-level\nManager module learns to design sub-goals and a low-level Worker module\nrecognizes the primitive actions to fulfill the sub-goal. With this\ncompositional framework to reinforce video captioning at different levels, our\napproach significantly outperforms all the baseline methods on a newly\nintroduced large-scale dataset for fine-grained video captioning. Furthermore,\nour non-ensemble model has already achieved the state-of-the-art results on the\nwidely-used MSR-VTT dataset.", "published": "2017-11-29 22:23:59", "link": "http://arxiv.org/abs/1711.11135v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Wisdom of Polarized Crowds", "abstract": "As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one's echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia's\nPolitical, Social Issues, and Science articles. We measure editors' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia's Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article \"talk\npages\" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.", "published": "2017-11-29 21:40:29", "link": "http://arxiv.org/abs/1712.06414v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.DL", "stat.AP"], "primary_category": "cs.SI"}
{"title": "HoME: a Household Multimodal Environment", "abstract": "We introduce HoME: a Household Multimodal Environment for artificial agents\nto learn from vision, audio, semantics, physics, and interaction with objects\nand other agents, all within a realistic context. HoME integrates over 45,000\ndiverse 3D house layouts based on the SUNCG dataset, a scale which may\nfacilitate learning, generalization, and transfer. HoME is an open-source,\nOpenAI Gym-compatible platform extensible to tasks in reinforcement learning,\nlanguage grounding, sound-based navigation, robotics, multi-agent learning, and\nmore. We hope HoME better enables artificial agents to learn as humans do: in\nan interactive, multimodal, and richly contextualized setting.", "published": "2017-11-29 18:45:59", "link": "http://arxiv.org/abs/1711.11017v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "RoboJam: A Musical Mixture Density Network for Collaborative Touchscreen\n  Interaction", "abstract": "RoboJam is a machine-learning system for generating music that assists users\nof a touchscreen music app by performing responses to their short\nimprovisations. This system uses a recurrent artificial neural network to\ngenerate sequences of touchscreen interactions and absolute timings, rather\nthan high-level musical notes. To accomplish this, RoboJam's network uses a\nmixture density layer to predict appropriate touch interaction locations in\nspace and time. In this paper, we describe the design and implementation of\nRoboJam's network and how it has been integrated into a touchscreen music app.\nA preliminary evaluation analyses the system in terms of training, musical\ngeneration and user interaction.", "published": "2017-11-29 09:48:06", "link": "http://arxiv.org/abs/1711.10746v1", "categories": ["cs.HC", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Now Playing: Continuous low-power music recognition", "abstract": "Existing music recognition applications require a connection to a server that\nperforms the actual recognition. In this paper we present a low-power music\nrecognizer that runs entirely on a mobile device and automatically recognizes\nmusic without user interaction. To reduce battery consumption, a small music\ndetector runs continuously on the mobile device's DSP chip and wakes up the\nmain application processor only when it is confident that music is present.\nOnce woken, the recognizer on the application processor is provided with a few\nseconds of audio which is fingerprinted and compared to the stored fingerprints\nin the on-device fingerprint database of tens of thousands of songs. Our\npresented system, Now Playing, has a daily battery usage of less than 1% on\naverage, respects user privacy by running entirely on-device and can passively\nrecognize a wide range of music.", "published": "2017-11-29 16:42:52", "link": "http://arxiv.org/abs/1711.10958v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stream Attention for far-field multi-microphone ASR", "abstract": "A stream attention framework has been applied to the posterior probabilities\nof the deep neural network (DNN) to improve the far-field automatic speech\nrecognition (ASR) performance in the multi-microphone configuration. The stream\nattention scheme has been realized through an attention vector, which is\nderived by predicting the ASR performance from the phoneme posterior\ndistribution of individual microphone stream, focusing the recognizer's\nattention to more reliable microphones. Investigation on the various ASR\nperformance measures has been carried out using the real recorded dataset.\nExperiments results show that the proposed framework has yielded substantial\nimprovements in word error rate (WER).", "published": "2017-11-29 22:45:05", "link": "http://arxiv.org/abs/1711.11141v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
