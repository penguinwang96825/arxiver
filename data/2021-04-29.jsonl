{"title": "Using Fisher's Exact Test to Evaluate Association Measures for N-grams", "abstract": "To determine whether some often-used lexical association measures assign high\nscores to n-grams that chance could have produced as frequently as observed, we\nused an extension of Fisher's exact test to sequences longer than two words to\nanalyse a corpus of four million words. The results, based on the\nprecision-recall curve and a new index called chance-corrected average\nprecision, show that, as expected, simple-ll is extremely effective. They also\nshow, however, that MI3 is more efficient than the other hypothesis tests-based\nmeasures and even reaches a performance level almost equal to simple-ll for\n3-grams. It is additionally observed that some measures are more efficient for\n3-grams than for 2-grams, while others stagnate.", "published": "2021-04-29 08:59:33", "link": "http://arxiv.org/abs/2104.14209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How (Non-)Optimal is the Lexicon?", "abstract": "The mapping of lexical meanings to wordforms is a major feature of natural\nlanguages. While usage pressures might assign short words to frequent meanings\n(Zipf's law of abbreviation), the need for a productive and open-ended\nvocabulary, local constraints on sequences of symbols, and various other\nfactors all shape the lexicons of the world's languages. Despite their\nimportance in shaping lexical structure, the relative contributions of these\nfactors have not been fully quantified. Taking a coding-theoretic view of the\nlexicon and making use of a novel generative statistical model, we define upper\nbounds for the compressibility of the lexicon under various constraints.\nExamining corpora from 7 typologically diverse languages, we use those upper\nbounds to quantify the lexicon's optimality and to explore the relative costs\nof major constraints on natural codes. We find that (compositional) morphology\nand graphotactics can sufficiently account for most of the complexity of\nnatural codes -- as measured by code length.", "published": "2021-04-29 11:55:47", "link": "http://arxiv.org/abs/2104.14279v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MOROCCO: Model Resource Comparison Framework", "abstract": "The new generation of pre-trained NLP models push the SOTA to the new limits,\nbut at the cost of computational resources, to the point that their use in real\nproduction environments is often prohibitively expensive. We tackle this\nproblem by evaluating not only the standard quality metrics on downstream tasks\nbut also the memory footprint and inference time. We present MOROCCO, a\nframework to compare language models compatible with \\texttt{jiant} environment\nwhich supports over 50 NLU tasks, including SuperGLUE benchmark and multiple\nprobing suites. We demonstrate its applicability for two GLUE-like suites in\ndifferent languages.", "published": "2021-04-29 13:01:27", "link": "http://arxiv.org/abs/2104.14314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMR Parsing with Action-Pointer Transformer", "abstract": "Abstract Meaning Representation parsing is a sentence-to-graph prediction\ntask where target nodes are not explicitly aligned to sentence tokens. However,\nsince graph nodes are semantically based on one or more sentence tokens,\nimplicit alignments can be derived. Transition-based parsers operate over the\nsentence from left to right, capturing this inductive bias via alignments at\nthe cost of limited expressiveness. In this work, we propose a transition-based\nsystem that combines hard-attention over sentences with a target-side action\npointer mechanism to decouple source tokens from node representations and\naddress alignments. We model the transitions as well as the pointer mechanism\nthrough straightforward modifications within a single Transformer architecture.\nParser state and graph structure information are efficiently encoded using\nattention heads. We show that our action-pointer approach leads to increased\nexpressiveness and attains large gains (+1.6 points) against the best\ntransition-based AMR parser in very similar conditions. While using no graph\nre-categorization, our single model yields the second best Smatch score on AMR\n2.0 (81.8), which is further improved to 83.4 with silver data and ensemble\ndecoding.", "published": "2021-04-29 22:01:41", "link": "http://arxiv.org/abs/2104.14674v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let's Play Mono-Poly: BERT Can Reveal Words' Polysemy Level and\n  Partitionability into Senses", "abstract": "Pre-trained language models (LMs) encode rich information about linguistic\nstructure but their knowledge about lexical polysemy remains unclear. We\npropose a novel experimental setup for analysing this knowledge in LMs\nspecifically trained for different languages (English, French, Spanish and\nGreek) and in multilingual BERT. We perform our analysis on datasets carefully\ndesigned to reflect different sense distributions, and control for parameters\nthat are highly correlated with polysemy such as frequency and grammatical\ncategory. We demonstrate that BERT-derived representations reflect words'\npolysemy level and their partitionability into senses. Polysemy-related\ninformation is more clearly present in English BERT embeddings, but models in\nother languages also manage to establish relevant distinctions between words at\ndifferent polysemy levels. Our results contribute to a better understanding of\nthe knowledge encoded in contextualised representations and open up new avenues\nfor multilingual lexical semantics research.", "published": "2021-04-29 23:15:13", "link": "http://arxiv.org/abs/2104.14694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recognition and Processing of NATOM", "abstract": "In this paper we show how to process the NOTAM (Notice to Airmen) data of the\nfield in civil aviation. The main research contents are as follows: 1.Data\npreprocessing: For the original data of the NOTAM, there is a mixture of\nChinese and English, and the structure is poor. The original data is cleaned,\nthe Chinese data and the English data are processed separately, word\nsegmentation is completed, and stopping-words are removed. Using Glove word\nvector methods to represent the data for using a custom mapping vocabulary.\n2.Decoupling features and classifiers: In order to improve the ability of the\ntext classification model to recognize minority samples, the overall model\ntraining process is decoupled from the perspective of the algorithm as a whole,\ndivided into two stages of feature learning and classifier learning. The\nweights of the feature learning stage and the classifier learning stage adopt\ndifferent strategies to overcome the influence of the head data and tail data\nof the imbalanced data set on the classification model. Experiments have proved\nthat the use of decoupling features and classifier methods based on the neural\nnetwork classification model can complete text multi-classification tasks in\nthe field of civil aviation, and at the same time can improve the recognition\naccuracy of the minority samples in the data set.", "published": "2021-04-29 10:12:00", "link": "http://arxiv.org/abs/2105.03314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Models for Suicide Prediction from Social Media Posts", "abstract": "We propose a deep learning architecture and test three other machine learning\nmodels to automatically detect individuals that will attempt suicide within (1)\n30 days and (2) six months, using their social media post data provided in the\nCLPsych 2021 shared task. Additionally, we create and extract three sets of\nhandcrafted features for suicide risk detection based on the three-stage theory\nof suicide and prior work on emotions and the use of pronouns among persons\nexhibiting suicidal ideations. Extensive experimentations show that some of the\ntraditional machine learning methods outperform the baseline with an F1 score\nof 0.741 and F2 score of 0.833 on subtask 1 (prediction of a suicide attempt 30\ndays prior). However, the proposed deep learning method outperforms the\nbaseline with F1 score of 0.737 and F2 score of 0.843 on subtask 2 (prediction\nof suicide 6 months prior).", "published": "2021-04-29 03:52:59", "link": "http://arxiv.org/abs/2105.03315v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text-to-Text Multi-view Learning for Passage Re-ranking", "abstract": "Recently, much progress in natural language processing has been driven by\ndeep contextualized representations pretrained on large corpora. Typically, the\nfine-tuning on these pretrained models for a specific downstream task is based\non single-view learning, which is however inadequate as a sentence can be\ninterpreted differently from different perspectives. Therefore, in this work,\nwe propose a text-to-text multi-view learning framework by incorporating an\nadditional view -- the text generation view -- into a typical single-view\npassage ranking model. Empirically, the proposed approach is of help to the\nranking performance compared to its single-view counterpart. Ablation studies\nare also reported in the paper.", "published": "2021-04-29 06:12:34", "link": "http://arxiv.org/abs/2104.14133v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "RECKONition: a NLP-based system for Industrial Accidents at Work\n  Prevention", "abstract": "Extracting patterns and useful information from Natural Language datasets is\na challenging task, especially when dealing with data written in a language\ndifferent from English, like Italian. Machine and Deep Learning, together with\nNatural Language Processing (NLP) techniques have widely spread and improved\nlately, providing a plethora of useful methods to address both Supervised and\nUnsupervised problems on textual information. We propose RECKONition, a\nNLP-based system for Industrial Accidents at Work Prevention. RECKONition,\nwhich is meant to provide Natural Language Understanding, Clustering and\nInference, is the result of a joint partnership with the Italian National\nInstitute for Insurance against Accidents at Work (INAIL). The obtained results\nshowed the ability to process textual data written in Italian describing\nindustrial accidents dynamics and consequences.", "published": "2021-04-29 07:13:07", "link": "http://arxiv.org/abs/2104.14150v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Variable-Length Codes Independent or Closed with respect to Edit\n  Relations", "abstract": "We investigate inference of variable-length codes in other domains of\ncomputer science, such as noisy information transmission or information\nretrieval-storage: in such topics, traditionally mostly constant-length\ncodewords act. The study is relied upon the two concepts of independent and\nclosed sets. We focus to those word relations whose images are computed by\napplying some peculiar combinations of deletion, insertion, or substitution. In\nparticular, characterizations of variable-length codes that are maximal in the\nfamilies of $\\tau$-independent or $\\tau$-closed codes are provided.", "published": "2021-04-29 08:03:33", "link": "http://arxiv.org/abs/2104.14185v1", "categories": ["cs.CL", "cs.DM"], "primary_category": "cs.CL"}
{"title": "Entailment as Few-Shot Learner", "abstract": "Large pre-trained language models (LMs) have demonstrated remarkable ability\nas few-shot learners. However, their success hinges largely on scaling model\nparameters to a degree that makes it challenging to train and serve. In this\npaper, we propose a new approach, named as EFL, that can turn small LMs into\nbetter few-shot learners. The key idea of this approach is to reformulate\npotential NLP task into an entailment one, and then fine-tune the model with as\nlittle as 8 examples. We further demonstrate our proposed method can be: (i)\nnaturally combined with an unsupervised contrastive learning-based data\naugmentation method; (ii) easily extended to multilingual few-shot learning. A\nsystematic evaluation on 18 standard NLP tasks demonstrates that this approach\nimproves the various existing SOTA few-shot learning methods by 12\\%, and\nyields competitive few-shot performance with 500 times larger models, such as\nGPT-3.", "published": "2021-04-29 22:52:26", "link": "http://arxiv.org/abs/2104.14690v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Zero Resource Speech Challenge 2021: Spoken language modelling", "abstract": "We present the Zero Resource Speech Challenge 2021, which asks participants\nto learn a language model directly from audio, without any text or labels. The\nchallenge is based on the Libri-light dataset, which provides up to 60k hours\nof audio from English audio books without any associated text. We provide a\npipeline baseline system consisting on an encoder based on contrastive\npredictive coding (CPC), a quantizer ($k$-means) and a standard language model\n(BERT or LSTM). The metrics evaluate the learned representations at the\nacoustic (ABX discrimination), lexical (spot-the-word), syntactic\n(acceptability judgment) and semantic levels (similarity judgment). We present\nan overview of the eight submitted systems from four groups and discuss the\nmain results.", "published": "2021-04-29 23:53:37", "link": "http://arxiv.org/abs/2104.14700v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Transformers to Provide Teachers with Personalized Feedback on\n  their Classroom Discourse: The TalkMoves Application", "abstract": "TalkMoves is an innovative application designed to support K-12 mathematics\nteachers to reflect on, and continuously improve their instructional practices.\nThis application combines state-of-the-art natural language processing\ncapabilities with automated speech recognition to automatically analyze\nclassroom recordings and provide teachers with personalized feedback on their\nuse of specific types of discourse aimed at broadening and deepening classroom\nconversations about mathematics. These specific discourse strategies are\nreferred to as \"talk moves\" within the mathematics education community and\nprior research has documented the ways in which systematic use of these\ndiscourse strategies can positively impact student engagement and learning. In\nthis article, we describe the TalkMoves application's cloud-based\ninfrastructure for managing and processing classroom recordings, and its\ninterface for providing teachers with feedback on their use of talk moves\nduring individual teaching episodes. We present the series of model\narchitectures we developed, and the studies we conducted, to develop our\nbest-performing, transformer-based model (F1 = 79.3%). We also discuss several\ntechnical challenges that need to be addressed when working with real-world\nspeech and language data from noisy K-12 classrooms.", "published": "2021-04-29 20:45:02", "link": "http://arxiv.org/abs/2105.07949v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Trakhtenbrot's Theorem in Coq: Finite Model Theory through the\n  Constructive Lens", "abstract": "We study finite first-order satisfiability (FSAT) in the constructive setting\nof dependent type theory. Employing synthetic accounts of enumerability and\ndecidability, we give a full classification of FSAT depending on the\nfirst-order signature of non-logical symbols. On the one hand, our development\nfocuses on Trakhtenbrot's theorem, stating that FSAT is undecidable as soon as\nthe signature contains an at least binary relation symbol. Our proof proceeds\nby a many-one reduction chain starting from the Post correspondence problem. On\nthe other hand, we establish the decidability of FSAT for monadic first-order\nlogic, i.e. where the signature only contains at most unary function and\nrelation symbols, as well as the enumerability of FSAT for arbitrary enumerable\nsignatures. To showcase an application of Trakhtenbrot's theorem, we continue\nour reduction chain with a many-one reduction from FSAT to separation logic.\nAll our results are mechanised in the framework of a growing Coq library of\nsynthetic undecidability proofs.", "published": "2021-04-29 16:05:31", "link": "http://arxiv.org/abs/2104.14445v5", "categories": ["cs.LO", "cs.CL", "math.LO"], "primary_category": "cs.LO"}
{"title": "Impact of Encoding and Segmentation Strategies on End-to-End\n  Simultaneous Speech Translation", "abstract": "Boosted by the simultaneous translation shared task at IWSLT 2020, promising\nend-to-end online speech translation approaches were recently proposed. They\nconsist in incrementally encoding a speech input (in a source language) and\ndecoding the corresponding text (in a target language) with the best possible\ntrade-off between latency and translation quality. This paper investigates two\nkey aspects of end-to-end simultaneous speech translation: (a) how to encode\nefficiently the continuous speech flow, and (b) how to segment the speech flow\nin order to alternate optimally between reading (R: encoding input) and writing\n(W: decoding output) operations. We extend our previously proposed end-to-end\nonline decoding strategy and show that while replacing BLSTM by ULSTM encoding\ndegrades performance in offline mode, it actually improves both efficiency and\nperformance in online mode. We also measure the impact of different methods to\nsegment the speech signal (using fixed interval boundaries, oracle word\nboundaries or randomly set boundaries) and show that our best end-to-end online\ndecoding strategy is surprisingly the one that alternates R/W operations on\nfixed size blocks on our English-German speech translation setup.", "published": "2021-04-29 16:33:08", "link": "http://arxiv.org/abs/2104.14470v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Experts, Errors, and Context: A Large-Scale Study of Human Evaluation\n  for Machine Translation", "abstract": "Human evaluation of modern high-quality machine translation systems is a\ndifficult problem, and there is increasing evidence that inadequate evaluation\nprocedures can lead to erroneous conclusions. While there has been considerable\nresearch on human evaluation, the field still lacks a commonly-accepted\nstandard procedure. As a step toward this goal, we propose an evaluation\nmethodology grounded in explicit error analysis, based on the Multidimensional\nQuality Metrics (MQM) framework. We carry out the largest MQM research study to\ndate, scoring the outputs of top systems from the WMT 2020 shared task in two\nlanguage pairs using annotations provided by professional translators with\naccess to full document context. We analyze the resulting data extensively,\nfinding among other results a substantially different ranking of evaluated\nsystems from the one established by the WMT crowd workers, exhibiting a clear\npreference for human over machine output. Surprisingly, we also find that\nautomatic metrics based on pre-trained embeddings can outperform human crowd\nworkers. We make our corpus publicly available for further research.", "published": "2021-04-29 16:42:09", "link": "http://arxiv.org/abs/2104.14478v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A First Look: Towards Explainable TextVQA Models via Visual and Textual\n  Explanations", "abstract": "Explainable deep learning models are advantageous in many situations. Prior\nwork mostly provide unimodal explanations through post-hoc approaches not part\nof the original system design. Explanation mechanisms also ignore useful\ntextual information present in images. In this paper, we propose MTXNet, an\nend-to-end trainable multimodal architecture to generate multimodal\nexplanations, which focuses on the text in the image. We curate a novel dataset\nTextVQA-X, containing ground truth visual and multi-reference textual\nexplanations that can be leveraged during both training and evaluation. We then\nquantitatively show that training with multimodal explanations complements\nmodel performance and surpasses unimodal baselines by up to 7% in CIDEr scores\nand 2% in IoU. More importantly, we demonstrate that the multimodal\nexplanations are consistent with human interpretations, help justify the\nmodels' decision, and provide useful insights to help diagnose an incorrect\nprediction. Finally, we describe a real-world e-commerce application for using\nthe generated multimodal explanations.", "published": "2021-04-29 00:36:17", "link": "http://arxiv.org/abs/2105.02626v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Improving Fairness in Speaker Recognition", "abstract": "The human voice conveys unique characteristics of an individual, making voice\nbiometrics a key technology for verifying identities in various industries.\nDespite the impressive progress of speaker recognition systems in terms of\naccuracy, a number of ethical and legal concerns has been raised, specifically\nrelating to the fairness of such systems. In this paper, we aim to explore the\ndisparity in performance achieved by state-of-the-art deep speaker recognition\nsystems, when different groups of individuals characterized by a common\nsensitive attribute (e.g., gender) are considered. In order to mitigate the\nunfairness we uncovered by means of an exploratory study, we investigate\nwhether balancing the representation of the different groups of individuals in\nthe training set can lead to a more equal treatment of these demographic\ngroups. Experiments on two state-of-the-art neural architectures and a\nlarge-scale public dataset show that models trained with\ndemographically-balanced training sets exhibit a fairer behavior on different\ngroups, while still being accurate. Our study is expected to provide a solid\nbasis for instilling beyond-accuracy objectives (e.g., fairness) in speaker\nrecognition.", "published": "2021-04-29 01:08:53", "link": "http://arxiv.org/abs/2104.14067v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hardware-Friendly Synaptic Orders and Timescales in Liquid State\n  Machines for Speech Classification", "abstract": "Liquid State Machines are brain inspired spiking neural networks (SNNs) with\nrandom reservoir connectivity and bio-mimetic neuronal and synaptic models.\nReservoir computing networks are proposed as an alternative to deep neural\nnetworks to solve temporal classification problems. Previous studies suggest\n2nd order (double exponential) synaptic waveform to be crucial for achieving\nhigh accuracy for TI-46 spoken digits recognition. The proposal of long-time\nrange (ms) bio-mimetic synaptic waveforms is a challenge to compact and power\nefficient neuromorphic hardware. In this work, we analyze the role of synaptic\norders namely: {\\delta} (high output for single time step), 0th (rectangular\nwith a finite pulse width), 1st (exponential fall) and 2nd order (exponential\nrise and fall) and synaptic timescales on the reservoir output response and on\nthe TI-46 spoken digits classification accuracy under a more comprehensive\nparameter sweep. We find the optimal operating point to be correlated to an\noptimal range of spiking activity in the reservoir. Further, the proposed 0th\norder synapses perform at par with the biologically plausible 2nd order\nsynapses. This is substantial relaxation for circuit designers as synapses are\nthe most abundant components in an in-memory implementation for SNNs. The\ncircuit benefits for both analog and mixed-signal realizations of 0th order\nsynapse are highlighted demonstrating 2-3 orders of savings in area and power\nconsumptions by eliminating Op-Amps and Digital to Analog Converter circuits.\nThis has major implications on a complete neural network implementation with\nfocus on peripheral limitations and algorithmic simplifications to overcome\nthem.", "published": "2021-04-29 11:20:39", "link": "http://arxiv.org/abs/2104.14264v1", "categories": ["eess.AS", "cs.NE", "cs.SD", "q-bio.NC"], "primary_category": "eess.AS"}
{"title": "End-to-End Speech Recognition from Federated Acoustic Models", "abstract": "Training Automatic Speech Recognition (ASR) models under federated learning\n(FL) settings has attracted a lot of attention recently. However, the FL\nscenarios often presented in the literature are artificial and fail to capture\nthe complexity of real FL systems. In this paper, we construct a challenging\nand realistic ASR federated experimental setup consisting of clients with\nheterogeneous data distributions using the French and Italian sets of the\nCommonVoice dataset, a large heterogeneous dataset containing thousands of\ndifferent speakers, acoustic environments and noises. We present the first\nempirical study on attention-based sequence-to-sequence End-to-End (E2E) ASR\nmodel with three aggregation weighting strategies -- standard FedAvg,\nloss-based aggregation and a novel word error rate (WER)-based aggregation,\ncompared in two realistic FL scenarios: cross-silo with 10 clients and\ncross-device with 2K and 4K clients. Our analysis on E2E ASR from heterogeneous\nand realistic federated acoustic models provides the foundations for future\nresearch and development of realistic FL-based ASR applications.", "published": "2021-04-29 12:31:57", "link": "http://arxiv.org/abs/2104.14297v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Star DGT: a Robust Gabor Transform for Speech Denoising", "abstract": "In this paper, we address the speech denoising problem, where Gaussian, pink\nand blue additive noises are to be removed from a given speech signal. Our\napproach is based on a redundant, analysis-sparse representation of the\noriginal speech signal. We pick an eigenvector of the Zauner unitary matrix and\n-- under certain assumptions on the ambient dimension -- we use it as window\nvector to generate a spark deficient Gabor frame. The analysis operator\nassociated with such a frame, is a (highly) redundant Gabor transform, which we\nuse as a sparsifying transform in denoising procedure. We conduct computational\nexperiments on real-world speech data, using as baseline three Gabor transforms\ngenerated by state-of-the-art window vectors in time-frequency analysis and\ncompare their performance to the proposed Gabor transform. The results show\nthat our proposed redundant Gabor transform outperforms all others,\nconsistently for all signals.", "published": "2021-04-29 16:31:31", "link": "http://arxiv.org/abs/2104.14468v3", "categories": ["cs.SD", "cs.IT", "eess.AS", "math.IT"], "primary_category": "cs.SD"}
{"title": "Simulating the DFT Algorithm for Audio Processing", "abstract": "Since the evolution of digital computers, the storage of data has always been\nin terms of discrete bits that can store values of either 1 or 0. Hence, all\ncomputer programs (such as MATLAB), convert any input continuous signal into a\ndiscrete dataset. Applying this to oscillating signals, such as audio, opens a\ndomain for processing as well as editing. The Fourier transform, which is an\nintegral over infinite limits, for the use of signal processing is discrete.\nThe essential feature of the Fourier transform is to decompose any signal into\na combination of multiple sinusoidal waves that are easy to deal with. The\ndiscrete Fourier transform (DFT) can be represented as a matrix, with each data\npoint acting as an orthogonal point, allowing one to perform complicated\ntransformations on individual frequencies. Due to this formulation, all the\nconcepts of linear algebra and linear transforms prove to be extremely useful\nhere. In this paper, we first explain the theoretical basis of audio processing\nusing linear algebra, and then focus on a simulation coded in MATLAB, to\nprocess and edit various audio samples. The code is open ended and easily\nexpandable by just defining newer matrices which can transform over the\noriginal audio signal. Finally, this paper attempts to highlight and briefly\nexplain the results that emerge from the simulation", "published": "2021-04-29 11:57:44", "link": "http://arxiv.org/abs/2105.02820v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
