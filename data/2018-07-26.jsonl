{"title": "Variational Memory Encoder-Decoder", "abstract": "Introducing variability while maintaining coherence is a core task in\nlearning to generate utterances in conversation. Standard neural\nencoder-decoder models and their extensions using conditional variational\nautoencoder often result in either trivial or digressive responses. To overcome\nthis, we explore a novel approach that injects variability into neural\nencoder-decoder via the use of external memory as a mixture model, namely\nVariational Memory Encoder-Decoder (VMED). By associating each memory read with\na mode in the latent mixture distribution at each timestep, our model can\ncapture the variability observed in sequential data such as natural\nconversations. We empirically compare the proposed model against other recent\napproaches on various conversational datasets. The results show that VMED\nconsistently achieves significant improvement over others in both metric-based\nand qualitative evaluations.", "published": "2018-07-26 04:41:30", "link": "http://arxiv.org/abs/1807.09950v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concurrent Learning of Semantic Relations", "abstract": "Discovering whether words are semantically related and identifying the\nspecific semantic relation that holds between them is of crucial importance for\nNLP as it is essential for tasks like query expansion in IR. Within this\ncontext, different methodologies have been proposed that either exclusively\nfocus on a single lexical relation (e.g. hypernymy vs. random) or learn\nspecific classifiers capable of identifying multiple semantic relations (e.g.\nhypernymy vs. synonymy vs. random). In this paper, we propose another way to\nlook at the problem that relies on the multi-task learning paradigm. In\nparticular, we want to study whether the learning process of a given semantic\nrelation (e.g. hypernymy) can be improved by the concurrent learning of another\nsemantic relation (e.g. co-hyponymy). Within this context, we particularly\nexamine the benefits of semi-supervised learning where the training of a\nprediction function is performed over few labeled data jointly with many\nunlabeled ones. Preliminary results based on simple learning strategies and\nstate-of-the-art distributional feature representations show that concurrent\nlearning can lead to improvements in a vast majority of tested situations.", "published": "2018-07-26 11:44:19", "link": "http://arxiv.org/abs/1807.10076v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Source Automatic Speech Recognition for German", "abstract": "High quality Automatic Speech Recognition (ASR) is a prerequisite for\nspeech-based applications and research. While state-of-the-art ASR software is\nfreely available, the language dependent acoustic models are lacking for\nlanguages other than English, due to the limited amount of freely available\ntraining data. We train acoustic models for German with Kaldi on two datasets,\nwhich are both distributed under a Creative Commons license. The resulting\nmodel is freely redistributable, lowering the cost of entry for German ASR. The\nmodels are trained on a total of 412 hours of German read speech data and we\nachieve a relative word error reduction of 26% by adding data from the Spoken\nWikipedia Corpus to the previously best freely available German acoustic model\nrecipe and dataset. Our best model achieves a word error rate of 14.38 on the\nTuda-De test set. Due to the large amount of speakers and the diversity of\ntopics included in the training data, our model is robust against speaker\nvariation and topic shift.", "published": "2018-07-26 18:31:08", "link": "http://arxiv.org/abs/1807.10311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Term Set Expansion based on Multi-Context Term Embeddings: an End-to-end\n  Workflow", "abstract": "We present SetExpander, a corpus-based system for expanding a seed set of\nterms into a more complete set of terms that belong to the same semantic class.\nSetExpander implements an iterative end-to end workflow for term set expansion.\nIt enables users to easily select a seed set of terms, expand it, view the\nexpanded set, validate it, re-expand the validated set and store it, thus\nsimplifying the extraction of domain-specific fine-grained semantic classes.\nSetExpander has been used for solving real-life use cases including integration\nin an automated recruitment system and an issues and defects resolution system.\nA video demo of SetExpander is available at\nhttps://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images\nwere blurred for privacy reasons).", "published": "2018-07-26 13:11:51", "link": "http://arxiv.org/abs/1807.10104v1", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Resource-Size matters: Improving Neural Named Entity Recognition with\n  Optimized Large Corpora", "abstract": "This study improves the performance of neural named entity recognition by a\nmargin of up to 11% in F-score on the example of a low-resource language like\nGerman, thereby outperforming existing baselines and establishing a new\nstate-of-the-art on each single open-source dataset. Rather than designing\ndeeper and wider hybrid neural architectures, we gather all available resources\nand perform a detailed optimization and grammar-dependent morphological\nprocessing consisting of lemmatization and part-of-speech tagging prior to\nexposing the raw data to any training process. We test our approach in a\nthreefold monolingual experimental setup of a) single, b) joint, and c)\noptimized training and shed light on the dependency of downstream-tasks on the\nsize of corpora used to compute word embeddings.", "published": "2018-07-26 17:05:20", "link": "http://arxiv.org/abs/1807.10675v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Modulation-Domain Kalman Filtering for Monaural Blind Speech Denoising\n  and Dereverberation", "abstract": "We describe a monaural speech enhancement algorithm based on\nmodulation-domain Kalman filtering to blindly track the time-frequency\nlog-magnitude spectra of speech and reverberation. We propose an adaptive\nalgorithm that performs blind joint denoising and dereverberation, while\naccounting for the inter-frame speech dynamics, by estimating the posterior\ndistribution of the speech log-magnitude spectrum given the log-magnitude\nspectrum of the noisy reverberant speech. The Kalman filter update step models\nthe non-linear relations between the speech, noise and reverberation\nlog-spectra. The Kalman filtering algorithm uses a signal model that takes into\naccount the reverberation parameters of the reverberation time, $T_{60}$, and\nthe direct-to-reverberant energy ratio (DRR) and also estimates and tracks the\n$T_{60}$ and the DRR in every frequency bin in order to improve the estimation\nof the speech log-magnitude spectrum. The Kalman filtering algorithm is tested\nand graphs that depict the estimated reverberation features over time are\nexamined. The proposed algorithm is evaluated in terms of speech quality,\nspeech intelligibility and dereverberation performance for a range of\nreverberation parameters and SNRs, in different noise types, and is also\ncompared to competing denoising and dereverberation techniques. Experimental\nresults using noisy reverberant speech demonstrate the effectiveness of the\nenhancement algorithm.", "published": "2018-07-26 16:40:12", "link": "http://arxiv.org/abs/1807.10236v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "General-purpose Tagging of Freesound Audio with AudioSet Labels: Task\n  Description, Dataset, and Baseline", "abstract": "This paper describes Task 2 of the DCASE 2018 Challenge, titled\n\"General-purpose audio tagging of Freesound content with AudioSet labels\". This\ntask was hosted on the Kaggle platform as \"Freesound General-Purpose Audio\nTagging Challenge\". The goal of the task is to build an audio tagging system\nthat can recognize the category of an audio clip from a subset of 41 diverse\ncategories drawn from the AudioSet Ontology. We present the task, the dataset\nprepared for the competition, and a baseline system.", "published": "2018-07-26 00:30:54", "link": "http://arxiv.org/abs/1807.09902v3", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
