{"title": "Label-Wise Document Pre-Training for Multi-Label Text Classification", "abstract": "A major challenge of multi-label text classification (MLTC) is to\nstimulatingly exploit possible label differences and label correlations. In\nthis paper, we tackle this challenge by developing Label-Wise Pre-Training\n(LW-PT) method to get a document representation with label-aware information.\nThe basic idea is that, a multi-label document can be represented as a\ncombination of multiple label-wise representations, and that, correlated labels\nalways cooccur in the same or similar documents. LW-PT implements this idea by\nconstructing label-wise document classification tasks and trains label-wise\ndocument encoders. Finally, the pre-trained label-wise encoder is fine-tuned\nwith the downstream MLTC task. Extensive experimental results validate that the\nproposed method has significant advantages over the previous state-of-the-art\nmodels and is able to discover reasonable label relationship. The code is\nreleased to facilitate other researchers.", "published": "2020-08-15 10:34:27", "link": "http://arxiv.org/abs/2008.06695v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Supervised Syntactic Parsing Beneficial for Language Understanding?\n  An Empirical Investigation", "abstract": "Traditional NLP has long held (supervised) syntactic parsing necessary for\nsuccessful higher-level semantic language understanding (LU). The recent advent\nof end-to-end neural models, self-supervised via language modeling (LM), and\ntheir success on a wide range of LU tasks, however, questions this belief. In\nthis work, we empirically investigate the usefulness of supervised parsing for\nsemantic LU in the context of LM-pretrained transformer networks. Relying on\nthe established fine-tuning paradigm, we first couple a pretrained transformer\nwith a biaffine parsing head, aiming to infuse explicit syntactic knowledge\nfrom Universal Dependencies treebanks into the transformer. We then fine-tune\nthe model for LU tasks and measure the effect of the intermediate parsing\ntraining (IPT) on downstream LU task performance. Results from both monolingual\nEnglish and zero-shot language transfer experiments (with intermediate\ntarget-language parsing) show that explicit formalized syntax, injected into\ntransformers through IPT, has very limited and inconsistent effect on\ndownstream LU performance. Our results, coupled with our analysis of\ntransformers' representation spaces before and after intermediate parsing, make\na significant step towards providing answers to an essential question: how\n(un)availing is supervised parsing for high-level semantic natural language\nunderstanding in the era of large neural models?", "published": "2020-08-15 21:03:36", "link": "http://arxiv.org/abs/2008.06788v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jointly Fine-Tuning \"BERT-like\" Self Supervised Models to Improve\n  Multimodal Speech Emotion Recognition", "abstract": "Multimodal emotion recognition from speech is an important area in affective\ncomputing. Fusing multiple data modalities and learning representations with\nlimited amounts of labeled data is a challenging task. In this paper, we\nexplore the use of modality-specific \"BERT-like\" pretrained Self Supervised\nLearning (SSL) architectures to represent both speech and text modalities for\nthe task of multimodal speech emotion recognition. By conducting experiments on\nthree publicly available datasets (IEMOCAP, CMU-MOSEI, and CMU-MOSI), we show\nthat jointly fine-tuning \"BERT-like\" SSL architectures achieve state-of-the-art\n(SOTA) results. We also evaluate two methods of fusing speech and text\nmodalities and show that a simple fusion mechanism can outperform more complex\nones when using SSL models that have similar architectural properties to BERT.", "published": "2020-08-15 08:54:48", "link": "http://arxiv.org/abs/2008.06682v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Search Query Intent Understanding", "abstract": "Understanding a user's query intent behind a search is critical for modern\nsearch engine success. Accurate query intent prediction allows the search\nengine to better serve the user's need by rendering results from more relevant\ncategories. This paper aims to provide a comprehensive learning framework for\nmodeling query intent under different stages of a search. We focus on the\ndesign for 1) predicting users' intents as they type in queries on-the-fly in\ntypeahead search using character-level models; and 2) accurate word-level\nintent prediction models for complete queries. Various deep learning components\nfor query text understanding are experimented. Offline evaluation and online\nA/B test experiments show that the proposed methods are effective in\nunderstanding query intent and efficient to scale for online search systems.", "published": "2020-08-15 18:19:56", "link": "http://arxiv.org/abs/2008.06759v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "EigenEmo: Spectral Utterance Representation Using Dynamic Mode\n  Decomposition for Speech Emotion Classification", "abstract": "Human emotional speech is, by its very nature, a variant signal. This results\nin dynamics intrinsic to automatic emotion classification based on speech. In\nthis work, we explore a spectral decomposition method stemming from\nfluid-dynamics, known as Dynamic Mode Decomposition (DMD), to computationally\nrepresent and analyze the global utterance-level dynamics of emotional speech.\nSpecifically, segment-level emotion-specific representations are first learned\nthrough an Emotion Distillation process. This forms a multi-dimensional signal\nof emotion flow for each utterance, called Emotion Profiles (EPs). The DMD\nalgorithm is then applied to the resultant EPs to capture the eigenfrequencies,\nand hence the fundamental transition dynamics of the emotion flow. Evaluation\nexperiments using the proposed approach, which we call EigenEmo, show promising\nresults. Moreover, due to the positive combination of their complementary\nproperties, concatenating the utterance representations generated by EigenEmo\nwith simple EPs averaging yields noticeable gains.", "published": "2020-08-15 07:00:11", "link": "http://arxiv.org/abs/2008.06665v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Advancing Multiple Instance Learning with Attention Modeling for\n  Categorical Speech Emotion Recognition", "abstract": "Categorical speech emotion recognition is typically performed as a\nsequence-to-label problem, i.e., to determine the discrete emotion label of the\ninput utterance as a whole. One of the main challenges in practice is that most\nof the existing emotion corpora do not give ground truth labels for each\nsegment; instead, we only have labels for whole utterances. To extract\nsegment-level emotional information from such weakly labeled emotion corpora,\nwe propose using multiple instance learning (MIL) to learn segment embeddings\nin a weakly supervised manner. Also, for a sufficiently long utterance, not all\nof the segments contain relevant emotional information. In this regard, three\nattention-based neural network models are then applied to the learned segment\nembeddings to attend the most salient part of a speech utterance. Experiments\non the CASIA corpus and the IEMOCAP database show better or highly competitive\nresults than other state-of-the-art approaches.", "published": "2020-08-15 07:23:43", "link": "http://arxiv.org/abs/2008.06667v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Experimental investigations of psychoacoustic characteristics of\n  household vacuum cleaners", "abstract": "Vacuum cleaners are one of the most widely used household appliances\nassociated with unpleasant noises. Previous studies have indicated the severity\nof vacuum cleaner noise and its impact on the users nearby. The quantified\nmeasurements of the generated noise standalone are not sufficient for the\nselection or designing of vacuum cleaners. The human perception must also be\nincluded for a better assessment of the quality of sound. A hybrid approach\nknown as psychoacoustics, which comprises subjective and objective evaluations\nof sounds, is widely used in recent times. This paper focuses on the\nexperimental assessment of psychoacoustical matrices for household vacuum\ncleaners. Three vacuum cleaners with different specifications have been\nselected as test candidates, and their sound qualities have been analyzed.\nBesides, the annoyance index has been assessed for these vacuum cleaners.", "published": "2020-08-15 11:17:41", "link": "http://arxiv.org/abs/2008.06702v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive\n  Naturalistic Apollo Data", "abstract": "The Fearless Steps Initiative by UTDallas-CRSS led to the digitization,\nrecovery, and diarization of 19,000 hours of original analog audio data, as\nwell as the development of algorithms to extract meaningful information from\nthis multi-channel naturalistic data resource. The 2020 FEARLESS STEPS (FS-2)\nChallenge is the second annual challenge held for the Speech and Language\nTechnology community to motivate supervised learning algorithm development for\nmulti-party and multi-stream naturalistic audio. In this paper, we present an\noverview of the challenge sub-tasks, data, performance metrics, and lessons\nlearned from Phase-2 of the Fearless Steps Challenge (FS-2). We present\nadvancements made in FS-2 through extensive community outreach and feedback. We\ndescribe innovations in the challenge corpus development, and present revised\nbaseline results. We finally discuss the challenge outcome and general trends\nin system development across both phases (Phase FS-1 Unsupervised, and Phase\nFS-2 Supervised) of the challenge, and its continuation into multi-channel\nchallenge tasks for the upcoming Fearless Steps Challenge Phase-3.", "published": "2020-08-15 18:52:29", "link": "http://arxiv.org/abs/2008.06764v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
