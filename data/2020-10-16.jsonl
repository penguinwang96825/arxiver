{"title": "Inferring symmetry in natural language", "abstract": "We present a methodological framework for inferring symmetry of verb\npredicates in natural language. Empirical work on predicate symmetry has taken\ntwo main approaches. The feature-based approach focuses on linguistic features\npertaining to symmetry. The context-based approach denies the existence of\nabsolute symmetry but instead argues that such inference is context dependent.\nWe develop methods that formalize these approaches and evaluate them against a\nnovel symmetry inference sentence (SIS) dataset comprised of 400 naturalistic\nusages of literature-informed verbs spanning the spectrum of\nsymmetry-asymmetry. Our results show that a hybrid transfer learning model that\nintegrates linguistic features with contextualized language models most\nfaithfully predicts the empirical data. Our work integrates existing approaches\nto symmetry in natural language and suggests how symmetry inference can improve\nsystematicity in state-of-the-art language models.", "published": "2020-10-16 01:25:01", "link": "http://arxiv.org/abs/2010.08090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexicon-constrained Copying Network for Chinese Abstractive\n  Summarization", "abstract": "Copy mechanism allows sequence-to-sequence models to choose words from the\ninput and put them directly into the output, which is finding increasing use in\nabstractive summarization. However, since there is no explicit delimiter in\nChinese sentences, most existing models for Chinese abstractive summarization\ncan only perform character copy, resulting in inefficient. To solve this\nproblem, we propose a lexicon-constrained copying network that models\nmulti-granularity in both encoder and decoder. On the source side, words and\ncharacters are aggregated into the same input memory using a Transformerbased\nencoder. On the target side, the decoder can copy either a character or a\nmulti-character word at each time step, and the decoding process is guided by a\nword-enhanced search algorithm that facilitates the parallel computation and\nencourages the model to copy more words. Moreover, we adopt a word selector to\nintegrate keyword information. Experiments results on a Chinese social media\ndataset show that our model can work standalone or with the word selector. Both\nforms can outperform previous character-based models and achieve competitive\nperformances.", "published": "2020-10-16 06:59:34", "link": "http://arxiv.org/abs/2010.08197v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coarse-to-Fine Pre-training for Named Entity Recognition", "abstract": "More recently, Named Entity Recognition hasachieved great advances aided by\npre-trainingapproaches such as BERT. However, currentpre-training techniques\nfocus on building lan-guage modeling objectives to learn a gen-eral\nrepresentation, ignoring the named entity-related knowledge. To this end, we\nproposea NER-specific pre-training framework to in-ject coarse-to-fine\nautomatically mined entityknowledge into pre-trained models. Specifi-cally, we\nfirst warm-up the model via an en-tity span identification task by training it\nwithWikipedia anchors, which can be deemed asgeneral-typed entities. Then we\nleverage thegazetteer-based distant supervision strategy totrain the model\nextract coarse-grained typedentities. Finally, we devise a\nself-supervisedauxiliary task to mine the fine-grained namedentity knowledge\nvia clustering.Empiricalstudies on three public NER datasets demon-strate that\nour framework achieves significantimprovements against several pre-trained\nbase-lines, establishing the new state-of-the-art per-formance on three\nbenchmarks. Besides, weshow that our framework gains promising re-sults without\nusing human-labeled trainingdata, demonstrating its effectiveness in label-few\nand low-resource scenarios", "published": "2020-10-16 07:39:20", "link": "http://arxiv.org/abs/2010.08210v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets", "abstract": "In this paper, we provide an overview of the WNUT-2020 shared task on the\nidentification of informative COVID-19 English Tweets. We describe how we\nconstruct a corpus of 10K Tweets and organize the development and evaluation\nphases for this task. In addition, we also present a brief summary of results\nobtained from the final system evaluation submissions of 55 teams, finding that\n(i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the\nmajority of the submissions achieve substantially higher results than the\nbaseline fastText (Joulin et al., 2017), and (iii) fine-tuning pre-trained\nlanguage models on relevant language data followed by supervised training\nperforms well in this task.", "published": "2020-10-16 08:28:05", "link": "http://arxiv.org/abs/2010.08232v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for\n  Pairwise Sentence Scoring Tasks", "abstract": "There are two approaches for pairwise sentence scoring: Cross-encoders, which\nperform full-attention over the input pair, and Bi-encoders, which map each\ninput independently to a dense vector space. While cross-encoders often achieve\nhigher performance, they are too slow for many practical use cases.\nBi-encoders, on the other hand, require substantial training data and\nfine-tuning over the target task to achieve competitive performance. We present\na simple yet efficient data augmentation strategy called Augmented SBERT, where\nwe use the cross-encoder to label a larger set of input pairs to augment the\ntraining data for the bi-encoder. We show that, in this process, selecting the\nsentence pairs is non-trivial and crucial for the success of the method. We\nevaluate our approach on multiple tasks (in-domain) as well as on a domain\nadaptation task. Augmented SBERT achieves an improvement of up to 6 points for\nin-domain and of up to 37 points for domain adaptation tasks compared to the\noriginal bi-encoder performance.", "published": "2020-10-16 08:43:27", "link": "http://arxiv.org/abs/2010.08240v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Extractive Summarization by Pre-training Hierarchical\n  Transformers", "abstract": "Unsupervised extractive document summarization aims to select important\nsentences from a document without using labeled summaries during training.\nExisting methods are mostly graph-based with sentences as nodes and edge\nweights measured by sentence similarities. In this work, we find that\ntransformer attentions can be used to rank sentences for unsupervised\nextractive summarization. Specifically, we first pre-train a hierarchical\ntransformer model using unlabeled documents only. Then we propose a method to\nrank sentences using sentence-level self-attentions and pre-training\nobjectives. Experiments on CNN/DailyMail and New York Times datasets show our\nmodel achieves state-of-the-art performance on unsupervised summarization. We\nalso find in experiments that our model is less dependent on sentence\npositions. When using a linear combination of our model and a recent\nunsupervised model explicitly modeling sentence positions, we obtain even\nbetter results.", "published": "2020-10-16 08:44:09", "link": "http://arxiv.org/abs/2010.08242v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SIGTYP 2020 Shared Task: Prediction of Typological Features", "abstract": "Typological knowledge bases (KBs) such as WALS (Dryer and Haspelmath, 2013)\ncontain information about linguistic properties of the world's languages. They\nhave been shown to be useful for downstream applications, including\ncross-lingual transfer learning and linguistic probing. A major drawback\nhampering broader adoption of typological KBs is that they are sparsely\npopulated, in the sense that most languages only have annotations for some\nfeatures, and skewed, in that few features have wide coverage. As typological\nfeatures often correlate with one another, it is possible to predict them and\nthus automatically populate typological KBs, which is also the focus of this\nshared task. Overall, the task attracted 8 submissions from 5 teams, out of\nwhich the most successful methods make use of such feature correlations.\nHowever, our error analysis reveals that even the strongest submitted systems\nstruggle with predicting feature values for languages where few features are\nknown.", "published": "2020-10-16 08:47:24", "link": "http://arxiv.org/abs/2010.08246v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "It's not Greek to mBERT: Inducing Word-Level Translations from\n  Multilingual BERT", "abstract": "Recent works have demonstrated that multilingual BERT (mBERT) learns rich\ncross-lingual representations, that allow for transfer across languages. We\nstudy the word-level translation information embedded in mBERT and present two\nsimple methods that expose remarkable translation capabilities with no\nfine-tuning. The results suggest that most of this information is encoded in a\nnon-linear way, while some of it can also be recovered with purely linear\ntools. As part of our analysis, we test the hypothesis that mBERT learns\nrepresentations which contain both a language-encoding component and an\nabstract, cross-lingual component, and explicitly identify an empirical\nlanguage-identity subspace within mBERT representations.", "published": "2020-10-16 09:49:32", "link": "http://arxiv.org/abs/2010.08275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning of Negation and Speculation for Targeted Sentiment\n  Classification", "abstract": "The majority of work in targeted sentiment analysis has concentrated on\nfinding better methods to improve the overall results. Within this paper we\nshow that these models are not robust to linguistic phenomena, specifically\nnegation and speculation. In this paper, we propose a multi-task learning\nmethod to incorporate information from syntactic and semantic auxiliary tasks,\nincluding negation and speculation scope detection, to create English-language\nmodels that are more robust to these phenomena. Further we create two challenge\ndatasets to evaluate model performance on negated and speculative samples. We\nfind that multi-task models and transfer learning via language modelling can\nimprove performance on these challenge datasets, but the overall performances\nindicate that there is still much room for improvement. We release both the\ndatasets and the source code at\nhttps://github.com/jerbarnes/multitask_negation_for_targeted_sentiment.", "published": "2020-10-16 11:20:03", "link": "http://arxiv.org/abs/2010.08318v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QA2Explanation: Generating and Evaluating Explanations for Question\n  Answering Systems over Knowledge Graph", "abstract": "In the era of Big Knowledge Graphs, Question Answering (QA) systems have\nreached a milestone in their performance and feasibility. However, their\napplicability, particularly in specific domains such as the biomedical domain,\nhas not gained wide acceptance due to their \"black box\" nature, which hinders\ntransparency, fairness, and accountability of QA systems. Therefore, users are\nunable to understand how and why particular questions have been answered,\nwhereas some others fail. To address this challenge, in this paper, we develop\nan automatic approach for generating explanations during various stages of a\npipeline-based QA system. Our approach is a supervised and automatic approach\nwhich considers three classes (i.e., success, no answer, and wrong answer) for\nannotating the output of involved QA components. Upon our prediction, a\ntemplate explanation is chosen and integrated into the output of the\ncorresponding component. To measure the effectiveness of the approach, we\nconducted a user survey as to how non-expert users perceive our generated\nexplanations. The results of our study show a significant increase in the four\ndimensions of the human factor from the Human-computer interaction community.", "published": "2020-10-16 11:32:12", "link": "http://arxiv.org/abs/2010.08323v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Delaying Interaction Layers in Transformer-based Encoders for Efficient\n  Open Domain Question Answering", "abstract": "Open Domain Question Answering (ODQA) on a large-scale corpus of documents\n(e.g. Wikipedia) is a key challenge in computer science. Although\ntransformer-based language models such as Bert have shown on SQuAD the ability\nto surpass humans for extracting answers in small passages of text, they suffer\nfrom their high complexity when faced to a much larger search space. The most\ncommon way to tackle this problem is to add a preliminary Information Retrieval\nstep to heavily filter the corpus and only keep the relevant passages. In this\npaper, we propose a more direct and complementary solution which consists in\napplying a generic change in the architecture of transformer-based models to\ndelay the attention between subparts of the input and allow a more efficient\nmanagement of computations. The resulting variants are competitive with the\noriginal models on the extractive task and allow, on the ODQA setting, a\nsignificant speedup and even a performance improvement in many cases.", "published": "2020-10-16 14:36:38", "link": "http://arxiv.org/abs/2010.08422v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Adversarial Learning for Cross-Lingual Word Embeddings", "abstract": "Generative adversarial networks (GANs) have succeeded in inducing\ncross-lingual word embeddings -- maps of matching words across languages --\nwithout supervision. Despite these successes, GANs' performance for the\ndifficult case of distant languages is still not satisfactory. These\nlimitations have been explained by GANs' incorrect assumption that source and\ntarget embedding spaces are related by a single linear mapping and are\napproximately isomorphic. We assume instead that, especially across distant\nlanguages, the mapping is only piece-wise linear, and propose a\nmulti-adversarial learning method. This novel method induces the seed\ncross-lingual dictionary through multiple mappings, each induced to fit the\nmapping for one subspace. Our experiments on unsupervised bilingual lexicon\ninduction show that this method improves performance over previous\nsingle-mapping methods, especially for distant languages.", "published": "2020-10-16 14:54:28", "link": "http://arxiv.org/abs/2010.08432v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Objectifying Language in Online Professor Reviews", "abstract": "Student reviews often make reference to professors' physical appearances.\nUntil recently RateMyProfessors.com, the website of this study's focus, used a\ndesign feature to encourage a \"hot or not\" rating of college professors. In the\nwake of recent #MeToo and #TimesUp movements, social awareness of the\ninappropriateness of these reviews has grown; however, objectifying comments\nremain and continue to be posted in this online context. We describe two\nsupervised text classifiers for detecting objectifying commentary in professor\nreviews. We then ensemble these classifiers and use the resulting model to\ntrack objectifying commentary at scale. We measure correlations between\nobjectifying commentary, changes to the review website interface, and teacher\ngender across a ten-year period.", "published": "2020-10-16 17:49:59", "link": "http://arxiv.org/abs/2010.08540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf\n  Language Models", "abstract": "Publicly available, large pretrained LanguageModels (LMs) generate text with\nremarkable quality, but only sequentially from left to right. As a result, they\nare not immediately applicable to generation tasks that break the\nunidirectional assumption, such as paraphrasing or text-infilling,\nnecessitating task-specific supervision.\n  In this paper, we present Reflective Decoding, a novel unsupervised algorithm\nthat allows for direct application of unidirectional LMs to non-sequential\ntasks. Our 2-step approach requires no supervision or even parallel corpora,\nonly two off-the-shelf pretrained LMs in opposite directions: forward and\nbackward. First, in the contextualization step, we use LMs to generate\nensembles of past and future contexts which collectively capture the input\n(e.g. the source sentence for paraphrasing). Second, in the reflection step, we\ncondition on these \"context ensembles\", generating outputs that are compatible\nwith them. Comprehensive empirical results demonstrate that Reflective Decoding\noutperforms strong unsupervised baselines on both paraphrasing and abductive\ntext infilling, significantly narrowing the gap between unsupervised and\nsupervised methods. Reflective Decoding surpasses multiple supervised baselines\non various metrics including human evaluation.", "published": "2020-10-16 18:02:07", "link": "http://arxiv.org/abs/2010.08566v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Fact Checking Summaries for Web Claims", "abstract": "We present SUMO, a neural attention-based approach that learns to establish\nthe correctness of textual claims based on evidence in the form of text\ndocuments (e.g., news articles or Web documents). SUMO further generates an\nextractive summary by presenting a diversified set of sentences from the\ndocuments that explain its decision on the correctness of the textual claim.\nPrior approaches to address the problem of fact checking and evidence\nextraction have relied on simple concatenation of claim and document word\nembeddings as an input to claim driven attention weight computation. This is\ndone so as to extract salient words and sentences from the documents that help\nestablish the correctness of the claim. However, this design of claim-driven\nattention does not capture the contextual information in documents properly. We\nimprove on the prior art by using improved claim and title guided hierarchical\nattention to model effective contextual cues. We show the efficacy of our\napproach on datasets concerning political, healthcare, and environmental\nissues.", "published": "2020-10-16 18:10:47", "link": "http://arxiv.org/abs/2010.08570v1", "categories": ["cs.CL", "68T50", "H.1.1; H.3.1; H.3.3"], "primary_category": "cs.CL"}
{"title": "Linguistically-Informed Transformations (LIT): A Method for\n  Automatically Generating Contrast Sets", "abstract": "Although large-scale pretrained language models, such as BERT and RoBERTa,\nhave achieved superhuman performance on in-distribution test sets, their\nperformance suffers on out-of-distribution test sets (e.g., on contrast sets).\nBuilding contrast sets often re-quires human-expert annotation, which is\nexpensive and hard to create on a large scale. In this work, we propose a\nLinguistically-Informed Transformation (LIT) method to automatically generate\ncontrast sets, which enables practitioners to explore linguistic phenomena of\ninterests as well as compose different phenomena. Experimenting with our method\non SNLI and MNLI shows that current pretrained language models, although being\nclaimed to contain sufficient linguistic knowledge, struggle on our\nautomatically generated contrast sets. Furthermore, we improve models'\nperformance on the contrast sets by apply-ing LIT to augment the training data,\nwithout affecting performance on the original data.", "published": "2020-10-16 18:23:05", "link": "http://arxiv.org/abs/2010.08580v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Substance over Style: Document-Level Targeted Content Transfer", "abstract": "Existing language models excel at writing from scratch, but many real-world\nscenarios require rewriting an existing document to fit a set of constraints.\nAlthough sentence-level rewriting has been fairly well-studied, little work has\naddressed the challenge of rewriting an entire document coherently. In this\nwork, we introduce the task of document-level targeted content transfer and\naddress it in the recipe domain, with a recipe as the document and a dietary\nrestriction (such as vegan or dairy-free) as the targeted constraint. We\npropose a novel model for this task based on the generative pre-trained\nlanguage model (GPT-2) and train on a large number of roughly-aligned recipe\npairs (https://github.com/microsoft/document-level-targeted-content-transfer).\nBoth automatic and human evaluations show that our model out-performs existing\nmethods by generating coherent and diverse rewrites that obey the constraint\nwhile remaining close to the original document. Finally, we analyze our model's\nrewrites to assess progress toward the goal of making language generation more\nattuned to constraints that are substantive rather than stylistic.", "published": "2020-10-16 20:26:10", "link": "http://arxiv.org/abs/2010.08618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Speech Recognition with Unstructured Audio Masking", "abstract": "Visual context has been shown to be useful for automatic speech recognition\n(ASR) systems when the speech signal is noisy or corrupted. Previous work,\nhowever, has only demonstrated the utility of visual context in an unrealistic\nsetting, where a fixed set of words are systematically masked in the audio. In\nthis paper, we simulate a more realistic masking scenario during model\ntraining, called RandWordMask, where the masking can occur for any word\nsegment. Our experiments on the Flickr 8K Audio Captions Corpus show that\nmultimodal ASR can generalize to recover different types of masked words in\nthis unstructured masking setting. Moreover, our analysis shows that our models\nare capable of attending to the visual signal when the audio signal is\ncorrupted. These results show that multimodal ASR systems can leverage the\nvisual signal in more generalized noisy scenarios.", "published": "2020-10-16 21:49:20", "link": "http://arxiv.org/abs/2010.08642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for\n  Natural Language Understanding", "abstract": "Data augmentation has been demonstrated as an effective strategy for\nimproving model generalization and data efficiency. However, due to the\ndiscrete nature of natural language, designing label-preserving transformations\nfor text data tends to be more challenging. In this paper, we propose a novel\ndata augmentation framework dubbed CoDA, which synthesizes diverse and\ninformative augmented examples by integrating multiple transformations\norganically. Moreover, a contrastive regularization objective is introduced to\ncapture the global relationship among all the data samples. A momentum encoder\nalong with a memory bank is further leveraged to better estimate the\ncontrastive loss. To verify the effectiveness of the proposed framework, we\napply CoDA to Transformer-based models on a wide range of natural language\nunderstanding tasks. On the GLUE benchmark, CoDA gives rise to an average\nimprovement of 2.2% while applied to the RoBERTa-large model. More importantly,\nit consistently exhibits stronger results relative to several competitive data\naugmentation and adversarial training base-lines (including the low-resource\nsettings). Extensive experiments show that the proposed contrastive objective\ncan be flexibly combined with various data augmentation approaches to further\nboost their performance, highlighting the wide applicability of the CoDA\nframework.", "published": "2020-10-16 23:57:03", "link": "http://arxiv.org/abs/2010.08670v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexicon generation for detecting fake news", "abstract": "With the digitization of media, an immense amount of news data has been\ngenerated by online sources, including mainstream media outlets as well as\nsocial networks. However, the ease of production and distribution resulted in\ncirculation of fake news as well as credible, authentic news. The pervasive\ndissemination of fake news has extreme negative impacts on individuals and\nsociety. Therefore, fake news detection has recently become an emerging topic\nas an interdisciplinary research field that is attracting significant attention\nfrom many research disciplines, including social sciences and linguistics. In\nthis study, we propose a method primarily based on lexicons including a scoring\nsystem to facilitate the detection of the fake news in Turkish. We contribute\nto the literature by collecting a novel, large scale, and credible dataset of\nTurkish news, and by constructing the first fake news detection lexicon for\nTurkish.", "published": "2020-10-16 20:39:57", "link": "http://arxiv.org/abs/2010.11089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Diverse Translation from Model Distribution with Dropout", "abstract": "Despite the improvement of translation quality, neural machine translation\n(NMT) often suffers from the lack of diversity in its generation. In this\npaper, we propose to generate diverse translations by deriving a large number\nof possible models with Bayesian modelling and sampling models from them for\ninference. The possible models are obtained by applying concrete dropout to the\nNMT model and each of them has specific confidence for its prediction, which\ncorresponds to a posterior model distribution under specific training data in\nthe principle of Bayesian modeling. With variational inference, the posterior\nmodel distribution can be approximated with a variational distribution, from\nwhich the final models for inference are sampled. We conducted experiments on\nChinese-English and English-German translation tasks and the results shows that\nour method makes a better trade-off between diversity and accuracy.", "published": "2020-10-16 05:50:00", "link": "http://arxiv.org/abs/2010.08178v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DiDi's Machine Translation System for WMT2020", "abstract": "This paper describes DiDi AI Labs' submission to the WMT2020 news translation\nshared task. We participate in the translation direction of Chinese->English.\nIn this direction, we use the Transformer as our baseline model, and integrate\nseveral techniques for model enhancement, including data filtering, data\nselection, back-translation, fine-tuning, model ensembling, and re-ranking. As\na result, our submission achieves a BLEU score of $36.6$ in Chinese->English.", "published": "2020-10-16 06:25:48", "link": "http://arxiv.org/abs/2010.08185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for\n  Open-Domain Question Answering", "abstract": "In open-domain question answering, dense passage retrieval has become a new\nparadigm to retrieve relevant passages for finding answers. Typically, the\ndual-encoder architecture is adopted to learn dense representations of\nquestions and passages for semantic matching. However, it is difficult to\neffectively train a dual-encoder due to the challenges including the\ndiscrepancy between training and inference, the existence of unlabeled\npositives and limited training data. To address these challenges, we propose an\noptimized training approach, called RocketQA, to improving dense passage\nretrieval. We make three major technical contributions in RocketQA, namely\ncross-batch negatives, denoised hard negatives and data augmentation. The\nexperiment results show that RocketQA significantly outperforms previous\nstate-of-the-art models on both MSMARCO and Natural Questions. We also conduct\nextensive experiments to examine the effectiveness of the three strategies in\nRocketQA. Besides, we demonstrate that the performance of end-to-end QA can be\nimproved based on our RocketQA retriever.", "published": "2020-10-16 06:54:05", "link": "http://arxiv.org/abs/2010.08191v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Natural Language Inference via Decoupled Multimodal\n  Contrastive Learning", "abstract": "We propose to solve the natural language inference problem without any\nsupervision from the inference labels via task-agnostic multimodal pretraining.\nAlthough recent studies of multimodal self-supervised learning also represent\nthe linguistic and visual context, their encoders for different modalities are\ncoupled. Thus they cannot incorporate visual information when encoding plain\ntext alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled\nlearning (MACD) network. MACD forces the decoupled text encoder to represent\nthe visual information via contrastive learning. Therefore, it embeds visual\nknowledge even for plain text inference. We conducted comprehensive experiments\nover plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD\neven outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.", "published": "2020-10-16 07:12:53", "link": "http://arxiv.org/abs/2010.08200v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training Flexible Depth Model by Multi-Task Learning for Neural Machine\n  Translation", "abstract": "The standard neural machine translation model can only decode with the same\ndepth configuration as training. Restricted by this feature, we have to deploy\nmodels of various sizes to maintain the same translation latency, because the\nhardware conditions on different terminal devices (e.g., mobile phones) may\nvary greatly. Such individual training leads to increased model maintenance\ncosts and slower model iterations, especially for the industry. In this work,\nwe propose to use multi-task learning to train a flexible depth model that can\nadapt to different depth configurations during inference. Experimental results\nshow that our approach can simultaneously support decoding in 24 depth\nconfigurations and is superior to the individual training and another flexible\ndepth model training method -- LayerDrop.", "published": "2020-10-16 09:37:27", "link": "http://arxiv.org/abs/2010.08265v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Talk to Action with Accountability: Monitoring the Public\n  Discussion of Policy Makers with Deep Neural Networks and Topic Modelling", "abstract": "Decades of research on climate have provided a consensus that human activity\nhas changed the climate and we are currently heading into a climate crisis.\nWhile public discussion and research efforts on climate change mitigation have\nincreased, potential solutions need to not only be discussed but also\neffectively deployed. For preventing mismanagement and holding policy makers\naccountable, transparency and degree of information about government processes\nhave been shown to be crucial. However, currently the quantity of information\nabout climate change discussions and the range of sources make it increasingly\ndifficult for the public and civil society to maintain an overview to hold\npoliticians accountable.\n  In response, we propose a multi-source topic aggregation system (MuSTAS)\nwhich processes policy makers speech and rhetoric from several publicly\navailable sources into an easily digestible topic summary. MuSTAS uses novel\nmulti-source hybrid latent Dirichlet allocation to model topics from a variety\nof documents. This topic digest will serve the general public and civil society\nin assessing where, how, and when politicians talk about climate and climate\npolicies, enabling them to hold politicians accountable for their actions to\nmitigate climate change and lack thereof.", "published": "2020-10-16 12:21:01", "link": "http://arxiv.org/abs/2010.08346v3", "categories": ["cs.CL", "cs.LG", "I.2.7; K.4.1"], "primary_category": "cs.CL"}
{"title": "An efficient representation of chronological events in medical texts", "abstract": "In this work we addressed the problem of capturing sequential information\ncontained in longitudinal electronic health records (EHRs). Clinical notes,\nwhich is a particular type of EHR data, are a rich source of information and\npractitioners often develop clever solutions how to maximise the sequential\ninformation contained in free-texts. We proposed a systematic methodology for\nlearning from chronological events available in clinical notes. The proposed\nmethodological {\\it path signature} framework creates a non-parametric\nhierarchical representation of sequential events of any type and can be used as\nfeatures for downstream statistical learning tasks. The methodology was\ndeveloped and externally validated using the largest in the UK secondary care\nmental health EHR data on a specific task of predicting survival risk of\npatients diagnosed with Alzheimer's disease. The signature-based model was\ncompared to a common survival random forest model. Our results showed a\n15.4$\\%$ increase of risk prediction AUC at the time point of 20 months after\nthe first admission to a specialist memory clinic and the signature method\noutperformed the baseline mixed-effects model by 13.2 $\\%$.", "published": "2020-10-16 14:54:29", "link": "http://arxiv.org/abs/2010.08433v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Analogous Process Structure Induction for Sub-event Sequence Prediction", "abstract": "Computational and cognitive studies of event understanding suggest that\nidentifying, comprehending, and predicting events depend on having structured\nrepresentations of a sequence of events and on conceptualizing (abstracting)\nits components into (soft) event categories. Thus, knowledge about a known\nprocess such as \"buying a car\" can be used in the context of a new but\nanalogous process such as \"buying a house\". Nevertheless, most event\nunderstanding work in NLP is still at the ground level and does not consider\nabstraction. In this paper, we propose an Analogous Process Structure Induction\nAPSI framework, which leverages analogies among processes and conceptualization\nof sub-event instances to predict the whole sub-event sequence of previously\nunseen open-domain processes. As our experiments and analysis indicate, APSI\nsupports the generation of meaningful sub-event sequences for unseen processes\nand can help predict missing events.", "published": "2020-10-16 17:35:40", "link": "http://arxiv.org/abs/2010.08525v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Evaluating Attribution Methods using White-Box LSTMs", "abstract": "Interpretability methods for neural networks are difficult to evaluate\nbecause we do not understand the black-box models typically used to test them.\nThis paper proposes a framework in which interpretability methods are evaluated\nusing manually constructed networks, which we call white-box networks, whose\nbehavior is understood a priori. We evaluate five methods for producing\nattribution heatmaps by applying them to white-box LSTM classifiers for tasks\nbased on formal languages. Although our white-box classifiers solve their tasks\nperfectly and transparently, we find that all five attribution methods fail to\nproduce the expected model explanations.", "published": "2020-10-16 19:55:32", "link": "http://arxiv.org/abs/2010.08606v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Distributed Representations of Entities in Open-World Knowledge Graphs", "abstract": "Graph neural network (GNN)-based methods have demonstrated remarkable\nperformance in various knowledge graph (KG) tasks. However, most existing\napproaches rely on observing all entities during training, posing a challenge\nin real-world knowledge graphs where new entities emerge frequently. To address\nthis limitation, we introduce Decentralized Attention Network (DAN). DAN\nleverages neighbor context as the query vector to score the neighbors of an\nentity, thereby distributing the entity semantics only among its neighbor\nembeddings. To effectively train a DAN, we introduce self-distillation, a\ntechnique that guides the network in generating desired representations.\nTheoretical analysis validates the effectiveness of our approach. We implement\nan end-to-end framework and conduct extensive experiments to evaluate our\nmethod, showcasing competitive performance on conventional entity alignment and\nentity prediction tasks. Furthermore, our method significantly outperforms\nexisting methods in open-world settings.", "published": "2020-10-16 02:31:22", "link": "http://arxiv.org/abs/2010.08114v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "PrivNet: Safeguarding Private Attributes in Transfer Learning for\n  Recommendation", "abstract": "Transfer learning is an effective technique to improve a target recommender\nsystem with the knowledge from a source domain. Existing research focuses on\nthe recommendation performance of the target domain while ignores the privacy\nleakage of the source domain. The transferred knowledge, however, may\nunintendedly leak private information of the source domain. For example, an\nattacker can accurately infer user demographics from their historical purchase\nprovided by a source domain data owner. This paper addresses the above\nprivacy-preserving issue by learning a privacy-aware neural representation by\nimproving target performance while protecting source privacy. The key idea is\nto simulate the attacks during the training for protecting unseen users'\nprivacy in the future, modeled by an adversarial game, so that the transfer\nlearning model becomes robust to attacks. Experiments show that the proposed\nPrivNet model can successfully disentangle the knowledge benefitting the\ntransfer from leaking the privacy.", "published": "2020-10-16 06:33:45", "link": "http://arxiv.org/abs/2010.08187v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Collaborative Training of GANs in Continuous and Discrete Spaces for\n  Text Generation", "abstract": "Applying generative adversarial networks (GANs) to text-related tasks is\nchallenging due to the discrete nature of language. One line of research\nresolves this issue by employing reinforcement learning (RL) and optimizing the\nnext-word sampling policy directly in a discrete action space. Such methods\ncompute the rewards from complete sentences and avoid error accumulation due to\nexposure bias. Other approaches employ approximation techniques that map the\ntext to continuous representation in order to circumvent the non-differentiable\ndiscrete process. Particularly, autoencoder-based methods effectively produce\nrobust representations that can model complex discrete structures. In this\npaper, we propose a novel text GAN architecture that promotes the collaborative\ntraining of the continuous-space and discrete-space methods. Our method employs\nan autoencoder to learn an implicit data manifold, providing a learning\nobjective for adversarial training in a continuous space. Furthermore, the\ncomplete textual output is directly evaluated and updated via RL in a discrete\nspace. The collaborative interplay between the two adversarial trainings\neffectively regularize the text representations in different spaces. The\nexperimental results on three standard benchmark datasets show that our model\nsubstantially outperforms state-of-the-art text GANs with respect to quality,\ndiversity, and global consistency.", "published": "2020-10-16 07:51:16", "link": "http://arxiv.org/abs/2010.08213v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effective Distributed Representations for Academic Expert Search", "abstract": "Expert search aims to find and rank experts based on a user's query. In\nacademia, retrieving experts is an efficient way to navigate through a large\namount of academic knowledge. Here, we study how different distributed\nrepresentations of academic papers (i.e. embeddings) impact academic expert\nretrieval. We use the Microsoft Academic Graph dataset and experiment with\ndifferent configurations of a document-centric voting model for retrieval. In\nparticular, we explore the impact of the use of contextualized embeddings on\nsearch performance. We also present results for paper embeddings that\nincorporate citation information through retrofitting. Additionally,\nexperiments are conducted using different techniques for assigning author\nweights based on author order. We observe that using contextual embeddings\nproduced by a transformer model trained for sentence similarity tasks produces\nthe most effective paper representations for document-centric expert retrieval.\nHowever, retrofitting the paper embeddings and using elaborate author\ncontribution weighting strategies did not improve retrieval performance.", "published": "2020-10-16 09:43:18", "link": "http://arxiv.org/abs/2010.08269v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Detecting ESG topics using domain-specific language models and data\n  augmentation approaches", "abstract": "Despite recent advances in deep learning-based language modelling, many\nnatural language processing (NLP) tasks in the financial domain remain\nchallenging due to the paucity of appropriately labelled data. Other issues\nthat can limit task performance are differences in word distribution between\nthe general corpora - typically used to pre-train language models - and\nfinancial corpora, which often exhibit specialized language and symbology.\nHere, we investigate two approaches that may help to mitigate these issues.\nFirstly, we experiment with further language model pre-training using large\namounts of in-domain data from business and financial news. We then apply\naugmentation approaches to increase the size of our dataset for model\nfine-tuning. We report our findings on an Environmental, Social and Governance\n(ESG) controversies dataset and demonstrate that both approaches are beneficial\nto accuracy in classification tasks.", "published": "2020-10-16 11:20:07", "link": "http://arxiv.org/abs/2010.08319v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adaptive Feature Selection for End-to-End Speech Translation", "abstract": "Information in speech signals is not evenly distributed, making it an\nadditional challenge for end-to-end (E2E) speech translation (ST) to learn to\nfocus on informative features. In this paper, we propose adaptive feature\nselection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR\nencoder and apply AFS to dynamically estimate the importance of each encoded\nspeech feature to SR. A ST encoder, stacked on top of the ASR encoder, then\nreceives the filtered features from the (frozen) ASR encoder. We take L0DROP\n(Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech\nfeatures with respect to both temporal and feature dimensions. Results on\nLibriSpeech En-Fr and MuST-C benchmarks show that AFS facilitates learning of\nST by pruning out ~84% temporal features, yielding an average translation gain\nof ~1.3-1.6 BLEU and a decoding speedup of ~1.4x. In particular, AFS reduces\nthe performance gap compared to the cascade baseline, and outperforms it on\nLibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation)", "published": "2020-10-16 17:21:00", "link": "http://arxiv.org/abs/2010.08518v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Mischief: A Simple Black-Box Attack Against Transformer Architectures", "abstract": "We introduce Mischief, a simple and lightweight method to produce a class of\nhuman-readable, realistic adversarial examples for language models. We perform\nexhaustive experimentations of our algorithm on four transformer-based\narchitectures, across a variety of downstream tasks, as well as under varying\nconcentrations of said examples. Our findings show that the presence of\nMischief-generated adversarial samples in the test set significantly degrades\n(by up to $20\\%$) the performance of these models with respect to their\nreported baselines. Nonetheless, we also demonstrate that, by including similar\nexamples in the training set, it is possible to restore the baseline scores on\nthe adversarial test set. Moreover, for certain tasks, the models trained with\nMischief set show a modest increase on performance with respect to their\noriginal, non-adversarial baseline.", "published": "2020-10-16 17:52:06", "link": "http://arxiv.org/abs/2010.08542v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Submodular Networks for Extractive Data Summarization", "abstract": "Deep Models are increasingly becoming prevalent in summarization problems\n(e.g. document, video and images) due to their ability to learn complex feature\ninteractions and representations. However, they do not model characteristics\nsuch as diversity, representation, and coverage, which are also very important\nfor summarization tasks. On the other hand, submodular functions naturally\nmodel these characteristics because of their diminishing returns property. Most\napproaches for modelling and learning submodular functions rely on very simple\nmodels, such as weighted mixtures of submodular functions. Unfortunately, these\nmodels only learn the relative importance of the different submodular functions\n(such as diversity, representation or importance), but cannot learn more\ncomplex feature representations, which are often required for state-of-the-art\nperformance. We propose Deep Submodular Networks (DSN), an end-to-end learning\nframework that facilitates the learning of more complex features and richer\nfunctions, crafted for better modelling of all aspects of summarization. The\nDSN framework can be used to learn features appropriate for summarization from\nscratch. We demonstrate the utility of DSNs on both generic and query focused\nimage-collection summarization, and show significant improvement over the\nstate-of-the-art. In particular, we show that DSNs outperform simple mixture\nmodels using off the shelf features. Secondly, we also show that just using\nfour submodular functions in a DSN with end-to-end learning performs comparably\nto the state-of-the-art mixture model with a hand-crafted set of 594 components\nand outperforms other methods for image collection summarization.", "published": "2020-10-16 19:06:15", "link": "http://arxiv.org/abs/2010.08593v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Cross-Lingual Relation Extraction with Transformers", "abstract": "Relation extraction (RE) is one of the most important tasks in information\nextraction, as it provides essential information for many NLP applications. In\nthis paper, we propose a cross-lingual RE approach that does not require any\nhuman annotation in a target language or any cross-lingual resources. Building\nupon unsupervised cross-lingual representation learning frameworks, we develop\nseveral deep Transformer based RE models with a novel encoding scheme that can\neffectively encode both entity location and entity type information. Our RE\nmodels, when trained with English data, outperform several deep neural network\nbased English RE models. More importantly, our models can be applied to perform\nzero-shot cross-lingual RE, achieving the state-of-the-art cross-lingual RE\nperformance on two datasets (68-89% of the accuracy of the supervised\ntarget-language RE model). The high cross-lingual transfer efficiency without\nrequiring additional training data or cross-lingual resources shows that our RE\nmodels are especially useful for low-resource languages.", "published": "2020-10-16 22:23:37", "link": "http://arxiv.org/abs/2010.08652v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Non-intrusive speech intelligibility prediction using automatic speech\n  recognition derived measures", "abstract": "The estimation of speech intelligibility is still far from being a solved\nproblem. Especially one aspect is problematic: most of the standard models\nrequire a clean reference signal in order to estimate intelligibility. This is\nan issue of some significance, as a reference signal is often unavailable in\npractice. In this work, therefore a non-intrusive speech intelligibility\nestimation framework is presented. In it, human listeners' performance in\nkeyword recognition tasks is predicted using intelligibility measures that are\nderived from models trained for automatic speech recognition (ASR). One such\nASR-based and one signal-based measure are combined into a full framework, the\nproposed NO-Reference Intelligibility (Nori) estimator, which is evaluated in\npredicting the performance of both normal-hearing and hearing-impaired\nlisteners in multiple noise conditions. It is shown that the Nori framework\neven outperforms the widely used reference-based (or intrusive) short-term\nobjective intelligibility (STOI) measure in most considered scenarios, while\nbeing applicable in fully blind scenarios with no reference signal or\ntranscription, creating perspectives for online and personalized optimization\nof speech enhancement systems.", "published": "2020-10-16 18:14:27", "link": "http://arxiv.org/abs/2010.08574v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Tongji University Team for the VoxCeleb Speaker Recognition Challenge\n  2020", "abstract": "In this report, we describe the submission of Tongji University team to the\nCLOSE track of the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020 at\nInterspeech 2020. We investigate different speaker recognition systems based on\nthe popular ResNet-34 architecture, and train multiple variants via various\nloss functions. Both Offline and online data augmentation are introduced to\nimprove the diversity of the training set, and score normalization with the\nexhaustive grid search is applied in the post-processing. Our best fusion of\nfive selected systems for the CLOSE track achieves 0.2800 DCF and 4.7770% EER\non the challenge.", "published": "2020-10-16 05:51:02", "link": "http://arxiv.org/abs/2010.08179v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Are Multiple Cross-Correlation Identities better than just Two?\n  Improving the Estimate of Time Differences-of-Arrivals from Blind Audio\n  Signals", "abstract": "Given an unknown audio source, the estimation of time differences-of-arrivals\n(TDOAs) can be efficiently and robustly solved using blind channel\nidentification and exploiting the cross-correlation identity (CCI). Prior\n\"blind\" works have improved the estimate of TDOAs by means of different\nalgorithmic solutions and optimization strategies, while always sticking to the\ncase N = 2 microphones. But what if we can obtain a direct improvement in\nperformance by just increasing N? In this paper we try to investigate this\ndirection, showing that, despite the arguable simplicity, this is capable of\n(sharply) improving upon state-of-the-art blind channel identification methods\nbased on CCI, without modifying the computational pipeline. Inspired by our\nresults, we seek to warm up the community and the practitioners by paving the\nway (with two concrete, yet preliminary, examples) towards joint approaches in\nwhich advances in the optimization are combined with an increased number of\nmicrophones, in order to achieve further improvements.", "published": "2020-10-16 14:47:26", "link": "http://arxiv.org/abs/2010.08428v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Classification of Manifest Huntington Disease using Vowel Distortion\n  Measures", "abstract": "Huntington disease (HD) is a fatal autosomal dominant neurocognitive disorder\nthat causes cognitive disturbances, neuropsychiatric symptoms, and impaired\nmotor abilities (e.g., gait, speech, voice). Due to its progressive nature, HD\ntreatment requires ongoing clinical monitoring of symptoms. Individuals with\nthe gene mutation which causes HD may exhibit a range of speech symptoms as\nthey progress from premanifest to manifest HD. Differentiating between\npremanifest and manifest HD is an important yet understudied problem, as this\ndistinction marks the need for increased treatment. Speech-based passive\nmonitoring has the potential to augment clinical assessments by continuously\ntracking manifestation symptoms. In this work we present the first\ndemonstration of how changes in connected speech can be measured to\ndifferentiate between premanifest and manifest HD. To do so, we focus on a key\nspeech symptom of HD: vowel distortion. We introduce a set of vowel features\nwhich we extract from connected speech. We show that our vowel features can\ndifferentiate between premanifest and manifest HD with 87% accuracy.", "published": "2020-10-16 16:58:59", "link": "http://arxiv.org/abs/2010.08503v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Joint Analysis of Sound Events and Acoustic Scenes Using Multitask\n  Learning", "abstract": "Sound event detection (SED) and acoustic scene classification (ASC) are\nimportant research topics in environmental sound analysis. Many research groups\nhave addressed SED and ASC using neural-network-based methods, such as the\nconvolutional neural network (CNN), recurrent neural network (RNN), and\nconvolutional recurrent neural network (CRNN). The conventional methods address\nSED and ASC separately even though sound events and acoustic scenes are closely\nrelated to each other. For example, in the acoustic scene \"office,\" the sound\nevents \"mouse clicking\" and \"keyboard typing\" are likely to occur. Therefore,\nit is expected that information on sound events and acoustic scenes will be of\nmutual aid for SED and ASC. In this paper, we propose multitask learning for\njoint analysis of sound events and acoustic scenes, in which the parts of the\nnetworks holding information on sound events and acoustic scenes in common are\nshared. Experimental results obtained using the TUT Sound Events 2016/2017 and\nTUT Acoustic Scenes 2016 datasets indicate that the proposed method improves\nthe performance of SED and ASC by 1.31 and 1.80 percentage points in terms of\nthe F-score, respectively, compared with the conventional CRNN-based method.", "published": "2020-10-16 05:51:32", "link": "http://arxiv.org/abs/2010.09213v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for\n  Symbolic Music", "abstract": "Definitive embeddings remain a fundamental challenge of computational\nmusicology for symbolic music in deep learning today. Analogous to natural\nlanguage, music can be modeled as a sequence of tokens. This motivates the\nmajority of existing solutions to explore the utilization of word embedding\nmodels to build music embeddings. However, music differs from natural languages\nin two key aspects: (1) musical token is multi-faceted -- it comprises of\npitch, rhythm and dynamics information; and (2) musical context is\ntwo-dimensional -- each musical token is dependent on both melodic and harmonic\ncontexts. In this work, we provide a comprehensive solution by proposing a\nnovel framework named PiRhDy that integrates pitch, rhythm, and dynamics\ninformation seamlessly. PiRhDy adopts a hierarchical strategy which can be\ndecomposed into two steps: (1) token (i.e., note event) modeling, which\nseparately represents pitch, rhythm, and dynamics and integrates them into a\nsingle token embedding; and (2) context modeling, which utilizes melodic and\nharmonic knowledge to train the token embedding. A thorough study was made on\neach component and sub-strategy of PiRhDy. We further validate our embeddings\nin three downstream tasks -- melody completion, accompaniment suggestion, and\ngenre classification. Results indicate a significant advancement of the neural\napproach towards symbolic music as well as PiRhDy's potential as a pretrained\ntool for a broad range of symbolic music applications.", "published": "2020-10-16 01:25:48", "link": "http://arxiv.org/abs/2010.08091v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Melody Classifier with Stacked-LSTM", "abstract": "Attempts to use generative models for music generation have been common in\nrecent years, and some of them have achieved good results. Pieces generated by\nsome of these models are almost indistinguishable from those being composed by\nhuman composers. However, the research on the evaluation system for\nmachine-generated music is still at a relatively early stage, and there is no\nuniform standard for such tasks. This paper proposes a stacked-LSTM binary\nclassifier based on a language model, which can be used to distinguish the\nhuman composer's work from the machine-generated melody by learning the MIDI\nfile's pitch, position, and duration.", "published": "2020-10-16 03:01:14", "link": "http://arxiv.org/abs/2010.08123v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Natural Bilingual and Code-Switched Speech Synthesis Based on\n  Mix of Monolingual Recordings and Cross-Lingual Voice Conversion", "abstract": "Recent state-of-the-art neural text-to-speech (TTS) synthesis models have\ndramatically improved intelligibility and naturalness of generated speech from\ntext. However, building a good bilingual or code-switched TTS for a particular\nvoice is still a challenge. The main reason is that it is not easy to obtain a\nbilingual corpus from a speaker who achieves native-level fluency in both\nlanguages. In this paper, we explore the use of Mandarin speech recordings from\na Mandarin speaker, and English speech recordings from another English speaker\nto build high-quality bilingual and code-switched TTS for both speakers. A\nTacotron2-based cross-lingual voice conversion system is employed to generate\nthe Mandarin speaker's English speech and the English speaker's Mandarin\nspeech, which show good naturalness and speaker similarity. The obtained\nbilingual data are then augmented with code-switched utterances synthesized\nusing a Transformer model. With these data, three neural TTS models --\nTacotron2, Transformer and FastSpeech are applied for building bilingual and\ncode-switched TTS. Subjective evaluation results show that all the three\nsystems can produce (near-)native-level speech in both languages for each of\nthe speaker.", "published": "2020-10-16 03:51:00", "link": "http://arxiv.org/abs/2010.08136v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
