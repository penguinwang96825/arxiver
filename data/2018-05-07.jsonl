{"title": "Learning Matching Models with Weak Supervision for Response Selection in\n  Retrieval-based Chatbots", "abstract": "We propose a method that can leverage unlabeled data to learn a matching\nmodel for response selection in retrieval-based chatbots. The method employs a\nsequence-to-sequence architecture (Seq2Seq) model as a weak annotator to judge\nthe matching degree of unlabeled pairs, and then performs learning with both\nthe weak signals and the unlabeled data. Experimental results on two public\ndata sets indicate that matching models get significant improvements when they\nare learned with the proposed method.", "published": "2018-05-07 03:31:00", "link": "http://arxiv.org/abs/1805.02333v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations", "abstract": "Revealing the implicit semantic relation between the constituents of a\nnoun-compound is important for many NLP applications. It has been addressed in\nthe literature either as a classification task to a set of pre-defined\nrelations or by producing free text paraphrases explicating the relations. Most\nexisting paraphrasing methods lack the ability to generalize, and have a hard\ntime interpreting infrequent or new noun-compounds. We propose a neural model\nthat generalizes better by representing paraphrases in a continuous space,\ngeneralizing for both unseen noun-compounds and rare paraphrases. Our model\nhelps improving performance on both the noun-compound paraphrasing and\nclassification tasks.", "published": "2018-05-07 11:14:07", "link": "http://arxiv.org/abs/1805.02442v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Graph-to-Sequence Model for AMR-to-Text Generation", "abstract": "The problem of AMR-to-text generation is to recover a text representing the\nsame meaning as an input AMR graph. The current state-of-the-art method uses a\nsequence-to-sequence model, leveraging LSTM for encoding a linearized AMR\nstructure. Although being able to model non-local semantic information, a\nsequence LSTM can lose information from the AMR graph structure, and thus faces\nchallenges with large graphs, which result in long sequences. We introduce a\nneural graph-to-sequence model, using a novel LSTM structure for directly\nencoding graph-level semantics. On a standard benchmark, our model shows\nsuperior results to existing methods in the literature.", "published": "2018-05-07 12:31:27", "link": "http://arxiv.org/abs/1805.02473v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stay On-Topic: Generating Context-specific Fake Restaurant Reviews", "abstract": "Automatically generated fake restaurant reviews are a threat to online review\nsystems. Recent research has shown that users have difficulties in detecting\nmachine-generated fake reviews hiding among real restaurant reviews. The method\nused in this work (char-LSTM ) has one drawback: it has difficulties staying in\ncontext, i.e. when it generates a review for specific target entity, the\nresulting review may contain phrases that are unrelated to the target, thus\nincreasing its detectability. In this work, we present and evaluate a more\nsophisticated technique based on neural machine translation (NMT) with which we\ncan generate reviews that stay on-topic. We test multiple variants of our\ntechnique using native English speakers on Amazon Mechanical Turk. We\ndemonstrate that reviews generated by the best variant have almost optimal\nundetectability (class-averaged F-score 47%). We conduct a user study with\nskeptical users and show that our method evades detection more frequently\ncompared to the state-of-the-art (average evasion 3.2/4 vs 1.5/4) with\nstatistical significance, at level {\\alpha} = 1% (Section 4.3). We develop very\neffective detection tools and reach average F-score of 97% in classifying\nthese. Although fake reviews are very effective in fooling people, effective\nautomatic detection is still feasible.", "published": "2018-05-07 08:37:04", "link": "http://arxiv.org/abs/1805.02400v4", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Improving Knowledge Graph Embedding Using Simple Constraints", "abstract": "Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of\ncurrent research. Early works performed this task via simple models developed\nover KG triples. Recent attempts focused on either designing more complicated\ntriple scoring models, or incorporating extra information beyond triples. This\npaper, by contrast, investigates the potential of using very simple constraints\nto improve KG embedding. We examine non-negativity constraints on entity\nrepresentations and approximate entailment constraints on relation\nrepresentations. The former help to learn compact and interpretable\nrepresentations for entities. The latter further encode regularities of logical\nentailment between relations into their distributed representations. These\nconstraints impose prior beliefs upon the structure of the embedding space,\nwithout negative impacts on efficiency or scalability. Evaluation on WordNet,\nFreebase, and DBpedia shows that our approach is simple yet surprisingly\neffective, significantly and consistently outperforming competitive baselines.\nThe constraints imposed indeed improve model interpretability, leading to a\nsubstantially increased structuring of the embedding space. Code and data are\navailable at https://github.com/iieir-km/ComplEx-NNE_AER.", "published": "2018-05-07 09:03:14", "link": "http://arxiv.org/abs/1805.02408v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Sentence-State LSTM for Text Representation", "abstract": "Bi-directional LSTMs are a powerful tool for text representation. On the\nother hand, they have been shown to suffer various limitations due to their\nsequential nature. We investigate an alternative LSTM structure for encoding\ntext, which consists of a parallel state for each word. Recurrent steps are\nused to perform local and global information exchange between words\nsimultaneously, rather than incremental reading of a sequence of words. Results\non various classification and sequence labelling benchmarks show that the\nproposed model has strong representation power, giving highly competitive\nperformances compared to stacked BiLSTM models with similar parameter numbers.", "published": "2018-05-07 12:36:54", "link": "http://arxiv.org/abs/1805.02474v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multimodal Machine Translation with Reinforcement Learning", "abstract": "Multimodal machine translation is one of the applications that integrates\ncomputer vision and language processing. It is a unique task given that in the\nfield of machine translation, many state-of-the-arts algorithms still only\nemploy textual information. In this work, we explore the effectiveness of\nreinforcement learning in multimodal machine translation. We present a novel\nalgorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically\ncater to the multimodal machine translation task of the EMNLP 2018 Third\nConference on Machine Translation (WMT18). We experiment our proposed algorithm\non the Multi30K multilingual English-German image description dataset and the\nFlickr30K image entity dataset. Our model takes two channels of inputs, image\nand text, uses translation evaluation metrics as training rewards, and achieves\nbetter results than supervised learning MLE baseline models. Furthermore, we\ndiscuss the prospects and limitations of using reinforcement learning for\nmachine translation. Our experiment results suggest a promising reinforcement\nlearning solution to the general task of multimodal sequence to sequence\nlearning.", "published": "2018-05-07 06:12:32", "link": "http://arxiv.org/abs/1805.02356v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.MA", "cs.MM"], "primary_category": "cs.CL"}
{"title": "MMDenseLSTM: An efficient combination of convolutional and recurrent\n  neural networks for audio source separation", "abstract": "Deep neural networks have become an indispensable technique for audio source\nseparation (ASS). It was recently reported that a variant of CNN architecture\ncalled MMDenseNet was successfully employed to solve the ASS problem of\nestimating source amplitudes, and state-of-the-art results were obtained for\nDSD100 dataset. To further enhance MMDenseNet, here we propose a novel\narchitecture that integrates long short-term memory (LSTM) in multiple scales\nwith skip connections to efficiently model long-term structures within an audio\ncontext. The experimental results show that the proposed method outperforms\nMMDenseNet, LSTM and a blend of the two networks. The number of parameters and\nprocessing time of the proposed model are significantly less than those for\nsimple blending. Furthermore, the proposed method yields better results than\nthose obtained using ideal binary masks for a singing voice separation task.", "published": "2018-05-07 09:18:25", "link": "http://arxiv.org/abs/1805.02410v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Data-Driven Approach to Smooth Pitch Correction for Singing Voice in\n  Pop Music", "abstract": "In this paper, we present a machine-learning approach to pitch correction for\nvoice in a karaoke setting, where the vocals and accompaniment are on separate\ntracks and time-aligned. The network takes as input the time-frequency\nrepresentation of the two tracks and predicts the amount of pitch-shifting in\ncents required to make the voice sound in-tune with the accompaniment. It is\ntrained on examples of semi-professional singing. The proposed approach differs\nfrom existing real-time pitch correction methods by replacing pitch tracking\nand mapping to a discrete set of notes---for example, the twelve classes of the\nequal-tempered scale---with learning a correction that is continuous both in\nfrequency and in time directly from the harmonics of the vocal and\naccompaniment tracks. A Recurrent Neural Network (RNN) model provides a\ncorrection that takes context into account, preserving expressive pitch bending\nand vibrato. This method can be extended into unsupervised pitch correction of\na vocal performance---popularly referred to as autotuning.", "published": "2018-05-07 16:32:39", "link": "http://arxiv.org/abs/1805.02603v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
