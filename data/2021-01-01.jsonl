{"title": "Multi-task Retrieval for Knowledge-Intensive Tasks", "abstract": "Retrieving relevant contexts from a large corpus is a crucial step for tasks\nsuch as open-domain question answering and fact checking. Although neural\nretrieval outperforms traditional methods like tf-idf and BM25, its performance\ndegrades considerably when applied to out-of-domain data.\n  Driven by the question of whether a neural retrieval model can be universal\nand perform robustly on a wide variety of problems, we propose a multi-task\ntrained model. Our approach not only outperforms previous methods in the\nfew-shot setting, but also rivals specialised neural retrievers, even when\nin-domain training data is abundant. With the help of our retriever, we improve\nexisting models for downstream tasks and closely match or improve the state of\nthe art on multiple benchmarks.", "published": "2021-01-01 00:16:34", "link": "http://arxiv.org/abs/2101.00117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WARP: Word-level Adversarial ReProgramming", "abstract": "Transfer learning from pretrained language models recently became the\ndominant approach for solving many NLP tasks. A common approach to transfer\nlearning for multiple tasks that maximize parameter sharing trains one or more\ntask-specific layers on top of the language model. In this paper, we present an\nalternative approach based on adversarial reprogramming, which extends earlier\nwork on automatic prompt generation. Adversarial reprogramming attempts to\nlearn task-specific word embeddings that, when concatenated to the input text,\ninstruct the language model to solve the specified task. Using up to 25K\ntrainable parameters per task, this approach outperforms all existing methods\nwith up to 25M trainable parameters on the public leaderboard of the GLUE\nbenchmark. Our method, initialized with task-specific human-readable prompts,\nalso works in a few-shot setting, outperforming GPT-3 on two SuperGLUE tasks\nwith just 32 training samples.", "published": "2021-01-01 00:41:03", "link": "http://arxiv.org/abs/2101.00121v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intent Classification and Slot Filling for Privacy Policies", "abstract": "Understanding privacy policies is crucial for users as it empowers them to\nlearn about the information that matters to them. Sentences written in a\nprivacy policy document explain privacy practices, and the constituent text\nspans convey further specific information about that practice. We refer to\npredicting the privacy practice explained in a sentence as intent\nclassification and identifying the text spans sharing specific information as\nslot filling. In this work, we propose PolicyIE, an English corpus consisting\nof 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of\nwebsites and mobile applications. PolicyIE corpus is a challenging real-world\nbenchmark with limited labeled examples reflecting the cost of collecting\nlarge-scale annotations from domain experts. We present two alternative neural\napproaches as baselines, (1) intent classification and slot filling as a joint\nsequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq)\nlearning task. The experiment results show that both approaches perform\ncomparably in intent classification, while the Seq2Seq method outperforms the\nsequence tagging approach in slot filling by a large margin. We perform a\ndetailed error analysis to reveal the challenges of the proposed corpus.", "published": "2021-01-01 00:44:41", "link": "http://arxiv.org/abs/2101.00123v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sensei: Self-Supervised Sensor Name Segmentation", "abstract": "A sensor name, typically an alphanumeric string, encodes the key context\n(e.g., function and location) of a sensor needed for deploying smart building\napplications. Sensor names, however, are curated in a building vendor-specific\nmanner using different structures and vocabularies that are often esoteric.\nThey thus require tremendous manual effort to annotate on a per-building basis;\neven to just segment these sensor names into meaningful chunks. In this paper,\nwe propose a fully automated self-supervised framework, Sensei, which can learn\nto segment sensor names without any human annotation. Specifically, we employ a\nneural language model to capture the underlying sensor naming structure and\nthen induce self-supervision based on information from the language model to\nbuild the segmentation model. Extensive experiments on five real-world\nbuildings comprising thousands of sensors demonstrate the superiority of Sensei\nover baseline methods.", "published": "2021-01-01 01:18:49", "link": "http://arxiv.org/abs/2101.00130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Lexicon Induction via Unsupervised Bitext Construction and\n  Word Alignment", "abstract": "Bilingual lexicons map words in one language to their translations in\nanother, and are typically induced by learning linear projections to align\nmonolingual word embedding spaces. In this paper, we show it is possible to\nproduce much higher quality lexicons with methods that combine (1) unsupervised\nbitext mining and (2) unsupervised word alignment. Directly applying a pipeline\nthat uses recent algorithms for both subproblems significantly improves induced\nlexicon quality and further gains are possible by learning to filter the\nresulting lexical entries, with both unsupervised and semi-supervised schemes.\nOur final model outperforms the state of the art on the BUCC 2020 shared task\nby 14 $F_1$ points averaged over 12 language pairs, while also providing a more\ninterpretable approach that allows for rich reasoning of word meaning in\ncontext. Further analysis of our output and the standard reference lexicons\nsuggests they are of comparable quality, and new benchmarks may be needed to\nmeasure further progress on this task.", "published": "2021-01-01 03:12:42", "link": "http://arxiv.org/abs/2101.00148v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graphmax for Text Generation", "abstract": "In text generation, a large language model (LM) makes a choice of each new\nword based only on the former selection of its context using the softmax\nfunction. Nevertheless, the link statistics information of concurrent words\nbased on a scene-specific corpus is valuable in choosing the next word, which\ncan help to ensure the topic of the generated text to be aligned with the\ncurrent task. To fully explore the co-occurrence information,we propose a\ngraphmax function for task-specific text generation. Using the graph-based\nregularization, graphmax enables the final word choice to be determined by both\nthe global knowledge from the LM and the local knowledge from the\nscene-specific corpus. The traditional softmax function is regularized with a\ngraph total variation (GTV) term, which incorporates the local knowledge into\nthe LM and encourages the model to consider the statistical relationships\nbetween words in a scene-specific corpus. The proposed graphmax is versatile\nand can be readily plugged into any large pre-trained LM for text generation\nand machine translation. Through extensive experiments, we demonstrate that the\nnew GTV-based regularization can improve performances in various natural\nlanguage processing tasks in comparison with existing methods. Moreover,\nthrough human experiments, we observe that participants can easily distinguish\nthe text generated by graphmax or softmax.", "published": "2021-01-01 03:29:21", "link": "http://arxiv.org/abs/2101.00153v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Do Your Biomedical Named Entity Recognition Models Generalize to\n  Novel Entities?", "abstract": "The number of biomedical literature on new biomedical concepts is rapidly\nincreasing, which necessitates a reliable biomedical named entity recognition\n(BioNER) model for identifying new and unseen entity mentions. However, it is\nquestionable whether existing models can effectively handle them. In this work,\nwe systematically analyze the three types of recognition abilities of BioNER\nmodels: memorization, synonym generalization, and concept generalization. We\nfind that although current best models achieve state-of-the-art performance on\nbenchmarks based on overall performance, they have limitations in identifying\nsynonyms and new biomedical concepts, indicating they are overestimated in\nterms of their generalization abilities. We also investigate failure cases of\nmodels and identify several difficulties in recognizing unseen mentions in\nbiomedical literature as follows: (1) models tend to exploit dataset biases,\nwhich hinders the models' abilities to generalize, and (2) several biomedical\nnames have novel morphological patterns with weak name regularity, and models\nfail to recognize them. We apply a statistics-based debiasing method to our\nproblem as a simple remedy and show the improvement in generalization to unseen\nmentions. We hope that our analyses and findings would be able to facilitate\nfurther research into the generalization capabilities of NER models in a domain\nwhere their reliability is of utmost importance.", "published": "2021-01-01 04:13:42", "link": "http://arxiv.org/abs/2101.00160v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Discourse Resources with Dependency Framework", "abstract": "For text-level discourse analysis, there are various discourse schemes but\nrelatively few labeled data, because discourse research is still immature and\nit is labor-intensive to annotate the inner logic of a text. In this paper, we\nattempt to unify multiple Chinese discourse corpora under different annotation\nschemes with discourse dependency framework by designing semi-automatic methods\nto convert them into dependency structures. We also implement several benchmark\ndependency parsers and research on how they can leverage the unified data to\nimprove performance.", "published": "2021-01-01 05:23:29", "link": "http://arxiv.org/abs/2101.00167v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer based Automatic COVID-19 Fake News Detection System", "abstract": "Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.", "published": "2021-01-01 06:49:27", "link": "http://arxiv.org/abs/2101.00180v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation", "abstract": "Fine-tuning is the de facto way to leverage large pretrained language models\nto perform downstream tasks. However, it modifies all the language model\nparameters and therefore necessitates storing a full copy for each task. In\nthis paper, we propose prefix-tuning, a lightweight alternative to fine-tuning\nfor natural language generation tasks, which keeps language model parameters\nfrozen, but optimizes a small continuous task-specific vector (called the\nprefix). Prefix-tuning draws inspiration from prompting, allowing subsequent\ntokens to attend to this prefix as if it were \"virtual tokens\". We apply\nprefix-tuning to GPT-2 for table-to-text generation and to BART for\nsummarization. We find that by learning only 0.1\\% of the parameters,\nprefix-tuning obtains comparable performance in the full data setting,\noutperforms fine-tuning in low-data settings, and extrapolates better to\nexamples with topics unseen during training.", "published": "2021-01-01 08:00:36", "link": "http://arxiv.org/abs/2101.00190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Explaining Your Explanations of BERT: An Empirical Study with\n  Sequence Classification", "abstract": "BERT, as one of the pretrianed language models, attracts the most attention\nin recent years for creating new benchmarks across GLUE tasks via fine-tuning.\nOne pressing issue is to open up the blackbox and explain the decision makings\nof BERT. A number of attribution techniques have been proposed to explain BERT\nmodels, but are often limited to sequence to sequence tasks. In this paper, we\nadapt existing attribution methods on explaining decision makings of BERT in\nsequence classification tasks. We conduct extensive analyses of four existing\nattribution methods by applying them to four different datasets in sentiment\nanalysis. We compare the reliability and robustness of each method via various\nablation studies. Furthermore, we test whether attribution methods explain\ngeneralized semantics across semantically similar tasks. Our work provides\nsolid guidance for using attribution methods to explain decision makings of\nBERT for downstream classification tasks.", "published": "2021-01-01 08:45:32", "link": "http://arxiv.org/abs/2101.00196v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource\n  Language Understanding Evaluation in Bangla", "abstract": "In this work, we introduce BanglaBERT, a BERT-based Natural Language\nUnderstanding (NLU) model pretrained in Bangla, a widely spoken yet\nlow-resource language in the NLP literature. To pretrain BanglaBERT, we collect\n27.5 GB of Bangla pretraining data (dubbed `Bangla2B+') by crawling 110 popular\nBangla sites. We introduce two downstream task datasets on natural language\ninference and question answering and benchmark on four diverse NLU tasks\ncovering text classification, sequence labeling, and span prediction. In the\nprocess, we bring them under the first-ever Bangla Language Understanding\nBenchmark (BLUB). BanglaBERT achieves state-of-the-art results outperforming\nmultilingual and monolingual models. We are making the models, datasets, and a\nleaderboard publicly available at https://github.com/csebuetnlp/banglabert to\nadvance Bangla NLP.", "published": "2021-01-01 09:28:45", "link": "http://arxiv.org/abs/2101.00204v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and\n  Improving Models", "abstract": "While counterfactual examples are useful for analysis and training of NLP\nmodels, current generation methods either rely on manual labor to create very\nfew counterfactuals, or only instantiate limited types of perturbations such as\nparaphrases or word substitutions. We present Polyjuice, a general-purpose\ncounterfactual generator that allows for control over perturbation types and\nlocations, trained by finetuning GPT-2 on multiple datasets of paired\nsentences. We show that Polyjuice produces diverse sets of realistic\ncounterfactuals, which in turn are useful in various distinct applications:\nimproving training and evaluation on three different tasks (with around 70%\nless annotation effort than manual generation), augmenting state-of-the-art\nexplanation techniques, and supporting systematic counterfactual error analysis\nby revealing behaviors easily missed by human experts.", "published": "2021-01-01 18:34:22", "link": "http://arxiv.org/abs/2101.00288v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Commonsense Emergence in Few-shot Knowledge Models", "abstract": "Recently, commonsense knowledge models - pretrained language models (LM)\nfine-tuned on knowledge graph (KG) tuples - showed that considerable amounts of\ncommonsense knowledge can be encoded in the parameters of large language\nmodels. However, as parallel studies show that LMs are poor hypothesizers of\ndeclarative commonsense relationships on their own, it remains unclear whether\nthis knowledge is learned during pretraining or from fine-tuning on KG\nexamples. To investigate this question, we train commonsense knowledge models\nin few-shot settings to study the emergence of their commonsense representation\nabilities. Our results show that commonsense knowledge models can rapidly adapt\nfrom limited examples, indicating that KG fine-tuning serves to learn an\ninterface to encoded knowledge learned during pretraining. Importantly, our\nanalysis of absolute, angular, and distributional parameter changes during\nfew-shot fine-tuning provides novel insights into how this interface is\nlearned.", "published": "2021-01-01 19:01:09", "link": "http://arxiv.org/abs/2101.00297v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons\n  Learned", "abstract": "We review the EfficientQA competition from NeurIPS 2020. The competition\nfocused on open-domain question answering (QA), where systems take natural\nlanguage questions as input and return natural language answers. The aim of the\ncompetition was to build systems that can predict correct answers while also\nsatisfying strict on-disk memory budgets. These memory budgets were designed to\nencourage contestants to explore the trade-off between storing retrieval\ncorpora or the parameters of learned models. In this report, we describe the\nmotivation and organization of the competition, review the best submissions,\nand analyze system predictions to inform a discussion of evaluation for\nopen-domain QA.", "published": "2021-01-01 01:24:34", "link": "http://arxiv.org/abs/2101.00133v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "De-identifying Australian Hospital Discharge Summaries: An End-to-End\n  Framework using Ensemble of Deep Learning Models", "abstract": "Electronic Medical Records (EMRs) contain clinical narrative text that is of\ngreat potential value to medical researchers. However, this information is\nmixed with Personally Identifiable Information (PII) that presents risks to\npatient and clinician confidentiality. This paper presents an end-to-end\ndeidentification framework to automatically remove PII from Australian hospital\ndischarge summaries. Our corpus included 600 hospital discharge summaries which\nwere extracted from the EMRs of two principal referral hospitals in Sydney,\nAustralia. Our end-to-end de-identification framework consists of three\ncomponents: 1) Annotation: labelling of PII in the 600 hospital discharge\nsummaries using five pre-defined categories: person, address, date of birth,\nindividual identification number, phone/fax number; 2) Modelling: training six\nnamed entity recognition (NER) deep learning base-models on balanced and\nimbalanced datasets; and evaluating ensembles that combine all six base-models,\nthe three base-models with the best F1 scores and the three base-models with\nthe best recall scores respectively, using token-level majority voting and\nstacking methods; and 3) De-identification: removing PII from the hospital\ndischarge summaries. Our results showed that the ensemble model combined using\nthe stacking Support Vector Machine (SVM) method on the three base-models with\nthe best F1 scores achieved excellent results with a F1 score of 99.16% on the\ntest set of our corpus. We also evaluated the robustness of our modelling\ncomponent on the 2014 i2b2 de-identification dataset. Our ensemble model, which\nuses the token-level majority voting method on all six basemodels, achieved the\nhighest F1 score of 96.24% at strict entity matching and the highest F1 score\nof 98.64% at binary token-level matching compared to two state-of-the-art\nmethods.", "published": "2021-01-01 03:09:31", "link": "http://arxiv.org/abs/2101.00146v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DISCOS: Bridging the Gap between Discourse Knowledge and Commonsense\n  Knowledge", "abstract": "Commonsense knowledge is crucial for artificial intelligence systems to\nunderstand natural language. Previous commonsense knowledge acquisition\napproaches typically rely on human annotations (for example, ATOMIC) or text\ngeneration models (for example, COMET.) Human annotation could provide\nhigh-quality commonsense knowledge, yet its high cost often results in\nrelatively small scale and low coverage. On the other hand, generation models\nhave the potential to automatically generate more knowledge. Nonetheless,\nmachine learning models often fit the training data well and thus struggle to\ngenerate high-quality novel knowledge. To address the limitations of previous\napproaches, in this paper, we propose an alternative commonsense knowledge\nacquisition framework DISCOS (from DIScourse to COmmonSense), which\nautomatically populates expensive complex commonsense knowledge to more\naffordable linguistic knowledge resources. Experiments demonstrate that we can\nsuccessfully convert discourse knowledge about eventualities from ASER, a\nlarge-scale discourse knowledge graph, into if-then commonsense knowledge\ndefined in ATOMIC without any additional annotation effort. Further study\nsuggests that DISCOS significantly outperforms previous supervised approaches\nin terms of novelty and diversity with comparable quality. In total, we can\nacquire 3.4M ATOMIC-like inferential commonsense knowledge by populating ATOMIC\non the core part of ASER. Codes and data are available at\nhttps://github.com/HKUST-KnowComp/DISCOS-commonsense.", "published": "2021-01-01 03:30:38", "link": "http://arxiv.org/abs/2101.00154v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UnitedQA: A Hybrid Approach for Open Domain Question Answering", "abstract": "To date, most of recent work under the retrieval-reader framework for\nopen-domain QA focuses on either extractive or generative reader exclusively.\nIn this paper, we study a hybrid approach for leveraging the strengths of both\nmodels. We apply novel techniques to enhance both extractive and generative\nreaders built upon recent pretrained neural language models, and find that\nproper training methods can provide large improvement over previous\nstate-of-the-art models. We demonstrate that a simple hybrid approach by\ncombining answers from both readers can efficiently take advantages of\nextractive and generative answer inference strategies and outperforms single\nmodels as well as homogeneous ensembles. Our approach outperforms previous\nstate-of-the-art models by 3.3 and 2.7 points in exact match on\nNaturalQuestions and TriviaQA respectively.", "published": "2021-01-01 06:36:16", "link": "http://arxiv.org/abs/2101.00178v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Subformer: Exploring Weight Sharing for Parameter Efficiency in\n  Generative Transformers", "abstract": "Transformers have shown improved performance when compared to previous\narchitectures for sequence processing such as RNNs. Despite their sizeable\nperformance gains, as recently suggested, the model is computationally\nexpensive to train and with a high parameter budget. In light of this, we\nexplore parameter-sharing methods in Transformers with a specific focus on\ngenerative models. We perform an analysis of different parameter\nsharing/reduction methods and develop the Subformer. Our model combines\nsandwich-style parameter sharing, which overcomes naive cross-layer parameter\nsharing in generative models, and self-attentive embedding factorization\n(SAFE). Experiments on machine translation, abstractive summarization and\nlanguage modeling show that the Subformer can outperform the Transformer even\nwhen using significantly fewer parameters.", "published": "2021-01-01 13:53:22", "link": "http://arxiv.org/abs/2101.00234v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Code Generation from Natural Language with Less Prior and More\n  Monolingual Data", "abstract": "Training datasets for semantic parsing are typically small due to the higher\nexpertise required for annotation than most other NLP tasks. As a result,\nmodels for this application usually need additional prior knowledge to be built\ninto the architecture or algorithm. The increased dependency on human experts\nhinders automation and raises the development and maintenance costs in\npractice. This work investigates whether a generic transformer-based seq2seq\nmodel can achieve competitive performance with minimal code-generation-specific\ninductive bias design. By exploiting a relatively sizeable monolingual corpus\nof the target programming language, which is cheap to mine from the web, we\nachieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.\nBoth are SOTA to the best of our knowledge. This positive evidence highlights a\npotentially easier path toward building accurate semantic parsers in practice.", "published": "2021-01-01 16:02:38", "link": "http://arxiv.org/abs/2101.00259v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Key Phrase Extraction & Applause Prediction", "abstract": "With the increase in content availability over the internet it is very\ndifficult to get noticed. It has become an upmost the priority of the blog\nwriters to get some feedback over their creations to be confident about the\nimpact of their article. We are training a machine learning model to learn\npopular article styles, in the form of vector space representations using\nvarious word embeddings, and their popularity based on claps and tags.", "published": "2021-01-01 12:49:43", "link": "http://arxiv.org/abs/2101.03235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discourse-level Relation Extraction via Graph Pooling", "abstract": "The ability to capture complex linguistic structures and long-term\ndependencies among words in the passage is essential for discourse-level\nrelation extraction (DRE) tasks. Graph neural networks (GNNs), one of the\nmethods to encode dependency graphs, have been shown effective in prior works\nfor DRE. However, relatively little attention has been paid to receptive fields\nof GNNs, which can be crucial for cases with extremely long text that requires\ndiscourse understanding. In this work, we leverage the idea of graph pooling\nand propose to use pooling-unpooling framework on DRE tasks. The pooling branch\nreduces the graph size and enables the GNNs to obtain larger receptive fields\nwithin fewer layers; the unpooling branch restores the pooled graph to its\noriginal resolution so that representations for entity mention can be\nextracted. We propose Clause Matching (CM), a novel linguistically inspired\ngraph pooling method for NLP tasks. Experiments on two DRE datasets demonstrate\nthat our models significantly improve over baselines when modeling long-term\ndependencies is required, which shows the effectiveness of the\npooling-unpooling framework and our CM pooling method.", "published": "2021-01-01 00:52:53", "link": "http://arxiv.org/abs/2101.00124v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded\n  Dialogue", "abstract": "A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.", "published": "2021-01-01 03:20:22", "link": "http://arxiv.org/abs/2101.00151v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "CIZSL++: Creativity Inspired Generative Zero-Shot Learning", "abstract": "Zero-shot learning (ZSL) aims at understanding unseen categories with no\ntraining examples from class-level descriptions. To improve the discriminative\npower of ZSL, we model the visual learning process of unseen categories with\ninspiration from the psychology of human creativity for producing novel art.\nFirst, we propose CIZSL-v1 as a creativity inspired model for generative ZSL.\nWe relate ZSL to human creativity by observing that ZSL is about recognizing\nthe unseen, and creativity is about creating a likable unseen. We introduce a\nlearning signal inspired by creativity literature that explores the unseen\nspace with hallucinated class-descriptions and encourages careful deviation of\ntheir visual feature generations from seen classes while allowing knowledge\ntransfer from seen to unseen classes. Second, CIZSL-v2 is proposed as an\nimproved version of CIZSL-v1 for generative zero-shot learning. CIZSL-v2\nconsists of an investigation of additional inductive losses for unseen classes\nalong with a semantic guided discriminator. Empirically, we show consistently\nthat CIZSL losses can improve generative ZSL models on the challenging task of\ngeneralized ZSL from a noisy text on CUB and NABirds datasets. We also show the\nadvantage of our approach to Attribute-based ZSL on AwA2, aPY, and SUN\ndatasets. We also show that CIZSL-v2 has improved performance compared to\nCIZSL-v1.", "published": "2021-01-01 05:47:57", "link": "http://arxiv.org/abs/2101.00173v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "VisualSparta: An Embarrassingly Simple Approach to Large-scale\n  Text-to-Image Search with Weighted Bag-of-words", "abstract": "Text-to-image retrieval is an essential task in cross-modal information\nretrieval, i.e., retrieving relevant images from a large and unlabelled dataset\ngiven textual queries. In this paper, we propose VisualSparta, a novel\n(Visual-text Sparse Transformer Matching) model that shows significant\nimprovement in terms of both accuracy and efficiency. VisualSparta is capable\nof outperforming previous state-of-the-art scalable methods in MSCOCO and\nFlickr30K. We also show that it achieves substantial retrieving speed\nadvantages, i.e., for a 1 million image index, VisualSparta using CPU gets\n~391X speedup compared to CPU vector search and ~5.4X speedup compared to\nvector search with GPU acceleration. Experiments show that this speed advantage\neven gets bigger for larger datasets because VisualSparta can be efficiently\nimplemented as an inverted index. To the best of our knowledge, VisualSparta is\nthe first transformer-based text-to-image retrieval model that can achieve\nreal-time searching for large-scale datasets, with significant accuracy\nimprovement compared to previous state-of-the-art methods.", "published": "2021-01-01 16:29:17", "link": "http://arxiv.org/abs/2101.00265v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Rider: Reader-Guided Passage Reranking for Open-Domain Question\n  Answering", "abstract": "Current open-domain question answering systems often follow a\nRetriever-Reader architecture, where the retriever first retrieves relevant\npassages and the reader then reads the retrieved passages to form an answer. In\nthis paper, we propose a simple and effective passage reranking method, named\nReader-guIDEd Reranker (RIDER), which does not involve training and reranks the\nretrieved passages solely based on the top predictions of the reader before\nreranking. We show that RIDER, despite its simplicity, achieves 10 to 20\nabsolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains\nwithout refining the retriever or reader. In addition, RIDER, without any\ntraining, outperforms state-of-the-art transformer-based supervised rerankers.\nRemarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM\non the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are\nused as the reader input after passage reranking.", "published": "2021-01-01 18:54:19", "link": "http://arxiv.org/abs/2101.00294v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Audio Content Analysis", "abstract": "Preprint for a book chapter introducing Audio Content Analysis. With a focus\non Music Information Retrieval systems, this chapter defines musical audio\ncontent, introduces the general process of audio content analysis, and surveys\nbasic approaches to audio content analysis. The various tasks in Audio Content\nAnalysis are categorized into three classes: music transcription, music\nperformance analysis, and music identification and categorization. The examples\nfor music transcription systems include music key detection, fundamental\nfrequency detection, and music structure detection. Music performance analysis\nsystems feature an overview of beat and tempo detection approaches as well as\nmusic performance assessment. The covered music classification systems are\naudio fingerprinting, music genre classification, and music emotion\nrecognition. The chapter concludes with a discussion and current challenges in\nthe field and a speculation on future perspectives.", "published": "2021-01-01 01:22:22", "link": "http://arxiv.org/abs/2101.00132v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Generative Deep Learning for Virtuosic Classical Music: Generative\n  Adversarial Networks as Renowned Composers", "abstract": "Current AI-generated music lacks fundamental principles of good compositional\ntechniques. By narrowing down implementation issues both programmatically and\nmusically, we can create a better understanding of what parameters are\nnecessary for a generated composition nearly indistinguishable from that of a\nmaster composer.", "published": "2021-01-01 05:40:12", "link": "http://arxiv.org/abs/2101.00169v3", "categories": ["cs.SD", "cs.LG", "cs.NE", "eess.AS", "I.2; I.5; I.7; J.5"], "primary_category": "cs.SD"}
{"title": "A Survey on Deep Reinforcement Learning for Audio-Based Applications", "abstract": "Deep reinforcement learning (DRL) is poised to revolutionise the field of\nartificial intelligence (AI) by endowing autonomous systems with high levels of\nunderstanding of the real world. Currently, deep learning (DL) is enabling DRL\nto effectively solve various intractable problems in various fields. Most\nimportantly, DRL algorithms are also being employed in audio signal processing\nto learn directly from speech, music and other sound signals in order to create\naudio-based autonomous systems that have many promising application in the real\nworld. In this article, we conduct a comprehensive survey on the progress of\nDRL in the audio domain by bringing together the research studies across\ndifferent speech and music-related areas. We begin with an introduction to the\ngeneral field of DL and reinforcement learning (RL), then progress to the main\nDRL methods and their applications in the audio domain. We conclude by\npresenting challenges faced by audio-based DRL agents and highlighting open\nareas for future research and investigation.", "published": "2021-01-01 14:15:20", "link": "http://arxiv.org/abs/2101.00240v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
