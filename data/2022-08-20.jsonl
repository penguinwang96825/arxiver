{"title": "General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase\n  Generation", "abstract": "Training keyphrase generation (KPG) models require a large amount of\nannotated data, which can be prohibitively expensive and often limited to\nspecific domains. In this study, we first demonstrate that large distribution\nshifts among different domains severely hinder the transferability of KPG\nmodels. We then propose a three-stage pipeline, which gradually guides KPG\nmodels' learning focus from general syntactical features to domain-related\nsemantics, in a data-efficient manner. With Domain-general Phrase pre-training,\nwe pre-train Sequence-to-Sequence models with generic phrase annotations that\nare widely available on the web, which enables the models to generate phrases\nin a wide range of domains. The resulting model is then applied in the Transfer\nLabeling stage to produce domain-specific pseudo keyphrases, which help adapt\nmodels to a new domain. Finally, we fine-tune the model with limited data with\ntrue labels to fully adapt it to the target domain. Our experiment results show\nthat the proposed process can produce good-quality keyphrases in new domains\nand achieve consistent improvements after adaptation with limited in-domain\nannotated data. All code and datasets are available at\nhttps://github.com/memray/OpenNMT-kpg-release.", "published": "2022-08-20 04:43:01", "link": "http://arxiv.org/abs/2208.09606v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pretrained Language Encoders are Natural Tagging Frameworks for Aspect\n  Sentiment Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract the spans of\naspect, opinion, and their sentiment relations as sentiment triplets. Existing\nworks usually formulate the span detection as a 1D token tagging problem, and\nmodel the sentiment recognition with a 2D tagging matrix of token pairs.\nMoreover, by leveraging the token representation of Pretrained Language\nEncoders (PLEs) like BERT, they can achieve better performance. However, they\nsimply leverage PLEs as feature extractors to build their modules but never\nhave a deep look at what specific knowledge does PLEs contain. In this paper,\nwe argue that instead of further designing modules to capture the inductive\nbias of ASTE, PLEs themselves contain \"enough\" features for 1D and 2D tagging:\n(1) The token representation contains the contextualized meaning of token\nitself, so this level feature carries necessary information for 1D tagging. (2)\nThe attention matrix of different PLE layers can further capture multi-level\nlinguistic knowledge existing in token pairs, which benefits 2D tagging. (3)\nFurthermore, with simple transformations, these two features can also be easily\nconverted to the 2D tagging matrix and 1D tagging sequence, respectively. That\nwill further boost the tagging results. By doing so, PLEs can be natural\ntagging frameworks and achieve a new state of the art, which is verified by\nextensive experiments and deep analyses.", "published": "2022-08-20 06:40:45", "link": "http://arxiv.org/abs/2208.09617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Context? On the Sense-wise Variance of Contextualized Word\n  Embeddings", "abstract": "Contextualized word embeddings in language models have given much advance to\nNLP. Intuitively, sentential information is integrated into the representation\nof words, which can help model polysemy. However, context sensitivity also\nleads to the variance of representations, which may break the semantic\nconsistency for synonyms. We quantify how much the contextualized embeddings of\neach word sense vary across contexts in typical pre-trained models. Results\nshow that contextualized embeddings can be highly consistent across contexts.\nIn addition, part-of-speech, number of word senses, and sentence length have an\ninfluence on the variance of sense representations. Interestingly, we find that\nword representations are position-biased, where the first words in different\ncontexts tend to be more similar. We analyze such a phenomenon and also propose\na simple way to alleviate such bias in distance-based word sense disambiguation\nsettings.", "published": "2022-08-20 12:27:25", "link": "http://arxiv.org/abs/2208.09669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining Compressions for Multiplicative Size Scaling on Natural\n  Language Tasks", "abstract": "Quantization, knowledge distillation, and magnitude pruning are among the\nmost popular methods for neural network compression in NLP. Independently,\nthese methods reduce model size and can accelerate inference, but their\nrelative benefit and combinatorial interactions have not been rigorously\nstudied. For each of the eight possible subsets of these techniques, we compare\naccuracy vs. model size tradeoffs across six BERT architecture sizes and eight\nGLUE tasks. We find that quantization and distillation consistently provide\ngreater benefit than pruning. Surprisingly, except for the pair of pruning and\nquantization, using multiple methods together rarely yields diminishing\nreturns. Instead, we observe complementary and super-multiplicative reductions\nto model size. Our work quantitatively demonstrates that combining compression\nmethods can synergistically reduce model size, and that practitioners should\nprioritize (1) quantization, (2) knowledge distillation, and (3) pruning to\nmaximize accuracy vs. model size tradeoffs.", "published": "2022-08-20 14:01:56", "link": "http://arxiv.org/abs/2208.09684v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Judge a Sentence by Its Content to Generate Grammatical Errors", "abstract": "Data sparsity is a well-known problem for grammatical error correction (GEC).\nGenerating synthetic training data is one widely proposed solution to this\nproblem, and has allowed models to achieve state-of-the-art (SOTA) performance\nin recent years. However, these methods often generate unrealistic errors, or\naim to generate sentences with only one error. We propose a learning based two\nstage method for synthetic data generation for GEC that relaxes this constraint\non sentences containing only one error. Errors are generated in accordance with\nsentence merit. We show that a GEC model trained on our synthetically generated\ncorpus outperforms models trained on synthetic data from prior work.", "published": "2022-08-20 14:31:34", "link": "http://arxiv.org/abs/2208.09693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "gBuilder: A Scalable Knowledge Graph Construction System for\n  Unstructured Corpus", "abstract": "We design a user-friendly and scalable knowledge graph construction (KGC)\nsystem for extracting structured knowledge from the unstructured corpus.\nDifferent from existing KGC systems, gBuilder provides a flexible and\nuser-defined pipeline to embrace the rapid development of IE models. More\nbuilt-in template-based or heuristic operators and programmable operators are\navailable for adapting to data from different domains. Furthermore, we also\ndesign a cloud-based self-adaptive task scheduling for gBuilder to ensure its\nscalability on large-scale knowledge graph construction. Experimental\nevaluation demonstrates the ability of gBuilder to organize multiple\ninformation extraction models for knowledge graph construction in a uniform\nplatform, and confirms its high scalability on large-scale KGC tasks.", "published": "2022-08-20 15:07:06", "link": "http://arxiv.org/abs/2208.09705v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BSpell: A CNN-Blended BERT Based Bangla Spell Checker", "abstract": "Bangla typing is mostly performed using English keyboard and can be highly\nerroneous due to the presence of compound and similarly pronounced letters.\nSpelling correction of a misspelled word requires understanding of word typing\npattern as well as the context of the word usage. A specialized BERT model\nnamed BSpell has been proposed in this paper targeted towards word for word\ncorrection in sentence level. BSpell contains an end-to-end trainable CNN\nsub-model named SemanticNet along with specialized auxiliary loss. This allows\nBSpell to specialize in highly inflected Bangla vocabulary in the presence of\nspelling errors. Furthermore, a hybrid pretraining scheme has been proposed for\nBSpell that combines word level and character level masking. Comparison on two\nBangla and one Hindi spelling correction dataset shows the superiority of our\nproposed approach. BSpell is available as a Bangla spell checking tool via\nGitHub: https://github.com/Hasiburshanto/Bangla-Spell-Checker", "published": "2022-08-20 15:21:35", "link": "http://arxiv.org/abs/2208.09709v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Multi-Encoder Fusion Strategies to Improve Personalized Response\n  Selection", "abstract": "Personalized response selection systems are generally grounded on persona.\nHowever, there exists a co-relation between persona and empathy, which is not\nexplored well in these systems. Also, faithfulness to the conversation context\nplunges when a contradictory or an off-topic response is selected. This paper\nattempts to address these issues by proposing a suite of fusion strategies that\ncapture the interaction between persona, emotion, and entailment information of\nthe utterances. Ablation studies on the Persona-Chat dataset show that\nincorporating emotion and entailment improves the accuracy of response\nselection. We combine our fusion strategies and concept-flow encoding to train\na BERT-based model which outperforms the previous methods by margins larger\nthan 2.3 % on original personas and 1.9 % on revised personas in terms of\nhits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the\nPersona-Chat dataset.", "published": "2022-08-20 04:13:27", "link": "http://arxiv.org/abs/2208.09601v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPOT: Knowledge-Enhanced Language Representations for Information\n  Extraction", "abstract": "Knowledge-enhanced pre-trained models for language representation have been\nshown to be more effective in knowledge base construction tasks (i.e.,~relation\nextraction) than language models such as BERT. These knowledge-enhanced\nlanguage models incorporate knowledge into pre-training to generate\nrepresentations of entities or relationships. However, existing methods\ntypically represent each entity with a separate embedding. As a result, these\nmethods struggle to represent out-of-vocabulary entities and a large amount of\nparameters, on top of their underlying token models (i.e.,~the transformer),\nmust be used and the number of entities that can be handled is limited in\npractice due to memory constraints. Moreover, existing models still struggle to\nrepresent entities and relationships simultaneously. To address these problems,\nwe propose a new pre-trained model that learns representations of both entities\nand relationships from token spans and span pairs in the text respectively. By\nencoding spans efficiently with span modules, our model can represent both\nentities and their relationships but requires fewer parameters than existing\nmodels. We pre-trained our model with the knowledge graph extracted from\nWikipedia and test it on a broad range of supervised and unsupervised\ninformation extraction tasks. Results show that our model learns better\nrepresentations for both entities and relationships than baselines, while in\nsupervised settings, fine-tuning our model outperforms RoBERTa consistently and\nachieves competitive results on information extraction tasks.", "published": "2022-08-20 07:32:25", "link": "http://arxiv.org/abs/2208.09625v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Persuasion Strategies in Advertisements", "abstract": "Modeling what makes an advertisement persuasive, i.e., eliciting the desired\nresponse from consumer, is critical to the study of propaganda, social\npsychology, and marketing. Despite its importance, computational modeling of\npersuasion in computer vision is still in its infancy, primarily due to the\nlack of benchmark datasets that can provide persuasion-strategy labels\nassociated with ads. Motivated by persuasion literature in social psychology\nand marketing, we introduce an extensive vocabulary of persuasion strategies\nand build the first ad image corpus annotated with persuasion strategies. We\nthen formulate the task of persuasion strategy prediction with multi-modal\nlearning, where we design a multi-task attention fusion model that can leverage\nother ad-understanding tasks to predict persuasion strategies. Further, we\nconduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500\ncompanies where we use our model's predictions to analyze which strategies work\nwith different demographics (age and gender). The dataset also provides image\nsegmentation masks, which labels persuasion strategies in the corresponding ad\nimages on the test split. We publicly release our code and dataset\nhttps://midas-research.github.io/persuasion-advertisements/.", "published": "2022-08-20 07:33:13", "link": "http://arxiv.org/abs/2208.09626v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Wolfies at SemEval-2022 Task 8: Feature extraction pipeline with\n  transformers for Multi-lingual news article similarity", "abstract": "This work is about finding the similarity between a pair of news articles.\nThere are seven different objective similarity metrics provided in the dataset\nfor each pair and the news articles are in multiple different languages. On top\nof the pre-trained embedding model, we calculated cosine similarity for\nbaseline results and feed-forward neural network was then trained on top of it\nto improve the results. We also built separate pipelines for each similarity\nmetric for feature extraction. We could see significant improvement from\nbaseline results using feature extraction and feed-forward neural network.", "published": "2022-08-20 16:06:53", "link": "http://arxiv.org/abs/2208.09715v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cognitive Modeling of Semantic Fluency Using Transformers", "abstract": "Can deep language models be explanatory models of human cognition? If so,\nwhat are their limits? In order to explore this question, we propose an\napproach called hyperparameter hypothesization that uses predictive\nhyperparameter tuning in order to find individuating descriptors of\ncognitive-behavioral profiles. We take the first step in this approach by\npredicting human performance in the semantic fluency task (SFT), a well-studied\ntask in cognitive science that has never before been modeled using\ntransformer-based language models (TLMs). In our task setup, we compare several\napproaches to predicting which word an individual performing SFT will utter\nnext. We report preliminary evidence suggesting that, despite obvious\nimplementational differences in how people and TLMs learn and use language,\nTLMs can be used to identify individual differences in human fluency task\nbehaviors better than existing computational models, and may offer insights\ninto human memory retrieval strategies -- cognitive process not typically\nconsidered to be the kinds of things TLMs can model. Finally, we discuss the\nimplications of this work for cognitive modeling of knowledge representations.", "published": "2022-08-20 16:48:04", "link": "http://arxiv.org/abs/2208.09719v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Domain Adaptation for Early Misinformation Detection: A Case\n  Study on COVID-19", "abstract": "Despite recent progress in improving the performance of misinformation\ndetection systems, classifying misinformation in an unseen domain remains an\nelusive challenge. To address this issue, a common approach is to introduce a\ndomain critic and encourage domain-invariant input features. However, early\nmisinformation often demonstrates both conditional and label shifts against\nexisting misinformation data (e.g., class imbalance in COVID-19 datasets),\nrendering such methods less effective for detecting early misinformation. In\nthis paper, we propose contrastive adaptation network for early misinformation\ndetection (CANMD). Specifically, we leverage pseudo labeling to generate\nhigh-confidence target examples for joint training with source data. We\nadditionally design a label correction component to estimate and correct the\nlabel shifts (i.e., class priors) between the source and target domains.\nMoreover, a contrastive adaptation loss is integrated in the objective function\nto reduce the intra-class discrepancy and enlarge the inter-class discrepancy.\nAs such, the adapted model learns corrected class priors and an invariant\nconditional distribution across both domains for improved estimation of the\ntarget data distribution. To demonstrate the effectiveness of the proposed\nCANMD, we study the case of COVID-19 early misinformation detection and perform\nextensive experiments using multiple real-world datasets. The results suggest\nthat CANMD can effectively adapt misinformation detection systems to the unseen\nCOVID-19 target domain with significant improvements compared to the\nstate-of-the-art baselines.", "published": "2022-08-20 02:09:35", "link": "http://arxiv.org/abs/2208.09578v4", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Trigger-free Event Detection via Derangement Reading Comprehension", "abstract": "Event detection (ED), aiming to detect events from texts and categorize them,\nis vital to understanding actual happenings in real life. However, mainstream\nevent detection models require high-quality expert human annotations of\ntriggers, which are often costly and thus deter the application of ED to new\ndomains. Therefore, in this paper, we focus on low-resource ED without triggers\nand aim to tackle the following formidable challenges: multi-label\nclassification, insufficient clues, and imbalanced events distribution. We\npropose a novel trigger-free ED method via Derangement mechanism on a machine\nReading Comprehension (DRC) framework. More specifically, we treat the input\ntext as Context and concatenate it with all event type tokens that are deemed\nas Answers with an omitted default question. So we can leverage the\nself-attention in pre-trained language models to absorb semantic relations\nbetween input text and the event types. Moreover, we design a simple yet\neffective event derangement module (EDM) to prevent major events from being\nexcessively learned so as to yield a more balanced training process. The\nexperiment results show that our proposed trigger-free ED model is remarkably\ncompetitive to mainstream trigger-based models, showing its strong performance\non low-source event detection.", "published": "2022-08-20 11:01:39", "link": "http://arxiv.org/abs/2208.09659v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition\n  using a Novel Transformers-based Model and an Innovative 270 Million-Words\n  Multi-Font Corpus of Classical Arabic with Diacritics", "abstract": "This research is the second phase in a series of investigations on developing\nan Optical Character Recognition (OCR) of Arabic historical documents and\nexamining how different modeling procedures interact with the problem. The\nfirst research studied the effect of Transformers on our custom-built Arabic\ndataset. One of the downsides of the first research was the size of the\ntraining data, a mere 15000 images from our 30 million images, due to lack of\nresources. Also, we add an image enhancement layer, time and space\noptimization, and Post-Correction layer to aid the model in predicting the\ncorrect word for the correct context. Notably, we propose an end-to-end text\nrecognition approach using Vision Transformers as an encoder, namely BEIT, and\nvanilla Transformer as a decoder, eliminating CNNs for feature extraction and\nreducing the model's complexity. The experiments show that our end-to-end model\noutperforms Convolutions Backbones. The model attained a CER of 4.46%.", "published": "2022-08-20 22:21:19", "link": "http://arxiv.org/abs/2208.11484v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Fully Automated End-to-End Fake Audio Detection", "abstract": "The existing fake audio detection systems often rely on expert experience to\ndesign the acoustic features or manually design the hyperparameters of the\nnetwork structure. However, artificial adjustment of the parameters can have a\nrelatively obvious influence on the results. It is almost impossible to\nmanually set the best set of parameters. Therefore this paper proposes a fully\nautomated end-toend fake audio detection method. We first use wav2vec\npre-trained model to obtain a high-level representation of the speech.\nFurthermore, for the network structure, we use a modified version of the\ndifferentiable architecture search (DARTS) named light-DARTS. It learns deep\nspeech representations while automatically learning and optimizing complex\nneural structures consisting of convolutional operations and residual blocks.\nThe experimental results on the ASVspoof 2019 LA dataset show that our proposed\nsystem achieves an equal error rate (EER) of 1.08%, which outperforms the\nstate-of-the-art single system.", "published": "2022-08-20 06:46:55", "link": "http://arxiv.org/abs/2208.09618v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Initial Investigation for Detecting Vocoder Fingerprints of Fake\n  Audio", "abstract": "Many effective attempts have been made for fake audio detection. However,\nthey can only provide detection results but no countermeasures to curb this\nharm. For many related practical applications, what model or algorithm\ngenerated the fake audio also is needed. Therefore, We propose a new problem\nfor detecting vocoder fingerprints of fake audio. Experiments are conducted on\nthe datasets synthesized by eight state-of-the-art vocoders. We have\npreliminarily explored the features and model architectures. The t-SNE\nvisualization shows that different vocoders generate distinct vocoder\nfingerprints.", "published": "2022-08-20 09:23:21", "link": "http://arxiv.org/abs/2208.09646v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
