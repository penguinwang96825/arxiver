{"title": "Handling Homographs in Neural Machine Translation", "abstract": "Homographs, words with different meanings but the same surface form, have\nlong caused difficulty for machine translation systems, as it is difficult to\nselect the correct translation based on the context. However, with the advent\nof neural machine translation (NMT) systems, which can theoretically take into\naccount global sentential context, one may hypothesize that this problem has\nbeen alleviated. In this paper, we first provide empirical evidence that\nexisting NMT systems in fact still have significant problems in properly\ntranslating ambiguous words. We then proceed to describe methods, inspired by\nthe word sense disambiguation literature, that model the context of the input\nword with context-aware word embeddings that help to differentiate the word\nsense be- fore feeding it into the encoder. Experiments on three language pairs\ndemonstrate that such models improve the performance of NMT systems both in\nterms of BLEU score and in the accuracy of translating homographs.", "published": "2017-08-22 06:48:27", "link": "http://arxiv.org/abs/1708.06510v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Golden Years, Golden Shores: A Study of Elders in Online Travel\n  Communities", "abstract": "In this paper we present our exploratory findings related to extracting\nknowledge and experiences from a community of senior tourists. By using tools\nof qualitative analysis as well as review of literature, we managed to verify a\nset of hypotheses related to the content created by senior tourists when\nparticipating in on-line communities. We also produced a codebook, representing\nvarious themes one may encounter in such communities. This codebook, derived\nfrom our own qualitative research, as well a literature review will serve as a\nbasis for further development of automated tools of knowledge extraction. We\nalso managed to find that older adults more often than other poster in tourists\nforums, mention their age in discussion, more often share their experiences and\nmotivation to travel, however they do not differ in relation to describing\nbarriers encountered while traveling.", "published": "2017-08-22 09:39:29", "link": "http://arxiv.org/abs/1708.06550v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Long-Short Range Context Neural Networks for Language Modeling", "abstract": "The goal of language modeling techniques is to capture the statistical and\nstructural properties of natural languages from training corpora. This task\ntypically involves the learning of short range dependencies, which generally\nmodel the syntactic properties of a language and/or long range dependencies,\nwhich are semantic in nature. We propose in this paper a new multi-span\narchitecture, which separately models the short and long context information\nwhile it dynamically merges them to perform the language modeling task. This is\ndone through a novel recurrent Long-Short Range Context (LSRC) network, which\nexplicitly models the local (short) and global (long) context using two\nseparate hidden states that evolve in time. This new architecture is an\nadaptation of the Long-Short Term Memory network (LSTM) to take into account\nthe linguistic properties. Extensive experiments conducted on the Penn Treebank\n(PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a\nsignificant reduction of the perplexity when compared to state-of-the-art\nlanguage modeling techniques.", "published": "2017-08-22 10:26:41", "link": "http://arxiv.org/abs/1708.06555v1", "categories": ["cs.CL", "cs.LG", "97K50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Classification of Radiology Reports Using Neural Attention Models", "abstract": "The electronic health record (EHR) contains a large amount of\nmulti-dimensional and unstructured clinical data of significant operational and\nresearch value. Distinguished from previous studies, our approach embraces a\ndouble-annotated dataset and strays away from obscure \"black-box\" models to\ncomprehensive deep learning models. In this paper, we present a novel neural\nattention mechanism that not only classifies clinically important findings.\nSpecifically, convolutional neural networks (CNN) with attention analysis are\nused to classify radiology head computed tomography reports based on five\ncategories that radiologists would account for in assessing acute and\ncommunicable findings in daily practice. The experiments show that our CNN\nattention models outperform non-neural models, especially when trained on a\nlarger dataset. Our attention analysis demonstrates the intuition behind the\nclassifier's decision by generating a heatmap that highlights attended terms\nused by the CNN model; this is valuable when potential downstream medical\ndecisions are to be performed by human experts or the classifier information is\nto be used in cohort construction such as for epidemiological studies.", "published": "2017-08-22 21:30:23", "link": "http://arxiv.org/abs/1708.06828v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
