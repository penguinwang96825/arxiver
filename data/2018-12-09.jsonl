{"title": "Dialogue Generation: From Imitation Learning to Inverse Reinforcement\n  Learning", "abstract": "The performance of adversarial dialogue generation models relies on the\nquality of the reward signal produced by the discriminator. The reward signal\nfrom a poor discriminator can be very sparse and unstable, which may lead the\ngenerator to fall into a local optimum or to produce nonsense replies. To\nalleviate the first problem, we first extend a recently proposed adversarial\ndialogue generation method to an adversarial imitation learning solution. Then,\nin the framework of adversarial inverse reinforcement learning, we propose a\nnew reward model for dialogue generation that can provide a more accurate and\nprecise reward signal for generator training. We evaluate the performance of\nthe resulting model with automatic metrics and human evaluations in two\nannotation settings. Our experimental results demonstrate that our model can\ngenerate more high-quality responses and achieve higher overall performance\nthan the state-of-the-art.", "published": "2018-12-09 16:05:43", "link": "http://arxiv.org/abs/1812.03509v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep-Net: Deep Neural Network for Cyber Security Use Cases", "abstract": "Deep neural networks (DNNs) have witnessed as a powerful approach in this\nyear by solving long-standing Artificial intelligence (AI) supervised and\nunsupervised tasks exists in natural language processing, speech processing,\ncomputer vision and others. In this paper, we attempt to apply DNNs on three\ndifferent cyber security use cases: Android malware classification, incident\ndetection and fraud detection. The data set of each use case contains real\nknown benign and malicious activities samples. The efficient network\narchitecture for DNN is chosen by conducting various trails of experiments for\nnetwork parameters and network structures. The experiments of such chosen\nefficient configurations of DNNs are run up to 1000 epochs with learning rate\nset in the range [0.01-0.5]. Experiments of DNN performed well in comparison to\nthe classical machine learning algorithms in all cases of experiments of cyber\nsecurity use cases. This is due to the fact that DNNs implicitly extract and\nbuild better features, identifies the characteristics of the data that lead to\nbetter accuracy. The best accuracy obtained by DNN and XGBoost on Android\nmalware classification 0.940 and 0.741, incident detection 1.00 and 0.997 fraud\ndetection 0.972 and 0.916 respectively.", "published": "2018-12-09 16:44:56", "link": "http://arxiv.org/abs/1812.03519v1", "categories": ["cs.LG", "cs.CL", "cs.CR", "68T50"], "primary_category": "cs.LG"}
{"title": "To Reverse the Gradient or Not: An Empirical Comparison of Adversarial\n  and Multi-task Learning in Speech Recognition", "abstract": "Transcribed datasets typically contain speaker identity for each instance in\nthe data. We investigate two ways to incorporate this information during\ntraining: Multi-Task Learning and Adversarial Learning. In multi-task learning,\nthe goal is speaker prediction; we expect a performance improvement with this\njoint training if the two tasks of speech recognition and speaker recognition\nshare a common set of underlying features. In contrast, adversarial learning is\na means to learn representations invariant to the speaker. We then expect\nbetter performance if this learnt invariance helps generalizing to new\nspeakers. While the two approaches seem natural in the context of speech\nrecognition, they are incompatible because they correspond to opposite\ngradients back-propagated to the model. In order to better understand the\neffect of these approaches in terms of error rates, we compare both strategies\nin controlled settings. Moreover, we explore the use of additional\nuntranscribed data in a semi-supervised, adversarial learning manner to improve\nerror rates. Our results show that deep models trained on big datasets already\ndevelop invariant representations to speakers without any auxiliary loss. When\nconsidering adversarial learning and multi-task learning, the impact on the\nacoustic model seems minor. However, models trained in a semi-supervised manner\ncan improve error-rates.", "published": "2018-12-09 13:18:02", "link": "http://arxiv.org/abs/1812.03483v3", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Increase Apparent Public Speaking Fluency By Speech Augmentation", "abstract": "Fluent and confident speech is desirable to every speaker. But professional\nspeech delivering requires a great deal of experience and practice. In this\npaper, we propose a speech stream manipulation system which can help\nnon-professional speakers to produce fluent, professional-like speech content,\nin turn contributing towards better listener engagement and comprehension. We\npropose to achieve this task by manipulating the disfluencies in human speech,\nlike the sounds 'uh' and 'um', the filler words and awkward long silences.\nGiven any unrehearsed speech we segment and silence the filled pauses and\ndoctor the duration of imposed silence as well as other long pauses\n('disfluent') by a predictive model learned using professional speech dataset.\nFinally, we output a audio stream in which speaker sounds more fluent,\nconfident and practiced compared to the original speech he/she recorded.\nAccording to our quantitative evaluation, we significantly increase the fluency\nof speech by reducing rate of pauses and fillers.", "published": "2018-12-09 02:19:39", "link": "http://arxiv.org/abs/1812.03415v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
