{"title": "Unsupervised Measure of Word Similarity: How to Outperform Co-occurrence\n  and Vector Cosine in VSMs", "abstract": "In this paper, we claim that vector cosine, which is generally considered\namong the most efficient unsupervised measures for identifying word similarity\nin Vector Space Models, can be outperformed by an unsupervised measure that\ncalculates the extent of the intersection among the most mutually dependent\ncontexts of the target words. To prove it, we describe and evaluate APSyn, a\nvariant of the Average Precision that, without any optimization, outperforms\nthe vector cosine and the co-occurrence on the standard ESL test set, with an\nimprovement ranging between +9.00% and +17.98%, depending on the number of\nchosen top contexts.", "published": "2016-03-30 07:05:45", "link": "http://arxiv.org/abs/1603.09054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Visual Sense Disambiguation for Verbs using Multimodal\n  Embeddings", "abstract": "We introduce a new task, visual sense disambiguation for verbs: given an\nimage and a verb, assign the correct sense of the verb, i.e., the one that\ndescribes the action depicted in the image. Just as textual word sense\ndisambiguation is useful for a wide range of NLP tasks, visual sense\ndisambiguation can be useful for multimodal tasks such as image retrieval,\nimage description, and text illustration. We introduce VerSe, a new dataset\nthat augments existing multimodal datasets (COCO and TUHOI) with sense labels.\nWe propose an unsupervised algorithm based on Lesk which performs visual sense\ndisambiguation using textual, visual, or multimodal embeddings. We find that\ntextual embeddings perform well when gold-standard textual annotations (object\nlabels and image descriptions) are available, while multimodal embeddings\nperform well on unannotated images. We also verify our findings by using the\ntextual and multimodal embeddings as features in a supervised setting and\nanalyse the performance of visual sense disambiguation task. VerSe is made\npublicly available and can be downloaded at:\nhttps://github.com/spandanagella/verse.", "published": "2016-03-30 13:43:38", "link": "http://arxiv.org/abs/1603.09188v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Bilingual Learning of Multi-sense Embeddings with Discrete Autoencoders", "abstract": "We present an approach to learning multi-sense word embeddings relying both\non monolingual and bilingual information. Our model consists of an encoder,\nwhich uses monolingual and bilingual context (i.e. a parallel sentence) to\nchoose a sense for a given word, and a decoder which predicts context words\nbased on the chosen sense. The two components are estimated jointly. We observe\nthat the word representations induced from bilingual data outperform the\nmonolingual counterparts across a range of evaluation tasks, even though\ncrosslingual information is not available at test time.", "published": "2016-03-30 11:09:01", "link": "http://arxiv.org/abs/1603.09128v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Model Interpolation with Trans-dimensional Random Field Language Models\n  for Speech Recognition", "abstract": "The dominant language models (LMs) such as n-gram and neural network (NN)\nmodels represent sentence probabilities in terms of conditionals. In contrast,\na new trans-dimensional random field (TRF) LM has been recently introduced to\nshow superior performances, where the whole sentence is modeled as a random\nfield. In this paper, we examine how the TRF models can be interpolated with\nthe NN models, and obtain 12.1\\% and 17.9\\% relative error rate reductions over\n6-gram LMs for English and Chinese speech recognition respectively through\nlog-linear combination.", "published": "2016-03-30 13:09:20", "link": "http://arxiv.org/abs/1603.09170v5", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Clinical Information Extraction via Convolutional Neural Network", "abstract": "We report an implementation of a clinical information extraction tool that\nleverages deep neural network to annotate event spans and their attributes from\nraw clinical notes and pathology reports. Our approach uses context words and\ntheir part-of-speech tags and shape information as features. Then we hire\ntemporal (1D) convolutional neural network to learn hidden feature\nrepresentations. Finally, we use Multilayer Perceptron (MLP) to predict event\nspans. The empirical evaluation demonstrates that our approach significantly\noutperforms baselines.", "published": "2016-03-30 20:57:07", "link": "http://arxiv.org/abs/1603.09381v1", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Enhancing Sentence Relation Modeling with Auxiliary Character-level\n  Embedding", "abstract": "Neural network based approaches for sentence relation modeling automatically\ngenerate hidden matching features from raw sentence pairs. However, the quality\nof matching feature representation may not be satisfied due to complex semantic\nrelations such as entailment or contradiction. To address this challenge, we\npropose a new deep neural network architecture that jointly leverage\npre-trained word embedding and auxiliary character embedding to learn sentence\nmeanings. The two kinds of word sequence representations as inputs into\nmulti-layer bidirectional LSTM to learn enhanced sentence representation. After\nthat, we construct matching features followed by another temporal CNN to learn\nhigh-level hidden matching feature representations. Experimental results\ndemonstrate that our approach consistently outperforms the existing methods on\nstandard evaluation datasets.", "published": "2016-03-30 22:39:59", "link": "http://arxiv.org/abs/1603.09405v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
