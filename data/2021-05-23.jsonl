{"title": "Automatic Product Ontology Extraction from Textual Reviews", "abstract": "Ontologies have proven beneficial in different settings that make use of\ntextual reviews. However, manually constructing ontologies is a laborious and\ntime-consuming process in need of automation. We propose a novel methodology\nfor automatically extracting ontologies, in the form of meronomies, from\nproduct reviews, using a very limited amount of hand-annotated training data.\nWe show that the ontologies generated by our method outperform hand-crafted\nontologies (WordNet) and ontologies extracted by existing methods (Text2Onto\nand COMET) in several, diverse settings. Specifically, our generated ontologies\noutperform the others when evaluated by human annotators as well as on an\nexisting Q&A dataset from Amazon. Moreover, our method is better able to\ngeneralise, in capturing knowledge about unseen products. Finally, we consider\na real-world setting, showing that our method is better able to determine\nrecommended products based on their reviews, in alternative to using Amazon's\nstandard score aggregations.", "published": "2021-05-23 16:06:38", "link": "http://arxiv.org/abs/2105.10966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RST Parsing from Scratch", "abstract": "We introduce a novel top-down end-to-end formulation of document-level\ndiscourse parsing in the Rhetorical Structure Theory (RST) framework. In this\nformulation, we consider discourse parsing as a sequence of splitting decisions\nat token boundaries and use a seq2seq network to model the splitting decisions.\nOur framework facilitates discourse parsing from scratch without requiring\ndiscourse segmentation as a prerequisite; rather, it yields segmentation as\npart of the parsing process. Our unified parsing model adopts a beam search to\ndecode the best tree structure by searching through a space of high-scoring\ntrees. With extensive experiments on the standard English RST discourse\ntreebank, we demonstrate that our parser outperforms existing methods by a good\nmargin in both end-to-end parsing and parsing with gold segmentation. More\nimportantly, it does so without using any handcrafted features, making it\nfaster and easily adaptable to new languages and domains.", "published": "2021-05-23 06:19:38", "link": "http://arxiv.org/abs/2105.10861v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Structural Pre-training for Dialogue Comprehension", "abstract": "Pre-trained language models (PrLMs) have demonstrated superior performance\ndue to their strong ability to learn universal language representations from\nself-supervised pre-training. However, even with the help of the powerful\nPrLMs, it is still challenging to effectively capture task-related knowledge\nfrom dialogue texts which are enriched by correlations among speaker-aware\nutterances. In this work, we present SPIDER, Structural Pre-traIned DialoguE\nReader, to capture dialogue exclusive features. To simulate the dialogue-like\nfeatures, we propose two training objectives in addition to the original LM\nobjectives: 1) utterance order restoration, which predicts the order of the\npermuted utterances in dialogue context; 2) sentence backbone regularization,\nwhich regularizes the model to improve the factual correctness of summarized\nsubject-verb-object triplets. Experimental results on widely used dialogue\nbenchmarks verify the effectiveness of the newly introduced self-supervised\ntasks.", "published": "2021-05-23 15:16:54", "link": "http://arxiv.org/abs/2105.10956v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DepressionNet: A Novel Summarization Boosted Deep Framework for\n  Depression Detection on Social Media", "abstract": "Twitter is currently a popular online social media platform which allows\nusers to share their user-generated content. This publicly-generated user data\nis also crucial to healthcare technologies because the discovered patterns\nwould hugely benefit them in several ways. One of the applications is in\nautomatically discovering mental health problems, e.g., depression. Previous\nstudies to automatically detect a depressed user on online social media have\nlargely relied upon the user behaviour and their linguistic patterns including\nuser's social interactions. The downside is that these models are trained on\nseveral irrelevant content which might not be crucial towards detecting a\ndepressed user. Besides, these content have a negative impact on the overall\nefficiency and effectiveness of the model. To overcome the shortcomings in the\nexisting automatic depression detection methods, we propose a novel\ncomputational framework for automatic depression detection that initially\nselects relevant content through a hybrid extractive and abstractive\nsummarization strategy on the sequence of all user tweets leading to a more\nfine-grained and relevant content. The content then goes to our novel deep\nlearning framework comprising of a unified learning machinery comprising of\nConvolutional Neural Network (CNN) coupled with attention-enhanced Gated\nRecurrent Units (GRU) models leading to better empirical performance than\nexisting strong baselines.", "published": "2021-05-23 08:05:53", "link": "http://arxiv.org/abs/2105.10878v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Killing One Bird with Two Stones: Model Extraction and Attribute\n  Inference Attacks against BERT-based APIs", "abstract": "The collection and availability of big data, combined with advances in\npre-trained models (e.g., BERT, XLNET, etc), have revolutionized the predictive\nperformance of modern natural language processing tasks, ranging from text\nclassification to text generation. This allows corporations to provide machine\nlearning as a service (MLaaS) by encapsulating fine-tuned BERT-based models as\nAPIs. However, BERT-based APIs have exhibited a series of security and privacy\nvulnerabilities. For example, prior work has exploited the security issues of\nthe BERT-based APIs through the adversarial examples crafted by the extracted\nmodel. However, the privacy leakage problems of the BERT-based APIs through the\nextracted model have not been well studied. On the other hand, due to the high\ncapacity of BERT-based APIs, the fine-tuned model is easy to be overlearned,\nbut what kind of information can be leaked from the extracted model remains\nunknown. In this work, we bridge this gap by first presenting an effective\nmodel extraction attack, where the adversary can practically steal a BERT-based\nAPI (the target/victim model) by only querying a limited number of queries. We\nfurther develop an effective attribute inference attack which can infer the\nsensitive attribute of the training data used by the BERT-based APIs. Our\nextensive experiments on benchmark datasets under various realistic settings\nvalidate the potential vulnerabilities of BERT-based APIs. Moreover, we\ndemonstrate that two promising defense methods become ineffective against our\nattacks, which calls for more effective defense methods.", "published": "2021-05-23 10:38:23", "link": "http://arxiv.org/abs/2105.10909v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "CiteWorth: Cite-Worthiness Detection for Improved Scientific Document\n  Understanding", "abstract": "Scientific document understanding is challenging as the data is highly domain\nspecific and diverse. However, datasets for tasks with scientific text require\nexpensive manual annotation and tend to be small and limited to only one or a\nfew fields. At the same time, scientific documents contain many potential\ntraining signals, such as citations, which can be used to build large labelled\ndatasets. Given this, we present an in-depth study of cite-worthiness detection\nin English, where a sentence is labelled for whether or not it cites an\nexternal source. To accomplish this, we introduce CiteWorth, a large,\ncontextualized, rigorously cleaned labelled dataset for cite-worthiness\ndetection built from a massive corpus of extracted plain-text scientific\ndocuments. We show that CiteWorth is high-quality, challenging, and suitable\nfor studying problems such as domain adaptation. Our best performing\ncite-worthiness detection model is a paragraph-level contextualized sentence\nlabelling model based on Longformer, exhibiting a 5 F1 point improvement over\nSciBERT which considers only individual sentences. Finally, we demonstrate that\nlanguage model fine-tuning with cite-worthiness as a secondary task leads to\nimproved performance on downstream scientific document understanding tasks.", "published": "2021-05-23 11:08:45", "link": "http://arxiv.org/abs/2105.10912v2", "categories": ["cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OntoED: Low-resource Event Detection with Ontology Embedding", "abstract": "Event Detection (ED) aims to identify event trigger words from a given text\nand classify it into an event type. Most of current methods to ED rely heavily\non training instances, and almost ignore the correlation of event types. Hence,\nthey tend to suffer from data scarcity and fail to handle new unseen event\ntypes. To address these problems, we formulate ED as a process of event\nontology population: linking event instances to pre-defined event types in\nevent ontology, and propose a novel ED framework entitled OntoED with ontology\nembedding. We enrich event ontology with linkages among event types, and\nfurther induce more event-event correlations. Based on the event ontology,\nOntoED can leverage and propagate correlation knowledge, particularly from\ndata-rich to data-poor event types. Furthermore, OntoED can be applied to new\nunseen event types, by establishing linkages to existing ones. Experiments\nindicate that OntoED is more predominant and robust than previous approaches to\nED, especially in data-scarce scenarios.", "published": "2021-05-23 12:00:22", "link": "http://arxiv.org/abs/2105.10922v4", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Controlling Text Edition by Changing Answers of Specific Questions", "abstract": "In this paper, we introduce the new task of controllable text edition, in\nwhich we take as input a long text, a question, and a target answer, and the\noutput is a minimally modified text, so that it fits the target answer. This\ntask is very important in many situations, such as changing some conditions,\nconsequences, or properties in a legal document, or changing some key\ninformation of an event in a news text. This is very challenging, as it is hard\nto obtain a parallel corpus for training, and we need to first find all text\npositions that should be changed and then decide how to change them. We\nconstructed the new dataset WikiBioCTE for this task based on the existing\ndataset WikiBio (originally created for table-to-text generation). We use\nWikiBioCTE for training, and manually labeled a test set for testing. We also\npropose novel evaluation metrics and a novel method for solving the new task.\nExperimental results on the test set show that our proposed method is a good\nfit for this novel NLP task.", "published": "2021-05-23 20:44:15", "link": "http://arxiv.org/abs/2105.11018v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
