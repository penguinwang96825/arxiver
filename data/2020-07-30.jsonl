{"title": "MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain\n  Question Answering", "abstract": "Progress in cross-lingual modeling depends on challenging, realistic, and\ndiverse evaluation sets. We introduce Multilingual Knowledge Questions and\nAnswers (MKQA), an open-domain question answering evaluation set comprising 10k\nquestion-answer pairs aligned across 26 typologically diverse languages (260k\nquestion-answer pairs in total). Answers are based on a heavily curated,\nlanguage-independent data representation, making results comparable across\nlanguages and independent of language-specific passages. With 26 languages,\nthis dataset supplies the widest range of languages to-date for evaluating\nquestion answering. We benchmark a variety of state-of-the-art methods and\nbaselines for generative and extractive question answering, trained on Natural\nQuestions, in zero shot and translation settings. Results indicate this dataset\nis challenging even in English, but especially in low-resource languages", "published": "2020-07-30 03:33:46", "link": "http://arxiv.org/abs/2007.15207v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leverage Unlabeled Data for Abstractive Speech Summarization with\n  Self-Supervised Learning and Back-Summarization", "abstract": "Supervised approaches for Neural Abstractive Summarization require large\nannotated corpora that are costly to build. We present a French meeting\nsummarization task where reports are predicted based on the automatic\ntranscription of the meeting audio recordings. In order to build a corpus for\nthis task, it is necessary to obtain the (automatic or manual) transcription of\neach meeting, and then to segment and align it with the corresponding manual\nreport to produce training examples suitable for training. On the other hand,\nwe have access to a very large amount of unaligned data, in particular reports\nwithout corresponding transcription. Reports are professionally written and\nwell formatted making pre-processing straightforward. In this context, we study\nhow to take advantage of this massive amount of unaligned data using two\napproaches (i) self-supervised pre-training using a target-side denoising\nencoder-decoder model; (ii) back-summarization i.e. reversing the summarization\nprocess by learning to predict the transcription given the report, in order to\nalign single reports with generated transcription, and use this synthetic\ndataset for further training. We report large improvements compared to the\nprevious baseline (trained on aligned data only) for both approaches on two\nevaluation sets. Moreover, combining the two gives even better results,\noutperforming the baseline by a large margin of +6 ROUGE-1 and ROUGE-L and +5\nROUGE-2 on two evaluation sets", "published": "2020-07-30 08:22:47", "link": "http://arxiv.org/abs/2007.15296v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Modeling for Named Entities and Morphology (NEMO^2)", "abstract": "Named Entity Recognition (NER) is a fundamental NLP task, commonly formulated\nas classification over a sequence of tokens. Morphologically-Rich Languages\n(MRLs) pose a challenge to this basic formulation, as the boundaries of Named\nEntities do not necessarily coincide with token boundaries, rather, they\nrespect morphological boundaries. To address NER in MRLs we then need to answer\ntwo fundamental questions, namely, what are the basic units to be labeled, and\nhow can these units be detected and classified in realistic settings, i.e.,\nwhere no gold morphology is available. We empirically investigate these\nquestions on a novel NER benchmark, with parallel tokenlevel and morpheme-level\nNER annotations, which we develop for Modern Hebrew, a morphologically\nrich-and-ambiguous language. Our results show that explicitly modeling\nmorphological boundaries leads to improved NER performance, and that a novel\nhybrid architecture, in which NER precedes and prunes morphological\ndecomposition, greatly outperforms the standard pipeline, where morphological\ndecomposition strictly precedes NER, setting a new performance bar for both\nHebrew NER and Hebrew morphological decomposition tasks.", "published": "2020-07-30 17:43:14", "link": "http://arxiv.org/abs/2007.15620v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Unreasonable Effectiveness of Machine Learning in Moldavian versus\n  Romanian Dialect Identification", "abstract": "Motivated by the seemingly high accuracy levels of machine learning models in\nMoldavian versus Romanian dialect identification and the increasing research\ninterest on this topic, we provide a follow-up on the Moldavian versus Romanian\nCross-Dialect Topic Identification (MRC) shared task of the VarDial 2019\nEvaluation Campaign. The shared task included two sub-task types: one that\nconsisted in discriminating between the Moldavian and Romanian dialects and one\nthat consisted in classifying documents by topic across the two dialects of\nRomanian. Participants achieved impressive scores, e.g. the top model for\nMoldavian versus Romanian dialect identification obtained a macro F1 score of\n0.895. We conduct a subjective evaluation by human annotators, showing that\nhumans attain much lower accuracy rates compared to machine learning (ML)\nmodels. Hence, it remains unclear why the methods proposed by participants\nattain such high accuracy rates. Our goal is to understand (i) why the proposed\nmethods work so well (by visualizing the discriminative features) and (ii) to\nwhat extent these methods can keep their high accuracy levels, e.g. when we\nshorten the text samples to single sentences or when we use tweets at inference\ntime. A secondary goal of our work is to propose an improved ML model using\nensemble learning. Our experiments show that ML models can accurately identify\nthe dialects, even at the sentence level and across different domains (news\narticles versus tweets). We also analyze the most discriminative features of\nthe best performing models, providing some explanations behind the decisions\ntaken by these models. Interestingly, we learn new dialectal patterns\npreviously unknown to us or to our human annotators. Furthermore, we conduct\nexperiments showing that the machine learning performance on the MRC shared\ntask can be improved through an ensemble based on stacking.", "published": "2020-07-30 19:25:00", "link": "http://arxiv.org/abs/2007.15700v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing RNN-T Models Surpassing High-Performance Hybrid Models with\n  Customization Capability", "abstract": "Because of its streaming nature, recurrent neural network transducer (RNN-T)\nis a very promising end-to-end (E2E) model that may replace the popular hybrid\nmodel for automatic speech recognition. In this paper, we describe our recent\ndevelopment of RNN-T models with reduced GPU memory consumption during\ntraining, better initialization strategy, and advanced encoder modeling with\nfuture lookahead. When trained with Microsoft's 65 thousand hours of anonymized\ntraining data, the developed RNN-T model surpasses a very well trained hybrid\nmodel with both better recognition accuracy and lower latency. We further study\nhow to customize RNN-T models to a new domain, which is important for deploying\nE2E models to practical scenarios. By comparing several methods leveraging\ntext-only data in the new domain, we found that updating RNN-T's prediction and\njoint networks using text-to-speech generated from domain-specific text is the\nmost effective.", "published": "2020-07-30 02:35:20", "link": "http://arxiv.org/abs/2007.15188v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NeuralQA: A Usable Library for Question Answering (Contextual Query\n  Expansion + BERT) on Large Datasets", "abstract": "Existing tools for Question Answering (QA) have challenges that limit their\nuse in practice. They can be complex to set up or integrate with existing\ninfrastructure, do not offer configurable interactive interfaces, and do not\ncover the full set of subtasks that frequently comprise the QA pipeline (query\nexpansion, retrieval, reading, and explanation/sensemaking). To help address\nthese issues, we introduce NeuralQA - a usable library for QA on large\ndatasets. NeuralQA integrates well with existing infrastructure (e.g.,\nElasticSearch instances and reader models trained with the HuggingFace\nTransformers API) and offers helpful defaults for QA subtasks. It introduces\nand implements contextual query expansion (CQE) using a masked language model\n(MLM) as well as relevant snippets (RelSnip) - a method for condensing large\ndocuments into smaller passages that can be speedily processed by a document\nreader model. Finally, it offers a flexible user interface to support workflows\nfor research explorations (e.g., visualization of gradient-based explanations\nto support qualitative inspection of model behaviour) and large scale search\ndeployment. Code and documentation for NeuralQA is available as open source on\nGithub (https://github.com/victordibia/neuralqa}{Github).", "published": "2020-07-30 03:38:30", "link": "http://arxiv.org/abs/2007.15211v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Photon: A Robust Cross-Domain Text-to-SQL System", "abstract": "Natural language interfaces to databases (NLIDB) democratize end user access\nto relational data. Due to fundamental differences between natural language\ncommunication and programming, it is common for end users to issue questions\nthat are ambiguous to the system or fall outside the semantic scope of its\nunderlying query language. We present Photon, a robust, modular, cross-domain\nNLIDB that can flag natural language input to which a SQL mapping cannot be\nimmediately determined. Photon consists of a strong neural semantic parser\n(63.2\\% structure accuracy on the Spider dev benchmark), a human-in-the-loop\nquestion corrector, a SQL executor and a response generator. The question\ncorrector is a discriminative neural sequence editor which detects confusion\nspan(s) in the input question and suggests rephrasing until a translatable\ninput is given by the user or a maximum number of iterations are conducted.\nExperiments on simulated data show that the proposed method effectively\nimproves the robustness of text-to-SQL system against untranslatable user\ninput. The live demo of our system is available at http://naturalsql.com.", "published": "2020-07-30 07:44:48", "link": "http://arxiv.org/abs/2007.15280v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "The optimality of syntactic dependency distances", "abstract": "It is often stated that human languages, as other biological systems, are\nshaped by cost-cutting pressures but, to what extent? Attempts to quantify the\ndegree of optimality of languages by means of an optimality score have been\nscarce and focused mostly on English. Here we recast the problem of the\noptimality of the word order of a sentence as an optimization problem on a\nspatial network where the vertices are words, arcs indicate syntactic\ndependencies and the space is defined by the linear order of the words in the\nsentence. We introduce a new score to quantify the cognitive pressure to reduce\nthe distance between linked words in a sentence. The analysis of sentences from\n93 languages representing 19 linguistic families reveals that half of languages\nare optimized to a 70% or more. The score indicates that distances are not\nsignificantly reduced in a few languages and confirms two theoretical\npredictions, i.e. that longer sentences are more optimized and that distances\nare more likely to be longer than expected by chance in short sentences. We\npresent a new hierarchical ranking of languages by their degree of\noptimization. The new score has implications for various fields of language\nresearch (dependency linguistics, typology, historical linguistics, clinical\nlinguistics and cognitive science). Finally, the principles behind the design\nof the score have implications for network science.", "published": "2020-07-30 09:40:41", "link": "http://arxiv.org/abs/2007.15342v4", "categories": ["cs.CL", "cs.DM", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "AI-based Monitoring and Response System for Hospital Preparedness\n  towards COVID-19 in Southeast Asia", "abstract": "This research paper proposes a COVID-19 monitoring and response system to\nidentify the surge in the volume of patients at hospitals and shortage of\ncritical equipment like ventilators in South-east Asian countries, to\nunderstand the burden on health facilities. This can help authorities in these\nregions with resource planning measures to redirect resources to the regions\nidentified by the model. Due to the lack of publicly available data on the\ninflux of patients in hospitals, or the shortage of equipment, ICU units or\nhospital beds that regions in these countries might be facing, we leverage\nTwitter data for gleaning this information. The approach has yielded accurate\nresults for states in India, and we are working on validating the model for the\nremaining countries so that it can serve as a reliable tool for authorities to\nmonitor the burden on hospitals.", "published": "2020-07-30 17:39:13", "link": "http://arxiv.org/abs/2007.15619v2", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "COVID-19 therapy target discovery with context-aware literature mining", "abstract": "The abundance of literature related to the widespread COVID-19 pandemic is\nbeyond manual inspection of a single expert. Development of systems, capable of\nautomatically processing tens of thousands of scientific publications with the\naim to enrich existing empirical evidence with literature-based associations is\nchallenging and relevant. We propose a system for contextualization of\nempirical expression data by approximating relations between entities, for\nwhich representations were learned from one of the largest COVID-19-related\nliterature corpora. In order to exploit a larger scientific context by transfer\nlearning, we propose a novel embedding generation technique that leverages\nSciBERT language model pretrained on a large multi-domain corpus of scientific\npublications and fine-tuned for domain adaptation on the CORD-19 dataset. The\nconducted manual evaluation by the medical expert and the quantitative\nevaluation based on therapy targets identified in the related work suggest that\nthe proposed method can be successfully employed for COVID-19 therapy target\ndiscovery and that it outperforms the baseline FastText method by a large\nmargin.", "published": "2020-07-30 18:37:36", "link": "http://arxiv.org/abs/2007.15681v2", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "abstract": "As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.", "published": "2020-07-30 08:56:51", "link": "http://arxiv.org/abs/2008.01535v2", "categories": ["cs.CL", "cs.SI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Speaking Speed Control of End-to-End Speech Synthesis using\n  Sentence-Level Conditioning", "abstract": "This paper proposes a controllable end-to-end text-to-speech (TTS) system to\ncontrol the speaking speed (speed-controllable TTS; SCTTS) of synthesized\nspeech with sentence-level speaking-rate value as an additional input. The\nspeaking-rate value, the ratio of the number of input phonemes to the length of\ninput speech, is adopted in the proposed system to control the speaking speed.\nFurthermore, the proposed SCTTS system can control the speaking speed while\nretaining other speech attributes, such as the pitch, by adopting the global\nstyle token-based style encoder. The proposed SCTTS does not require any\nadditional well-trained model or an external speech database to extract\nphoneme-level duration information and can be trained in an end-to-end manner.\nIn addition, our listening tests on fast-, normal-, and slow-speed speech\nshowed that the SCTTS can generate more natural speech than other phoneme\nduration control approaches which increase or decrease duration at the same\nrate for the entire sentence, especially in the case of slow-speed speech.", "published": "2020-07-30 07:48:31", "link": "http://arxiv.org/abs/2007.15281v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested\n  Adversarial Network", "abstract": "We present a novel high-fidelity real-time neural vocoder called VocGAN. A\nrecently developed GAN-based vocoder, MelGAN, produces speech waveforms in\nreal-time. However, it often produces a waveform that is insufficient in\nquality or inconsistent with acoustic characteristics of the input mel\nspectrogram. VocGAN is nearly as fast as MelGAN, but it significantly improves\nthe quality and consistency of the output waveform. VocGAN applies a\nmulti-scale waveform generator and a hierarchically-nested discriminator to\nlearn multiple levels of acoustic properties in a balanced way. It also applies\nthe joint conditional and unconditional objective, which has shown successful\nresults in high-resolution image synthesis. In experiments, VocGAN synthesizes\nspeech waveforms 416.7x faster on a GTX 1080Ti GPU and 3.24x faster on a CPU\nthan real-time. Compared with MelGAN, it also exhibits significantly improved\nquality in multiple evaluation metrics including mean opinion score (MOS) with\nminimal additional overhead. Additionally, compared with Parallel WaveGAN,\nanother recently developed high-fidelity vocoder, VocGAN is 6.98x faster on a\nCPU and exhibits higher MOS.", "published": "2020-07-30 06:33:53", "link": "http://arxiv.org/abs/2007.15256v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A Comparative Re-Assessment of Feature Extractors for Deep Speaker\n  Embeddings", "abstract": "Modern automatic speaker verification relies largely on deep neural networks\n(DNNs) trained on mel-frequency cepstral coefficient (MFCC) features. While\nthere are alternative feature extraction methods based on phase, prosody and\nlong-term temporal operations, they have not been extensively studied with\nDNN-based methods. We aim to fill this gap by providing extensive re-assessment\nof 14 feature extractors on VoxCeleb and SITW datasets. Our findings reveal\nthat features equipped with techniques such as spectral centroids, group delay\nfunction, and integrated noise suppression provide promising alternatives to\nMFCCs for deep speaker embeddings extraction. Experimental results demonstrate\nup to 16.3\\% (VoxCeleb) and 25.1\\% (SITW) relative decrease in equal error rate\n(EER) to the baseline.", "published": "2020-07-30 07:55:58", "link": "http://arxiv.org/abs/2007.15283v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Detecting Distrust Towards the Skills of a Virtual Assistant Using\n  Speech", "abstract": "Research has shown that trust is an essential aspect of human-computer\ninteraction directly determining the degree to which the person is willing to\nuse the system. An automatic prediction of the level of trust that a user has\non a certain system could be used to attempt to correct potential distrust by\nhaving the system take relevant actions like, for example, explaining its\nactions more thoroughly. In this work, we explore the feasibility of\nautomatically detecting the level of trust that a user has on a virtual\nassistant (VA) based on their speech. We use a dataset collected for this\npurpose, containing human-computer speech interactions where subjects were\nasked to answer various factual questions with the help of a virtual assistant,\nwhich they were led to believe was either very reliable or unreliable. We find\nthat the subject's speech can be used to detect which type of VA they were\nusing, which could be considered a proxy for the user's trust toward the VA's\nabilities, with an accuracy up to 76\\%, compared to a random baseline of 50\\%.\nThese results are obtained using features that have been previously found\nuseful for detecting speech directed to infants and non-native speakers.", "published": "2020-07-30 19:56:17", "link": "http://arxiv.org/abs/2007.15711v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hearing What You Cannot See: Acoustic Vehicle Detection Around Corners", "abstract": "This work proposes to use passive acoustic perception as an additional\nsensing modality for intelligent vehicles. We demonstrate that approaching\nvehicles behind blind corners can be detected by sound before such vehicles\nenter in line-of-sight. We have equipped a research vehicle with a roof-mounted\nmicrophone array, and show on data collected with this sensor setup that wall\nreflections provide information on the presence and direction of occluded\napproaching vehicles. A novel method is presented to classify if and from what\ndirection a vehicle is approaching before it is visible, using as input\nDirection-of-Arrival features that can be efficiently computed from the\nstreaming microphone array data. Since the local geometry around the\nego-vehicle affects the perceived patterns, we systematically study several\nenvironment types, and investigate generalization across these environments.\nWith a static ego-vehicle, an accuracy of 0.92 is achieved on the hidden\nvehicle classification task. Compared to a state-of-the-art visual detector,\nFaster R-CNN, our pipeline achieves the same accuracy more than one second\nahead, providing crucial reaction time for the situations we study. While the\nego-vehicle is driving, we demonstrate positive results on acoustic detection,\nstill achieving an accuracy of 0.84 within one environment type. We further\nstudy failure cases across environments to identify future research directions.", "published": "2020-07-30 20:57:13", "link": "http://arxiv.org/abs/2007.15739v2", "categories": ["cs.RO", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
