{"title": "A Self-Assessing Compilation Based Search Approach for Analytical Research and Data Retrieval", "abstract": "While meta-analytic research is performed, it becomes time-consuming to filter through the sheer amount of sources made available by individual databases and search engines and therefore degrades the specificity of source analysis. This study sought to predict the feasibility of a research-oriented searching algorithm across all topics and a search technique to combat flaws in dealing with large datasets by automating three key components of meta-analysis: a query-based search associated with the intended research topic, selecting given sources and determining their relevance to the original query, and extracting applicable information including excerpts and citations. The algorithm was evaluated using 5 key historical topics, and results were broken down into 4 categories: the total number of relevant sources retrieved, the efficiency given a particular search, the total time it takes to finish a complete cycle, and the quality of the extracted sources when compared to results from current searching methods. Although results differed through several searches, on average, the program collected a total of 126 sources per search with an average efficiency of 19.55 sources per second which, when compared and qualitatively evaluated for definitive results, indicates that an algorithm developed across all subject areas will make progress in future research methods.", "published": "2020-07-30 23:51:02", "link": "http://arxiv.org/abs/2008.01189v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Is there something I'm missing? Topic Modeling in eDiscovery", "abstract": "In legal eDiscovery, the parties are required to search through their electronically stored information to find documents that are relevant to a specific case. Negotiations over the scope of these searches are often based on a fear that something will be missed. This paper continues an argument that discovery should be based on identifying the facts of a case. If a search process is less than complete (if it has Recall less than 100%), it may still be complete in presenting all of the relevant available topics. In this study, Latent Dirichlet Allocation was used to identify 100 topics from all of the known relevant documents. The documents were then categorized to about 80% Recall (i.e., 80% of the relevant documents were found by the categorizer, designated the hit set and 20% were missed, designated the missed set). Despite the fact that less than all of the relevant documents were identified by the categorizer, the documents that were identified contained all of the topics derived from the full set of documents. This same pattern held whether the categorizer was a na\u00efve Bayes categorizer trained on a random selection of documents or a Support Vector Machine trained with Continuous Active Learning (which focuses evaluation on the most-likely-to-be-relevant documents). No topics were identified in either categorizer's missed set that were not already seen in the hit set. Not only is a computer-assisted search process reasonable (as required by the Federal Rules of Civil Procedure), it is also complete when measured by topics.", "published": "2020-07-30 20:37:27", "link": "http://arxiv.org/abs/2007.15731v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
