{"title": "MuSe-Toolbox: The Multimodal Sentiment Analysis Continuous Annotation\n  Fusion and Discrete Class Transformation Toolbox", "abstract": "We introduce the MuSe-Toolbox - a Python-based open-source toolkit for\ncreating a variety of continuous and discrete emotion gold standards. In a\nsingle framework, we unify a wide range of fusion methods and propose the novel\nRater Aligned Annotation Weighting (RAAW), which aligns the annotations in a\ntranslation-invariant way before weighting and fusing them based on the\ninter-rater agreements between the annotations. Furthermore, discrete\ncategories tend to be easier for humans to interpret than continuous signals.\nWith this in mind, the MuSe-Toolbox provides the functionality to run\nexhaustive searches for meaningful class clusters in the continuous gold\nstandards. To our knowledge, this is the first toolkit that provides a wide\nselection of state-of-the-art emotional gold standard methods and their\ntransformation to discrete classes. Experimental results indicate that\nMuSe-Toolbox can provide promising and novel class formations which can be\nbetter predicted than hard-coded classes boundaries with minimal human\nintervention. The implementation (1) is out-of-the-box available with all\ndependencies using a Docker container (2).", "published": "2021-07-25 08:46:18", "link": "http://arxiv.org/abs/2107.11757v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Controlled and Diverse Generation of Article Comments", "abstract": "Much research in recent years has focused on automatic article commenting.\nHowever, few of previous studies focus on the controllable generation of\ncomments. Besides, they tend to generate dull and commonplace comments, which\nfurther limits their practical application. In this paper, we make the first\nstep towards controllable generation of comments, by building a system that can\nexplicitly control the emotion of the generated comments. To achieve this, we\nassociate each kind of emotion category with an embedding and adopt a dynamic\nfusion mechanism to fuse this embedding into the decoder. A sentence-level\nemotion classifier is further employed to better guide the model to generate\ncomments expressing the desired emotion. To increase the diversity of the\ngenerated comments, we propose a hierarchical copy mechanism that allows our\nmodel to directly copy words from the input articles. We also propose a\nrestricted beam search (RBS) algorithm to increase intra-sentence diversity.\nExperimental results show that our model can generate informative and diverse\ncomments that express the desired emotions with high accuracy.", "published": "2021-07-25 11:06:22", "link": "http://arxiv.org/abs/2107.11781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-free Multi-hop Reading Comprehension: A Select-to-Guide Strategy", "abstract": "Multi-hop reading comprehension (MHRC) requires not only to predict the\ncorrect answer span in the given passage, but also to provide a chain of\nsupporting evidences for reasoning interpretability. It is natural to model\nsuch a process into graph structure by understanding multi-hop reasoning as\njumping over entity nodes, which has made graph modelling dominant on this\ntask. Recently, there have been dissenting voices about whether graph modelling\nis indispensable due to the inconvenience of the graph building, however\nexisting state-of-the-art graph-free attempts suffer from huge performance gap\ncompared to graph-based ones. This work presents a novel graph-free alternative\nwhich firstly outperform all graph models on MHRC. In detail, we exploit a\nselect-to-guide (S2G) strategy to accurately retrieve evidence paragraphs in a\ncoarse-to-fine manner, incorporated with two novel attention mechanisms, which\nsurprisingly shows conforming to the nature of multi-hop reasoning. Our\ngraph-free model achieves significant and consistent performance gain over\nstrong baselines and the current new state-of-the-art on the MHRC benchmark,\nHotpotQA, among all the published works.", "published": "2021-07-25 15:07:24", "link": "http://arxiv.org/abs/2107.11823v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Joint and Domain-Adaptive Approach to Spoken Language Understanding", "abstract": "Spoken Language Understanding (SLU) is composed of two subtasks: intent\ndetection (ID) and slot filling (SF). There are two lines of research on SLU.\nOne jointly tackles these two subtasks to improve their prediction accuracy,\nand the other focuses on the domain-adaptation ability of one of the subtasks.\nIn this paper, we attempt to bridge these two lines of research and propose a\njoint and domain adaptive approach to SLU. We formulate SLU as a constrained\ngeneration task and utilize a dynamic vocabulary based on domain-specific\nontology. We conduct experiments on the ASMixed and MTOD datasets and achieve\ncompetitive performance with previous state-of-the-art joint models. Besides,\nresults show that our joint model can be effectively adapted to a new domain.", "published": "2021-07-25 09:38:42", "link": "http://arxiv.org/abs/2107.11768v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learn to Focus: Hierarchical Dynamic Copy Network for Dialogue State\n  Tracking", "abstract": "Recently, researchers have explored using the encoder-decoder framework to\ntackle dialogue state tracking (DST), which is a key component of task-oriented\ndialogue systems. However, they regard a multi-turn dialogue as a flat\nsequence, failing to focus on useful information when the sequence is long. In\nthis paper, we propose a Hierarchical Dynamic Copy Network (HDCN) to facilitate\nfocusing on the most informative turn, making it easier to extract slot values\nfrom the dialogue context. Based on the encoder-decoder framework, we adopt a\nhierarchical copy approach that calculates two levels of attention at the word-\nand turn-level, which are then renormalized to obtain the final copy\ndistribution. A focus loss term is employed to encourage the model to assign\nthe highest turn-level attention weight to the most informative turn.\nExperimental results show that our model achieves 46.76% joint accuracy on the\nMultiWOZ 2.1 dataset.", "published": "2021-07-25 10:43:28", "link": "http://arxiv.org/abs/2107.11778v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transferable Dialogue Systems and User Simulators", "abstract": "One of the difficulties in training dialogue systems is the lack of training\ndata. We explore the possibility of creating dialogue data through the\ninteraction between a dialogue system and a user simulator. Our goal is to\ndevelop a modelling framework that can incorporate new dialogue scenarios\nthrough self-play between the two agents. In this framework, we first pre-train\nthe two agents on a collection of source domain dialogues, which equips the\nagents to converse with each other via natural language. With further\nfine-tuning on a small amount of target domain data, the agents continue to\ninteract with the aim of improving their behaviors using reinforcement learning\nwith structured reward functions. In experiments on the MultiWOZ dataset, two\npractical transfer learning problems are investigated: 1) domain adaptation and\n2) single-to-multiple domain transfer. We demonstrate that the proposed\nframework is highly effective in bootstrapping the performance of the two\nagents in transfer learning. We also show that our method leads to improvements\nin dialogue system performance on complete datasets.", "published": "2021-07-25 22:59:09", "link": "http://arxiv.org/abs/2107.11904v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for\n  Sequences", "abstract": "We describe an efficient hierarchical method to compute attention in the\nTransformer architecture. The proposed attention mechanism exploits a matrix\nstructure similar to the Hierarchical Matrix (H-Matrix) developed by the\nnumerical analysis community, and has linear run time and memory complexity. We\nperform extensive experiments to show that the inductive bias embodied by our\nhierarchical attention is effective in capturing the hierarchical structure in\nthe sequences typical for natural language and vision tasks. Our method is\nsuperior to alternative sub-quadratic proposals by over +6 points on average on\nthe Long Range Arena benchmark. It also sets a new SOTA test perplexity on\nOne-Billion Word dataset with 5x fewer model parameters than that of the\nprevious-best Transformer-based models.", "published": "2021-07-25 23:07:03", "link": "http://arxiv.org/abs/2107.11906v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A comparison of latent semantic analysis and correspondence analysis of\n  document-term matrices", "abstract": "Latent semantic analysis (LSA) and correspondence analysis (CA) are two\ntechniques that use a singular value decomposition (SVD) for dimensionality\nreduction. LSA has been extensively used to obtain low-dimensional\nrepresentations that capture relationships among documents and terms. In this\narticle, we present a theoretical analysis and comparison of the two techniques\nin the context of document-term matrices. We show that CA has some attractive\nproperties as compared to LSA, for instance that effects of margins, i.e. sums\nof row elements and column elements, arising from differing document-lengths\nand term-frequencies are effectively eliminated, so that the CA solution is\noptimally suited to focus on relationships among documents and terms. A\nunifying framework is proposed that includes both CA and LSA as special cases.\nWe empirically compare CA to various LSA based methods on text categorization\nin English and authorship attribution on historical Dutch texts, and find that\nCA performs significantly better. We also apply CA to a long-standing question\nregarding the authorship of the Dutch national anthem Wilhelmus and provide\nfurther support that it can be attributed to the author Datheen, amongst\nseveral contenders.", "published": "2021-07-25 09:10:10", "link": "http://arxiv.org/abs/2108.06197v4", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Hybrid Autoregressive Inference for Scalable Multi-hop Explanation\n  Regeneration", "abstract": "Regenerating natural language explanations in the scientific domain has been\nproposed as a benchmark to evaluate complex multi-hop and explainable\ninference. In this context, large language models can achieve state-of-the-art\nperformance when employed as cross-encoder architectures and fine-tuned on\nhuman-annotated explanations. However, while much attention has been devoted to\nthe quality of the explanations, the problem of performing inference\nefficiently is largely under-studied. Cross-encoders, in fact, are\nintrinsically not scalable, possessing limited applicability to real-world\nscenarios that require inference on massive facts banks. To enable complex\nmulti-hop reasoning at scale, this paper focuses on bi-encoder architectures,\ninvestigating the problem of scientific explanation regeneration at the\nintersection of dense and sparse models. Specifically, we present SCAR (for\nScalable Autoregressive Inference), a hybrid framework that iteratively\ncombines a Transformer-based bi-encoder with a sparse model of explanatory\npower, designed to leverage explicit inference patterns in the explanations.\nOur experiments demonstrate that the hybrid framework significantly outperforms\nprevious sparse models, achieving performance comparable with that of\nstate-of-the-art cross-encoders while being approx 50 times faster and scalable\nto corpora of millions of facts. Further analyses on semantic drift and\nmulti-hop question answering reveal that the proposed hybridisation boosts the\nquality of the most challenging explanations, contributing to improved\nperformance on downstream inference tasks.", "published": "2021-07-25 19:29:53", "link": "http://arxiv.org/abs/2107.11879v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Cough Detection from Acoustic signals for patient monitoring system", "abstract": "Cough is one of the most common symptoms in all respiratory diseases. In\ncases like Chronic Obstructive Pulmonary Disease, Asthma, acute and chronic\nBronchitis and the recent pandemic Covid-19, the early identification of cough\nis important to provide healthcare professionals with useful clinical\ninformation such as frequency, severity, and nature of cough to enable better\ndiagnosis. This paper presents and demonstrates best feature selection using\nMFCC which can help to determine cough events, eventually helping a neural\nnetwork to learn and improve accuracy of cough detection. The paper proposes to\nachieve performance of 97.77% Sensitivity (SE), 98.75% Specificity (SP) and\n98.17% F1-score with a very light binary classification network of size close\nto 16K parameters, enabling fitment into smart IoT devices.", "published": "2021-07-25 16:24:15", "link": "http://arxiv.org/abs/2107.11835v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adding air attenuation to simulated room impulse responses: A modal\n  approach", "abstract": "Air absorption is an important effect to consider when simulating room\nacoustics as it leads to significant attenuation in high frequencies. In this\nstudy, an offline method for adding air absorption to simulated room impulse\nresponses is devised. The proposed method is based on a modal scheme for a\nsystem of one-dimensional dissipative wave equations, which can be used to\npost-process a room impulse response simulated without air absorption, thereby\nincorporating missing frequency-dependent distance-based air attenuation.\nNumerical examples are presented to evaluate the proposed method, along with\ncomparisons to existing filter-based methods.", "published": "2021-07-25 19:03:49", "link": "http://arxiv.org/abs/2107.11871v1", "categories": ["math.NA", "cs.NA", "cs.SD", "eess.AS"], "primary_category": "math.NA"}
{"title": "A Study on Speech Enhancement Based on Diffusion Probabilistic Model", "abstract": "Diffusion probabilistic models have demonstrated an outstanding capability to\nmodel natural images and raw audio waveforms through a paired diffusion and\nreverse processes. The unique property of the reverse process (namely,\neliminating non-target signals from the Gaussian noise and noisy signals) could\nbe utilized to restore clean signals. Based on this property, we propose a\ndiffusion probabilistic model-based speech enhancement (DiffuSE) model that\naims to recover clean speech signals from noisy signals. The fundamental\narchitecture of the proposed DiffuSE model is similar to that of DiffWave--a\nhigh-quality audio waveform generation model that has a relatively low\ncomputational cost and footprint. To attain better enhancement performance, we\ndesigned an advanced reverse process, termed the supportive reverse process,\nwhich adds noisy speech in each time-step to the predicted speech. The\nexperimental results show that DiffuSE yields performance that is comparable to\nrelated audio generative models on the standardized Voice Bank corpus SE task.\nMoreover, relative to the generally suggested full sampling schedule, the\nproposed supportive reverse process especially improved the fast sampling,\ntaking few steps to yield better enhancement results over the conventional full\nstep inference process.", "published": "2021-07-25 19:23:18", "link": "http://arxiv.org/abs/2107.11876v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
