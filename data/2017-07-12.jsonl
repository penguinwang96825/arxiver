{"title": "Geospatial Semantics", "abstract": "Geospatial semantics is a broad field that involves a variety of research\nareas. The term semantics refers to the meaning of things, and is in contrast\nwith the term syntactics. Accordingly, studies on geospatial semantics usually\nfocus on understanding the meaning of geographic entities as well as their\ncounterparts in the cognitive and digital world, such as cognitive geographic\nconcepts and digital gazetteers. Geospatial semantics can also facilitate the\ndesign of geographic information systems (GIS) by enhancing the\ninteroperability of distributed systems and developing more intelligent\ninterfaces for user interactions. During the past years, a lot of research has\nbeen conducted, approaching geospatial semantics from different perspectives,\nusing a variety of methods, and targeting different problems. Meanwhile, the\narrival of big geo data, especially the large amount of unstructured text data\non the Web, and the fast development of natural language processing methods\nenable new research directions in geospatial semantics. This chapter,\ntherefore, provides a systematic review on the existing geospatial semantic\nresearch. Six major research areas are identified and discussed, including\nsemantic interoperability, digital gazetteers, geographic information\nretrieval, geospatial Semantic Web, place semantics, and cognitive geographic\nconcepts.", "published": "2017-07-12 05:41:06", "link": "http://arxiv.org/abs/1707.03550v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Case for Being Average: A Mediocrity Approach to Style Masking and\n  Author Obfuscation", "abstract": "Users posting online expect to remain anonymous unless they have logged in,\nwhich is often needed for them to be able to discuss freely on various topics.\nPreserving the anonymity of a text's writer can be also important in some other\ncontexts, e.g., in the case of witness protection or anonymity programs.\nHowever, each person has his/her own style of writing, which can be analyzed\nusing stylometry, and as a result, the true identity of the author of a piece\nof text can be revealed even if s/he has tried to hide it. Thus, it could be\nhelpful to design automatic tools that can help a person obfuscate his/her\nidentity when writing text. In particular, here we propose an approach that\nchanges the text, so that it is pushed towards average values for some general\nstylometric characteristics, thus making the use of these characteristics less\ndiscriminative. The approach consists of three main steps: first, we calculate\nthe values for some popular stylometric metrics that can indicate authorship;\nthen we apply various transformations to the text, so that these metrics are\nadjusted towards the average level, while preserving the semantics and the\nsoundness of the text; and finally, we add random noise. This approach turned\nout to be very efficient, and yielded the best performance on the Author\nObfuscation task at the PAN-2016 competition.", "published": "2017-07-12 14:27:00", "link": "http://arxiv.org/abs/1707.03736v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "N-GrAM: New Groningen Author-profiling Model", "abstract": "We describe our participation in the PAN 2017 shared task on Author\nProfiling, identifying authors' gender and language variety for English,\nSpanish, Arabic and Portuguese. We describe both the final, submitted system,\nand a series of negative results. Our aim was to create a single model for both\ngender and language, and for all language varieties. Our best-performing system\n(on cross-validated results) is a linear support vector machine (SVM) with word\nunigrams and character 3- to 5-grams as features. A set of additional features,\nincluding POS tags, additional datasets, geographic entities, and Twitter\nhandles, hurt, rather than improve, performance. Results from cross-validation\nindicated high performance overall and results on the test set confirmed them,\nat 0.86 averaged accuracy, with performance on sub-tasks ranging from 0.68 to\n0.98.", "published": "2017-07-12 15:34:21", "link": "http://arxiv.org/abs/1707.03764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Critique of a Critique of Word Similarity Datasets: Sanity Check or\n  Unnecessary Confusion?", "abstract": "Critical evaluation of word similarity datasets is very important for\ncomputational lexical semantics. This short report concerns the sanity check\nproposed in Batchkarov et al. (2016) to evaluate several popular datasets such\nas MC, RG and MEN -- the first two reportedly failed. I argue that this test is\nunstable, offers no added insight, and needs major revision in order to fulfill\nits purported goal.", "published": "2017-07-12 10:09:32", "link": "http://arxiv.org/abs/1707.03819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Negative Sampling Improves Hypernymy Extraction Based on Projection\n  Learning", "abstract": "We present a new approach to extraction of hypernyms based on projection\nlearning and word embeddings. In contrast to classification-based approaches,\nprojection-based methods require no candidate hyponym-hypernym pairs. While it\nis natural to use both positive and negative training examples in supervised\nrelation extraction, the impact of negative examples on hypernym prediction was\nnot studied so far. In this paper, we show that explicit negative examples used\nfor regularization of the model significantly improve performance compared to\nthe state-of-the-art approach of Fu et al. (2014) on three datasets from\ndifferent languages.", "published": "2017-07-12 20:47:47", "link": "http://arxiv.org/abs/1707.03903v2", "categories": ["cs.CL", "I.2.6; I.5.3; I.2.4"], "primary_category": "cs.CL"}
{"title": "Explainable Entity-based Recommendations with Knowledge Graphs", "abstract": "Explainable recommendation is an important task. Many methods have been\nproposed which generate explanations from the content and reviews written for\nitems. When review text is unavailable, generating explanations is still a hard\nproblem. In this paper, we illustrate how explanations can be generated in such\na scenario by leveraging external knowledge in the form of knowledge graphs.\nOur method jointly ranks items and knowledge graph entities using a\nPersonalized PageRank procedure to produce recommendations together with their\nexplanations.", "published": "2017-07-12 23:18:58", "link": "http://arxiv.org/abs/1707.05254v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multitask Learning for Fine-Grained Twitter Sentiment Analysis", "abstract": "Traditional sentiment analysis approaches tackle problems like ternary\n(3-category) and fine-grained (5-category) classification by learning the tasks\nseparately. We argue that such classification tasks are correlated and we\npropose a multitask approach based on a recurrent neural network that benefits\nby jointly learning them. Our study demonstrates the potential of multitask\nmodels on this type of problems and improves the state-of-the-art results in\nthe fine-grained sentiment classification problem.", "published": "2017-07-12 07:17:50", "link": "http://arxiv.org/abs/1707.03569v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Source-Target Inference Models for Spatial Instruction Understanding", "abstract": "Models that can execute natural language instructions for situated robotic\ntasks such as assembly and navigation have several useful applications in\nhomes, offices, and remote scenarios. We study the semantics of\nspatially-referred configuration and arrangement instructions, based on the\nchallenging Bisk-2016 blank-labeled block dataset. This task involves finding a\nsource block and moving it to the target position (mentioned via a reference\nblock and offset), where the blocks have no names or colors and are just\nreferred to via spatial location features. We present novel models for the\nsubtasks of source block classification and target position regression, based\non joint-loss language and spatial-world representation learning, as well as\nCNN-based and dual attention models to compute the alignment between the world\nblocks and the instruction phrases. For target position prediction, we compare\ntwo inference approaches: annealed sampling via policy gradient versus\nexpectation inference via supervised regression. Our models achieve the new\nstate-of-the-art on this task, with an improvement of 47% on source block\naccuracy and 22% on target position distance.", "published": "2017-07-12 17:15:57", "link": "http://arxiv.org/abs/1707.03804v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Quasar: Datasets for Question Answering by Search and Reading", "abstract": "We present two new large-scale datasets aimed at evaluating systems designed\nto comprehend a natural language query and extract its answer from a large\ncorpus of text. The Quasar-S dataset consists of 37000 cloze-style\n(fill-in-the-gap) queries constructed from definitions of software entity tags\non the popular website Stack Overflow. The posts and comments on the website\nserve as the background corpus for answering the cloze questions. The Quasar-T\ndataset consists of 43000 open-domain trivia questions and their answers\nobtained from various internet sources. ClueWeb09 serves as the background\ncorpus for extracting these answers. We pose these datasets as a challenge for\ntwo related subtasks of factoid Question Answering: (1) searching for relevant\npieces of text that include the correct answer to a query, and (2) reading the\nretrieved text to answer the query. We also describe a retrieval system for\nextracting relevant sentences and documents from the corpus given a query, and\ninclude these in the release for researchers wishing to only focus on (2). We\nevaluate several baselines on both datasets, ranging from simple heuristics to\npowerful neural models, and show that these lag behind human performance by\n16.4% and 32.1% for Quasar-S and -T respectively. The datasets are available at\nhttps://github.com/bdhingra/quasar .", "published": "2017-07-12 20:53:26", "link": "http://arxiv.org/abs/1707.03904v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
