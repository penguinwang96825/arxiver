{"title": "On the Similarities Between Native, Non-native and Translated Texts", "abstract": "We present a computational analysis of three language varieties: native,\nadvanced non-native, and translation. Our goal is to investigate the\nsimilarities and differences between non-native language productions and\ntranslations, contrasting both with native language. Using a collection of\ncomputational methods we establish three main results: (1) the three types of\ntexts are easily distinguishable; (2) non-native language and translations are\ncloser to each other than each of them is to native language; and (3) some of\nthese characteristics depend on the source or native language, while others do\nnot, reflecting, perhaps, unified principles that similarly affect translations\nand non-native language.", "published": "2016-09-11 19:51:46", "link": "http://arxiv.org/abs/1609.03204v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Identification of Translationese", "abstract": "Translated texts are distinctively different from original ones, to the\nextent that supervised text classification methods can distinguish between them\nwith high accuracy. These differences were proven useful for statistical\nmachine translation. However, it has been suggested that the accuracy of\ntranslation detection deteriorates when the classifier is evaluated outside the\ndomain it was trained on. We show that this is indeed the case, in a variety of\nevaluation scenarios. We then show that unsupervised classification is highly\naccurate on this task. We suggest a method for determining the correct labels\nof the clustering outcomes, and then use the labels for voting, improving the\naccuracy even further. Moreover, we suggest a simple method for clustering in\nthe challenging case of mixed-domain datasets, in spite of the dominance of\ndomain-related features over translation-related ones. The result is an\neffective, fully-unsupervised method for distinguishing between original and\ntranslated texts that can be applied to new domains with reasonable accuracy.", "published": "2016-09-11 19:52:28", "link": "http://arxiv.org/abs/1609.03205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Divide and...conquer? On the limits of algorithmic approaches to\n  syntactic semantic structure", "abstract": "In computer science, divide and conquer (D&C) is an algorithm design paradigm\nbased on multi-branched recursion. A D&C algorithm works by recursively and\nmonotonically breaking down a problem into sub problems of the same (or a\nrelated) type, until these become simple enough to be solved directly. The\nsolutions to the sub problems are then combined to give a solution to the\noriginal problem. The present work identifies D&C algorithms assumed within\ncontemporary syntactic theory, and discusses the limits of their applicability\nin the realms of the syntax semantics and syntax morphophonology interfaces. We\nwill propose that D&C algorithms, while valid for some processes, fall short on\nflexibility given a mixed approach to the structure of linguistic phrase\nmarkers. Arguments in favour of a computationally mixed approach to linguistic\nstructure will be presented as an alternative that offers advantages to uniform\nD&C approaches.", "published": "2016-09-11 10:20:48", "link": "http://arxiv.org/abs/1609.03148v1", "categories": ["cs.CL", "cs.FL", "68Q42"], "primary_category": "cs.CL"}
{"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition,\ncombining a convolutional network based acoustic model and a graph decoding. It\nis trained to output letters, with transcribed speech, without the need for\nforce alignment of phonemes. We introduce an automatic segmentation criterion\nfor training from sequence annotation without alignment that is on par with CTC\nwhile being simpler. We show competitive results in word error rate on the\nLibrispeech corpus with MFCC features, and promising results from raw waveform.", "published": "2016-09-11 18:56:53", "link": "http://arxiv.org/abs/1609.03193v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "Multiplex lexical networks reveal patterns in early word acquisition in\n  children", "abstract": "Network models of language have provided a way of linking cognitive processes\nto the structure and connectivity of language. However, one shortcoming of\ncurrent approaches is focusing on only one type of linguistic relationship at a\ntime, missing the complex multi-relational nature of language. In this work, we\novercome this limitation by modelling the mental lexicon of English-speaking\ntoddlers as a multiplex lexical network, i.e. a multi-layered network where\nN=529 words/nodes are connected according to four types of relationships: (i)\nfree associations, (ii) feature sharing, (iii) co-occurrence, and (iv)\nphonological similarity. We provide analysis of the topology of the resulting\nmultiplex and then proceed to evaluate single layers as well as the full\nmultiplex structure on their ability to predict empirically observed age of\nacquisition data of English speaking toddlers. We find that the emerging\nmultiplex network topology is an important proxy of the cognitive processes of\nacquisition, capable of capturing emergent lexicon structure. In fact, we show\nthat the multiplex topology is fundamentally more powerful than individual\nlayers in predicting the ordering with which words are acquired. Furthermore,\nmultiplex analysis allows for a quantification of distinct phases of lexical\nacquisition in early learners: while initially all the multiplex layers\ncontribute to word learning, after about month 23 free associations take the\nlead in driving word acquisition.", "published": "2016-09-11 19:59:18", "link": "http://arxiv.org/abs/1609.03207v2", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cs.CL", "cs.LG"], "primary_category": "physics.soc-ph"}
