{"title": "Building Sequential Inference Models for End-to-End Response Selection", "abstract": "This paper presents an end-to-end response selection model for Track 1 of the\n7th Dialogue System Technology Challenges (DSTC7). This task focuses on\nselecting the correct next utterance from a set of candidates given a partial\nconversation. We propose an end-to-end neural network based on enhanced\nsequential inference model (ESIM) for this task. Our proposed model differs\nfrom the original ESIM model in the following four aspects. First, a new word\nrepresentation method which combines the general pre-trained word embeddings\nwith those estimated on the task-specific training set is adopted in order to\naddress the challenge of out-of-vocabulary (OOV) words. Second, an attentive\nhierarchical recurrent encoder (AHRE) is designed which is capable to encode\nsentences hierarchically and generate more descriptive representations by\naggregation. Third, a new pooling method which combines multi-dimensional\npooling and last-state pooling is used instead of the simple combination of max\npooling and average pooling in the original ESIM. Last, a modification layer is\nadded before the softmax layer to emphasize the importance of the last\nutterance in the context for response selection. In the released evaluation\nresults of DSTC7, our proposed method ranked second on the Ubuntu dataset and\nthird on the Advising dataset in subtask 1 of Track 1.", "published": "2018-12-03 11:46:43", "link": "http://arxiv.org/abs/1812.00686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The RGNLP Machine Translation Systems for WAT 2018", "abstract": "This paper presents the system description of Machine Translation (MT)\nsystem(s) for Indic Languages Multilingual Task for the 2018 edition of the WAT\nShared Task. In our experiments, we (the RGNLP team) explore both statistical\nand neural methods across all language pairs. (We further present an extensive\ncomparison of language-related problems for both the approaches in the context\nof low-resourced settings.) Our PBSMT models were highest score on all\nautomatic evaluation metrics in the English into Telugu, Hindi, Bengali, Tamil\nportion of the shared task.", "published": "2018-12-03 14:53:41", "link": "http://arxiv.org/abs/1812.00798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Neural- and N-Gram-Based Language Models for Word Segmentation", "abstract": "Word segmentation is the task of inserting or deleting word boundary\ncharacters in order to separate character sequences that correspond to words in\nsome language. In this article we propose an approach based on a beam search\nalgorithm and a language model working at the byte/character level, the latter\ncomponent implemented either as an n-gram model or a recurrent neural network.\nThe resulting system analyzes the text input with no word boundaries one token\nat a time, which can be a character or a byte, and uses the information\ngathered by the language model to determine if a boundary must be placed in the\ncurrent position or not. Our aim is to use this system in a preprocessing step\nfor a microtext normalization system. This means that it needs to effectively\ncope with the data sparsity present on this kind of texts. We also strove to\nsurpass the performance of two readily available word segmentation systems: The\nwell-known and accessible Word Breaker by Microsoft, and the Python module\nWordSegment by Grant Jenks. The results show that we have met our objectives,\nand we hope to continue to improve both the precision and the efficiency of our\nsystem in the future.", "published": "2018-12-03 15:04:23", "link": "http://arxiv.org/abs/1812.00815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Scalable Neural Dialogue State Tracking Model", "abstract": "The latency in the current neural based dialogue state tracking models\nprohibits them from being used efficiently for deployment in production\nsystems, albeit their highly accurate performance. This paper proposes a new\nscalable and accurate neural dialogue state tracking model, based on the\nrecently proposed Global-Local Self-Attention encoder (GLAD) model by Zhong et\nal. which uses global modules to share parameters between estimators for\ndifferent types (called slots) of dialogue states, and uses local modules to\nlearn slot-specific features. By using only one recurrent networks with global\nconditioning, compared to (1 + \\# slots) recurrent networks with global and\nlocal conditioning used in the GLAD model, our proposed model reduces the\nlatency in training and inference times by $35\\%$ on average, while preserving\nperformance of belief state tracking, by $97.38\\%$ on turn request and\n$88.51\\%$ on joint goal and accuracy. Evaluation on Multi-domain dataset\n(Multi-WoZ) also demonstrates that our model outperforms GLAD on turn inform\nand joint goal accuracy.", "published": "2018-12-03 16:52:34", "link": "http://arxiv.org/abs/1812.00899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Semantic Parsing", "abstract": "A significant amount of information in today's world is stored in structured\nand semi-structured knowledge bases. Efficient and simple methods to query them\nare essential and must not be restricted to only those who have expertise in\nformal query languages. The field of semantic parsing deals with converting\nnatural language utterances to logical forms that can be easily executed on a\nknowledge base. In this survey, we examine the various components of a semantic\nparsing system and discuss prominent work ranging from the initial rule based\nmethods to the current neural approaches to program synthesis. We also discuss\nmethods that operate using varying levels of supervision and highlight the key\nchallenges involved in the learning of such systems.", "published": "2018-12-03 18:53:08", "link": "http://arxiv.org/abs/1812.00978v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A System for Automated Image Editing from Natural Language Commands", "abstract": "This work presents the task of modifying images in an image editing program\nusing natural language written commands. We utilize a corpus of over 6000 image\nedit text requests to alter real world images collected via crowdsourcing. A\nnovel framework composed of actions and entities to map a user's natural\nlanguage request to executable commands in an image editing program is\ndescribed. We resolve previously labeled annotator disagreement through a\nvoting process and complete annotation of the corpus. We experimented with\ndifferent machine learning models and found that the LSTM, the SVM, and the\nbidirectional LSTM-CRF joint models are the best to detect image editing\nactions and associated entities in a given utterance.", "published": "2018-12-03 21:12:31", "link": "http://arxiv.org/abs/1812.01083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clinical Document Classification Using Labeled and Unlabeled Data Across\n  Hospitals", "abstract": "Reviewing radiology reports in emergency departments is an essential but\nlaborious task. Timely follow-up of patients with abnormal cases in their\nradiology reports may dramatically affect the patient's outcome, especially if\nthey have been discharged with a different initial diagnosis. Machine learning\napproaches have been devised to expedite the process and detect the cases that\ndemand instant follow up. However, these approaches require a large amount of\nlabeled data to train reliable predictive models. Preparing such a large\ndataset, which needs to be manually annotated by health professionals, is\ncostly and time-consuming. This paper investigates a semi-supervised learning\nframework for radiology report classification across three hospitals. The main\ngoal is to leverage clinical unlabeled data in order to augment the learning\nprocess where limited labeled data is available. To further improve the\nclassification performance, we also integrate a transfer learning technique\ninto the semi-supervised learning pipeline . Our experimental findings show\nthat (1) convolutional neural networks (CNNs), while being independent of any\nproblem-specific feature engineering, achieve significantly higher\neffectiveness compared to conventional supervised learning approaches, (2)\nleveraging unlabeled data in training a CNN-based classifier reduces the\ndependency on labeled data by more than 50% to reach the same performance of a\nfully supervised CNN, and (3) transferring the knowledge gained from available\nlabeled data in an external source hospital significantly improves the\nperformance of a semi-supervised CNN model over their fully supervised\ncounterparts in a target hospital.", "published": "2018-12-03 11:34:26", "link": "http://arxiv.org/abs/1812.00677v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Solving Text-based Games by Producing Adaptive Action Spaces", "abstract": "To solve a text-based game, an agent needs to formulate valid text commands\nfor a given context and find the ones that lead to success. Recent attempts at\nsolving text-based games with deep reinforcement learning have focused on the\nlatter, i.e., learning to act optimally when valid actions are known in\nadvance. In this work, we propose to tackle the first task and train a model\nthat generates the set of all valid commands for a given context. We try three\ngenerative models on a dataset generated with Textworld. The best model can\ngenerate valid commands which were unseen at training and achieve high $F_1$\nscore on the test set.", "published": "2018-12-03 16:00:48", "link": "http://arxiv.org/abs/1812.00855v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generating Diverse Programs with Instruction Conditioned Reinforced\n  Adversarial Learning", "abstract": "Advances in Deep Reinforcement Learning have led to agents that perform well\nacross a variety of sensory-motor domains. In this work, we study the setting\nin which an agent must learn to generate programs for diverse scenes\nconditioned on a given symbolic instruction. Final goals are specified to our\nagent via images of the scenes. A symbolic instruction consistent with the goal\nimages is used as the conditioning input for our policies. Since a single\ninstruction corresponds to a diverse set of different but still consistent\nend-goal images, the agent needs to learn to generate a distribution over\nprograms given an instruction. We demonstrate that with simple changes to the\nreinforced adversarial learning objective, we can learn instruction conditioned\npolicies to achieve the corresponding diverse set of goals. Most importantly,\nour agent's stochastic policy is shown to more accurately capture the diversity\nin the goal distribution than a fixed pixel-based reward function baseline. We\ndemonstrate the efficacy of our approach on two domains: (1) drawing MNIST\ndigits with a paint software conditioned on instructions and (2) constructing\nscenes in a 3D editor that satisfies a certain instruction.", "published": "2018-12-03 16:51:35", "link": "http://arxiv.org/abs/1812.00898v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep Learning Model for Finding New Superconductors", "abstract": "Exploration of new superconductors still relies on the experience and\nintuition of experts and is largely a process of experimental trial and error.\nIn one study, only 3% of the candidate materials showed superconductivity.\nHere, we report the first deep learning model for finding new superconductors.\nWe introduced the method named \"reading periodic table\" which represented the\nperiodic table in a way that allows deep learning to learn to read the periodic\ntable and to learn the law of elements for the purpose of discovering novel\nsuperconductors that are outside the training data. It is recognized that it is\ndifficult for deep learning to predict something outside the training data.\nAlthough we used only the chemical composition of materials as information, we\nobtained an $R^{2}$ value of 0.92 for predicting $T_\\text{c}$ for materials in\na database of superconductors. We also introduced the method named \"garbage-in\"\nto create synthetic data of non-superconductors that do not exist.\nNon-superconductors are not reported, but the data must be required for deep\nlearning to distinguish between superconductors and non-superconductors. We\nobtained three remarkable results. The deep learning can predict\nsuperconductivity for a material with a precision of 62%, which shows the\nusefulness of the model; it found the recently discovered superconductor CaBi2\nand another one Hf0.5Nb0.2V2Zr0.3, neither of which is in the superconductor\ndatabase; and it found Fe-based high-temperature superconductors (discovered in\n2008) from the training data before 2008. These results open the way for the\ndiscovery of new high-temperature superconductor families. The candidate\nmaterials list, data, and method are openly available from the link\nhttps://github.com/tomo835g/Deep-Learning-to-find-Superconductors.", "published": "2018-12-03 05:30:34", "link": "http://arxiv.org/abs/1812.01995v4", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.CL", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Bach2Bach: Generating Music Using A Deep Reinforcement Learning Approach", "abstract": "A model of music needs to have the ability to recall past details and have a\nclear, coherent understanding of musical structure. Detailed in the paper is a\ndeep reinforcement learning architecture that predicts and generates polyphonic\nmusic aligned with musical rules. The probabilistic model presented is a\nBi-axial LSTM trained with a pseudo-kernel reminiscent of a convolutional\nkernel. To encourage exploration and impose greater global coherence on the\ngenerated music, a deep reinforcement learning approach DQN is adopted. When\nanalyzed quantitatively and qualitatively, this approach performs well in\ncomposing polyphonic music.", "published": "2018-12-03 20:09:05", "link": "http://arxiv.org/abs/1812.01060v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Feature Extraction for Temporal Signal Recognition: An Overview", "abstract": "Due to the huge progress of the recording devices, data from heterogeneous\nnature can be recorded, such as spatial, temporal and spatio-temporal.\nNowadays, time-based data is of particular interest since it has the ability to\ncapture the characteristics evolution of the data over time. The temporal data\ncould be gait, auditory scene, piece of music, and so on. In this paper, we are\nparticularly interested in feature extraction for two different temporal\nrecognition applications namely, audio and human behavior analysis and\nrecognition. Indeed, relevant and discriminative features are of critical and\nfundamental importance to achieve high performances in any automatic pattern\nrecognition system. This work is intended to provide researchers with a brief\noverview of the different existing features through an understanding of basic\ntaxonomies which may serve as a reference to identify the adequate features for\na specific task.", "published": "2018-12-03 21:26:57", "link": "http://arxiv.org/abs/1812.01780v1", "categories": ["eess.AS", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
