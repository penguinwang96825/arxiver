{"title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "abstract": "We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-based information retrieval, cross-modal semantic similarity,\nand programming code search. Comprehensive evaluations demonstrate that\njina-embeddings-v4 achieves state-of-the-art performance on both single- modal\nand cross-modal retrieval tasks, with particular strength in processing\nvisually rich content such as tables, charts, diagrams, and mixed-media\nformats. To facilitate evaluation of this capability, we also introduce\nJina-VDR, a novel benchmark specifically designed for visually rich image\nretrieval.", "published": "2025-06-23 17:59:55", "link": "http://arxiv.org/abs/2506.18902v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations", "abstract": "This paper presents a multimodal framework that attempts to unify visual\nunderstanding and generation within a shared discrete semantic representation.\nAt its core is the Text-Aligned Tokenizer (TA-Tok), which converts images into\ndiscrete tokens using a text-aligned codebook projected from a large language\nmodel's (LLM) vocabulary. By integrating vision and text into a unified space\nwith an expanded vocabulary, our multimodal LLM, Tar, enables cross-modal input\nand output through a shared interface, without the need for modality-specific\ndesigns. Additionally, we propose scale-adaptive encoding and decoding to\nbalance efficiency and visual detail, along with a generative de-tokenizer to\nproduce high-fidelity visual outputs. To address diverse decoding needs, we\nutilize two complementary de-tokenizers: a fast autoregressive model and a\ndiffusion-based model. To enhance modality fusion, we investigate advanced\npre-training tasks, demonstrating improvements in both visual understanding and\ngeneration. Experiments across benchmarks show that Tar matches or surpasses\nexisting multimodal LLM methods, achieving faster convergence and greater\ntraining efficiency. Code, models, and data are available at\nhttps://tar.csuhan.com", "published": "2025-06-23 17:59:14", "link": "http://arxiv.org/abs/2506.18898v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs", "abstract": "Process Reward Models (PRMs) have recently emerged as a powerful framework\nfor supervising intermediate reasoning steps in large language models (LLMs).\nPrevious PRMs are primarily trained on model final output responses and\nstruggle to evaluate intermediate thinking trajectories robustly, especially in\nthe emerging setting of trajectory-response outputs generated by frontier\nreasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a\nnovel trajectory-aware PRM explicitly designed to evaluate the\ntrajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both\nstep-level and trajectory-level supervision, enabling fine-grained reward\nassignment aligned with structured chain-of-thought data. We adapt\nReasonFlux-PRM to support reward supervision under both offline and online\nsettings, including (i) selecting high-quality model distillation data for\ndownstream supervised fine-tuning of smaller models, (ii) providing dense\nprocess-level rewards for policy optimization during reinforcement learning,\nand (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results\non challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond\ndemonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs\n(e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our\nderived ReasonFlux-PRM-7B yields consistent performance improvements, achieving\naverage gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement\nlearning, and 6.3% in test-time scaling. We also release our efficient\nReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment.\nProjects: https://github.com/Gen-Verse/ReasonFlux", "published": "2025-06-23 17:59:02", "link": "http://arxiv.org/abs/2506.18896v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization", "abstract": "Recent large-scale language models (LLMs) with long Chain-of-Thought\nreasoning-such as DeepSeek-R1-have achieved impressive results on\nOlympiad-level mathematics benchmarks. However, they often rely on a narrow set\nof strategies and struggle with problems that require a novel way of thinking.\nTo systematically investigate these limitations, we introduce\nOMEGA-Out-of-distribution Math Problems Evaluation with 3 Generalization Axes-a\ncontrolled yet diverse benchmark designed to evaluate three axes of\nout-of-distribution generalization, inspired by Boden's typology of creativity:\n(1) Exploratory-applying known problem solving skills to more complex instances\nwithin the same problem domain; (2) Compositional-combining distinct reasoning\nskills, previously learned in isolation, to solve novel problems that require\nintegrating these skills in new and coherent ways; and (3)\nTransformative-adopting novel, often unconventional strategies by moving beyond\nfamiliar approaches to solve problems more effectively. OMEGA consists of\nprogrammatically generated training-test pairs derived from templated problem\ngenerators across geometry, number theory, algebra, combinatorics, logic, and\npuzzles, with solutions verified using symbolic, numerical, or graphical\nmethods. We evaluate frontier (or top-tier) LLMs and observe sharp performance\ndegradation as problem complexity increases. Moreover, we fine-tune the\nQwen-series models across all generalization settings and observe notable\nimprovements in exploratory generalization, while compositional generalization\nremains limited and transformative reasoning shows little to no improvement. By\nisolating and quantifying these fine-grained failures, OMEGA lays the\ngroundwork for advancing LLMs toward genuine mathematical creativity beyond\nmechanical proficiency.", "published": "2025-06-23 17:51:40", "link": "http://arxiv.org/abs/2506.18880v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CommVQ: Commutative Vector Quantization for KV Cache Compression", "abstract": "Large Language Models (LLMs) are increasingly used in applications requiring\nlong context lengths, but the key-value (KV) cache often becomes a memory\nbottleneck on GPUs as context grows. To address this, we propose Commutative\nVector Quantization (CommVQ) to significantly reduce memory usage for\nlong-context LLM inference. We first introduce additive quantization with a\nlightweight encoder and codebook to compress the KV cache, which can be decoded\nvia simple matrix multiplication. To further reduce computational costs during\ndecoding, we design the codebook to be commutative with Rotary Position\nEmbedding (RoPE) and train it using an Expectation-Maximization (EM) algorithm.\nThis enables efficient integration of decoding into the self-attention\nmechanism. Our approach achieves high accuracy with additive quantization and\nlow overhead via the RoPE-commutative codebook. Experiments on long-context\nbenchmarks and GSM8K show that our method reduces FP16 KV cache size by 87.5%\nwith 2-bit quantization, while outperforming state-of-the-art KV cache\nquantization methods. Notably, it enables 1-bit KV cache quantization with\nminimal accuracy loss, allowing a LLaMA-3.1 8B model to run with a 128K context\nlength on a single RTX 4090 GPU. The source code is available at:\nhttps://github.com/UMass-Embodied-AGI/CommVQ.", "published": "2025-06-23 17:50:11", "link": "http://arxiv.org/abs/2506.18879v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OmniGen2: Exploration to Advanced Multimodal Generation", "abstract": "In this work, we introduce OmniGen2, a versatile and open-source generative\nmodel designed to provide a unified solution for diverse generation tasks,\nincluding text-to-image, image editing, and in-context generation. Unlike\nOmniGen v1, OmniGen2 features two distinct decoding pathways for text and image\nmodalities, utilizing unshared parameters and a decoupled image tokenizer. This\ndesign enables OmniGen2 to build upon existing multimodal understanding models\nwithout the need to re-adapt VAE inputs, thereby preserving the original text\ngeneration capabilities. To facilitate the training of OmniGen2, we developed\ncomprehensive data construction pipelines, encompassing image editing and\nin-context generation data. Additionally, we introduce a reflection mechanism\ntailored for image generation tasks and curate a dedicated reflection dataset\nbased on OmniGen2. Despite its relatively modest parameter size, OmniGen2\nachieves competitive results on multiple task benchmarks, including\ntext-to-image and image editing. To further evaluate in-context generation,\nalso referred to as subject-driven tasks, we introduce a new benchmark named\nOmniContext. OmniGen2 achieves state-of-the-art performance among open-source\nmodels in terms of consistency. We will release our models, training code,\ndatasets, and data construction pipeline to support future research in this\nfield. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:\nhttps://github.com/VectorSpaceLab/OmniGen2", "published": "2025-06-23 17:38:54", "link": "http://arxiv.org/abs/2506.18871v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Mechanistic Interpretability Needs Philosophy", "abstract": "Mechanistic interpretability (MI) aims to explain how neural networks work by\nuncovering their underlying causal mechanisms. As the field grows in influence,\nit is increasingly important to examine not just models themselves, but the\nassumptions, concepts and explanatory strategies implicit in MI research. We\nargue that mechanistic interpretability needs philosophy: not as an\nafterthought, but as an ongoing partner in clarifying its concepts, refining\nits methods, and assessing the epistemic and ethical stakes of interpreting AI\nsystems. Taking three open problems from the MI literature as examples, this\nposition paper illustrates the value philosophy can add to MI research, and\noutlines a path toward deeper interdisciplinary dialogue.", "published": "2025-06-23 17:13:30", "link": "http://arxiv.org/abs/2506.18852v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "USAD: Universal Speech and Audio Representation via Distillation", "abstract": "Self-supervised learning (SSL) has revolutionized audio representations, yet\nmodels often remain domain-specific, focusing on either speech or non-speech\ntasks. In this work, we present Universal Speech and Audio Distillation (USAD),\na unified approach to audio representation learning that integrates diverse\naudio types - speech, sound, and music - into a single model. USAD employs\nefficient layer-to-layer distillation from domain-specific SSL models to train\na student on a comprehensive audio dataset. USAD offers competitive performance\nacross various benchmarks and datasets, including frame and instance-level\nspeech processing tasks, audio tagging, and sound classification, achieving\nnear state-of-the-art results with a single encoder on SUPERB and HEAR\nbenchmarks.", "published": "2025-06-23 17:02:00", "link": "http://arxiv.org/abs/2506.18843v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning", "abstract": "Ultra-long generation by large language models (LLMs) is a widely demanded\nscenario, yet it remains a significant challenge due to their maximum\ngeneration length limit and overall quality degradation as sequence length\nincreases. Previous approaches, exemplified by LongWriter, typically rely on\n''teaching'', which involves supervised fine-tuning (SFT) on synthetic\nlong-form outputs. However, this strategy heavily depends on synthetic SFT\ndata, which is difficult and costly to construct, often lacks coherence and\nconsistency, and tends to be overly artificial and structurally monotonous. In\nthis work, we propose an incentivization-based approach that, starting entirely\nfrom scratch and without relying on any annotated or synthetic data, leverages\nreinforcement learning (RL) to foster the emergence of ultra-long, high-quality\ntext generation capabilities in LLMs. We perform RL training starting from a\nbase model, similar to R1-Zero, guiding it to engage in reasoning that\nfacilitates planning and refinement during the writing process. To support\nthis, we employ specialized reward models that steer the LLM towards improved\nlength control, writing quality, and structural formatting. Experimental\nevaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B,\nconsistently outperforms traditional SFT methods on long-form writing tasks,\nachieving state-of-the-art results across all metrics on WritingBench and\nArena-Write, and even surpassing 100B+ models such as DeepSeek R1 and\nQwen3-235B. We open-source our data and model checkpoints under\nhttps://huggingface.co/THU-KEG/LongWriter-Zero-32B", "published": "2025-06-23 16:59:02", "link": "http://arxiv.org/abs/2506.18841v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "STU-PID: Steering Token Usage via PID Controller for Efficient Large Language Model Reasoning", "abstract": "Large Language Models employing extended chain-of-thought (CoT) reasoning\noften suffer from the overthinking phenomenon, generating excessive and\nredundant reasoning steps that increase computational costs while potentially\ndegrading performance. While recent work has explored static steering\napproaches to mitigate this issue, they lack the adaptability to dynamically\nadjust intervention strength based on real-time reasoning quality. We propose\nSTUPID (Steering Token Usage via PID controller), a novel training-free method\nthat employs a PID controller to dynamically modulate activation steering\nstrength during inference. Our approach combines a chunk-level classifier for\ndetecting redundant reasoning patterns with a PID control mechanism that\nadaptively adjusts steering intensity based on the predicted redundancy\nprobability. Experimental evaluation on GSM8K demonstrates that STUPID achieves\na 6% improvement in accuracy while reducing token usage by 32%, outperforming\nstatic steering baselines. Our method provides a principled framework for\ndynamic reasoning calibration that maintains reasoning quality while\nsignificantly improving computational efficiency.", "published": "2025-06-23 16:47:19", "link": "http://arxiv.org/abs/2506.18831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task", "abstract": "This work describes the participation of the MLLP-VRAIN research group in the\nshared task of the IWSLT 2025 Simultaneous Speech Translation track. Our\nsubmission addresses the unique challenges of real-time translation of\nlong-form speech by developing a modular cascade system that adapts strong\npre-trained models to streaming scenarios. We combine Whisper Large-V3-Turbo\nfor ASR with the multilingual NLLB-3.3B model for MT, implementing lightweight\nadaptation techniques rather than training new end-to-end models from scratch.\nOur approach employs document-level adaptation with prefix training to enhance\nthe MT model's ability to handle incomplete inputs, while incorporating\nadaptive emission policies including a wait-$k$ strategy and RALCP for managing\nthe translation stream. Specialized buffer management techniques and\nsegmentation strategies ensure coherent translations across long audio\nsequences. Experimental results on the ACL60/60 dataset demonstrate that our\nsystem achieves a favorable balance between translation quality and latency,\nwith a BLEU score of 31.96 and non-computational-aware StreamLAAL latency of\n2.94 seconds. Our final model achieves a preliminary score on the official test\nset (IWSLT25Instruct) of 29.8 BLEU. Our work demonstrates that carefully\nadapted pre-trained components can create effective simultaneous translation\nsystems for long-form content without requiring extensive in-domain parallel\ndata or specialized end-to-end training.", "published": "2025-06-23 16:44:01", "link": "http://arxiv.org/abs/2506.18828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies", "abstract": "Large Language Models (LLMs) have been extensively evaluated for general\nsummarization tasks as well as medical research assistance, but they have not\nbeen specifically evaluated for the task of summarizing real-world evidence\n(RWE) from structured output of RWE studies. We introduce RWESummary, a\nproposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,\n2025) to enable benchmarking of LLMs for this task. RWESummary includes one\nscenario and three evaluations covering major types of errors observed in\nsummarization of medical research studies and was developed using Atropos\nHealth proprietary data. Additionally, we use RWESummary to compare the\nperformance of different LLMs in our internal RWE summarization tool. At the\ntime of publication, with 13 distinct RWE studies, we found the Gemini 2.5\nmodels performed best overall (both Flash and Pro). We suggest RWESummary as a\nnovel and useful foundation model benchmark for real-world evidence study\nsummarization.", "published": "2025-06-23 16:28:03", "link": "http://arxiv.org/abs/2506.18819v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "abstract": "Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.", "published": "2025-06-23 16:20:44", "link": "http://arxiv.org/abs/2506.18810v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Existing LLMs Are Not Self-Consistent For Simple Tasks", "abstract": "Large Language Models (LLMs) have grown increasingly powerful, yet ensuring\ntheir decisions remain transparent and trustworthy requires self-consistency --\nno contradictions in their internal reasoning. Our study reveals that even on\nsimple tasks, such as comparing points on a line or a plane, or reasoning in a\nfamily tree, all smaller models are highly inconsistent, and even\nstate-of-the-art models like DeepSeek-R1 and GPT-o4-mini are not fully\nself-consistent. To quantify and mitigate these inconsistencies, we introduce\ninconsistency metrics and propose two automated methods -- a graph-based and an\nenergy-based approach. While these fixes provide partial improvements, they\nalso highlight the complexity and importance of self-consistency in building\nmore reliable and interpretable AI. The code and data are available at\nhttps://github.com/scorpio-nova/llm-self-consistency.", "published": "2025-06-23 15:50:21", "link": "http://arxiv.org/abs/2506.18781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training", "abstract": "Training large language models (LLMs) on source code significantly enhances\ntheir general-purpose reasoning abilities, but the mechanisms underlying this\ngeneralisation are poorly understood. In this paper, we propose Programming by\nBackprop (PBB) as a potential driver of this effect - teaching a model to\nevaluate a program for inputs by training on its source code alone, without\never seeing I/O examples. To explore this idea, we finetune LLMs on two sets of\nprograms representing simple maths problems and algorithms: one with source\ncode and I/O examples (w/ IO), the other with source code only (w/o IO). We\nfind evidence that LLMs have some ability to evaluate w/o IO programs for\ninputs in a range of experimental settings, and make several observations.\nFirstly, PBB works significantly better when programs are provided as code\nrather than semantically equivalent language descriptions. Secondly, LLMs can\nproduce outputs for w/o IO programs directly, by implicitly evaluating the\nprogram within the forward pass, and more reliably when stepping through the\nprogram in-context via chain-of-thought. We further show that PBB leads to more\nrobust evaluation of programs across inputs than training on I/O pairs drawn\nfrom a distribution that mirrors naturally occurring data. Our findings suggest\na mechanism for enhanced reasoning through code training: it allows LLMs to\ninternalise reusable algorithmic abstractions. Significant scope remains for\nfuture work to enable LLMs to more effectively learn from symbolic procedures,\nand progress in this direction opens other avenues like model alignment by\ntraining on formal constitutional principles.", "published": "2025-06-23 15:45:44", "link": "http://arxiv.org/abs/2506.18777v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Neural Total Variation Distance Estimators for Changepoint Detection in News Data", "abstract": "Detecting when public discourse shifts in response to major events is crucial\nfor understanding societal dynamics. Real-world data is high-dimensional,\nsparse, and noisy, making changepoint detection in this domain a challenging\nendeavor. In this paper, we leverage neural networks for changepoint detection\nin news data, introducing a method based on the so-called learning-by-confusion\nscheme, which was originally developed for detecting phase transitions in\nphysical systems. We train classifiers to distinguish between articles from\ndifferent time periods. The resulting classification accuracy is used to\nestimate the total variation distance between underlying content distributions,\nwhere significant distances highlight changepoints. We demonstrate the\neffectiveness of this method on both synthetic datasets and real-world data\nfrom The Guardian newspaper, successfully identifying major historical events\nincluding 9/11, the COVID-19 pandemic, and presidential elections. Our approach\nrequires minimal domain knowledge, can autonomously discover significant shifts\nin public discourse, and yields a quantitative measure of change in content,\nmaking it valuable for journalism, policy analysis, and crisis monitoring.", "published": "2025-06-23 15:33:30", "link": "http://arxiv.org/abs/2506.18764v1", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Multi-modal Anchor Gated Transformer with Knowledge Distillation for Emotion Recognition in Conversation", "abstract": "Emotion Recognition in Conversation (ERC) aims to detect the emotions of\nindividual utterances within a conversation. Generating efficient and\nmodality-specific representations for each utterance remains a significant\nchallenge. Previous studies have proposed various models to integrate features\nextracted using different modality-specific encoders. However, they neglect the\nvarying contributions of modalities to this task and introduce high complexity\nby aligning modalities at the frame level. To address these challenges, we\npropose the Multi-modal Anchor Gated Transformer with Knowledge Distillation\n(MAGTKD) for the ERC task. Specifically, prompt learning is employed to enhance\ntextual modality representations, while knowledge distillation is utilized to\nstrengthen representations of weaker modalities. Furthermore, we introduce a\nmulti-modal anchor gated transformer to effectively integrate utterance-level\nrepresentations across modalities. Extensive experiments on the IEMOCAP and\nMELD datasets demonstrate the effectiveness of knowledge distillation in\nenhancing modality representations and achieve state-of-the-art performance in\nemotion recognition. Our code is available at:\nhttps://github.com/JieLi-dd/MAGTKD.", "published": "2025-06-23 14:53:22", "link": "http://arxiv.org/abs/2506.18716v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Benchmarking the Pedagogical Knowledge of Large Language Models", "abstract": "Benchmarks like Massive Multitask Language Understanding (MMLU) have played a\npivotal role in evaluating AI's knowledge and abilities across diverse domains.\nHowever, existing benchmarks predominantly focus on content knowledge, leaving\na critical gap in assessing models' understanding of pedagogy - the method and\npractice of teaching. This paper introduces The Pedagogy Benchmark, a novel\ndataset designed to evaluate large language models on their Cross-Domain\nPedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)\npedagogical knowledge. These benchmarks are built on a carefully curated set of\nquestions sourced from professional development exams for teachers, which cover\na range of pedagogical subdomains such as teaching strategies and assessment\nmethods. Here we outline the methodology and development of these benchmarks.\nWe report results for 97 models, with accuracies spanning a range from 28% to\n89% on the pedagogical knowledge questions. We consider the relationship\nbetween cost and accuracy and chart the progression of the Pareto value\nfrontier over time. We provide online leaderboards at\nhttps://rebrand.ly/pedagogy which are updated with new models and allow\ninteractive exploration and filtering based on various model properties, such\nas cost per token and open-vs-closed weights, as well as looking at performance\nin different subjects. LLMs and generative AI have tremendous potential to\ninfluence education and help to address the global learning crisis.\nEducation-focused benchmarks are crucial to measure models' capacities to\nunderstand pedagogical concepts, respond appropriately to learners' needs, and\nsupport effective teaching practices across diverse contexts. They are needed\nfor informing the responsible and evidence-based deployment of LLMs and\nLLM-based tools in educational settings, and for guiding both development and\npolicy decisions.", "published": "2025-06-23 14:49:01", "link": "http://arxiv.org/abs/2506.18710v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition", "abstract": "Neural sequence-to-sequence systems deliver state-of-the-art performance for\nautomatic speech recognition. When using appropriate modeling units, e.g.,\nbyte-pair encoded characters, these systems are in principal open vocabulary\nsystems. In practice, however, they often fail to recognize words not seen\nduring training, e.g., named entities, acronyms, or domain-specific special\nwords. To address this problem, many context biasing methods have been\nproposed; however, for words with a pronunciation-orthography mismatch, these\nmethods may still struggle. We propose a method which allows corrections of\nsubstitution errors to improve the recognition accuracy of such challenging\nwords. Users can add corrections on the fly during inference. We show that with\nthis method we get a relative improvement in biased word error rate of up to\n11\\%, while maintaining a competitive overall word error rate.", "published": "2025-06-23 14:42:03", "link": "http://arxiv.org/abs/2506.18703v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is There a Case for Conversation Optimized Tokenizers in Large Language Models?", "abstract": "The computational and energy costs of Large Language Models (LLMs) have\nincreased exponentially driven by the growing model sizes and the massive\nadoption of LLMs by hundreds of millions of users. The unit cost of an LLM is\nthe computation of a token. Therefore, the tokenizer plays an important role in\nthe efficiency of a model, and they are carefully optimized to minimize the\nnumber of tokens for the text in their training corpus. One of the most popular\napplications of LLMs are chatbots that interact with users. A key observation\nis that, for those chatbots, what is important is the performance of the\ntokenizer in the user text input and the chatbot responses. Those are most\nlikely different from the text in the training corpus. So, a question that\nimmediately arises is whether there is a potential benefit in optimizing\ntokenizers for chatbot conversations. In this paper, this idea is explored for\ndifferent tokenizers by using a publicly available corpus of chatbot\nconversations to redesign their vocabularies and evaluate their performance in\nthis domain. The results show that conversation-optimized tokenizers\nconsistently reduce the number of tokens in chatbot dialogues, which can lead\nto meaningful energy savings, in the range of 5% to 10% while having minimal or\neven slightly positive impact on tokenization efficiency for the original\ntraining corpus.", "published": "2025-06-23 14:18:46", "link": "http://arxiv.org/abs/2506.18674v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ByteSpan: Information-Driven Subword Tokenisation", "abstract": "Recent dynamic tokenisation methods operate directly on bytes and pool their\nlatent representations into patches. This bears similarities to computational\nmodels of word segmentation that determine lexical boundaries using spikes in\nan autoregressive model's prediction error. Inspired by this connection, we\nexplore whether grouping predictable bytes - rather than pooling their\nrepresentations - can yield a useful fixed subword vocabulary. We propose a new\ninformation-driven subword tokeniser, ByteSpan, that uses an external\nbyte-level LM during training to identify contiguous predictable byte sequences\nand group them into subwords. Experiments show that ByteSpan yields efficient\nvocabularies with higher morphological alignment scores than BPE for English.\nMultilingual experiments show similar compression and R\\'enyi efficiency for 25\nlanguages.", "published": "2025-06-23 13:42:00", "link": "http://arxiv.org/abs/2506.18639v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "abstract": "DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning\ncapabilities through its rule-based reward system. While it's a ''perfect''\nreward system that effectively mitigates reward hacking, such reward functions\nare often discrete. Our experimental observations suggest that discrete rewards\ncan lead to gradient anomaly, unstable optimization, and slow convergence. To\naddress this issue, we propose ReDit (Reward Dithering), a method that dithers\nthe discrete reward signal by adding simple random noise. With this perturbed\nreward, exploratory gradients are continuously provided throughout the learning\nprocess, enabling smoother gradient updates and accelerating convergence. The\ninjected noise also introduces stochasticity into flat reward regions,\nencouraging the model to explore novel policies and escape local optima.\nExperiments across diverse tasks demonstrate the effectiveness and efficiency\nof ReDit. On average, ReDit achieves performance comparable to vanilla GRPO\nwith only approximately 10% the training steps, and furthermore, still exhibits\na 4% performance improvement over vanilla GRPO when trained for a similar\nduration. Visualizations confirm significant mitigation of gradient issues with\nReDit. Moreover, theoretical analyses are provided to further validate these\nadvantages.", "published": "2025-06-23 13:36:24", "link": "http://arxiv.org/abs/2506.18631v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs", "abstract": "In real-world applications, Large Language Models (LLMs) often hallucinate,\neven in Retrieval-Augmented Generation (RAG) settings, which poses a\nsignificant challenge to their deployment. In this paper, we introduce\nAggTruth, a method for online detection of contextual hallucinations by\nanalyzing the distribution of internal attention scores in the provided context\n(passage). Specifically, we propose four different variants of the method, each\nvarying in the aggregation technique used to calculate attention scores. Across\nall LLMs examined, AggTruth demonstrated stable performance in both same-task\nand cross-task setups, outperforming the current SOTA in multiple scenarios.\nFurthermore, we conducted an in-depth analysis of feature selection techniques\nand examined how the number of selected attention heads impacts detection\nperformance, demonstrating that careful selection of heads is essential to\nachieve optimal results.", "published": "2025-06-23 13:35:05", "link": "http://arxiv.org/abs/2506.18628v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches", "abstract": "This study examines how large language models understand the concept of\npersuasiveness in public speaking by modifying speech transcripts from PhD\ncandidates in the \"Ma These en 180 Secondes\" competition, using the 3MT French\ndataset. Our contributions include a novel methodology and an interpretable\ntextual feature set integrating rhetorical devices and discourse markers. We\nprompt GPT-4o to enhance or diminish persuasiveness and analyze linguistic\nshifts between original and generated speech in terms of the new features.\nResults indicate that GPT-4o applies systematic stylistic modifications rather\nthan optimizing persuasiveness in a human-like manner. Notably, it manipulates\nemotional lexicon and syntactic structures (such as interrogative and\nexclamatory clauses) to amplify rhetorical impact.", "published": "2025-06-23 13:28:33", "link": "http://arxiv.org/abs/2506.18621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic similarity estimation for domain specific data using BERT and other techniques", "abstract": "Estimation of semantic similarity is an important research problem both in\nnatural language processing and the natural language understanding, and that\nhas tremendous application on various downstream tasks such as question\nanswering, semantic search, information retrieval, document clustering,\nword-sense disambiguation and machine translation. In this work, we carry out\nthe estimation of semantic similarity using different state-of-the-art\ntechniques including the USE (Universal Sentence Encoder), InferSent and the\nmost recent BERT, or Bidirectional Encoder Representations from Transformers,\nmodels. We use two question pairs datasets for the analysis, one is a domain\nspecific in-house dataset and the other is a public dataset which is the\nQuora's question pairs dataset. We observe that the BERT model gave much\nsuperior performance as compared to the other methods. This should be because\nof the fine-tuning procedure that is involved in its training process, allowing\nit to learn patterns based on the training data that is used. This works\ndemonstrates the applicability of BERT on domain specific datasets. We infer\nfrom the analysis that BERT is the best technique to use in the case of domain\nspecific data.", "published": "2025-06-23 13:03:59", "link": "http://arxiv.org/abs/2506.18602v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Reply to \"Emergent LLM behaviors are observationally equivalent to data leakage\"", "abstract": "A potential concern when simulating populations of large language models\n(LLMs) is data contamination, i.e. the possibility that training data may shape\noutcomes in unintended ways. While this concern is important and may hinder\ncertain experiments with multi-agent models, it does not preclude the study of\ngenuinely emergent dynamics in LLM populations. The recent critique by Barrie\nand T\\\"ornberg [1] of the results of Flint Ashery et al. [2] offers an\nopportunity to clarify that self-organisation and model-dependent emergent\ndynamics can be studied in LLM populations, highlighting how such dynamics have\nbeen empirically observed in the specific case of social conventions.", "published": "2025-06-23 12:59:34", "link": "http://arxiv.org/abs/2506.18600v1", "categories": ["cs.CL", "cs.GT", "cs.MA"], "primary_category": "cs.CL"}
{"title": "No Training Wheels: Steering Vectors for Bias Correction at Inference Time", "abstract": "Neural network classifiers trained on datasets with uneven group\nrepresentation often inherit class biases and learn spurious correlations.\nThese models may perform well on average but consistently fail on atypical\ngroups. For example, in hair color classification, datasets may over-represent\nfemales with blond hair, reinforcing stereotypes. Although various algorithmic\nand data-centric methods have been proposed to address such biases, they often\nrequire retraining or significant compute. In this work, we propose a cheap,\ntraining-free method inspired by steering vectors used to edit behaviors in\nlarge language models. We compute the difference in mean activations between\nmajority and minority groups to define a \"bias vector,\" which we subtract from\nthe model's residual stream. This leads to reduced classification bias and\nimproved worst-group accuracy. We explore multiple strategies for extracting\nand applying these vectors in transformer-like classifiers, showing that\nsteering vectors, traditionally used in generative models, can also be\neffective in classification. More broadly, we showcase an extremely cheap,\ninference time, training free method to mitigate bias in classification models.", "published": "2025-06-23 12:58:54", "link": "http://arxiv.org/abs/2506.18598v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Airalogy: AI-empowered universal data digitization for research automation", "abstract": "Research data are the foundation of Artificial Intelligence (AI)-driven\nscience, yet current AI applications remain limited to a few fields with\nreadily available, well-structured, digitized datasets. Achieving comprehensive\nAI empowerment across multiple disciplines is still out of reach. Present-day\nresearch data collection is often fragmented, lacking unified standards,\ninefficiently managed, and difficult to share. Creating a single platform for\nstandardized data digitization needs to overcome the inherent challenge of\nbalancing between universality (supporting the diverse, ever-evolving needs of\nvarious disciplines) and standardization (enforcing consistent formats to fully\nenable AI). No existing platform accommodates both facets. Building a truly\nmultidisciplinary platform requires integrating scientific domain knowledge\nwith sophisticated computing skills. Researchers often lack the computational\nexpertise to design customized and standardized data recording methods, whereas\nplatform developers rarely grasp the intricate needs of multiple scientific\ndomains. These gaps impede research data standardization and hamper AI-driven\nprogress. In this study, we address these challenges by developing Airalogy\n(https://airalogy.com), the world's first AI- and community-driven platform\nthat balances universality and standardization for digitizing research data\nacross multiple disciplines. Airalogy represents entire research workflows\nusing customizable, standardized data records and offers an advanced AI\nresearch copilot for intelligent Q&A, automated data entry, analysis, and\nresearch automation. Already deployed in laboratories across all four schools\nof Westlake University, Airalogy has the potential to accelerate and automate\nscientific innovation in universities, industry, and the global research\ncommunity-ultimately benefiting humanity as a whole.", "published": "2025-06-23 12:43:16", "link": "http://arxiv.org/abs/2506.18586v1", "categories": ["cs.AI", "cs.CE", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Parallel Continuous Chain-of-Thought with Jacobi Iteration", "abstract": "Continuous chain-of-thought has been shown to be effective in saving\nreasoning tokens for large language models. By reasoning with continuous latent\nthought tokens, continuous CoT is able to perform implicit reasoning in a\ncompact manner. However, the sequential dependencies between latent thought\ntokens spoil parallel training, leading to long training time. In this paper,\nwe propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi\niteration on the latent thought tokens, updating them iteratively in parallel\ninstead of sequentially and thus improving both training and inference\nefficiency of continuous CoT. Experiments demonstrate that by choosing the\nproper number of iterations, we are able to achieve comparable or even better\nperformance while saving nearly 50% of the training and inference time.\nMoreover, PCCoT shows better stability and robustness in the training process.\nOur code is available at https://github.com/whyNLP/PCCoT.", "published": "2025-06-23 12:35:41", "link": "http://arxiv.org/abs/2506.18582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance", "abstract": "Detecting harmful content is a crucial task in the landscape of NLP\napplications for Social Good, with hate speech being one of its most dangerous\nforms. But what do we mean by hate speech, how can we define it, and how does\nprompting different definitions of hate speech affect model performance? The\ncontribution of this work is twofold. At the theoretical level, we address the\nambiguity surrounding hate speech by collecting and analyzing existing\ndefinitions from the literature. We organize these definitions into a taxonomy\nof 14 Conceptual Elements-building blocks that capture different aspects of\nhate speech definitions, such as references to the target of hate (individual\nor groups) or of the potential consequences of it. At the experimental level,\nwe employ the collection of definitions in a systematic zero-shot evaluation of\nthree LLMs, on three hate speech datasets representing different types of data\n(synthetic, human-in-the-loop, and real-world). We find that choosing different\ndefinitions, i.e., definitions with a different degree of specificity in terms\nof encoded elements, impacts model performance, but this effect is not\nconsistent across all architectures.", "published": "2025-06-23 12:28:13", "link": "http://arxiv.org/abs/2506.18576v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking", "abstract": "This paper investigates the counterintuitive phenomenon where fine-tuning\npre-trained transformer models degrades performance on the MS MARCO passage\nranking task. Through comprehensive experiments involving five model\nvariants-including full parameter fine-tuning and parameter efficient LoRA\nadaptations-we demonstrate that all fine-tuning approaches underperform the\nbase sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our\nanalysis reveals that fine-tuning disrupts the optimal embedding space\nstructure learned during the base model's extensive pre-training on 1 billion\nsentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations\nshow progressive embedding space flattening, while training dynamics analysis\nand computational efficiency metrics further support our findings. These\nresults challenge conventional wisdom about transfer learning effectiveness on\nsaturated benchmarks and suggest architectural innovations may be necessary for\nmeaningful improvements.", "published": "2025-06-23 11:46:05", "link": "http://arxiv.org/abs/2506.18535v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "End-to-End Spoken Grammatical Error Correction", "abstract": "Grammatical Error Correction (GEC) and feedback play a vital role in\nsupporting second language (L2) learners, educators, and examiners. While\nwritten GEC is well-established, spoken GEC (SGEC), aiming to provide feedback\nbased on learners' speech, poses additional challenges due to disfluencies,\ntranscription errors, and the lack of structured input. SGEC systems typically\nfollow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),\ndisfluency detection, and GEC, making them vulnerable to error propagation\nacross modules. This work examines an End-to-End (E2E) framework for SGEC and\nfeedback generation, highlighting challenges and possible solutions when\ndeveloping these systems. Cascaded, partial-cascaded and E2E architectures are\ncompared, all built on the Whisper foundation model. A challenge for E2E\nsystems is the scarcity of GEC labeled spoken data. To address this, an\nautomatic pseudo-labeling framework is examined, increasing the training data\nfrom 77 to over 2500 hours. To improve the accuracy of the SGEC system,\nadditional contextual information, exploiting the ASR output, is investigated.\nCandidate feedback of their mistakes is an essential step to improving\nperformance. In E2E systems the SGEC output must be compared with an estimate\nof the fluent transcription to obtain the feedback. To improve the precision of\nthis feedback, a novel reference alignment process is proposed that aims to\nremove hypothesised edits that results from fluent transcription errors.\nFinally, these approaches are combined with an edit confidence estimation\napproach, to exclude low-confidence edits. Experiments on the in-house\nLinguaskill (LNG) corpora and the publicly available Speak & Improve (S&I)\ncorpus show that the proposed approaches significantly boost E2E SGEC\nperformance.", "published": "2025-06-23 11:40:04", "link": "http://arxiv.org/abs/2506.18532v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts", "abstract": "Accurate detection of disfluencies in spoken language is crucial for\nenhancing the performance of automatic speech and language processing systems,\nas well as fostering the development of more inclusive speech and language\ntechnologies. Leveraging the growing trend of large language models (LLMs) as\nversatile learners capable of processing both lexical and non-lexical inputs\n(e.g., audio and video), we propose a novel approach to transcribing\ndisfluencies as explicit tokens with timestamps, enabling the generation of\nfully annotated disfluency-rich transcripts. Our method integrates acoustic\nrepresentations extracted from an audio encoder with textual inputs of varying\nquality: clean transcriptions without disfluencies, time-aligned transcriptions\nfrom aligners, or outputs from phoneme-based ASR models -- all of which may\ncontain imperfections. Importantly, our experiments demonstrate that textual\ninputs do not need to be flawless. As long as they include timestamp-related\ncues, LLMs can effectively smooth the input and produce fully\ndisfluency-annotated transcripts, underscoring their robustness in handling\nimperfect hints.", "published": "2025-06-23 11:04:20", "link": "http://arxiv.org/abs/2506.18510v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance", "abstract": "The increasing use of large language models (LLMs) in natural language\nprocessing (NLP) tasks has sparked significant interest in evaluating their\neffectiveness across diverse applications. While models like ChatGPT and\nDeepSeek have shown strong results in many NLP domains, a comprehensive\nevaluation is needed to understand their strengths, weaknesses, and\ndomain-specific abilities. This is critical as these models are applied to\nvarious tasks, from sentiment analysis to more nuanced tasks like textual\nentailment and translation. This study aims to evaluate ChatGPT and DeepSeek\nacross five key NLP tasks: sentiment analysis, topic classification, text\nsummarization, machine translation, and textual entailment. A structured\nexperimental protocol is used to ensure fairness and minimize variability. Both\nmodels are tested with identical, neutral prompts and evaluated on two\nbenchmark datasets per task, covering domains like news, reviews, and\nformal/informal texts. The results show that DeepSeek excels in classification\nstability and logical reasoning, while ChatGPT performs better in tasks\nrequiring nuanced understanding and flexibility. These findings provide\nvaluable insights for selecting the appropriate LLM based on task requirements.", "published": "2025-06-23 10:52:54", "link": "http://arxiv.org/abs/2506.18501v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI-Generated Song Detection via Lyrics Transcripts", "abstract": "The recent rise in capabilities of AI-based music generation tools has\ncreated an upheaval in the music industry, necessitating the creation of\naccurate methods to detect such AI-generated content. This can be done using\naudio-based detectors; however, it has been shown that they struggle to\ngeneralize to unseen generators or when the audio is perturbed. Furthermore,\nrecent work used accurate and cleanly formatted lyrics sourced from a lyrics\nprovider database to detect AI-generated music. However, in practice, such\nperfect lyrics are not available (only the audio is); this leaves a substantial\ngap in applicability in real-life use cases. In this work, we instead propose\nsolving this gap by transcribing songs using general automatic speech\nrecognition (ASR) models. We do this using several detectors. The results on\ndiverse, multi-genre, and multi-lingual lyrics show generally strong detection\nperformance across languages and genres, particularly for our best-performing\nmodel using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that\nour method is more robust than state-of-the-art audio-based ones when the audio\nis perturbed in different ways and when evaluated on different music\ngenerators. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "published": "2025-06-23 10:42:50", "link": "http://arxiv.org/abs/2506.18488v1", "categories": ["cs.SD", "cs.AI", "cs.CL"], "primary_category": "cs.SD"}
{"title": "MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful learn-to-reason paradigm for Large Language Models (LLMs) to tackle\ncomplex reasoning tasks. However, existing RLVR methods overlook one of the\nmost distinctive capabilities of LLMs, their in-context learning ability, as\nprominently demonstrated by the success of Chain-of-Thought (CoT) prompting.\nThis motivates us to explore how reinforcement learning can be effectively\ncombined with in-context learning to better improve the reasoning capabilities\nof LLMs. In this paper, we introduce Motivation-enhanced Reinforcement\nFinetuning} (MeRF), an intuitive yet effective method enhancing reinforcement\nlearning of LLMs by involving ``telling LLMs the rules of the game''.\nSpecifically, MeRF directly injects the reward specification into the prompt,\nwhich serves as an in-context motivation for model to improve its responses\nwith awareness of the optimization objective. This simple modification\nleverages the in-context learning ability of LLMs aligning generation with\noptimization, thereby incentivizing the model to generate desired outputs from\nboth inner motivation and external reward. Empirical evaluations on the Knights\nand Knaves~(K&K) logic puzzle reasoning benchmark demonstrate that\n\\texttt{MeRF} achieves substantial performance gains over baselines. Moreover,\nablation studies show that performance improves with greater consistency\nbetween the in-context motivation and the external reward function, while the\nmodel also demonstrates an ability to adapt to misleading motivations through\nreinforcement learning.", "published": "2025-06-23 10:37:57", "link": "http://arxiv.org/abs/2506.18485v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models", "abstract": "The majority of data in businesses and industries is stored in tables,\ndatabases, and data warehouses. Reasoning with table-structured data poses\nsignificant challenges for large language models (LLMs) due to its hidden\nsemantics, inherent complexity, and structured nature. One of these challenges\nis lacking an effective evaluation benchmark fairly reflecting the performances\nof LLMs on broad table reasoning abilities. In this paper, we fill in this gap,\npresenting a comprehensive table reasoning evolution benchmark, TReB, which\nmeasures both shallow table understanding abilities and deep table reasoning\nabilities, a total of 26 sub-tasks. We construct a high quality dataset through\nan iterative data processing procedure. We create an evaluation framework to\nrobustly measure table reasoning capabilities with three distinct inference\nmodes, TCoT, PoT and ICoT. Further, we benchmark over 20 state-of-the-art LLMs\nusing this frame work and prove its effectiveness. Experimental results reveal\nthat existing LLMs still have significant room for improvement in addressing\nthe complex and real world Table related tasks. Both the dataset and evaluation\nframework are publicly available, with the dataset hosted on [HuggingFace] and\nthe framework on [GitHub].", "published": "2025-06-23 09:02:04", "link": "http://arxiv.org/abs/2506.18421v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lemmatization as a Classification Task: Results from Arabic across Multiple Genres", "abstract": "Lemmatization is crucial for NLP tasks in morphologically rich languages with\nambiguous orthography like Arabic, but existing tools face challenges due to\ninconsistent standards and limited genre coverage. This paper introduces two\nnovel approaches that frame lemmatization as classification into a\nLemma-POS-Gloss (LPG) tagset, leveraging machine translation and semantic\nclustering. We also present a new Arabic lemmatization test set covering\ndiverse genres, standardized alongside existing datasets. We evaluate character\nlevel sequence-to-sequence models, which perform competitively and offer\ncomplementary value, but are limited to lemma prediction (not LPG) and prone to\nhallucinating implausible forms. Our results show that classification and\nclustering yield more robust, interpretable outputs, setting new benchmarks for\nArabic lemmatization.", "published": "2025-06-23 08:34:33", "link": "http://arxiv.org/abs/2506.18399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics", "abstract": "This study investigates how accurately different evaluation metrics capture\nthe quality of causal explanations in automatically generated diagnostic\nreports. We compare six metrics: BERTScore, Cosine Similarity, BioSentVec,\nGPT-White, GPT-Black, and expert qualitative assessment across two input types:\nobservation-based and multiple-choice-based report generation. Two weighting\nstrategies are applied: one reflecting task-specific priorities, and the other\nassigning equal weights to all metrics. Our results show that GPT-Black\ndemonstrates the strongest discriminative power in identifying logically\ncoherent and clinically valid causal narratives. GPT-White also aligns well\nwith expert evaluations, while similarity-based metrics diverge from clinical\nreasoning quality. These findings emphasize the impact of metric selection and\nweighting on evaluation outcomes, supporting the use of LLM-based evaluation\nfor tasks requiring interpretability and causal reasoning.", "published": "2025-06-23 08:19:21", "link": "http://arxiv.org/abs/2506.18387v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SlimMoE: Structured Compression of Large MoE Models via Expert Slimming and Distillation", "abstract": "The Mixture of Experts (MoE) architecture has emerged as a powerful paradigm\nfor scaling large language models (LLMs) while maintaining inference\nefficiency. However, their enormous memory requirements make them prohibitively\nexpensive to fine-tune or deploy in resource-constrained environments. To\naddress this challenge, we introduce SlimMoE, a multi-stage compression\nframework for transforming large MoE models into much smaller, efficient\nvariants without incurring the prohibitive costs of training from scratch. Our\nmethod systematically reduces parameter counts by slimming experts and\ntransferring knowledge through intermediate stages, effectively mitigating the\nperformance degradation common in one-shot pruning approaches. Using this\nframework, we compress Phi 3.5-MoE (41.9B total/6.6B activated parameters) to\ncreate Phi-mini-MoE (7.6B total/2.4B activated parameters) and Phi-tiny-MoE\n(3.8B total/1.1B activated parameters) using only 400B tokens--less than 10% of\nthe original model's training data. These compressed models can be fine-tuned\non a single GPU (A100 for Phi-mini-MoE, A6000 for Phi-tiny-MoE), making them\nhighly suitable for academic and resource-limited settings. Our experiments\ndemonstrate that these compressed models outperform others of similar size and\nremain competitive with larger models. For instance, Phi-mini-MoE achieves\nsimilar or better performance to Phi-3-mini using only 2/3 of the activated\nparameters and yields comparable MMLU scores to Llama 3.1 8B despite having\nsignificantly lower latency. Our findings demonstrate that structured pruning\ncombined with staged distillation offers an effective path to creating\nhigh-quality, compact MoE models, paving the way for broader adoption of MoE\narchitectures. We make our models publicly available at\nhttps://huggingface.co/microsoft/Phi-mini-MoE-instruct and\nhttps://huggingface.co/microsoft/Phi-tiny-MoE-instruct .", "published": "2025-06-23 07:15:59", "link": "http://arxiv.org/abs/2506.18349v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs", "abstract": "This paper explores the challenges of test-time scaling of large language\nmodels (LLMs), regarding both the data and inference efficiency. We highlight\nthe diversity of multi-lingual reasoning based on our pilot studies, and then\nintroduce a novel approach, \\(L^2\\) multi-lingual unification learning with a\ndecoding intervention strategy for further investigation. The basic idea of\n\\(L^2\\) is that the reasoning process varies across different languages, which\nmay be mutually beneficial to enhance both model performance and efficiency. In\nspecific, there are two types of multi-lingual data: the entire long\nchain-of-thought annotations in different languages and the step-wise mixture\nof languages. By further tuning based on them, we show that even small amounts\nof data can significantly improve reasoning capabilities. Our findings suggest\nthat multilingual learning reduces both the required data and the number of\ninference tokens while maintaining a comparable performance. Furthermore,\n\\(L^2\\) is orthogonal to other data efficient methods. Thus, we also emphasize\nthe importance of diverse data selection. The \\(L^2\\) method offers a promising\nsolution to the challenges of data collection and test-time compute efficiency\nin LLMs.", "published": "2025-06-23 06:47:28", "link": "http://arxiv.org/abs/2506.18341v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance", "abstract": "Machine translation (MT) post-editing and research data collection often rely\non inefficient, disconnected workflows. We introduce TranslationCorrect, an\nintegrated framework designed to streamline these tasks. TranslationCorrect\ncombines MT generation using models like NLLB, automated error prediction using\nmodels like XCOMET or LLM APIs (providing detailed reasoning), and an intuitive\npost-editing interface within a single environment. Built with human-computer\ninteraction (HCI) principles in mind to minimize cognitive load, as confirmed\nby a user study. For translators, it enables them to correct errors and batch\ntranslate efficiently. For researchers, TranslationCorrect exports high-quality\nspan-based annotations in the Error Span Annotation (ESA) format, using an\nerror taxonomy inspired by Multidimensional Quality Metrics (MQM). These\noutputs are compatible with state-of-the-art error detection models and\nsuitable for training MT or post-editing systems. Our user study confirms that\nTranslationCorrect significantly improves translation efficiency and user\nsatisfaction over traditional annotation methods.", "published": "2025-06-23 06:38:49", "link": "http://arxiv.org/abs/2506.18337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning", "abstract": "We introduce Confucius3-Math, an open-source large language model with 14B\nparameters that (1) runs efficiently on a single consumer-grade GPU; (2)\nachieves SOTA performances on a range of mathematical reasoning tasks,\noutperforming many models with significantly larger sizes. In particular, as\npart of our mission to enhancing education and knowledge dissemination with AI,\nConfucius3-Math is specifically committed to mathematics learning for Chinese\nK-12 students and educators. Built via post-training with large-scale\nreinforcement learning (RL), Confucius3-Math aligns with national curriculum\nand excels at solving main-stream Chinese K-12 mathematical problems with low\ncost. In this report we share our development recipe, the challenges we\nencounter and the techniques we develop to overcome them. In particular, we\nintroduce three technical innovations: Targeted Entropy Regularization, Recent\nSample Recovery and Policy-Specific Hardness Weighting. These innovations\nencompass a new entropy regularization, a novel data scheduling policy, and an\nimproved group-relative advantage estimator. Collectively, they significantly\nstabilize the RL training, improve data efficiency, and boost performance. Our\nwork demonstrates the feasibility of building strong reasoning models in a\nparticular domain at low cost. We open-source our model and code at\nhttps://github.com/netease-youdao/Confucius3-Math.", "published": "2025-06-23 06:23:53", "link": "http://arxiv.org/abs/2506.18330v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Entity Aware Machine Translation with Multi-task Learning", "abstract": "Entity-aware machine translation (EAMT) is a complicated task in natural\nlanguage processing due to not only the shortage of translation data related to\nthe entities needed to translate but also the complexity in the context needed\nto process while translating those entities. In this paper, we propose a method\nthat applies multi-task learning to optimize the performance of the two\nsubtasks named entity recognition and machine translation, which improves the\nfinal performance of the Entity-aware machine translation task. The result and\nanalysis are performed on the dataset provided by the organizer of Task 2 of\nthe SemEval 2025 competition.", "published": "2025-06-23 06:05:46", "link": "http://arxiv.org/abs/2506.18318v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Team LA at SCIDOCA shared task 2025: Citation Discovery via relation-based zero-shot retrieval", "abstract": "The Citation Discovery Shared Task focuses on predicting the correct citation\nfrom a given candidate pool for a given paragraph. The main challenges stem\nfrom the length of the abstract paragraphs and the high similarity among\ncandidate abstracts, making it difficult to determine the exact paper to cite.\nTo address this, we develop a system that first retrieves the top-k most\nsimilar abstracts based on extracted relational features from the given\nparagraph. From this subset, we leverage a Large Language Model (LLM) to\naccurately identify the most relevant citation. We evaluate our framework on\nthe training dataset provided by the SCIDOCA 2025 organizers, demonstrating its\neffectiveness in citation prediction.", "published": "2025-06-23 06:01:21", "link": "http://arxiv.org/abs/2506.18316v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Enhancing Document Retrieval in COVID-19 Research: Leveraging Large Language Models for Hidden Relation Extraction", "abstract": "In recent years, with the appearance of the COVID-19 pandemic, numerous\npublications relevant to this disease have been issued. Because of the massive\nvolume of publications, an efficient retrieval system is necessary to provide\nresearchers with useful information if an unexpected pandemic happens so\nsuddenly, like COVID-19. In this work, we present a method to help the\nretrieval system, the Covrelex-SE system, to provide more high-quality search\nresults. We exploited the power of the large language models (LLMs) to extract\nthe hidden relationships inside the unlabeled publication that cannot be found\nby the current parsing tools that the system is using. Since then, help the\nsystem to have more useful information during retrieval progress.", "published": "2025-06-23 05:55:53", "link": "http://arxiv.org/abs/2506.18311v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "RLPR: Extrapolating RLVR to General Domains without Verifiers", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates promising\npotential in advancing the reasoning capabilities of LLMs. However, its success\nremains largely confined to mathematical and code domains. This primary\nlimitation stems from the heavy reliance on domain-specific verifiers, which\nresults in prohibitive complexity and limited scalability. To address the\nchallenge, our key observation is that LLM's intrinsic probability of\ngenerating a correct free-form answer directly indicates its own evaluation of\nthe reasoning reward (i.e., how well the reasoning process leads to the correct\nanswer). Building on this insight, we propose RLPR, a simple verifier-free\nframework that extrapolates RLVR to broader general domains. RLPR uses the\nLLM's own token probability scores for reference answers as the reward signal\nand maximizes the expected reward during training. We find that addressing the\nhigh variance of this noisy probability reward is crucial to make it work, and\npropose prob-to-reward and stabilizing methods to ensure a precise and stable\nreward from LLM intrinsic probabilities. Comprehensive experiments in four\ngeneral-domain benchmarks and three mathematical benchmarks show that RLPR\nconsistently improves reasoning capabilities in both areas for Gemma, Llama,\nand Qwen based models. Notably, RLPR outperforms concurrent VeriFree by 7.6\npoints on TheoremQA and 7.5 points on Minerva, and even surpasses strong\nverifier-model-dependent approaches General-Reasoner by 1.6 average points\nacross seven benchmarks.", "published": "2025-06-23 02:56:36", "link": "http://arxiv.org/abs/2506.18254v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AdapThink: Adaptive Thinking Preferences for Reasoning Language Model", "abstract": "Reinforcement Learning (RL)-based post-training has significantly advanced\nthe complex reasoning capabilities of language models, fostering sophisticated\nself-reflection processes. However, this ``slow thinking'' paradigm presents a\ncritical challenge to reasoning efficiency: models may expend excessive\ncomputation on simple questions and shift reasoning prematurely for complex\nones. Previous mechanisms typically rely on static length budgets or predefined\nrules, lacking the adaptability for varying question complexities and models'\nevolving capabilities. To this end, we propose AdapThink, an adaptive\npost-training framework designed to induce more efficient thinking while\nmaintaining the performance of reasoning language models. Specifically,\nAdapThink incorporates two key mechanisms: 1) A group-relative reward function\nthat leverages model confidence and response's characteristic to dynamically\nadjust the preference of reflection-related transition words without resorting\nto a fixed length preference. 2) A diversity-aware sampling mechanism that\nbalances the training group's solution accuracy with reasoning diversity via an\nentropy-guided score. Experiments on several mathematical reasoning datasets\nwith DeepSeek-distilled models demonstrate AdapThink's advantages in enabling\nadaptive reasoning patterns and mitigating the inefficiencies.", "published": "2025-06-23 02:06:04", "link": "http://arxiv.org/abs/2506.18237v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MinD: Unified Visual Imagination and Control via Hierarchical World Models", "abstract": "Video generation models (VGMs) offer a promising pathway for unified world\nmodeling in robotics by integrating simulation, prediction, and manipulation.\nHowever, their practical application remains limited due to (1) slowgeneration\nspeed, which limits real-time interaction, and (2) poor consistency between\nimagined videos and executable actions. To address these challenges, we propose\nManipulate in Dream (MinD), a hierarchical diffusion-based world model\nframework that employs a dual-system design for vision-language manipulation.\nMinD executes VGM at low frequencies to extract video prediction features,\nwhile leveraging a high-frequency diffusion policy for real-time interaction.\nThis architecture enables low-latency, closed-loop control in manipulation with\ncoherent visual guidance. To better coordinate the two systems, we introduce a\nvideo-action diffusion matching module (DiffMatcher), with a novel co-training\nstrategy that uses separate schedulers for each diffusion model. Specifically,\nwe introduce a diffusion-forcing mechanism to DiffMatcher that aligns their\nintermediate representations during training, helping the fast action model\nbetter understand video-based predictions. Beyond manipulation, MinD also\nfunctions as a world simulator, reliably predicting task success or failure in\nlatent space before execution. Trustworthy analysis further shows that VGMs can\npreemptively evaluate task feasibility and mitigate risks. Extensive\nexperiments across multiple benchmarks demonstrate that MinD achieves\nstate-of-the-art manipulation (63%+) in RL-Bench, advancing the frontier of\nunified world modeling in robotics.", "published": "2025-06-23 17:59:06", "link": "http://arxiv.org/abs/2506.18897v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation", "abstract": "This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems.", "published": "2025-06-23 17:56:34", "link": "http://arxiv.org/abs/2506.18887v1", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "I.2.7; I.2.6; I.2.1; D.3.3; C.4"], "primary_category": "cs.AI"}
{"title": "OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation", "abstract": "Significant progress has been made in audio-driven human animation, while\nmost existing methods focus mainly on facial movements, limiting their ability\nto create full-body animations with natural synchronization and fluidity. They\nalso struggle with precise prompt control for fine-grained generation. To\ntackle these challenges, we introduce OmniAvatar, an innovative audio-driven\nfull-body video generation model that enhances human animation with improved\nlip-sync accuracy and natural movements. OmniAvatar introduces a pixel-wise\nmulti-hierarchical audio embedding strategy to better capture audio features in\nthe latent space, enhancing lip-syncing across diverse scenes. To preserve the\ncapability for prompt-driven control of foundation models while effectively\nincorporating audio features, we employ a LoRA-based training approach.\nExtensive experiments show that OmniAvatar surpasses existing models in both\nfacial and semi-body video generation, offering precise text-based control for\ncreating videos in various domains, such as podcasts, human interactions,\ndynamic scenes, and singing. Our project page is\nhttps://omni-avatar.github.io/.", "published": "2025-06-23 17:33:03", "link": "http://arxiv.org/abs/2506.18866v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting", "abstract": "Satellite image time-series analysis demands fine-grained spatial-temporal\nreasoning, which remains a challenge for existing multimodal large language\nmodels (MLLMs). In this work, we study the capabilities of MLLMs on a novel\ntask that jointly targets temporal change understanding and future scene\ngeneration, aiming to assess their potential for modeling complex multimodal\ndynamics over time. We propose TAMMs, a Temporal-Aware Multimodal Model for\nsatellite image change understanding and forecasting, which enhances frozen\nMLLMs with lightweight temporal modules for structured sequence encoding and\ncontextual prompting. To guide future image generation, TAMMs introduces a\nSemantic-Fused Control Injection (SFCI) mechanism that adaptively combines\nhigh-level semantic reasoning and structural priors within an enhanced\nControlNet. This dual-path conditioning enables temporally consistent and\nsemantically grounded image synthesis. Experiments demonstrate that TAMMs\noutperforms strong MLLM baselines in both temporal change understanding and\nfuture image forecasting tasks, highlighting how carefully designed temporal\nreasoning and semantic fusion can unlock the full potential of MLLMs for\nspatio-temporal understanding.", "published": "2025-06-23 17:26:16", "link": "http://arxiv.org/abs/2506.18862v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories", "abstract": "Large Language Model (LLM)-based agents are increasingly employed to automate\ncomplex software engineering tasks such as program repair and issue resolution.\nThese agents operate by autonomously generating natural language thoughts,\ninvoking external tools, and iteratively refining their solutions. Despite\ntheir widespread adoption, the internal decision-making processes of these\nagents remain largely unexplored, limiting our understanding of their\noperational dynamics and failure modes. In this paper, we present a large-scale\nempirical study of the thought-action-result trajectories of three\nstate-of-the-art LLM-based agents: \\textsc{RepairAgent},\n\\textsc{AutoCodeRover}, and \\textsc{OpenHands}. We unify their interaction logs\ninto a common format, capturing 120 trajectories and 2822 LLM interactions\nfocused on program repair and issue resolution. Our study combines quantitative\nanalyses of structural properties, action patterns, and token usage with\nqualitative assessments of reasoning coherence and feedback integration. We\nidentify key trajectory characteristics such as iteration counts and token\nconsumption, recurring action sequences, and the semantic coherence linking\nthoughts, actions, and their results. Our findings reveal behavioral motifs and\nanti-patterns that distinguish successful from failed executions, providing\nactionable insights for improving agent design, including prompting strategies,\nfailure diagnosis, and anti-pattern detection. We release our dataset and\nannotation framework to support further research on transparent and robust\nautonomous software engineering agents.", "published": "2025-06-23 16:34:52", "link": "http://arxiv.org/abs/2506.18824v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness", "abstract": "Autonomous driving perception faces significant challenges due to occlusions\nand incomplete scene data in the environment. To overcome these issues, the\ntask of semantic occupancy prediction (SOP) is proposed, which aims to jointly\ninfer both the geometry and semantic labels of a scene from images. However,\nconventional camera-based methods typically treat all categories equally and\nprimarily rely on local features, leading to suboptimal predictions, especially\nfor dynamic foreground objects. To address this, we propose Object-Centric SOP\n(OC-SOP), a framework that integrates high-level object-centric cues extracted\nvia a detection branch into the semantic occupancy prediction pipeline. This\nobject-centric integration significantly enhances the prediction accuracy for\nforeground objects and achieves state-of-the-art performance among all\ncategories on SemanticKITTI.", "published": "2025-06-23 16:03:53", "link": "http://arxiv.org/abs/2506.18798v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning", "abstract": "Federated Learning (FL) enables collaborative model training across\ndecentralized clients without sharing raw data, yet faces significant\nchallenges in real-world settings where client data distributions evolve\ndynamically over time. This paper tackles the critical problem of covariate and\nlabel shifts in streaming FL environments, where non-stationary data\ndistributions degrade model performance and require adaptive middleware\nsolutions. We introduce ShiftEx, a shift-aware mixture of experts framework\nthat dynamically creates and trains specialized global models in response to\ndetected distribution shifts using Maximum Mean Discrepancy for covariate\nshifts. The framework employs a latent memory mechanism for expert reuse and\nimplements facility location-based optimization to jointly minimize covariate\nmismatch, expert creation costs, and label imbalance. Through theoretical\nanalysis and comprehensive experiments on benchmark datasets, we demonstrate\n5.5-12.9 percentage point accuracy improvements and 22-95 % faster adaptation\ncompared to state-of-the-art FL baselines across diverse shift scenarios. The\nproposed approach offers a scalable, privacy-preserving middleware solution for\nFL systems operating in non-stationary, real-world conditions while minimizing\ncommunication and computational overhead.", "published": "2025-06-23 15:59:21", "link": "http://arxiv.org/abs/2506.18789v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving", "abstract": "Perception systems in autonomous driving rely on sensors such as LiDAR and\ncameras to perceive the 3D environment. However, due to occlusions and data\nsparsity, these sensors often fail to capture complete information. Semantic\nOccupancy Prediction (SOP) addresses this challenge by inferring both occupancy\nand semantics of unobserved regions. Existing transformer-based SOP methods\nlack explicit modeling of spatial structure in attention computation, resulting\nin limited geometric awareness and poor performance in sparse or occluded\nareas. To this end, we propose Spatially-aware Window Attention (SWA), a novel\nmechanism that incorporates local spatial context into attention. SWA\nsignificantly improves scene completion and achieves state-of-the-art results\non LiDAR-based SOP benchmarks. We further validate its generality by\nintegrating SWA into a camera-based SOP pipeline, where it also yields\nconsistent gains across modalities.", "published": "2025-06-23 15:54:28", "link": "http://arxiv.org/abs/2506.18785v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation", "abstract": "TRIZ, the Theory of Inventive Problem Solving, is a structured,\nknowledge-based framework for innovation and abstracting problems to find\ninventive solutions. However, its application is often limited by the\ncomplexity and deep interdisciplinary knowledge required. Advancements in Large\nLanguage Models (LLMs) have revealed new possibilities for automating parts of\nthis process. While previous studies have explored single LLMs in TRIZ\napplications, this paper introduces a multi-agent approach. We propose an\nLLM-based multi-agent system, called TRIZ agents, each with specialized\ncapabilities and tool access, collaboratively solving inventive problems based\non the TRIZ methodology. This multi-agent system leverages agents with various\ndomain expertise to efficiently navigate TRIZ steps. The aim is to model and\nsimulate an inventive process with language agents. We assess the effectiveness\nof this team of agents in addressing complex innovation challenges based on a\nselected case study in engineering. We demonstrate the potential of agent\ncollaboration to produce diverse, inventive solutions. This research\ncontributes to the future of AI-driven innovation, showcasing the advantages of\ndecentralized problem-solving in complex ideation tasks.", "published": "2025-06-23 15:53:14", "link": "http://arxiv.org/abs/2506.18783v1", "categories": ["cs.AI", "cs.MA", "68T07", "I.2.11; I.2.7; I.2.8"], "primary_category": "cs.AI"}
{"title": "Sensitivity Analysis of Image Classification Models using Generalized Polynomial Chaos", "abstract": "Integrating advanced communication protocols in production has accelerated\nthe adoption of data-driven predictive quality methods, notably machine\nlearning (ML) models. However, ML models in image classification often face\nsignificant uncertainties arising from model, data, and domain shifts. These\nuncertainties lead to overconfidence in the classification model's output. To\nbetter understand these models, sensitivity analysis can help to analyze the\nrelative influence of input parameters on the output. This work investigates\nthe sensitivity of image classification models used for predictive quality. We\npropose modeling the distributional domain shifts of inputs with random\nvariables and quantifying their impact on the model's outputs using Sobol\nindices computed via generalized polynomial chaos (GPC). This approach is\nvalidated through a case study involving a welding defect classification\nproblem, utilizing a fine-tuned ResNet18 model and an emblem classification\nmodel used in BMW Group production facilities.", "published": "2025-06-23 15:22:31", "link": "http://arxiv.org/abs/2506.18751v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ContinualFlow: Learning and Unlearning with Neural Flow Matching", "abstract": "We introduce ContinualFlow, a principled framework for targeted unlearning in\ngenerative models via Flow Matching. Our method leverages an energy-based\nreweighting loss to softly subtract undesired regions of the data distribution\nwithout retraining from scratch or requiring direct access to the samples to be\nunlearned. Instead, it relies on energy-based proxies to guide the unlearning\nprocess. We prove that this induces gradients equivalent to Flow Matching\ntoward a soft mass-subtracted target, and validate the framework through\nexperiments on 2D and image domains, supported by interpretable visualizations\nand quantitative evaluations.", "published": "2025-06-23 15:20:58", "link": "http://arxiv.org/abs/2506.18747v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On the Existence of Universal Simulators of Attention", "abstract": "Prior work on the learnability of transformers has established its capacity\nto approximate specific algorithmic patterns through training under restrictive\narchitectural assumptions. Fundamentally, these arguments remain data-driven\nand therefore can only provide a probabilistic guarantee. Expressivity, on the\ncontrary, has theoretically been explored to address the problems\n\\emph{computable} by such architecture. These results proved the\nTuring-completeness of transformers, investigated bounds focused on circuit\ncomplexity, and formal logic. Being at the crossroad between learnability and\nexpressivity, the question remains: \\emph{can transformer architectures exactly\nsimulate an arbitrary attention mechanism, or in particular, the underlying\noperations?} In this study, we investigate the transformer encoder's ability to\nsimulate a vanilla attention mechanism. By constructing a universal simulator\n$\\mathcal{U}$ composed of transformer encoders, we present algorithmic\nsolutions to identically replicate attention outputs and the underlying\nelementary matrix and activation operations via RASP, a formal framework for\ntransformer computation. Our proofs, for the first time, show the existence of\nan algorithmically achievable data-agnostic solution, previously known to be\napproximated only by learning.", "published": "2025-06-23 15:15:25", "link": "http://arxiv.org/abs/2506.18739v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deep CNN Face Matchers Inherently Support Revocable Biometric Templates", "abstract": "One common critique of biometric authentication is that if an individual's\nbiometric is compromised, then the individual has no recourse. The concept of\nrevocable biometrics was developed to address this concern. A biometric scheme\nis revocable if an individual can have their current enrollment in the scheme\nrevoked, so that the compromised biometric template becomes worthless, and the\nindividual can re-enroll with a new template that has similar recognition\npower. We show that modern deep CNN face matchers inherently allow for a robust\nrevocable biometric scheme. For a given state-of-the-art deep CNN backbone and\ntraining set, it is possible to generate an unlimited number of distinct face\nmatcher models that have both (1) equivalent recognition power, and (2)\nstrongly incompatible biometric templates. The equivalent recognition power\nextends to the point of generating impostor and genuine distributions that have\nthe same shape and placement on the similarity dimension, meaning that the\nmodels can share a similarity threshold for a 1-in-10,000 false match rate. The\nbiometric templates from different model instances are so strongly incompatible\nthat the cross-instance similarity score for images of the same person is\ntypically lower than the same-instance similarity score for images of different\npersons. That is, a stolen biometric template that is revoked is of less value\nin attempting to match the re-enrolled identity than the average impostor\ntemplate. We also explore the feasibility of using a Vision Transformer (ViT)\nbackbone-based face matcher in the revocable biometric system proposed in this\nwork and demonstrate that it is less suitable compared to typical ResNet-based\ndeep CNN backbones.", "published": "2025-06-23 15:09:04", "link": "http://arxiv.org/abs/2506.18731v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners", "abstract": "We propose MuseControlLite, a lightweight mechanism designed to fine-tune\ntext-to-music generation models for precise conditioning using various\ntime-varying musical attributes and reference audio signals. The key finding is\nthat positional embeddings, which have been seldom used by text-to-music\ngeneration models in the conditioner for text conditions, are critical when the\ncondition of interest is a function of time. Using melody control as an\nexample, our experiments show that simply adding rotary positional embeddings\nto the decoupled cross-attention layers increases control accuracy from 56.6%\nto 61.1%, while requiring 6.75 times fewer trainable parameters than\nstate-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion\nTransformer model of Stable Audio Open. We evaluate various forms of musical\nattribute control, audio inpainting, and audio outpainting, demonstrating\nimproved controllability over MusicGen-Large and Stable Audio Open ControlNet\nat a significantly lower fine-tuning cost, with only 85M trainble parameters.\nSource code, model checkpoints, and demo examples are available at: https:\n//MuseControlLite.github.io/web/.", "published": "2025-06-23 15:08:03", "link": "http://arxiv.org/abs/2506.18729v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer", "abstract": "Stock price prediction is vital for investment decisions and risk management,\nyet remains challenging due to markets' nonlinear dynamics and time-varying\ninter-stock correlations. Traditional static-correlation models fail to capture\nevolving stock relationships. To address this, we propose a Differential Graph\nTransformer (DGT) framework for dynamic relationship modeling and price\nprediction. Our DGT integrates sequential graph structure changes into\nmulti-head self-attention via a differential graph mechanism, adaptively\npreserving high-value connections while suppressing noise. Causal temporal\nattention captures global/local dependencies in price sequences. We further\nevaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's\nTau) across global/local/dual scopes as spatial-attention priors. Using 10\nyears of S&P 500 closing prices (z-score normalized; 64-day sliding windows),\nDGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).\nKendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means\nclustering revealed \"high-volatility growth\" and \"defensive blue-chip\" stocks,\nwith the latter showing lower errors (RMSE: 0.13) due to stable correlations.\nKendall's Tau and Mutual Information excelled in volatile sectors. This study\ninnovatively combines differential graph structures with Transformers,\nvalidating dynamic relationship modeling and identifying optimal correlation\nmetrics/scopes. Clustering analysis supports tailored quantitative strategies.\nOur framework advances financial time-series prediction through dynamic\nmodeling and cross-asset interaction analysis.", "published": "2025-06-23 14:53:31", "link": "http://arxiv.org/abs/2506.18717v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Frequency-Weighted Training Losses for Phoneme-Level DNN-based Speech Enhancement", "abstract": "Recent advances in deep learning have significantly improved multichannel\nspeech enhancement algorithms, yet conventional training loss functions such as\nthe scale-invariant signal-to-distortion ratio (SDR) may fail to preserve\nfine-grained spectral cues essential for phoneme intelligibility. In this work,\nwe propose perceptually-informed variants of the SDR loss, formulated in the\ntime-frequency domain and modulated by frequency-dependent weighting schemes.\nThese weights are designed to emphasize time-frequency regions where speech is\nprominent or where the interfering noise is particularly strong. We investigate\nboth fixed and adaptive strategies, including ANSI band-importance weights,\nspectral magnitude-based weighting, and dynamic weighting based on the relative\namount of speech and noise. We train the FaSNet multichannel speech enhancement\nmodel using these various losses. Experimental results show that while standard\nmetrics such as the SDR are only marginally improved, their perceptual\nfrequency-weighted counterparts exhibit a more substantial improvement.\nBesides, spectral and phoneme-level analysis indicates better consonant\nreconstruction, which points to a better preservation of certain acoustic cues.", "published": "2025-06-23 14:52:34", "link": "http://arxiv.org/abs/2506.18714v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Matrix-Game: Interactive World Foundation Model", "abstract": "We introduce Matrix-Game, an interactive world foundation model for\ncontrollable game world generation. Matrix-Game is trained using a two-stage\npipeline that first performs large-scale unlabeled pretraining for environment\nunderstanding, followed by action-labeled training for interactive video\ngeneration. To support this, we curate Matrix-Game-MC, a comprehensive\nMinecraft dataset comprising over 2,700 hours of unlabeled gameplay video clips\nand over 1,000 hours of high-quality labeled clips with fine-grained keyboard\nand mouse action annotations. Our model adopts a controllable image-to-world\ngeneration paradigm, conditioned on a reference image, motion context, and user\nactions. With over 17 billion parameters, Matrix-Game enables precise control\nover character actions and camera movements, while maintaining high visual\nquality and temporal coherence. To evaluate performance, we develop GameWorld\nScore, a unified benchmark measuring visual quality, temporal quality, action\ncontrollability, and physical rule understanding for Minecraft world\ngeneration. Extensive experiments show that Matrix-Game consistently\noutperforms prior open-source Minecraft world models (including Oasis and\nMineWorld) across all metrics, with particularly strong gains in\ncontrollability and physical consistency. Double-blind human evaluations\nfurther confirm the superiority of Matrix-Game, highlighting its ability to\ngenerate perceptually realistic and precisely controllable videos across\ndiverse game scenarios. To facilitate future research on interactive\nimage-to-world generation, we will open-source the Matrix-Game model weights\nand the GameWorld Score benchmark at https://github.com/SkyworkAI/Matrix-Game.", "published": "2025-06-23 14:40:49", "link": "http://arxiv.org/abs/2506.18701v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NOVA: Navigation via Object-Centric Visual Autonomy for High-Speed Target Tracking in Unstructured GPS-Denied Environments", "abstract": "Autonomous aerial target tracking in unstructured and GPS-denied environments\nremains a fundamental challenge in robotics. Many existing methods rely on\nmotion capture systems, pre-mapped scenes, or feature-based localization to\nensure safety and control, limiting their deployment in real-world conditions.\nWe introduce NOVA, a fully onboard, object-centric framework that enables\nrobust target tracking and collision-aware navigation using only a stereo\ncamera and an IMU. Rather than constructing a global map or relying on absolute\nlocalization, NOVA formulates perception, estimation, and control entirely in\nthe target's reference frame. A tightly integrated stack combines a lightweight\nobject detector with stereo depth completion, followed by histogram-based\nfiltering to infer robust target distances under occlusion and noise. These\nmeasurements feed a visual-inertial state estimator that recovers the full\n6-DoF pose of the robot relative to the target. A nonlinear model predictive\ncontroller (NMPC) plans dynamically feasible trajectories in the target frame.\nTo ensure safety, high-order control barrier functions are constructed online\nfrom a compact set of high-risk collision points extracted from depth, enabling\nreal-time obstacle avoidance without maps or dense representations. We validate\nNOVA across challenging real-world scenarios, including urban mazes, forest\ntrails, and repeated transitions through buildings with intermittent GPS loss\nand severe lighting changes that disrupt feature-based localization. Each\nexperiment is repeated multiple times under similar conditions to assess\nresilience, showing consistent and reliable performance. NOVA achieves agile\ntarget following at speeds exceeding 50 km/h. These results show that\nhigh-speed vision-based tracking is possible in the wild using only onboard\nsensing, with no reliance on external localization or environment assumptions.", "published": "2025-06-23 14:28:30", "link": "http://arxiv.org/abs/2506.18689v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification", "abstract": "We introduce the Shape-Image Multimodal Network (SIM-Net), a novel 2D image\nclassification architecture that integrates 3D point cloud representations\ninferred directly from RGB images. Our key contribution lies in a\npixel-to-point transformation that converts 2D object masks into 3D point\nclouds, enabling the fusion of texture-based and geometric features for\nenhanced classification performance. SIM-Net is particularly well-suited for\nthe classification of digitized herbarium specimens (a task made challenging by\nheterogeneous backgrounds), non-plant elements, and occlusions that compromise\nconventional image-based models. To address these issues, SIM-Net employs a\nsegmentation-based preprocessing step to extract object masks prior to 3D point\ncloud generation. The architecture comprises a CNN encoder for 2D image\nfeatures and a PointNet-based encoder for geometric features, which are fused\ninto a unified latent space. Experimental evaluations on herbarium datasets\ndemonstrate that SIM-Net consistently outperforms ResNet101, achieving gains of\nup to 9.9% in accuracy and 12.3% in F-score. It also surpasses several\ntransformer-based state-of-the-art architectures, highlighting the benefits of\nincorporating 3D structural reasoning into 2D image classification tasks.", "published": "2025-06-23 14:25:40", "link": "http://arxiv.org/abs/2506.18683v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi-Scale Spectral Attention Module-based Hyperspectral Segmentation in Autonomous Driving Scenarios", "abstract": "Recent advances in autonomous driving (AD) have highlighted the potential of\nHyperspectral Imaging (HSI) for enhanced environmental perception, particularly\nin challenging weather and lighting conditions. However, efficiently processing\nits high-dimensional spectral data remains a significant challenge. This paper\nintroduces a Multi-scale Spectral Attention Module (MSAM) that enhances\nspectral feature extraction through three parallel 1D convolutions with varying\nkernel sizes between 1 to 11, coupled with an adaptive feature aggregation\nmechanism. By integrating MSAM into UNet's skip connections (UNet-SC), our\nproposed UNet-MSAM achieves significant improvements in semantic segmentation\nperformance across multiple HSI datasets: HyKo-VIS v2, HSI-Drive v2, and\nHyperspectral City v2. Our comprehensive experiments demonstrate that with\nminimal computational overhead (on average 0.02% in parameters and 0.82%\nGFLOPS), UNet-MSAM consistently outperforms UNet-SC, achieving average\nimprovements of 3.61% in mean IoU and 3.80% in mF1 across the three datasets.\nThrough extensive ablation studies, we have established that multi-scale kernel\ncombinations perform better than single-scale configurations. These findings\ndemonstrate the potential of HSI processing for AD and provide valuable\ninsights into designing robust, multi-scale spectral feature extractors for\nreal-world applications.", "published": "2025-06-23 14:24:20", "link": "http://arxiv.org/abs/2506.18682v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping", "abstract": "Pretraining on large-scale, in-domain datasets grants histopathology\nfoundation models (FM) the ability to learn task-agnostic data representations,\nenhancing transfer learning on downstream tasks. In computational pathology,\nautomated whole slide image analysis requires multiple instance learning (MIL)\nframeworks due to the gigapixel scale of the slides. The diversity among\nhistopathology FMs has highlighted the need to design real-world challenges for\nevaluating their effectiveness. To bridge this gap, our work presents a novel\nbenchmark for evaluating histopathology FMs as patch-level feature extractors\nwithin a MIL classification framework. For that purpose, we leverage the\nAI4SkIN dataset, a multi-center cohort encompassing slides with challenging\ncutaneous spindle cell neoplasm subtypes. We also define the Foundation Model -\nSilhouette Index (FM-SI), a novel metric to measure model consistency against\ndistribution shifts. Our experimentation shows that extracting less biased\nfeatures enhances classification performance, especially in similarity-based\nMIL classifiers.", "published": "2025-06-23 14:12:16", "link": "http://arxiv.org/abs/2506.18668v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Historical Report Guided Bi-modal Concurrent Learning for Pathology Report Generation", "abstract": "Automated pathology report generation from Whole Slide Images (WSIs) faces\ntwo key challenges: (1) lack of semantic content in visual features and (2)\ninherent information redundancy in WSIs. To address these issues, we propose a\nnovel Historical Report Guided \\textbf{Bi}-modal Concurrent Learning Framework\nfor Pathology Report \\textbf{Gen}eration (BiGen) emulating pathologists'\ndiagnostic reasoning, consisting of: (1) A knowledge retrieval mechanism to\nprovide rich semantic content, which retrieves WSI-relevant knowledge from\npre-built medical knowledge bank by matching high-attention patches and (2) A\nbi-modal concurrent learning strategy instantiated via a learnable visual token\nand a learnable textual token to dynamically extract key visual features and\nretrieved knowledge, where weight-shared layers enable cross-modal alignment\nbetween visual features and knowledge features. Our multi-modal decoder\nintegrates both modals for comprehensive diagnostic reports generation.\nExperiments on the PathText (BRCA) dataset demonstrate our framework's\nsuperiority, achieving state-of-the-art performance with 7.4\\% relative\nimprovement in NLP metrics and 19.1\\% enhancement in classification metrics for\nHer-2 prediction versus existing methods. Ablation studies validate the\nnecessity of our proposed modules, highlighting our method's ability to provide\nWSI-relevant rich semantic content and suppress information redundancy in WSIs.\nCode is publicly available at https://github.com/DeepMed-Lab-ECNU/BiGen.", "published": "2025-06-23 14:00:21", "link": "http://arxiv.org/abs/2506.18658v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems", "abstract": "Behavioral diversity in Multi-agent reinforcement learning(MARL) represents\nan emerging and promising research area. Prior work has largely centered on\nintra-group behavioral consistency in multi-agent systems, with limited\nattention given to behavioral consistency in multi-agent grouping scenarios. In\nthis paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL\ncontrol method designed to explicitly regulate agent behaviors at both\nintra-group and inter-group levels. DLBC partitions agents into distinct groups\nand dynamically modulates behavioral diversity both within and between these\ngroups. By dynamically modulating behavioral diversity within and between these\ngroups, DLBC achieves enhanced division of labor through inter-group\nconsistency, which constrains behavioral strategies across different groups.\nSimultaneously, intra-group consistency, achieved by aligning behavioral\nstrategies within each group, fosters stronger intra-group cooperation.\nCrucially, DLBC's direct constraint of agent policy functions ensures its broad\napplicability across various algorithmic frameworks. Experimental results in\nvarious grouping cooperation scenarios demonstrate that DLBC significantly\nenhances both intra-group cooperative performance and inter-group task\nspecialization, yielding substantial performance improvements. DLBC provides\nnew ideas for behavioral consistency control of multi-intelligent body systems,\nand its potential for application in more complex tasks and dynamic\nenvironments can be further explored in the future.", "published": "2025-06-23 13:54:34", "link": "http://arxiv.org/abs/2506.18651v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Federated Loss Exploration for Improved Convergence on Non-IID Data", "abstract": "Federated learning (FL) has emerged as a groundbreaking paradigm in machine\nlearning (ML), offering privacy-preserving collaborative model training across\ndiverse datasets. Despite its promise, FL faces significant hurdles in\nnon-identically and independently distributed (non-IID) data scenarios, where\nmost existing methods often struggle with data heterogeneity and lack\nrobustness in performance. This paper introduces Federated Loss Exploration\n(FedLEx), an innovative approach specifically designed to tackle these\nchallenges. FedLEx distinctively addresses the shortcomings of existing FL\nmethods in non-IID settings by optimizing its learning behavior for scenarios\nin which assumptions about data heterogeneity are impractical or unknown. It\nemploys a federated loss exploration technique, where clients contribute to a\nglobal guidance matrix by calculating gradient deviations for model parameters.\nThis matrix serves as a strategic compass to guide clients' gradient updates in\nsubsequent FL rounds, thereby fostering optimal parameter updates for the\nglobal model. FedLEx effectively navigates the complex loss surfaces inherent\nin non-IID data, enhancing knowledge transfer in an efficient manner, since\nonly a small number of epochs and small amount of data are required to build a\nstrong global guidance matrix that can achieve model convergence without the\nneed for additional data sharing or data distribution statics in a large client\nscenario. Our extensive experiments with state-of-the art FL algorithms\ndemonstrate significant improvements in performance, particularly under\nrealistic non-IID conditions, thus highlighting FedLEx's potential to overcome\ncritical barriers in diverse FL applications.", "published": "2025-06-23 13:42:07", "link": "http://arxiv.org/abs/2506.18640v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Granular-Ball-Induced Multiple Kernel K-Means", "abstract": "Most existing multi-kernel clustering algorithms, such as multi-kernel\nK-means, often struggle with computational efficiency and robustness when faced\nwith complex data distributions. These challenges stem from their dependence on\npoint-to-point relationships for optimization, which can lead to difficulty in\naccurately capturing data sets' inherent structure and diversity. Additionally,\nthe intricate interplay between multiple kernels in such algorithms can further\nexacerbate these issues, effectively impacting their ability to cluster data\npoints in high-dimensional spaces. In this paper, we leverage granular-ball\ncomputing to improve the multi-kernel clustering framework. The core of\ngranular-ball computing is to adaptively fit data distribution by balls from\ncoarse to acceptable levels. Each ball can enclose data points based on a\ndensity consistency measurement. Such ball-based data description thus improves\nthe computational efficiency and the robustness to unknown noises.\nSpecifically, based on granular-ball representations, we introduce the\ngranular-ball kernel (GBK) and its corresponding granular-ball multi-kernel\nK-means framework (GB-MKKM) for efficient clustering. Using granular-ball\nrelationships in multiple kernel spaces, the proposed GB-MKKM framework shows\nits superiority in efficiency and clustering performance in the empirical\nevaluation of various clustering tasks.", "published": "2025-06-23 13:39:32", "link": "http://arxiv.org/abs/2506.18637v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits", "abstract": "Inverse design of photonic integrated circuits (PICs) has traditionally\nrelied on gradientbased optimization. However, this approach is prone to end up\nin local minima, which results in suboptimal design functionality. As interest\nin PICs increases due to their potential for addressing modern hardware demands\nthrough optical computing, more adaptive optimization algorithms are needed. We\npresent a reinforcement learning (RL) environment as well as multi-agent RL\nalgorithms for the design of PICs. By discretizing the design space into a\ngrid, we formulate the design task as an optimization problem with thousands of\nbinary variables. We consider multiple two- and three-dimensional design tasks\nthat represent PIC components for an optical computing system. By decomposing\nthe design space into thousands of individual agents, our algorithms are able\nto optimize designs with only a few thousand environment samples. They\noutperform previous state-of-the-art gradient-based optimization in both twoand\nthree-dimensional design tasks. Our work may also serve as a benchmark for\nfurther exploration of sample-efficient RL for inverse design in photonics.", "published": "2025-06-23 13:34:27", "link": "http://arxiv.org/abs/2506.18627v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Frequency Control in Microgrids: An Adaptive Fuzzy-Neural-Network Virtual Synchronous Generator", "abstract": "The reliance on distributed renewable energy has increased recently. As a\nresult, power electronic-based distributed generators replaced synchronous\ngenerators which led to a change in the dynamic characteristics of the\nmicrogrid. Most critically, they reduced system inertia and damping. Virtual\nsynchronous generators emulated in power electronics, which mimic the dynamic\nbehaviour of synchronous generators, are meant to fix this problem. However,\nfixed virtual synchronous generator parameters cannot guarantee a frequency\nregulation within the acceptable tolerance range. Conversely, a dynamic\nadjustment of these virtual parameters promises robust solution with stable\nfrequency. This paper proposes a method to adapt the inertia, damping, and\ndroop parameters dynamically through a fuzzy neural network controller. This\ncontroller trains itself online to choose appropriate values for these virtual\nparameters. The proposed method can be applied to a typical AC microgrid by\nconsidering the penetration and impact of renewable energy sources. We study\nthe system in a MATLAB/Simulink model and validate it experimentally in real\ntime using hardware-in-the-loop based on an embedded ARM system (SAM3X8E,\nCortex-M3). Compared to traditional and fuzzy logic controller methods, the\nresults demonstrate that the proposed method significantly reduces the\nfrequency deviation to less than 0.03 Hz and shortens the stabilizing/recovery\ntime.", "published": "2025-06-23 13:16:52", "link": "http://arxiv.org/abs/2506.18611v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Simulation-Free Differential Dynamics through Neural Conservation Laws", "abstract": "We present a novel simulation-free framework for training continuous-time\ndiffusion processes over very general objective functions. Existing methods\ntypically involve either prescribing the optimal diffusion process -- which\nonly works for heavily restricted problem formulations -- or require expensive\nsimulation to numerically obtain the time-dependent densities and sample from\nthe diffusion process. In contrast, we propose a coupled parameterization which\njointly models a time-dependent density function, or probability path, and the\ndynamics of a diffusion process that generates this probability path. To\naccomplish this, our approach directly bakes in the Fokker-Planck equation and\ndensity function requirements as hard constraints, by extending and greatly\nsimplifying the construction of Neural Conservation Laws. This enables\nsimulation-free training for a large variety of problem formulations, from\ndata-driven objectives as in generative modeling and dynamical optimal\ntransport, to optimality-based objectives as in stochastic optimal control,\nwith straightforward extensions to mean-field objectives due to the ease of\naccessing exact density functions. We validate our method in a diverse range of\napplication domains from modeling spatio-temporal events to learning optimal\ndynamics from population data.", "published": "2025-06-23 13:04:23", "link": "http://arxiv.org/abs/2506.18604v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BulletGen: Improving 4D Reconstruction with Bullet-Time Generation", "abstract": "Transforming casually captured, monocular videos into fully immersive dynamic\nexperiences is a highly ill-posed task, and comes with significant challenges,\ne.g., reconstructing unseen regions, and dealing with the ambiguity in\nmonocular depth estimation. In this work we introduce BulletGen, an approach\nthat takes advantage of generative models to correct errors and complete\nmissing information in a Gaussian-based dynamic scene representation. This is\ndone by aligning the output of a diffusion-based video generation model with\nthe 4D reconstruction at a single frozen \"bullet-time\" step. The generated\nframes are then used to supervise the optimization of the 4D Gaussian model.\nOur method seamlessly blends generative content with both static and dynamic\nscene components, achieving state-of-the-art results on both novel-view\nsynthesis, and 2D/3D tracking tasks.", "published": "2025-06-23 13:03:42", "link": "http://arxiv.org/abs/2506.18601v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Optimization-Induced Dynamics of Lipschitz Continuity in Neural Networks", "abstract": "Lipschitz continuity characterizes the worst-case sensitivity of neural\nnetworks to small input perturbations; yet its dynamics (i.e. temporal\nevolution) during training remains under-explored. We present a rigorous\nmathematical framework to model the temporal evolution of Lipschitz continuity\nduring training with stochastic gradient descent (SGD). This framework\nleverages a system of stochastic differential equations (SDEs) to capture both\ndeterministic and stochastic forces. Our theoretical analysis identifies three\nprincipal factors driving the evolution: (i) the projection of gradient flows,\ninduced by the optimization dynamics, onto the operator-norm Jacobian of\nparameter matrices; (ii) the projection of gradient noise, arising from the\nrandomness in mini-batch sampling, onto the operator-norm Jacobian; and (iii)\nthe projection of the gradient noise onto the operator-norm Hessian of\nparameter matrices. Furthermore, our theoretical framework sheds light on such\nas how noisy supervision, parameter initialization, batch size, and mini-batch\nsampling trajectories, among other factors, shape the evolution of the\nLipschitz continuity of neural networks. Our experimental results demonstrate\nstrong agreement between the theoretical implications and the observed\nbehaviors.", "published": "2025-06-23 12:49:13", "link": "http://arxiv.org/abs/2506.18588v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent", "abstract": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems.", "published": "2025-06-23 12:11:15", "link": "http://arxiv.org/abs/2506.18559v1", "categories": ["cs.AI", "cs.LO", "I.2.7; F.4.1"], "primary_category": "cs.AI"}
{"title": "Security Assessment of DeepSeek and GPT Series Models against Jailbreak Attacks", "abstract": "The widespread deployment of large language models (LLMs) has raised critical\nconcerns over their vulnerability to jailbreak attacks, i.e., adversarial\nprompts that bypass alignment mechanisms and elicit harmful or policy-violating\noutputs. While proprietary models like GPT-4 have undergone extensive\nevaluation, the robustness of emerging open-source alternatives such as\nDeepSeek remains largely underexplored, despite their growing adoption in\nreal-world applications. In this paper, we present the first systematic\njailbreak evaluation of DeepSeek-series models, comparing them with GPT-3.5 and\nGPT-4 using the HarmBench benchmark. We evaluate seven representative attack\nstrategies across 510 harmful behaviors categorized by both function and\nsemantic domain. Our analysis reveals that DeepSeek's Mixture-of-Experts (MoE)\narchitecture introduces routing sparsity that offers selective robustness\nagainst optimization-based attacks such as TAP-T, but leads to significantly\nhigher vulnerability under prompt-based and manually engineered attacks. In\ncontrast, GPT-4 Turbo demonstrates stronger and more consistent safety\nalignment across diverse behaviors, likely due to its dense Transformer design\nand reinforcement learning from human feedback. Fine-grained behavioral\nanalysis and case studies further show that DeepSeek often routes adversarial\nprompts to under-aligned expert modules, resulting in inconsistent refusal\nbehaviors. These findings highlight a fundamental trade-off between\narchitectural efficiency and alignment generalization, emphasizing the need for\ntargeted safety tuning and modular alignment strategies to ensure secure\ndeployment of open-source LLMs.", "published": "2025-06-23 11:53:31", "link": "http://arxiv.org/abs/2506.18543v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence", "abstract": "Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is\ncrucial for mitigating biases and promoting equitable decision-making. However,\nexisting AI risk assessment frameworks often overlook inclusivity, lacking\nstandardized tools to measure an AI system's alignment with D&I principles.\nThis paper introduces a structured AI inclusivity question bank, a\ncomprehensive set of 253 questions designed to evaluate AI inclusivity across\nfive pillars: Humans, Data, Process, System, and Governance. The development of\nthe question bank involved an iterative, multi-source approach, incorporating\ninsights from literature reviews, D&I guidelines, Responsible AI frameworks,\nand a simulated user study. The simulated evaluation, conducted with 70\nAI-generated personas related to different AI jobs, assessed the question\nbank's relevance and effectiveness for AI inclusivity across diverse roles and\napplication domains. The findings highlight the importance of integrating D&I\nprinciples into AI development workflows and governance structures. The\nquestion bank provides an actionable tool for researchers, practitioners, and\npolicymakers to systematically assess and enhance the inclusivity of AI\nsystems, paving the way for more equitable and responsible AI technologies.", "published": "2025-06-23 11:48:38", "link": "http://arxiv.org/abs/2506.18538v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Embedded FPGA Acceleration of Brain-Like Neural Networks: Online Learning to Scalable Inference", "abstract": "Edge AI applications increasingly require models that can learn and adapt\non-device with minimal energy budget. Traditional deep learning models, while\npowerful, are often overparameterized, energy-hungry, and dependent on cloud\nconnectivity. Brain-Like Neural Networks (BLNNs), such as the Bayesian\nConfidence Propagation Neural Network (BCPNN), propose a neuromorphic\nalternative by mimicking cortical architecture and biologically-constrained\nlearning. They offer sparse architectures with local learning rules and\nunsupervised/semi-supervised learning, making them well-suited for low-power\nedge intelligence. However, existing BCPNN implementations rely on GPUs or\ndatacenter FPGAs, limiting their applicability to embedded systems. This work\npresents the first embedded FPGA accelerator for BCPNN on a Zynq UltraScale+\nSoC using High-Level Synthesis. We implement both online learning and\ninference-only kernels with support for variable and mixed precision. Evaluated\non MNIST, Pneumonia, and Breast Cancer datasets, our accelerator achieves up to\n17.5x latency and 94% energy savings over ARM baselines, without sacrificing\naccuracy. This work enables practical neuromorphic computing on edge devices,\nbridging the gap between brain-like learning and real-world deployment.", "published": "2025-06-23 11:35:20", "link": "http://arxiv.org/abs/2506.18530v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance", "abstract": "Identifying the appropriate regulatory standard applicability remains a\ncritical yet understudied challenge in medical device compliance, frequently\nnecessitating expert interpretation of fragmented and heterogeneous\ndocumentation across different jurisdictions. To address this challenge, we\nintroduce a modular AI system that leverages a retrieval-augmented generation\n(RAG) pipeline to automate standard applicability determination. Given a\nfree-text device description, our system retrieves candidate standards from a\ncurated corpus and uses large language models to infer jurisdiction-specific\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\ntraceable justifications. We construct an international benchmark dataset of\nmedical device descriptions with expert-annotated standard mappings, and\nevaluate our system against retrieval-only, zero-shot, and rule-based\nbaselines. The proposed approach attains a classification accuracy of 73% and a\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\nrelevant regulatory standards. We introduce the first end-to-end system for\nstandard applicability reasoning, enabling scalable and interpretable\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\nconflict resolution and applicability justification across regulatory\nframeworks.", "published": "2025-06-23 11:04:58", "link": "http://arxiv.org/abs/2506.18511v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey", "abstract": "Recently, vision-language pretraining has emerged as a transformative\ntechnique that integrates the strengths of both visual and textual modalities,\nresulting in powerful vision-language models (VLMs). Leveraging web-scale\npretraining data, these models exhibit strong zero-shot capabilities. However,\ntheir performance often deteriorates when confronted with domain-specific or\nspecialized generalization tasks. To address this, a growing body of research\nfocuses on transferring or generalizing the rich knowledge embedded in VLMs to\nvarious downstream applications. This survey aims to comprehensively summarize\nthe generalization settings, methodologies, benchmarking and results in VLM\nliteratures. Delving into the typical VLM structures, current literatures are\ncategorized into prompt-based, parameter-based and feature-based methods\naccording to the transferred modules. The differences and characteristics in\neach category are furthered summarized and discussed by revisiting the typical\ntransfer learning (TL) settings, providing novel interpretations for TL in the\nera of VLMs. Popular benchmarks for VLM generalization are further introduced\nwith thorough performance comparisons among the reviewed methods. Following the\nadvances in large-scale generalizable pretraining, this survey also discusses\nthe relations and differences between VLMs and up-to-date multimodal large\nlanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the\nsurging literatures in vision-language research from a novel and practical\ngeneralization prospective, this survey contributes to a clear landscape of\ncurrent and future multimodal researches.", "published": "2025-06-23 10:56:37", "link": "http://arxiv.org/abs/2506.18504v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PuckTrick: A Library for Making Synthetic Data More Realistic", "abstract": "The increasing reliance on machine learning (ML) models for decision-making\nrequires high-quality training data. However, access to real-world datasets is\noften restricted due to privacy concerns, proprietary restrictions, and\nincomplete data availability. As a result, synthetic data generation (SDG) has\nemerged as a viable alternative, enabling the creation of artificial datasets\nthat preserve the statistical properties of real data while ensuring privacy\ncompliance. Despite its advantages, synthetic data is often overly clean and\nlacks real-world imperfections, such as missing values, noise, outliers, and\nmisclassified labels, which can significantly impact model generalization and\nrobustness. To address this limitation, we introduce Pucktrick, a Python\nlibrary designed to systematically contaminate synthetic datasets by\nintroducing controlled errors. The library supports multiple error types,\nincluding missing data, noisy values, outliers, label misclassification,\nduplication, and class imbalance, offering a structured approach to evaluating\nML model resilience under real-world data imperfections. Pucktrick provides two\ncontamination modes: one for injecting errors into clean datasets and another\nfor further corrupting already contaminated datasets. Through extensive\nexperiments on real-world financial datasets, we evaluate the impact of\nsystematic data contamination on model performance. Our findings demonstrate\nthat ML models trained on contaminated synthetic data outperform those trained\non purely synthetic, error-free data, particularly for tree-based and linear\nmodels such as SVMs and Extra Trees.", "published": "2025-06-23 10:51:45", "link": "http://arxiv.org/abs/2506.18499v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "H.4.1; I.2.1"], "primary_category": "cs.LG"}
{"title": "A Deep Convolutional Neural Network-Based Novel Class Balancing for Imbalance Data Segmentation", "abstract": "Retinal fundus images provide valuable insights into the human eye's interior\nstructure and crucial features, such as blood vessels, optic disk, macula, and\nfovea. However, accurate segmentation of retinal blood vessels can be\nchallenging due to imbalanced data distribution and varying vessel thickness.\nIn this paper, we propose BLCB-CNN, a novel pipeline based on deep learning and\nbi-level class balancing scheme to achieve vessel segmentation in retinal\nfundus images. The BLCB-CNN scheme uses a Convolutional Neural Network (CNN)\narchitecture and an empirical approach to balance the distribution of pixels\nacross vessel and non-vessel classes and within thin and thick vessels. Level-I\nis used for vessel/non-vessel balancing and Level-II is used for thick/thin\nvessel balancing. Additionally, pre-processing of the input retinal fundus\nimage is performed by Global Contrast Normalization (GCN), Contrast Limited\nAdaptive Histogram Equalization (CLAHE), and gamma corrections to increase\nintensity uniformity as well as to enhance the contrast between vessels and\nbackground pixels. The resulting balanced dataset is used for\nclassification-based segmentation of the retinal vascular tree. We evaluate the\nproposed scheme on standard retinal fundus images and achieve superior\nperformance measures, including an area under the ROC curve of 98.23%, Accuracy\nof 96.22%, Sensitivity of 81.57%, and Specificity of 97.65%. We also\ndemonstrate the method's efficacy through external cross-validation on STARE\nimages, confirming its generalization ability.", "published": "2025-06-23 10:15:54", "link": "http://arxiv.org/abs/2506.18474v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging", "abstract": "Artificial Intelligence (AI) holds significant promise for improving\nprognosis prediction in medical imaging, yet its effective application remains\nchallenging. In this work, we introduce a structured benchmark explicitly\ndesigned to evaluate and compare the transferability of Convolutional Neural\nNetworks and Foundation Models in predicting clinical outcomes in COVID-19\npatients, leveraging diverse publicly available Chest X-ray datasets. Our\nexperimental methodology extensively explores a wide set of fine-tuning\nstrategies, encompassing traditional approaches such as Full Fine-Tuning and\nLinear Probing, as well as advanced Parameter-Efficient Fine-Tuning methods\nincluding Low-Rank Adaptation, BitFit, VeRA, and IA3. The evaluations were\nconducted across multiple learning paradigms, including both extensive\nfull-data scenarios and more clinically realistic Few-Shot Learning settings,\nwhich are critical for modeling rare disease outcomes and rapidly emerging\nhealth threats. By implementing a large-scale comparative analysis involving a\ndiverse selection of pretrained models, including general-purpose architectures\npretrained on large-scale datasets such as CLIP and DINOv2, to\nbiomedical-specific models like MedCLIP, BioMedCLIP, and PubMedCLIP, we\nrigorously assess each model's capacity to effectively adapt and generalize to\nprognosis tasks, particularly under conditions of severe data scarcity and\npronounced class imbalance. The benchmark was designed to capture critical\nconditions common in prognosis tasks, including variations in dataset size and\nclass distribution, providing detailed insights into the strengths and\nlimitations of each fine-tuning strategy. This extensive and structured\nevaluation aims to inform the practical deployment and adoption of robust,\nefficient, and generalizable AI-driven solutions in real-world clinical\nprognosis prediction workflows.", "published": "2025-06-23 09:16:04", "link": "http://arxiv.org/abs/2506.18434v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models", "abstract": "Model editing offers a low-cost technique to inject or correct a particular\nbehavior in a pre-trained model without extensive retraining, supporting\napplications such as factual correction and bias mitigation. Despite this\ncommon practice, it remains unknown whether edits persist after fine-tuning or\nwhether they are inadvertently reversed. This question has fundamental\npractical implications. For example, if fine-tuning removes prior edits, it\ncould serve as a defence mechanism against hidden malicious edits. Vice versa,\nthe unintended removal of edits related to bias mitigation could pose serious\nsafety concerns. We systematically investigate the interaction between model\nediting and fine-tuning in the context of T2I diffusion models, which are known\nto exhibit biases and generate inappropriate content. Our study spans two T2I\nmodel families (Stable Diffusion and FLUX), two sota editing techniques, and\nthree fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive\nempirical analysis across diverse editing tasks and evaluation metrics, our\nfindings reveal a trend: edits generally fail to persist through fine-tuning,\neven when fine-tuning is tangential or unrelated to the edits. Notably, we\nobserve that DoRA exhibits the strongest edit reversal effect. At the same\ntime, among editing methods, UCE demonstrates greater robustness, retaining\nsignificantly higher efficacy post-fine-tuning compared to ReFACT. These\nfindings highlight a crucial limitation in current editing methodologies,\nemphasizing the need for more robust techniques to ensure reliable long-term\ncontrol and alignment of deployed AI systems. These findings have dual\nimplications for AI safety: they suggest that fine-tuning could serve as a\nremediation mechanism for malicious edits while simultaneously highlighting the\nneed for re-editing after fine-tuning to maintain beneficial safety and\nalignment properties.", "published": "2025-06-23 09:10:29", "link": "http://arxiv.org/abs/2506.18428v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction", "abstract": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods.", "published": "2025-06-23 09:03:58", "link": "http://arxiv.org/abs/2506.18424v1", "categories": ["cs.AI", "cs.ET"], "primary_category": "cs.AI"}
{"title": "Latent Space Analysis for Melanoma Prevention", "abstract": "Melanoma represents a critical health risk due to its aggressive progression\nand high mortality, underscoring the need for early, interpretable diagnostic\ntools. While deep learning has advanced in skin lesion classification, most\nexisting models provide only binary outputs, offering limited clinical insight.\nThis work introduces a novel approach that extends beyond classification,\nenabling interpretable risk modelling through a Conditional Variational\nAutoencoder. The proposed method learns a structured latent space that captures\nsemantic relationships among lesions, allowing for a nuanced, continuous\nassessment of morphological differences. An SVM is also trained on this\nrepresentation effectively differentiating between benign nevi and melanomas,\ndemonstrating strong and consistent performance. More importantly, the learned\nlatent space supports visual and geometric interpretation of malignancy, with\nthe spatial proximity of a lesion to known melanomas serving as a meaningful\nindicator of risk. This approach bridges predictive performance with clinical\napplicability, fostering early detection, highlighting ambiguous cases, and\nenhancing trust in AI-assisted diagnosis through transparent and interpretable\ndecision-making.", "published": "2025-06-23 08:49:57", "link": "http://arxiv.org/abs/2506.18414v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs", "abstract": "The effectiveness of AI debugging follows a predictable exponential decay\npattern; most models lose 60-80% of their debugging capability within just 2-3\nattempts, despite iterative debugging being a critical capability for practical\ncode generation systems. We introduce the Debugging Decay Index (DDI), a\nmathematical framework that quantifies when debugging becomes ineffective and\npredicts intervention points. Our strategic fresh start approach shifts from\nexploitation to exploration at strategic points in the debugging process,\ndemonstrating that well-timed interventions can rescue the effectiveness of\ndebugging. DDI reveals a fundamental limitation in current AI debugging and\nprovides the first quantitative framework for optimising iterative code\ngeneration strategies.", "published": "2025-06-23 08:40:45", "link": "http://arxiv.org/abs/2506.18403v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "ADNF-Clustering: An Adaptive and Dynamic Neuro-Fuzzy Clustering for Leukemia Prediction", "abstract": "Leukemia diagnosis and monitoring rely increasingly on high-throughput image\ndata, yet conventional clustering methods lack the flexibility to accommodate\nevolving cellular patterns and quantify uncertainty in real time. We introduce\nAdaptive and Dynamic Neuro-Fuzzy Clustering, a novel streaming-capable\nframework that combines Convolutional Neural Network-based feature extraction\nwith an online fuzzy clustering engine. ADNF initializes soft partitions via\nFuzzy C-Means, then continuously updates micro-cluster centers, densities, and\nfuzziness parameters using a Fuzzy Temporal Index (FTI) that measures entropy\nevolution. A topology refinement stage performs density-weighted merging and\nentropy-guided splitting to guard against over- and under-segmentation. On the\nC-NMC leukemia microscopy dataset, our tool achieves a silhouette score of\n0.51, demonstrating superior cohesion and separation over static baselines. The\nmethod's adaptive uncertainty modeling and label-free operation hold immediate\npotential for integration within the INFANT pediatric oncology network,\nenabling scalable, up-to-date support for personalized leukemia management.", "published": "2025-06-23 08:30:17", "link": "http://arxiv.org/abs/2506.18396v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LOGICPO: Efficient Translation of NL-based Logical Problems to FOL using LLMs and Preference Optimization", "abstract": "Logical reasoning is a key task for artificial intelligence due to it's role\nin major downstream tasks such as Question Answering, Summarization. Recent\nmethods in improving the reasoning ability of LLMs fall short in correctly\nconverting a natural language reasoning problem to an equivalent logical\nformulation, which hinders the framework's overall ability to reason. Towards\nthis, we propose to use finetuning on a preference optimization dataset to\nlearn to parse and represent a natural language problem as a whole to a\nconsistent logical program by 1) introducing a new supervised and preference\noptimization dataset LogicPO, and 2) adopting popular techniques such as Direct\nPreference Optimization (DPO), Kahneman-Tversky optimization (KTO) to finetune\nopen-source LLMs. Our best model with Phi-3.5 consistently outperforms\nGPT-3.5-turbo's (8-shot) by producing 10% more logically correct and with 14%\nless syntax errors. Through the framework and our improved evaluation metrics,\nwe offer a promising direction in improving the logical reasoning of LLMs by\nbetter representing them in their logical formulations.", "published": "2025-06-23 08:15:24", "link": "http://arxiv.org/abs/2506.18383v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PERSCEN: Learning Personalized Interaction Pattern and Scenario Preference for Multi-Scenario Matching", "abstract": "With the expansion of business scales and scopes on online platforms,\nmulti-scenario matching has become a mainstream solution to reduce maintenance\ncosts and alleviate data sparsity. The key to effective multi-scenario\nrecommendation lies in capturing both user preferences shared across all\nscenarios and scenario-aware preferences specific to each scenario. However,\nexisting methods often overlook user-specific modeling, limiting the generation\nof personalized user representations. To address this, we propose PERSCEN, an\ninnovative approach that incorporates user-specific modeling into\nmulti-scenario matching. PERSCEN constructs a user-specific feature graph based\non user characteristics and employs a lightweight graph neural network to\ncapture higher-order interaction patterns, enabling personalized extraction of\npreferences shared across scenarios. Additionally, we leverage vector\nquantization techniques to distil scenario-aware preferences from users'\nbehavior sequence within individual scenarios, facilitating user-specific and\nscenario-aware preference modeling. To enhance efficient and flexible\ninformation transfer, we introduce a progressive scenario-aware gated linear\nunit that allows fine-grained, low-latency fusion. Extensive experiments\ndemonstrate that PERSCEN outperforms existing methods. Further efficiency\nanalysis confirms that PERSCEN effectively balances performance with\ncomputational cost, ensuring its practicality for real-world industrial\nsystems.", "published": "2025-06-23 08:15:16", "link": "http://arxiv.org/abs/2506.18382v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots", "abstract": "Despite growing interest in Learning-by-Teaching (LbT), few studies have\nexplored how this paradigm can be implemented with autonomous, peer-like social\nrobots in real classrooms. Most prior work has relied on scripted or\nWizard-of-Oz behaviors, limiting our understanding of how real-time,\ninteractive learning can be supported by artificial agents. This study\naddresses this gap by introducing Interactive Reinforcement Learning (RL) as a\ncognitive model for teachable social robots. We conducted two between-subject\nexperiments with 58 primary school children, who either taught a robot or\npracticed independently on a tablet while learning French vocabulary\n(memorization) and grammatical rules (inference). The robot, powered by\nInteractive RL, learned from the child's evaluative feedback. Children in the\nLbT condition achieved significantly higher retention gains compared to those\nin the self-practice condition, especially on the grammar task. Learners with\nlower prior knowledge benefited most from teaching the robot. Behavioural\nmetrics revealed that children adapted their teaching strategies over time and\nengaged more deeply during inference tasks. This work makes two contributions:\n(1) it introduces Interactive RL as a pedagogically effective and scalable\nmodel for peer-robot learning, and (2) it demonstrates, for the first time, the\nfeasibility of deploying multiple autonomous robots simultaneously in real\nclassrooms. These findings extend theoretical understanding of LbT by showing\nthat social robots can function not only as passive tutees but as adaptive\npartners that enhance meta-cognitive engagement and long-term learning\noutcomes.", "published": "2025-06-23 07:51:04", "link": "http://arxiv.org/abs/2506.18365v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "abstract": "Scientific progress increasingly relies on effective collaboration among\nresearchers, a dynamic that large language models (LLMs) have only begun to\nemulate. While recent LLM-based scientist agents show promise in autonomous\nscientific discovery, they often lack the interactive reasoning and evaluation\nmechanisms essential to real-world research. We propose IDVSCI (Internal\nDiscussion and Vote SCIentists), a multi-agent framework built on LLMs that\nincorporates two key innovations: a Dynamic Knowledge Exchange mechanism\nenabling iterative feedback among agents, and a Dual-Diversity Review paradigm\nthat simulates heterogeneous expert evaluation. These components jointly\npromote deeper reasoning and the generation of more creative and impactful\nscientific ideas. To evaluate the effectiveness and generalizability of our\napproach, we conduct experiments on two datasets: a widely used benchmark in\ncomputer science and a new dataset we introduce in the health sciences domain.\nResults show that IDVSCI consistently achieves the best performance across both\ndatasets, outperforming existing systems such as AI Scientist and VIRSCI. These\nfindings highlight the value of modeling interaction and peer review dynamics\nin LLM-based autonomous research.", "published": "2025-06-23 07:12:08", "link": "http://arxiv.org/abs/2506.18348v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Controlled Generation with Equivariant Variational Flow Matching", "abstract": "We derive a controlled generation objective within the framework of\nVariational Flow Matching (VFM), which casts flow matching as a variational\ninference problem. We demonstrate that controlled generation can be implemented\ntwo ways: (1) by way of end-to-end training of conditional generative models,\nor (2) as a Bayesian inference problem, enabling post hoc control of\nunconditional models without retraining. Furthermore, we establish the\nconditions required for equivariant generation and provide an equivariant\nformulation of VFM tailored for molecular generation, ensuring invariance to\nrotations, translations, and permutations. We evaluate our approach on both\nuncontrolled and controlled molecular generation, achieving state-of-the-art\nperformance on uncontrolled generation and outperforming state-of-the-art\nmodels in controlled generation, both with end-to-end training and in the\nBayesian inference setting. This work strengthens the connection between\nflow-based generative modeling and Bayesian inference, offering a scalable and\nprincipled framework for constraint-driven and symmetry-aware generation.", "published": "2025-06-23 06:42:48", "link": "http://arxiv.org/abs/2506.18340v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Structured Kolmogorov-Arnold Neural ODEs for Interpretable Learning and Symbolic Discovery of Nonlinear Dynamics", "abstract": "Understanding and modeling nonlinear dynamical systems is a fundamental\nproblem across scientific and engineering domains. While deep learning has\ndemonstrated remarkable potential for learning complex system behavior,\nachieving models that are both highly accurate and physically interpretable\nremains a major challenge. To address this, we propose Structured\nKolmogorov-Arnold Neural ODEs (SKANODEs), a novel framework that integrates\nstructured state-space modeling with the Kolmogorov-Arnold Network (KAN).\nSKANODE first employs a fully trainable KAN as a universal function\napproximator within a structured Neural ODE framework to perform virtual\nsensing, recovering latent states that correspond to physically interpretable\nquantities such as positions and velocities. Once this structured latent\nrepresentation is established, we exploit the symbolic regression capability of\nKAN to extract compact and interpretable expressions for the system's governing\ndynamics. The resulting symbolic expression is then substituted back into the\nNeural ODE framework and further calibrated through continued training to\nrefine its coefficients, enhancing both the precision of the discovered\nequations and the predictive accuracy of system responses. Extensive\nexperiments on both simulated and real-world systems demonstrate that SKANODE\nachieves superior performance while offering interpretable, physics-consistent\nmodels that uncover the underlying mechanisms of nonlinear dynamical systems.", "published": "2025-06-23 06:42:43", "link": "http://arxiv.org/abs/2506.18339v1", "categories": ["cs.LG", "cs.AI", "cs.SC", "nlin.CD", "physics.data-an"], "primary_category": "cs.LG"}
{"title": "Bias vs Bias -- Dawn of Justice: A Fair Fight in Recommendation Systems", "abstract": "Recommendation systems play a crucial role in our daily lives by impacting\nuser experience across various domains, including e-commerce, job\nadvertisements, entertainment, etc. Given the vital role of such systems in our\nlives, practitioners must ensure they do not produce unfair and imbalanced\nrecommendations. Previous work addressing bias in recommendations overlooked\nbias in certain item categories, potentially leaving some biases unaddressed.\nAdditionally, most previous work on fair re-ranking focused on binary-sensitive\nattributes. In this paper, we address these issues by proposing a\nfairness-aware re-ranking approach that helps mitigate bias in different\ncategories of items. This re-ranking approach leverages existing biases to\ncorrect disparities in recommendations across various demographic groups. We\nshow how our approach can mitigate bias on multiple sensitive attributes,\nincluding gender, age, and occupation. We experimented on three real-world\ndatasets to evaluate the effectiveness of our re-ranking scheme in mitigating\nbias in recommendations. Our results show how this approach helps mitigate\nsocial bias with little to no degradation in performance.", "published": "2025-06-23 06:19:02", "link": "http://arxiv.org/abs/2506.18327v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "A Multi-Scale Spatial Attention-Based Zero-Shot Learning Framework for Low-Light Image Enhancement", "abstract": "Low-light image enhancement remains a challenging task, particularly in the\nabsence of paired training data. In this study, we present LucentVisionNet, a\nnovel zero-shot learning framework that addresses the limitations of\ntraditional and deep learning-based enhancement methods. The proposed approach\nintegrates multi-scale spatial attention with a deep curve estimation network,\nenabling fine-grained enhancement while preserving semantic and perceptual\nfidelity. To further improve generalization, we adopt a recurrent enhancement\nstrategy and optimize the model using a composite loss function comprising six\ntailored components, including a novel no-reference image quality loss inspired\nby human visual perception. Extensive experiments on both paired and unpaired\nbenchmark datasets demonstrate that LucentVisionNet consistently outperforms\nstate-of-the-art supervised, unsupervised, and zero-shot methods across\nmultiple full-reference and no-reference image quality metrics. Our framework\nachieves high visual quality, structural consistency, and computational\nefficiency, making it well-suited for deployment in real-world applications\nsuch as mobile photography, surveillance, and autonomous navigation.", "published": "2025-06-23 06:11:55", "link": "http://arxiv.org/abs/2506.18323v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Use Property-Based Testing to Bridge LLM Code Generation and Validation", "abstract": "Large Language Models (LLMs) excel at code generation, but ensuring their\noutputs to be functionally correct, especially in complex programming tasks, is\na persistent challenge. While traditional Test-Driven Development (TDD) offers\na path for code refinement, its efficacy with LLMs is often undermined by the\nscarcity of high-quality test cases or the pitfalls of automated test\ngeneration, including biased tests or inaccurate output predictions that can\nmisdirect the correction process. This paper introduces Property-Generated\nSolver, a novel framework that leverages Property-Based Testing (PBT) to\nvalidate high-level program properties or invariants, instead of relying on\nspecific input-output examples. These properties are often simpler to define\nand verify than directly predicting exhaustive test oracles, breaking the\n\"cycle of self-deception\" where tests might share flaws with the code they are\nmeant to validate. Property-Generated Solver employs two collaborative\nLLM-based agents: a Generator dedicated to code generation and iterative\nrefinement, and a Tester that manages the PBT life-cycle and formulate\nsemantically rich feedback from property violations. The resulting\ncomprehensive and actionable feedback then guides the Generator in its\nrefinement efforts. By establishing PBT as the core validation engine within\nthis iterative, closed-loop paradigm, Property-Generated Solver provides a\nrobust mechanism for steering LLMs towards more correct and generalizable code.\nExtensive experimental results on multiple code generation benchmarks\ndemonstrate that Property-Generated Solver achieves substantial pass@1\nimprovements, ranging from 23.1% to 37.3% relative gains over established TDD\nmethods.", "published": "2025-06-23 06:01:12", "link": "http://arxiv.org/abs/2506.18315v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "LettinGo: Explore User Profile Generation for Recommendation System", "abstract": "User profiling is pivotal for recommendation systems, as it transforms raw\nuser interaction data into concise and structured representations that drive\npersonalized recommendations. While traditional embedding-based profiles lack\ninterpretability and adaptability, recent advances with large language models\n(LLMs) enable text-based profiles that are semantically richer and more\ntransparent. However, existing methods often adhere to fixed formats that limit\ntheir ability to capture the full diversity of user behaviors. In this paper,\nwe introduce LettinGo, a novel framework for generating diverse and adaptive\nuser profiles. By leveraging the expressive power of LLMs and incorporating\ndirect feedback from downstream recommendation tasks, our approach avoids the\nrigid constraints imposed by supervised fine-tuning (SFT). Instead, we employ\nDirect Preference Optimization (DPO) to align the profile generator with\ntask-specific performance, ensuring that the profiles remain adaptive and\neffective. LettinGo operates in three stages: (1) exploring diverse user\nprofiles via multiple LLMs, (2) evaluating profile quality based on their\nimpact in recommendation systems, and (3) aligning the profile generation\nthrough pairwise preference data derived from task performance. Experimental\nresults demonstrate that our framework significantly enhances recommendation\naccuracy, flexibility, and contextual awareness. This work enhances profile\ngeneration as a key innovation for next-generation recommendation systems.", "published": "2025-06-23 05:51:52", "link": "http://arxiv.org/abs/2506.18309v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Spiffy: Efficient Implementation of CoLaNET for Raspberry Pi", "abstract": "This paper presents a lightweight software-based approach for running spiking\nneural networks (SNNs) without relying on specialized neuromorphic hardware or\nframeworks. Instead, we implement a specific SNN architecture (CoLaNET) in Rust\nand optimize it for common computing platforms. As a case study, we demonstrate\nour implementation, called Spiffy, on a Raspberry Pi using the MNIST dataset.\nSpiffy achieves 92% accuracy with low latency - just 0.9 ms per training step\nand 0.45 ms per inference step. The code is open-source.", "published": "2025-06-23 05:47:14", "link": "http://arxiv.org/abs/2506.18306v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Sharpening the Spear: Adaptive Expert-Guided Adversarial Attack Against DRL-based Autonomous Driving Policies", "abstract": "Deep reinforcement learning (DRL) has emerged as a promising paradigm for\nautonomous driving. However, despite their advanced capabilities, DRL-based\npolicies remain highly vulnerable to adversarial attacks, posing serious safety\nrisks in real-world deployments. Investigating such attacks is crucial for\nrevealing policy vulnerabilities and guiding the development of more robust\nautonomous systems. While prior attack methods have made notable progress, they\nstill face several challenges: 1) they often rely on high-frequency attacks,\nyet critical attack opportunities are typically context-dependent and\ntemporally sparse, resulting in inefficient attack patterns; 2) restricting\nattack frequency can improve efficiency but often results in unstable training\ndue to the adversary's limited exploration. To address these challenges, we\npropose an adaptive expert-guided adversarial attack method that enhances both\nthe stability and efficiency of attack policy training. Our method first\nderives an expert policy from successful attack demonstrations using imitation\nlearning, strengthened by an ensemble Mixture-of-Experts architecture for\nrobust generalization across scenarios. This expert policy then guides a\nDRL-based adversary through a KL-divergence regularization term. Due to the\ndiversity of scenarios, expert policies may be imperfect. To address this, we\nfurther introduce a performance-aware annealing strategy that gradually reduces\nreliance on the expert as the adversary improves. Extensive experiments\ndemonstrate that our method achieves outperforms existing approaches in terms\nof collision rate, attack efficiency, and training stability, especially in\ncases where the expert policy is sub-optimal.", "published": "2025-06-23 05:42:49", "link": "http://arxiv.org/abs/2506.18304v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GeNeRT: A Physics-Informed Approach to Intelligent Wireless Channel Modeling via Generalizable Neural Ray Tracing", "abstract": "Neural ray tracing (RT) has emerged as a promising paradigm for channel\nmodeling by combining physical propagation principles with neural networks. It\nenables high modeling accuracy and efficiency. However, current neural RT\nmethods face two key limitations: constrained generalization capability due to\nstrong spatial dependence, and weak adherence to electromagnetic laws. In this\npaper, we propose GeNeRT, a Generalizable Neural RT framework with enhanced\ngeneralization, accuracy and efficiency. GeNeRT supports both intra-scenario\nspatial transferability and inter-scenario zero-shot generalization. By\nincorporating Fresnel-inspired neural network design, it also achieves higher\naccuracy in multipath component (MPC) prediction. Furthermore, a GPU-tensorized\nacceleration strategy is introduced to improve runtime efficiency. Extensive\nexperiments conducted in outdoor scenarios demonstrate that GeNeRT generalizes\nwell across untrained regions within a scenario and entirely unseen\nenvironments, and achieves superior accuracy in MPC prediction compared to\nbaselines. Moreover, it outperforms Wireless Insite in runtime efficiency,\nparticularly in multi-transmitter settings. Ablation experiments validate the\neffectiveness of the network architecture and training strategy in capturing\nphysical principles of ray-surface interactions.", "published": "2025-06-23 05:17:01", "link": "http://arxiv.org/abs/2506.18295v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Selective Social-Interaction via Individual Importance for Fast Human Trajectory Prediction", "abstract": "This paper presents an architecture for selecting important neighboring\npeople to predict the primary person's trajectory. To achieve effective\nneighboring people selection, we propose a people selection module called the\nImportance Estimator which outputs the importance of each neighboring person\nfor predicting the primary person's future trajectory. To prevent gradients\nfrom being blocked by non-differentiable operations when sampling surrounding\npeople based on their importance, we employ the Gumbel Softmax for training.\nExperiments conducted on the JRDB dataset show that our method speeds up the\nprocess with competitive prediction accuracy.", "published": "2025-06-23 05:01:24", "link": "http://arxiv.org/abs/2506.18291v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Tu(r)ning AI Green: Exploring Energy Efficiency Cascading with Orthogonal Optimizations", "abstract": "AI's exponential growth intensifies computational demands and energy\nchallenges. While practitioners employ various optimization techniques, that we\nrefer as \"knobs\" in this paper, to tune model efficiency, these are typically\nafterthoughts and reactive ad-hoc changes applied in isolation without\nunderstanding their combinatorial effects on energy efficiency. This paper\nemphasizes on treating energy efficiency as the first-class citizen and as a\nfundamental design consideration for a compute-intensive pipeline. We show that\nstrategic selection across five AI pipeline phases (data, model, training,\nsystem, inference) creates cascading efficiency. Experimental validation shows\northogonal combinations reduce energy consumption by up to $94.6$% while\npreserving $95.95$% of the original F1 score of non-optimized pipelines. This\ncurated approach provides actionable frameworks for informed sustainable AI\nthat balance efficiency, performance, and environmental responsibility.", "published": "2025-06-23 04:52:08", "link": "http://arxiv.org/abs/2506.18289v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Learning Causal Graphs at Scale: A Foundation Model Approach", "abstract": "Due to its human-interpretability and invariance properties, Directed Acyclic\nGraph (DAG) has been a foundational tool across various areas of AI research,\nleading to significant advancements. However, DAG learning remains highly\nchallenging, due to its super-exponential growth in computational cost and\nidentifiability issues, particularly in small-sample regimes. To address these\ntwo challenges, in this work we leverage the recent success of linear\ntransformers and develop a foundation model approach for discovering multiple\norder-consistent DAGs across tasks. In particular, we propose Attention-DAG\n(ADAG), a novel attention-mechanism-based architecture for learning multiple\nlinear Structural Equation Models (SEMs). ADAG learns the mapping from observed\ndata to both graph structure and parameters via a nonlinear attention-based\nkernel, enabling efficient multi-task estimation of the underlying linear SEMs.\nBy formulating the learning process across multiple tasks as a continuous\noptimization problem, the pre-trained ADAG model captures the common structural\nproperties as a shared low-dimensional prior, thereby reducing the\nill-posedness of downstream DAG learning tasks in small-sample regimes. We\nevaluate our proposed approach on benchmark synthetic datasets and find that\nADAG achieves substantial improvements in both DAG learning accuracy and\nzero-shot inference efficiency. To the best of our knowledge, this is the first\npractical approach for pre-training a foundation model specifically designed\nfor DAG learning, representing a step toward more efficient and generalizable\ndown-stream applications in causal discovery.", "published": "2025-06-23 04:41:02", "link": "http://arxiv.org/abs/2506.18285v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Open Set Recognition for Endoscopic Image Classification: A Deep Learning Approach on the Kvasir Dataset", "abstract": "Endoscopic image classification plays a pivotal role in medical diagnostics\nby identifying anatomical landmarks and pathological findings. However,\nconventional closed-set classification frameworks are inherently limited in\nopen-world clinical settings, where previously unseen conditions can arise\nandcompromise model reliability. To address this, we explore the application of\nOpen Set Recognition (OSR) techniques on the Kvasir dataset, a publicly\navailable and diverse endoscopic image collection. In this study, we evaluate\nand compare the OSR capabilities of several representative deep learning\narchitectures, including ResNet-50, Swin Transformer, and a hybrid\nResNet-Transformer model, under both closed-set and open-set conditions.\nOpenMax is adopted as a baseline OSR method to assess the ability of these\nmodels to distinguish known classes from previously unseen categories. This\nwork represents one of the first efforts to apply open set recognition to the\nKvasir dataset and provides a foundational benchmark for evaluating OSR\nperformance in medical image analysis. Our results offer practical insights\ninto model behavior in clinically realistic settings and highlight the\nimportance of OSR techniques for the safe deployment of AI systems in\nendoscopy.", "published": "2025-06-23 04:39:07", "link": "http://arxiv.org/abs/2506.18284v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ARD-LoRA: Dynamic Rank Allocation for Parameter-Efficient Fine-Tuning of Foundation Models with Heterogeneous Adaptation Needs", "abstract": "Conventional Low-Rank Adaptation (LoRA) methods employ a fixed rank, imposing\nuniform adaptation across transformer layers and attention heads despite their\nheterogeneous learning dynamics. This paper introduces Adaptive Rank Dynamic\nLoRA (ARD-LoRA), a novel framework that automates rank allocation through\nlearnable scaling factors. These factors are optimized via a meta-objective\nbalancing task performance and parameter efficiency, incorporating $\\ell_1$\nsparsity for minimal rank and Total Variation regularization for stable rank\ntransitions. ARD-LoRA enables continuous, differentiable, per-head rank\nadaptation. Experiments on LLAMA-3.1-70B and PaliGemma-2 demonstrate ARD-LoRA's\nefficacy, achieving up to 99.3% of full fine-tuning performance with only 0.32%\ntrainable parameters, outperforming strong baselines like DoRA and AdaLoRA.\nFurthermore, it reduces multimodal adaptation memory by 41%. These results\nestablish dynamic, fine-grained rank allocation as a critical paradigm for\nefficient foundation model adaptation.", "published": "2025-06-23 03:45:37", "link": "http://arxiv.org/abs/2506.18267v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Advanced For-Loop for QML algorithm search", "abstract": "This paper introduces an advanced framework leveraging Large Language\nModel-based Multi-Agent Systems (LLMMA) for the automated search and\noptimization of Quantum Machine Learning (QML) algorithms. Inspired by Google\nDeepMind's FunSearch, the proposed system works on abstract level to\niteratively generates and refines quantum transformations of classical machine\nlearning algorithms (concepts), such as the Multi-Layer Perceptron,\nforward-forward and backpropagation algorithms. As a proof of concept, this\nwork highlights the potential of agentic frameworks to systematically explore\nclassical machine learning concepts and adapt them for quantum computing,\npaving the way for efficient and automated development of QML algorithms.\nFuture directions include incorporating planning mechanisms and optimizing\nstrategy in the search space for broader applications in quantum-enhanced\nmachine learning.", "published": "2025-06-23 03:19:36", "link": "http://arxiv.org/abs/2506.18260v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models", "abstract": "In this paper, we present Morse, a simple dual-sampling framework for\naccelerating diffusion models losslessly. The key insight of Morse is to\nreformulate the iterative generation (from noise to data) process via taking\nadvantage of fast jump sampling and adaptive residual feedback strategies.\nSpecifically, Morse involves two models called Dash and Dot that interact with\neach other. The Dash model is just the pre-trained diffusion model of any type,\nbut operates in a jump sampling regime, creating sufficient space for sampling\nefficiency improvement. The Dot model is significantly faster than the Dash\nmodel, which is learnt to generate residual feedback conditioned on the\nobservations at the current jump sampling point on the trajectory of the Dash\nmodel, lifting the noise estimate to easily match the next-step estimate of the\nDash model without jump sampling. By chaining the outputs of the Dash and Dot\nmodels run in a time-interleaved fashion, Morse exhibits the merit of flexibly\nattaining desired image generation performance while improving overall runtime\nefficiency. With our proposed weight sharing strategy between the Dash and Dot\nmodels, Morse is efficient for training and inference. Our method shows a\nlossless speedup of 1.78X to 3.31X on average over a wide range of sampling\nstep budgets relative to 9 baseline diffusion models on 6 image generation\ntasks. Furthermore, we show that our method can be also generalized to improve\nthe Latent Consistency Model (LCM-SDXL, which is already accelerated with\nconsistency distillation technique) tailored for few-step text-to-image\nsynthesis. The code and models are available at\nhttps://github.com/deep-optimization/Morse.", "published": "2025-06-23 02:43:21", "link": "http://arxiv.org/abs/2506.18251v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "abstract": "Generative adversarial attacks train a perturbation generator on a white-box\nsurrogate model and subsequently apply the crafted perturbations to unseen\nblack-box victim models. In contrast to iterative attacks, these methods\ndeliver superior inference-time efficiency, scalability, and transferability;\nhowever, up until now, existing studies have not fully exploited the\nrepresentational capacity of generative models to preserve and harness semantic\ninformation. Specifically, the intermediate activations of the generator encode\nrich semantic features--object boundaries and coarse shapes--that remain\nunder-exploited, thereby limiting the alignment of perturbations with\nobject-salient regions which are critical for adversarial transferability. To\nremedy this, we introduce a semantic structure-aware attack framework based on\nthe Mean Teacher, which serves as a temporally smoothed feature reference. With\nthis smoothed reference, we further direct semantic consistency between the\nearly-layer activations in the student and those of the semantically rich\nteacher by feature distillation. By anchoring perturbation synthesis to the\nsemantically salient early intermediate blocks within the generator based on\nempirical findings, our method guides progressive adversarial perturbation on\nregions that substantially enhance adversarial transferability. We conduct\nextensive experiments over diverse models, domains and tasks to demonstrate\nconsistent improvements relative to state-of-the-art generative attacks,\ncomprehensively evaluated using conventional metrics and our newly proposed\nAccidental Correction Rate (ACR).", "published": "2025-06-23 02:35:09", "link": "http://arxiv.org/abs/2506.18248v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection", "abstract": "Smart contract vulnerability detection remains a major challenge in\nblockchain security. Existing vulnerability detection methods face two main\nissues: (1) Existing datasets lack comprehensive coverage and high-quality\nexplanations for preference learning. (2) Large language models (LLMs) often\nstruggle with accurately interpreting specific concepts in smart contract\nsecurity. Empirical analysis shows that even after continual pre-training (CPT)\nand supervised fine-tuning (SFT), LLMs may misinterpret the execution order of\nstate changes, resulting in incorrect explanations despite making correct\ndetection decisions. To address these challenges, we propose Smart-LLaMA-DPO\nbased on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major\nvulnerability types and machine-unauditable vulnerabilities, including precise\nlabels, explanations, and locations for SFT, as well as high-quality and\nlow-quality output pairs for Direct Preference Optimization (DPO). Second, we\nperform CPT using large-scale smart contract to enhance the LLM's understanding\nof specific security practices in smart contracts. Futhermore, we conduct SFT\nwith our comprehensive dataset. Finally, we apply DPO, leveraging human\nfeedback and a specially designed loss function that increases the probability\nof preferred explanations while reducing the likelihood of non-preferred\noutputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types:\nreentrancy, timestamp dependence, integer overflow/underflow, and delegatecall,\nas well as machine-unauditable vulnerabilities. Our method significantly\noutperforms state-of-the-art baselines, with average improvements of 10.43% in\nF1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human\nevaluation confirm that our method generates more correct, thorough, and clear\nexplanations.", "published": "2025-06-23 02:24:07", "link": "http://arxiv.org/abs/2506.18245v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Quantum-Classical Hybrid Quantized Neural Network", "abstract": "Here in this work, we present a novel Quadratic Binary Optimization (QBO)\nmodel for quantized neural network training, enabling the use of arbitrary\nactivation and loss functions through spline interpolation. We introduce\nForward Interval Propagation (FIP), a method designed to tackle the challenges\nof non-linearity and the multi-layer composite structure in neural networks by\ndiscretizing activation functions into linear subintervals. This approach\npreserves the universal approximation properties of neural networks while\nallowing complex nonlinear functions to be optimized using quantum computers,\nthus broadening their applicability in artificial intelligence. We provide\ntheoretical upper bounds on the approximation error and the number of Ising\nspins required, by deriving the sample complexity of the empirical risk\nminimization problem, from an optimization perspective. A significant challenge\nin solving the associated Quadratic Constrained Binary Optimization (QCBO)\nmodel on a large scale is the presence of numerous constraints. When employing\nthe penalty method to handle these constraints, tuning a large number of\npenalty coefficients becomes a critical hyperparameter optimization problem,\nincreasing computational complexity and potentially affecting solution quality.\nTo address this, we employ the Quantum Conditional Gradient Descent (QCGD)\nalgorithm, which leverages quantum computing to directly solve the QCBO\nproblem. We prove the convergence of QCGD under a quantum oracle with\nrandomness and bounded variance in objective value, as well as under limited\nprecision constraints in the coefficient matrix. Additionally, we provide an\nupper bound on the Time-To-Solution for the QCBO solving process. Experimental\nresults using a coherent Ising machine (CIM) demonstrate a 94.95% accuracy on\nthe Fashion MNIST classification task, with only 1.1-bit precision.", "published": "2025-06-23 02:12:36", "link": "http://arxiv.org/abs/2506.18240v1", "categories": ["cs.LG", "cs.AI", "physics.optics"], "primary_category": "cs.LG"}
{"title": "The 4th Dimension for Scaling Model Size", "abstract": "Scaling the size of large language models typically involves three\ndimensions: depth, width, and the number of parameters. In this work, we\nexplore a fourth dimension, virtual logical depth (VLD), which increases the\neffective algorithmic depth without changing the overall parameter count by\nreusing parameters within the model. Although parameter reuse is not a new\nconcept, its potential and characteristics in model scaling have not been\nthoroughly studied. Through carefully designed controlled experiments, we make\nthe following key discoveries regarding VLD scaling:\n  VLD scaling forces the knowledge capacity of the model to remain almost\nconstant, with only minor variations.\n  VLD scaling enables a significant improvement in reasoning capability,\nprovided the scaling method is properly implemented.\n  The number of parameters correlates with knowledge capacity, but not with\nreasoning capability. Under certain conditions, it is not necessary to increase\nthe parameter count to enhance reasoning.\n  These findings are consistent across various model configurations and are\nlikely to be generally valid within the scope of our experiments.", "published": "2025-06-23 01:56:25", "link": "http://arxiv.org/abs/2506.18233v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation", "abstract": "Autoregressive conditional image generation models have emerged as a dominant\nparadigm in text-to-image synthesis. These methods typically convert images\ninto one-dimensional token sequences and leverage the self-attention mechanism,\nwhich has achieved remarkable success in natural language processing, to\ncapture long-range dependencies, model global context, and ensure semantic\ncoherence. However, excessively long contexts during inference lead to\nsignificant memory overhead caused by KV-cache and computational delays. To\nalleviate these challenges, we systematically analyze how global semantics,\nspatial layouts, and fine-grained textures are formed during inference, and\npropose a novel training-free context optimization method called Adaptive\nDynamic Sparse Attention (ADSA). Conceptually, ADSA dynamically identifies\nhistorical tokens crucial for maintaining local texture consistency and those\nessential for ensuring global semantic coherence, thereby efficiently\nstreamlining attention computation. Additionally, we introduce a dynamic\nKV-cache update mechanism tailored for ADSA, reducing GPU memory consumption\nduring inference by approximately $50\\%$. Extensive qualitative and\nquantitative experiments demonstrate the effectiveness and superiority of our\napproach in terms of both generation quality and resource efficiency.", "published": "2025-06-23 01:27:06", "link": "http://arxiv.org/abs/2506.18226v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining", "abstract": "Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.", "published": "2025-06-23 01:04:29", "link": "http://arxiv.org/abs/2506.18221v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Cross-Architecture Knowledge Distillation (KD) for Retinal Fundus Image Anomaly Detection on NVIDIA Jetson Nano", "abstract": "Early and accurate identification of retinal ailments is crucial for averting\nocular decline; however, access to dependable diagnostic devices is not often\navailable in low-resourced settings. This project proposes to solve that by\ndeveloping a lightweight, edge-device deployable disease classifier using\ncross-architecture knowledge distilling. We first train a high-capacity vision\ntransformer (ViT) teacher model, pre-trained using I-JEPA self-supervised\nlearning, to classify fundus images into four classes: Normal, Diabetic\nRetinopathy, Glaucoma, and Cataract. We kept an Internet of Things (IoT) focus\nwhen compressing to a CNN-based student model for deployment in\nresource-limited conditions, such as the NVIDIA Jetson Nano. This was\naccomplished using a novel framework which included a Partitioned\nCross-Attention (PCA) projector, a Group-Wise Linear (GL) projector, and a\nmulti-view robust training method. The teacher model has 97.4 percent more\nparameters than the student model, with it achieving 89 percent classification\nwith a roughly 93 percent retention of the teacher model's diagnostic\nperformance. The retention of clinical classification behavior supports our\nmethod's initial aim: compression of the ViT while retaining accuracy. Our work\nserves as an example of a scalable, AI-driven triage solution for retinal\ndisorders in under-resourced areas.", "published": "2025-06-23 00:57:43", "link": "http://arxiv.org/abs/2506.18220v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07", "I.2.6; I.5.1; J.3"], "primary_category": "cs.CV"}
{"title": "A Conceptual Framework for AI Capability Evaluations", "abstract": "As AI systems advance and integrate into society, well-designed and\ntransparent evaluations are becoming essential tools in AI governance,\ninforming decisions by providing evidence about system capabilities and risks.\nYet there remains a lack of clarity on how to perform these assessments both\ncomprehensively and reliably. To address this gap, we propose a conceptual\nframework for analyzing AI capability evaluations, offering a structured,\ndescriptive approach that systematizes the analysis of widely used methods and\nterminology without imposing new taxonomies or rigid formats. This framework\nsupports transparency, comparability, and interpretability across diverse\nevaluations. It also enables researchers to identify methodological weaknesses,\nassists practitioners in designing evaluations, and provides policymakers with\nan accessible tool to scrutinize, compare, and navigate complex evaluation\nlandscapes.", "published": "2025-06-23 00:19:27", "link": "http://arxiv.org/abs/2506.18213v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TC-Light: Temporally Consistent Relighting for Dynamic Long Videos", "abstract": "Editing illumination in long videos with complex dynamics has significant\nvalue in various downstream tasks, including visual content creation and\nmanipulation, as well as data scaling up for embodied AI through sim2real and\nreal2real transfer. Nevertheless, existing video relighting techniques are\npredominantly limited to portrait videos or fall into the bottleneck of\ntemporal consistency and computation efficiency. In this paper, we propose\nTC-Light, a novel paradigm characterized by the proposed two-stage post\noptimization mechanism. Starting from the video preliminarily relighted by an\ninflated video relighting model, it optimizes appearance embedding in the first\nstage to align global illumination. Then it optimizes the proposed canonical\nvideo representation, i.e., Unique Video Tensor (UVT), to align fine-grained\ntexture and lighting in the second stage. To comprehensively evaluate\nperformance, we also establish a long and highly dynamic video benchmark.\nExtensive experiments show that our method enables physically plausible\nrelighting results with superior temporal coherence and low computation cost.\nThe code and video demos are available at\nhttps://dekuliutesla.github.io/tclight/.", "published": "2025-06-23 17:59:58", "link": "http://arxiv.org/abs/2506.18904v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory", "abstract": "We propose a novel memory mechanism to build video generators that can\nexplore environments interactively. Similar results have previously been\nachieved by out-painting 2D views of the scene while incrementally\nreconstructing its 3D geometry, which quickly accumulates errors, or by video\ngenerators with a short context window, which struggle to maintain scene\ncoherence over the long term. To address these limitations, we introduce\nSurfel-Indexed View Memory (VMem), a mechanism that remembers past views by\nindexing them geometrically based on the 3D surface elements (surfels) they\nhave observed. VMem enables the efficient retrieval of the most relevant past\nviews when generating new ones. By focusing only on these relevant views, our\nmethod produces consistent explorations of imagined environments at a fraction\nof the computational cost of using all past views as context. We evaluate our\napproach on challenging long-term scene synthesis benchmarks and demonstrate\nsuperior performance compared to existing methods in maintaining scene\ncoherence and camera control.", "published": "2025-06-23 17:59:56", "link": "http://arxiv.org/abs/2506.18903v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Virtual Games to Real-World Play", "abstract": "We introduce RealPlay, a neural network-based real-world game engine that\nenables interactive video generation from user control signals. Unlike prior\nworks focused on game-style visuals, RealPlay aims to produce photorealistic,\ntemporally consistent video sequences that resemble real-world footage. It\noperates in an interactive loop: users observe a generated scene, issue a\ncontrol command, and receive a short video chunk in response. To enable such\nrealistic and responsive generation, we address key challenges including\niterative chunk-wise prediction for low-latency feedback, temporal consistency\nacross iterations, and accurate control response. RealPlay is trained on a\ncombination of labeled game data and unlabeled real-world videos, without\nrequiring real-world action annotations. Notably, we observe two forms of\ngeneralization: (1) control transfer-RealPlay effectively maps control signals\nfrom virtual to real-world scenarios; and (2) entity transfer-although training\nlabels originate solely from a car racing game, RealPlay generalizes to control\ndiverse real-world entities, including bicycles and pedestrians, beyond\nvehicles. Project page can be found: https://wenqsun.github.io/RealPlay/", "published": "2025-06-23 17:59:53", "link": "http://arxiv.org/abs/2506.18901v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models", "abstract": "Story visualization has become a popular task where visual scenes are\ngenerated to depict a narrative across multiple panels. A central challenge in\nthis setting is maintaining visual consistency, particularly in how characters\nand objects persist and evolve throughout the story. Despite recent advances in\ndiffusion models, current approaches often fail to preserve key character\nattributes, leading to incoherent narratives. In this work, we propose a\ncollaborative multi-agent framework that autonomously identifies, corrects, and\nrefines inconsistencies across multi-panel story visualizations. The agents\noperate in an iterative loop, enabling fine-grained, panel-level updates\nwithout re-generating entire sequences. Our framework is model-agnostic and\nflexibly integrates with a variety of diffusion models, including rectified\nflow transformers such as Flux and latent diffusion models such as Stable\nDiffusion. Quantitative and qualitative experiments show that our method\noutperforms prior approaches in terms of multi-panel consistency.", "published": "2025-06-23 17:59:29", "link": "http://arxiv.org/abs/2506.18900v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FilMaster: Bridging Cinematic Principles and Generative AI for Automated Film Generation", "abstract": "AI-driven content creation has shown potential in film production. However,\nexisting film generation systems struggle to implement cinematic principles and\nthus fail to generate professional-quality films, particularly lacking diverse\ncamera language and cinematic rhythm. This results in templated visuals and\nunengaging narratives. To address this, we introduce FilMaster, an end-to-end\nAI system that integrates real-world cinematic principles for\nprofessional-grade film generation, yielding editable, industry-standard\noutputs. FilMaster is built on two key principles: (1) learning cinematography\nfrom extensive real-world film data and (2) emulating professional,\naudience-centric post-production workflows. Inspired by these principles,\nFilMaster incorporates two stages: a Reference-Guided Generation Stage which\ntransforms user input to video clips, and a Generative Post-Production Stage\nwhich transforms raw footage into audiovisual outputs by orchestrating visual\nand auditory elements for cinematic rhythm. Our generation stage highlights a\nMulti-shot Synergized RAG Camera Language Design module to guide the AI in\ngenerating professional camera language by retrieving reference clips from a\nvast corpus of 440,000 film clips. Our post-production stage emulates\nprofessional workflows by designing an Audience-Centric Cinematic Rhythm\nControl module, including Rough Cut and Fine Cut processes informed by\nsimulated audience feedback, for effective integration of audiovisual elements\nto achieve engaging content. The system is empowered by generative AI models\nlike (M)LLMs and video generation models. Furthermore, we introduce FilmEval, a\ncomprehensive benchmark for evaluating AI-generated films. Extensive\nexperiments show FilMaster's superior performance in camera language design and\ncinematic rhythm control, advancing generative AI in professional filmmaking.", "published": "2025-06-23 17:59:16", "link": "http://arxiv.org/abs/2506.18899v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4D-LRM: Large Space-Time Reconstruction Model From and To Any View at Any Time", "abstract": "Can we scale 4D pretraining to learn general space-time representations that\nreconstruct an object from a few views at some times to any view at any time?\nWe provide an affirmative answer with 4D-LRM, the first large-scale 4D\nreconstruction model that takes input from unconstrained views and timestamps\nand renders arbitrary novel view-time combinations. Unlike prior 4D approaches,\ne.g., optimization-based, geometry-based, or generative, that struggle with\nefficiency, generalization, or faithfulness, 4D-LRM learns a unified space-time\nrepresentation and directly predicts per-pixel 4D Gaussian primitives from\nposed image tokens across time, enabling fast, high-quality rendering at, in\nprinciple, infinite frame rate. Our results demonstrate that scaling\nspatiotemporal pretraining enables accurate and efficient 4D reconstruction. We\nshow that 4D-LRM generalizes to novel objects, interpolates across time, and\nhandles diverse camera setups. It reconstructs 24-frame sequences in one\nforward pass with less than 1.5 seconds on a single A100 GPU.", "published": "2025-06-23 17:57:47", "link": "http://arxiv.org/abs/2506.18890v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM", "abstract": "3D Gaussian splatting has emerged as an expressive scene representation for\nRGB-D visual SLAM, but its application to large-scale, multi-agent outdoor\nenvironments remains unexplored. Multi-agent Gaussian SLAM is a promising\napproach to rapid exploration and reconstruction of environments, offering\nscalable environment representations, but existing approaches are limited to\nsmall-scale, indoor environments. To that end, we propose Gaussian\nReconstruction via Multi-Agent Dense SLAM, or GRAND-SLAM, a collaborative\nGaussian splatting SLAM method that integrates i) an implicit tracking module\nbased on local optimization over submaps and ii) an approach to inter- and\nintra-robot loop closure integrated into a pose-graph optimization framework.\nExperiments show that GRAND-SLAM provides state-of-the-art tracking performance\nand 28% higher PSNR than existing methods on the Replica indoor dataset, as\nwell as 91% lower multi-agent tracking error and improved rendering over\nexisting multi-agent methods on the large-scale, outdoor Kimera-Multi dataset.", "published": "2025-06-23 17:55:42", "link": "http://arxiv.org/abs/2506.18885v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Universal Video Temporal Grounding with Generative Multi-modal Large Language Models", "abstract": "This paper presents a computational model for universal video temporal\ngrounding, which accurately localizes temporal moments in videos based on\nnatural language queries (e.g., questions or descriptions). Unlike existing\nmethods that are often limited to specific video domains or durations, we\npropose UniTime, a robust and universal video grounding model leveraging the\nstrong vision-language understanding capabilities of generative Multi-modal\nLarge Language Models (MLLMs). Our model effectively handles videos of diverse\nviews, genres, and lengths while comprehending complex language queries. The\nkey contributions include: (i) We consider steering strong MLLMs for temporal\ngrounding in videos. To enable precise timestamp outputs, we incorporate\ntemporal information by interleaving timestamp tokens with video tokens. (ii)\nBy training the model to handle videos with different input granularities\nthrough adaptive frame scaling, our approach achieves robust temporal grounding\nfor both short and long videos. (iii) Comprehensive experiments show that\nUniTime outperforms state-of-the-art approaches in both zero-shot and\ndataset-specific finetuned settings across five public temporal grounding\nbenchmarks. (iv) When employed as a preliminary moment retriever for long-form\nvideo question-answering (VideoQA), UniTime significantly improves VideoQA\naccuracy, highlighting its value for complex video understanding tasks.", "published": "2025-06-23 17:53:18", "link": "http://arxiv.org/abs/2506.18883v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Light of Normals: Unified Feature Representation for Universal Photometric Stereo", "abstract": "Universal photometric stereo (PS) aims to recover high-quality surface\nnormals from objects under arbitrary lighting conditions without relying on\nspecific illumination models. Despite recent advances such as SDM-UniPS and Uni\nMS-PS, two fundamental challenges persist: 1) the deep coupling between varying\nillumination and surface normal features, where ambiguity in observed intensity\nmakes it difficult to determine whether brightness variations stem from\nlighting changes or surface orientation; and 2) the preservation of\nhigh-frequency geometric details in complex surfaces, where intricate\ngeometries create self-shadowing, inter-reflections, and subtle normal\nvariations that conventional feature processing operations struggle to capture\naccurately.", "published": "2025-06-23 17:53:11", "link": "http://arxiv.org/abs/2506.18882v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Let Your Video Listen to Your Music!", "abstract": "Aligning the rhythm of visual motion in a video with a given music track is a\npractical need in multimedia production, yet remains an underexplored task in\nautonomous video editing. Effective alignment between motion and musical beats\nenhances viewer engagement and visual appeal, particularly in music videos,\npromotional content, and cinematic editing. Existing methods typically depend\non labor-intensive manual cutting, speed adjustments, or heuristic-based\nediting techniques to achieve synchronization. While some generative models\nhandle joint video and music generation, they often entangle the two\nmodalities, limiting flexibility in aligning video to music beats while\npreserving the full visual content. In this paper, we propose a novel and\nefficient framework, termed MVAA (Music-Video Auto-Alignment), that\nautomatically edits video to align with the rhythm of a given music track while\npreserving the original visual content. To enhance flexibility, we modularize\nthe task into a two-step process in our MVAA: aligning motion keyframes with\naudio beats, followed by rhythm-aware video inpainting. Specifically, we first\ninsert keyframes at timestamps aligned with musical beats, then use a\nframe-conditioned diffusion model to generate coherent intermediate frames,\npreserving the original video's semantic content. Since comprehensive test-time\ntraining can be time-consuming, we adopt a two-stage strategy: pretraining the\ninpainting module on a small video set to learn general motion priors, followed\nby rapid inference-time fine-tuning for video-specific adaptation. This hybrid\napproach enables adaptation within 10 minutes with one epoch on a single NVIDIA\n4090 GPU using CogVideoX-5b-I2V as the backbone. Extensive experiments show\nthat our approach can achieve high-quality beat alignment and visual\nsmoothness.", "published": "2025-06-23 17:52:16", "link": "http://arxiv.org/abs/2506.18881v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base", "abstract": "Accurate 6D pose estimation is key for robotic manipulation, enabling precise\nobject localization for tasks like grasping. We present RAG-6DPose, a\nretrieval-augmented approach that leverages 3D CAD models as a knowledge base\nby integrating both visual and geometric cues. Our RAG-6DPose roughly contains\nthree stages: 1) Building a Multi-Modal CAD Knowledge Base by extracting 2D\nvisual features from multi-view CAD rendered images and also attaching 3D\npoints; 2) Retrieving relevant CAD features from the knowledge base based on\nthe current query image via our ReSPC module; and 3) Incorporating retrieved\nCAD information to refine pose predictions via retrieval-augmented decoding.\nExperimental results on standard benchmarks and real-world robotic tasks\ndemonstrate the effectiveness and robustness of our approach, particularly in\nhandling occlusions and novel viewpoints. Supplementary material is available\non our project website: https://sressers.github.io/RAG-6DPose .", "published": "2025-06-23 17:19:41", "link": "http://arxiv.org/abs/2506.18856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Phantom-Data : Towards a General Subject-Consistent Video Generation Dataset", "abstract": "Subject-to-video generation has witnessed substantial progress in recent\nyears. However, existing models still face significant challenges in faithfully\nfollowing textual instructions. This limitation, commonly known as the\ncopy-paste problem, arises from the widely used in-pair training paradigm. This\napproach inherently entangles subject identity with background and contextual\nattributes by sampling reference images from the same scene as the target\nvideo. To address this issue, we introduce \\textbf{Phantom-Data, the first\ngeneral-purpose cross-pair subject-to-video consistency dataset}, containing\napproximately one million identity-consistent pairs across diverse categories.\nOur dataset is constructed via a three-stage pipeline: (1) a general and\ninput-aligned subject detection module, (2) large-scale cross-context subject\nretrieval from more than 53 million videos and 3 billion images, and (3)\nprior-guided identity verification to ensure visual consistency under\ncontextual variation. Comprehensive experiments show that training with\nPhantom-Data significantly improves prompt alignment and visual quality while\npreserving identity consistency on par with in-pair baselines.", "published": "2025-06-23 17:11:56", "link": "http://arxiv.org/abs/2506.18851v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LIGHTHOUSE: Fast and precise distance to shoreline calculations from anywhere on earth", "abstract": "We introduce a new dataset and algorithm for fast and efficient coastal\ndistance calculations from Anywhere on Earth (AoE). Existing global coastal\ndatasets are only available at coarse resolution (e.g. 1-4 km) which limits\ntheir utility. Publicly available satellite imagery combined with computer\nvision enable much higher precision. We provide a global coastline dataset at\n10 meter resolution, a 100+ fold improvement in precision over existing data.\nTo handle the computational challenge of querying at such an increased scale,\nwe introduce a new library: Layered Iterative Geospatial Hierarchical\nTerrain-Oriented Unified Search Engine (Lighthouse). Lighthouse is both\nexceptionally fast and resource-efficient, requiring only 1 CPU and 2 GB of RAM\nto achieve millisecond online inference, making it well suited for real-time\napplications in resource-constrained environments.", "published": "2025-06-23 17:00:34", "link": "http://arxiv.org/abs/2506.18842v1", "categories": ["cs.DB", "cs.CV", "cs.LG"], "primary_category": "cs.DB"}
{"title": "PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications", "abstract": "Real-time, on-device segmentation is critical for latency-sensitive and\nprivacy-aware applications like smart glasses and IoT devices. We introduce\nPicoSAM2, a lightweight (1.3M parameters, 336M MACs) promptable segmentation\nmodel optimized for edge and in-sensor execution, including the Sony IMX500. It\nbuilds on a depthwise separable U-Net, with knowledge distillation and\nfixed-point prompt encoding to learn from the Segment Anything Model 2 (SAM2).\nOn COCO and LVIS, it achieves 51.9% and 44.9% mIoU, respectively. The quantized\nmodel (1.22MB) runs at 14.3 ms on the IMX500-achieving 86 MACs/cycle, making it\nthe only model meeting both memory and compute constraints for in-sensor\ndeployment. Distillation boosts LVIS performance by +3.5% mIoU and +5.1% mAP.\nThese results demonstrate that efficient, promptable segmentation is feasible\ndirectly on-camera, enabling privacy-preserving vision without cloud or host\nprocessing.", "published": "2025-06-23 16:16:02", "link": "http://arxiv.org/abs/2506.18807v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs", "abstract": "Dynamic Novel View Synthesis aims to generate photorealistic views of moving\nsubjects from arbitrary viewpoints. This task is particularly challenging when\nrelying on monocular video, where disentangling structure from motion is\nill-posed and supervision is scarce. We introduce Video Diffusion-Aware\nReconstruction (ViDAR), a novel 4D reconstruction framework that leverages\npersonalised diffusion models to synthesise a pseudo multi-view supervision\nsignal for training a Gaussian splatting representation. By conditioning on\nscene-specific features, ViDAR recovers fine-grained appearance details while\nmitigating artefacts introduced by monocular ambiguity. To address the\nspatio-temporal inconsistency of diffusion-based supervision, we propose a\ndiffusion-aware loss function and a camera pose optimisation strategy that\naligns synthetic views with the underlying scene geometry. Experiments on\nDyCheck, a challenging benchmark with extreme viewpoint variation, show that\nViDAR outperforms all state-of-the-art baselines in visual quality and\ngeometric consistency. We further highlight ViDAR's strong improvement over\nbaselines on dynamic regions and provide a new benchmark to compare performance\nin reconstructing motion-rich parts of the scene. Project page:\nhttps://vidar-4d.github.io", "published": "2025-06-23 16:01:15", "link": "http://arxiv.org/abs/2506.18792v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers", "abstract": "The evolution of Vision Transformers has led to their widespread adaptation\nto different domains. Despite large-scale success, there remain significant\nchallenges including their reliance on extensive computational and memory\nresources for pre-training on huge datasets as well as difficulties in\ntask-specific transfer learning. These limitations coupled with energy\ninefficiencies mainly arise due to the computation-intensive self-attention\nmechanism. To address these issues, we propose a novel Super-Pixel Based Patch\nPooling (SPPP) technique that generates context-aware, semantically rich, patch\nembeddings to effectively reduce the architectural complexity and improve\nefficiency. Additionally, we introduce the Light Latent Attention (LLA) module\nin our pipeline by integrating latent tokens into the attention mechanism\nallowing cross-attention operations to significantly reduce the time and space\ncomplexity of the attention module. By leveraging the data-intuitive patch\nembeddings coupled with dynamic positional encodings, our approach adaptively\nmodulates the cross-attention process to focus on informative regions while\nmaintaining the global semantic structure. This targeted attention improves\ntraining efficiency and accelerates convergence. Notably, the SPPP module is\nlightweight and can be easily integrated into existing transformer\narchitectures. Extensive experiments demonstrate that our proposed architecture\nprovides significant improvements in terms of computational efficiency while\nachieving comparable results with the state-of-the-art approaches, highlighting\nits potential for energy-efficient transformers suitable for edge deployment.\n(The code is available on our GitHub repository:\nhttps://github.com/zser092/Focused-Attention-ViT).", "published": "2025-06-23 16:00:57", "link": "http://arxiv.org/abs/2506.18791v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "3D Arena: An Open Platform for Generative 3D Evaluation", "abstract": "Evaluating Generative 3D models remains challenging due to misalignment\nbetween automated metrics and human perception of quality. Current benchmarks\nrely on image-based metrics that ignore 3D structure or geometric measures that\nfail to capture perceptual appeal and real-world utility. To address this gap,\nwe present 3D Arena, an open platform for evaluating image-to-3D generation\nmodels through large-scale human preference collection using pairwise\ncomparisons.\n  Since launching in June 2024, the platform has collected 123,243 votes from\n8,096 users across 19 state-of-the-art models, establishing the largest human\npreference evaluation for Generative 3D. We contribute the iso3d dataset of 100\nevaluation prompts and demonstrate quality control achieving 99.75% user\nauthenticity through statistical fraud detection. Our ELO-based ranking system\nprovides reliable model assessment, with the platform becoming an established\nevaluation resource.\n  Through analysis of this preference data, we present insights into human\npreference patterns. Our findings reveal preferences for visual presentation\nfeatures, with Gaussian splat outputs achieving a 16.6 ELO advantage over\nmeshes and textured models receiving a 144.1 ELO advantage over untextured\nmodels. We provide recommendations for improving evaluation methods, including\nmulti-criteria assessment, task-oriented evaluation, and format-aware\ncomparison. The platform's community engagement establishes 3D Arena as a\nbenchmark for the field while advancing understanding of human-centered\nevaluation in Generative 3D.", "published": "2025-06-23 15:57:10", "link": "http://arxiv.org/abs/2506.18787v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "USVTrack: USV-Based 4D Radar-Camera Tracking Dataset for Autonomous Driving in Inland Waterways", "abstract": "Object tracking in inland waterways plays a crucial role in safe and\ncost-effective applications, including waterborne transportation, sightseeing\ntours, environmental monitoring and surface rescue. Our Unmanned Surface\nVehicle (USV), equipped with a 4D radar, a monocular camera, a GPS, and an IMU,\ndelivers robust tracking capabilities in complex waterborne environments. By\nleveraging these sensors, our USV collected comprehensive object tracking data,\nwhich we present as USVTrack, the first 4D radar-camera tracking dataset\ntailored for autonomous driving in new generation waterborne transportation\nsystems. Our USVTrack dataset presents rich scenarios, featuring diverse\nvarious waterways, varying times of day, and multiple weather and lighting\nconditions. Moreover, we present a simple but effective radar-camera matching\nmethod, termed RCM, which can be plugged into popular two-stage association\ntrackers. Experimental results utilizing RCM demonstrate the effectiveness of\nthe radar-camera matching in improving object tracking accuracy and reliability\nfor autonomous driving in waterborne environments. The USVTrack dataset is\npublic on https://usvtrack.github.io.", "published": "2025-06-23 15:13:57", "link": "http://arxiv.org/abs/2506.18737v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "TDACloud: Point Cloud Recognition Using Topological Data Analysis", "abstract": "Point cloud-based object/place recognition remains a problem of interest in\napplications such as autonomous driving, scene reconstruction, and\nlocalization. Extracting meaningful local descriptors from a query point cloud\nthat can be matched with the descriptors of the collected point clouds is a\nchallenging problem. Furthermore, when the query point cloud is noisy or has\nbeen transformed (e.g., rotated), it adds to the complexity. To this end, we\npropose a novel methodology, named TDACloud, using Topological Data Analysis\n(TDA) for local descriptor extraction from a point cloud, which does not need\nresource-intensive GPU-based machine learning training. More specifically, we\nused the ATOL vectorization method to generate vectors for point clouds. Unlike\nvoxelization, our proposed technique can take raw point clouds as inputs and\noutputs a fixed-size TDA-descriptor vector. To test the quality of the proposed\nTDACloud technique, we have implemented it on multiple real-world (e.g., Oxford\nRobotCar, KITTI-360) and realistic (e.g., ShapeNet) point cloud datasets for\nobject and place recognition. We have also tested TDACloud on noisy and\ntransformed test cases where the query point cloud has been scaled, translated,\nor rotated. Our results demonstrate high recognition accuracies in noisy\nconditions and large-scale real-world place recognition while outperforming the\nbaselines by up to approximately 14%.", "published": "2025-06-23 14:59:39", "link": "http://arxiv.org/abs/2506.18725v1", "categories": ["cs.RO", "cs.CG", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Including Semantic Information via Word Embeddings for Skeleton-based Action Recognition", "abstract": "Effective human action recognition is widely used for cobots in Industry 4.0\nto assist in assembly tasks. However, conventional skeleton-based methods often\nlose keypoint semantics, limiting their effectiveness in complex interactions.\nIn this work, we introduce a novel approach to skeleton-based action\nrecognition that enriches input representations by leveraging word embeddings\nto encode semantic information. Our method replaces one-hot encodings with\nsemantic volumes, enabling the model to capture meaningful relationships\nbetween joints and objects. Through extensive experiments on multiple assembly\ndatasets, we demonstrate that our approach significantly improves\nclassification performance, and enhances generalization capabilities by\nsimultaneously supporting different skeleton types and object classes. Our\nfindings highlight the potential of incorporating semantic information to\nenhance skeleton-based action recognition in dynamic and diverse environments.", "published": "2025-06-23 14:57:06", "link": "http://arxiv.org/abs/2506.18721v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Temporal Neural Cellular Automata: Application to modeling of contrast enhancement in breast MRI", "abstract": "Synthetic contrast enhancement offers fast image acquisition and eliminates\nthe need for intravenous injection of contrast agent. This is particularly\nbeneficial for breast imaging, where long acquisition times and high cost are\nsignificantly limiting the applicability of magnetic resonance imaging (MRI) as\na widespread screening modality. Recent studies have demonstrated the\nfeasibility of synthetic contrast generation. However, current state-of-the-art\n(SOTA) methods lack sufficient measures for consistent temporal evolution.\nNeural cellular automata (NCA) offer a robust and lightweight architecture to\nmodel evolving patterns between neighboring cells or pixels. In this work we\nintroduce TeNCA (Temporal Neural Cellular Automata), which extends and further\nrefines NCAs to effectively model temporally sparse, non-uniformly sampled\nimaging data. To achieve this, we advance the training strategy by enabling\nadaptive loss computation and define the iterative nature of the method to\nresemble a physical progression in time. This conditions the model to learn a\nphysiologically plausible evolution of contrast enhancement. We rigorously\ntrain and test TeNCA on a diverse breast MRI dataset and demonstrate its\neffectiveness, surpassing the performance of existing methods in generation of\nimages that align with ground truth post-contrast sequences.", "published": "2025-06-23 14:56:45", "link": "http://arxiv.org/abs/2506.18720v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DuetGen: Music Driven Two-Person Dance Generation via Hierarchical Masked Modeling", "abstract": "We present DuetGen, a novel framework for generating interactive two-person\ndances from music. The key challenge of this task lies in the inherent\ncomplexities of two-person dance interactions, where the partners need to\nsynchronize both with each other and with the music. Inspired by the recent\nadvances in motion synthesis, we propose a two-stage solution: encoding\ntwo-person motions into discrete tokens and then generating these tokens from\nmusic. To effectively capture intricate interactions, we represent both\ndancers' motions as a unified whole to learn the necessary motion tokens, and\nadopt a coarse-to-fine learning strategy in both the stages. Our first stage\nutilizes a VQ-VAE that hierarchically separates high-level semantic features at\na coarse temporal resolution from low-level details at a finer resolution,\nproducing two discrete token sequences at different abstraction levels.\nSubsequently, in the second stage, two generative masked transformers learn to\nmap music signals to these dance tokens: the first producing high-level\nsemantic tokens, and the second, conditioned on music and these semantic\ntokens, producing the low-level tokens. We train both transformers to learn to\npredict randomly masked tokens within the sequence, enabling them to\niteratively generate motion tokens by filling an empty token sequence during\ninference. Through the hierarchical masked modeling and dedicated interaction\nrepresentation, DuetGen achieves the generation of synchronized and interactive\ntwo-person dances across various genres. Extensive experiments and user studies\non a benchmark duet dance dataset demonstrate state-of-the-art performance of\nDuetGen in motion realism, music-dance alignment, and partner coordination.", "published": "2025-06-23 14:22:50", "link": "http://arxiv.org/abs/2506.18680v1", "categories": ["cs.GR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation", "abstract": "We introduce MARL-MambaContour, the first contour-based medical image\nsegmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our\napproach reframes segmentation as a multi-agent cooperation task focused on\ngenerate topologically consistent object-level contours, addressing the\nlimitations of traditional pixel-based methods which could lack topological\nconstraints and holistic structural awareness of anatomical regions. Each\ncontour point is modeled as an autonomous agent that iteratively adjusts its\nposition to align precisely with the target boundary, enabling adaptation to\nblurred edges and intricate morphologies common in medical images. This\niterative adjustment process is optimized by a contour-specific Soft\nActor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization\nAdjustment Mechanism (ERAM) which dynamically balance agent exploration with\ncontour smoothness. Furthermore, the framework incorporates a Mamba-based\npolicy network featuring a novel Bidirectional Cross-attention Hidden-state\nFusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion\nlimitations associated with long-range modeling in state space models, thereby\nfacilitating more accurate inter-agent information exchange and informed\ndecision-making. Extensive experiments on five diverse medical imaging datasets\ndemonstrate the state-of-the-art performance of MARL-MambaContour, highlighting\nits potential as an accurate and robust clinical application.", "published": "2025-06-23 14:22:49", "link": "http://arxiv.org/abs/2506.18679v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation", "abstract": "Neural implicit scene representations have recently shown promising results\nin dense visual SLAM. However, existing implicit SLAM algorithms are\nconstrained to single-agent scenarios, and fall difficulties in large-scale\nscenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks\ncannot meet the constraints of communication bandwidth. To this end, we propose\nthe first distributed multi-agent collaborative neural SLAM framework with\nhybrid scene representation, distributed camera tracking, intra-to-inter loop\nclosure, and online distillation for multiple submap fusion. A novel\ntriplane-grid joint scene representation method is proposed to improve scene\nreconstruction. A novel intra-to-inter loop closure method is designed to\nachieve local (single-agent) and global (multi-agent) consistency. We also\ndesign a novel online distillation method to fuse the information of different\nsubmaps to achieve global consistency. Furthermore, to the best of our\nknowledge, there is no real-world dataset for NeRF-based/GS-based SLAM that\nprovides both continuous-time trajectories groundtruth and high-accuracy 3D\nmeshes groundtruth. To this end, we propose the first real-world Dense slam\n(DES) dataset covering both single-agent and multi-agent scenarios, ranging\nfrom small rooms to large-scale outdoor scenes, with high-accuracy ground truth\nfor both 3D mesh and continuous-time camera trajectory. This dataset can\nadvance the development of the research in both SLAM, 3D reconstruction, and\nvisual foundation model. Experiments on various datasets demonstrate the\nsuperiority of the proposed method in both mapping, tracking, and\ncommunication. The dataset and code will open-source on\nhttps://github.com/dtc111111/mcnslam.", "published": "2025-06-23 14:22:29", "link": "http://arxiv.org/abs/2506.18678v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Reconstructing Tornadoes in 3D with Gaussian Splatting", "abstract": "Accurately reconstructing the 3D structure of tornadoes is critically\nimportant for understanding and preparing for this highly destructive weather\nphenomenon. While modern 3D scene reconstruction techniques, such as 3D\nGaussian splatting (3DGS), could provide a valuable tool for reconstructing the\n3D structure of tornados, at present we are critically lacking a controlled\ntornado dataset with which to develop and validate these tools. In this work we\ncapture and release a novel multiview dataset of a small lab-based tornado. We\ndemonstrate one can effectively reconstruct and visualize the 3D structure of\nthis tornado using 3DGS.", "published": "2025-06-23 14:22:28", "link": "http://arxiv.org/abs/2506.18677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography", "abstract": "Music-driven dance generation has garnered significant attention due to its\nwide range of industrial applications, particularly in the creation of group\nchoreography. During the group dance generation process, however, most existing\nmethods still face three primary issues: multi-dancer collisions, single-dancer\nfoot sliding and abrupt swapping in the generation of long group dance. In this\npaper, we propose TCDiff++, a music-driven end-to-end framework designed to\ngenerate harmonious group dance. Specifically, to mitigate multi-dancer\ncollisions, we utilize a dancer positioning embedding to better maintain the\nrelative positioning among dancers. Additionally, we incorporate a\ndistance-consistency loss to ensure that inter-dancer distances remain within\nplausible ranges. To address the issue of single-dancer foot sliding, we\nintroduce a swap mode embedding to indicate dancer swapping patterns and design\na Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For\nlong group dance generation, we present a long group diffusion sampling\nstrategy that reduces abrupt position shifts by injecting positional\ninformation into the noisy input. Furthermore, we integrate a Sequence Decoder\nlayer to enhance the model's ability to selectively process long sequences.\nExtensive experiments demonstrate that our TCDiff++ achieves state-of-the-art\nperformance, particularly in long-duration scenarios, ensuring high-quality and\ncoherent group dance generation.", "published": "2025-06-23 14:15:20", "link": "http://arxiv.org/abs/2506.18671v1", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MedSeg-R: Medical Image Segmentation with Clinical Reasoning", "abstract": "Medical image segmentation is challenging due to overlapping anatomies with\nambiguous boundaries and a severe imbalance between the foreground and\nbackground classes, which particularly affects the delineation of small\nlesions. Existing methods, including encoder-decoder networks and prompt-driven\nvariants of the Segment Anything Model (SAM), rely heavily on local cues or\nuser prompts and lack integrated semantic priors, thus failing to generalize\nwell to low-contrast or overlapping targets. To address these issues, we\npropose MedSeg-R, a lightweight, dual-stage framework inspired by inspired by\nclinical reasoning. Its cognitive stage interprets medical report into\nstructured semantic priors (location, texture, shape), which are fused via\ntransformer block. In the perceptual stage, these priors modulate the SAM\nbackbone: spatial attention highlights likely lesion regions, dynamic\nconvolution adapts feature filters to expected textures, and deformable\nsampling refines spatial support. By embedding this fine-grained guidance\nearly, MedSeg-R disentangles inter-class confusion and amplifies minority-class\ncues, greatly improving sensitivity to small lesions. In challenging\nbenchmarks, MedSeg-R produces large Dice improvements in overlapping and\nambiguous structures, demonstrating plug-and-play compatibility with SAM-based\nsystems.", "published": "2025-06-23 14:14:09", "link": "http://arxiv.org/abs/2506.18669v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RDPO: Real Data Preference Optimization for Physics Consistency Video Generation", "abstract": "Video generation techniques have achieved remarkable advancements in visual\nquality, yet faithfully reproducing real-world physics remains elusive.\nPreference-based model post-training may improve physical consistency, but\nrequires costly human-annotated datasets or reward models that are not yet\nfeasible. To address these challenges, we present Real Data Preference\nOptimisation (RDPO), an annotation-free framework that distills physical priors\ndirectly from real-world videos. Specifically, the proposed RDPO\nreverse-samples real video sequences with a pre-trained generator to\nautomatically build preference pairs that are statistically distinguishable in\nterms of physical correctness. A multi-stage iterative training schedule then\nguides the generator to obey physical laws increasingly well. Benefiting from\nthe dynamic information explored from real videos, our proposed RDPO\nsignificantly improves the action coherence and physical realism of the\ngenerated videos. Evaluations on multiple benchmarks and human evaluations have\ndemonstrated that RDPO achieves improvements across multiple dimensions. The\nsource code and demonstration of this paper are available at:\nhttps://wwenxu.github.io/RDPO/", "published": "2025-06-23 13:55:24", "link": "http://arxiv.org/abs/2506.18655v1", "categories": ["cs.CV", "I.2.6; I.2.10"], "primary_category": "cs.CV"}
{"title": "SpaNN: Detecting Multiple Adversarial Patches on CNNs by Spanning Saliency Thresholds", "abstract": "State-of-the-art convolutional neural network models for object detection and\nimage classification are vulnerable to physically realizable adversarial\nperturbations, such as patch attacks. Existing defenses have focused,\nimplicitly or explicitly, on single-patch attacks, leaving their sensitivity to\nthe number of patches as an open question or rendering them computationally\ninfeasible or inefficient against attacks consisting of multiple patches in the\nworst cases. In this work, we propose SpaNN, an attack detector whose\ncomputational complexity is independent of the expected number of adversarial\npatches. The key novelty of the proposed detector is that it builds an ensemble\nof binarized feature maps by applying a set of saliency thresholds to the\nneural activations of the first convolutional layer of the victim model. It\nthen performs clustering on the ensemble and uses the cluster features as the\ninput to a classifier for attack detection. Contrary to existing detectors,\nSpaNN does not rely on a fixed saliency threshold for identifying adversarial\nregions, which makes it robust against white box adversarial attacks. We\nevaluate SpaNN on four widely used data sets for object detection and\nclassification, and our results show that SpaNN outperforms state-of-the-art\ndefenses by up to 11 and 27 percentage points in the case of object detection\nand the case of image classification, respectively. Our code is available at\nhttps://github.com/gerkbyrd/SpaNN.", "published": "2025-06-23 12:51:10", "link": "http://arxiv.org/abs/2506.18591v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing", "abstract": "Given the abundance of unlabeled Satellite Image Time Series (SITS) and the\nscarcity of labeled data, contrastive self-supervised pretraining emerges as a\nnatural tool to leverage this vast quantity of unlabeled data. However,\ndesigning effective data augmentations for contrastive learning remains\nchallenging for time series. We introduce a novel resampling-based augmentation\nstrategy that generates positive pairs by upsampling time series and extracting\ndisjoint subsequences while preserving temporal coverage. We validate our\napproach on multiple agricultural classification benchmarks using Sentinel-2\nimagery, showing that it outperforms common alternatives such as jittering,\nresizing, and masking. Further, we achieve state-of-the-art performance on the\nS2-Agri100 dataset without employing spatial information or temporal encodings,\nsurpassing more complex masked-based SSL frameworks. Our method offers a\nsimple, yet effective, contrastive learning augmentation for remote sensing\ntime series.", "published": "2025-06-23 12:48:19", "link": "http://arxiv.org/abs/2506.18587v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "2D Triangle Splatting for Direct Differentiable Mesh Training", "abstract": "Differentiable rendering with 3D Gaussian primitives has emerged as a\npowerful method for reconstructing high-fidelity 3D scenes from multi-view\nimages. While it offers improvements over NeRF-based methods, this\nrepresentation still encounters challenges with rendering speed and advanced\nrendering effects, such as relighting and shadow rendering, compared to\nmesh-based models. In this paper, we propose 2D Triangle Splatting (2DTS), a\nnovel method that replaces 3D Gaussian primitives with 2D triangle facelets.\nThis representation naturally forms a discrete mesh-like structure while\nretaining the benefits of continuous volumetric modeling. By incorporating a\ncompactness parameter into the triangle primitives, we enable direct training\nof photorealistic meshes. Our experimental results demonstrate that our\ntriangle-based method, in its vanilla version (without compactness tuning),\nachieves higher fidelity compared to state-of-the-art Gaussian-based methods.\nFurthermore, our approach produces reconstructed meshes with superior visual\nquality compared to existing mesh reconstruction methods.", "published": "2025-06-23 12:26:47", "link": "http://arxiv.org/abs/2506.18575v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VisualChef: Generating Visual Aids in Cooking via Mask Inpainting", "abstract": "Cooking requires not only following instructions but also understanding,\nexecuting, and monitoring each step - a process that can be challenging without\nvisual guidance. Although recipe images and videos offer helpful cues, they\noften lack consistency in focus, tools, and setup. To better support the\ncooking process, we introduce VisualChef, a method for generating contextual\nvisual aids tailored to cooking scenarios. Given an initial frame and a\nspecified action, VisualChef generates images depicting both the action's\nexecution and the resulting appearance of the object, while preserving the\ninitial frame's environment. Previous work aims to integrate knowledge\nextracted from large language models by generating detailed textual\ndescriptions to guide image generation, which requires fine-grained\nvisual-textual alignment and involves additional annotations. In contrast,\nVisualChef simplifies alignment through mask-based visual grounding. Our key\ninsight is identifying action-relevant objects and classifying them to enable\ntargeted modifications that reflect the intended action and outcome while\nmaintaining a consistent environment. In addition, we propose an automated\npipeline to extract high-quality initial, action, and final state frames. We\nevaluate VisualChef quantitatively and qualitatively on three egocentric video\ndatasets and show its improvements over state-of-the-art methods.", "published": "2025-06-23 12:23:21", "link": "http://arxiv.org/abs/2506.18569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning", "abstract": "Recent advances in AI-generated content (AIGC) have led to the emergence of\npowerful text-to-video generation models. Despite these successes, evaluating\nthe quality of AIGC-generated videos remains challenging due to limited\ngeneralization, lack of temporal awareness, heavy reliance on large-scale\nannotated datasets, and the lack of effective interaction with generation\nmodels. Most current approaches rely on supervised finetuning of\nvision-language models (VLMs), which often require large-scale annotated\ndatasets and tend to decouple understanding and generation. To address these\nshortcomings, we propose VQ-Insight, a novel reasoning-style VLM framework for\nAIGC video quality assessment. Our approach features: (1) a progressive video\nquality learning scheme that combines image quality warm-up, general\ntask-specific temporal learning, and joint optimization with the video\ngeneration model; (2) the design of multi-dimension scoring rewards, preference\ncomparison rewards, and temporal modeling rewards to enhance both\ngeneralization and specialization in video quality evaluation. Extensive\nexperiments demonstrate that VQ-Insight consistently outperforms\nstate-of-the-art baselines in preference comparison, multi-dimension scoring,\nand natural video scoring, bringing significant improvements for video\ngeneration tasks.", "published": "2025-06-23 12:20:14", "link": "http://arxiv.org/abs/2506.18564v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Object-aware Sound Source Localization via Audio-Visual Scene Understanding", "abstract": "Audio-visual sound source localization task aims to spatially localize\nsound-making objects within visual scenes by integrating visual and audio cues.\nHowever, existing methods struggle with accurately localizing sound-making\nobjects in complex scenes, particularly when visually similar silent objects\ncoexist. This limitation arises primarily from their reliance on simple\naudio-visual correspondence, which does not capture fine-grained semantic\ndifferences between sound-making and silent objects. To address these\nchallenges, we propose a novel sound source localization framework leveraging\nMultimodal Large Language Models (MLLMs) to generate detailed contextual\ninformation that explicitly distinguishes between sound-making foreground\nobjects and silent background objects. To effectively integrate this detailed\ninformation, we introduce two novel loss functions: Object-aware Contrastive\nAlignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive\nexperimental results on MUSIC and VGGSound datasets demonstrate the\neffectiveness of our approach, significantly outperforming existing methods in\nboth single-source and multi-source localization scenarios. Code and generated\ndetailed contextual information are available at:\nhttps://github.com/VisualAIKHU/OA-SSL.", "published": "2025-06-23 12:08:07", "link": "http://arxiv.org/abs/2506.18557v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Normality Prior Guided Multi-Semantic Fusion Network for Unsupervised Image Anomaly Detection", "abstract": "Recently, detecting logical anomalies is becoming a more challenging task\ncompared to detecting structural ones. Existing encoder decoder based methods\ntypically compress inputs into low-dimensional bottlenecks on the assumption\nthat the compression process can effectively suppress the transmission of\nlogical anomalies to the decoder. However, logical anomalies present a\nparticular difficulty because, while their local features often resemble normal\nsemantics, their global semantics deviate significantly from normal patterns.\nThanks to the generalisation capabilities inherent in neural networks, these\nabnormal semantic features can propagate through low-dimensional bottlenecks.\nThis ultimately allows the decoder to reconstruct anomalous images with\nmisleading fidelity. To tackle the above challenge, we propose a novel\nnormality prior guided multi-semantic fusion network for unsupervised anomaly\ndetection. Instead of feeding the compressed bottlenecks to the decoder\ndirectly, we introduce the multi-semantic features of normal samples into the\nreconstruction process. To this end, we first extract abstract global semantics\nof normal cases by a pre-trained vision-language network, then the learnable\nsemantic codebooks are constructed to store representative feature vectors of\nnormal samples by vector quantisation. Finally, the above multi-semantic\nfeatures are fused and employed as input to the decoder to guide the\nreconstruction of anomalies to approximate normality. Extensive experiments are\nconducted to validate the effectiveness of our proposed method, and it achieves\nthe SOTA performance on the MVTec LOCO AD dataset with improvements of 5.7% in\npixel-sPRO and 2.6% in image-AUROC. The source code is available at\nhttps://github.com/Xmh-L/NPGMF.", "published": "2025-06-23 11:54:15", "link": "http://arxiv.org/abs/2506.18544v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces", "abstract": "Learning in hyperbolic spaces has attracted increasing attention due to its\nsuperior ability to model hierarchical structures of data. Most existing\nhyperbolic learning methods use fixed distance measures for all data, assuming\na uniform hierarchy across all data points. However, real-world hierarchical\nstructures exhibit significant diversity, making this assumption overly\nrestrictive. In this paper, we propose a geometry-aware distance measure in\nhyperbolic spaces, which dynamically adapts to varying hierarchical structures.\nOur approach derives the distance measure by generating tailored projections\nand curvatures for each pair of data points, effectively mapping them to an\nappropriate hyperbolic space. We introduce a revised low-rank decomposition\nscheme and a hard-pair mining mechanism to mitigate the computational cost of\npair-wise distance computation without compromising accuracy. We present an\nupper bound on the low-rank approximation error using Talagrand's concentration\ninequality, ensuring theoretical robustness. Extensive experiments on standard\nimage classification (MNIST, CIFAR-10 and CIFAR-100), hierarchical\nclassification (5-level CIFAR-100), and few-shot learning tasks (mini-ImageNet,\ntiered-ImageNet) demonstrate the effectiveness of our method. Our approach\nconsistently outperforms learning methods that use fixed distance measures,\nwith notable improvements on few-shot learning tasks, where it achieves over\n5\\% gains on mini-ImageNet. The results reveal that adaptive distance measures\nbetter capture diverse hierarchical structures, with visualization showing\nclearer class boundaries and improved prototype separation in hyperbolic\nspaces.", "published": "2025-06-23 11:43:39", "link": "http://arxiv.org/abs/2506.18533v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Set-to-Set Distance Measure in Hyperbolic Space", "abstract": "We propose a hyperbolic set-to-set distance measure for computing\ndissimilarity between sets in hyperbolic space. While point-to-point distances\nin hyperbolic space effectively capture hierarchical relationships between data\npoints, many real-world applications require comparing sets of hyperbolic data\npoints, where the local structure and the global structure of the sets carry\ncrucial semantic information. The proposed the \\underline{h}yperbolic\n\\underline{s}et-\\underline{to}-\\underline{s}et \\underline{d}istance measure\n(HS2SD) integrates both global and local structural information: global\nstructure through geodesic distances between Einstein midpoints of hyperbolic\nsets, and local structure through topological characteristics of the two sets.\nTo efficiently compute topological differences, we prove that using a finite\nThue-Morse sequence of degree and adjacency matrices can serve as a robust\napproximation to capture the topological structure of a set. In this case, by\nconsidering the topological differences, HS2SD provides a more nuanced\nunderstanding of the relationships between two hyperbolic sets. Empirical\nevaluation on entity matching, standard image classification, and few-shot\nimage classification demonstrates that our distance measure outperforms\nexisting methods by effectively modeling the hierarchical and complex\nrelationships inherent in hyperbolic sets.", "published": "2025-06-23 11:31:40", "link": "http://arxiv.org/abs/2506.18529v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Auto-Regressively Generating Multi-View Consistent Images", "abstract": "Generating multi-view images from human instructions is crucial for 3D\ncontent creation. The primary challenges involve maintaining consistency across\nmultiple views and effectively synthesizing shapes and textures under diverse\nconditions. In this paper, we propose the Multi-View Auto-Regressive (MV-AR)\nmethod, which leverages an auto-regressive model to progressively generate\nconsistent multi-view images from arbitrary prompts. Firstly, the\nnext-token-prediction capability of the AR model significantly enhances its\neffectiveness in facilitating progressive multi-view synthesis. When generating\nwidely-separated views, MV-AR can utilize all its preceding views to extract\neffective reference information. Subsequently, we propose a unified model that\naccommodates various prompts via architecture designing and training\nstrategies. To address multiple conditions, we introduce condition injection\nmodules for text, camera pose, image, and shape. To manage multi-modal\nconditions simultaneously, a progressive training strategy is employed. This\nstrategy initially adopts the text-to-multi-view (t2mv) model as a baseline to\nenhance the development of a comprehensive X-to-multi-view (X2mv) model through\nthe randomly dropping and combining conditions. Finally, to alleviate the\noverfitting problem caused by limited high-quality data, we propose the\n\"Shuffle View\" data augmentation technique, thus significantly expanding the\ntraining data by several magnitudes. Experiments demonstrate the performance\nand versatility of our MV-AR, which consistently generates consistent\nmulti-view images across a range of conditions and performs on par with leading\ndiffusion-based multi-view image generation models. Code and models will be\nreleased at https://github.com/MILab-PKU/MVAR.", "published": "2025-06-23 11:28:37", "link": "http://arxiv.org/abs/2506.18527v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Scale Representation of Follicular Lymphoma Pathology Images in a Single Hyperbolic Space", "abstract": "We propose a method for representing malignant lymphoma pathology images,\nfrom high-resolution cell nuclei to low-resolution tissue images, within a\nsingle hyperbolic space using self-supervised learning. To capture\nmorphological changes that occur across scales during disease progression, our\napproach embeds tissue and corresponding nucleus images close to each other\nbased on inclusion relationships. Using the Poincar\\'e ball as the feature\nspace enables effective encoding of this hierarchical structure. The learned\nrepresentations capture both disease state and cell type variations.", "published": "2025-06-23 11:25:55", "link": "http://arxiv.org/abs/2506.18523v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Image Restoration Transformer via Adaptive Translation Equivariance", "abstract": "Translation equivariance is a fundamental inductive bias in image\nrestoration, ensuring that translated inputs produce translated outputs.\nAttention mechanisms in modern restoration transformers undermine this\nproperty, adversely impacting both training convergence and generalization. To\nalleviate this issue, we propose two key strategies for incorporating\ntranslation equivariance: slide indexing and component stacking. Slide indexing\nmaintains operator responses at fixed positions, with sliding window attention\nbeing a notable example, while component stacking enables the arrangement of\ntranslation-equivariant operators in parallel or sequentially, thereby building\ncomplex architectures while preserving translation equivariance. However, these\nstrategies still create a dilemma in model design between the high\ncomputational cost of self-attention and the fixed receptive field associated\nwith sliding window attention. To address this, we develop an adaptive sliding\nindexing mechanism to efficiently select key-value pairs for each query, which\nare then concatenated in parallel with globally aggregated key-value pairs. The\ndesigned network, called the Translation Equivariance Adaptive Transformer\n(TEAFormer), is assessed across a variety of image restoration tasks. The\nresults highlight its superiority in terms of effectiveness, training\nconvergence, and generalization.", "published": "2025-06-23 11:23:04", "link": "http://arxiv.org/abs/2506.18520v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis", "abstract": "Accurate and interpretable multi-disease diagnosis remains a critical\nchallenge in medical research, particularly when leveraging heterogeneous\nmultimodal medical data. Current approaches often rely on single-modal data,\nlimiting their ability to comprehensively understand complex diseases. To\naddress this, we propose MedTVT-R1, a novel Multimodal Large Language Model\n(MLLM) framework designed to integrate clinical multimodal data for reasoning\nand diagnosing multiple diseases. We construct MedTVT-QA, a curated instruction\ndataset that provides question-answer pairs for physiological-level\ninterpretations and disease-level diagnoses with a Chain of Evidence approach.\nMedTVT-R1 incorporates a modality perception layer to capture inter-modal\ndependencies and adaptively weight modality contributions. Additionally, we\nemploy Group Relative Policy Optimization (GRPO)-based Reinforcement\nFine-Tuning with a Jaccard Reward function to enhance diagnostic reasoning.\nExperimental results demonstrate MedTVT-R1's superiority in multimodal feature\nutilization and multi-disease diagnosis, offering significant potential for\nclinical applications such as diagnostic report generation and comorbidity\nreasoning. The dataset and code are available at\nhttps://github.com/keke-nice/MedTVT-R1.", "published": "2025-06-23 11:06:31", "link": "http://arxiv.org/abs/2506.18512v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Biased Teacher, Balanced Student", "abstract": "Knowledge Distillation (KD) is a widely adopted model compression technique\nwhere a compact student model learns from the output of a larger, pre-trained\nteacher. While effective in balanced settings, conventional KD suffers\nsignificantly when applied to long-tailed data distributions, as the teacher\nmodel tends to be biased toward head classes and provides limited supervision\nfor tail classes. In this paper, we propose Long-Tailed Knowledge Distillation\n(LTKD), a novel framework tailored for class-imbalanced scenarios. We begin by\nreformulating the standard KD objective into two components: inter-group and\nintra-group Kullback-Leibler (KL) divergence, corresponding to the prediction\ndistributions across and within class groups (head, medium, tail),\nrespectively. This decomposition allows us to identify and quantify the sources\nof teacher bias. To address them, we introduce (1) a rebalanced inter-group\nloss that calibrates the teacher's group-level predictions and (2) a uniform\nintra-group loss that ensures equal contribution from all groups during\ndistillation. Extensive experiments on CIFAR-100-LT, TinyImageNet-LT, and\nImageNet-LT show that LTKD consistently outperforms existing KD methods,\nachieving significant gains in both overall accuracy and tail-class\nperformance. Our results demonstrate that LTKD enables effective knowledge\ntransfer even from biased teachers, making it a strong candidate for real-world\ndeployment in resource-constrained and imbalanced settings.", "published": "2025-06-23 10:46:44", "link": "http://arxiv.org/abs/2506.18496v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ShowFlow: From Robust Single Concept to Condition-Free Multi-Concept Generation", "abstract": "Customizing image generation remains a core challenge in controllable image\nsynthesis. For single-concept generation, maintaining both identity\npreservation and prompt alignment is challenging. In multi-concept scenarios,\nrelying solely on a prompt without additional conditions like layout boxes or\nsemantic masks, often leads to identity loss and concept omission. In this\npaper, we introduce ShowFlow, a comprehensive framework designed to tackle\nthese challenges. We propose ShowFlow-S for single-concept image generation,\nand ShowFlow-M for handling multiple concepts. ShowFlow-S introduces a\nKronA-WED adapter, which integrates a Kronecker adapter with weight and\nembedding decomposition, and employs a disentangled learning approach with a\nnovel attention regularization objective to enhance single-concept generation.\nBuilding on this foundation, ShowFlow-M directly reuses the learned models from\nShowFlow-S to support multi-concept generation without extra conditions,\nincorporating a Subject-Adaptive Matching Attention (SAMA) and a layout\nconsistency strategy as the plug-and-play module. Extensive experiments and\nuser studies validate ShowFlow's effectiveness, highlighting its potential in\nreal-world applications like advertising and virtual dressing.", "published": "2025-06-23 10:44:19", "link": "http://arxiv.org/abs/2506.18493v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GANs vs. Diffusion Models for virtual staining with the HER2match dataset", "abstract": "Virtual staining is a promising technique that uses deep generative models to\nrecreate histological stains, providing a faster and more cost-effective\nalternative to traditional tissue chemical staining. Specifically for H&E-HER2\nstaining transfer, despite a rising trend in publications, the lack of\nsufficient public datasets has hindered progress in the topic. Additionally, it\nis currently unclear which model frameworks perform best for this particular\ntask. In this paper, we introduce the HER2match dataset, the first publicly\navailable dataset with the same breast cancer tissue sections stained with both\nH&E and HER2. Furthermore, we compare the performance of several Generative\nAdversarial Networks (GANs) and Diffusion Models (DMs), and implement a novel\nBrownian Bridge Diffusion Model for H&E-HER2 translation. Our findings indicate\nthat, overall, GANs perform better than DMs, with only the BBDM achieving\ncomparable results. Furthermore, we emphasize the importance of data alignment,\nas all models trained on HER2match produced vastly improved visuals compared to\nthe widely used consecutive-slide BCI dataset. This research provides a new\nhigh-quality dataset ([available upon publication acceptance]), improving both\nmodel training and evaluation. In addition, our comparison of frameworks offers\nvaluable guidance for researchers working on the topic.", "published": "2025-06-23 10:37:41", "link": "http://arxiv.org/abs/2506.18484v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Context Consistency Learning via Sentence Removal for Semi-Supervised Video Paragraph Grounding", "abstract": "Semi-Supervised Video Paragraph Grounding (SSVPG) aims to localize multiple\nsentences in a paragraph from an untrimmed video with limited temporal\nannotations. Existing methods focus on teacher-student consistency learning and\nvideo-level contrastive loss, but they overlook the importance of perturbing\nquery contexts to generate strong supervisory signals. In this work, we propose\na novel Context Consistency Learning (CCL) framework that unifies the paradigms\nof consistency regularization and pseudo-labeling to enhance semi-supervised\nlearning. Specifically, we first conduct teacher-student learning where the\nstudent model takes as inputs strongly-augmented samples with sentences removed\nand is enforced to learn from the adequately strong supervisory signals from\nthe teacher model. Afterward, we conduct model retraining based on the\ngenerated pseudo labels, where the mutual agreement between the original and\naugmented views' predictions is utilized as the label confidence. Extensive\nexperiments show that CCL outperforms existing methods by a large margin.", "published": "2025-06-23 10:22:46", "link": "http://arxiv.org/abs/2506.18476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AViLA: Asynchronous Vision-Language Agent for Streaming Multimodal Data Interaction", "abstract": "An ideal vision-language agent serves as a bridge between the human users and\ntheir surrounding physical world in real-world applications like autonomous\ndriving and embodied agents, and proactively provides accurate and timely\nresponses given user intents. An intriguing challenge arises when agents\ninteract with the world as a dynamic data stream and ad-hoc queries from users:\nsupporting knowledge for queries, namely evidence, usually appears\nasynchronously with the arrival time of queries, and agents need to ground\ntheir responses in historical data, present observations, and even future\nstreams. We frame this challenge as Query-Evidence Asynchrony, where user\nqueries and their supporting evidence typically arrive asynchronously in the\nstreaming setting. This setting requires not only strong reasoning capabilities\nbut also the ability to retain past observations and respond to queries with\ntemporal awareness. In this paper, we introduce a diagnostic benchmark that\nevaluates Multimodal Large Language Models (MLLMs) on their ability to handle\ninteraction with streaming data. Further, we present AViLA, Asynchronous\nVideo-Language Agent for streaming data interaction that can handle ad-hoc\nqueries and give time-aware responses. For this purpose, AViLA consists of\nthree key modules: comprehensive memory retention, evidence identification, and\nevidence-grounded trigger, that are designed to maintain a general-purpose\nmemory and respond readily and timely to queries. Our experiments show that\nexisting models often fail to respond at appropriate times, while AViLA\nsignificantly improves both accuracy and temporal awareness. Our code and\ndataset will be publicly available.", "published": "2025-06-23 10:11:30", "link": "http://arxiv.org/abs/2506.18472v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DIP: Unsupervised Dense In-Context Post-training of Visual Representations", "abstract": "We introduce DIP, a novel unsupervised post-training method designed to\nenhance dense image representations in large-scale pretrained vision encoders\nfor in-context scene understanding. Unlike prior approaches that rely on\ncomplex self-distillation architectures, our method trains the vision encoder\nusing pseudo-tasks that explicitly simulate downstream in-context scenarios,\ninspired by meta-learning principles. To enable post-training on unlabeled\ndata, we propose an automatic mechanism for generating in-context tasks that\ncombines a pretrained diffusion model and the vision encoder itself. DIP is\nsimple, unsupervised, and computationally efficient, requiring less than 9\nhours on a single A100 GPU. By learning dense representations through pseudo\nin-context tasks, it achieves strong performance across a wide variety of\ndownstream real-world in-context scene understanding tasks. It outperforms both\nthe initial vision encoder and prior methods, offering a practical and\neffective solution for improving dense representations. Code available here:\nhttps://github.com/sirkosophia/DIP", "published": "2025-06-23 10:01:14", "link": "http://arxiv.org/abs/2506.18463v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation", "abstract": "Achieving reliable ego motion estimation for agile robots, e.g., aerobatic\naircraft, remains challenging because most robot sensors fail to respond timely\nand clearly to highly dynamic robot motions, often resulting in measurement\nblurring, distortion, and delays. In this paper, we propose an IMU-free and\nfeature-association-free framework to achieve aggressive ego-motion velocity\nestimation of a robot platform in highly dynamic scenarios by combining two\ntypes of exteroceptive sensors, an event camera and a millimeter wave radar,\nFirst, we used instantaneous raw events and Doppler measurements to derive\nrotational and translational velocities directly. Without a sophisticated\nassociation process between measurement frames, the proposed method is more\nrobust in texture-less and structureless environments and is more\ncomputationally efficient for edge computing devices. Then, in the back-end, we\npropose a continuous-time state-space model to fuse the hybrid time-based and\nevent-based measurements to estimate the ego-motion velocity in a fixed-lagged\nsmoother fashion. In the end, we validate our velometer framework extensively\nin self-collected experiment datasets. The results indicate that our IMU-free\nand association-free ego motion estimation framework can achieve reliable and\nefficient velocity output in challenging environments. The source code,\nillustrative video and dataset are available at\nhttps://github.com/ZzhYgwh/TwistEstimator.", "published": "2025-06-23 09:27:22", "link": "http://arxiv.org/abs/2506.18443v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing", "abstract": "Editing natural images using textual descriptions in text-to-image diffusion\nmodels remains a significant challenge, particularly in achieving consistent\ngeneration and handling complex, non-rigid objects. Existing methods often\nstruggle to preserve textures and identity, require extensive fine-tuning, and\nexhibit limitations in editing specific spatial regions or objects while\nretaining background details. This paper proposes Context-Preserving Adaptive\nManipulation (CPAM), a novel zero-shot framework for complicated, non-rigid\nreal image editing. Specifically, we propose a preservation adaptation module\nthat adjusts self-attention mechanisms to preserve and independently control\nthe object and background effectively. This ensures that the objects' shapes,\ntextures, and identities are maintained while keeping the background\nundistorted during the editing process using the mask guidance technique.\nAdditionally, we develop a localized extraction module to mitigate the\ninterference with the non-desired modified regions during conditioning in\ncross-attention mechanisms. We also introduce various mask-guidance strategies\nto facilitate diverse image manipulation tasks in a simple manner. Extensive\nexperiments on our newly constructed Image Manipulation BenchmArk (IMBA), a\nrobust benchmark dataset specifically designed for real image editing,\ndemonstrate that our proposed method is the preferred choice among human\nraters, outperforming existing state-of-the-art editing techniques.", "published": "2025-06-23 09:19:38", "link": "http://arxiv.org/abs/2506.18438v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Frequency-Domain Fusion Transformer for Image Inpainting", "abstract": "Image inpainting plays a vital role in restoring missing image regions and\nsupporting high-level vision tasks, but traditional methods struggle with\ncomplex textures and large occlusions. Although Transformer-based approaches\nhave demonstrated strong global modeling capabilities, they often fail to\npreserve high-frequency details due to the low-pass nature of self-attention\nand suffer from high computational costs. To address these challenges, this\npaper proposes a Transformer-based image inpainting method incorporating\nfrequency-domain fusion. Specifically, an attention mechanism combining wavelet\ntransform and Gabor filtering is introduced to enhance multi-scale structural\nmodeling and detail preservation. Additionally, a learnable frequency-domain\nfilter based on the fast Fourier transform is designed to replace the\nfeedforward network, enabling adaptive noise suppression and detail retention.\nThe model adopts a four-level encoder-decoder structure and is guided by a\nnovel loss strategy to balance global semantics and fine details. Experimental\nresults demonstrate that the proposed method effectively improves the quality\nof image inpainting by preserving more high-frequency information.", "published": "2025-06-23 09:19:04", "link": "http://arxiv.org/abs/2506.18437v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What You Think Is What You Get: Bridge User Intent and Transfer Function Design through Multimodal Large Language Models", "abstract": "Direct volume rendering (DVR) is a fundamental technique for visualizing\nvolumetric data, with transfer functions (TFs) playing a crucial role in\nextracting meaningful structures. However, designing effective TFs remains\nunintuitive due to the semantic gap between user intent and TF parameter space.\nResearchers have developed numerous TF optimization methods to bridge this gap.\nHowever, existing methods still face two challenges: large exploration space\nand weak generalizability. To address these issues, we propose What You Think\nis What You Get (WYTWYG) framework, which leveraging Multi-model Large Language\nModels (MLLMs) to guide the TF optimization based on user intent. Specifically,\nwe first introduce a novel TF optimization approach comprising two core\ncomponents: (1) an evolution-based explorer for effective exploration of the TF\nspace, and (2) a volume rendering quality evaluator based on MLLMs to provide\ngeneralizable visual guidance. We further propose a TF interactive design\nsystem based on this approach. We demonstrate the general applicability of our\nframework through three case studies, and validate the effectiveness of each\ncomponent through extensive experiments. Our code is available at:\nhttps://github.com/wyysteelhead/TFevolve.", "published": "2025-06-23 08:42:57", "link": "http://arxiv.org/abs/2506.18407v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Distributed Poisson multi-Bernoulli filtering via generalised covariance intersection", "abstract": "This paper presents the distributed Poisson multi-Bernoulli (PMB) filter\nbased on the generalised covariance intersection (GCI) fusion rule for\ndistributed multi-object filtering. Since the exact GCI fusion of two PMB\ndensities is intractable, we derive a principled approximation. Specifically,\nwe approximate the power of a PMB density as an unnormalised PMB density, which\ncorresponds to an upper bound of the PMB density. Then, the GCI fusion rule\ncorresponds to the normalised product of two unnormalised PMB densities. We\nshow that the result is a Poisson multi-Bernoulli mixture (PMBM), which can be\nexpressed in closed form. Future prediction and update steps in each filter\npreserve the PMBM form, which can be projected back to a PMB density before the\nnext fusion step. Experimental results show the benefits of this approach\ncompared to other distributed multi-object filters.", "published": "2025-06-23 08:32:16", "link": "http://arxiv.org/abs/2506.18397v1", "categories": ["cs.CV", "math.ST", "stat.TH"], "primary_category": "cs.CV"}
{"title": "InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models", "abstract": "Recent benchmarks and datasets have been proposed to improve spatial\nreasoning in vision-language models (VLMs), yet existing open resources remain\nlimited in scale, visual diversity, and instruction expressiveness. In this\nwork, we introduce InternSpatial, the largest open-source dataset for spatial\nreasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluation\nbenchmark designed to assess spatial understanding under diverse instruction\nformats. InternSpatial comprises 12 million QA pairs spanning both single-view\nand multi-view settings, drawn from diverse visual environments and supporting\n19 instruction formats that reflect varied query styles. For evaluation, we\npropose InternSpatial-Bench for single-view tasks and expand multi-view\nreasoning by introducing a novel rotation angle prediction task that has not\nbeen explored in prior work. Experimental results show that models trained on\nInternSpatial achieve 12.1% improvement on InternSpatial-Bench and 10.7% on\nVSI-Bench, while maintaining strong performance on general-purpose benchmarks.\nWe hope these resources will support the development of spatially capable VLMs\nin practical applications such as robotics and embodied AI.", "published": "2025-06-23 08:17:22", "link": "http://arxiv.org/abs/2506.18385v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review", "abstract": "Modern Vision-Language Models (VLMs) exhibit unprecedented capabilities in\ncross-modal semantic understanding between visual and textual modalities. Given\nthe intrinsic need for multi-modal integration in clinical applications, VLMs\nhave emerged as a promising solution for a wide range of medical image analysis\ntasks. However, adapting general-purpose VLMs to medical domain poses numerous\nchallenges, such as large domain gaps, complicated pathological variations, and\ndiversity and uniqueness of different tasks. The central purpose of this review\nis to systematically summarize recent advances in adapting VLMs for medical\nimage analysis, analyzing current challenges, and recommending promising yet\nurgent directions for further investigations. We begin by introducing core\nlearning strategies for medical VLMs, including pretraining, fine-tuning, and\nprompt learning. We then categorize five major VLM adaptation strategies for\nmedical image analysis. These strategies are further analyzed across eleven\nmedical imaging tasks to illustrate their current practical implementations.\nFurthermore, we analyze key challenges that impede the effective adaptation of\nVLMs to clinical applications and discuss potential directions for future\nresearch. We also provide an open-access repository of related literature to\nfacilitate further research, available at\nhttps://github.com/haonenglin/Awesome-VLM-for-MIA. It is anticipated that this\narticle can help researchers who are interested in harnessing VLMs in medical\nimage analysis tasks have a better understanding on their capabilities and\nlimitations, as well as current technical barriers, to promote their\ninnovative, robust, and safe application in clinical practice.", "published": "2025-06-23 08:11:24", "link": "http://arxiv.org/abs/2506.18378v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "OpenEvents V1: Large-Scale Benchmark Dataset for Multimodal Event Grounding", "abstract": "We introduce OpenEvents V1, a large-scale benchmark dataset aimed at\nadvancing event-centric vision-language understanding. Unlike conventional\nimage captioning and retrieval datasets that emphasize surface-level\ndescriptions, OpenEvents V1 focuses on contextual and temporal grounding\nthrough two primary tasks: (1) generating rich, event-aware image captions and\n(2) retrieving event-relevant images based on narrative-style textual queries.\nThe dataset contains over 200,000 news articles and 400,000 associated images\nsourced from CNN and The Guardian, spanning diverse domains and time periods.\nWe provide extensive baseline results and standardized evaluation protocols for\nboth tasks. OpenEvents V1 establishes a robust foundation for developing\nmultimodal models capable of deep reasoning over complex real-world events. The\ndataset is available at https://ltnghia.github.io/eventa/openevents-v1", "published": "2025-06-23 07:57:38", "link": "http://arxiv.org/abs/2506.18372v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transforming H&E images into IHC: A Variance-Penalized GAN for Precision Oncology", "abstract": "The overexpression of the human epidermal growth factor receptor 2 (HER2) in\nbreast cells is a key driver of HER2-positive breast cancer, a highly\naggressive subtype requiring precise diagnosis and targeted therapy.\nImmunohistochemistry (IHC) is the standard technique for HER2 assessment but is\ncostly, labor-intensive, and highly dependent on antibody selection. In\ncontrast, hematoxylin and eosin (H&E) staining, a routine histopathological\nprocedure, offers broader accessibility but lacks HER2 specificity. This study\nproposes an advanced deep learning-based image translation framework to\ngenerate highfidelity IHC images from H&E-stained tissue samples, enabling\ncost-effective and scalable HER2 assessment. By modifying the loss function of\npyramid pix2pix, we mitigate mode collapse, a fundamental limitation in\ngenerative adversarial networks (GANs), and introduce a novel variance-based\npenalty that enforces structural diversity in generated images. Our model\nparticularly excels in translating HER2-positive (IHC 3+) images, which have\nremained challenging for existing methods due to their complex morphological\nvariations. Extensive evaluations on the BCI histopathological dataset\ndemonstrate that our model surpasses state-of-the-art methods in terms of peak\nsignal-tonoise ratio (PSNR), structural similarity index (SSIM), and Frechet\nInception Distance (FID), particularly in accurately translating HER2-positive\n(IHC 3+) images. Beyond medical imaging, our model exhibits superior\nperformance in general image-to-image translation tasks, showcasing its\npotential across multiple domains. This work marks a significant step toward\nAI-driven precision oncology, offering a reliable and efficient alternative to\ntraditional HER2 diagnostics.", "published": "2025-06-23 07:57:22", "link": "http://arxiv.org/abs/2506.18371v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models", "abstract": "Recent multi-modal large language models (MLLMs) often struggle to generate\npersonalized image captions, even when trained on high-quality captions. In\nthis work, we observe that such limitations persist in existing\npost-training-based MLLM personalization methods. Specifically, despite being\npost-tuned with large-scale caption data through supervised fine-tuning (SFT),\nthese models frequently fail to produce faithful descriptions in real-world\nscenarios, such as multi-concept image captioning. However, acquiring\nlarge-scale, high-quality captions for such complex settings is both costly and\ndifficult. To address the data-centric nature of SFT, we propose a\nreinforcement learning (RL)-based post-training framework. To the best of our\nknowledge, this is the first RL-based approach to post-train MLLMs for\npersonalized image captioning. Our method significantly enhances both visual\nrecognition and personalized generation capabilities of MLLMs, and consistently\noutperforms existing SFT-based baselines, especially in the challenging\nmulti-concept image captioning task.", "published": "2025-06-23 07:55:52", "link": "http://arxiv.org/abs/2506.18369v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection", "abstract": "Detecting anomalous human behaviour is an important visual task in\nsafety-critical applications such as healthcare monitoring, workplace safety,\nor public surveillance. In these contexts, abnormalities are often reflected\nwith unusual human poses. Thus, we propose SeeKer, a method for detecting\nanomalies in sequences of human skeletons. Our method formulates the skeleton\nsequence density through autoregressive factorization at the keypoint level.\nThe corresponding conditional distributions represent probable keypoint\nlocations given prior skeletal motion. We formulate the joint distribution of\nthe considered skeleton as causal prediction of conditional Gaussians across\nits constituent keypoints. A skeleton is flagged as anomalous if its keypoint\nlocations surprise our model (i.e. receive a low density). In practice, our\nanomaly score is a weighted sum of per-keypoint log-conditionals, where the\nweights account for the confidence of the underlying keypoint detector. Despite\nits conceptual simplicity, SeeKer surpasses all previous methods on the\nUBnormal and MSAD-HR datasets while delivering competitive performance on the\nShanghaiTech dataset.", "published": "2025-06-23 07:55:28", "link": "http://arxiv.org/abs/2506.18368v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatial frequency information fusion network for few-shot learning", "abstract": "The objective of Few-shot learning is to fully leverage the limited data\nresources for exploring the latent correlations within the data by applying\nalgorithms and training a model with outstanding performance that can\nadequately meet the demands of practical applications. In practical\napplications, the number of images in each category is usually less than that\nin traditional deep learning, which can lead to over-fitting and poor\ngeneralization performance. Currently, many Few-shot classification models pay\nmore attention to spatial domain information while neglecting frequency domain\ninformation, which contains more feature information. Ignoring frequency domain\ninformation will prevent the model from fully exploiting feature information,\nwhich would effect the classification performance. Based on conventional data\naugmentation, this paper proposes an SFIFNet with innovative data\npreprocessing. The key of this method is enhancing the accuracy of image\nfeature representation by integrating frequency domain information with spatial\ndomain information. The experimental results demonstrate the effectiveness of\nthis method in enhancing classification performance.", "published": "2025-06-23 07:47:11", "link": "http://arxiv.org/abs/2506.18364v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement", "abstract": "Current low-light image enhancement (LLIE) methods face significant\nlimitations in simultaneously improving brightness while preserving semantic\nconsistency, fine details, and computational efficiency. With the emergence of\nstate-space models, particularly Mamba, image restoration has achieved\nremarkable performance, yet existing visual Mamba approaches flatten 2D images\ninto 1D token sequences using fixed scanning rules, critically limiting\ninteractions between distant tokens with causal relationships and constraining\ntheir ability to capture meaningful long-range dependencies. To address these\nfundamental limitations, we propose BSMamba, a novel visual Mamba architecture\ncomprising two specially designed components: Brightness Mamba and Semantic\nMamba. The Brightness Mamba revolutionizes token interaction patterns by\nprioritizing connections between distant tokens with similar brightness levels,\neffectively addressing the challenge of brightness restoration in LLIE tasks\nthrough brightness-guided selective attention. Complementing this, the Semantic\nMamba establishes priority interactions between tokens sharing similar semantic\nmeanings, allowing the model to maintain contextual consistency by connecting\nsemantically related regions across the image, thus preserving the hierarchical\nnature of image semantics during enhancement. By intelligently modeling tokens\nbased on brightness and semantic similarity rather than arbitrary scanning\npatterns, BSMamba transcends the constraints of conventional token sequencing\nwhile adhering to the principles of causal modeling. Extensive experiments\ndemonstrate that BSMamba achieves state-of-the-art performance in LLIE while\npreserving semantic consistency.", "published": "2025-06-23 07:04:34", "link": "http://arxiv.org/abs/2506.18346v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention", "abstract": "Segmenting biomarkers in medical images is crucial for various biotech\napplications. Despite advances, Transformer and CNN based methods often\nstruggle with variations in staining and morphology, limiting feature\nextraction. In medical image segmentation, where datasets often have limited\nsample availability, recent state-of-the-art (SOTA) methods achieve higher\naccuracy by leveraging pre-trained encoders, whereas end-to-end methods tend to\nunderperform. This is due to challenges in effectively transferring rich\nmultiscale features from encoders to decoders, as well as limitations in\ndecoder efficiency. To address these issues, we propose an architecture that\ncaptures multi-scale local and global contextual information and a novel\ndecoder design, which effectively integrates features from the encoder,\nemphasizes important channels and regions, and reconstructs spatial dimensions\nto enhance segmentation accuracy. Our method, compatible with various encoders,\noutperforms SOTA methods, as demonstrated by experiments on four datasets and\nablation studies. Specifically, our method achieves absolute performance gains\nof 2.76% on MoNuSeg, 3.12% on DSB, 2.87% on Electron Microscopy, and 4.03% on\nTNBC datasets compared to existing SOTA methods. Code:\nhttps://github.com/saadwazir/MCADS-Decoder", "published": "2025-06-23 06:32:36", "link": "http://arxiv.org/abs/2506.18335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geometry-Aware Preference Learning for 3D Texture Generation", "abstract": "Recent advances in 3D generative models have achieved impressive results but\n3D contents generated by these models may not align with subjective human\npreferences or task-specific criteria. Moreover, a core challenge in the 3D\ntexture generation domain remains: most existing approaches rely on repeated\ncalls to 2D text-to-image generative models, which lack an inherent\nunderstanding of the 3D structure of the input 3D mesh object. To address this,\nwe propose an end-to-end differentiable preference learning framework that\nback-propagates human preferences, represented by differentiable reward\nfunctions, through the entire 3D generative pipeline, making the process\ninherently geometry-aware. We demonstrate the effectiveness of our framework\nusing four proposed novel geometry-aware reward functions, offering a more\ncontrollable and interpretable pathway for high-quality 3D content creation\nfrom natural language.", "published": "2025-06-23 06:24:12", "link": "http://arxiv.org/abs/2506.18331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NSFW-Classifier Guided Prompt Sanitization for Safe Text-to-Image Generation", "abstract": "The rapid advancement of text-to-image (T2I) models, such as Stable\nDiffusion, has enhanced their capability to synthesize images from textual\nprompts. However, this progress also raises significant risks of misuse,\nincluding the generation of harmful content (e.g., pornography, violence,\ndiscrimination), which contradicts the ethical goals of T2I technology and\nhinders its sustainable development. Inspired by \"jailbreak\" attacks in large\nlanguage models, which bypass restrictions through subtle prompt modifications,\nthis paper proposes NSFW-Classifier Guided Prompt Sanitization (PromptSan), a\nnovel approach to detoxify harmful prompts without altering model architecture\nor degrading generation capability. PromptSan includes two variants:\nPromptSan-Modify, which iteratively identifies and replaces harmful tokens in\ninput prompts using text NSFW classifiers during inference, and\nPromptSan-Suffix, which trains an optimized suffix token sequence to neutralize\nharmful intent while passing both text and image NSFW classifier checks.\nExtensive experiments demonstrate that PromptSan achieves state-of-the-art\nperformance in reducing harmful content generation across multiple metrics,\neffectively balancing safety and usability.", "published": "2025-06-23 06:17:30", "link": "http://arxiv.org/abs/2506.18325v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?", "abstract": "Finetuning can cause spurious correlations to arise between non-essential\nfeatures and the target labels, but benchmarks to study these effects involve\ncontrived settings and narrow tasks. In contrast, we consider spurious\ncorrelations in multi-modal Large Vision Language Models (LVLMs) pretrained on\nextensive and diverse datasets without explicit task supervision. We develop a\nbenchmark by sourcing GPT-4o errors on real-world visual-question-answering\n(VQA) benchmarks, then curating a subset through LVLM-human annotation and\nsynthetic counterfactual evaluation to identify errors caused by spurious\ncorrelations. This process yields SpuriVerse, a novel benchmark comprised of\n124 distinct types of spurious correlations extracted from real-world datasets,\neach containing 1 realistic and 10 synthetic VQA samples for a total of 1364\nmultiple choice questions. We evaluate 15 open and closed-source LVLMs on\nSpuriVerse, finding that even state-of-the-art closed-source models struggle\nsignificantly, achieving at best only 37.1% accuracy. Fine-tuning on synthetic\nexamples that emphasize the spurious correlation improves performance to\n78.40%, suggesting that training on diverse spurious patterns generalizes to\nunseen situations: models appear to learn to avoid \"shortcuts\" and attend to\nthe overall image context.", "published": "2025-06-23 06:11:43", "link": "http://arxiv.org/abs/2506.18322v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Attention-Based Ensemble Learning for Crop Classification Using Landsat 8-9 Fusion", "abstract": "Remote sensing offers a highly effective method for obtaining accurate\ninformation on total cropped area and crop types. The study focuses on crop\ncover identification for irrigated regions of Central Punjab. Data collection\nwas executed in two stages: the first involved identifying and geocoding six\ntarget crops through field surveys conducted in January and February 2023. The\nsecond stage involved acquiring Landsat 8-9 imagery for each geocoded field to\nconstruct a labelled dataset. The satellite imagery underwent extensive\npre-processing, including radiometric calibration for reflectance values,\natmospheric correction, and georeferencing verification to ensure consistency\nwithin a common coordinate system. Subsequently, image fusion techniques were\napplied to combine Landsat 8 and 9 spectral bands, creating a composite image\nwith enhanced spectral information, followed by contrast enhancement. During\ndata acquisition, farmers were interviewed, and fields were meticulously mapped\nusing GPS instruments, resulting in a comprehensive dataset of 50,835 data\npoints. This dataset facilitated the extraction of vegetation indices such as\nNDVI, SAVO, RECI, and NDRE. These indices and raw reflectance values were\nutilized for classification modeling using conventional classifiers, ensemble\nlearning, and artificial neural networks. A feature selection approach was also\nincorporated to identify the optimal feature set for classification learning.\nThis study demonstrates the effectiveness of combining remote sensing data and\nadvanced modeling techniques to improve crop classification accuracy in\nirrigated agricultural regions.", "published": "2025-06-23 06:09:39", "link": "http://arxiv.org/abs/2506.18321v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture", "abstract": "Quantitative descriptions of complete canopy architecture are crucial for\nevaluating crop photosynthesis and yield to guide ideotype design. Although\nthree-dimensional (3D) sensing technologies have been developed for plant and\ncanopy reconstruction, severe occlusion and complex architectures hinder\naccurate canopy descriptions. In this study, we propose a point cloud\ncompletion model for 3D reconstruction of rapeseed populations from seeding to\nsilique stages using multi-view imaging. A complete point cloud generation\nframework was developed with the virtual-real integration (VRI) simulation\nmethod and occlusion point detection algorithm to annotate the training dataset\nby distinguishing surface from occluded points. The rapeseed population point\ncloud completion network (RP-PCN) was designed with a multi-resolution dynamic\ngraph convolutional encoder (MRDG) and point pyramid decoder (PPD) to predict\noccluded points based on input surface point clouds. A dynamic graph\nconvolutional feature extractor (DGCFE) was introduced to capture structural\nvariations across the growth period. The effectiveness of point cloud\ncompletion was validated by predicting yield using architectural indicators\nfrom complete point clouds of rapeseed population. The results demonstrated\nthat RP-PCN achieved chamfer distance (CD) values of 3.35 cm, 3.46 cm, 4.32 cm,\nand 4.51 cm at the seedling, bolting, flowering, and silique stages,\nrespectively. Ablation studies showed the effectiveness of the MRDG and DGCFE\nmodules, reducing CD values by 10% and 23%, respectively. The silique\nefficiency index (SEI) from RP-PCN improved yield prediction accuracy by 11.2%\ncompared to incomplete point clouds. The RP-PCN pipeline proposed in this study\nhas the potential to be extended to other crops, significantly enhancing the\nanalysis of population canopy architectures in field environments.", "published": "2025-06-23 05:02:31", "link": "http://arxiv.org/abs/2506.18292v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReFrame: Rectification Framework for Image Explaining Architectures", "abstract": "Image explanation has been one of the key research interests in the Deep\nLearning field. Throughout the years, several approaches have been adopted to\nexplain an input image fed by the user. From detecting an object in a given\nimage to explaining it in human understandable sentence, to having a\nconversation describing the image, this problem has seen an immense change\nthroughout the years, However, the existing works have been often found to (a)\nhallucinate objects that do not exist in the image and/or (b) lack identifying\nthe complete set of objects present in the image. In this paper, we propose a\nnovel approach to mitigate these drawbacks of inconsistency and incompleteness\nof the objects recognized during the image explanation. To enable this, we\npropose an interpretable framework that can be plugged atop diverse image\nexplaining frameworks including Image Captioning, Visual Question Answering\n(VQA) and Prompt-based AI using LLMs, thereby enhancing their explanation\ncapabilities by rectifying the incorrect or missing objects. We further measure\nthe efficacy of the rectified explanations generated through our proposed\napproaches leveraging object based precision metrics, and showcase the\nimprovements in the inconsistency and completeness of image explanations.\nQuantitatively, the proposed framework is able to improve the explanations over\nthe baseline architectures of Image Captioning (improving the completeness by\n81.81% and inconsistency by 37.10%), Visual Question Answering(average of 9.6%\nand 37.10% in completeness and inconsistency respectively) and Prompt-based AI\nmodel (0.01% and 5.2% for completeness and inconsistency respectively)\nsurpassing the current state-of-the-art by a substantial margin.", "published": "2025-06-23 03:58:09", "link": "http://arxiv.org/abs/2506.18272v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adaptive Mask-guided K-space Diffusion for Accelerated MRI Reconstruction", "abstract": "As the deep learning revolution marches on, masked modeling has emerged as a\ndistinctive approach that involves predicting parts of the original data that\nare proportionally masked during training, and has demonstrated exceptional\nperformance in multiple fields. Magnetic Resonance Imaging (MRI) reconstruction\nis a critical task in medical imaging that seeks to recover high-quality images\nfrom under-sampled k-space data. However, previous MRI reconstruction\nstrategies usually optimized the entire image domain or k-space, without\nconsidering the importance of different frequency regions in the k-space This\nwork introduces a diffusion model based on adaptive masks (AMDM), which\nutilizes the adaptive adjustment of frequency distribution based on k-space\ndata to develop a hybrid masks mechanism that adapts to different k-space\ninputs. This enables the effective separation of high-frequency and\nlow-frequency components, producing diverse frequency-specific representations.\nAdditionally, the k-space frequency distribution informs the generation of\nadaptive masks, which, in turn, guide a closed-loop diffusion process.\nExperimental results verified the ability of this method to learn specific\nfrequency information and thereby improved the quality of MRI reconstruction,\nproviding a flexible framework for optimizing k-space data using masks in the\nfuture.", "published": "2025-06-23 03:54:53", "link": "http://arxiv.org/abs/2506.18270v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ThermalLoc: A Vision Transformer-Based Approach for Robust Thermal Camera Relocalization in Large-Scale Environments", "abstract": "Thermal cameras capture environmental data through heat emission, a\nfundamentally different mechanism compared to visible light cameras, which rely\non pinhole imaging. As a result, traditional visual relocalization methods\ndesigned for visible light images are not directly applicable to thermal\nimages. Despite significant advancements in deep learning for camera\nrelocalization, approaches specifically tailored for thermal camera-based\nrelocalization remain underexplored. To address this gap, we introduce\nThermalLoc, a novel end-to-end deep learning method for thermal image\nrelocalization. ThermalLoc effectively extracts both local and global features\nfrom thermal images by integrating EfficientNet with Transformers, and performs\nabsolute pose regression using two MLP networks. We evaluated ThermalLoc on\nboth the publicly available thermal-odometry dataset and our own dataset. The\nresults demonstrate that ThermalLoc outperforms existing representative methods\nemployed for thermal camera relocalization, including AtLoc, MapNet, PoseNet,\nand RobustLoc, achieving superior accuracy and robustness.", "published": "2025-06-23 03:52:35", "link": "http://arxiv.org/abs/2506.18268v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos", "abstract": "3D semantic occupancy prediction in the past was considered to require\nprecise geometric relationships in order to enable effective training. However,\nin complex indoor environments, the large-scale and widespread collection of\ndata, along with the necessity for fine-grained annotations, becomes\nimpractical due to the complexity of data acquisition setups and privacy\nconcerns. In this paper, we demonstrate that 3D spatially-accurate training can\nbe achieved using only indoor Internet data, without the need for any\npre-knowledge of intrinsic or extrinsic camera parameters. In our framework, we\ncollect a web dataset, YouTube-Occ, which comprises house tour videos from\nYouTube, providing abundant real house scenes for 3D representation learning.\nUpon on this web dataset, we establish a fully self-supervised model to\nleverage accessible 2D prior knowledge for reaching powerful 3D indoor\nperception. Specifically, we harness the advantages of the prosperous vision\nfoundation models, distilling the 2D region-level knowledge into the occupancy\nnetwork by grouping the similar pixels into superpixels. Experimental results\nshow that our method achieves state-of-the-art zero-shot performance on two\npopular benchmarks (NYUv2 and OccScanNet", "published": "2025-06-23 03:44:43", "link": "http://arxiv.org/abs/2506.18266v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Weakly Supervised Temporal Action Localization by Exploiting Multi-resolution Information in Temporal Domain", "abstract": "Weakly supervised temporal action localization is a challenging task as only\nthe video-level annotation is available during the training process. To address\nthis problem, we propose a two-stage approach to fully exploit multi-resolution\ninformation in the temporal domain and generate high quality frame-level pseudo\nlabels based on both appearance and motion streams. Specifically, in the first\nstage, we generate reliable initial frame-level pseudo labels, and in the\nsecond stage, we iteratively refine the pseudo labels and use a set of selected\nframes with highly confident pseudo labels to train neural networks and better\npredict action class scores at each frame. We fully exploit temporal\ninformation at multiple scales to improve temporal action localization\nperformance. Specifically, in order to obtain reliable initial frame-level\npseudo labels, in the first stage, we propose an Initial Label Generation (ILG)\nmodule, which leverages temporal multi-resolution consistency to generate high\nquality class activation sequences (CASs), which consist of a number of\nsequences with each sequence measuring how likely each video frame belongs to\none specific action class. In the second stage, we propose a Progressive\nTemporal Label Refinement (PTLR) framework. In our PTLR framework, two networks\ncalled Network-OTS and Network-RTS, which are respectively used to generate\nCASs for the original temporal scale and the reduced temporal scales, are used\nas two streams (i.e., the OTS stream and the RTS stream) to refine the pseudo\nlabels in turn. By this way, the multi-resolution information in the temporal\ndomain is exchanged at the pseudo label level, and our work can help improve\neach stream (i.e., the OTS/RTS stream) by exploiting the refined pseudo labels\nfrom another stream (i.e., the RTS/OTS stream).", "published": "2025-06-23 03:20:18", "link": "http://arxiv.org/abs/2506.18261v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Referring Expression Instance Retrieval and A Strong End-to-End Baseline", "abstract": "Natural language querying of visual content underpins many vision-language\ntasks, typically categorized by text granularity and visual search scope.\nText-Image Retrieval (TIR) retrieves whole images using coarse descriptions,\nwhile Referring Expression Comprehension (REC) localizes objects using\nfine-grained expressions within a single image. However, real-world scenarios\noften require both instance-level retrieval and localization across large\ngalleries -- tasks where TIR lacks precision and REC lacks scalability. To\naddress this gap, we propose a new task: Referring Expression Instance\nRetrieval (REIR), which jointly supports instance-level retrieval and\nlocalization. We introduce REIRCOCO, a large-scale benchmark constructed by\nprompting vision-language models to generate fine-grained expressions for\nMSCOCO and RefCOCO instances. We also present a baseline method, CLARE,\nfeaturing a dual-stream architecture with a Mix of Relation Experts (MORE)\nmodule for capturing inter-instance relationships. CLARE integrates object\ndetection and REC pretraining with Contrastive Language-Instance Alignment\n(CLIA) for end-to-end optimization. Experiments show that CLARE achieves\nstate-of-the-art performance on REIR and generalizes well to TIR and REC,\nhighlighting its effectiveness and versatility.", "published": "2025-06-23 02:28:44", "link": "http://arxiv.org/abs/2506.18246v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning", "abstract": "Large vision-language models (VLMs) for autonomous driving (AD) are evolving\nbeyond perception and cognition tasks toward motion planning. However, we\nidentify two critical challenges in this direction: (1) VLMs tend to learn\nshortcuts by relying heavily on history input information, achieving seemingly\nstrong planning results without genuinely understanding the visual inputs; and\n(2) the chain-ofthought (COT) reasoning processes are always misaligned with\nthe motion planning outcomes, and how to effectively leverage the complex\nreasoning capability to enhance planning remains largely underexplored. In this\npaper, we start from a small-scale domain-specific VLM and propose Drive-R1\ndesigned to bridges the scenario reasoning and motion planning for AD. Drive-R1\nfirst undergoes the supervised finetuning on a elaborate dataset containing\nboth long and short COT data. Drive-R1 is encouraged to reason step-by-step\nfrom visual input to final planning decisions. Subsequently, Drive-R1 is\ntrained within a reinforcement learning framework that incentivizes the\ndiscovery of reasoning paths that are more informative for planning, guided by\nrewards based on predicted trajectories and meta actions. Experimental\nevaluations on the nuScenes and DriveLM-nuScenes benchmarks demonstrate that\nDrive-R1 achieves superior performance compared to existing state-of-the-art\nVLMs. We believe that Drive-R1 presents a promising direction for bridging\nreasoning and planning in AD, offering methodological insights for future\nresearch and applications.", "published": "2025-06-23 01:57:14", "link": "http://arxiv.org/abs/2506.18234v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Shape from Polarization of Thermal Emission and Reflection", "abstract": "Shape estimation for transparent objects is challenging due to their complex\nlight transport. To circumvent these difficulties, we leverage the Shape from\nPolarization (SfP) technique in the Long-Wave Infrared (LWIR) spectrum, where\nmost materials are opaque and emissive. While a few prior studies have explored\nLWIR SfP, these attempts suffered from significant errors due to inadequate\npolarimetric modeling, particularly the neglect of reflection. Addressing this\ngap, we formulated a polarization model that explicitly accounts for the\ncombined effects of emission and reflection. Based on this model, we estimated\nsurface normals using not only a direct model-based method but also a\nlearning-based approach employing a neural network trained on a\nphysically-grounded synthetic dataset. Furthermore, we modeled the LWIR\npolarimetric imaging process, accounting for inherent systematic errors to\nensure accurate polarimetry. We implemented a prototype system and created\nThermoPol, the first real-world benchmark dataset for LWIR SfP. Through\ncomprehensive experiments, we demonstrated the high accuracy and broad\napplicability of our method across various materials, including those\ntransparent in the visible spectrum.", "published": "2025-06-23 00:33:17", "link": "http://arxiv.org/abs/2506.18217v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Perfect phylogenies via the Minimum Uncovering Branching problem: efficiently solvable cases", "abstract": "In this paper, we present new efficiently solvable cases of the Minimum\nUncovering Branching problem, an optimization problem with applications in\ncancer genomics introduced by Hujdurovi\\'c, Husi\\'c, Milani\\v{c}, Rizzi, and\nTomescu in 2018. The problem involves a family of finite sets, and the goal is\nto map each non-maximal set to exactly one set that contains it, minimizing the\nsum of uncovered elements across all sets in the family. Hujdurovi\\'c et al.\nformulated the problem in terms of branchings of the digraph formed by the\nproper set inclusion relation on the input sets and studied the problem\ncomplexity based on properties of the corresponding partially ordered set, in\nparticular, with respect to its height and width, defined respectively as the\nmaximum cardinality of a chain and an antichain. They showed that the problem\nis APX-complete for instances of bounded height and that a constant-factor\napproximation algorithm exists for instances of bounded width, but left the\nexact complexity for bounded-width instances open. In this paper, we answer\nthis question by proving that the problem is solvable in polynomial time. We\nderive this result by examining the structural properties of optimal solutions\nand reducing the problem to computing maximum matchings in bipartite graphs and\nmaximum weight antichains in partially ordered sets. We also introduce a new\npolynomially computable lower bound and identify another condition for\npolynomial-time solvability.", "published": "2025-06-23 12:29:44", "link": "http://arxiv.org/abs/2506.18578v1", "categories": ["cs.DM", "cs.DS", "math.CO", "q-bio.PE", "05C85 (Primary), 05C20, 05C90, 06A07, 92D10 (Secondary)"], "primary_category": "cs.DM"}
{"title": "Distribution of codewords on the faces of a hypercube and new combinatorial identities", "abstract": "We present a novel framework for studying combinatorial identities through\nthe geometric lens of subset distributions in q-valued cubes. By analyzing how\nelements of arbitrary subsets are distributed among the faces of the cube\nE_q^n, we discover new combinatorial identities with geometric significance. We\nprove that for any subset A contained in E_2^n, the rank function satisfies\nrefined bounds that lead to exact computations for small cardinalities.\nSpecifically, we show that for odd cardinalities, the lower bound is\n4D_A/(|A|^2-1) where D_A is the sum of all pairwise Hamming distances in A. Our\nmain theorem establishes identities connecting the number of k-dimensional\nfaces containing exactly e elements of a subset to binomial sums over all\nsubsets of specified cardinality. This yields a parametric family of identities\nwhere classical results emerge as special cases. As applications, we derive a\ngeometric interpretation of Vandermonde's identity by examining faces of\nq-valued cubes, revealing that this classical result naturally arises from\ncounting element distributions. We also obtain a completely new identity for\neven-weight vectors: (2^(k-1) - 1) times 2^(n-1) times binomial(n,k) equals the\nsum over i from 1 to floor(n/2) of binomial(n,2i) times binomial(n-2i,k-2i).\nThis identity, valid for all 1 <= k <= n, demonstrates how geometric\nperspectives can uncover hidden combinatorial relationships. Our framework\nprovides a unified approach for generating new identities and understanding\nexisting ones through subset rank analysis.", "published": "2025-06-23 10:44:31", "link": "http://arxiv.org/abs/2506.18494v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting on Spotify", "abstract": "Spotify, a large-scale multimedia platform, attracts over 675 million monthly\nactive users who collectively consume millions of hours of music, podcasts,\naudiobooks, and video content. This diverse content consumption pattern\nintroduces unique challenges for computational advertising, which must\neffectively integrate a variety of ad modalities, including audio, video, and\ndisplay, within a single user experience. Traditional ad recommendation models,\nprimarily designed for foregrounded experiences, often struggle to reconcile\nthe platform's inherent audio-centrality with the demands of optimizing ad\nperformance across multiple formats and modalities. To overcome these\nchallenges, we introduce Cross-modal Adaptive Mixture-of-Experts (CAMoE), a\nnovel framework for optimizing click-through rate (CTR) prediction in both\naudio-centric and multi-modal settings. CAMoE enhances traditional\nmixture-of-experts models by incorporating modality-aware task grouping,\nadaptive loss masking, and deep-cross networks (DCN) to capture complex feature\ninteractions within a multi-modal ad ecosystem. Through extensive ablation\nstudies, we demonstrate that this approach achieves near Pareto-optimal\nperformance across audio, video, and display ad formats, significantly\nimproving AUC-PR compared to conventional single-task and content-based\nmulti-task learning baselines. When deployed at scale on Spotify's ad serving\nplatform, CAMoE delivered substantial gains, yielding a 14.5% increase in CTR\nfor audio ads, a 1.3% increase for video ads, and a 4.8% reduction in expected\ncost-per-click (eCPC) for audio slots.", "published": "2025-06-23 15:11:43", "link": "http://arxiv.org/abs/2506.18735v1", "categories": ["cs.IR", "eess.AS", "H.3.3; I.2.1; I.2.6"], "primary_category": "cs.IR"}
{"title": "Harnessing the Power of Reinforcement Learning for Language-Model-Based Information Retriever via Query-Document Co-Augmentation", "abstract": "Recent studies have proposed leveraging Large Language Models (LLMs) as\ninformation retrievers through query rewriting. However, for challenging\ncorpora, we argue that enhancing queries alone is insufficient for robust\nsemantic matching; the LLM should also have sufficient understanding of the\ncorpus by directly handling and augmenting the documents themselves. To this\nend, we present an LLM-based retriever empowered to augment both user queries\nand corpus documents, with its policy fully explored via reinforcement learning\n(RL) and minimal human inductive bias. Notably, we find that simply allowing\nthe LLM to modify documents yields little benefit unless paired with our\ncarefully designed bidirectional RL framework, which enables the LLM to\nsimultaneously learn and collaborate on both query and document augmentation\npolicies. A key technical challenge in realizing such a framework lies in\njointly updating both policies during training, where the rewards for the two\ndirections depend on each other, making their entangled reward intractable. Our\napproach addresses this by introducing a reward sampling strategy and a\nspecifically designed RL algorithm that enables effective training with these\nsampled rewards. Experimental results demonstrate that our approach\nsignificantly enhances LLM-based retrieval performance in both sparse and dense\nsettings, particularly in difficult retrieval domains, and achieves strong\ncross-benchmark generalization. Our code is released at\nhttps://github.com/liujm2001/CoAugRetriever.", "published": "2025-06-23 14:14:43", "link": "http://arxiv.org/abs/2506.18670v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Rethinking Click Models in Light of Carousel Interfaces: Theory-Based Categorization and Design of Click Models", "abstract": "Click models are a well-established for modeling user interactions with web\ninterfaces. Previous work has mainly focused on traditional single-list web\nsearch settings; this includes existing surveys that introduced categorizations\nbased on the first generation of probabilistic graphical model (PGM) click\nmodels that have become standard. However, these categorizations have become\noutdated, as their conceptualizations are unable to meaningfully compare PGM\nwith neural network (NN) click models nor generalize to newer interfaces, such\nas carousel interfaces. We argue that this outdated view fails to adequately\nexplain the fundamentals of click model designs, thus hindering the development\nof novel click models.\n  This work reconsiders what should be the fundamental concepts in click model\ndesign, grounding them - unlike previous approaches - in their mathematical\nproperties. We propose three fundamental key-design choices that explain what\nstatistical patterns a click model can capture, and thus indirectly, what user\nbehaviors they can capture. Based on these choices, we create a novel click\nmodel taxonomy that allows a meaningful comparison of all existing click\nmodels; this is the first taxonomy of single-list, grid and carousel click\nmodels that includes PGMs and NNs. Finally, we show how our conceptualization\nprovides a foundation for future click model design by an example derivation of\na novel design for carousel interfaces.", "published": "2025-06-23 11:57:11", "link": "http://arxiv.org/abs/2506.18548v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Comparative Analysis of Lion and AdamW Optimizers for Cross-Encoder Reranking with MiniLM, GTE, and ModernBERT", "abstract": "Modern information retrieval systems often employ a two-stage pipeline: an\nefficient initial retrieval stage followed by a computationally intensive\nreranking stage. Cross-encoders have shown strong effectiveness for reranking\ndue to their deep analysis of query-document pairs. This paper studies the\nimpact of the Lion optimizer, a recent alternative to AdamW, during fine-tuning\nof cross-encoder rerankers. We fine-tune three transformer models-MiniLM, GTE,\nand ModernBERT-on the MS MARCO passage ranking dataset using both optimizers.\nGTE and ModernBERT support extended context lengths (up to 8192 tokens). We\nevaluate effectiveness using TREC 2019 Deep Learning Track and MS MARCO dev set\n(MRR@10). Experiments, run on the Modal cloud platform, reveal that ModernBERT\nwith Lion achieves the best NDCG@10 (0.7225) and MAP (0.5121) on TREC DL 2019,\nwhile MiniLM with Lion ties ModernBERT for MRR@10 (0.5988) on MS MARCO dev.\nLion also provides superior GPU efficiency, improving utilization by 2.67% to\n10.33% across models. We analyze performance trends using standard IR metrics\nand discuss the optimizer's impact on training dynamics across architectures.", "published": "2025-06-23 05:30:09", "link": "http://arxiv.org/abs/2506.18297v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Oblivious Deletion Codes", "abstract": "We construct deletion error-correcting codes in the oblivious model, where\nerrors are adversarial but oblivious to the encoder's randomness. Oblivious\nerrors bridge the gap between the adversarial and random error models, and are\nmotivated by applications like DNA storage, where the noise is caused by\nhard-to-model physical phenomena, but not by an adversary.\n  (1) (Explicit oblivious) We construct $t$ oblivious deletion codes, with\nredundancy $\\sim 2t\\log n$, matching the existential bound for adversarial\ndeletions.\n  (2) (List decoding implies explicit oblivious) We show that explicit\nlist-decodable codes yield explicit oblivious deletion codes with essentially\nthe same parameters. By a work of Guruswami and H\\r{a}stad (IEEE TIT, 2021),\nthis gives 2 oblivious deletion codes with redundancy $\\sim 3\\log n$, beating\nthe existential redundancy for 2 adversarial deletions.\n  (3) (Randomized oblivious) We give a randomized construction of oblivious\ncodes that, with probability at least $1-2^{-n}$, produces a code correcting\n$t$ oblivious deletions with redundancy $\\sim(t+1)\\log n$, beating the\nexistential adversarial redundancy of $\\sim 2t\\log n$.\n  (4) (Randomized adversarial) Studying the oblivious model can inform better\nconstructions of adversarial codes. The same technique produces, with\nprobability at least $1-2^{-n}$, a code correcting $t$ adversarial deletions\nwith redundancy $\\sim (2t+1)\\log n$, nearly matching the existential redundancy\nof $\\sim 2t\\log n$.\n  The common idea behind these results is to reduce the hash size by modding by\na prime chosen (randomly) from a small subset, and including a small encoding\nof the prime in the hash.", "published": "2025-06-23 17:49:56", "link": "http://arxiv.org/abs/2506.18878v1", "categories": ["cs.IT", "cs.CC", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cellular Automata as Generators of Interleaving Sequences", "abstract": "An interleaving sequence is obtained by combining or intertwining elements\nfrom two or more sequences. On the other hand, cellular automata are known to\nbe generators for keystream sequences. In this paper we present two families of\none-dimensional cellular automata as generators of interleaving sequences. This\nstudy aims to close a notable gap within the current body of literature by\nexploring the capacity of cellular automata to generate interleaving sequences.\nWhile previous works have separately examined cellular automata as sequence\ngenerators and interleaving sequences, there exists limited literature\ninterconnecting these two topics. Our study seeks to bridge this gap, providing\nperspectives on the generation of interleaving sequences through the\nutilisation of cellular automata, thereby fostering a deeper understanding of\nboth disciplines.", "published": "2025-06-23 17:07:27", "link": "http://arxiv.org/abs/2506.18848v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Spatial Regionalization: A Hybrid Quantum Computing Approach", "abstract": "Quantum computing has shown significant potential to address complex\noptimization problems; however, its application remains confined to specific\nproblems at limited scales. Spatial regionalization remains largely unexplored\nin quantum computing due to its complexity and large number of variables. In\nthis paper, we introduce the first hybrid quantum-classical method to spatial\nregionalization by decomposing the problem into manageable subproblems,\nleveraging the strengths of both classical and quantum computation. This study\nestablishes a foundational framework for effectively integrating quantum\ncomputing methods into realistic and complex spatial optimization tasks. Our\ninitial results show a promising quantum performance advantage for a broad\nrange of spatial regionalization problems and their variants.", "published": "2025-06-23 16:04:05", "link": "http://arxiv.org/abs/2506.18799v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Semidefinite Programming for the Asymmetric Stochastic Block Model", "abstract": "We consider semidefinite programming (SDP) for the binary stochastic block\nmodel with equal-sized communities. Prior work of Hajek, Wu, and Xu proposed an\nSDP (sym-SDP) for the symmetric case where the intra-community edge\nprobabilities are equal, and showed that the SDP achieves the\ninformation-theoretic threshold for exact recovery under the symmetry\nassumption. A key open question is whether SDPs can be used to achieve exact\nrecovery for non-symmetric block models. In order to inform the design of a new\nSDP for the non-symmetric setting, we investigate the failure of sym-SDP when\nit is applied to non-symmetric settings. We formally show that sym-SDP fails to\nreturn the correct labeling of the vertices in some information-theoretically\nfeasible, asymmetric cases. In addition, we give an intuitive geometric\ninterpretation of the failure of sym-SDP in asymmetric settings, which in turn\nsuggests an SDP formulation to handle the asymmetric setting. Still, this new\nSDP cannot be readily analyzed by existing techniques, suggesting a fundamental\nlimitation in the design of SDPs for community detection.", "published": "2025-06-23 15:25:19", "link": "http://arxiv.org/abs/2506.18754v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Explicit Constructions of Sum-Rank Metric Codes from Quadratic Kummer Extensions", "abstract": "This paper presents new constructions of sum-rank metric codes derived from\nalgebraic function fields, while the existing results about such codes remain\nlimited. A central challenge in this field involves the determination of\nparameters. We address this challenge through quadratic Kummer extensions, and\npropose two general constructions of $2\\times2$ sum-rank codes. The novel\nsum-rank metric code constructions derived from algebraic function fields\ndemonstrate superior code lengths compared to conventional coding paradigms,\nparticularly when contrasted with linearized Reed-Solomon codes under\nequivalent code parameter constraints. We also establish explicit parameters\nincluding dimensions and minimum distances of our codes. Finally, an\nillustrative example through elliptic function fields is constructed for\nvalidating the theoretical framework.", "published": "2025-06-23 13:55:11", "link": "http://arxiv.org/abs/2506.18653v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Simple but Accurate Approximation for Multivariate Gaussian Rate-Distortion Function and Its Application in Maximal Coding Rate Reduction", "abstract": "The multivariate Gaussian rate-distortion (RD) function is crucial in various\napplications, such as digital communications, data storage, or neural networks.\nHowever, the complex form of the multivariate Gaussian RD function prevents its\napplication in many neural network-based scenarios that rely on its analytical\nproperties, for example, white-box neural networks, multi-device task-oriented\ncommunication, and semantic communication. This paper proposes a simple but\naccurate approximation for the multivariate Gaussian RD function. The upper and\nlower bounds on the approximation error (the difference between the approximate\nand the exact value) are derived, which indicate that for well-conditioned\ncovariance matrices, the approximation error is small. In particular, when the\ncondition number of the covariance matrix approaches 1, the approximation error\napproaches 0. In addition, based on the proposed approximation, a new\nclassification algorithm called Adaptive Regularized ReduNet (AR-ReduNet) is\nderived by applying the approximation to ReduNet, which is a white-box\nclassification network oriented from Maximal Coding Rate Reduction (MCR$^2$)\nprinciple. Simulation results indicate that AR-ReduNet achieves higher accuracy\nand more efficient optimization than ReduNet.", "published": "2025-06-23 13:19:31", "link": "http://arxiv.org/abs/2506.18613v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A scalable estimator of high-order information in complex dynamical systems", "abstract": "Our understanding of neural systems rests on our ability to characterise how\nthey perform distributed computation and integrate information. Advances in\ninformation theory have introduced several quantities to describe complex\ninformation structures, where collective patterns of coordination emerge from\nhigh-order (i.e. beyond-pairwise) interdependencies. Unfortunately, the use of\nthese approaches to study large neural systems is severely hindered by the poor\nscalability of existing techniques. Moreover, there are relatively few measures\nspecifically designed for multivariate time series data. Here we introduce a\nnovel measure of information about macroscopic structures, termed\nM-information, which quantifies the high-order integration of information in\ncomplex dynamical systems. We show that M-information can be calculated via a\nconvex optimisation problem, and we derive a robust and efficient algorithm\nthat scales gracefully with system size. Our analyses show that M-information\nis resilient to noise, indexes critical behaviour in artificial neuronal\npopulations, and reflects task performance in real-world mouse brain activity\ndata. Furthermore, M-information can be incorporated into existing information\ndecomposition frameworks to reveal a comprehensive taxonomy of information\ndynamics. Taken together, these results help us unravel collective computation\nin complex neural systems.", "published": "2025-06-23 10:50:24", "link": "http://arxiv.org/abs/2506.18498v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-user Downlink with Reconfigurable Intelligent Metasurface Antennas (RIMSA) Array", "abstract": "Reconfigurable Intelligent Surfaces (RIS) is a transformative technology with\ngreat potential in many applications in wireless communications and realizing\nthe Internet of Everything at sixth generation (6G). In this study, we propose\na wireless system where the RIS acts as an antenna, which we call\nReconfigurable Intelligent Metasurface Antennas (RIMSA). In particular, the\nbase station (BS) equipped with a RIMSA array performs downlink transmissions\nto multiple users, where each user has a single or multiple RIMSA/RF links, and\nwe aim to solve the sum-rate maximization problem by jointly optimizing the\ndigital processing matrix of the transceivers and the phase responses of RIMSA\narray at both BS and users. For the multi-user multiple-input single-output\n(MU-MISO) scenario, we develop an alternating optimization algorithm to slove\nthe problem, where a fractional programming (FP) is used to optimize the\ndigital processing matrix and a product manifold optimization (PMO) is proposed\nto provide the optimal phase responses of the RIMSA array at both BS and users.\nFor the multi-user multiple-input multiple-output (MU-MIMO) scenario, we equate\nit to a weighted sum of mean square errors minimization problem, which can be\nsolved by three subproblems iteratively. Both the optimal digital precoder\nsubproblem and the optimal digital combiner subproblem have closed-form\nsolutions, and the subproblem of RIMSA configuration is solved by the PMO\nalgorithm as well. Simulation results demonstrate that the proposed algorithms\nachieve significant performance gains over conventional algorithms.", "published": "2025-06-23 09:00:24", "link": "http://arxiv.org/abs/2506.18418v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "$(\\ell,\u03b4)$-Diversity: Linkage-Robustness via a Composition Theorem", "abstract": "In this paper, we consider the problem of degradation of anonymity upon\nlinkages of anonymized datasets. We work in the setting where an adversary\nlinks together $t\\geq 2$ anonymized datasets in which a user of interest\nparticipates, based on the user's known quasi-identifiers, which motivates the\nuse of $\\ell$-diversity as the notion of dataset anonymity. We first argue that\nin the worst case, such linkage attacks can reveal the exact sensitive\nattribute of the user, even when each dataset respects $\\ell$-diversity, for\nmoderately large values of $\\ell$. This issue motivates our definition of\n(approximate) $(\\ell,\\delta)$-diversity -- a parallel of (approximate)\n$(\\epsilon,\\delta)$-differential privacy (DP) -- which simply requires that a\ndataset respect $\\ell$-diversity, with high probability. We then present a\nmechanism for achieving $(\\ell,\\delta)$-diversity, in the setting of\nindependent and identically distributed samples. Next, we establish bounds on\nthe degradation of $(\\ell,\\delta)$-diversity, via a simple ``composition\ntheorem,'' similar in spirit to those in the DP literature, thereby showing\nthat approximate diversity, unlike standard diversity, is roughly preserved\nupon linkage. Finally, we describe simple algorithms for maximizing utility,\nmeasured in terms of the number of anonymized ``equivalence classes,'' and\nderive explicit lower bounds on the utility, for special sample distributions.", "published": "2025-06-23 08:42:14", "link": "http://arxiv.org/abs/2506.18405v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Rack-Aware MSR Codes with Linear Field Size and Smaller Sub-Packetization for Tolerating Multiple Erasures", "abstract": "In an $(n,k,d)$ rack-aware storage model, the system consists of $n$ nodes\nuniformly distributed across $\\bar{n}$ successive racks, such that each rack\ncontains $u$ nodes of equal capacity and the reconstructive degree satisfies\n$k=\\bar{k}u+v$ where $0\\leq v\\leq u-1$. Suppose there are $h\\geq1$ failed nodes\nin a rack (called the host rack). Then together with its surviving nodes, the\nhost rack downloads recovery data from $\\bar{d}$ helper racks and repairs its\nfailed nodes. In this paper, we focus on studying the rack-aware minimum\nstorage generating (MSR) codes for repairing $h$ failed nodes within the same\nrack. By using the coupled-layer construction with the alignment technique, we\nconstruct the first class of rack-aware MSR codes for all\n$\\bar{k}+1\\leq\\bar{d}\\leq\\bar{n}-1$ which achieve the small sub-packetization\n$l=\\bar{s}^{\\lceil\\bar{n}/\\bar{s}\\rceil}$ where the field size $q$ increases\nlinearly with $n$ and $\\bar{s}=\\bar{d}-\\bar{k}+1$. In addition, these codes\nachieve optimal repair bandwidth for $1\\leq h\\leq u-v$, and asymptotically\noptimal repair bandwidth for $u-v+1\\leq h\\leq u$. In particular, they achieve\noptimal access when $h=u-v$. It is worth noting that the existing rack-aware\nMSR codes which achieve the same sub-packetization\n$l=\\bar{s}^{\\lceil\\bar{n}/\\bar{s}\\rceil}$ are only known for the special case\nof $\\bar{d}=\\bar{n}-1$, $h=1$, and the field size is much larger than ours.\nThen, based on our first construction we further develop another class of\nexplicit rack-aware MSR codes with even smaller sub-packetization\n$l=\\bar{s}^{\\lceil\\bar{n}/(\\bar{s}+1)\\rceil}$ for all admissible values of\n$\\bar{d}$.", "published": "2025-06-23 07:52:20", "link": "http://arxiv.org/abs/2506.18367v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Phase retrieval with rank $d$ measurements -- \\emph{descending} algorithms phase transitions", "abstract": "Companion paper [118] developed a powerful \\emph{Random duality theory} (RDT)\nbased analytical program to statistically characterize performance of\n\\emph{descending} phase retrieval algorithms (dPR) (these include all variants\nof gradient descents and among them widely popular Wirtinger flows). We here\ngeneralize the program and show how it can be utilized to handle rank $d$\npositive definite phase retrieval (PR) measurements (with special cases $d=1$\nand $d=2$ serving as emulations of the real and complex phase retrievals,\nrespectively). In particular, we observe that the minimal sample complexity\nratio (number of measurements scaled by the dimension of the unknown signal)\nwhich ensures dPR's success exhibits a phase transition (PT) phenomenon. For\nboth plain and lifted RDT we determine phase transitions locations. To\ncomplement theoretical results we implement a log barrier gradient descent\nvariant and observe that, even in small dimensional scenarios (with problem\nsizes on the order of 100), the simulated phase transitions are in an excellent\nagreement with the theoretical predictions.", "published": "2025-06-23 04:28:46", "link": "http://arxiv.org/abs/2506.18282v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Optimal spectral initializers impact on phase retrieval phase transitions -- an RDT view", "abstract": "We analyze the relation between spectral initializers and theoretical limits\nof \\emph{descending} phase retrieval algorithms (dPR). In companion paper\n[104], for any sample complexity ratio, $\\alpha$, \\emph{parametric manifold},\n${\\mathcal {PM}}(\\alpha)$, is recognized as a critically important structure\nthat generically determines dPRs abilities to solve phase retrieval (PR).\nMoreover, overlap between the algorithmic solution and the true signal is\npositioned as a key ${\\mathcal {PM}}$'s component. We here consider the\nso-called \\emph{overlap optimal} spectral initializers (OptSpins) as dPR's\nstarting points and develop a generic \\emph{Random duality theory} (RDT) based\nprogram to statistically characterize them. In particular, we determine the\nfunctional structure of OptSpins and evaluate the starting overlaps that they\nprovide for the dPRs. Since ${\\mathcal {PM}}$'s so-called \\emph{flat regions}\nare highly susceptible to \\emph{local jitteriness} and as such are key\nobstacles on dPR's path towards PR's global optimum, a precise characterization\nof the starting overlap allows to determine if such regions can be successfully\ncircumvented. Through the presented theoretical analysis we observe two key\npoints in that regard: \\textbf{\\emph{(i)}} dPR's theoretical phase transition\n(critical $\\alpha$ above which they solve PR) might be difficult to practically\nachieve as the ${\\mathcal {PM}}$'s flat regions are large causing the\nassociated OptSpins to fall exactly within them; and \\textbf{\\emph{(ii)}}\nOpting for so-called ``\\emph{safer compression}'' and slightly increasing\n$\\alpha$ (by say $15\\%$) shrinks flat regions and allows OptSpins to fall\noutside them and dPRs to ultimately solve PR. Numerical simulations are\nconducted as well and shown to be in an excellent agreement with theoretical\npredictions.", "published": "2025-06-23 04:20:24", "link": "http://arxiv.org/abs/2506.18279v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Phase transition of \\emph{descending} phase retrieval algorithms", "abstract": "We study theoretical limits of \\emph{descending} phase retrieval algorithms.\nUtilizing \\emph{Random duality theory} (RDT) we develop a generic program that\nallows statistical characterization of various algorithmic performance metrics.\nThrough these we identify the concepts of \\emph{parametric manifold} and its\n\\emph{funneling points} as key mathematical objects that govern the underlying\nalgorithms' behavior. An isomorphism between single funneling point manifolds\nand global convergence of descending algorithms is established. The structure\nand shape of the parametric manifold as well as its dependence on the sample\ncomplexity are studied through both plain and lifted RDT. Emergence of a phase\ntransition is observed. Namely, as sample complexity increases, parametric\nmanifold transitions from a multi to a single funneling point structure. This\nin return corresponds to a transition from the scenarios where descending\nalgorithms generically fail to the scenarios where they succeed in solving\nphase retrieval. We also develop and implement a practical algorithmic variant\nthat in a hybrid alternating fashion combines a barrier and a plain gradient\ndescent. Even though the theoretical results are obtained for infinite\ndimensional scenarios (and consequently non-jittery parametric manifolds), we\nobserve a strong agrement between theoretical and simulated phase transitions\npredictions for fairly small dimensions on the order of a few hundreds.", "published": "2025-06-23 04:10:35", "link": "http://arxiv.org/abs/2506.18275v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Frequency Range 3 for ISAC in 6G: Potentials and Challenges", "abstract": "Spanning 7-24 GHz, frequency range 3 (FR3), is a key enabler for\nnext-generation wireless networks by bridging the coverage of sub-6 GHz and the\ncapacity of millimeter-wave bands. Its unique propagation characteristics, such\nas extended near-field regions and spatially nonstationary fading, enable new\ntransmission strategies. This article explores the potential of FR3 for\nintegrated sensing and communication (ISAC), which unifies wireless\ncommunication and environmental sensing. We show that FR3's bandwidth and\nmultiple-input multiple-output (MIMO) capabilities enable high-resolution\nsensing, multi-target tracking, and fast data transmission. We emphasize the\nimportance of ultra-massive MIMO with extremely large aperture arrays (ELAAs)\nand the need for unified near-field and far-field channel models to support\nefficient ISAC. Finally, we outline challenges and future research directions\nfor ELAA-based ISAC in 6G FR3.", "published": "2025-06-23 02:17:59", "link": "http://arxiv.org/abs/2506.18243v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Offline Goal-Conditioned Reinforcement Learning with Projective Quasimetric Planning", "abstract": "Offline Goal-Conditioned Reinforcement Learning seeks to train agents to\nreach specified goals from previously collected trajectories. Scaling that\npromises to long-horizon tasks remains challenging, notably due to compounding\nvalue-estimation errors. Principled geometric offers a potential solution to\naddress these issues. Following this insight, we introduce Projective\nQuasimetric Planning (ProQ), a compositional framework that learns an\nasymmetric distance and then repurposes it, firstly as a repulsive energy\nforcing a sparse set of keypoints to uniformly spread over the learned latent\nspace, and secondly as a structured directional cost guiding towards proximal\nsub-goals. In particular, ProQ couples this geometry with a Lagrangian\nout-of-distribution detector to ensure the learned keypoints stay within\nreachable areas. By unifying metric learning, keypoint coverage, and\ngoal-conditioned control, our approach produces meaningful sub-goals and\nrobustly drives long-horizon goal-reaching on diverse a navigation benchmarks.", "published": "2025-06-23 17:07:20", "link": "http://arxiv.org/abs/2506.18847v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Agent Online Control with Adversarial Disturbances", "abstract": "Multi-agent control problems involving a large number of agents with\ncompeting and time-varying objectives are increasingly prevalent in\napplications across robotics, economics, and energy systems. In this paper, we\nstudy online control in multi-agent linear dynamical systems with disturbances.\nIn contrast to most prior work in multi-agent control, we consider an online\nsetting where disturbances are adversarial and where each agent seeks to\nminimize its own, adversarial sequence of convex losses. In this setting, we\ninvestigate the robustness of gradient-based controllers from single-agent\nonline control, with a particular focus on understanding how individual regret\nguarantees are influenced by the number of agents in the system. Under minimal\ncommunication assumptions, we prove near-optimal sublinear regret bounds that\nhold uniformly for all agents. Finally, when the objectives of the agents are\naligned, we show that the multi-agent control problem induces a time-varying\npotential game for which we derive equilibrium gap guarantees.", "published": "2025-06-23 16:24:31", "link": "http://arxiv.org/abs/2506.18814v1", "categories": ["cs.LG", "cs.GT", "math.OC"], "primary_category": "cs.LG"}
{"title": "Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures", "abstract": "Physics-informed deep learning has achieved remarkable progress by embedding\ngeometric priors, such as Hamiltonian symmetries and variational principles,\ninto neural networks, enabling structure-preserving models that extrapolate\nwith high accuracy. However, in systems with dissipation and holonomic\nconstraints, ubiquitous in legged locomotion and multibody robotics, the\ncanonical symplectic form becomes degenerate, undermining the very invariants\nthat guarantee stability and long-term prediction. In this work, we tackle this\nfoundational limitation by introducing Presymplectification Networks (PSNs),\nthe first framework to learn the symplectification lift via Dirac structures,\nrestoring a non-degenerate symplectic geometry by embedding constrained systems\ninto a higher-dimensional manifold. Our architecture combines a recurrent\nencoder with a flow-matching objective to learn the augmented phase-space\ndynamics end-to-end. We then attach a lightweight Symplectic Network (SympNet)\nto forecast constrained trajectories while preserving energy, momentum, and\nconstraint satisfaction. We demonstrate our method on the dynamics of the\nANYmal quadruped robot, a challenging contact-rich, multibody system. To the\nbest of our knowledge, this is the first framework that effectively bridges the\ngap between constrained, dissipative mechanical systems and symplectic\nlearning, unlocking a whole new class of geometric machine learning models,\ngrounded in first principles yet adaptable from data.", "published": "2025-06-23 16:23:37", "link": "http://arxiv.org/abs/2506.18812v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "A Multi-view Divergence-Convergence Feature Augmentation Framework for Drug-related Microbes Prediction", "abstract": "In the study of drug function and precision medicine, identifying new\ndrug-microbe associations is crucial. However, current methods isolate\nassociation and similarity analysis of drug and microbe, lacking effective\ninter-view optimization and coordinated multi-view feature fusion. In our\nstudy, a multi-view Divergence-Convergence Feature Augmentation framework for\nDrug-related Microbes Prediction (DCFA_DMP) is proposed, to better learn and\nintegrate association information and similarity information. In the divergence\nphase, DCFA_DMP strengthens the complementarity and diversity between\nheterogeneous information and similarity information by performing Adversarial\nLearning method between the association network view and different similarity\nviews, optimizing the feature space. In the convergence phase, a novel\nBidirectional Synergistic Attention Mechanism is proposed to deeply synergize\nthe complementary features between different views, achieving a deep fusion of\nthe feature space. Moreover, Transformer graph learning is alternately applied\non the drug-microbe heterogeneous graph, enabling each drug or microbe node to\nfocus on the most relevant nodes. Numerous experiments demonstrate DCFA_DMP's\nsignificant performance in predicting drug-microbe associations. It also proves\neffectiveness in predicting associations for new drugs and microbes in cold\nstart experiments, further confirming its stability and reliability in\npredicting potential drug-microbe associations.", "published": "2025-06-23 16:03:46", "link": "http://arxiv.org/abs/2506.18797v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DPG loss functions for learning parameter-to-solution maps by neural networks", "abstract": "We develop, analyze, and experimentally explore residual-based loss functions\nfor machine learning of parameter-to-solution maps in the context of\nparameter-dependent families of partial differential equations (PDEs). Our\nprimary concern is on rigorous accuracy certification to enhance prediction\ncapability of resulting deep neural network reduced models. This is achieved by\nthe use of variationally correct loss functions. Through one specific example\nof an elliptic PDE, details for establishing the variational correctness of a\nloss function from an ultraweak Discontinuous Petrov Galerkin (DPG)\ndiscretization are worked out. Despite the focus on the example, the proposed\nconcepts apply to a much wider scope of problems, namely problems for which\nstable DPG formulations are available. The issue of {high-contrast} diffusion\nfields and ensuing difficulties with degrading ellipticity are discussed. Both\nnumerical results and theoretical arguments illustrate that for high-contrast\ndiffusion parameters the proposed DPG loss functions deliver much more robust\nperformance than simpler least-squares losses.", "published": "2025-06-23 15:40:56", "link": "http://arxiv.org/abs/2506.18773v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Local Averaging Accurately Distills Manifold Structure From Noisy Data", "abstract": "High-dimensional data are ubiquitous, with examples ranging from natural\nimages to scientific datasets, and often reside near low-dimensional manifolds.\nLeveraging this geometric structure is vital for downstream tasks, including\nsignal denoising, reconstruction, and generation. However, in practice, the\nmanifold is typically unknown and only noisy samples are available. A\nfundamental approach to uncovering the manifold structure is local averaging,\nwhich is a cornerstone of state-of-the-art provable methods for manifold\nfitting and denoising. However, to the best of our knowledge, there are no\nworks that rigorously analyze the accuracy of local averaging in a manifold\nsetting in high-noise regimes. In this work, we provide theoretical analyses of\na two-round mini-batch local averaging method applied to noisy samples drawn\nfrom a $d$-dimensional manifold $\\mathcal M \\subset \\mathbb{R}^D$, under a\nrelatively high-noise regime where the noise size is comparable to the reach\n$\\tau$. We show that with high probability, the averaged point $\\hat{\\mathbf\nq}$ achieves the bound $d(\\hat{\\mathbf q}, \\mathcal M) \\leq \\sigma\n\\sqrt{d\\left(1+\\frac{\\kappa\\mathrm{diam}(\\mathcal {M})}{\\log(D)}\\right)}$,\nwhere $\\sigma, \\mathrm{diam(\\mathcal M)},\\kappa$ denote the standard deviation\nof the Gaussian noise, manifold's diameter and a bound on its extrinsic\ncurvature, respectively. This is the first analysis of local averaging accuracy\nover the manifold in the relatively high noise regime where $\\sigma \\sqrt{D}\n\\approx \\tau$. The proposed method can serve as a preprocessing step for a wide\nrange of provable methods designed for lower-noise regimes. Additionally, our\nframework can provide a theoretical foundation for a broad spectrum of\ndenoising and dimensionality reduction methods that rely on local averaging\ntechniques.", "published": "2025-06-23 15:32:16", "link": "http://arxiv.org/abs/2506.18761v1", "categories": ["stat.ML", "cs.CG", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Fast State-Augmented Learning for Wireless Resource Allocation with Dual Variable Regression", "abstract": "We consider resource allocation problems in multi-user wireless networks,\nwhere the goal is to optimize a network-wide utility function subject to\nconstraints on the ergodic average performance of users. We demonstrate how a\nstate-augmented graph neural network (GNN) parametrization for the resource\nallocation policy circumvents the drawbacks of the ubiquitous dual subgradient\nmethods by representing the network configurations (or states) as graphs and\nviewing dual variables as dynamic inputs to the model, viewed as graph signals\nsupported over the graphs. Lagrangian maximizing state-augmented policies are\nlearned during the offline training phase, and the dual variables evolve\nthrough gradient updates while executing the learned state-augmented policies\nduring the inference phase. Our main contributions are to illustrate how\nnear-optimal initialization of dual multipliers for faster inference can be\naccomplished with dual variable regression, leveraging a secondary GNN\nparametrization, and how maximization of the Lagrangian over the multipliers\nsampled from the dual descent dynamics substantially improves the training of\nstate-augmented models. We demonstrate the superior performance of the proposed\nalgorithm with extensive numerical experiments in a case study of transmit\npower control. Finally, we prove a convergence result and an exponential\nprobability bound on the excursions of the dual function (iterate) optimality\ngaps.", "published": "2025-06-23 15:20:58", "link": "http://arxiv.org/abs/2506.18748v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Experimenting, Fast and Slow: Bayesian Optimization of Long-term Outcomes with Online Experiments", "abstract": "Online experiments in internet systems, also known as A/B tests, are used for\na wide range of system tuning problems, such as optimizing recommender system\nranking policies and learning adaptive streaming controllers. Decision-makers\ngenerally wish to optimize for long-term treatment effects of the system\nchanges, which often requires running experiments for a long time as short-term\nmeasurements can be misleading due to non-stationarity in treatment effects\nover time. The sequential experimentation strategies--which typically involve\nseveral iterations--can be prohibitively long in such cases. We describe a\nnovel approach that combines fast experiments (e.g., biased experiments run\nonly for a few hours or days) and/or offline proxies (e.g., off-policy\nevaluation) with long-running, slow experiments to perform sequential, Bayesian\noptimization over large action spaces in a short amount of time.", "published": "2025-06-23 15:18:54", "link": "http://arxiv.org/abs/2506.18744v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Group Fairness with Multiple Sensitive Attributes in Federated Foundation Models", "abstract": "The deep integration of foundation models (FM) with federated learning (FL)\nenhances personalization and scalability for diverse downstream tasks, making\nit crucial in sensitive domains like healthcare. Achieving group fairness has\nbecome an increasingly prominent issue in the era of federated foundation\nmodels (FFMs), since biases in sensitive attributes might lead to inequitable\ntreatment for under-represented demographic groups. Existing studies mostly\nfocus on achieving fairness with respect to a single sensitive attribute. This\nrenders them unable to provide clear interpretability of dependencies among\nmultiple sensitive attributes which is required to achieve group fairness. Our\npaper takes the first attempt towards a causal analysis of the relationship\nbetween group fairness across various sensitive attributes in the FFM. We\nextend the FFM structure to trade off multiple sensitive attributes\nsimultaneously and quantify the causal effect behind the group fairness through\ncausal discovery and inference. Extensive experiments validate its\neffectiveness, offering insights into interpretability towards building\ntrustworthy and fair FFM systems.", "published": "2025-06-23 15:09:14", "link": "http://arxiv.org/abs/2506.18732v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries", "abstract": "LLM serving systems typically treat user prompts as monolithic inputs,\noptimizing inference through decoding tricks or inter-query batching. However,\nmany real-world prompts contain latent semantic parallelism--decomposable\nstructures where subtasks can be executed independently to reduce latency while\npreserving meaning. We introduce PARALLELPROMPT, the first benchmark for\nmeasuring intra-query parallelism in natural user prompts. Our dataset\ncomprises over 37,000 real-world prompts from public LLM chat logs, each\nannotated with a structured schema capturing task templates, shared context,\nand iteration inputs. These schemas are extracted using LLM-assisted prompting\nwith rule-based multilingual validation. To evaluate the benefits of\ndecomposition, we provide an execution suite that benchmarks serial vs.\nparallel strategies, measuring latency, structural adherence, and semantic\nfidelity. Our results show that intra-query parallelism can be successfully\nparsed in over 75% of curated datasets, unlocking up to 5x speedups on tasks\nlike translation, comprehension, and comparative analysis, with minimal quality\ndegradation. By releasing this benchmark, curation pipeline, and evaluation\nsuite, we provide the first standardized testbed for studying structure-aware\nexecution in LLM serving pipelines.", "published": "2025-06-23 15:05:54", "link": "http://arxiv.org/abs/2506.18728v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SaGIF: Improving Individual Fairness in Graph Neural Networks via Similarity Encoding", "abstract": "Individual fairness (IF) in graph neural networks (GNNs), which emphasizes\nthe need for similar individuals should receive similar outcomes from GNNs, has\nbeen a critical issue. Despite its importance, research in this area has been\nlargely unexplored in terms of (1) a clear understanding of what induces\nindividual unfairness in GNNs and (2) a comprehensive consideration of\nidentifying similar individuals. To bridge these gaps, we conduct a preliminary\nanalysis to explore the underlying reason for individual unfairness and observe\ncorrelations between IF and similarity consistency, a concept introduced to\nevaluate the discrepancy in identifying similar individuals based on graph\nstructure versus node features. Inspired by our observations, we introduce two\nmetrics to assess individual similarity from two distinct perspectives:\ntopology fusion and feature fusion. Building upon these metrics, we propose\nSimilarity-aware GNNs for Individual Fairness, named SaGIF. The key insight\nbehind SaGIF is the integration of individual similarities by independently\nlearning similarity representations, leading to an improvement of IF in GNNs.\nOur experiments on several real-world datasets validate the effectiveness of\nour proposed metrics and SaGIF. Specifically, SaGIF consistently outperforms\nstate-of-the-art IF methods while maintaining utility performance. Code is\navailable at: https://github.com/ZzoomD/SaGIF.", "published": "2025-06-23 14:34:26", "link": "http://arxiv.org/abs/2506.18696v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Random Matrix Analysis of In-context Memorization for Nonlinear Attention", "abstract": "Attention mechanisms have revolutionized machine learning (ML) by enabling\nefficient modeling of global dependencies across inputs. Their inherently\nparallelizable structures allow for efficient scaling with the exponentially\nincreasing size of both pretrained data and model parameters. Yet, despite\ntheir central role as the computational backbone of modern large language\nmodels (LLMs), the theoretical understanding of Attentions, especially in the\nnonlinear setting, remains limited.\n  In this paper, we provide a precise characterization of the \\emph{in-context\nmemorization error} of \\emph{nonlinear Attention}, in the high-dimensional\nproportional regime where the number of input tokens $n$ and their embedding\ndimension $p$ are both large and comparable. Leveraging recent advances in the\ntheory of large kernel random matrices, we show that nonlinear Attention\ntypically incurs higher memorization error than linear ridge regression on\nrandom inputs. However, this gap vanishes, and can even be reversed, when the\ninput exhibits statistical structure, particularly when the Attention weights\nalign with the input signal direction. Our results reveal how nonlinearity and\ninput structure interact with each other to govern the memorization performance\nof nonlinear Attention. The theoretical insights are supported by numerical\nexperiments.", "published": "2025-06-23 13:56:43", "link": "http://arxiv.org/abs/2506.18656v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Tight Generalization Error Bounds for Stochastic Gradient Descent in Non-convex Learning", "abstract": "Stochastic Gradient Descent (SGD) is fundamental for training deep neural\nnetworks, especially in non-convex settings. Understanding SGD's generalization\nproperties is crucial for ensuring robust model performance on unseen data. In\nthis paper, we analyze the generalization error bounds of SGD for non-convex\nlearning by introducing the Type II perturbed SGD (T2pm-SGD), which\naccommodates both sub-Gaussian and bounded loss functions. The generalization\nerror bound is decomposed into two components: the trajectory term and the\nflatness term. Our analysis improves the trajectory term to $O(n^{-1})$,\nsignificantly enhancing the previous $O((nb)^{-1/2})$ bound for bounded losses,\nwhere n is the number of training samples and b is the batch size. By selecting\nan optimal variance for the perturbation noise, the overall bound is further\nrefined to $O(n^{-2/3})$. For sub-Gaussian loss functions, a tighter trajectory\nterm is also achieved. In both cases, the flatness term remains stable across\niterations and is smaller than those reported in previous literature, which\nincrease with iterations. This stability, ensured by T2pm-SGD, leads to tighter\ngeneralization error bounds for both loss function types. Our theoretical\nresults are validated through extensive experiments on benchmark datasets,\nincluding MNIST and CIFAR-10, demonstrating the effectiveness of T2pm-SGD in\nestablishing tighter generalization bounds.", "published": "2025-06-23 13:47:25", "link": "http://arxiv.org/abs/2506.18645v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "On Union-Closedness of Language Generation", "abstract": "We investigate language generation in the limit - a model by Kleinberg and\nMullainathan [NeurIPS 2024] and extended by Li, Raman, and Tewari [COLT 2025].\nWhile Kleinberg and Mullainathan proved generation is possible for all\ncountable collections, Li et al. defined a hierarchy of generation notions\n(uniform, non-uniform, and generatable) and explored their feasibility for\nuncountable collections.\n  Our first set of results resolve two open questions of Li et al. by proving\nfinite unions of generatable or non-uniformly generatable classes need not be\ngeneratable. These follow from a stronger result: there is a non-uniformly\ngeneratable class and a uniformly generatable class whose union is\nnon-generatable. This adds to the aspects along which language generation in\nthe limit is different from traditional tasks in statistical learning theory\nlike classification, which are closed under finite unions. In particular, it\nimplies that given two generators for different collections, one cannot combine\nthem to obtain a single \"more powerful\" generator, prohibiting this notion of\nboosting.\n  Our construction also addresses a third open question of Li et al. on whether\nthere are uncountable classes that are non-uniformly generatable and do not\nsatisfy the eventually unbounded closure (EUC) condition introduced by Li,\nRaman, and Tewari. Our approach utilizes carefully constructed classes along\nwith a novel diagonalization argument that could be of independent interest in\nthe growing area of language generation.", "published": "2025-06-23 13:42:25", "link": "http://arxiv.org/abs/2506.18642v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Trustworthy Prediction with Gaussian Process Knowledge Scores", "abstract": "Probabilistic models are often used to make predictions in regions of the\ndata space where no observations are available, but it is not always clear\nwhether such predictions are well-informed by previously seen data. In this\npaper, we propose a knowledge score for predictions from Gaussian process\nregression (GPR) models that quantifies the extent to which observing data have\nreduced our uncertainty about a prediction. The knowledge score is\ninterpretable and naturally bounded between 0 and 1. We demonstrate in several\nexperiments that the knowledge score can anticipate when predictions from a GPR\nmodel are accurate, and that this anticipation improves performance in tasks\nsuch as anomaly detection, extrapolation, and missing data imputation. Source\ncode for this project is available online at\nhttps://github.com/KurtButler/GP-knowledge.", "published": "2025-06-23 13:36:06", "link": "http://arxiv.org/abs/2506.18630v1", "categories": ["stat.ML", "cs.LG", "eess.SP", "68T37"], "primary_category": "stat.ML"}
{"title": "On Equivariant Model Selection through the Lens of Uncertainty", "abstract": "Equivariant models leverage prior knowledge on symmetries to improve\npredictive performance, but misspecified architectural constraints can harm it\ninstead. While work has explored learning or relaxing constraints, selecting\namong pretrained models with varying symmetry biases remains challenging. We\nexamine this model selection task from an uncertainty-aware perspective,\ncomparing frequentist (via Conformal Prediction), Bayesian (via the marginal\nlikelihood), and calibration-based measures to naive error-based evaluation. We\nfind that uncertainty metrics generally align with predictive performance, but\nBayesian model evidence does so inconsistently. We attribute this to a mismatch\nin Bayesian and geometric notions of model complexity, and discuss possible\nremedies. Our findings point towards the potential of uncertainty in guiding\nsymmetry-aware model selection.", "published": "2025-06-23 13:35:06", "link": "http://arxiv.org/abs/2506.18629v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Pr{\u00e9}diction optimale pour un mod{\u00e8}le ordinal {\u00e0} covariables fonctionnelles", "abstract": "We present a prediction framework for ordinal models: we introduce optimal\npredictions using loss functions and give the explicit form of the\nLeast-Absolute-Deviation prediction for these models. Then, we reformulate an\nordinal model with functional covariates to a classic ordinal model with\nmultiple scalar covariates. We illustrate all the proposed methods and try to\napply these to a dataset collected by EssilorLuxottica for the development of a\ncontrol algorithm for the shade of connected glasses.", "published": "2025-06-23 13:20:33", "link": "http://arxiv.org/abs/2506.18615v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Policy gradient methods for ordinal policies", "abstract": "In reinforcement learning, the softmax parametrization is the standard\napproach for policies over discrete action spaces. However, it fails to capture\nthe order relationship between actions. Motivated by a real-world industrial\nproblem, we propose a novel policy parametrization based on ordinal regression\nmodels adapted to the reinforcement learning setting. Our approach addresses\npractical challenges, and numerical experiments demonstrate its effectiveness\nin real applications and in continuous action tasks, where discretizing the\naction space and applying the ordinal policy yields competitive performance.", "published": "2025-06-23 13:19:36", "link": "http://arxiv.org/abs/2506.18614v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Transformer World Model for Sample Efficient Multi-Agent Reinforcement Learning", "abstract": "We present the Multi-Agent Transformer World Model (MATWM), a novel\ntransformer-based world model designed for multi-agent reinforcement learning\nin both vector- and image-based environments. MATWM combines a decentralized\nimagination framework with a semi-centralized critic and a teammate prediction\nmodule, enabling agents to model and anticipate the behavior of others under\npartial observability. To address non-stationarity, we incorporate a\nprioritized replay mechanism that trains the world model on recent experiences,\nallowing it to adapt to agents' evolving policies. We evaluated MATWM on a\nbroad suite of benchmarks, including the StarCraft Multi-Agent Challenge,\nPettingZoo, and MeltingPot. MATWM achieves state-of-the-art performance,\noutperforming both model-free and prior world model approaches, while\ndemonstrating strong sample efficiency, achieving near-optimal performance in\nas few as 50K environment interactions. Ablation studies confirm the impact of\neach component, with substantial gains in coordination-heavy tasks.", "published": "2025-06-23 11:47:17", "link": "http://arxiv.org/abs/2506.18537v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Federated Learning from Molecules to Processes: A Perspective", "abstract": "We present a perspective on federated learning in chemical engineering that\nenvisions collaborative efforts in machine learning (ML) developments within\nthe chemical industry. Large amounts of chemical and process data are\nproprietary to chemical companies and are therefore locked in data silos,\nhindering the training of ML models on large data sets in chemical engineering.\nRecently, the concept of federated learning has gained increasing attention in\nML research, enabling organizations to jointly train machine learning models\nwithout disclosure of their individual data. We discuss potential applications\nof federated learning in several fields of chemical engineering, from the\nmolecular to the process scale. In addition, we apply federated learning in two\nexemplary case studies that simulate practical scenarios of multiple chemical\ncompanies holding proprietary data sets: (i) prediction of binary mixture\nactivity coefficients with graph neural networks and (ii) system identification\nof a distillation column with autoencoders. Our results indicate that ML models\njointly trained with federated learning yield significantly higher accuracy\nthan models trained by each chemical company individually and can perform\nsimilarly to models trained on combined datasets from all companies. Federated\nlearning has therefore great potential to advance ML models in chemical\nengineering while respecting corporate data privacy, making it promising for\nfuture industrial applications.", "published": "2025-06-23 11:27:34", "link": "http://arxiv.org/abs/2506.18525v1", "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "cs.LG"}
{"title": "DDOT: A Derivative-directed Dual-decoder Ordinary Differential Equation Transformer for Dynamic System Modeling", "abstract": "Uncovering the underlying ordinary differential equations (ODEs) that govern\ndynamic systems is crucial for advancing our understanding of complex\nphenomena. Traditional symbolic regression methods often struggle to capture\nthe temporal dynamics and intervariable correlations inherent in ODEs.\nODEFormer, a state-of-the-art method for inferring multidimensional ODEs from\nsingle trajectories, has made notable progress. However, its focus on\nsingle-trajectory evaluation is highly sensitive to initial starting points,\nwhich may not fully reflect true performance. To address this, we propose the\ndivergence difference metric (DIV-diff), which evaluates divergence over a grid\nof points within the target region, offering a comprehensive and stable\nanalysis of the variable space. Alongside, we introduce DDOT\n(Derivative-Directed Dual-Decoder Ordinary Differential Equation Transformer),\na transformer-based model designed to reconstruct multidimensional ODEs in\nsymbolic form. By incorporating an auxiliary task predicting the ODE's\nderivative, DDOT effectively captures both structure and dynamic behavior.\nExperiments on ODEBench show DDOT outperforms existing symbolic regression\nmethods, achieving an absolute improvement of 4.58% and 1.62% in $P(R^2 > 0.9)$\nfor reconstruction and generalization tasks, respectively, and an absolute\nreduction of 3.55% in DIV-diff. Furthermore, DDOT demonstrates real-world\napplicability on an anesthesia dataset, highlighting its practical impact.", "published": "2025-06-23 11:24:52", "link": "http://arxiv.org/abs/2506.18522v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Theoretical guarantees for neural estimators in parametric statistics", "abstract": "Neural estimators are simulation-based estimators for the parameters of a\nfamily of statistical models, which build a direct mapping from the sample to\nthe parameter vector. They benefit from the versatility of available network\narchitectures and efficient training methods developed in the field of deep\nlearning. Neural estimators are amortized in the sense that, once trained, they\ncan be applied to any new data set with almost no computational cost. While\nmany papers have shown very good performance of these methods in simulation\nstudies and real-world applications, so far no statistical guarantees are\navailable to support these observations theoretically. In this work, we study\nthe risk of neural estimators by decomposing it into several terms that can be\nanalyzed separately. We formulate easy-to-check assumptions ensuring that each\nterm converges to zero, and we verify them for popular applications of neural\nestimators. Our results provide a general recipe to derive theoretical\nguarantees also for broader classes of architectures and estimation problems.", "published": "2025-06-23 11:02:08", "link": "http://arxiv.org/abs/2506.18508v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Leveraging neural network interatomic potentials for a foundation model of chemistry", "abstract": "Large-scale foundation models, including neural network interatomic\npotentials (NIPs) in computational materials science, have demonstrated\nsignificant potential. However, despite their success in accelerating atomistic\nsimulations, NIPs face challenges in directly predicting electronic properties\nand often require coupling to higher-scale models or extensive simulations for\nmacroscopic properties. Machine learning (ML) offers alternatives for\nstructure-to-property mapping but faces trade-offs: feature-based methods often\nlack generalizability, while deep neural networks require significant data and\ncomputational power. To address these trade-offs, we introduce HackNIP, a\ntwo-stage pipeline that leverages pretrained NIPs. This method first extracts\nfixed-length feature vectors (embeddings) from NIP foundation models and then\nuses these embeddings to train shallow ML models for downstream\nstructure-to-property predictions. This study investigates whether such a\nhybridization approach, by ``hacking\" the NIP, can outperform end-to-end deep\nneural networks, determines the dataset size at which this transfer learning\napproach surpasses direct fine-tuning of the NIP, and identifies which NIP\nembedding depths yield the most informative features. HackNIP is benchmarked on\nMatbench, evaluated for data efficiency, and tested on diverse tasks including\n\\textit{ab initio}, experimental, and molecular properties. We also analyze how\nembedding depth impacts performance. This work demonstrates a hybridization\nstrategy to overcome ML trade-offs in materials science, aiming to democratize\nhigh-performance predictive modeling.", "published": "2025-06-23 10:49:19", "link": "http://arxiv.org/abs/2506.18497v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "AnalogNAS-Bench: A NAS Benchmark for Analog In-Memory Computing", "abstract": "Analog In-memory Computing (AIMC) has emerged as a highly efficient paradigm\nfor accelerating Deep Neural Networks (DNNs), offering significant energy and\nlatency benefits over conventional digital hardware. However, state-of-the-art\nneural networks are not inherently designed for AIMC, as they fail to account\nfor its unique non-idealities. Neural Architecture Search (NAS) is thus needed\nto systematically discover neural architectures optimized explicitly for AIMC\nconstraints. However, comparing NAS methodologies and extracting insights about\nrobust architectures for AIMC requires a dedicated NAS benchmark that\nexplicitly accounts for AIMC-specific hardware non-idealities. To address this,\nwe introduce AnalogNAS-Bench, the first NAS benchmark tailored specifically for\nAIMC. Our study reveals three key insights: (1) standard quantization\ntechniques fail to capture AIMC-specific noises, (2) robust architectures tend\nto feature wider and branched blocks, (3) skip connections improve resilience\nto temporal drift noise. These insights highlight the limitations of current\nNAS benchmarks for AIMC and pave the way for future analog-aware NAS. All the\nimplementations used in this paper can be found at\nhttps://github.com/IBM/analog-nas/tree/main/analognasbench.", "published": "2025-06-23 10:44:32", "link": "http://arxiv.org/abs/2506.18495v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Reliability-Adjusted Prioritized Experience Replay", "abstract": "Experience replay enables data-efficient learning from past experiences in\nonline reinforcement learning agents. Traditionally, experiences were sampled\nuniformly from a replay buffer, regardless of differences in\nexperience-specific learning potential. In an effort to sample more\nefficiently, researchers introduced Prioritized Experience Replay (PER). In\nthis paper, we propose an extension to PER by introducing a novel measure of\ntemporal difference error reliability. We theoretically show that the resulting\ntransition selection algorithm, Reliability-adjusted Prioritized Experience\nReplay (ReaPER), enables more efficient learning than PER. We further present\nempirical results showing that ReaPER outperforms PER across various\nenvironment types, including the Atari-5 benchmark.", "published": "2025-06-23 10:35:36", "link": "http://arxiv.org/abs/2506.18482v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FREQuency ATTribution: Benchmarking Frequency-based Occlusion for Time Series Data", "abstract": "Deep neural networks are among the most successful algorithms in terms of\nperformance and scalability in different domains. However, since these networks\nare black boxes, their usability is severely restricted due to the lack of\ninterpretability. Existing interpretability methods do not address the analysis\nof time-series-based networks specifically enough. This paper shows that an\nanalysis in the frequency domain can not only highlight relevant areas in the\ninput signal better than existing methods, but is also more robust to\nfluctuations in the signal. In this paper, FreqATT is presented, a framework\nthat enables post-hoc networks to interpret time series analysis. To achieve\nthis, the relevant different frequencies are evaluated and the signal is either\nfiltered or the relevant input data is marked.", "published": "2025-06-23 10:34:44", "link": "http://arxiv.org/abs/2506.18481v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Motivational Architecture for Open-Ended Learning Challenges in Robots", "abstract": "Developing agents capable of autonomously interacting with complex and\ndynamic environments, where task structures may change over time and prior\nknowledge cannot be relied upon, is a key prerequisite for deploying artificial\nsystems in real-world settings. The open-ended learning framework identifies\nthe core challenges for creating such agents, including the ability to\nautonomously generate new goals, acquire the necessary skills (or curricula of\nskills) to achieve them, and adapt to non-stationary environments. While many\nexisting works tackles various aspects of these challenges in isolation, few\npropose integrated solutions that address them simultaneously. In this paper,\nwe introduce H-GRAIL, a hierarchical architecture that, through the use of\ndifferent typologies of intrinsic motivations and interconnected learning\nmechanisms, autonomously discovers new goals, learns the required skills for\ntheir achievement, generates skill sequences for tackling interdependent tasks,\nand adapts to non-stationary environments. We tested H-GRAIL in a real robotic\nscenario, demonstrating how the proposed solutions effectively address the\nvarious challenges of open-ended learning.", "published": "2025-06-23 09:46:05", "link": "http://arxiv.org/abs/2506.18454v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "New Hardness Results for Low-Rank Matrix Completion", "abstract": "The low-rank matrix completion problem asks whether a given real matrix with\nmissing values can be completed so that the resulting matrix has low rank or is\nclose to a low-rank matrix. The completed matrix is often required to satisfy\nadditional structural constraints, such as positive semi-definiteness or a\nbounded infinity norm. The problem arises in various research fields, including\nmachine learning, statistics, and theoretical computer science, and has broad\nreal-world applications.\n  This paper presents new $\\mathsf{NP} $-hardness results for low-rank matrix\ncompletion problems. We show that for every sufficiently large integer $d$ and\nany real number $\\varepsilon \\in [ 2^{-O(d)},\\frac{1}{7}]$, given a partial\nmatrix $A$ with exposed values of magnitude at most $1$ that admits a positive\nsemi-definite completion of rank $d$, it is $\\mathsf{NP}$-hard to find a\npositive semi-definite matrix that agrees with each given value of $A$ up to an\nadditive error of at most $\\varepsilon$, even when the rank is allowed to\nexceed $d$ by a multiplicative factor of $O (\\frac{1}{\\varepsilon ^2 \\cdot\n\\log(1/\\varepsilon)} )$. This strengthens a result of Hardt, Meka, Raghavendra,\nand Weitz (COLT, 2014), which applies to multiplicative factors smaller than\n$2$ and to $\\varepsilon $ that decays polynomially in $d$. We establish similar\n$\\mathsf{NP}$-hardness results for the case where the completed matrix is\nconstrained to have a bounded infinity norm (rather than be positive\nsemi-definite), for which all previous hardness results rely on complexity\nassumptions related to the Unique Games Conjecture. Our proofs involve a novel\nnotion of nearly orthonormal representations of graphs, the concept of line\ndigraphs, and bounds on the rank of perturbed identity matrices.", "published": "2025-06-23 09:22:28", "link": "http://arxiv.org/abs/2506.18440v1", "categories": ["cs.CC", "cs.LG"], "primary_category": "cs.CC"}
{"title": "Dynamic Hybrid Modeling: Incremental Identification and Model Predictive Control", "abstract": "Mathematical models are crucial for optimizing and controlling chemical\nprocesses, yet they often face significant limitations in terms of\ncomputational time, algorithm complexity, and development costs. Hybrid models,\nwhich combine mechanistic models with data-driven models (i.e. models derived\nvia the application of machine learning to experimental data), have emerged as\na promising solution to these challenges. However, the identification of\ndynamic hybrid models remains difficult due to the need to integrate\ndata-driven models within mechanistic model structures. We present an\nincremental identification approach for dynamic hybrid models that decouples\nthe mechanistic and data-driven components to overcome computational and\nconceptual difficulties. Our methodology comprises four key steps: (1)\nregularized dynamic parameter estimation to determine optimal time profiles for\nflux variables, (2) correlation analysis to evaluate relationships between\nvariables, (3) data-driven model identification using advanced machine learning\ntechniques, and (4) hybrid model integration to combine the mechanistic and\ndata-driven components. This approach facilitates early evaluation of model\nstructure suitability, accelerates the development of hybrid models, and allows\nfor independent identification of data-driven components. Three case studies\nare presented to illustrate the robustness, reliability, and efficiency of our\nincremental approach in handling complex systems and scenarios with limited\ndata.", "published": "2025-06-23 06:55:32", "link": "http://arxiv.org/abs/2506.18344v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC", "93A30, 37N35, 68T05", "I.2.6; I.2.8; I.6.3; I.6.5; G.1.6; J.2"], "primary_category": "eess.SY"}
{"title": "BrainSymphony: A Transformer-Driven Fusion of fMRI Time Series and Structural Connectivity", "abstract": "Existing foundation models for neuroimaging are often prohibitively large and\ndata-intensive. We introduce BrainSymphony, a lightweight, parameter-efficient\nfoundation model that achieves state-of-the-art performance while being\npre-trained on significantly smaller public datasets. BrainSymphony's strong\nmultimodal architecture processes functional MRI data through parallel spatial\nand temporal transformer streams, which are then efficiently distilled into a\nunified representation by a Perceiver module. Concurrently, it models\nstructural connectivity from diffusion MRI using a novel signed graph\ntransformer to encode the brain's anatomical structure. These powerful,\nmodality-specific representations are then integrated via an adaptive fusion\ngate. Despite its compact design, our model consistently outperforms larger\nmodels on a diverse range of downstream benchmarks, including classification,\nprediction, and unsupervised network identification tasks. Furthermore, our\nmodel revealed novel insights into brain dynamics using attention maps on a\nunique external psilocybin neuroimaging dataset (pre- and post-administration).\nBrainSymphony establishes that architecturally-aware, multimodal models can\nsurpass their larger counterparts, paving the way for more accessible and\npowerful research in computational neuroscience.", "published": "2025-06-23 06:00:21", "link": "http://arxiv.org/abs/2506.18314v1", "categories": ["q-bio.QM", "cs.LG", "q-bio.NC"], "primary_category": "q-bio.QM"}
{"title": "Instability in Diffusion ODEs: An Explanation for Inaccurate Image Reconstruction", "abstract": "Diffusion reconstruction plays a critical role in various applications such\nas image editing, restoration, and style transfer. In theory, the\nreconstruction should be simple - it just inverts and regenerates images by\nnumerically solving the Probability Flow-Ordinary Differential Equation\n(PF-ODE). Yet in practice, noticeable reconstruction errors have been observed,\nwhich cannot be well explained by numerical errors. In this work, we identify a\ndeeper intrinsic property in the PF-ODE generation process, the instability,\nthat can further amplify the reconstruction errors. The root of this\ninstability lies in the sparsity inherent in the generation distribution, which\nmeans that the probability is concentrated on scattered and small regions while\nthe vast majority remains almost empty. To demonstrate the existence of\ninstability and its amplification on reconstruction error, we conduct\nexperiments on both toy numerical examples and popular open-sourced diffusion\nmodels. Furthermore, based on the characteristics of image data, we\ntheoretically prove that the instability's probability converges to one as the\ndata dimensionality increases. Our findings highlight the inherent challenges\nin diffusion-based reconstruction and can offer insights for future\nimprovements.", "published": "2025-06-23 04:59:49", "link": "http://arxiv.org/abs/2506.18290v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning High-Quality Latent Representations for Anomaly Detection and Signal Integrity Enhancement in High-Speed Signals", "abstract": "This paper addresses the dual challenge of improving anomaly detection and\nsignal integrity in high-speed dynamic random access memory signals. To achieve\nthis, we propose a joint training framework that integrates an autoencoder with\na classifier to learn more distinctive latent representations by focusing on\nvalid data features. Our approach is evaluated across three anomaly detection\nalgorithms and consistently outperforms two baseline methods. Detailed ablation\nstudies further support these findings. Furthermore, we introduce a signal\nintegrity enhancement algorithm that improves signal integrity by an average of\n11.3%. The source code and data used in this study are available at\nhttps://github.com/Usama1002/learning-latent-representations.", "published": "2025-06-23 04:48:22", "link": "http://arxiv.org/abs/2506.18288v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantifying Uncertainty in the Presence of Distribution Shifts", "abstract": "Neural networks make accurate predictions but often fail to provide reliable\nuncertainty estimates, especially under covariate distribution shifts between\ntraining and testing. To address this problem, we propose a Bayesian framework\nfor uncertainty estimation that explicitly accounts for covariate shifts. While\nconventional approaches rely on fixed priors, the key idea of our method is an\nadaptive prior, conditioned on both training and new covariates. This prior\nnaturally increases uncertainty for inputs that lie far from the training\ndistribution in regions where predictive performance is likely to degrade. To\nefficiently approximate the resulting posterior predictive distribution, we\nemploy amortized variational inference. Finally, we construct synthetic\nenvironments by drawing small bootstrap samples from the training data,\nsimulating a range of plausible covariate shift using only the original\ndataset. We evaluate our method on both synthetic and real-world data. It\nyields substantially improved uncertainty estimates under distribution shifts.", "published": "2025-06-23 04:30:36", "link": "http://arxiv.org/abs/2506.18283v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Leveraging Large Language Models for Information Verification -- an Engineering Approach", "abstract": "For the ACMMM25 challenge, we present a practical engineering approach to\nmultimedia news source verification, utilizing Large Language Models (LLMs)\nlike GPT-4o as the backbone of our pipeline. Our method processes images and\nvideos through a streamlined sequence of steps: First, we generate metadata\nusing general-purpose queries via Google tools, capturing relevant content and\nlinks. Multimedia data is then segmented, cleaned, and converted into frames,\nfrom which we select the top-K most informative frames. These frames are\ncross-referenced with metadata to identify consensus or discrepancies.\nAdditionally, audio transcripts are extracted for further verification.\nNoticeably, the entire pipeline is automated using GPT-4o through prompt\nengineering, with human intervention limited to final validation.", "published": "2025-06-23 04:08:38", "link": "http://arxiv.org/abs/2506.18274v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Memory-Augmented Architecture for Long-Term Context Handling in Large Language Models", "abstract": "Large Language Models face significant challenges in maintaining coherent\ninteractions over extended dialogues due to their limited contextual memory.\nThis limitation often leads to fragmented exchanges and reduced relevance in\nresponses, diminishing user experience. To address these issues, we propose a\nmemory-augmented architecture that dynamically retrieves, updates, and prunes\nrelevant information from past interactions, ensuring effective long-term\ncontext handling. Experimental results demonstrate that our solution\nsignificantly improves contextual coherence, reduces memory overhead, and\nenhances response quality, showcasing its potential for real-time applications\nin interactive systems.", "published": "2025-06-23 03:57:25", "link": "http://arxiv.org/abs/2506.18271v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ground tracking for improved landmine detection in a GPR system", "abstract": "Ground penetrating radar (GPR) provides a promising technology for accurate\nsubsurface object detection. In particular, it has shown promise for detecting\nlandmines with low metal content. However, the ground bounce (GB) that is\npresent in GPR data, which is caused by the dielectric discontinuity between\nsoil and air, is a major source of interference and degrades landmine detection\nperformance. To mitigate this interference, GB tracking algorithms formulated\nusing both a Kalman filter (KF) and a particle filter (PF) framework are\nproposed. In particular, the location of the GB in the radar signal is modeled\nas the hidden state in a stochastic system for the PF approach. The\nobservations are the 2D radar images, which arrive scan by scan along the\ndown-track direction. An initial training stage sets parameters automatically\nto accommodate different ground and weather conditions. The features associated\nwith the GB description are updated adaptively with the arrival of new data.\nThe prior distribution for a given location is predicted by propagating\ninformation from two adjacent channels/scans, which ensures that the overall GB\nsurface remains smooth. The proposed algorithms are verified in experiments\nutilizing real data, and their performances are compared with other GB tracking\napproaches. We demonstrate that improved GB tracking contributes to improved\nperformance for the landmine detection problem.", "published": "2025-06-23 03:06:55", "link": "http://arxiv.org/abs/2506.18258v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures", "abstract": "Quantifying and propagating modeling uncertainties is crucial for reliability\nanalysis, robust optimization, and other model-based algorithmic processes in\nengineering design and control. Now, physics-informed machine learning (PIML)\nmethods have emerged in recent years as a new alternative to traditional\ncomputational modeling and surrogate modeling methods, offering a balance\nbetween computing efficiency, modeling accuracy, and interpretability. However,\ntheir ability to predict and propagate modeling uncertainties remains mostly\nunexplored. In this paper, a promising class of auto-differentiable hybrid PIML\narchitectures that combine partial physics and neural networks or ANNs (for\ninput transformation or adaptive parameter estimation) is integrated with\nBayesian Neural networks (replacing the ANNs); this is done with the goal to\nexplore whether BNNs can successfully provision uncertainty propagation\ncapabilities in the PIML architectures as well, further supported by the\nauto-differentiability of these architectures. A two-stage training process is\nused to alleviate the challenges traditionally encountered in training\nprobabilistic ML models. The resulting BNN-integrated PIML architecture is\nevaluated on an analytical benchmark problem and flight experiments data for a\nfixed-wing RC aircraft, with prediction performance observed to be slightly\nworse or at par with purely data-driven ML and original PIML models. Moreover,\nMonte Carlo sampling of probabilistic BNN weights was found to be most\neffective in propagating uncertainty in the BNN-integrated PIML architectures.", "published": "2025-06-23 02:32:20", "link": "http://arxiv.org/abs/2506.18247v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dual-Forward Path Teacher Knowledge Distillation: Bridging the Capacity Gap Between Teacher and Student", "abstract": "Knowledge distillation (KD) provides an effective way to improve the\nperformance of a student network under the guidance of pre-trained teachers.\nHowever, this approach usually brings in a large capacity gap between teacher\nand student networks, limiting the distillation gains. Previous methods\naddressing this problem either discard accurate knowledge representation or\nfail to dynamically adjust the transferred knowledge, which is less effective\nin addressing the capacity gap problem and hinders students from achieving\ncomparable performance with the pre-trained teacher. In this work, we extend\nthe ideology of prompt-based learning to address the capacity gap problem, and\npropose Dual-Forward Path Teacher Knowledge Distillation (DFPT-KD), which\nreplaces the pre-trained teacher with a novel dual-forward path teacher to\nsupervise the learning of student. The key to DFPT-KD is prompt-based tuning,\ni.e., establishing an additional prompt-based forward path within the\npre-trained teacher and optimizing it with the pre-trained teacher frozen to\nmake the transferred knowledge compatible with the representation ability of\nthe student. Extensive experiments demonstrate that DFPT-KD leads to trained\nstudents performing better than the vanilla KD. To make the transferred\nknowledge better compatible with the representation abilities of the student,\nwe further fine-tune the whole prompt-based forward path, yielding a novel\ndistillation approach dubbed DFPT-KD+. By extensive experiments, it is shown\nthat DFPT-KD+ improves upon DFPT-KD and achieves state-of-the-art accuracy\nperformance.", "published": "2025-06-23 02:22:53", "link": "http://arxiv.org/abs/2506.18244v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Convex-concave splitting for the Allen-Cahn equation leads to $\\varepsilon^2$-slow movement of interfaces", "abstract": "The convex-concave splitting discretization of the Allen-Cahn is easy to\nimplement and guaranteed to be energy decreasing even for large time-steps. We\nanalyze the time-stepping scheme for a large class of potentials which includes\nthe standard potential as well as two extreme settings: Potentials with\nquadratic convex part (uniform positive curvature), and potentials which are\nconcave between the potential wells and either linear or infinite outside\n(highly concentrated curvature). In all three scenarios, the 'effective time\nstep size' of the scheme scales with the square of the small parameter\n$\\varepsilon$ governing the width of transition layers. A weaker 'slow motion'\nresult is proved under much more general assumptions. Thus, stability is\nachieved by effectively 'freezing' the interfaces in place. The time step\nlimitation is not geometric in origin, but depends on the phase-field parameter\n$\\varepsilon$. Along the way, we establish a new link between an Allen-Cahn\ntype equation and a thresholding approximation of mean curvature flow.", "published": "2025-06-23 17:38:33", "link": "http://arxiv.org/abs/2506.18869v1", "categories": ["math.NA", "cs.NA", "math.AP", "65M12, 35A35, 49Q05"], "primary_category": "math.NA"}
{"title": "Unconditionally stable space-time isogeometric method for the linear Schr\u00f6dinger equation", "abstract": "We propose and analyze a space-time isogeometric finite element method based\non splines with maximal regularity in time for the linear time-dependent\nSchr\\\"odinger equation with a spatially varying potential. We investigate the\nstability and conservation properties of the method, demonstrating that it\npreserves both mass and energy at the final time, and it is unconditionally\nstable. Numerical experiments confirm our theoretical findings and illustrate\nthe convergence behavior of the scheme. Incidentally, our analysis also\nprovides an alternative proof of unconditional stability of the\nfirst-order-in-time isogeometric method for the wave equation proposed in (M.\nFerrari, S. Fraschini, G. Loli and I. Perugia (2025)), eliminating the need for\nthe numerical verifications required in the previous analysis.", "published": "2025-06-23 17:22:10", "link": "http://arxiv.org/abs/2506.18859v1", "categories": ["math.NA", "cs.NA", "35Q41, 65M60, 15A12, 78M10, 15B05"], "primary_category": "math.NA"}
{"title": "Bayesian decomposition using Besov priors", "abstract": "In many inverse problems, the unknown is composed of multiple components with\ndifferent regularities, for example, in imaging problems, where the unknown can\nhave both rough and smooth features. We investigate linear Bayesian inverse\nproblems, where the unknown consists of two components: one smooth and one\npiecewise constant. We model the unknown as a sum of two components and assign\nindividual priors on each component to impose the assumed behavior. We propose\nand compare two prior models: (i) a combination of a Haar wavelet-based Besov\nprior and a smoothing Besov prior, and (ii) a hierarchical Gaussian prior on\nthe gradient coupled with a smoothing Besov prior. To achieve a balanced\nreconstruction, we place hyperpriors on the prior parameters and jointly infer\nboth the components and the hyperparameters. We propose Gibbs sampling schemes\nfor posterior inference in both prior models. We demonstrate the capabilities\nof our approach on 1D and 2D deconvolution problems, where the unknown consists\nof smooth parts with jumps. The numerical results indicate that our methods\nimprove the reconstruction quality compared to single-prior approaches and that\nthe prior parameters can be successfully estimated to yield a balanced\ndecomposition.", "published": "2025-06-23 17:07:04", "link": "http://arxiv.org/abs/2506.18846v1", "categories": ["stat.CO", "cs.NA", "math.NA", "G.3; G.4"], "primary_category": "stat.CO"}
{"title": "Optimal adaptive implicit time stepping", "abstract": "We revisit adaptive time stepping, one of the classical topics of numerical\nanalysis and computational engineering. While widely used in application and\nsubject of many theoretical works, a complete understanding is still missing.\nApart from special cases, there does not exist a complete theory that shows how\nto choose the time steps such that convergence towards the exact solution is\nguaranteed with the optimal convergence rate. In this work, we use recent\nadvances in adaptive mesh refinement to propose an adaptive time stepping\nalgorithm that is mathematically guaranteed to be optimal in the sense that it\nachieves the best possible convergence of the error with respect to the number\nof time steps, and it can be implemented using a time stepping scheme as a\nblack box.", "published": "2025-06-23 16:19:14", "link": "http://arxiv.org/abs/2506.18809v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the computation of tensor functions under tensor-tensor multiplications with linear maps", "abstract": "In this paper we study the computation of both algebraic and non-algebraic\ntensor functions under the tensor-tensor multiplication with linear maps. In\nthe case of algebraic tensor functions, we prove that the asymptotic exponent\nof both the tensor-tensor multiplication and the tensor polynomial evaluation\nproblem under this multiplication is the same as that of the matrix\nmultiplication, unless the linear map is injective. As for non-algebraic\nfunctions, we define the tensor geometric mean and the tensor Wasserstein mean\nfor pseudo-positive-definite tensors under the tensor-tensor multiplication\nwith invertible linear maps, and we show that the tensor geometric mean can be\ncalculated by solving a specific Riccati tensor equation. Furthermore, we show\nthat the tensor geometric mean does not satisfy the resultantal (determinantal)\nidentity in general, which the matrix geometric mean always satisfies. Then we\ndefine a pseudo-SVD for the injective linear map case and we apply it on image\ndata compression.", "published": "2025-06-23 14:51:35", "link": "http://arxiv.org/abs/2506.18713v1", "categories": ["math.NA", "cs.CC", "cs.NA", "math.AC", "68Q17, 15A69, 14N07, 94A08, 47A64"], "primary_category": "math.NA"}
{"title": "Shifted HSS preconditioners for the indefinite Helmholtz equation", "abstract": "We provide a preconditioning approach for the indefinite Helmholtz equation\ndiscretised using finite elements, based upon a Hermitian Skew-Hermitian\nSplitting (HSS) iteration applied to the shifted operator, and prove that the\npreconditioner is k- and mesh-robust when O(k) HSS iterations are performed.\nThe HSS iterations involve solving a shifted operator that is suitable for\napproximation by multigrid using standard smoothers and transfer operators,\nleading to a fully scalable algorithm. We argue that the algorithm converges in\nO(k) wallclock time when within the range of scalability of the multigrid. We\nprovide numerical results verifying our proofs and demonstrating this claim.\nThis establishes a scalable O(k) method using multigrid with entirely standard\ncomponents.", "published": "2025-06-23 14:33:42", "link": "http://arxiv.org/abs/2506.18694v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Semi-discrete heat equations with variable coefficients and the parametrix method", "abstract": "We develop a parametrix approach for constructing solutions and establishing\ngrid-size independent estimates for semi-discrete heat equations with variable\ncoefficients. While the classical continuous setting benefits from Gaussian\nestimates of the constant coefficient heat kernel, such estimates are not\navailable in the semi-discrete context. To address this complication, we derive\nestimates involving products of heavy-tailed Lorentz (also known as Cauchy)\nprobability densities. These Lorentzian estimates provide a sufficient handle\non certain iterated convolutions involving Bessel functions, enabling us to\nachieve convergence of the parametrix approach.", "published": "2025-06-23 13:53:44", "link": "http://arxiv.org/abs/2506.18649v1", "categories": ["math.NA", "cs.NA", "35K15, 35K08 (Primary) 65M06, 33C10 (Secondary)"], "primary_category": "math.NA"}
{"title": "A Complete-Electrode-Model-Based Forward Approach for Transcranial Temporal Interference Stimulation with Linearization: Numerical Simulation Study", "abstract": "Background and Objective: Transcranial temporal interference stimulation\n(tTIS) is a promising non-invasive brain stimulation technique in which\ninterference between electrical current fields extends the possibilities of\nelectrical brain stimulation. The objective of this study is to develop an\nefficient mathematical tTIS forward modelling scheme that allows for realistic\nand adaptable simulation and can be updated accurately when the stimulation\nfrequency is modified in one or more electrodes. Such a model is vital, for\nexample, in optimization processes that seek the best possible stimulation\ncurrents to exhibit or inhibit a given brain region. This study aims to\nestablish and evaluate the complete electrode model (CEM), i.e., a set of\nboundary conditions incorporating electrode impedance and contact patch, as a\nforward finite-element-method-based simulation technique for tTIS and\ninvestigate linearized CEM as a surrogate.\n  Results: The CEM-based forward simulation successfully reproduced the\nvolumetric stimulating fields induced by tTIS. Sensitivity analysis showed that\nvariations in electrode impedance substantially affect the field distribution,\nespecially in regions where the interfering currents have nearly equal\namplitudes. The linearized CEM model closely matched the full nonlinear model\nwithin a predefined peak signal-to-noise ratio (PSNR) threshold for relative\nerror. Both models exhibited the highest sensitivity near the focal region.", "published": "2025-06-23 09:17:25", "link": "http://arxiv.org/abs/2506.18436v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stabilizing randomized GMRES through flexible GMRES", "abstract": "We explore the use of flexible GMRES as an outer wrapper for sketched GMRES.\nBuilding on a new bound for the residual of FGMRES in terms of the residual of\nthe preconditioner, we derive a practical randomized solver that requires very\nlittle parameter tuning, while still being efficient and robust in the sense of\ngenerating non-increasing residual norms.", "published": "2025-06-23 08:43:47", "link": "http://arxiv.org/abs/2506.18408v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A high-order, conservative and positivity-preserving intersection-based remapping method between meshes with isoparametric curvilinear cells", "abstract": "This paper presents a novel intersection-based remapping method for\nisoparametric curvilinear meshes within the indirect arbitrary\nLagrangian-Eulerian (ALE) framework, addressing the challenges of transferring\nphysical quantities between high-order curved-edge meshes. Our method leverages\nthe Weiler-Atherton clipping algorithm to compute intersections between\ncurved-edge quadrangles, enabling robust handling of arbitrary order\nisoparametric curves. By integrating multi-resolution weighted essentially\nnon-oscillatory (WENO) reconstruction, we achieve high-order accuracy while\nsuppressing numerical oscillations near discontinuities. A\npositivity-preserving limiter is further applied to ensure physical quantities\nsuch as density remain non-negative without compromising conservation or\naccuracy. Notably, the computational cost of handling higher-order curved\nmeshes, such as cubic or even higher-degree parametric curves, does not\nsignificantly increase compared to secondorder curved meshes. This ensures that\nour method remains efficient and scalable, making it applicable to arbitrary\nhigh-order isoparametric curvilinear cells without compromising performance.\nNumerical experiments demonstrate that the proposed method achieves highorder\naccuracy, strict conservation (with errors approaching machine precision),\nessential non-oscillation and positivity-preserving.", "published": "2025-06-23 08:25:53", "link": "http://arxiv.org/abs/2506.18389v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Probabilistic approximation of fully nonlinear second-order PIDEs with convergence rates for the universal robust limit theorem", "abstract": "This paper develops a probabilistic approximation scheme for a class of\nnonstandard, fully nonlinear second-order partial integro-differential\nequations (PIDEs) arising from nonlinear L\\'evy processes under Peng's\nG-expectation framework. The PIDE involves a supremum over a set of\n\\(\\alpha\\)-stable L\\'evy measures, potentially with degenerate diffusion and a\nnon-separable uncertainty set, which renders existing numerical results\ninapplicable. We construct a recursive, piecewise-constant approximation to the\nviscosity solution and derive explicit error bounds. A key application of our\nanalysis is the quantification of convergence rates for the universal robust\nlimit theorem under sublinear expectations, unifying Peng's robust central\nlimit theorem, laws of large numbers, and the \\(\\alpha\\)-stable limit theorem\nof Bayraktar and Munk, with explicit Berry--Esseen-type bounds.", "published": "2025-06-23 08:00:15", "link": "http://arxiv.org/abs/2506.18374v1", "categories": ["math.PR", "cs.NA", "math.NA", "60F05, 65M15, 60H30, 45K05"], "primary_category": "math.PR"}
{"title": "Accuracy and componentwise accuracy in multilinear PageRank", "abstract": "We study the stability with respect to perturbations and the accuracy of\nnumerical algorithms for computing solutions to the multilinear PageRank\nproblem $\\mathbf{x} = (1-\\alpha)\\mathbf{v} + \\alpha \\mathcal{P} \\mathbf{x}^2$.\nOur results reveal that the solution can be more stable with respect to\nperturbations and numerical errors with respect to the classical bounds for\nnonlinear systems of equations (based on the norm of the Jacobian). In detail,\none can obtain bounds for the minimal solution which ignore the singularity of\nthe problem for $\\alpha=1/2$, and one can show that the limiting accuracy of\nthe Newton method depends not on the norm of the Jacobian but on a quantity\nthat can be much smaller thanks to the nonnegativity structure of the equation.\nFor the minimal solution, we also suggest subtraction-free modifications to the\nexisting algorithms to achieve componentwise stability.\n  Some of the theoretical results we obtain are interesting even outside the\nscope of this problem: bounds for more general quadratic vector equations, and\na partial inverse for M-matrices which remains bounded when the matrix to\ninvert approaches singularity.", "published": "2025-06-23 07:31:32", "link": "http://arxiv.org/abs/2506.18356v1", "categories": ["math.NA", "cs.NA", "15A69, 15B51, 65H10"], "primary_category": "math.NA"}
{"title": "AE-PINNs: Attention-enhanced physics-informed neural networks for solving elliptic interface problems", "abstract": "Inspired by the attention mechanism, we develop an attention-enhanced\nphysics-informed neural networks (AE-PINNs) for solving elliptic interface\nequations. In AE-PINNs, we decompose the solution into two complementary\ncomponents: a continuous component and a component with discontinuities across\nthe interface. The continuous component is approximated by a fully connected\nneural network in the whole domain, while the discontinuous component is\napproximated by an interface-attention neural network in each subdomain\nseparated by the interface. The interface-attention neural network adopts a\nnetwork structure similar to the attention mechanism to focus on the interface,\nwith its key extension is to introduce a neural network that transmits\ninterface information. Some numerical experiments have confirmed the\neffectiveness of the AE-PINNs, demonstrating higher accuracy compared with\nPINNs, I-PINNs and M-PINNs.", "published": "2025-06-23 06:24:24", "link": "http://arxiv.org/abs/2506.18332v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Exponential of Skew-Symmetric Matrices: A Nearby Inverse and Efficient Computation of Derivatives", "abstract": "The matrix exponential restricted to skew-symmetric matrices has numerous\napplications, notably in view of its interpretation as the Lie group\nexponential and Riemannian exponential for the special orthogonal group. We\ncharacterize the invertibility of the derivative of the skew-restricted\nexponential, thereby providing a simple expression of the tangent conjugate\nlocus of the orthogonal group. In view of the skew restriction, this\ncharacterization differs from the classic result on the invertibility of the\nderivative of the exponential of real matrices. Based on this characterization,\nfor every skew-symmetric matrix $A$ outside the (zero-measure) tangent\nconjugate locus, we explicitly construct the domain and image of a smooth\ninverse -- which we term \\emph{nearby logarithm} -- of the skew-restricted\nexponential around $A$. This nearby logarithm reduces to the classic principal\nlogarithm of special orthogonal matrices when $A=\\mathbf{0}$. The symbolic\nformulae for the differentiation and its inverse are derived and implemented\nefficiently. The extensive numerical experiments show that the proposed\nformulae are up to $3.9$-times and $3.6$-times faster than the current\nstate-of-the-art robust formulae for the differentiation and its inversion,\nrespectively.", "published": "2025-06-23 05:40:31", "link": "http://arxiv.org/abs/2506.18302v1", "categories": ["math.DG", "cs.NA", "math.NA", "15B10, 65F60"], "primary_category": "math.DG"}
{"title": "American options valuation in time-dependent jump-diffusion models via integral equations and characteristic functions", "abstract": "Despite significant advancements in machine learning for derivative pricing,\nthe efficient and accurate valuation of American options remains a persistent\nchallenge due to complex exercise boundaries, near-expiry behavior, and\nintricate contractual features. This paper extends a semi-analytical approach\nfor pricing American options in time-inhomogeneous models, including pure\ndiffusions, jump-diffusions, and Levy processes. Building on prior work, we\nderive and solve Volterra integral equations of the second kind to determine\nthe exercise boundary explicitly, offering a computationally superior\nalternative to traditional finite-difference and Monte Carlo methods. We\naddress key open problems: (1) extending the decomposition method, i.e.\nsplitting the American option price into its European counterpart and an early\nexercise premium, to general jump-diffusion and Levy models; (2) handling cases\nwhere closed-form transition densities are unavailable by leveraging\ncharacteristic functions via, e.g., the COS method; and (3) generalizing the\nframework to multidimensional diffusions. Numerical examples demonstrate the\nmethod's efficiency and robustness. Our results underscore the advantages of\nthe integral equation approach for large-scale industrial applications, while\nresolving some limitations of existing techniques.", "published": "2025-06-23 00:13:08", "link": "http://arxiv.org/abs/2506.18210v1", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "The Within-Orbit Adaptive Leapfrog No-U-Turn Sampler", "abstract": "Locally adapting parameters within Markov chain Monte Carlo methods while\npreserving reversibility is notoriously difficult. The success of the No-U-Turn\nSampler (NUTS) largely stems from its clever local adaptation of the\nintegration time in Hamiltonian Monte Carlo via a geometric U-turn condition.\nHowever, posterior distributions frequently exhibit multi-scale geometries with\nextreme variations in scale, making it necessary to also adapt the leapfrog\nintegrator's step size locally and dynamically. Despite its practical\nimportance, this problem has remained largely open since the introduction of\nNUTS by Hoffman and Gelman (2014). To address this issue, we introduce the\nWithin-orbit Adaptive Leapfrog No-U-Turn Sampler (WALNUTS), a generalization of\nNUTS that adapts the leapfrog step size at fixed intervals of simulated time as\nthe orbit evolves. At each interval, the algorithm selects the largest step\nsize from a dyadic schedule that keeps the energy error below a user-specified\nthreshold. Like NUTS, WALNUTS employs biased progressive state selection to\nfavor states with positions that are further from the initial point along the\norbit. Empirical evaluations on multiscale target distributions, including\nNeal's funnel and the Stock-Watson stochastic volatility time-series model,\ndemonstrate that WALNUTS achieves substantial improvements in sampling\nefficiency and robustness compared to standard NUTS.", "published": "2025-06-23 15:20:46", "link": "http://arxiv.org/abs/2506.18746v1", "categories": ["stat.CO", "math.PR", "stat.ML"], "primary_category": "stat.CO"}
{"title": "PCA-Guided Quantile Sampling: Preserving Data Structure in Large-Scale Subsampling", "abstract": "We introduce Principal Component Analysis guided Quantile Sampling (PCA QS),\na novel sampling framework designed to preserve both the statistical and\ngeometric structure of large scale datasets. Unlike conventional PCA, which\nreduces dimensionality at the cost of interpretability, PCA QS retains the\noriginal feature space while using leading principal components solely to guide\na quantile based stratification scheme. This principled design ensures that\nsampling remains representative without distorting the underlying data\nsemantics. We establish rigorous theoretical guarantees, deriving convergence\nrates for empirical quantiles, Kullback Leibler divergence, and Wasserstein\ndistance, thus quantifying the distributional fidelity of PCA QS samples.\nPractical guidelines for selecting the number of principal components, quantile\nbins, and sampling rates are provided based on these results. Extensive\nempirical studies on both synthetic and real-world datasets show that PCA QS\nconsistently outperforms simple random sampling, yielding better structure\npreservation and improved downstream model performance. Together, these\ncontributions position PCA QS as a scalable, interpretable, and theoretically\ngrounded solution for efficient data summarization in modern machine learning\nworkflows.", "published": "2025-06-23 02:37:05", "link": "http://arxiv.org/abs/2506.18249v1", "categories": ["stat.ME", "stat.ML", "62"], "primary_category": "stat.ME"}
{"title": "Evaluating Multichannel Speech Enhancement Algorithms at the Phoneme Scale Across Genders", "abstract": "Multichannel speech enhancement algorithms are essential for improving the\nintelligibility of speech signals in noisy environments. These algorithms are\nusually evaluated at the utterance level, but this approach overlooks the\ndisparities in acoustic characteristics that are observed in different phoneme\ncategories and between male and female speakers. In this paper, we investigate\nthe impact of gender and phonetic content on speech enhancement algorithms. We\nmotivate this approach by outlining phoneme- and gender-specific spectral\nfeatures. Our experiments reveal that while utterance-level differences between\ngenders are minimal, significant variations emerge at the phoneme level.\nResults show that the tested algorithms better reduce interference with fewer\nartifacts on female speech, particularly in plosives, fricatives, and vowels.\nAdditionally, they demonstrate greater performance for female speech in terms\nof perceptual and speech recognition metrics.", "published": "2025-06-23 14:29:56", "link": "http://arxiv.org/abs/2506.18691v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient and Generalizable Speaker Diarization via Structured Pruning of Self-Supervised Models", "abstract": "Self-supervised learning (SSL) models such as WavLM have brought substantial\nimprovements to speaker diarization by providing rich contextual\nrepresentations. However, the high computational and memory costs of these\nmodels hinder their deployment in real-time and resource-constrained scenarios.\nIn this work, we present a comprehensive study on compressing SSL-based\ndiarization models through structured pruning guided by knowledge distillation.\nBuilding upon our previous work, we extend the analysis to include pruning\nobjectives based on multiply-accumulate operations (MACs), investigate\nmodule-wise and progressive pruning strategies, and examine the impact of\ntraining data quantity. Experimental results show that our method reduces model\nsize by up to 80% without degrading performance, achieving up to 4x faster\ninference on a single GPU. We further perform large-scale evaluations on a\ndiverse compound dataset comprising eight public diarization corpora, where our\nbest pruned model achieves state-of-the-art performance across most conditions.\nAdditionally, we show strong generalization to the CHiME-6 dataset, attaining\nperformance comparable to the third-place system in the CHiME-7 challenge\nwithout any domain adaptation. All models and code are publicly released to\nsupport reproducibility and future research.", "published": "2025-06-23 13:29:51", "link": "http://arxiv.org/abs/2506.18623v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Fully Few-shot Class-incremental Audio Classification Using Multi-level Embedding Extractor and Ridge Regression Classifier", "abstract": "In the task of Few-shot Class-incremental Audio Classification (FCAC),\ntraining samples of each base class are required to be abundant to train model.\nHowever, it is not easy to collect abundant training samples for many base\nclasses due to data scarcity and high collection cost. We discuss a more\nrealistic issue, Fully FCAC (FFCAC), in which training samples of both base and\nincremental classes are only a few. Furthermore, we propose a FFCAC method\nusing a model which is decoupled into a multi-level embedding extractor and a\nridge regression classifier. The embedding extractor consists of an encoder of\naudio spectrogram Transformer and a fusion module, and is trained in the base\nsession but frozen in all incremental sessions. The classifier is updated\ncontinually in each incremental session. Results on three public datasets show\nthat our method exceeds current methods in accuracy, and has advantage over\nmost of them in complexity. The code is at https://github.com/YongjieSi/MAR.", "published": "2025-06-23 08:42:28", "link": "http://arxiv.org/abs/2506.18406v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Infant Cry Emotion Recognition Using Improved ECAPA-TDNN with Multiscale Feature Fusion and Attention Enhancement", "abstract": "Infant cry emotion recognition is crucial for parenting and medical\napplications. It faces many challenges, such as subtle emotional variations,\nnoise interference, and limited data. The existing methods lack the ability to\neffectively integrate multi-scale features and temporal-frequency\nrelationships. In this study, we propose a method for infant cry emotion\nrecognition using an improved Emphasized Channel Attention, Propagation and\nAggregation in Time Delay Neural Network (ECAPA-TDNN) with both multi-scale\nfeature fusion and attention enhancement. Experiments on a public dataset show\nthat the proposed method achieves accuracy of 82.20%, number of parameters of\n1.43 MB and FLOPs of 0.32 Giga. Moreover, our method has advantage over the\nbaseline methods in terms of accuracy. The code is at\nhttps://github.com/kkpretend/IETMA.", "published": "2025-06-23 08:39:48", "link": "http://arxiv.org/abs/2506.18402v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Selecting N-lowest scores for training MOS prediction models", "abstract": "The automatic speech quality assessment (SQA) has been extensively studied to\npredict the speech quality without time-consuming questionnaires. Recently,\nneural-based SQA models have been actively developed for speech samples\nproduced by text-to-speech or voice conversion, with a primary focus on\ntraining mean opinion score (MOS) prediction models. The quality of each speech\nsample may not be consistent across the entire duration, and it remains unclear\nwhich segments of the speech receive the primary focus from humans when\nassigning subjective evaluation for MOS calculation. We hypothesize that when\nhumans rate speech, they tend to assign more weight to low-quality speech\nsegments, and the variance in ratings for each sample is mainly due to\naccidental assignment of higher scores when overlooking the poor quality speech\nsegments. Motivated by the hypothesis, we analyze the VCC2018 and BVCC\ndatasets. Based on the hypothesis, we propose the more reliable representative\nvalue N_low-MOS, the mean of the $N$-lowest opinion scores. Our experiments\nshow that LCC and SRCC improve compared to regular MOS when employing N_low-MOS\nto MOSNet training. This result suggests that N_low-MOS is a more intrinsic\nrepresentative value of subjective speech quality and makes MOSNet a better\ncomparator of VC models.", "published": "2025-06-23 06:18:59", "link": "http://arxiv.org/abs/2506.18326v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Large-Scale Training Data Attribution for Music Generative Models via Unlearning", "abstract": "This paper explores the use of unlearning methods for training data\nattribution (TDA) in music generative models trained on large-scale datasets.\nTDA aims to identify which specific training data points contributed to the\ngeneration of a particular output from a specific model. This is crucial in the\ncontext of AI-generated music, where proper recognition and credit for original\nartists are generally overlooked. By enabling white-box attribution, our work\nsupports a fairer system for acknowledging artistic contributions and addresses\npressing concerns related to AI ethics and copyright. We apply unlearning-based\nattribution to a text-to-music diffusion model trained on a large-scale dataset\nand investigate its feasibility and behavior in this setting. To validate the\nmethod, we perform a grid search over different hyperparameter configurations\nand quantitatively evaluate the consistency of the unlearning approach. We then\ncompare attribution patterns from unlearning with those from a similarity-based\napproach. Our findings suggest that unlearning-based approaches can be\neffectively adapted to music generative models, introducing large-scale TDA to\nthis domain and paving the way for more ethical and accountable AI systems for\nmusic creation.", "published": "2025-06-23 05:58:43", "link": "http://arxiv.org/abs/2506.18312v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rethinking Mean Opinion Scores in Speech Quality Assessment: Aggregation through Quantized Distribution Fitting", "abstract": "Speech quality assessment (SQA) aims to evaluate the quality of speech\nsamples without relying on time-consuming listener questionnaires. Recent\nefforts have focused on training neural-based SQA models to predict the mean\nopinion score (MOS) of speech samples produced by text-to-speech or voice\nconversion systems. This paper targets the enhancement of MOS prediction\nmodels' performance. We propose a novel score aggregation method to address the\nlimitations of conventional annotations for MOS, which typically involve\nratings on a scale from 1 to 5. Our method is based on the hypothesis that\nannotators internally consider continuous scores and then choose the nearest\ndiscrete rating. By modeling this process, we approximate the generative\ndistribution of ratings by quantizing the latent continuous distribution. We\nthen use the peak of this latent distribution, estimated through the loss\nbetween the quantized distribution and annotated ratings, as a new\nrepresentative value instead of MOS. Experimental results demonstrate that\nsubstituting MOSNet's predicted target with this proposed value improves\nprediction performance.", "published": "2025-06-23 05:48:58", "link": "http://arxiv.org/abs/2506.18307v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JIS: A Speech Corpus of Japanese Idol Speakers with Various Speaking Styles", "abstract": "We construct Japanese Idol Speech Corpus (JIS) to advance research in speech\ngeneration AI, including text-to-speech synthesis (TTS) and voice conversion\n(VC). JIS will facilitate more rigorous evaluations of speaker similarity in\nTTS and VC systems since all speakers in JIS belong to a highly specific\ncategory: \"young female live idols\" in Japan, and each speaker is identified by\na stage name, enabling researchers to recruit listeners familiar with these\nidols for listening experiments. With its unique speaker attributes, JIS will\nfoster compelling research, including generating voices tailored to listener\npreferences-an area not yet widely studied. JIS will be distributed free of\ncharge to promote research in speech generation AI, with usage restricted to\nnon-commercial, basic research. We describe the construction of JIS, provide an\noverview of Japanese live idol culture to support effective and ethical use of\nJIS, and offer a basic analysis to guide application of JIS.", "published": "2025-06-23 05:23:34", "link": "http://arxiv.org/abs/2506.18296v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Blind Source Separation in Biomedical Signals Using Variational Methods", "abstract": "This study introduces a novel unsupervised approach for separating\noverlapping heart and lung sounds using variational autoencoders (VAEs). In\nclinical settings, these sounds often interfere with each other, making manual\nseparation difficult and error-prone. The proposed model learns to encode mixed\nsignals into a structured latent space and reconstructs the individual\ncomponents using a probabilistic decoder, all without requiring labeled data or\nprior knowledge of source characteristics. We apply this method to real\nrecordings obtained from a clinical manikin using a digital stethoscope.\nResults demonstrate distinct latent clusters corresponding to heart and lung\nsources, as well as accurate reconstructions that preserve key spectral\nfeatures of the original signals. The approach offers a robust and\ninterpretable solution for blind source separation and has potential\napplications in portable diagnostic tools and intelligent stethoscope systems.", "published": "2025-06-23 04:27:22", "link": "http://arxiv.org/abs/2506.18281v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Achieving 70 Gb/s Over A VCSEL-Based Optical Wireless Link Using A Multi-Mode Fiber-Coupled Receiver", "abstract": "In this paper, we demonstrate a laser-based optical wireless communication\n(OWC) system employing a 940 nm single-mode (SM) vertical cavity surface\nemitting laser (VCSEL) and a multi-mode (MM) fiber-coupled receiver, achieving\na record data rate beyond 70 Gb/s, while the optical transmit power is below 5\nmW. The use of a high speed fiber-optic photoreceiver avoids limiting the\ncommunication bandwidth by the receiver, enabling ultra-high capacity and\nenergy-efficient light fidelity (LiFi) links to unlock new applications. This\nwork experimentally validates the feasibility of ultra-high speed indoor OWC\nsystems using a single low-power and low-cost VCSEL for next-generation LiFi\nconnectivity.", "published": "2025-06-23 17:28:54", "link": "http://arxiv.org/abs/2506.18864v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Variational Bayesian Channel Estimation and Data Detection for Cell-Free Massive MIMO with Low-Resolution Quantized Fronthaul Links", "abstract": "We study the joint channel estimation and data detection (JED) problem in a\ncell-free massive multiple-input multiple-output (CF-mMIMO) network, where\naccess points (APs) communicate with a central processing unit (CPU) over\nfronthaul links. However, the bandwidth of these links is limited, and thus,\npresents challenges to the applicability of CF-mMIMO, especially with an\never-increasing number of users. To address this, we propose a method based on\nvariational Bayesian (VB) inference for performing the JED process, where the\nAPs forward low-resolution quantized versions of the signals to the CPU. We\nconsider two approaches: \\emph{quantization-and-estimation} (Q-E) and\n\\emph{estimation-and-quantization} (E-Q). In the Q-E approach, each AP uses a\nlow-bit quantizer to quantize the signal before forwarding it to the CPU, while\nin the E-Q approach, each AP first performs local channel estimation and then\nsends a low-bit quantized version of the estimated channel to the CPU. We\nevaluate the performance of our VB-based approach under perfect fronthaul link\n(PFL) with unquantized received signals, Q-E, and E-Q in terms of symbol error\nrate (SER), normalized mean square error (NMSE) of the channel estimation,\ncomputational complexity, and fronthaul signaling overhead. We also compare\nthese results with those of the linear minimum mean squared error (LMMSE)\nmethod under the PFL scenario. Our numerical results show that both the VB(Q-E)\nand VB(E-Q) approaches achieve superior performance compared to LMMSE(PFL),\nbenefiting from the nonlinear modeling inherent in VB. Furthermore, the VB(Q-E)\nmethod outperforms VB(E-Q) due to errors in the local channel estimation\nprocess at the APs within the VB(E-Q) approach.", "published": "2025-06-23 17:26:40", "link": "http://arxiv.org/abs/2506.18863v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Selection of Distributions and Their Fourier Transforms with Applications in Magnetic Resonance Imaging", "abstract": "This note presents a rigorous introduction to a selection of distributions\nalong with their Fourier transforms, which are commonly encountered in signal\nprocessing and, in particular, magnetic resonance imaging (MRI). In contrast to\nmany textbooks on the principles of MRI, which place more emphasis on the\nsignal processing aspect, this note will take a more mathematical approach. In\nparticular, we will make explicit the underlying topological space of interest\nand clarify the exact sense in which these distributions and their Fourier\ntransforms are defined. Key results presented in this note involve the Poisson\nsummation formula and the Fourier transform of a Gaussian function via an\nordinary differential equation (ODE) argument, etc. Although the readers are\nexpected to have prior exposure to functional analysis and distribution theory,\nthis note is intended to be self-contained.", "published": "2025-06-23 13:41:57", "link": "http://arxiv.org/abs/2506.18638v1", "categories": ["math.FA", "eess.IV", "eess.SP", "physics.med-ph"], "primary_category": "math.FA"}
{"title": "Sizing Antenna Arrays for Near-field Communication and Sensing", "abstract": "This paper presents key performance metrics for near-field communication and\nsensing systems with a focus on their scaling behavior as a function of the\nantenna array aperture. Analytical expressions are derived for several standard\narray geometries to enable the design of the large antenna arrays for given\nsystem requirements. First, the near-field beam focusing is analyzed and the\nminimum beamdepth is observed to rapidly saturate to a low asymptotic limit as\nthe array aperture increases. In contrast, the near-field region span is shown\nto scale quadratically with the array aperture. Based on these two metrics, the\nmaximum number of resolvable beamspots at 3 dB separation is derived\nanalytically, exhibiting a linear dependence on the array aperture. Finally,\nthe number of significant singular values of a channel observed at the array's\nbroadside is estimated, showing a power-law dependence on the aperture. The\nresulting expressions provide practical design guidelines for evaluating\naperture requirements in near-field communication and sensing applications.", "published": "2025-06-23 10:06:24", "link": "http://arxiv.org/abs/2506.18465v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A New Pathway to Integrated Learning and Communication (ILAC): Large AI Model and Hyperdimensional Computing for Communication", "abstract": "The rapid evolution of forthcoming sixth-generation (6G) wireless networks\nnecessitates the seamless integration of artificial intelligence (AI) with\nwireless communications to support emerging intelligent applications that\ndemand both efficient communication and robust learning performance. This dual\nrequirement calls for a unified framework of integrated learning and\ncommunication (ILAC), where AI enhances communication through intelligent\nsignal processing and adaptive resource management, while wireless networks\nsupport AI model deployment by enabling efficient and reliable data exchanges.\nHowever, achieving this integration presents significant challenges in\npractice. Communication constraints, such as limited bandwidth and fluctuating\nchannels, hinder learning accuracy and convergence. Simultaneously, AI-driven\nlearning dynamics, including model updates and task-driven inference, introduce\nexcessive burdens on communication systems, necessitating flexible,\ncontext-aware transmission strategies. Finally, we present a case study on a\ncost-to-performance optimization problem, where task assignments, model size\nselection, bandwidth allocation, and transmission power control are jointly\noptimized, considering computational cost, communication efficiency, and\ninference accuracy. Leveraging the Dinkelbach and alternating optimization\nalgorithms, we offer a practical and effective solution to achieve an optimal\nbalance between learning performance and communication constraints.", "published": "2025-06-23 09:13:54", "link": "http://arxiv.org/abs/2506.18432v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generative Diffusion Receivers: Achieving Pilot-Efficient MIMO-OFDM Communications", "abstract": "This paper focuses on wireless multiple-input multiple-output\n(MIMO)-orthogonal frequency division multiplex (OFDM) receivers. Traditional\nwireless receivers have relied on mathematical modeling and Bayesian inference,\nachieving remarkable success in most areas but falling short in their ability\nto characterize channel matrices. Neural networks (NNs) have demonstrated\nsignificant potential in this aspect. Nevertheless, integrating traditional\ninference methods with NNs presents challenges, particularly in tracking the\nerror progression. Given the inevitable presence of noise in wireless systems,\ngenerative models that are more resilient to noise are garnering increased\nattention. In this paper, we propose re-evaluating the MIMO-OFDM receiver using\ndiffusion models, which is a common generative approach. With diffusion models,\nwe can effectively leverage prior knowledge of channel matrices and incorporate\ntraditional signal estimation components. Specifically, we explore the\ndiffusion system and introduce an imagination-screening strategy to guide the\ndiffusion process. Furthermore, diffusion models enable adaptation to varying\nnoise levels and pilot schemes using the same NN, significantly reducing\ntraining and deployment costs. Simulated results reveal that, for pilot\ndensities ranging from 4-6 pilots per 64-subcarrier block and signal-to-noise\nratios (SNRs) from -4 dB to 0 dB, our proposed receiver reduces\nchannel-reconstruction error by up to two times compared to leading\ndeep-learning models, with the most pronounced improvements observed in\nlow-pilot conditions. Additionally, performance enhancements can be achieved\nwith a larger imagination size, despite increased computational complexity.", "published": "2025-06-23 09:00:50", "link": "http://arxiv.org/abs/2506.18419v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ARSAR-Net: Adaptively Regularized SAR Imaging Network via Non-matrix-inversion ADMM", "abstract": "Deep unfolding networks have constituted an emerging method for synthetic\naperture radar (SAR) imaging. However, baseline unfolding networks, when\nunfolded from the alternating direction method of multipliers (ADMM), lack\ngeneralization capability across scenes as the regularizers are empirically\ndesigned. In this study, we introduce a learnable regularizer to the unfolding\nnetwork and create an adaptively regularized SAR imaging network (ARSAR-Net),\nwhich pursues generalization capability across scenes, including varying\nsparsity levels and heterogeneous scenes with offshore ships, islands, urban\nareas, and mountainous terrain. In practice, the vanilla ARSAR-Net suffers from\ninherent structural limitations in 2D signal processing, primarily due to its\nreliance on matrix inversion. To conquer this challenge, we introduce the\nnon-matrix-inversion ADMM algorithm, which replaces inefficient matrix\ninversion with efficient linear approximations. Extensive validation through\nsimulated and real-data experiments (including GF-3 satellite echoes)\ndemonstrates ARSAR-Net's triple advantage: (1) 50\\% faster imaging speed\ncompared to existing unfolding networks, (2) up to 2.0 dB PSNR improvement in\nimaging quality, and (3) enhanced adaptability to complex heterogeneous scenes.\nThese advancements establish a new paradigm for computationally efficient and\ngeneralizable SAR imaging systems.", "published": "2025-06-23 06:16:08", "link": "http://arxiv.org/abs/2506.18324v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLM-Integrated Digital Twins for Hierarchical Resource Allocation in 6G Networks", "abstract": "Next-generation (NextG) wireless networks are expected to require\nintelligent, scalable, and context-aware radio resource management (RRM) to\nsupport ultra-dense deployments, diverse service requirements, and dynamic\nnetwork conditions. Digital twins (DTs) offer a powerful tool for network\nmanagement by creating high-fidelity virtual replicas that model real-time\nnetwork behavior, while large language models (LLMs) enhance decision-making\nthrough their advanced generalization and contextual reasoning capabilities.\nThis article proposes LLM-driven DTs for network optimization (LLM-DTNet), a\nhierarchical framework that integrates multi-layer DT architectures with\nLLM-based orchestration to enable adaptive, real-time RRM in heterogeneous\nNextG networks. We present the fundamentals and design considerations of\nLLM-DTNet while discussing its effectiveness in proactive and situation-aware\nnetwork management across terrestrial and non-terrestrial applications.\nFurthermore, we highlight key challenges, including scalable DT modeling,\nsecure LLM-DT integration, energy-efficient implementations, and multimodal\ndata processing, shaping future advancements in NextG intelligent wireless\nnetworks.", "published": "2025-06-23 05:03:49", "link": "http://arxiv.org/abs/2506.18293v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multimodal Visual Image Based User Association and Beamforming Using Graph Neural Networks", "abstract": "This paper proposes an approach that leverages multimodal data by integrating\nvisual images with radio frequency (RF) pilots to optimize user association and\nbeamforming in a downlink wireless cellular network under a max-min fairness\ncriterion. Traditional methods typically optimize wireless system parameters\nbased on channel state information (CSI). However, obtaining accurate CSI\nrequires extensive pilot transmissions, which lead to increased overhead and\nlatency. Moreover, the optimization of user association and beamforming is a\ndiscrete and non-convex optimization problem, which is challenging to solve\nanalytically. In this paper, we propose to incorporate visual camera data in\naddition to the RF pilots to perform the joint optimization of user association\nand beamforming. The visual image data helps enhance channel awareness, thereby\nreducing the dependency on extensive pilot transmissions for system\noptimization. We employ a learning-based approach based on using first a\ndetection neural network that estimates user locations from images, and\nsubsequently two graph neural networks (GNNs) that extract features for system\noptimization based on the location information and the received pilots,\nrespectively. Then, a multimodal GNN is constructed to integrate the features\nfor the joint optimization user association and beamforming. Simulation results\ndemonstrate that the proposed method achieves superior performance, while\nhaving low computational complexity and being interpretable and generalizable,\nmaking it an effective solution as compared to traditional methods based only\non RF pilots.", "published": "2025-06-23 00:36:31", "link": "http://arxiv.org/abs/2506.18218v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "abstract": "We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-document retrieval, semantic text similarity, and code search.\nComprehensive evaluations demonstrate that jina-embeddings-v4 achieves\nstate-of-the-art performance on both single-modal and cross-modal retrieval\ntasks, with particular strength in processing visually rich content such as\ntables, charts, diagrams, and mixed-media formats. To facilitate evaluation of\nthis capability, we also introduce Jina-VDR, a novel benchmark specifically\ndesigned for visually rich image retrieval.", "published": "2025-06-23 17:59:55", "link": "http://arxiv.org/abs/2506.18902v2", "categories": ["cs.AI", "cs.CL", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.AI"}
{"title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "abstract": "Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.", "published": "2025-06-23 16:20:44", "link": "http://arxiv.org/abs/2506.18810v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Benchmarking the Pedagogical Knowledge of Large Language Models", "abstract": "Benchmarks like Massive Multitask Language Understanding (MMLU) have played a\npivotal role in evaluating AI's knowledge and abilities across diverse domains.\nHowever, existing benchmarks predominantly focus on content knowledge, leaving\na critical gap in assessing models' understanding of pedagogy - the method and\npractice of teaching. This paper introduces The Pedagogy Benchmark, a novel\ndataset designed to evaluate large language models on their Cross-Domain\nPedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)\npedagogical knowledge. These benchmarks are built on a carefully curated set of\nquestions sourced from professional development exams for teachers, which cover\na range of pedagogical subdomains such as teaching strategies and assessment\nmethods. Here we outline the methodology and development of these benchmarks.\nWe report results for 97 models, with accuracies spanning a range from 28% to\n89% on the pedagogical knowledge questions. We consider the relationship\nbetween cost and accuracy and chart the progression of the Pareto value\nfrontier over time. We provide online leaderboards at\nhttps://rebrand.ly/pedagogy which are updated with new models and allow\ninteractive exploration and filtering based on various model properties, such\nas cost per token and open-vs-closed weights, as well as looking at performance\nin different subjects. LLMs and generative AI have tremendous potential to\ninfluence education and help to address the global learning crisis.\nEducation-focused benchmarks are crucial to measure models' capacities to\nunderstand pedagogical concepts, respond appropriately to learners' needs, and\nsupport effective teaching practices across diverse contexts. They are needed\nfor informing the responsible and evidence-based deployment of LLMs and\nLLM-based tools in educational settings, and for guiding both development and\npolicy decisions.", "published": "2025-06-23 14:49:01", "link": "http://arxiv.org/abs/2506.18710v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "abstract": "DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning\ncapabilities through its rule-based reward system. While it's a ''perfect''\nreward system that effectively mitigates reward hacking, such reward functions\nare often discrete. Our experimental observations suggest that discrete rewards\ncan lead to gradient anomaly, unstable optimization, and slow convergence. To\naddress this issue, we propose ReDit (Reward Dithering), a method that dithers\nthe discrete reward signal by adding simple random noise. With this perturbed\nreward, exploratory gradients are continuously provided throughout the learning\nprocess, enabling smoother gradient updates and accelerating convergence. The\ninjected noise also introduces stochasticity into flat reward regions,\nencouraging the model to explore novel policies and escape local optima.\nExperiments across diverse tasks demonstrate the effectiveness and efficiency\nof ReDit. On average, ReDit achieves performance comparable to vanilla GRPO\nwith only approximately 10% the training steps, and furthermore, still exhibits\na 4% performance improvement over vanilla GRPO when trained for a similar\nduration. Visualizations confirm significant mitigation of gradient issues with\nReDit. Moreover, theoretical analyses are provided to further validate these\nadvantages.", "published": "2025-06-23 13:36:24", "link": "http://arxiv.org/abs/2506.18631v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners", "abstract": "We propose MuseControlLite, a lightweight mechanism designed to fine-tune\ntext-to-music generation models for precise conditioning using various\ntime-varying musical attributes and reference audio signals. The key finding is\nthat positional embeddings, which have been seldom used by text-to-music\ngeneration models in the conditioner for text conditions, are critical when the\ncondition of interest is a function of time. Using melody control as an\nexample, our experiments show that simply adding rotary positional embeddings\nto the decoupled cross-attention layers increases control accuracy from 56.6%\nto 61.1%, while requiring 6.75 times fewer trainable parameters than\nstate-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion\nTransformer model of Stable Audio Open. We evaluate various forms of musical\nattribute control, audio inpainting, and audio outpainting, demonstrating\nimproved controllability over MusicGen-Large and Stable Audio Open ControlNet\nat a significantly lower fine-tuning cost, with only 85M trainble parameters.\nSource code, model checkpoints, and demo examples are available at:\nhttps://musecontrollite.github.io/web/.", "published": "2025-06-23 15:08:03", "link": "http://arxiv.org/abs/2506.18729v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Light of Normals: Unified Feature Representation for Universal Photometric Stereo", "abstract": "Universal photometric stereo (PS) aims to recover high-quality surface\nnormals from objects under arbitrary lighting conditions without relying on\nspecific illumination models. Despite recent advances such as SDM-UniPS and Uni\nMS-PS, two fundamental challenges persist: 1) the deep coupling between varying\nillumination and surface normal features, where ambiguity in observed intensity\nmakes it difficult to determine whether brightness variations stem from\nlighting changes or surface orientation; and 2) the preservation of\nhigh-frequency geometric details in complex surfaces, where intricate\ngeometries create self-shadowing, inter-reflections, and subtle normal\nvariations that conventional feature processing operations struggle to capture\naccurately.", "published": "2025-06-23 17:53:11", "link": "http://arxiv.org/abs/2506.18882v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications", "abstract": "Real-time, on-device segmentation is critical for latency-sensitive and\nprivacy-aware applications like smart glasses and IoT devices. We introduce\nPicoSAM2, a lightweight (1.3M parameters, 336M MACs) promptable segmentation\nmodel optimized for edge and in-sensor execution, including the Sony IMX500. It\nbuilds on a depthwise separable U-Net, with knowledge distillation and\nfixed-point prompt encoding to learn from the Segment Anything Model 2 (SAM2).\nOn COCO and LVIS, it achieves 51.9% and 44.9% mIoU, respectively. The quantized\nmodel (1.22MB) runs at 14.3 ms on the IMX500-achieving 86 MACs/cycle, making it\nthe only model meeting both memory and compute constraints for in-sensor\ndeployment. Distillation boosts LVIS performance by +3.5% mIoU and +5.1% mAP.\nThese results demonstrate that efficient, promptable segmentation is feasible\ndirectly on-camera, enabling privacy-preserving vision without cloud or host\nprocessing.", "published": "2025-06-23 16:16:02", "link": "http://arxiv.org/abs/2506.18807v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Object-aware Sound Source Localization via Audio-Visual Scene Understanding", "abstract": "Audio-visual sound source localization task aims to spatially localize\nsound-making objects within visual scenes by integrating visual and audio cues.\nHowever, existing methods struggle with accurately localizing sound-making\nobjects in complex scenes, particularly when visually similar silent objects\ncoexist. This limitation arises primarily from their reliance on simple\naudio-visual correspondence, which does not capture fine-grained semantic\ndifferences between sound-making and silent objects. To address these\nchallenges, we propose a novel sound source localization framework leveraging\nMultimodal Large Language Models (MLLMs) to generate detailed contextual\ninformation that explicitly distinguishes between sound-making foreground\nobjects and silent background objects. To effectively integrate this detailed\ninformation, we introduce two novel loss functions: Object-aware Contrastive\nAlignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive\nexperimental results on MUSIC and VGGSound datasets demonstrate the\neffectiveness of our approach, significantly outperforming existing methods in\nboth single-source and multi-source localization scenarios. Code and generated\ndetailed contextual information are available at:\nhttps://github.com/VisualAIKHU/OA-SSL.", "published": "2025-06-23 12:08:07", "link": "http://arxiv.org/abs/2506.18557v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Referring Expression Instance Retrieval and A Strong End-to-End Baseline", "abstract": "Natural language querying of visual content underpins many vision-language\ntasks, typically categorized by text granularity and visual search scope.\nText-Image Retrieval (TIR) retrieves whole images using coarse descriptions,\nwhile Referring Expression Comprehension (REC) localizes objects using\nfine-grained expressions within a single image. However, real-world scenarios\noften require both instance-level retrieval and localization across large\ngalleries -- tasks where TIR lacks precision and REC lacks scalability. To\naddress this gap, we propose a new task: Referring Expression Instance\nRetrieval (REIR), which jointly supports instance-level retrieval and\nlocalization. We introduce REIRCOCO, a large-scale benchmark constructed by\nprompting vision-language models to generate fine-grained expressions for\nMSCOCO and RefCOCO instances. We also present a baseline method, CLARE,\nfeaturing a dual-stream architecture with a Mix of Relation Experts (MORE)\nmodule for capturing inter-instance relationships. CLARE integrates object\ndetection and REC pretraining with Contrastive Language-Instance Alignment\n(CLIA) for end-to-end optimization. Experiments show that CLARE achieves\nstate-of-the-art performance on REIR and generalizes well to TIR and REC,\nhighlighting its effectiveness and versatility.", "published": "2025-06-23 02:28:44", "link": "http://arxiv.org/abs/2506.18246v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "$(\\ell,\u03b4)$-Diversity: Linkage-Robustness via a Composition Theorem", "abstract": "In this paper, we consider the problem of degradation of anonymity upon\nlinkages of anonymized datasets. We work in the setting where an adversary\nlinks together $t\\geq 2$ anonymized datasets in which a user of interest\nparticipates, based on the user's known quasi-identifiers, which motivates the\nuse of $\\ell$-diversity as the notion of dataset anonymity. We first argue that\nin the worst case, such linkage attacks can reveal the exact sensitive\nattribute of the user, even when each dataset respects $\\ell$-diversity, for\nmoderately large values of $\\ell$. This issue motivates our definition of\n(approximate) $(\\ell,\\delta)$-diversity -- a parallel of (approximate)\n$(\\epsilon,\\delta)$-differential privacy (DP) -- which simply requires that a\ndataset respect $\\ell$-diversity, with high probability. We then present a\nmechanism for achieving $(\\ell,\\delta)$-diversity, in the setting of\nindependent and identically distributed samples. Next, we establish bounds on\nthe degradation of $(\\ell,\\delta)$-diversity, via a simple ``composition\ntheorem,'' similar in spirit to those in the DP literature, thereby showing\nthat approximate diversity, unlike standard diversity, is roughly preserved\nupon linkage. Finally, we describe simple algorithms for maximizing utility,\nmeasured in terms of the number of anonymized ``equivalence classes,'' and\nderive explicit lower bounds on the utility, for special sample distributions.", "published": "2025-06-23 08:42:14", "link": "http://arxiv.org/abs/2506.18405v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A New Pathway to Integrated Learning and Communication (ILAC): Large AI Model and Hyperdimensional Computing for Communication", "abstract": "The rapid evolution of forthcoming sixth-generation (6G) wireless networks\nnecessitates the seamless integration of artificial intelligence (AI) with\nwireless communications to support emerging intelligent applications that\ndemand both efficient communication and robust learning performance. This dual\nrequirement calls for a unified framework of integrated learning and\ncommunication (ILAC), where AI enhances communication through intelligent\nsignal processing and adaptive resource management, while wireless networks\nsupport AI model deployment by enabling efficient and reliable data exchanges.\nHowever, achieving this integration presents significant challenges in\npractice. Communication constraints, such as limited bandwidth and fluctuating\nchannels, hinder learning accuracy and convergence. Simultaneously, AI-driven\nlearning dynamics, including model updates and task-driven inference, introduce\nexcessive burdens on communication systems, necessitating flexible,\ncontext-aware transmission strategies. Finally, we present a case study on a\ncost-to-performance optimization problem, where task assignments, model size\nselection, bandwidth allocation, and transmission power control are jointly\noptimized, considering computational cost, communication efficiency, and\ninference accuracy. Leveraging the Dinkelbach and alternating optimization\nalgorithms, we offer a practical and effective solution to achieve an optimal\nbalance between learning performance and communication constraints.", "published": "2025-06-23 09:13:54", "link": "http://arxiv.org/abs/2506.18432v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "abstract": "We introduce a mathematically rigorous framework for an artificial\nintelligence system composed of probabilistic agents evolving through\nstructured competition and belief revision. The architecture, grounded in\nBayesian inference, measure theory, and population dynamics, defines agent\nfitness as a function of alignment with a fixed external oracle representing\nground truth. Agents compete in a discrete-time environment, adjusting\nposterior beliefs through observed outcomes, with higher-rated agents\nreproducing and lower-rated agents undergoing extinction. Ratings are updated\nvia pairwise truth-aligned utility comparisons, and belief updates preserve\nmeasurable consistency and stochastic convergence. We introduce hash-based\ncryptographic identity commitments to ensure traceability, alongside causal\ninference operators using do-calculus. Formal theorems on convergence,\nrobustness, and evolutionary stability are provided. The system establishes\ntruth as an evolutionary attractor, demonstrating that verifiable knowledge\narises from adversarial epistemic pressure within a computable, self-regulating\nswarm.", "published": "2025-06-23 23:27:44", "link": "http://arxiv.org/abs/2506.19191v1", "categories": ["cs.AI", "cs.CL", "cs.GT", "math.LO", "68T05, 68Q87, 03E20", "I.2.6; I.2.3; F.1.1"], "primary_category": "cs.AI"}
{"title": "Prompt, Translate, Fine-Tune, Re-Initialize, or Instruction-Tune? Adapting LLMs for In-Context Learning in Low-Resource Languages", "abstract": "LLMs are typically trained in high-resource languages, and tasks in\nlower-resourced languages tend to underperform the higher-resource language\ncounterparts for in-context learning. Despite the large body of work on\nprompting settings, it is still unclear how LLMs should be adapted\ncross-lingually specifically for in-context learning in the low-resource target\nlanguages. We perform a comprehensive study spanning five diverse target\nlanguages, three base LLMs, and seven downstream tasks spanning over 4,100 GPU\ntraining hours (9,900+ TFLOPs) across various adaptation techniques: few-shot\nprompting, translate-test, fine-tuning, embedding re-initialization, and\ninstruction fine-tuning. Our results show that the few-shot prompting and\ntranslate-test settings tend to heavily outperform the gradient-based\nadaptation methods. To better understand this discrepancy, we design a novel\nmetric, Valid Output Recall (VOR), and analyze model outputs to empirically\nattribute the degradation of these trained models to catastrophic forgetting.\nTo the extent of our knowledge, this is the largest study done on in-context\nlearning for low-resource languages with respect to train compute and number of\nadaptation techniques considered. We make all our datasets and trained models\navailable for public use.", "published": "2025-06-23 23:22:11", "link": "http://arxiv.org/abs/2506.19187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Hybrid Transducer and Attention Encoder Decoder with Text Data", "abstract": "A joint speech and text optimization method is proposed for hybrid transducer\nand attention-based encoder decoder (TAED) modeling to leverage large amounts\nof text corpus and enhance ASR accuracy. The joint TAED (J-TAED) is trained\nwith both speech and text input modalities together, while it only takes speech\ndata as input during inference. The trained model can unify the internal\nrepresentations from different modalities, and be further extended to\ntext-based domain adaptation. It can effectively alleviate data scarcity for\nmismatch domain tasks since no speech data is required. Our experiments show\nJ-TAED successfully integrates speech and linguistic information into one\nmodel, and reduce the WER by 5.8 ~12.8% on the Librispeech dataset. The model\nis also evaluated on two out-of-domain datasets: one is finance and another is\nnamed entity focused. The text-based domain adaptation brings 15.3% and 17.8%\nWER reduction on those two datasets respectively.", "published": "2025-06-23 21:51:39", "link": "http://arxiv.org/abs/2506.19159v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Thought Anchors: Which LLM Reasoning Steps Matter?", "abstract": "Reasoning large language models have recently achieved state-of-the-art\nperformance in many fields. However, their long-form chain-of-thought reasoning\ncreates interpretability challenges as each generated token depends on all\nprevious ones, making the computation harder to decompose. We argue that\nanalyzing reasoning traces at the sentence level is a promising approach to\nunderstanding reasoning processes. We present three complementary attribution\nmethods: (1) a black-box method measuring each sentence's counterfactual\nimportance by comparing final answers across 100 rollouts conditioned on the\nmodel generating that sentence or one with a different meaning; (2) a white-box\nmethod of aggregating attention patterns between pairs of sentences, which\nidentified ``broadcasting'' sentences that receive disproportionate attention\nfrom all future sentences via ``receiver'' attention heads; (3) a causal\nattribution method measuring logical connections between sentences by\nsuppressing attention toward one sentence and measuring the effect on each\nfuture sentence's tokens. Each method provides evidence for the existence of\nthought anchors, reasoning steps that have outsized importance and that\ndisproportionately influence the subsequent reasoning process. These thought\nanchors are typically planning or backtracking sentences. We provide an\nopen-source tool (www.thought-anchors.com) for visualizing the outputs of our\nmethods, and present a case study showing converging patterns across methods\nthat map how a model performs multi-step reasoning. The consistency across\nmethods demonstrates the potential of sentence-level analysis for a deeper\nunderstanding of reasoning models.", "published": "2025-06-23 21:28:45", "link": "http://arxiv.org/abs/2506.19143v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Human-Aligned Faithfulness in Toxicity Explanations of LLMs", "abstract": "The discourse around toxicity and LLMs in NLP largely revolves around\ndetection tasks. This work shifts the focus to evaluating LLMs' reasoning about\ntoxicity -- from their explanations that justify a stance -- to enhance their\ntrustworthiness in downstream tasks. Despite extensive research on\nexplainability, it is not straightforward to adopt existing methods to evaluate\nfree-form toxicity explanation due to their over-reliance on input text\nperturbations, among other challenges. To account for these, we propose a\nnovel, theoretically-grounded multi-dimensional criterion, Human-Aligned\nFaithfulness (HAF), that measures the extent to which LLMs' free-form toxicity\nexplanations align with those of a rational human under ideal conditions. We\ndevelop six metrics, based on uncertainty quantification, to comprehensively\nevaluate \\haf of LLMs' toxicity explanations with no human involvement, and\nhighlight how \"non-ideal\" the explanations are. We conduct several experiments\non three Llama models (of size up to 70B) and an 8B Ministral model on five\ndiverse toxicity datasets. Our results show that while LLMs generate plausible\nexplanations to simple prompts, their reasoning about toxicity breaks down when\nprompted about the nuanced relations between the complete set of reasons, the\nindividual reasons, and their toxicity stances, resulting in inconsistent and\nnonsensical responses. We open-source our code and LLM-generated explanations\nat https://github.com/uofthcdslab/HAF.", "published": "2025-06-23 20:41:45", "link": "http://arxiv.org/abs/2506.19113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting", "abstract": "We introduce $\\texttt{StorySim}$, a programmable framework for synthetically\ngenerating stories to evaluate the theory of mind (ToM) and world modeling (WM)\ncapabilities of large language models (LLMs). Unlike prior benchmarks that may\nsuffer from contamination in pretraining data, $\\texttt{StorySim}$ produces\nnovel, compositional story prompts anchored by a highly controllable\n$\\texttt{Storyboard}$, enabling precise manipulation of character perspectives\nand events. We use this framework to design first- and second-order ToM tasks\nalongside WM tasks that control for the ability to track and model mental\nstates. Our experiments across a suite of state-of-the-art LLMs reveal that\nmost models perform better on WM tasks than ToM tasks, and that models tend to\nperform better reasoning with humans compared to inanimate objects.\nAdditionally, our framework enabled us to find evidence of heuristic behavior\nsuch as recency bias and an over-reliance on earlier events in the story. All\ncode for generating data and evaluations is freely available.", "published": "2025-06-23 20:06:53", "link": "http://arxiv.org/abs/2506.19089v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanation", "abstract": "Ensuring the moral reasoning capabilities of Large Language Models (LLMs) is\na growing concern as these systems are used in socially sensitive tasks.\nNevertheless, current evaluation benchmarks present two major shortcomings: a\nlack of annotations that justify moral classifications, which limits\ntransparency and interpretability; and a predominant focus on English, which\nconstrains the assessment of moral reasoning across diverse cultural settings.\nIn this paper, we introduce MFTCXplain, a multilingual benchmark dataset for\nevaluating the moral reasoning of LLMs via hate speech multi-hop explanation\nusing Moral Foundation Theory (MFT). The dataset comprises 3,000 tweets across\nPortuguese, Italian, Persian, and English, annotated with binary hate speech\nlabels, moral categories, and text span-level rationales. Empirical results\nhighlight a misalignment between LLM outputs and human annotations in moral\nreasoning tasks. While LLMs perform well in hate speech detection (F1 up to\n0.836), their ability to predict moral sentiments is notably weak (F1 < 0.35).\nFurthermore, rationale alignment remains limited mainly in underrepresented\nlanguages. These findings show the limited capacity of current LLMs to\ninternalize and reflect human moral reasoning.", "published": "2025-06-23 19:44:21", "link": "http://arxiv.org/abs/2506.19073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models", "abstract": "Improving the visual understanding ability of vision-language models (VLMs)\nis crucial for enhancing their performance across various tasks. While using\nmultiple pretrained visual experts has shown great promise, it often incurs\nsignificant computational costs during training and inference. To address this\nchallenge, we propose HAWAII, a novel framework that distills knowledge from\nmultiple visual experts into a single vision encoder, enabling it to inherit\nthe complementary strengths of several experts with minimal computational\noverhead. To mitigate conflicts among different teachers and switch between\ndifferent teacher-specific knowledge, instead of using a fixed set of adapters\nfor multiple teachers, we propose to use teacher-specific Low-Rank Adaptation\n(LoRA) adapters with a corresponding router. Each adapter is aligned with a\nspecific teacher, avoiding noisy guidance during distillation. To enable\nefficient knowledge distillation, we propose fine-grained and coarse-grained\ndistillation. At the fine-grained level, token importance scores are employed\nto emphasize the most informative tokens from each teacher adaptively. At the\ncoarse-grained level, we summarize the knowledge from multiple teachers and\ntransfer it to the student using a set of general-knowledge LoRA adapters with\na router. Extensive experiments on various vision-language tasks demonstrate\nthe superiority of HAWAII, compared to the popular open-source VLMs.", "published": "2025-06-23 19:43:25", "link": "http://arxiv.org/abs/2506.19072v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "NLPnorth @ TalentCLEF 2025: Comparing Discriminative, Contrastive, and Prompt-Based Methods for Job Title and Skill Matching", "abstract": "Matching job titles is a highly relevant task in the computational job market\ndomain, as it improves e.g., automatic candidate matching, career path\nprediction, and job market analysis. Furthermore, aligning job titles to job\nskills can be considered an extension to this task, with similar relevance for\nthe same downstream tasks. In this report, we outline NLPnorth's submission to\nTalentCLEF 2025, which includes both of these tasks: Multilingual Job Title\nMatching, and Job Title-Based Skill Prediction. For both tasks we compare\n(fine-tuned) classification-based, (fine-tuned) contrastive-based, and\nprompting methods. We observe that for Task A, our prompting approach performs\nbest with an average of 0.492 mean average precision (MAP) on test data,\naveraged over English, Spanish, and German. For Task B, we obtain an MAP of\n0.290 on test data with our fine-tuned classification-based approach.\nAdditionally, we made use of extra data by pulling all the language-specific\ntitles and corresponding \\emph{descriptions} from ESCO for each job and skill.\nOverall, we find that the largest multilingual language models perform best for\nboth tasks. Per the provisional results and only counting the unique teams, the\nranking on Task A is 5$^{\\text{th}}$/20 and for Task B 3$^{\\text{rd}}$/14.", "published": "2025-06-23 19:18:25", "link": "http://arxiv.org/abs/2506.19058v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models", "abstract": "Masked diffusion language models (MDLM) have shown strong promise for\nnon-autoregressive text generation, yet existing samplers act as implicit\nplanners, selecting tokens to unmask via denoiser confidence or entropy scores.\nSuch heuristics falter under parallel unmasking - they ignore pairwise\ninteractions between tokens and cannot account for dependencies when unmasking\nmultiple positions at once, limiting their inference time to traditional\nauto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking\nStrategy (DUS), an inference-only, planner-model-free method that requires no\nadditional training. DUS leverages a first-order Markov assumption to partition\nsequence positions into dilation-based groups of non-adjacent tokens, enabling\nindependent, parallel unmasking steps that respect local context that minimizes\nthe joint entropy of each iteration step. Unlike semi-AR block approaches\n(e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces\nthe number of denoiser calls to O(log B) per generation block - yielding\nsubstantial speedup over the O(B) run time of state-of-the-art diffusion\nmodels, where B is the block size in the semi-AR inference process. In\nexperiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks -\ndomains suited to non-ordinal generation - DUS improves scores over parallel\nconfidence-based planner, without modifying the underlying denoiser. DUS offers\na lightweight, budget-aware approach to efficient, high-quality text\ngeneration, paving the way to unlock the true capabilities of MDLMs.", "published": "2025-06-23 18:49:23", "link": "http://arxiv.org/abs/2506.19037v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "cs.NE", "math.IT"], "primary_category": "cs.CL"}
{"title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "abstract": "Large Language Models (LLMs) often generate responses with inherent biases,\nundermining their reliability in real-world applications. Existing evaluation\nmethods often overlook biases in long-form responses and the intrinsic\nvariability of LLM outputs. To address these challenges, we propose\nFiSCo(Fine-grained Semantic Computation), a novel statistical framework to\nevaluate group-level fairness in LLMs by detecting subtle semantic differences\nin long-form responses across demographic groups. Unlike prior work focusing on\nsentiment or token-level comparisons, FiSCo goes beyond surface-level analysis\nby operating at the claim level, leveraging entailment checks to assess the\nconsistency of meaning across responses. We decompose model outputs into\nsemantically distinct claims and apply statistical hypothesis testing to\ncompare inter- and intra-group similarities, enabling robust detection of\nsubtle biases. We formalize a new group counterfactual fairness definition and\nvalidate FiSCo on both synthetic and human-annotated datasets spanning gender,\nrace, and age. Experiments show that FiSco more reliably identifies nuanced\nbiases while reducing the impact of stochastic LLM variability, outperforming\nvarious evaluation metrics.", "published": "2025-06-23 18:31:22", "link": "http://arxiv.org/abs/2506.19028v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations", "abstract": "Modern tokenizers employ deterministic algorithms to map text into a single\n\"canonical\" token sequence, yet the same string can be encoded as many\nnon-canonical tokenizations using the tokenizer vocabulary. In this work, we\ninvestigate the robustness of LMs to text encoded with non-canonical\ntokenizations entirely unseen during training. Surprisingly, when evaluated\nacross 20 benchmarks, we find that instruction-tuned models retain up to 93.4%\nof their original performance when given a randomly sampled tokenization, and\n90.8% with character-level tokenization. We see that overall stronger models\ntend to be more robust, and robustness diminishes as the tokenization departs\nfarther from the canonical form. Motivated by these results, we then identify\nsettings where non-canonical tokenization schemes can *improve* performance,\nfinding that character-level segmentation improves string manipulation and code\nunderstanding tasks by up to +14%, and right-aligned digit grouping enhances\nlarge-number arithmetic by +33%. Finally, we investigate the source of this\nrobustness, finding that it arises in the instruction-tuning phase. We show\nthat while both base and post-trained models grasp the semantics of\nnon-canonical tokenizations (perceiving them as containing misspellings), base\nmodels try to mimic the imagined mistakes and degenerate into nonsensical\noutput, while post-trained models are committed to fluent responses. Overall,\nour findings suggest that models are less tied to their tokenizer than\npreviously believed, and demonstrate the promise of intervening on tokenization\nat inference time to boost performance.", "published": "2025-06-23 18:02:26", "link": "http://arxiv.org/abs/2506.19004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge", "abstract": "When artificial intelligence mistakes memorization for intelligence, it\ncreates a dangerous mirage of reasoning. Existing studies treat memorization\nand self-knowledge deficits in LLMs as separate issues and do not recognize an\nintertwining link that degrades the trustworthiness of LLM responses. In our\nstudy, we utilize a novel framework to ascertain if LLMs genuinely learn\nreasoning patterns from training data or merely memorize them to assume\ncompetence across problems of similar complexity focused on STEM domains. Our\nanalysis shows a noteworthy problem in generalization: LLMs draw confidence\nfrom memorized solutions to infer a higher self-knowledge about their reasoning\nability, which manifests as an over 45% inconsistency in feasibility\nassessments when faced with self-validated, logically coherent task\nperturbations. This effect is most pronounced in science and medicine domains,\nwhich tend to have maximal standardized jargon and problems, further confirming\nour approach. Significant wavering within the self-knowledge of LLMs also shows\nflaws in current architectures and training patterns, highlighting the need for\ntechniques that ensure a balanced, consistent stance on models' perceptions of\ntheir own knowledge for maximum AI explainability and trustworthiness. Our code\nand results are available publicly at\nhttps://github.com/knowledge-verse-ai/LLM-Memorization_SK_Eval-.", "published": "2025-06-23 18:01:16", "link": "http://arxiv.org/abs/2506.18998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "abstract": "Information retrieval is a cornerstone of modern knowledge acquisition,\nenabling billions of queries each day across diverse domains. However,\ntraditional keyword-based search engines are increasingly inadequate for\nhandling complex, multi-step information needs. Our position is that Large\nLanguage Models (LLMs), endowed with reasoning and agentic capabilities, are\nushering in a new paradigm termed Agentic Deep Research. These systems\ntranscend conventional information search techniques by tightly integrating\nautonomous reasoning, iterative retrieval, and information synthesis into a\ndynamic feedback loop. We trace the evolution from static web search to\ninteractive, agent-based systems that plan, explore, and learn. We also\nintroduce a test-time scaling law to formalize the impact of computational\ndepth on reasoning and search. Supported by benchmark results and the rise of\nopen-source implementations, we demonstrate that Agentic Deep Research not only\nsignificantly outperforms existing approaches, but is also poised to become the\ndominant paradigm for future information seeking. All the related resources,\nincluding industry products, research papers, benchmark datasets, and\nopen-source implementations, are collected for the community in\nhttps://github.com/DavidZWZ/Awesome-Deep-Research.", "published": "2025-06-23 17:27:19", "link": "http://arxiv.org/abs/2506.18959v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "abstract": "The recent work by Shojaee et al. (2025), titled The Illusion of Thinking:\nUnderstanding the Strengths and Limitations of Reasoning Models via the Lens of\nProblem Complexity, presents a compelling empirical finding, a reasoning cliff,\nwhere the performance of Large Reasoning Models (LRMs) collapses beyond a\nspecific complexity threshold, which the authors posit as an intrinsic scaling\nlimitation of Chain-of-Thought (CoT) reasoning. This commentary, while\nacknowledging the study's methodological rigor, contends that this conclusion\nis confounded by experimental artifacts. We argue that the observed failure is\nnot evidence of a fundamental cognitive boundary, but rather a predictable\noutcome of system-level constraints in the static, text-only evaluation\nparadigm, including tool use restrictions, context window recall issues, the\nabsence of crucial cognitive baselines, inadequate statistical reporting, and\noutput generation limits. We reframe this performance collapse through the lens\nof an agentic gap, asserting that the models are not failing at reasoning, but\nat execution within a profoundly restrictive interface. We empirically\nsubstantiate this critique by demonstrating a striking reversal. A model,\ninitially declaring a puzzle impossible when confined to text-only generation,\nnow employs agentic tools to not only solve it but also master variations of\ncomplexity far beyond the reasoning cliff it previously failed to surmount.\nAdditionally, our empirical analysis of tool-enabled models like o4-mini and\nGPT-4o reveals a hierarchy of agentic reasoning, from simple procedural\nexecution to complex meta-cognitive self-correction, which has significant\nimplications for how we define and measure machine intelligence. The illusion\nof thinking attributed to LRMs is less a reasoning deficit and more a\nconsequence of an otherwise capable mind lacking the tools for action.", "published": "2025-06-23 17:14:21", "link": "http://arxiv.org/abs/2506.18957v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs", "abstract": "Traditional mental health support systems often generate responses based\nsolely on the user's current emotion and situations, resulting in superficial\ninterventions that fail to address deeper emotional needs. This study\nintroduces a novel framework by integrating spiritual wisdom from the Bhagavad\nGita with advanced large language model GPT-4o to enhance emotional well-being.\nWe present the GITes (Gita Integrated Therapy for Emotional Support) dataset,\nwhich enhances the existing ExTES mental health dataset by including 10,729\nspiritually guided responses generated by GPT-4o and evaluated by domain\nexperts. We benchmark GITes against 12 state-of-the-art LLMs, including both\nmental health specific and general purpose models. To evaluate spiritual\nrelevance in generated responses beyond what conventional n-gram based metrics\ncapture, we propose a novel Spiritual Insight metric and automate assessment\nvia an LLM as jury framework using chain-of-thought prompting. Integrating\nspiritual guidance into AI driven support enhances both NLP and spiritual\nmetrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving\nimprovements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score,\n15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance\ncompared to its zero-shot counterpart. While these results reflect substantial\nimprovements across automated empathy and spirituality metrics, further\nvalidation in real world patient populations remains a necessary step. Our\nfindings indicate a strong potential for AI systems enriched with spiritual\nguidance to enhance user satisfaction and perceived support outcomes. The code\nand dataset will be publicly available to advance further research in this\nemerging area.", "published": "2025-06-23 23:02:57", "link": "http://arxiv.org/abs/2506.19185v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MOSCARD -- Causal Reasoning and De-confounding for Multimodal Opportunistic Screening of Cardiovascular Adverse Events", "abstract": "Major Adverse Cardiovascular Events (MACE) remain the leading cause of\nmortality globally, as reported in the Global Disease Burden Study 2021.\nOpportunistic screening leverages data collected from routine health check-ups\nand multimodal data can play a key role to identify at-risk individuals. Chest\nX-rays (CXR) provide insights into chronic conditions contributing to major\nadverse cardiovascular events (MACE), while 12-lead electrocardiogram (ECG)\ndirectly assesses cardiac electrical activity and structural abnormalities.\nIntegrating CXR and ECG could offer a more comprehensive risk assessment than\nconventional models, which rely on clinical scores, computed tomography (CT)\nmeasurements, or biomarkers, which may be limited by sampling bias and single\nmodality constraints. We propose a novel predictive modeling framework -\nMOSCARD, multimodal causal reasoning with co-attention to align two distinct\nmodalities and simultaneously mitigate bias and confounders in opportunistic\nrisk estimation. Primary technical contributions are - (i) multimodal alignment\nof CXR with ECG guidance; (ii) integration of causal reasoning; (iii) dual\nback-propagation graph for de-confounding. Evaluated on internal, shift data\nfrom emergency department (ED) and external MIMIC datasets, our model\noutperformed single modality and state-of-the-art foundational models - AUC:\n0.75, 0.83, 0.71 respectively. Proposed cost-effective opportunistic screening\nenables early intervention, improving patient outcomes and reducing\ndisparities.", "published": "2025-06-23 22:28:37", "link": "http://arxiv.org/abs/2506.19174v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PRISM: Perceptual Recognition for Identifying Standout Moments in Human-Centric Keyframe Extraction", "abstract": "Online videos play a central role in shaping political discourse and\namplifying cyber social threats such as misinformation, propaganda, and\nradicalization. Detecting the most impactful or \"standout\" moments in video\ncontent is crucial for content moderation, summarization, and forensic\nanalysis. In this paper, we introduce PRISM (Perceptual Recognition for\nIdentifying Standout Moments), a lightweight and perceptually-aligned framework\nfor keyframe extraction. PRISM operates in the CIELAB color space and uses\nperceptual color difference metrics to identify frames that align with human\nvisual sensitivity. Unlike deep learning-based approaches, PRISM is\ninterpretable, training-free, and computationally efficient, making it well\nsuited for real-time and resource-constrained environments. We evaluate PRISM\non four benchmark datasets: BBC, TVSum, SumMe, and ClipShots, and demonstrate\nthat it achieves strong accuracy and fidelity while maintaining high\ncompression ratios. These results highlight PRISM's effectiveness in both\nstructured and unstructured video content, and its potential as a scalable tool\nfor analyzing and moderating harmful or politically sensitive media in online\nplatforms.", "published": "2025-06-23 22:06:45", "link": "http://arxiv.org/abs/2506.19168v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Deep Learning Based Method for Fast Registration of Cardiac Magnetic Resonance Images", "abstract": "Image registration is used in many medical image analysis applications, such\nas tracking the motion of tissue in cardiac images, where cardiac kinematics\ncan be an indicator of tissue health. Registration is a challenging problem for\ndeep learning algorithms because ground truth transformations are not feasible\nto create, and because there are potentially multiple transformations that can\nproduce images that appear correlated with the goal. Unsupervised methods have\nbeen proposed to learn to predict effective transformations, but these methods\ntake significantly longer to predict than established baseline methods. For a\ndeep learning method to see adoption in wider research and clinical settings,\nit should be designed to run in a reasonable time on common, mid-level\nhardware. Fast methods have been proposed for the task of image registration\nbut often use patch-based methods which can affect registration accuracy for a\nhighly dynamic organ such as the heart.\n  In this thesis, a fast, volumetric registration model is proposed for the use\nof quantifying cardiac strain. The proposed Deep Learning Neural Network (DLNN)\nis designed to utilize an architecture that can compute convolutions incredibly\nefficiently, allowing the model to achieve registration fidelity similar to\nother state-of-the-art models while taking a fraction of the time to perform\ninference. The proposed fast and lightweight registration (FLIR) model is used\nto predict tissue motion which is then used to quantify the non-uniform strain\nexperienced by the tissue. For acquisitions taken from the same patient at\napproximately the same time, it would be expected that strain values measured\nbetween the acquisitions would have very small differences. Using this metric,\nstrain values computed using the FLIR method are shown to be very consistent.", "published": "2025-06-23 22:06:07", "link": "http://arxiv.org/abs/2506.19167v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Lightweight RGB-T Tracking with Mobile Vision Transformers", "abstract": "Single-modality object tracking (e.g., RGB-only) encounters difficulties in\nchallenging imaging conditions, such as low illumination and adverse weather\nconditions. To solve this, multimodal tracking (e.g., RGB-T models) aims to\nleverage complementary data such as thermal infrared features. While recent\nVision Transformer-based multimodal trackers achieve strong performance, they\nare often computationally expensive due to large model sizes. In this work, we\npropose a novel lightweight RGB-T tracking algorithm based on Mobile Vision\nTransformers (MobileViT). Our tracker introduces a progressive fusion framework\nthat jointly learns intra-modal and inter-modal interactions between the\ntemplate and search regions using separable attention. This design produces\neffective feature representations that support more accurate target\nlocalization while achieving a small model size and fast inference speed.\nCompared to state-of-the-art efficient multimodal trackers, our model achieves\ncomparable accuracy while offering significantly lower parameter counts (less\nthan 4 million) and the fastest GPU inference speed of 122 frames per second.\nThis paper is the first to propose a tracker using Mobile Vision Transformers\nfor RGB-T tracking and multimodal tracking at large. Tracker code and model\nweights will be made publicly available upon acceptance.", "published": "2025-06-23 21:46:22", "link": "http://arxiv.org/abs/2506.19154v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction", "abstract": "Recent advances in 3D Gaussian representations have significantly improved\nthe quality and efficiency of image-based scene reconstruction. Their explicit\nnature facilitates real-time rendering and fast optimization, yet extracting\naccurate surfaces - particularly in large-scale, unbounded environments -\nremains a difficult task. Many existing methods rely on approximate depth\nestimates and global sorting heuristics, which can introduce artifacts and\nlimit the fidelity of the reconstructed mesh. In this paper, we present Sorted\nOpacity Fields (SOF), a method designed to recover detailed surfaces from 3D\nGaussians with both speed and precision. Our approach improves upon prior work\nby introducing hierarchical resorting and a robust formulation of Gaussian\ndepth, which better aligns with the level-set. To enhance mesh quality, we\nincorporate a level-set regularizer operating on the opacity field and\nintroduce losses that encourage geometrically-consistent primitive shapes. In\naddition, we develop a parallelized Marching Tetrahedra algorithm tailored to\nour opacity formulation, reducing meshing time by up to an order of magnitude.\nAs demonstrated by our quantitative evaluation, SOF achieves higher\nreconstruction accuracy while cutting total processing time by more than a\nfactor of three. These results mark a step forward in turning efficient\nGaussian-based rendering into equally efficient geometry extraction.", "published": "2025-06-23 21:20:52", "link": "http://arxiv.org/abs/2506.19139v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "PrITTI: Primitive-based Generation of Controllable and Editable 3D Semantic Scenes", "abstract": "Large-scale 3D semantic scene generation has predominantly relied on\nvoxel-based representations, which are memory-intensive, bound by fixed\nresolutions, and challenging to edit. In contrast, primitives represent\nsemantic entities using compact, coarse 3D structures that are easy to\nmanipulate and compose, making them an ideal representation for this task. In\nthis paper, we introduce PrITTI, a latent diffusion-based framework that\nleverages primitives as the main foundational elements for generating\ncompositional, controllable, and editable 3D semantic scene layouts. Our method\nadopts a hybrid representation, modeling ground surfaces in a rasterized format\nwhile encoding objects as vectorized 3D primitives. This decomposition is also\nreflected in a structured latent representation that enables flexible scene\nmanipulation of ground and object components. To overcome the orientation\nambiguities in conventional encoding methods, we introduce a stable\nCholesky-based parameterization that jointly encodes object size and\norientation. Experiments on the KITTI-360 dataset show that PrITTI outperforms\na voxel-based baseline in generation quality, while reducing memory\nrequirements by up to $3\\times$. In addition, PrITTI enables direct\ninstance-level manipulation of objects in the scene and supports a range of\ndownstream applications, including scene inpainting, outpainting, and\nphoto-realistic street-view synthesis.", "published": "2025-06-23 20:47:18", "link": "http://arxiv.org/abs/2506.19117v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Staining normalization in histopathology: Method benchmarking using multicenter dataset", "abstract": "Hematoxylin and Eosin (H&E) has been the gold standard in tissue analysis for\ndecades, however, tissue specimens stained in different laboratories vary,\noften significantly, in appearance. This variation poses a challenge for both\npathologists' and AI-based downstream analysis. Minimizing stain variation\ncomputationally is an active area of research. To further investigate this\nproblem, we collected a unique multi-center tissue image dataset, wherein\ntissue samples from colon, kidney, and skin tissue blocks were distributed to\n66 different labs for routine H&E staining. To isolate staining variation,\nother factors affecting the tissue appearance were kept constant. Further, we\nused this tissue image dataset to compare the performance of eight different\nstain normalization methods, including four traditional methods, namely,\nhistogram matching, Macenko, Vahadane, and Reinhard normalization, and two deep\nlearning-based methods namely CycleGAN and Pixp2pix, both with two variants\neach. We used both quantitative and qualitative evaluation to assess the\nperformance of these methods. The dataset's inter-laboratory staining variation\ncould also guide strategies to improve model generalizability through varied\ntraining data", "published": "2025-06-23 20:37:40", "link": "http://arxiv.org/abs/2506.19106v1", "categories": ["eess.IV", "cs.CV", "q-bio.TO", "I.2.1; I.4.0"], "primary_category": "eess.IV"}
{"title": "Inverse-and-Edit: Effective and Fast Image Editing by Cycle Consistency Models", "abstract": "Recent advances in image editing with diffusion models have achieved\nimpressive results, offering fine-grained control over the generation process.\nHowever, these methods are computationally intensive because of their iterative\nnature. While distilled diffusion models enable faster inference, their editing\ncapabilities remain limited, primarily because of poor inversion quality.\nHigh-fidelity inversion and reconstruction are essential for precise image\nediting, as they preserve the structural and semantic integrity of the source\nimage. In this work, we propose a novel framework that enhances image inversion\nusing consistency models, enabling high-quality editing in just four steps. Our\nmethod introduces a cycle-consistency optimization strategy that significantly\nimproves reconstruction accuracy and enables a controllable trade-off between\neditability and content preservation. We achieve state-of-the-art performance\nacross various image editing tasks and datasets, demonstrating that our method\nmatches or surpasses full-step diffusion models while being substantially more\nefficient. The code of our method is available on GitHub at\nhttps://github.com/ControlGenAI/Inverse-and-Edit.", "published": "2025-06-23 20:34:43", "link": "http://arxiv.org/abs/2506.19103v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation", "abstract": "Automated detection of small and rare wildlife in aerial imagery is crucial\nfor effective conservation, yet remains a significant technical challenge.\nPrairie dogs exemplify this issue: their ecological importance as keystone\nspecies contrasts sharply with their elusive presence--marked by small size,\nsparse distribution, and subtle visual features--which undermines existing\ndetection approaches. To address these challenges, we propose RareSpot, a\nrobust detection framework integrating multi-scale consistency learning and\ncontext-aware augmentation. Our multi-scale consistency approach leverages\nstructured alignment across feature pyramids, enhancing fine-grained object\nrepresentation and mitigating scale-related feature loss. Complementarily,\ncontext-aware augmentation strategically synthesizes challenging training\ninstances by embedding difficult-to-detect samples into realistic environmental\ncontexts, significantly boosting model precision and recall. Evaluated on an\nexpert-annotated prairie dog drone imagery benchmark, our method achieves\nstate-of-the-art performance, improving detection accuracy by over 35% compared\nto baseline methods. Importantly, it generalizes effectively across additional\nwildlife datasets, demonstrating broad applicability. The RareSpot benchmark\nand approach not only support critical ecological monitoring but also establish\na new foundation for detecting small, rare species in complex aerial scenes.", "published": "2025-06-23 20:03:43", "link": "http://arxiv.org/abs/2506.19087v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Solution to a problem on isolation of $3$-vertex paths", "abstract": "The $3$-path isolation number of a connected $n$-vertex graph $G$, denoted by\n$\\iota(G,P_3)$, is the size of a smallest subset $D$ of the vertex set of $G$\nsuch that the closed neighbourhood $N[D]$ of $D$ in $G$ intersects each\n$3$-vertex path of $G$, meaning that no two edges of $G-N[D]$ intersect. Zhang\nand Wu proved that $\\iota(G,P_3) \\leq 2n/7$ unless $G$ is a $3$-path or a\n$3$-cycle or a $6$-cycle. The bound is attained by infinitely many graphs\nhaving induced $6$-cycles. Huang, Zhang and Jin proved that if $G$ has no\n$6$-cycles, or $G$ has no induced $5$-cycles and no induced $6$-cycles, then\n$\\iota(G, P_3) \\leq n/4$ unless $G$ is a $3$-path or a $3$-cycle or a $7$-cycle\nor an $11$-cycle. They asked if the bound still holds asymptotically for\nconnected graphs having no induced $6$-cycles. More precisely, taking $f(n)$ to\nbe the maximum value of $\\iota(G,P_3)$ over all connected $n$-vertex graphs $G$\nhaving no induced $6$-cycles, their question is whether $\\limsup_{n\n\\to\\infty}\\frac{f(n)}{n} = \\frac{1}{4}$. We verify this by proving that $f(n) =\n\\left \\lfloor (n+1)/4 \\right \\rfloor$. The proof hinges on further proving that\nif $G$ is such a graph and $\\iota(G, P_3) = (n+1)/4$, then $\\iota(G-v, P_3) <\n\\iota(G, P_3)$ for each vertex $v$ of $G$. This new idea promises to be of\nfurther use. We also prove that if the maximum degree of such a graph $G$ is at\nleast $5$, then $\\iota(G,P_3) \\leq n/4$.", "published": "2025-06-23 21:38:22", "link": "http://arxiv.org/abs/2506.19149v1", "categories": ["math.CO", "cs.DM", "05C35, 05C38, 05C69"], "primary_category": "math.CO"}
{"title": "Fast repetitivity in non-rectifiable Delone sets", "abstract": "We present a construction of non-rectifiable, repetitive Delone sets in every\nEuclidean space $\\mathbb{R}^d$ with $d \\geq 2$. We further obtain a close to\noptimal repetitivity function for such sets. The proof is based on the process\nof encoding a non-realisable density in a Delone set, due to Burago and\nKleiner.", "published": "2025-06-23 20:42:11", "link": "http://arxiv.org/abs/2506.19114v1", "categories": ["math.MG", "cs.DM", "math.FA", "51F23, 52C23, 51M05, 28A33, 30L05, 26B10"], "primary_category": "math.MG"}
{"title": "On reversible and reversible-complementary DNA codes over $\\mathbb{F}_{4}$", "abstract": "A method to construct and count all the linear codes (of arbitrary length) in\n$\\mathbb{F}_{4}$ that are invariant under reverse permutation and that contain\nthe repetition code is presented. These codes are suitable for constructing DNA\ncodes that satisfy the reverse and reverse-complement constraints. By analyzing\na module-theoretic structure of these codes, their generating matrices are\ncharacterized in terms of their isomorphism type, and explicit formulas for\ncounting them are provided. The proposed construction method based on this\ncharacterization outperforms the one given by Abualrub et al. for cyclic codes\n(of odd length) over $\\mathbb{F}_{4}$, and the counting method solves a problem\nthat can not be solved using the one given by Fripertinger for invariant\nsubspaces under a linear endomorphism of $\\mathbb{F}_{q}^{n}$. Additionally,\nseveral upper bounds and an identity for the minimum Hamming distance of\ncertain reversible codes are provided.", "published": "2025-06-23 22:10:15", "link": "http://arxiv.org/abs/2506.19170v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SIM-Enabled Hybrid Digital-Wave Beamforming for Fronthaul-Constrained Cell-Free Massive MIMO Systems", "abstract": "As the dense deployment of access points (APs) in cell-free massive\nmultiple-input multiple-output (CF-mMIMO) systems presents significant\nchallenges, per-AP coverage can be expanded using large-scale antenna arrays\n(LAAs). However, this approach incurs high implementation costs and substantial\nfronthaul demands due to the need for dedicated RF chains for all antennas. To\naddress these challenges, we propose a hybrid beamforming framework that\nintegrates wave-domain beamforming via stacked intelligent metasurfaces (SIM)\nwith conventional digital processing. By dynamically manipulating\nelectromagnetic waves, SIM-equipped APs enhance beamforming gains while\nsignificantly reducing RF chain requirements. We formulate a joint optimization\nproblem for digital and wave-domain beamforming along with fronthaul\ncompression to maximize the weighted sum-rate for both uplink and downlink\ntransmission under finite-capacity fronthaul constraints. Given the high\ndimensionality and non-convexity of the problem, we develop alternating\noptimization-based algorithms that iteratively optimize digital and wave-domain\nvariables. Numerical results demonstrate that the proposed hybrid schemes\noutperform conventional hybrid schemes, that rely on randomly set wave-domain\nbeamformers or restrict digital beamforming to simple power control. Moreover,\nthe proposed scheme employing sufficiently deep SIMs achieves near\nfully-digital performance with fewer RF chains in most simulated cases, except\nin the downlink at low signal-to-noise ratios.", "published": "2025-06-23 20:08:05", "link": "http://arxiv.org/abs/2506.19090v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Simulation of a closed-loop dc-dc converter using a physics-informed neural network-based model", "abstract": "The growing reliance on power electronics introduces new challenges requiring\ndetailed time-domain analyses with fast and accurate circuit simulation tools.\nCurrently, commercial time-domain simulation software are mainly relying on\nphysics-based methods to simulate power electronics. Recent work showed that\ndata-driven and physics-informed learning methods can increase simulation speed\nwith limited compromise on accuracy, but many challenges remain before\ndeployment in commercial tools can be possible. In this paper, we propose a\nphysics-informed bidirectional long-short term memory neural network\n(BiLSTM-PINN) model to simulate the time-domain response of a closed-loop dc-dc\nboost converter for various operating points, parameters, and perturbations. A\nphysics-informed fully-connected neural network (FCNN) and a BiLSTM are also\ntrained to establish a comparison. The three methods are then compared using\nstep-response tests to assess their performance and limitations in terms of\naccuracy. The results show that the BiLSTM-PINN and BiLSTM models outperform\nthe FCNN model by more than 9 and 4.5 times, respectively, in terms of median\nRMSE. Their standard deviation values are more than 2.6 and 1.7 smaller than\nthe FCNN's, making them also more consistent. Those results illustrate that the\nproposed BiLSTM-PINN is a potential alternative to other physics-based or\ndata-driven methods for power electronics simulations.", "published": "2025-06-23 22:44:56", "link": "http://arxiv.org/abs/2506.19178v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Distilling Tool Knowledge into Language Models via Back-Translated Traces", "abstract": "Large language models (LLMs) often struggle with mathematical problems that\nrequire exact computation or multi-step algebraic reasoning. Tool-integrated\nreasoning (TIR) offers a promising solution by leveraging external tools such\nas code interpreters to ensure correctness, but it introduces inference-time\ndependencies that hinder scalability and deployment. In this work, we propose a\nnew paradigm for distilling tool knowledge into LLMs purely through natural\nlanguage. We first construct a Solver Agent that solves math problems by\ninterleaving planning, symbolic tool calls, and reflective reasoning. Then,\nusing a back-translation pipeline powered by multiple LLM-based agents, we\nconvert interleaved TIR traces into natural language reasoning traces. A\nTranslator Agent generates explanations for individual tool calls, while a\nRephrase Agent merges them into a fluent and globally coherent narrative.\nEmpirically, we show that fine-tuning a small open-source model on these\nsynthesized traces enables it to internalize both tool knowledge and structured\nreasoning patterns, yielding gains on competition-level math benchmarks without\nrequiring tool access at inference.", "published": "2025-06-23 22:10:38", "link": "http://arxiv.org/abs/2506.19171v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Low-Cost Infrastructure-Free 3D Relative Localization with Sub-Meter Accuracy in Near Field", "abstract": "Relative localization in the near-field scenario is critically important for\nunmanned vehicle (UxV) applications. Although related works addressing 2D\nrelative localization problem have been widely studied for unmanned ground\nvehicles (UGVs), the problem in 3D scenarios for unmanned aerial vehicles\n(UAVs) involves more uncertainties and remains to be investigated. Inspired by\nthe phenomenon that animals can achieve swarm behaviors solely based on\nindividual perception of relative information, this study proposes an\ninfrastructure-free 3D relative localization framework that relies exclusively\non onboard ultra-wideband (UWB) sensors. Leveraging 2D relative positioning\nresearch, we conducted feasibility analysis, system modeling, simulations,\nperformance evaluation, and field tests using UWB sensors. The key\ncontributions of this work include: derivation of the Cram\\'er-Rao lower bound\n(CRLB) and geometric dilution of precision (GDOP) for near-field scenarios;\ndevelopment of two localization algorithms -- one based on Euclidean distance\nmatrix (EDM) and another employing maximum likelihood estimation (MLE);\ncomprehensive performance comparison and computational complexity analysis\nagainst state-of-the-art methods; simulation studies and field experiments; a\nnovel sensor deployment strategy inspired by animal behavior, enabling\nsingle-sensor implementation within the proposed framework for UxV\napplications. The theoretical, simulation, and experimental results demonstrate\nstrong generalizability to other 3D near-field localization tasks, with\nsignificant potential for a cost-effective cross-platform UxV collaborative\nsystem.", "published": "2025-06-23 23:58:06", "link": "http://arxiv.org/abs/2506.19199v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Online Learning for Dynamic Vickrey-Clarke-Groves Mechanism in Sequential Auctions under Unknown Environments", "abstract": "We consider the problem of online dynamic mechanism design for sequential\nauctions in unknown environments, where the underlying market and, thus, the\nbidders' values vary over time as interactions between the seller and the\nbidders progress. We model the sequential auctions as an infinite-horizon\naverage-reward Markov decision process (MDP), where the transition kernel and\nreward functions are unknown to the seller. In each round, the seller\ndetermines an allocation and a payment for each bidder. Each bidder receives a\nprivate reward and submits a sealed bid to the seller. The state, which\nrepresents the underlying market, evolves according to an unknown transition\nkernel and the seller's allocation policy. Unlike existing works that formulate\nthe problem as a multi-armed bandit model or as an episodic MDP, where the\nenvironment resets to an initial state after each round or episode, our paper\nconsiders a more realistic and sophisticated setting in which the market\ncontinues to evolve without restarting. We first extend the\nVickrey-Clarke-Groves (VCG) mechanism, which is known to be efficient,\ntruthful, and individually rational for one-shot static auctions, to sequential\nauctions, thereby obtaining a dynamic VCG mechanism counterpart that preserves\nthese desired properties. We then focus on the online setting and develop an\nonline reinforcement learning algorithm for the seller to learn the underlying\nMDP model and implement a mechanism that closely resembles the dynamic VCG\nmechanism. We show that the learned online mechanism asymptotically converges\nto a dynamic mechanism that approximately satisfies efficiency, truthfulness,\nand individual rationality with arbitrarily high probability and achieves\nguaranteed performance in terms of various notions of regret.", "published": "2025-06-23 18:52:32", "link": "http://arxiv.org/abs/2506.19038v1", "categories": ["cs.GT", "cs.LG", "cs.MA", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.GT"}
{"title": "On the algorithmic construction of deep ReLU networks", "abstract": "It is difficult to describe in mathematical terms what a neural network\ntrained on data represents. On the other hand, there is a growing mathematical\nunderstanding of what neural networks are in principle capable of representing.\nFeedforward neural networks using the ReLU activation function represent\ncontinuous and piecewise linear functions and can approximate many others. The\nstudy of their expressivity addresses the question: which ones? Contributing to\nthe available answers, we take the perspective of a neural network as an\nalgorithm. In this analogy, a neural network is programmed constructively,\nrather than trained from data. An interesting example is a sorting algorithm:\nwe explicitly construct a neural network that sorts its inputs exactly, not\napproximately, and that, in a sense, has optimal computational complexity if\nthe input dimension is large. Such constructed networks may have several\nbillion parameters. We construct and analyze several other examples, both\nexisting and new. We find that, in these examples, neural networks as\nalgorithms are typically recursive and parallel. Compared to conventional\nalgorithms, ReLU networks are restricted by having to be continuous. Moreover,\nthe depth of recursion is limited by the depth of the network, with deep\nnetworks having superior properties over shallow ones.", "published": "2025-06-23 20:35:52", "link": "http://arxiv.org/abs/2506.19104v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65D15 (Primary) 68T07 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Modular data assimilation for flow prediction", "abstract": "This report develops several modular, 2-step realizations (inspired by Kalman\nfilter algorithms) of nudging-based data assimilation \\begin{equation*}\n\\begin{array}{cc} Step{{{\\text { }}}}1 & \\begin{array}{c} \\frac{\\widetilde\n{v}^{n+1}-v^{n}}{k}+v^{n}\\cdot \\nabla \\widetilde {v}% ^{n+1}-\\nu \\triangle\n\\widetilde {v}^{n+1}+\\nabla q^{n+1}=f(x){{{{\\text { }}}}% } \\\\ \\nabla \\cdot\n\\widetilde {v}^{n+1}=0% \\end{array} \\\\ Step{{{\\text { }}}}2 &\n\\frac{v^{n+1}-\\widetilde {v}^{n+1}}{k}-\\chi I_{H}(u(t^{n+1})-v^{n+1})=0.%\n\\end{array}% \\end{equation*} Several variants of this algorithm are developed.\nThree main results are developed. The first is that if $I_{H}^{2}=I_{H}$, then\nStep 2 can be rewritten as the explicit step \\begin{equation*}\nv^{n+1}=\\widetilde {v}^{n+1}+\\frac{k\\chi }{1+k\\chi }[I_{H}u(t^{n+1})-I_{H}%\n\\widetilde {v}^{n+1}]. \\end{equation*} This means Step 2 has the greater\nstability of an implicit update and the lesser complexity of an explicit\nanalysis step. The second is that the basic result of nudging (that for $H$\n\\textit{small enough} and $\\chi $\\ \\textit{large enough} predictability\nhorizons are infinite) holds for one variant of the modular algorithm. The\nthird is that, for \\textit{any} $H>0$ and \\textit{any} $\\chi>0$, one step of\nthe modular algorithm decreases the next step's error and \\textit{increases}\n(an estimate of) predictability horizons. A method synthesizing assimilation\nwith eddy viscosity models of turbulence is also presented. Numerical tests are\ngiven, confirming the effectiveness of the modular assimilation algorithm. The\nconclusion is that the modular, 2-step method overcomes many algorithmic\ninadequacies of standard nudging methods and retains a robust mathematical\nfoundation.", "published": "2025-06-23 18:01:48", "link": "http://arxiv.org/abs/2506.19002v1", "categories": ["math.NA", "cs.NA", "65M12, 37L99, 76D55"], "primary_category": "math.NA"}
{"title": "Numerical analysis of scattered point measurement-based regularization for backward problems for fractional wave equations", "abstract": "In this work, our aim is to reconstruct the unknown initial value from\nterminal data. We develop a numerical framework on nonuniform time grids for\nfractional wave equations under the lower regularity assumptions. Then, we\nintroduce a regularization method that effectively handles scattered point\nmeasurements contaminated with stochastic noise. The optimal error estimates of\nstochastic convergence not only balance discretization errors, the noise, and\nthe number of observation points, but also propose an a priori choice of\nregularization parameters. Finally, several numerical experiments are presented\nto demonstrate the efficiency and accuracy of the algorithm.", "published": "2025-06-23 05:37:39", "link": "http://arxiv.org/abs/2506.18948v1", "categories": ["math.NA", "cs.NA", "35R11"], "primary_category": "math.NA"}
{"title": "Making Leveraged Exchange-Traded Funds Work for your Portfolio", "abstract": "We examine strategically incorporating broad stock market leveraged\nexchange-traded funds (LETFs) into investment portfolios. We demonstrate that\neasily understandable and implementable strategies can enhance the risk-return\nprofile of a portfolio containing LETFs. Our analysis shows that seemingly\nreasonable investment strategies may result in undesirable Omega ratios, with\nthese effects compounding across rebalancing periods. By contrast, relatively\nsimple dynamic strategies that systematically de-risk the portfolio once gains\nare observed can exploit this compounding effect, taking advantage of favorable\nOmega ratio dynamics. Our findings suggest that LETFs represent a valuable tool\nfor investors employing dynamic strategies, while confirming their\nwell-documented unsuitability for passive or static approaches.", "published": "2025-06-23 23:59:03", "link": "http://arxiv.org/abs/2506.19200v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "From Minimax Optimal Importance Sampling to Uniformly Ergodic Importance-tempered MCMC", "abstract": "We make two closely related theoretical contributions to the use of\nimportance sampling schemes. First, for independent sampling, we prove that the\nminimax optimal trial distribution coincides with the target if and only if the\ntarget distribution has no atom with probability greater than $1/2$, where\n\"minimax\" means that the worst-case asymptotic variance of the self-normalized\nimportance sampling estimator is minimized. When a large atom exists, it should\nbe downweighted by the trial distribution. A similar phenomenon holds for a\ncontinuous target distribution concentrated on a small set. Second, we argue\nthat it is often advantageous to run the Metropolis--Hastings algorithm with a\ntempered stationary distribution, $\\pi(x)^\\beta$, and correct for the bias by\nimportance weighting. The dynamics of this \"importance-tempered\" sampling\nscheme can be described by a continuous-time Markov chain. We prove that for\none-dimensional targets with polynomial tails, $\\pi(x) \\propto (1 +\n|x|)^{-\\gamma}$, this chain is uniformly ergodic if and only if $1/\\gamma <\n\\beta < (\\gamma - 2)/\\gamma$. These results suggest that for target\ndistributions with light or polynomial tails of order $\\gamma > 3$, importance\ntempering can improve the precision of time-average estimators and essentially\neliminate the need for burn-in.", "published": "2025-06-23 23:05:06", "link": "http://arxiv.org/abs/2506.19186v1", "categories": ["stat.CO", "math.PR", "stat.ML", "65C05, 60J25"], "primary_category": "stat.CO"}
{"title": "Posterior Contraction for Sparse Neural Networks in Besov Spaces with Intrinsic Dimensionality", "abstract": "This work establishes that sparse Bayesian neural networks achieve optimal\nposterior contraction rates over anisotropic Besov spaces and their\nhierarchical compositions. These structures reflect the intrinsic\ndimensionality of the underlying function, thereby mitigating the curse of\ndimensionality. Our analysis shows that Bayesian neural networks equipped with\neither sparse or continuous shrinkage priors attain the optimal rates which are\ndependent on the intrinsic dimension of the true structures. Moreover, we show\nthat these priors enable rate adaptation, allowing the posterior to contract at\nthe optimal rate even when the smoothness level of the true function is\nunknown. The proposed framework accommodates a broad class of functions,\nincluding additive and multiplicative Besov functions as special cases. These\nresults advance the theoretical foundations of Bayesian neural networks and\nprovide rigorous justification for their practical effectiveness in\nhigh-dimensional, structured estimation problems.", "published": "2025-06-23 21:29:40", "link": "http://arxiv.org/abs/2506.19144v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Inferring Diffusion Structures of Heterogeneous Network Cascade", "abstract": "Network cascade refers to diffusion processes in which outcome changes within\npart of an interconnected population trigger a sequence of changes across the\nentire network. These cascades are governed by underlying diffusion networks,\nwhich are often latent. Inferring such networks is critical for understanding\ncascade pathways, uncovering Granger causality of interaction mechanisms among\nindividuals, and enabling tasks such as forecasting or maximizing information\npropagation. In this project, we propose a novel double mixture directed graph\nmodel for inferring multi-layer diffusion networks from cascade data. The\nproposed model represents cascade pathways as a mixture of diffusion networks\nacross different layers, effectively capturing the strong heterogeneity present\nin real-world cascades. Additionally, the model imposes layer-specific\nstructural constraints, enabling diffusion networks at different layers to\ncapture complementary cascading patterns at the population level. A key\nadvantage of our model is its convex formulation, which allows us to establish\nboth statistical and computational guarantees for the resulting diffusion\nnetwork estimates. We conduct extensive simulation studies to demonstrate the\nmodel's performance in recovering diverse diffusion structures. Finally, we\napply the proposed method to analyze cascades of research topics in the social\nsciences across U.S. universities, revealing the underlying diffusion networks\nof research topic propagation among institutions.", "published": "2025-06-23 21:26:19", "link": "http://arxiv.org/abs/2506.19142v1", "categories": ["cs.SI", "stat.ML"], "primary_category": "cs.SI"}
{"title": "Riemannian generative decoder", "abstract": "Riemannian representation learning typically relies on approximating\ndensities on chosen manifolds. This involves optimizing difficult objectives,\npotentially harming models. To completely circumvent this issue, we introduce\nthe Riemannian generative decoder which finds manifold-valued maximum\nlikelihood latents with a Riemannian optimizer while training a decoder\nnetwork. By discarding the encoder, we vastly simplify the manifold constraint\ncompared to current approaches which often only handle few specific manifolds.\nWe validate our approach on three case studies -- a synthetic branching\ndiffusion process, human migrations inferred from mitochondrial DNA, and cells\nundergoing a cell division cycle -- each showing that learned representations\nrespect the prescribed geometry and capture intrinsic non-Euclidean structure.\nOur method requires only a decoder, is compatible with existing architectures,\nand yields interpretable latent spaces aligned with data geometry.", "published": "2025-06-23 21:06:13", "link": "http://arxiv.org/abs/2506.19133v1", "categories": ["cs.LG", "q-bio.QM", "stat.ML", "68T07 (Primary) 62H30, 53B21, 92C37 (Secondary)", "I.2.6; I.5.4; G.1.6; G.3; J.3"], "primary_category": "cs.LG"}
{"title": "When Diffusion Models Memorize: Inductive Biases in Probability Flow of Minimum-Norm Shallow Neural Nets", "abstract": "While diffusion models generate high-quality images via probability flow, the\ntheoretical understanding of this process remains incomplete. A key question is\nwhen probability flow converges to training samples or more general points on\nthe data manifold. We analyze this by studying the probability flow of shallow\nReLU neural network denoisers trained with minimal $\\ell^2$ norm. For\nintuition, we introduce a simpler score flow and show that for orthogonal\ndatasets, both flows follow similar trajectories, converging to a training\npoint or a sum of training points. However, early stopping by the diffusion\ntime scheduler allows probability flow to reach more general manifold points.\nThis reflects the tendency of diffusion models to both memorize training\nsamples and generate novel points that combine aspects of multiple samples,\nmotivating our study of such behavior in simplified settings. We extend these\nresults to obtuse simplex data and, through simulations in the orthogonal case,\nconfirm that probability flow converges to a training point, a sum of training\npoints, or a manifold point. Moreover, memorization decreases when the number\nof training samples grows, as fewer samples accumulate near training points.", "published": "2025-06-23 18:38:55", "link": "http://arxiv.org/abs/2506.19031v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "abstract": "In many applications of optimal transport (OT), the object of primary\ninterest is the optimal transport map. This map rearranges mass from one\nprobability distribution to another in the most efficient way possible by\nminimizing a specified cost. In this paper we review recent advances in\nestimating and developing limit theorems for the OT map, using samples from the\nunderlying distributions. We also review parallel lines of work that establish\nsimilar results for special cases and variants of the basic OT setup. We\nconclude with a discussion of key directions for future research with the goal\nof providing practitioners with reliable inferential tools.", "published": "2025-06-23 18:28:48", "link": "http://arxiv.org/abs/2506.19025v1", "categories": ["math.ST", "cs.AI", "cs.LG", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Simulation-Based Sensitivity Analysis in Optimal Treatment Regimes and Causal Decomposition with Individualized Interventions", "abstract": "Causal decomposition analysis aims to assess the effect of modifying risk\nfactors on reducing social disparities in outcomes. Recently, this analysis has\nincorporated individual characteristics when modifying risk factors by\nutilizing optimal treatment regimes (OTRs). Since the newly defined\nindividualized effects rely on the no omitted confounding assumption,\ndeveloping sensitivity analyses to account for potential omitted confounding is\nessential. Moreover, OTRs and individualized effects are primarily based on\nbinary risk factors, and no formal approach currently exists to benchmark the\nstrength of omitted confounding using observed covariates for binary risk\nfactors. To address this gap, we extend a simulation-based sensitivity analysis\nthat simulates unmeasured confounders, addressing two sources of bias emerging\nfrom deriving OTRs and estimating individualized effects. Additionally, we\npropose a formal bounding strategy that benchmarks the strength of omitted\nconfounding for binary risk factors. Using the High School Longitudinal Study\n2009 (HSLS:09), we demonstrate this sensitivity analysis and benchmarking\nmethod.", "published": "2025-06-23 18:05:30", "link": "http://arxiv.org/abs/2506.19010v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Causal Decomposition Analysis with Synergistic Interventions: A Triply-Robust Machine Learning Approach to Addressing Multiple Dimensions of Social Disparities", "abstract": "Educational disparities are rooted in and perpetuate social inequalities\nacross multiple dimensions such as race, socioeconomic status, and geography.\nTo reduce disparities, most intervention strategies focus on a single domain\nand frequently evaluate their effectiveness by using causal decomposition\nanalysis. However, a growing body of research suggests that single-domain\ninterventions may be insufficient for individuals marginalized on multiple\nfronts. While interventions across multiple domains are increasingly proposed,\nthere is limited guidance on appropriate methods for evaluating their\neffectiveness. To address this gap, we develop an extended causal decomposition\nanalysis that simultaneously targets multiple causally ordered intervening\nfactors, allowing for the assessment of their synergistic effects. These\nscenarios often involve challenges related to model misspecification due to\ncomplex interactions among group categories, intervening factors, and their\nconfounders with the outcome. To mitigate these challenges, we introduce a\ntriply robust estimator that leverages machine learning techniques to address\npotential model misspecification. We apply our method to a cohort of students\nfrom the High School Longitudinal Study, focusing on math achievement\ndisparities between Black, Hispanic, and White high schoolers. Specifically, we\nexamine how two sequential interventions - equalizing the proportion of\nstudents who attend high-performing schools and equalizing enrollment in\nAlgebra I by 9th grade across racial groups - may reduce these disparities.", "published": "2025-06-23 18:00:50", "link": "http://arxiv.org/abs/2506.18994v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection", "abstract": "Advancements in audio deepfake technology offers benefits like AI assistants,\nbetter accessibility for speech impairments, and enhanced entertainment.\nHowever, it also poses significant risks to security, privacy, and trust in\ndigital communications. Detecting and mitigating these threats requires\ncomprehensive datasets. Existing datasets lack diverse ethnic accents, making\nthem inadequate for many real-world scenarios. Consequently, models trained on\nthese datasets struggle to detect audio deepfakes in diverse linguistic and\ncultural contexts such as in South-Asian countries. Ironically, there is a\nstark lack of South-Asian speaker samples in the existing datasets despite\nconstituting a quarter of the worlds population. This work introduces the\nIndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio\nfrom 50 English speaking Indian speakers. IFD offers balanced data distribution\nand includes speaker-level characterization, absent in datasets like ASVspoof21\n(DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF)\nand In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to\nbe more challenging compared to benchmark ITW dataset. The dataset will be\npublicly available upon acceptance.", "published": "2025-06-23 18:10:06", "link": "http://arxiv.org/abs/2506.19014v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer", "abstract": "This paper describes a sound source localization (SSL) technique that\ncombines an $\\alpha$-stable model for the observed signal with a neural\nnetwork-based approach for modeling steering vectors. Specifically, a\nphysics-informed neural network, referred to as Neural Steerer, is used to\ninterpolate measured steering vectors (SVs) on a fixed microphone array. This\nallows for a more robust estimation of the so-called $\\alpha$-stable spatial\nmeasure, which represents the most plausible direction of arrival (DOA) of a\ntarget signal. As an $\\alpha$-stable model for the non-Gaussian case ($\\alpha$\n$\\in$ (0, 2)) theoretically defines a unique spatial measure, we choose to\nleverage it to account for residual reconstruction error of the Neural Steerer\nin the downstream tasks. The objective scores indicate that our proposed\ntechnique outperforms state-of-the-art methods in the case of multiple sound\nsources.", "published": "2025-06-23 13:11:29", "link": "http://arxiv.org/abs/2506.18954v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EEG Foundation Challenge: From Cross-Task to Cross-Subject EEG Decoding", "abstract": "Current electroencephalogram (EEG) decoding models are typically trained on\nsmall numbers of subjects performing a single task. Here, we introduce a\nlarge-scale, code-submission-based competition comprising two challenges.\nFirst, the Transfer Challenge asks participants to build and test a model that\ncan zero-shot decode new tasks and new subjects from their EEG data. Second,\nthe Psychopathology factor prediction Challenge asks participants to infer\nsubject measures of mental health from EEG data. For this, we use an\nunprecedented, multi-terabyte dataset of high-density EEG signals (128\nchannels) recorded from over 3,000 child to young adult subjects engaged in\nmultiple active and passive tasks. We provide several tunable neural network\nbaselines for each of these two challenges, including a simple network and\ndemographic-based regression models. Developing models that generalise across\ntasks and individuals will pave the way for ML network architectures capable of\nadapting to EEG data collected from diverse tasks and individuals. Similarly,\npredicting mental health-relevant personality trait values from EEG might\nidentify objective biomarkers useful for clinical diagnosis and design of\npersonalised treatment for psychological conditions. Ultimately, the advances\nspurred by this challenge could contribute to the development of computational\npsychiatry and useful neurotechnology, and contribute to breakthroughs in both\nfundamental neuroscience and applied clinical research.", "published": "2025-06-23 21:25:19", "link": "http://arxiv.org/abs/2506.19141v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Thought Anchors: Which LLM Reasoning Steps Matter?", "abstract": "Reasoning large language models have recently achieved state-of-the-art\nperformance in many fields. However, their long-form chain-of-thought reasoning\ncreates interpretability challenges as each generated token depends on all\nprevious ones, making the computation harder to decompose. We argue that\nanalyzing reasoning traces at the sentence level is a promising approach to\nunderstanding reasoning processes. We present three complementary attribution\nmethods: (1) a black-box method measuring each sentence's counterfactual\nimportance by comparing final answers across 100 rollouts conditioned on the\nmodel generating that sentence or one with a different meaning; (2) a white-box\nmethod of aggregating attention patterns between pairs of sentences, which\nidentified \"broadcasting\" sentences that receive disproportionate attention\nfrom all future sentences via \"receiver\" attention heads; (3) a causal\nattribution method measuring logical connections between sentences by\nsuppressing attention toward one sentence and measuring the effect on each\nfuture sentence's tokens. Each method provides evidence for the existence of\nthought anchors, reasoning steps that have outsized importance and that\ndisproportionately influence the subsequent reasoning process. These thought\nanchors are typically planning or backtracking sentences. We provide an\nopen-source tool (www.thought-anchors.com) for visualizing the outputs of our\nmethods, and present a case study showing converging patterns across methods\nthat map how a model performs multi-step reasoning. The consistency across\nmethods demonstrates the potential of sentence-level analysis for a deeper\nunderstanding of reasoning models.", "published": "2025-06-23 21:28:45", "link": "http://arxiv.org/abs/2506.19143v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "abstract": "Large Language Models (LLMs) often generate responses with inherent biases,\nundermining their reliability in real-world applications. Existing evaluation\nmethods often overlook biases in long-form responses and the intrinsic\nvariability of LLM outputs. To address these challenges, we propose\nFiSCo(Fine-grained Semantic Computation), a novel statistical framework to\nevaluate group-level fairness in LLMs by detecting subtle semantic differences\nin long-form responses across demographic groups. Unlike prior work focusing on\nsentiment or token-level comparisons, FiSCo goes beyond surface-level analysis\nby operating at the claim level, leveraging entailment checks to assess the\nconsistency of meaning across responses. We decompose model outputs into\nsemantically distinct claims and apply statistical hypothesis testing to\ncompare inter- and intra-group similarities, enabling robust detection of\nsubtle biases. We formalize a new group counterfactual fairness definition and\nvalidate FiSCo on both synthetic and human-annotated datasets spanning gender,\nrace, and age. Experiments show that FiSco more reliably identifies nuanced\nbiases while reducing the impact of stochastic LLM variability, outperforming\nvarious evaluation metrics.", "published": "2025-06-23 18:31:22", "link": "http://arxiv.org/abs/2506.19028v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "OmniGen2: Exploration to Advanced Multimodal Generation", "abstract": "In this work, we introduce OmniGen2, a versatile and open-source generative\nmodel designed to provide a unified solution for diverse generation tasks,\nincluding text-to-image, image editing, and in-context generation. Unlike\nOmniGen v1, OmniGen2 features two distinct decoding pathways for text and image\nmodalities, utilizing unshared parameters and a decoupled image tokenizer. This\ndesign enables OmniGen2 to build upon existing multimodal understanding models\nwithout the need to re-adapt VAE inputs, thereby preserving the original text\ngeneration capabilities. To facilitate the training of OmniGen2, we developed\ncomprehensive data construction pipelines, encompassing image editing and\nin-context generation data. Additionally, we introduce a reflection mechanism\ntailored for image generation tasks and curate a dedicated reflection dataset\nbased on OmniGen2. Despite its relatively modest parameter size, OmniGen2\nachieves competitive results on multiple task benchmarks, including\ntext-to-image and image editing. To further evaluate in-context generation,\nalso referred to as subject-driven tasks, we introduce a new benchmark named\nOmniContext. OmniGen2 achieves state-of-the-art performance among open-source\nmodels in terms of consistency. We will release our models, training code,\ndatasets, and data construction pipeline to support future research in this\nfield. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:\nhttps://github.com/VectorSpaceLab/OmniGen2", "published": "2025-06-23 17:38:54", "link": "http://arxiv.org/abs/2506.18871v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "American options valuation in time-dependent jump-diffusion models via integral equations and characteristic functions", "abstract": "Despite significant advancements in machine learning for derivative pricing,\nthe efficient and accurate valuation of American options remains a persistent\nchallenge due to complex exercise boundaries, near-expiry behavior, and\nintricate contractual features. This paper extends a semi-analytical approach\nfor pricing American options in time-inhomogeneous models, including pure\ndiffusions, jump-diffusions, and Levy processes. Building on prior work, we\nderive and solve Volterra integral equations of the second kind to determine\nthe exercise boundary explicitly, offering a computationally superior\nalternative to traditional finite-difference and Monte Carlo methods. We\naddress key open problems: (1) extending the decomposition method, i.e.\nsplitting the American option price into its European counterpart and an early\nexercise premium, to general jump-diffusion and Levy models; (2) handling cases\nwhere closed-form transition densities are unavailable by leveraging\ncharacteristic functions via, e.g., the COS method; and (3) generalizing the\nframework to multidimensional diffusions. Numerical examples demonstrate the\nmethod's efficiency and robustness. Our results underscore the advantages of\nthe integral equation approach for large-scale industrial applications, while\nresolving some limitations of existing techniques.", "published": "2025-06-23 00:13:08", "link": "http://arxiv.org/abs/2506.18210v2", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography", "abstract": "Music-driven dance generation has garnered significant attention due to its\nwide range of industrial applications, particularly in the creation of group\nchoreography. During the group dance generation process, however, most existing\nmethods still face three primary issues: multi-dancer collisions, single-dancer\nfoot sliding and abrupt swapping in the generation of long group dance. In this\npaper, we propose TCDiff++, a music-driven end-to-end framework designed to\ngenerate harmonious group dance. Specifically, to mitigate multi-dancer\ncollisions, we utilize a dancer positioning embedding to better maintain the\nrelative positioning among dancers. Additionally, we incorporate a\ndistance-consistency loss to ensure that inter-dancer distances remain within\nplausible ranges. To address the issue of single-dancer foot sliding, we\nintroduce a swap mode embedding to indicate dancer swapping patterns and design\na Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For\nlong group dance generation, we present a long group diffusion sampling\nstrategy that reduces abrupt position shifts by injecting positional\ninformation into the noisy input. Furthermore, we integrate a Sequence Decoder\nlayer to enhance the model's ability to selectively process long sequences.\nExtensive experiments demonstrate that our TCDiff++ achieves state-of-the-art\nperformance, particularly in long-duration scenarios, ensuring high-quality and\ncoherent group dance generation.", "published": "2025-06-23 14:15:20", "link": "http://arxiv.org/abs/2506.18671v2", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Finite-Time Information-Theoretic Bounds in Queueing Control", "abstract": "We establish the first finite-time information-theoretic lower bounds-and\nderive new policies that achieve them-for the total queue length in scheduling\nproblems over stochastic processing networks with both adversarial and\nstochastic arrivals. Prior analyses of MaxWeight guarantee only stability and\nasymptotic optimality in heavy traffic; we prove that, at finite horizons,\nMaxWeight can incur strictly larger backlog by problem-dependent factors which\nwe identify. Our main innovations are 1) a minimax framework that pinpoints the\nprecise problem parameters governing any policy's finite-time performance; 2)\nan information-theoretic lower bound on total queue length; 3) fundamental\nlimitation of MaxWeight that it is suboptimal in finite time; and 4) a new\nscheduling rule that minimizes the full Lyapunov drift-including its\nsecond-order term-thereby matching the lower bound under certain conditions, up\nto universal constants. These findings reveal a fundamental limitation on\n\"drift-only\" methods and points the way toward principled, non-asymptotic\noptimality in queueing control.", "published": "2025-06-23 04:14:40", "link": "http://arxiv.org/abs/2506.18278v1", "categories": ["math.OC", "cs.IT", "cs.LG", "math.IT"], "primary_category": "math.OC"}
{"title": "Speaker Embeddings to Improve Tracking of Intermittent and Moving Speakers", "abstract": "Speaker tracking methods often rely on spatial observations to assign\ncoherent track identities over time. This raises limits in scenarios with\nintermittent and moving speakers, i.e., speakers that may change position when\nthey are inactive, thus leading to discontinuous spatial trajectories. This\npaper proposes to investigate the use of speaker embeddings, in a simple\nsolution to this issue. We propose to perform identity reassignment\npost-tracking, using speaker embeddings. We leverage trajectory-related\ninformation provided by an initial tracking step and multichannel audio signal.\nBeamforming is used to enhance the signal towards the speakers' positions in\norder to compute speaker embeddings. These are then used to assign new track\nidentities based on an enrollment pool. We evaluate the performance of the\nproposed speaker embedding-based identity reassignment method on a dataset\nwhere speakers change position during inactivity periods. Results show that it\nconsistently improves the identity assignment performance of neural and\nstandard tracking systems. In particular, we study the impact of beamforming\nand input duration for embedding extraction.", "published": "2025-06-23 13:02:20", "link": "http://arxiv.org/abs/2506.19875v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "RL-Driven Semantic Compression Model Selection and Resource Allocation in Semantic Communication Systems", "abstract": "Semantic communication (SemCom) is an emerging paradigm that leverages\nsemantic-level understanding to improve communication efficiency, particularly\nin resource-constrained scenarios. However, existing SemCom systems often\noverlook diverse computational and communication capabilities and requirements\namong different users. Motivated by the need to adaptively balance semantic\naccuracy, latency, and energy consumption, this paper presents a reinforcement\nlearning (RL)-driven framework for semantic compression model (SCM) selection\nand resource allocation in multi-user SemCom systems. To address the challenges\nof balancing image reconstruction quality and communication performance, a\nsystem-level optimization metric called Rate-Distortion Efficiency (RDE) has\nbeen defined. The framework considers multiple SCMs with varying complexity and\nresource requirements. A proximal policy optimization (PPO)-based RL approach\nis developed to dynamically select SCMs and allocate bandwidth and power under\nnon-convex constraints. Simulations demonstrate that the proposed method\noutperforms several baseline strategies. This paper also discusses the\ngeneralization ability, computational complexity, scalability, and practical\nimplications of the framework for real-world SemCom systems.", "published": "2025-06-23 14:02:01", "link": "http://arxiv.org/abs/2506.18660v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "abstract": "Information retrieval is a cornerstone of modern knowledge acquisition,\nenabling billions of queries each day across diverse domains. However,\ntraditional keyword-based search engines are increasingly inadequate for\nhandling complex, multi-step information needs. Our position is that Large\nLanguage Models (LLMs), endowed with reasoning and agentic capabilities, are\nushering in a new paradigm termed Agentic Deep Research. These systems\ntranscend conventional information search techniques by tightly integrating\nautonomous reasoning, iterative retrieval, and information synthesis into a\ndynamic feedback loop. We trace the evolution from static web search to\ninteractive, agent-based systems that plan, explore, and learn. We also\nintroduce a test-time scaling law to formalize the impact of computational\ndepth on reasoning and search. Supported by benchmark results and the rise of\nopen-source implementations, we demonstrate that Agentic Deep Research not only\nsignificantly outperforms existing approaches, but is also poised to become the\ndominant paradigm for future information seeking. All the related resources,\nincluding industry products, research papers, benchmark datasets, and\nopen-source implementations, are collected for the community in\nhttps://github.com/DavidZWZ/Awesome-Deep-Research.", "published": "2025-06-23 17:27:19", "link": "http://arxiv.org/abs/2506.18959v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining", "abstract": "Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.", "published": "2025-06-23 01:04:29", "link": "http://arxiv.org/abs/2506.18221v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection", "abstract": "Advancements in audio deepfake technology offers benefits like AI assistants,\nbetter accessibility for speech impairments, and enhanced entertainment.\nHowever, it also poses significant risks to security, privacy, and trust in\ndigital communications. Detecting and mitigating these threats requires\ncomprehensive datasets. Existing datasets lack diverse ethnic accents, making\nthem inadequate for many real-world scenarios. Consequently, models trained on\nthese datasets struggle to detect audio deepfakes in diverse linguistic and\ncultural contexts such as in South-Asian countries. Ironically, there is a\nstark lack of South-Asian speaker samples in the existing datasets despite\nconstituting a quarter of the worlds population. This work introduces the\nIndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio\nfrom 50 English speaking Indian speakers. IFD offers balanced data distribution\nand includes speaker-level characterization, absent in datasets like ASVspoof21\n(DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF)\nand In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to\nbe more challenging compared to benchmark ITW dataset. The complete dataset,\nalong with documentation and sample reference clips, is publicly accessible for\nresearch use on project website.", "published": "2025-06-23 18:10:06", "link": "http://arxiv.org/abs/2506.19014v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography", "abstract": "Music-driven dance generation has garnered significant attention due to its\nwide range of industrial applications, particularly in the creation of group\nchoreography. During the group dance generation process, however, most existing\nmethods still face three primary issues: multi-dancer collisions, single-dancer\nfoot sliding and abrupt swapping in the generation of long group dance. In this\npaper, we propose TCDiff++, a music-driven end-to-end framework designed to\ngenerate harmonious group dance. Specifically, to mitigate multi-dancer\ncollisions, we utilize a dancer positioning embedding to better maintain the\nrelative positioning among dancers. Additionally, we incorporate a\ndistance-consistency loss to ensure that inter-dancer distances remain within\nplausible ranges. To address the issue of single-dancer foot sliding, we\nintroduce a swap mode embedding to indicate dancer swapping patterns and design\na Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For\nlong group dance generation, we present a long group diffusion sampling\nstrategy that reduces abrupt position shifts by injecting positional\ninformation into the noisy input. Furthermore, we integrate a Sequence Decoder\nlayer to enhance the model's ability to selectively process long sequences.\nExtensive experiments demonstrate that our TCDiff++ achieves state-of-the-art\nperformance, particularly in long-duration scenarios, ensuring high-quality and\ncoherent group dance generation.", "published": "2025-06-23 14:15:20", "link": "http://arxiv.org/abs/2506.18671v3", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ARSAR-Net: Intelligent SAR Imaging with Adaptive Regularization", "abstract": "Deep unfolding networks have recently emerged as a promising approach for\nsynthetic aperture radar (SAR) imaging. However, baseline unfolding networks,\ntypically derived from iterative reconstruction algorithms such as the\nalternating direction method of multipliers (ADMM), lack generalization\ncapability across scenes, primarily because their regularizers are empirically\ndesigned rather than learned from data. In this study, we introduce a learnable\nregularizer into the unfolding network and propose a SAR imaging network with\nadaptive regularization (ARSAR-Net), which aims to generalize across\nheterogeneous scenes including offshore ships, islands, urban areas, and\nmountainous terrain. Furthermore, two variants of ARSAR-Net are developed,\ntargeting improved imaging efficiency and reconstruction quality, respectively.\nExtensive validation through simulated and real-data experiments demonstrates\nthree key advantages of ARSAR-Net: (1) a 50% increase in imaging speed over\nexisting unfolding networks, (2) a PSNR gain of up to 2.0 dB in imaging\nquality, and (3) enhanced adaptability to complex scenes. These advancements\nestablish a new paradigm for computationally efficient and generalizable SAR\nimaging systems.", "published": "2025-06-23 06:16:08", "link": "http://arxiv.org/abs/2506.18324v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech", "abstract": "Speech impairments caused by conditions such as cerebral palsy or genetic\ndisorders pose significant challenges for automatic speech recognition (ASR)\nsystems. Despite recent advances, ASR models like Whisper struggle with\nnon-normative speech due to limited training data and the difficulty of\ncollecting and annotating non-normative speech samples. In this work, we\npropose a practical and lightweight pipeline to personalize ASR models,\nformalizing the selection of words and enriching a small, speech-impaired\ndataset with semantic coherence. Applied to data from a child with a structural\nspeech impairment, our approach shows promising improvements in transcription\nquality, demonstrating the potential to reduce communication barriers for\nindividuals with atypical speech patterns.", "published": "2025-06-23 15:30:50", "link": "http://arxiv.org/abs/2506.21622v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech", "abstract": "Large-scale text-to-speech (TTS) models are typically categorized into\nautoregressive and non-autoregressive systems. Although autoregressive systems\nexhibit certain advantages in speech naturalness, their token-by-token\ngeneration mechanism makes it difficult to precisely control the duration of\nsynthesized speech. This is a key limitation in applications such as video\ndubbing that require strict audio-visual synchronization. This paper introduces\nIndexTTS2, which proposes a novel and autoregressive-model-friendly method for\nspeech duration control. The method supports two generation modes: one allows\nexplicit specification of the number of generated tokens for precise duration\ncontrol; the other does not require manual input and lets the model freely\ngenerate speech while preserving prosodic characteristics from the input\nprompt. Furthermore, IndexTTS2 achieves disentanglement between emotional\nexpression and speaker identity, enabling independent control of timbre and\nemotion. In the zero-shot setting, the model can perfectly reproduce the\nemotional characteristics of the input prompt. Users may also provide a\nseparate emotion prompt, even from a different speaker, allowing the model to\nreconstruct the target timbre while conveying the desired emotion. To enhance\nclarity during strong emotional expressions, we incorporate GPT latent\nrepresentations to improve speech stability. Meanwhile, to lower the barrier\nfor emotion control, we design a soft instruction mechanism based on textual\ndescriptions by fine-tuning Qwen3. This enables effective guidance of speech\ngeneration with desired emotional tendencies using natural language input.\nExperimental results demonstrate that IndexTTS2 outperforms existing\nstate-of-the-art zero-shot TTS models in word error rate, speaker similarity,\nand emotional fidelity.", "published": "2025-06-23 08:33:40", "link": "http://arxiv.org/abs/2506.21619v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
