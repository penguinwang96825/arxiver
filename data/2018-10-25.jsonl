{"title": "Word Embedding based Edit Distance", "abstract": "Text similarity calculation is a fundamental problem in natural language\nprocessing and related fields. In recent years, deep neural networks have been\ndeveloped to perform the task and high performances have been achieved. The\nneural networks are usually trained with labeled data in supervised learning,\nand creation of labeled data is usually very costly. In this short paper, we\naddress unsupervised learning for text similarity calculation. We propose a new\nmethod called Word Embedding based Edit Distance (WED), which incorporates word\nembedding into edit distance. Experiments on three benchmark datasets show WED\noutperforms state-of-the-art unsupervised methods including edit distance,\nTF-IDF based cosine, word embedding based cosine, Jaccard index, etc.", "published": "2018-10-25 07:50:17", "link": "http://arxiv.org/abs/1810.10752v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Logoscope: a Semi-Automatic Tool for Detecting and Documenting\n  French New Words", "abstract": "In this article we present the design and implementation of the Logoscope,\nthe first tool especially developed to detect new words of the French language,\nto document them and allow a public access through a web interface.\n  This semi-automatic tool collects new words daily by browsing the online\nversions of French well known newspapers such as Le Monde, Le Figaro, L'Equipe,\nLib\\'eration, La Croix, Les \\'Echos. In contrast to other existing tools\nessentially dedicated to dictionary development, the Logoscope attempts to give\na more complete account of the context in which the new words occur. In\naddition to the commonly given morpho-syntactic information it also provides\ninformation about the textual and discursive contexts of the word creation; in\nparticular, it automatically determines the (journalistic) topics of the text\ncontaining the new word.\n  In this article we first give a general overview of the developed tool. We\nthen describe the approach taken, we discuss the linguistic background which\nguided our design decisions and present the computational methods we used to\nimplement it.", "published": "2018-10-25 09:16:52", "link": "http://arxiv.org/abs/1810.10797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Oracles for Top-Down and In-Order Shift-Reduce Constituent\n  Parsing", "abstract": "We introduce novel dynamic oracles for training two of the most accurate\nknown shift-reduce algorithms for constituent parsing: the top-down and\nin-order transition-based parsers. In both cases, the dynamic oracles manage to\nnotably increase their accuracy, in comparison to that obtained by performing\nclassic static training. In addition, by improving the performance of the\nstate-of-the-art in-order shift-reduce parser, we achieve the best accuracy to\ndate (92.0 F1) obtained by a fully-supervised single-model greedy shift-reduce\nconstituent parser on the WSJ benchmark.", "published": "2018-10-25 13:58:20", "link": "http://arxiv.org/abs/1810.10882v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Learning Emotion from 100 Observations: Unexpected Robustness of Deep\n  Learning under Strong Data Limitations", "abstract": "One of the major downsides of Deep Learning is its supposed need for vast\namounts of training data. As such, these techniques appear ill-suited for NLP\nareas where annotated data is limited, such as less-resourced languages or\nemotion analysis, with its many nuanced and hard-to-acquire annotation formats.\nWe conduct a questionnaire study indicating that indeed the vast majority of\nresearchers in emotion analysis deems neural models inferior to traditional\nmachine learning when training data is limited. In stark contrast to those\nsurvey results, we provide empirical evidence for English, Polish, and\nPortuguese that commonly used neural architectures can be trained on\nsurprisingly few observations, outperforming $n$-gram based ridge regression on\nonly 100 data points. Our analysis suggests that high-quality, pre-trained word\nembeddings are a main factor for achieving those results.", "published": "2018-10-25 16:08:18", "link": "http://arxiv.org/abs/1810.10949v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching Syntax by Adversarial Distraction", "abstract": "Existing entailment datasets mainly pose problems which can be answered\nwithout attention to grammar or word order. Learning syntax requires comparing\nexamples where different grammar and word order change the desired\nclassification. We introduce several datasets based on synthetic\ntransformations of natural entailment examples in SNLI or FEVER, to teach\naspects of grammar and word order. We show that without retraining, popular\nentailment models are unaware that these syntactic differences change meaning.\nWith retraining, some but not all popular entailment models can learn to\ncompare the syntax properly.", "published": "2018-10-25 18:54:49", "link": "http://arxiv.org/abs/1810.11067v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniMorph 2.0: Universal Morphology", "abstract": "The Universal Morphology UniMorph project is a collaborative effort to\nimprove how NLP handles complex morphology across the world's languages. The\nproject releases annotated morphological data using a universal tagset, the\nUniMorph schema. Each inflected form is associated with a lemma, which\ntypically carries its underlying lexical meaning, and a bundle of morphological\nfeatures from our schema. Additional supporting data and tools are also\nreleased on a per-language basis when available. UniMorph is based at the\nCenter for Language and Speech Processing (CLSP) at Johns Hopkins University in\nBaltimore, Maryland and is sponsored by the DARPA LORELEI program. This paper\ndetails advances made to the collection, annotation, and dissemination of\nproject resources since the initial UniMorph release described at LREC 2016.\nlexical resources} }", "published": "2018-10-25 20:42:40", "link": "http://arxiv.org/abs/1810.11101v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Corpus for Conversation Disentanglement", "abstract": "Disentangling conversations mixed together in a single stream of messages is\na difficult task, made harder by the lack of large manually annotated datasets.\nWe created a new dataset of 77,563 messages manually annotated with\nreply-structure graphs that both disentangle conversations and define internal\nconversation structure. Our dataset is 16 times larger than all previously\nreleased datasets combined, the first to include adjudication of annotation\ndisagreements, and the first to include context. We use our data to re-examine\nprior work, in particular, finding that 80% of conversations in a widely used\ndialogue corpus are either missing messages or contain extra messages. Our\nmanually-annotated data presents an opportunity to develop robust data-driven\nmethods for conversation disentanglement, which will help advance dialogue\nresearch.", "published": "2018-10-25 21:44:14", "link": "http://arxiv.org/abs/1810.11118v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Understanding the Role of Two-Sided Argumentation in Online Consumer\n  Reviews: A Language-Based Perspective", "abstract": "This paper examines the effect of two-sided argumentation on the perceived\nhelpfulness of online consumer reviews. In contrast to previous works, our\nanalysis thereby sheds light on the reception of reviews from a language-based\nperspective. For this purpose, we propose an intriguing text analysis approach\nbased on distributed text representations and multi-instance learning to\noperationalize the two-sidedness of argumentation in review texts. A subsequent\nempirical analysis using a large corpus of Amazon reviews suggests that\ntwo-sided argumentation in reviews significantly increases their helpfulness.\nWe find this effect to be stronger for positive reviews than for negative\nreviews, whereas a higher degree of emotional language weakens the effect. Our\nfindings have immediate implications for retailer platforms, which can utilize\nour results to optimize their customer feedback system and to present more\nuseful product reviews.", "published": "2018-10-25 15:57:45", "link": "http://arxiv.org/abs/1810.10942v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Engaging Image Captioning Via Personality", "abstract": "Standard image captioning tasks such as COCO and Flickr30k are factual,\nneutral in tone and (to a human) state the obvious (e.g., \"a man playing a\nguitar\"). While such tasks are useful to verify that a machine understands the\ncontent of an image, they are not engaging to humans as captions. With this in\nmind we define a new task, Personality-Captions, where the goal is to be as\nengaging to humans as possible by incorporating controllable style and\npersonality traits. We collect and release a large dataset of 201,858 of such\ncaptions conditioned over 215 possible traits. We build models that combine\nexisting work from (i) sentence representations (Mazare et al., 2018) with\nTransformers trained on 1.7 billion dialogue examples; and (ii) image\nrepresentations (Mahajan et al., 2018) with ResNets trained on 3.5 billion\nsocial media images. We obtain state-of-the-art performance on Flickr30k and\nCOCO, and strong performance on our new task. Finally, online evaluations\nvalidate that our task and models are engaging to humans, with our best model\nclose to human performance.", "published": "2018-10-25 00:46:16", "link": "http://arxiv.org/abs/1810.10665v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Tackling Sequence to Sequence Mapping Problems with Neural Networks", "abstract": "In Natural Language Processing (NLP), it is important to detect the\nrelationship between two sequences or to generate a sequence of tokens given\nanother observed sequence. We call the type of problems on modelling sequence\npairs as sequence to sequence (seq2seq) mapping problems. A lot of research has\nbeen devoted to finding ways of tackling these problems, with traditional\napproaches relying on a combination of hand-crafted features, alignment models,\nsegmentation heuristics, and external linguistic resources. Although great\nprogress has been made, these traditional approaches suffer from various\ndrawbacks, such as complicated pipeline, laborious feature engineering, and the\ndifficulty for domain adaptation. Recently, neural networks emerged as a\npromising solution to many problems in NLP, speech recognition, and computer\nvision. Neural models are powerful because they can be trained end to end,\ngeneralise well to unseen examples, and the same framework can be easily\nadapted to a new domain.\n  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping\nproblems with neural networks. We explore solutions from three major aspects:\ninvestigating neural models for representing sequences, modelling interactions\nbetween sequences, and using unpaired data to boost the performance of neural\nmodels. For each aspect, we propose novel models and evaluate their efficacy on\nvarious tasks of seq2seq mapping.", "published": "2018-10-25 09:24:13", "link": "http://arxiv.org/abs/1810.10802v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Bayesian Compression for Natural Language Processing", "abstract": "In natural language processing, a lot of the tasks are successfully solved\nwith recurrent neural networks, but such models have a huge number of\nparameters. The majority of these parameters are often concentrated in the\nembedding layer, which size grows proportionally to the vocabulary length. We\npropose a Bayesian sparsification technique for RNNs which allows compressing\nthe RNN dozens or hundreds of times without time-consuming hyperparameters\ntuning. We also generalize the model for vocabulary sparsification to filter\nout unnecessary words and compress the RNN even further. We show that the\nchoice of the kept words is interpretable. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN", "published": "2018-10-25 15:27:23", "link": "http://arxiv.org/abs/1810.10927v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-Channel Auto-Encoder for Speech Emotion Recognition", "abstract": "Inferring emotion status from users' queries plays an important role to\nenhance the capacity in voice dialogues applications. Even though several\nrelated works obtained satisfactory results, the performance can still be\nfurther improved. In this paper, we proposed a novel framework named\nmulti-channel auto-encoder (MTC-AE) on emotion recognition from acoustic\ninformation. MTC-AE contains multiple local DNNs based on different low-level\ndescriptors with different statistics functions that are partly concatenated\ntogether, by which the structure is enabled to consider both local and global\nfeatures simultaneously. Experiment based on a benchmark dataset IEMOCAP shows\nthat our method significantly outperforms the existing state-of-the-art\nresults, achieving $64.8\\%$ leave-one-speaker-out unweighted accuracy, which is\n$2.4\\%$ higher than the best result on this dataset.", "published": "2018-10-25 00:22:59", "link": "http://arxiv.org/abs/1810.10662v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reducing over-smoothness in speech synthesis using Generative\n  Adversarial Networks", "abstract": "Speech synthesis is widely used in many practical applications. In recent\nyears, speech synthesis technology has developed rapidly. However, one of the\nreasons why synthetic speech is unnatural is that it often has over-smoothness.\nIn order to improve the naturalness of synthetic speech, we first extract the\nmel-spectrogram of speech and convert it into a real image, then take the\nover-smooth mel-spectrogram image as input, and use image-to-image translation\nGenerative Adversarial Networks(GANs) framework to generate a more realistic\nmel-spectrogram. Finally, the results show that this method greatly reduces the\nover-smoothness of synthesized speech and is more close to the mel-spectrogram\nof real speech.", "published": "2018-10-25 17:23:53", "link": "http://arxiv.org/abs/1810.10989v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker Selective Beamformer with Keyword Mask Estimation", "abstract": "This paper addresses the problem of automatic speech recognition (ASR) of a\ntarget speaker in background speech. The novelty of our approach is that we\nfocus on a wakeup keyword, which is usually used for activating ASR systems\nlike smart speakers. The proposed method firstly utilizes a DNN-based mask\nestimator to separate the mixture signal into the keyword signal uttered by the\ntarget speaker and the remaining background speech. Then the separated signals\nare used for calculating a beamforming filter to enhance the subsequent\nutterances from the target speaker. Experimental evaluations show that the\ntrained DNN-based mask can selectively separate the keyword and background\nspeech from the mixture signal. The effectiveness of the proposed method is\nalso verified with Japanese ASR experiments, and we confirm that the character\nerror rates are significantly improved by the proposed method for both\nsimulated and real recorded test sets.", "published": "2018-10-25 05:45:06", "link": "http://arxiv.org/abs/1810.10727v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Short utterance compensation in speaker verification via cosine-based\n  teacher-student learning of speaker embeddings", "abstract": "The short duration of an input utterance is one of the most critical threats\nthat degrade the performance of speaker verification systems. This study aimed\nto develop an integrated text-independent speaker verification system that\ninputs utterances with short duration of 2 seconds or less. We propose an\napproach using a teacher-student learning framework for this goal, applied to\nshort utterance compensation for the first time in our knowledge. The core\nconcept of the proposed system is to conduct the compensation throughout the\nnetwork that extracts the speaker embedding, mainly in phonetic-level, rather\nthan compensating via a separate system after extracting the speaker embedding.\nIn the proposed architecture, phonetic-level features where each feature\nrepresents a segment of 130 ms are extracted using convolutional layers. A\nlayer of gated recurrent units extracts an utterance-level feature using\nphonetic-level features. The proposed approach also adopts a new objective\nfunction for teacher-student learning that considers both Kullback-Leibler\ndivergence of output layers and cosine distance of speaker embeddings layers.\nExperiments were conducted using deep neural networks that take raw waveforms\nas input, and output speaker embeddings on VoxCeleb1 dataset. The proposed\nmodel could compensate approximately 65 \\% of the performance degradation due\nto the shortened duration.", "published": "2018-10-25 14:03:01", "link": "http://arxiv.org/abs/1810.10884v2", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
