{"title": "Economic effects on households of an augmentation of the cash back duration of real estate loan", "abstract": "This article examines the economic effects of an increase in the duration of\nhome loans on households, focusing on the French real estate market. It\nhighlights trends in the property market, existing loan systems in other\ncountries (such as bullet loans in Sweden and Japanese home loans), the current\nstate of the property market in France, the potential effects of an increase in\nthe amortization period of home loans, and the financial implications for\nhouseholds.The article points out that increasing the repayment period on home\nloans could reduce the amount of monthly instalments to be repaid, thereby\nfacilitating access to credit for the most modest households. However, this\nmeasure also raises concerns about overall credit costs, financial stability\nand the impact on property prices. In addition, it highlights the differences\nbetween existing lending systems in other countries, such as the bullet loan in\nSweden and Japanese home loans, and the current characteristics of home loans\nin France, notably interest rates and house price trends. The article proposes\na model of the potential effects of an increase in the amortization period of\nhome loans on housing demand, housing supply, property prices and the\nassociated financial risks.In conclusion, the article highlights the crucial\nimportance of household debt for individual and economic financial stability.\nIt highlights the distortion between supply and demand for home loans as\namortization periods increase, and the significant rise in overall loan costs\nfor households. It also underlines the need to address structural issues such\nas the sustainable reduction in interest rates, the stabilization of banks'\nequity capital and the development of a regulatory framework for\nintergenerational lending to ensure a properly functioning market.", "published": "2024-09-23 06:52:03", "link": "http://arxiv.org/abs/2409.14748v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "From Gini index as a Lyapunov functional to convergence in Wasserstein distance", "abstract": "In several recent works on infinite-dimensional systems of ODEs\n\\cite{cao_derivation_2021,cao_explicit_2021,cao_iterative_2024,cao_sticky_2024},\nwhich arise from the mean-field limit of agent-based models in economics and\nsocial sciences and model the evolution of probability distributions (on the\nset of non-negative integers), it is often shown that the Gini index serves as\na natural Lyapunov functional along the solution to a given system.\nFurthermore, the Gini index converges to that of the equilibrium distribution.\nHowever, it is not immediately clear whether this convergence at the level of\nthe Gini index implies convergence in the sense of probability distributions or\neven stronger notions of convergence. In this paper, we prove several results\nin this direction, highlighting the interplay between the Gini index and other\npopular metrics, such as the Wasserstein distance and the usual $\\ell^p$\ndistance, which are used to quantify the closeness of probability\ndistributions.", "published": "2024-09-23 17:14:45", "link": "http://arxiv.org/abs/2409.15225v1", "categories": ["q-fin.MF", "math.CA", "math.PR", "34A35, 91B80, 91B70, 60J28"], "primary_category": "q-fin.MF"}
{"title": "Consistent Estimation of the High-Dimensional Efficient Frontier", "abstract": "In this paper, we analyze the asymptotic behavior of the main characteristics\nof the mean-variance efficient frontier employing random matrix theory. Our\nparticular interest covers the case when the dimension $p$ and the sample size\n$n$ tend to infinity simultaneously and their ratio $p/n$ tends to a positive\nconstant $c\\in(0,1)$. We neither impose any distributional nor structural\nassumptions on the asset returns. For the developed theoretical framework, some\nregularity conditions, like the existence of the $4$th moments, are needed.\n  It is shown that two out of three quantities of interest are biased and\noverestimated by their sample counterparts under the high-dimensional\nasymptotic regime. This becomes evident based on the asymptotic deterministic\nequivalents of the sample plug-in estimators. Using them we construct\nconsistent estimators of the three characteristics of the efficient frontier.\nIt it shown that the additive and/or the multiplicative biases of the sample\nestimates are solely functions of the concentration ratio $c$. Furthermore, the\nasymptotic normality of the considered estimators of the parameters of the\nefficient frontier is proved. Verifying the theoretical results based on an\nextensive simulation study we show that the proposed estimator for the\nefficient frontier is a valuable alternative to the sample estimator for high\ndimensional data. Finally, we present an empirical application, where we\nestimate the efficient frontier based on the stocks included in S\\&P 500 index.", "published": "2024-09-23 15:16:01", "link": "http://arxiv.org/abs/2409.15103v1", "categories": ["q-fin.ST", "math.ST", "q-fin.MF", "stat.TH"], "primary_category": "q-fin.ST"}
{"title": "Position-building in competition with real-world constraints", "abstract": "This paper extends the optimal-trading framework developed in\narXiv:2409.03586v1 to compute optimal strategies with real-world constraints.\nThe aim of the current paper, as with the previous, is to study trading in the\ncontext of multi-player non-cooperative games. While the former paper relies on\nmethods from the calculus of variations and optimal strategies arise as the\nsolution of partial differential equations, the current paper demonstrates that\nthe entire framework may be re-framed as a quadratic programming problem and\ncast in this light constraints are readily incorporated into the calculation of\noptimal strategies. An added benefit is that two-trader equilibria may be\ncalculated as the end-points of a dynamic process of traders forming repeated\nadjustments to each other's strategy.", "published": "2024-09-23 18:36:57", "link": "http://arxiv.org/abs/2409.15459v2", "categories": ["q-fin.TR", "cs.GT"], "primary_category": "q-fin.TR"}
{"title": "Building Tamil Treebanks", "abstract": "Treebanks are important linguistic resources, which are structured and\nannotated corpora with rich linguistic annotations. These resources are used in\nNatural Language Processing (NLP) applications, supporting linguistic analyses,\nand are essential for training and evaluating various computational models.\nThis paper discusses the creation of Tamil treebanks using three distinct\napproaches: manual annotation, computational grammars, and machine learning\ntechniques. Manual annotation, though time-consuming and requiring linguistic\nexpertise, ensures high-quality and rich syntactic and semantic information.\nComputational deep grammars, such as Lexical Functional Grammar (LFG), offer\ndeep linguistic analyses but necessitate significant knowledge of the\nformalism. Machine learning approaches, utilising off-the-shelf frameworks and\ntools like Stanza, UDpipe, and UUParser, facilitate the automated annotation of\nlarge datasets but depend on the availability of quality annotated data,\ncross-linguistic training resources, and computational power. The paper\ndiscusses the challenges encountered in building Tamil treebanks, including\nissues with Internet data, the need for comprehensive linguistic analysis, and\nthe difficulty of finding skilled annotators. Despite these challenges, the\ndevelopment of Tamil treebanks is essential for advancing linguistic research\nand improving NLP tools for Tamil.", "published": "2024-09-23 01:58:50", "link": "http://arxiv.org/abs/2409.14657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Direct Judgement Preference Optimization", "abstract": "Auto-evaluation is crucial for assessing response quality and offering\nfeedback for model development. Recent studies have explored training large\nlanguage models (LLMs) as generative judges to evaluate and critique other\nmodels' outputs. In this work, we investigate the idea of learning from both\npositive and negative data with preference optimization to enhance the\nevaluation capabilities of LLM judges across an array of different use cases.\nWe achieve this by employing three approaches to collect the preference pairs\nfor different use cases, each aimed at improving our generative judge from a\ndifferent perspective. Our comprehensive study over a wide range of benchmarks\ndemonstrates the effectiveness of our method. In particular, our generative\njudge achieves the best performance on 10 out of 13 benchmarks, outperforming\nstrong baselines like GPT-4o and specialized judge models. Further analysis\nshow that our judge model robustly counters inherent biases such as position\nand length bias, flexibly adapts to any evaluation protocol specified by\npractitioners, and provides helpful language feedback for improving downstream\ngenerator models.", "published": "2024-09-23 02:08:20", "link": "http://arxiv.org/abs/2409.14664v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LINKAGE: Listwise Ranking among Varied-Quality References for\n  Non-Factoid QA Evaluation via LLMs", "abstract": "Non-Factoid (NF) Question Answering (QA) is challenging to evaluate due to\ndiverse potential answers and no objective criterion. The commonly used\nautomatic evaluation metrics like ROUGE or BERTScore cannot accurately measure\nsemantic similarities or answers from different perspectives. Recently, Large\nLanguage Models (LLMs) have been resorted to for NFQA evaluation due to their\ncompelling performance on various NLP tasks. Common approaches include\npointwise scoring of each candidate answer and pairwise comparisons between\nanswers. Inspired by the evolution from pointwise to pairwise to listwise in\nlearning-to-rank methods, we propose a novel listwise NFQA evaluation approach,\nthat utilizes LLMs to rank candidate answers in a list of reference answers\nsorted by descending quality. Moreover, for NF questions that do not have\nmulti-grade or any golden answers, we leverage LLMs to generate the reference\nanswer list of various quality to facilitate the listwise evaluation. Extensive\nexperimental results on three NFQA datasets, i.e., ANTIQUE, the TREC-DL-NF, and\nWebGLM show that our method has significantly higher correlations with human\nannotations compared to automatic scores and common pointwise and pairwise\napproaches.", "published": "2024-09-23 06:42:21", "link": "http://arxiv.org/abs/2409.14744v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language-Agnostic Analysis of Speech Depression Detection", "abstract": "The people with Major Depressive Disorder (MDD) exhibit the symptoms of tonal\nvariations in their speech compared to the healthy counterparts. However, these\ntonal variations not only confine to the state of MDD but also on the language,\nwhich has unique tonal patterns. This work analyzes automatic speech-based\ndepression detection across two languages, English and Malayalam, which\nexhibits distinctive prosodic and phonemic characteristics. We propose an\napproach that utilizes speech data collected along with self-reported labels\nfrom participants reading sentences from IViE corpus, in both English and\nMalayalam. The IViE corpus consists of five sets of sentences: simple\nsentences, WH-questions, questions without morphosyntactic markers, inversion\nquestions and coordinations, that can naturally prompt speakers to speak in\ndifferent tonal patterns. Convolutional Neural Networks (CNNs) are employed for\ndetecting depression from speech. The CNN model is trained to identify acoustic\nfeatures associated with depression in speech, focusing on both languages. The\nmodel's performance is evaluated on the collected dataset containing recordings\nfrom both depressed and non-depressed speakers, analyzing its effectiveness in\ndetecting depression across the two languages. Our findings and collected data\ncould contribute to the development of language-agnostic speech-based\ndepression detection systems, thereby enhancing accessibility for diverse\npopulations.", "published": "2024-09-23 07:35:56", "link": "http://arxiv.org/abs/2409.14769v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OMPar: Automatic Parallelization with AI-Driven Source-to-Source\n  Compilation", "abstract": "Manual parallelization of code remains a significant challenge due to the\ncomplexities of modern software systems and the widespread adoption of\nmulti-core architectures. This paper introduces OMPar, an AI-driven tool\ndesigned to automate the parallelization of C/C++ code using OpenMP pragmas.\nOMPar integrates Large Language Models (LLMs) through two key components:\nOMPify, which assesses loop parallelization potential, and MonoCoder-OMP, a new\nfine-tuned model which generates precise OpenMP pragmas. The evaluation of\nOMPar follows the same rigorous process applied to traditional tools like\nsource-to-source AutoPar and ICPC compilers: (1) ensuring the generated code\ncompiles and runs correctly in serial form, (2) assessing performance with the\ngradual addition of threads and corresponding physical cores, and (3) verifying\nand validating the correctness of the code's output. Benchmarks from HeCBench\nand ParEval are used to evaluate accuracy and performance. Experimental results\ndemonstrate that OMPar significantly outperforms traditional methods, achieving\nhigher accuracy in identifying parallelizable loops and generating efficient\npragmas. Beyond accuracy, OMPar offers advantages such as the ability to work\non partial or incomplete codebases and the capacity to continuously learn from\nnew code patterns, enhancing its parallelization capabilities over time. These\nresults underscore the potential of LLMs in revolutionizing automatic\nparallelization techniques, paving the way for more efficient and scalable\nparallel computing systems.", "published": "2024-09-23 07:39:01", "link": "http://arxiv.org/abs/2409.14771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations", "abstract": "Detecting critical moments, such as emotional outbursts or changes in\ndecisions during conversations, is crucial for understanding shifts in human\nbehavior and their consequences. Our work introduces a novel problem setting\nfocusing on these moments as turning points (TPs), accompanied by a\nmeticulously curated, high-consensus, human-annotated multi-modal dataset. We\nprovide precise timestamps, descriptions, and visual-textual evidence\nhigh-lighting changes in emotions, behaviors, perspectives, and decisions at\nthese turning points. We also propose a framework, TPMaven, utilizing\nstate-of-the-art vision-language models to construct a narrative from the\nvideos and large language models to classify and detect turning points in our\nmulti-modal dataset. Evaluation results show that TPMaven achieves an F1-score\nof 0.88 in classification and 0.61 in detection, with additional explanations\naligning with human expectations.", "published": "2024-09-23 08:26:08", "link": "http://arxiv.org/abs/2409.14801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Planning in Large Language Models for Domain-Aligned\n  Counseling Summarization", "abstract": "In mental health counseling, condensing dialogues into concise and relevant\nsummaries (aka counseling notes) holds pivotal significance. Large Language\nModels (LLMs) exhibit remarkable capabilities in various generative tasks;\nhowever, their adaptation to domain-specific intricacies remains challenging,\nespecially within mental health contexts. Unlike standard LLMs, mental health\nexperts first plan to apply domain knowledge in writing summaries. Our work\nenhances LLMs' ability by introducing a novel planning engine to orchestrate\nstructuring knowledge alignment. To achieve high-order planning, we divide\nknowledge encapsulation into two major phases: (i) holding dialogue structure\nand (ii) incorporating domain-specific knowledge. We employ a planning engine\non Llama-2, resulting in a novel framework, PIECE. Our proposed system employs\nknowledge filtering-cum-scaffolding to encapsulate domain knowledge.\nAdditionally, PIECE leverages sheaf convolution learning to enhance its\nunderstanding of the dialogue's structural nuances. We compare PIECE with 14\nbaseline methods and observe a significant improvement across ROUGE and Bleurt\nscores. Further, expert evaluation and analyses validate the generation quality\nto be effective, sometimes even surpassing the gold standard. We further\nbenchmark PIECE with other LLMs and report improvement, including Llama-2\n(+2.72%), Mistral (+2.04%), and Zephyr (+1.59%), to justify the\ngeneralizability of the planning engine.", "published": "2024-09-23 11:01:31", "link": "http://arxiv.org/abs/2409.14907v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with\n  Multimodal Large Language Models", "abstract": "Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have\ndemonstrated aptitude as potential substitutes for human participants in\nexperiments testing psycholinguistic phenomena. However, an understudied\nquestion is to what extent models that only have access to vision and text\nmodalities are able to implicitly understand sound-based phenomena via abstract\nreasoning from orthography and imagery alone. To investigate this, we analyse\nthe ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognise\na non-arbitrary link between sounds and concepts) as well as their ability to\n\"hear\" via the interplay of the language and vision modules of open and\nclosed-source multimodal models. We perform multiple experiments, including\nreplicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolism\ntasks, and comparing human judgements of linguistic iconicity with that of\nLLMs. Our results show that VLMs demonstrate varying levels of agreement with\nhuman labels, and more task information may be required for VLMs versus their\nhuman counterparts for in silico experimentation. We additionally see through\nhigher maximum agreement levels that Magnitude Symbolism is an easier pattern\nfor VLMs to identify than Shape Symbolism, and that an understanding of\nlinguistic iconicity is highly dependent on model size.", "published": "2024-09-23 11:13:25", "link": "http://arxiv.org/abs/2409.14917v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Rhetorical Structure Parsing with Large Parallel Annotations", "abstract": "Discourse parsing is a crucial task in natural language processing that aims\nto reveal the higher-level relations in a text. Despite growing interest in\ncross-lingual discourse parsing, challenges persist due to limited parallel\ndata and inconsistencies in the Rhetorical Structure Theory (RST) application\nacross languages and corpora. To address this, we introduce a parallel Russian\nannotation for the large and diverse English GUM RST corpus. Leveraging recent\nadvances, our end-to-end RST parser achieves state-of-the-art results on both\nEnglish and Russian corpora. It demonstrates effectiveness in both monolingual\nand bilingual settings, successfully transferring even with limited\nsecond-language annotation. To the best of our knowledge, this work is the\nfirst to evaluate the potential of cross-lingual end-to-end RST parsing on a\nmanually annotated parallel corpus.", "published": "2024-09-23 12:40:33", "link": "http://arxiv.org/abs/2409.14969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining\n  for Clinical LLMs", "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\ntransforming clinical applications. In this study, we investigate the efficacy\nof four techniques in adapting LLMs for clinical use-cases: continuous\npretraining, instruct fine-tuning, NEFTune, and prompt engineering. We employ\nthese methods on Mistral 7B and Mixtral 8x7B models, leveraging a large-scale\nclinical pretraining dataset of 50 billion tokens and an instruct fine-tuning\ndataset of 500 million tokens. Our evaluation across various clinical tasks\nreveals the impact of each technique. While continuous pretraining beyond 250\nbillion tokens yields marginal improvements on its own, it establishes a strong\nfoundation for instruct fine-tuning. Notably, NEFTune, designed primarily to\nenhance generation quality, surprisingly demonstrates additional gains on our\nbenchmark. Complex prompt engineering methods further enhance performance.\nThese findings show the importance of tailoring fine-tuning strategies and\nexploring innovative techniques to optimize LLM performance in the clinical\ndomain.", "published": "2024-09-23 13:09:57", "link": "http://arxiv.org/abs/2409.14988v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Aspect-based Sentiment Analysis in Tourism Using Large\n  Language Models and Positional Information", "abstract": "Aspect-Based Sentiment Analysis (ABSA) in tourism plays a significant role in\nunderstanding tourists' evaluations of specific aspects of attractions, which\nis crucial for driving innovation and development in the tourism industry.\nHowever, traditional pipeline models are afflicted by issues such as error\npropagation and incomplete extraction of sentiment elements. To alleviate this\nissue, this paper proposes an aspect-based sentiment analysis model, ACOS_LLM,\nfor Aspect-Category-Opinion-Sentiment Quadruple Extraction (ACOSQE). The model\ncomprises two key stages: auxiliary knowledge generation and ACOSQE. Firstly,\nAdalora is used to fine-tune large language models for generating high-quality\nauxiliary knowledge. To enhance model efficiency, Sparsegpt is utilized to\ncompress the fine-tuned model to 50% sparsity. Subsequently, Positional\ninformation and sequence modeling are employed to achieve the ACOSQE task, with\nauxiliary knowledge and the original text as inputs. Experiments are conducted\non both self-created tourism datasets and publicly available datasets, Rest15\nand Rest16. Results demonstrate the model's superior performance, with an F1\nimprovement of 7.49% compared to other models on the tourism dataset.\nAdditionally, there is an F1 improvement of 0.05% and 1.06% on the Rest15 and\nRest16 datasets, respectively.", "published": "2024-09-23 13:19:17", "link": "http://arxiv.org/abs/2409.14997v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Similarity to Evaluate Factual Consistency in Summaries", "abstract": "Cutting-edge abstractive summarisers generate fluent summaries, but the\nfactuality of the generated text is not guaranteed. Early summary factuality\nevaluation metrics are usually based on n-gram overlap and embedding\nsimilarity, but are reported fail to align with human annotations. Therefore,\nmany techniques for detecting factual inconsistencies build pipelines around\nnatural language inference (NLI) or question-answering (QA) models with\nadditional supervised learning steps. In this paper, we revisit\nsimilarity-based metrics, showing that this failure stems from the comparison\ntext selection and its granularity. We propose a new zero-shot factuality\nevaluation metric, Sentence-BERT Score (SBERTScore), which compares sentences\nbetween the summary and the source document. It outperforms widely-used\nword-word metrics including BERTScore and can compete with existing NLI and\nQA-based factuality metrics on the benchmark without needing any fine-tuning.\nOur experiments indicate that each technique has different strengths, with\nSBERTScore particularly effective in identifying correct summaries. We\ndemonstrate how a combination of techniques is more effective in detecting\nvarious types of error.", "published": "2024-09-23 15:02:38", "link": "http://arxiv.org/abs/2409.15090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inferring Scientific Cross-Document Coreference and Hierarchy with\n  Definition-Augmented Relational Reasoning", "abstract": "We address the fundamental task of inferring cross-document coreference and\nhierarchy in scientific texts, which has important applications in knowledge\ngraph construction, search, recommendation and discovery. LLMs can struggle\nwhen faced with many long-tail technical concepts with nuanced variations. We\npresent a novel method which generates context-dependent definitions of concept\nmentions by retrieving full-text literature, and uses the definitions to\nenhance detection of cross-document relations. We further generate relational\ndefinitions, which describe how two concept mentions are related or different,\nand design an efficient re-ranking approach to address the combinatorial\nexplosion involved in inferring links across papers. In both fine-tuning and\nin-context learning settings we achieve large gains in performance. We provide\nanalysis of generated definitions, shedding light on the relational reasoning\nability of LLMs over fine-grained scientific concepts.", "published": "2024-09-23 15:20:27", "link": "http://arxiv.org/abs/2409.15113v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUTE: Measuring LLMs' Understanding of Their Tokens", "abstract": "Large Language Models (LLMs) show remarkable performance on a wide variety of\ntasks. Most LLMs split text into multi-character tokens and process them as\natomic units without direct access to individual characters. This raises the\nquestion: To what extent can LLMs learn orthographic information? To answer\nthis, we propose a new benchmark, CUTE, which features a collection of tasks\ndesigned to test the orthographic knowledge of LLMs. We evaluate popular LLMs\non CUTE, finding that most of them seem to know the spelling of their tokens,\nyet fail to use this information effectively to manipulate text, calling into\nquestion how much of this knowledge is generalizable.", "published": "2024-09-23 18:27:03", "link": "http://arxiv.org/abs/2409.15452v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harmonising the Clinical Melody: Tuning Large Language Models for\n  Hospital Course Summarisation in Clinical Coding", "abstract": "The increasing volume and complexity of clinical documentation in Electronic\nMedical Records systems pose significant challenges for clinical coders, who\nmust mentally process and summarise vast amounts of clinical text to extract\nessential information needed for coding tasks. While large language models have\nbeen successfully applied to shorter summarisation tasks in recent years, the\nchallenge of summarising a hospital course remains an open area for further\nresearch and development. In this study, we adapted three pre trained LLMs,\nLlama 3, BioMistral, Mistral Instruct v0.1 for the hospital course\nsummarisation task, using Quantized Low Rank Adaptation fine tuning. We created\na free text clinical dataset from MIMIC III data by concatenating various\nclinical notes as the input clinical text, paired with ground truth Brief\nHospital Course sections extracted from the discharge summaries for model\ntraining. The fine tuned models were evaluated using BERTScore and ROUGE\nmetrics to assess the effectiveness of clinical domain fine tuning.\nAdditionally, we validated their practical utility using a novel hospital\ncourse summary assessment metric specifically tailored for clinical coding. Our\nfindings indicate that fine tuning pre trained LLMs for the clinical domain can\nsignificantly enhance their performance in hospital course summarisation and\nsuggest their potential as assistive tools for clinical coding. Future work\nshould focus on refining data curation methods to create higher quality\nclinical datasets tailored for hospital course summary tasks and adapting more\nadvanced open source LLMs comparable to proprietary models to further advance\nthis research.", "published": "2024-09-23 00:35:23", "link": "http://arxiv.org/abs/2409.14638v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language\n  Models in Few-Shot Computational Social Science", "abstract": "Real-world applications of large language models (LLMs) in computational\nsocial science (CSS) tasks primarily depend on the effectiveness of instruction\ntuning (IT) or in-context learning (ICL). While IT has shown highly effective\nat fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task\nadaptation by learning from examples without explicit gradient updates. In this\npaper, we evaluate the classification performance of LLMs using IT versus ICL\nin few-shot CSS tasks. The experimental results indicate that ICL consistently\noutperforms IT in most CSS tasks. Additionally, we investigate the relationship\nbetween the increasing number of training samples and LLM performance. Our\nfindings show that simply increasing the number of samples without considering\ntheir quality does not consistently enhance the performance of LLMs with either\nICL or IT and can sometimes even result in a performance decline. Finally, we\ncompare three prompting strategies, demonstrating that ICL is more effective\nthan zero-shot and Chain-of-Thought (CoT). Our research highlights the\nsignificant advantages of ICL in handling CSS tasks in few-shot settings and\nemphasizes the importance of optimizing sample quality and prompting strategies\nto improve LLM classification performance. The code will be made available.", "published": "2024-09-23 02:43:08", "link": "http://arxiv.org/abs/2409.14673v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Target-Aware Language Modeling via Granular Data Sampling", "abstract": "Language model pretraining generally targets a broad range of use cases and\nincorporates data from diverse sources. However, there are instances where we\ndesire a model that excels in specific areas without markedly compromising\nperformance in other areas. A cost-effective and straightforward approach is\nsampling with low-dimensional data features, which allows to select large-scale\npretraining data for domain-specific use cases. In this work, we revisit\nimportance sampling with n-gram features consisting of multi-granular tokens,\nwhich strikes a good balance between sentence compression and representation\ncapabilities. We observed the sampled data to have a high correlation with the\ntarget downstream task performance while preserving its effectiveness on other\ntasks. This leads to the proposed data sampling paradigm where language models\ncan be pretrained more efficiently on selected documents. On eight benchmarks\nwe demonstrate with $\\sim$1% of the data, pretrained models perform on par with\nthe full RefinedWeb data and outperform randomly selected samples for model\nsizes ranging from 125M to 1.5B.", "published": "2024-09-23 04:52:17", "link": "http://arxiv.org/abs/2409.14705v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning", "abstract": "Role-playing is an emerging application in the field of Human-Computer\nInteraction (HCI), primarily implemented through the alignment training of a\nlarge language model (LLM) with assigned characters. Despite significant\nprogress, role-playing agents (RPLAs) still struggle with maintaining\nrole-consistency across conversations, particularly when confronted with\nboundary queries subtly related to character attributes. In this paper, we\npresent ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities\nthrough boundary-aware learning. ERABAL encompasses a generation pipeline for\nrole-specific dialogues and a concomitant methodology for alignment training.\nThrough comprehensive evaluations, we demonstrate that ERABAL is both efficient\nand effective. By training with significantly fewer dialogues than those used\nin leading approaches, ERABAL achieves notable improvements across\nWikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared\nto the generalist baseline models. Our code and datasets will be made publicly\navailable to support further research.", "published": "2024-09-23 05:12:13", "link": "http://arxiv.org/abs/2409.14710v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful\n  Information", "abstract": "In different NLP tasks, detecting harmful content is crucial for online\nenvironments, especially with the growing influence of social media. However,\nprevious research has two main issues: 1) a lack of data in low-resource\nsettings, and 2) inconsistent definitions and criteria for judging harmful\ncontent, requiring classification models to be robust to spurious features and\ndiverse. We propose Toxicraft, a novel framework for synthesizing datasets of\nharmful information to address these weaknesses. With only a small amount of\nseed data, our framework can generate a wide variety of synthetic, yet\nremarkably realistic, examples of toxic information. Experimentation across\nvarious datasets showcases a notable enhancement in detection model robustness\nand adaptability, surpassing or close to the gold labels. We release the\ngenerated data at Github upon acceptance.", "published": "2024-09-23 06:36:57", "link": "http://arxiv.org/abs/2409.14740v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional\n  Referring Expression Comprehension", "abstract": "Referring Expression Comprehension (REC) is a crucial cross-modal task that\nobjectively evaluates the capabilities of language understanding, image\ncomprehension, and language-to-image grounding. Consequently, it serves as an\nideal testing ground for Multi-modal Large Language Models (MLLMs). In pursuit\nof this goal, we have established a new REC dataset characterized by two key\nfeatures: Firstly, it is designed with controllable varying levels of\ndifficulty, necessitating multi-level fine-grained reasoning across object\ncategories, attributes, and multi-hop relationships. Secondly, it includes\nnegative text and images created through fine-grained editing and generation\nbased on existing data, thereby testing the model's ability to correctly reject\nscenarios where the target object is not visible in the image--an essential\naspect often overlooked in existing datasets and approaches. Utilizing this\nhigh-quality dataset, we conducted comprehensive evaluations of both\nstate-of-the-art specialist models and MLLMs. Our findings indicate that there\nremains a significant gap in achieving satisfactory grounding performance. We\nanticipate that our dataset will inspire new approaches to enhance visual\nreasoning and develop more advanced cross-modal interaction strategies,\nultimately unlocking the full potential of MLLMs. Our code and the datasets are\navailable at https://github.com/liujunzhuo/FineCops-Ref.", "published": "2024-09-23 06:56:51", "link": "http://arxiv.org/abs/2409.14750v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Do Large Language Models have Problem-Solving Capability under\n  Incomplete Information Scenarios?", "abstract": "The evaluation of the problem-solving capability under incomplete information\nscenarios of Large Language Models (LLMs) is increasingly important,\nencompassing capabilities such as questioning, knowledge search, error\ndetection, and path planning. Current research mainly focus on LLMs'\nproblem-solving capability such as ``Twenty Questions''. However, these kinds\nof games do not require recognizing misleading cues which are necessary in the\nincomplete information scenario. Moreover, the existing game such as ``Who is\nundercover'' are highly subjective, making it challenging for evaluation.\nTherefore, in this paper, we introduce a novel game named BrainKing based on\nthe ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM\ncapabilities under incomplete information scenarios. It requires LLMs to\nidentify target entities with limited yes-or-no questions and potential\nmisleading answers. By setting up easy, medium, and hard difficulty modes, we\ncomprehensively assess the performance of LLMs across various aspects. Our\nresults reveal the capabilities and limitations of LLMs in BrainKing, providing\nsignificant insights of LLM problem-solving levels.", "published": "2024-09-23 07:18:02", "link": "http://arxiv.org/abs/2409.14762v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pretraining Data Detection for Large Language Models: A Divergence-based\n  Calibration Method", "abstract": "As the scale of training corpora for large language models (LLMs) grows,\nmodel developers become increasingly reluctant to disclose details on their\ndata. This lack of transparency poses challenges to scientific evaluation and\nethical deployment. Recently, pretraining data detection approaches, which\ninfer whether a given text was part of an LLM's training data through black-box\naccess, have been explored. The Min-K\\% Prob method, which has achieved\nstate-of-the-art results, assumes that a non-training example tends to contain\na few outlier words with low token probabilities. However, the effectiveness\nmay be limited as it tends to misclassify non-training texts that contain many\ncommon words with high probabilities predicted by LLMs. To address this issue,\nwe introduce a divergence-based calibration method, inspired by the\ndivergence-from-randomness concept, to calibrate token probabilities for\npretraining data detection. We compute the cross-entropy (i.e., the divergence)\nbetween the token probability distribution and the token frequency distribution\nto derive a detection score. We have developed a Chinese-language benchmark,\nPatentMIA, to assess the performance of detection approaches for LLMs on\nChinese text. Experimental results on English-language benchmarks and PatentMIA\ndemonstrate that our proposed method significantly outperforms existing\nmethods. Our code and PatentMIA benchmark are available at\nhttps://github.com/zhang-wei-chao/DC-PDD.", "published": "2024-09-23 07:55:35", "link": "http://arxiv.org/abs/2409.14781v5", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Towards Efficient and Robust VQA-NLE Data Generation with Large\n  Vision-Language Models", "abstract": "Natural Language Explanation (NLE) aims to elucidate the decision-making\nprocess by providing detailed, human-friendly explanations in natural language.\nIt helps demystify the decision-making processes of large vision-language\nmodels (LVLMs) through the use of language models. While existing methods for\ncreating a Vision Question-Answering with Natural Language Explanation\n(VQA-NLE) datasets can provide explanations, they heavily rely on human\nannotations that are time-consuming and costly. In this study, we propose a\nnovel approach that leverages LVLMs to efficiently generate high-quality\nsynthetic VQA-NLE datasets. By evaluating our synthetic data, we showcase how\nadvanced prompting techniques can lead to the production of high-quality\nVQA-NLE data. Our findings indicate that this proposed method achieves up to\n20x faster than human annotation, with only a minimal decrease in qualitative\nmetrics, achieving robust quality that is nearly equivalent to human-annotated\ndata. Furthermore, we show that incorporating visual prompts significantly\nenhances the relevance of text generation. Our study paves the way for a more\nefficient and robust automated generation of multi-modal NLE data, offering a\npromising solution to the problem.", "published": "2024-09-23 07:59:50", "link": "http://arxiv.org/abs/2409.14785v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI\n  Understanding", "abstract": "Recently, mobile AI agents based on VLMs have been gaining increasing\nattention. These works typically utilize VLM as a foundation, fine-tuning it\nwith instruction-based mobile datasets. However, these VLMs are typically\npre-trained on general-domain data, which often results in a lack of\nfundamental capabilities specific to the mobile domain. Therefore, they may\nstruggle to recognize specific UI elements and understand intra-UI fine-grained\ninformation. In addition, the current fine-tuning task focuses on interacting\nwith the most relevant element for the given instruction. These fine-tuned VLMs\nmay still ignore the relationships between UI pages, neglect the roles of\nelements in page transitions and lack inter-UI understanding. To address\nissues, we propose a VLM called MobileVLM, which includes two additional\npre-training stages to enhance both intra- and inter-UI understanding. We\ndefined four UI-based pre-training tasks, enabling the model to better perceive\nfine-grained elements and capture page transition actions. To address the lack\nof mobile pre-training data, we built a large Chinese mobile dataset Mobile3M\nfrom scratch, which contains 3 million UI pages, and real-world transition\nactions, forming a directed graph structure. Experimental results show\nMobileVLM excels on both our test set and public mobile benchmarks,\noutperforming existing VLMs.", "published": "2024-09-23 08:47:54", "link": "http://arxiv.org/abs/2409.14818v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Past Meets Present: Creating Historical Analogy with Large Language\n  Models", "abstract": "Historical analogies, which compare known past events with contemporary but\nunfamiliar events, are important abilities that help people make decisions and\nunderstand the world. However, research in applied history suggests that people\nhave difficulty finding appropriate analogies. And previous studies in the AI\ncommunity have also overlooked historical analogies. To fill this gap, in this\npaper, we focus on the historical analogy acquisition task, which aims to\nacquire analogous historical events for a given event. We explore retrieval and\ngeneration methods for acquiring historical analogies based on different large\nlanguage models (LLMs). Furthermore, we propose a self-reflection method to\nmitigate hallucinations and stereotypes when LLMs generate historical\nanalogies. Through human evaluations and our specially designed automatic\nmulti-dimensional assessment, we find that LLMs generally have a good potential\nfor historical analogies. And the performance of the models can be further\nimproved by using our self-reflection method.", "published": "2024-09-23 08:52:09", "link": "http://arxiv.org/abs/2409.14820v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions\n  with Path Planning and Feedback", "abstract": "Recently, tool-augmented LLMs have gained increasing attention. Given an\ninstruction, tool-augmented LLMs can interact with various external tools in\nmultiple rounds and provide a final answer. However, previous LLMs were trained\non overly detailed instructions, which included API names or parameters, while\nreal users would not explicitly mention these API details. This leads to a gap\nbetween trained LLMs and real-world scenarios. In addition, most works ignore\nwhether the interaction process follows the instruction. To address these\nissues, we constructed a training dataset called MGToolBench, which contains\nstatement and category-level instructions to better reflect real-world\nscenarios. In addition, we propose ToolPlanner, a two-stage reinforcement\nlearning framework that utilizes path planning and two feedback mechanisms to\nenhance the LLM's task completion and instruction-following capabilities.\nExperimental results show that ToolPlanner significantly improves the Match\nRate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA\nmodel. Human evaluation verifies that the multi-granularity instructions can\nbetter align with users' usage habits. Our data and code will be released upon\nacceptance.", "published": "2024-09-23 08:58:48", "link": "http://arxiv.org/abs/2409.14826v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HW-TSC's Submission to the CCMT 2024 Machine Translation Tasks", "abstract": "This paper presents the submission of Huawei Translation Services Center\n(HW-TSC) to machine translation tasks of the 20th China Conference on Machine\nTranslation (CCMT 2024). We participate in the bilingual machine translation\ntask and multi-domain machine translation task. For these two translation\ntasks, we use training strategies such as regularized dropout, bidirectional\ntraining, data diversification, forward translation, back translation,\nalternated training, curriculum learning, and transductive ensemble learning to\ntrain neural machine translation (NMT) models based on the deep Transformer-big\narchitecture. Furthermore, to explore whether large language model (LLM) can\nhelp improve the translation quality of NMT systems, we use supervised\nfine-tuning to train llama2-13b as an Automatic post-editing (APE) model to\nimprove the translation results of the NMT model on the multi-domain machine\ntranslation task. By using these plyometric strategies, our submission achieves\na competitive result in the final evaluation.", "published": "2024-09-23 09:20:19", "link": "http://arxiv.org/abs/2409.14842v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "End-to-End Graph Flattening Method for Large Language Models", "abstract": "In recent years, the breakthrough of Large Language Models (LLMs) offers new\nideas for achieving universal methods on graph data. The common practice of\nconverting graphs into natural language for LLMs, which refers to graph\nflattening, exhibits good generalizability and interpretability. However, the\npoor organization of the textual format results in poor performance in\nlong-distance scenario understanding. Inspired by human cognitive reasoning\nhabits, we propose a novel method for graph flattening to fit LLMs, termed as\nEnd-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show\nthat EEDP enhances the reasoning performance of LLMs in long-distance scenarios\nwhile maintaining excellent performance in short-distance scenarios,\ndemonstrating good robustness in the face of distance variations.", "published": "2024-09-23 10:28:47", "link": "http://arxiv.org/abs/2409.14880v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language\n  Models", "abstract": "The use of pre-trained language models fine-tuned to address specific\ndownstream tasks is a common approach in natural language processing (NLP).\nHowever, acquiring domain-specific knowledge via fine-tuning is challenging.\nTraditional methods involve pretraining language models using vast amounts of\ndomain-specific data before fine-tuning for particular tasks. This study\ninvestigates emergency/non-emergency classification tasks based on electronic\nmedical record (EMR) data obtained from pediatric emergency departments (PEDs)\nin Korea. Our findings reveal that existing domain-specific pre-trained\nlanguage models underperform compared to general language models in handling\nN-lingual free-text data characteristics of non-English-speaking regions. To\naddress these limitations, we propose a domain knowledge transfer methodology\nthat leverages knowledge distillation to infuse general language models with\ndomain-specific knowledge via fine-tuning. This study demonstrates the\neffective transfer of specialized knowledge between models by defining a\ngeneral language model as the student model and a domain-specific pre-trained\nmodel as the teacher model. In particular, we address the complexities of EMR\ndata obtained from PEDs in non-English-speaking regions, such as Korea, and\ndemonstrate that the proposed method enhances classification performance in\nsuch contexts. The proposed methodology not only outperforms baseline models on\nKorean PED EMR data, but also promises broader applicability in various\nprofessional and technical domains. In future works, we intend to extend this\nmethodology to include diverse non-English-speaking regions and address\nadditional downstream tasks, with the aim of developing advanced model\narchitectures using state-of-the-art KD techniques. The code is available in\nhttps://github.com/JoSangYeon/DSG-KD.", "published": "2024-09-23 10:59:02", "link": "http://arxiv.org/abs/2409.14904v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey\n  on How to Make your LLMs use External Data More Wisely", "abstract": "Large language models (LLMs) augmented with external data have demonstrated\nremarkable capabilities in completing real-world tasks. Techniques for\nintegrating external data into LLMs, such as Retrieval-Augmented Generation\n(RAG) and fine-tuning, are gaining increasing attention and widespread\napplication. Nonetheless, the effective deployment of data-augmented LLMs\nacross various specialized fields presents substantial challenges. These\nchallenges encompass a wide range of issues, from retrieving relevant data and\naccurately interpreting user intent to fully harnessing the reasoning\ncapabilities of LLMs for complex tasks. We believe that there is no\none-size-fits-all solution for data-augmented LLM applications. In practice,\nunderperformance often arises from a failure to correctly identify the core\nfocus of a task or because the task inherently requires a blend of multiple\ncapabilities that must be disentangled for better resolution. In this survey,\nwe propose a RAG task categorization method, classifying user queries into four\nlevels based on the type of external data required and primary focus of the\ntask: explicit fact queries, implicit fact queries, interpretable rationale\nqueries, and hidden rationale queries. We define these levels of queries,\nprovide relevant datasets, and summarize the key challenges and most effective\ntechniques for addressing these challenges. Finally, we discuss three main\nforms of integrating external data into LLMs: context, small model, and\nfine-tuning, highlighting their respective strengths, limitations, and the\ntypes of problems they are suited to solve. This work aims to help readers\nthoroughly understand and decompose the data requirements and key bottlenecks\nin building LLM applications, offering solutions to the different challenges\nand serving as a guide to systematically developing such applications.", "published": "2024-09-23 11:20:20", "link": "http://arxiv.org/abs/2409.14924v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain\n  Beliefs of Others in Conversation Forecasting", "abstract": "Typically, when evaluating Theory of Mind, we consider the beliefs of others\nto be binary: held or not held. But what if someone is unsure about their own\nbeliefs? How can we quantify this uncertainty? We propose a new suite of tasks,\nchallenging language models (LMs) to model the uncertainty of others in\ndialogue. We design these tasks around conversation forecasting, wherein an\nagent forecasts an unobserved outcome to a conversation. Uniquely, we view\ninterlocutors themselves as forecasters, asking an LM to predict the\nuncertainty of the interlocutors (a probability). We experiment with re-scaling\nmethods, variance reduction strategies, and demographic context, for this\nregression task, conducting experiments on three dialogue corpora (social,\nnegotiation, task-oriented) with eight LMs. While LMs can explain up to 7%\nvariance in the uncertainty of others, we highlight the difficulty of the tasks\nand room for future work, especially in practical applications, like\nanticipating ``false", "published": "2024-09-23 13:05:25", "link": "http://arxiv.org/abs/2409.14986v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inference-Friendly Models With MixAttention", "abstract": "The size of the key-value (KV) cache plays a critical role in determining\nboth the maximum context length and the number of concurrent requests supported\nduring inference in modern language models. The KV cache size grows\nproportionally with the number of attention heads and the tokens processed,\nleading to increased memory consumption and slower inference for long inputs.\nIn this work, we explore the use of MixAttention, a model architecture\nmodification closely related to a blog published by Character.AI. MixAttention\ncombines sliding window attention, where only a small subset of recent tokens\nis stored in the KV cache, with KV cache sharing across layers. Our experiments\ndemonstrate that MixAttention significantly reduces memory usage and improves\ninference speed without sacrificing model performance in both short and\nlong-context tasks. We also explore various configurations of this\narchitecture, identifying those that maintain quality across evaluation metrics\nwhile optimizing resource efficiency.", "published": "2024-09-23 13:37:25", "link": "http://arxiv.org/abs/2409.15012v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative LLM Powered Conversational AI Application for Personalized\n  Risk Assessment: A Case Study in COVID-19", "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language tasks and are increasingly being applied in healthcare\ndomains. This work demonstrates a new LLM-powered disease risk assessment\napproach via streaming human-AI conversation, eliminating the need for\nprogramming required by traditional machine learning approaches. In a COVID-19\nseverity risk assessment case study, we fine-tune pre-trained generative LLMs\n(e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language\nexamples, comparing their performance with traditional classifiers (i.e.,\nLogistic Regression, XGBoost, Random Forest) that are trained de novo using\ntabular data across various experimental settings. We develop a mobile\napplication that uses these fine-tuned LLMs as its generative AI (GenAI) core\nto facilitate real-time interaction between clinicians and patients, providing\nno-code risk assessment through conversational interfaces. This integration not\nonly allows for the use of streaming Questions and Answers (QA) as inputs but\nalso offers personalized feature importance analysis derived from the LLM's\nattention layers, enhancing the interpretability of risk assessments. By\nachieving high Area Under the Curve (AUC) scores with a limited number of\nfine-tuning samples, our results demonstrate the potential of generative LLMs\nto outperform discriminative classification methods in low-data regimes,\nhighlighting their real-world adaptability and effectiveness. This work aims to\nfill the existing gap in leveraging generative LLMs for interactive no-code\nrisk assessment and to encourage further research in this emerging field.", "published": "2024-09-23 13:55:13", "link": "http://arxiv.org/abs/2409.15027v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP", "abstract": "CLIP has demonstrated great versatility in adapting to various downstream\ntasks, such as image editing and generation, visual question answering, and\nvideo understanding. However, CLIP-based applications often suffer from\nmisunderstandings regarding user intent, leading to discrepancies between the\nrequired number of objects and the actual outputs in image generation tasks. In\nthis work, we empirically investigate the quantity bias in CLIP. By carefully\ndesigning different experimental settings and datasets, we comprehensively\nevaluate CLIP's understanding of quantity from text, image, and cross-modal\nperspectives. Our experimental results reveal a quantity bias in CLIP\nembeddings, impacting the reliability of downstream tasks.", "published": "2024-09-23 14:01:16", "link": "http://arxiv.org/abs/2409.15035v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Scaling Laws of Decoder-Only Models on the Multilingual Machine\n  Translation Task", "abstract": "Recent studies have showcased remarkable capabilities of decoder-only models\nin many NLP tasks, including translation. Yet, the machine translation field\nhas been largely dominated by encoder-decoder models based on the Transformer\narchitecture. As a consequence, scaling laws of encoder-decoder models for\nneural machine translation have already been well studied, but decoder-only\nmodels have received less attention. This work explores the scaling laws of\ndecoder-only models on the multilingual and multidomain translation task. We\ntrained a collection of six decoder-only models, ranging from 70M to 7B\nparameters, on a sentence-level, multilingual and multidomain dataset. We\nconducted a series of experiments showing that the loss of decoder-only models\ncan be estimated using a scaling law similar to the one discovered for large\nlanguage models, but we also show that this scaling law has difficulties to\ngeneralize to too large models or to a different data distribution. We also\nstudy different scaling methods and show that scaling the depth and the width\nof a model lead to similar test loss improvements, but with different impact on\nthe model's efficiency.", "published": "2024-09-23 14:26:01", "link": "http://arxiv.org/abs/2409.15051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual\n  Conversations for Cross-Lingual Image Captioning", "abstract": "In this paper, we describe our system under the team name Brotherhood for the\nEnglish-to-Lowres Multi-Modal Translation Task. We participate in the\nmulti-modal translation tasks for English-Hindi, English-Hausa,\nEnglish-Bengali, and English-Malayalam language pairs. We present a method\nleveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and\nClaude 3.5 Sonnet, to enhance cross-lingual image captioning without\ntraditional training or fine-tuning. Our approach utilizes instruction-tuned\nprompting to generate rich, contextual conversations about cropped images,\nusing their English captions as additional context. These synthetic\nconversations are then translated into the target languages. Finally, we employ\na weighted prompting strategy, balancing the original English caption with the\ntranslated conversation to generate captions in the target language. This\nmethod achieved competitive results, scoring 37.90 BLEU on the English-Hindi\nChallenge Set and ranking first and second for English-Hausa on the Challenge\nand Evaluation Leaderboards, respectively. We conduct additional experiments on\na subset of 250 images, exploring the trade-offs between BLEU scores and\nsemantic similarity across various weighting schemes.", "published": "2024-09-23 14:29:46", "link": "http://arxiv.org/abs/2409.15052v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lessons Learned on Information Retrieval in Electronic Health Records: A\n  Comparison of Embedding Models and Pooling Strategies", "abstract": "Objective: Applying large language models (LLMs) to the clinical domain is\nchallenging due to the context-heavy nature of processing medical records.\nRetrieval-augmented generation (RAG) offers a solution by facilitating\nreasoning over large text sources. However, there are many parameters to\noptimize in just the retrieval system alone. This paper presents an ablation\nstudy exploring how different embedding models and pooling methods affect\ninformation retrieval for the clinical domain.\n  Methods: Evaluating on three retrieval tasks on two electronic health record\n(EHR) data sources, we compared seven models, including medical- and\ngeneral-domain models, specialized encoder embedding models, and off-the-shelf\ndecoder LLMs. We also examine the choice of embedding pooling strategy for each\nmodel, independently on the query and the text to retrieve.\n  Results: We found that the choice of embedding model significantly impacts\nretrieval performance, with BGE, a comparatively small general-domain model,\nconsistently outperforming all others, including medical-specific models.\nHowever, our findings also revealed substantial variability across datasets and\nquery text phrasings. We also determined the best pooling methods for each of\nthese models to guide future design of retrieval systems.\n  Discussion: The choice of embedding model, pooling strategy, and query\nformulation can significantly impact retrieval performance and the performance\nof these models on other public benchmarks does not necessarily transfer to new\ndomains. Further studies such as this one are vital for guiding\nempirically-grounded development of retrieval frameworks, such as in the\ncontext of RAG, for the clinical domain.", "published": "2024-09-23 16:16:08", "link": "http://arxiv.org/abs/2409.15163v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large\n  Language Models", "abstract": "Effective patient-provider communication is crucial in clinical care,\ndirectly impacting patient outcomes and quality of life. Traditional evaluation\nmethods, such as human ratings, patient feedback, and provider\nself-assessments, are often limited by high costs and scalability issues.\nAlthough existing natural language processing (NLP) techniques show promise,\nthey struggle with the nuances of clinical communication and require sensitive\nclinical data for training, reducing their effectiveness in real-world\napplications. Emerging large language models (LLMs) offer a new approach to\nassessing complex communication metrics, with the potential to advance the\nfield through integration into passive sensing and just-in-time intervention\nsystems. This study explores LLMs as evaluators of palliative care\ncommunication quality, leveraging their linguistic, in-context learning, and\nreasoning capabilities. Specifically, using simulated scripts crafted and\nlabeled by healthcare professionals, we test proprietary models (e.g., GPT-4)\nand fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset\ngenerated by GPT-4 to evaluate clinical conversations, to identify key metrics\nsuch as `understanding' and `empathy'. Our findings demonstrated LLMs' superior\nperformance in evaluating clinical communication, providing actionable feedback\nwith reasoning, and demonstrating the feasibility and practical viability of\ndeveloping in-house LLMs. This research highlights LLMs' potential to enhance\npatient-provider interactions and lays the groundwork for downstream steps in\ndeveloping LLM-empowered clinical health systems.", "published": "2024-09-23 16:39:12", "link": "http://arxiv.org/abs/2409.15188v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Learning from Contrastive Prompts: Automated Optimization and Adaptation", "abstract": "As LLMs evolve, significant effort is spent on manually crafting prompts.\nWhile existing prompt optimization methods automate this process, they rely\nsolely on learning from incorrect samples, leading to a sub-optimal\nperformance. Additionally, an unexplored challenge in the literature is prompts\neffective for prior models may not perform well on newer versions or different\nlanguages. We propose the Learning from Contrastive Prompts (LCP) framework to\naddress these gaps, enhancing both prompt optimization and adaptation. LCP\nemploys contrastive learning to generate effective prompts by analyzing\npatterns in good and bad prompt examples. Our evaluation on the Big-Bench Hard\ndataset shows that LCP has a win rate of over 76% over existing methods in\nprompt optimization and demonstrates strong adaptability across different model\nversions, families, and languages. LCP offers a systematic approach to prompt\nengineering, reducing manual effort in deploying LLMs across varied contexts.", "published": "2024-09-23 16:47:23", "link": "http://arxiv.org/abs/2409.15199v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue\n  Generation", "abstract": "Long-term memory is important for chatbots and dialogue systems (DS) to\ncreate consistent and human-like conversations, evidenced by numerous developed\nmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,\nexisting commonly used evaluation metrics, like retrieval accuracy and\nperplexity (PPL), mainly focus on query-oriented factualness and language\nquality assessment. However, these metrics often lack practical value.\nMoreover, the evaluation dimensions are insufficient for human-like assessment\nin DS. Regarding memory-recalling paradigms, current evaluation schemes only\nconsider passive memory retrieval while ignoring diverse memory recall with\nrich triggering factors, e.g., emotions and surroundings, which can be\nessential in emotional support scenarios. To bridge the gap, we construct a\nnovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various\nmemory-recalling paradigms based on cognitive science and psychology theories.\nThe benchmark assesses two tasks separately: memory retrieval and memory\nrecognition with the incorporation of both passive and proactive memory recall\ndata. We introduce new scoring criteria to the evaluation, including memory\ninjection, emotion support (ES) proficiency, and intimacy, to comprehensively\nassess generated responses. Results from cutting-edge embedding models and\nlarge language models on this benchmark indicate the potential for further\nadvancement. Extensive testing further reveals correlations between memory\ninjection, ES proficiency, and intimacy.", "published": "2024-09-23 17:38:41", "link": "http://arxiv.org/abs/2409.15240v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View", "abstract": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models\n(LLMs) was equipped with vision modules to create more human-like models.\nHowever, we should carefully evaluate their applications in different domains,\nas they may possess undesired biases. Our work studies the potential behavioral\nbiases of LVLMs from a behavioral finance perspective, an interdisciplinary\nsubject that jointly considers finance and psychology. We propose an end-to-end\nframework, from data collection to new evaluation metrics, to assess LVLMs'\nreasoning capabilities and the dynamic behaviors manifested in two established\nhuman financial behavioral biases: recency bias and authority bias. Our\nevaluations find that recent open-source LVLMs such as LLaVA-NeXT,\nMobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer\nsignificantly from these two biases, while the proprietary model GPT-4o is\nnegligibly impacted. Our observations highlight directions in which open-source\nmodels can improve. The code is available at\nhttps://github.com/mydcxiao/vlm_behavioral_fin.", "published": "2024-09-23 17:54:47", "link": "http://arxiv.org/abs/2409.15256v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?", "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across\nvarious domains and tasks, pushing the boundaries of our knowledge in learning\nand cognition. The latest model, OpenAI's o1, stands out as the first LLM with\nan internalized chain-of-thought technique using reinforcement learning\nstrategies. While it has demonstrated surprisingly strong capabilities on\nvarious general language tasks, its performance in specialized fields such as\nmedicine remains unknown. To this end, this report provides a comprehensive\nexploration of o1 on different medical scenarios, examining 3 key aspects:\nunderstanding, reasoning, and multilinguality. Specifically, our evaluation\nencompasses 6 tasks using data from 37 medical datasets, including two newly\nconstructed and more challenging question-answering (QA) tasks based on\nprofessional medical quizzes from the New England Journal of Medicine (NEJM)\nand The Lancet. These datasets offer greater clinical relevance compared to\nstandard medical QA benchmarks such as MedQA, translating more effectively into\nreal-world clinical utility. Our analysis of o1 suggests that the enhanced\nreasoning ability of LLMs may (significantly) benefit their capability to\nunderstand various medical instructions and reason through complex clinical\nscenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average\nof 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.\nBut meanwhile, we identify several weaknesses in both the model capability and\nthe existing evaluation protocols, including hallucination, inconsistent\nmultilingual ability, and discrepant metrics for evaluation. We release our raw\ndata and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future\nresearch.", "published": "2024-09-23 17:59:43", "link": "http://arxiv.org/abs/2409.15277v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Parse Trees Guided LLM Prompt Compression", "abstract": "Offering rich contexts to Large Language Models (LLMs) has shown to boost the\nperformance in various tasks, but the resulting longer prompt would increase\nthe computational cost and might exceed the input limit of LLMs. Recently, some\nprompt compression methods have been suggested to shorten the length of prompts\nby using language models to generate shorter prompts or by developing\ncomputational models to select important parts of original prompt. The\ngenerative compression methods would suffer from issues like hallucination,\nwhile the selective compression methods have not involved linguistic rules and\noverlook the global structure of prompt. To this end, we propose a novel\nselective compression method called PartPrompt. It first obtains a parse tree\nfor each sentence based on linguistic rules, and calculates local information\nentropy for each node in a parse tree. These local parse trees are then\norganized into a global tree according to the hierarchical structure such as\nthe dependency of sentences, paragraphs, and sections. After that, the\nroot-ward propagation and leaf-ward propagation are proposed to adjust node\nvalues over the global tree. Finally, a recursive algorithm is developed to\nprune the global tree based on the adjusted node values. The experiments show\nthat PartPrompt receives the state-of-the-art performance across various\ndatasets, metrics, compression ratios, and target LLMs for inference. The\nin-depth ablation studies confirm the effectiveness of designs in PartPrompt,\nand other additional experiments also demonstrate its superiority in terms of\nthe coherence of compressed prompts and in the extreme long prompt scenario.", "published": "2024-09-23 06:21:40", "link": "http://arxiv.org/abs/2409.15395v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors\n  in Pretrained Language Models", "abstract": "Recent advancements in artificial intelligence have led to the creation of\nhighly capable large language models (LLMs) that can perform tasks in a\nhuman-like manner. However, LLMs exhibit only infant-level cognitive abilities\nin certain areas. One such area is the A-Not-B error, a phenomenon seen in\ninfants where they repeat a previously rewarded behavior despite well-observed\nchanged conditions. This highlights their lack of inhibitory control -- the\nability to stop a habitual or impulsive response. In our work, we design a\ntext-based multi-choice QA scenario similar to the A-Not-B experimental\nsettings to systematically test the inhibitory control abilities of LLMs. We\nfound that state-of-the-art LLMs (like Llama3-8b) perform consistently well\nwith in-context learning (ICL) but make errors and show a significant drop of\nas many as 83.3% in reasoning tasks when the context changes trivially. This\nsuggests that LLMs only have inhibitory control abilities on par with human\ninfants in this regard, often failing to suppress the previously established\nresponse pattern during ICL.", "published": "2024-09-23 18:30:31", "link": "http://arxiv.org/abs/2409.15454v1", "categories": ["cs.CL", "cs.AI", "I.2.0"], "primary_category": "cs.CL"}
{"title": "RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented\n  Multi-role Multi-expert Collaboration", "abstract": "Recently, many studies focus on utilizing large language models (LLMs) into\neducational dialogues. Especially, within liberal arts dialogues, educators\nmust balance \\textbf{H}umanized communication, \\textbf{T}eaching expertise, and\n\\textbf{S}afety-ethics (\\textbf{HTS}), besides the subject knowledge itself.\nHowever, due to collecting massive amounts of HTS-compliant teaching dialogues\nfrom real world as training corpus is expensive, the outputs of existing LLMs\nin teaching dialogues fall short of human standards. To address this, we design\na Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework\nto automatically generate such dialogues data. Specifically, we first establish\nHTS-guided knowledge bases, encompassing three domain knowledge in teaching\nskills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are\nretrieval-augmented by the above different knowledge bases, into multi-experts\ngroups with distinct roles to generate the HTS-compliant educational dialogues\ndataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations\nindicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering\nmore personalized, and ethically safe teaching response, demonstrating RAM2C's\npracticality and high quality. We release the experiments at\n\\hyperlink{https://github.com/ram2c/ram2c}{https://github.com/ram2c/ram2c}.", "published": "2024-09-23 18:38:04", "link": "http://arxiv.org/abs/2409.15461v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Learning When to Retrieve, What to Rewrite, and How to Respond in\n  Conversational QA", "abstract": "Augmenting Large Language Models (LLMs) with information retrieval\ncapabilities (i.e., Retrieval-Augmented Generation (RAG)) has proven beneficial\nfor knowledge-intensive tasks. However, understanding users' contextual search\nintent when generating responses is an understudied topic for conversational\nquestion answering (QA). This conversational extension leads to additional\nconcerns when compared to single-turn QA as it is more challenging for systems\nto comprehend conversational context and manage retrieved passages over\nmultiple turns. In this work, we propose a method for enabling LLMs to decide\nwhen to retrieve in RAG settings given a conversational context. When retrieval\nis deemed necessary, the LLM then rewrites the conversation for passage\nretrieval and judges the relevance of returned passages before response\ngeneration. Operationally, we build on the single-turn SELF-RAG framework (Asai\net al., 2023) and propose SELF-multi-RAG for conversational settings.\nSELF-multi-RAG demonstrates improved capabilities over single-turn variants\nwith respect to retrieving relevant passages (by using summarized\nconversational context) and assessing the quality of generated responses.\nExperiments on three conversational QA datasets validate the enhanced response\ngeneration capabilities of SELF-multi-RAG, with improvements of ~13% measured\nby human annotation.", "published": "2024-09-23 20:05:12", "link": "http://arxiv.org/abs/2409.15515v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation", "abstract": "The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility'' questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI's text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.", "published": "2024-09-23 21:42:47", "link": "http://arxiv.org/abs/2409.15566v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimizing News Text Classification with Bi-LSTM and Attention Mechanism\n  for Efficient Data Processing", "abstract": "The development of Internet technology has led to a rapid increase in news\ninformation. Filtering out valuable content from complex information has become\nan urgentproblem that needs to be solved. In view of the shortcomings of\ntraditional manual classification methods that are time-consuming and\ninefficient, this paper proposes an automaticclassification scheme for news\ntexts based on deep learning. This solution achieves efficient classification\nand management of news texts by introducing advanced machine learning\nalgorithms, especially an optimization model that combines Bi-directional Long\nShort-Term Memory Network (Bi-LSTM) and Attention Mechanism. Experimental\nresults show that this solution can not only significantly improve the accuracy\nand timeliness of classification, but also significantly reduce the need for\nmanual intervention. It has important practical significance for improving the\ninformation processing capabilities of the news industry and accelerating the\nspeed of information flow. Through comparative analysis of multiple common\nmodels, the effectiveness and advancement of the proposed method are proved,\nlaying a solid foundation for future news text classification research.", "published": "2024-09-23 22:23:08", "link": "http://arxiv.org/abs/2409.15576v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Lost in the Logic: An Evaluation of Large Language Models' Reasoning\n  Capabilities on LSAT Logic Games", "abstract": "In this thesis, I evaluate the performance of Large Language Models (LLMs) on\nthe Law School Admissions Test (LSAT), specifically the Logic Games section of\nthe test. I focus on this section because it presents a complex logical\nreasoning task and thus is a valuable source of data for evaluating how modern,\nincreasingly capable LLMs can handle hard logical reasoning tasks. I construct\na dataset of LSAT logic games and their associated metadata, and extensively\nevaluate LLMs' performance in a Chain-of-Thought prompting setting. Given the\nweak performance in this setting, I explore other prompting frameworks on a\nsmaller subset of the dataset, adapting ideas from Reflexion to this task. This\nresults in a substantially improved accuracy of 70 percent for GPT-4 and 46\npercent for GPT-3.5 on this data subset, highlighting the capacity of LLMs to\nrevise their logical errors, despite initially weak performance. Finally, I\nanalyze the types of logic games that models perform better or worse on, as\nwell as the types of logical errors I observe from human annotation, providing\ndetailed insights on the logical reasoning capabilities of LLMs.", "published": "2024-09-23 21:37:40", "link": "http://arxiv.org/abs/2409.19012v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation\n  Learning", "abstract": "Developing robust and correctable visuomotor policies for robotic\nmanipulation is challenging due to the lack of self-recovery mechanisms from\nfailures and the limitations of simple language instructions in guiding robot\nactions. To address these issues, we propose a scalable data generation\npipeline that automatically augments expert demonstrations with failure\nrecovery trajectories and fine-grained language annotations for training. We\nthen introduce Rich languAge-guided failure reCovERy (RACER), a\nsupervisor-actor framework, which combines failure recovery data with rich\nlanguage descriptions to enhance robot control. RACER features a\nvision-language model (VLM) that acts as an online supervisor, providing\ndetailed language guidance for error correction and task execution, and a\nlanguage-conditioned visuomotor policy as an actor to predict the next actions.\nOur experimental results show that RACER outperforms the state-of-the-art\nRobotic View Transformer (RVT) on RLbench across various evaluation settings,\nincluding standard long-horizon tasks, dynamic goal-change tasks and zero-shot\nunseen tasks, achieving superior performance in both simulated and real world\nenvironments. Videos and code are available at:\nhttps://rich-language-failure-recovery.github.io.", "published": "2024-09-23 02:50:33", "link": "http://arxiv.org/abs/2409.14674v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Reducing the Footprint of Multi-Vector Retrieval with Minimal\n  Performance Impact via Token Pooling", "abstract": "Over the last few years, multi-vector retrieval methods, spearheaded by\nColBERT, have become an increasingly popular approach to Neural IR. By storing\nrepresentations at the token level rather than at the document level, these\nmethods have demonstrated very strong retrieval performance, especially in\nout-of-domain settings. However, the storage and memory requirements necessary\nto store the large number of associated vectors remain an important drawback,\nhindering practical adoption. In this paper, we introduce a simple\nclustering-based token pooling approach to aggressively reduce the number of\nvectors that need to be stored. This method can reduce the space & memory\nfootprint of ColBERT indexes by 50% with virtually no retrieval performance\ndegradation. This method also allows for further reductions, reducing the\nvector count by 66%-to-75% , with degradation remaining below 5% on a vast\nmajority of datasets. Importantly, this approach requires no architectural\nchange nor query-time processing, and can be used as a simple drop-in during\nindexation with any ColBERT-like model.", "published": "2024-09-23 03:12:43", "link": "http://arxiv.org/abs/2409.14683v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MemeCLIP: Leveraging CLIP Representations for Multimodal Meme\n  Classification", "abstract": "The complexity of text-embedded images presents a formidable challenge in\nmachine learning given the need for multimodal understanding of multiple\naspects of expression conveyed by them. While previous research in multimodal\nanalysis has primarily focused on singular aspects such as hate speech and its\nsubclasses, this study expands this focus to encompass multiple aspects of\nlinguistics: hate, targets of hate, stance, and humor. We introduce a novel\ndataset PrideMM comprising 5,063 text-embedded images associated with the\nLGBTQ+ Pride movement, thereby addressing a serious gap in existing resources.\nWe conduct extensive experimentation on PrideMM by using unimodal and\nmultimodal baseline methods to establish benchmarks for each task.\nAdditionally, we propose a novel framework MemeCLIP for efficient downstream\nlearning while preserving the knowledge of the pre-trained CLIP model. The\nresults of our experiments show that MemeCLIP achieves superior performance\ncompared to previously proposed frameworks on two real-world datasets. We\nfurther compare the performance of MemeCLIP and zero-shot GPT-4 on the hate\nclassification task. Finally, we discuss the shortcomings of our model by\nqualitatively analyzing misclassified samples. Our code and dataset are\npublicly available at: https://github.com/SiddhantBikram/MemeCLIP.", "published": "2024-09-23 04:49:08", "link": "http://arxiv.org/abs/2409.14703v2", "categories": ["cs.LG", "cs.CL", "cs.MM"], "primary_category": "cs.LG"}
{"title": "VLEU: a Method for Automatic Evaluation for Generalizability of\n  Text-to-Image Models", "abstract": "Progress in Text-to-Image (T2I) models has significantly improved the\ngeneration of images from textual descriptions. However, existing evaluation\nmetrics do not adequately assess the models' ability to handle a diverse range\nof textual prompts, which is crucial for their generalizability. To address\nthis, we introduce a new metric called Visual Language Evaluation Understudy\n(VLEU). VLEU uses large language models to sample from the visual text domain,\nthe set of all possible input texts for T2I models, to generate a wide variety\nof prompts. The images generated from these prompts are evaluated based on\ntheir alignment with the input text using the CLIP model.VLEU quantifies a\nmodel's generalizability by computing the Kullback-Leibler divergence between\nthe marginal distribution of the visual text and the conditional distribution\nof the images generated by the model. This metric provides a quantitative way\nto compare different T2I models and track improvements during model finetuning.\nOur experiments demonstrate the effectiveness of VLEU in evaluating the\ngeneralization capability of various T2I models, positioning it as an essential\nmetric for future research in text-to-image synthesis.", "published": "2024-09-23 04:50:36", "link": "http://arxiv.org/abs/2409.14704v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "I.2.10; I.2.7; I.3.7"], "primary_category": "cs.CV"}
{"title": "Orthogonal Finetuning for Direct Preference Optimization", "abstract": "DPO is an effective preference optimization algorithm. However, the DPO-tuned\nmodels tend to overfit on the dispreferred samples, manifested as overly long\ngenerations lacking diversity. While recent regularization approaches have\nendeavored to alleviate this issue by modifying the objective function, they\nachieved that at the cost of alignment performance degradation. In this paper,\nwe innovatively incorporate regularization from the perspective of weight\nupdating to curb alignment overfitting. Through the pilot experiment, we\ndiscovered that there exists a positive correlation between overfitting and the\nhyperspherical energy fluctuation. Hence, we introduce orthogonal finetuning\nfor DPO via a weight-Rotated Preference Optimization (RoPO) method, which\nmerely conducts rotational and magnitude-stretching updates on the weight\nparameters to maintain the hyperspherical energy invariant, thereby preserving\nthe knowledge encoded in the angle between neurons. Extensive experiments\ndemonstrate that our model aligns perfectly with human preferences while\nretaining the original expressive capacity using only 0.0086% of the trainable\nparameters, suggesting an effective regularization against overfitting.\nSpecifically, RoPO outperforms DPO by up to 10 points on MT-Bench and by up to\n2.8 points on AlpacaEval 2, while enhancing the generation diversity by an\naverage of 6 points.", "published": "2024-09-23 09:09:16", "link": "http://arxiv.org/abs/2409.14836v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Privacy Policy Analysis through Prompt Engineering for LLMs", "abstract": "Privacy policies are often obfuscated by their complexity, which impedes\ntransparency and informed consent. Conventional machine learning approaches for\nautomatically analyzing these policies demand significant resources and\nsubstantial domain-specific training, causing adaptability issues. Moreover,\nthey depend on extensive datasets that may require regular maintenance due to\nchanging privacy concerns.\n  In this paper, we propose, apply, and assess PAPEL (Privacy Policy Analysis\nthrough Prompt Engineering for LLMs), a framework harnessing the power of Large\nLanguage Models (LLMs) through prompt engineering to automate the analysis of\nprivacy policies. PAPEL aims to streamline the extraction, annotation, and\nsummarization of information from these policies, enhancing their accessibility\nand comprehensibility without requiring additional model training. By\nintegrating zero-shot, one-shot, and few-shot learning approaches and the\nchain-of-thought prompting in creating predefined prompts and prompt templates,\nPAPEL guides LLMs to efficiently dissect, interpret, and synthesize the\ncritical aspects of privacy policies into user-friendly summaries. We\ndemonstrate the effectiveness of PAPEL with two applications: (i) annotation\nand (ii) contradiction analysis. We assess the ability of several LLaMa and GPT\nmodels to identify and articulate data handling practices, offering insights\ncomparable to existing automated analysis approaches while reducing training\nefforts and increasing the adaptability to new analytical needs. The\nexperiments demonstrate that the LLMs PAPEL utilizes (LLaMA and Chat GPT\nmodels) achieve robust performance in privacy policy annotation, with F1 scores\nreaching 0.8 and above (using the OPP-115 gold standard), underscoring the\neffectiveness of simpler prompts across various advanced language models.", "published": "2024-09-23 10:23:31", "link": "http://arxiv.org/abs/2409.14879v1", "categories": ["cs.CL", "cs.CY", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Towards a Realistic Long-Term Benchmark for Open-Web Research Agents", "abstract": "We present initial results of a forthcoming benchmark for evaluating LLM\nagents on white-collar tasks of economic value. We evaluate agents on\nreal-world \"messy\" open-web research tasks of the type that are routine in\nfinance and consulting. In doing so, we lay the groundwork for an LLM agent\nevaluation suite where good performance directly corresponds to a large\neconomic and societal impact. We built and tested several agent architectures\nwith o1-preview, GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), and GPT-4o-mini.\nOn average, LLM agents powered by Claude-3.5 Sonnet and o1-preview\nsubstantially outperformed agents using GPT-4o, with agents based on Llama 3.1\n(405b) and GPT-4o-mini lagging noticeably behind. Across LLMs, a ReAct\narchitecture with the ability to delegate subtasks to subagents performed best.\nIn addition to quantitative evaluations, we qualitatively assessed the\nperformance of the LLM agents by inspecting their traces and reflecting on\ntheir observations. Our evaluation represents the first in-depth assessment of\nagents' abilities to conduct challenging, economically valuable analyst-style\nresearch on the real open web.", "published": "2024-09-23 11:08:04", "link": "http://arxiv.org/abs/2409.14913v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from\n  Unstructured Financial Documents", "abstract": "Multimodal key information extraction (KIE) models have been studied\nextensively on semi-structured documents. However, their investigation on\nunstructured documents is an emerging research topic. The paper presents an\napproach to adapt a multimodal transformer (i.e., ViBERTgrid previously\nexplored on semi-structured documents) for unstructured financial documents, by\nincorporating a BiLSTM-CRF layer. The proposed ViBERTgrid BiLSTM-CRF model\ndemonstrates a significant improvement in performance (up to 2 percentage\npoints) on named entity recognition from unstructured documents in financial\ndomain, while maintaining its KIE performance on semi-structured documents. As\nan additional contribution, we publicly released token-level annotations for\nthe SROIE dataset in order to pave the way for its use in multimodal sequence\nlabeling models.", "published": "2024-09-23 13:28:06", "link": "http://arxiv.org/abs/2409.15004v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Evaluating the Usability of LLMs in Threat Intelligence Enrichment", "abstract": "Large Language Models (LLMs) have the potential to significantly enhance\nthreat intelligence by automating the collection, preprocessing, and analysis\nof threat data. However, the usability of these tools is critical to ensure\ntheir effective adoption by security professionals. Despite the advanced\ncapabilities of LLMs, concerns about their reliability, accuracy, and potential\nfor generating inaccurate information persist. This study conducts a\ncomprehensive usability evaluation of five LLMs ChatGPT, Gemini, Cohere,\nCopilot, and Meta AI focusing on their user interface design, error handling,\nlearning curve, performance, and integration with existing tools in threat\nintelligence enrichment. Utilizing a heuristic walkthrough and a user study\nmethodology, we identify key usability issues and offer actionable\nrecommendations for improvement. Our findings aim to bridge the gap between LLM\nfunctionality and user experience, thereby promoting more efficient and\naccurate threat intelligence practices by ensuring these tools are\nuser-friendly and reliable.", "published": "2024-09-23 14:44:56", "link": "http://arxiv.org/abs/2409.15072v1", "categories": ["cs.CR", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Enhancing Scientific Reproducibility Through Automated BioCompute Object\n  Creation Using Retrieval-Augmented Generation from Publications", "abstract": "The exponential growth in computational power and accessibility has\ntransformed the complexity and scale of bioinformatics research, necessitating\nstandardized documentation for transparency, reproducibility, and regulatory\ncompliance. The IEEE BioCompute Object (BCO) standard addresses this need but\nfaces adoption challenges due to the overhead of creating compliant\ndocumentation, especially for legacy research. This paper presents a novel\napproach to automate the creation of BCOs from scientific papers using\nRetrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We\ndescribe the development of the BCO assistant tool that leverages RAG to\nextract relevant information from source papers and associated code\nrepositories, addressing key challenges such as LLM hallucination and\nlong-context understanding. The implementation incorporates optimized retrieval\nprocesses, including a two-pass retrieval with re-ranking, and employs\ncarefully engineered prompts for each BCO domain. We discuss the tool's\narchitecture, extensibility, and evaluation methods, including automated and\nmanual assessment approaches. The BCO assistant demonstrates the potential to\nsignificantly reduce the time and effort required for retroactive documentation\nof bioinformatics research while maintaining compliance with the standard. This\napproach opens avenues for AI-assisted scientific documentation and knowledge\nextraction from publications thereby enhancing scientific reproducibility. The\nBCO assistant tool and documentation is available at\nhttps://biocompute-objects.github.io/bco-rag/.", "published": "2024-09-23 14:51:22", "link": "http://arxiv.org/abs/2409.15076v1", "categories": ["cs.CL", "cs.AI", "q-bio.OT"], "primary_category": "cs.CL"}
{"title": "Efficiently Dispatching Flash Attention For Partially Filled Attention\n  Masks", "abstract": "Transformers are widely used across various applications, many of which yield\nsparse or partially filled attention matrices. Examples include attention masks\ndesigned to reduce the quadratic complexity of attention, sequence packing\ntechniques, and recent innovations like tree masking for fast validation in\nMEDUSA. Despite the inherent sparsity in these matrices, the state-of-the-art\nalgorithm Flash Attention still processes them with quadratic complexity as\nthough they were dense. In this paper, we introduce Binary Block Masking, a\nhighly efficient modification that enhances Flash Attention by making it\nmask-aware. We further propose two optimizations: one tailored for masks with\ncontiguous non-zero patterns and another for extremely sparse masks. Our\nexperiments on attention masks derived from real-world scenarios demonstrate up\nto a 9x runtime improvement. The implementation will be publicly released to\nfoster further research and application.", "published": "2024-09-23 15:11:07", "link": "http://arxiv.org/abs/2409.15097v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet\n  Extraction", "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model.", "published": "2024-09-23 16:49:47", "link": "http://arxiv.org/abs/2409.15202v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Archon: An Architecture Search Framework for Inference-Time Techniques", "abstract": "Inference-time techniques are emerging as highly effective tools to enhance\nlarge language model (LLM) capabilities. However, best practices for developing\nsystems that combine these techniques remain underdeveloped due to our limited\nunderstanding of the utility of individual inference-time techniques and the\ninteractions between them. Additionally, efficiently and automatically\nsearching the space of model choices, inference-time techniques, and their\ncompositions is challenging due to the large design space. To address these\nchallenges, we introduce Archon, a modular framework for selecting, combining,\nand stacking layers of inference-time techniques to construct optimized LLM\nsystems for target benchmarks. Rather than relying on a single LLM called once,\nwe leverage a diverse set of LLMs and inference-time techniques, creating LLM\nsystems greater than the sum of their parts. Archon defines an extensible\ndesign space, encompassing techniques such as generation ensembling, repeated\nsampling, ranking, fusion, critiquing, verification, and unit testing. It\ntransforms the problem of building LLM systems into a hyperparameter\noptimization objective. Given the available LLMs, inference-time techniques,\nand compute budget, Archon utilizes hyperparameter search techniques to\ndiscover optimized architectures for target benchmark(s). We evaluate Archon\narchitectures across a range of instruction-following, reasoning, and coding\nbenchmarks, including MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval,\nMixEval Hard, MATH, and CodeContests. Archon architectures outperform frontier\nmodels, such as GPT-4o and Claude 3.5 Sonnet, on these benchmarks, achieving an\naverage accuracy increase of 15.1 percentage points by using all available\nLLMs. We make our code and datasets available publicly on Github:\nhttps://github.com/ScalingIntelligence/Archon.", "published": "2024-09-23 17:53:42", "link": "http://arxiv.org/abs/2409.15254v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "OmniBench: Towards The Future of Universal Omni-Language Models", "abstract": "Recent advancements in multimodal large language models (MLLMs) have focused\non integrating multiple modalities, yet their ability to simultaneously process\nand reason across different inputs remains underexplored. We introduce\nOmniBench, a novel benchmark designed to evaluate models' ability to recognize,\ninterpret, and reason across visual, acoustic, and textual inputs\nsimultaneously. We define language models capable of such tri-modal processing\nas omni-language models (OLMs). OmniBench features high-quality human\nannotations that require integrated understanding across all modalities. Our\nevaluation reveals that: i) open-source OLMs show significant limitations in\ninstruction-following and reasoning in tri-modal contexts; and ii) most\nbaseline models perform poorly (around 50% accuracy) even with textual\nalternatives to image/audio inputs. To address these limitations, we develop\nOmniInstruct, an 96K-sample instruction tuning dataset for training OLMs. We\nadvocate for developing more robust tri-modal integration techniques and\ntraining strategies to enhance OLM performance. Codes and data could be found\nat our repo (https://github.com/multimodal-art-projection/OmniBench).", "published": "2024-09-23 17:59:05", "link": "http://arxiv.org/abs/2409.15272v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The ParlaSpeech Collection of Automatically Generated Speech and Text\n  Datasets from Parliamentary Proceedings", "abstract": "Recent significant improvements in speech and language technologies come both\nfrom self-supervised approaches over raw language data as well as various types\nof explicit supervision. To ensure high-quality processing of spoken data, the\nmost useful type of explicit supervision is still the alignment between the\nspeech signal and its corresponding text transcript, which is a data type that\nis not available for many languages. In this paper, we present our approach to\nbuilding large and open speech-and-text-aligned datasets of less-resourced\nlanguages based on transcripts of parliamentary proceedings and their\nrecordings. Our starting point are the ParlaMint comparable corpora of\ntranscripts of parliamentary proceedings of 26 national European parliaments.\nIn the pilot run on expanding the ParlaMint corpora with aligned publicly\navailable recordings, we focus on three Slavic languages, namely Croatian,\nPolish, and Serbian. The main challenge of our approach is the lack of any\nglobal alignment between the ParlaMint texts and the available recordings, as\nwell as the sometimes varying data order in each of the modalities, which\nrequires a novel approach in aligning long sequences of text and audio in a\nlarge search space. The results of this pilot run are three high-quality\ndatasets that span more than 5,000 hours of speech and accompanying text\ntranscripts. Although these datasets already make a huge difference in the\navailability of spoken and textual data for the three languages, we want to\nemphasize the potential of the presented approach in building similar datasets\nfor many more languages.", "published": "2024-09-23 10:12:18", "link": "http://arxiv.org/abs/2409.15397v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Rethinking Emotion Bias in Music via Frechet Audio Distance", "abstract": "The subjective nature of music emotion introduces inherent bias in both\nrecognition and generation, especially when relying on a single audio encoder,\nemotion classifier, or evaluation metric. In this work, we conduct a study on\nMusic Emotion Recognition (MER) and Emotional Music Generation (EMG), employing\ndiverse audio encoders alongside the Frechet Audio Distance (FAD), a\nreference-free evaluation metric. Our study begins with a benchmark evaluation\nof MER, highlighting the limitations associated with using a single audio\nencoder and the disparities observed across different measurements. We then\npropose assessing MER performance using FAD from multiple encoders to provide a\nmore objective measure of music emotion. Furthermore, we introduce an enhanced\nEMG approach designed to improve both the variation and prominence of generated\nmusic emotion, thus enhancing realism. Additionally, we investigate the realism\ndisparities between the emotions conveyed in real and synthetic music,\ncomparing our EMG model against two baseline models. Experimental results\nunderscore the emotion bias problem in both MER and EMG and demonstrate the\npotential of using FAD and diverse audio encoders to evaluate music emotion\nobjectively.", "published": "2024-09-23 20:59:15", "link": "http://arxiv.org/abs/2409.15545v2", "categories": ["eess.AS", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Asking an AI for salary negotiation advice is a matter of concern:\n  Controlled experimental perturbation of ChatGPT for protected and\n  non-protected group discrimination on a contextual task with no clear ground\n  truth answers", "abstract": "We conducted controlled experimental bias audits for four versions of\nChatGPT, which we asked to recommend an opening offer in salary negotiations\nfor a new hire. We submitted 98,800 prompts to each version, systematically\nvarying the employee's gender, university, and major, and tested prompts in\nvoice of each side of the negotiation: the employee versus employer. We find\nChatGPT as a multi-model platform is not robust and consistent enough to be\ntrusted for such a task. We observed statistically significant salary offers\nwhen varying gender for all four models, although with smaller gaps than for\nother attributes tested. The largest gaps were different model versions and\nbetween the employee- vs employer-voiced prompts. We also observed substantial\ngaps when varying university and major, but many of the biases were not\nconsistent across model versions. We tested for fictional and fraudulent\nuniversities and found wildly inconsistent results across cases and model\nversions. We make broader contributions to the AI/ML fairness literature. Our\nscenario and our experimental design differ from mainstream AI/ML auditing\nefforts in key ways. Bias audits typically test discrimination for protected\nclasses like gender, which we contrast with testing non-protected classes of\nuniversity and major. Asking for negotiation advice includes how aggressive one\nought to be in a negotiation relative to known empirical salary distributions\nand scales, which is a deeply contextual and personalized task that has no\nobjective ground truth to validate. These results raise concerns for the\nspecific model versions we tested and ChatGPT as a multi-model platform in\ncontinuous development. Our epistemology does not permit us to definitively\ncertify these models as either generally biased or unbiased on the attributes\nwe test, but our study raises matters of concern for stakeholders to further\ninvestigate.", "published": "2024-09-23 21:48:32", "link": "http://arxiv.org/abs/2409.15567v3", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue\n  Agents", "abstract": "Despite broad interest in modeling spoken dialogue agents, most approaches\nare inherently \"half-duplex\" -- restricted to turn-based interaction with\nresponses requiring explicit prompting by the user or implicit tracking of\ninterruption or silence events. Human dialogue, by contrast, is \"full-duplex\"\nallowing for rich synchronicity in the form of quick and dynamic turn-taking,\noverlapping speech, and backchanneling. Technically, the challenge of achieving\nfull-duplex dialogue with LLMs lies in modeling synchrony as pre-trained LLMs\ndo not have a sense of \"time\". To bridge this gap, we propose Synchronous LLMs\nfor full-duplex spoken dialogue modeling. We design a novel mechanism to\nintegrate time information into Llama3-8b so that they run synchronously with\nthe real-world clock. We also introduce a training recipe that uses 212k hours\nof synthetic spoken dialogue data generated from text dialogue data to create a\nmodel that generates meaningful and natural spoken dialogue, with just 2k hours\nof real-world spoken dialogue data. Synchronous LLMs outperform\nstate-of-the-art in dialogue meaningfulness while maintaining naturalness.\nFinally, we demonstrate the model's ability to participate in full-duplex\ndialogue by simulating interaction between two agents trained on different\ndatasets, while considering Internet-scale latencies of up to 240 ms. Webpage:\nhttps://syncllm.cs.washington.edu/.", "published": "2024-09-23 23:01:31", "link": "http://arxiv.org/abs/2409.15594v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Fully automatic extraction of morphological traits from the Web: utopia\n  or reality?", "abstract": "Plant morphological traits, their observable characteristics, are fundamental\nto understand the role played by each species within their ecosystem. However,\ncompiling trait information for even a moderate number of species is a\ndemanding task that may take experts years to accomplish. At the same time,\nmassive amounts of information about species descriptions is available online\nin the form of text, although the lack of structure makes this source of data\nimpossible to use at scale. To overcome this, we propose to leverage recent\nadvances in large language models (LLMs) and devise a mechanism for gathering\nand processing information on plant traits in the form of unstructured textual\ndescriptions, without manual curation. We evaluate our approach by\nautomatically replicating three manually created species-trait matrices. Our\nmethod managed to find values for over half of all species-trait pairs, with an\nF1-score of over 75%. Our results suggest that large-scale creation of\nstructured trait databases from unstructured online text is currently feasible\nthanks to the information extraction capabilities of LLMs, being limited by the\navailability of textual descriptions covering all the traits of interest.", "published": "2024-09-23 17:40:24", "link": "http://arxiv.org/abs/2409.17179v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unveiling the Potential of Graph Neural Networks in SME Credit Risk\n  Assessment", "abstract": "This paper takes the graph neural network as the technical framework,\nintegrates the intrinsic connections between enterprise financial indicators,\nand proposes a model for enterprise credit risk assessment. The main research\nwork includes: Firstly, based on the experience of predecessors, we selected 29\nenterprise financial data indicators, abstracted each indicator as a vertex,\ndeeply analyzed the relationships between the indicators, constructed a\nsimilarity matrix of indicators, and used the maximum spanning tree algorithm\nto achieve the graph structure mapping of enterprises; secondly, in the\nrepresentation learning phase of the mapped graph, a graph neural network model\nwas built to obtain its embedded representation. The feature vector of each\nnode was expanded to 32 dimensions, and three GraphSAGE operations were\nperformed on the graph, with the results pooled using the Pool operation, and\nthe final output of three feature vectors was averaged to obtain the graph's\nembedded representation; finally, a classifier was constructed using a\ntwo-layer fully connected network to complete the prediction task. Experimental\nresults on real enterprise data show that the model proposed in this paper can\nwell complete the multi-level credit level estimation of enterprises.\nFurthermore, the tree-structured graph mapping deeply portrays the intrinsic\nconnections of various indicator data of the company, and according to the ROC\nand other evaluation criteria, the model's classification effect is significant\nand has good \"robustness\".", "published": "2024-09-23 22:41:54", "link": "http://arxiv.org/abs/2409.17909v1", "categories": ["q-fin.RM", "cs.CL", "cs.LG"], "primary_category": "q-fin.RM"}
{"title": "A comprehensive study of on-device NLP applications -- VQA, automated\n  Form filling, Smart Replies for Linguistic Codeswitching", "abstract": "Recent improvement in large language models, open doors for certain new\nexperiences for on-device applications which were not possible before. In this\nwork, we propose 3 such new experiences in 2 categories. First we discuss\nexperiences which can be powered in screen understanding i.e. understanding\nwhats on user screen namely - (1) visual question answering, and (2) automated\nform filling based on previous screen. The second category of experience which\ncan be extended are smart replies to support for multilingual speakers with\ncode-switching. Code-switching occurs when a speaker alternates between two or\nmore languages. To the best of our knowledge, this is first such work to\npropose these tasks and solutions to each of them, to bridge the gap between\nlatest research and real world impact of the research in on-device\napplications.", "published": "2024-09-23 19:28:52", "link": "http://arxiv.org/abs/2409.19010v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Academic Skills Assessment with NLP and Ensemble Learning", "abstract": "This study addresses the critical challenges of assessing foundational\nacademic skills by leveraging advancements in natural language processing\n(NLP). Traditional assessment methods often struggle to provide timely and\ncomprehensive feedback on key cognitive and linguistic aspects, such as\ncoherence, syntax, and analytical reasoning. Our approach integrates multiple\nstate-of-the-art NLP models, including BERT, RoBERTa, BART, DeBERTa, and T5,\nwithin an ensemble learning framework. These models are combined through\nstacking techniques using LightGBM and Ridge regression to enhance predictive\naccuracy. The methodology involves detailed data preprocessing, feature\nextraction, and pseudo-label learning to optimize model performance. By\nincorporating sophisticated NLP techniques and ensemble learning, this study\nsignificantly improves the accuracy and efficiency of assessments, offering a\nrobust solution that surpasses traditional methods and opens new avenues for\neducational technology research focused on enhancing core academic\ncompetencies.", "published": "2024-09-23 23:43:43", "link": "http://arxiv.org/abs/2409.19013v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FeruzaSpeech: A 60 Hour Uzbek Read Speech Corpus with Punctuation,\n  Casing, and Context", "abstract": "This paper introduces FeruzaSpeech, a read speech corpus of the Uzbek\nlanguage, containing transcripts in both Cyrillic and Latin alphabets, freely\navailable for academic research purposes. This corpus includes 60 hours of\nhigh-quality recordings from a single native female speaker from Tashkent,\nUzbekistan. These recordings consist of short excerpts from a book and BBC\nNews. This paper discusses the enhancement of the Word Error Rates (WERs) on\nCommonVoice 16.1's Uzbek data, Uzbek Speech Corpus data, and FeruzaSpeech data\nupon integrating FeruzaSpeech.", "published": "2024-09-23 03:07:30", "link": "http://arxiv.org/abs/2410.00035v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Revise, Reason, and Recognize: LLM-Based Emotion Recognition via\n  Emotion-Specific Prompts and ASR Error Correction", "abstract": "Annotating and recognizing speech emotion using prompt engineering has\nrecently emerged with the advancement of Large Language Models (LLMs), yet its\nefficacy and reliability remain questionable. In this paper, we conduct a\nsystematic study on this topic, beginning with the proposal of novel prompts\nthat incorporate emotion-specific knowledge from acoustics, linguistics, and\npsychology. Subsequently, we examine the effectiveness of LLM-based prompting\non Automatic Speech Recognition (ASR) transcription, contrasting it with\nground-truth transcription. Furthermore, we propose a Revise-Reason-Recognize\nprompting pipeline for robust LLM-based emotion recognition from spoken\nlanguage with ASR errors. Additionally, experiments on context-aware learning,\nin-context learning, and instruction tuning are performed to examine the\nusefulness of LLM training schemes in this direction. Finally, we investigate\nthe sensitivity of LLMs to minor prompt variations. Experimental results\ndemonstrate the efficacy of the emotion-specific prompts, ASR error correction,\nand LLM training schemes for LLM-based emotion recognition. Our study aims to\nrefine the use of LLMs in emotion recognition and related domains.", "published": "2024-09-23 21:07:06", "link": "http://arxiv.org/abs/2409.15551v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Video-to-Audio Generation with Fine-grained Temporal Semantics", "abstract": "With recent advances of AIGC, video generation have gained a surge of\nresearch interest in both academia and industry (e.g., Sora). However, it\nremains a challenge to produce temporally aligned audio to synchronize the\ngenerated video, considering the complicated semantic information included in\nthe latter. In this work, inspired by the recent success of text-to-audio (TTA)\ngeneration, we first investigate the video-to-audio (VTA) generation framework\nbased on latent diffusion model (LDM). Similar to latest pioneering exploration\nin VTA, our preliminary results also show great potentials of LDM in VTA task,\nbut it still suffers from sub-optimal temporal alignment. To this end, we\npropose to enhance the temporal alignment of VTA with frame-level semantic\ninformation. With the recently popular grounding segment anything model\n(Grounding SAM), we can extract the fine-grained semantics in video frames to\nenable VTA to produce better-aligned audio signal. Extensive experiments\ndemonstrate the effectiveness of our system on both objective and subjective\nevaluation metrics, which shows both better audio quality and fine-grained\ntemporal alignment.", "published": "2024-09-23 05:05:47", "link": "http://arxiv.org/abs/2409.14709v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Room Impulse Responses help attackers to evade Deep Fake Detection", "abstract": "The ASVspoof 2021 benchmark, a widely-used evaluation framework for\nanti-spoofing, consists of two subsets: Logical Access (LA) and Deepfake (DF),\nfeaturing samples with varied coding characteristics and compression artifacts.\nNotably, the current state-of-the-art (SOTA) system boasts impressive\nperformance, achieving an Equal Error Rate (EER) of 0.87% on the LA subset and\n2.58% on the DF. However, benchmark accuracy is no guarantee of robustness in\nreal-world scenarios. This paper investigates the effectiveness of utilizing\nroom impulse responses (RIRs) to enhance fake speech and increase their\nlikelihood of evading fake speech detection systems. Our findings reveal that\nthis simple approach significantly improves the evasion rate, doubling the SOTA\nsystem's EER. To counter this type of attack, We augmented training data with a\nlarge-scale synthetic/simulated RIR dataset. The results demonstrate\nsignificant improvement on both reverberated fake speech and original samples,\nreducing DF task EER to 2.13%.", "published": "2024-09-23 05:17:30", "link": "http://arxiv.org/abs/2409.14712v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LlamaPartialSpoof: An LLM-Driven Fake Speech Dataset Simulating\n  Disinformation Generation", "abstract": "Previous fake speech datasets were constructed from a defender's perspective\nto develop countermeasure (CM) systems without considering diverse motivations\nof attackers. To better align with real-life scenarios, we created\nLlamaPartialSpoof, a 130-hour dataset that contains both fully and partially\nfake speech, using a large language model (LLM) and voice cloning technologies\nto evaluate the robustness of CMs. By examining valuable information for both\nattackers and defenders, we identify several key vulnerabilities in current CM\nsystems, which can be exploited to enhance attack success rates, including\nbiases toward certain text-to-speech models or concatenation methods. Our\nexperimental results indicate that the current fake speech detection system\nstruggle to generalize to unseen scenarios, achieving a best performance of\n24.49% equal error rate.", "published": "2024-09-23 06:41:52", "link": "http://arxiv.org/abs/2409.14743v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HiFi-Glot: Neural Formant Synthesis with Differentiable Resonant Filters", "abstract": "We introduce an end-to-end neural speech synthesis system that uses the\nsource-filter model of speech production. Specifically, we apply differentiable\nresonant filters to a glottal waveform generated by a neural vocoder. The aim\nis to obtain a controllable synthesiser, similar to classic formant synthesis,\nbut with much higher perceptual quality - filling a research gap in current\nneural waveform generators and responding to hitherto unmet needs in the speech\nsciences. Our setup generates audio from a core set of phonetically meaningful\nspeech parameters, with the filters providing direct control over formant\nfrequency resonances in synthesis. Direct synthesis control is a key feature\nfor reliable stimulus creation in important speech science experiments. We show\nthat the proposed source-filter method gives better perceptual quality than the\nindustry standard for formant manipulation (i.e., Praat), whilst being\ncompetitive in terms of formant frequency control accuracy.", "published": "2024-09-23 08:55:27", "link": "http://arxiv.org/abs/2409.14823v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Voice Conversion-based Privacy through Adversarial Information Hiding", "abstract": "Privacy-preserving voice conversion aims to remove only the attributes of\nspeech audio that convey identity information, keeping other speech\ncharacteristics intact. This paper presents a mechanism for privacy-preserving\nvoice conversion that allows controlling the leakage of identity-bearing\ninformation using adversarial information hiding. This enables a deliberate\ntrade-off between maintaining source-speech characteristics and modification of\nspeaker identity. As such, the approach improves on voice-conversion techniques\nlike CycleGAN and StarGAN, which were not designed for privacy, meaning that\nconverted speech may leak personal information in unpredictable ways. Our\napproach is also more flexible than ASR-TTS voice conversion pipelines, which\nby design discard all prosodic information linked to textual content.\nEvaluations show that the proposed system successfully modifies perceived\nspeaker identity whilst well maintaining source lexical content.", "published": "2024-09-23 11:16:49", "link": "http://arxiv.org/abs/2409.14919v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GALD-SE: Guided Anisotropic Lightweight Diffusion for Efficient Speech\n  Enhancement", "abstract": "Speech enhancement is designed to enhance the intelligibility and quality of\nspeech across diverse noise conditions. Recently, diffusion model has gained\nlots of attention in speech enhancement area, achieving competitive results.\nCurrent diffusion-based methods blur the signal with isotropic Gaussian noise\nand recover clean speech from the prior. However, these methods often suffer\nfrom a substantial computational burden. We argue that the computational\ninefficiency partially stems from the oversight that speech enhancement is not\npurely a generative task; it primarily involves noise reduction and completion\nof missing information, while the clean clues in the original mixture do not\nneed to be regenerated. In this paper, we propose a method that introduces\nnoise with anisotropic guidance during the diffusion process, allowing the\nneural network to preserve clean clues within noisy recordings. This approach\nsubstantially reduces computational complexity while exhibiting robustness\nagainst various forms of noise and speech distortion. Experiments demonstrate\nthat the proposed method achieves state-of-the-art results with only\napproximately 4.5 million parameters, a number significantly lower than that\nrequired by other diffusion methods. This effectively narrows the model size\ndisparity between diffusion-based and predictive speech enhancement approaches.\nAdditionally, the proposed method performs well in very noisy scenarios,\ndemonstrating its potential for applications in highly challenging\nenvironments.", "published": "2024-09-23 15:12:05", "link": "http://arxiv.org/abs/2409.15101v5", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptive Learning via a Negative Selection Strategy for Few-Shot\n  Bioacoustic Event Detection", "abstract": "Although the Prototypical Network (ProtoNet) has demonstrated effectiveness\nin few-shot biological event detection, two persistent issues remain. Firstly,\nthere is difficulty in constructing a representative negative prototype due to\nthe absence of explicitly annotated negative samples. Secondly, the durations\nof the target biological vocalisations vary across tasks, making it challenging\nfor the model to consistently yield optimal results across all tasks. To\naddress these issues, we propose a novel adaptive learning framework with an\nadaptive learning loss to guide classifier updates. Additionally, we propose a\nnegative selection strategy to construct a more representative negative\nprototype for ProtoNet. All experiments ware performed on the DCASE 2023 TASK5\nfew-shot bioacoustic event detection dataset. The results show that our\nproposed method achieves an F-measure of 0.703, an improvement of 12.84%.", "published": "2024-09-23 16:23:15", "link": "http://arxiv.org/abs/2409.15168v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comprehensive Survey with Critical Analysis for Deepfake Speech\n  Detection", "abstract": "Thanks to advancements in deep learning, speech generation systems now power\na variety of real-world applications, such as text-to-speech for individuals\nwith speech disorders, voice chatbots in call centers, cross-linguistic speech\ntranslation, etc. While these systems can autonomously generate human-like\nspeech and replicate specific voices, they also pose risks when misused for\nmalicious purposes. This motivates the research community to develop models for\ndetecting synthesized speech (e.g., fake speech) generated by\ndeep-learning-based models, referred to as the Deepfake Speech Detection task.\nAs the Deepfake Speech Detection task has emerged in recent years, there are\nnot many survey papers proposed for this task. Additionally, existing surveys\nfor the Deepfake Speech Detection task tend to summarize techniques used to\nconstruct a Deepfake Speech Detection system rather than providing a thorough\nanalysis. This gap motivated us to conduct a comprehensive survey, providing a\ncritical analysis of the challenges and developments in Deepfake Speech\nDetection. Our survey is innovatively structured, offering an in-depth analysis\nof current challenge competitions, public datasets, and the deep-learning\ntechniques that provide enhanced solutions to address existing challenges in\nthe field. From our analysis, we propose hypotheses on leveraging and combining\nspecific deep learning techniques to improve the effectiveness of Deepfake\nSpeech Detection systems. Beyond conducting a survey, we perform extensive\nexperiments to validate these hypotheses and propose a highly competitive model\nfor the task of Deepfake Speech Detection. Given the analysis and the\nexperimental results, we finally indicate potential and promising research\ndirections for the Deepfake Speech Detection task.", "published": "2024-09-23 16:34:53", "link": "http://arxiv.org/abs/2409.15180v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CA-MHFA: A Context-Aware Multi-Head Factorized Attentive Pooling for\n  SSL-Based Speaker Verification", "abstract": "Self-supervised learning (SSL) models for speaker verification (SV) have\ngained significant attention in recent years. However, existing SSL-based SV\nsystems often struggle to capture local temporal dependencies and generalize\nacross different tasks. In this paper, we propose context-aware multi-head\nfactorized attentive pooling (CA-MHFA), a lightweight framework that\nincorporates contextual information from surrounding frames. CA-MHFA leverages\ngrouped, learnable queries to effectively model contextual dependencies while\nmaintaining efficiency by sharing keys and values across groups. Experimental\nresults on the VoxCeleb dataset show that CA-MHFA achieves EERs of 0.42\\%,\n0.48\\%, and 0.96\\% on Vox1-O, Vox1-E, and Vox1-H, respectively, outperforming\ncomplex models like WavLM-TDNN with fewer parameters and faster convergence.\nAdditionally, CA-MHFA demonstrates strong generalization across multiple SSL\nmodels and tasks, including emotion recognition and anti-spoofing, highlighting\nits robustness and versatility.", "published": "2024-09-23 17:30:30", "link": "http://arxiv.org/abs/2409.15234v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Blind Localization of Early Room Reflections with Arbitrary Microphone\n  Array", "abstract": "Blindly estimating the direction of arrival (DoA) of early room reflections\nwithout prior knowledge of the room impulse response or source signal is highly\nvaluable in audio signal processing applications. The FF-PHALCOR (Frequency\nFocusing PHase ALigned CORrelation) method was recently developed for this\npurpose, extending the original PHALCOR method to work with arbitrary arrays\nrather than just spherical ones. Previous studies have provided only initial\ninsights into its performance. This study offers a comprehensive analysis of\nthe method's performance and limitations, examining how reflection\ncharacteristics such as delay, amplitude, and spatial density affect its\neffectiveness. The research also proposes improvements to overcome these\nlimitations, enhancing detection quality and reducing false alarms.\nAdditionally, the study examined how spatial perception is affected by\ngenerating room impulse responses using estimated reflection information. The\nfindings suggest a perceptual advantage of the proposed approach over the\nbaseline, with particularly high perceptual quality when using the spherical\narray with 32 microphones. However, the quality is somewhat reduced when using\na semi-circular array with only 6 microphones.", "published": "2024-09-23 19:11:16", "link": "http://arxiv.org/abs/2409.15484v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Blind Spatial Impulse Response Generation from Separate Room- and\n  Scene-Specific Information", "abstract": "For audio in augmented reality (AR), knowledge of the users' real acoustic\nenvironment is crucial for rendering virtual sounds that seamlessly blend into\nthe environment. As acoustic measurements are usually not feasible in practical\nAR applications, information about the room needs to be inferred from available\nsound sources. Then, additional sound sources can be rendered with the same\nroom acoustic qualities. Crucially, these are placed at different positions\nthan the sources available for estimation. Here, we propose to use an encoder\nnetwork trained using a contrastive loss that maps input sounds to a\nlow-dimensional feature space representing only room-specific information.\nThen, a diffusion-based spatial room impulse response generator is trained to\ntake the latent space and generate a new response, given a new source-receiver\nposition. We show how both room- and position-specific parameters are\nconsidered in the final output.", "published": "2024-09-23 12:41:31", "link": "http://arxiv.org/abs/2409.14971v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LoVA: Long-form Video-to-Audio Generation", "abstract": "Video-to-audio (V2A) generation is important for video editing and\npost-processing, enabling the creation of semantics-aligned audio for silent\nvideo. However, most existing methods focus on generating short-form audio for\nshort video segment (less than 10 seconds), while giving little attention to\nthe scenario of long-form video inputs. For current UNet-based diffusion V2A\nmodels, an inevitable problem when handling long-form audio generation is the\ninconsistencies within the final concatenated audio. In this paper, we first\nhighlight the importance of long-form V2A problem. Besides, we propose LoVA, a\nnovel model for Long-form Video-to-Audio generation. Based on the Diffusion\nTransformer (DiT) architecture, LoVA proves to be more effective at generating\nlong-form audio compared to existing autoregressive models and UNet-based\ndiffusion models. Extensive objective and subjective experiments demonstrate\nthat LoVA achieves comparable performance on 10-second V2A benchmark and\noutperforms all other baselines on a benchmark with long-form video input.", "published": "2024-09-23 16:04:50", "link": "http://arxiv.org/abs/2409.15157v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech2rtMRI: Speech-Guided Diffusion Model for Real-time MRI Video of\n  the Vocal Tract during Speech", "abstract": "Understanding speech production both visually and kinematically can inform\nsecond language learning system designs, as well as the creation of speaking\ncharacters in video games and animations. In this work, we introduce a\ndata-driven method to visually represent articulator motion in Magnetic\nResonance Imaging (MRI) videos of the human vocal tract during speech based on\narbitrary audio or speech input. We leverage large pre-trained speech models,\nwhich are embedded with prior knowledge, to generalize the visual domain to\nunseen data using a speech-to-video diffusion model. Our findings demonstrate\nthat the visual generation significantly benefits from the pre-trained speech\nrepresentations. We also observed that evaluating phonemes in isolation is\nchallenging but becomes more straightforward when assessed within the context\nof spoken words. Limitations of the current results include the presence of\nunsmooth tongue motion and video distortion when the tongue contacts the\npalate.", "published": "2024-09-23 20:19:24", "link": "http://arxiv.org/abs/2409.15525v1", "categories": ["eess.IV", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "eess.IV"}
{"title": "Safe Guard: an LLM-agent for Real-time Voice-based Hate Speech Detection\n  in Social Virtual Reality", "abstract": "In this paper, we present Safe Guard, an LLM-agent for the detection of hate\nspeech in voice-based interactions in social VR (VRChat). Our system leverages\nOpen AI GPT and audio feature extraction for real-time voice interactions. We\ncontribute a system design and evaluation of the system that demonstrates the\ncapability of our approach in detecting hate speech, and reducing false\npositives compared to currently available approaches. Our results indicate the\npotential of LLM-based agents in creating safer virtual environments and set\nthe groundwork for further advancements in LLM-driven moderation approaches.", "published": "2024-09-23 23:54:45", "link": "http://arxiv.org/abs/2409.15623v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "InsightPulse: An IoT-based System for User Experience Interview Analysis", "abstract": "Conducting efficient and effective user experience (UX) interviews often\nposes challenges, such as maintaining focus on key topics and managing the\nduration of interviews and post-interview analyses. To address these issues,\nthis paper introduces InsightPulse, an Internet of Things (IoT)-based hardware\nand software system designed to streamline and enhance the UX interview process\nthrough speech analysis and Artificial Intelligence. InsightPulse provides\nreal-time support during user interviews by automatically identifying and\nhighlighting key discussion points, proactively suggesting follow-up questions,\nand generating thematic summaries. These features enable more insightful\ndiscoveries and help to manage interview duration effectively. Additionally,\nthe system features a robust backend analytics dashboard that simplifies the\npost-interview review process, thus facilitating the quick extraction of\nactionable insights and enhancing overall UX research efficiency.", "published": "2024-09-23 21:39:34", "link": "http://arxiv.org/abs/2410.00036v1", "categories": ["cs.HC", "cs.AI", "eess.AS"], "primary_category": "cs.HC"}
