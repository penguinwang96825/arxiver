{"title": "The Next Chapter: A Study of Large Language Models in Storytelling", "abstract": "To enhance the quality of generated stories, recent story generation models\nhave been investigating the utilization of higher-level attributes like plots\nor commonsense knowledge. The application of prompt-based learning with large\nlanguage models (LLMs), exemplified by GPT-3, has exhibited remarkable\nperformance in diverse natural language processing (NLP) tasks. This paper\nconducts a comprehensive investigation, utilizing both automatic and human\nevaluation, to compare the story generation capacity of LLMs with recent models\nacross three datasets with variations in style, register, and length of\nstories. The results demonstrate that LLMs generate stories of significantly\nhigher quality compared to other story generation models. Moreover, they\nexhibit a level of performance that competes with human authors, albeit with\nthe preliminary observation that they tend to replicate real stories in\nsituations involving world knowledge, resembling a form of plagiarism.", "published": "2023-01-24 02:44:02", "link": "http://arxiv.org/abs/2301.09790v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Resource Compositional Semantic Parsing with Concept Pretraining", "abstract": "Semantic parsing plays a key role in digital voice assistants such as Alexa,\nSiri, and Google Assistant by mapping natural language to structured meaning\nrepresentations. When we want to improve the capabilities of a voice assistant\nby adding a new domain, the underlying semantic parsing model needs to be\nretrained using thousands of annotated examples from the new domain, which is\ntime-consuming and expensive. In this work, we present an architecture to\nperform such domain adaptation automatically, with only a small amount of\nmetadata about the new domain and without any new training data (zero-shot) or\nwith very few examples (few-shot). We use a base seq2seq (sequence-to-sequence)\narchitecture and augment it with a concept encoder that encodes intent and slot\ntags from the new domain. We also introduce a novel decoder-focused approach to\npretrain seq2seq models to be concept aware using Wikidata and use it to help\nour model learn important concepts and perform well in low-resource settings.\nWe report few-shot and zero-shot results for compositional semantic parsing on\nthe TOPv2 dataset and show that our model outperforms prior approaches in\nfew-shot settings for the TOPv2 and SNIPS datasets.", "published": "2023-01-24 04:27:27", "link": "http://arxiv.org/abs/2301.09809v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Identification of Disaster News For Crisis Management Using\n  Machine Learning", "abstract": "A lot of news sources picked up on Typhoon Rai (also known locally as Typhoon\nOdette), along with fake news outlets. The study honed in on the issue, to\ncreate a model that can identify between legitimate and illegitimate news\narticles. With this in mind, we chose the following machine learning algorithms\nin our development: Logistic Regression, Random Forest and Multinomial Naive\nBayes. Bag of Words, TF-IDF and Lemmatization were implemented in the Model.\nGathering 160 datasets from legitimate and illegitimate sources, the machine\nlearning was trained and tested. By combining all the machine learning\ntechniques, the Combined BOW model was able to reach an accuracy of 91.07%,\nprecision of 88.33%, recall of 94.64%, and F1 score of 91.38% and Combined\nTF-IDF model was able to reach an accuracy of 91.18%, precision of 86.89%,\nrecall of 94.64%, and F1 score of 90.60%.", "published": "2023-01-24 10:13:00", "link": "http://arxiv.org/abs/2301.09896v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conclusion-based Counter-Argument Generation", "abstract": "In real-world debates, the most common way to counter an argument is to\nreason against its main point, that is, its conclusion. Existing work on the\nautomatic generation of natural language counter-arguments does not address the\nrelation to the conclusion, possibly because many arguments leave their\nconclusion implicit. In this paper, we hypothesize that the key to effective\ncounter-argument generation is to explicitly model the argument's conclusion\nand to ensure that the stance of the generated counter is opposite to that\nconclusion. In particular, we propose a multitask approach that jointly learns\nto generate both the conclusion and the counter of an input argument. The\napproach employs a stance-based ranking component that selects the counter from\na diverse set of generated candidates whose stance best opposes the generated\nconclusion. In both automatic and manual evaluation, we provide evidence that\nour approach generates more relevant and stance-adhering counters than strong\nbaselines.", "published": "2023-01-24 10:49:01", "link": "http://arxiv.org/abs/2301.09911v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applications and Challenges of Sentiment Analysis in Real-life Scenarios", "abstract": "Sentiment analysis has benefited from the availability of lexicons and\nbenchmark datasets created over decades of research. However, its applications\nto the real world are a driving force for research in SA. This chapter\ndescribes some of these applications and related challenges in real-life\nscenarios. In this chapter, we focus on five applications of SA: health, social\npolicy, e-commerce, digital humanities and other areas of NLP. This chapter is\nintended to equip an NLP researcher with the `what', `why' and `how' of\napplications of SA: what is the application about, why it is important and\nchallenging and how current research in SA deals with the application. We note\nthat, while the use of deep learning techniques is a popular paradigm that\nspans these applications, challenges around privacy and selection bias of\ndatasets is a recurring theme across several applications.", "published": "2023-01-24 10:49:21", "link": "http://arxiv.org/abs/2301.09912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multitask Instruction-based Prompting for Fallacy Recognition", "abstract": "Fallacies are used as seemingly valid arguments to support a position and\npersuade the audience about its validity. Recognizing fallacies is an\nintrinsically difficult task both for humans and machines. Moreover, a big\nchallenge for computational models lies in the fact that fallacies are\nformulated differently across the datasets with differences in the input format\n(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,\nsocial media, dialogue, news), as well as types and number of fallacies (from 5\nto 18 types per dataset). To move towards solving the fallacy recognition task,\nwe approach these differences across datasets as multiple tasks and show how\ninstruction-based prompting in a multitask setup based on the T5 model improves\nthe results against approaches built for a specific dataset such as T5, BERT or\nGPT-3. We show the ability of this multitask prompting approach to recognize 28\nunique fallacies across domains and genres and study the effect of model size\nand prompt choice by analyzing the per-class (i.e., fallacy type) results.\nFinally, we analyze the effect of annotation quality on model performance, and\nthe feasibility of complementing this approach with external knowledge.", "published": "2023-01-24 13:39:23", "link": "http://arxiv.org/abs/2301.09992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Neutralization for an Inclusive Machine Translation: from\n  Theoretical Foundations to Open Challenges", "abstract": "Gender inclusivity in language technologies has become a prominent research\ntopic. In this study, we explore gender-neutral translation (GNT) as a form of\ngender inclusivity and a goal to be achieved by machine translation (MT)\nmodels, which have been found to perpetuate gender bias and discrimination.\nSpecifically, we focus on translation from English into Italian, a language\npair representative of salient gender-related linguistic transfer problems. To\ndefine GNT, we review a selection of relevant institutional guidelines for\ngender-inclusive language, discuss its scenarios of use, and examine the\ntechnical challenges of performing GNT in MT, concluding with a discussion of\npotential solutions to encourage advancements toward greater inclusivity in MT.", "published": "2023-01-24 15:26:36", "link": "http://arxiv.org/abs/2301.10075v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViHOS: Hate Speech Spans Detection for Vietnamese", "abstract": "The rise in hateful and offensive language directed at other users is one of\nthe adverse side effects of the increased use of social networking platforms.\nThis could make it difficult for human moderators to review tagged comments\nfiltered by classification systems. To help address this issue, we present the\nViHOS (Vietnamese Hate and Offensive Spans) dataset, the first human-annotated\ncorpus containing 26k spans on 11k comments. We also provide definitions of\nhateful and offensive spans in Vietnamese comments as well as detailed\nannotation guidelines. Besides, we conduct experiments with various\nstate-of-the-art models. Specifically, XLM-R$_{Large}$ achieved the best\nF1-scores in Single span detection and All spans detection, while\nPhoBERT$_{Large}$ obtained the highest in Multiple spans detection. Finally,\nour error analysis demonstrates the difficulties in detecting specific types of\nspans in our data for future research.\n  Disclaimer: This paper contains real comments that could be considered\nprofane, offensive, or abusive.", "published": "2023-01-24 17:53:21", "link": "http://arxiv.org/abs/2301.10186v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-Patcher: One Mistake worth One Neuron", "abstract": "Large Transformer-based Pretrained Language Models (PLMs) dominate almost all\nNatural Language Processing (NLP) tasks. Nevertheless, they still make mistakes\nfrom time to time. For a model deployed in an industrial environment, fixing\nthese mistakes quickly and robustly is vital to improve user experiences.\nPrevious works formalize such problems as Model Editing (ME) and mostly focus\non fixing one mistake. However, the one-mistake-fixing scenario is not an\naccurate abstraction of the real-world challenge. In the deployment of AI\nservices, there are ever-emerging mistakes, and the same mistake may recur if\nnot corrected in time. Thus a preferable solution is to rectify the mistakes as\nsoon as they appear nonstop. Therefore, we extend the existing ME into\nSequential Model Editing (SME) to help develop more practical editing methods.\nOur study shows that most current ME methods could yield unsatisfying results\nin this scenario. We then introduce Transformer-Patcher, a novel model editor\nthat can shift the behavior of transformer-based models by simply adding and\ntraining a few neurons in the last Feed-Forward Network layer. Experimental\nresults on both classification and generation tasks show that\nTransformer-Patcher can successively correct up to thousands of errors\n(Reliability) and generalize to their equivalent inputs (Generality) while\nretaining the model's accuracy on irrelevant inputs (Locality). Our method\noutperforms previous fine-tuning and HyperNetwork-based methods and achieves\nstate-of-the-art performance for Sequential Model Editing (SME). The code is\navailable at https://github.com/ZeroYuHuang/Transformer-Patcher.", "published": "2023-01-24 02:12:42", "link": "http://arxiv.org/abs/2301.09785v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual German Biomedical Information Extraction: from Zero-shot\n  to Human-in-the-Loop", "abstract": "This paper presents our project proposal for extracting biomedical\ninformation from German clinical narratives with limited amounts of\nannotations. We first describe the applied strategies in transfer learning and\nactive learning for solving our problem. After that, we discuss the design of\nthe user interface for both supplying model inspection and obtaining user\nannotations in the interactive environment.", "published": "2023-01-24 10:35:28", "link": "http://arxiv.org/abs/2301.09908v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Opportunities and Challenges in Neural Dialog Tutoring", "abstract": "Designing dialog tutors has been challenging as it involves modeling the\ndiverse and complex pedagogical strategies employed by human tutors. Although\nthere have been significant recent advances in neural conversational systems\nusing large language models (LLMs) and growth in available dialog corpora,\ndialog tutoring has largely remained unaffected by these advances. In this\npaper, we rigorously analyze various generative language models on two dialog\ntutoring datasets for language learning using automatic and human evaluations\nto understand the new opportunities brought by these advances as well as the\nchallenges we must overcome to build models that would be usable in real\neducational settings. We find that although current approaches can model\ntutoring in constrained learning scenarios when the number of concepts to be\ntaught and possible teacher strategies are small, they perform poorly in less\nconstrained scenarios. Our human quality evaluation shows that both models and\nground-truth annotations exhibit low performance in terms of equitable\ntutoring, which measures learning opportunities for students and how engaging\nthe dialog is. To understand the behavior of our models in a real tutoring\nsetting, we conduct a user study using expert annotators and find a\nsignificantly large number of model reasoning errors in 45% of conversations.\nFinally, we connect our findings to outline future work.", "published": "2023-01-24 11:00:17", "link": "http://arxiv.org/abs/2301.09919v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Semantic Scholar Open Data Platform", "abstract": "The volume of scientific output is creating an urgent need for automated\ntools to help scientists keep up with developments in their field. Semantic\nScholar (S2) is an open data platform and website aimed at accelerating science\nby helping scholars discover and understand scientific literature. We combine\npublic and proprietary data sources using state-of-the-art techniques for\nscholarly PDF content extraction and automatic knowledge graph construction to\nbuild the Semantic Scholar Academic Graph, the largest open scientific\nliterature graph to-date, with 200M+ papers, 80M+ authors, 550M+\npaper-authorship edges, and 2.4B+ citation edges. The graph includes advanced\nsemantic features such as structurally parsed text, natural language summaries,\nand vector embeddings. In this paper, we describe the components of the S2 data\nprocessing pipeline and the associated APIs offered by the platform. We will\nupdate this living document to reflect changes as we add new data offerings and\nimprove existing services.", "published": "2023-01-24 17:13:08", "link": "http://arxiv.org/abs/2301.10140v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Audience-Centric Natural Language Generation via Style Infusion", "abstract": "Adopting contextually appropriate, audience-tailored linguistic styles is\ncritical to the success of user-centric language generation systems (e.g.,\nchatbots, computer-aided writing, dialog systems). While existing approaches\ndemonstrate textual style transfer with large volumes of parallel or\nnon-parallel data, we argue that grounding style on audience-independent\nexternal factors is innately limiting for two reasons. First, it is difficult\nto collect large volumes of audience-specific stylistic data. Second, some\nstylistic objectives (e.g., persuasiveness, memorability, empathy) are hard to\ndefine without audience feedback.\n  In this paper, we propose the novel task of style infusion - infusing the\nstylistic preferences of audiences in pretrained language generation models.\nSince humans are better at pairwise comparisons than direct scoring - i.e., is\nSample-A more persuasive/polite/empathic than Sample-B - we leverage limited\npairwise human judgments to bootstrap a style analysis model and augment our\nseed set of judgments. We then infuse the learned textual style in a GPT-2\nbased text generator while balancing fluency and style adoption. With\nquantitative and qualitative assessments, we show that our infusion approach\ncan generate compelling stylized examples with generic text prompts. The code\nand data are accessible at https://github.com/CrowdDynamicsLab/StyleInfusion.", "published": "2023-01-24 19:57:50", "link": "http://arxiv.org/abs/2301.10283v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large language models can segment narrative events similarly to humans", "abstract": "Humans perceive discrete events such as \"restaurant visits\" and \"train rides\"\nin their continuous experience. One important prerequisite for studying human\nevent perception is the ability of researchers to quantify when one event ends\nand another begins. Typically, this information is derived by aggregating\nbehavioral annotations from several observers. Here we present an alternative\ncomputational approach where event boundaries are derived using a large\nlanguage model, GPT-3, instead of using human annotations. We demonstrate that\nGPT-3 can segment continuous narrative text into events. GPT-3-annotated events\nare significantly correlated with human event annotations. Furthermore, these\nGPT-derived annotations achieve a good approximation of the \"consensus\"\nsolution (obtained by averaging across human annotations); the boundaries\nidentified by GPT-3 are closer to the consensus, on average, than boundaries\nidentified by individual human annotators. This finding suggests that GPT-3\nprovides a feasible solution for automated event annotations, and it\ndemonstrates a further parallel between human cognition and prediction in large\nlanguage models. In the future, GPT-3 may thereby help to elucidate the\nprinciples underlying human event perception.", "published": "2023-01-24 20:34:37", "link": "http://arxiv.org/abs/2301.10297v1", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "AI vs. Human -- Differentiation Analysis of Scientific Content\n  Generation", "abstract": "Recent neural language models have taken a significant step forward in\nproducing remarkably controllable, fluent, and grammatical text. Although\nstudies have found that AI-generated text is not distinguishable from\nhuman-written text for crowd-sourcing workers, there still exist errors in\nAI-generated text which are even subtler and harder to spot. We primarily focus\non the scenario in which scientific AI writing assistant is deeply involved.\nFirst, we construct a feature description framework to distinguish between\nAI-generated text and human-written text from syntax, semantics, and pragmatics\nbased on the human evaluation. Then we utilize the features, i.e., writing\nstyle, coherence, consistency, and argument logistics, from the proposed\nframework to analyze two types of content. Finally, we adopt several publicly\navailable methods to investigate the gap of between AI-generated scientific\ntext and human-written scientific text by AI-generated scientific text\ndetection models. The results suggest that while AI has the potential to\ngenerate scientific content that is as accurate as human-written content, there\nis still a gap in terms of depth and overall quality. The AI-generated\nscientific content is more likely to contain errors in factual issues. We find\nthat there exists a \"writing style\" gap between AI-generated scientific text\nand human-written scientific text. Based on the analysis result, we summarize a\nseries of model-agnostic and distribution-agnostic features for detection tasks\nin other domains. Findings in this paper contribute to guiding the optimization\nof AI models to produce high-quality content and addressing related ethical and\nsecurity concerns.", "published": "2023-01-24 04:23:20", "link": "http://arxiv.org/abs/2301.10416v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semi-Automated Construction of Food Composition Knowledge Base", "abstract": "A food composition knowledge base, which stores the essential phyto-, micro-,\nand macro-nutrients of foods is useful for both research and industrial\napplications. Although many existing knowledge bases attempt to curate such\ninformation, they are often limited by time-consuming manual curation\nprocesses. Outside of the food science domain, natural language processing\nmethods that utilize pre-trained language models have recently shown promising\nresults for extracting knowledge from unstructured text. In this work, we\npropose a semi-automated framework for constructing a knowledge base of food\ncomposition from the scientific literature available online. To this end, we\nutilize a pre-trained BioBERT language model in an active learning setup that\nallows the optimal use of limited training data. Our work demonstrates how\nhuman-in-the-loop models are a step toward AI-assisted food systems that scale\nwell to the ever-increasing big data.", "published": "2023-01-24 22:08:49", "link": "http://arxiv.org/abs/2301.11322v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Causal-Discovery Performance of ChatGPT in the context of Neuropathic\n  Pain Diagnosis", "abstract": "ChatGPT has demonstrated exceptional proficiency in natural language\nconversation, e.g., it can answer a wide range of questions while no previous\nlarge language models can. Thus, we would like to push its limit and explore\nits ability to answer causal discovery questions by using a medical benchmark\n(Tu et al. 2019) in causal discovery.", "published": "2023-01-24 19:23:38", "link": "http://arxiv.org/abs/2301.13819v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Truveta Mapper: A Zero-shot Ontology Alignment Framework", "abstract": "In this paper, a new perspective is suggested for unsupervised Ontology\nMatching (OM) or Ontology Alignment (OA) by treating it as a translation task.\nOntologies are represented as graphs, and the translation is performed from a\nnode in the source ontology graph to a path in the target ontology graph. The\nproposed framework, Truveta Mapper (TM), leverages a multi-task\nsequence-to-sequence transformer model to perform alignment across multiple\nontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables\nthe model to implicitly learn the relationship between different ontologies via\ntransfer-learning without requiring any explicit cross-ontology manually\nlabeled data. This also enables the formulated framework to outperform existing\nsolutions for both runtime latency and alignment quality. The model is\npre-trained and fine-tuned only on publicly available text corpus and\ninner-ontologies data. The proposed solution outperforms state-of-the-art\napproaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented\nnew OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers\nlog-linear complexity, and overall makes the OM task efficient and more\nstraightforward without much post-processing involving mapping extension or\nmapping repair. We are open sourcing our solution.", "published": "2023-01-24 00:32:56", "link": "http://arxiv.org/abs/2301.09767v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Stability Analysis of Fine-Tuning a Pre-Trained Model", "abstract": "Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,\netc.) has proven to be one of the most promising paradigms in recent NLP\nresearch. However, numerous recent works indicate that fine-tuning suffers from\nthe instability problem, i.e., tuning the same model under the same setting\nresults in significantly different performance. Many recent works have proposed\ndifferent methods to solve this problem, but there is no theoretical\nunderstanding of why and how these methods work. In this paper, we propose a\nnovel theoretical stability analysis of fine-tuning that focuses on two\ncommonly used settings, namely, full fine-tuning and head tuning. We define the\nstability under each setting and prove the corresponding stability bounds. The\ntheoretical bounds explain why and how several existing methods can stabilize\nthe fine-tuning procedure. In addition to being able to explain most of the\nobserved empirical discoveries, our proposed theoretical analysis framework can\nalso help in the design of effective and provable methods. Based on our theory,\nwe propose three novel strategies to stabilize the fine-tuning procedure,\nnamely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self\nUnsupervised Re-Training (SURT). We extensively evaluate our proposed\napproaches on 11 widely used real-world benchmark datasets, as well as hundreds\nof synthetic classification datasets. The experiment results show that our\nproposed methods significantly stabilize the fine-tuning procedure and also\ncorroborate our theoretical analysis.", "published": "2023-01-24 05:11:17", "link": "http://arxiv.org/abs/2301.09820v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models as Fiduciaries: A Case Study Toward Robustly\n  Communicating With Artificial Intelligence Through Legal Standards", "abstract": "Artificial Intelligence (AI) is taking on increasingly autonomous roles,\ne.g., browsing the web as a research assistant and managing money. But\nspecifying goals and restrictions for AI behavior is difficult. Similar to how\nparties to a legal contract cannot foresee every potential \"if-then\"\ncontingency of their future relationship, we cannot specify desired AI behavior\nfor all circumstances. Legal standards facilitate robust communication of\ninherently vague and underspecified goals. Instructions (in the case of\nlanguage models, \"prompts\") that employ legal standards will allow AI agents to\ndevelop shared understandings of the spirit of a directive that generalize\nexpectations regarding acceptable actions to take in unspecified states of the\nworld. Standards have built-in context that is lacking from other goal\nspecification languages, such as plain language and programming languages.\nThrough an empirical study on thousands of evaluation labels we constructed\nfrom U.S. court opinions, we demonstrate that large language models (LLMs) are\nbeginning to exhibit an \"understanding\" of one of the most relevant legal\nstandards for AI agents: fiduciary obligations. Performance comparisons across\nmodels suggest that, as LLMs continue to exhibit improved core capabilities,\ntheir legal standards understanding will also continue to improve. OpenAI's\nlatest LLM has 78% accuracy on our data, their previous release has 73%\naccuracy, and a model from their 2020 GPT-3 paper has 27% accuracy (worse than\nrandom). Our research is an initial step toward a framework for evaluating AI\nunderstanding of legal standards more broadly, and for conducting reinforcement\nlearning with legal feedback (RLLF).", "published": "2023-01-24 16:03:20", "link": "http://arxiv.org/abs/2301.10095v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Watermark for Large Language Models", "abstract": "Potential harms of large language models can be mitigated by watermarking\nmodel output, i.e., embedding signals into generated text that are invisible to\nhumans but algorithmically detectable from a short span of tokens. We propose a\nwatermarking framework for proprietary language models. The watermark can be\nembedded with negligible impact on text quality, and can be detected using an\nefficient open-source algorithm without access to the language model API or\nparameters. The watermark works by selecting a randomized set of \"green\" tokens\nbefore a word is generated, and then softly promoting use of green tokens\nduring sampling. We propose a statistical test for detecting the watermark with\ninterpretable p-values, and derive an information-theoretic framework for\nanalyzing the sensitivity of the watermark. We test the watermark using a\nmulti-billion parameter model from the Open Pretrained Transformer (OPT)\nfamily, and discuss robustness and security.", "published": "2023-01-24 18:52:59", "link": "http://arxiv.org/abs/2301.10226v4", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Interactive-Chain-Prompting: Ambiguity Resolution for Crosslingual\n  Conditional Generation with Interaction", "abstract": "Crosslingual conditional generation (e.g., machine translation) has long\nenjoyed the benefits of scaling. Nonetheless, there are still issues that scale\nalone may not overcome. A source query in one language, for instance, may yield\nseveral translation options in another language without any extra context. Only\none translation could be acceptable however, depending on the translator's\npreferences and goals. Choosing the incorrect option might significantly affect\ntranslation usefulness and quality. We propose a novel method interactive-chain\nprompting -- a series of question, answering and generation intermediate steps\nbetween a Translator model and a User model -- that reduces translations into a\nlist of subproblems addressing ambiguities and then resolving such subproblems\nbefore producing the final text to be translated. To check ambiguity resolution\ncapabilities and evaluate translation quality, we create a dataset exhibiting\ndifferent linguistic phenomena which leads to ambiguities at inference for four\nlanguages. To encourage further exploration in this direction, we release all\ndatasets. We note that interactive-chain prompting, using eight interactions as\nexemplars, consistently surpasses prompt-based methods with direct access to\nbackground information to resolve ambiguities.", "published": "2023-01-24 21:08:13", "link": "http://arxiv.org/abs/2301.10309v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Generating High-Precision Feedback for Programming Syntax Errors using\n  Large Language Models", "abstract": "Large language models (LLMs), such as Codex, hold great promise in enhancing\nprogramming education by automatically generating feedback for students. We\ninvestigate using LLMs to generate feedback for fixing syntax errors in Python\nprograms, a key scenario in introductory programming. More concretely, given a\nstudent's buggy program, our goal is to generate feedback comprising a fixed\nprogram along with a natural language explanation describing the errors/fixes,\ninspired by how a human tutor would give feedback. While using LLMs is\npromising, the critical challenge is to ensure high precision in the generated\nfeedback, which is imperative before deploying such technology in classrooms.\nThe main research question we study is: Can we develop LLMs-based feedback\ngeneration techniques with a tunable precision parameter, giving educators\nquality control over the feedback that students receive? To this end, we\nintroduce PyFiXV, our technique to generate high-precision feedback powered by\nCodex. The key idea behind PyFiXV is to use a novel run-time validation\nmechanism to decide whether the generated feedback is suitable for sharing with\nthe student; notably, this validation mechanism also provides a precision knob\nto educators. We perform an extensive evaluation using two real-world datasets\nof Python programs with syntax errors and show the efficacy of PyFiXV in\ngenerating high-precision feedback.", "published": "2023-01-24 13:00:25", "link": "http://arxiv.org/abs/2302.04662v2", "categories": ["cs.PL", "cs.AI", "cs.CL"], "primary_category": "cs.PL"}
{"title": "A Comparison of Temporal Encoders for Neuromorphic Keyword Spotting with\n  Few Neurons", "abstract": "With the expansion of AI-powered virtual assistants, there is a need for\nlow-power keyword spotting systems providing a \"wake-up\" mechanism for\nsubsequent computationally expensive speech recognition. One promising approach\nis the use of neuromorphic sensors and spiking neural networks (SNNs)\nimplemented in neuromorphic processors for sparse event-driven sensing.\nHowever, this requires resource-efficient SNN mechanisms for temporal encoding,\nwhich need to consider that these systems process information in a streaming\nmanner, with physical time being an intrinsic property of their operation. In\nthis work, two candidate neurocomputational elements for temporal encoding and\nfeature extraction in SNNs described in recent literature - the spiking\ntime-difference encoder (TDE) and disynaptic excitatory-inhibitory (E-I)\nelements - are comparatively investigated in a keyword-spotting task on\nformants computed from spoken digits in the TIDIGITS dataset. While both\nencoders improve performance over direct classification of the formant features\nin the training data, enabling a complete binary classification with a logistic\nregression model, they show no clear improvements on the test set.\nResource-efficient keyword spotting applications may benefit from the use of\nthese encoders, but further work on methods for learning the time constants and\nweights is required to investigate their full potential.", "published": "2023-01-24 12:50:54", "link": "http://arxiv.org/abs/2301.09962v1", "categories": ["cs.NE", "eess.AS"], "primary_category": "cs.NE"}
{"title": "Perceptual evaluation of listener envelopment using spatial granular\n  synthesis", "abstract": "Listener envelopment refers to the sensation of being surrounded by sound,\neither by multiple direct sound events or by a diffuse reverberant sound field.\nMore recently, a specific attribute for the sensation of being covered by sound\nfrom elevated directions has been proposed by Sazdov et al. and was termed\nlistener engulfment. This contribution investigates the effect of the temporal\nand directional density of sound events on listener envelopment and engulfment.\nA spatial granular synthesis technique is used to precisely control the\ntemporal and directional density of sound events. Experimental results indicate\nthat a directionally uniform distribution of sound events at time intervals\n$\\Delta t < 20$ milliseconds is required to elicit a sensation of diffuse\nenvelopment, whereas longer time intervals lead to localized auditory events.\nIt shows that elevated loudspeaker layers do not increase envelopment, but\ncontribute specifically to listener engulfment. Lowpass-filtered stimuli\nincrease envelopment, but lead to a decreased control over engulfment. The\nresults can be exploited in the technical design and creative application of\nspatial sound synthesis and reverberation algorithms.", "published": "2023-01-24 18:36:13", "link": "http://arxiv.org/abs/2301.10210v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mesostructures: Beyond Spectrogram Loss in Differentiable Time-Frequency\n  Analysis", "abstract": "Computer musicians refer to mesostructures as the intermediate levels of\narticulation between the microstructure of waveshapes and the macrostructure of\nmusical forms. Examples of mesostructures include melody, arpeggios,\nsyncopation, polyphonic grouping, and textural contrast. Despite their central\nrole in musical expression, they have received limited attention in deep\nlearning. Currently, autoencoders and neural audio synthesizers are only\ntrained and evaluated at the scale of microstructure: i.e., local amplitude\nvariations up to 100 milliseconds or so. In this paper, we formulate and\naddress the problem of mesostructural audio modeling via a composition of a\ndifferentiable arpeggiator and time-frequency scattering. We empirically\ndemonstrate that time--frequency scattering serves as a differentiable model of\nsimilarity between synthesis parameters that govern mesostructure. By exposing\nthe sensitivity of short-time spectral distances to time alignment, we motivate\nthe need for a time-invariant and multiscale differentiable time--frequency\nmodel of similarity at the level of both local spectra and spectrotemporal\nmodulations.", "published": "2023-01-24 17:50:19", "link": "http://arxiv.org/abs/2301.10183v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WhisperWand: Simultaneous Voice and Gesture Tracking Interface", "abstract": "This paper presents the design and implementation of WhisperWand, a\ncomprehensive voice and motion tracking interface for voice assistants.\nDistinct from prior works, WhisperWand is a precise tracking interface that can\nco-exist with the voice interface on low sampling rate voice assistants. Taking\nhandwriting as a specific application, it can also capture natural strokes and\nthe individualized style of writing while occupying only a single frequency.\nThe core technique includes an accurate acoustic ranging method called Cross\nFrequency Continuous Wave (CFCW) sonar, enabling voice assistants to use\nultrasound as a ranging signal while using the regular microphone system of\nvoice assistants as a receiver. We also design a new optimization algorithm\nthat only requires a single frequency for time difference of arrival.\nWhisperWand prototype achieves 73 um of median error for 1D ranging and 1.4 mm\nof median error in 3D tracking of an acoustic beacon using the microphone array\nused in voice assistants. Our implementation of an in-air handwriting interface\nachieves 94.1% accuracy with automatic handwriting-to-text software, similar to\nwriting on paper (96.6%). At the same time, the error rate of voice-based user\nauthentication only increases from 6.26% to 8.28%.", "published": "2023-01-24 21:30:11", "link": "http://arxiv.org/abs/2301.10314v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Multilingual Multiaccented Multispeaker TTS with RADTTS", "abstract": "We work to create a multilingual speech synthesis system which can generate\nspeech with the proper accent while retaining the characteristics of an\nindividual voice. This is challenging to do because it is expensive to obtain\nbilingual training data in multiple languages, and the lack of such data\nresults in strong correlations that entangle speaker, language, and accent,\nresulting in poor transfer capabilities. To overcome this, we present a\nmultilingual, multiaccented, multispeaker speech synthesis model based on\nRADTTS with explicit control over accent, language, speaker and fine-grained\n$F_0$ and energy features. Our proposed model does not rely on bilingual\ntraining data. We demonstrate an ability to control synthesized accent for any\nspeaker in an open-source dataset comprising of 7 accents. Human subjective\nevaluation demonstrates that our model can better retain a speaker's voice and\naccent quality than controlled baselines while synthesizing fluent speech in\nall target languages and accents in our dataset.", "published": "2023-01-24 22:39:04", "link": "http://arxiv.org/abs/2301.10335v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from\n  Smartphone Cameras with Rolling Shutters and Movable Lenses", "abstract": "Our research discovers how the rolling shutter and movable lens structures\nwidely found in smartphone cameras modulate structure-borne sounds onto camera\nimages, creating a point-of-view (POV) optical-acoustic side channel for\nacoustic eavesdropping. The movement of smartphone camera hardware leaks\nacoustic information because images unwittingly modulate ambient sound as\nimperceptible distortions. Our experiments find that the side channel is\nfurther amplified by intrinsic behaviors of Complementary\nmetal-oxide-semiconductor (CMOS) rolling shutters and movable lenses such as in\nOptical Image Stabilization (OIS) and Auto Focus (AF). Our paper characterizes\nthe limits of acoustic information leakage caused by structure-borne sound that\nperturbs the POV of smartphone cameras. In contrast with traditional\noptical-acoustic eavesdropping on vibrating objects, this side channel requires\nno line of sight and no object within the camera's field of view (images of a\nceiling suffice). Our experiments test the limits of this side channel with a\nnovel signal processing pipeline that extracts and recognizes the leaked\nacoustic information. Our evaluation with 10 smartphones on a spoken digit\ndataset reports 80.66%, 91.28%, and 99.67% accuracies on recognizing 10 spoken\ndigits, 20 speakers, and 2 genders respectively. We further systematically\ndiscuss the possible defense strategies and implementations. By modeling,\nmeasuring, and demonstrating the limits of acoustic eavesdropping from\nsmartphone camera image streams, our contributions explain the physics-based\ncausality and possible ways to reduce the threat on current and future devices.", "published": "2023-01-24 15:00:47", "link": "http://arxiv.org/abs/2301.10056v2", "categories": ["cs.CR", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion\n  Model", "abstract": "Speech-driven gesture synthesis is a field of growing interest in virtual\nhuman creation. However, a critical challenge is the inherent intricate\none-to-many mapping between speech and gestures. Previous studies have explored\nand achieved significant progress with generative models. Notwithstanding, most\nsynthetic gestures are still vastly less natural. This paper presents\nDiffMotion, a novel speech-driven gesture synthesis architecture based on\ndiffusion models. The model comprises an autoregressive temporal encoder and a\ndenoising diffusion probability Module. The encoder extracts the temporal\ncontext of the speech input and historical gestures. The diffusion module\nlearns a parameterized Markov chain to gradually convert a simple distribution\ninto a complex distribution and generates the gestures according to the\naccompanied speech. Compared with baselines, objective and subjective\nevaluations confirm that our approach can produce natural and diverse\ngesticulation and demonstrate the benefits of diffusion-based models on\nspeech-driven gesture synthesis.", "published": "2023-01-24 14:44:03", "link": "http://arxiv.org/abs/2301.10047v2", "categories": ["cs.GR", "cs.CV", "cs.HC", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.GR"}
