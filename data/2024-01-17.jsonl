{"title": "ReFT: Reasoning with Reinforced Fine-Tuning", "abstract": "One way to enhance the reasoning capability of Large Language Models (LLMs)\nis to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT)\nannotations. This approach does not show sufficiently strong generalization\nability, however, because the training only relies on the given CoT data. In\nmath problem-solving, for example, there is usually only one annotated\nreasoning path for each question in the training data. Intuitively, it would be\nbetter for the algorithm to learn from multiple annotated reasoning paths given\na question. To address this issue, we propose a simple yet effective approach\ncalled Reinforced Fine-Tuning (ReFT) to enhance the generalizability of\nlearning LLMs for reasoning, with math problem-solving as an example. ReFT\nfirst warmups the model with SFT, and then employs on-line reinforcement\nlearning, specifically the PPO algorithm in this paper, to further fine-tune\nthe model, where an abundance of reasoning paths are automatically sampled\ngiven the question and the rewards are naturally derived from the ground-truth\nanswers. Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that\nReFT significantly outperforms SFT, and the performance can be potentially\nfurther boosted by combining inference-time strategies such as majority voting\nand re-ranking. Note that ReFT obtains the improvement by learning from the\nsame training questions as SFT, without relying on extra or augmented training\nquestions. This indicates a superior generalization ability for ReFT.", "published": "2024-01-17 04:43:21", "link": "http://arxiv.org/abs/2401.08967v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on\n  Large Language Models", "abstract": "Jailbreak attacks represent one of the most sophisticated threats to the\nsecurity of large language models (LLMs). To deal with such risks, we introduce\nan innovative framework that can help evaluate the effectiveness of jailbreak\nattacks on LLMs. Unlike traditional binary evaluations focusing solely on the\nrobustness of LLMs, our method assesses the attacking prompts' effectiveness.\nWe present two distinct evaluation frameworks: a coarse-grained evaluation and\na fine-grained evaluation. Each framework uses a scoring range from 0 to 1,\noffering unique perspectives and allowing for the assessment of attack\neffectiveness in different scenarios. Additionally, we develop a comprehensive\nground truth dataset specifically tailored for jailbreak prompts. This dataset\nis a crucial benchmark for our current study and provides a foundational\nresource for future research. By comparing with traditional evaluation methods,\nour study shows that the current results align with baseline metrics while\noffering a more nuanced and fine-grained assessment. It also helps identify\npotentially harmful attack prompts that might appear harmless in traditional\nevaluations. Overall, our work establishes a solid foundation for assessing a\nbroader range of attack prompts in prompt injection.", "published": "2024-01-17 06:42:44", "link": "http://arxiv.org/abs/2401.09002v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with\n  Explanation", "abstract": "Cyberbullying has become a big issue with the popularity of different social\nmedia networks and online communication apps. While plenty of research is going\non to develop better models for cyberbullying detection in monolingual\nlanguage, there is very little research on the code-mixed languages and\nexplainability aspect of cyberbullying. Recent laws like \"right to\nexplanations\" of General Data Protection Regulation, have spurred research in\ndeveloping interpretable models rather than focusing on performance. Motivated\nby this we develop the first interpretable multi-task model called {\\em mExCB}\nfor automatic cyberbullying detection from code-mixed languages which can\nsimultaneously solve several tasks, cyberbullying detection,\nexplanation/rationale identification, target group detection and sentiment\nanalysis. We have introduced {\\em BullyExplain}, the first benchmark dataset\nfor explainable cyberbullying detection in code-mixed language. Each post in\n{\\em BullyExplain} dataset is annotated with four labels, i.e., {\\em bully\nlabel, sentiment label, target and rationales (explainability)}, i.e., which\nphrases are being responsible for annotating the post as a bully. The proposed\nmultitask framework (mExCB) based on CNN and GRU with word and sub-sentence\n(SS) level attention is able to outperform several baselines and state of the\nart models when applied on {\\em BullyExplain} dataset.", "published": "2024-01-17 07:36:22", "link": "http://arxiv.org/abs/2401.09023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Textual Summarisation of Large Sets: Towards a General Approach", "abstract": "We are developing techniques to generate summary descriptions of sets of\nobjects. In this paper, we present and evaluate a rule-based NLG technique for\nsummarising sets of bibliographical references in academic papers. This extends\nour previous work on summarising sets of consumer products and shows how our\nmodel generalises across these two very different domains.", "published": "2024-01-17 08:16:05", "link": "http://arxiv.org/abs/2401.09041v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Research and Readers: A Multi-Modal Automated Academic Papers\n  Interpretation System", "abstract": "In the contemporary information era, significantly accelerated by the advent\nof Large-scale Language Models, the proliferation of scientific literature is\nreaching unprecedented levels. Researchers urgently require efficient tools for\nreading and summarizing academic papers, uncovering significant scientific\nliterature, and employing diverse interpretative methodologies. To address this\nburgeoning demand, the role of automated scientific literature interpretation\nsystems has become paramount. However, prevailing models, both commercial and\nopen-source, confront notable challenges: they often overlook multimodal data,\ngrapple with summarizing over-length texts, and lack diverse user interfaces.\nIn response, we introduce an open-source multi-modal automated academic paper\ninterpretation system (MMAPIS) with three-step process stages, incorporating\nLLMs to augment its functionality. Our system first employs the hybrid modality\npreprocessing and alignment module to extract plain text, and tables or figures\nfrom documents separately. It then aligns this information based on the section\nnames they belong to, ensuring that data with identical section names are\ncategorized under the same section. Following this, we introduce a hierarchical\ndiscourse-aware summarization method. It utilizes the extracted section names\nto divide the article into shorter text segments, facilitating specific\nsummarizations both within and between sections via LLMs with specific prompts.\nFinally, we have designed four types of diversified user interfaces, including\npaper recommendation, multimodal Q\\&A, audio broadcasting, and interpretation\nblog, which can be widely applied across various scenarios. Our qualitative and\nquantitative evaluations underscore the system's superiority, especially in\nscientific summarization, where it outperforms solutions relying solely on\nGPT-4.", "published": "2024-01-17 11:50:53", "link": "http://arxiv.org/abs/2401.09150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Strategies for Domain Specific Question Answering under Low\n  Annotation Budget Constraints", "abstract": "The progress introduced by pre-trained language models and their fine-tuning\nhas resulted in significant improvements in most downstream NLP tasks. The\nunsupervised training of a language model combined with further target task\nfine-tuning has become the standard QA fine-tuning procedure. In this work, we\ndemonstrate that this strategy is sub-optimal for fine-tuning QA models,\nespecially under a low QA annotation budget, which is a usual setting in\npractice due to the extractive QA labeling cost. We draw our conclusions by\nconducting an exhaustive analysis of the performance of the alternatives of the\nsequential fine-tuning strategy on different QA datasets. Based on the\nexperiments performed, we observed that the best strategy to fine-tune the QA\nmodel in low-budget settings is taking a pre-trained language model (PLM) and\nthen fine-tuning PLM with a dataset composed of the target dataset and SQuAD\ndataset. With zero extra annotation effort, the best strategy outperforms the\nstandard strategy by 2.28% to 6.48%. Our experiments provide one of the first\ninvestigations on how to best fine-tune a QA system under a low budget and are\ntherefore of the utmost practical interest to the QA practitioners.", "published": "2024-01-17 12:21:20", "link": "http://arxiv.org/abs/2401.09168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QAnswer: Towards Question Answering Search over Websites", "abstract": "Question Answering (QA) is increasingly used by search engines to provide\nresults to their end-users, yet very few websites currently use QA technologies\nfor their search functionality. To illustrate the potential of QA technologies\nfor the website search practitioner, we demonstrate web searches that combine\nQA over knowledge graphs and QA over free text -- each being usually tackled\nseparately. We also discuss the different benefits and drawbacks of both\napproaches for web site searches. We use the case studies made of websites\nhosted by the Wikimedia Foundation (namely Wikipedia and Wikidata). Differently\nfrom a search engine (e.g. Google, Bing, etc), the data are indexed integrally,\ni.e. we do not index only a subset, and they are indexed exclusively, i.e. we\nindex only data available on the corresponding website.", "published": "2024-01-17 12:31:45", "link": "http://arxiv.org/abs/2401.09175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniVIE: A Unified Label Space Approach to Visual Information Extraction\n  from Form-like Documents", "abstract": "Existing methods for Visual Information Extraction (VIE) from form-like\ndocuments typically fragment the process into separate subtasks, such as key\ninformation extraction, key-value pair extraction, and choice group extraction.\nHowever, these approaches often overlook the hierarchical structure of form\ndocuments, including hierarchical key-value pairs and hierarchical choice\ngroups. To address these limitations, we present a new perspective, reframing\nVIE as a relation prediction problem and unifying labels of different tasks\ninto a single label space. This unified approach allows for the definition of\nvarious relation types and effectively tackles hierarchical relationships in\nform-like documents. In line with this perspective, we present UniVIE, a\nunified model that addresses the VIE problem comprehensively. UniVIE functions\nusing a coarse-to-fine strategy. It initially generates tree proposals through\na tree proposal network, which are subsequently refined into hierarchical trees\nby a relation decoder module. To enhance the relation prediction capabilities\nof UniVIE, we incorporate two novel tree constraints into the relation decoder:\na tree attention mask and a tree level embedding. Extensive experimental\nevaluations on both our in-house dataset HierForms and a publicly available\ndataset SIBR, substantiate that our method achieves state-of-the-art results,\nunderscoring the effectiveness and potential of our unified approach in\nadvancing the field of VIE.", "published": "2024-01-17 14:02:36", "link": "http://arxiv.org/abs/2401.09220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Offensive Language Detection: A Systematic Review of\n  Datasets, Transfer Approaches and Challenges", "abstract": "The growing prevalence and rapid evolution of offensive language in social\nmedia amplify the complexities of detection, particularly highlighting the\nchallenges in identifying such content across diverse languages. This survey\npresents a systematic and comprehensive exploration of Cross-Lingual Transfer\nLearning (CLTL) techniques in offensive language detection in social media. Our\nstudy stands as the first holistic overview to focus exclusively on the\ncross-lingual scenario in this domain. We analyse 67 relevant papers and\ncategorise these studies across various dimensions, including the\ncharacteristics of multilingual datasets used, the cross-lingual resources\nemployed, and the specific CLTL strategies implemented. According to \"what to\ntransfer\", we also summarise three main CLTL transfer approaches: instance,\nfeature, and parameter transfer. Additionally, we shed light on the current\nchallenges and future research opportunities in this field. Furthermore, we\nhave made our survey resources available online, including two comprehensive\ntables that provide accessible references to the multilingual datasets and CLTL\nmethods used in the reviewed literature.", "published": "2024-01-17 14:44:27", "link": "http://arxiv.org/abs/2401.09244v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient slot labelling", "abstract": "Slot labelling is an essential component of any dialogue system, aiming to\nfind important arguments in every user turn. Common approaches involve large\npre-trained language models (PLMs) like BERT or RoBERTa, but they face\nchallenges such as high computational requirements and dependence on\npre-training data. In this work, we propose a lightweight method which performs\non par or better than the state-of-the-art PLM-based methods, while having\nalmost 10x less trainable parameters. This makes it especially applicable for\nreal-life industry scenarios.", "published": "2024-01-17 17:08:36", "link": "http://arxiv.org/abs/2401.09343v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs' Mathematical and Coding Competency through\n  Ontology-guided Interventions", "abstract": "Recent advancements in Large Language Models (LLMs) have showcased striking\nresults on existing logical reasoning benchmarks, with some models even\nsurpassing human performance. However, the true depth of their competencies and\nrobustness in reasoning tasks remains an open question. To this end, in this\npaper, we focus on two popular reasoning tasks: arithmetic reasoning and code\ngeneration. Particularly, we introduce (i) a general ontology of perturbations\nfor math and coding questions, (ii) a semi-automatic method to apply these\nperturbations, and (iii) two datasets, GSMORE and HUMANEVAL-CORE, respectively,\nof perturbed math and coding problems to probe LLM capabilities in numeric\nreasoning and coding tasks. Through comprehensive evaluations of both\nclosed-source and open-source LLMs, we show a significant performance drop\nacross all the models against the perturbed questions, suggesting that the\ncurrent LLMs lack robust problem solving skills and structured reasoning\nabilities in many areas, as defined by our ontology. We open-source the\ndatasets and source codes at: https://github.com/declare-lab/LLM-ReasoningTest.", "published": "2024-01-17 18:13:07", "link": "http://arxiv.org/abs/2401.09395v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimating the severity of dental and oral problems via sentiment\n  classification over clinical reports", "abstract": "Analyzing authors' sentiments in texts as a technique for identifying text\npolarity can be practical and useful in various fields, including medicine and\ndentistry. Currently, due to factors such as patients' limited knowledge about\ntheir condition, difficulties in accessing specialist doctors, or fear of\nillness, particularly in pandemic conditions, there might be a delay between\nreceiving a radiology report and consulting a doctor. In some cases, this delay\ncan pose significant risks to the patient, making timely decision-making\ncrucial. Having an automatic system that can inform patients about the\ndeterioration of their condition by analyzing the text of radiology reports\ncould greatly impact timely decision-making. In this study, a dataset\ncomprising 1,134 cone-beam computed tomography (CBCT) photo reports was\ncollected from the Shiraz University of Medical Sciences. Each case was\nexamined, and an expert labeled a severity level for the patient's condition on\neach document. After preprocessing all the text data, a deep learning model\nbased on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)\nnetwork architecture, known as CNN-LSTM, was developed to detect the severity\nlevel of the patient's problem based on sentiment analysis in the radiologist's\nreport. The model's performance was evaluated on two datasets, each with two\nand four classes, in both imbalanced and balanced scenarios. Finally, to\ndemonstrate the effectiveness of our model, we compared its performance with\nthat of other classification models. The results, along with one-way ANOVA and\nTukey's test, indicated that our proposed model (CNN-LSTM) performed the best\naccording to precision, recall, and f-measure criteria. This suggests that it\ncan be a reliable model for estimating the severity of oral and dental\ndiseases, thereby assisting patients.", "published": "2024-01-17 14:33:13", "link": "http://arxiv.org/abs/2401.12993v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Context-Contrastive Inference Approach To Partial Diacritization", "abstract": "Diacritization plays a pivotal role in improving readability and\ndisambiguating the meaning of Arabic texts. Efforts have so far focused on\nmarking every eligible character (Full Diacritization). Comparatively\noverlooked, Partial Diacritzation (PD) is the selection of a subset of\ncharacters to be marked to aid comprehension where needed. Research has\nindicated that excessive diacritic marks can hinder skilled readers -- reducing\nreading speed and accuracy. We conduct a behavioral experiment and show that\npartially marked text is often easier to read than fully marked text, and\nsometimes easier than plain text. In this light, we introduce\nContext-Contrastive Partial Diacritization (CCPD) -- a novel approach to PD\nwhich integrates seamlessly with existing Arabic diacritization systems. CCPD\nprocesses each word twice, once with context and once without, and diacritizes\nonly the characters with disparities between the two inferences. Further, we\nintroduce novel indicators for measuring partial diacritization quality,\nessential for establishing this as a machine learning task. Lastly, we\nintroduce TD2, a Transformer-variant of an established model which offers a\nmarkedly different performance profile on our proposed indicators compared to\nall other known systems.", "published": "2024-01-17 02:04:59", "link": "http://arxiv.org/abs/2401.08919v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs for Relational Reasoning: How Far are We?", "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural\nlanguage processing, software engineering, etc.) by achieving state-of-the-art\nperformance on extensive downstream tasks. Aiming to achieve robust and general\nartificial intelligence, there has been a surge of interest in investigating\nthe reasoning ability of the LLMs. Whereas the textual and numerical reasoning\nbenchmarks adopted by previous works are rather shallow and simple, it is hard\nto conclude that the LLMs possess strong reasoning ability by merely achieving\npositive results on these benchmarks. Recent efforts have demonstrated that the\nLLMs are poor at solving sequential decision-making problems that require\ncommon-sense planning by evaluating their performance on the reinforcement\nlearning benchmarks. In this work, we conduct an in-depth assessment of several\nstate-of-the-art LLMs' reasoning ability based on the inductive logic\nprogramming (ILP) benchmark, which is broadly recognized as a representative\nand challenging measurement for evaluating logic program induction/synthesis\nsystems as it requires inducing strict cause-effect logic to achieve robust\ndeduction on independent and identically distributed (IID) and\nout-of-distribution (OOD) test samples. Our evaluations illustrate that\ncompared with the neural program induction systems which are much smaller in\nmodel size, the state-of-the-art LLMs are much poorer in terms of reasoning\nability by achieving much lower performance and generalization using either\nnatural language prompting or truth-value matrix prompting.", "published": "2024-01-17 08:22:52", "link": "http://arxiv.org/abs/2401.09042v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Asynchronous Local-SGD Training for Language Modeling", "abstract": "Local stochastic gradient descent (Local-SGD), also referred to as federated\naveraging, is an approach to distributed optimization where each device\nperforms more than one SGD update per communication. This work presents an\nempirical study of {\\it asynchronous} Local-SGD for training language models;\nthat is, each worker updates the global parameters as soon as it has finished\nits SGD steps. We conduct a comprehensive investigation by examining how worker\nhardware heterogeneity, model size, number of workers, and optimizer could\nimpact the learning performance. We find that with naive implementations,\nasynchronous Local-SGD takes more iterations to converge than its synchronous\ncounterpart despite updating the (global) model parameters more frequently. We\nidentify momentum acceleration on the global parameters when worker gradients\nare stale as a key challenge. We propose a novel method that utilizes a delayed\nNesterov momentum update and adjusts the workers' local training steps based on\ntheir computation speed. This approach, evaluated with models up to 150M\nparameters on the C4 dataset, matches the performance of synchronous Local-SGD\nin terms of perplexity per update step, and significantly surpasses it in terms\nof wall clock time.", "published": "2024-01-17 11:17:04", "link": "http://arxiv.org/abs/2401.09135v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning from Implicit User Feedback, Emotions and Demographic\n  Information in Task-Oriented and Document-Grounded Dialogues", "abstract": "Implicit user feedback, user emotions and demographic information have shown\nto be promising sources for improving the accuracy and user engagement of\nresponses generated by dialogue systems. However, the influence of such\ninformation on task completion and factual consistency, which are important\ncriteria for task-oriented and document-grounded dialogues, is not yet known.\nTo address this, we introduce FEDI, the first English task-oriented and\ndocument-grounded dialogue dataset annotated with this information. Our\nexperiments with Flan-T5, GPT-2 and Llama 2 show a particularly positive impact\non task completion and factual consistency. Participants in our human\nevaluation reported that the responses generated by the feedback-trained models\nwere more informative (Flan-T5 and GPT-2), relevant and factual consistent\n(Llama 2).", "published": "2024-01-17 14:52:26", "link": "http://arxiv.org/abs/2401.09248v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Machines Do See Color: A Guideline to Classify Different Forms of Racist\n  Discourse in Large Corpora", "abstract": "Current methods to identify and classify racist language in text rely on\nsmall-n qualitative approaches or large-n approaches focusing exclusively on\novert forms of racist discourse. This article provides a step-by-step\ngeneralizable guideline to identify and classify different forms of racist\ndiscourse in large corpora. In our approach, we start by conceptualizing racism\nand its different manifestations. We then contextualize these racist\nmanifestations to the time and place of interest, which allows researchers to\nidentify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a\ncross-lingual model for supervised text classification with a cutting-edge\ncontextual understanding of text. We show that XLM-R and XLM-R-Racismo, our\npretrained model, outperform other state-of-the-art approaches in classifying\nracism in large corpora. We illustrate our approach using a corpus of tweets\nrelating to the Ecuadorian ind\\'igena community between 2018 and 2021.", "published": "2024-01-17 16:57:18", "link": "http://arxiv.org/abs/2401.09333v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Neurosymbolic Reasoners", "abstract": "A wide range of real-world applications is characterized by their symbolic\nnature, necessitating a strong capability for symbolic reasoning. This paper\ninvestigates the potential application of Large Language Models (LLMs) as\nsymbolic reasoners. We focus on text-based games, significant benchmarks for\nagents with natural language capabilities, particularly in symbolic tasks like\nmath, map reading, sorting, and applying common sense in text-based worlds. To\nfacilitate these agents, we propose an LLM agent designed to tackle symbolic\nchallenges and achieve in-game objectives. We begin by initializing the LLM\nagent and informing it of its role. The agent then receives observations and a\nset of valid actions from the text-based games, along with a specific symbolic\nmodule. With these inputs, the LLM agent chooses an action and interacts with\nthe game environments. Our experimental results demonstrate that our method\nsignificantly enhances the capability of LLMs as automated agents for symbolic\nreasoning, and our LLM agent is effective in text-based games involving\nsymbolic tasks, achieving an average performance of 88% across all tasks.", "published": "2024-01-17 16:57:19", "link": "http://arxiv.org/abs/2401.09334v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deciphering Textual Authenticity: A Generalized Strategy through the\n  Lens of Large Language Semantics for Detecting Human vs. Machine-Generated\n  Text", "abstract": "With the recent proliferation of Large Language Models (LLMs), there has been\nan increasing demand for tools to detect machine-generated text. The effective\ndetection of machine-generated text face two pertinent problems: First, they\nare severely limited in generalizing against real-world scenarios, where\nmachine-generated text is produced by a variety of generators, including but\nnot limited to GPT-4 and Dolly, and spans diverse domains, ranging from\nacademic manuscripts to social media posts. Second, existing detection\nmethodologies treat texts produced by LLMs through a restrictive binary\nclassification lens, neglecting the nuanced diversity of artifacts generated by\ndifferent LLMs. In this work, we undertake a systematic study on the detection\nof machine-generated text in real-world scenarios. We first study the\neffectiveness of state-of-the-art approaches and find that they are severely\nlimited against text produced by diverse generators and domains in the real\nworld. Furthermore, t-SNE visualizations of the embeddings from a pretrained\nLLM's encoder show that they cannot reliably distinguish between human and\nmachine-generated text. Based on our findings, we introduce a novel system,\nT5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder\ncombined with LLM embedding sub-clustering to address the text produced by\ndiverse generators and domains in the real world. We evaluate our approach\nacross 9 machine-generated text systems and 9 domains and find that our\napproach provides state-of-the-art generalization ability, with an average\nincrease in F1 score on machine-generated text of 19.6\\% on unseen generators\nand domains compared to the top performing existing approaches and correctly\nattributes the generator of text with an accuracy of 93.6\\%.", "published": "2024-01-17 18:45:13", "link": "http://arxiv.org/abs/2401.09407v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BERTologyNavigator: Advanced Question Answering with BERT-based\n  Semantics", "abstract": "The development and integration of knowledge graphs and language models has\nsignificance in artificial intelligence and natural language processing. In\nthis study, we introduce the BERTologyNavigator -- a two-phased system that\ncombines relation extraction techniques and BERT embeddings to navigate the\nrelationships within the DBLP Knowledge Graph (KG). Our approach focuses on\nextracting one-hop relations and labelled candidate pairs in the first phases.\nThis is followed by employing BERT's CLS embeddings and additional heuristics\nfor relation selection in the second phase. Our system reaches an F1 score of\n0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score\non the subset of the DBLP QuAD test dataset during the QA phase.", "published": "2024-01-17 19:11:30", "link": "http://arxiv.org/abs/2401.09553v1", "categories": ["cs.CL", "cs.AI", "I.2.4; I.2.7"], "primary_category": "cs.CL"}
{"title": "Aligning Large Language Models with Counterfactual DPO", "abstract": "Advancements in large language models (LLMs) have demonstrated remarkable\ncapabilities across a diverse range of applications. These models excel in\ngenerating text completions that are contextually coherent and cover an\nextensive array of subjects. However, the vast datasets required for their\ntraining make aligning response styles during the pretraining and instruction\ntuning phases challenging. Consequently, an additional alignment phase is\ntypically employed, wherein the model is further trained with human preference\ndata to better align its outputs with human expectations. While this process\ndoesn't introduce new capabilities per se, it does accentuate generation styles\ninnate to the model. This paper explores the utilization of counterfactual\nprompting within the framework of Direct Preference Optimization (DPO) to align\nthe model's style without relying on human intervention. We demonstrate that\nthis method effectively instils desirable behaviour, mitigates undesirable\nones, and encourages the model to disregard inappropriate instructions. Our\nfindings suggest that counterfactual prompting with DPO presents a low-resource\nway to fine-tune LLMs to meet the demands for responsible and ethically aligned\nAI systems.", "published": "2024-01-17 19:43:43", "link": "http://arxiv.org/abs/2401.09566v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed\n  Reality", "abstract": "One key challenge in Augmented Reality is the placement of virtual content in\nnatural locations. Most existing automated techniques can only work with a\nclosed-vocabulary, fixed set of objects. In this paper, we introduce and\nevaluate several methods for automatic object placement using recent advances\nin open-vocabulary vision-language models. Through a multifaceted evaluation,\nwe identify a new state-of-the-art method, OCTO+. We also introduce a benchmark\nfor automatically evaluating the placement of virtual objects in augmented\nreality, alleviating the need for costly user studies. Through this, in\naddition to human evaluations, we find that OCTO+ places objects in a valid\nregion over 70% of the time, outperforming other methods on a range of metrics.", "published": "2024-01-17 04:52:40", "link": "http://arxiv.org/abs/2401.08973v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Adapter Finetuning for Tail Languages in Streaming\n  Multilingual ASR", "abstract": "The end-to-end ASR model is often desired in the streaming multilingual\nscenario since it is easier to deploy and can benefit from pre-trained speech\nmodels such as powerful foundation models. Meanwhile, the heterogeneous nature\nand imbalanced data abundance of different languages may cause performance\ndegradation, leading to asynchronous peak performance for different languages\nduring training, especially on tail ones. Sometimes even the data itself may\nbecome unavailable as a result of the enhanced privacy protection. Existing\nwork tend to significantly increase the model size or learn language-specific\ndecoders to accommodate each language separately. In this study, we explore\nsimple yet effective Language-Dependent Adapter (LDA) finetuning under a\ncascaded Conformer transducer framework enhanced by teacher pseudo-labeling for\ntail languages in the streaming multilingual ASR. The adapter only accounts for\n0.4% of the full model per language. It is plugged into the frozen foundation\nmodel and is the only trainable module during the finetuning process with noisy\nstudent training. The final model merges the adapter parameters from different\ncheckpoints for different languages. The model performance is validated on a\nchallenging multilingual dictation dataset, which includes 39 tail languages\nacross Latin, Greek, Arabic, etc. Our proposed method brings 12.2% word error\nrate reduction on average and up to 37.5% on a single locale. Furthermore, we\nshow that our parameter-efficient LDA can match the quality of the full model\nfinetuning, thus greatly alleviating the asynchronous peak performance issue.", "published": "2024-01-17 06:01:16", "link": "http://arxiv.org/abs/2401.08992v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Augmenting Math Word Problems via Iterative Question Composing", "abstract": "Despite the advancements in large language models (LLMs) for mathematical\nreasoning, solving competition-level math problems remains a significant\nchallenge, especially for open-source LLMs without external tools. We introduce\nthe MMIQC dataset, comprising a mixture of processed web data and synthetic\nquestion-response pairs, aimed at enhancing the mathematical reasoning\ncapabilities of base language models. Models fine-tuned on MMIQC consistently\nsurpass their counterparts in performance on the MATH benchmark across various\nmodel sizes. Notably, Qwen-72B-MMIQC achieves a 45.0% accuracy, exceeding the\nprevious open-source state-of-the-art by 8.2% and outperforming the initial\nversion GPT-4 released in 2023. Extensive evaluation results on Hungarian high\nschool finals suggest that such improvement can generalize to unseen data. Our\nablation study on MMIQC reveals that a large part of the improvement can be\nattributed to our novel augmentation method, Iterative Question Composing\n(IQC), which involves iteratively composing new questions from seed problems\nusing an LLM and applying rejection sampling through another LLM.", "published": "2024-01-17 06:48:16", "link": "http://arxiv.org/abs/2401.09003v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Code Simulation Challenges for Large Language Models", "abstract": "Many reasoning, planning, and problem-solving tasks share an intrinsic\nalgorithmic nature: correctly simulating each step is a sufficient condition to\nsolve them correctly. This work studies to what extent Large Language Models\n(LLMs) can simulate coding and algorithmic tasks to provide insights into\ngeneral capabilities in such algorithmic reasoning tasks. We introduce\nbenchmarks for straight-line programs, code that contains critical paths, and\napproximate and redundant instructions. We further assess the simulation\ncapabilities of LLMs with sorting algorithms and nested loops and show that a\nroutine's computational complexity directly affects an LLM's ability to\nsimulate its execution. While the most powerful LLMs exhibit relatively strong\nsimulation capabilities, the process is fragile, seems to rely heavily on\npattern recognition, and is affected by memorisation. We propose a novel\noff-the-shelf prompting method, Chain of Simulation (CoSm), which instructs\nLLMs to simulate code execution line by line/follow the computation pattern of\ncompilers. CoSm efficiently helps LLMs reduce memorisation and shallow pattern\nrecognition while improving simulation performance. We consider the success of\nCoSm in code simulation to be inspirational for other general routine\nsimulation reasoning tasks.", "published": "2024-01-17 09:23:59", "link": "http://arxiv.org/abs/2401.09074v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.LG"}
{"title": "Should agentic conversational AI change how we think about ethics?\n  Characterising an interactional ethics centred on respect", "abstract": "With the growing popularity of conversational agents based on large language\nmodels (LLMs), we need to ensure their behaviour is ethical and appropriate.\nWork in this area largely centres around the 'HHH' criteria: making outputs\nmore helpful and honest, and avoiding harmful (biased, toxic, or inaccurate)\nstatements. Whilst this semantic focus is useful when viewing LLM agents as\nmere mediums or output-generating systems, it fails to account for pragmatic\nfactors that can make the same speech act seem more or less tactless or\ninconsiderate in different social situations. With the push towards agentic AI,\nwherein systems become increasingly proactive in chasing goals and performing\nactions in the world, considering the pragmatics of interaction becomes\nessential. We propose an interactional approach to ethics that is centred on\nrelational and situational factors. We explore what it means for a system, as a\nsocial actor, to treat an individual respectfully in a (series of)\ninteraction(s). Our work anticipates a set of largely unexplored risks at the\nlevel of situated social interaction, and offers practical suggestions to help\nagentic LLM technologies treat people well.", "published": "2024-01-17 09:44:03", "link": "http://arxiv.org/abs/2401.09082v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "68T42", "H.5.2; I.2; I.2.1; J.4; J.5"], "primary_category": "cs.CL"}
{"title": "Improving Classification Performance With Human Feedback: Label a few,\n  we label the rest", "abstract": "In the realm of artificial intelligence, where a vast majority of data is\nunstructured, obtaining substantial amounts of labeled data to train supervised\nmachine learning models poses a significant challenge. To address this, we\ndelve into few-shot and active learning, where are goal is to improve AI models\nwith human feedback on a few labeled examples. This paper focuses on\nunderstanding how a continuous feedback loop can refine models, thereby\nenhancing their accuracy, recall, and precision through incremental human\ninput. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and\nSetFit, we aim to analyze the efficacy of using a limited number of labeled\nexamples to substantially improve model accuracy. We benchmark this approach on\nthe Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to\nprove that with just a few labeled examples, we are able to surpass the\naccuracy of zero shot large language models to provide enhanced text\nclassification performance. We demonstrate that rather than needing to manually\nlabel millions of rows of data, we just need to label a few and the model can\neffectively predict the rest.", "published": "2024-01-17 19:13:05", "link": "http://arxiv.org/abs/2401.09555v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning Shortcuts: On the Misleading Promise of NLU in Language Models", "abstract": "The advent of large language models (LLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found that LLMs often resort to shortcuts when performing tasks,\ncreating an illusion of enhanced performance while lacking generalizability in\ntheir decision rules. This phenomenon introduces challenges in accurately\nassessing natural language understanding in LLMs. Our paper provides a concise\nsurvey of relevant research in this area and puts forth a perspective on the\nimplications of shortcut learning in the evaluation of language models,\nspecifically for NLU tasks. This paper urges more research efforts to be put\ntowards deepening our comprehension of shortcut learning, contributing to the\ndevelopment of more robust language models, and raising the standards of NLU\nevaluation in real-world scenarios.", "published": "2024-01-17 21:55:15", "link": "http://arxiv.org/abs/2401.09615v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Impact of Large Language Model Assistance on Patients Reading Clinical\n  Notes: A Mixed-Methods Study", "abstract": "Large language models (LLMs) have immense potential to make information more\naccessible, particularly in medicine, where complex medical jargon can hinder\npatient comprehension of clinical notes. We developed a patient-facing tool\nusing LLMs to make clinical notes more readable by simplifying, extracting\ninformation from, and adding context to the notes. We piloted the tool with\nclinical notes donated by patients with a history of breast cancer and\nsynthetic notes from a clinician. Participants (N=200, healthy,\nfemale-identifying patients) were randomly assigned three clinical notes in our\ntool with varying levels of augmentations and answered quantitative and\nqualitative questions evaluating their understanding of follow-up actions.\nAugmentations significantly increased their quantitative understanding scores.\nIn-depth interviews were conducted with participants (N=7, patients with a\nhistory of breast cancer), revealing both positive sentiments about the\naugmentations and concerns about AI. We also performed a qualitative\nclinician-driven analysis of the model's error modes.", "published": "2024-01-17 23:14:52", "link": "http://arxiv.org/abs/2401.09637v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on\n  Climate Change", "abstract": "This paper introduces ClimateGPT, a model family of domain-specific large\nlanguage models that synthesize interdisciplinary research on climate change.\nWe trained two 7B models from scratch on a science-oriented dataset of 300B\ntokens. For the first model, the 4.2B domain-specific tokens were included\nduring pre-training and the second was adapted to the climate domain after\npre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously\npre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each\nmodel is instruction fine-tuned on a high-quality and human-generated\ndomain-specific dataset that has been created in close cooperation with climate\nscientists. To reduce the number of hallucinations, we optimize the model for\nretrieval augmentation and propose a hierarchical retrieval strategy. To\nincrease the accessibility of our model to non-English speakers, we propose to\nmake use of cascaded machine translation and show that this approach can\nperform comparably to natively multilingual models while being easier to scale\nto a large number of languages. Further, to address the intrinsic\ninterdisciplinary aspect of climate change we consider different research\nperspectives. Therefore, the model can produce in-depth answers focusing on\ndifferent perspectives in addition to an overall answer. We propose a suite of\nautomatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,\nClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model\nwhile not degrading results on general domain benchmarks. Our human evaluation\nconfirms the trends we saw in our benchmarks. All models were trained and\nevaluated using renewable energy and are released publicly.", "published": "2024-01-17 23:29:46", "link": "http://arxiv.org/abs/2401.09646v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models Help Reveal Unhealthy Diet and Body Concerns in\n  Online Eating Disorders Communities", "abstract": "Eating disorders (ED), a severe mental health condition with high rates of\nmortality and morbidity, affect millions of people globally, especially\nadolescents. The proliferation of online communities that promote and normalize\nED has been linked to this public health crisis. However, identifying harmful\ncommunities is challenging due to the use of coded language and other\nobfuscations. To address this challenge, we propose a novel framework to\nsurface implicit attitudes of online communities by adapting large language\nmodels (LLMs) to the language of the community. We describe an alignment method\nand evaluate results along multiple dimensions of semantics and affect. We then\nuse the community-aligned LLM to respond to psychometric questionnaires\ndesigned to identify ED in individuals. We demonstrate that LLMs can\neffectively adopt community-specific perspectives and reveal significant\nvariations in eating disorder risks in different online communities. These\nfindings highlight the utility of LLMs to reveal implicit attitudes and\ncollective mindsets of communities, offering new tools for mitigating harmful\ncontent on social media.", "published": "2024-01-17 23:32:56", "link": "http://arxiv.org/abs/2401.09647v2", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "RELIANCE: Reliable Ensemble Learning for Information and News\n  Credibility Evaluation", "abstract": "In the era of information proliferation, discerning the credibility of news\ncontent poses an ever-growing challenge. This paper introduces RELIANCE, a\npioneering ensemble learning system designed for robust information and fake\nnews credibility evaluation. Comprising five diverse base models, including\nSupport Vector Machine (SVM), naive Bayes, logistic regression, random forest,\nand Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs\nan innovative approach to integrate their strengths, harnessing the collective\nintelligence of the ensemble for enhanced accuracy. Experiments demonstrate the\nsuperiority of RELIANCE over individual models, indicating its efficacy in\ndistinguishing between credible and non-credible information sources. RELIANCE,\nalso surpasses baseline models in information and news credibility assessment,\nestablishing itself as an effective solution for evaluating the reliability of\ninformation sources.", "published": "2024-01-17 13:11:09", "link": "http://arxiv.org/abs/2401.10940v2", "categories": ["cs.IR", "cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.IR"}
{"title": "TranSentence: Speech-to-speech Translation via Language-agnostic\n  Sentence-level Speech Encoding without Language-parallel Data", "abstract": "Although there has been significant advancement in the field of\nspeech-to-speech translation, conventional models still require\nlanguage-parallel speech data between the source and target languages for\ntraining. In this paper, we introduce TranSentence, a novel speech-to-speech\ntranslation without language-parallel speech data. To achieve this, we first\nadopt a language-agnostic sentence-level speech encoding that captures the\nsemantic information of speech, irrespective of language. We then train our\nmodel to generate speech based on the encoded embedding obtained from a\nlanguage-agnostic sentence-level speech encoder that is pre-trained with\nvarious languages. With this method, despite training exclusively on the target\nlanguage's monolingual data, we can generate target language speech in the\ninference stage using language-agnostic speech embedding from the source\nlanguage speech. Furthermore, we extend TranSentence to multilingual\nspeech-to-speech translation. The experimental results demonstrate that\nTranSentence is superior to other models.", "published": "2024-01-17 11:52:40", "link": "http://arxiv.org/abs/2401.12992v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene\n  Understanding", "abstract": "3D vision-language grounding, which focuses on aligning language with the 3D\nphysical environment, stands as a cornerstone in the development of embodied\nagents. In comparison to recent advancements in the 2D domain, grounding\nlanguage in 3D scenes faces several significant challenges: (i) the inherent\ncomplexity of 3D scenes due to the diverse object configurations, their rich\nattributes, and intricate relationships; (ii) the scarcity of paired 3D\nvision-language data to support grounded learning; and (iii) the absence of a\nunified learning framework to distill knowledge from grounded 3D data. In this\nwork, we aim to address these three major challenges in 3D vision-language by\nexamining the potential of systematically upscaling 3D vision-language learning\nin indoor environments. We introduce the first million-scale 3D vision-language\ndataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising\n2.5M vision-language pairs derived from both human annotations and our scalable\nscene-graph-based generation approach. We demonstrate that this scaling allows\nfor a unified pre-training framework, Grounded Pre-training for Scenes (GPS),\nfor 3D vision-language learning. Through extensive experiments, we showcase the\neffectiveness of GPS by achieving state-of-the-art performance on all existing\n3D visual grounding benchmarks. The vast potential of SceneVerse and GPS is\nunveiled through zero-shot transfer experiments in the challenging 3D\nvision-language tasks. Project website: https://scene-verse.github.io.", "published": "2024-01-17 17:04:35", "link": "http://arxiv.org/abs/2401.09340v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "On Speech Pre-emphasis as a Simple and Inexpensive Method to Boost\n  Speech Enhancement", "abstract": "Pre-emphasis filtering, compensating for the natural energy decay of speech\nat higher frequencies, has been considered as a common pre-processing step in a\nnumber of speech processing tasks over the years. In this work, we demonstrate,\nfor the first time, that pre-emphasis filtering may also be used as a simple\nand computationally-inexpensive way to leverage deep neural network-based\nspeech enhancement performance. Particularly, we look into pre-emphasizing the\nestimated and actual clean speech prior to loss calculation so that different\nspeech frequency components better mirror their perceptual importance during\nthe training phase. Experimental results on a noisy version of the TIMIT\ndataset show that integrating the pre-emphasis-based methodology at hand yields\nrelative estimated speech quality improvements of up to 4.6% and 3.4% for noise\ntypes seen and unseen, respectively, during the training phase. Similar to the\ncase of pre-emphasis being considered as a default pre-processing step in\nclassical automatic speech recognition and speech coding systems, the\npre-emphasis-based methodology analyzed in this article may potentially become\na default add-on for modern speech enhancement.", "published": "2024-01-17 16:41:20", "link": "http://arxiv.org/abs/2401.09315v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Two-pass Endpoint Detection for Speech Recognition", "abstract": "Endpoint (EP) detection is a key component of far-field speech recognition\nsystems that assist the user through voice commands. The endpoint detector has\nto trade-off between accuracy and latency, since waiting longer reduces the\ncases of users being cut-off early. We propose a novel two-pass solution for\nendpointing, where the utterance endpoint detected from a first pass endpointer\nis verified by a 2nd-pass model termed EP Arbitrator. Our method improves the\ntrade-off between early cut-offs and latency over a baseline endpointer, as\ntested on datasets including voice-assistant transactional queries,\nconversational speech, and the public SLURP corpus. We demonstrate that our\nmethod shows improvements regardless of the first-pass EP model used.", "published": "2024-01-17 02:00:07", "link": "http://arxiv.org/abs/2401.08916v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting\n  Networks?", "abstract": "In the design of traffic monitoring solutions for optimizing the urban\nmobility infrastructure, acoustic vehicle counting models have received\nattention due to their cost effectiveness and energy efficiency. Although deep\nlearning has proven effective for visual traffic monitoring, its use has not\nbeen thoroughly investigated in the audio domain, likely due to real-world data\nscarcity. In this work, we propose a novel approach to acoustic vehicle\ncounting by developing: i) a traffic noise simulation framework to synthesize\nrealistic vehicle pass-by events; ii) a strategy to mix synthetic and real data\nto train a deep-learning model for traffic counting. The proposed system is\ncapable of simultaneously counting cars and commercial vehicles driving on a\ntwo-lane road, and identifying their direction of travel under moderate traffic\ndensity conditions. With only 24 hours of labeled real-world traffic noise, we\nare able to improve counting accuracy on real-world data from $63\\%$ to $88\\%$\nfor cars and from $86\\%$ to $94\\%$ for commercial vehicles.", "published": "2024-01-17 16:18:49", "link": "http://arxiv.org/abs/2401.09308v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MLAAD: The Multi-Language Audio Anti-Spoofing Dataset", "abstract": "Text-to-Speech (TTS) technology offers notable benefits, such as providing a\nvoice for individuals with speech impairments, but it also facilitates the\ncreation of audio deepfakes and spoofing attacks. AI-based detection methods\ncan help mitigate these risks; however, the performance of such models is\ninherently dependent on the quality and diversity of their training data.\nPresently, the available datasets are heavily skewed towards English and\nChinese audio, which limits the global applicability of these anti-spoofing\nsystems. To address this limitation, this paper presents the Multi-Language\nAudio Anti-Spoof Dataset (MLAAD), created using 82 TTS models, comprising 33\ndifferent architectures, to generate 378.0 hours of synthetic voice in 38\ndifferent languages. We train and evaluate three state-of-the-art deepfake\ndetection models with MLAAD and observe that it demonstrates superior\nperformance over comparable datasets like InTheWild and Fake- OrReal when used\nas a training resource. Moreover, compared to the renowned ASVspoof 2019\ndataset, MLAAD proves to be a complementary resource. In tests across eight\ndatasets, MLAAD and ASVspoof 2019 alternately outperformed each other, each\nexcelling on four datasets. By publishing MLAAD and making a trained model\naccessible via an interactive webserver, we aim to democratize anti-spoofing\ntechnology, making it accessible beyond the realm of specialists, and\ncontributing to global efforts against audio spoofing and deepfakes.", "published": "2024-01-17 15:09:02", "link": "http://arxiv.org/abs/2401.09512v5", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Tempo estimation as fully self-supervised binary classification", "abstract": "This paper addresses the problem of global tempo estimation in musical audio.\nGiven that annotating tempo is time-consuming and requires certain musical\nexpertise, few publicly available data sources exist to train machine learning\nmodels for this task. Towards alleviating this issue, we propose a fully\nself-supervised approach that does not rely on any human labeled data. Our\nmethod builds on the fact that generic (music) audio embeddings already encode\na variety of properties, including information about tempo, making them easily\nadaptable for downstream tasks. While recent work in self-supervised tempo\nestimation aimed to learn a tempo specific representation that was subsequently\nused to train a supervised classifier, we reformulate the task into the binary\nclassification problem of predicting whether a target track has the same or a\ndifferent tempo compared to a reference. While the former still requires\nlabeled training data for the final classification model, our approach uses\narbitrary unlabeled music data in combination with time-stretching for model\ntraining as well as a small set of synthetically created reference samples for\npredicting the final tempo. Evaluation of our approach in comparison with the\nstate-of-the-art reveals highly competitive performance when the constraint of\nfinding the precise tempo octave is relaxed.", "published": "2024-01-17 00:15:16", "link": "http://arxiv.org/abs/2401.08891v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DOO-RE: A dataset of ambient sensors in a meeting room for activity\n  recognition", "abstract": "With the advancement of IoT technology, recognizing user activities with\nmachine learning methods is a promising way to provide various smart services\nto users. High-quality data with privacy protection is essential for deploying\nsuch services in the real world. Data streams from surrounding ambient sensors\nare well suited to the requirement. Existing ambient sensor datasets only\nsupport constrained private spaces and those for public spaces have yet to be\nexplored despite growing interest in research on them. To meet this need, we\nbuild a dataset collected from a meeting room equipped with ambient sensors.\nThe dataset, DOO-RE, includes data streams from various ambient sensor types\nsuch as Sound and Projector. Each sensor data stream is segmented into activity\nunits and multiple annotators provide activity labels through a\ncross-validation annotation process to improve annotation quality. We finally\nobtain 9 types of activities. To our best knowledge, DOO-RE is the first\ndataset to support the recognition of both single and group activities in a\nreal meeting room with reliable annotations.", "published": "2024-01-17 04:21:04", "link": "http://arxiv.org/abs/2401.08962v1", "categories": ["cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "A Real-Time Lyrics Alignment System Using Chroma And Phonetic Features\n  For Classical Vocal Performance", "abstract": "The goal of real-time lyrics alignment is to take live singing audio as input\nand to pinpoint the exact position within given lyrics on the fly. The task can\nbenefit real-world applications such as the automatic subtitling of live\nconcerts or operas. However, designing a real-time model poses a great\nchallenge due to the constraints of only using past input and operating within\na minimal latency. Furthermore, due to the lack of datasets for real-time\nmodels for lyrics alignment, previous studies have mostly evaluated with\nprivate in-house datasets, resulting in a lack of standard evaluation methods.\nThis paper presents a real-time lyrics alignment system for classical vocal\nperformances with two contributions. First, we improve the lyrics alignment\nalgorithm by finding an optimal combination of chromagram and phonetic\nposteriorgram (PPG) that capture melodic and phonetics features of the singing\nvoice, respectively. Second, we recast the Schubert Winterreise Dataset (SWD)\nwhich contains multiple performance renditions of the same pieces as an\nevaluation set for the real-time lyrics alignment.", "published": "2024-01-17 13:25:32", "link": "http://arxiv.org/abs/2401.09200v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting Post-Stroke Aphasia Via Brain Responses to Speech in a Deep\n  Learning Framework", "abstract": "Aphasia, a language disorder primarily caused by a stroke, is traditionally\ndiagnosed using behavioral language tests. However, these tests are\ntime-consuming, require manual interpretation by trained clinicians, suffer\nfrom low ecological validity, and diagnosis can be biased by comorbid motor and\ncognitive problems present in aphasia. In this study, we introduce an automated\nscreening tool for speech processing impairments in aphasia that relies on\ntime-locked brain responses to speech, known as neural tracking, within a deep\nlearning framework. We modeled electroencephalography (EEG) responses to\nacoustic, segmentation, and linguistic speech representations of a story using\nconvolutional neural networks trained on a large sample of healthy\nparticipants, serving as a model for intact neural tracking of speech.\nSubsequently, we evaluated our models on an independent sample comprising 26\nindividuals with aphasia (IWA) and 22 healthy controls. Our results reveal\ndecreased tracking of all speech representations in IWA. Utilizing a support\nvector machine classifier with neural tracking measures as input, we\ndemonstrate high accuracy in aphasia detection at the individual level\n(85.42\\%) in a time-efficient manner (requiring 9 minutes of EEG data). Given\nits high robustness, time efficiency, and generalizability to unseen data, our\napproach holds significant promise for clinical applications.", "published": "2024-01-17 08:31:54", "link": "http://arxiv.org/abs/2401.10291v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "On the Effect of Data-Augmentation on Local Embedding Properties in the\n  Contrastive Learning of Music Audio Representations", "abstract": "Audio embeddings are crucial tools in understanding large catalogs of music.\nTypically embeddings are evaluated on the basis of the performance they provide\nin a wide range of downstream tasks, however few studies have investigated the\nlocal properties of the embedding spaces themselves which are important in\nnearest neighbor algorithms, commonly used in music search and recommendation.\nIn this work we show that when learning audio representations on music datasets\nvia contrastive learning, musical properties that are typically homogeneous\nwithin a track (e.g., key and tempo) are reflected in the locality of\nneighborhoods in the resulting embedding space. By applying appropriate data\naugmentation strategies, localisation of such properties can not only be\nreduced but the localisation of other attributes is increased. For example,\nlocality of features such as pitch and tempo that are less relevant to\nnon-expert listeners, may be mitigated while improving the locality of more\nsalient features such as genre and mood, achieving state-of-the-art performance\nin nearest neighbor retrieval accuracy. Similarly, we show that the optimal\nselection of data augmentation strategies for contrastive learning of music\naudio embeddings is dependent on the downstream task, highlighting this as an\nimportant embedding design decision.", "published": "2024-01-17 00:12:13", "link": "http://arxiv.org/abs/2401.08889v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Similar but Faster: Manipulation of Tempo in Music Audio Embeddings for\n  Tempo Prediction and Search", "abstract": "Audio embeddings enable large scale comparisons of the similarity of audio\nfiles for applications such as search and recommendation. Due to the\nsubjectivity of audio similarity, it can be desirable to design systems that\nanswer not only whether audio is similar, but similar in what way (e.g., wrt.\ntempo, mood or genre). Previous works have proposed disentangled embedding\nspaces where subspaces representing specific, yet possibly correlated,\nattributes can be weighted to emphasize those attributes in downstream tasks.\nHowever, no research has been conducted into the independence of these\nsubspaces, nor their manipulation, in order to retrieve tracks that are similar\nbut different in a specific way. Here, we explore the manipulation of tempo in\nembedding spaces as a case-study towards this goal. We propose tempo\ntranslation functions that allow for efficient manipulation of tempo within a\npre-existing embedding space whilst maintaining other properties such as genre.\nAs this translation is specific to tempo it enables retrieval of tracks that\nare similar but have specifically different tempi. We show that such a function\ncan be used as an efficient data augmentation strategy for both training of\ndownstream tempo predictors, and improved nearest neighbor retrieval of\nproperties largely independent of tempo.", "published": "2024-01-17 01:06:22", "link": "http://arxiv.org/abs/2401.08902v1", "categories": ["cs.SD", "cs.DL", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "T-FOLEY: A Controllable Waveform-Domain Diffusion Model for\n  Temporal-Event-Guided Foley Sound Synthesis", "abstract": "Foley sound, audio content inserted synchronously with videos, plays a\ncritical role in the user experience of multimedia content. Recently, there has\nbeen active research in Foley sound synthesis, leveraging the advancements in\ndeep generative models. However, such works mainly focus on replicating a\nsingle sound class or a textual sound description, neglecting temporal\ninformation, which is crucial in the practical applications of Foley sound. We\npresent T-Foley, a Temporal-event-guided waveform generation model for Foley\nsound synthesis. T-Foley generates high-quality audio using two conditions: the\nsound class and temporal event feature. For temporal conditioning, we devise a\ntemporal event feature and a novel conditioning technique named Block-FiLM.\nT-Foley achieves superior performance in both objective and subjective\nevaluation metrics and generates Foley sound well-synchronized with the\ntemporal events. Additionally, we showcase T-Foley's practical applications,\nparticularly in scenarios involving vocal mimicry for temporal event control.\nWe show the demo on our companion website.", "published": "2024-01-17 15:54:36", "link": "http://arxiv.org/abs/2401.09294v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
