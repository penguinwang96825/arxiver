{"title": "Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an\n  Entity-Centric Perspective", "abstract": "Recently developed pre-trained text-and-layout models (PTLMs) have shown\nremarkable success in multiple information extraction tasks on visually-rich\ndocuments. However, the prevailing evaluation pipeline may not be sufficiently\nrobust for assessing the information extraction ability of PTLMs, due to\ninadequate annotations within the benchmarks. Therefore, we claim the necessary\nstandards for an ideal benchmark to evaluate the information extraction ability\nof PTLMs. We then introduce EC-FUNSD, an entity-centric benckmark designed for\nthe evaluation of semantic entity recognition and entity linking on\nvisually-rich documents. This dataset contains diverse formats of document\nlayouts and annotations of semantic-driven entities and their relations.\nMoreover, this dataset disentangles the falsely coupled annotation of segment\nand entity that arises from the block-level annotation of FUNSD. Experiment\nresults demonstrate that state-of-the-art PTLMs exhibit overfitting tendencies\non the prevailing benchmarks, as their performance sharply decrease when the\ndataset bias is removed.", "published": "2024-02-04 07:33:45", "link": "http://arxiv.org/abs/2402.02379v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NavHint: Vision and Language Navigation Agent with a Hint Generator", "abstract": "Existing work on vision and language navigation mainly relies on\nnavigation-related losses to establish the connection between vision and\nlanguage modalities, neglecting aspects of helping the navigation agent build a\ndeep understanding of the visual environment. In our work, we provide indirect\nsupervision to the navigation agent through a hint generator that provides\ndetailed visual descriptions. The hint generator assists the navigation agent\nin developing a global understanding of the visual environment. It directs the\nagent's attention toward related navigation details, including the relevant\nsub-instruction, potential challenges in recognition and ambiguities in\ngrounding, and the targeted viewpoint description. To train the hint generator,\nwe construct a synthetic dataset based on landmarks in the instructions and\nvisible and distinctive objects in the visual environment. We evaluate our\nmethod on the R2R and R4R datasets and achieve state-of-the-art on several\nmetrics. The experimental results demonstrate that generating hints not only\nenhances the navigation performance but also helps improve the interpretability\nof the agent's actions.", "published": "2024-02-04 16:23:16", "link": "http://arxiv.org/abs/2402.02559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Quantitative Discourse Analysis of Asian Workers in the US Historical\n  Newspapers", "abstract": "Warning: This paper contains examples of offensive language targetting\nmarginalized population. The digitization of historical texts invites\nresearchers to explore the large-scale corpus of historical texts with\ncomputational methods. In this study, we present computational text analysis on\na relatively understudied topic of how Asian workers are represented in\nhistorical newspapers in the United States. We found that the word \"coolie\" was\nsemantically different in some States (e.g., Massachusetts, Rhode Island,\nWyoming, Oklahoma, and Arkansas) with the different discourses around coolie.\nWe also found that then-Confederate newspapers and then-Union newspapers formed\ndistinctive discourses by measuring over-represented words. Newspapers from\nthen-Confederate States associated coolie with slavery-related words. In\naddition, we found Asians were perceived to be inferior to European immigrants\nand subjected to the target of racism. This study contributes to supplementing\nthe qualitative analysis of racism in the United States with quantitative\ndiscourse analysis.", "published": "2024-02-04 17:32:52", "link": "http://arxiv.org/abs/2402.02572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the performance of phonetic algorithms in microtext normalization", "abstract": "User-generated content published on microblogging social networks constitutes\na priceless source of information. However, microtexts usually deviate from the\nstandard lexical and grammatical rules of the language, thus making its\nprocessing by traditional intelligent systems very difficult. As an answer,\nmicrotext normalization consists in transforming those non-standard microtexts\ninto standard well-written texts as a preprocessing step, allowing traditional\napproaches to continue with their usual processing. Given the importance of\nphonetic phenomena in non-standard text formation, an essential element of the\nknowledge base of a normalizer would be the phonetic rules that encode these\nphenomena, which can be found in the so-called phonetic algorithms.\n  In this work we experiment with a wide range of phonetic algorithms for the\nEnglish language. The aim of this study is to determine the best phonetic\nalgorithms within the context of candidate generation for microtext\nnormalization. In other words, we intend to find those algorithms that taking\nas input non-standard terms to be normalized allow us to obtain as output the\nsmallest possible sets of normalization candidates which still contain the\ncorresponding target standard words. As it will be stated, the choice of the\nphonetic algorithm will depend heavily on the capabilities of the candidate\nselection mechanism which we usually find at the end of a microtext\nnormalization pipeline. The faster it can make the right choices among big\nenough sets of candidates, the more we can sacrifice on the precision of the\nphonetic algorithms in favour of coverage in order to increase the overall\nperformance of the normalization system.\n  KEYWORDS: microtext normalization; phonetic algorithm; fuzzy matching;\nTwitter; texting", "published": "2024-02-04 19:54:44", "link": "http://arxiv.org/abs/2402.02591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"It's how you do things that matters\": Attending to Process to Better\n  Serve Indigenous Communities with Language Technologies", "abstract": "Indigenous languages are historically under-served by Natural Language\nProcessing (NLP) technologies, but this is changing for some languages with the\nrecent scaling of large multilingual models and an increased focus by the NLP\ncommunity on endangered languages. This position paper explores ethical\nconsiderations in building NLP technologies for Indigenous languages, based on\nthe premise that such projects should primarily serve Indigenous communities.\nWe report on interviews with 17 researchers working in or with Aboriginal\nand/or Torres Strait Islander communities on language technology projects in\nAustralia. Drawing on insights from the interviews, we recommend practices for\nNLP researchers to increase attention to the process of engagements with\nIndigenous communities, rather than focusing only on decontextualised\nartefacts.", "published": "2024-02-04 23:23:51", "link": "http://arxiv.org/abs/2402.02639v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Data Selection for LLM Instruction Tuning", "abstract": "Instruction tuning is a vital step of training large language models (LLM),\nso how to enhance the effect of instruction tuning has received increased\nattention. Existing works indicate that the quality of the dataset is more\ncrucial than the quantity during instruction tuning of LLM. Therefore, recently\na lot of studies focus on exploring the methods of selecting high-quality\nsubset from instruction datasets, aiming to reduce training costs and enhance\nthe instruction-following capabilities of LLMs. This paper presents a\ncomprehensive survey on data selection for LLM instruction tuning. Firstly, we\nintroduce the wildly used instruction datasets. Then, we propose a new taxonomy\nof the data selection methods and provide a detailed introduction of recent\nadvances,and the evaluation strategies and results of data selection methods\nare also elaborated in detail. Finally, we emphasize the open challenges and\npresent new frontiers of this task.", "published": "2024-02-04 13:32:01", "link": "http://arxiv.org/abs/2402.05123v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Large Language Models in Finance (FinLLMs)", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across a wide\nvariety of Natural Language Processing (NLP) tasks and have attracted attention\nfrom multiple domains, including financial services. Despite the extensive\nresearch into general-domain LLMs, and their immense potential in finance,\nFinancial LLM (FinLLM) research remains limited. This survey provides a\ncomprehensive overview of FinLLMs, including their history, techniques,\nperformance, and opportunities and challenges. Firstly, we present a\nchronological overview of general-domain Pre-trained Language Models (PLMs)\nthrough to current FinLLMs, including the GPT-series, selected open-source\nLLMs, and financial LMs. Secondly, we compare five techniques used across\nfinancial PLMs and FinLLMs, including training methods, training data, and\nfine-tuning methods. Thirdly, we summarize the performance evaluations of six\nbenchmark tasks and datasets. In addition, we provide eight advanced financial\nNLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we\ndiscuss the opportunities and the challenges facing FinLLMs, such as\nhallucination, privacy, and efficiency. To support AI research in finance, we\ncompile a collection of accessible datasets and evaluation benchmarks on\nGitHub.", "published": "2024-02-04 02:06:57", "link": "http://arxiv.org/abs/2402.02315v1", "categories": ["cs.CL", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "Diversity Measurement and Subset Selection for Instruction Tuning\n  Datasets", "abstract": "We aim to select data subsets for the fine-tuning of large language models to\nmore effectively follow instructions. Prior work has emphasized the importance\nof diversity in dataset curation but relied on heuristics such as the number of\ntasks. In this paper, we use determinantal point processes to capture the\ndiversity and quality of instruction tuning datasets for subset selection. We\npropose to measure dataset diversity with log determinant distance that is the\ndistance between the dataset of interest and a maximally diverse reference\ndataset. Our experiments demonstrate that the proposed diversity measure in the\nnormalized weight gradient space is correlated with downstream\ninstruction-following performance. Consequently, it can be used to inform when\ndata selection is the most helpful and to analyze dataset curation strategies.\nWe demonstrate the utility of our approach on various instruction tuning\ndatasets.", "published": "2024-02-04 02:09:43", "link": "http://arxiv.org/abs/2402.02318v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhance Reasoning for Large Language Models in the Game Werewolf", "abstract": "This paper presents an innovative framework that integrates Large Language\nModels (LLMs) with an external Thinker module to enhance the reasoning\ncapabilities of LLM-based agents. Unlike augmenting LLMs with prompt\nengineering, Thinker directly harnesses knowledge from databases and employs\nvarious optimization techniques. The framework forms a reasoning hierarchy\nwhere LLMs handle intuitive System-1 tasks such as natural language processing,\nwhile the Thinker focuses on cognitive System-2 tasks that require complex\nlogical analysis and domain-specific knowledge. Our framework is presented\nusing a 9-player Werewolf game that demands dual-system reasoning. We introduce\na communication protocol between LLMs and the Thinker, and train the Thinker\nusing data from 18800 human sessions and reinforcement learning. Experiments\ndemonstrate the framework's effectiveness in deductive reasoning, speech\ngeneration, and online game evaluation. Additionally, we fine-tune a 6B LLM to\nsurpass GPT4 when integrated with the Thinker. This paper also contributes the\nlargest dataset for social deduction games to date.", "published": "2024-02-04 03:47:10", "link": "http://arxiv.org/abs/2402.02330v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "AutoTimes: Autoregressive Time Series Forecasters via Large Language\n  Models", "abstract": "Foundation models of time series have not been fully developed due to the\nlimited availability of time series corpora and the underexploration of\nscalable pre-training. Based on the similar sequential formulation of time\nseries and natural language, increasing research demonstrates the feasibility\nof leveraging large language models (LLM) for time series. Nevertheless, the\ninherent autoregressive property and decoder-only architecture of LLMs have not\nbeen fully considered, resulting in insufficient utilization of LLM abilities.\nTo fully revitalize the general-purpose token transition and multi-step\ngeneration capability of large language models, we propose AutoTimes to\nrepurpose LLMs as autoregressive time series forecasters, which projects time\nseries into the embedding space of language tokens and autoregressively\ngenerates future predictions with arbitrary lengths. Compatible with any\ndecoder-only LLMs, the consequent forecaster exhibits the flexibility of the\nlookback length and scalability with larger LLMs. Further, we formulate time\nseries as prompts, extending the context for prediction beyond the lookback\nwindow, termed in-context forecasting. By introducing LLM-embedded textual\ntimestamps, AutoTimes can utilize chronological information to align\nmultivariate time series. Empirically, AutoTimes achieves state-of-the-art with\n0.1% trainable parameters and over $5\\times$ training/inference speedup\ncompared to advanced LLM-based forecasters. Code is available at this\nrepository: https://github.com/thuml/AutoTimes.", "published": "2024-02-04 06:59:21", "link": "http://arxiv.org/abs/2402.02370v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge\n  Graph Completion", "abstract": "Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph\nincompleteness and supporting downstream applications. Many models have been\nproposed for KGC. They can be categorized into two main classes: triple-based\nand text-based approaches. Triple-based methods struggle with long-tail\nentities due to limited structural information and imbalanced entity\ndistributions. Text-based methods alleviate this issue but require costly\ntraining for language models and specific finetuning for knowledge graphs,\nwhich limits their efficiency. To alleviate these limitations, in this paper,\nwe propose KICGPT, a framework that integrates a large language model (LLM) and\na triple-based KGC retriever. It alleviates the long-tail problem without\nincurring additional training overhead. KICGPT uses an in-context learning\nstrategy called Knowledge Prompt, which encodes structural knowledge into\ndemonstrations to guide the LLM. Empirical results on benchmark datasets\ndemonstrate the effectiveness of KICGPT with smaller training overhead and no\nfinetuning.", "published": "2024-02-04 08:01:07", "link": "http://arxiv.org/abs/2402.02389v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large\n  Language Model", "abstract": "Despite the rapid progress of large language models (LLMs), their task\nperformance remains sensitive to prompt design. Recent studies have explored\nleveraging the LLM itself as an optimizer to identify optimal prompts that\nmaximize task accuracy. However, when evaluating prompts, such approaches\nheavily rely on elusive manually annotated gold labels to calculate task\naccuracy for each candidate prompt, which hinders the widespread implementation\nand generality. To overcome the limitation, this work proposes a gold\nlabel-agnostic prompt evaluation (GLaPE) to alleviate dependence on gold\nlabels. Motivated by the observed correlation between self-consistency and the\naccuracy of the answer, we adopt self-consistency as the initial evaluation\nscore. Subsequently, we refine the scores of prompts producing identical\nanswers to be mutually consistent. Experimental results show that GLaPE\nprovides reliable evaluations uniform with accuracy, even in the absence of\ngold labels. Moreover, on six popular reasoning tasks, our GLaPE-based prompt\noptimization yields effective prompts comparable to accuracy-based ones. The\ncode is publicly available at https://github.com/thunderous77/GLaPE.", "published": "2024-02-04 08:57:54", "link": "http://arxiv.org/abs/2402.02408v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Factuality of Large Language Models: A Survey", "abstract": "Large language models (LLMs), especially when instruction-tuned for chat,\nhave become part of our daily lives, freeing people from the process of\nsearching, extracting, and integrating information from multiple sources by\noffering a straightforward answer to a variety of questions in a single place.\nUnfortunately, in many cases, LLM responses are factually incorrect, which\nlimits their applicability in real-world scenarios. As a result, research on\nevaluating and improving the factuality of LLMs has attracted a lot of\nattention recently. In this survey, we critically analyze existing work with\nthe aim to identify the major challenges and their associated causes, pointing\nout to potential solutions for improving the factuality of LLMs, and analyzing\nthe obstacles to automated factuality evaluation for open-ended text\ngeneration. We further offer an outlook on where future research should go.", "published": "2024-02-04 09:36:31", "link": "http://arxiv.org/abs/2402.02420v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LQER: Low-Rank Quantization Error Reconstruction for LLMs", "abstract": "Post-training quantization of Large Language Models (LLMs) is challenging. In\nthis work, we introduce Low-rank Quantization Error Reduction (LQER), which\ncombines quantization and low-rank approximation to recover the model\ncapability. LQER leverages an activation-induced scale matrix to drive the\nsingular value distribution of quantization error towards a desirable\ndistribution, which enables nearly-lossless W4A8 quantization on various LLMs\nand downstream tasks without the need for knowledge distillation, grid search,\nor gradient-base iterative optimization. Unlike existing methods, the\ncomputation pattern of LQER eliminates the need for specialized Scatter and\nGather processes to collect high-precision weights from irregular memory\nlocations. Our W4A8 LLMs achieve near-lossless performance on six popular\ndownstream tasks, while using 1.36$\\times$ fewer hardware resources than the\nleading state-of-the-art method. We open-source our framework at\nhttps://github.com/ChengZhang-98/lqer", "published": "2024-02-04 10:59:52", "link": "http://arxiv.org/abs/2402.02446v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Breaking MLPerf Training: A Case Study on Optimizing BERT", "abstract": "Speeding up the large-scale distributed training is challenging in that it\nrequires improving various components of training including load balancing,\ncommunication, optimizers, etc. We present novel approaches for fast\nlarge-scale training of BERT model which individually ameliorates each\ncomponent thereby leading to a new level of BERT training performance. Load\nbalancing is imperative in distributed BERT training since its training\ndatasets are characterized by samples with various lengths. Communication cost,\nwhich is proportional to the scale of distributed training, needs to be hidden\nby useful computation. In addition, the optimizers, e.g., ADAM, LAMB, etc.,\nneed to be carefully re-evaluated in the context of large-scale distributed\ntraining. We propose two new ideas, (1) local presorting based on dataset\nstratification for load balancing and (2) bucket-wise gradient clipping before\nallreduce which allows us to benefit from the overlap of gradient computation\nand synchronization as well as the fast training of gradient clipping before\nallreduce. We also re-evaluate existing optimizers via hyperparameter\noptimization and utilize ADAM, which also contributes to fast training via\nlarger batches than existing methods. Our proposed methods, all combined, give\nthe fastest MLPerf BERT training of 25.1 (22.3) seconds on 1,024 NVIDIA A100\nGPUs, which is 1.33x (1.13x) and 1.57x faster than the other top two (one)\nsubmissions to MLPerf v1.1 (v2.0). Our implementation and evaluation results\nare available at MLPerf v1.1~v2.1.", "published": "2024-02-04 11:12:17", "link": "http://arxiv.org/abs/2402.02447v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Surfing the modeling of PoS taggers in low-resource scenarios", "abstract": "The recent trend towards the application of deep structured techniques has\nrevealed the limits of huge models in natural language processing. This has\nreawakened the interest in traditional machine learning algorithms, which have\nproved still to be competitive in certain contexts, in particular low-resource\nsettings. In parallel, model selection has become an essential task to boost\nperformance at reasonable cost, even more so when we talk about processes\ninvolving domains where the training and/or computational resources are scarce.\nAgainst this backdrop, we evaluate the early estimation of learning curves as a\npractical mechanism for selecting the most appropriate model in scenarios\ncharacterized by the use of non-deep learners in resource-lean settings. On the\nbasis of a formal approximation model previously evaluated under conditions of\nwide availability of training and validation resources, we study the\nreliability of such an approach in a different and much more demanding\noperationalenvironment. Using as case study the generation of PoS taggers for\nGalician, a language belonging to the Western Ibero-Romance group, the\nexperimental results are consistent with our expectations.", "published": "2024-02-04 11:38:12", "link": "http://arxiv.org/abs/2402.02449v1", "categories": ["cs.CL", "cs.LG", "68, 68T50"], "primary_category": "cs.CL"}
{"title": "tnGPS: Discovering Unknown Tensor Network Structure Search Algorithms\n  via Large Language Models (LLMs)", "abstract": "Tensor networks are efficient for extremely high-dimensional representation,\nbut their model selection, known as tensor network structure search (TN-SS), is\na challenging problem. Although several works have targeted TN-SS, most\nexisting algorithms are manually crafted heuristics with poor performance,\nsuffering from the curse of dimensionality and local convergence. In this work,\nwe jump out of the box, studying how to harness large language models (LLMs) to\nautomatically discover new TN-SS algorithms, replacing the involvement of human\nexperts. By observing how human experts innovate in research, we model their\ncommon workflow and propose an automatic algorithm discovery framework called\ntnGPS. The proposed framework is an elaborate prompting pipeline that instruct\nLLMs to generate new TN-SS algorithms through iterative refinement and\nenhancement. The experimental results demonstrate that the algorithms\ndiscovered by tnGPS exhibit superior performance in benchmarks compared to the\ncurrent state-of-the-art methods.", "published": "2024-02-04 12:06:13", "link": "http://arxiv.org/abs/2402.02456v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GeReA: Question-Aware Prompt Captions for Knowledge-based Visual\n  Question Answering", "abstract": "Knowledge-based visual question answering (VQA) requires world knowledge\nbeyond the image for accurate answer. Recently, instead of extra knowledge\nbases, a large language model (LLM) like GPT-3 is activated as an implicit\nknowledge engine to jointly acquire and reason the necessary knowledge for\nanswering by converting images into textual information (e.g., captions and\nanswer candidates). However, such conversion may introduce irrelevant\ninformation, which causes the LLM to misinterpret images and ignore visual\ndetails crucial for accurate knowledge. We argue that multimodal large language\nmodel (MLLM) is a better implicit knowledge engine than the LLM for its\nsuperior capability of visual understanding. Despite this, how to activate the\ncapacity of MLLM as the implicit knowledge engine has not been explored yet.\nTherefore, we propose GeReA, a generate-reason framework that prompts a MLLM\nlike InstructBLIP with question relevant vision and language information to\ngenerate knowledge-relevant descriptions and reasons those descriptions for\nknowledge-based VQA. Specifically, the question-relevant image regions and\nquestion-specific manual prompts are encoded in the MLLM to generate the\nknowledge relevant descriptions, referred to as question-aware prompt captions.\nAfter that, the question-aware prompt captions, image-question pair, and\nsimilar samples are sent into the multi-modal reasoning model to learn a joint\nknowledge-image-question representation for answer prediction. GeReA unlocks\nthe use of MLLM as the implicit knowledge engine, surpassing all previous\nstate-of-the-art methods on OK-VQA and A-OKVQA datasets, with test accuracies\nof 66.5% and 63.3% respectively. Our code will be released at\nhttps://github.com/Upper9527/GeReA.", "published": "2024-02-04 14:28:23", "link": "http://arxiv.org/abs/2402.02503v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Integration of cognitive tasks into artificial general intelligence test\n  for large models", "abstract": "During the evolution of large models, performance evaluation is necessarily\nperformed to assess their capabilities and ensure safety before practical\napplication. However, current model evaluations mainly rely on specific tasks\nand datasets, lacking a united framework for assessing the multidimensional\nintelligence of large models. In this perspective, we advocate for a\ncomprehensive framework of cognitive science-inspired artificial general\nintelligence (AGI) tests, aimed at fulfilling the testing needs of large models\nwith enhanced capabilities. The cognitive science-inspired AGI tests encompass\nthe full spectrum of intelligence facets, including crystallized intelligence,\nfluid intelligence, social intelligence, and embodied intelligence. To assess\nthe multidimensional intelligence of large models, the AGI tests consist of a\nbattery of well-designed cognitive tests adopted from human intelligence tests,\nand then naturally encapsulates into an immersive virtual community. We propose\nincreasing the complexity of AGI testing tasks commensurate with advancements\nin large models and emphasizing the necessity for the interpretation of test\nresults to avoid false negatives and false positives. We believe that cognitive\nscience-inspired AGI tests will effectively guide the targeted improvement of\nlarge models in specific dimensions of intelligence and accelerate the\nintegration of large models into human society.", "published": "2024-02-04 15:50:42", "link": "http://arxiv.org/abs/2402.02547v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generalizable Entity Grounding via Assistance of Large Language Model", "abstract": "In this work, we propose a novel approach to densely ground visual entities\nfrom a long caption. We leverage a large multimodal model (LMM) to extract\nsemantic nouns, a class-agnostic segmentation model to generate entity-level\nsegmentation, and the proposed multi-modal feature fusion module to associate\neach semantic noun with its corresponding segmentation mask. Additionally, we\nintroduce a strategy of encoding entity segmentation masks into a colormap,\nenabling the preservation of fine-grained predictions from features of\nhigh-resolution masks. This approach allows us to extract visual features from\nlow-resolution images using the CLIP vision encoder in the LMM, which is more\ncomputationally efficient than existing approaches that use an additional\nencoder for high-resolution images. Our comprehensive experiments demonstrate\nthe superiority of our method, outperforming state-of-the-art techniques on\nthree tasks, including panoptic narrative grounding, referring expression\nsegmentation, and panoptic segmentation.", "published": "2024-02-04 16:06:05", "link": "http://arxiv.org/abs/2402.02555v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing Robustness in Biomedical NLI Models: A Probing Approach for\n  Clinical Trials", "abstract": "Large Language Models have revolutionized various fields and industries, such\nas Conversational AI, Content Generation, Information Retrieval, Business\nIntelligence, and Medical, to name a few. One major application in the field of\nmedical is to analyze and investigate clinical trials for entailment\ntasks.However, It has been observed that Large Language Models are susceptible\nto shortcut learning, factual inconsistency, and performance degradation with\nlittle variation in context. Adversarial and robust testing is performed to\nensure the integrity of models output. But, ambiguity still persists. In order\nto ensure the integrity of the reasoning performed and investigate the model\nhas correct syntactic and semantic understanding probing is used. Here, I used\nmnestic probing to investigate the Sci-five model, trained on clinical trial. I\ninvestigated the model for feature learnt with respect to natural logic. To\nachieve the target, I trained task specific probes. Used these probes to\ninvestigate the final layers of trained model. Then, fine tuned the trained\nmodel using iterative null projection. The results shows that model accuracy\nimproved. During experimentation, I observed that size of the probe has affect\non the fine tuning process.", "published": "2024-02-04 16:18:01", "link": "http://arxiv.org/abs/2402.02558v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Arithmetic in Transformers Explained", "abstract": "While recent work has shown transformers can learn addition, previous models\nexhibit poor prediction accuracy and are limited to small numbers. Furthermore,\nthe relationship between single-task and multitask arithmetic capabilities\nremains unexplored. In this work, we analyze 44 autoregressive transformer\nmodels trained on addition, subtraction, or both. These include 16\naddition-only models, 2 subtraction-only models, 8 \"mixed\" models trained to\nperform addition and subtraction, and 14 mixed models initialized with\nparameters from an addition-only model. The models span 5- to 15-digit\nquestions, 2 to 4 attention heads, and 2 to 3 layers. We show that the addition\nmodels converge on a common logical algorithm, with most models achieving\n>99.999% prediction accuracy. We provide a detailed mechanistic explanation of\nhow this algorithm is implemented within the network architecture.\nSubtraction-only models have lower accuracy. With the initialized mixed models,\nthrough parameter transfer experiments, we explore how multitask learning\ndynamics evolve, revealing that some features originally specialized for\naddition become polysemantic, serving both operations, and boosting subtraction\naccuracy. We explain the mixed algorithm mechanically. Finally, we introduce a\nreusable library of mechanistic interpretability tools to define, locate, and\nvisualize these algorithmic circuits across multiple models.", "published": "2024-02-04 21:33:18", "link": "http://arxiv.org/abs/2402.02619v9", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DenseFormer: Enhancing Information Flow in Transformers via Depth\n  Weighted Averaging", "abstract": "The transformer architecture by Vaswani et al. (2017) is now ubiquitous\nacross application domains, from natural language processing to speech\nprocessing and image understanding. We propose DenseFormer, a simple\nmodification to the standard architecture that improves the perplexity of the\nmodel without increasing its size -- adding a few thousand parameters for\nlarge-scale models in the 100B parameters range. Our approach relies on an\nadditional averaging step after each transformer block, which computes a\nweighted average of current and past representations -- we refer to this\noperation as Depth-Weighted-Average (DWA). The learned DWA weights exhibit\ncoherent patterns of information flow, revealing the strong and structured\nreuse of activations from distant layers. Experiments demonstrate that\nDenseFormer is more data efficient, reaching the same perplexity of much deeper\ntransformer models, and that for the same perplexity, these new models\noutperform transformer baselines in terms of memory efficiency and inference\ntime.", "published": "2024-02-04 21:44:09", "link": "http://arxiv.org/abs/2402.02622v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GIRT-Model: Automated Generation of Issue Report Templates", "abstract": "Platforms such as GitHub and GitLab introduce Issue Report Templates (IRTs)\nto enable more effective issue management and better alignment with developer\nexpectations. However, these templates are not widely adopted in most\nrepositories, and there is currently no tool available to aid developers in\ngenerating them. In this work, we introduce GIRT-Model, an assistant language\nmodel that automatically generates IRTs based on the developer's instructions\nregarding the structure and necessary fields. We create GIRT-Instruct, a\ndataset comprising pairs of instructions and IRTs, with the IRTs sourced from\nGitHub repositories. We use GIRT-Instruct to instruction-tune a T5-base model\nto create the GIRT-Model. In our experiments, GIRT-Model outperforms general\nlanguage models (T5 and Flan-T5 with different parameter sizes) in IRT\ngeneration by achieving significantly higher scores in ROUGE, BLEU, METEOR, and\nhuman evaluation. Additionally, we analyze the effectiveness of GIRT-Model in a\nuser study in which participants wrote short IRTs with GIRT-Model. Our results\nshow that the participants find GIRT-Model useful in the automated generation\nof templates. We hope that through the use of GIRT-Model, we can encourage more\ndevelopers to adopt IRTs in their repositories. We publicly release our code,\ndataset, and model at https://github.com/ISE-Research/girt-model.", "published": "2024-02-04 22:53:38", "link": "http://arxiv.org/abs/2402.02632v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Predicting Machine Translation Performance on Low-Resource Languages:\n  The Role of Domain Similarity", "abstract": "Fine-tuning and testing a multilingual large language model is expensive and\nchallenging for low-resource languages (LRLs). While previous studies have\npredicted the performance of natural language processing (NLP) tasks using\nmachine learning methods, they primarily focus on high-resource languages,\noverlooking LRLs and shifts across domains. Focusing on LRLs, we investigate\nthree factors: the size of the fine-tuning corpus, the domain similarity\nbetween fine-tuning and testing corpora, and the language similarity between\nsource and target languages. We employ classical regression models to assess\nhow these factors impact the model's performance. Our results indicate that\ndomain similarity has the most critical impact on predicting the performance of\nMachine Translation models.", "published": "2024-02-04 22:56:56", "link": "http://arxiv.org/abs/2402.02633v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Model for Table Processing: A Survey", "abstract": "Tables, typically two-dimensional and structured to store large amounts of\ndata, are essential in daily activities like database queries, spreadsheet\nmanipulations, web table question answering, and image table information\nextraction. Automating these table-centric tasks with Large Language Models\n(LLMs) or Visual Language Models (VLMs) offers significant public benefits,\ngarnering interest from academia and industry. This survey provides a\ncomprehensive overview of table-related tasks, examining both user scenarios\nand technical aspects. It covers traditional tasks like table question\nanswering as well as emerging fields such as spreadsheet manipulation and table\ndata analysis. We summarize the training techniques for LLMs and VLMs tailored\nfor table processing. Additionally, we discuss prompt engineering, particularly\nthe use of LLM-powered agents, for various table-related tasks. Finally, we\nhighlight several challenges, including diverse user input when serving and\nslow thinking using chain-of-thought.", "published": "2024-02-04 00:47:53", "link": "http://arxiv.org/abs/2402.05121v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Jailbreaking Attack against Multimodal Large Language Model", "abstract": "This paper focuses on jailbreaking attacks against multi-modal large language\nmodels (MLLMs), seeking to elicit MLLMs to generate objectionable responses to\nharmful user queries. A maximum likelihood-based algorithm is proposed to find\nan \\emph{image Jailbreaking Prompt} (imgJP), enabling jailbreaks against MLLMs\nacross multiple unseen prompts and images (i.e., data-universal property). Our\napproach exhibits strong model-transferability, as the generated imgJP can be\ntransferred to jailbreak various models, including MiniGPT-v2, LLaVA,\nInstructBLIP, and mPLUG-Owl2, in a black-box manner. Moreover, we reveal a\nconnection between MLLM-jailbreaks and LLM-jailbreaks. As a result, we\nintroduce a construction-based method to harness our approach for\nLLM-jailbreaks, demonstrating greater efficiency than current state-of-the-art\nmethods. The code is available here. \\textbf{Warning: some content generated by\nlanguage models may be offensive to some readers.}", "published": "2024-02-04 01:29:24", "link": "http://arxiv.org/abs/2402.02309v1", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Selecting Large Language Model to Fine-tune via Rectified Scaling Law", "abstract": "The ever-growing ecosystem of LLMs has posed a challenge in selecting the\nmost appropriate pre-trained model to fine-tune amidst a sea of options. Given\nconstrained resources, fine-tuning all models and making selections afterward\nis unrealistic. In this work, we formulate this resource-constrained selection\ntask into predicting fine-tuning performance and illustrate its natural\nconnection with Scaling Law. Unlike pre-training, we find that the fine-tuning\nscaling curve includes not just the well-known \"power phase\" but also the\npreviously unobserved \"pre-power phase\". We also explain why existing Scaling\nLaw fails to capture this phase transition phenomenon both theoretically and\nempirically. To address this, we introduce the concept of \"pre-learned data\nsize\" into our Rectified Scaling Law, which overcomes theoretical limitations\nand fits experimental results much better. By leveraging our law, we propose a\nnovel LLM selection algorithm that selects the near-optimal model with hundreds\nof times less resource consumption, while other methods may provide negatively\ncorrelated selection. The project page is available at\nrectified-scaling-law.github.io.", "published": "2024-02-04 01:55:00", "link": "http://arxiv.org/abs/2402.02314v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Loss Landscape Degeneracy Drives Stagewise Development in Transformers", "abstract": "Deep learning involves navigating a high-dimensional loss landscape over the\nneural network parameter space. Over the course of training, complex\ncomputational structures form and re-form inside the neural network, leading to\nshifts in input/output behavior. It is a priority for the science of deep\nlearning to uncover principles governing the development of neural network\nstructure and behavior. Drawing on the framework of singular learning theory,\nwe propose that model development is deeply linked to degeneracy in the local\ngeometry of the loss landscape. We investigate this link by monitoring loss\nlandscape degeneracy throughout training, as quantified by the local learning\ncoefficient, for a transformer language model and an in-context linear\nregression transformer. We show that training can be divided into distinct\nperiods of change in loss landscape degeneracy, and that these changes in\ndegeneracy coincide with significant changes in the internal computational\nstructure and the input/output behavior of the transformers. This finding\nunderscores the potential of a degeneracy-based perspective for understanding\nmodern deep learning.", "published": "2024-02-04 06:23:05", "link": "http://arxiv.org/abs/2402.02364v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face\n  Generation and Editing", "abstract": "Human face generation and editing represent an essential task in the era of\ncomputer vision and the digital world. Recent studies have shown remarkable\nprogress in multi-modal face generation and editing, for instance, using face\nsegmentation to guide image generation. However, it may be challenging for some\nusers to create these conditioning modalities manually. Thus, we introduce\nM3Face, a unified multi-modal multilingual framework for controllable face\ngeneration and editing. This framework enables users to utilize only text input\nto generate controlling modalities automatically, for instance, semantic\nsegmentation or facial landmarks, and subsequently generate face images. We\nconduct extensive qualitative and quantitative experiments to showcase our\nframeworks face generation and editing capabilities. Additionally, we propose\nthe M3CelebA Dataset, a large-scale multi-modal and multilingual face dataset\ncontaining high-quality images, semantic segmentations, facial landmarks, and\ndifferent captions for each image in multiple languages. The code and the\ndataset will be released upon publication.", "published": "2024-02-04 06:56:23", "link": "http://arxiv.org/abs/2402.02369v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Evaluating Large Language Models in Analysing Classroom Dialogue", "abstract": "This study explores the application of Large Language Models (LLMs),\nspecifically GPT-4, in the analysis of classroom dialogue, a crucial research\ntask for both teaching diagnosis and quality improvement. Recognizing the\nknowledge-intensive and labor-intensive nature of traditional qualitative\nmethods in educational research, this study investigates the potential of LLM\nto streamline and enhance the analysis process. The study involves datasets\nfrom a middle school, encompassing classroom dialogues across mathematics and\nChinese classes. These dialogues were manually coded by educational experts and\nthen analyzed using a customised GPT-4 model. This study focuses on comparing\nmanual annotations with the outputs of GPT-4 to evaluate its efficacy in\nanalyzing educational dialogues. Time efficiency, inter-coder agreement, and\ninter-coder reliability between human coders and GPT-4 are evaluated. Results\nindicate substantial time savings with GPT-4, and a high degree of consistency\nin coding between the model and human coders, with some discrepancies in\nspecific codes. These findings highlight the strong potential of LLM in\nteaching evaluation and facilitation.", "published": "2024-02-04 07:39:06", "link": "http://arxiv.org/abs/2402.02380v3", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Solution-oriented Agent-based Models Generation with Verifier-assisted\n  Iterative In-context Learning", "abstract": "Agent-based models (ABMs) stand as an essential paradigm for proposing and\nvalidating hypothetical solutions or policies aimed at addressing challenges\nposed by complex systems and achieving various objectives. This process demands\nlabor-intensive endeavors and multidisciplinary expertise. Large language\nmodels (LLMs) encapsulating cross-domain knowledge and programming proficiency\ncould potentially alleviate the difficulty of this process. However, LLMs excel\nin handling sequential information, making it challenging for analyzing the\nintricate interactions and nonlinear dynamics inherent in ABMs. Additionally,\ndue to the lack of self-evaluation capability of LLMs, relying solely on LLMs\nis insufficient to effectively accomplish this process. In this paper, we\npresent SAGE, a general solution-oriented ABM generation framework designed for\nautomatic modeling and generating solutions for targeted problems. Unlike\napproaches reliant on expert handcrafting or resource-intensive neural network\ntraining, SAGE establishes a verifier-assisted iterative in-context learning\nprocess employing large language models (LLMs) to leverages their inherent\ncross-domain knowledge for tackling intricate demands from diverse domain\nscenarios. In SAGE, we introduce an semi-structured conceptual representation\nexpliciting the intricate structures of ABMs and an objective representation to\nguide LLMs in modeling scenarios and proposing hypothetical solutions through\nin-context learning. To ensure the model executability and solution\nfeasibility, SAGE devises a two-level verifier with chain-of-thought prompting\ntailored to the complex interactions and non-linear dynamics of ABMs, driving\nthe iterative generation optimization. Moreover, we construct an evaluation\ndataset of solution-oriented ABMs from open sources.It contains practical\nmodels across various domains.", "published": "2024-02-04 07:59:06", "link": "http://arxiv.org/abs/2402.02388v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models", "abstract": "The potential of large language models (LLMs) as decision support tools is\nincreasingly being explored in fields such as business, engineering, and\nmedicine, which often face challenging tasks of decision-making under\nuncertainty. In this paper, we show that directly prompting LLMs on these types\nof decision-making problems can yield poor results, especially as the problem\ncomplexity increases. To aid in these tasks, we propose DeLLMa (Decision-making\nLarge Language Model assistant), a framework designed to enhance\ndecision-making accuracy in uncertain environments. DeLLMa involves a\nmulti-step reasoning procedure that integrates recent best practices in scaling\ninference-time reasoning, drawing upon principles from decision theory and\nutility theory, to provide an accurate and human-auditable decision-making\nprocess. We validate our procedure on multiple realistic decision-making\nenvironments, demonstrating that DeLLMa can consistently enhance the\ndecision-making performance of leading language models, and achieve up to a 40%\nincrease in accuracy over competing methods. Additionally, we show how\nperformance improves when scaling compute at test time, and carry out human\nevaluations to benchmark components of DeLLMa.", "published": "2024-02-04 08:11:45", "link": "http://arxiv.org/abs/2402.02392v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Aligner: Efficient Alignment by Learning to Correct", "abstract": "With the rapid development of large language models (LLMs) and ever-evolving\npractical requirements, finding an efficient and effective alignment method has\nnever been more critical. However, the tension between the complexity of\ncurrent alignment methods and the need for rapid iteration in deployment\nscenarios necessitates the development of a model-agnostic alignment approach\nthat can operate under these constraints. In this paper, we introduce Aligner,\na novel and simple alignment paradigm that learns the correctional residuals\nbetween preferred and dispreferred answers using a small model. Designed as a\nmodel-agnostic, plug-and-play module, Aligner can be directly applied to\nvarious open-source and API-based models with only one-off training, making it\nsuitable for rapid iteration. Notably, Aligner can be applied to any powerful,\nlarge-scale upstream models. Moreover, it can even iteratively bootstrap the\nupstream models using corrected responses as synthetic human preference data,\nbreaking through the model's performance ceiling. Our experiments demonstrate\nperformance improvements by deploying the same Aligner model across 11\ndifferent LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and\nhonesty). Specifically, Aligner-7B has achieved an average improvement of 68.9%\nin helpfulness and 23.8% in harmlessness across the tested LLMs while also\neffectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking\nAligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%,\nsurpassing GPT-4 Omni's 57.5% Win Rate (community report).", "published": "2024-02-04 09:24:51", "link": "http://arxiv.org/abs/2402.02416v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BRAIn: Bayesian Reward-conditioned Amortized Inference for natural\n  language generation from feedback", "abstract": "Distribution matching methods for language model alignment such as Generation\nwith Distributional Control (GDC) and Distributional Policy Gradient (DPG) have\nnot received the same level of attention in reinforcement learning from human\nfeedback (RLHF) as contrastive methods such as Sequence Likelihood Calibration\n(SLiC), Direct Preference Optimization (DPO) and its variants. We identify high\nvariance of the gradient estimate as the primary reason for the lack of success\nof these methods and propose a self-normalized baseline to reduce the variance.\nWe further generalize the target distribution in DPG, GDC and DPO by using\nBayes' rule to define the reward-conditioned posterior. The resulting approach,\nreferred to as BRAIn - Bayesian Reward-conditioned Amortized Inference acts as\na bridge between distribution matching methods and DPO and significantly\noutperforms prior art in summarization and Antropic HH tasks.", "published": "2024-02-04 13:16:29", "link": "http://arxiv.org/abs/2402.02479v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Early stopping by correlating online indicators in neural networks", "abstract": "In order to minimize the generalization error in neural networks, a novel\ntechnique to identify overfitting phenomena when training the learner is\nformally introduced. This enables support of a reliable and trustworthy early\nstopping condition, thus improving the predictive power of that type of\nmodeling. Our proposal exploits the correlation over time in a collection of\nonline indicators, namely characteristic functions for indicating if a set of\nhypotheses are met, associated with a range of independent stopping conditions\nbuilt from a canary judgment to evaluate the presence of overfitting. That way,\nwe provide a formal basis for decision making in terms of interrupting the\nlearning process.\n  As opposed to previous approaches focused on a single criterion, we take\nadvantage of subsidiarities between independent assessments, thus seeking both\na wider operating range and greater diagnostic reliability. With a view to\nillustrating the effectiveness of the halting condition described, we choose to\nwork in the sphere of natural language processing, an operational continuum\nincreasingly based on machine learning. As a case study, we focus on parser\ngeneration, one of the most demanding and complex tasks in the domain. The\nselection of cross-validation as a canary function enables an actual comparison\nwith the most representative early stopping conditions based on overfitting\nidentification, pointing to a promising start toward an optimal bias and\nvariance control.", "published": "2024-02-04 14:57:20", "link": "http://arxiv.org/abs/2402.02513v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Modeling of learning curves with applications to pos tagging", "abstract": "An algorithm to estimate the evolution of learning curves on the whole of a\ntraining data base, based on the results obtained from a portion and using a\nfunctional strategy, is introduced. We approximate iteratively the sought value\nat the desired time, independently of the learning technique used and once a\npoint in the process, called prediction level, has been passed. The proposal\nproves to be formally correct with respect to our working hypotheses and\nincludes a reliable proximity condition. This allows the user to fix a\nconvergence threshold with respect to the accuracy finally achievable, which\nextends the concept of stopping criterion and seems to be effective even in the\npresence of distorting observations.\n  Our aim is to evaluate the training effort, supporting decision making in\norder to reduce the need for both human and computational resources during the\nlearning process. The proposal is of interest in at least three operational\nprocedures. The first is the anticipation of accuracy gain, with the purpose of\nmeasuring how much work is needed to achieve a certain degree of performance.\nThe second relates the comparison of efficiency between systems at training\ntime, with the objective of completing this task only for the one that best\nsuits our requirements. The prediction of accuracy is also a valuable item of\ninformation for customizing systems, since we can estimate in advance the\nimpact of settings on both the performance and the development costs. Using the\ngeneration of part-of-speech taggers as an example application, the\nexperimental results are consistent with our expectations.", "published": "2024-02-04 15:00:52", "link": "http://arxiv.org/abs/2402.02515v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive scheduling for adaptive sampling in POS taggers construction", "abstract": "We introduce an adaptive scheduling for adaptive sampling as a novel way of\nmachine learning in the construction of part-of-speech taggers. The goal is to\nspeed up the training on large data sets, without significant loss of\nperformance with regard to an optimal configuration. In contrast to previous\nmethods using a random, fixed or regularly rising spacing between the\ninstances, ours analyzes the shape of the learning curve geometrically in\nconjunction with a functional model to increase or decrease it at any time. The\nalgorithm proves to be formally correct regarding our working hypotheses.\nNamely, given a case, the following one is the nearest ensuring a net gain of\nlearning ability from the former, it being possible to modulate the level of\nrequirement for this condition. We also improve the robustness of sampling by\npaying greater attention to those regions of the training data base subject to\na temporary inflation in performance, thus preventing the learning from\nstopping prematurely.\n  The proposal has been evaluated on the basis of its reliability to identify\nthe convergence of models, corroborating our expectations. While a concrete\nhalting condition is used for testing, users can choose any condition\nwhatsoever to suit their own specific needs.", "published": "2024-02-04 15:02:17", "link": "http://arxiv.org/abs/2402.02516v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Absolute convergence and error thresholds in non-active adaptive\n  sampling", "abstract": "Non-active adaptive sampling is a way of building machine learning models\nfrom a training data base which are supposed to dynamically and automatically\nderive guaranteed sample size. In this context and regardless of the strategy\nused in both scheduling and generating of weak predictors, a proposal for\ncalculating absolute convergence and error thresholds is described. We not only\nmake it possible to establish when the quality of the model no longer\nincreases, but also supplies a proximity condition to estimate in absolute\nterms how close it is to achieving such a goal, thus supporting decision making\nfor fine-tuning learning parameters in model selection. The technique proves\nits correctness and completeness with respect to our working hypotheses, in\naddition to strengthening the robustness of the sampling scheme. Tests meet our\nexpectations and illustrate the proposal in the domain of natural language\nprocessing, taking the generation of part-of-speech taggers as case study.", "published": "2024-02-04 15:10:34", "link": "http://arxiv.org/abs/2402.02522v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Generation for Zero-shot Knowledge-based VQA", "abstract": "Previous solutions to knowledge-based visual question answering~(K-VQA)\nretrieve knowledge from external knowledge bases and use supervised learning to\ntrain the K-VQA model. Recently pre-trained LLMs have been used as both a\nknowledge source and a zero-shot QA model for K-VQA and demonstrated promising\nresults. However, these recent methods do not explicitly show the knowledge\nneeded to answer the questions and thus lack interpretability. Inspired by\nrecent work on knowledge generation from LLMs for text-based QA, in this work\nwe propose and test a similar knowledge-generation-based K-VQA method, which\nfirst generates knowledge from an LLM and then incorporates the generated\nknowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA\nbenchmarks and found that our method performs better than previous zero-shot\nK-VQA methods and our generated knowledge is generally relevant and helpful.", "published": "2024-02-04 15:41:35", "link": "http://arxiv.org/abs/2402.02541v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "\"What's my model inside of?\": Exploring the role of environments for\n  grounded natural language understanding", "abstract": "In contrast to classical cognitive science which studied brains in isolation,\necological approaches focused on the role of the body and environment in\nshaping cognition. Similarly, in this thesis we adopt an ecological approach to\ngrounded natural language understanding (NLU) research. Grounded language\nunderstanding studies language understanding systems situated in the context of\nevents, actions and precepts in naturalistic/simulated virtual environments.\nWhere classic research tends to focus on designing new models and optimization\nmethods while treating environments as given, we explore the potential of\nenvironment design for improving data collection and model development. We\ndeveloped novel training and annotation approaches for procedural text\nunderstanding based on text-based game environments. We also drew upon embodied\ncognitive linguistics literature to propose a roadmap for grounded NLP\nresearch, and to inform the development of a new benchmark for measuring the\nprogress of large language models on challenging commonsense reasoning tasks.\nWe leveraged the richer supervision provided by text-based game environments to\ndevelop Breakpoint Transformers, a novel approach to modeling intermediate\nsemantic information in long narrative or procedural texts. Finally, we\nintegrated theories on the role of environments in collective human\nintelligence to propose a design for AI-augmented \"social thinking\nenvironments\" for knowledge workers like scientists.", "published": "2024-02-04 15:52:46", "link": "http://arxiv.org/abs/2402.02548v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models Table-based Fact-Checkers?", "abstract": "Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.", "published": "2024-02-04 15:52:59", "link": "http://arxiv.org/abs/2402.02549v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language\n  Models", "abstract": "Large language models (LLMs) have shown impressive emergent abilities in a\nwide range of tasks, but the associated expensive API cost greatly limits the\nreal application. Previous works like chain-of-thought (CoT) and\ntree-of-thoughts (ToT) have predominately focused on enhancing accuracy, but\noverlook the rapidly increasing API cost, which could be particularly\nproblematic for open-ended real-world tasks with huge solution spaces.\nMotivated by the dual process theory of human cognition, we propose \"Synergy of\nThoughts\"(SoT) to unleash the synergistic potential of hybrid LLMs with\ndifferent scales for efficient reasoning. By default, SoT uses smaller-scale\nlanguage models to generate multiple low-cost intuitive thoughts, which\nresembles the parallel intuitions produced by System 1. We then design a\nconfidence evaluator where the intuitive thoughts are cross-evaluated and\nintroduce a controllable threshold mechanism to decide their mutual conflict.\nIf these intuitive thoughts exhibit conflicts, SoT will invoke the reflective\nreasoning of scaled-up language models to emulate the intervention of System 2,\nwhich will override the intuitive thoughts and rectify the reasoning results.\nThis framework is model-agnostic and training-free, which can be flexibly\nimplemented with various off-the-shelf LLMs. Experiments on six representative\nreasoning tasks show that SoT substantially reduces the API cost by\n38.3%-75.1%, and simultaneously achieves state-of-the-art reasoning accuracy\nand solution diversity. Notably, the average token cost reduction on open-ended\ntasks reaches up to 69.1%.", "published": "2024-02-04 16:45:01", "link": "http://arxiv.org/abs/2402.02563v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Truly Joint Neural Architecture for Segmentation and Parsing", "abstract": "Contemporary multilingual dependency parsers can parse a diverse set of\nlanguages, but for Morphologically Rich Languages (MRLs), performance is\nattested to be lower than other languages. The key challenge is that, due to\nhigh morphological complexity and ambiguity of the space-delimited input\ntokens, the linguistic units that act as nodes in the tree are not known in\nadvance. Pre-neural dependency parsers for MRLs subscribed to the joint\nmorpho-syntactic hypothesis, stating that morphological segmentation and\nsyntactic parsing should be solved jointly, rather than as a pipeline where\nsegmentation precedes parsing. However, neural state-of-the-art parsers to date\nuse a strict pipeline. In this paper we introduce a joint neural architecture\nwhere a lattice-based representation preserving all morphological ambiguity of\nthe input is provided to an arc-factored model, which then solves the\nmorphological segmentation and syntactic parsing tasks at once. Our experiments\non Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art\nperformance on parsing, tagging and segmentation of the Hebrew section of UD,\nusing a single model. This proposed architecture is LLM-based and language\nagnostic, providing a solid foundation for MRLs to obtain further performance\nimprovements and bridge the gap with other languages.", "published": "2024-02-04 16:56:08", "link": "http://arxiv.org/abs/2402.02564v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FCoReBench: Can Large Language Models Solve Challenging First-Order\n  Combinatorial Reasoning Problems?", "abstract": "Can the large language models (LLMs) solve challenging first-order\ncombinatorial reasoning problems such as graph coloring, knapsack, and\ncryptarithmetic? By first-order, we mean these problems can be instantiated\nwith potentially an infinite number of problem instances of varying sizes. They\nare also challenging being NP-hard and requiring several reasoning steps to\nreach a solution. While existing work has focused on coming up with datasets\nwith hard benchmarks, there is limited work which exploits the first-order\nnature of the problem structure. To address this challenge, we present\nFCoReBench, a dataset of 40 such challenging problems, along with scripts to\ngenerate problem instances of varying sizes and automatically verify and\ngenerate their solutions. We first observe that LLMs, even when aided by\nsymbolic solvers, perform rather poorly on our dataset, being unable to\nleverage the underlying structure of these problems. We specifically observe a\ndrop in performance with increasing problem size. In response, we propose a new\napproach, SymPro-LM, which combines LLMs with both symbolic solvers and program\ninterpreters, along with feedback from a few solved examples, to achieve huge\nperformance gains. Our proposed approach is robust to changes in the problem\nsize, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM's effectiveness on other logical reasoning benchmarks.", "published": "2024-02-04 20:56:09", "link": "http://arxiv.org/abs/2402.02611v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study\n  on Speech Emotion Recognition", "abstract": "The efficacy of self-supervised speech models has been validated, yet the\noptimal utilization of their representations remains challenging across diverse\ntasks. In this study, we delve into Acoustic Word Embeddings (AWEs), a\nfixed-length feature derived from continuous representations, to explore their\nadvantages in specific tasks. AWEs have previously shown utility in capturing\nacoustic discriminability. In light of this, we propose measuring layer-wise\nsimilarity between AWEs and word embeddings, aiming to further investigate the\ninherent context within AWEs. Moreover, we evaluate the contribution of AWEs,\nin comparison to other types of speech features, in the context of Speech\nEmotion Recognition (SER). Through a comparative experiment and a layer-wise\naccuracy analysis on two distinct corpora, IEMOCAP and ESD, we explore\ndifferences between AWEs and raw self-supervised representations, as well as\nthe proper utilization of AWEs alone and in combination with word embeddings.\nOur findings underscore the acoustic context conveyed by AWEs and showcase the\nhighly competitive SER accuracies by appropriately employing AWEs.", "published": "2024-02-04 21:24:54", "link": "http://arxiv.org/abs/2402.02617v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Transformer RNNs with Multiple Temporal Perspectives", "abstract": "We introduce the concept of multiple temporal perspectives, a novel approach\napplicable to Recurrent Neural Network (RNN) architectures for enhancing their\nunderstanding of sequential data. This method involves maintaining diverse\ntemporal views of previously encountered text, significantly enriching the\nlanguage models' capacity to interpret context. To show the efficacy of this\napproach, we incorporate it into the Receptance Weighted Key Value (RWKV)\narchitecture, addressing its inherent challenge of retaining all historical\ninformation within a single hidden state. Notably, this improvement is achieved\nwith a minimal increase in the number of parameters --even as little as\n$0.04\\%$ of the original number of parameters. Further, the additional\nparameters necessary for the multiple temporal perspectives are fine-tuned with\nminimal computational overhead, avoiding the need for a full pre-training. The\nresulting model maintains linear computational complexity during prompt\ninference, ensuring consistent efficiency across various sequence lengths. The\nempirical results and ablation studies included in our research validate the\neffectiveness of our approach, showcasing improved performance across multiple\nbenchmarks. The code, model weights and datasets are open-sourced at:\nhttps://github.com/RazvanDu/TemporalRNNs.", "published": "2024-02-04 22:12:29", "link": "http://arxiv.org/abs/2402.02625v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.0; I.2.7"], "primary_category": "cs.LG"}
{"title": "LLM-Enhanced Data Management", "abstract": "Machine learning (ML) techniques for optimizing data management problems have\nbeen extensively studied and widely deployed in recent five years. However\ntraditional ML methods have limitations on generalizability (adapting to\ndifferent scenarios) and inference ability (understanding the context).\nFortunately, large language models (LLMs) have shown high generalizability and\nhuman-competitive abilities in understanding context, which are promising for\ndata management tasks (e.g., database diagnosis, database tuning). However,\nexisting LLMs have several limitations: hallucination, high cost, and low\naccuracy for complicated tasks. To address these challenges, we design LLMDB,\nan LLM-enhanced data management paradigm which has generalizability and high\ninference ability while avoiding hallucination, reducing LLM cost, and\nachieving high accuracy. LLMDB embeds domain-specific knowledge to avoid\nhallucination by LLM fine-tuning and prompt engineering. LLMDB reduces the high\ncost of LLMs by vector databases which provide semantic search and caching\nabilities. LLMDB improves the task accuracy by LLM agent which provides\nmultiple-round inference and pipeline executions. We showcase three real-world\nscenarios that LLMDB can well support, including query rewrite, database\ndiagnosis and data analytics. We also summarize the open research challenges of\nLLMDB.", "published": "2024-02-04 23:42:02", "link": "http://arxiv.org/abs/2402.02643v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "History of generative Artificial Intelligence (AI) chatbots: past,\n  present, and future development", "abstract": "This research provides an in-depth comprehensive review of the progress of\nchatbot technology over time, from the initial basic systems relying on rules\nto today's advanced conversational bots powered by artificial intelligence.\nSpanning many decades, the paper explores the major milestones, innovations,\nand paradigm shifts that have driven the evolution of chatbots. Looking back at\nthe very basic statistical model in 1906 via the early chatbots, such as ELIZA\nand ALICE in the 1960s and 1970s, the study traces key innovations leading to\ntoday's advanced conversational agents, such as ChatGPT and Google Bard. The\nstudy synthesizes insights from academic literature and industry sources to\nhighlight crucial milestones, including the introduction of Turing tests,\ninfluential projects such as CALO, and recent transformer-based models. Tracing\nthe path forward, the paper highlights how natural language processing and\nmachine learning have been integrated into modern chatbots for more\nsophisticated capabilities. This chronological survey of the chatbot landscape\nprovides a holistic reference to understand the technological and historical\nfactors propelling conversational AI. By synthesizing learnings from this\nhistorical analysis, the research offers important context about the\ndevelopmental trajectory of chatbots and their immense future potential across\nvarious field of application which could be the potential take ways for the\nrespective research community and stakeholders.", "published": "2024-02-04 05:01:38", "link": "http://arxiv.org/abs/2402.05122v1", "categories": ["cs.GL", "cs.CL", "cs.HC"], "primary_category": "cs.GL"}
{"title": "Advancing Graph Representation Learning with Large Language Models: A\n  Comprehensive Survey of Techniques", "abstract": "The integration of Large Language Models (LLMs) with Graph Representation\nLearning (GRL) marks a significant evolution in analyzing complex data\nstructures. This collaboration harnesses the sophisticated linguistic\ncapabilities of LLMs to improve the contextual understanding and adaptability\nof graph models, thereby broadening the scope and potential of GRL. Despite a\ngrowing body of research dedicated to integrating LLMs into the graph domain, a\ncomprehensive review that deeply analyzes the core components and operations\nwithin these models is notably lacking. Our survey fills this gap by proposing\na novel taxonomy that breaks down these models into primary components and\noperation techniques from a novel technical perspective. We further dissect\nrecent literature into two primary components including knowledge extractors\nand organizers, and two operation techniques including integration and training\nstratigies, shedding light on effective model design and training strategies.\nAdditionally, we identify and explore potential future research avenues in this\nnascent yet underexplored field, proposing paths for continued progress.", "published": "2024-02-04 05:51:14", "link": "http://arxiv.org/abs/2402.05952v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Navigating the Peril of Generated Alternative Facts: A ChatGPT-4\n  Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation", "abstract": "In an era where artificial intelligence (AI) intertwines with medical\nresearch, the delineation of truth becomes increasingly complex. This study\nostensibly examines a purported novel SARS-CoV-2 variant, dubbed the Omega\nvariant, showcasing 31 unique mutations in the S gene region. However, the real\nundercurrent of this narrative is a demonstration of the ease with which AI,\nspecifically ChatGPT-4, can fabricate convincing yet entirely fictional\nscientific data. The so-called Omega variant was identified in a fully\nvaccinated, previously infected 35-year-old male presenting with severe\nCOVID-19 symptoms. Through a detailed, albeit artificial, genomic analysis and\ncontact tracing, this study mirrors the rigorous methodology of genuine case\nreports, thereby setting the stage for a compelling but entirely constructed\nnarrative. The entire case study was generated by ChatGPT-4, a large language\nmodel by OpenAI. The fabricated Omega variant features an ensemble of\nmutations, including N501Y and E484K, known for enhancing ACE2 receptor\naffinity, alongside L452R and P681H, ostensibly indicative of immune evasion.\nThis variant's contrived interaction dynamics - severe symptoms in a vaccinated\nindividual versus mild ones in unvaccinated contacts - were designed to mimic\nreal-world complexities, including suggestions of antibody-dependent\nenhancement (ADE). While the Omega variant is a product of AI-generated\nfiction, the implications of this exercise are real and profound. The ease with\nwhich AI can generate believable but false scientific information, as\nillustrated in this case, raises significant concerns about the potential for\nmisinformation in medicine. This study, therefore, serves as a cautionary tale,\nemphasizing the necessity for critical evaluation of sources, especially in an\nage where AI tools like ChatGPT are becoming increasingly sophisticated and\nwidespread in their use.", "published": "2024-02-04 13:21:19", "link": "http://arxiv.org/abs/2403.09674v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Learn Independent Causal Mechanisms?", "abstract": "Despite impressive performance on language modelling and complex reasoning\ntasks, Large Language Models (LLMs) fall short on the same tasks in uncommon\nsettings or with distribution shifts, exhibiting a lack of generalisation\nability. By contrast, systems such as causal models, that learn abstract\nvariables and causal relationships, can demonstrate increased robustness\nagainst changes in the distribution. One reason for this success is the\nexistence and use of Independent Causal Mechanisms (ICMs) representing\nhigh-level concepts that only sparsely interact. In this work, we apply two\nconcepts from causality to learn ICMs within LLMs. We develop a new LLM\narchitecture composed of multiple sparsely interacting language modelling\nmodules. We show that such causal constraints can improve out-of-distribution\nperformance on abstract and causal reasoning tasks. We also investigate the\nlevel of independence and domain specialisation and show that LLMs rely on\npre-trained partially domain-invariant mechanisms resilient to fine-tuning.", "published": "2024-02-04 23:04:02", "link": "http://arxiv.org/abs/2402.02636v2", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "math.IT", "I.2.3; I.2.6; I.2.7; G.3"], "primary_category": "cs.CL"}
{"title": "UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large\n  Language Models for Program Testing", "abstract": "The remarkable capability of large language models (LLMs) in generating\nhigh-quality code has drawn increasing attention in the software testing\ncommunity. However, existing code LLMs often demonstrate unsatisfactory\ncapabilities in generating accurate and complete tests since they were trained\non code snippets collected without differentiating between code for testing\npurposes and other code. In this paper, we present a large-scale dataset\nUniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test\nSynthesis. Associating tests with the tested functions is crucial for LLMs to\ninfer the expected behavior and the logic paths to be verified. By leveraging\nLanguage Server Protocol, UniTSyn achieves the challenging goal of collecting\nfocal-test pairs without per-project execution setups or per-language\nheuristics that tend to be fragile and difficult to scale. It contains 2.7\nmillion focal-test pairs across five mainstream programming languages, making\nit possible to be utilized for enhancing the test generation ability of LLMs.\nThe details of UniTSyn can be found in Table 1. Our experiments demonstrate\nthat, by building an autoregressive model based on UniTSyn, we can achieve\nsignificant benefits in learning and understanding unit test representations,\nresulting in improved generation accuracy and code coverage across all\nevaluated programming languages. Code and data will be publicly available.", "published": "2024-02-04 22:48:05", "link": "http://arxiv.org/abs/2402.03396v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Improving Assessment of Tutoring Practices using Retrieval-Augmented\n  Generation", "abstract": "One-on-one tutoring is an effective instructional method for enhancing\nlearning, yet its efficacy hinges on tutor competencies. Novice math tutors\noften prioritize content-specific guidance, neglecting aspects such as\nsocial-emotional learning. Social-emotional learning promotes equity and\ninclusion and nurturing relationships with students, which is crucial for\nholistic student development. Assessing the competencies of tutors accurately\nand efficiently can drive the development of tailored tutor training programs.\nHowever, evaluating novice tutor ability during real-time tutoring remains\nchallenging as it typically requires experts-in-the-loop. To address this\nchallenge, this preliminary study aims to harness Generative Pre-trained\nTransformers (GPT), such as GPT-3.5 and GPT-4 models, to automatically assess\ntutors' ability of using social-emotional tutoring strategies. Moreover, this\nstudy also reports on the financial dimensions and considerations of employing\nthese models in real-time and at scale for automated assessment. The current\nstudy examined four prompting strategies: two basic Zero-shot prompt\nstrategies, Tree of Thought prompt, and Retrieval-Augmented Generator (RAG)\nbased prompt. The results indicate that the RAG prompt demonstrated more\naccurate performance (assessed by the level of hallucination and correctness in\nthe generated assessment texts) and lower financial costs than the other\nstrategies evaluated. These findings inform the development of personalized\ntutor training interventions to enhance the the educational effectiveness of\ntutored learning.", "published": "2024-02-04 20:42:30", "link": "http://arxiv.org/abs/2402.14594v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.CY"}
{"title": "Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues", "abstract": "How to effectively interact audio with vision has garnered considerable\ninterest within the multi-modality research field. Recently, a novel\naudio-visual segmentation (AVS) task has been proposed, aiming to segment the\nsounding objects in video frames under the guidance of audio cues. However,\nmost existing AVS methods are hindered by a modality imbalance where the visual\nfeatures tend to dominate those of the audio modality, due to a unidirectional\nand insufficient integration of audio cues. This imbalance skews the feature\nrepresentation towards the visual aspect, impeding the learning of joint\naudio-visual representations and potentially causing segmentation inaccuracies.\nTo address this issue, we propose AVSAC. Our approach features a Bidirectional\nAudio-Visual Decoder (BAVD) with integrated bidirectional bridges, enhancing\naudio cues and fostering continuous interplay between audio and visual\nmodalities. This bidirectional interaction narrows the modality imbalance,\nfacilitating more effective learning of integrated audio-visual\nrepresentations. Additionally, we present a strategy for audio-visual\nframe-wise synchrony as fine-grained guidance of BAVD. This strategy enhances\nthe share of auditory components in visual features, contributing to a more\nbalanced audio-visual representation learning. Extensive experiments show that\nour method attains new benchmarks in AVS performance.", "published": "2024-02-04 03:02:35", "link": "http://arxiv.org/abs/2402.02327v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Acoustic Local Positioning With Encoded Emission Beacons", "abstract": "Acoustic local positioning systems (ALPSs) are an interesting alternative for\nindoor positioning due to certain advantages over other approaches, including\ntheir relatively high accuracy, low cost, and room-level signal propagation.\nCentimeter-level or fine-grained indoor positioning can be an asset for robot\nnavigation, guiding a person to, for instance, a particular piece in a museum\nor to a specific product in a shop, targeted advertising, or augmented reality.\nIn airborne system applications, acoustic positioning can be based on using\nopportunistic signals or sounds produced by the person or object to be located\n(e.g., noise from appliances or the speech from a speaker) or from encoded\nemission beacons (or anchors) specifically designed for this purpose. This work\npresents a review of the different challenges that designers of systems based\non encoded emission beacons must address in order to achieve suitable\nperformance. At low-level processing, the waveform design (coding and\nmodulation) and the processing of the received signal are key factors to\naddress such drawbacks as multipath propagation, multiple-access interference,\nnearfar effect, or Doppler shifting. With regards to high-level system design,\nthe issues to be addressed are related to the distribution of beacons, ease of\ndeployment, and calibration and positioning algorithms, including the possible\nfusion of information. Apart from theoretical discussions, this work also\nincludes the description of an ALPS that was implemented, installed in a large\narea and tested for mobile robot navigation. In addition to practical interest\nfor real applications, airborne ALPSs can also be used as an excellent platform\nto test complex algorithms, which can be subsequently adapted for other\npositioning systems, such as underwater acoustic systems or ultrawideband\nradiofrequency (UWB RF) systems.", "published": "2024-02-04 07:51:39", "link": "http://arxiv.org/abs/2402.02384v1", "categories": ["eess.SP", "cs.AR", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
