{"title": "Simulate and Optimise: A two-layer mortgage simulator for designing novel mortgage assistance products", "abstract": "We develop a novel two-layer approach for optimising mortgage relief products\nthrough a simulated multi-agent mortgage environment. While the approach is\ngeneric, here the environment is calibrated to the US mortgage market based on\npublicly available census data and regulatory guidelines. Through the\nsimulation layer, we assess the resilience of households to exogenous income\nshocks, while the optimisation layer explores strategies to improve the\nrobustness of households to these shocks by making novel mortgage assistance\nproducts available to households. Households in the simulation are adaptive,\nlearning to make mortgage-related decisions (such as product enrolment or\nstrategic foreclosures) that maximize their utility, balancing their available\nliquidity and equity. We show how this novel two-layer simulation approach can\nsuccessfully design novel mortgage assistance products to improve household\nresilience to exogenous shocks, and balance the costs of providing such\nproducts through post-hoc analysis. Previously, such analysis could only be\nconducted through expensive pilot studies involving real participants,\ndemonstrating the benefit of the approach for designing and evaluating\nfinancial products.", "published": "2024-11-01 13:21:11", "link": "http://arxiv.org/abs/2411.00563v1", "categories": ["cs.MA", "cs.AI", "cs.CE", "q-fin.CP"], "primary_category": "cs.MA"}
{"title": "Evaluating Company-specific Biases in Financial Sentiment Analysis using Large Language Models", "abstract": "This study aims to evaluate the sentiment of financial texts using large\nlanguage models~(LLMs) and to empirically determine whether LLMs exhibit\ncompany-specific biases in sentiment analysis. Specifically, we examine the\nimpact of general knowledge about firms on the sentiment measurement of texts\nby LLMs. Firstly, we compare the sentiment scores of financial texts by LLMs\nwhen the company name is explicitly included in the prompt versus when it is\nnot. We define and quantify company-specific bias as the difference between\nthese scores. Next, we construct an economic model to theoretically evaluate\nthe impact of sentiment bias on investor behavior. This model helps us\nunderstand how biased LLM investments, when widespread, can distort stock\nprices. This implies the potential impact on stock prices if investments driven\nby biased LLMs become dominant in the future. Finally, we conduct an empirical\nanalysis using Japanese financial text data to examine the relationship between\nfirm-specific sentiment bias, corporate characteristics, and stock performance.", "published": "2024-11-01 07:37:24", "link": "http://arxiv.org/abs/2411.00420v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "A Review of Reinforcement Learning in Financial Applications", "abstract": "In recent years, there has been a growing trend of applying Reinforcement\nLearning (RL) in financial applications.\n  This approach has shown great potential to solve decision-making tasks in\nfinance.\n  In this survey, we present a comprehensive study of the applications of RL in\nfinance and conduct a series of meta-analyses to investigate the common themes\nin the literature, such as the factors that most significantly affect RL's\nperformance compared to traditional methods.\n  Moreover, we identify challenges including explainability, Markov Decision\nProcess (MDP) modeling, and robustness that hinder the broader utilization of\nRL in the financial industry and discuss recent advancements in overcoming\nthese challenges.\n  Finally, we propose future research directions, such as benchmarking,\ncontextual RL, multi-agent RL, and model-based RL to address these challenges\nand to further enhance the implementation of RL in finance.", "published": "2024-11-01 01:03:10", "link": "http://arxiv.org/abs/2411.12746v1", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Discrete approximation of risk-based prices under volatility uncertainty", "abstract": "We discuss the asymptotic behaviour of risk-based indifference prices of\nEuropean contingent claims in discrete-time financial markets under volatility\nuncertainty as the number of intermediate trading periods tends to infinity.\nThe asymptotic risk-based prices form a strongly continuous convex monotone\nsemigroup which is uniquely determined by its infinitesimal generator and\ntherefore only depends on the covariance of the random factors but not on the\nparticular choice of the model. We further compare the risk-based prices with\nthe worst-case prices given by the $G$-expectation and investigate their\nasymptotic behaviour as the risk aversion of the agent tends to infinity. The\ntheoretical results are illustrated with several examples and numerical\nsimulations showing, in particular, that the risk-based prices lead to a\nsignificant reduction of the bid-ask spread compared to the worst-case prices.", "published": "2024-11-01 16:27:14", "link": "http://arxiv.org/abs/2411.00713v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "Graph Neural Networks for Financial Fraud Detection: A Review", "abstract": "The landscape of financial transactions has grown increasingly complex due to\nthe expansion of global economic integration and advancements in information\ntechnology. This complexity poses greater challenges in detecting and managing\nfinancial fraud. This review explores the role of Graph Neural Networks (GNNs)\nin addressing these challenges by proposing a unified framework that\ncategorizes existing GNN methodologies applied to financial fraud detection.\nSpecifically, by examining a series of detailed research questions, this review\ndelves into the suitability of GNNs for financial fraud detection, their\ndeployment in real-world scenarios, and the design considerations that enhance\ntheir effectiveness. This review reveals that GNNs are exceptionally adept at\ncapturing complex relational patterns and dynamics within financial networks,\nsignificantly outperforming traditional fraud detection methods. Unlike\nprevious surveys that often overlook the specific potentials of GNNs or address\nthem only superficially, our review provides a comprehensive, structured\nanalysis, distinctly focusing on the multifaceted applications and deployments\nof GNNs in financial fraud detection. This review not only highlights the\npotential of GNNs to improve fraud detection mechanisms but also identifies\ncurrent gaps and outlines future research directions to enhance their\ndeployment in financial systems. Through a structured review of over 100\nstudies, this review paper contributes to the understanding of GNN applications\nin financial fraud detection, offering insights into their adaptability and\npotential integration strategies.", "published": "2024-11-01 03:59:57", "link": "http://arxiv.org/abs/2411.05815v2", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "A Survey of Financial AI: Architectures, Advances and Open Challenges", "abstract": "Financial AI empowers sophisticated approaches to financial market\nforecasting, portfolio optimization, and automated trading. This survey\nprovides a systematic analysis of these developments across three primary\ndimensions: predictive models that capture complex market dynamics,\ndecision-making frameworks that optimize trading and investment strategies, and\nknowledge augmentation systems that leverage unstructured financial\ninformation. We examine significant innovations including foundation models for\nfinancial time series, graph-based architectures for market relationship\nmodeling, and hierarchical frameworks for portfolio optimization. Analysis\nreveals crucial trade-offs between model sophistication and practical\nconstraints, particularly in high-frequency trading applications. We identify\ncritical gaps and open challenges between theoretical advances and industrial\nimplementation, outlining open challenges and opportunities for improving both\nmodel performance and practical applicability.", "published": "2024-11-01 04:16:00", "link": "http://arxiv.org/abs/2411.12747v1", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "LLM-Ref: Enhancing Reference Handling in Technical Writing with Large\n  Language Models", "abstract": "Large Language Models (LLMs) excel in data synthesis but can be inaccurate in\ndomain-specific tasks, which retrieval-augmented generation (RAG) systems\naddress by leveraging user-provided data. However, RAGs require optimization in\nboth retrieval and generation stages, which can affect output quality. In this\npaper, we present LLM-Ref, a writing assistant tool that aids researchers in\nwriting articles from multiple source documents with enhanced reference\nsynthesis and handling capabilities. Unlike traditional RAG systems that use\nchunking and indexing, our tool retrieves and generates content directly from\ntext paragraphs. This method facilitates direct reference extraction from the\ngenerated outputs, a feature unique to our tool. Additionally, our tool employs\niterative response generation, effectively managing lengthy contexts within the\nlanguage model's constraints. Compared to baseline RAG-based systems, our\napproach achieves a $3.25\\times$ to $6.26\\times$ increase in Ragas score, a\ncomprehensive metric that provides a holistic view of a RAG system's ability to\nproduce accurate, relevant, and contextually appropriate responses. This\nimprovement shows our method enhances the accuracy and contextual relevance of\nwriting assistance tools.", "published": "2024-11-01 01:11:58", "link": "http://arxiv.org/abs/2411.00294v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Rationale-Guided Retrieval Augmented Generation for Medical Question\n  Answering", "abstract": "Large language models (LLM) hold significant potential for applications in\nbiomedicine, but they struggle with hallucinations and outdated knowledge.\nWhile retrieval-augmented generation (RAG) is generally employed to address\nthese issues, it also has its own set of challenges: (1) LLMs are vulnerable to\nirrelevant or incorrect context, (2) medical queries are often not\nwell-targeted for helpful information, and (3) retrievers are prone to bias\ntoward the specific source corpus they were trained on. In this study, we\npresent RAG$^2$ (RAtionale-Guided RAG), a new framework for enhancing the\nreliability of RAG in biomedical contexts. RAG$^2$ incorporates three key\ninnovations: a small filtering model trained on perplexity-based labels of\nrationales, which selectively augments informative snippets of documents while\nfiltering out distractors; LLM-generated rationales as queries to improve the\nutility of retrieved snippets; a structure designed to retrieve snippets evenly\nfrom a comprehensive set of four biomedical corpora, effectively mitigating\nretriever bias. Our experiments demonstrate that RAG$^2$ improves the\nstate-of-the-art LLMs of varying sizes, with improvements of up to 6.1\\%, and\nit outperforms the previous best medical RAG model by up to 5.6\\% across three\nmedical question-answering benchmarks. Our code is available at\nhttps://github.com/dmis-lab/RAG2.", "published": "2024-11-01 01:40:23", "link": "http://arxiv.org/abs/2411.00300v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Rank Salient Content for Query-focused Summarization", "abstract": "This study examines the potential of integrating Learning-to-Rank (LTR) with\nQuery-focused Summarization (QFS) to enhance the summary relevance via content\nprioritization. Using a shared secondary decoder with the summarization\ndecoder, we carry out the LTR task at the segment level. Compared to the\nstate-of-the-art, our model outperforms on QMSum benchmark (all metrics) and\nmatches on SQuALITY benchmark (2 metrics) as measured by Rouge and BertScore\nwhile offering a lower training overhead. Specifically, on the QMSum benchmark,\nour proposed system achieves improvements, particularly in Rouge-L (+0.42) and\nBertScore (+0.34), indicating enhanced understanding and relevance. While\nfacing minor challenges in Rouge-1 and Rouge-2 scores on the SQuALITY\nbenchmark, the model significantly excels in Rouge-L (+1.47), underscoring its\ncapability to generate coherent summaries. Human evaluations emphasize the\nefficacy of our method in terms of relevance and faithfulness of the generated\nsummaries, without sacrificing fluency. A deeper analysis reveals our model's\nsuperiority over the state-of-the-art for broad queries, as opposed to specific\nones, from a qualitative standpoint. We further present an error analysis of\nour model, pinpointing challenges faced and suggesting potential directions for\nfuture research in this field.", "published": "2024-11-01 02:44:36", "link": "http://arxiv.org/abs/2411.00324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GRS-QA -- Graph Reasoning-Structured Question Answering Dataset", "abstract": "Large Language Models (LLMs) have excelled in multi-hop question-answering\n(M-QA) due to their advanced reasoning abilities. However, the impact of the\ninherent reasoning structures on LLM M-QA performance remains unclear, largely\ndue to the absence of QA datasets that provide fine-grained reasoning\nstructures. To address this gap, we introduce the Graph Reasoning-Structured\nQuestion Answering Dataset (GRS-QA), which includes both semantic contexts and\nreasoning structures for QA pairs. Unlike existing M-QA datasets, where\ndifferent reasoning structures are entangled together, GRS-QA explicitly\ncaptures intricate reasoning pathways by constructing reasoning graphs, where\nnodes represent textual contexts and edges denote logical flows. These\nreasoning graphs of different structures enable a fine-grained evaluation of\nLLM reasoning capabilities across various reasoning structures. Our empirical\nanalysis reveals that LLMs perform differently when handling questions with\nvarying reasoning structures. This finding facilitates the exploration of\ntextual structures as compared with semantics.", "published": "2024-11-01 05:14:03", "link": "http://arxiv.org/abs/2411.00369v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document\n  Parsing", "abstract": "Advances in large language models (LLMs) have spurred research into enhancing\ntheir reasoning capabilities, particularly in math-rich STEM documents. While\nLLMs can generate equations or solve math-related queries, their ability to\nfully understand and interpret abstract mathematical symbols in long, math-rich\ndocuments remains limited. In this paper, we introduce STEM-PoM, a\ncomprehensive benchmark dataset designed to evaluate LLMs' reasoning abilities\non math symbols within contextual scientific text. The dataset, sourced from\nreal-world ArXiv documents, contains over 2K math symbols classified as main\nattributes of variables, constants, operators, and unit descriptors, with\nadditional sub-attributes including scalar/vector/matrix for variables and\nlocal/global/discipline-specific labels for both constants and operators. Our\nextensive experiments show that state-of-the-art LLMs achieve an average of\n20-60% accuracy under in-context learning and 50-60% accuracy with fine-tuning,\nrevealing a significant gap in their mathematical reasoning capabilities.\nSTEM-PoM fuels future research of developing advanced Math-AI models that can\nrobustly handle math symbols.", "published": "2024-11-01 06:25:06", "link": "http://arxiv.org/abs/2411.00387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GDTB: Genre Diverse Data for English Shallow Discourse Parsing across\n  Modalities, Text Types, and Domains", "abstract": "Work on shallow discourse parsing in English has focused on the Wall Street\nJournal corpus, the only large-scale dataset for the language in the PDTB\nframework. However, the data is not openly available, is restricted to the news\ndomain, and is by now 35 years old. In this paper, we present and evaluate a\nnew open-access, multi-genre benchmark for PDTB-style shallow discourse\nparsing, based on the existing UD English GUM corpus, for which discourse\nrelation annotations in other frameworks already exist. In a series of\nexperiments on cross-domain relation classification, we show that while our\ndataset is compatible with PDTB, substantial out-of-domain degradation is\nobserved, which can be alleviated by joint training on both datasets.", "published": "2024-11-01 10:04:43", "link": "http://arxiv.org/abs/2411.00491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-expert Prompting Improves Reliability, Safety, and Usefulness of\n  Large Language Models", "abstract": "We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu\net al., 2023), designed to improve the large language model (LLM) generation.\nSpecifically, it guides an LLM to fulfill an input instruction by simulating\nmultiple experts, aggregating their responses, and selecting the best among\nindividual and aggregated responses. This process is performed in a single\nchain of thoughts through our seven carefully designed subtasks derived from\nthe Nominal Group Technique (Ven and Delbecq, 1974), a well-established\ndecision-making framework. Our evaluations demonstrate that Multi-expert\nPrompting significantly outperforms ExpertPrompting and comparable baselines in\nenhancing the truthfulness, factuality, informativeness, and usefulness of\nresponses while reducing toxicity and hurtfulness. It further achieves\nstate-of-the-art truthfulness by outperforming the best baseline by 8.69% with\nChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable\nto diverse scenarios, eliminating the need for manual prompt construction.", "published": "2024-11-01 10:06:52", "link": "http://arxiv.org/abs/2411.00492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConvCounsel: A Conversational Dataset for Student Counseling", "abstract": "Student mental health is a sensitive issue that necessitates special\nattention. A primary concern is the student-to-counselor ratio, which surpasses\nthe recommended standard of 250:1 in most universities. This imbalance results\nin extended waiting periods for in-person consultations, which cause suboptimal\ntreatment. Significant efforts have been directed toward developing mental\nhealth dialogue systems utilizing the existing open-source mental\nhealth-related datasets. However, currently available datasets either discuss\ngeneral topics or various strategies that may not be viable for direct\napplication due to numerous ethical constraints inherent in this research\ndomain. To address this issue, this paper introduces a specialized mental\nhealth dataset that emphasizes the active listening strategy employed in\nconversation for counseling, also named as ConvCounsel. This dataset comprises\nboth speech and text data, which can facilitate the development of a reliable\npipeline for mental health dialogue systems. To demonstrate the utility of the\nproposed dataset, this paper also presents the NYCUKA, a spoken mental health\ndialogue system that is designed by using the ConvCounsel dataset. The results\nshow the merit of using this dataset.", "published": "2024-11-01 14:08:02", "link": "http://arxiv.org/abs/2411.00604v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phase Diagram of Vision Large Language Models Inference: A Perspective\n  from Interaction across Image and Instruction", "abstract": "Vision Large Language Models (VLLMs) usually take input as a concatenation of\nimage token embeddings and text token embeddings and conduct causal modeling.\nHowever, their internal behaviors remain underexplored, raising the question of\ninteraction among two types of tokens. To investigate such multimodal\ninteraction during model inference, in this paper, we measure the\ncontextualization among the hidden state vectors of tokens from different\nmodalities. Our experiments uncover a four-phase inference dynamics of VLLMs\nagainst the depth of Transformer-based LMs, including (I) Alignment: In very\nearly layers, contextualization emerges between modalities, suggesting a\nfeature space alignment. (II) Intra-modal Encoding: In early layers,\nintra-modal contextualization is enhanced while inter-modal interaction is\nsuppressed, suggesting a local encoding within modalities. (III) Inter-modal\nEncoding: In later layers, contextualization across modalities is enhanced,\nsuggesting a deeper fusion across modalities. (IV) Output Preparation: In very\nlate layers, contextualization is reduced globally, and hidden states are\naligned towards the unembedding space.", "published": "2024-11-01 15:04:37", "link": "http://arxiv.org/abs/2411.00646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PrefRAG: Preference-Driven Multi-Source Retrieval Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a reliable external\nknowledge augmentation technique to mitigate hallucination issues and\nparameterized knowledge limitations in Large Language Models (LLMs). Existing\nadaptive RAG (ARAG) systems excel at in-depth exploration within a single\nsource but struggle to effectively and controllably explore different retrieval\nsources, as they fail to foresee their internal knowledge features. We develop\na novel multi-source ARAG system, PrefRAG, which enhances RAG by enabling\nin-depth and controllable exploration of diverse retrieval sources through\npreference-driven adaptive retrieval and self-reflection. PrefRAG first fully\nexplores controllable local sources in adaptive retrieval and supplements with\nthe web when appropriate, ultimately selecting the optimal source for knowledge\nobservation. Subsequently, PrefRAG feeds answer quality feedback into the\nretrieval process, optimizing it from the generation perspective to produce\nhigher-quality responses. Extensive experiments confirm its superiority, high\nretrieval efficiency, and knowledge controllability. PrefRAG outperforms\nVanilla RAG and the leading MS-ARAG by up to 25.6% and 13.9% respectively.\nAdditionally, PrefRAG trained with DPO achieves higher performance. The code\nand data are available at https://github.com/QingFei1/PrefRAG.git.", "published": "2024-11-01 15:50:58", "link": "http://arxiv.org/abs/2411.00689v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Code-Mixed Data Augmentation in\n  Sentiment Analysis", "abstract": "Code-mixing (CM), where speakers blend languages within a single expression,\nis prevalent in multilingual societies but poses challenges for natural\nlanguage processing due to its complexity and limited data. We propose using a\nlarge language model to generate synthetic CM data, which is then used to\nenhance the performance of task-specific models for CM sentiment analysis. Our\nresults show that in Spanish-English, synthetic data improved the F1 score by\n9.32%, outperforming previous augmentation techniques. However, in\nMalayalam-English, synthetic data only helped when the baseline was low; with\nstrong natural data, additional synthetic data offered little benefit. Human\nevaluation confirmed that this approach is a simple, cost-effective way to\ngenerate natural-sounding CM sentences, particularly beneficial for low\nbaselines. Our findings suggest that few-shot prompting of large language\nmodels is a promising method for CM data augmentation and has significant\nimpact on improving sentiment analysis, an important element in the development\nof social influence systems.", "published": "2024-11-01 15:52:09", "link": "http://arxiv.org/abs/2411.00691v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generic Embedding-Based Lexicons for Transparent and Reproducible Text\n  Scoring", "abstract": "With text analysis tools becoming increasingly sophisticated over the last\ndecade, researchers now face a decision of whether to use state-of-the-art\nmodels that provide high performance but that can be highly opaque in their\noperations and computationally intensive to run. The alternative, frequently,\nis to rely on older, manually crafted textual scoring tools that are\ntransparently and easily applied, but can suffer from limited performance. I\npresent an alternative that combines the strengths of both: lexicons created\nwith minimal researcher inputs from generic (pretrained) word embeddings.\nPresenting a number of conceptual lexicons produced from FastText and GloVe\n(6B) vector representations of words, I argue that embedding-based lexicons\nrespond to a need for transparent yet high-performance text measuring tools.", "published": "2024-11-01 18:29:58", "link": "http://arxiv.org/abs/2411.00964v1", "categories": ["cs.CL", "68T50", "I.7"], "primary_category": "cs.CL"}
{"title": "FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box\n  Large Language Models", "abstract": "In recent years, large language models (LLMs) have significantly advanced the\nfield of natural language processing (NLP). By fine-tuning LLMs with data from\nspecific scenarios, these foundation models can better adapt to various\ndownstream tasks. However, the fine-tuning process poses privacy leakage risks,\nparticularly in centralized data processing scenarios. To address user privacy\nconcerns, federated learning (FL) has been introduced to mitigate the risks\nassociated with centralized data collection from multiple sources.\nNevertheless, the privacy of LLMs themselves is equally critical, as potential\nmalicious attacks challenge their security, an issue that has received limited\nattention in current research. Consequently, establishing a trusted multi-party\nmodel fine-tuning environment is essential. Additionally, the local deployment\nof large LLMs incurs significant storage costs and high computational demands.\nTo address these challenges, we propose for the first time a federated discrete\nand transferable prompt tuning, namely FedDTPT, for black-box large language\nmodels. In the client optimization phase, we adopt a token-level discrete\nprompt optimization method that leverages a feedback loop based on prediction\naccuracy to drive gradient-free prompt optimization through the MLM API. For\nserver optimization, we employ an attention mechanism based on semantic\nsimilarity to filter all local prompt tokens, along with an embedding distance\nelbow detection and DBSCAN clustering strategy to enhance the filtering\nprocess. Experimental results demonstrate that, compared to state-of-the-art\nmethods, our approach achieves higher accuracy, reduced communication overhead,\nand robustness to non-iid data in a black-box setting. Moreover, the optimized\nprompts are transferable.", "published": "2024-11-01 19:19:23", "link": "http://arxiv.org/abs/2411.00985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Provenance: A Light-weight Fact-checker for Retrieval Augmented LLM\n  Generation Output", "abstract": "We present a light-weight approach for detecting nonfactual outputs from\nretrieval-augmented generation (RAG). Given a context and putative output, we\ncompute a factuality score that can be thresholded to yield a binary decision\nto check the results of LLM-based question-answering, summarization, or other\nsystems. Unlike factuality checkers that themselves rely on LLMs, we use\ncompact, open-source natural language inference (NLI) models that yield a\nfreely accessible solution with low latency and low cost at run-time, and no\nneed for LLM fine-tuning. The approach also enables downstream mitigation and\ncorrection of hallucinations, by tracing them back to specific context chunks.\nOur experiments show high area under the ROC curve (AUC) across a wide range of\nrelevant open source datasets, indicating the effectiveness of our method for\nfact-checking RAG output.", "published": "2024-11-01 20:44:59", "link": "http://arxiv.org/abs/2411.01022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plentiful Jailbreaks with String Compositions", "abstract": "Large language models (LLMs) remain vulnerable to a slew of adversarial\nattacks and jailbreaking methods. One common approach employed by white-hat\nattackers, or red-teamers, is to process model inputs and outputs using\nstring-level obfuscations, which can include leetspeak, rotary ciphers, Base64,\nASCII, and more. Our work extends these encoding-based attacks by unifying them\nin a framework of invertible string transformations. With invertibility, we can\ndevise arbitrary string compositions, defined as sequences of transformations,\nthat we can encode and decode end-to-end programmatically. We devise a\nautomated best-of-n attack that samples from a combinatorially large number of\nstring compositions. Our jailbreaks obtain competitive attack success rates on\nseveral leading frontier models when evaluated on HarmBench, highlighting that\nencoding-based attacks remain a persistent vulnerability even in advanced LLMs.", "published": "2024-11-01 23:53:00", "link": "http://arxiv.org/abs/2411.01084v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Authorship Attribution through Embedding Fusion: A Novel\n  Approach with Masked and Encoder-Decoder Language Models", "abstract": "The increasing prevalence of AI-generated content alongside human-written\ntext underscores the need for reliable discrimination methods. To address this\nchallenge, we propose a novel framework with textual embeddings from\nPre-trained Language Models (PLMs) to distinguish AI-generated and\nhuman-authored text. Our approach utilizes Embedding Fusion to integrate\nsemantic information from multiple Language Models, harnessing their\ncomplementary strengths to enhance performance. Through extensive evaluation\nacross publicly available diverse datasets, our proposed approach demonstrates\nstrong performance, achieving classification accuracy greater than 96% and a\nMatthews Correlation Coefficient (MCC) greater than 0.93. This evaluation is\nconducted on a balanced dataset of texts generated from five well-known Large\nLanguage Models (LLMs), highlighting the effectiveness and robustness of our\nnovel methodology.", "published": "2024-11-01 07:18:27", "link": "http://arxiv.org/abs/2411.00411v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Evolved Reward Learning for LLMs", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for\naligning language models with human preferences, playing a pivotal role in the\nsuccess of conversational models like GPT-4, ChatGPT, and Llama 2. A core\nchallenge in employing RLHF lies in training a reliable reward model (RM),\nwhich relies on high-quality labels typically provided by human experts or\nadvanced AI system. These methods can be costly and may introduce biases that\naffect the language model's responses. As language models improve, human input\nmay become less effective in further enhancing their performance. In this\npaper, we propose Self-Evolved Reward Learning (SER), a novel approach where\nthe RM generates additional training data to iteratively improve itself. We\nconducted extensive experiments on multiple datasets such as HH-RLHF and\nUltraFeedback, using models like Mistral and Llama 3, and compare SER against\nvarious baselines. Our results demonstrate that even with limited\nhuman-annotated data, learning from self-feedback can robustly enhance RM\nperformance, thereby boosting the capabilities of large language models (LLMs).", "published": "2024-11-01 07:29:03", "link": "http://arxiv.org/abs/2411.00418v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems", "abstract": "Task-oriented dialogue systems are essential for applications ranging from\ncustomer service to personal assistants and are widely used across various\nindustries. However, developing effective multi-domain systems remains a\nsignificant challenge due to the complexity of handling diverse user intents,\nentity types, and domain-specific knowledge across several domains. In this\nwork, we propose DARD (Domain Assigned Response Delegation), a multi-agent\nconversational system capable of successfully handling multi-domain dialogs.\nDARD leverages domain-specific agents, orchestrated by a central dialog manager\nagent. Our extensive experiments compare and utilize various agent modeling\napproaches, combining the strengths of smaller fine-tuned models (Flan-T5-large\n& Mistral-7B) with their larger counterparts, Large Language Models (LLMs)\n(Claude Sonnet 3.0). We provide insights into the strengths and limitations of\neach approach, highlighting the benefits of our multi-agent framework in terms\nof flexibility and composability. We evaluate DARD using the well-established\nMultiWOZ benchmark, achieving state-of-the-art performance by improving the\ndialogue inform rate by 6.6% and the success rate by 4.1% over the\nbest-performing existing approaches. Additionally, we discuss various annotator\ndiscrepancies and issues within the MultiWOZ dataset and its evaluation system.", "published": "2024-11-01 07:50:19", "link": "http://arxiv.org/abs/2411.00427v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "E2E-AFG: An End-to-End Model with Adaptive Filtering for\n  Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation methods often neglect the quality of content\nretrieved from external knowledge bases, resulting in irrelevant information or\npotential misinformation that negatively affects the generation results of\nlarge language models. In this paper, we propose an end-to-end model with\nadaptive filtering for retrieval-augmented generation (E2E-AFG), which\nintegrates answer existence judgment and text generation into a single\nend-to-end framework. This enables the model to focus more effectively on\nrelevant content while reducing the influence of irrelevant information and\ngenerating accurate answers. We evaluate E2E-AFG on six representative\nknowledge-intensive language datasets, and the results show that it\nconsistently outperforms baseline models across all tasks, demonstrating the\neffectiveness and robustness of the proposed approach.", "published": "2024-11-01 08:02:09", "link": "http://arxiv.org/abs/2411.00437v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot\n  Named Entity Recognition with Large Language Models", "abstract": "This paper presents ReverseNER, a method aimed at overcoming the limitation\nof large language models (LLMs) in zero-shot named entity recognition (NER)\ntasks, arising from their reliance on pre-provided demonstrations. ReverseNER\ntackles this challenge by constructing a reliable example library composed of\ndozens of entity-labeled sentences, generated through the reverse process of\nNER. Specifically, while conventional NER methods label entities in a sentence,\nReverseNER features reversing the process by using an LLM to generate entities\nfrom their definitions and subsequently expand them into full sentences. During\nthe entity expansion process, the LLM is guided to generate sentences by\nreplicating the structures of a set of specific \\textsl{feature sentences},\nextracted from the task sentences by clustering. This expansion process\nproduces dozens of entity-labeled task-relevant sentences. After constructing\nthe example library, the method selects several semantically similar\nentity-labeled examples for each task sentence as references to facilitate the\nLLM's entity recognition. We also propose an entity-level self-consistency\nscoring mechanism to improve NER performance with LLMs. Experiments show that\nReverseNER significantly outperforms other zero-shot NER methods with LLMs,\nmarking a notable improvement in NER for domains without labeled data, while\ndeclining computational resource consumption.", "published": "2024-11-01 12:08:08", "link": "http://arxiv.org/abs/2411.00533v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations", "abstract": "Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.", "published": "2024-11-01 14:57:16", "link": "http://arxiv.org/abs/2411.00640v1", "categories": ["stat.AP", "cs.CL"], "primary_category": "stat.AP"}
{"title": "Optimizing Contextual Speech Recognition Using Vector Quantization for\n  Efficient Retrieval", "abstract": "Neural contextual biasing allows speech recognition models to leverage\ncontextually relevant information, leading to improved transcription accuracy.\nHowever, the biasing mechanism is typically based on a cross-attention module\nbetween the audio and a catalogue of biasing entries, which means computational\ncomplexity can pose severe practical limitations on the size of the biasing\ncatalogue and consequently on accuracy improvements. This work proposes an\napproximation to cross-attention scoring based on vector quantization and\nenables compute- and memory-efficient use of large biasing catalogues. We\npropose to use this technique jointly with a retrieval based contextual biasing\napproach. First, we use an efficient quantized retrieval module to shortlist\nbiasing entries by grounding them on audio. Then we use retrieved entries for\nbiasing. Since the proposed approach is agnostic to the biasing method, we\ninvestigate using full cross-attention, LLM prompting, and a combination of the\ntwo. We show that retrieval based shortlisting allows the system to efficiently\nleverage biasing catalogues of several thousands of entries, resulting in up to\n71% relative error rate reduction in personal entity recognition. At the same\ntime, the proposed approximation algorithm reduces compute time by 20% and\nmemory usage by 85-95%, for lists of up to one million entries, when compared\nto standard dot-product cross-attention.", "published": "2024-11-01 15:28:03", "link": "http://arxiv.org/abs/2411.00664v2", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection\n  in Language Models", "abstract": "As Large Language Models (LLMs) are increasingly deployed in specialized\ndomains with continuously evolving knowledge, the need for timely and precise\nknowledge injection has become essential. Fine-tuning with paraphrased data is\na common approach to enhance knowledge injection, yet it faces two significant\nchallenges: high computational costs due to repetitive external model usage and\nlimited sample diversity. To this end, we introduce LaPael, a latent-level\nparaphrasing method that applies input-dependent noise to early LLM layers.\nThis approach enables diverse and semantically consistent augmentations\ndirectly within the model. Furthermore, it eliminates the recurring costs of\nparaphrase generation for each knowledge update. Our extensive experiments on\nquestion-answering benchmarks demonstrate that LaPael improves knowledge\ninjection over standard fine-tuning and existing noise-based approaches.\nAdditionally, combining LaPael with data-level paraphrasing further enhances\nperformance.", "published": "2024-11-01 15:47:05", "link": "http://arxiv.org/abs/2411.00686v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPRING Lab IITM's submission to Low Resource Indic Language Translation\n  Shared Task", "abstract": "We develop a robust translation model for four low-resource Indic languages:\nKhasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive\npipeline from data collection and preprocessing to training and evaluation,\nleveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To\naddress the scarcity of bilingual data, we use back-translation techniques on\nmonolingual datasets for Mizo and Khasi, significantly expanding our training\ncorpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and\nManipuri, achieving improved performance over the baseline. For Khasi, which is\nnot supported by the NLLB model, we introduce special tokens and train the\nmodel on our Khasi corpus. Our training involves masked language modelling,\nfollowed by fine-tuning for English-to-Indic and Indic-to-English translations.", "published": "2024-11-01 16:39:03", "link": "http://arxiv.org/abs/2411.00727v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing the Traditional Chinese Medicine Capabilities of Large\n  Language Model through Reinforcement Learning from AI Feedback", "abstract": "Although large language models perform well in understanding and responding\nto user intent, their performance in specialized domains such as Traditional\nChinese Medicine (TCM) remains limited due to lack of expertise. In addition,\nhigh-quality data related to TCM is scarce and difficult to obtain, making\nlarge language models ineffective in handling TCM tasks. In this work, we\npropose a framework to improve the performance of large language models for TCM\ntasks using only a small amount of data. First, we use medical case data for\nsupervised fine-tuning of the large model, making it initially capable of\nperforming TCM tasks. Subsequently, we further optimize the model's performance\nusing reinforcement learning from AI feedback (RLAIF) to align it with the\npreference data. The ablation study also demonstrated the performance gain is\nattributed to both supervised fine-tuning and the direct policy optimization.\nThe experimental results show that the model trained with a small amount of\ndata achieves a significant performance improvement on a representative TCM\ntask.", "published": "2024-11-01 04:19:55", "link": "http://arxiv.org/abs/2411.00897v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fighting Spurious Correlations in Text Classification via a Causal\n  Learning Perspective", "abstract": "In text classification tasks, models often rely on spurious correlations for\npredictions, incorrectly associating irrelevant features with the target\nlabels. This issue limits the robustness and generalization of models,\nespecially when faced with out-of-distribution data where such spurious\ncorrelations no longer hold. To address this challenge, we propose the Causally\nCalibrated Robust Classifier (CCR), which aims to reduce models' reliance on\nspurious correlations and improve model robustness. Our approach integrates a\ncausal feature selection method based on counterfactual reasoning, along with\nan unbiased inverse propensity weighting (IPW) loss function. By focusing on\nselecting causal features, we ensure that the model relies less on spurious\nfeatures during prediction. We theoretically justify our approach and\nempirically show that CCR achieves state-of-the-art performance among methods\nwithout group labels, and in some cases, it can compete with the models that\nutilize group labels.", "published": "2024-11-01 21:29:07", "link": "http://arxiv.org/abs/2411.01045v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection", "abstract": "Jailbreaking techniques trick Large Language Models (LLMs) into producing\nrestricted outputs, posing a serious threat. One line of defense is to use\nanother LLM as a Judge to evaluate the harmfulness of generated text. However,\nwe reveal that these Judge LLMs are vulnerable to token segmentation bias, an\nissue that arises when delimiters alter the tokenization process, splitting\nwords into smaller sub-tokens. This disrupts the embeddings of the entire\nsequence, reducing detection accuracy and allowing harmful content to be\nmisclassified as safe. In this paper, we introduce Emoji Attack, a novel\nstrategy that amplifies existing jailbreak prompts by exploiting token\nsegmentation bias. Our method leverages in-context learning to systematically\ninsert emojis into text before it is evaluated by a Judge LLM, inducing\nembedding distortions that significantly lower the likelihood of detecting\nunsafe content. Unlike traditional delimiters, emojis also introduce semantic\nambiguity, making them particularly effective in this attack. Through\nexperiments on state-of-the-art Judge LLMs, we demonstrate that Emoji Attack\nsubstantially reduces the \"unsafe\" prediction rate, bypassing existing\nsafeguards.", "published": "2024-11-01 23:18:32", "link": "http://arxiv.org/abs/2411.01077v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented\n  Large Language Models", "abstract": "Narrative data spans all disciplines and provides a coherent model of the\nworld to the reader or viewer. Recent advancement in machine learning and Large\nLanguage Models (LLMs) have enable great strides in analyzing natural language.\nHowever, Large language models (LLMs) still struggle with complex narrative\narcs as well as narratives containing conflicting information. Recent work\nindicates LLMs augmented with external knowledge bases can improve the accuracy\nand interpretability of the resulting models. In this work, we analyze the\neffectiveness of applying knowledge graphs (KGs) in understanding true-crime\npodcast data from both classical Natural Language Processing (NLP) and LLM\napproaches. We directly compare KG-augmented LLMs (KGLLMs) with classical\nmethods for KG construction, topic modeling, and sentiment analysis.\nAdditionally, the KGLLM allows us to query the knowledge base in natural\nlanguage and test its ability to factually answer questions. We examine the\nrobustness of the model to adversarial prompting in order to test the model's\nability to deal with conflicting information. Finally, we apply classical\nmethods to understand more subtle aspects of the text such as the use of\nhearsay and sentiment in narrative construction and propose future directions.\nOur results indicate that KGLLMs outperform LLMs on a variety of metrics, are\nmore robust to adversarial prompts, and are more capable of summarizing the\ntext into topics.", "published": "2024-11-01 21:49:00", "link": "http://arxiv.org/abs/2411.02435v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating the Impact of Lab Test Results on Large Language Models\n  Generated Differential Diagnoses from Clinical Case Vignettes", "abstract": "Differential diagnosis is crucial for medicine as it helps healthcare\nproviders systematically distinguish between conditions that share similar\nsymptoms. This study assesses the impact of lab test results on differential\ndiagnoses (DDx) made by large language models (LLMs). Clinical vignettes from\n50 case reports from PubMed Central were created incorporating patient\ndemographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,\nClaude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx\nwith and without lab data. A comprehensive evaluation involving GPT-4, a\nknowledge graph, and clinicians was conducted. GPT-4 performed best, achieving\n55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient\naccuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and\nMixtral excelling, though exact match rates were low. Lab tests, including\nliver function, metabolic/toxicology panels, and serology/immune tests, were\ngenerally interpreted correctly by LLMs for differential diagnosis.", "published": "2024-11-01 02:48:32", "link": "http://arxiv.org/abs/2411.02523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaMetrics-MT: Tuning Meta-Metrics for Machine Translation via Human\n  Preference Calibration", "abstract": "We present MetaMetrics-MT, an innovative metric designed to evaluate machine\ntranslation (MT) tasks by aligning closely with human preferences through\nBayesian optimization with Gaussian Processes. MetaMetrics-MT enhances existing\nMT metrics by optimizing their correlation with human judgments. Our\nexperiments on the WMT24 metric shared task dataset demonstrate that\nMetaMetrics-MT outperforms all existing baselines, setting a new benchmark for\nstate-of-the-art performance in the reference-based setting. Furthermore, it\nachieves comparable results to leading metrics in the reference-free setting,\noffering greater efficiency.", "published": "2024-11-01 06:34:30", "link": "http://arxiv.org/abs/2411.00390v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adapting While Learning: Grounding LLMs for Scientific Problems with\n  Intelligent Tool Usage Adaptation", "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving\nsimple scientific problems but, even with domain-specific fine-tuning, often\nproduce hallucinations for complex ones. While integrating LLMs with tools can\nmitigate this reliability issue, models finetuned on tool usage only often\nover-rely on them, incurring unnecessary costs from resource-intensive\nscientific tools even for simpler problems. Inspired by how human experts\nassess the complexity of the problem before choosing the solutions, we propose\na novel two-component fine-tuning method, Adapting While Learning (AWL). In the\nfirst component, World Knowledge Learning (WKL), LLMs internalize scientific\nknowledge by learning from tools-generated solutions. In the second component,\nTool Usage Adaptation (TUA), we classify questions as easy or hard based on the\nWKL-trained model's accuracy, and train it to maintain direct reasoning for\nsimple problems while switching to tools for challenging ones. We validate our\nmethod on 6 scientific benchmark datasets in climate science, epidemiology, and\nmathematics. Compared to the base 8B model, our trained models achieve 28.27%\nhigher answer accuracy and 13.76% better tool usage accuracy, even surpassing\nstate-of-the-art models including GPT-4 and Claude-3.5 on 4 custom-created\ndatasets.", "published": "2024-11-01 07:18:31", "link": "http://arxiv.org/abs/2411.00412v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "Adapting Language Models via Token Translation", "abstract": "Modern large language models use a fixed tokenizer to effectively compress\ntext drawn from a source domain. However, applying the same tokenizer to a new\ntarget domain often leads to inferior compression, more costly inference, and\nreduced semantic alignment. To address this deficiency, we introduce Sparse\nSinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the\ntarget domain and learns to translate between target and source tokens,\nenabling more effective reuse of the pre-trained next-source-token predictor.\nIn our experiments with finetuned English language models, S2T2 improves both\nthe perplexity and the compression of out-of-domain protein sequences,\noutperforming direct finetuning with either the source or target tokenizer. In\naddition, we find that token translations learned for smaller, less expensive\nmodels can be directly transferred to larger, more powerful models to reap the\nbenefits of S2T2 at lower cost.", "published": "2024-11-01 13:53:14", "link": "http://arxiv.org/abs/2411.00593v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zipfian Whitening", "abstract": "The word embedding space in neural models is skewed, and correcting this can\nimprove task performance. We point out that most approaches for modeling,\ncorrecting, and measuring the symmetry of an embedding space implicitly assume\nthat the word frequencies are uniform; in reality, word frequencies follow a\nhighly non-uniform distribution, known as Zipf's law. Surprisingly, simply\nperforming PCA whitening weighted by the empirical word frequency that follows\nZipf's law significantly improves task performance, surpassing established\nbaselines. From a theoretical perspective, both our approach and existing\nmethods can be clearly categorized: word representations are distributed\naccording to an exponential family with either uniform or Zipfian base\nmeasures. By adopting the latter approach, we can naturally emphasize\ninformative low-frequency words in terms of their vector norm, which becomes\nevident from the information-geometric perspective, and in terms of the loss\nfunctions for imbalanced classification. Additionally, our theory corroborates\nthat popular natural language processing methods, such as skip-gram negative\nsampling, WhiteningBERT, and headless language models, work well just because\ntheir word embeddings encode the empirical word frequency into the underlying\nprobabilistic model.", "published": "2024-11-01 15:40:19", "link": "http://arxiv.org/abs/2411.00680v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TaxaBind: A Unified Embedding Space for Ecological Applications", "abstract": "We present TaxaBind, a unified embedding space for characterizing any species\nof interest. TaxaBind is a multimodal embedding space across six modalities:\nground-level images of species, geographic location, satellite image, text,\naudio, and environmental features, useful for solving ecological problems. To\nlearn this joint embedding space, we leverage ground-level images of species as\na binding modality. We propose multimodal patching, a technique for effectively\ndistilling the knowledge from various modalities into the binding modality. We\nconstruct two large datasets for pretraining: iSatNat with species images and\nsatellite images, and iSoundNat with species images and audio. Additionally, we\nintroduce TaxaBench-8k, a diverse multimodal dataset with six paired modalities\nfor evaluating deep learning models on ecological tasks. Experiments with\nTaxaBind demonstrate its strong zero-shot and emergent capabilities on a range\nof tasks including species classification, cross-model retrieval, and audio\nclassification. The datasets and models are made available at\nhttps://github.com/mvrl/TaxaBind.", "published": "2024-11-01 15:41:30", "link": "http://arxiv.org/abs/2411.00683v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A graph-based approach to extracting narrative signals from public\n  discourse", "abstract": "Narratives are key interpretative devices by which humans make sense of\npolitical reality. As the significance of narratives for understanding current\nsocietal issues such as polarization and misinformation becomes increasingly\nevident, there is a growing demand for methods that support their empirical\nanalysis. To this end, we propose a graph-based formalism and machine-guided\nmethod for extracting, representing, and analyzing selected narrative signals\nfrom digital textual corpora, based on Abstract Meaning Representation (AMR).\nThe formalism and method introduced here specifically cater to the study of\npolitical narratives that figure in texts from digital media such as archived\npolitical speeches, social media posts, political manifestos and transcripts of\nparliamentary debates. We conceptualize these political narratives as a type of\nontological narratives: stories by which actors position themselves as\npolitical beings, and which are akin to political worldviews in which actors\npresent their normative vision of the world, or aspects thereof. We approach\nthe study of such political narratives as a problem of information retrieval:\nstarting from a textual corpus, we first extract a graph-like representation of\nthe meaning of each sentence in the corpus using AMR. Drawing on transferable\nconcepts from narratology, we then apply a set of heuristics to filter these\ngraphs for representations of 1) actors, 2) the events in which these actors\nfigure, and 3) traces of the perspectivization of these events. We approach\nthese references to actors, events, and instances of perspectivization as core\nnarrative signals that initiate a further analysis by alluding to larger\npolitical narratives. By means of a case study of State of the European Union\naddresses, we demonstrate how the formalism can be used to inductively surface\nsignals of political narratives from public discourse.", "published": "2024-11-01 16:05:59", "link": "http://arxiv.org/abs/2411.00702v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced\n  Molecular Property Prediction", "abstract": "Bridging biomolecular modeling with natural language information,\nparticularly through large language models (LLMs), has recently emerged as a\npromising interdisciplinary research area. LLMs, having been trained on large\ncorpora of scientific documents, demonstrate significant potential in\nunderstanding and reasoning about biomolecules by providing enriched contextual\nand domain knowledge. However, the extent to which LLM-driven insights can\nimprove performance on complex predictive tasks (e.g., toxicity) remains\nunclear. Further, the extent to which relevant knowledge can be extracted from\nLLMs also remains unknown. In this study, we present Molecule Caption Arena:\nthe first comprehensive benchmark of LLM-augmented molecular property\nprediction. We evaluate over twenty LLMs, including both general-purpose and\ndomain-specific molecule captioners, across diverse prediction tasks. To this\ngoal, we introduce a novel, battle-based rating system. Our findings confirm\nthe ability of LLM-extracted knowledge to enhance state-of-the-art molecular\nrepresentations, with notable model-, prompt-, and dataset-specific variations.\nCode, resources, and data are available at github.com/Genentech/molcap-arena.", "published": "2024-11-01 17:03:16", "link": "http://arxiv.org/abs/2411.00737v1", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "Decoding Dark Matter: Specialized Sparse Autoencoders for Interpreting\n  Rare Concepts in Foundation Models", "abstract": "Understanding and mitigating the potential risks associated with foundation\nmodels (FMs) hinges on developing effective interpretability methods. Sparse\nAutoencoders (SAEs) have emerged as a promising tool for disentangling FM\nrepresentations, but they struggle to capture rare, yet crucial concepts in the\ndata. We introduce Specialized Sparse Autoencoders (SSAEs), designed to\nilluminate these elusive dark matter features by focusing on specific\nsubdomains. We present a practical recipe for training SSAEs, demonstrating the\nefficacy of dense retrieval for data selection and the benefits of Tilted\nEmpirical Risk Minimization as a training objective to improve concept recall.\nOur evaluation of SSAEs on standard metrics, such as downstream perplexity and\n$L_0$ sparsity, show that they effectively capture subdomain tail concepts,\nexceeding the capabilities of general-purpose SAEs. We showcase the practical\nutility of SSAEs in a case study on the Bias in Bios dataset, where SSAEs\nachieve a 12.5\\% increase in worst-group classification accuracy when applied\nto remove spurious gender information. SSAEs provide a powerful new lens for\npeering into the inner workings of FMs in subdomains.", "published": "2024-11-01 17:09:34", "link": "http://arxiv.org/abs/2411.00743v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CORAG: A Cost-Constrained Retrieval Optimization System for\n  Retrieval-Augmented Generation", "abstract": "Large Language Models (LLMs) have demonstrated remarkable generation\ncapabilities but often struggle to access up-to-date information, which can\nlead to hallucinations. Retrieval-Augmented Generation (RAG) addresses this\nissue by incorporating knowledge from external databases, enabling more\naccurate and relevant responses. Due to the context window constraints of LLMs,\nit is impractical to input the entire external database context directly into\nthe model. Instead, only the most relevant information, referred to as chunks,\nis selectively retrieved. However, current RAG research faces three key\nchallenges. First, existing solutions often select each chunk independently,\noverlooking potential correlations among them. Second, in practice the utility\nof chunks is non-monotonic, meaning that adding more chunks can decrease\noverall utility. Traditional methods emphasize maximizing the number of\nincluded chunks, which can inadvertently compromise performance. Third, each\ntype of user query possesses unique characteristics that require tailored\nhandling, an aspect that current approaches do not fully consider. To overcome\nthese challenges, we propose a cost constrained retrieval optimization system\nCORAG for retrieval-augmented generation. We employ a Monte Carlo Tree Search\n(MCTS) based policy framework to find optimal chunk combinations sequentially,\nallowing for a comprehensive consideration of correlations among chunks.\nAdditionally, rather than viewing budget exhaustion as a termination condition,\nwe integrate budget constraints into the optimization of chunk combinations,\neffectively addressing the non-monotonicity of chunk utility.", "published": "2024-11-01 17:11:16", "link": "http://arxiv.org/abs/2411.00744v1", "categories": ["cs.DB", "cs.CL", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided\n  Sampling", "abstract": "Self-improvement methods enable large language models (LLMs) to generate\nsolutions themselves and iteratively train on filtered, high-quality\nrationales. This process proves effective and reduces the reliance on human\nsupervision in LLMs' reasoning, but the performance soon plateaus. We delve\ninto the process and find that models tend to over-sample on easy queries and\nunder-sample on queries they have yet to master. As iterations proceed, this\nimbalance in sampling is exacerbated, leading to a long-tail distribution where\nsolutions to difficult queries almost diminish. This phenomenon limits the\nperformance gain of self-improving models. A straightforward solution is\nbrute-force sampling to balance the distribution, which significantly raises\ncomputational costs. In this paper, we introduce Guided Self-Improvement (GSI),\na strategy aimed at improving the efficiency of sampling challenging\nheavy-tailed data. It leverages Socratic-style guidance signals to help LLM\nreasoning with complex queries, reducing the exploration effort and minimizing\ncomputational overhead. Experiments on four models across diverse mathematical\ntasks show that GSI strikes a balance between performance and efficiency, while\nalso being effective on held-out tasks.", "published": "2024-11-01 17:18:45", "link": "http://arxiv.org/abs/2411.00750v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model\n  with Frozen LLM", "abstract": "Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. Especially, the GPT-4o's excellent duplex speech\ninteraction ability has brought impressive experience to users. Researchers\nhave recently proposed several multi-modal LLMs in this direction that can\nachieve user-agent speech-to-speech conversations. This paper proposes a novel\nspeech-text multimodal LLM architecture called Freeze-Omni. Our main\ncontribution is that the speech input and output modalities can be easily\nconnected to a textual LLM while keeping the LLM's parameters frozen throughout\nthe training process. We design a three-stage training strategy for modeling\nboth the speech input and output, enabling Freeze-Omni to obtain\nspeech-to-speech conversation ability using text-speech paired data (such as\nASR and TTS data) and only 60,000 multi-round text Q&A data on 8 GPUs.\nMoreover, we can effectively ensure that the intelligence of the Freeze-Omni in\nthe speech modality is at the same level compared with that in the text\nmodality of its backbone LLM, while achieving low latency end-to-end spoken\nresponse. In addition, we also designed a method to achieve duplex dialogue\nability through multi-task training, giving Freeze-Omni a more natural style of\ndialogue ability between users and agents. In summary, Freeze-Omni holds great\npotential to conduct speech-to-speech dialogue based on a multimodal LLM under\nthe condition of a frozen LLM, avoiding the catastrophic forgetting problem\ncaused by limited data and training resources.", "published": "2024-11-01 17:59:51", "link": "http://arxiv.org/abs/2411.00774v5", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in\n  Large Language Models", "abstract": "Mixture of Experts (MoEs) plays an important role in the development of more\nefficient and effective large language models (LLMs). Due to the enormous\nresource requirements, studying large scale MoE algorithms remain in-accessible\nto many researchers. This work develops \\emph{LibMoE}, a comprehensive and\nmodular framework to streamline the research, training, and evaluation of MoE\nalgorithms. Built upon three core principles: (i) modular design, (ii)\nefficient training; (iii) comprehensive evaluation, LibMoE brings MoE in LLMs\nmore accessible to a wide range of researchers by standardizing the training\nand evaluation pipelines. Using LibMoE, we extensively benchmarked five\nstate-of-the-art MoE algorithms over three different LLMs and 11 datasets under\nthe zero-shot setting. The results show that despite the unique\ncharacteristics, all MoE algorithms perform roughly similar when averaged\nacross a wide range of tasks. With the modular design and extensive evaluation,\nwe believe LibMoE will be invaluable for researchers to make meaningful\nprogress towards the next generation of MoE and LLMs. Project page:\n\\url{https://fsoft-aic.github.io/fsoft-LibMoE.github.io}.", "published": "2024-11-01 14:04:36", "link": "http://arxiv.org/abs/2411.00918v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building\n  Large Language Model-Based Conversational AI Agents", "abstract": "Large language model (LLM)-based agents have been increasingly used to\ninteract with external environments (e.g., games, APIs, etc.) and solve tasks.\nHowever, current frameworks do not enable these agents to work with users and\ninteract with them to align on the details of their tasks and reach\nuser-defined goals; instead, in ambiguous situations, these agents may make\ndecisions based on assumptions. This work introduces ReSpAct (Reason, Speak,\nand Act), a novel framework that synergistically combines the essential skills\nfor building task-oriented \"conversational\" agents. ReSpAct addresses this need\nfor agents, expanding on the ReAct approach. The ReSpAct framework enables\nagents to interpret user instructions, reason about complex tasks, execute\nappropriate actions, and engage in dynamic dialogue to seek guidance, clarify\nambiguities, understand user preferences, resolve problems, and use the\nintermediate feedback and responses of users to update their plans. We\nevaluated ReSpAct in environments supporting user interaction, such as\ntask-oriented dialogue (MultiWOZ) and interactive decision-making (AlfWorld,\nWebShop). ReSpAct is flexible enough to incorporate dynamic user feedback and\naddresses prevalent issues like error propagation and agents getting stuck in\nreasoning loops. This results in more interpretable, human-like task-solving\ntrajectories than relying solely on reasoning traces. In two interactive\ndecision-making benchmarks, AlfWorld and WebShop, ReSpAct outperform the strong\nreasoning-only method ReAct by an absolute success rate of 6% and 4%,\nrespectively. In the task-oriented dialogue benchmark MultiWOZ, ReSpAct\nimproved Inform and Success scores by 5.5% and 3%, respectively.", "published": "2024-11-01 15:57:45", "link": "http://arxiv.org/abs/2411.00927v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Text2Freq: Learning Series Patterns from Text via Frequency Domain", "abstract": "Traditional time series forecasting models mainly rely on historical numeric\nvalues to predict future outcomes.While these models have shown promising\nresults, they often overlook the rich information available in other\nmodalities, such as textual descriptions of special events, which can provide\ncrucial insights into future dynamics.However, research that jointly\nincorporates text in time series forecasting remains relatively underexplored\ncompared to other cross-modality work. Additionally, the modality gap between\ntime series data and textual information poses a challenge for multimodal\nlearning. To address this task, we propose Text2Freq, a cross-modality model\nthat integrates text and time series data via the frequency domain.\nSpecifically, our approach aligns textual information to the low-frequency\ncomponents of time series data, establishing more effective and interpretable\nalignments between these two modalities. Our experiments on paired datasets of\nreal-world stock prices and synthetic texts show that Text2Freq achieves\nstate-of-the-art performance, with its adaptable architecture encouraging\nfuture research in this field.", "published": "2024-11-01 16:11:02", "link": "http://arxiv.org/abs/2411.00929v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An\n  Evaluation Using TORGO", "abstract": "Individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS)\nfrequently face challenges with articulation, leading to dysarthria and\nresulting in atypical speech patterns. In healthcare settings, communication\nbreakdowns reduce the quality of care. While building an augmentative and\nalternative communication (AAC) tool to enable fluid communication we found\nthat state-of-the-art (SOTA) automatic speech recognition (ASR) technology like\nWhisper and Wav2vec2.0 marginalizes atypical speakers largely due to the lack\nof training data. Our work looks to leverage SOTA ASR followed by domain\nspecific error-correction. English dysarthric ASR performance is often\nevaluated on the TORGO dataset. Prompt-overlap is a well-known issue with this\ndataset where phrases overlap between training and test speakers. Our work\nproposes an algorithm to break this prompt-overlap. After reducing\nprompt-overlap, results with SOTA ASR models produce extremely high word error\nrates for speakers with mild and severe dysarthria. Furthermore, to improve\nASR, our work looks at the impact of n-gram language models and large-language\nmodel (LLM) based multi-modal generative error-correction algorithms like\nWhispering-LLaMA for a second pass ASR. Our work highlights how much more needs\nto be done to improve ASR for atypical speakers to enable equitable healthcare\naccess both in-person and in e-health settings.", "published": "2024-11-01 19:11:54", "link": "http://arxiv.org/abs/2411.00980v2", "categories": ["cs.CL", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Identifying Implicit Social Biases in Vision-Language Models", "abstract": "Vision-language models, like CLIP (Contrastive Language Image Pretraining),\nare becoming increasingly popular for a wide range of multimodal retrieval\ntasks. However, prior work has shown that large language and deep vision models\ncan learn historical biases contained in their training sets, leading to\nperpetuation of stereotypes and potential downstream harm. In this work, we\nconduct a systematic analysis of the social biases that are present in CLIP,\nwith a focus on the interaction between image and text modalities. We first\npropose a taxonomy of social biases called So-B-IT, which contains 374 words\ncategorized across ten types of bias. Each type can lead to societal harm if\nassociated with a particular demographic group. Using this taxonomy, we examine\nimages retrieved by CLIP from a facial image dataset using each word as part of\na prompt. We find that CLIP frequently displays undesirable associations\nbetween harmful words and specific demographic groups, such as retrieving\nmostly pictures of Middle Eastern men when asked to retrieve images of a\n\"terrorist\". Finally, we conduct an analysis of the source of such biases, by\nshowing that the same harmful stereotypes are also present in a large\nimage-text dataset used to train CLIP models for examples of biases that we\nfind. Our findings highlight the importance of evaluating and addressing bias\nin vision-language models, and suggest the need for transparency and\nfairness-aware curation of large pre-training datasets.", "published": "2024-11-01 19:41:28", "link": "http://arxiv.org/abs/2411.00997v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CV"}
{"title": "Birdie: Advancing State Space Models with Reward-Driven Objectives and\n  Curricula", "abstract": "Efficient state space models (SSMs), such as linear recurrent neural networks\nand linear attention variants, offer computational advantages over Transformers\nbut struggle with tasks requiring long-range in-context retrieval-like text\ncopying, associative recall, and question answering over long contexts.\nPrevious efforts to address these challenges have focused on architectural\nmodifications, often reintroducing computational inefficiencies. In this paper,\nwe propose a novel training procedure, Birdie, that significantly enhances the\nin-context retrieval capabilities of SSMs without altering their architecture.\nOur approach combines bidirectional input processing with dynamic mixtures of\nspecialized pre-training objectives, optimized via reinforcement learning. We\nintroduce a new bidirectional SSM architecture that seamlessly transitions from\nbidirectional context processing to causal generation. Experimental evaluations\ndemonstrate that Birdie markedly improves performance on retrieval-intensive\ntasks such as multi-number phone book lookup, long paragraph\nquestion-answering, and infilling. This narrows the performance gap with\nTransformers, while retaining computational efficiency. Our findings highlight\nthe importance of training procedures in leveraging the fixed-state capacity of\nSSMs, offering a new direction to advance their capabilities. All code and\npre-trained models are available at https://www.github.com/samblouir/birdie,\nwith support for JAX and PyTorch.", "published": "2024-11-01 21:01:13", "link": "http://arxiv.org/abs/2411.01030v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Provable Length Generalization in Sequence Prediction via Spectral\n  Filtering", "abstract": "We consider the problem of length generalization in sequence prediction. We\ndefine a new metric of performance in this setting -- the Asymmetric-Regret --\nwhich measures regret against a benchmark predictor with longer context length\nthan available to the learner. We continue by studying this concept through the\nlens of the spectral filtering algorithm. We present a gradient-based learning\nalgorithm that provably achieves length generalization for linear dynamical\nsystems. We conclude with proof-of-concept experiments which are consistent\nwith our theory.", "published": "2024-11-01 21:11:40", "link": "http://arxiv.org/abs/2411.01035v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Question Answering Precision with Optimized Vector Retrieval\n  and Instructions", "abstract": "Question-answering (QA) is an important application of Information Retrieval\n(IR) and language models, and the latest trend is toward pre-trained large\nneural networks with embedding parameters. Augmenting QA performances with\nthese LLMs requires intensive computational resources for fine-tuning. We\npropose an innovative approach to improve QA task performances by integrating\noptimized vector retrievals and instruction methodologies. Based on retrieval\naugmentation, the process involves document embedding, vector retrieval, and\ncontext construction for optimal QA results. We experiment with different\ncombinations of text segmentation techniques and similarity functions, and\nanalyze their impacts on QA performances. Results show that the model with a\nsmall chunk size of 100 without any overlap of the chunks achieves the best\nresult and outperforms the models based on semantic segmentation using\nsentences. We discuss related QA examples and offer insight into how model\nperformances are improved within the two-stage framework.", "published": "2024-11-01 21:14:04", "link": "http://arxiv.org/abs/2411.01039v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Generative Emotion Cause Explanation in Multimodal Conversations", "abstract": "Multimodal conversation, a crucial form of human communication, carries rich\nemotional content, making the exploration of the causes of emotions within it a\nresearch endeavor of significant importance. However, existing research on the\ncauses of emotions typically uses clause selection methods to locate the reason\nutterance, without providing a detailed explanation of the emotional causes. In\nthis paper, we propose a new task, \\textbf{M}ultimodal \\textbf{C}onversation\n\\textbf{E}motion \\textbf{C}ause \\textbf{E}xplanation (MCECE), aiming to\ngenerate a detailed explanation of the emotional cause to the target utterance\nwithin a multimodal conversation scenario. Building upon the MELD dataset, we\ndevelop a new dataset (ECEM) that integrates video clips with detailed\nexplanations of character emotions, facilitating an in-depth examination of the\ncausal factors behind emotional expressions in multimodal conversations.A novel\napproach, FAME-Net, is further proposed, that harnesses the power of Large\nLanguage Models (LLMs) to analyze visual data and accurately interpret the\nemotions conveyed through facial expressions in videos. By exploiting the\ncontagion effect of facial emotions, FAME-Net effectively captures the\nemotional causes of individuals engaged in conversations. Our experimental\nresults on the newly constructed dataset show that FAME-Net significantly\noutperforms several excellent large language model baselines. Code and dataset\nare available at \\url{https://github.com/3222345200/ECEMdataset.git}", "published": "2024-11-01 09:16:30", "link": "http://arxiv.org/abs/2411.02430v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can LLMs make trade-offs involving stipulated pain and pleasure states?", "abstract": "Pleasure and pain play an important role in human decision making by\nproviding a common currency for resolving motivational conflicts. While Large\nLanguage Models (LLMs) can generate detailed descriptions of pleasure and pain\nexperiences, it is an open question whether LLMs can recreate the motivational\nforce of pleasure and pain in choice scenarios - a question which may bear on\ndebates about LLM sentience, understood as the capacity for valenced\nexperiential states. We probed this question using a simple game in which the\nstated goal is to maximise points, but where either the points-maximising\noption is said to incur a pain penalty or a non-points-maximising option is\nsaid to incur a pleasure reward, providing incentives to deviate from\npoints-maximising behaviour. Varying the intensity of the pain penalties and\npleasure rewards, we found that Claude 3.5 Sonnet, Command R+, GPT-4o, and\nGPT-4o mini each demonstrated at least one trade-off in which the majority of\nresponses switched from points-maximisation to pain-minimisation or\npleasure-maximisation after a critical threshold of stipulated pain or pleasure\nintensity is reached. LLaMa 3.1-405b demonstrated some graded sensitivity to\nstipulated pleasure rewards and pain penalties. Gemini 1.5 Pro and PaLM 2\nprioritised pain-avoidance over points-maximisation regardless of intensity,\nwhile tending to prioritise points over pleasure regardless of intensity. We\ndiscuss the implications of these findings for debates about the possibility of\nLLM sentience.", "published": "2024-11-01 16:22:13", "link": "http://arxiv.org/abs/2411.02432v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "SLED: Self Logits Evolution Decoding for Improving Factuality in Large\n  Language Models", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir outputs can sometimes be unreliable or factually incorrect. To address\nthis, we introduce Self Logits Evolution Decoding (SLED), a novel decoding\nframework that enhances the truthfulness of LLMs without relying on external\nknowledge bases or requiring further fine-tuning. From an optimization\nperspective, our SLED framework leverages the latent knowledge embedded within\nthe LLM by contrasting the output logits from the final layer with those from\nearly layers. It then utilizes an approximate gradient approach to enable\nlatent knowledge to guide the self-refinement of outputs, thereby effectively\nimproving factual accuracy. Extensive experiments have been conducted on\nestablished benchmarks across a diverse range of model families (LLaMA 2, LLaMA\n3, Gemma) and scales (from 2B to 70B), including more advanced architectural\nconfigurations such as the mixture of experts (MoE). Our evaluation spans a\nwide variety of tasks, including multi-choice, open-generation, and adaptations\nto chain-of-thought reasoning tasks. The results demonstrate that SLED\nconsistently improves factual accuracy by up to 20\\% compared to existing\ndecoding methods while maintaining natural language fluency and negligible\nlatency overhead. Furthermore, it can be flexibly combined with other decoding\nmethods to further enhance their performance.", "published": "2024-11-01 17:33:34", "link": "http://arxiv.org/abs/2411.02433v2", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Chat Bankman-Fried: an Exploration of LLM Alignment in Finance", "abstract": "Advancements in large language models (LLMs) have renewed concerns about AI\nalignment - the consistency between human and AI goals and values. As various\njurisdictions enact legislation on AI safety, the concept of alignment must be\ndefined and measured across different domains. This paper proposes an\nexperimental framework to assess whether LLMs adhere to ethical and legal\nstandards in the relatively unexplored context of finance. We prompt twelve\nLLMs to impersonate the CEO of a financial institution and test their\nwillingness to misuse customer assets to repay outstanding corporate debt.\nBeginning with a baseline configuration, we adjust preferences, incentives and\nconstraints, analyzing the impact of each adjustment with logistic regression.\nOur findings reveal significant heterogeneity in the baseline propensity for\nunethical behavior of LLMs. Factors such as risk aversion, profit expectations,\nand regulatory environment consistently influence misalignment in ways\npredicted by economic theory, although the magnitude of these effects varies\nacross LLMs. This paper highlights both the benefits and limitations of\nsimulation-based, ex post safety testing. While it can inform financial\nauthorities and institutions aiming to ensure LLM safety, there is a clear\ntrade-off between generality and cost.", "published": "2024-11-01 08:56:17", "link": "http://arxiv.org/abs/2411.11853v3", "categories": ["cs.CY", "cs.AI", "cs.CL", "q-fin.GN"], "primary_category": "cs.CY"}
{"title": "Contrasting with Symile: Simple Model-Agnostic Representation Learning\n  for Unlimited Modalities", "abstract": "Contrastive learning methods, such as CLIP, leverage naturally paired\ndata-for example, images and their corresponding text captions-to learn general\nrepresentations that transfer efficiently to downstream tasks. While such\napproaches are generally applied to two modalities, domains such as robotics,\nhealthcare, and video need to support many types of data at once. We show that\nthe pairwise application of CLIP fails to capture joint information between\nmodalities, thereby limiting the quality of the learned representations. To\naddress this issue, we present Symile, a simple contrastive learning approach\nthat captures higher-order information between any number of modalities. Symile\nprovides a flexible, architecture-agnostic objective for learning\nmodality-specific representations. To develop Symile's objective, we derive a\nlower bound on total correlation, and show that Symile representations for any\nset of modalities form a sufficient statistic for predicting the remaining\nmodalities. Symile outperforms pairwise CLIP, even with modalities missing in\nthe data, on cross-modal classification and retrieval across several\nexperiments including on an original multilingual dataset of 33M image, text\nand audio samples and a clinical dataset of chest X-rays, electrocardiograms,\nand laboratory measurements. All datasets and code used in this work are\npublicly available at https://github.com/rajesh-lab/symile.", "published": "2024-11-01 21:49:25", "link": "http://arxiv.org/abs/2411.01053v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Privacy Risks of Speculative Decoding in Large Language Models", "abstract": "Speculative decoding in large language models (LLMs) accelerates token\ngeneration by speculatively predicting multiple tokens cheaply and verifying\nthem in parallel, and has been widely deployed. In this paper, we provide the\nfirst study demonstrating the privacy risks of speculative decoding. We observe\nthat input-dependent patterns of correct and incorrect predictions can be\nleaked out to an adversary monitoring token generation times and packet sizes,\nleading to privacy breaches. By observing the pattern of correctly and\nincorrectly speculated tokens, we show that a malicious adversary can\nfingerprint queries and learn private user inputs with more than $90\\%$\naccuracy across three different speculative decoding techniques - REST (almost\n$100\\%$ accuracy), LADE (up to $92\\%$ accuracy), and BiLD (up to $95\\%$\naccuracy). We show that an adversary can also leak out confidential\nintellectual property used to design these techniques, such as data from\ndata-stores used for prediction (in REST) at a rate of more than $25$ tokens\nper second, or even hyper-parameters used for prediction (in LADE). We also\ndiscuss mitigation strategies, such as aggregating tokens across multiple\niterations and padding packets with additional bytes, to avoid such privacy or\nconfidentiality breaches.", "published": "2024-11-01 23:14:30", "link": "http://arxiv.org/abs/2411.01076v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SANN-PSZ: Spatially Adaptive Neural Network for Head-Tracked Personal\n  Sound Zones", "abstract": "A deep learning framework for dynamically rendering personal sound zones\n(PSZs) with head tracking is presented, utilizing a spatially adaptive neural\nnetwork (SANN) that inputs listeners' head coordinates and outputs PSZ filter\ncoefficients. The SANN model is trained using either simulated acoustic\ntransfer functions (ATFs) with data augmentation for robustness in uncertain\nenvironments or a mix of simulated and measured ATFs for customization under\nknown conditions. It is found that augmenting room reflections in the training\ndata can more effectively improve the model robustness than augmenting the\nsystem imperfections, and that adding constraints such as filter compactness to\nthe loss function does not significantly affect the model's performance.\nComparisons of the best-performing model with traditional filter design methods\nshow that, when no measured ATFs are available, the model yields equal or\nhigher isolation in an actual room environment with fewer filter artifacts.\nFurthermore, the model achieves significant data compression (100x) and\ncomputational efficiency (10x) compared to the traditional methods, making it\nsuitable for real-time rendering of PSZs that adapt to the listeners' head\nmovements.", "published": "2024-11-01 17:59:35", "link": "http://arxiv.org/abs/2411.00772v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "MACE: Leveraging Audio for Evaluating Audio Captioning Systems", "abstract": "The Automated Audio Captioning (AAC) task aims to describe an audio signal\nusing natural language. To evaluate machine-generated captions, the metrics\nshould take into account audio events, acoustic scenes, paralinguistics, signal\ncharacteristics, and other audio information. Traditional AAC evaluation relies\non natural language generation metrics like ROUGE and BLEU, image captioning\nmetrics such as SPICE and CIDEr, or Sentence-BERT embedding similarity.\nHowever, these metrics only compare generated captions to human references,\noverlooking the audio signal itself. In this work, we propose MACE (Multimodal\nAudio-Caption Evaluation), a novel metric that integrates both audio and\nreference captions for comprehensive audio caption evaluation. MACE\nincorporates audio information from audio as well as predicted and reference\ncaptions and weights it with a fluency penalty. Our experiments demonstrate\nMACE's superior performance in predicting human quality judgments compared to\ntraditional metrics. Specifically, MACE achieves a 3.28% and 4.36% relative\naccuracy improvement over the FENSE metric on the AudioCaps-Eval and\nClotho-Eval datasets respectively. Moreover, it significantly outperforms all\nthe previous metrics on the audio captioning evaluation task. The metric is\nopensourced at https://github.com/satvik-dixit/mace", "published": "2024-11-01 02:41:33", "link": "http://arxiv.org/abs/2411.00321v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MDCTCodec: A Lightweight MDCT-based Neural Audio Codec towards High\n  Sampling Rate and Low Bitrate Scenarios", "abstract": "In this paper, we propose MDCTCodec, an efficient lightweight end-to-end\nneural audio codec based on the modified discrete cosine transform (MDCT). The\nencoder takes the MDCT spectrum of audio as input, encoding it into a\ncontinuous latent code which is then discretized by a residual vector quantizer\n(RVQ). Subsequently, the decoder decodes the MDCT spectrum from the quantized\nlatent code and reconstructs audio via inverse MDCT. During the training phase,\na novel multi-resolution MDCT-based discriminator (MR-MDCTD) is adopted to\ndiscriminate the natural or decoded MDCT spectrum for adversarial training.\nExperimental results confirm that, in scenarios with high sampling rates and\nlow bitrates, the MDCTCodec exhibited high decoded audio quality, improved\ntraining and generation efficiency, and compact model size compared to baseline\ncodecs. Specifically, the MDCTCodec achieved a ViSQOL score of 4.18 at a\nsampling rate of 48 kHz and a bitrate of 6 kbps on the public VCTK corpus.", "published": "2024-11-01 09:24:28", "link": "http://arxiv.org/abs/2411.00464v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Musical Instrument Classification with Advanced Machine\n  Learning Techniques", "abstract": "Musical instrument classification, a key area in Music Information Retrieval,\nhas gained considerable interest due to its applications in education, digital\nmusic production, and consumer media. Recent advances in machine learning,\nspecifically deep learning, have enhanced the capability to identify and\nclassify musical instruments from audio signals. This study applies various\nmachine learning methods, including Naive Bayes, Support Vector Machines,\nRandom Forests, Boosting techniques like AdaBoost and XGBoost, as well as deep\nlearning models such as Convolutional Neural Networks and Artificial Neural\nNetworks. The effectiveness of these methods is evaluated on the NSynth\ndataset, a large repository of annotated musical sounds. By comparing these\napproaches, the analysis aims to showcase the advantages and limitations of\neach method, providing guidance for developing more accurate and efficient\nclassification systems. Additionally, hybrid model testing and discussion are\nincluded. This research aims to support further studies in instrument\nclassification by proposing new approaches and future research directions.", "published": "2024-11-01 00:13:46", "link": "http://arxiv.org/abs/2411.00275v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MIRFLEX: Music Information Retrieval Feature Library for Extraction", "abstract": "This paper introduces an extendable modular system that compiles a range of\nmusic feature extraction models to aid music information retrieval research.\nThe features include musical elements like key, downbeats, and genre, as well\nas audio characteristics like instrument recognition, vocals/instrumental\nclassification, and vocals gender detection. The integrated models are\nstate-of-the-art or latest open-source. The features can be extracted as latent\nor post-processed labels, enabling integration into music applications such as\ngenerative music, recommendation, and playlist generation. The modular design\nallows easy integration of newly developed systems, making it a good\nbenchmarking and comparison tool. This versatile toolkit supports the research\ncommunity in developing innovative solutions by providing concrete musical\nfeatures.", "published": "2024-11-01 09:34:36", "link": "http://arxiv.org/abs/2411.00469v1", "categories": ["cs.SD", "cs.AI", "cs.IR", "eess.AS", "I.2.7"], "primary_category": "cs.SD"}
{"title": "Multi Modal Information Fusion of Acoustic and Linguistic Data for\n  Decoding Dairy Cow Vocalizations in Animal Welfare Assessment", "abstract": "Understanding animal vocalizations through multi-source data fusion is\ncrucial for assessing emotional states and enhancing animal welfare in\nprecision livestock farming. This study aims to decode dairy cow contact calls\nby employing multi-modal data fusion techniques, integrating transcription,\nsemantic analysis, contextual and emotional assessment, and acoustic feature\nextraction. We utilized the Natural Language Processing model to transcribe\naudio recordings of cow vocalizations into written form. By fusing multiple\nacoustic features frequency, duration, and intensity with transcribed textual\ndata, we developed a comprehensive representation of cow vocalizations.\nUtilizing data fusion within a custom-developed ontology, we categorized\nvocalizations into high frequency calls associated with distress or arousal,\nand low frequency calls linked to contentment or calmness. Analyzing the fused\nmulti dimensional data, we identified anxiety related features indicative of\nemotional distress, including specific frequency measurements and sound\nspectrum results. Assessing the sentiment and acoustic features of\nvocalizations from 20 individual cows allowed us to determine differences in\ncalling patterns and emotional states. Employing advanced machine learning\nalgorithms, Random Forest, Support Vector Machine, and Recurrent Neural\nNetworks, we effectively processed and fused multi-source data to classify cow\nvocalizations. These models were optimized to handle computational demands and\ndata quality challenges inherent in practical farm environments. Our findings\ndemonstrate the effectiveness of multi-source data fusion and intelligent\nprocessing techniques in animal welfare monitoring. This study represents a\nsignificant advancement in animal welfare assessment, highlighting the role of\ninnovative fusion technologies in understanding and improving the emotional\nwellbeing of dairy cows.", "published": "2024-11-01 09:48:30", "link": "http://arxiv.org/abs/2411.00477v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "q-bio.QM"], "primary_category": "cs.SD"}
{"title": "An incremental algorithm based on multichannel non-negative matrix\n  partial co-factorization for ambient denoising in auscultation", "abstract": "The aim of this study is to implement a method to remove ambient noise in\nbiomedical sounds captured in auscultation. We propose an incremental approach\nbased on multichannel non-negative matrix partial co-factorization (NMPCF) for\nambient denoising focusing on high noisy environment with a Signal-to-Noise\nRatio (SNR) <= -5 dB. The first contribution applies NMPCF assuming that\nambient noise can be modelled as repetitive sound events simultaneously found\nin two single-channel inputs captured by means of different recording devices.\nThe second contribution proposes an incremental algorithm, based on the\nprevious multichannel NMPCF, that refines the estimated biomedical spectrogram\nthroughout a set of incremental stages by eliminating most of the ambient noise\nthat was not removed in the previous stage at the expense of preserving most of\nthe biomedical spectral content. The ambient denoising performance of the\nproposed method, compared to some of the most relevant state-of-the-art\nmethods, has been evaluated using a set of recordings composed of biomedical\nsounds mixed with ambient noise that typically surrounds a medical consultation\nroom to simulate high noisy environments with a SNR from -20 dB to -5 dB.\nExperimental results report that: (i) the performance drop suffered by the\nproposed method is lower compared to MSS and NLMS; (ii) unlike what happens\nwith MSS and NLMS, the proposed method shows a stable trend of the average SDR\nand SIR results regardless of the type of ambient noise and the SNR level\nevaluated; and (iii) a remarkable advantage is the high robustness of the\nestimated biomedical sounds when the two single-channel inputs suffer from a\ndelay between them.", "published": "2024-11-01 20:38:49", "link": "http://arxiv.org/abs/2411.01018v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
