{"title": "Deep Reinforcement Learning Strategies in Finance: Insights into Asset Holding, Trading Behavior, and Purchase Diversity", "abstract": "Recent deep reinforcement learning (DRL) methods in finance show promising\noutcomes. However, there is limited research examining the behavior of these\nDRL algorithms. This paper aims to investigate their tendencies towards holding\nor trading financial assets as well as purchase diversity. By analyzing their\ntrading behaviors, we provide insights into the decision-making processes of\nDRL models in finance applications. Our findings reveal that each DRL algorithm\nexhibits unique trading patterns and strategies, with A2C emerging as the top\nperformer in terms of cumulative rewards. While PPO and SAC engage in\nsignificant trades with a limited number of stocks, DDPG and TD3 adopt a more\nbalanced approach. Furthermore, SAC and PPO tend to hold positions for shorter\ndurations, whereas DDPG, A2C, and TD3 display a propensity to remain stationary\nfor extended periods.", "published": "2024-06-29 20:56:58", "link": "http://arxiv.org/abs/2407.09557v1", "categories": ["q-fin.TR", "cs.AI", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "LLM-Generated Natural Language Meets Scaling Laws: New Explorations and\n  Data Augmentation Methods", "abstract": "With the ascent of large language models (LLM), natural language processing\nhas witnessed enhancements, such as LLM-based data augmentation. Nonetheless,\nprior research harbors two primary concerns: firstly, a lack of contemplation\nregarding whether the natural language generated by LLM (LLMNL) truly aligns\nwith human natural language (HNL), a critical foundational question; secondly,\nan oversight that augmented data is randomly generated by LLM, implying that\nnot all data may possess equal training value, that could impede the\nperformance of classifiers. To address these challenges, we introduce the\nscaling laws to intrinsically calculate LLMNL and HNL. Through extensive\nexperiments, we reveal slight deviations (approximately 0.2 Mandelbrot\nexponent) from Mandelbrot's law in LLMNL, underscore a complexity advantage in\nHNL, and supplement an interpretive discussion on language style. This\nestablishes a solid foundation for LLM's expansion. Further, we introduce a\nnovel data augmentation method for few-shot text classification, termed ZGPTDA,\nwhich leverages fuzzy computing mechanisms driven by the conformity to scaling\nlaws to make decisions about GPT-4 augmented data. Extensive experiments,\nconducted in real-world scenarios, confirms the effectiveness (improving F1 of\nBert and RoBerta by 7-10%) and competitiveness (surpassing recent AugGPT and\nGENCO methods by about 2% accuracy on DeBerta) of ZGPTDA. In addition, we\nreveal some interesting insights, e.g., Hilberg's law and Taylor's law can\nimpart more benefits to text classification, etc.", "published": "2024-06-29 05:40:17", "link": "http://arxiv.org/abs/2407.00322v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Iterative Data Generation with Large Language Models for Aspect-based\n  Sentiment Analysis", "abstract": "Aspect-based Sentiment Analysis (ABSA) is an important sentiment analysis\ntask, which aims to determine the sentiment polarity towards an aspect in a\nsentence. Due to the expensive and limited labeled data, data generation (DG)\nhas become the standard for improving the performance of ABSA. However, current\nDG methods usually have some shortcomings: 1) poor fluency and coherence, 2)\nlack of diversity of generated data, and 3) reliance on some existing labeled\ndata, hindering its applications in real-world scenarios. With the advancement\nof large language models (LLMs), LLM-based DG has the potential to solve the\nabove issues. Unfortunately, directly prompting LLMs struggles to generate the\ndesired pseudo-label ABSA data, as LLMs are prone to hallucinations, leading to\nundesired data generation. To this end, we propose a systematic Iterative Data\nGeneration framework, namely IDG, to boost the performance of ABSA. The core of\nIDG is to make full use of the powerful abilities (i.e., instruction-following,\nin-context learning and self-reflection) of LLMs to iteratively generate more\nfluent and diverse pseudo-label data, starting from an unsupervised sentence\ncorpus. Specifically, IDG designs a novel iterative data generation mechanism\nand a self-reflection data filtering module to tackle the challenges of\nunexpected data generation caused by hallucinations. Extensive experiments on\nfour widely-used ABSA benchmarks show that IDG brings consistent and\nsignificant performance gains among five baseline ABSA models. More\nencouragingly, the synthetic data generated by IDG can achieve comparable or\neven better performance against the manually annotated data.", "published": "2024-06-29 07:00:37", "link": "http://arxiv.org/abs/2407.00341v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Financial Knowledge Large Language Model", "abstract": "Artificial intelligence is making significant strides in the finance\nindustry, revolutionizing how data is processed and interpreted. Among these\ntechnologies, large language models (LLMs) have demonstrated substantial\npotential to transform financial services by automating complex tasks,\nenhancing customer service, and providing detailed financial analysis. Firstly,\nwe introduce IDEA-FinBench, an evaluation benchmark specifically tailored for\nassessing financial knowledge in large language models (LLMs). This benchmark\nutilizes questions from two globally respected and authoritative financial\nprofessional exams, aimimg to comprehensively evaluate the capability of LLMs\nto directly address exam questions pertinent to the finance sector. Secondly,\nwe propose IDEA-FinKER, a Financial Knowledge Enhancement framework designed to\nfacilitate the rapid adaptation of general LLMs to the financial domain,\nintroducing a retrieval-based few-shot learning method for real-time\ncontext-level knowledge injection, and a set of high-quality financial\nknowledge instructions for fine-tuning any general LLM. Finally, we present\nIDEA-FinQA, a financial question-answering system powered by LLMs. This system\nis structured around a scheme of real-time knowledge injection and factual\nenhancement using external knowledge. IDEA-FinQA is comprised of three main\nmodules: the data collector, the data querying module, and LLM-based agents\ntasked with specific functions.", "published": "2024-06-29 08:26:49", "link": "http://arxiv.org/abs/2407.00365v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open\n  Models", "abstract": "Given the growing influx of misinformation across news and social media,\nthere is a critical need for systems that can provide effective real-time\nverification of news claims. Large language or multimodal model based\nverification has been proposed to scale up online policing mechanisms for\nmitigating spread of false and harmful content. While these can potentially\nreduce burden on human fact-checkers, such efforts may be hampered by\nfoundation model training data becoming outdated. In this work, we test the\nlimits of improving foundation model performance without continual updating\nthrough an initial study of knowledge transfer using either existing intra- and\ninter- domain benchmarks or explanations generated from large language models\n(LLMs). We evaluate on 12 public benchmarks for fact-checking and\nmisinformation detection as well as two other tasks relevant to content\nmoderation -- toxicity and stance detection. Our results on two recent\nmulti-modal fact-checking benchmarks, Mocheg and Fakeddit, indicate that\nknowledge transfer strategies can improve Fakeddit performance over the\nstate-of-the-art by up to 1.7% and Mocheg performance by up to 2.9%.", "published": "2024-06-29 08:39:07", "link": "http://arxiv.org/abs/2407.00369v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Process Verification for Large Language Models via Tree-Based\n  Preference Learning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\nhandling complex reasoning tasks by generating step-by-step rationales.Some\nmethods have proven effective in boosting accuracy by introducing extra\nverifiers to assess these paths. However, existing verifiers, typically trained\non binary-labeled reasoning paths, fail to fully utilize the relative merits of\nintermediate steps, thereby limiting the effectiveness of the feedback\nprovided. To overcome this limitation, we propose Tree-based Preference\nLearning Verifier (Tree-PLV), a novel approach that constructs reasoning trees\nvia a best-first search algorithm and collects step-level paired data for\npreference training. Compared to traditional binary classification, step-level\npreferences more finely capture the nuances between reasoning steps, allowing\nfor a more precise evaluation of the complete reasoning path. We empirically\nevaluate Tree-PLV across a range of arithmetic and commonsense reasoning tasks,\nwhere it significantly outperforms existing benchmarks. For instance, Tree-PLV\nachieved substantial performance gains over the Mistral-7B self-consistency\nbaseline on GSM8K (67.55% to 82.79%), MATH (17.00% to 26.80%), CSQA (68.14% to\n72.97%), and StrategyQA (82.86% to 83.25%).Additionally, our study explores the\nappropriate granularity for applying preference learning, revealing that\nstep-level guidance provides feedback that better aligns with the evaluation of\nthe reasoning process.", "published": "2024-06-29 10:09:49", "link": "http://arxiv.org/abs/2407.00390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Too Late to Train, Too Early To Use? A Study on Necessity and Viability\n  of Low-Resource Bengali LLMs", "abstract": "Each new generation of English-oriented Large Language Models (LLMs) exhibits\nenhanced cross-lingual transfer capabilities and significantly outperforms\nolder LLMs on low-resource languages. This prompts the question: Is there a\nneed for LLMs dedicated to a particular low-resource language? We aim to\nexplore this question for Bengali, a low-to-moderate resource Indo-Aryan\nlanguage native to the Bengal region of South Asia.\n  We compare the performance of open-weight and closed-source LLMs such as\nLLaMA-3 and GPT-4 against fine-tuned encoder-decoder models across a diverse\nset of Bengali downstream tasks, including translation, summarization,\nparaphrasing, question-answering, and natural language inference. Our findings\nreveal that while LLMs generally excel in reasoning tasks, their performance in\ntasks requiring Bengali script generation is inconsistent. Key challenges\ninclude inefficient tokenization of Bengali script by existing LLMs, leading to\nincreased computational costs and potential performance degradation.\nAdditionally, we highlight biases in machine-translated datasets commonly used\nfor Bengali NLP tasks. We conclude that there is a significant need for a\nBengali-oriented LLM, but the field currently lacks the high-quality\npretraining and instruction-tuning datasets necessary to develop a highly\neffective model.", "published": "2024-06-29 11:50:16", "link": "http://arxiv.org/abs/2407.00416v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Brevity is the soul of wit: Pruning long files for code generation", "abstract": "Data curation is commonly considered a \"secret-sauce\" for LLM training, with\nhigher quality data usually leading to better LLM performance. Given the scale\nof internet-scraped corpora, data pruning has become a larger and larger focus.\nSpecifically, many have shown that de-duplicating data, or sub-selecting higher\nquality data, can lead to efficiency or performance improvements. Generally,\nthree types of methods are used to filter internet-scale corpora:\nembedding-based, heuristic-based, and classifier-based. In this work, we\ncontrast the former two in the domain of finetuning LLMs for code generation.\nWe find that embedding-based methods are often confounded by length, and that a\nsimple heuristic--pruning long files--outperforms other methods in\ncompute-limited regimes. Our method can yield up to a 2x efficiency benefit in\ntraining (while matching performance) or a 3.5% absolute performance\nimprovement on HumanEval (while matching compute). However, we find that\nperplexity on held-out long files can increase, begging the question of whether\noptimizing data mixtures for common coding benchmarks (HumanEval, MBPP)\nactually best serves downstream use cases. Overall, we hope our work builds\nuseful intuitions about code data (specifically, the low quality of extremely\nlong code files) provides a compelling heuristic-based method for data pruning,\nand brings to light questions in how we evaluate code generation models.", "published": "2024-06-29 13:08:24", "link": "http://arxiv.org/abs/2407.00434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Recipe of Parallel Corpora Exploitation for Multilingual Large\n  Language Models", "abstract": "Recent studies have highlighted the potential of exploiting parallel corpora\nto enhance multilingual large language models, improving performance in both\nbilingual tasks, e.g., machine translation, and general-purpose tasks, e.g.,\ntext classification. Building upon these findings, our comprehensive study aims\nto identify the most effective strategies for leveraging parallel corpora. We\ninvestigate the impact of parallel corpora quality and quantity, training\nobjectives, and model size on the performance of multilingual large language\nmodels enhanced with parallel corpora across diverse languages and tasks. Our\nanalysis reveals several key insights: (i) filtering noisy translations is\nessential for effectively exploiting parallel corpora, while language\nidentification and short sentence filtering have little effect; (ii) even a\ncorpus with just 10K parallel sentences can yield results comparable to those\nobtained from much larger datasets; (iii) employing only the machine\ntranslation objective yields the best results among various training objectives\nand their combinations; (iv) larger multilingual language models benefit more\nfrom parallel corpora than smaller models. Our study offers valuable insights\ninto the optimal utilization of parallel corpora to enhance multilingual large\nlanguage models, extending the generalizability of previous findings from\nlimited languages and tasks to a broader range of scenarios.", "published": "2024-06-29 13:12:39", "link": "http://arxiv.org/abs/2407.00436v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Translate-Train: Enhancing Cross-Lingual Transfer of Large Language\n  Models via Inherent Capability", "abstract": "Zero-shot cross-lingual transfer by fine-tuning multilingual pretrained\nmodels shows promise for low-resource languages, but often suffers from\nmisalignment of internal representations between languages. We hypothesize that\neven when the model cannot generalize across languages effectively in\nfine-tuning, it still captures cross-lingual correspondence useful for\ncross-lingual transfer. We explore this hypothesis with Self-Translate-Train, a\nmethod that lets large language models (LLMs) to translate training data into\nthe target language and fine-tunes the model on its own generated data. By\ndemonstrating that Self-Translate-Train outperforms zero-shot transfer, we\nencourage further exploration of better methods to elicit cross-lingual\ncapabilities of LLMs.", "published": "2024-06-29 14:40:23", "link": "http://arxiv.org/abs/2407.00454v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Classifier identification in Ancient Egyptian as a low-resource\n  sequence-labelling task", "abstract": "The complex Ancient Egyptian (AE) writing system was characterised by\nwidespread use of graphemic classifiers (determinatives): silent (unpronounced)\nhieroglyphic signs clarifying the meaning or indicating the pronunciation of\nthe host word. The study of classifiers has intensified in recent years with\nthe launch and quick growth of the iClassifier project, a web-based platform\nfor annotation and analysis of classifiers in ancient and modern languages.\nThanks to the data contributed by the project participants, it is now possible\nto formulate the identification of classifiers in AE texts as an NLP task. In\nthis paper, we make first steps towards solving this task by implementing a\nseries of sequence-labelling neural models, which achieve promising performance\ndespite the modest amount of training data. We discuss tokenisation and\noperationalisation issues arising from tackling AE texts and contrast our\napproach with frequency-based baselines.", "published": "2024-06-29 15:40:25", "link": "http://arxiv.org/abs/2407.00475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Massive Multilingual Holistic Bias", "abstract": "In the current landscape of automatic language generation, there is a need to\nunderstand, evaluate, and mitigate demographic biases as existing models are\nbecoming increasingly multilingual. To address this, we present the initial\neight languages from the MASSIVE MULTILINGUAL HOLISTICBIAS (MMHB) dataset and\nbenchmark consisting of approximately 6 million sentences representing 13\ndemographic axes. We propose an automatic construction methodology to further\nscale up MMHB sentences in terms of both language coverage and size, leveraging\nlimited human annotation. Our approach utilizes placeholders in multilingual\nsentence construction and employs a systematic method to independently\ntranslate sentence patterns, nouns, and descriptors. Combined with human\ntranslation, this technique carefully designs placeholders to dynamically\ngenerate multiple sentence variations and significantly reduces the human\ntranslation workload. The translation process has been meticulously conducted\nto avoid an English-centric perspective and include all necessary morphological\nvariations for languages that require them, improving from the original English\nHOLISTICBIAS. Finally, we utilize MMHB to report results on gender bias and\nadded toxicity in machine translation tasks. On the gender analysis, MMHB\nunveils: (1) a lack of gender robustness showing almost +4 chrf points in\naverage for masculine semantic sentences compared to feminine ones and (2) a\npreference to overgeneralize to masculine forms by reporting more than +12 chrf\npoints in average when evaluating with masculine compared to feminine\nreferences. MMHB triggers added toxicity up to 2.3%.", "published": "2024-06-29 16:26:27", "link": "http://arxiv.org/abs/2407.00486v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "It's Morphing Time: Unleashing the Potential of Multiple LLMs via\n  Multi-objective Optimization", "abstract": "In this paper, we introduce a novel approach for addressing the\nmulti-objective optimization problem in large language model merging via\nblack-box multi-objective optimization algorithms. The goal of model merging is\nto combine multiple models, each excelling in different tasks, into a single\nmodel that outperforms any of the individual source models. However, model\nmerging faces two significant challenges: First, existing methods rely heavily\non human knowledge or intuition. Second, it's difficult to obtain the great\nmodel merging configuration in limited evaluations. To address these\nchallenges, we formalize model merging as a multi-objective optimization\nproblem and propose an automated optimization approach named MM-MO. This method\nleverages multi-objective optimization algorithms to autonomously search for\noptimal merging configurations across various tasks, alleviating the need for\nhuman intervention. In MM-MO, a weak-to-strong method is employed to enhance\nthe acquisition function, allowing previously evaluated superior configurations\nto guide the search for new ones. Meanwhile, Fisher information is applied to\nscreen these configurations, increasing the possibility of identifying\nhigh-quality merging configuration. Additionally, we designed a sparsity metric\nas an additional optimization objective to enhance the model's generalization\nperformance across different tasks. We conducted comprehensive experiments with\nother mainstream model merging methods, demonstrating that the proposed MM-MO\nalgorithm is competitive and effective in achieving high-quality model merging.", "published": "2024-06-29 16:34:23", "link": "http://arxiv.org/abs/2407.00487v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs-as-Instructors: Learning from Errors Toward Automating Model\n  Improvement", "abstract": "This paper introduces the innovative \"LLMs-as-Instructors\" framework, which\nleverages the advanced Large Language Models (LLMs) to autonomously enhance the\ntraining of smaller target models. Inspired by the theory of \"Learning from\nErrors\", this framework employs an instructor LLM to meticulously analyze the\nspecific errors within a target model, facilitating targeted and efficient\ntraining cycles. Within this framework, we implement two strategies: \"Learning\nfrom Error,\" which focuses solely on incorrect responses to tailor training\ndata, and \"Learning from Error by Contrast\", which uses contrastive learning to\nanalyze both correct and incorrect responses for a deeper understanding of\nerrors.\n  Our empirical studies, conducted with several open-source models, demonstrate\nsignificant improvements across multiple benchmarks, including mathematical\nreasoning, coding abilities, and factual knowledge. Notably, the refined\nLlama-3-8b-Instruction has outperformed ChatGPT, illustrating the effectiveness\nof our approach. By leveraging the strengths of both strategies, we have\nattained a more balanced performance improvement on both in-domain and\nout-of-domain benchmarks. Our code can be found at\nhttps://yingjiahao14.github.io/LLMs-as-Instructors-pages/.", "published": "2024-06-29 17:16:04", "link": "http://arxiv.org/abs/2407.00497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KPC-cF: Aspect-Based Sentiment Analysis via Implicit-Feature Alignment\n  with Corpus Filtering", "abstract": "Investigations into Aspect-Based Sentiment Analysis (ABSA) for Korean\nindustrial reviews are notably lacking in the existing literature. Our research\nproposes an intuitive and effective framework for ABSA in low-resource\nlanguages such as Korean. It optimizes prediction labels by integrating\ntranslated benchmark and unlabeled Korean data. Using a model fine-tuned on\ntranslated data, we pseudo-labeled the actual Korean NLI set. Subsequently, we\napplied LaBSE and \\MSP{}-based filtering to this pseudo-NLI set as implicit\nfeature, enhancing Aspect Category Detection and Polarity determination through\nadditional training. Incorporating dual filtering, this model bridged dataset\ngaps and facilitates feature alignment with minimal resources. By implementing\nalignment pipelines, our approach aims to leverage high-resource datasets to\ndevelop reliable predictive and refined models within corporate or individual\ncommunities in low-resource language countries. Compared to English ABSA, our\nframework showed an approximately 3\\% difference in F1 scores and accuracy. We\nwill release our dataset and code for Korean ABSA, at this link.", "published": "2024-06-29 07:01:51", "link": "http://arxiv.org/abs/2407.00342v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From RAG to RICHES: Retrieval Interlaced with Sequence Generation", "abstract": "We present RICHES, a novel approach that interleaves retrieval with sequence\ngeneration tasks. RICHES offers an alternative to conventional RAG systems by\neliminating the need for separate retriever and generator. It retrieves\ndocuments by directly decoding their contents, constrained on the corpus.\nUnifying retrieval with generation allows us to adapt to diverse new tasks via\nprompting alone. RICHES can work with any Instruction-tuned model, without\nadditional training. It provides attributed evidence, supports multi-hop\nretrievals and interleaves thoughts to plan on what to retrieve next, all\nwithin a single decoding pass of the LLM. We demonstrate the strong performance\nof RICHES across ODQA tasks including attributed and multi-hop QA.", "published": "2024-06-29 08:16:58", "link": "http://arxiv.org/abs/2407.00361v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GraphArena: Evaluating and Exploring Large Language Models on Graph\n  Computation", "abstract": "The ``arms race'' of Large Language Models (LLMs) demands new benchmarks to\nexamine their progresses. In this paper, we introduce GraphArena, a\nbenchmarking tool designed to evaluate LLMs on real-world graph computational\nproblems. It offers a suite of four polynomial-time tasks (e.g., Shortest\nDistance) and six NP-complete challenges (e.g., Traveling Salesman Problem).\nGraphArena features a rigorous evaluation framework that classifies LLM outputs\nas correct, suboptimal (feasible but not optimal), hallucinatory (properly\nformatted but infeasible), or missing. Evaluation of over 10 LLMs reveals that\neven top-performing LLMs struggle with larger, more complex graph problems and\nexhibit hallucination issues. We further explore four potential solutions to\naddress this issue and improve LLMs on graph computation, including\nchain-of-thought prompting, instruction tuning, code writing, and scaling\ntest-time compute, each demonstrating unique strengths and limitations.\nGraphArena complements the existing LLM benchmarks and is open-sourced at\nhttps://github.com/squareRoot3/GraphArena.", "published": "2024-06-29 09:19:23", "link": "http://arxiv.org/abs/2407.00379v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Study on Effect of Reference Knowledge Choice in Generating Technical\n  Content Relevant to SAPPhIRE Model Using Large Language Model", "abstract": "Representation of systems using the SAPPhIRE model of causality can be an\ninspirational stimulus in design. However, creating a SAPPhIRE model of a\ntechnical or a natural system requires sourcing technical knowledge from\nmultiple technical documents regarding how the system works. This research\ninvestigates how to generate technical content accurately relevant to the\nSAPPhIRE model of causality using a Large Language Model, also called LLM. This\npaper, which is the first part of the two-part research, presents a method for\nhallucination suppression using Retrieval Augmented Generating with LLM to\ngenerate technical content supported by the scientific information relevant to\na SAPPhIRE con-struct. The result from this research shows that the selection\nof reference knowledge used in providing context to the LLM for generating the\ntechnical content is very important. The outcome of this research is used to\nbuild a software support tool to generate the SAPPhIRE model of a given\ntechnical system.", "published": "2024-06-29 10:46:01", "link": "http://arxiv.org/abs/2407.00396v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is It Really Long Context if All You Need Is Retrieval? Towards\n  Genuinely Difficult Long Context NLP", "abstract": "Improvements in language models' capabilities have pushed their applications\ntowards longer contexts, making long-context evaluation and development an\nactive research area. However, many disparate use-cases are grouped together\nunder the umbrella term of \"long-context\", defined simply by the total length\nof the model's input, including - for example - Needle-in-a-Haystack tasks,\nbook summarization, and information aggregation. Given their varied difficulty,\nin this position paper we argue that conflating different tasks by their\ncontext length is unproductive. As a community, we require a more precise\nvocabulary to understand what makes long-context tasks similar or different. We\npropose to unpack the taxonomy of long-context based on the properties that\nmake them more difficult with longer contexts. We propose two orthogonal axes\nof difficulty: (I) Diffusion: How hard is it to find the necessary information\nin the context? (II) Scope: How much necessary information is there to find? We\nsurvey the literature on long-context, provide justification for this taxonomy\nas an informative descriptor, and situate the literature with respect to it. We\nconclude that the most difficult and interesting settings, whose necessary\ninformation is very long and highly diffused within the input, is severely\nunder-explored. By using a descriptive vocabulary and discussing the relevant\nproperties of difficulty in long-context, we can implement more informed\nresearch in this area. We call for a careful design of tasks and benchmarks\nwith distinctly long context, taking into account the characteristics that make\nit qualitatively different from shorter context.", "published": "2024-06-29 11:09:47", "link": "http://arxiv.org/abs/2407.00402v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SHADE: Semantic Hypernym Annotator for Domain-specific Entities -- DnD\n  Domain Use Case", "abstract": "Manual data annotation is an important NLP task but one that takes\nconsiderable amount of resources and effort. In spite of the costs, labeling\nand categorizing entities is essential for NLP tasks such as semantic\nevaluation. Even though annotation can be done by non-experts in most cases,\ndue to the fact that this requires human labor, the process is costly. Another\nmajor challenge encountered in data annotation is maintaining the annotation\nconsistency. Annotation efforts are typically carried out by teams of multiple\nannotators. The annotations need to maintain the consistency in relation to\nboth the domain truth and annotation format while reducing human errors.\nAnnotating a specialized domain that deviates significantly from the general\ndomain, such as fantasy literature, will see a lot of human error and annotator\ndisagreement. So it is vital that proper guidelines and error reduction\nmechanisms are enforced. One such way to enforce these constraints is using a\nspecialized application. Such an app can ensure that the notations are\nconsistent, and the labels can be pre-defined or restricted reducing the room\nfor errors. In this paper, we present SHADE, an annotation software that can be\nused to annotate entities in the high fantasy literature domain. Specifically\nin Dungeons and Dragons lore extracted from the Forgotten Realms Fandom Wiki.", "published": "2024-06-29 11:21:40", "link": "http://arxiv.org/abs/2407.00407v1", "categories": ["cs.CE", "cs.CL"], "primary_category": "cs.CE"}
{"title": "eFontes. Part of Speech Tagging and Lemmatization of Medieval Latin\n  Texts.A Cross-Genre Survey", "abstract": "This study introduces the eFontes models for automatic linguistic annotation\nof Medieval Latin texts, focusing on lemmatization, part-of-speech tagging, and\nmorphological feature determination. Using the Transformers library, these\nmodels were trained on Universal Dependencies (UD) corpora and the newly\ndeveloped eFontes corpus of Polish Medieval Latin. The research evaluates the\nmodels' performance, addressing challenges such as orthographic variations and\nthe integration of Latinized vernacular terms. The models achieved high\naccuracy rates: lemmatization at 92.60%, part-of-speech tagging at 83.29%, and\nmorphological feature determination at 88.57%. The findings underscore the\nimportance of high-quality annotated corpora and propose future enhancements,\nincluding extending the models to Named Entity Recognition.", "published": "2024-06-29 11:59:20", "link": "http://arxiv.org/abs/2407.00418v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PerSEval: Assessing Personalization in Text Summarizers", "abstract": "Personalized summarization models cater to individuals' subjective\nunderstanding of saliency, as represented by their reading history and current\ntopics of attention. Existing personalized text summarizers are primarily\nevaluated based on accuracy measures such as BLEU, ROUGE, and METEOR. However,\na recent study argued that accuracy measures are inadequate for evaluating the\ndegree of personalization of these models and proposed EGISES, the first metric\nto evaluate personalized text summaries. It was suggested that accuracy is a\nseparate aspect and should be evaluated standalone. In this paper, we challenge\nthe necessity of an accuracy leaderboard, suggesting that relying on\naccuracy-based aggregated results might lead to misleading conclusions. To\nsupport this, we delve deeper into EGISES, demonstrating both theoretically and\nempirically that it measures the degree of responsiveness, a necessary but not\nsufficient condition for degree-of-personalization. We subsequently propose\nPerSEval, a novel measure that satisfies the required sufficiency condition.\nBased on the benchmarking of ten SOTA summarization models on the PENS dataset,\nwe empirically establish that -- (i) PerSEval is reliable w.r.t human-judgment\ncorrelation (Pearson's r = 0.73; Spearman's $\\rho$ = 0.62; Kendall's $\\tau$ =\n0.42), (ii) PerSEval has high rank-stability, (iii) PerSEval as a rank-measure\nis not entailed by EGISES-based ranking, and (iv) PerSEval can be a standalone\nrank-measure without the need of any aggregated ranking.", "published": "2024-06-29 14:37:36", "link": "http://arxiv.org/abs/2407.00453v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Polarization and Morality: Lexical Analysis of Abortion Discourse on\n  Reddit", "abstract": "This study investigates whether division on political topics is mapped with\nthe distinctive patterns of language use. We collect a total 145,832 Reddit\ncomments on the abortion debate and explore the languages of subreddit\ncommunities r/prolife and r/prochoice. With consideration of the Moral\nFoundations Theory, we examine lexical patterns in three ways. First, we\ncompute proportional frequencies of lexical items from the Moral Foundations\nDictionary in order to make inferences about each group's moral considerations\nwhen forming arguments for and against abortion. We then create n-gram models\nto reveal frequent collocations from each stance group and better understand\nhow commonly used words are patterned in their linguistic context and in\nrelation to morality values. Finally, we use Latent Dirichlet Allocation to\nidentify underlying topical structures in the corpus data. Results show that\nthe use of morality words is mapped with the stances on abortion.", "published": "2024-06-29 14:50:55", "link": "http://arxiv.org/abs/2407.00455v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for\n  Biomedical Science", "abstract": "Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,\ndraws increasing attention, where one common approach is to build a copilot\nagent driven by Large Language Models (LLMs). However, to evaluate such\nsystems, people either rely on direct Question-Answering (QA) to the LLM\nitself, or in a biomedical experimental manner. How to precisely benchmark\nbiomedical agents from an AI Scientist perspective remains largely unexplored.\nTo this end, we draw inspiration from one most important abilities of\nscientists, understanding the literature, and introduce BioKGBench. In contrast\nto traditional evaluation benchmark that only focuses on factual QA, where the\nLLMs are known to have hallucination issues, we first disentangle\n\"Understanding Literature\" into two atomic abilities, i) \"Understanding\" the\nunstructured text from research papers by performing scientific claim\nverification, and ii) Ability to interact with structured Knowledge-Graph\nQuestion-Answering (KGQA) as a form of \"Literature\" grounding. We then\nformulate a novel agent task, dubbed KGCheck, using KGQA and domain-based\nRetrieval-Augmented Generation (RAG) to identify the factual errors of existing\nlarge-scale knowledge graph databases. We collect over two thousand data for\ntwo atomic tasks and 225 high-quality annotated data for the agent task.\nSurprisingly, we discover that state-of-the-art agents, both daily scenarios\nand biomedical ones, have either failed or inferior performance on our\nbenchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.\nOn the widely used popular knowledge graph, we discover over 90 factual errors\nwhich provide scenarios for agents to make discoveries and demonstrate the\neffectiveness of our approach. The code and data are available at\nhttps://github.com/westlake-autolab/BioKGBench.", "published": "2024-06-29 15:23:28", "link": "http://arxiv.org/abs/2407.00466v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PFME: A Modular Approach for Fine-grained Hallucination Detection and\n  Editing of Large Language Models", "abstract": "Large Language Models (LLMs) excel in fluency but risk producing inaccurate\ncontent, called \"hallucinations.\" This paper outlines a standardized process\nfor categorizing fine-grained hallucination types and proposes an innovative\nframework--the Progressive Fine-grained Model Editor (PFME)--specifically\ndesigned to detect and correct fine-grained hallucinations in LLMs. PFME\nconsists of two collaborative modules: the Real-time Fact Retrieval Module and\nthe Fine-grained Hallucination Detection and Editing Module. The former\nidentifies key entities in the document and retrieves the latest factual\nevidence from credible sources. The latter further segments the document into\nsentence-level text and, based on relevant evidence and previously edited\ncontext, identifies, locates, and edits each sentence's hallucination type.\nExperimental results on FavaBench and FActScore demonstrate that PFME\noutperforms existing methods in fine-grained hallucination detection tasks.\nParticularly, when using the Llama3-8B-Instruct model, PFME's performance in\nfine-grained hallucination detection with external knowledge assistance\nimproves by 8.7 percentage points (pp) compared to ChatGPT. In editing tasks,\nPFME further enhances the FActScore of FActScore-Alpaca13B and\nFActScore-ChatGPT datasets, increasing by 16.2pp and 4.6pp, respectively.", "published": "2024-06-29 16:35:57", "link": "http://arxiv.org/abs/2407.00488v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LiteSearch: Efficacious Tree Search for LLM", "abstract": "Recent research suggests that tree search algorithms (e.g. Monte Carlo Tree\nSearch) can dramatically boost LLM performance on complex mathematical\nreasoning tasks. However, they often require more than 10 times the\ncomputational resources of greedy decoding due to wasteful search strategies,\nmaking them difficult to be deployed in practical applications. This study\nintroduces a novel guided tree search algorithm with dynamic node selection and\nnode-level exploration budget (maximum number of children) calculation to\ntackle this issue. By considering the search progress towards the final answer\n(history) and the guidance from a value network (future) trained without any\nstep-wise annotations, our algorithm iteratively selects the most promising\ntree node before expanding it within the boundaries of the allocated\ncomputational budget. Experiments conducted on the GSM8K and TabMWP datasets\ndemonstrate that our approach not only offers competitive performance but also\nenjoys significantly lower computational costs compared to baseline methods.", "published": "2024-06-29 05:14:04", "link": "http://arxiv.org/abs/2407.00320v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation:\n  Benchmark and Fact-Augmented Intervention", "abstract": "Prompt-based \"diversity interventions\" are commonly adopted to improve the\ndiversity of Text-to-Image (T2I) models depicting individuals with various\nracial or gender traits. However, will this strategy result in nonfactual\ndemographic distribution, especially when generating real historical figures.\nIn this work, we propose DemOgraphic FActualIty Representation (DoFaiR), a\nbenchmark to systematically quantify the trade-off between using diversity\ninterventions and preserving demographic factuality in T2I models. DoFaiR\nconsists of 756 meticulously fact-checked test instances to reveal the\nfactuality tax of various diversity prompts through an automated\nevidence-supported evaluation pipeline. Experiments on DoFaiR unveil that\ndiversity-oriented instructions increase the number of different gender and\nracial groups in DALLE-3's generations at the cost of historically inaccurate\ndemographic distributions. To resolve this issue, we propose Fact-Augmented\nIntervention (FAI), which instructs a Large Language Model (LLM) to reflect on\nverbalized or retrieved factual information about gender and racial\ncompositions of generation subjects in history, and incorporate it into the\ngeneration context of T2I models. By orienting model generations using the\nreflected historical truths, FAI significantly improves the demographic\nfactuality under diversity interventions while preserving diversity.", "published": "2024-06-29 09:09:42", "link": "http://arxiv.org/abs/2407.00377v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and\n  Efficient Evaluation", "abstract": "Large Multimodal Models (LMMs) exhibit impressive cross-modal understanding\nand reasoning abilities, often assessed through multiple-choice questions\n(MCQs) that include an image, a question, and several options. However, many\nbenchmarks used for such evaluations suffer from systematic biases. Remarkably,\nLarge Language Models (LLMs) without any visual perception capabilities achieve\nnon-trivial performance, undermining the credibility of these evaluations. To\naddress this issue while maintaining the efficiency of MCQ evaluations, we\npropose MMEvalPro, a benchmark designed to avoid Type-I errors through a\ntrilogy evaluation pipeline and more rigorous metrics. For each original\nquestion from existing benchmarks, human annotators augment it by creating one\nperception question and one knowledge anchor question through a meticulous\nannotation process. MMEvalPro comprises $2,138$ question triplets, totaling\n$6,414$ distinct questions. Two-thirds of these questions are manually labeled\nby human experts, while the rest are sourced from existing benchmarks (MMMU,\nScienceQA, and MathVista). Compared with the existing benchmarks, our\nexperiments with the latest LLMs and LMMs demonstrate that MMEvalPro is more\nchallenging (the best LMM lags behind human performance by $31.73\\%$, compared\nto an average gap of $8.03\\%$ in previous benchmarks) and more trustworthy (the\nbest LLM trails the best LMM by $23.09\\%$, whereas the gap for previous\nbenchmarks is just $14.64\\%$). Our in-depth analysis explains the reason for\nthe large performance gap and justifies the trustworthiness of evaluation,\nunderscoring its significant potential for advancing future research.", "published": "2024-06-29 15:28:45", "link": "http://arxiv.org/abs/2407.00468v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Large Language Models for Power Scheduling: A User-Centric Approach", "abstract": "While traditional optimization and scheduling schemes are designed to meet\nfixed, predefined system requirements, future systems are moving toward\nuser-driven approaches and personalized services, aiming to achieve high\nquality-of-experience (QoE) and flexibility. This challenge is particularly\npronounced in wireless and digitalized energy networks, where users'\nrequirements have largely not been taken into consideration due to the lack of\na common language between users and machines. The emergence of powerful large\nlanguage models (LLMs) marks a radical departure from traditional\nsystem-centric methods into more advanced user-centric approaches by providing\na natural communication interface between users and devices. In this paper, for\nthe first time, we introduce a novel architecture for resource scheduling\nproblems by constructing three LLM agents to convert an arbitrary user's voice\nrequest (VRQ) into a resource allocation vector. Specifically, we design an LLM\nintent recognition agent to translate the request into an optimization problem\n(OP), an LLM OP parameter identification agent, and an LLM OP solving agent. To\nevaluate system performance, we construct a database of typical VRQs in the\ncontext of electric vehicle (EV) charging. As a proof of concept, we primarily\nuse Llama 3 8B. Through testing with different prompt engineering scenarios,\nthe obtained results demonstrate the efficiency of the proposed architecture.\nThe conducted performance analysis allows key insights to be extracted. For\ninstance, having a larger set of candidate OPs to model the real-world problem\nmight degrade the final performance because of a higher recognition/OP\nclassification noise level. All results and codes are open source.", "published": "2024-06-29 15:47:28", "link": "http://arxiv.org/abs/2407.00476v3", "categories": ["cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.CL"}
{"title": "ConU: Conformal Uncertainty in Large Language Models with Correctness\n  Coverage Guarantees", "abstract": "Uncertainty quantification (UQ) in natural language generation (NLG) tasks\nremains an open challenge, exacerbated by the closed-source nature of the\nlatest large language models (LLMs). This study investigates applying conformal\nprediction (CP), which can transform any heuristic uncertainty notion into\nrigorous prediction sets, to black-box LLMs in open-ended NLG tasks. We\nintroduce a novel uncertainty measure based on self-consistency theory, and\nthen develop a conformal uncertainty criterion by integrating the uncertainty\ncondition aligned with correctness into the CP algorithm. Empirical evaluations\nindicate that our uncertainty measure outperforms prior state-of-the-art\nmethods. Furthermore, we achieve strict control over the correctness coverage\nrate utilizing 7 popular LLMs on 4 free-form NLG datasets, spanning\ngeneral-purpose and medical scenarios. Additionally, the calibrated prediction\nsets with small size further highlights the efficiency of our method in\nproviding trustworthy guarantees for practical open-ended NLG applications.", "published": "2024-06-29 17:33:07", "link": "http://arxiv.org/abs/2407.00499v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Answering real-world clinical questions using large language model based\n  systems", "abstract": "Evidence to guide healthcare decisions is often limited by a lack of relevant\nand trustworthy literature as well as difficulty in contextualizing existing\nresearch for a specific patient. Large language models (LLMs) could potentially\naddress both challenges by either summarizing published literature or\ngenerating new studies based on real-world data (RWD). We evaluated the ability\nof five LLM-based systems in answering 50 clinical questions and had nine\nindependent physicians review the responses for relevance, reliability, and\nactionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,\nGemini Pro 1.5) rarely produced answers that were deemed relevant and\nevidence-based (2% - 10%). In contrast, retrieval augmented generation\n(RAG)-based and agentic LLM systems produced relevant and evidence-based\nanswers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic\nChatRWD was able to answer novel questions compared to other LLMs (65% vs.\n0-9%). These results suggest that while general-purpose LLMs should not be used\nas-is, a purpose-built system for evidence summarization based on RAG and one\nfor generating novel evidence working synergistically would improve\navailability of pertinent evidence for patient care.", "published": "2024-06-29 22:39:20", "link": "http://arxiv.org/abs/2407.00541v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SPARKLE: Enhancing SPARQL Generation with Direct KG Integration in\n  Decoding", "abstract": "Existing KBQA methods have traditionally relied on multi-stage methodologies,\ninvolving tasks such as entity linking, subgraph retrieval and query structure\ngeneration. However, multi-stage approaches are dependent on the accuracy of\npreceding steps, leading to cascading errors and increased inference time.\nAlthough a few studies have explored the use of end-to-end models, they often\nsuffer from lower accuracy and generate inoperative query that is not supported\nby the underlying data. Furthermore, most prior approaches are limited to the\nstatic training data, potentially overlooking the evolving nature of knowledge\nbases over time. To address these challenges, we present a novel end-to-end\nnatural language to SPARQL framework, SPARKLE. Notably SPARKLE leverages the\nstructure of knowledge base directly during the decoding, effectively\nintegrating knowledge into the query generation. Our study reveals that simply\nreferencing knowledge base during inference significantly reduces the\noccurrence of inexecutable query generations. SPARKLE achieves new\nstate-of-the-art results on SimpleQuestions-Wiki and highest F1 score on LCQuAD\n1.0 (among models not using gold entities), while getting slightly lower result\non the WebQSP dataset. Finally, we demonstrate SPARKLE's fast inference speed\nand its ability to adapt when the knowledge base differs between the training\nand inference stages.", "published": "2024-06-29 06:43:11", "link": "http://arxiv.org/abs/2407.01626v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables", "abstract": "Tabular reasoning involves interpreting natural language queries about\ntabular data, which presents a unique challenge of combining language\nunderstanding with structured data analysis. Existing methods employ either\ntextual reasoning, which excels in semantic interpretation but struggles with\nmathematical operations, or symbolic reasoning, which handles computations well\nbut lacks semantic understanding. This paper introduces a novel algorithm\nH-STAR that integrates both symbolic and semantic (textual) approaches in a\ntwo-stage process to address these limitations. H-STAR employs: (1) step-wise\ntable extraction using `multi-view' column retrieval followed by row\nextraction, and (2) adaptive reasoning that adapts reasoning strategies based\non question types, utilizing semantic reasoning for direct lookup and complex\nlexical queries while augmenting textual reasoning with symbolic reasoning\nsupport for quantitative and logical tasks. Our extensive experiments\ndemonstrate that H-STAR significantly outperforms state-of-the-art methods\nacross three tabular question-answering (QA) and fact-verification datasets,\nunderscoring its effectiveness and efficiency.", "published": "2024-06-29 21:24:19", "link": "http://arxiv.org/abs/2407.05952v3", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Error Correction by Paying Attention to Both Acoustic and Confidence\n  References for Automatic Speech Recognition", "abstract": "Accurately finding the wrong words in the automatic speech recognition (ASR)\nhypothesis and recovering them well-founded is the goal of speech error\ncorrection. In this paper, we propose a non-autoregressive speech error\ncorrection method. A Confidence Module measures the uncertainty of each word of\nthe N-best ASR hypotheses as the reference to find the wrong word position.\nBesides, the acoustic feature from the ASR encoder is also used to provide the\ncorrect pronunciation references. N-best candidates from ASR are aligned using\nthe edit path, to confirm each other and recover some missing character errors.\nFurthermore, the cross-attention mechanism fuses the information between error\ncorrection references and the ASR hypothesis. The experimental results show\nthat both the acoustic and confidence references help with error correction.\nThe proposed system reduces the error rate by 21% compared with the ASR model.", "published": "2024-06-29 17:56:28", "link": "http://arxiv.org/abs/2407.12817v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Open-Source Conversational AI with SpeechBrain 1.0", "abstract": "SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,\nfocused particularly on speech processing tasks such as speech recognition,\nspeech enhancement, speaker recognition, text-to-speech, and much more. It\npromotes transparency and replicability by releasing both the pre-trained\nmodels and the complete \"recipes\" of code and algorithms required for training\nthem. This paper presents SpeechBrain 1.0, a significant milestone in the\nevolution of the toolkit, which now has over 200 recipes for speech, audio, and\nlanguage processing tasks, and more than 100 models available on Hugging Face.\nSpeechBrain 1.0 introduces new technologies to support diverse learning\nmodalities, Large Language Model (LLM) integration, and advanced decoding\nstrategies, along with novel models, tasks, and modalities. It also includes a\nnew benchmark repository, offering researchers a unified platform for\nevaluating models across diverse tasks.", "published": "2024-06-29 15:20:11", "link": "http://arxiv.org/abs/2407.00463v5", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC", "eess.AS"], "primary_category": "cs.LG"}
{"title": "FMSG-JLESS Submission for DCASE 2024 Task4 on Sound Event Detection with\n  Heterogeneous Training Dataset and Potentially Missing Labels", "abstract": "This report presents the systems developed and submitted by Fortemedia\nSingapore (FMSG) and Joint Laboratory of Environmental Sound Sensing (JLESS)\nfor DCASE 2024 Task 4. The task focuses on recognizing event classes and their\ntime boundaries, given that multiple events can be present and may overlap in\nan audio recording. The novelty this year is a dataset with two sources, making\nit challenging to achieve good performance without knowing the source of the\naudio clips during evaluation. To address this, we propose a sound event\ndetection method using domain generalization. Our approach integrates features\nfrom bidirectional encoder representations from audio transformers and a\nconvolutional recurrent neural network. We focus on three main strategies to\nimprove our method. First, we apply mixstyle to the frequency dimension to\nadapt the mel-spectrograms from different domains. Second, we consider training\nloss of our model specific to each datasets for their corresponding classes.\nThis independent learning framework helps the model extract domain-specific\nfeatures effectively. Lastly, we use the sound event bounding boxes method for\npost-processing. Our proposed method shows superior macro-average pAUC and\npolyphonic SED score performance on the DCASE 2024 Challenge Task 4 validation\ndataset and public evaluation dataset.", "published": "2024-06-29 03:11:00", "link": "http://arxiv.org/abs/2407.00291v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Characterizing Continual Learning Scenarios and Strategies for Audio\n  Analysis", "abstract": "Audio analysis is useful in many application scenarios. The state-of-the-art\naudio analysis approaches assume the data distribution at training and\ndeployment time will be the same. However, due to various real-life challenges,\nthe data may encounter drift in its distribution or can encounter new classes\nin the late future. Thus, a one-time trained model might not perform\nadequately. Continual learning (CL) approaches are devised to handle such\nchanges in data distribution. There have been a few attempts to use CL\napproaches for audio analysis. Yet, there is a lack of a systematic evaluation\nframework. In this paper, we create a comprehensive CL dataset and characterize\nCL approaches for audio-based monitoring tasks. We have investigated the\nfollowing CL and non-CL approaches: EWC, LwF, SI, GEM, A-GEM, GDumb, Replay,\nNaive, Cumulative, and Joint training. The study is very beneficial for\nresearchers and practitioners working in the area of audio analysis for\ndeveloping adaptive models. We observed that Replay achieved better results\nthan other methods in the DCASE challenge data. It achieved an accuracy of\n70.12% for the domain incremental scenario and an accuracy of 96.98% for the\nclass incremental scenario.", "published": "2024-06-29 15:21:20", "link": "http://arxiv.org/abs/2407.00465v2", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Interpreting Pretrained Speech Models for Automatic Speech Assessment of\n  Voice Disorders", "abstract": "Speech contains information that is clinically relevant to some diseases,\nwhich has the potential to be used for health assessment. Recent work shows an\ninterest in applying deep learning algorithms, especially pretrained large\nspeech models to the applications of Automatic Speech Assessment. One question\nthat has not been explored is how these models output the results based on\ntheir inputs. In this work, we train and compare two configurations of Audio\nSpectrogram Transformer in the context of Voice Disorder Detection and apply\nthe attention rollout method to produce model relevance maps, the computed\nrelevance of the spectrogram regions when the model makes predictions. We use\nthese maps to analyse how models make predictions in different conditions and\nto show that the spread of attention is reduced as a model is finetuned, and\nthe model attention is concentrated on specific phoneme regions.", "published": "2024-06-29 21:14:48", "link": "http://arxiv.org/abs/2407.00531v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting and Identifying Selection Structure in Sequential Data", "abstract": "We argue that the selective inclusion of data points based on latent\nobjectives is common in practical situations, such as music sequences. Since\nthis selection process often distorts statistical analysis, previous work\nprimarily views it as a bias to be corrected and proposes various methods to\nmitigate its effect. However, while controlling this bias is crucial, selection\nalso offers an opportunity to provide a deeper insight into the hidden\ngeneration process, as it is a fundamental mechanism underlying what we\nobserve. In particular, overlooking selection in sequential data can lead to an\nincomplete or overcomplicated inductive bias in modeling, such as assuming a\nuniversal autoregressive structure for all dependencies. Therefore, rather than\nmerely viewing it as a bias, we explore the causal structure of selection in\nsequential data to delve deeper into the complete causal process. Specifically,\nwe show that selection structure is identifiable without any parametric\nassumptions or interventional experiments. Moreover, even in cases where\nselection variables coexist with latent confounders, we still establish the\nnonparametric identifiability under appropriate structural conditions.\nMeanwhile, we also propose a provably correct algorithm to detect and identify\nselection structures as well as other types of dependencies. The framework has\nbeen validated empirically on both synthetic data and real-world music.", "published": "2024-06-29 20:56:34", "link": "http://arxiv.org/abs/2407.00529v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
