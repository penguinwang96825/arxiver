{"title": "End-to-End Training Approaches for Discriminative Segmental Models", "abstract": "Recent work on discriminative segmental models has shown that they can\nachieve competitive speech recognition performance, using features based on\ndeep neural frame classifiers. However, segmental models can be more\nchallenging to train than standard frame-based approaches. While some segmental\nmodels have been successfully trained end to end, there is a lack of\nunderstanding of their training under different settings and with different\nlosses.\n  We investigate a model class based on recent successful approaches,\nconsisting of a linear model that combines segmental features based on an LSTM\nframe classifier. Similarly to hybrid HMM-neural network models, segmental\nmodels of this class can be trained in two stages (frame classifier training\nfollowed by linear segmental model weight training), end to end (joint training\nof both frame classifier and linear weights), or with end-to-end fine-tuning\nafter two-stage training.\n  We study segmental models trained end to end with hinge loss, log loss,\nlatent hinge loss, and marginal log loss. We consider several losses for the\ncase where training alignments are available as well as where they are not.\n  We find that in general, marginal log loss provides the most consistent\nstrong performance without requiring ground-truth alignments. We also find that\ntraining with dropout is very important in obtaining good performance with\nend-to-end training. Finally, the best results are typically obtained by a\ncombination of two-stage training and fine-tuning.", "published": "2016-10-21 08:45:35", "link": "http://arxiv.org/abs/1610.06700v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Automated Big Text Security Classification", "abstract": "In recent years, traditional cybersecurity safeguards have proven ineffective\nagainst insider threats. Famous cases of sensitive information leaks caused by\ninsiders, including the WikiLeaks release of diplomatic cables and the Edward\nSnowden incident, have greatly harmed the U.S. government's relationship with\nother governments and with its own citizens. Data Leak Prevention (DLP) is a\nsolution for detecting and preventing information leaks from within an\norganization's network. However, state-of-art DLP detection models are only\nable to detect very limited types of sensitive information, and research in the\nfield has been hindered due to the lack of available sensitive texts. Many\nresearchers have focused on document-based detection with artificially labeled\n\"confidential documents\" for which security labels are assigned to the entire\ndocument, when in reality only a portion of the document is sensitive. This\ntype of whole-document based security labeling increases the chances of\npreventing authorized users from accessing non-sensitive information within\nsensitive documents. In this paper, we introduce Automated Classification\nEnabled by Security Similarity (ACESS), a new and innovative detection model\nthat penetrates the complexity of big text security classification/detection.\nTo analyze the ACESS system, we constructed a novel dataset, containing\nformerly classified paragraphs from diplomatic cables made public by the\nWikiLeaks organization. To our knowledge this paper is the first to analyze a\ndataset that contains actual formerly sensitive information annotated at\nparagraph granularity.", "published": "2016-10-21 16:53:09", "link": "http://arxiv.org/abs/1610.06856v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CR"}
