{"title": "Context-Aware Self-Attention Networks", "abstract": "Self-attention model have shown its flexibility in parallel computation and\nthe effectiveness on modeling both long- and short-term dependencies. However,\nit calculates the dependencies between representations without considering the\ncontextual information, which have proven useful for modeling dependencies\namong neural representations in various natural language tasks. In this work,\nwe focus on improving self-attention networks through capturing the richness of\ncontext. To maintain the simplicity and flexibility of the self-attention\nnetworks, we propose to contextualize the transformations of the query and key\nlayers, which are used to calculates the relevance between elements.\nSpecifically, we leverage the internal representations that embed both global\nand deep contexts, thus avoid relying on external resources. Experimental\nresults on WMT14 English-German and WMT17 Chinese-English translation tasks\ndemonstrate the effectiveness and universality of the proposed methods.\nFurthermore, we conducted extensive analyses to quantity how the context\nvectors participate in the self-attention model.", "published": "2019-02-15 11:03:52", "link": "http://arxiv.org/abs/1902.05766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Word Representations: A Contextual Introduction", "abstract": "This introduction aims to tell the story of how we put words into computers.\nIt is part of the story of the field of natural language processing (NLP), a\nbranch of artificial intelligence. It targets a wide audience with a basic\nunderstanding of computer programming, but avoids a detailed mathematical\ntreatment, and it does not present any algorithms. It also does not focus on\nany particular application of NLP such as translation, question answering, or\ninformation extraction. The ideas presented here were developed by many\nresearchers over many decades, so the citations are not exhaustive but rather\ndirect the reader to a handful of papers that are, in the author's view,\nseminal. After reading this document, you should have a general understanding\nof word vectors (also known as word embeddings): why they exist, what problems\nthey solve, where they come from, how they have changed over time, and what\nsome of the open questions about them are. Readers already familiar with word\nvectors are advised to skip to Section 5 for the discussion of the most recent\nadvance, contextual word vectors.", "published": "2019-02-15 23:28:36", "link": "http://arxiv.org/abs/1902.06006v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Natural Language Explanations for Visual Question Answering\n  using Scene Graphs and Visual Attention", "abstract": "In this paper, we present a novel approach for the task of eXplainable\nQuestion Answering (XQA), i.e., generating natural language (NL) explanations\nfor the Visual Question Answering (VQA) problem. We generate NL explanations\ncomprising of the evidence to support the answer to a question asked to an\nimage using two sources of information: (a) annotations of entities in an image\n(e.g., object labels, region descriptions, relation phrases) generated from the\nscene graph of the image, and (b) the attention map generated by a VQA model\nwhen answering the question. We show how combining the visual attention map\nwith the NL representation of relevant scene graph entities, carefully selected\nusing a language model, can give reasonable textual explanations without the\nneed of any additional collected data (explanation captions, etc). We run our\nalgorithms on the Visual Genome (VG) dataset and conduct internal user-studies\nto demonstrate the efficacy of our approach over a strong baseline. We have\nalso released a live web demo showcasing our VQA and textual explanation\ngeneration using scene graphs and visual attention.", "published": "2019-02-15 07:59:11", "link": "http://arxiv.org/abs/1902.05715v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic Layer Aggregation for Neural Machine Translation with\n  Routing-by-Agreement", "abstract": "With the promising progress of deep neural networks, layer aggregation has\nbeen used to fuse information across layers in various fields, such as computer\nvision and machine translation. However, most of the previous methods combine\nlayers in a static fashion in that their aggregation strategy is independent of\nspecific hidden states. Inspired by recent progress on capsule networks, in\nthis paper we propose to use routing-by-agreement strategies to aggregate\nlayers dynamically. Specifically, the algorithm learns the probability of a\npart (individual layer representations) assigned to a whole (aggregated\nrepresentations) in an iterative way and combines parts accordingly. We\nimplement our algorithm on top of the state-of-the-art neural machine\ntranslation model TRANSFORMER and conduct experiments on the widely-used WMT14\nEnglish-German and WMT17 Chinese-English translation datasets. Experimental\nresults across language pairs show that the proposed approach consistently\noutperforms the strong baseline model and a representative static aggregation\nmodel.", "published": "2019-02-15 11:14:35", "link": "http://arxiv.org/abs/1902.05770v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Semantic Parsing for Task Oriented Dialog", "abstract": "Semantic parsing using hierarchical representations has recently been\nproposed for task oriented dialog with promising results [Gupta et al 2018]. In\nthis paper, we present three different improvements to the model:\ncontextualized embeddings, ensembling, and pairwise re-ranking based on a\nlanguage model. We taxonomize the errors possible for the hierarchical\nrepresentation, such as wrong top intent, missing spans or split spans, and\nshow that the three approaches correct different kinds of errors. The best\nmodel combines the three techniques and gives 6.4% better exact match accuracy\nthan the state-of-the-art, with an error reduction of 33%, resulting in a new\nstate-of-the-art result on the Task Oriented Parsing (TOP) dataset.", "published": "2019-02-15 22:54:32", "link": "http://arxiv.org/abs/1902.06000v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An improved uncertainty propagation method for robust i-vector based\n  speaker recognition", "abstract": "The performance of automatic speaker recognition systems degrades when facing\ndistorted speech data containing additive noise and/or reverberation.\nStatistical uncertainty propagation has been introduced as a promising paradigm\nto address this challenge. So far, different uncertainty propagation methods\nhave been proposed to compensate noise and reverberation in i-vectors in the\ncontext of speaker recognition. They have achieved promising results on small\ndatasets such as YOHO and Wall Street Journal, but little or no improvement on\nthe larger, highly variable NIST Speaker Recognition Evaluation (SRE) corpus.\nIn this paper, we propose a complete uncertainty propagation method, whereby we\nmodel the effect of uncertainty both in the computation of unbiased Baum-Welch\nstatistics and in the derivation of the posterior expectation of the i-vector.\nWe conduct experiments on the NIST-SRE corpus mixed with real domestic noise\nand reverberation from the CHiME-2 corpus and preprocessed by multichannel\nspeech enhancement. The proposed method improves the equal error rate (EER) by\n4% relative compared to a conventional i-vector based speaker verification\nbaseline. This is to be compared with previous methods which degrade\nperformance.", "published": "2019-02-15 10:45:02", "link": "http://arxiv.org/abs/1902.05761v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
