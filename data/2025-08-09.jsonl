{"title": "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution", "abstract": "Large language models (LLMs) have achieved impressive performance, leading to\ntheir widespread adoption as decision-support tools in resource-constrained\ncontexts like hiring and admissions. There is, however, scientific consensus\nthat AI systems can reflect and exacerbate societal biases, raising concerns\nabout identity-based harm when used in critical social contexts. Prior work has\nlaid a solid foundation for assessing bias in LLMs by evaluating demographic\ndisparities in different language reasoning tasks. In this work, we extend\nsingle-axis fairness evaluations to examine intersectional bias, recognizing\nthat when multiple axes of discrimination intersect, they create distinct\npatterns of disadvantage. We create a new benchmark called WinoIdentity by\naugmenting the WinoBias dataset with 25 demographic markers across 10\nattributes, including age, nationality, and race, intersected with binary\ngender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.\nFocusing on harms of omission due to underrepresentation, we investigate bias\nthrough the lens of uncertainty and propose a group (un)fairness metric called\nCoreference Confidence Disparity which measures whether models are more or less\nconfident for some intersectional identities than others. We evaluate five\nrecently published LLMs and find confidence disparities as high as 40% along\nvarious demographic attributes including body type, sexual orientation and\nsocio-economic status, with models being most uncertain about\ndoubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,\ncoreference confidence decreases even for hegemonic or privileged markers,\nindicating that the recent impressive performance of LLMs is more likely due to\nmemorization than logical reasoning. Notably, these are two independent\nfailures in value alignment and validity that can compound to cause social\nharm.", "published": "2025-08-09 22:24:40", "link": "http://arxiv.org/abs/2508.07111v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning", "abstract": "Large reasoning models achieve strong performance through test-time scaling\nbut incur substantial computational overhead, particularly from excessive token\ngeneration when processing short input prompts. While sparse attention\nmechanisms can reduce latency and memory usage, existing approaches suffer from\nsignificant accuracy degradation due to accumulated errors during\nlong-generation reasoning. These methods generally require either high token\nretention rates or expensive retraining. We introduce LessIsMore, a\ntraining-free sparse attention mechanism for reasoning tasks, which leverages\nglobal attention patterns rather than relying on traditional head-specific\nlocal optimizations. LessIsMore aggregates token selections from local\nattention heads with recent contextual information, enabling unified cross-head\ntoken ranking for future decoding layers. This unified selection improves\ngeneralization and efficiency by avoiding the need to maintain separate token\nsubsets per head. Evaluation across diverse reasoning tasks and benchmarks\nshows that LessIsMore preserves -- and in some cases improves -- accuracy while\nachieving a $1.1\\times$ average decoding speed-up compared to full attention.\nMoreover, LessIsMore attends to $2\\times$ fewer tokens without accuracy loss,\nachieving a $1.13\\times$ end-to-end speed-up compared to existing sparse\nattention methods.", "published": "2025-08-09 21:10:33", "link": "http://arxiv.org/abs/2508.07101v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context", "abstract": "Evaluating social biases in language models (LMs) is crucial for ensuring\nfairness and minimizing the reinforcement of harmful stereotypes in AI systems.\nExisting benchmarks, such as the Bias Benchmark for Question Answering (BBQ),\nprimarily focus on Western contexts, limiting their applicability to the Indian\ncontext. To address this gap, we introduce BharatBBQ, a culturally adapted\nbenchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,\nTelugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3\nintersectional groups, reflecting prevalent biases in the Indian sociocultural\nlandscape. Our dataset contains 49,108 examples in one language that are\nexpanded using translation and verification to 392,864 examples in eight\ndifferent languages. We evaluate five multilingual LM families across zero and\nfew-shot settings, analyzing their bias and stereotypical bias scores. Our\nfindings highlight persistent biases across languages and social categories and\noften amplified biases in Indian languages compared to English, demonstrating\nthe necessity of linguistically and culturally grounded benchmarks for bias\nevaluation.", "published": "2025-08-09 20:24:24", "link": "http://arxiv.org/abs/2508.07090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQL-Exchange: Transforming SQL Queries Across Domains", "abstract": "We introduce SQL-Exchange, a framework for mapping SQL queries across\ndifferent database schemas by preserving the source query structure while\nadapting domain-specific elements to align with the target schema. We\ninvestigate the conditions under which such mappings are feasible and\nbeneficial, and examine their impact on enhancing the in-context learning\nperformance of text-to-SQL systems as a downstream task. Our comprehensive\nevaluation across multiple model families and benchmark datasets--assessing\nstructural alignment with source queries, execution validity on target\ndatabases, and semantic correctness--demonstrates that SQL-Exchange is\neffective across a wide range of schemas and query types. Our results further\nshow that using mapped queries as in-context examples consistently improves\ntext-to-SQL performance over using queries from the source schema.", "published": "2025-08-09 19:55:54", "link": "http://arxiv.org/abs/2508.07087v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages", "abstract": "Although numerous datasets have been developed to support dialogue systems,\nmost existing chit-chat datasets overlook the cultural nuances inherent in\nnatural human conversations. To address this gap, we introduce SEADialogues, a\nculturally grounded dialogue dataset centered on Southeast Asia, a region with\nover 700 million people and immense cultural diversity. Our dataset features\ndialogues in eight languages from six Southeast Asian countries, many of which\nare low-resource despite having sizable speaker populations. To enhance\ncultural relevance and personalization, each dialogue includes persona\nattributes and two culturally grounded topics that reflect everyday life in the\nrespective communities. Furthermore, we release a multi-turn dialogue dataset\nto advance research on culturally aware and human-centric large language\nmodels, including conversational dialogue agents.", "published": "2025-08-09 18:22:35", "link": "http://arxiv.org/abs/2508.07069v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "abstract": "Large Language Model (LLM) based listwise ranking has shown superior\nperformance in many passage ranking tasks. With the development of Large\nReasoning Models, many studies have demonstrated that step-by-step reasoning\nduring test-time helps improve listwise ranking performance. However, due to\nthe scarcity of reasoning-intensive training data, existing rerankers perform\npoorly in many complex ranking scenarios and the ranking ability of\nreasoning-intensive rerankers remains largely underdeveloped. In this paper, we\nfirst propose an automated reasoning-intensive training data synthesis\nframework, which sources training queries and passages from diverse domains and\napplies DeepSeek-R1 to generate high-quality training labels. A\nself-consistency data filtering mechanism is designed to ensure the data\nquality. To empower the listwise reranker with strong reasoning ability, we\nfurther propose a two-stage post-training approach, which includes a cold-start\nsupervised fine-tuning (SFT) stage for reasoning pattern learning and a\nreinforcement learning (RL) stage for further ranking ability enhancement.\nDuring the RL stage, based on the nature of listwise ranking, we design a\nmulti-view ranking reward, which is more effective than a ranking metric-based\nreward. Extensive experiments demonstrate that our trained reasoning-intensive\nreranker \\textbf{ReasonRank} outperforms existing baselines significantly and\nalso achieves much lower latency than pointwise reranker Rank1. \\textbf{Through\nfurther experiments, our ReasonRank has achieved state-of-the-art (SOTA)\nperformance 40.6 on the BRIGHT\nleaderboard\\footnote{https://brightbenchmark.github.io/}.} Our codes are\navailable at https://github.com/8421BCD/ReasonRank.", "published": "2025-08-09 17:26:18", "link": "http://arxiv.org/abs/2508.07050v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA", "abstract": "Knowledge editing (KE) provides a scalable approach for updating factual\nknowledge in large language models without full retraining. While previous\nstudies have demonstrated effectiveness in general domains and medical QA\ntasks, little attention has been paid to KE in multimodal medical scenarios.\nUnlike text-only settings, medical KE demands integrating updated knowledge\nwith visual reasoning to support safe and interpretable clinical decisions. To\naddress this gap, we propose MultiMedEdit, the first benchmark tailored to\nevaluating KE in clinical multimodal tasks. Our framework spans both\nunderstanding and reasoning task types, defines a three-dimensional metric\nsuite (reliability, generality, and locality), and supports cross-paradigm\ncomparisons across general and domain-specific models. We conduct extensive\nexperiments under single-editing and lifelong-editing settings. Results suggest\nthat current methods struggle with generalization and long-tail reasoning,\nparticularly in complex clinical workflows. We further present an efficiency\nanalysis (e.g., edit latency, memory footprint), revealing practical trade-offs\nin real-world deployment across KE paradigms. Overall, MultiMedEdit not only\nreveals the limitations of current approaches but also provides a solid\nfoundation for developing clinically robust knowledge editing techniques in the\nfuture.", "published": "2025-08-09 15:36:08", "link": "http://arxiv.org/abs/2508.07022v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.AI"}
{"title": "Convergence Sans Synchronization", "abstract": "We currently see a steady rise in the usage and size of multiprocessor\nsystems, and so the community is evermore interested in developing fast\nparallel processing algorithms. However, most algorithms require a\nsynchronization mechanism, which is costly in terms of computational resources\nand time. If an algorithm can be executed in asynchrony, then it can use all\nthe available computation power, and the nodes can execute without being\nscheduled or locked. However, to show that an algorithm guarantees convergence\nin asynchrony, we need to generate the entire global state transition graph and\ncheck for the absence of cycles. This takes time exponential in the size of the\nglobal state space. In this dissertation, we present a theory that explains the\nnecessary and sufficient properties of a multiprocessor algorithm that\nguarantees convergence even without synchronization. We develop algorithms for\nvarious problems that do not require synchronization. Additionally, we show for\nseveral existing algorithms that they can be executed without any\nsynchronization mechanism. A significant theoretical benefit of our work is in\nproving that an algorithm can converge even in asynchrony. Our theory implies\nthat we can make such conclusions about an algorithm, by only showing that the\nlocal state transition graph of a computing node forms a partial order, rather\nthan generating the entire global state space and determining the absence of\ncycles in it. Thus, the complexity of rendering such proofs, formal or social,\nis phenomenally reduced. Experiments show a significant reduction in time taken\nto converge, when we compare the execution time of algorithms in the literature\nversus the algorithms that we design. We get similar results when we run an\nalgorithm, that guarantees convergence in asynchrony, under a scheduler versus\nin asynchrony.", "published": "2025-08-09 11:46:53", "link": "http://arxiv.org/abs/2508.06949v1", "categories": ["cs.DC", "cs.DM"], "primary_category": "cs.DC"}
{"title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization", "abstract": "Local search is an important class of incomplete algorithms for solving\nDistributed Constraint Optimization Problems (DCOPs) but it often converges to\npoor local optima. While GDBA provides a comprehensive rule set to escape\npremature convergence, its empirical benefits remain marginal on general-valued\nproblems. In this work, we systematically examine GDBA and identify three\nfactors that potentially lead to its inferior performance, i.e.,\nover-aggressive constraint violation conditions, unbounded penalty\naccumulation, and uncoordinated penalty updates. To address these issues, we\npropose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs\nthat incorporates an adaptive violation condition to selectively penalize\nconstraints with high cost, a penalty evaporation mechanism to control the\nmagnitude of penalization, and a synchronization scheme for coordinated penalty\nupdates. We theoretically show that the penalty values are bounded, and agents\nplay a potential game in our DGLS. Our extensive empirical results on various\nstandard benchmarks demonstrate the great superiority of DGLS over\nstate-of-the-art baselines. Particularly, compared to Damped Max-sum with high\ndamping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance\non general-valued problems, and outperforms it by significant margins\n(\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.", "published": "2025-08-09 09:12:06", "link": "http://arxiv.org/abs/2508.06899v1", "categories": ["cs.AI", "cs.DM"], "primary_category": "cs.AI"}
{"title": "TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations", "abstract": "Time series forecasting is critical across various domains, such as weather,\nfinance and real estate forecasting, as accurate forecasts support informed\ndecision-making and risk mitigation. While recent deep learning models have\nimproved predictive capabilities, they often overlook time-lagged\ncross-correlations between related sequences, which are crucial for capturing\ncomplex temporal relationships. To address this, we propose the Time-Lagged\nCross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances\nforecasting accuracy by effectively integrating time-lagged cross-correlated\nsequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)\nalgorithm to capture lagged correlations and a contrastive learning-based\nencoder to efficiently approximate SSDTW distances.\n  Experimental results on weather, finance and real estate time series datasets\ndemonstrate the effectiveness of our framework. On the weather dataset, SSDTW\nreduces mean squared error (MSE) by 16.01% compared with single-sequence\nmethods, while the contrastive learning encoder (CLE) further decreases MSE by\n17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE\nreduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by\n21.29% and 8.62%, respectively. Additionally, the contrastive learning approach\ndecreases SSDTW computational time by approximately 99%, ensuring scalability\nand real-time applicability across multiple time series forecasting tasks.", "published": "2025-08-09 15:29:14", "link": "http://arxiv.org/abs/2508.07016v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction", "abstract": "Quranic Question Answering presents unique challenges due to the linguistic\ncomplexity of Classical Arabic and the semantic richness of religious texts. In\nthis paper, we propose a novel two-stage framework that addresses both passage\nretrieval and answer extraction. For passage retrieval, we ensemble fine-tuned\nArabic language models to achieve superior ranking performance. For answer\nextraction, we employ instruction-tuned large language models with few-shot\nprompting to overcome the limitations of fine-tuning on small datasets. Our\napproach achieves state-of-the-art results on the Quran QA 2023 Shared Task,\nwith a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of\n0.669 for extraction, substantially outperforming previous methods. These\nresults demonstrate that combining model ensembling and instruction-tuned\nlanguage models effectively addresses the challenges of low-resource question\nanswering in specialized domains.", "published": "2025-08-09 12:37:19", "link": "http://arxiv.org/abs/2508.06971v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Blending Sequential Embeddings, Graphs, and Engineered Features: 4th Place Solution in RecSys Challenge 2025", "abstract": "This paper describes the 4th-place solution by team ambitious for the RecSys\nChallenge 2025, organized by Synerise and ACM RecSys, which focused on\nuniversal behavioral modeling. The challenge objective was to generate user\nembeddings effective across six diverse downstream tasks. Our solution\nintegrates (1) a sequential encoder to capture the temporal evolution of user\ninterests, (2) a graph neural network to enhance generalization, (3) a deep\ncross network to model high-order feature interactions, and (4)\nperformance-critical feature engineering.", "published": "2025-08-09 12:35:52", "link": "http://arxiv.org/abs/2508.06970v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CLAP: Coreference-Linked Augmentation for Passage Retrieval", "abstract": "Large Language Model (LLM)-based passage expansion has shown promise for\nenhancing first-stage retrieval, but often underperforms with dense retrievers\ndue to semantic drift and misalignment with their pretrained semantic space.\nBeyond this, only a portion of a passage is typically relevant to a query,\nwhile the rest introduces noise--an issue compounded by chunking techniques\nthat break coreference continuity. We propose Coreference-Linked Augmentation\nfor Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that\nsegments passages into coherent chunks, resolves coreference chains, and\ngenerates localized pseudo-queries aligned with dense retriever\nrepresentations. A simple fusion of global topical signals and fine-grained\nsubtopic signals achieves robust performance across domains. CLAP yields\nconsistent gains even as retriever strength increases, enabling dense\nretrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B,\nwith up to 20.68% absolute nDCG@10 improvement. These improvements are\nespecially notable in out-of-domain settings, where conventional LLM-based\nexpansion methods relying on domain knowledge often falter. CLAP instead adopts\na logic-centric pipeline that enables robust, domain-agnostic generalization.", "published": "2025-08-09 11:26:10", "link": "http://arxiv.org/abs/2508.06941v1", "categories": ["cs.IR", "cs.AI", "68T50", "I.2.7; H.3.3"], "primary_category": "cs.IR"}
{"title": "The ReQAP System for Question Answering over Personal Information", "abstract": "Personal information is abundant on users' devices, from structured data in\ncalendar, shopping records or fitness tools, to unstructured contents in mail\nand social media posts. This works presents the ReQAP system that supports\nusers with answers for complex questions that involve filters, joins and\naggregation over heterogeneous sources. The unique trait of ReQAP is that it\nrecursively decomposes questions and incrementally builds an operator tree for\nexecution. Both the question interpretation and the individual operators make\nsmart use of light-weight language models, with judicious fine-tuning. The demo\nshowcases the rich functionality for advanced user questions, and also offers\ndetailed tracking of how the answers are computed by the operators in the\nexecution tree. Being able to trace answers back to the underlying sources is\nvital for human comprehensibility and user trust in the system.", "published": "2025-08-09 08:21:53", "link": "http://arxiv.org/abs/2508.06880v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation", "abstract": "Neural sentence embedding models for dense retrieval typically rely on binary\nrelevance labels, treating query-document pairs as either relevant or\nirrelevant. However, real-world relevance often exists on a continuum, and\nrecent advances in large language models (LLMs) have made it feasible to scale\nthe generation of fine-grained graded relevance labels. In this work, we\npropose BiXSE, a simple and effective pointwise training method that optimizes\nbinary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE\ninterprets these scores as probabilistic targets, enabling granular supervision\nfrom a single labeled query-document pair per query. Unlike pairwise or\nlistwise losses that require multiple annotated comparisons per query, BiXSE\nachieves strong performance with reduced annotation and compute costs by\nleveraging in-batch negatives. Extensive experiments across sentence embedding\n(MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently\noutperforms softmax-based contrastive learning (InfoNCE), and matches or\nexceeds strong pairwise ranking baselines when trained on LLM-supervised data.\nBiXSE offers a robust, scalable alternative for training dense retrieval models\nas graded relevance supervision becomes increasingly accessible.", "published": "2025-08-09 02:15:17", "link": "http://arxiv.org/abs/2508.06781v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications", "abstract": "Reconfigurable Intelligent Surfaces (RISs) have emerged as a promising\ntechnology for next-generation wireless communications, offering\nenergy-efficient control of electromagnetic (EM) waves. While conventional RIS\nmodels based on phase shifts and amplitude adjustments have been widely\nstudied, they overlook complex EM phenomena such as mutual coupling, which are\ncrucial for advanced wave manipulations. Recent efforts in EM-consistent\nmodelling have provided more accurate representations of RIS behavior,\nhighlighting challenges like structural scattering-an unwanted signal\nreflection that can lead to interference. In this paper, we analyze the impact\nof structural scattering in RIS architectures and compare traditional and\nEM-consistent models through full-wave simulations, thus providing practical\ninsights on the realistic performance of current RIS designs. Our findings\nreveal the limitations of current modelling approaches in mitigating this\nissue, underscoring the need for new optimization strategies.", "published": "2025-08-09 21:02:31", "link": "http://arxiv.org/abs/2508.07098v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalized Quasi-Cyclic LDPC Codes: Design and Efficient Encoding", "abstract": "Generalized low-density parity-check (GLDPC) codes, where single parity-check\nconstraints on the code bits are replaced with generalized constraints (an\narbitrary linear code), are a promising class of codes for low-latency\ncommunication. The block error rate performance of the GLDPC codes, combined\nwith a complementary outer code, has been shown to outperform a variety of\nstate-of-the-art code and decoder designs with suitable lengths and rates for\nthe 5G ultra-reliable low-latency communication (URLLC) regime. A major\ndrawback of these codes is that it is not known how to construct appropriate\npolynomial matrices to encode them efficiently. In this paper, we analyze\npractical constructions of quasi-cyclic GLDPC (QC-GLDPC) codes and show how to\nconstruct polynomial generator matrices in various forms using minors of the\npolynomial matrix. The approach can be applied to fully generalized matrices or\npartially generalized (with mixed constraint node types) to find better\nperformance/rate trade-offs. The resulting encoding matrices are presented in\nuseful forms that facilitate efficient implementation. The rich substructure\ndisplayed also provides us with new methods of determining low weight\ncodewords, providing lower and upper bounds on the minimum distance and often\ngiving those of weight equal to the minimum distance. Based on the minors of\nthe polynomial parity-check matrix, we also give a formula for the rank of any\nparity-check matrix representing a QC-LDPC or QC-GLDPC code, and hence, the\ndimension of the code. Finally, we show that by applying double graph-liftings,\nthe code parameters can be improved without affecting the ability to obtain a\npolynomial generator matrix.", "published": "2025-08-09 16:03:39", "link": "http://arxiv.org/abs/2508.07030v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems", "abstract": "Intelligent Reflecting Surfaces (IRSs) have potential for significant\nperformance gains in next-generation wireless networks but face key challenges,\nnotably severe double-pathloss and complex multi-user scheduling due to\nhardware constraints. Active IRSs partially address pathloss but still require\nefficient scheduling in cell-level multi-IRS multi-user systems, whereby the\noverhead/delay of channel state acquisition and the scheduling complexity both\nrise dramatically as the user density and channel dimensions increase.\nMotivated by these challenges, this paper proposes a novel scheduling framework\nbased on neural Channel Knowledge Map (CKM), designing Transformer-based deep\nneural networks (DNNs) to predict ergodic spectral efficiency (SE) from\nhistorical channel/throughput measurements tagged with user positions.\nSpecifically, two cascaded networks, LPS-Net and SE-Net, are designed to\npredict link power statistics (LPS) and ergodic SE accurately. We further\npropose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling\nalgorithm. Numerical evaluations verify that the proposed neural CKM\nsignificantly enhances prediction accuracy and computational efficiency, while\nthe SM-IB algorithm effectively achieves near-optimal max-min throughput with\ngreatly reduced complexity.", "published": "2025-08-09 15:14:03", "link": "http://arxiv.org/abs/2508.07009v1", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Neural Beam Field for Spatial Beam RSRP Prediction", "abstract": "Accurately predicting beam-level reference signal received power (RSRP) is\nessential for beam management in dense multi-user wireless networks, yet\nchallenging due to high measurement overhead and fast channel variations. This\npaper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for\nefficient and interpretable spatial beam RSRP prediction. Central to our\napproach is the introduction of the Multi-path Conditional Power Profile\n(MCPP), which bridges site-specific multipath propagation with antenna/beam\nconfigurations via closed-form analytical modeling. We adopt a decoupled\n``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN)\nlearns the MCPP from sparse user measurements and positions, while a\nphysics-inspired module analytically infers beam RSRP statistics. To improve\nconvergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC)\nstrategy that leverages ray-tracing priors and on-site calibration using RSRP\ndata. Extensive simulations results demonstrate that NBF significantly\noutperforms conventional table-based channel knowledge maps (CKMs) and pure\nblackbox DNNs in prediction accuracy, training efficiency, and generalization,\nwhile maintaining a compact model size. The proposed framework offers a\nscalable and physically grounded solution for intelligent beam management in\nnext-generation dense wireless networks.", "published": "2025-08-09 12:05:51", "link": "http://arxiv.org/abs/2508.06956v1", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalized Samorodnitsky noisy function inequalities, with applications to error-correcting codes", "abstract": "An inequality by Samorodnitsky states that if $f : \\mathbb{F}_2^n \\to\n\\mathbb{R}$ is a nonnegative boolean function, and $S \\subseteq [n]$ is chosen\nby randomly including each coordinate with probability a certain $\\lambda =\n\\lambda(q,\\rho) < 1$, then \\begin{equation}\n  \\log \\|T_\\rho f\\|_q \\leq \\mathbb{E}_{S} \\log \\|\\mathbb{E}(f|S)\\|_q\\;.\n\\end{equation} Samorodnitsky's inequality has several applications to the\ntheory of error-correcting codes. Perhaps most notably, it can be used to show\nthat \\emph{any} binary linear code (with minimum distance $\\omega(\\log n)$)\nthat has vanishing decoding error probability on the BEC$(\\lambda)$ (binary\nerasure channel) also has vanishing decoding error on \\emph{all} memoryless\nsymmetric channels with capacity above some $C = C(\\lambda)$.\n  Samorodnitsky determined the optimal $\\lambda = \\lambda(q,\\rho)$ for his\ninequality in the case that $q \\geq 2$ is an integer. In this work, we\ngeneralize the inequality to $f : \\Omega^n \\to \\mathbb{R}$ under any product\nprobability distribution $\\mu^{\\otimes n}$ on $\\Omega^n$; moreover, we\ndetermine the optimal value of $\\lambda = \\lambda(q,\\mu,\\rho)$ for any real $q\n\\in [2,\\infty]$, $\\rho \\in [0,1]$, and distribution~$\\mu$. As one consequence,\nwe obtain the aforementioned coding theory result for linear codes over\n\\emph{any} finite alphabet.", "published": "2025-08-09 11:13:44", "link": "http://arxiv.org/abs/2508.06940v1", "categories": ["cs.IT", "math.IT", "68P30 (Primary) 68Q30, 94B70 (Secondary)"], "primary_category": "cs.IT"}
{"title": "Secure Transmission for Cell-Free Symbiotic Radio Communications with Movable Antenna: Continuous and Discrete Positioning Designs", "abstract": "In this paper, we study a movable antenna (MA) empowered secure transmission\nscheme for reconfigurable intelligent surface (RIS) aided cell-free symbiotic\nradio (SR) system. Specifically, the MAs deployed at distributed access points\n(APs) work collaboratively with the RIS to establish high-quality propagation\nlinks for both primary and secondary transmissions, as well as suppressing the\nrisk of eavesdropping on confidential primary information. We consider both\ncontinuous and discrete MA position cases and maximize the secrecy rate of\nprimary transmission under the secondary transmission constraints,\nrespectively. For the continuous position case, we propose a two-layer\niterative optimization method based on differential evolution with one-in-one\nrepresentation (DEO), to find a high-quality solution with relatively moderate\ncomputational complexity. For the discrete position case, we first extend the\nDEO based iterative framework by introducing the mapping and determination\noperations to handle the characteristic of discrete MA positions. To further\nreduce the computational complexity, we then design an alternating optimization\n(AO) iterative framework to solve all variables within a single layer. In\nparticular, we develop an efficient strategy to derive the sub-optimal solution\nfor the discrete MA positions, superseding the DEO-based method. Numerical\nresults validate the effectiveness of the proposed MA empowered secure\ntransmission scheme along with its optimization algorithms.", "published": "2025-08-09 07:37:42", "link": "http://arxiv.org/abs/2508.06868v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "PROPS: Progressively Private Self-alignment of Large Language Models", "abstract": "Alignment is a key step in developing Large Language Models (LLMs) using\nhuman feedback to ensure adherence to human values and societal norms.\nDependence on human feedback raises privacy concerns about how much a labeler's\npreferences may reveal about their personal values, beliefs, and personality\ntraits. Existing approaches, such as Differentially Private SGD (DP-SGD),\nprovide rigorous privacy guarantees by privatizing gradients during fine-tuning\nand alignment but can provide more privacy than necessary as human preferences\nare tied only to labels of (prompt, response) pairs and can degrade model\nutility. This work focuses on LLM alignment with preference-level privacy,\nwhich preserves the privacy of preference labels provided by humans. We propose\nPROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving\nalignment framework where privately aligned models in previous stages can serve\nas labelers for supplementing training data in the subsequent stages of\nalignment. We present theoretical guarantees for PROPS as well as comprehensive\nvalidation using multiple models (Pythia and GPT) and datasets (AlpacaEval,\nAnthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over\nexisting methods while still providing high privacy. For the same privacy\nbudget, alignment via PROPS can achieve up to 3x higher win-rates compared to\nDP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based\nalignment.", "published": "2025-08-09 02:17:47", "link": "http://arxiv.org/abs/2508.06783v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis", "abstract": "The complexity of modern bioinformatics analysis has created a critical gap\nbetween data generation and developing scientific insights. While large\nlanguage models (LLMs) have shown promise in scientific reasoning, they remain\nfundamentally limited when dealing with real-world analytical workflows that\ndemand iterative computation, tool integration and rigorous validation. We\nintroduce K-Dense Analyst, a hierarchical multi-agent system that achieves\nautonomous bioinformatics analysis through a dual-loop architecture. K-Dense\nAnalyst, part of the broader K-Dense platform, couples planning with validated\nexecution using specialized agents to decompose complex objectives into\nexecutable, verifiable tasks within secure computational environments. On\nBixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense\nAnalyst achieves 29.2% accuracy, surpassing the best-performing language model\n(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what\nis widely considered the most powerful LLM available. Remarkably, K-Dense\nAnalyst achieves this performance using Gemini 2.5 Pro, which attains only\n18.3% accuracy when used directly, demonstrating that our architectural\ninnovations unlock capabilities far beyond the underlying model's baseline\nperformance. Our insights demonstrate that autonomous scientific reasoning\nrequires more than enhanced language models, it demands purpose-built systems\nthat can bridge the gap between high-level scientific objectives and low-level\ncomputational execution. These results represent a significant advance toward\nfully autonomous computational biologists capable of accelerating discovery\nacross the life sciences.", "published": "2025-08-09 16:59:55", "link": "http://arxiv.org/abs/2508.07043v1", "categories": ["cs.AI", "cs.MA", "q-bio.GN", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV", "abstract": "Serialized television narratives present significant analytical challenges\ndue to their complex, temporally distributed storylines that necessitate\nsophisticated information management. This paper introduces a multi-agent\nsystem (MAS) designed to extract and analyze narrative arcs by implementing\nprinciples of computational memory architectures. The system conceptualizes\nnarrative understanding through analogues of human memory: Large Language\nModels (LLMs) provide a form of semantic memory for general narrative patterns,\nwhile a vector database stores specific arc progressions as episodic memories.\nA multi-agent workflow simulates working memory processes to integrate these\ninformation types. Tested on the first season of Grey's Anatomy (ABC 2005-),\nthe MAS identifies three arc types: Anthology (self-contained), Soap\n(relationship-focused), and Genre-Specific. These arcs and their episodic\ndevelopments are stored in a vector database, facilitating structured analysis\nand semantic comparison. To bridge automation with critical interpretation, a\ngraphical interface enables human oversight and refinement of the system's\nnarrative memory. While demonstrating strong performance in identifying\nAnthology Arcs and character entities, the system's reliance on textual\nparatexts (episode summaries) revealed limitations in discerning overlapping\narcs and opaque dynamics, underscoring the challenges in computational memory\nconsolidation versus human holistic understanding. This memory-centric approach\nhighlights the potential of combining AI-driven memory processing with human\nexpertise. Beyond television, it offers promise for serialized written formats\nwhere narrative is entirely text-based. Future work will focus on integrating\nmultimodal inputs to enrich episodic memory, refining memory integration\nmechanisms within the MAS, and expanding testing across diverse genres.", "published": "2025-08-09 15:16:45", "link": "http://arxiv.org/abs/2508.07010v1", "categories": ["cs.MM", "cs.HC", "cs.MA"], "primary_category": "cs.MM"}
{"title": "Conformal Set-based Human-AI Complementarity with Multiple Experts", "abstract": "Decision support systems are designed to assist human experts in\nclassification tasks by providing conformal prediction sets derived from a\npre-trained model. This human-AI collaboration has demonstrated enhanced\nclassification performance compared to using either the model or the expert\nindependently. In this study, we focus on the selection of instance-specific\nexperts from a pool of multiple human experts, contrasting it with existing\nresearch that typically focuses on single-expert scenarios. We characterize the\nconditions under which multiple experts can benefit from the conformal sets.\nWith the insight that only certain experts may be relevant for each instance,\nwe explore the problem of subset selection and introduce a greedy algorithm\nthat utilizes conformal sets to identify the subset of expert predictions that\nwill be used in classifying an instance. This approach is shown to yield better\nperformance compared to naive methods for human subset selection. Based on real\nexpert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation\nstudy indicates that our proposed greedy algorithm achieves near-optimal\nsubsets, resulting in improved classification performance among multiple\nexperts.", "published": "2025-08-09 14:17:51", "link": "http://arxiv.org/abs/2508.06997v1", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach", "abstract": "Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access\nedge computing (MEC) as edge servers. It is desirable to design UAVs'\ntrajectories and user to UAV assignments to ensure satisfactory service to the\nusers and energy efficient operation simultaneously. The posed optimization\nproblem is challenging to solve because: (i) The formulated problem is\nnon-convex, (ii) Due to the mobility of ground users, their future positions\nand channel gains are not known in advance, (iii) Local UAVs' observations\nshould be communicated to a central entity that solves the optimization\nproblem. The (semi-) centralized processing leads to communication overhead,\ncommunication/processing bottlenecks, lack of flexibility and scalability, and\nloss of robustness to system failures. To simultaneously address all these\nlimitations, we advocate a fully decentralized setup with no centralized\nentity. Each UAV obtains its local observation and then communicates with its\nimmediate neighbors only. After sharing information with neighbors, each UAV\ndetermines its next position via a locally run deep reinforcement learning\n(DRL) algorithm. None of the UAVs need to know the global communication graph.\nTwo main components of our proposed solution are (i) Graph attention layers\n(GAT), and (ii) Experience and parameter sharing proximal policy optimization\n(EPS-PPO). Our proposed approach eliminates all the limitations of\nsemi-centralized MADRL methods such as MAPPO and MA deep deterministic policy\ngradient (MADDPG), while guaranteeing a better performance than independent\nlocal DRLs such as in IPPO. Numerical results reveal notable performance gains\nin several different criteria compared to the existing MADDPG algorithm,\ndemonstrating the potential for offering a better performance, while utilizing\nlocal communications only.", "published": "2025-08-09 07:24:12", "link": "http://arxiv.org/abs/2508.06863v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection", "abstract": "Sarcasm detection is a crucial yet challenging Natural Language Processing\ntask. Existing Large Language Model methods are often limited by\nsingle-perspective analysis, static reasoning pathways, and a susceptibility to\nhallucination when processing complex ironic rhetoric, which impacts their\naccuracy and reliability. To address these challenges, we propose **SEVADE**, a\nnovel **S**elf-**Ev**olving multi-agent **A**nalysis framework with\n**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The\ncore of our framework is a Dynamic Agentive Reasoning Engine (DARE), which\nutilizes a team of specialized agents grounded in linguistic theory to perform\na multifaceted deconstruction of the text and generate a structured reasoning\nchain. Subsequently, a separate lightweight rationale adjudicator (RA) performs\nthe final classification based solely on this reasoning chain. This decoupled\narchitecture is designed to mitigate the risk of hallucination by separating\ncomplex reasoning from the final judgment. Extensive experiments on four\nbenchmark datasets demonstrate that our framework achieves state-of-the-art\nperformance, with average improvements of **6.75%** in Accuracy and **6.29%**\nin Macro-F1 score.", "published": "2025-08-09 03:25:45", "link": "http://arxiv.org/abs/2508.06803v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems", "abstract": "Digital Twins (DTs) are transforming industries through advanced data\nprocessing and analysis, positioning the world of DTs, Digital World, as a\ncornerstone of nextgeneration technologies including embodied AI. As robotics\nand automated systems scale, efficient data-sharing frameworks and robust\nalgorithms become critical. We explore the pivotal role of data handling in\nnext-gen networks, focusing on dynamics between application and network\nproviders (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with\nPriority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)\nbased multi-agent path finding (MAPF). By adopting a Centralized Training with\nDecentralized Execution (CTDE) framework and asynchronous actor-learner\narchitectures, PANAMA accelerates training while enabling autonomous task\nexecution by embodied AI. Our approach demonstrates superior pathfinding\nperformance in accuracy, speed, and scalability compared to existing\nbenchmarks. Through simulations, we highlight optimized data-sharing strategies\nfor scalable, automated systems, ensuring resilience in complex, real-world\nenvironments. PANAMA bridges the gap between network-aware decision-making and\nrobust multi-agent coordination, advancing the synergy between DTs, wireless\nnetworks, and AI-driven automation.", "published": "2025-08-09 00:59:55", "link": "http://arxiv.org/abs/2508.06767v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.MA", "cs.RO"], "primary_category": "cs.LG"}
{"title": "A brief introduction to matrix hydrodynamics", "abstract": "This survey gives a basic demonstration of matrix hydrodynamics; the field\npioneered by V. Zeitlin, where 2-D incompressible fluids are spatially\ndiscretized via quantization theory.", "published": "2025-08-09 19:57:44", "link": "http://arxiv.org/abs/2508.07088v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.DG", "math.MP", "35Q31, 53D50, 76M60, 76B47, 53D25"], "primary_category": "math.NA"}
{"title": "$C^{\\infty}$ rational approximation and quasi-histopolation of functions with jumps through multinode Shepard functions", "abstract": "Histopolation, or interpolation on segments, is a mathematical technique used\nto approximate a function $f$ over a given interval $I=[a,b]$ by exploiting\nintegral information over a set of subintervals of $I$. Unlike classical\npolynomial interpolation, which is based on pointwise function evaluations,\nhistopolation reconstructs a function using integral data. However, similar to\nclassical polynomial interpolation, histopolation suffers from the well-known\nRunge phenomenon when integral data are based on a grid with many equispaced\nnodes, as well as the Gibbs phenomenon when approximating discontinuous\nfunctions. In contrast, quasi-histopolation is designed to relax the strict\nrequirement of passing through all the given data points. This inherent\nflexibility can reduce the likelihood of oscillatory behavior using, for\nexample, rational approximation operators. In this work, we introduce a\n$C^{\\infty}$ rational quasi-histopolation operator, for bounded (integrable)\nfunctions, which reconstruct a function by defeating both the Runge and Gibbs\nphenomena. A key element of our approach is to blend local histopolation\npolynomials on a few nodes using multinode Shepard functions as blending\nfunctions. Several numerical experiments demonstrate the accuracy of our\nmethod.", "published": "2025-08-09 18:31:25", "link": "http://arxiv.org/abs/2508.07070v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A novel interpolation-regression approach for function approximation on the disk and its application to cubature formulas", "abstract": "The interpolation-regression approximation is a powerful tool in numerical\nanalysis for reconstructing functions defined on square or triangular domains\nfrom their evaluations at a regular set of nodes. The importance of this\ntechnique lies in its ability to avoid the Runge phenomenon. In this paper, we\npresent a polynomial approximation method based on an interpolation-regression\napproach for reconstructing functions defined on disk domains from their\nevaluations at a general set of sampling points. Special attention is devoted\nto the selection of interpolation nodes to ensure numerical stability,\nparticularly in the context of Zernike polynomials. As an application, the\nproposed method is used to derive accurate cubature formulas for numerical\nintegration over the disk.", "published": "2025-08-09 17:17:07", "link": "http://arxiv.org/abs/2508.07047v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Nonconforming approximation methods for function reconstruction on general polygonal meshes via orthogonal polynomials", "abstract": "In this work, we introduce new families of nonconforming approximation\nmethods for reconstructing functions on general polygonal meshes. These methods\nare defined using degrees of freedom based on weighted moments of orthogonal\npolynomials and can reproduce higher-degree polynomials. This setting naturally\narises in applications where pointwise evaluations are unavailable and only\nintegral measurements over subdomains are accessible. We develop a unisolvence\ntheory and derive necessary and sufficient conditions for the associated\napproximation spaces to be unisolvent. Specifically, it is shown that\nunisolvence depends on the parity of the product of the polynomial degree~$m$\nand the number of polygon edges~$N$. When this condition is not satisfied, we\nintroduce an enrichment strategy involving an additional linear functional and\na suitably designed enrichment function to ensure unisolvence. Numerical\nexperiments confirm the accuracy of the proposed method.", "published": "2025-08-09 16:31:14", "link": "http://arxiv.org/abs/2508.07036v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Structure-Preserving Digital Twins via Conditional Neural Whitney Forms", "abstract": "We present a framework for constructing real-time digital twins based on\nstructure-preserving reduced finite element models conditioned on a latent\nvariable Z. The approach uses conditional attention mechanisms to learn both a\nreduced finite element basis and a nonlinear conservation law within the\nframework of finite element exterior calculus (FEEC). This guarantees numerical\nwell-posedness and exact preservation of conserved quantities, regardless of\ndata sparsity or optimization error. The conditioning mechanism supports\nreal-time calibration to parametric variables, allowing the construction of\ndigital twins which support closed loop inference and calibration to sensor\ndata. The framework interfaces with conventional finite element machinery in a\nnon-invasive manner, allowing treatment of complex geometries and integration\nof learned models with conventional finite element techniques.\n  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,\nand a complex battery thermal runaway problem. The method achieves accurate\npredictions on complex geometries with sparse data (25 LES simulations),\nincluding capturing the transition to turbulence and achieving real-time\ninference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source\nimplementation is available on GitHub.", "published": "2025-08-09 13:26:44", "link": "http://arxiv.org/abs/2508.06981v1", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Efficient iterative linearised solvers for numerical approximations of stochastic Stefan problems", "abstract": "We present iterative solvers to approximate the solution of numerical schemes\nfor stochastic Stefan problems. After briefly talking about the convergence\nresults, we tackle the question of efficient strategies for solving the\nnonlinear equation associated with this scheme. We explore several approaches,\nfrom a standard Newton technique to linearised solvers. The latter offer the\nadvantage of using the same coefficient matrix of the linearised system in each\nnonlinear iteration, for all time steps, and across all realisations of the\nBrownian motions. As a consequence, the system can be factorised once and for\nall. Although the linearised approach has a slower convergence rate, our\nsensitivity analysis and the use of adaptive tolerance in both deterministic\nand stochastic cases provide valuable insights for choosing the most effective\nsolver across various scenarii.", "published": "2025-08-09 07:36:06", "link": "http://arxiv.org/abs/2508.06867v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient data-driven regression for reduced-order modeling of spatial pattern formation", "abstract": "We present an efficient data-driven regression approach for constructing\nreduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern\nformation. The ROMs are learned non-intrusively from available training data of\nphysically accurate numerical simulations. The method can be applied to general\nnonlinear systems through the use of polynomial model form, while not requiring\nknowledge of the underlying physical model, governing equations, or numerical\nsolvers. The process of learning ROMs is posed as a low-cost least-squares\nproblem in a reduced-order subspace identified via Proper Orthogonal\nDecomposition (POD). Numerical experiments on classical pattern-forming\nsystems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate\nthat higher-order surrogate models significantly improve prediction accuracy\nwhile maintaining low computational cost. The proposed method provides a\nflexible, non-intrusive model reduction framework, well suited for the analysis\nof complex spatio-temporal pattern formation phenomena.", "published": "2025-08-09 05:12:57", "link": "http://arxiv.org/abs/2508.06833v1", "categories": ["nlin.PS", "cs.NA", "math.NA"], "primary_category": "nlin.PS"}
{"title": "Onsager Principle-Based Domain Embedding for Thermodynamically Consistent Cahn-Hilliard Model in Arbitrary Domain", "abstract": "The original Cahn-Hilliard model in an arbitrary domain with two prescribed\nboundary conditions is extended to a Cahn-Hilliard-type model in a larger,\nregular domain with homogeneous Neumann boundary conditions. The extension is\nbased on the Onsager principle-based domain embedding (OPBDE) method, which has\nbeen developed as a systematic domain embedding framework to ensure\nthermodynamic consistency. By introducing a modified conservation law, the flux\nat the boundary of the original domain is incorporated into the conservation\nlaw as a source term. Our variational approach demonstrates that, even without\na prior knowledge on the specific form of the rate of free energy pumped into\nthe system, the Onsager principle remains an effective instrument in deriving\nthe constitutive equation of the extended system. This approach clarifies the\nintrinsic structure of the extended model in the perspectives of free energy\nand its dissipation. Asymptotic analysis is carried out for the extended OPBDE\nCahn-Hilliard model, demonstrating that the original Cahn-Hilliard model,\nincluding its boundary conditions, can be fully recovered. To validate our\napproach, a structure-preserving numerical scheme is developed to discretize\nthe extended model. Numerical results show that the OPBDE Cahn-Hilliard model\nis accurate, effective, and robust, highlighting the capability of the OPBDE\nmethod in handling gradient flow problems in arbitrary domain geometries.", "published": "2025-08-09 05:00:49", "link": "http://arxiv.org/abs/2508.06830v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation", "abstract": "The time-fractional Black-Scholes equation (TFBSE) is intended to price the\noptions for which the underlying price fluctuates within a correlated fractal\ntransmission system. Although the TFBSE is an influential approach for grasping\nthe long-term memory traits of financial markets, the non-local nature of\nfractional derivatives makes significant challenges in finding an accurate\nsolution. We perform an efficient use of the differential quadrature method\n(DQM) based on modified cubic B-splines to solve the TFBSE governing European\noptions. This paper constructs an algorithm by the combination of time\nfractional discretization using the finite difference method $L1$ and space\ndiscretization using the modified cubic B-spline-based differential quadrature\nmethod. Uniform meshes are considered for the discretization of both temporal\nand spatial domains. Theoretical stability has been established by finding an\nestimate for the maximum norm of the inverse operator regardless of the\ninvolvement of mesh parameters. We trigger the Neumann series theorem to obtain\na uniform bound for the inverse operator under reasonable conditions on the\nmesh parameters. The numerical illustrations show that this implicit numerical\nmethod exhibits a fourth-order convergence in the space direction and the order\n$2-\\alpha$ in time. Moreover, we observe an enhancement in order of spatial\nconvergence whenever $\\alpha$ tends to $0$. The results obtained are then\ncompared with existing popular techniques to demonstrate the accuracy of\nmodified cubic B-spline-based DQM.", "published": "2025-08-09 02:12:59", "link": "http://arxiv.org/abs/2508.06780v1", "categories": ["math.NA", "cs.NA", "65M12, 26A33, 91G60"], "primary_category": "math.NA"}
{"title": "Proactive Market Making and Liquidity Analysis for Everlasting Options in DeFi Ecosystems", "abstract": "Everlasting options, a relatively new class of perpetual financial\nderivatives, have emerged to tackle the challenges of rolling contracts and\nliquidity fragmentation in decentralized finance markets. This paper offers an\nin-depth analysis of markets for everlasting options, modeled using a dynamic\nproactive market maker. We examine the behavior of funding fees and transaction\ncosts across varying liquidity conditions. Using simulations and modeling, we\ndemonstrate that liquidity providers can aim to achieve a net positive PnL by\nemploying effective hedging strategies, even in challenging environments\ncharacterized by low liquidity and high transaction costs. Additionally, we\nprovide insights into the incentives that drive liquidity providers to support\nthe growth of everlasting option markets and highlight the significant benefits\nthese instruments offer to traders as a reliable and efficient financial tool.", "published": "2025-08-09 18:19:45", "link": "http://arxiv.org/abs/2508.07068v1", "categories": ["q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.CP"}
{"title": "Free Lunches with Vanishing Risks Most Likely Exist", "abstract": "The hypothesis that there do not exist free lunches with vanishing risk\n(FLVRs) in the real market underpins the popular risk-neutral pricing and\nhedging methodology in quantitative finance. The paper documents the fact that\nthis hypothesis can be safely rejected. It performs extremely accurately the\nhedging of an extreme-maturity zero-coupon bond (ZCB). This hedge is part of a\nportfolio that starts with zero initial wealth and invests dynamically in a\ntotal return stock market index and the savings account to generate at the\nmaturity date of the extreme-maturity ZCB a strictly positive amount with\nstrictly positive probability, which represents an FLVR. The fact that FLVRs\nnaturally exist in the real market can be accommodated theoretically under the\nbenchmark approach.", "published": "2025-08-09 21:33:57", "link": "http://arxiv.org/abs/2508.07108v1", "categories": ["q-fin.MF", "62P05, 60G35, 62P20"], "primary_category": "q-fin.MF"}
{"title": "Prediction of high-frequency futures return directions based on the mean uncertainty classification methods: An application in China's future market", "abstract": "In this paper, we mainly focus on the prediction of short-term average return\ndirections in China's high-frequency futures market. As minor fluctuations with\nlimited amplitude and short duration are typically regarded as random noise,\nonly price movements of sufficient magnitude qualify as statistically\nsignificant signals. Therefore data imbalance emerges as a key problem during\npredictive modeling. From the view of data distribution imbalance, we employee\nthe mean-uncertainty logistic regression (mean-uncertainty LR) classification\nmethod under the sublinear expectation (SLE) framework, and further propose the\nmean-uncertainty support vector machines (mean-uncertainty SVM) method for the\nprediction. Corresponding investment strategies are developed based on the\nprediction results. For data selection, we utilize trading data and limit order\nbook data of the top 15 liquid products among the most active contracts in\nChina's future market. Empirical results demonstrate that comparing with\nconventional LR-related and SVM-related imbalanced data classification methods,\nthe two mean-uncertainty approaches yields significant advantages in both\nclassification metrics and average returns per trade.", "published": "2025-08-09 09:56:48", "link": "http://arxiv.org/abs/2508.06914v1", "categories": ["q-fin.TR", "91B82, 68T10,", "I.6.3; J.4"], "primary_category": "q-fin.TR"}
{"title": "Interaction between Returns and Order Flow Imbalances: Endogeneity, Intraday Variations, and Macroeconomic News Announcements", "abstract": "The study examines the interaction between returns and order flow imbalances\n(differences between buy and sell orders), constructed from the best bid and\noffer files of S&P 500 E-mini futures contract, using a structural vector\nautoregressive model. The intraday variation in market activity is considered\nby applying the model for each short interval each day, whereas the endogeneity\ndue to time aggregation is handled by estimating the structural parameters via\nthe identification through heteroskedasticity. The estimation results show that\nsignificant endogeneity exists and that the estimated parameters and impulse\nresponses exhibit significant intraday variations, reflecting intense or mild\norder submission activities. Further, the estimated parameters change around\nmacroeconomic news announcements, suggesting inactive order submission periods\nexist when they occur. Overall, such announcement effects are mostly explained\nby the order submission activities reflecting the public information.", "published": "2025-08-09 02:34:23", "link": "http://arxiv.org/abs/2508.06788v1", "categories": ["q-fin.TR", "econ.EM"], "primary_category": "q-fin.TR"}
{"title": "Membership Inference Attacks with False Discovery Rate Control", "abstract": "Recent studies have shown that deep learning models are vulnerable to\nmembership inference attacks (MIAs), which aim to infer whether a data record\nwas used to train a target model or not. To analyze and study these\nvulnerabilities, various MIA methods have been proposed. Despite the\nsignificance and popularity of MIAs, existing works on MIAs are limited in\nproviding guarantees on the false discovery rate (FDR), which refers to the\nexpected proportion of false discoveries among the identified positive\ndiscoveries. However, it is very challenging to ensure the false discovery rate\nguarantees, because the underlying distribution is usually unknown, and the\nestimated non-member probabilities often exhibit interdependence. To tackle the\nabove challenges, in this paper, we design a novel membership inference attack\nmethod, which can provide the guarantees on the false discovery rate.\nAdditionally, we show that our method can also provide the marginal probability\nguarantee on labeling true non-member data as member data. Notably, our method\ncan work as a wrapper that can be seamlessly integrated with existing MIA\nmethods in a post-hoc manner, while also providing the FDR control. We perform\nthe theoretical analysis for our method. Extensive experiments in various\nsettings (e.g., the black-box setting and the lifelong learning setting) are\nalso conducted to verify the desirable performance of our method.", "published": "2025-08-09 18:14:50", "link": "http://arxiv.org/abs/2508.07066v1", "categories": ["stat.ML", "cs.CV", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation", "abstract": "Anomaly detection (AD) plays a vital role across a wide range of domains, but\nits performance might deteriorate when applied to target domains with limited\ndata. Domain Adaptation (DA) offers a solution by transferring knowledge from a\nrelated source domain with abundant data. However, this adaptation process can\nintroduce additional uncertainty, making it difficult to draw statistically\nvalid conclusions from AD results. In this paper, we propose STAND-DA -- a\nnovel framework for statistically rigorous Autoencoder-based AD after\nRepresentation Learning-based DA. Built on the Selective Inference (SI)\nframework, STAND-DA computes valid $p$-values for detected anomalies and\nrigorously controls the false positive rate below a pre-specified level\n$\\alpha$ (e.g., 0.05). To address the computational challenges of applying SI\nto deep learning models, we develop the GPU-accelerated SI implementation,\nsignificantly enhancing both scalability and runtime performance. This\nadvancement makes SI practically feasible for modern, large-scale deep\narchitectures. Extensive experiments on synthetic and real-world datasets\nvalidate the theoretical results and computational efficiency of the proposed\nSTAND-DA method.", "published": "2025-08-09 17:24:02", "link": "http://arxiv.org/abs/2508.07049v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MOCA-HESP: Meta High-dimensional Bayesian Optimization for Combinatorial and Mixed Spaces via Hyper-ellipsoid Partitioning", "abstract": "High-dimensional Bayesian Optimization (BO) has attracted significant\nattention in recent research. However, existing methods have mainly focused on\noptimizing in continuous domains, while combinatorial (ordinal and categorical)\nand mixed domains still remain challenging. In this paper, we first propose\nMOCA-HESP, a novel high-dimensional BO method for combinatorial and mixed\nvariables. The key idea is to leverage the hyper-ellipsoid space partitioning\n(HESP) technique with different categorical encoders to work with\nhigh-dimensional, combinatorial and mixed spaces, while adaptively selecting\nthe optimal encoders for HESP using a multi-armed bandit technique. Our method,\nMOCA-HESP, is designed as a \\textit{meta-algorithm} such that it can\nincorporate other combinatorial and mixed BO optimizers to further enhance the\noptimizers' performance. Finally, we develop three practical BO methods by\nintegrating MOCA-HESP with state-of-the-art BO optimizers for combinatorial and\nmixed variables: standard BO, CASMOPOLITAN, and Bounce. Our experimental\nresults on various synthetic and real-world benchmarks show that our methods\noutperform existing baselines. Our code implementation can be found at\nhttps://github.com/LamNgo1/moca-hesp", "published": "2025-08-09 06:04:59", "link": "http://arxiv.org/abs/2508.06847v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions", "abstract": "We propose a novel framework for adaptively learning the time-evolving\nsolutions of stochastic partial differential equations (SPDEs) using\nscore-based diffusion models within a recursive Bayesian inference setting.\nSPDEs play a central role in modeling complex physical systems under\nuncertainty, but their numerical solutions often suffer from model errors and\nreduced accuracy due to incomplete physical knowledge and environmental\nvariability. To address these challenges, we encode the governing physics into\nthe score function of a diffusion model using simulation data and incorporate\nobservational information via a likelihood-based correction in a reverse-time\nstochastic differential equation. This enables adaptive learning through\niterative refinement of the solution as new data becomes available. To improve\ncomputational efficiency in high-dimensional settings, we introduce the\nensemble score filter, a training-free approximation of the score function\ndesigned for real-time inference. Numerical experiments on benchmark SPDEs\ndemonstrate the accuracy and robustness of the proposed method under sparse and\nnoisy observations.", "published": "2025-08-09 05:24:21", "link": "http://arxiv.org/abs/2508.06834v1", "categories": ["stat.CO", "cs.LG", "math.DS", "math.PR", "stat.ML", "Stochastic partial differential equation, score-based diffusion\n  model, adaptive learning, Ensemble Score Filter, data assimilation, Bayesian\n  inference"], "primary_category": "stat.CO"}
{"title": "Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift", "abstract": "We present Zero-Direction Probing (ZDP), a theory-only framework for\ndetecting model drift from null directions of transformer activations without\ntask labels or output evaluations. Under assumptions A1--A6, we prove: (i) the\nVariance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound\nfor low-rank updates, and (iv) a logarithmic-regret guarantee for online\nnull-space trackers. We derive a Spectral Null-Leakage (SNL) metric with\nnon-asymptotic tail bounds and a concentration inequality, yielding a-priori\nthresholds for drift under a Gaussian null model. These results show that\nmonitoring right/left null spaces of layer activations and their Fisher\ngeometry provides concrete, testable guarantees on representational change.", "published": "2025-08-09 02:05:59", "link": "http://arxiv.org/abs/2508.06776v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree", "abstract": "Recognizing specific key phrases is an essential task for contextualized\nAutomatic Speech Recognition (ASR). However, most existing context-biasing\napproaches have limitations associated with the necessity of additional model\ntraining, significantly slow down the decoding process, or constrain the choice\nof the ASR system type. This paper proposes a universal ASR context-biasing\nframework that supports all major types: CTC, Transducers, and Attention\nEncoder-Decoder models. The framework is based on a GPU-accelerated word\nboosting tree, which enables it to be used in shallow fusion mode for greedy\nand beam search decoding without noticeable speed degradation, even with a vast\nnumber of key phrases (up to 20K items). The obtained results showed high\nefficiency of the proposed method, surpassing the considered open-source\ncontext-biasing approaches in accuracy and decoding speed. Our context-biasing\nframework is open-sourced as a part of the NeMo toolkit.", "published": "2025-08-09 15:27:07", "link": "http://arxiv.org/abs/2508.07014v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Head-steered channel selection method for hearing aid applications using remote microphones", "abstract": "We propose a channel selection method for hearing aid applications using\nremote microphones, in the presence of multiple competing talkers. The proposed\nchannel selection method uses the hearing aid user's head-steering direction to\nidentify the remote channel originating from the frontal direction of the\nhearing aid user, which captures the target talker signal. We pose the channel\nselection task as a multiple hypothesis testing problem, and derive a maximum\nlikelihood solution. Under realistic, simplifying assumptions, the solution\nselects the remote channel which has the highest weighted squared absolute\ncorrelation coefficient with the output of the head-steered hearing aid\nbeamformer. We analyze the performance of the proposed channel selection method\nusing close-talking remote microphones and table microphone arrays. Through\nsimulations using realistic acoustic scenes, we show that the proposed channel\nselection method consistently outperforms existing methods in accurately\nfinding the remote channel that captures the target talker signal, in the\npresence of multiple competing talkers, without the use of any additional\nsensors.", "published": "2025-08-09 10:50:06", "link": "http://arxiv.org/abs/2508.06928v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speech Enhancement based on cascaded two flow", "abstract": "Speech enhancement (SE) based on diffusion probabilistic models has exhibited\nimpressive performance, while requiring a relatively high number of function\nevaluations (NFE). Recently, SE based on flow matching has been proposed, which\nshowed competitive performance with a small NFE. Early approaches adopted the\nnoisy speech as the only conditioning variable. There have been other\napproaches which utilize speech enhanced with a predictive model as another\nconditioning variable and to sample an initial value, but they require a\nseparate predictive model on top of the generative SE model. In this work, we\npropose to employ an identical model based on flow matching for both SE and\ngenerating enhanced speech used as an initial starting point and a conditioning\nvariable. Experimental results showed that the proposed method required the\nsame or fewer NFEs even with two cascaded generative methods while achieving\nequivalent or better performances to the previous baselines.", "published": "2025-08-09 05:50:46", "link": "http://arxiv.org/abs/2508.06842v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "FlowSE: Flow Matching-based Speech Enhancement", "abstract": "Diffusion probabilistic models have shown impressive performance for speech\nenhancement, but they typically require 25 to 60 function evaluations in the\ninference phase, resulting in heavy computational complexity. Recently, a\nfine-tuning method was proposed to correct the reverse process, which\nsignificantly lowered the number of function evaluations (NFE). Flow matching\nis a method to train continuous normalizing flows which model probability paths\nfrom known distributions to unknown distributions including those described by\ndiffusion processes. In this paper, we propose a speech enhancement based on\nconditional flow matching. The proposed method achieved the performance\ncomparable to those for the diffusion-based speech enhancement with the NFE of\n60 when the NFE was 5, and showed similar performance with the diffusion model\ncorrecting the reverse process at the same NFE from 1 to 5 without additional\nfine tuning procedure. We also have shown that the corresponding diffusion\nmodel derived from the conditional probability path with a modified optimal\ntransport conditional vector field demonstrated similar performances with the\nNFE of 5 without any fine-tuning procedure.", "published": "2025-08-09 05:45:17", "link": "http://arxiv.org/abs/2508.06840v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Differentiable Adaptive Kalman Filtering via Optimal Transport", "abstract": "Learning-based filtering has demonstrated strong performance in non-linear\ndynamical systems, particularly when the statistics of noise are unknown.\nHowever, in real-world deployments, environmental factors, such as changing\nwind conditions or electromagnetic interference, can induce unobserved\nnoise-statistics drift, leading to substantial degradation of learning-based\nmethods. To address this challenge, we propose OTAKNet, the first online\nsolution to noise-statistics drift within learning-based adaptive Kalman\nfiltering. Unlike existing learning-based methods that perform offline\nfine-tuning using batch pointwise matching over entire trajectories, OTAKNet\nestablishes a connection between the state estimate and the drift via one-step\npredictive measurement likelihood, and addresses it using optimal transport.\nThis leverages OT's geometry - aware cost and stable gradients to enable fully\nonline adaptation without ground truth labels or retraining. We compare OTAKNet\nagainst classical model-based adaptive Kalman filtering and offline\nlearning-based filtering. The performance is demonstrated on both synthetic and\nreal-world NCLT datasets, particularly under limited training data.", "published": "2025-08-09 16:36:33", "link": "http://arxiv.org/abs/2508.07037v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Robust Super-Resolution Compressive Sensing: A Two-timescale Alternating MAP Approach", "abstract": "The problem of super-resolution compressive sensing (SR-CS) is crucial for\nvarious wireless sensing and communication applications. Existing methods often\nsuffer from limited resolution capabilities and sensitivity to\nhyper-parameters, hindering their ability to accurately recover sparse signals\nwhen the grid parameters do not lie precisely on a fixed grid and are close to\neach other. To overcome these limitations, this paper introduces a novel robust\nsuper-resolution compressive sensing algorithmic framework using a\ntwo-timescale alternating maximum a posteriori (MAP) approach. At the slow\ntimescale, the proposed framework iterates between a sparse signal estimation\nmodule and a grid update module. In the sparse signal estimation module, a\nhyperbolic-tangent prior distribution based variational Bayesian inference\n(tanh-VBI) algorithm with a strong sparsity promotion capability is adopted to\nestimate the posterior probability of the sparse vector and accurately identify\nactive grid components carrying primary energy under a dense grid.\nSubsequently, the grid update module utilizes the BFGS algorithm to refine\nthese low-dimensional active grid components at a faster timescale to achieve\nsuper-resolution estimation of the grid parameters with a low computational\ncost. The proposed scheme is applied to the channel extrapolation problem, and\nsimulation results demonstrate the superiority of the proposed scheme compared\nto baseline schemes.", "published": "2025-08-09 15:27:02", "link": "http://arxiv.org/abs/2508.07013v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Beamforming Optimization for Pinching-Antenna Systems (PASS)-assisted Symbiotic Radio", "abstract": "This paper investigates a novel downlink symbiotic radio (SR) framework\nempowered by the pinching antenna system (PASS), aiming to enhance both primary\nand secondary transmissions through reconfigurable antenna positioning. PASS\nconsists of multiple waveguides equipped with numerous low-cost pinching\nantennas (PAs), whose positions can be flexibly adjusted to simultaneously\nmanipulate large-scale path loss and signal phases.We formulate a joint\ntransmit and pinching beamforming optimization problem to maximize the\nachievable sum rate while satisfying the detection error probability constraint\nfor the IR and the feasible deployment region constraints for the PAs. This\nproblem is inherently nonconvex and highly coupled. To address it, two solution\nstrategies are developed. 1) A learning-aided gradient descent (LGD) algorithm\nis proposed, where the constrained problem is reformulated into a\ndifferentiable form and solved through end-to-end learning based on the\nprinciple of gradient descent. The PA position matrix is reparameterized to\ninherently satisfy minimum spacing constraints, while transmit power and\nwaveguide length limits are enforced via projection and normalization. 2) A\ntwo-stage optimization-based approach is designed, in which the transmit\nbeamforming is first optimized via successive convex approximation (SCA),\nfollowed by pinching beamforming optimization using a particle swarm\noptimization (PSO) search over candidate PA placements. The SCA-PSO algorithm\nachieves performance close to that of the element-wise method while\nsignificantly reducing computational complexity by exploring a randomly\ngenerated effective solution subspace, while further improving upon the LGD\nmethod by avoiding undesirable local optima.", "published": "2025-08-09 14:41:20", "link": "http://arxiv.org/abs/2508.07002v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Millimeter-Wave Position Sensing Using Reconfigurable Intelligent Surfaces: Positioning Error Bound and Phase Shift Configuration", "abstract": "Millimeter-wave (mmWave) positioning has emerged as a promising technology\nfor next-generation intelligent systems. The advent of reconfigurable\nintelligent surfaces (RISs) has revolutionized high-precision mmWave\nlocalization by enabling dynamic manipulation of wireless propagation\nenvironments. This paper investigates a three-dimensional (3D) multi-input\nsingle-output (MISO) mmWave positioning system assisted by multiple RISs. We\nintroduce a measurement framework incorporating sequential RIS activation and\ndirectional beamforming to fully exploit virtual line-of-sight (VLoS) paths.\nThe theoretical performance limits are rigorously analyzed through derivation\nof the Fisher information and subsequent positioning error bound (PEB). To\nminimize the PEB, two distinct optimization approaches are proposed for\ncontinuous and discrete phase shift configurations of RISs. For continuous\nphase shifts, a Riemannian manifold-based optimization algorithm is proposed.\nFor discrete phase shifts, a heuristic algorithm incorporating the grey wolf\noptimizer is proposed. Extensive numerical simulations demonstrate the\neffectiveness of the proposed algorithms in reducing the PEB and validate the\nimprovement in positioning accuracy achieved by multiple RISs.", "published": "2025-08-09 12:06:48", "link": "http://arxiv.org/abs/2508.06958v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Extremely Large-Scale Dynamic Metasurface Antennas for 6G Near-Field Networks: Opportunities and Challenges", "abstract": "6G networks will need to support higher data rates, high-precision\nlocalization, and imaging capabilities. Near-field technologies, enabled by\nextremely large-scale (XL)-arrays, are expected to be essential physical-layer\nsolutions to meet these ambitious requirements. However, implementing XL-array\nsystems using traditional fully-digital or hybrid analog/digital architectures\nposes significant challenges due to high power consumption and implementation\ncosts. Emerging XL-dynamic metasurface antennas (XL-DMAs) provide a promising\nalternative, enabling ultra-low power and cost-efficient solutions, making them\nideal candidates for 6G near-field networks. In this article, we discuss the\nopportunities and challenges of XL-DMAs employed in 6G near-field networks. We\nfirst outline the fundamental principles of XL-DMAs and present the specifics\nof the near-field model of XL-DMAs. We then highlight several promising\napplications that might benefit from XL-DMAs, including near-field\ncommunication, localization, and imaging. Finally, we discuss several open\nproblems and potential future directions that should be addressed to fully\nexploit the capabilities of XL-DMAs in the next 6G near-field networks.", "published": "2025-08-09 11:58:04", "link": "http://arxiv.org/abs/2508.06952v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work", "abstract": "Sign Language Production (SLP) is the task of generating sign language video\nfrom spoken language inputs. The field has seen a range of innovations over the\nlast few years, with the introduction of deep learning-based approaches\nproviding significant improvements in the realism and naturalness of generated\noutputs. However, the lack of standardized evaluation metrics for SLP\napproaches hampers meaningful comparisons across different systems. To address\nthis, we introduce the first Sign Language Production Challenge, held as part\nof the third SLRTP Workshop at CVPR 2025. The competition's aims are to\nevaluate architectures that translate from spoken language sentences to a\nsequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a\nrange of metrics. For our evaluation data, we use the\nRWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche\nGebardensprache (DGS) weather broadcast dataset. In addition, we curate a\ncustom hidden test set from a similar domain of discourse. This paper presents\nthe challenge design and the winning methodologies. The challenge attracted 33\nparticipants who submitted 231 solutions, with the top-performing team\nachieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach\nutilized a retrieval-based framework and a pre-trained language model. As part\nof the workshop, we release a standardized evaluation network, including\nhigh-quality skeleton extraction-based keypoints establishing a consistent\nbaseline for the SLP field, which will enable future researchers to compare\ntheir work against a broader range of methods.", "published": "2025-08-09 11:57:33", "link": "http://arxiv.org/abs/2508.06951v1", "categories": ["cs.CV", "eess.IV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Deep Domain-Adversarial Adaptation for Automatic Modulation Classification under Channel Variability", "abstract": "Automatic Modulation Classification (AMC) plays a significant role in modern\ncognitive and intelligent radio systems, where accurate identification of\nmodulation is crucial for adaptive communication. The presence of heterogeneous\nwireless channel conditions, such as Rayleigh and Rician fading, poses\nsignificant challenges to the generalization ability of conventional AMC\nmodels. In this work, a domain-adversarial neural network (DANN) based deep\nlearning framework is proposed that explicitly mitigates channel-induced\ndistribution shifts between source and target domains. The approach is\nevaluated using a comprehensive simulated dataset containing five modulation\nschemes (BPSK, QPSK, 16QAM, 64QAM, 256QAM) across Rayleigh and Rician fading\nchannels at five frequency bands. Comparative experiments demonstrate that the\nDANN-based model achieves up to 14.93% absolute accuracy improvement in certain\nmodulation cases compared to a baseline supervised model trained solely on the\nsource domain. The findings establish the engineering feasibility of domain\nadversarial learning in AMC tasks under real-world channel variability and\noffer a robust direction for future research in adaptive spectrum intelligence", "published": "2025-08-09 05:00:34", "link": "http://arxiv.org/abs/2508.06829v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physical Layer Authentication Based on Hierarchical Variational Auto-Encoder for Industrial Internet of Things", "abstract": "Recently, Physical Layer Authentication (PLA) has attracted much attention\nsince it takes advantage of the channel randomness nature of transmission media\nto achieve communication confidentiality and authentication. In the complex\nenvironment, such as the Industrial Internet of Things (IIoT), machine learning\n(ML) is widely employed with PLA to extract and analyze complex channel\ncharacteristics for identity authentication. However, most PLA schemes for IIoT\nrequire attackers' prior channel information, leading to severe performance\ndegradation when the source of the received signals is unknown in the training\nstage. Thus, a channel impulse response (CIR)-based PLA scheme named\n\"Hierarchical Variational Auto-Encoder (HVAE)\" for IIoT is proposed in this\narticle, aiming at achieving high authentication performance without knowing\nattackers' prior channel information even when trained on a few data in the\ncomplex environment. HVAE consists of an Auto-Encoder (AE) module for CIR\ncharacteristics extraction and a Variational Auto-Encoder (VAE) module for\nimproving the representation ability of the CIR characteristic and outputting\nthe authentication results. Besides, a new objective function is constructed in\nwhich both the single-peak and the double-peak Gaussian distribution are taken\ninto consideration in the VAE module. Moreover, the simulations are conducted\nunder the static and mobile IIoT scenario, which verify the superiority of the\nproposed HVAE over three comparison PLA schemes even with a few training data.", "published": "2025-08-09 02:55:29", "link": "http://arxiv.org/abs/2508.06794v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree", "abstract": "Recognizing specific key phrases is an essential task for contextualized\nAutomatic Speech Recognition (ASR). However, most existing context-biasing\napproaches have limitations associated with the necessity of additional model\ntraining, significantly slow down the decoding process, or constrain the choice\nof the ASR system type. This paper proposes a universal ASR context-biasing\nframework that supports all major types: CTC, Transducers, and Attention\nEncoder-Decoder models. The framework is based on a GPU-accelerated word\nboosting tree, which enables it to be used in shallow fusion mode for greedy\nand beam search decoding without noticeable speed degradation, even with a vast\nnumber of key phrases (up to 20K items). The obtained results showed high\nefficiency of the proposed method, surpassing the considered open-source\ncontext-biasing approaches in accuracy and decoding speed. Our context-biasing\nframework is open-sourced as a part of the NeMo toolkit.", "published": "2025-08-09 15:27:07", "link": "http://arxiv.org/abs/2508.07014v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization", "abstract": "Voice anonymization protects speaker privacy by concealing identity while\npreserving linguistic and paralinguistic content. Self-supervised learning\n(SSL) representations encode linguistic features but preserve speaker traits.\nWe propose a novel speaker-embedding-free framework called SEF-MK. Instead of\nusing a single k-means model trained on the entire dataset, SEF-MK anonymizes\nSSL representations for each utterance by randomly selecting one of multiple\nk-means models, each trained on a different subset of speakers. We explore this\napproach from both attacker and user perspectives. Extensive experiments show\nthat, compared to a single k-means model, SEF-MK with multiple k-means models\nbetter preserves linguistic and emotional content from the user's viewpoint.\nHowever, from the attacker's perspective, utilizing multiple k-means models\nboosts the effectiveness of privacy attacks. These insights can aid users in\ndesigning voice anonymization systems to mitigate attacker threats.", "published": "2025-08-09 19:47:34", "link": "http://arxiv.org/abs/2508.07086v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer", "abstract": "Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive\napplications such as real-time captioning and meeting transcription. However,\ntruly parallel ASR decoding remains challenging due to the sequential nature of\nautoregressive (AR) decoders and the context limitations of non-autoregressive\n(NAR) methods. While modern ASR encoders can process up to 30 seconds of audio\nat once, AR decoders still generate tokens sequentially, creating a latency\nbottleneck. We propose Whisfusion, the first framework to fuse a pre-trained\nWhisper encoder with a text diffusion decoder. This NAR architecture resolves\nthe AR latency bottleneck by processing the entire acoustic context in parallel\nat every decoding step. A lightweight cross-attention adapter trained via\nparameter-efficient fine-tuning (PEFT) bridges the two modalities. We also\nintroduce a batch-parallel, multi-step decoding strategy that improves accuracy\nby increasing the number of candidates with minimal impact on speed. Fine-tuned\nsolely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny\n(8.3% vs. 9.7%), and offers comparable latency on short audio. For longer\nutterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a\nnew, efficient operating point for long-form ASR. The implementation and\ntraining scripts are available at https://github.com/taeyoun811/Whisfusion.", "published": "2025-08-09 17:20:54", "link": "http://arxiv.org/abs/2508.07048v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody", "abstract": "Emotional voice conversion (EVC) aims to modify the emotional style of speech\nwhile preserving its linguistic content. In practical EVC, controllability, the\nability to independently control speaker identity and emotional style using\ndistinct references, is crucial. However, existing methods often struggle to\nfully disentangle these attributes and lack the ability to model fine-grained\nemotional expressions such as temporal dynamics. We propose Maestro-EVC, a\ncontrollable EVC framework that enables independent control of content, speaker\nidentity, and emotion by effectively disentangling each attribute from separate\nreferences. We further introduce a temporal emotion representation and an\nexplicit prosody modeling with prosody augmentation to robustly capture and\ntransfer the temporal dynamics of the target emotion, even under\nprosody-mismatched conditions. Experimental results confirm that Maestro-EVC\nachieves high-quality, controllable, and emotionally expressive speech\nsynthesis.", "published": "2025-08-09 08:46:32", "link": "http://arxiv.org/abs/2508.06890v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Text to Speech System for Meitei Mayek Script", "abstract": "This paper presents the development of a Text-to-Speech (TTS) system for the\nManipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and\nHiFi-GAN, we introduce a neural TTS architecture adapted to support tonal\nphonology and under-resourced linguistic environments. We develop a phoneme\nmapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and\ndemonstrate intelligible and natural speech synthesis, validated through\nsubjective and objective metrics. This system lays the groundwork for\nlinguistic preservation and technological inclusion of Manipuri.", "published": "2025-08-09 07:40:53", "link": "http://arxiv.org/abs/2508.06870v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Speech Enhancement based on cascaded two flow", "abstract": "Speech enhancement (SE) based on diffusion probabilistic models has exhibited\nimpressive performance, while requiring a relatively high number of function\nevaluations (NFE). Recently, SE based on flow matching has been proposed, which\nshowed competitive performance with a small NFE. Early approaches adopted the\nnoisy speech as the only conditioning variable. There have been other\napproaches which utilize speech enhanced with a predictive model as another\nconditioning variable and to sample an initial value, but they require a\nseparate predictive model on top of the generative SE model. In this work, we\npropose to employ an identical model based on flow matching for both SE and\ngenerating enhanced speech used as an initial starting point and a conditioning\nvariable. Experimental results showed that the proposed method required the\nsame or fewer NFEs even with two cascaded generative methods while achieving\nequivalent or better performances to the previous baselines.", "published": "2025-08-09 05:50:46", "link": "http://arxiv.org/abs/2508.06842v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization", "abstract": "Voice anonymization protects speaker privacy by concealing identity while\npreserving linguistic and paralinguistic content. Self-supervised learning\n(SSL) representations encode linguistic features but preserve speaker traits.\nWe propose a novel speaker-embedding-free framework called SEF-MK. Instead of\nusing a single k-means model trained on the entire dataset, SEF-MK anonymizes\nSSL representations for each utterance by randomly selecting one of multiple\nk-means models, each trained on a different subset of speakers. We explore this\napproach from both attacker and user perspectives. Extensive experiments show\nthat, compared to a single k-means model, SEF-MK with multiple k-means models\nbetter preserves linguistic and emotional content from the user's viewpoint.\nHowever, from the attacker's perspective, utilizing multiple k-means models\nboosts the effectiveness of privacy attacks. These insights can aid users in\ndesigning voice anonymization systems to mitigate attacker threats.", "published": "2025-08-09 19:47:34", "link": "http://arxiv.org/abs/2508.07086v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
