{"title": "A Survey on Neural Network-Based Summarization Methods", "abstract": "Automatic text summarization, the automated process of shortening a text\nwhile reserving the main ideas of the document(s), is a critical research area\nin natural language processing. The aim of this literature review is to survey\nthe recent work on neural-based models in automatic text summarization. We\nexamine in detail ten state-of-the-art neural-based summarizers: five\nabstractive models and five extractive models. In addition, we discuss the\nrelated techniques that can be applied to the summarization tasks and present\npromising paths for future research in neural-based summarization.", "published": "2018-03-19 18:49:16", "link": "http://arxiv.org/abs/1804.04589v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acoustic feature learning using cross-domain articulatory measurements", "abstract": "Previous work has shown that it is possible to improve speech recognition by\nlearning acoustic features from paired acoustic-articulatory data, for example\nby using canonical correlation analysis (CCA) or its deep extensions. One\nlimitation of this prior work is that the learned feature models are difficult\nto port to new datasets or domains, and articulatory data is not available for\nmost speech corpora. In this work we study the problem of acoustic feature\nlearning in the setting where we have access to an external, domain-mismatched\ndataset of paired speech and articulatory measurements, either with or without\nlabels. We develop methods for acoustic feature learning in these settings,\nbased on deep variational CCA and extensions that use both source and target\ndomain data and labels. Using this approach, we improve phonetic recognition\naccuracies on both TIMIT and Wall Street Journal and analyze a number of design\nchoices.", "published": "2018-03-19 05:13:09", "link": "http://arxiv.org/abs/1803.06805v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polyglot Semantic Parsing in APIs", "abstract": "Traditional approaches to semantic parsing (SP) work by training individual\nmodels for each available parallel dataset of text-meaning pairs. In this\npaper, we explore the idea of polyglot semantic translation, or learning\nsemantic parsing models that are trained on multiple datasets and natural\nlanguages. In particular, we focus on translating text to code signature\nrepresentations using the software component datasets of Richardson and Kuhn\n(2017a,b). The advantage of such models is that they can be used for parsing a\nwide variety of input natural languages and output programming languages, or\nmixed input languages, using a single unified model. To facilitate modeling of\nthis type, we develop a novel graph-based decoding framework that achieves\nstate-of-the-art performance on the above datasets, and apply this method to\ntwo other benchmark SP tasks.", "published": "2018-03-19 14:55:12", "link": "http://arxiv.org/abs/1803.06966v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Decoding for More Abstractive Summaries with Copy-Based\n  Networks", "abstract": "Attention-based neural abstractive summarization systems equipped with copy\nmechanisms have shown promising results. Despite this success, it has been\nnoticed that such a system generates a summary by mostly, if not entirely,\ncopying over phrases, sentences, and sometimes multiple consecutive sentences\nfrom an input paragraph, effectively performing extractive summarization. In\nthis paper, we verify this behavior using the latest neural abstractive\nsummarization system - a pointer-generator network. We propose a simple\nbaseline method that allows us to control the amount of copying without\nretraining. Experiments indicate that the method provides a strong baseline for\nabstractive systems looking to obtain high ROUGE scores while minimizing\noverlap with the source article, substantially reducing the n-gram overlap with\nthe original article while keeping within 2 points of the original model's\nROUGE score.", "published": "2018-03-19 17:02:23", "link": "http://arxiv.org/abs/1803.07038v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Generate Wikipedia Summaries for Underserved Languages from\n  Wikidata", "abstract": "While Wikipedia exists in 287 languages, its content is unevenly distributed\namong them. In this work, we investigate the generation of open domain\nWikipedia summaries in underserved languages using structured data from\nWikidata. To this end, we propose a neural network architecture equipped with\ncopy actions that learns to generate single-sentence and comprehensible textual\nsummaries from Wikidata triples. We demonstrate the effectiveness of the\nproposed approach by evaluating it against a set of baselines on two languages\nof different natures: Arabic, a morphological rich language with a larger\nvocabulary than English, and Esperanto, a constructed language known for its\neasy acquisition.", "published": "2018-03-19 18:53:17", "link": "http://arxiv.org/abs/1803.07116v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Natural Language Processing with Recurrence Quantification\n  Analysis", "abstract": "Writing and reading are dynamic processes. As an author composes a text, a\nsequence of words is produced. This sequence is one that, the author hopes,\ncauses a revisitation of certain thoughts and ideas in others. These processes\nof composition and revisitation by readers are ordered in time. This means that\ntext itself can be investigated under the lens of dynamical systems. A common\ntechnique for analyzing the behavior of dynamical systems, known as recurrence\nquantification analysis (RQA), can be used as a method for analyzing sequential\nstructure of text. RQA treats text as a sequential measurement, much like a\ntime series, and can thus be seen as a kind of dynamic natural language\nprocessing (NLP). The extension has several benefits. Because it is part of a\nsuite of time series analysis tools, many measures can be extracted in one\ncommon framework. Secondly, the measures have a close relationship with some\ncommonly used measures from natural language processing. Finally, using\nrecurrence analysis offers an opportunity expand analysis of text by developing\ntheoretical descriptions derived from complex dynamic systems. We showcase an\nexample analysis on 8,000 texts from the Gutenberg Project, compare it to\nwell-known NLP approaches, and describe an R package (crqanlp) that can be used\nin conjunction with R library crqa.", "published": "2018-03-19 19:45:38", "link": "http://arxiv.org/abs/1803.07136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "English-Catalan Neural Machine Translation in the Biomedical Domain\n  through the cascade approach", "abstract": "This paper describes the methodology followed to build a neural machine\ntranslation system in the biomedical domain for the English-Catalan language\npair. This task can be considered a low-resourced task from the point of view\nof the domain and the language pair. To face this task, this paper reports\nexperiments on a cascade pivot strategy through Spanish for the neural machine\ntranslation using the English-Spanish SCIELO and Spanish-Catalan El Peri\\'odico\ndatabase. To test the final performance of the system, we have created a new\ntest data set for English-Catalan in the biomedical domain which is freely\navailable on request.", "published": "2018-03-19 19:48:48", "link": "http://arxiv.org/abs/1803.07139v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Sentiment Analysis: Addressing Key Issues and Setting up the\n  Baselines", "abstract": "We compile baselines, along with dataset split, for multimodal sentiment\nanalysis. In this paper, we explore three different deep-learning based\narchitectures for multimodal sentiment classification, each improving upon the\nprevious. Further, we evaluate these architectures with multiple datasets with\nfixed train/test partition. We also discuss some major issues, frequently\nignored in multimodal sentiment analysis research, e.g., role of\nspeaker-exclusive models, importance of different modalities, and\ngeneralizability. This framework illustrates the different facets of analysis\nto be considered while performing multimodal sentiment analysis and, hence,\nserves as a new benchmark for future research in this emerging field.", "published": "2018-03-19 02:23:30", "link": "http://arxiv.org/abs/1803.07427v2", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Music Style Transfer: A Position Paper", "abstract": "Led by the success of neural style transfer on visual arts, there has been a\nrising trend very recently in the effort of music style transfer. However,\n\"music style\" is not yet a well-defined concept from a scientific point of\nview. The difficulty lies in the intrinsic multi-level and multi-modal\ncharacter of music representation (which is very different from image\nrepresentation). As a result, depending on their interpretation of \"music\nstyle\", current studies under the category of \"music style transfer\", are\nactually solving completely different problems that belong to a variety of\nsub-fields of Computer Music. Also, a vanilla end-to-end approach, which aims\nat dealing with all levels of music representation at once by directly adopting\nthe method of image style transfer, leads to poor results. Thus, we vitally\npropose a more scientifically-viable definition of music style transfer by\nbreaking it down into precise concepts of timbre style transfer, performance\nstyle transfer and composition style transfer, as well as to connect different\naspects of music style transfer with existing well-established sub-fields of\ncomputer music studies. In addition, we discuss the current limitations of\nmusic style modeling and its future directions by drawing spirit from some deep\ngenerative models, especially the ones using unsupervised learning and\ndisentanglement techniques.", "published": "2018-03-19 09:21:34", "link": "http://arxiv.org/abs/1803.06841v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
