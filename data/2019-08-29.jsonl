{"title": "A Joint Model for Aspect-Category Sentiment Analysis with Shared\n  Sentiment Prediction Layer", "abstract": "Aspect-category sentiment analysis (ACSA) aims to predict the aspect\ncategories mentioned in texts and their corresponding sentiment polarities.\nSome joint models have been proposed to address this task. Given a text, these\njoint models detect all the aspect categories mentioned in the text and predict\nthe sentiment polarities toward them at once. Although these joint models\nobtain promising performances, they train separate parameters for each aspect\ncategory and therefore suffer from data deficiency of some aspect categories.\nTo solve this problem, we propose a novel joint model which contains a shared\nsentiment prediction layer. The shared sentiment prediction layer transfers\nsentiment knowledge between aspect categories and alleviates the problem caused\nby data deficiency. Experiments conducted on SemEval-2016 Datasets demonstrate\nthe effectiveness of our model.", "published": "2019-08-29 02:00:37", "link": "http://arxiv.org/abs/1908.11017v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Regularized Context Gates on Transformer for Machine Translation", "abstract": "Context gates are effective to control the contributions from the source and\ntarget contexts in the recurrent neural network (RNN) based neural machine\ntranslation (NMT). However, it is challenging to extend them into the advanced\nTransformer architecture, which is more complicated than RNN. This paper first\nprovides a method to identify source and target contexts and then introduce a\ngate mechanism to control the source and target contributions in Transformer.\nIn addition, to further reduce the bias problem in the gate mechanism, this\npaper proposes a regularization method to guide the learning of the gates with\nsupervision automatically generated using pointwise mutual information.\nExtensive experiments on 4 translation datasets demonstrate that the proposed\nmodel obtains an averaged gain of 1.0 BLEU score over a strong Transformer\nbaseline.", "published": "2019-08-29 02:20:26", "link": "http://arxiv.org/abs/1908.11020v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of\n  NER", "abstract": "BiLSTM has been prevalently used as a core module for NER in a\nsequence-labeling setup. State-of-the-art approaches use BiLSTM with additional\nresources such as gazetteers, language-modeling, or multi-task supervision to\nfurther improve NER. This paper instead takes a step back and focuses on\nanalyzing problems of BiLSTM itself and how exactly self-attention can bring\nimprovements. We formally show the limitation of (CRF-)BiLSTM in modeling\ncross-context patterns for each word -- the XOR limitation. Then, we show that\ntwo types of simple cross-structures -- self-attention and Cross-BiLSTM -- can\neffectively remedy the problem. We test the practical impacts of the deficiency\non real-world NER datasets, OntoNotes 5.0 and WNUT 2017, with clear and\nconsistent improvements over the baseline, up to 8.7% on some of the\nmulti-token entity mentions. We give in-depth analyses of the improvements\nacross several aspects of NER, especially the identification of multi-token\nmentions. This study should lay a sound foundation for future improvements on\nsequence-labeling NER. (Source codes:\nhttps://github.com/jacobvsdanniel/cross-ner)", "published": "2019-08-29 04:36:30", "link": "http://arxiv.org/abs/1908.11046v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shallow Syntax in Deep Water", "abstract": "Shallow syntax provides an approximation of phrase-syntactic structure of\nsentences; it can be produced with high accuracy, and is computationally cheap\nto obtain. We investigate the role of shallow syntax-aware representations for\nNLP tasks using two techniques. First, we enhance the ELMo architecture to\nallow pretraining on predicted shallow syntactic parses, instead of just raw\ntext, so that contextual embeddings make use of shallow syntactic context. Our\nsecond method involves shallow syntactic features obtained automatically on\ndownstream task data. Neither approach leads to a significant gain on any of\nthe four downstream tasks we considered relative to ELMo-only baselines.\nFurther analysis using black-box probes confirms that our shallow-syntax-aware\ncontextual embeddings do not transfer to linguistic tasks any more easily than\nELMo's embeddings. We take these findings as evidence that ELMo-style\npretraining discovers representations which make additional awareness of\nshallow syntax redundant.", "published": "2019-08-29 04:45:38", "link": "http://arxiv.org/abs/1908.11047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual and Multi-Aspect Hate Speech Analysis", "abstract": "Current research on hate speech analysis is typically oriented towards\nmonolingual and single classification tasks. In this paper, we present a new\nmultilingual multi-aspect hate speech analysis dataset and use it to test the\ncurrent state-of-the-art multilingual multitask learning approaches. We\nevaluate our dataset in various classification settings, then we discuss how to\nleverage our annotations in order to improve hate speech detection and\nclassification in general.", "published": "2019-08-29 04:53:29", "link": "http://arxiv.org/abs/1908.11049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Representations Learned by Multimodal Recurrent and Transformer\n  Models", "abstract": "Recent literature shows that large-scale language modeling provides excellent\nreusable sentence representations with both recurrent and self-attentive\narchitectures. However, there has been less clarity on the commonalities and\ndifferences in the representational properties induced by the two\narchitectures. It also has been shown that visual information serves as one of\nthe means for grounding sentence representations. In this paper, we present a\nmeta-study assessing the representational quality of models where the training\nsignal is obtained from different modalities, in particular, language modeling,\nimage features prediction, and both textual and multimodal machine translation.\nWe evaluate textual and visual features of sentence representations obtained\nusing predominant approaches on image retrieval and semantic textual\nsimilarity. Our experiments reveal that on moderate-sized datasets, a sentence\ncounterpart in a target language or visual modality provides much stronger\ntraining signal for sentence representation than language modeling.\nImportantly, we observe that while the Transformer models achieve superior\nmachine translation quality, representations from the recurrent neural network\nbased models perform significantly better over tasks focused on semantic\nrelevance.", "published": "2019-08-29 09:47:48", "link": "http://arxiv.org/abs/1908.11125v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Ellipsis Resolution as Question Answering: An Evaluation", "abstract": "Most, if not all forms of ellipsis (e.g., so does Mary) are similar to\nreading comprehension questions (what does Mary do), in that in order to\nresolve them, we need to identify an appropriate text span in the preceding\ndiscourse. Following this observation, we present an alternative approach for\nEnglish ellipsis resolution relying on architectures developed for question\nanswering (QA). We present both single-task models, and joint models trained on\nauxiliary QA and coreference resolution datasets, clearly outperforming the\ncurrent state of the art for Sluice Ellipsis (from 70.00 to 86.01 F1) and Verb\nPhrase Ellipsis (from 72.89 to 78.66 F1).", "published": "2019-08-29 10:25:10", "link": "http://arxiv.org/abs/1908.11141v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Summarization System for Scientific Documents", "abstract": "We present a novel system providing summaries for Computer Science\npublications. Through a qualitative user study, we identified the most valuable\nscenarios for discovery, exploration and understanding of scientific documents.\nBased on these findings, we built a system that retrieves and summarizes\nscientific documents for a given information need, either in form of a\nfree-text query or by choosing categorized values such as scientific tasks,\ndatasets and more. Our system ingested 270,000 papers, and its summarization\nmodule aims to generate concise yet detailed summaries. We validated our\napproach with human experts.", "published": "2019-08-29 11:17:33", "link": "http://arxiv.org/abs/1908.11152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global Reasoning over Database Structures for Text-to-SQL Parsing", "abstract": "State-of-the-art semantic parsers rely on auto-regressive decoding, emitting\none symbol at a time. When tested against complex databases that are unobserved\nat training time (zero-shot), the parser often struggles to select the correct\nset of database constants in the new database, due to the local nature of\ndecoding. In this work, we propose a semantic parser that globally reasons\nabout the structure of the output query to make a more contextually-informed\nselection of database constants. We use message-passing through a graph neural\nnetwork to softly select a subset of database constants for the output query,\nconditioned on the question. Moreover, we train a model to rank queries based\non the global alignment of database constants to question words. We apply our\ntechniques to the current state-of-the-art model for Spider, a zero-shot\nsemantic parsing dataset with complex databases, increasing accuracy from 39.4%\nto 47.4%.", "published": "2019-08-29 13:29:36", "link": "http://arxiv.org/abs/1908.11214v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FAMULUS: Interactive Annotation and Feedback Generation for Teaching\n  Diagnostic Reasoning", "abstract": "Our proposed system FAMULUS helps students learn to diagnose based on\nautomatic feedback in virtual patient simulations, and it supports instructors\nin labeling training data.\n  Diagnosing is an exceptionally difficult skill to obtain but vital for many\ndifferent professions (e.g., medical doctors, teachers).\n  Previous case simulation systems are limited to multiple-choice questions and\nthus cannot give constructive individualized feedback on a student's diagnostic\nreasoning process.\n  Given initially only limited data, we leverage a (replaceable) NLP model to\nboth support experts in their further data annotation with automatic\nsuggestions, and we provide automatic feedback for students.\n  We argue that because the central model consistently improves, our\ninteractive approach encourages both students and instructors to recurrently\nuse the tool, and thus accelerate the speed of data creation and annotation.\n  We show results from two user studies on diagnostic reasoning in medicine and\nteacher education and outline how our system can be extended to further use\ncases.", "published": "2019-08-29 14:25:23", "link": "http://arxiv.org/abs/1908.11254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounded Agreement Games: Emphasizing Conversational Grounding in Visual\n  Dialogue Settings", "abstract": "Where early work on dialogue in Computational Linguistics put much emphasis\non dialogue structure and its relation to the mental states of the dialogue\nparticipants (e.g., Allen 1979, Grosz & Sidner 1986), current work mostly\nreduces dialogue to the task of producing at any one time a next utterance;\ne.g. in neural chatbot or Visual Dialogue settings. As a methodological\ndecision, this is sound: Even the longest journey is a sequence of steps. It\nbecomes detrimental, however, when the tasks and datasets from which dialogue\nbehaviour is to be learned are tailored too much to this framing of the\nproblem. In this short note, we describe a family of settings which still allow\nto keep dialogues simple, but add a constraint that makes participants care\nabout reaching mutual understanding. In such agreement games, there is a\nsecondary, but explicit goal besides the task level goal, and that is to reach\nmutual understanding about whether the task level goal has been reached. As we\nargue, this naturally triggers meta-semantic interaction and mutual engagement,\nand hence leads to richer data from which to induce models.", "published": "2019-08-29 15:05:52", "link": "http://arxiv.org/abs/1908.11279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CCKS 2019 Shared Task on Inter-Personal Relationship Extraction", "abstract": "The CCKS2019 shared task was devoted to inter-personal relationship\nextraction. Given two person entities and at least one sentence containing\nthese two entities, participating teams are asked to predict the relationship\nbetween the entities according to a given relation list. This year, 358 teams\nfrom various universities and organizations participated in this task. In this\npaper, we present the task definition, the description of data and the\nevaluation methodology used during this shared task. We also present a brief\noverview of the various methods adopted by the participating teams. Finally, we\npresent the evaluation results.", "published": "2019-08-29 16:42:19", "link": "http://arxiv.org/abs/1908.11337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Deep Transformer with Depth-Scaled Initialization and Merged\n  Attention", "abstract": "The general trend in NLP is towards increasing model capacity and performance\nvia deeper neural networks. However, simply stacking more layers of the popular\nTransformer architecture for machine translation results in poor convergence\nand high computational overhead. Our empirical analysis suggests that\nconvergence is poor due to gradient vanishing caused by the interaction between\nresidual connections and layer normalization. We propose depth-scaled\ninitialization (DS-Init), which decreases parameter variance at the\ninitialization stage, and reduces output variance of residual connections so as\nto ease gradient back-propagation through normalization layers. To address\ncomputational cost, we propose a merged attention sublayer (MAtt) which\ncombines a simplified averagebased self-attention sublayer and the\nencoderdecoder attention sublayer on the decoder side. Results on WMT and IWSLT\ntranslation tasks with five translation directions show that deep Transformers\nwith DS-Init and MAtt can substantially outperform their base counterpart in\nterms of BLEU (+1.1 BLEU on average for 12-layer models), while matching the\ndecoding speed of the baseline model thanks to the efficiency improvements of\nMAtt.", "published": "2019-08-29 17:50:55", "link": "http://arxiv.org/abs/1908.11365v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Latent Parameters without Human Response Patterns: Item\n  Response Theory with Artificial Crowds", "abstract": "Incorporating Item Response Theory (IRT) into NLP tasks can provide valuable\ninformation about model performance and behavior. Traditionally, IRT models are\nlearned using human response pattern (RP) data, presenting a significant\nbottleneck for large data sets like those required for training deep neural\nnetworks (DNNs). In this work we propose learning IRT models using RPs\ngenerated from artificial crowds of DNN models. We demonstrate the\neffectiveness of learning IRT models using DNN-generated data through\nquantitative and qualitative analyses for two NLP tasks. Parameters learned\nfrom human and machine RPs for natural language inference and sentiment\nanalysis exhibit medium to large positive correlations. We demonstrate a\nuse-case for latent difficulty item parameters, namely training set filtering,\nand show that using difficulty to sample training data outperforms baseline\nmethods. Finally, we highlight cases where human expectation about item\ndifficulty does not match difficulty as estimated from the machine RPs.", "published": "2019-08-29 18:50:51", "link": "http://arxiv.org/abs/1908.11421v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual topic prediction for speech using translations", "abstract": "Given a large amount of unannotated speech in a low-resource language, can we\nclassify the speech utterances by topic? We consider this question in the\nsetting where a small amount of speech in the low-resource language is paired\nwith text translations in a high-resource language. We develop an effective\ncross-lingual topic classifier by training on just 20 hours of translated\nspeech, using a recent model for direct speech-to-text translation. While the\ntranslations are poor, they are still good enough to correctly classify the\ntopic of 1-minute speech segments over 70% of the time - a 20% improvement over\na majority-class baseline. Such a system could be useful for humanitarian\napplications like crisis response, where incoming speech in a foreign\nlow-resource language must be quickly assessed for further action.", "published": "2019-08-29 19:11:26", "link": "http://arxiv.org/abs/1908.11425v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Feature2Vec: Distributional semantic modelling of human property\n  knowledge", "abstract": "Feature norm datasets of human conceptual knowledge, collected in surveys of\nhuman volunteers, yield highly interpretable models of word meaning and play an\nimportant role in neurolinguistic research on semantic cognition. However,\nthese datasets are limited in size due to practical obstacles associated with\nexhaustively listing properties for a large number of words. In contrast, the\ndevelopment of distributional modelling techniques and the availability of vast\ntext corpora have allowed researchers to construct effective vector space\nmodels of word meaning over large lexicons. However, this comes at the cost of\ninterpretable, human-like information about word meaning. We propose a method\nfor mapping human property knowledge onto a distributional semantic space,\nwhich adapts the word2vec architecture to the task of modelling concept\nfeatures. Our approach gives a measure of concept and feature affinity in a\nsingle semantic space, which makes for easy and efficient ranking of candidate\nhuman-derived semantic properties for arbitrary words. We compare our model\nwith a previous approach, and show that it performs better on several\nevaluation tasks. Finally, we discuss how our method could be used to develop\nefficient sampling techniques to extend existing feature norm datasets in a\nreliable way.", "published": "2019-08-29 19:57:25", "link": "http://arxiv.org/abs/1908.11439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NarrativeTime: Dense Temporal Annotation on a Timeline", "abstract": "For the past decade, temporal annotation has been sparse: only a small\nportion of event pairs in a text was annotated. We present NarrativeTime, the\nfirst timeline-based annotation framework that achieves full coverage of all\npossible TLinks. To compare with the previous SOTA in dense temporal\nannotation, we perform full re-annotation of TimeBankDense corpus, which shows\ncomparable agreement with a significant increase in density. We contribute\nTimeBankNT corpus (with each text fully annotated by two expert annotators),\nextensive annotation guidelines, open-source tools for annotation and\nconversion to TimeML format, baseline results, as well as quantitative and\nqualitative analysis of inter-annotator agreement.", "published": "2019-08-29 20:09:27", "link": "http://arxiv.org/abs/1908.11443v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting and Reducing Bias in a High Stakes Domain", "abstract": "Gang-involved youth in cities such as Chicago sometimes post on social media\nto express their aggression towards rival gangs and previous research has\ndemonstrated that a deep learning approach can predict aggression and loss in\nposts. To address the possibility of bias in this sensitive application, we\ndeveloped an approach to systematically interpret the state of the art model.\nWe found, surprisingly, that it frequently bases its predictions on stop words\nsuch as \"a\" or \"on\", an approach that could harm social media users who have no\naggressive intentions. To tackle this bias, domain experts annotated the\nrationales, highlighting words that explain why a tweet is labeled as\n\"aggression\". These new annotations enable us to quantitatively measure how\njustified the model predictions are, and build models that drastically reduce\nbias. Our study shows that in high stake scenarios, accuracy alone cannot\nguarantee a good system and we need new evaluation methods.", "published": "2019-08-29 22:44:41", "link": "http://arxiv.org/abs/1908.11474v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Snowball for Few-Shot Relation Learning", "abstract": "Knowledge graphs typically undergo open-ended growth of new relations. This\ncannot be well handled by relation extraction that focuses on pre-defined\nrelations with sufficient training data. To address new relations with few-shot\ninstances, we propose a novel bootstrapping approach, Neural Snowball, to learn\nnew relations by transferring semantic knowledge about existing relations. More\nspecifically, we use Relational Siamese Networks (RSN) to learn the metric of\nrelational similarities between instances based on existing relations and their\nlabeled data. Afterwards, given a new relation and its few-shot instances, we\nuse RSN to accumulate reliable instances from unlabeled corpora; these\ninstances are used to train a relation classifier, which can further identify\nnew facts of the new relation. The process is conducted iteratively like a\nsnowball. Experiments show that our model can gather high-quality instances for\nbetter few-shot relation learning and achieves significant improvement compared\nto baselines. Codes and datasets are released on\nhttps://github.com/thunlp/Neural-Snowball.", "published": "2019-08-29 01:25:52", "link": "http://arxiv.org/abs/1908.11007v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Ethical Content-Based Detection of Online Influence Campaigns", "abstract": "The detection of clandestine efforts to influence users in online communities\nis a challenging problem with significant active development. We demonstrate\nthat features derived from the text of user comments are useful for identifying\nsuspect activity, but lead to increased erroneous identifications when keywords\nover-represented in past influence campaigns are present. Drawing on research\nin native language identification (NLI), we use \"named entity masking\" (NEM) to\ncreate sentence features robust to this shortcoming, while maintaining\ncomparable classification accuracy. We demonstrate that while NEM consistently\nreduces false positives when key named entities are mentioned, both masked and\nunmasked models exhibit increased false positive rates on English sentences by\nRussian native speakers, raising ethical considerations that should be\naddressed in future research.", "published": "2019-08-29 03:18:21", "link": "http://arxiv.org/abs/1908.11030v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Zero-shot Text-to-SQL Learning with Auxiliary Task", "abstract": "Recent years have seen great success in the use of neural seq2seq models on\nthe text-to-SQL task. However, little work has paid attention to how these\nmodels generalize to realistic unseen data, which naturally raises a question:\ndoes this impressive performance signify a perfect generalization model, or are\nthere still some limitations?\n  In this paper, we first diagnose the bottleneck of text-to-SQL task by\nproviding a new testbed, in which we observe that existing models present poor\ngeneralization ability on rarely-seen data. The above analysis encourages us to\ndesign a simple but effective auxiliary task, which serves as a supportive\nmodel as well as a regularization term to the generation task to increase the\nmodels generalization. Experimentally, We evaluate our models on a large\ntext-to-SQL dataset WikiSQL. Compared to a strong baseline coarse-to-fine\nmodel, our models improve over the baseline by more than 3% absolute in\naccuracy on the whole dataset. More interestingly, on a zero-shot subset test\nof WikiSQL, our models achieve 5% absolute accuracy gain over the baseline,\nclearly demonstrating its superior generalizability.", "published": "2019-08-29 05:01:39", "link": "http://arxiv.org/abs/1908.11052v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Frequent Query Substructures to Generate Formal Queries for\n  Complex Question Answering", "abstract": "Formal query generation aims to generate correct executable queries for\nquestion answering over knowledge bases (KBs), given entity and relation\nlinking results. Current approaches build universal paraphrasing or ranking\nmodels for the whole questions, which are likely to fail in generating queries\nfor complex, long-tail questions. In this paper, we propose SubQG, a new query\ngeneration approach based on frequent query substructures, which helps rank the\nexisting (but nonsignificant) query structures or build new query structures.\nOur experiments on two benchmark datasets show that our approach significantly\noutperforms the existing ones, especially for complex questions. Also, it\nachieves promising performance with limited training data and noisy\nentity/relation linking results.", "published": "2019-08-29 05:03:57", "link": "http://arxiv.org/abs/1908.11053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Document Hashing with Mixture-Prior Generative Models", "abstract": "Hashing is promising for large-scale information retrieval tasks thanks to\nthe efficiency of distance evaluation between binary codes. Generative hashing\nis often used to generate hashing codes in an unsupervised way. However,\nexisting generative hashing methods only considered the use of simple priors,\nlike Gaussian and Bernoulli priors, which limits these methods to further\nimprove their performance. In this paper, two mixture-prior generative models\nare proposed, under the objective to produce high-quality hashing codes for\ndocuments. Specifically, a Gaussian mixture prior is first imposed onto the\nvariational auto-encoder (VAE), followed by a separate step to cast the\ncontinuous latent representation of VAE into binary code. To avoid the\nperformance loss caused by the separate casting, a model using a Bernoulli\nmixture prior is further developed, in which an end-to-end training is admitted\nby resorting to the straight-through (ST) discrete gradient estimator.\nExperimental results on several benchmark datasets demonstrate that the\nproposed methods, especially the one using Bernoulli mixture priors,\nconsistently outperform existing ones by a substantial margin.", "published": "2019-08-29 07:29:28", "link": "http://arxiv.org/abs/1908.11078v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "KBSET -- Knowledge-Based Support for Scholarly Editing and Text\n  Processing", "abstract": "KBSET supports a practical workflow for scholarly editing, based on using\nLaTeX with dedicated commands for semantics-oriented markup and a\nProlog-implemented core system. Prolog plays there various roles: as query\nlanguage and access mechanism for large Semantic Web fact bases, as data\nrepresentation of structured documents and as a workflow model for advanced\napplication tasks. The core system includes a LaTeX parser and a facility for\nthe identification of named entities. We also sketch future perspectives of\nthis approach to scholarly editing based on techniques of computational logic.", "published": "2019-08-29 10:14:40", "link": "http://arxiv.org/abs/1908.11135v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Aesthetic Image Captioning From Weakly-Labelled Photographs", "abstract": "Aesthetic image captioning (AIC) refers to the multi-modal task of generating\ncritical textual feedbacks for photographs. While in natural image captioning\n(NIC), deep models are trained in an end-to-end manner using large curated\ndatasets such as MS-COCO, no such large-scale, clean dataset exists for AIC.\nTowards this goal, we propose an automatic cleaning strategy to create a\nbenchmarking AIC dataset, by exploiting the images and noisy comments easily\navailable from photography websites. We propose a probabilistic\ncaption-filtering method for cleaning the noisy web-data, and compile a\nlarge-scale, clean dataset \"AVA-Captions\", (230, 000 images with 5 captions per\nimage). Additionally, by exploiting the latent associations between aesthetic\nattributes, we propose a strategy for training the convolutional neural network\n(CNN) based visual feature extractor, the first component of the AIC framework.\nThe strategy is weakly supervised and can be effectively used to learn rich\naesthetic representations, without requiring expensive ground-truth\nannotations. We finally show-case a thorough analysis of the proposed\ncontributions using automatic metrics and subjective evaluations.", "published": "2019-08-29 15:50:28", "link": "http://arxiv.org/abs/1908.11310v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Translate and Label! An Encoder-Decoder Approach for Cross-lingual\n  Semantic Role Labeling", "abstract": "We propose a Cross-lingual Encoder-Decoder model that simultaneously\ntranslates and generates sentences with Semantic Role Labeling annotations in a\nresource-poor target language. Unlike annotation projection techniques, our\nmodel does not need parallel data during inference time. Our approach can be\napplied in monolingual, multilingual and cross-lingual settings and is able to\nproduce dependency-based and span-based SRL annotations. We benchmark the\nlabeling performance of our model in different monolingual and multilingual\nsettings using well-known SRL datasets. We then train our model in a\ncross-lingual setting to generate new SRL labeled data. Finally, we measure the\neffectiveness of our method by using the generated data to augment the training\nbasis for resource-poor languages and perform manual evaluation to show that it\nproduces high-quality sentences and assigns accurate semantic role annotations.\nOur proposed architecture offers a flexible method for leveraging SRL data in\nmultiple languages.", "published": "2019-08-29 16:17:53", "link": "http://arxiv.org/abs/1908.11326v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Two-Pass End-to-End Speech Recognition", "abstract": "The requirements for many applications of state-of-the-art speech recognition\nsystems include not only low word error rate (WER) but also low latency.\nSpecifically, for many use-cases, the system must be able to decode utterances\nin a streaming fashion and faster than real-time. Recently, a streaming\nrecurrent neural network transducer (RNN-T) end-to-end (E2E) model has shown to\nbe a good candidate for on-device speech recognition, with improved WER and\nlatency metrics compared to conventional on-device models [1]. However, this\nmodel still lags behind a large state-of-the-art conventional model in quality\n[2]. On the other hand, a non-streaming E2E Listen, Attend and Spell (LAS)\nmodel has shown comparable quality to large conventional models [3]. This work\naims to bring the quality of an E2E streaming model closer to that of a\nconventional system by incorporating a LAS network as a second-pass component,\nwhile still abiding by latency constraints. Our proposed two-pass model\nachieves a 17%-22% relative reduction in WER compared to RNN-T alone and\nincreases latency by a small fraction over RNN-T.", "published": "2019-08-29 00:18:05", "link": "http://arxiv.org/abs/1908.10992v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scientific Statement Classification over arXiv.org", "abstract": "We introduce a new classification task for scientific statements and release\na large-scale dataset for supervised learning. Our resource is derived from a\nmachine-readable representation of the arXiv.org collection of preprint\narticles. We explore fifty author-annotated categories and empirically motivate\na task design of grouping 10.5 million annotated paragraphs into thirteen\nclasses. We demonstrate that the task setup aligns with known success rates\nfrom the state of the art, peaking at a 0.91 F1-score via a BiLSTM\nencoder-decoder model. Additionally, we introduce a lexeme serialization for\nmathematical formulas, and observe that context-aware models could improve when\nalso trained on the symbolic modality. Finally, we discuss the limitations of\nboth data and task design, and outline potential directions towards\nincreasingly complex models of scientific discourse, beyond isolated\nstatements.", "published": "2019-08-29 00:25:38", "link": "http://arxiv.org/abs/1908.10993v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "A Deep Neural Information Fusion Architecture for Textual Network\n  Embeddings", "abstract": "Textual network embeddings aim to learn a low-dimensional representation for\nevery node in the network so that both the structural and textual information\nfrom the networks can be well preserved in the representations. Traditionally,\nthe structural and textual embeddings were learned by models that rarely take\nthe mutual influences between them into account. In this paper, a deep neural\narchitecture is proposed to effectively fuse the two kinds of informations into\none representation. The novelties of the proposed architecture are manifested\nin the aspects of a newly defined objective function, the complementary\ninformation fusion method for structural and textual features, and the mutual\ngate mechanism for textual feature extraction. Experimental results show that\nthe proposed model outperforms the comparing methods on all three datasets.", "published": "2019-08-29 05:19:53", "link": "http://arxiv.org/abs/1908.11057v2", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "From the Token to the Review: A Hierarchical Multimodal approach to\n  Opinion Mining", "abstract": "The task of predicting fine grained user opinion based on spontaneous spoken\nlanguage is a key problem arising in the development of Computational Agents as\nwell as in the development of social network based opinion miners.\nUnfortunately, gathering reliable data on which a model can be trained is\nnotoriously difficult and existing works rely only on coarsely labeled\nopinions. In this work we aim at bridging the gap separating fine grained\nopinion models already developed for written language and coarse grained models\ndeveloped for spontaneous multimodal opinion mining. We take advantage of the\nimplicit hierarchical structure of opinions to build a joint fine and coarse\ngrained opinion model that exploits different views of the opinion expression.\nThe resulting model shares some properties with attention-based models and is\nshown to provide competitive results on a recently released multimodal fine\ngrained annotated corpus.", "published": "2019-08-29 13:34:50", "link": "http://arxiv.org/abs/1908.11216v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "HARE: a Flexible Highlighting Annotator for Ranking and Exploration", "abstract": "Exploration and analysis of potential data sources is a significant challenge\nin the application of NLP techniques to novel information domains. We describe\nHARE, a system for highlighting relevant information in document collections to\nsupport ranking and triage, which provides tools for post-processing and\nqualitative analysis for model development and tuning. We apply HARE to the use\ncase of narrative descriptions of mobility information in clinical data, and\ndemonstrate its utility in comparing candidate embedding features. We provide a\nweb-based interface for annotation visualization and document ranking, with a\nmodular backend to support interoperability with existing annotation tools. Our\nsystem is available online at https://github.com/OSU-slatelab/HARE.", "published": "2019-08-29 15:36:40", "link": "http://arxiv.org/abs/1908.11302v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Memorizing All for Implicit Discourse Relation Recognition", "abstract": "Implicit discourse relation recognition is a challenging task due to the\nabsence of the necessary informative clue from explicit connectives. The\nprediction of relations requires a deep understanding of the semantic meanings\nof sentence pairs. As implicit discourse relation recognizer has to carefully\ntackle the semantic similarity of the given sentence pairs and the severe data\nsparsity issue exists in the meantime, it is supposed to be beneficial from\nmastering the entire training data. Thus in this paper, we propose a novel\nmemory mechanism to tackle the challenges for further performance improvement.\nThe memory mechanism is adequately memorizing information by pairing\nrepresentations and discourse relations of all training instances, which right\nfills the slot of the data-hungry issue in the current implicit discourse\nrelation recognizer. Our experiments show that our full model with memorizing\nthe entire training set reaches new state-of-the-art against strong baselines,\nwhich especially for the first time exceeds the milestone of 60% accuracy in\nthe 4-way task.", "published": "2019-08-29 16:00:25", "link": "http://arxiv.org/abs/1908.11317v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human-grounded Evaluations of Explanation Methods for Text\n  Classification", "abstract": "Due to the black-box nature of deep learning models, methods for explaining\nthe models' results are crucial to gain trust from humans and support\ncollaboration between AIs and humans. In this paper, we consider several\nmodel-agnostic and model-specific explanation methods for CNNs for text\nclassification and conduct three human-grounded evaluations, focusing on\ndifferent purposes of explanations: (1) revealing model behavior, (2)\njustifying model predictions, and (3) helping humans investigate uncertain\npredictions. The results highlight dissimilar qualities of the various\nexplanation methods we consider and show the degree to which these methods\ncould serve for each purpose.", "published": "2019-08-29 17:12:04", "link": "http://arxiv.org/abs/1908.11355v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Bayesian Unsupervised Source Separation Based on a Complex Gaussian\n  Mixture Model", "abstract": "This paper presents an unsupervised method that trains neural source\nseparation by using only multichannel mixture signals. Conventional neural\nseparation methods require a lot of supervised data to achieve excellent\nperformance. Although multichannel methods based on spatial information can\nwork without such training data, they are often sensitive to parameter\ninitialization and degraded with the sources located close to each other. The\nproposed method uses a cost function based on a spatial model called a complex\nGaussian mixture model (cGMM). This model has the time-frequency (TF) masks and\ndirection of arrivals (DoAs) of sources as latent variables and is used for\ntraining separation and localization networks that respectively estimate these\nvariables. This joint training solves the frequency permutation ambiguity of\nthe spatial model in a unified deep Bayesian framework. In addition, the\npre-trained network can be used not only for conducting monaural separation but\nalso for efficiently initializing a multichannel separation algorithm.\nExperimental results with simulated speech mixtures showed that our method\noutperformed a conventional initialization method.", "published": "2019-08-29 15:45:20", "link": "http://arxiv.org/abs/1908.11307v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
