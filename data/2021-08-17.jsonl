{"title": "Annotation Guidelines for the Turku Paraphrase Corpus", "abstract": "This document describes the annotation guidelines used to construct the Turku\nParaphrase Corpus. These guidelines were developed together with the corpus\nannotation, revising and extending the guidelines regularly during the\nannotation work. Our paraphrase annotation scheme uses the base scale 1-4,\nwhere labels 1 and 2 are used for negative candidates (not paraphrases), while\nlabels 3 and 4 are paraphrases at least in the given context if not everywhere.\nIn addition to base labeling, the scheme is enriched with additional\nsubcategories (flags) for categorizing different types of paraphrases inside\nthe two positive labels, making the annotation scheme suitable for more\nfine-grained paraphrase categorization. The annotation scheme is used to\nannotate over 100,000 Finnish paraphrase pairs.", "published": "2021-08-17 08:32:55", "link": "http://arxiv.org/abs/2108.07499v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPMoE: Generate Multiple Pattern-Aware Outputs with Sparse Pattern\n  Mixture of Experts", "abstract": "Many generation tasks follow a one-to-many mapping relationship: each input\ncould be associated with multiple outputs. Existing methods like Conditional\nVariational AutoEncoder(CVAE) employ a latent variable to model this\none-to-many relationship. However, this high-dimensional and dense latent\nvariable lacks explainability and usually leads to poor and uncontrollable\ngenerations. In this paper, we innovatively introduce the linguistic concept of\npattern to decompose the one-to-many mapping into multiple one-to-one mappings\nand further propose a model named Sparse Pattern Mixture of Experts(SPMoE).\nEach one-to-one mapping is associated with a conditional generation pattern and\nis modeled with an expert in SPMoE. To ensure each language pattern can be\nexclusively handled with an expert model for better explainability and\ndiversity, a sparse mechanism is employed to coordinate all the expert models\nin SPMoE. We assess the performance of our SPMoE on the paraphrase generation\ntask and the experiment results prove that SPMoE can achieve a good balance in\nterms of quality, pattern-level diversity, and corpus-level diversity.", "published": "2021-08-17 09:37:37", "link": "http://arxiv.org/abs/2108.07535v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph Capsule Aggregation for Unaligned Multimodal Sequences", "abstract": "Humans express their opinions and emotions through multiple modalities which\nmainly consist of textual, acoustic and visual modalities. Prior works on\nmultimodal sentiment analysis mostly apply Recurrent Neural Network (RNN) to\nmodel aligned multimodal sequences. However, it is unpractical to align\nmultimodal sequences due to different sample rates for different modalities.\nMoreover, RNN is prone to the issues of gradient vanishing or exploding and it\nhas limited capacity of learning long-range dependency which is the major\nobstacle to model unaligned multimodal sequences. In this paper, we introduce\nGraph Capsule Aggregation (GraphCAGE) to model unaligned multimodal sequences\nwith graph-based neural model and Capsule Network. By converting sequence data\ninto graph, the previously mentioned problems of RNN are avoided. In addition,\nthe aggregation capability of Capsule Network and the graph-based structure\nenable our model to be interpretable and better solve the problem of long-range\ndependency. Experimental results suggest that GraphCAGE achieves\nstate-of-the-art performance on two benchmark datasets with representations\nrefined by Capsule Network and interpretation provided.", "published": "2021-08-17 10:04:23", "link": "http://arxiv.org/abs/2108.07543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Linearizations Are Equally Data-Hungry in Sequence Labeling\n  Parsing", "abstract": "Different linearizations have been proposed to cast dependency parsing as\nsequence labeling and solve the task as: (i) a head selection problem, (ii)\nfinding a representation of the token arcs as bracket strings, or (iii)\nassociating partial transition sequences of a transition-based parser to words.\nYet, there is little understanding about how these linearizations behave in\nlow-resource setups. Here, we first study their data efficiency, simulating\ndata-restricted setups from a diverse set of rich-resource treebanks. Second,\nwe test whether such differences manifest in truly low-resource setups. The\nresults show that head selection encodings are more data-efficient and perform\nbetter in an ideal (gold) framework, but that such advantage greatly vanishes\nin favour of bracketing formats when the running setup resembles a real-world\nlow-resource configuration.", "published": "2021-08-17 10:47:30", "link": "http://arxiv.org/abs/2108.07556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Weakly Supervised Dataset of Fine-Grained Emotions in Portuguese", "abstract": "Affective Computing is the study of how computers can recognize, interpret\nand simulate human affects. Sentiment Analysis is a common task inNLP related\nto this topic, but it focuses only on emotion valence (positive, negative,\nneutral). An emerging approach in NLP is Emotion Recognition, which relies on\nfined-grained classification. This research describes an approach to create a\nlexical-based weakly supervised corpus for fine-grained emotion in Portuguese.\nWe evaluated our dataset by fine-tuning a transformer-based language model\n(BERT) and validating it on a Gold Standard annotated validation set. Our\nresults (F1-score=.64) suggest lexical-based weak supervision as an appropriate\nstrategy for initial work in low resourced environment.", "published": "2021-08-17 14:08:23", "link": "http://arxiv.org/abs/2108.07638v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Game Interface to Study Semantic Grounding in Text-Based Models", "abstract": "Can language models learn grounded representations from text distribution\nalone? This question is both central and recurrent in natural language\nprocessing; authors generally agree that grounding requires more than textual\ndistribution. We propose to experimentally test this claim: if any two words\nhave different meanings and yet cannot be distinguished from distribution\nalone, then grounding is out of the reach of text-based models. To that end, we\npresent early work on an online game for the collection of human judgments on\nthe distributional similarity of word pairs in five languages. We further\nreport early results of our data collection campaign.", "published": "2021-08-17 15:50:44", "link": "http://arxiv.org/abs/2108.07708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges and Applications of Automated Extraction of Socio-political\n  Events from Text (CASE 2021): Workshop and Shared Task Report", "abstract": "This workshop is the fourth issue of a series of workshops on automatic\nextraction of socio-political events from news, organized by the Emerging\nMarket Welfare Project, with the support of the Joint Research Centre of the\nEuropean Commission and with contributions from many other prominent scholars\nin this field. The purpose of this series of workshops is to foster research\nand development of reliable, valid, robust, and practical solutions for\nautomatically detecting descriptions of socio-political events, such as\nprotests, riots, wars and armed conflicts, in text streams. This year workshop\ncontributors make use of the state-of-the-art NLP technologies, such as Deep\nLearning, Word Embeddings and Transformers and cover a wide range of topics\nfrom text classification to news bias detection. Around 40 teams have\nregistered and 15 teams contributed to three tasks that are i) multilingual\nprotest news detection, ii) fine-grained classification of socio-political\nevents, and iii) discovering Black Lives Matter protest events. The workshop\nalso highlights two keynote and four invited talks about various aspects of\ncreating event data sets and multi- and cross-lingual machine learning in few-\nand zero-shot settings.", "published": "2021-08-17 20:29:49", "link": "http://arxiv.org/abs/2108.07865v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualizing Variation in Text Style Transfer Datasets", "abstract": "Text style transfer involves rewriting the content of a source sentence in a\ntarget style. Despite there being a number of style tasks with available data,\nthere has been limited systematic discussion of how text style datasets relate\nto each other. This understanding, however, is likely to have implications for\nselecting multiple data sources for model training. While it is prudent to\nconsider inherent stylistic properties when determining these relationships, we\nalso must consider how a style is realized in a particular dataset. In this\npaper, we conduct several empirical analyses of existing text style datasets.\nBased on our results, we propose a categorization of stylistic and dataset\nproperties to consider when utilizing or comparing text style datasets.", "published": "2021-08-17 20:54:24", "link": "http://arxiv.org/abs/2108.07871v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MigrationsKB: A Knowledge Base of Public Attitudes towards Migrations\n  and their Driving Factors", "abstract": "With the increasing trend in the topic of migration in Europe, the public is\nnow more engaged in expressing their opinions through various platforms such as\nTwitter. Understanding the online discourses is therefore essential to capture\nthe public opinion. The goal of this study is the analysis of social media\nplatform to quantify public attitudes towards migrations and the identification\nof different factors causing these attitudes. The tweets spanning from 2013 to\nJul-2021 in the European countries which are hosts to immigrants are collected,\npre-processed, and filtered using advanced topic modeling technique. BERT-based\nentity linking and sentiment analysis, and attention-based hate speech\ndetection are performed to annotate the curated tweets. Moreover, the external\ndatabases are used to identify the potential social and economic factors\ncausing negative attitudes of the people about migration. To further promote\nresearch in the interdisciplinary fields of social science and computer\nscience, the outcomes are integrated into a Knowledge Base (KB), i.e.,\nMigrationsKB which significantly extends the existing models to take into\naccount the public attitudes towards migrations and the economic indicators.\nThis KB is made public using FAIR principles, which can be queried through\nSPARQL endpoint. Data dumps are made available on Zenodo.", "published": "2021-08-17 12:50:39", "link": "http://arxiv.org/abs/2108.07593v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T07"], "primary_category": "cs.CL"}
{"title": "On Incorrectness Logic and Kleene Algebra with Top and Tests", "abstract": "Kleene algebra with tests (KAT) is a foundational equational framework for\nreasoning about programs, which has found applications in program\ntransformations, networking and compiler optimizations, among many other areas.\nIn his seminal work, Kozen proved that KAT subsumes propositional Hoare logic,\nshowing that one can reason about the (partial) correctness of while programs\nby means of the equational theory of KAT. In this work, we investigate the\nsupport that KAT provides for reasoning about incorrectness, instead, as\nembodied by Ohearn's recently proposed incorrectness logic. We show that KAT\ncannot directly express incorrectness logic. The main reason for this\nlimitation can be traced to the fact that KAT cannot express explicitly the\nnotion of codomain, which is essential to express incorrectness triples. To\naddress this issue, we study Kleene Algebra with Top and Tests (TopKAT), an\nextension of KAT with a top element. We show that TopKAT is powerful enough to\nexpress a codomain operation, to express incorrectness triples, and to prove\nall the rules of incorrectness logic sound. This shows that one can reason\nabout the incorrectness of while-like programs by means of the equational\ntheory of TopKAT.", "published": "2021-08-17 15:50:21", "link": "http://arxiv.org/abs/2108.07707v4", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Higher-Order Concurrency for Microcontrollers", "abstract": "Programming microcontrollers involves low-level interfacing with hardware and\nperipherals that are concurrent and reactive. Such programs are typically\nwritten in a mixture of C and assembly using concurrent language extensions\n(like $\\texttt{FreeRTOS tasks}$ and $\\texttt{semaphores}$), resulting in\nunsafe, callback-driven, error-prone and difficult-to-maintain code.\n  We address this challenge by introducing $\\texttt{SenseVM}$ - a\nbytecode-interpreted virtual machine that provides a message-passing based\n$\\textit{higher-order concurrency}$ model, originally introduced by Reppy, for\nmicrocontroller programming. This model treats synchronous operations as\nfirst-class values (called $\\texttt{Events}$) akin to the treatment of\nfirst-class functions in functional languages. This primarily allows the\nprogrammer to compose and tailor their own concurrency abstractions and,\nadditionally, abstracts away unsafe memory operations, common in shared-memory\nconcurrency models, thereby making microcontroller programs safer, composable\nand easier-to-maintain.\n  Our VM is made portable via a low-level $\\textit{bridge}$ interface, built\natop the embedded OS - Zephyr. The bridge is implemented by all drivers and\ndesigned such that programming in response to a software message or a hardware\ninterrupt remains uniform and indistinguishable. In this paper we demonstrate\nthe features of our VM through an example, written in a Caml-like functional\nlanguage, running on the $\\texttt{nRF52840}$ and $\\texttt{STM32F4}$\nmicrocontrollers.", "published": "2021-08-17 15:11:03", "link": "http://arxiv.org/abs/2108.07805v2", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Modulating Language Models with Emotions", "abstract": "Generating context-aware language that embodies diverse emotions is an\nimportant step towards building empathetic NLP systems. In this paper, we\npropose a formulation of modulated layer normalization -- a technique inspired\nby computer vision -- that allows us to use large-scale language models for\nemotional response generation. In automatic and human evaluation on the\nMojiTalk dataset, our proposed modulated layer normalization method outperforms\nprior baseline methods while maintaining diversity, fluency, and coherence. Our\nmethod also obtains competitive performance even when using only 10% of the\navailable training data.", "published": "2021-08-17 21:32:49", "link": "http://arxiv.org/abs/2108.07886v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modeling Protein Using Large-scale Pretrain Language Model", "abstract": "Protein is linked to almost every life process. Therefore, analyzing the\nbiological structure and property of protein sequences is critical to the\nexploration of life, as well as disease detection and drug discovery.\nTraditional protein analysis methods tend to be labor-intensive and\ntime-consuming. The emergence of deep learning models makes modeling data\npatterns in large quantities of data possible. Interdisciplinary researchers\nhave begun to leverage deep learning methods to model large biological\ndatasets, e.g. using long short-term memory and convolutional neural network\nfor protein sequence classification. After millions of years of evolution,\nevolutionary information is encoded in protein sequences. Inspired by the\nsimilarity between natural language and protein sequences, we use large-scale\nlanguage models to model evolutionary-scale protein sequences, encoding protein\nbiology information in representation. Significant improvements are observed in\nboth token-level and sequence-level tasks, demonstrating that our large-scale\nmodel can accurately capture evolution information from pretraining on\nevolutionary-scale individual sequences. Our code and model are available at\nhttps://github.com/THUDM/ProteinLM.", "published": "2021-08-17 04:13:11", "link": "http://arxiv.org/abs/2108.07435v2", "categories": ["cs.LG", "cs.CL", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "A Light-weight contextual spelling correction model for customizing\n  transducer-based speech recognition systems", "abstract": "It's challenging to customize transducer-based automatic speech recognition\n(ASR) system with context information which is dynamic and unavailable during\nmodel training. In this work, we introduce a light-weight contextual spelling\ncorrection model to correct context-related recognition errors in\ntransducer-based ASR systems. We incorporate the context information into the\nspelling correction model with a shared context encoder and use a filtering\nalgorithm to handle large-size context lists. Experiments show that the model\nimproves baseline ASR model performance with about 50% relative word error rate\nreduction, which also significantly outperforms the baseline method such as\ncontextual LM biasing. The model also shows excellent performance for\nout-of-vocabulary terms not seen during training.", "published": "2021-08-17 08:14:37", "link": "http://arxiv.org/abs/2108.07493v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ACM-CR: A Manually Annotated Test Collection for Citation Recommendation", "abstract": "Citation recommendation is intended to assist researchers in the process of\nsearching for relevant papers to cite by recommending appropriate citations for\na given input text. Existing test collections for this task are noisy and\nunreliable since they are built automatically from parsed PDF papers. In this\npaper, we present our ongoing effort at creating a publicly available, manually\nannotated test collection for citation recommendation. We also conduct a series\nof experiments to evaluate the effectiveness of content-based baseline models\non the test collection, providing results for future work to improve upon. Our\ntest collection and code to replicate experiments are available at\nhttps://github.com/boudinfl/acm-cr", "published": "2021-08-17 11:51:51", "link": "http://arxiv.org/abs/2108.07571v1", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Combining speakers of multiple languages to improve quality of neural\n  voices", "abstract": "In this work, we explore multiple architectures and training procedures for\ndeveloping a multi-speaker and multi-lingual neural TTS system with the goals\nof a) improving the quality when the available data in the target language is\nlimited and b) enabling cross-lingual synthesis. We report results from a large\nexperiment using 30 speakers in 8 different languages across 15 different\nlocales. The system is trained on the same amount of data per speaker. Compared\nto a single-speaker model, when the suggested system is fine tuned to a\nspeaker, it produces significantly better quality in most of the cases while it\nonly uses less than $40\\%$ of the speaker's data used to build the\nsingle-speaker model. In cross-lingual synthesis, on average, the generated\nquality is within $80\\%$ of native single-speaker models, in terms of Mean\nOpinion Score.", "published": "2021-08-17 16:14:13", "link": "http://arxiv.org/abs/2108.07737v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A comparative study of universal quantum computing models: towards a\n  physical unification", "abstract": "Quantum computing has been a fascinating research field in quantum physics.\nRecent progresses motivate us to study in depth the universal quantum computing\nmodels (UQCM), which lie at the foundation of quantum computing and have tight\nconnections with fundamental physics. Although being developed decades ago, a\nphysically concise principle or picture to formalize and understand UQCM is\nstill lacking. This is challenging given the diversity of still-emerging\nmodels, but important to understand the difference between classical and\nquantum computing. In this work, we carried out a primary attempt to unify UQCM\nby classifying a few of them as two categories, hence making a table of models.\nWith such a table, some known models or schemes appear as hybridization or\ncombination of models, and more importantly, it leads to new schemes that have\nnot been explored yet. Our study of UQCM also leads to some insights into\nquantum algorithms. This work reveals the importance and feasibility of\nsystematic study of computing models.", "published": "2021-08-17 23:56:04", "link": "http://arxiv.org/abs/2108.07909v3", "categories": ["quant-ph", "cond-mat.str-el", "cs.CL"], "primary_category": "quant-ph"}
{"title": "General Theory of Music by Icosahedron 2: Analysis of musical pieces by\n  the exceptional musical icosahedra", "abstract": "We propose a new way of analyzing musical pieces by using the exceptional\nmusical icosahedra where all the major/minor triads are represented by golden\ntriangles or golden gnomons. First, we introduce a concept of the golden\nneighborhood that characterizes golden triangles/gnomons that neighbor a given\ngolden triangle or gnomon. Then, we investigate a relation between the\nexceptional musical icosahedra and the neo-Riemannian theory, and find that the\ngolden neighborhoods and the icosahedron symmetry relate any major/minor triad\nwith any major/minor triad. Second, we show how the exceptional musical\nicosahedra are applied to analyzing harmonies constructed by four or more\ntones. We introduce two concepts, golden decomposition and golden singular. The\ngolden decomposition is a decomposition of a given harmony into the minimum\nnumber of harmonies constructing the given harmony and represented by the\ngolden figure (a golden triangle, a golden gnomon, or a golden rectangle). A\nharmony is golden singular if and only if the harmony does not have golden\ndecompositions. We show results of the golden analysis (analysis by the golden\ndecomposition) of the tertian seventh chords and the mystic chord. While the\ndominant seventh chord is the only tertian seventh chord that is golden\nsingular in the type 1[star] and the type 4[star] exceptional musical\nicosahedron, the half-diminished seventh chord is the only tertian seventh\nchord that is golden singular in the type 2 [star] and the type 3[star]\nexceptional musical icosahedron. Last, we apply the golden analysis to the\nfamous prelude in C major composed by Johann Sebastian Bach (BWV 846). We found\n7 combinations of the golden figures on the type 2 [star] or the type 3 [star]\nexceptional musical icosahedron dually represent all the measures of the BWV\n846.", "published": "2021-08-17 15:19:38", "link": "http://arxiv.org/abs/2108.10294v3", "categories": ["cs.SD", "eess.AS", "00A65"], "primary_category": "cs.SD"}
{"title": "NeuralSound: Learning-based Modal Sound Synthesis With Acoustic Transfer", "abstract": "We present a novel learning-based modal sound synthesis approach that\nincludes a mixed vibration solver for modal analysis and an end-to-end sound\nradiation network for acoustic transfer. Our mixed vibration solver consists of\na 3D sparse convolution network and a Locally Optimal Block Preconditioned\nConjugate Gradient module (LOBPCG) for iterative optimization. Moreover, we\nhighlight the correlation between a standard modal vibration solver and our\nnetwork architecture. Our radiation network predicts the Far-Field Acoustic\nTransfer maps (FFAT Maps) from the surface vibration of the object. The overall\nrunning time of our learning method for any new object is less than one second\non a GTX 3080 Ti GPU while maintaining a high sound quality close to the ground\ntruth that is computed using standard numerical methods. We also evaluate the\nnumerical accuracy and perceptual accuracy of our sound synthesis approach on\ndifferent objects corresponding to various materials.", "published": "2021-08-17 03:44:45", "link": "http://arxiv.org/abs/2108.07425v4", "categories": ["cs.SD", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neonatal Bowel Sound Detection Using Convolutional Neural Network and\n  Laplace Hidden Semi-Markov Model", "abstract": "Abdominal auscultation is a convenient, safe and inexpensive method to assess\nbowel conditions, which is essential in neonatal care. It helps early detection\nof neonatal bowel dysfunctions and allows timely intervention. This paper\npresents a neonatal bowel sound detection method to assist the auscultation.\nSpecifically, a Convolutional Neural Network (CNN) is proposed to classify\nperistalsis and non-peristalsis sounds. The classification is then optimized\nusing a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is\nvalidated on abdominal sounds from 49 newborn infants admitted to our tertiary\nNeonatal Intensive Care Unit (NICU). The results show that the method can\neffectively detect bowel sounds with accuracy and area under curve (AUC) score\nbeing 89.81% and 83.96% respectively, outperforming 13 baseline methods.\nFurthermore, the proposed Laplace HSMM refinement strategy is proven capable to\nenhance other bowel sound detection models. The outcomes of this work have the\npotential to facilitate future telehealth applications for neonatal care. The\nsource code of our work can be found at:\nhttps://bitbucket.org/chirudeakin/neonatal-bowel-sound-classification/", "published": "2021-08-17 06:50:17", "link": "http://arxiv.org/abs/2108.07467v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Look Who's Talking: Active Speaker Detection in the Wild", "abstract": "In this work, we present a novel audio-visual dataset for active speaker\ndetection in the wild. A speaker is considered active when his or her face is\nvisible and the voice is audible simultaneously. Although active speaker\ndetection is a crucial pre-processing step for many audio-visual tasks, there\nis no existing dataset of natural human speech to evaluate the performance of\nactive speaker detection. We therefore curate the Active Speakers in the Wild\n(ASW) dataset which contains videos and co-occurring speech segments with dense\nspeech activity labels. Videos and timestamps of audible segments are parsed\nand adopted from VoxConverse, an existing speaker diarisation dataset that\nconsists of videos in the wild. Face tracks are extracted from the videos and\nactive segments are annotated based on the timestamps of VoxConverse in a\nsemi-automatic way. Two reference systems, a self-supervised system and a fully\nsupervised one, are evaluated on the dataset to provide the baseline\nperformances of ASW. Cross-domain evaluation is conducted in order to show the\nnegative effect of dubbed videos in the training data.", "published": "2021-08-17 14:16:56", "link": "http://arxiv.org/abs/2108.07640v1", "categories": ["cs.CV", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.CV"}
