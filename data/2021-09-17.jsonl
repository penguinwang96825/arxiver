{"title": "Self-training with Few-shot Rationalization: Teacher Explanations Aid\n  Student in Few-shot NLU", "abstract": "While pre-trained language models have obtained state-of-the-art performance\nfor several natural language understanding tasks, they are quite opaque in\nterms of their decision-making process. While some recent works focus on\nrationalizing neural predictions by highlighting salient concepts in the text\nas justifications or rationales, they rely on thousands of labeled training\nexamples for both task labels as well as an-notated rationales for every\ninstance. Such extensive large-scale annotations are infeasible to obtain for\nmany tasks. To this end, we develop a multi-task teacher-student framework\nbased on self-training language models with limited task-specific labels and\nrationales, and judicious sample selection to learn from informative\npseudo-labeled examples1. We study several characteristics of what constitutes\na good rationale and demonstrate that the neural model performance can be\nsignificantly improved by making it aware of its rationalized predictions,\nparticularly in low-resource settings. Extensive experiments in several\nbench-mark datasets demonstrate the effectiveness of our approach.", "published": "2021-09-17 00:36:46", "link": "http://arxiv.org/abs/2109.08259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multimodal Sentiment Dataset for Video Recommendation", "abstract": "Recently, multimodal sentiment analysis has seen remarkable advance and a lot\nof datasets are proposed for its development. In general, current multimodal\nsentiment analysis datasets usually follow the traditional system of\nsentiment/emotion, such as positive, negative and so on. However, when applied\nin the scenario of video recommendation, the traditional sentiment/emotion\nsystem is hard to be leveraged to represent different contents of videos in the\nperspective of visual senses and language understanding. Based on this, we\npropose a multimodal sentiment analysis dataset, named baiDu Video Sentiment\ndataset (DuVideoSenti), and introduce a new sentiment system which is designed\nto describe the sentimental style of a video on recommendation scenery.\nSpecifically, DuVideoSenti consists of 5,630 videos which displayed on Baidu,\neach video is manually annotated with a sentimental style label which describes\nthe user's real feeling of a video. Furthermore, we propose UNIMO as our\nbaseline for DuVideoSenti. Experimental results show that DuVideoSenti brings\nnew challenges to multimodal sentiment analysis, and could be used as a new\nbenchmark for evaluating approaches designed for video understanding and\nmultimodal fusion. We also expect our proposed DuVideoSenti could further\nimprove the development of multimodal sentiment analysis and its application to\nvideo recommendations.", "published": "2021-09-17 03:10:42", "link": "http://arxiv.org/abs/2109.08333v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task-adaptive Pre-training of Language Models with Word Embedding\n  Regularization", "abstract": "Pre-trained language models (PTLMs) acquire domain-independent linguistic\nknowledge through pre-training with massive textual resources. Additional\npre-training is effective in adapting PTLMs to domains that are not well\ncovered by the pre-training corpora. Here, we focus on the static word\nembeddings of PTLMs for domain adaptation to teach PTLMs domain-specific\nmeanings of words. We propose a novel fine-tuning process: task-adaptive\npre-training with word embedding regularization (TAPTER). TAPTER runs\nadditional pre-training by making the static word embeddings of a PTLM close to\nthe word embeddings obtained in the target domain with fastText. TAPTER\nrequires no additional corpus except for the training data of the downstream\ntask. We confirmed that TAPTER improves the performance of the standard\nfine-tuning and the task-adaptive pre-training on BioASQ (question answering in\nthe biomedical domain) and on SQuAD (the Wikipedia domain) when their\npre-training corpora were not dominated by in-domain data.", "published": "2021-09-17 05:26:33", "link": "http://arxiv.org/abs/2109.08354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To be Closer: Learning to Link up Aspects with Opinions", "abstract": "Dependency parse trees are helpful for discovering the opinion words in\naspect-based sentiment analysis (ABSA). However, the trees obtained from\noff-the-shelf dependency parsers are static, and could be sub-optimal in ABSA.\nThis is because the syntactic trees are not designed for capturing the\ninteractions between opinion words and aspect words. In this work, we aim to\nshorten the distance between aspects and corresponding opinion words by\nlearning an aspect-centric tree structure. The aspect and opinion words are\nexpected to be closer along such tree structure compared to the standard\ndependency parse tree. The learning process allows the tree structure to\nadaptively correlate the aspect and opinion words, enabling us to better\nidentify the polarity in the ABSA task. We conduct experiments on five\naspect-based sentiment datasets, and the proposed model significantly\noutperforms recent strong baselines. Furthermore, our thorough analysis\ndemonstrates the average distance between aspect and opinion words are\nshortened by at least 19% on the standard SemEval Restaurant14 dataset.", "published": "2021-09-17 07:37:13", "link": "http://arxiv.org/abs/2109.08382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "reproducing \"ner and pos when nothing is capitalized\"", "abstract": "Capitalization is an important feature in many NLP tasks such as Named Entity\nRecognition (NER) or Part of Speech Tagging (POS). We are trying to reproduce\nresults of paper which shows how to mitigate a significant performance drop\nwhen casing is mismatched between training and testing data. In particular we\nshow that lowercasing 50% of the dataset provides the best performance,\nmatching the claims of the original paper. We also show that we got slightly\nlower performance in almost all experiments we have tried to reproduce,\nsuggesting that there might be some hidden factors impacting our performance.\nLastly, we make all of our work available in a public github repository.", "published": "2021-09-17 08:12:44", "link": "http://arxiv.org/abs/2109.08396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Tuned Transformers Show Clusters of Similar Representations Across\n  Layers", "abstract": "Despite the success of fine-tuning pretrained language encoders like BERT for\ndownstream natural language understanding (NLU) tasks, it is still poorly\nunderstood how neural networks change after fine-tuning. In this work, we use\ncentered kernel alignment (CKA), a method for comparing learned\nrepresentations, to measure the similarity of representations in task-tuned\nmodels across layers. In experiments across twelve NLU tasks, we discover a\nconsistent block diagonal structure in the similarity of representations within\nfine-tuned RoBERTa and ALBERT models, with strong similarity within clusters of\nearlier and later layers, but not between them. The similarity of later layer\nrepresentations implies that later layers only marginally contribute to task\nperformance, and we verify in experiments that the top few layers of fine-tuned\nTransformers can be discarded without hurting performance, even with no further\ntuning.", "published": "2021-09-17 08:32:41", "link": "http://arxiv.org/abs/2109.08406v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Role-Selected Sharing Network for Joint Machine-Human Chatting Handoff\n  and Service Satisfaction Analysis", "abstract": "Chatbot is increasingly thriving in different domains, however, because of\nunexpected discourse complexity and training data sparseness, its potential\ndistrust hatches vital apprehension. Recently, Machine-Human Chatting Handoff\n(MHCH), predicting chatbot failure and enabling human-algorithm collaboration\nto enhance chatbot quality, has attracted increasing attention from industry\nand academia. In this study, we propose a novel model, Role-Selected Sharing\nNetwork (RSSN), which integrates both dialogue satisfaction estimation and\nhandoff prediction in one multi-task learning framework. Unlike prior efforts\nin dialog mining, by utilizing local user satisfaction as a bridge, global\nsatisfaction detector and handoff predictor can effectively exchange critical\ninformation. Specifically, we decouple the relation and interaction between the\ntwo tasks by the role information after the shared encoder. Extensive\nexperiments on two public datasets demonstrate the effectiveness of our model.", "published": "2021-09-17 08:39:45", "link": "http://arxiv.org/abs/2109.08412v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Unification for Logic Reasoning over Natural Language", "abstract": "Automated Theorem Proving (ATP) deals with the development of computer\nprograms being able to show that some conjectures (queries) are a logical\nconsequence of a set of axioms (facts and rules). There exists several\nsuccessful ATPs where conjectures and axioms are formally provided (e.g.\nformalised as First Order Logic formulas). Recent approaches, such as (Clark et\nal., 2020), have proposed transformer-based architectures for deriving\nconjectures given axioms expressed in natural language (English). The\nconjecture is verified through a binary text classifier, where the transformers\nmodel is trained to predict the truth value of a conjecture given the axioms.\nThe RuleTaker approach of (Clark et al., 2020) achieves appealing results both\nin terms of accuracy and in the ability to generalize, showing that when the\nmodel is trained with deep enough queries (at least 3 inference steps), the\ntransformers are able to correctly answer the majority of queries (97.6%) that\nrequire up to 5 inference steps. In this work we propose a new architecture,\nnamely the Neural Unifier, and a relative training procedure, which achieves\nstate-of-the-art results in term of generalisation, showing that mimicking a\nwell-known inference procedure, the backward chaining, it is possible to answer\ndeep queries even when the model is trained only on shallow ones. The approach\nis demonstrated in experiments using a diverse set of benchmark data.", "published": "2021-09-17 10:48:39", "link": "http://arxiv.org/abs/2109.08460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Multitask Learning for Low-Resource AbstractiveSummarization", "abstract": "This paper explores the effect of using multitask learning for abstractive\nsummarization in the context of small training corpora. In particular, we\nincorporate four different tasks (extractive summarization, language modeling,\nconcept detection, and paraphrase detection) both individually and in\ncombination, with the goal of enhancing the target task of abstractive\nsummarization via multitask learning. We show that for many task combinations,\na model trained in a multitask setting outperforms a model trained only for\nabstractive summarization, with no additional summarization data introduced.\nAdditionally, we do a comprehensive search and find that certain tasks (e.g.\nparaphrase detection) consistently benefit abstractive summarization, not only\nwhen combined with other tasks but also when using different architectures and\ntraining corpora.", "published": "2021-09-17 14:23:58", "link": "http://arxiv.org/abs/2109.08565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Data Scarceness through Data Synthesis, Augmentation and\n  Curriculum for Abstractive Summarization", "abstract": "This paper explores three simple data manipulation techniques (synthesis,\naugmentation, curriculum) for improving abstractive summarization models\nwithout the need for any additional data. We introduce a method of data\nsynthesis with paraphrasing, a data augmentation technique with sample mixing,\nand curriculum learning with two new difficulty metrics based on specificity\nand abstractiveness. We conduct experiments to show that these three techniques\ncan help improve abstractive summarization across two summarization models and\ntwo different small datasets. Furthermore, we show that these techniques can\nimprove performance when applied in isolation and when combined.", "published": "2021-09-17 14:31:08", "link": "http://arxiv.org/abs/2109.08569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Commonsense help in detecting Sarcasm?", "abstract": "Sarcasm detection is important for several NLP tasks such as sentiment\nidentification in product reviews, user feedback, and online forums. It is a\nchallenging task requiring a deep understanding of language, context, and world\nknowledge. In this paper, we investigate whether incorporating commonsense\nknowledge helps in sarcasm detection. For this, we incorporate commonsense\nknowledge into the prediction process using a graph convolution network with\npre-trained language model embeddings as input. Our experiments with three\nsarcasm detection datasets indicate that the approach does not outperform the\nbaseline model. We perform an exhaustive set of experiments to analyze where\ncommonsense support adds value and where it hurts classification. Our\nimplementation is publicly available at:\nhttps://github.com/brcsomnath/commonsense-sarcasm.", "published": "2021-09-17 15:07:38", "link": "http://arxiv.org/abs/2109.08588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The futility of STILTs for the classification of lexical borrowings in\n  Spanish", "abstract": "The first edition of the IberLEF 2021 shared task on automatic detection of\nborrowings (ADoBo) focused on detecting lexical borrowings that appeared in the\nSpanish press and that have recently been imported into the Spanish language.\nIn this work, we tested supplementary training on intermediate labeled-data\ntasks (STILTs) from part of speech (POS), named entity recognition (NER),\ncode-switching, and language identification approaches to the classification of\nborrowings at the token level using existing pre-trained transformer-based\nlanguage models. Our extensive experimental results suggest that STILTs do not\nprovide any improvement over direct fine-tuning of multilingual models.\nHowever, multilingual models trained on small subsets of languages perform\nreasonably better than multilingual BERT but not as good as multilingual\nRoBERTa for the given dataset.", "published": "2021-09-17 15:32:02", "link": "http://arxiv.org/abs/2109.08607v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Scrubbing of Demographic Information for Text Classification", "abstract": "Contextual representations learned by language models can often encode\nundesirable attributes, like demographic associations of the users, while being\ntrained for an unrelated target task. We aim to scrub such undesirable\nattributes and learn fair representations while maintaining performance on the\ntarget task. In this paper, we present an adversarial learning framework\n\"Adversarial Scrubber\" (ADS), to debias contextual representations. We perform\ntheoretical analysis to show that our framework converges without leaking\ndemographic information under certain conditions. We extend previous evaluation\ntechniques by evaluating debiasing performance using Minimum Description Length\n(MDL) probing. Experimental evaluations on 8 datasets show that ADS generates\nrepresentations with minimal information about demographic attributes while\nbeing maximally informative about the target task.", "published": "2021-09-17 15:38:43", "link": "http://arxiv.org/abs/2109.08613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CKMorph: A Comprehensive Morphological Analyzer for Central Kurdish", "abstract": "A morphological analyzer, which is a significant component of many natural\nlanguage processing applications especially for morphologically rich languages,\ndivides an input word into all its composing morphemes and identifies their\nmorphological roles. In this paper, we introduce a comprehensive morphological\nanalyzer for Central Kurdish (CK), a low-resourced language with a rich\nmorphology. Building upon the limited existing literature, we first assembled\nand systematically categorized a comprehensive collection of the morphological\nand morphophonological rules of the language. Additionally, we collected and\nmanually labeled a generative lexicon containing nearly 10,000 verb, noun and\nadjective stems, named entities, and other types of word stems. We used these\nrule sets and resources to implement CKMorph Analyzer based on finite-state\ntransducers. In order to provide a benchmark for future research, we collected,\nmanually labeled, and publicly shared test sets for evaluating accuracy and\ncoverage of the analyzer. CKMorph was able to correctly analyze 95.9% of the\naccuracy test set, containing 1,000 CK words morphologically analyzed according\nto the context. Moreover, CKMorph gave at least one analysis for 95.5% of 4.22M\nCK tokens of the coverage test set. The demonstration of the application and\nresources including CK verb database and test sets are openly accessible at\nhttps://github.com/CKMorph.", "published": "2021-09-17 15:45:27", "link": "http://arxiv.org/abs/2109.08615v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Classification-based Quality Estimation: Small and Efficient Models for\n  Real-world Applications", "abstract": "Sentence-level Quality estimation (QE) of machine translation is\ntraditionally formulated as a regression task, and the performance of QE models\nis typically measured by Pearson correlation with human labels. Recent QE\nmodels have achieved previously-unseen levels of correlation with human\njudgments, but they rely on large multilingual contextualized language models\nthat are computationally expensive and make them infeasible for real-world\napplications. In this work, we evaluate several model compression techniques\nfor QE and find that, despite their popularity in other NLP tasks, they lead to\npoor performance in this regression setting. We observe that a full model\nparameterization is required to achieve SoTA results in a regression task.\nHowever, we argue that the level of expressiveness of a model in a continuous\nrange is unnecessary given the downstream applications of QE, and show that\nreframing QE as a classification problem and evaluating QE models using\nclassification metrics would better reflect their actual performance in\nreal-world applications.", "published": "2021-09-17 16:14:52", "link": "http://arxiv.org/abs/2109.08627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Handling Unconstrained User Preferences in Dialogue", "abstract": "A user input to a schema-driven dialogue information navigation system, such\nas venue search, is typically constrained by the underlying database which\nrestricts the user to specify a predefined set of preferences, or slots,\ncorresponding to the database fields. We envision a more natural information\nnavigation dialogue interface where a user has flexibility to specify\nunconstrained preferences that may not match a predefined schema. We propose to\nuse information retrieval from unstructured knowledge to identify entities\nrelevant to a user request. We update the Cambridge restaurants database with\nunstructured knowledge snippets (reviews and information from the web) for each\nof the restaurants and annotate a set of query-snippet pairs with a relevance\nlabel. We use the annotated dataset to train and evaluate snippet relevance\nclassifiers, as a proxy to evaluating recommendation accuracy. We show that\nwith a pretrained transformer model as an encoder, an unsupervised/supervised\nclassifier achieves a weighted F1 of .661/.856.", "published": "2021-09-17 17:14:14", "link": "http://arxiv.org/abs/2109.08650v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base\n  Question Answering", "abstract": "Existing KBQA approaches, despite achieving strong performance on i.i.d. test\ndata, often struggle in generalizing to questions involving unseen KB schema\nitems. Prior ranking-based approaches have shown some success in\ngeneralization, but suffer from the coverage issue. We present RnG-KBQA, a\nRank-and-Generate approach for KBQA, which remedies the coverage issue with a\ngeneration model while preserving a strong generalization capability. Our\napproach first uses a contrastive ranker to rank a set of candidate logical\nforms obtained by searching over the knowledge graph. It then introduces a\ntailored generation model conditioned on the question and the top-ranked\ncandidates to compose the final logical form. We achieve new state-of-the-art\nresults on GrailQA and WebQSP datasets. In particular, our method surpasses the\nprior state-of-the-art by a large margin on the GrailQA leaderboard. In\naddition, RnG-KBQA outperforms all prior approaches on the popular WebQSP\nbenchmark, even including the ones that use the oracle entity linking. The\nexperimental results demonstrate the effectiveness of the interplay between\nranking and generation, which leads to the superior performance of our proposed\napproach across all settings with especially strong improvements in zero-shot\ngeneralization.", "published": "2021-09-17 17:58:28", "link": "http://arxiv.org/abs/2109.08678v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When a Computer Cracks a Joke: Automated Generation of Humorous\n  Headlines", "abstract": "Automated news generation has become a major interest for new agencies in the\npast. Oftentimes headlines for such automatically generated news articles are\nunimaginative as they have been generated with ready-made templates. We present\na computationally creative approach for headline generation that can generate\nhumorous versions of existing headlines. We evaluate our system with human\njudges and compare the results to human authored humorous titles. The headlines\nproduced by the system are considered funny 36\\% of the time by human\nevaluators.", "published": "2021-09-17 18:08:37", "link": "http://arxiv.org/abs/2109.08702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task", "abstract": "This paper presents the JHU-Microsoft joint submission for WMT 2021 quality\nestimation shared task. We only participate in Task 2 (post-editing effort\nestimation) of the shared task, focusing on the target-side word-level quality\nestimation. The techniques we experimented with include Levenshtein Transformer\ntraining and data augmentation with a combination of forward, backward,\nround-trip translation, and pseudo post-editing of the MT output. We\ndemonstrate the competitiveness of our system compared to the widely adopted\nOpenKiwi-XLM baseline. Our system is also the top-ranking system on the MT MCC\nmetric for the English-German language pair.", "published": "2021-09-17 19:13:31", "link": "http://arxiv.org/abs/2109.08724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Few-Shot Intent Classification and Slot Filling", "abstract": "Intent classification (IC) and slot filling (SF) are two fundamental tasks in\nmodern Natural Language Understanding (NLU) systems. Collecting and annotating\nlarge amounts of data to train deep learning models for such systems is not\nscalable. This problem can be addressed by learning from few examples using\nfast supervised meta-learning techniques such as prototypical networks. In this\nwork, we systematically investigate how contrastive learning and unsupervised\ndata augmentation methods can benefit these existing supervised meta-learning\npipelines for jointly modelled IC/SF tasks. Through extensive experiments\nacross standard IC/SF benchmarks (SNIPS and ATIS), we show that our proposed\nsemi-supervised approaches outperform standard supervised meta-learning\nmethods: contrastive losses in conjunction with prototypical networks\nconsistently outperform the existing state-of-the-art for both IC and SF tasks,\nwhile data augmentation strategies primarily improve few-shot IC by a\nsignificant margin.", "published": "2021-09-17 20:26:23", "link": "http://arxiv.org/abs/2109.08754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical text summarization using Conditional Generative Adversarial\n  Network(CGAN)", "abstract": "Text summarization in medicine can help doctors for reducing the time to\naccess important information from countless documents. The paper offers a\nsupervised extractive summarization method based on conditional generative\nadversarial networks using convolutional neural networks. Unlike previous\nmodels, which often use greedy methods to select sentences, we use a new\napproach for selecting sentences. Moreover, we provide a network for biomedical\nword embedding, which improves summarization. An essential contribution of the\npaper is introducing a new loss function for the discriminator, making the\ndiscriminator perform better. The proposed model achieves results comparable to\nthe state-of-the-art approaches, as determined by the ROUGE metric. Experiments\non the medical dataset show that the proposed method works on average 5% better\nthan the competing models and is more similar to the reference summaries.", "published": "2021-09-17 17:13:56", "link": "http://arxiv.org/abs/2110.11870v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ethics Sheet for Automatic Emotion Recognition and Sentiment Analysis", "abstract": "The importance and pervasiveness of emotions in our lives makes affective\ncomputing a tremendously important and vibrant line of work. Systems for\nautomatic emotion recognition (AER) and sentiment analysis can be facilitators\nof enormous progress (e.g., in improving public health and commerce) but also\nenablers of great harm (e.g., for suppressing dissidents and manipulating\nvoters). Thus, it is imperative that the affective computing community actively\nengage with the ethical ramifications of their creations. In this paper, I have\nsynthesized and organized information from AI Ethics and Emotion Recognition\nliterature to present fifty ethical considerations relevant to AER. Notably,\nthe sheet fleshes out assumptions hidden in how AER is commonly framed, and in\nthe choices often made regarding the data, method, and evaluation. Special\nattention is paid to the implications of AER on privacy and social groups.\nAlong the way, key recommendations are made for responsible AER. The objective\nof the sheet is to facilitate and encourage more thoughtfulness on why to\nautomate, how to automate, and how to judge success well before the building of\nAER systems. Additionally, the sheet acts as a useful introductory document on\nemotion recognition (complementing survey articles).", "published": "2021-09-17 00:18:28", "link": "http://arxiv.org/abs/2109.08256v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Models as a Knowledge Source for Cognitive Agents", "abstract": "Language models (LMs) are sentence-completion engines trained on massive\ncorpora. LMs have emerged as a significant breakthrough in natural-language\nprocessing, providing capabilities that go far beyond sentence completion\nincluding question answering, summarization, and natural-language inference.\nWhile many of these capabilities have potential application to cognitive\nsystems, exploiting language models as a source of task knowledge, especially\nfor task learning, offers significant, near-term benefits. We introduce\nlanguage models and the various tasks to which they have been applied and then\nreview methods of knowledge extraction from language models. The resulting\nanalysis outlines both the challenges and opportunities for using language\nmodels as a new knowledge source for cognitive systems. It also identifies\npossible ways to improve knowledge extraction from language models using the\ncapabilities provided by cognitive systems. Central to success will be the\nability of a cognitive agent to itself learn an abstract model of the knowledge\nimplicit in the LM as well as methods to extract high-quality knowledge\neffectively and efficiently. To illustrate, we introduce a hypothetical robot\nagent and describe how language models could extend its task knowledge and\nimprove its performance and the kinds of knowledge and methods the agent can\nuse to exploit the knowledge within a language model.", "published": "2021-09-17 01:12:34", "link": "http://arxiv.org/abs/2109.08270v3", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.11"], "primary_category": "cs.AI"}
{"title": "SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based\n  Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) is an emerging fine-grained sentiment\nanalysis task that aims to extract aspects, classify corresponding sentiment\npolarities and find opinions as the causes of sentiment. The latest research\ntends to solve the ABSA task in a unified way with end-to-end frameworks. Yet,\nthese frameworks get fine-tuned from downstream tasks without any task-adaptive\nmodification. Specifically, they do not use task-related knowledge well or\nexplicitly model relations between aspect and opinion terms, hindering them\nfrom better performance. In this paper, we propose SentiPrompt to use sentiment\nknowledge enhanced prompts to tune the language model in the unified framework.\nWe inject sentiment knowledge regarding aspects, opinions, and polarities into\nprompt and explicitly model term relations via constructing consistency and\npolarity judgment templates from the ground truth triplets. Experimental\nresults demonstrate that our approach can outperform strong baselines on\nTriplet Extraction, Pair Extraction, and Aspect Term Extraction with Sentiment\nClassification by a notable margin.", "published": "2021-09-17 01:56:06", "link": "http://arxiv.org/abs/2109.08306v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CodeQA: A Question Answering Dataset for Source Code Comprehension", "abstract": "We propose CodeQA, a free-form question answering dataset for the purpose of\nsource code comprehension: given a code snippet and a question, a textual\nanswer is required to be generated. CodeQA contains a Java dataset with 119,778\nquestion-answer pairs and a Python dataset with 70,085 question-answer pairs.\nTo obtain natural and faithful questions and answers, we implement syntactic\nrules and semantic analysis to transform code comments into question-answer\npairs. We present the construction process and conduct systematic analysis of\nour dataset. Experiment results achieved by several neural baselines on our\ndataset are shown and discussed. While research on question-answering and\nmachine reading comprehension develops rapidly, few prior work has drawn\nattention to code question answering. This new dataset can serve as a useful\nresearch benchmark for source code comprehension.", "published": "2021-09-17 06:06:38", "link": "http://arxiv.org/abs/2109.08365v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "General Cross-Architecture Distillation of Pretrained Language Models\n  into Matrix Embeddings", "abstract": "Large pretrained language models (PreLMs) are revolutionizing natural\nlanguage processing across all benchmarks. However, their sheer size is\nprohibitive for small laboratories or for deployment on mobile devices.\nApproaches like pruning and distillation reduce the model size but typically\nretain the same model architecture. In contrast, we explore distilling PreLMs\ninto a different, more efficient architecture, Continual Multiplication of\nWords (CMOW), which embeds each word as a matrix and uses matrix multiplication\nto encode sequences. We extend the CMOW architecture and its CMOW/CBOW-Hybrid\nvariant with a bidirectional component for more expressive power, per-token\nrepresentations for a general (task-agnostic) distillation during pretraining,\nand a two-sequence encoding scheme that facilitates downstream tasks on\nsentence pairs, such as sentence similarity and natural language inference. Our\nmatrix-based bidirectional CMOW/CBOW-Hybrid model is competitive to DistilBERT\non question similarity and recognizing textual entailment, but uses only half\nof the number of parameters and is three times faster in terms of inference\nspeed. We match or exceed the scores of ELMo for all tasks of the GLUE\nbenchmark except for the sentiment analysis task SST-2 and the linguistic\nacceptability task CoLA. However, compared to previous cross-architecture\ndistillation approaches, we demonstrate a doubling of the scores on detecting\nlinguistic acceptability. This shows that matrix-based embeddings can be used\nto distill large PreLM into competitive models and motivates further research\nin this direction.", "published": "2021-09-17 10:15:06", "link": "http://arxiv.org/abs/2109.08449v2", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "GoG: Relation-aware Graph-over-Graph Network for Visual Dialog", "abstract": "Visual dialog, which aims to hold a meaningful conversation with humans about\na given image, is a challenging task that requires models to reason the complex\ndependencies among visual content, dialog history, and current questions. Graph\nneural networks are recently applied to model the implicit relations between\nobjects in an image or dialog. However, they neglect the importance of 1)\ncoreference relations among dialog history and dependency relations between\nwords for the question representation; and 2) the representation of the image\nbased on the fully represented question. Therefore, we propose a novel\nrelation-aware graph-over-graph network (GoG) for visual dialog. Specifically,\nGoG consists of three sequential graphs: 1) H-Graph, which aims to capture\ncoreference relations among dialog history; 2) History-aware Q-Graph, which\naims to fully understand the question through capturing dependency relations\nbetween words based on coreference resolution on the dialog history; and 3)\nQuestion-aware I-Graph, which aims to capture the relations between objects in\nan image based on fully question representation. As an additional feature\nrepresentation module, we add GoG to the existing visual dialogue model.\nExperimental results show that our model outperforms the strong baseline in\nboth generative and discriminative settings by a significant margin.", "published": "2021-09-17 11:37:33", "link": "http://arxiv.org/abs/2109.08475v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Simple Entity-Centric Questions Challenge Dense Retrievers", "abstract": "Open-domain question answering has exploded in popularity recently due to the\nsuccess of dense retrieval models, which have surpassed sparse models using\nonly a few supervised training examples. However, in this paper, we demonstrate\ncurrent dense models are not yet the holy grail of retrieval. We first\nconstruct EntityQuestions, a set of simple, entity-rich questions based on\nfacts from Wikidata (e.g., \"Where was Arve Furset born?\"), and observe that\ndense retrievers drastically underperform sparse methods. We investigate this\nissue and uncover that dense retrievers can only generalize to common entities\nunless the question pattern is explicitly observed during training. We discuss\ntwo simple solutions towards addressing this critical problem. First, we\ndemonstrate that data augmentation is unable to fix the generalization problem.\nSecond, we argue a more robust passage encoder helps facilitate better question\nadaptation using specialized question encoders. We hope our work can shed light\non the challenges in creating a robust, universal dense retriever that works\nwell across different input distributions.", "published": "2021-09-17 13:19:03", "link": "http://arxiv.org/abs/2109.08535v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Hierarchy-Aware T5 with Path-Adaptive Mask Mechanism for Hierarchical\n  Text Classification", "abstract": "Hierarchical Text Classification (HTC), which aims to predict text labels\norganized in hierarchical space, is a significant task lacking in investigation\nin natural language processing. Existing methods usually encode the entire\nhierarchical structure and fail to construct a robust label-dependent model,\nmaking it hard to make accurate predictions on sparse lower-level labels and\nachieving low Macro-F1. In this paper, we propose a novel PAMM-HiA-T5 model for\nHTC: a hierarchy-aware T5 model with path-adaptive mask mechanism that not only\nbuilds the knowledge of upper-level labels into low-level ones but also\nintroduces path dependency information in label prediction. Specifically, we\ngenerate a multi-level sequential label structure to exploit hierarchical\ndependency across different levels with Breadth-First Search (BFS) and T5\nmodel. To further improve label dependency prediction within each path, we then\npropose an original path-adaptive mask mechanism (PAMM) to identify the label's\npath information, eliminating sources of noises from other paths. Comprehensive\nexperiments on three benchmark datasets show that our novel PAMM-HiA-T5 model\ngreatly outperforms all state-of-the-art HTC approaches especially in Macro-F1.\nThe ablation studies show that the improvements mainly come from our innovative\napproach instead of T5.", "published": "2021-09-17 15:03:03", "link": "http://arxiv.org/abs/2109.08585v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Boosting Transformers for Job Expression Extraction and Classification\n  in a Low-Resource Setting", "abstract": "In this paper, we explore possible improvements of transformer models in a\nlow-resource setting. In particular, we present our approaches to tackle the\nfirst two of three subtasks of the MEDDOPROF competition, i.e., the extraction\nand classification of job expressions in Spanish clinical texts. As neither\nlanguage nor domain experts, we experiment with the multilingual XLM-R\ntransformer model and tackle these low-resource information extraction tasks as\nsequence-labeling problems. We explore domain- and language-adaptive\npretraining, transfer learning and strategic datasplits to boost the\ntransformer model. Our results show strong improvements using these methods by\nup to 5.3 F1 points compared to a fine-tuned XLM-R model. Our best models\nachieve 83.2 and 79.3 F1 for the first two tasks, respectively.", "published": "2021-09-17 15:21:02", "link": "http://arxiv.org/abs/2109.08597v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Grounding Natural Language Instructions: Can Large Language Models\n  Capture Spatial Information?", "abstract": "Models designed for intelligent process automation are required to be capable\nof grounding user interface elements. This task of interface element grounding\nis centred on linking instructions in natural language to their target\nreferents. Even though BERT and similar pre-trained language models have\nexcelled in several NLP tasks, their use has not been widely explored for the\nUI grounding domain. This work concentrates on testing and probing the\ngrounding abilities of three different transformer-based models: BERT, RoBERTa\nand LayoutLM. Our primary focus is on these models' spatial reasoning skills,\ngiven their importance in this domain. We observe that LayoutLM has a promising\nadvantage for applications in this domain, even though it was created for a\ndifferent original purpose (representing scanned documents): the learned\nspatial features appear to be transferable to the UI grounding setting,\nespecially as they demonstrate the ability to discriminate between target\ndirections in natural language instructions.", "published": "2021-09-17 16:36:30", "link": "http://arxiv.org/abs/2109.08634v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Relating Neural Text Degeneration to Exposure Bias", "abstract": "This work focuses on relating two mysteries in neural-based text generation:\nexposure bias, and text degeneration. Despite the long time since exposure bias\nwas mentioned and the numerous studies for its remedy, to our knowledge, its\nimpact on text generation has not yet been verified. Text degeneration is a\nproblem that the widely-used pre-trained language model GPT-2 was recently\nfound to suffer from (Holtzman et al., 2020). Motivated by the unknown\ncausation of the text degeneration, in this paper we attempt to relate these\ntwo mysteries. Specifically, we first qualitatively quantitatively identify\nmistakes made before text degeneration occurs. Then we investigate the\nsignificance of the mistakes by inspecting the hidden states in GPT-2. Our\nresults show that text degeneration is likely to be partly caused by exposure\nbias. We also study the self-reinforcing mechanism of text degeneration,\nexplaining why the mistakes amplify. In sum, our study provides a more concrete\nfoundation for further investigation on exposure bias and text degeneration\nproblems.", "published": "2021-09-17 18:11:03", "link": "http://arxiv.org/abs/2109.08705v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Variational Graph Autoencoders for Unsupervised Cross-domain\n  Prerequisite Chains", "abstract": "Prerequisite chain learning helps people acquire new knowledge efficiently.\nWhile people may quickly determine learning paths over concepts in a domain,\nfinding such paths in other domains can be challenging. We introduce\nDomain-Adversarial Variational Graph Autoencoders (DAVGAE) to solve this\ncross-domain prerequisite chain learning task efficiently. Our novel model\nconsists of a variational graph autoencoder (VGAE) and a domain discriminator.\nThe VGAE is trained to predict concept relations through link prediction, while\nthe domain discriminator takes both source and target domain data as input and\nis trained to predict domain labels. Most importantly, this method only needs\nsimple homogeneous graphs as input, compared with the current state-of-the-art\nmodel. We evaluate our model on the LectureBankCD dataset, and results show\nthat our model outperforms recent graph-based benchmarks while using only 1/10\nof graph scale and 1/3 computation time.", "published": "2021-09-17 19:07:27", "link": "http://arxiv.org/abs/2109.08722v5", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Algorithm for Generating Gap-Fill Multiple Choice Questions of an\n  Expert System", "abstract": "This research is aimed to propose an artificial intelligence algorithm\ncomprising an ontology-based design, text mining, and natural language\nprocessing for automatically generating gap-fill multiple choice questions\n(MCQs). The simulation of this research demonstrated an application of the\nalgorithm in generating gap-fill MCQs about software testing. The simulation\nresults revealed that by using 103 online documents as inputs, the algorithm\ncould automatically produce more than 16 thousand valid gap-fill MCQs covering\na variety of topics in the software testing domain. Finally, in the discussion\nsection of this paper we suggest how the proposed algorithm should be applied\nto produce gap-fill MCQs being collected in a question pool used by a knowledge\nexpert system.", "published": "2021-09-17 02:49:37", "link": "http://arxiv.org/abs/2109.11421v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generalized Funnelling: Ensemble Learning and Heterogeneous Document\n  Embeddings for Cross-Lingual Text Classification", "abstract": "\\emph{Funnelling} (Fun) is a recently proposed method for cross-lingual text\nclassification (CLTC) based on a two-tier learning ensemble for heterogeneous\ntransfer learning (HTL). In this ensemble method, 1st-tier classifiers, each\nworking on a different and language-dependent feature space, return a vector of\ncalibrated posterior probabilities (with one dimension for each class) for each\ndocument, and the final classification decision is taken by a metaclassifier\nthat uses this vector as its input. The metaclassifier can thus exploit\nclass-class correlations, and this (among other things) gives Fun an edge over\nCLTC systems in which these correlations cannot be brought to bear. In this\npaper we describe \\emph{Generalized Funnelling} (gFun), a generalization of Fun\nconsisting of an HTL architecture in which 1st-tier components can be arbitrary\n\\emph{view-generating functions}, i.e., language-dependent functions that each\nproduce a language-independent representation (\"view\") of the (monolingual)\ndocument. We describe an instance of gFun in which the metaclassifier receives\nas input a vector of calibrated posterior probabilities (as in Fun) aggregated\nto other embedded representations that embody other types of correlations, such\nas word-class correlations (as encoded by \\emph{Word-Class Embeddings}),\nword-word correlations (as encoded by \\emph{Multilingual Unsupervised or\nSupervised Embeddings}), and word-context correlations (as encoded by\n\\emph{multilingual BERT}). We show that this instance of \\textsc{gFun}\nsubstantially improves over Fun and over state-of-the-art baselines, by\nreporting experimental results obtained on two large, standard datasets for\nmultilingual multilabel text classification. Our code that implements gFun is\npublicly available.", "published": "2021-09-17 23:33:04", "link": "http://arxiv.org/abs/2110.14764v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling Linguistic Context for Language Model Compression", "abstract": "A computationally expensive and memory intensive neural network lies behind\nthe recent success of language representation learning. Knowledge distillation,\na major technique for deploying such a vast language model in resource-scarce\nenvironments, transfers the knowledge on individual word representations\nlearned without restrictions. In this paper, inspired by the recent\nobservations that language representations are relatively positioned and have\nmore semantic knowledge as a whole, we present a new knowledge distillation\nobjective for language representation learning that transfers the contextual\nknowledge via two types of relationships across representations: Word Relation\nand Layer Transforming Relation. Unlike other recent distillation techniques\nfor the language models, our contextual distillation does not have any\nrestrictions on architectural changes between teacher and student. We validate\nthe effectiveness of our method on challenging benchmarks of language\nunderstanding tasks, not only in architectures of various sizes, but also in\ncombination with DynaBERT, the recently proposed adaptive size pruning method.", "published": "2021-09-17 05:51:45", "link": "http://arxiv.org/abs/2109.08359v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Incremental Transformer with Visual Grounding for Visual\n  Dialogue Generation", "abstract": "Visual dialogue is a challenging task since it needs to answer a series of\ncoherent questions on the basis of understanding the visual environment.\nPrevious studies focus on the implicit exploration of multimodal co-reference\nby implicitly attending to spatial image features or object-level image\nfeatures but neglect the importance of locating the objects explicitly in the\nvisual content, which is associated with entities in the textual content.\nTherefore, in this paper we propose a {\\bf M}ultimodal {\\bf I}ncremental {\\bf\nT}ransformer with {\\bf V}isual {\\bf G}rounding, named MITVG, which consists of\ntwo key parts: visual grounding and multimodal incremental transformer. Visual\ngrounding aims to explicitly locate related objects in the image guided by\ntextual entities, which helps the model exclude the visual content that does\nnot need attention. On the basis of visual grounding, the multimodal\nincremental transformer encodes the multi-turn dialogue history combined with\nvisual scene step by step according to the order of the dialogue and then\ngenerates a contextually and visually coherent response. Experimental results\non the VisDial v0.9 and v1.0 datasets demonstrate the superiority of the\nproposed model, which achieves comparable performance.", "published": "2021-09-17 11:39:29", "link": "http://arxiv.org/abs/2109.08478v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and\n  Symbolic Logic Rules", "abstract": "One of the challenges faced by conversational agents is their inability to\nidentify unstated presumptions of their users' commands, a task trivial for\nhumans due to their common sense. In this paper, we propose a zero-shot\ncommonsense reasoning system for conversational agents in an attempt to achieve\nthis. Our reasoner uncovers unstated presumptions from user commands satisfying\na general template of if-(state), then-(action), because-(goal). Our reasoner\nuses a state-of-the-art transformer-based generative commonsense knowledge base\n(KB) as its source of background knowledge for reasoning. We propose a novel\nand iterative knowledge query mechanism to extract multi-hop reasoning chains\nfrom the neural KB which uses symbolic logic rules to significantly reduce the\nsearch space. Similar to any KBs gathered to date, our commonsense KB is prone\nto missing knowledge. Therefore, we propose to conversationally elicit the\nmissing knowledge from human users with our novel dynamic question generation\nstrategy, which generates and presents contextualized queries to human users.\nWe evaluate the model with a user study with human users that achieves a 35%\nhigher success rate compared to SOTA.", "published": "2021-09-17 13:40:07", "link": "http://arxiv.org/abs/2109.08544v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Slot Filling for Biomedical Information Extraction", "abstract": "Information Extraction (IE) from text refers to the task of extracting\nstructured knowledge from unstructured text. The task typically consists of a\nseries of sub-tasks such as Named Entity Recognition and Relation Extraction.\nSourcing entity and relation type specific training data is a major bottleneck\nin domains with limited resources such as biomedicine. In this work we present\na slot filling approach to the task of biomedical IE, effectively replacing the\nneed for entity and relation-specific training data, allowing us to deal with\nzero-shot settings. We follow the recently proposed paradigm of coupling a\nTranformer-based bi-encoder, Dense Passage Retrieval, with a Transformer-based\nreading comprehension model to extract relations from biomedical text. We\nassemble a biomedical slot filling dataset for both retrieval and reading\ncomprehension and conduct a series of experiments demonstrating that our\napproach outperforms a number of simpler baselines. We also evaluate our\napproach end-to-end for standard as well as zero-shot settings. Our work\nprovides a fresh perspective on how to solve biomedical IE tasks, in the\nabsence of relevant training data. Our code, models and datasets are available\nat https://github.com/ypapanik/biomedical-slot-filling.", "published": "2021-09-17 14:16:00", "link": "http://arxiv.org/abs/2109.08564v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Primer: Searching for Efficient Transformers for Language Modeling", "abstract": "Large Transformer models have been central to recent advances in natural\nlanguage processing. The training and inference costs of these models, however,\nhave grown rapidly and become prohibitively expensive. Here we aim to reduce\nthe costs of Transformers by searching for a more efficient variant. Compared\nto previous approaches, our search is performed at a lower level, over the\nprimitives that define a Transformer TensorFlow program. We identify an\narchitecture, named Primer, that has a smaller training cost than the original\nTransformer and other variants for auto-regressive language modeling. Primer's\nimprovements can be mostly attributed to two simple modifications: squaring\nReLU activations and adding a depthwise convolution layer after each Q, K, and\nV projection in self-attention.\n  Experiments show Primer's gains over Transformer increase as compute scale\ngrows and follow a power law with respect to quality at optimal model sizes. We\nalso verify empirically that Primer can be dropped into different codebases to\nsignificantly speed up training without additional tuning. For example, at a\n500M parameter size, Primer improves the original T5 architecture on C4\nauto-regressive language modeling, reducing the training cost by 4X.\nFurthermore, the reduced training cost means Primer needs much less compute to\nreach a target one-shot performance. For instance, in a 1.9B parameter\nconfiguration similar to GPT-3 XL, Primer uses 1/3 of the training compute to\nachieve the same one-shot performance as Transformer. We open source our models\nand several comparisons in T5 to help with reproducibility.", "published": "2021-09-17 17:50:39", "link": "http://arxiv.org/abs/2109.08668v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "On-device neural speech synthesis", "abstract": "Recent advances in text-to-speech (TTS) synthesis, such as Tacotron and\nWaveRNN, have made it possible to construct a fully neural network based TTS\nsystem, by coupling the two components together. Such a system is conceptually\nsimple as it only takes grapheme or phoneme input, uses Mel-spectrogram as an\nintermediate feature, and directly generates speech samples. The system\nachieves quality equal or close to natural speech. However, the high\ncomputational cost of the system and issues with robustness have limited their\nusage in real-world speech synthesis applications and products. In this paper,\nwe present key modeling improvements and optimization strategies that enable\ndeploying these models, not only on GPU servers, but also on mobile devices.\nThe proposed system can generate high-quality 24 kHz speech at 5x faster than\nreal time on server and 3x faster than real time on mobile devices.", "published": "2021-09-17 18:31:31", "link": "http://arxiv.org/abs/2109.08710v1", "categories": ["eess.AS", "cs.CL", "cs.PF", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Back-translation for Large-Scale Multilingual Machine Translation", "abstract": "This paper illustrates our approach to the shared task on large-scale\nmultilingual machine translation in the sixth conference on machine translation\n(WMT-21). This work aims to build a single multilingual translation system with\na hypothesis that a universal cross-language representation leads to better\nmultilingual translation performance. We extend the exploration of different\nback-translation methods from bilingual translation to multilingual\ntranslation. Better performance is obtained by the constrained sampling method,\nwhich is different from the finding of the bilingual translation. Besides, we\nalso explore the effect of vocabularies and the amount of synthetic data.\nSurprisingly, the smaller size of vocabularies perform better, and the\nextensive monolingual English data offers a modest improvement. We submitted to\nboth the small tasks and achieved the second place.", "published": "2021-09-17 18:33:15", "link": "http://arxiv.org/abs/2109.08712v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continuous Streaming Multi-Talker ASR with Dual-path Transducers", "abstract": "Streaming recognition of multi-talker conversations has so far been evaluated\nonly for 2-speaker single-turn sessions. In this paper, we investigate it for\nmulti-turn meetings containing multiple speakers using the Streaming Unmixing\nand Recognition Transducer (SURT) model, and show that naively extending the\nsingle-turn model to this harder setting incurs a performance penalty. As a\nsolution, we propose the dual-path (DP) modeling strategy first used for\ntime-domain speech separation. We experiment with LSTM and Transformer based DP\nmodels, and show that they improve word error rate (WER) performance while\nyielding faster convergence. We also explore training strategies such as chunk\nwidth randomization and curriculum learning for these models, and demonstrate\ntheir importance through ablation studies. Finally, we evaluate our models on\nthe LibriCSS meeting data, where they perform competitively with offline\nseparation-based methods.", "published": "2021-09-17 13:57:52", "link": "http://arxiv.org/abs/2109.08555v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker Placement Agnosticism: Improving the Distance-based Amplitude\n  Panning Algorithm", "abstract": "Lossius et. al introduced the distance-based amplitude panning algorithm, or\nDBAP, to enable flexibility of loudspeaker placement in artistic and scientific\ncontexts. The algorithm allows for arbitrary loudspeaker locations in a 2D\nplane so that a virtual sound source may navigate the 2D space. The gains for\neach speaker are calculated as a function of the source's distance to each\nloudspeaker, thus creating a sound field. This gives the listener the\nimpression of a source moving through the field of loudspeakers. This paper\nintroduces a heuristically developed robust variation of DBAP that corrects for\nfaulty assumptions in the implementation of Lossius. Specifically, this paper\ndevelops a method for working with sound sources outside the field of\nloudspeakers in which the Lossius version produces distorted aural impressions\nand wildly undulating amplitudes caused by spatial discontinuities in the gains\nof the various loudspeakers. In smoothing the spatial impression of the virtual\nsource, we are also able to eliminate the calculation of the convex hull\nentirely, a necessary component of the original implementation. This\nsignificantly simplifies and reduces the calculations required for any space in\neither two or three dimensions.", "published": "2021-09-17 18:10:04", "link": "http://arxiv.org/abs/2109.08704v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dual-Encoder Architecture with Encoder Selection for Joint Close-Talk\n  and Far-Talk Speech Recognition", "abstract": "In this paper, we propose a dual-encoder ASR architecture for joint modeling\nof close-talk (CT) and far-talk (FT) speech, in order to combine the advantages\nof CT and FT devices for better accuracy. The key idea is to add an encoder\nselection network to choose the optimal input source (CT or FT) and the\ncorresponding encoder. We use a single-channel encoder for CT speech and a\nmulti-channel encoder with Spatial Filtering neural beamforming for FT speech,\nwhich are jointly trained with the encoder selection. We validate our approach\non both attention-based and RNN Transducer end-to-end ASR systems. The\nexperiments are done with conversational speech from a medical use case, which\nis recorded simultaneously with a CT device and a microphone array. Our results\nshow that the proposed dual-encoder architecture obtains up to 9% relative WER\nreduction when using both CT and FT input, compared to the best single-encoder\nsystem trained and tested in matched condition.", "published": "2021-09-17 19:52:47", "link": "http://arxiv.org/abs/2109.08744v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
