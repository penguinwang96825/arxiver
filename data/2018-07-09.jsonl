{"title": "Predicting Concreteness and Imageability of Words Within and Across\n  Languages via Word Embeddings", "abstract": "The notions of concreteness and imageability, traditionally important in\npsycholinguistics, are gaining significance in semantic-oriented natural\nlanguage processing tasks. In this paper we investigate the predictability of\nthese two concepts via supervised learning, using word embeddings as\nexplanatory variables. We perform predictions both within and across languages\nby exploiting collections of cross-lingual embeddings aligned to a single\nvector space. We show that the notions of concreteness and imageability are\nhighly predictable both within and across languages, with a moderate loss of up\nto 20% in correlation when predicting across languages. We further show that\nthe cross-lingual transfer via word embeddings is more efficient than the\nsimple transfer via bilingual dictionaries.", "published": "2018-07-09 00:44:47", "link": "http://arxiv.org/abs/1807.02903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Combined CNN and LSTM Model for Arabic Sentiment Analysis", "abstract": "Deep neural networks have shown good data modelling capabilities when dealing\nwith challenging and large datasets from a wide range of application areas.\nConvolutional Neural Networks (CNNs) offer advantages in selecting good\nfeatures and Long Short-Term Memory (LSTM) networks have proven good abilities\nof learning sequential data. Both approaches have been reported to provide\nimproved results in areas such image processing, voice recognition, language\ntranslation and other Natural Language Processing (NLP) tasks. Sentiment\nclassification for short text messages from Twitter is a challenging task, and\nthe complexity increases for Arabic language sentiment classification tasks\nbecause Arabic is a rich language in morphology. In addition, the availability\nof accurate pre-processing tools for Arabic is another current limitation,\nalong with limited research available in this area. In this paper, we\ninvestigate the benefits of integrating CNNs and LSTMs and report obtained\nimproved accuracy for Arabic sentiment analysis on different datasets.\nAdditionally, we seek to consider the morphological diversity of particular\nArabic words by using different sentiment classification levels.", "published": "2018-07-09 01:41:20", "link": "http://arxiv.org/abs/1807.02911v3", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Universal Word Segmentation: Implementation and Interpretation", "abstract": "Word segmentation is a low-level NLP task that is non-trivial for a\nconsiderable number of languages. In this paper, we present a sequence tagging\nframework and apply it to word segmentation for a wide range of languages with\ndifferent writing systems and typological characteristics. Additionally, we\ninvestigate the correlations between various typological factors and word\nsegmentation accuracy. The experimental results indicate that segmentation\naccuracy is positively related to word boundary markers and negatively to the\nnumber of unique non-segmental terms. Based on the analysis, we design a small\nset of language-specific settings and extensively evaluate the segmentation\nsystem on the Universal Dependencies datasets. Our model obtains\nstate-of-the-art accuracies on all the UD languages. It performs substantially\nbetter on languages that are non-trivial to segment, such as Chinese, Japanese,\nArabic and Hebrew, when compared to previous work.", "published": "2018-07-09 07:51:51", "link": "http://arxiv.org/abs/1807.02974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Enhancing Lexical Resource and Using Sense-annotations of\n  OntoSenseNet for Sentiment Analysis", "abstract": "This paper illustrates the interface of the tool we developed for crowd\nsourcing and we explain the annotation procedure in detail. Our tool is named\nas 'Parupalli Padajaalam' which means web of words by Parupalli. The aim of\nthis tool is to populate the OntoSenseNet, sentiment polarity annotated Telugu\nresource. Recent works have shown the importance of word-level annotations on\nsentiment analysis. With this as basis, we aim to analyze the importance of\nsense-annotations obtained from OntoSenseNet in performing the task of\nsentiment analysis. We explain the fea- tures extracted from OntoSenseNet\n(Telugu). Furthermore we compute and explain the adverbial class distribution\nof verbs in OntoSenseNet. This task is known to aid in disambiguating\nword-senses which helps in enhancing the performance of word-sense\ndisambiguation (WSD) task(s).", "published": "2018-07-09 09:27:25", "link": "http://arxiv.org/abs/1807.03004v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sequence-to-Sequence Model for Semantic Role Labeling", "abstract": "We explore a novel approach for Semantic Role Labeling (SRL) by casting it as\na sequence-to-sequence process. We employ an attention-based model enriched\nwith a copying mechanism to ensure faithful regeneration of the input sequence,\nwhile enabling interleaved generation of argument role labels. Here, we apply\nthis model in a monolingual setting, performing PropBank SRL on English\nlanguage data. The constrained sequence generation set-up enforced with the\ncopying mechanism allows us to analyze the performance and special properties\nof the model on manually labeled data and benchmarking against state-of-the-art\nsequence labeling models. We show that our model is able to solve the SRL\nargument labeling task on English data, yet further structural decoding\nconstraints will need to be added to make the model truly competitive. Our work\nrepresents a first step towards more advanced, generative SRL labeling setups.", "published": "2018-07-09 09:37:43", "link": "http://arxiv.org/abs/1807.03006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NMT-Keras: a Very Flexible Toolkit with a Focus on Interactive NMT and\n  Online Learning", "abstract": "We present NMT-Keras, a flexible toolkit for training deep learning models,\nwhich puts a particular emphasis on the development of advanced applications of\nneural machine translation systems, such as interactive-predictive translation\nprotocols and long-term adaptation of the translation system via continuous\nlearning. NMT-Keras is based on an extended version of the popular Keras\nlibrary, and it runs on Theano and Tensorflow. State-of-the-art neural machine\ntranslation models are deployed and used following the high-level framework\nprovided by Keras. Given its high modularity and flexibility, it also has been\nextended to tackle different problems, such as image and video captioning,\nsentence classification and visual question answering.", "published": "2018-07-09 13:14:00", "link": "http://arxiv.org/abs/1807.03096v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discriminating between Indo-Aryan Languages Using SVM Ensembles", "abstract": "In this paper we present a system based on SVM ensembles trained on\ncharacters and words to discriminate between five similar languages of the\nIndo-Aryan family: Hindi, Braj Bhasha, Awadhi, Bhojpuri, and Magahi. We\ninvestigate the performance of individual features and combine the output of\nsingle classifiers to maximize performance. The system competed in the\nIndo-Aryan Language Identification (ILI) shared task organized within the\nVarDial Evaluation Campaign 2018. Our best entry in the competition, named\nILIdentification, scored 88:95% F1 score and it was ranked 3rd out of 8 teams.", "published": "2018-07-09 13:26:44", "link": "http://arxiv.org/abs/1807.03108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Better UD Parsing: Deep Contextualized Word Embeddings,\n  Ensemble, and Treebank Concatenation", "abstract": "This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared\ntask on Multilingual Parsing from Raw Text to Universal Dependencies. We base\nour submission on Stanford's winning system for the CoNLL 2017 shared task and\nmake two effective extensions: 1) incorporating deep contextualized word\nembeddings into both the part of speech tagger and parser; 2) ensembling\nparsers trained with different initialization. We also explore different ways\nof concatenating treebanks for further improvements. Experimental results on\nthe development data show the effectiveness of our methods. In the final\nevaluation, our system was ranked first according to LAS (75.84%) and\noutperformed the other systems by a large margin.", "published": "2018-07-09 13:34:16", "link": "http://arxiv.org/abs/1807.03121v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Levels of Depression in Text Based on Metrics", "abstract": "Depression is one of the most common and a major concern for society. Proper\nmonitoring using devices that can aid in its detection could be helpful to\nprevent it all together. The Distress Analysis Interview Corpus (DAIC) is used\nto build a metric-based depression detection. We have designed a metric to\ndescribe the level of depression using negative sentences and classify the\nparticipant accordingly. The score generated from the algorithm is then\nlevelled up to denote the intensity of depression. The results show that\nmeasuring depression is very complex to using text alone as other factors are\nnot taken into consideration. Further, In the paper, the limitations of\nmeasuring depression using text are described, and future suggestions are made.", "published": "2018-07-09 21:32:47", "link": "http://arxiv.org/abs/1807.03397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who is Killed by Police: Introducing Supervised Attention for\n  Hierarchical LSTMs", "abstract": "Finding names of people killed by police has become increasingly important as\npolice shootings get more and more public attention (police killing detection).\nUnfortunately, there has been not much work in the literature addressing this\nproblem. The early work in this field \\cite{keith2017identifying} proposed a\ndistant supervision framework based on Expectation Maximization (EM) to deal\nwith the multiple appearances of the names in documents. However, such EM-based\nframework cannot take full advantages of deep learning models, necessitating\nthe use of hand-designed features to improve the detection performance. In this\nwork, we present a novel deep learning method to solve the problem of police\nkilling recognition. The proposed method relies on hierarchical LSTMs to model\nthe multiple sentences that contain the person names of interests, and\nintroduce supervised attention mechanisms based on semantical word lists and\ndependency trees to upweight the important contextual words. Our experiments\ndemonstrate the benefits of the proposed model and yield the state-of-the-art\nperformance for police killing detection.", "published": "2018-07-09 22:28:09", "link": "http://arxiv.org/abs/1807.03409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constructing a Word Similarity Graph from Vector based Word\n  Representation for Named Entity Recognition", "abstract": "In this paper, we discuss a method for identifying a seed word that would\nbest represent a class of named entities in a graphical representation of words\nand their similarities. Word networks, or word graphs, are representations of\nvectorized text where nodes are the words encountered in a corpus, and the\nweighted edges incident on the nodes represent how similar the words are to\neach other. We intend to build a bilingual word graph and identify seed words\nthrough community analysis that would be best used to segment a graph according\nto its named entities, therefore providing an unsupervised way of tagging named\nentities for a bilingual language base.", "published": "2018-07-09 09:43:23", "link": "http://arxiv.org/abs/1807.03012v1", "categories": ["cs.CL", "cs.IR", "68T50"], "primary_category": "cs.CL"}
{"title": "A deep learning approach for understanding natural language commands for\n  mobile service robots", "abstract": "Using natural language to give instructions to robots is challenging, since\nnatural language understanding is still largely an open problem. In this paper\nwe address this problem by restricting our attention to commands modeled as one\naction, plus arguments (also known as slots). For action detection (also called\nintent detection) and slot filling various architectures of Recurrent Neural\nNetworks and Long Short Term Memory (LSTM) networks were evaluated, having\nLSTMs achieved a superior accuracy. As the action requested may not fall within\nthe robots capabilities, a Support Vector Machine(SVM) is used to determine\nwhether it is or not. For the input of the neural networks, several word\nembedding algorithms were compared. Finally, to implement the system in a\nrobot, a ROS package is created using a SMACH state machine. The proposed\nsystem is then evaluated both using well-known datasets and benchmarks in the\ncontext of domestic service robots.", "published": "2018-07-09 11:34:21", "link": "http://arxiv.org/abs/1807.03053v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Jointly Embedding Entities and Text with Distant Supervision", "abstract": "Learning representations for knowledge base entities and concepts is becoming\nincreasingly important for NLP applications. However, recent entity embedding\nmethods have relied on structured resources that are expensive to create for\nnew domains and corpora. We present a distantly-supervised method for jointly\nlearning embeddings of entities and text from an unnanotated corpus, using only\na list of mappings between entities and surface forms. We learn embeddings from\nopen-domain and biomedical corpora, and compare against prior methods that rely\non human-annotated text or large knowledge graph structure. Our embeddings\ncapture entity similarity and relatedness better than prior work, both in\nexisting biomedical datasets and a new Wikipedia-based dataset that we release\nto the community. Results on analogy completion and entity sense disambiguation\nindicate that entities and words capture complementary information that can be\neffectively combined for downstream use.", "published": "2018-07-09 21:40:53", "link": "http://arxiv.org/abs/1807.03399v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Position-aware Self-attention with Relative Positional Encodings for\n  Slot Filling", "abstract": "This paper describes how to apply self-attention with relative positional\nencodings to the task of relation extraction. We propose to use the\nself-attention encoder layer together with an additional position-aware\nattention layer that takes into account positions of the query and the object\nin the sentence. The self-attention encoder also uses a custom implementation\nof relative positional encodings which allow each word in the sentence to take\ninto account its left and right context. The evaluation of the model is done on\nthe TACRED dataset. The proposed model relies only on attention (no recurrent\nor convolutional layers are used), while improving performance w.r.t. the\nprevious state of the art.", "published": "2018-07-09 11:34:13", "link": "http://arxiv.org/abs/1807.03052v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Talk the Walk: Navigating New York City through Grounded Dialogue", "abstract": "We introduce \"Talk The Walk\", the first large-scale dialogue dataset grounded\nin action and perception. The task involves two agents (a \"guide\" and a\n\"tourist\") that communicate via natural language in order to achieve a common\ngoal: having the tourist navigate to a given target location. The task and\ndataset, which are described in detail, are challenging and their full solution\nis an open problem that we pose to the community. We (i) focus on the task of\ntourist localization and develop the novel Masked Attention for Spatial\nConvolutions (MASC) mechanism that allows for grounding tourist utterances into\nthe guide's map, (ii) show it yields significant improvements for both emergent\nand natural language communication, and (iii) using this method, we establish\nnon-trivial baselines on the full task.", "published": "2018-07-09 20:05:24", "link": "http://arxiv.org/abs/1807.03367v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "On Training Recurrent Networks with Truncated Backpropagation Through\n  Time in Speech Recognition", "abstract": "Recurrent neural networks have been the dominant models for many speech and\nlanguage processing tasks. However, we understand little about the behavior and\nthe class of functions recurrent networks can realize. Moreover, the heuristics\nused during training complicate the analyses. In this paper, we study recurrent\nnetworks' ability to learn long-term dependency in the context of speech\nrecognition. We consider two decoding approaches, online and batch decoding,\nand show the classes of functions to which the decoding approaches correspond.\nWe then draw a connection between batch decoding and a popular training\napproach for recurrent networks, truncated backpropagation through time.\nChanging the decoding approach restricts the amount of past history recurrent\nnetworks can use for prediction, allowing us to analyze their ability to\nremember. Empirically, we utilize long-term dependency in subphonetic states,\nphonemes, and words, and show how the design decisions, such as the decoding\napproach, lookahead, context frames, and consecutive prediction, characterize\nthe behavior of recurrent networks. Finally, we draw a connection between\nMarkov processes and vanishing gradients. These results have implications for\nstudying the long-term dependency in speech data and how these properties are\nlearned by recurrent networks.", "published": "2018-07-09 21:31:49", "link": "http://arxiv.org/abs/1807.03396v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Robust Text-to-SQL Generation with Execution-Guided Decoding", "abstract": "We consider the problem of neural semantic parsing, which translates natural\nlanguage questions into executable SQL queries. We introduce a new mechanism,\nexecution guidance, to leverage the semantics of SQL. It detects and excludes\nfaulty programs during the decoding procedure by conditioning on the execution\nof partially generated program. The mechanism can be used with any\nautoregressive generative model, which we demonstrate on four state-of-the-art\nrecurrent or template-based semantic parsing models. We demonstrate that\nexecution guidance universally improves model performance on various\ntext-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\nand GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\nof 83.8% on WikiSQL.", "published": "2018-07-09 13:20:28", "link": "http://arxiv.org/abs/1807.03100v3", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Deep Multimodal Clustering for Unsupervised Audiovisual Learning", "abstract": "The seen birds twitter, the running cars accompany with noise, etc. These\nnaturally audiovisual correspondences provide the possibilities to explore and\nunderstand the outside world. However, the mixed multiple objects and sounds\nmake it intractable to perform efficient matching in the unconstrained\nenvironment. To settle this problem, we propose to adequately excavate audio\nand visual components and perform elaborate correspondence learning among them.\nConcretely, a novel unsupervised audiovisual learning model is proposed, named\nas \\Deep Multimodal Clustering (DMC), that synchronously performs sets of\nclustering with multimodal vectors of convolutional maps in different shared\nspaces for capturing multiple audiovisual correspondences. And such integrated\nmultimodal clustering network can be effectively trained with max-margin loss\nin the end-to-end fashion. Amounts of experiments in feature evaluation and\naudiovisual tasks are performed. The results demonstrate that DMC can learn\neffective unimodal representation, with which the classifier can even\noutperform human performance. Further, DMC shows noticeable performance in\nsound localization, multisource detection, and audiovisual understanding.", "published": "2018-07-09 13:13:10", "link": "http://arxiv.org/abs/1807.03094v3", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "AudioMNIST: Exploring Explainable Artificial Intelligence for Audio\n  Analysis on a Simple Benchmark", "abstract": "Explainable Artificial Intelligence (XAI) is targeted at understanding how\nmodels perform feature selection and derive their classification decisions.\nThis paper explores post-hoc explanations for deep neural networks in the audio\ndomain. Notably, we present a novel Open Source audio dataset consisting of\n30,000 audio samples of English spoken digits which we use for classification\ntasks on spoken digits and speakers' biological sex. We use the popular XAI\ntechnique Layer-wise Relevance Propagation (LRP) to identify relevant features\nfor two neural network architectures that process either waveform or\nspectrogram representations of the data. Based on the relevance scores obtained\nfrom LRP, hypotheses about the neural networks' feature selection are derived\nand subsequently tested through systematic manipulations of the input data.\nFurther, we take a step beyond visual explanations and introduce audible\nheatmaps. We demonstrate the superior interpretability of audible explanations\nover visual ones in a human user study.", "published": "2018-07-09 23:11:17", "link": "http://arxiv.org/abs/1807.03418v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Foreign English Accent Adjustment by Learning Phonetic Patterns", "abstract": "State-of-the-art automatic speech recognition (ASR) systems struggle with the\nlack of data for rare accents. For sufficiently large datasets, neural engines\ntend to outshine statistical models in most natural language processing\nproblems. However, a speech accent remains a challenge for both approaches.\nPhonologists manually create general rules describing a speaker's accent, but\ntheir results remain underutilized. In this paper, we propose a model that\nautomatically retrieves phonological generalizations from a small dataset. This\nmethod leverages the difference in pronunciation between a particular dialect\nand General American English (GAE) and creates new accented samples of words.\nThe proposed model is able to learn all generalizations that previously were\nmanually obtained by phonologists. We use this statistical method to generate a\nmillion phonological variations of words from the CMU Pronouncing Dictionary\nand train a sequence-to-sequence RNN to recognize accented words with 59%\naccuracy.", "published": "2018-07-09 17:38:23", "link": "http://arxiv.org/abs/1807.03625v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Approximate k-space models and Deep Learning for fast photoacoustic\n  reconstruction", "abstract": "We present a framework for accelerated iterative reconstructions using a fast\nand approximate forward model that is based on k-space methods for\nphotoacoustic tomography. The approximate model introduces aliasing artefacts\nin the gradient information for the iterative reconstruction, but these\nartefacts are highly structured and we can train a CNN that can use the\napproximate information to perform an iterative reconstruction. We show\nfeasibility of the method for human in-vivo measurements in a limited-view\ngeometry. The proposed method is able to produce superior results to total\nvariation reconstructions with a speed-up of 32 times.", "published": "2018-07-09 14:32:18", "link": "http://arxiv.org/abs/1807.03191v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS", "math.OC", "49N45, 65T50"], "primary_category": "cs.CV"}
{"title": "Deep Learning for Singing Processing: Achievements, Challenges and\n  Impact on Singers and Listeners", "abstract": "This paper summarizes some recent advances on a set of tasks related to the\nprocessing of singing using state-of-the-art deep learning techniques. We\ndiscuss their achievements in terms of accuracy and sound quality, and the\ncurrent challenges, such as availability of data and computing resources. We\nalso discuss the impact that these advances do and will have on listeners and\nsingers when they are integrated in commercial applications.", "published": "2018-07-09 11:19:42", "link": "http://arxiv.org/abs/1807.03046v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "cs.MM", "eess.AS", "stat.ML", "97M80"], "primary_category": "cs.SD"}
