{"title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense\n  Inference", "abstract": "Given a partial description like \"she opened the hood of the car,\" humans can\nreason about the situation and anticipate what might come next (\"then, she\nexamined the engine\"). In this paper, we introduce the task of grounded\ncommonsense inference, unifying natural language inference and commonsense\nreasoning.\n  We present SWAG, a new dataset with 113k multiple choice questions about a\nrich spectrum of grounded situations. To address the recurring challenges of\nthe annotation artifacts and human biases found in many existing datasets, we\npropose Adversarial Filtering (AF), a novel procedure that constructs a\nde-biased dataset by iteratively training an ensemble of stylistic classifiers,\nand using them to filter the data. To account for the aggressive adversarial\nfiltering, we use state-of-the-art language models to massively oversample a\ndiverse set of potential counterfactuals. Empirical results demonstrate that\nwhile humans can solve the resulting inference problems with high accuracy\n(88%), various competitive models struggle on our task. We provide\ncomprehensive analysis that indicates significant opportunities for future\nresearch.", "published": "2018-08-16 02:21:01", "link": "http://arxiv.org/abs/1808.05326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computing Word Classes Using Spectral Clustering", "abstract": "Clustering a lexicon of words is a well-studied problem in natural language\nprocessing (NLP). Word clusters are used to deal with sparse data in\nstatistical language processing, as well as features for solving various NLP\ntasks (text categorization, question answering, named entity recognition and\nothers).\n  Spectral clustering is a widely used technique in the field of image\nprocessing and speech recognition. However, it has scarcely been explored in\nthe context of NLP; specifically, the method used in this (Meila and Shi, 2001)\nhas never been used to cluster a general word lexicon.\n  We apply spectral clustering to a lexicon of words, evaluating the resulting\nclusters by using them as features for solving two classical NLP tasks:\nsemantic role labeling and dependency parsing. We compare performance with\nBrown clustering, a widely-used technique for word clustering, as well as with\nother clustering methods. We show that spectral clusters produce similar\nresults to Brown clusters, and outperform other clustering methods. In\naddition, we quantify the overlap between spectral and Brown clusters, showing\nthat each model captures some information which is uncaptured by the other.", "published": "2018-08-16 08:11:24", "link": "http://arxiv.org/abs/1808.05374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sememe Prediction: Learning Semantic Knowledge from Unstructured Textual\n  Wiki Descriptions", "abstract": "Huge numbers of new words emerge every day, leading to a great need for\nrepresenting them with semantic meaning that is understandable to NLP systems.\nSememes are defined as the minimum semantic units of human languages, the\ncombination of which can represent the meaning of a word. Manual construction\nof sememe based knowledge bases is time-consuming and labor-intensive.\nFortunately, communities are devoted to composing the descriptions of words in\nthe wiki websites. In this paper, we explore to automatically predict lexical\nsememes based on the descriptions of the words in the wiki websites. We view\nthis problem as a weakly ordered multi-label task and propose a Label\nDistributed seq2seq model (LD-seq2seq) with a novel soft loss function to solve\nthe problem. In the experiments, we take a real-world sememe knowledge base\nHowNet and the corresponding descriptions of the words in Baidu Wiki for\ntraining and evaluation. The results show that our LD-seq2seq model not only\nbeats all the baselines significantly on the test set, but also outperforms\namateur human annotators in a random subset of the test set.", "published": "2018-08-16 12:13:16", "link": "http://arxiv.org/abs/1808.05437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paraphrase Thought: Sentence Embedding Module Imitating Human Language\n  Recognition", "abstract": "Sentence embedding is an important research topic in natural language\nprocessing. It is essential to generate a good embedding vector that fully\nreflects the semantic meaning of a sentence in order to achieve an enhanced\nperformance for various natural language processing tasks, such as machine\ntranslation and document classification. Thus far, various sentence embedding\nmodels have been proposed, and their feasibility has been demonstrated through\ngood performances on tasks following embedding, such as sentiment analysis and\nsentence classification. However, because the performances of sentence\nclassification and sentiment analysis can be enhanced by using a simple\nsentence representation method, it is not sufficient to claim that these models\nfully reflect the meanings of sentences based on good performances for such\ntasks. In this paper, inspired by human language recognition, we propose the\nfollowing concept of semantic coherence, which should be satisfied for a good\nsentence embedding method: similar sentences should be located close to each\nother in the embedding space. Then, we propose the Paraphrase-Thought\n(P-thought) model to pursue semantic coherence as much as possible.\nExperimental results on two paraphrase identification datasets (MS COCO and STS\nbenchmark) show that the P-thought models outperform the benchmarked sentence\nembedding methods.", "published": "2018-08-16 14:20:50", "link": "http://arxiv.org/abs/1808.05505v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Graph Embeddings from WordNet-based Similarity Measures", "abstract": "We present path2vec, a new approach for learning graph embeddings that relies\non structural measures of pairwise node similarities. The model learns\nrepresentations for nodes in a dense space that approximate a given\nuser-defined graph distance measure, such as e.g. the shortest path distance or\ndistance measures that take information beyond the graph structure into\naccount. Evaluation of the proposed model on semantic similarity and word sense\ndisambiguation tasks, using various WordNet-based similarity measures, show\nthat our approach yields competitive results, outperforming strong graph\nembedding baselines. The model is computationally efficient, being orders of\nmagnitude faster than the direct computation of graph-based distances.", "published": "2018-08-16 17:59:14", "link": "http://arxiv.org/abs/1808.05611v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Human Trustfulness from Facebook Language", "abstract": "Trustfulness -- one's general tendency to have confidence in unknown people\nor situations -- predicts many important real-world outcomes such as mental\nhealth and likelihood to cooperate with others such as clinicians. While\ndata-driven measures of interpersonal trust have previously been introduced,\nhere, we develop the first language-based assessment of the personality trait\nof trustfulness by fitting one's language to an accepted questionnaire-based\ntrust score. Further, using trustfulness as a type of case study, we explore\nthe role of questionnaire size as well as word count in developing\nlanguage-based predictive models of users' psychological traits. We find that\nleveraging a longer questionnaire can yield greater test set accuracy, while,\nfor training, we find it beneficial to include users who took smaller\nquestionnaires which offers more observations for training. Similarly, after\nnoting a decrease in individual prediction error as word count increased, we\nfound a word count-weighted training scheme was helpful when there were very\nfew users in the first place.", "published": "2018-08-16 20:22:18", "link": "http://arxiv.org/abs/1808.05668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Statistical Machine Translation with Subword Translation of\n  Out-of-Vocabulary Words", "abstract": "Most statistical machine translation systems cannot translate words that are\nunseen in the training data. However, humans can translate many classes of\nout-of-vocabulary (OOV) words (e.g., novel morphological variants,\nmisspellings, and compounds) without context by using orthographic clues.\nFollowing this observation, we describe and evaluate several general methods\nfor OOV translation that use only subword information. We pose the OOV\ntranslation problem as a standalone task and intrinsically evaluate our\napproaches on fourteen typologically diverse languages across varying resource\nlevels. Adding OOV translators to a statistical machine translation system\nyields consistent BLEU gains (0.5 points on average, and up to 2.0) for all\nfourteen languages, especially in low-resource scenarios.", "published": "2018-08-16 23:05:17", "link": "http://arxiv.org/abs/1808.05700v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward domain-invariant speech recognition via large scale training", "abstract": "Current state-of-the-art automatic speech recognition systems are trained to\nwork in specific `domains', defined based on factors like application, sampling\nrate and codec. When such recognizers are used in conditions that do not match\nthe training domain, performance significantly drops. This work explores the\nidea of building a single domain-invariant model for varied use-cases by\ncombining large scale training data from multiple application domains. Our\nfinal system is trained using 162,000 hours of speech. Additionally, each\nutterance is artificially distorted during training to simulate effects like\nbackground noise, codec distortion, and sampling rates. Our results show that,\neven at such a scale, a model thus trained works almost as well as those\nfine-tuned to specific subsets: A single model can be robust to multiple\napplication domains, and variations like codecs and noise. More importantly,\nsuch models generalize better to unseen conditions and allow for rapid\nadaptation -- we show that by using as little as 10 hours of data from a new\ndomain, an adapted domain-invariant model can match performance of a\ndomain-specific model trained from scratch using 70 times as much data. We also\nhighlight some of the limitations of such models and areas that need addressing\nin future work.", "published": "2018-08-16 00:24:49", "link": "http://arxiv.org/abs/1808.05312v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Linguistic data mining with complex networks: a stylometric-oriented\n  approach", "abstract": "By representing a text by a set of words and their co-occurrences, one\nobtains a word-adjacency network being a reduced representation of a given\nlanguage sample. In this paper, the possibility of using network representation\nto extract information about individual language styles of literary texts is\nstudied. By determining selected quantitative characteristics of the networks\nand applying machine learning algorithms, it is possible to distinguish between\ntexts of different authors. Within the studied set of texts, English and\nPolish, a properly rescaled weighted clustering coefficients and weighted\ndegrees of only a few nodes in the word-adjacency networks are sufficient to\nobtain the authorship attribution accuracy over 90%. A correspondence between\nthe text authorship and the word-adjacency network structure can therefore be\nfound. The network representation allows to distinguish individual language\nstyles by comparing the way the authors use particular words and punctuation\nmarks. The presented approach can be viewed as a generalization of the\nauthorship attribution methods based on simple lexical features.\n  Additionally, other network parameters are studied, both local and global\nones, for both the unweighted and weighted networks. Their potential to capture\nthe writing style diversity is discussed; some differences between languages\nare observed.", "published": "2018-08-16 12:14:07", "link": "http://arxiv.org/abs/1808.05439v2", "categories": ["cs.CL", "nlin.AO"], "primary_category": "cs.CL"}
{"title": "Improving Conditional Sequence Generative Adversarial Networks by\n  Stepwise Evaluation", "abstract": "Sequence generative adversarial networks (SeqGAN) have been used to improve\nconditional sequence generation tasks, for example, chit-chat dialogue\ngeneration. To stabilize the training of SeqGAN, Monte Carlo tree search (MCTS)\nor reward at every generation step (REGS) is used to evaluate the goodness of a\ngenerated subsequence. MCTS is computationally intensive, but the performance\nof REGS is worse than MCTS. In this paper, we propose stepwise GAN (StepGAN),\nin which the discriminator is modified to automatically assign scores\nquantifying the goodness of each subsequence at every generation step. StepGAN\nhas significantly less computational costs than MCTS. We demonstrate that\nStepGAN outperforms previous GAN-based methods on both synthetic experiment and\nchit-chat dialogue generation.", "published": "2018-08-16 17:41:00", "link": "http://arxiv.org/abs/1808.05599v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Combining time-series and textual data for taxi demand prediction in\n  event areas: a deep learning approach", "abstract": "Accurate time-series forecasting is vital for numerous areas of application\nsuch as transportation, energy, finance, economics, etc. However, while modern\ntechniques are able to explore large sets of temporal data to build forecasting\nmodels, they typically neglect valuable information that is often available\nunder the form of unstructured text. Although this data is in a radically\ndifferent format, it often contains contextual explanations for many of the\npatterns that are observed in the temporal data. In this paper, we propose two\ndeep learning architectures that leverage word embeddings, convolutional layers\nand attention mechanisms for combining text information with time-series data.\nWe apply these approaches for the problem of taxi demand forecasting in event\nareas. Using publicly available taxi data from New York, we empirically show\nthat by fusing these two complementary cross-modal sources of information, the\nproposed models are able to significantly reduce the error in the forecasts.", "published": "2018-08-16 15:19:34", "link": "http://arxiv.org/abs/1808.05535v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Deep Bayesian Active Learning for Natural Language Processing: Results\n  of a Large-Scale Empirical Study", "abstract": "Several recent papers investigate Active Learning (AL) for mitigating the\ndata dependence of deep learning for natural language processing. However, the\napplicability of AL to real-world problems remains an open question. While in\nsupervised learning, practitioners can try many different methods, evaluating\neach against a validation set before selecting a model, AL affords no such\nluxury. Over the course of one AL run, an agent annotates its dataset\nexhausting its labeling budget. Thus, given a new task, an active learner has\nno opportunity to compare models and acquisition functions. This paper provides\na large scale empirical study of deep active learning, addressing multiple\ntasks and, for each, multiple datasets, multiple models, and a full suite of\nacquisition functions. We find that across all settings, Bayesian active\nlearning by disagreement, using uncertainty estimates provided either by\nDropout or Bayes-by Backprop significantly improves over i.i.d. baselines and\nusually outperforms classic uncertainty sampling.", "published": "2018-08-16 22:46:40", "link": "http://arxiv.org/abs/1808.05697v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Story Disambiguation: Tracking Evolving News Stories across News and\n  Social Streams", "abstract": "Following a particular news story online is an important but difficult task,\nas the relevant information is often scattered across different domains/sources\n(e.g., news articles, blogs, comments, tweets), presented in various formats\nand language styles, and may overlap with thousands of other stories. In this\nwork we join the areas of topic tracking and entity disambiguation, and propose\na framework named Story Disambiguation - a cross-domain story tracking approach\nthat builds on real-time entity disambiguation and a learning-to-rank framework\nto represent and update the rich semantic structure of news stories. Given a\ntarget news story, specified by a seed set of documents, the goal is to\neffectively select new story-relevant documents from an incoming document\nstream. We represent stories as entity graphs and we model the story tracking\nproblem as a learning-to-rank task. This enables us to track content with high\naccuracy, from multiple domains, in real-time. We study a range of text, entity\nand graph based features to understand which type of features are most\neffective for representing stories. We further propose new semi-supervised\nlearning techniques to automatically update the story representation over time.\nOur empirical study shows that we outperform the accuracy of state-of-the-art\nmethods for tracking mixed-domain document streams, while requiring fewer\nlabeled data to seed the tracked stories. This is particularly the case for\nlocal news stories that are easily over shadowed by other trending stories, and\nfor complex news stories with ambiguous content in noisy stream environments.", "published": "2018-08-16 09:02:37", "link": "http://arxiv.org/abs/1808.05906v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improved Chord Recognition by Combining Duration and Harmonic Language\n  Models", "abstract": "Chord recognition systems typically comprise an acoustic model that predicts\nchords for each audio frame, and a temporal model that casts these predictions\ninto labelled chord segments. However, temporal models have been shown to only\nsmooth predictions, without being able to incorporate musical information about\nchord progressions. Recent research discovered that it might be the low\nhierarchical level such models have been applied to (directly on audio frames)\nwhich prevents learning musical relationships, even for expressive models such\nas recurrent neural networks (RNNs). However, if applied on the level of chord\nsequences, RNNs indeed can become powerful chord predictors. In this paper, we\ndisentangle temporal models into a harmonic language model---to be applied on\nchord sequences---and a chord duration model that connects the chord-level\npredictions of the language model to the frame-level predictions of the\nacoustic model. In our experiments, we explore the impact of each model on the\nchord recognition score, and show that using harmonic language and duration\nmodels improves the results.", "published": "2018-08-16 03:34:27", "link": "http://arxiv.org/abs/1808.05335v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Genre-Agnostic Key Classification With Convolutional Neural Networks", "abstract": "We propose modifications to the model structure and training procedure to a\nrecently introduced Convolutional Neural Network for musical key\nclassification. These modifications enable the network to learn a\ngenre-independent model that performs better than models trained for specific\nmusic styles, which has not been the case in existing work. We analyse this\ngeneralisation capability on three datasets comprising distinct genres. We then\nevaluate the model on a number of unseen data sets, and show its superior\nperformance compared to the state of the art. Finally, we investigate the\nmodel's performance on short excerpts of audio. From these experiments, we\nconclude that models need to consider the harmonic coherence of the whole piece\nwhen classifying the local key of short segments of audio.", "published": "2018-08-16 03:57:03", "link": "http://arxiv.org/abs/1808.05340v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Chord Recognition with Higher-Order Harmonic Language\n  Modelling", "abstract": "Common temporal models for automatic chord recognition model chord changes on\na frame-wise basis. Due to this fact, they are unable to capture musical\nknowledge about chord progressions. In this paper, we propose a temporal model\nthat enables explicit modelling of chord changes and durations. We then apply\nN-gram models and a neural-network-based acoustic model within this framework,\nand evaluate the effect of model overconfidence. Our results show that model\noverconfidence plays only a minor role (but target smoothing still improves the\nacoustic model), and that stronger chord language models do improve recognition\nresults, however their effects are small compared to other domains.", "published": "2018-08-16 04:10:02", "link": "http://arxiv.org/abs/1808.05341v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model\n  based on BLSTM", "abstract": "Nowadays, most of the objective speech quality assessment tools (e.g.,\nperceptual evaluation of speech quality (PESQ)) are based on the comparison of\nthe degraded/processed speech with its clean counterpart. The need of a\n\"golden\" reference considerably restricts the practicality of such assessment\ntools in real-world scenarios since the clean reference usually cannot be\naccessed. On the other hand, human beings can readily evaluate the speech\nquality without any reference (e.g., mean opinion score (MOS) tests), implying\nthe existence of an objective and non-intrusive (no clean reference needed)\nquality assessment mechanism. In this study, we propose a novel end-to-end,\nnon-intrusive speech quality evaluation model, termed Quality-Net, based on\nbidirectional long short-term memory. The evaluation of utterance-level quality\nin Quality-Net is based on the frame-level assessment. Frame constraints and\nsensible initializations of forget gate biases are applied to learn meaningful\nframe-level quality assessment from the utterance-level quality label.\nExperimental results show that Quality-Net can yield high correlation to PESQ\n(0.9 for the noisy speech and 0.84 for the speech processed by speech\nenhancement). We believe that Quality-Net has potential to be used in a wide\nvariety of applications of speech signal processing.", "published": "2018-08-16 04:26:41", "link": "http://arxiv.org/abs/1808.05344v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adversarial Attacks Against Automatic Speech Recognition Systems via\n  Psychoacoustic Hiding", "abstract": "Voice interfaces are becoming accepted widely as input methods for a diverse\nset of devices. This development is driven by rapid improvements in automatic\nspeech recognition (ASR), which now performs on par with human listening in\nmany tasks. These improvements base on an ongoing evolution of DNNs as the\ncomputational core of ASR. However, recent research results show that DNNs are\nvulnerable to adversarial perturbations, which allow attackers to force the\ntranscription into a malicious output.\n  In this paper, we introduce a new type of adversarial examples based on\npsychoacoustic hiding. Our attack exploits the characteristics of DNN-based ASR\nsystems, where we extend the original analysis procedure by an additional\nbackpropagation step. We use this backpropagation to learn the degrees of\nfreedom for the adversarial perturbation of the input signal, i.e., we apply a\npsychoacoustic model and manipulate the acoustic signal below the thresholds of\nhuman perception. To further minimize the perceptibility of the perturbations,\nwe use forced alignment to find the best fitting temporal alignment between the\noriginal audio sample and the malicious target transcription. These extensions\nallow us to embed an arbitrary audio input with a malicious voice command that\nis then transcribed by the ASR system, with the audio signal remaining barely\ndistinguishable from the original signal. In an experimental evaluation, we\nattack the state-of-the-art speech recognition system Kaldi and determine the\nbest performing parameter and analysis setup for different types of input. Our\nresults show that we are successful in up to 98% of cases with a computational\neffort of fewer than two minutes for a ten-second audio file. Based on user\nstudies, we found that none of our target transcriptions were audible to human\nlisteners, who still understand the original speech content with unchanged\naccuracy.", "published": "2018-08-16 20:00:47", "link": "http://arxiv.org/abs/1808.05665v2", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
