{"title": "Memorization Without Overfitting: Analyzing the Training Dynamics of\n  Large Language Models", "abstract": "Despite their wide adoption, the underlying training and memorization\ndynamics of very large language models is not well understood. We empirically\nstudy exact memorization in causal and masked language modeling, across model\nsizes and throughout the training process. We measure the effects of dataset\nsize, learning rate, and model size on memorization, finding that larger\nlanguage models memorize training data faster across all settings.\nSurprisingly, we show that larger models can memorize a larger portion of the\ndata before over-fitting and tend to forget less throughout the training\nprocess. We also analyze the memorization dynamics of different parts of speech\nand find that models memorize nouns and numbers first; we hypothesize and\nprovide empirical evidence that nouns and numbers act as a unique identifier\nfor memorizing individual training examples. Together, these findings present\nanother piece of the broader puzzle of trying to understand what actually\nimproves as models get bigger.", "published": "2022-05-22 07:43:50", "link": "http://arxiv.org/abs/2205.10770v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction Induction: From Few Examples to Natural Language Task\n  Descriptions", "abstract": "Large language models are able to perform a task by conditioning on a few\ninput-output demonstrations - a paradigm known as in-context learning. We show\nthat language models can explicitly infer an underlying task from a few\ndemonstrations by prompting them to generate a natural language instruction\nthat fits the examples. To explore this ability, we introduce the instruction\ninduction challenge, compile a dataset consisting of 24 tasks, and define a\nnovel evaluation metric based on executing the generated instruction. We\ndiscover that, to a large extent, the ability to generate instructions does\nindeed emerge when using a model that is both large enough and aligned to\nfollow instructions; InstructGPT achieves 65.7% of human performance in our\nexecution-based metric, while the original GPT-3 model reaches only 9.8% of\nhuman performance. This surprising result suggests that instruction induction\nmight be a viable learning paradigm in and of itself, where instead of fitting\na set of latent continuous parameters to the data, one searches for the best\ndescription in the natural language hypothesis space.", "published": "2022-05-22 09:22:37", "link": "http://arxiv.org/abs/2205.10782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Machine Translation with Hyper-Adapters", "abstract": "Multilingual machine translation suffers from negative interference across\nlanguages. A common solution is to relax parameter sharing with\nlanguage-specific modules like adapters. However, adapters of related languages\nare unable to transfer information, and their total number of parameters\nbecomes prohibitively expensive as the number of languages grows. In this work,\nwe overcome these drawbacks using hyper-adapters -- hyper-networks that\ngenerate adapters from language and layer embeddings. While past work had poor\nresults when scaling hyper-networks, we propose a rescaling fix that\nsignificantly improves convergence and enables training larger hyper-networks.\nWe find that hyper-adapters are more parameter efficient than regular adapters,\nreaching the same performance with up to 12 times less parameters. When using\nthe same number of parameters and FLOPS, our approach consistently outperforms\nregular adapters. Also, hyper-adapters converge faster than alternative\napproaches and scale better than regular dense networks. Our analysis shows\nthat hyper-adapters learn to encode language relatedness, enabling positive\ntransfer across languages.", "published": "2022-05-22 14:24:58", "link": "http://arxiv.org/abs/2205.10835v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AFEC: A Knowledge Graph Capturing Social Intelligence in Casual\n  Conversations", "abstract": "This paper introduces AFEC, an automatically curated knowledge graph based on\npeople's day-to-day casual conversations. The knowledge captured in this graph\nbears potential for conversational systems to understand how people offer\nacknowledgement, consoling, and a wide range of empathetic responses in social\nconversations. For this body of knowledge to be comprehensive and meaningful,\nwe curated a large-scale corpus from the r/CasualConversation SubReddit. After\ntaking the first two turns of all conversations, we obtained 134K speaker nodes\nand 666K listener nodes. To demonstrate how a chatbot can converse in social\nsettings, we built a retrieval-based chatbot and compared it with existing\nempathetic dialog models. Experiments show that our model is capable of\ngenerating much more diverse responses (at least 15% higher diversity scores in\nhuman evaluation), while still outperforming two out of the four baselines in\nterms of response quality.", "published": "2022-05-22 15:19:12", "link": "http://arxiv.org/abs/2205.10850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blackbird's language matrices (BLMs): a new benchmark to investigate\n  disentangled generalisation in neural networks", "abstract": "Current successes of machine learning architectures are based on\ncomputationally expensive algorithms and prohibitively large amounts of data.\nWe need to develop tasks and data to train networks to reach more complex and\nmore compositional skills. In this paper, we illustrate Blackbird's language\nmatrices (BLMs), a novel grammatical dataset developed to test a linguistic\nvariant of Raven's progressive matrices, an intelligence test usually based on\nvisual stimuli. The dataset consists of 44800 sentences, generatively\nconstructed to support investigations of current models' linguistic mastery of\ngrammatical agreement rules and their ability to generalise them. We present\nthe logic of the dataset, the method to automatically construct data on a large\nscale and the architecture to learn them. Through error analysis and several\nexperiments on variations of the dataset, we demonstrate that this language\ntask and the data that instantiate it provide a new challenging testbed to\nunderstand generalisation and abstraction.", "published": "2022-05-22 16:51:24", "link": "http://arxiv.org/abs/2205.10866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Action: Grammatical Error Correction with Action Guided\n  Sequence Generation", "abstract": "The task of Grammatical Error Correction (GEC) has received remarkable\nattention with wide applications in Natural Language Processing (NLP) in recent\nyears. While one of the key principles of GEC is to keep the correct parts\nunchanged and avoid over-correction, previous sequence-to-sequence (seq2seq)\nmodels generate results from scratch, which are not guaranteed to follow the\noriginal sentence structure and may suffer from the over-correction problem. In\nthe meantime, the recently proposed sequence tagging models can overcome the\nover-correction problem by only generating edit operations, but are conditioned\non human designed language-specific tagging labels. In this paper, we combine\nthe pros and alleviate the cons of both models by proposing a novel\nSequence-to-Action~(S2A) module. The S2A module jointly takes the source and\ntarget sentences as input, and is able to automatically generate a token-level\naction sequence before predicting each token, where each action is generated\nfrom three choices named SKIP, COPY and GENerate. Then the actions are fused\nwith the basic seq2seq framework to provide final predictions. We conduct\nexperiments on the benchmark datasets of both English and Chinese GEC tasks.\nOur model consistently outperforms the seq2seq baselines, while being able to\nsignificantly alleviate the over-correction problem as well as holding better\ngenerality and diversity in the generation results compared to the sequence\ntagging models.", "published": "2022-05-22 17:47:06", "link": "http://arxiv.org/abs/2205.10884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Case for Perspective in Multimodal Datasets", "abstract": "This paper argues in favor of the adoption of annotation practices for\nmultimodal datasets that recognize and represent the inherently perspectivized\nnature of multimodal communication. To support our claim, we present a set of\nannotation experiments in which FrameNet annotation is applied to the Multi30k\nand the Flickr 30k Entities datasets. We assess the cosine similarity between\nthe semantic representations derived from the annotation of both pictures and\ncaptions for frames. Our findings indicate that: (i) frame semantic similarity\nbetween captions of the same picture produced in different languages is\nsensitive to whether the caption is a translation of another caption or not,\nand (ii) picture annotation for semantic frames is sensitive to whether the\nimage is annotated in presence of a caption or not.", "published": "2022-05-22 18:37:05", "link": "http://arxiv.org/abs/2205.10902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diversity Enhanced Table-to-Text Generation via Type Control", "abstract": "Generating natural language statements to convey logical inferences from\ntabular data (i.e., Logical NLG) is a process with one input and a variety of\nvalid outputs. This characteristic underscores the need for a method to produce\na diverse set of valid outputs, presenting different perspectives of the input\ndata. We propose a simple yet effective diversity-enhancing scheme that builds\nupon an inherent property of the statements, their logic-types, by using a\ntype-controlled table-to-text generation model. We demonstrate, through\nextensive automatic and human evaluations over the two publicly available\nLogical NLG datasets, that our proposed method both facilitates the ability to\neffectively control the generated statement type, and produces results superior\nto the strongest baselines in terms of quality and factuality-diversity\ntrade-off.", "published": "2022-05-22 22:05:21", "link": "http://arxiv.org/abs/2205.10938v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Geometry of Multilingual Language Model Representations", "abstract": "We assess how multilingual language models maintain a shared multilingual\nrepresentation space while still encoding language-sensitive information in\neach language. Using XLM-R as a case study, we show that languages occupy\nsimilar linear subspaces after mean-centering, evaluated based on causal\neffects on language modeling performance and direct comparisons between\nsubspaces for 88 languages. The subspace means differ along language-sensitive\naxes that are relatively stable throughout middle layers, and these axes encode\ninformation such as token vocabularies. Shifting representations by language\nmeans is sufficient to induce token predictions in different languages.\nHowever, we also identify stable language-neutral axes that encode information\nsuch as token positions and part-of-speech. We visualize representations\nprojected onto language-sensitive and language-neutral axes, identifying\nlanguage family and part-of-speech clusters, along with spirals, toruses, and\ncurves representing token position information. These results demonstrate that\nmultilingual language models encode information along orthogonal\nlanguage-sensitive and language-neutral axes, allowing the models to extract a\nvariety of features for downstream tasks and cross-lingual transfer learning.", "published": "2022-05-22 23:58:24", "link": "http://arxiv.org/abs/2205.10964v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phrase-level Textual Adversarial Attack with Label Preservation", "abstract": "Generating high-quality textual adversarial examples is critical for\ninvestigating the pitfalls of natural language processing (NLP) models and\nfurther promoting their robustness. Existing attacks are usually realized\nthrough word-level or sentence-level perturbations, which either limit the\nperturbation space or sacrifice fluency and textual quality, both affecting the\nattack effectiveness. In this paper, we propose Phrase-Level Textual\nAdversarial aTtack (PLAT) that generates adversarial samples through\nphrase-level perturbations. PLAT first extracts the vulnerable phrases as\nattack targets by a syntactic parser, and then perturbs them by a pre-trained\nblank-infilling model. Such flexible perturbation design substantially expands\nthe search space for more effective attacks without introducing too many\nmodifications, and meanwhile maintaining the textual fluency and grammaticality\nvia contextualized generation using surrounding texts. Moreover, we develop a\nlabel-preservation filter leveraging the likelihoods of language models\nfine-tuned on each class, rather than textual similarity, to rule out those\nperturbations that potentially alter the original class label for humans.\nExtensive experiments and human evaluation demonstrate that PLAT has a superior\nattack effectiveness as well as a better label consistency than strong\nbaselines.", "published": "2022-05-22 02:22:38", "link": "http://arxiv.org/abs/2205.10710v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretable Proof Generation via Iterative Backward Reasoning", "abstract": "We present IBR, an Iterative Backward Reasoning model to solve the proof\ngeneration tasks on rule-based Question Answering (QA), where models are\nrequired to reason over a series of textual rules and facts to find out the\nrelated proof path and derive the final answer. We handle the limitations of\nexisted works in two folds: 1) enhance the interpretability of reasoning\nprocedures with detailed tracking, by predicting nodes and edges in the proof\npath iteratively backward from the question; 2) promote the efficiency and\naccuracy via reasoning on the elaborate representations of nodes and history\npaths, without any intermediate texts that may introduce external noise during\nproof generation. There are three main modules in IBR, QA and proof strategy\nprediction to obtain the answer and offer guidance for the following procedure;\nparent node prediction to determine a node in the existing proof that a new\nchild node will link to; child node prediction to find out which new node will\nbe added to the proof. Experiments on both synthetic and paraphrased datasets\ndemonstrate that IBR has better in-domain performance as well as cross-domain\ntransferability than several strong baselines. Our code and models are\navailable at https://github.com/find-knowledge/IBR .", "published": "2022-05-22 02:44:14", "link": "http://arxiv.org/abs/2205.10714v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "All Birds with One Stone: Multi-task Text Classification for Efficient\n  Inference with One Forward Pass", "abstract": "Multi-Task Learning (MTL) models have shown their robustness, effectiveness,\nand efficiency for transferring learned knowledge across tasks. In real\nindustrial applications such as web content classification, multiple\nclassification tasks are predicted from the same input text such as a web\narticle. However, at the serving time, the existing multitask transformer\nmodels such as prompt or adaptor based approaches need to conduct N forward\npasses for N tasks with O(N) computation cost. To tackle this problem, we\npropose a scalable method that can achieve stronger performance with close to\nO(1) computation cost via only one forward pass. To illustrate real application\nusage, we release a multitask dataset on news topic and style classification.\nOur experiments show that our proposed method outperforms strong baselines on\nboth the GLUE benchmark and our news dataset. Our code and dataset are publicly\navailable at https://bit.ly/mtop-code.", "published": "2022-05-22 05:16:03", "link": "http://arxiv.org/abs/2205.10744v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How sensitive are translation systems to extra contexts? Mitigating\n  gender bias in Neural Machine Translation models through relevant contexts", "abstract": "Neural Machine Translation systems built on top of Transformer-based\narchitectures are routinely improving the state-of-the-art in translation\nquality according to word-overlap metrics. However, a growing number of studies\nalso highlight the inherent gender bias that these models incorporate during\ntraining, which reflects poorly in their translations. In this work, we\ninvestigate whether these models can be instructed to fix their bias during\ninference using targeted, guided instructions as contexts. By translating\nrelevant contextual sentences during inference along with the input, we observe\nlarge improvements in reducing the gender bias in translations, across three\npopular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric\nto assess several large pre-trained models (OPUS-MT, M2M-100) on their\nsensitivity towards using contexts during translation to correct their biases.\nOur approach requires no fine-tuning and thus can be used easily in production\nsystems to de-bias translations from stereotypical gender-occupation bias 1. We\nhope our method, along with our metric, can be used to build better, bias-free\ntranslation systems.", "published": "2022-05-22 06:31:54", "link": "http://arxiv.org/abs/2205.10762v2", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Domain-adaptive Pre-training Approach for Language Bias Detection in\n  News", "abstract": "Media bias is a multi-faceted construct influencing individual behavior and\ncollective decision-making. Slanted news reporting is the result of one-sided\nand polarized writing which can occur in various forms. In this work, we focus\non an important form of media bias, i.e. bias by word choice. Detecting biased\nword choices is a challenging task due to its linguistic complexity and the\nlack of representative gold-standard corpora. We present DA-RoBERTa, a new\nstate-of-the-art transformer-based model adapted to the media bias domain which\nidentifies sentence-level bias with an F1 score of 0.814. In addition, we also\ntrain, DA-BERT and DA-BART, two more transformer models adapted to the bias\ndomain. Our proposed domain-adapted models outperform prior bias detection\napproaches on the same data.", "published": "2022-05-22 08:18:19", "link": "http://arxiv.org/abs/2205.10773v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Graph Enhanced BERT Model for Event Prediction", "abstract": "Predicting the subsequent event for an existing event context is an important\nbut challenging task, as it requires understanding the underlying relationship\nbetween events. Previous methods propose to retrieve relational features from\nevent graph to enhance the modeling of event correlation. However, the sparsity\nof event graph may restrict the acquisition of relevant graph information, and\nhence influence the model performance. To address this issue, we consider\nautomatically building of event graph using a BERT model. To this end, we\nincorporate an additional structured variable into BERT to learn to predict the\nevent connections in the training process. Hence, in the test process, the\nconnection relationship for unseen events can be predicted by the structured\nvariable. Results on two event prediction tasks: script event prediction and\nstory ending prediction, show that our approach can outperform state-of-the-art\nbaseline methods.", "published": "2022-05-22 13:37:38", "link": "http://arxiv.org/abs/2205.10822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TWEET-FID: An Annotated Dataset for Multiple Foodborne Illness Detection\n  Tasks", "abstract": "Foodborne illness is a serious but preventable public health problem -- with\ndelays in detecting the associated outbreaks resulting in productivity loss,\nexpensive recalls, public safety hazards, and even loss of life. While social\nmedia is a promising source for identifying unreported foodborne illnesses,\nthere is a dearth of labeled datasets for developing effective outbreak\ndetection models. To accelerate the development of machine learning-based\nmodels for foodborne outbreak detection, we thus present TWEET-FID\n(TWEET-Foodborne Illness Detection), the first publicly available annotated\ndataset for multiple foodborne illness incident detection tasks. TWEET-FID\ncollected from Twitter is annotated with three facets: tweet class, entity\ntype, and slot type, with labels produced by experts as well as by crowdsource\nworkers. We introduce several domain tasks leveraging these three facets: text\nrelevance classification (TRC), entity mention detection (EMD), and slot\nfilling (SF). We describe the end-to-end methodology for dataset design,\ncreation, and labeling for supporting model development for these tasks. A\ncomprehensive set of results for these tasks leveraging state-of-the-art\nsingle- and multi-task deep learning methods on the TWEET-FID dataset are\nprovided. This dataset opens opportunities for future research in foodborne\noutbreak detection.", "published": "2022-05-22 03:47:18", "link": "http://arxiv.org/abs/2205.10726v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evidence for Hypodescent in Visual Semantic AI", "abstract": "We examine the state-of-the-art multimodal \"visual semantic\" model CLIP\n(\"Contrastive Language Image Pretraining\") for the rule of hypodescent, or\none-drop rule, whereby multiracial people are more likely to be assigned a\nracial or ethnic label corresponding to a minority or disadvantaged racial or\nethnic group than to the equivalent majority or advantaged group. A face\nmorphing experiment grounded in psychological research demonstrating\nhypodescent indicates that, at the midway point of 1,000 series of morphed\nimages, CLIP associates 69.7% of Black-White female images with a Black text\nlabel over a White text label, and similarly prefers Latina (75.8%) and Asian\n(89.1%) text labels at the midway point for Latina-White female and Asian-White\nfemale morphs, reflecting hypodescent. Additionally, assessment of the\nunderlying cosine similarities in the model reveals that association with White\nis correlated with association with \"person,\" with Pearson's rho as high as\n0.82 over a 21,000-image morph series, indicating that a White person\ncorresponds to the default representation of a person in CLIP. Finally, we show\nthat the stereotype-congruent pleasantness association of an image correlates\nwith association with the Black text label in CLIP, with Pearson's rho = 0.48\nfor 21,000 Black-White multiracial male images, and rho = 0.41 for Black-White\nmultiracial female images. CLIP is trained on English-language text gathered\nusing data collected from an American website (Wikipedia), and our findings\ndemonstrate that CLIP embeds the values of American racial hierarchy,\nreflecting the implicit and explicit beliefs that are present in human minds.\nWe contextualize these findings within the history and psychology of\nhypodescent. Overall, the data suggests that AI supervised using natural\nlanguage will, unless checked, learn biases that reflect racial hierarchies.", "published": "2022-05-22 06:46:39", "link": "http://arxiv.org/abs/2205.10764v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CV"}
{"title": "What Do Compressed Multilingual Machine Translation Models Forget?", "abstract": "Recently, very large pre-trained models achieve state-of-the-art results in\nvarious natural language processing (NLP) tasks, but their size makes it more\nchallenging to apply them in resource-constrained environments. Compression\ntechniques allow to drastically reduce the size of the models and therefore\ntheir inference time with negligible impact on top-tier metrics. However, the\ngeneral performance averaged across multiple tasks and/or languages may hide a\ndrastic performance drop on under-represented features, which could result in\nthe amplification of biases encoded by the models. In this work, we assess the\nimpact of compression methods on Multilingual Neural Machine Translation models\n(MNMT) for various language groups, gender, and semantic biases by extensive\nanalysis of compressed models on different machine translation benchmarks, i.e.\nFLORES-101, MT-Gender, and DiBiMT. We show that the performance of\nunder-represented languages drops significantly, while the average BLEU metric\nonly slightly decreases. Interestingly, the removal of noisy memorization with\ncompression leads to a significant improvement for some medium-resource\nlanguages. Finally, we demonstrate that compression amplifies intrinsic gender\nand semantic biases, even in high-resource languages. Code:\nhttps://github.com/alirezamshi/bias-compressedMT", "published": "2022-05-22 13:54:44", "link": "http://arxiv.org/abs/2205.10828v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Commonsense Knowledge Salience Evaluation with a Benchmark Dataset in\n  E-commerce", "abstract": "In e-commerce, the salience of commonsense knowledge (CSK) is beneficial for\nwidespread applications such as product search and recommendation. For example,\nwhen users search for ``running'' in e-commerce, they would like to find\nproducts highly related to running, such as ``running shoes'' rather than\n``shoes''. Nevertheless, many existing CSK collections rank statements solely\nby confidence scores, and there is no information about which ones are salient\nfrom a human perspective. In this work, we define the task of supervised\nsalience evaluation, where given a CSK triple, the model is required to learn\nwhether the triple is salient or not. In addition to formulating the new task,\nwe also release a new Benchmark dataset of Salience Evaluation in E-commerce\n(BSEE) and hope to promote related research on commonsense knowledge salience\nevaluation. We conduct experiments in the dataset with several representative\nbaseline models. The experimental results show that salience evaluation is a\nchallenging task where models perform poorly on our evaluation set. We further\npropose a simple but effective approach, PMI-tuning, which shows promise for\nsolving this novel problem. Code is available in\n\\url{https://github.com/OpenBGBenchmark/OpenBG-CSK.", "published": "2022-05-22 15:01:23", "link": "http://arxiv.org/abs/2205.10843v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations", "abstract": "Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.", "published": "2022-05-22 15:30:18", "link": "http://arxiv.org/abs/2205.10852v6", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RVAE-LAMOL: Residual Variational Autoencoder to Enhance Lifelong\n  Language Learning", "abstract": "Lifelong Language Learning (LLL) aims to train a neural network to learn a\nstream of NLP tasks while retaining knowledge from previous tasks. However,\nprevious works which followed data-free constraint still suffer from\ncatastrophic forgetting issue, where the model forgets what it just learned\nfrom previous tasks. In order to alleviate catastrophic forgetting, we propose\nthe residual variational autoencoder (RVAE) to enhance LAMOL, a recent LLL\nmodel, by mapping different tasks into a limited unified semantic space. In\nthis space, previous tasks are easy to be correct to their own distribution by\npseudo samples. Furthermore, we propose an identity task to make the model is\ndiscriminative to recognize the sample belonging to which task. For training\nRVAE-LAMOL better, we propose a novel training scheme Alternate Lag Training.\nIn the experiments, we test RVAE-LAMOL on permutations of three datasets from\nDecaNLP. The experimental results demonstrate that RVAE-LAMOL outperforms\nna\\\"ive LAMOL on all permutations and generates more meaningful pseudo-samples.", "published": "2022-05-22 15:52:35", "link": "http://arxiv.org/abs/2205.10857v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Argumentative Explanations for Pattern-Based Text Classifiers", "abstract": "Recent works in Explainable AI mostly address the transparency issue of\nblack-box models or create explanations for any kind of models (i.e., they are\nmodel-agnostic), while leaving explanations of interpretable models largely\nunderexplored. In this paper, we fill this gap by focusing on explanations for\na specific interpretable model, namely pattern-based logistic regression (PLR)\nfor binary text classification. We do so because, albeit interpretable, PLR is\nchallenging when it comes to explanations. In particular, we found that a\nstandard way to extract explanations from this model does not consider\nrelations among the features, making the explanations hardly plausible to\nhumans. Hence, we propose AXPLR, a novel explanation method using (forms of)\ncomputational argumentation to generate explanations (for outputs computed by\nPLR) which unearth model agreements and disagreements among the features.\nSpecifically, we use computational argumentation as follows: we see features\n(patterns) in PLR as arguments in a form of quantified bipolar argumentation\nframeworks (QBAFs) and extract attacks and supports between arguments based on\nspecificity of the arguments; we understand logistic regression as a gradual\nsemantics for these QBAFs, used to determine the arguments' dialectic strength;\nand we study standard properties of gradual semantics for QBAFs in the context\nof our argumentative re-interpretation of PLR, sanctioning its suitability for\nexplanatory purposes. We then show how to extract intuitive explanations (for\noutputs computed by PLR) from the constructed QBAFs. Finally, we conduct an\nempirical evaluation and two experiments in the context of human-AI\ncollaboration to demonstrate the advantages of our resulting AXPLR method.", "published": "2022-05-22 21:16:49", "link": "http://arxiv.org/abs/2205.10932v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
