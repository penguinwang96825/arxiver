{"title": "Character-based Surprisal as a Model of Reading Difficulty in the\n  Presence of Error", "abstract": "Intuitively, human readers cope easily with errors in text; typos,\nmisspelling, word substitutions, etc. do not unduly disrupt natural reading.\nPrevious work indicates that letter transpositions result in increased reading\ntimes, but it is unclear if this effect generalizes to more natural errors. In\nthis paper, we report an eye-tracking study that compares two error types\n(letter transpositions and naturally occurring misspelling) and two error rates\n(10% or 50% of all words contain errors). We find that human readers show\nunimpaired comprehension in spite of these errors, but error words cause more\nreading difficulty than correct words. Also, transpositions are more difficult\nthan misspellings, and a high error rate increases difficulty for all words,\nincluding correct ones. We then present a computational model that uses\ncharacter-based (rather than traditional word-based) surprisal to account for\nthese results. The model explains that transpositions are harder than\nmisspellings because they contain unexpected letter combinations. It also\nexplains the error rate effect: upcoming words are more difficultto predict\nwhen the context is degraded, leading to increased surprisal.", "published": "2019-02-02 00:32:11", "link": "http://arxiv.org/abs/1902.00595v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing, Sentiment Analysis and Clinical Analytics", "abstract": "Recent advances in Big Data has prompted health care practitioners to utilize\nthe data available on social media to discern sentiment and emotions\nexpression. Health Informatics and Clinical Analytics depend heavily on\ninformation gathered from diverse sources. Traditionally, a healthcare\npractitioner will ask a patient to fill out a questionnaire that will form the\nbasis of diagnosing the medical condition. However, medical practitioners have\naccess to many sources of data including the patients writings on various\nmedia. Natural Language Processing (NLP) allows researchers to gather such data\nand analyze it to glean the underlying meaning of such writings. The field of\nsentiment analysis (applied to many other domains) depend heavily on techniques\nutilized by NLP. This work will look into various prevalent theories underlying\nthe NLP field and how they can be leveraged to gather users sentiments on\nsocial media. Such sentiments can be culled over a period of time thus\nminimizing the errors introduced by data input and other stressors.\nFurthermore, we look at some applications of sentiment analysis and application\nof NLP to mental health. The reader will also learn about the NLTK toolkit that\nimplements various NLP theories and how they can make the data scavenging\nprocess a lot easier.", "published": "2019-02-02 09:30:26", "link": "http://arxiv.org/abs/1902.00679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making a Case for Social Media Corpus for Detecting Depression", "abstract": "The social media platform provides an opportunity to gain valuable insights\ninto user behaviour. Users mimic their internal feelings and emotions in a\ndisinhibited fashion using natural language. Techniques in Natural Language\nProcessing have helped researchers decipher standard documents and cull\ntogether inferences from massive amount of data. A representative corpus is a\nprerequisite for NLP and one of the challenges we face today is the\nnon-standard and noisy language that exists on the internet. Our work focuses\non building a corpus from social media that is focused on detecting mental\nillness. We use depression as a case study and demonstrate the effectiveness of\nusing such a corpus for helping practitioners detect such cases. Our results\nshow a high correlation between our Social Media Corpus and the standard corpus\nfor depression.", "published": "2019-02-02 11:59:28", "link": "http://arxiv.org/abs/1902.00702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph Neural Networks with Generated Parameters for Relation Extraction", "abstract": "Recently, progress has been made towards improving relational reasoning in\nmachine learning field. Among existing models, graph neural networks (GNNs) is\none of the most effective approaches for multi-hop relational reasoning. In\nfact, multi-hop relational reasoning is indispensable in many natural language\nprocessing tasks such as relation extraction. In this paper, we propose to\ngenerate the parameters of graph neural networks (GP-GNNs) according to natural\nlanguage sentences, which enables GNNs to process relational reasoning on\nunstructured text inputs. We verify GP-GNNs in relation extraction from text.\nExperimental results on a human-annotated dataset and two distantly supervised\ndatasets show that our model achieves significant improvements compared to\nbaselines. We also perform a qualitative analysis to demonstrate that our model\ncould discover more accurate relations by multi-hop relational reasoning.", "published": "2019-02-02 17:34:19", "link": "http://arxiv.org/abs/1902.00756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Resolution Word Embedding for Document Retrieval from Large\n  Unstructured Knowledge Bases", "abstract": "Deep language models learning a hierarchical representation proved to be a\npowerful tool for natural language processing, text mining and information\nretrieval. However, representations that perform well for retrieval must\ncapture semantic meaning at different levels of abstraction or context-scopes.\nIn this paper, we propose a new method to generate multi-resolution word\nembeddings that represent documents at multiple resolutions in terms of\ncontext-scopes. In order to investigate its performance,we use the Stanford\nQuestion Answering Dataset (SQuAD) and the Question Answering by Search And\nReading (QUASAR) in an open-domain question-answering setting, where the first\ntask is to find documents useful for answering a given question. To this end,\nwe first compare the quality of various text-embedding methods for retrieval\nperformance and give an extensive empirical comparison with the performance of\nvarious non-augmented base embeddings with and without multi-resolution\nrepresentation. We argue that multi-resolution word embeddings are consistently\nsuperior to the original counterparts and deep residual neural models\nspecifically trained for retrieval purposes can yield further significant gains\nwhen they are used for augmenting those embeddings.", "published": "2019-02-02 07:44:41", "link": "http://arxiv.org/abs/1902.00663v7", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Query-oriented text summarization based on hypergraph transversals", "abstract": "Existing graph- and hypergraph-based algorithms for document summarization\nrepresent the sentences of a corpus as the nodes of a graph or a hypergraph in\nwhich the edges represent relationships of lexical similarities between\nsentences. Each sentence of the corpus is then scored individually, using\npopular node ranking algorithms, and a summary is produced by extracting highly\nscored sentences. This approach fails to select a subset of jointly relevant\nsentences and it may produce redundant summaries that are missing important\ntopics of the corpus. To alleviate this issue, a new hypergraph-based\nsummarizer is proposed in this paper, in which each node is a sentence and each\nhyperedge is a theme, namely a group of sentences sharing a topic. Themes are\nweighted in terms of their prominence in the corpus and their relevance to a\nuser-defined query. It is further shown that the problem of identifying a\nsubset of sentences covering the relevant themes of the corpus is equivalent to\nthat of finding a hypergraph transversal in our theme-based hypergraph. Two\nextensions of the notion of hypergraph transversal are proposed for the purpose\nof summarization, and polynomial time algorithms building on the theory of\nsubmodular functions are proposed for solving the associated discrete\noptimization problems. The worst-case time complexity of the proposed\nalgorithms is squared in the number of terms, which makes it cheaper than the\nexisting hypergraph-based methods. A thorough comparative analysis with related\nmodels on DUC benchmark datasets demonstrates the effectiveness of our\napproach, which outperforms existing graph- or hypergraph-based methods by at\nleast 6% of ROUGE-SU4 score.", "published": "2019-02-02 08:52:44", "link": "http://arxiv.org/abs/1902.00672v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How to Write High-quality News on Social Network? Predicting News\n  Quality by Mining Writing Style", "abstract": "Rapid development of Internet technologies promotes traditional newspapers to\nreport news on social networks. However, people on social networks may have\ndifferent needs which naturally arises the question: whether can we analyze the\ninfluence of writing style on news quality automatically and assist writers in\nimproving news quality? It's challenging due to writing style and 'quality' are\nhard to measure. First, we use 'popularity' as the measure of 'quality'. It is\nnatural on social networks but brings new problems: popularity are also\ninfluenced by event and publisher. So we design two methods to alleviate their\ninfluence. Then, we proposed eight types of linguistic features (53 features in\nall) according eight writing guidelines and analyze their relationship with\nnews quality. The experimental results show these linguistic features influence\ngreatly on news quality. Based on it, we design a news quality assessment model\non social network (SNQAM). SNQAM performs excellently on predicting quality,\npresenting interpretable quality score and giving accessible suggestions on how\nto improve it according to writing guidelines we referred to.", "published": "2019-02-02 16:29:12", "link": "http://arxiv.org/abs/1902.00750v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Word Embeddings for Sentiment Analysis: A Comprehensive Empirical Survey", "abstract": "This work investigates the role of factors like training method, training\ncorpus size and thematic relevance of texts in the performance of word\nembedding features on sentiment analysis of tweets, song lyrics, movie reviews\nand item reviews. We also explore specific training or post-processing methods\nthat can be used to enhance the performance of word embeddings in certain tasks\nor domains. Our empirical observations indicate that models trained with\nmultithematic texts that are large and rich in vocabulary are the best in\nanswering syntactic and semantic word analogy questions. We further observe\nthat influence of thematic relevance is stronger on movie and phone reviews,\nbut weaker on tweets and lyrics. These two later domains are more sensitive to\ncorpus size and training method, with Glove outperforming Word2vec. \"Injecting\"\nextra intelligence from lexicons or generating sentiment specific word\nembeddings are two prominent alternatives for increasing performance of word\nembedding features.", "published": "2019-02-02 17:04:14", "link": "http://arxiv.org/abs/1902.00753v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Non-Suicidal Self-Injury Online Posts: Implications for Mental Health\n  Professionals", "abstract": "While non-suicidal self-injury (NSSI) is not a new phenomenon, there is still\na limited yet little is still known about understanding of the behavior, the\nintent behind the behavior and what the individuals themselves say about their\nbehavior. This study collected pro-NSSI public blog posts from Reddit on\npro-NSSI and analyzed the content linguistically using LIWC software, in order\nto examine the use of NSSI specific words, linguistic properties and the\npsychological linguistic properties. were examined. The results inform current\ncounseling practices by dispelling myths and providing insight into the inner\nworld of people who engage in use NSSII to cope. The most frequently appearing\ncategory of For NSSI specific words categories, in the Reddit blogs was the\nreasons in which one engagesfor engaging in NSSI was the most frequently used\nin the Reddit blogs. The linguistic properties found in the analysis reflected\nthe predicted results; authors of pro-NSSI posts used demonstrated expected\nresults of first-person singular pronouns extensively, which indicatesing high\nlevels of mental health distress and isolation. The psychological linguistic\nproperties that could be observed of in these public Reddit posts were\ndominantly in a negative emotional tone which demonstrates youth and\nimpulsivity. The linguistic properties found when these posts were analyzed\nsupports the work of earlier studies that dispelled common myths about NSSI\nthat were circulating in the mental health community. These findings suggest\nthat the language of people who engage in NSSI supports research findings in\ndispelling common myths about NSSI.", "published": "2019-02-02 23:42:42", "link": "http://arxiv.org/abs/1902.06689v2", "categories": ["cs.CY", "cs.CL", "62G10", "J.4"], "primary_category": "cs.CY"}
{"title": "Understanding Composition of Word Embeddings via Tensor Decomposition", "abstract": "Word embedding is a powerful tool in natural language processing. In this\npaper we consider the problem of word embedding composition \\--- given vector\nrepresentations of two words, compute a vector for the entire phrase. We give a\ngenerative model that can capture specific syntactic relations between words.\nUnder our model, we prove that the correlations between three words (measured\nby their PMI) form a tensor that has an approximate low rank Tucker\ndecomposition. The result of the Tucker decomposition gives the word embeddings\nas well as a core tensor, which can be used to produce better compositions of\nthe word embeddings. We also complement our theoretical results with\nexperiments that verify our assumptions, and demonstrate the effectiveness of\nthe new composition method.", "published": "2019-02-02 01:34:56", "link": "http://arxiv.org/abs/1902.00613v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Parameter-Efficient Transfer Learning for NLP", "abstract": "Fine-tuning large pre-trained models is an effective transfer mechanism in\nNLP. However, in the presence of many downstream tasks, fine-tuning is\nparameter inefficient: an entire new model is required for every task. As an\nalternative, we propose transfer with adapter modules. Adapter modules yield a\ncompact and extensible model; they add only a few trainable parameters per\ntask, and new tasks can be added without revisiting previous ones. The\nparameters of the original network remain fixed, yielding a high degree of\nparameter sharing. To demonstrate adapter's effectiveness, we transfer the\nrecently proposed BERT Transformer model to 26 diverse text classification\ntasks, including the GLUE benchmark. Adapters attain near state-of-the-art\nperformance, whilst adding only a few parameters per task. On GLUE, we attain\nwithin 0.4% of the performance of full fine-tuning, adding only 3.6% parameters\nper task. By contrast, fine-tuning trains 100% of the parameters per task.", "published": "2019-02-02 16:29:47", "link": "http://arxiv.org/abs/1902.00751v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Using multi-task learning to improve the performance of acoustic-to-word\n  and conventional hybrid models", "abstract": "Acoustic-to-word (A2W) models that allow direct mapping from acoustic signals\nto word sequences are an appealing approach to end-to-end automatic speech\nrecognition due to their simplicity. However, prior works have shown that\nmodelling A2W typically encounters issues of data sparsity that prevent\ntraining such a model directly. So far, pre-training initialization is the only\napproach proposed to deal with this issue. In this work, we propose to build a\nshared neural network and optimize A2W and conventional hybrid models in a\nmulti-task manner. Our results show that training an A2W model is much more\nstable with our multi-task model without pre-training initialization, and\nresults in a significant improvement compared to a baseline model. Experiments\nalso reveal that the performance of a hybrid acoustic model can be further\nimproved when jointly training with a sequence-level optimization criterion\nsuch as acoustic-to-word.", "published": "2019-02-02 07:33:48", "link": "http://arxiv.org/abs/1902.01951v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Is CQT more suitable for monaural speech separation than STFT? an\n  empirical study", "abstract": "Short-time Fourier transform (STFT) is used as the front end of many popular\nsuccessful monaural speech separation methods, such as deep clustering (DPCL),\npermutation invariant training (PIT) and their various variants. Since the\nfrequency component of STFT is linear, while the frequency distribution of\nhuman auditory system is nonlinear. In this work we propose and give an\nempirical study to use an alternative front end called constant Q transform\n(CQT) instead of STFT to achieve a better simulation of the frequency resolving\npower of the human auditory system. The upper bound in signal-to-distortion\n(SDR) of ideal speech separation based on CQT's ideal ration mask (IRM) is\nhigher than that based on STFT. In the same experimental setting on WSJ0-2mix\ncorpus, we examined the performance of CQT under different backends, including\nthe original DPCL, utterance level PIT, and some of their variants. It is found\nthat all CQT-based methods are better than STFT-based methods, and achieved on\naverage 0.4dB better performance than STFT based method in SDR improvements.", "published": "2019-02-02 03:01:13", "link": "http://arxiv.org/abs/1902.00631v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FurcaNet: An end-to-end deep gated convolutional, long short-term\n  memory, deep neural networks for single channel speech separation", "abstract": "Deep gated convolutional networks have been proved to be very effective in\nsingle channel speech separation. However current state-of-the-art framework\noften considers training the gated convolutional networks in time-frequency\n(TF) domain. Such an approach will result in limited perceptual score, such as\nsignal-to-distortion ratio (SDR) upper bound of separated utterances and also\nfail to exploit an end-to-end framework. In this paper we present an integrated\nsimple and effective end-to-end approach to monaural speech separation, which\nconsists of deep gated convolutional neural networks (GCNN) that takes the\nmixed utterance of two speakers and maps it to two separated utterances, where\neach utterance contains only one speaker's voice. In addition long short-term\nmemory (LSTM) is employed for long term temporal modeling. For the objective,\nwe propose to train the network by directly optimizing utterance level SDR in a\npermutation invariant training (PIT) style. Our experiments on the public\nWSJ0-2mix data corpus demonstrate that this new scheme can produce more\ndiscriminative separated utterances and leading to performance improvement on\nthe speaker separation task.", "published": "2019-02-02 06:36:20", "link": "http://arxiv.org/abs/1902.00651v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Event Detection Using Graph Laplacian Regularization Based on\n  Event Co-occurrence", "abstract": "The types of sound events that occur in a situation are limited, and some\nsound events are likely to co-occur; for instance, ``dishes'' and ``glass\njingling.'' In this paper, we propose a technique of sound event detection\nutilizing graph Laplacian regularization taking the sound event co-occurrence\ninto account. In the proposed method, sound event occurrences are represented\nas a graph whose nodes indicate the frequency of event occurrence and whose\nedges indicate the co-occurrence of sound events. This graph representation is\nthen utilized for sound event modeling, which is optimized under an objective\nfunction with a regularization term considering the graph structure.\nExperimental results obtained using TUT Sound Events 2016 development, 2017\ndevelopment, and TUT Acoustic Scenes 2016 development indicate that the\nproposed method improves the detection performance of sound events by 7.9\npercentage points compared to that of the conventional CNN-BiGRU-based method\nin terms of the segment-based F1-score. Moreover, the results show that the\nproposed method can detect co-occurring sound events more accurately than the\nconventional method.", "published": "2019-02-02 23:50:52", "link": "http://arxiv.org/abs/1902.00816v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
