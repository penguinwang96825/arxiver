{"title": "The word entropy of natural languages", "abstract": "The average uncertainty associated with words is an information-theoretic\nconcept at the heart of quantitative and computational linguistics. The entropy\nhas been established as a measure of this average uncertainty - also called\naverage information content. We here use parallel texts of 21 languages to\nestablish the number of tokens at which word entropies converge to stable\nvalues. These convergence points are then used to select texts from a massively\nparallel corpus, and to estimate word entropies across more than 1000\nlanguages. Our results help to establish quantitative language comparisons, to\nunderstand the performance of multilingual translation systems, and to\nnormalize semantic similarity measures.", "published": "2016-06-22 16:00:52", "link": "http://arxiv.org/abs/1606.06996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing to Probabilistic Programs for Situated Question\n  Answering", "abstract": "Situated question answering is the problem of answering questions about an\nenvironment such as an image or diagram. This problem requires jointly\ninterpreting a question and an environment using background knowledge to select\nthe correct answer. We present Parsing to Probabilistic Programs (P3), a novel\nsituated question answering model that can use background knowledge and global\nfeatures of the question/environment interpretation while retaining efficient\napproximate inference. Our key insight is to treat semantic parses as\nprobabilistic programs that execute nondeterministically and whose possible\nexecutions represent environmental uncertainty. We evaluate our approach on a\nnew, publicly-released data set of 5000 science diagram questions,\noutperforming several competitive classical and neural baselines.", "published": "2016-06-22 19:19:29", "link": "http://arxiv.org/abs/1606.07046v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inferring Logical Forms From Denotations", "abstract": "A core problem in learning semantic parsers from denotations is picking out\nconsistent logical forms--those that yield the correct denotation--from a\ncombinatorially large space. To control the search space, previous work relied\non restricted set of rules, which limits expressivity. In this paper, we\nconsider a much more expressive class of logical forms, and show how to use\ndynamic programming to efficiently represent the complete set of consistent\nlogical forms. Expressivity also introduces many more spurious logical forms\nwhich are consistent with the correct denotation but do not represent the\nmeaning of the utterance. To address this, we generate fictitious worlds and\nuse crowdsourced denotations on these worlds to filter out spurious logical\nforms. On the WikiTableQuestions dataset, we increase the coverage of\nanswerable questions from 53.5% to 76%, and the additional crowdsourced\nsupervision lets us rule out 92.1% of spurious logical forms.", "published": "2016-06-22 11:07:43", "link": "http://arxiv.org/abs/1606.06900v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning text representation using recurrent convolutional neural\n  network with highway layers", "abstract": "Recently, the rapid development of word embedding and neural networks has\nbrought new inspiration to various NLP and IR tasks. In this paper, we describe\na staged hybrid model combining Recurrent Convolutional Neural Networks (RCNN)\nwith highway layers. The highway network module is incorporated in the middle\ntakes the output of the bi-directional Recurrent Neural Network (Bi-RNN) module\nin the first stage and provides the Convolutional Neural Network (CNN) module\nin the last stage with the input. The experiment shows that our model\noutperforms common neural network models (CNN, RNN, Bi-RNN) on a sentiment\nanalysis task. Besides, the analysis of how sequence length influences the RCNN\nwith highway layers shows that our model could learn good representation for\nthe long text.", "published": "2016-06-22 11:30:47", "link": "http://arxiv.org/abs/1606.06905v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A segmental framework for fully-unsupervised large-vocabulary speech\n  recognition", "abstract": "Zero-resource speech technology is a growing research area that aims to\ndevelop methods for speech processing in the absence of transcriptions,\nlexicons, or language modelling text. Early term discovery systems focused on\nidentifying isolated recurring patterns in a corpus, while more recent\nfull-coverage systems attempt to completely segment and cluster the audio into\nword-like units---effectively performing unsupervised speech recognition. This\narticle presents the first attempt we are aware of to apply such a system to\nlarge-vocabulary multi-speaker data. Our system uses a Bayesian modelling\nframework with segmental word representations: each word segment is represented\nas a fixed-dimensional acoustic embedding obtained by mapping the sequence of\nfeature frames to a single embedding vector. We compare our system on English\nand Xitsonga datasets to state-of-the-art baselines, using a variety of\nmeasures including word error rate (obtained by mapping the unsupervised output\nto ground truth transcriptions). Very high word error rates are reported---in\nthe order of 70--80% for speaker-dependent and 80--95% for speaker-independent\nsystems---highlighting the difficulty of this task. Nevertheless, in terms of\ncluster quality and word segmentation metrics, we show that by imposing a\nconsistent top-down segmentation while also using bottom-up knowledge from\ndetected syllable boundaries, both single-speaker and multi-speaker versions of\nour system outperform a purely bottom-up single-speaker syllable-based\napproach. We also show that the discovered clusters can be made less speaker-\nand gender-specific by using an unsupervised autoencoder-like feature extractor\nto learn better frame-level features (prior to embedding). Our system's\ndiscovered clusters are still less pure than those of unsupervised term\ndiscovery systems, but provide far greater coverage.", "published": "2016-06-22 13:51:57", "link": "http://arxiv.org/abs/1606.06950v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward Word Embedding for Personalized Information Retrieval", "abstract": "This paper presents preliminary works on using Word Embedding (word2vec) for\nquery expansion in the context of Personalized Information Retrieval.\nTraditionally, word embeddings are learned on a general corpus, like Wikipedia.\nIn this work we try to personalize the word embeddings learning, by achieving\nthe learning on the user's profile. The word embeddings are then in the same\ncontext than the user interests. Our proposal is evaluated on the CLEF Social\nBook Search 2016 collection. The results obtained show that some efforts should\nbe made in the way to apply Word Embedding in the context of Personalized\nInformation Retrieval.", "published": "2016-06-22 15:53:29", "link": "http://arxiv.org/abs/1606.06991v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Using Word Embeddings in Twitter Election Classification", "abstract": "Word embeddings and convolutional neural networks (CNN) have attracted\nextensive attention in various classification tasks for Twitter, e.g. sentiment\nclassification. However, the effect of the configuration used to train and\ngenerate the word embeddings on the classification performance has not been\nstudied in the existing literature. In this paper, using a Twitter election\nclassification task that aims to detect election-related tweets, we investigate\nthe impact of the background dataset used to train the embedding models, the\ncontext window size and the dimensionality of word embeddings on the\nclassification performance. By comparing the classification results of two word\nembedding models, which are trained using different background corpora (e.g.\nWikipedia articles and Twitter microposts), we show that the background data\ntype should align with the Twitter classification dataset to achieve a better\nperformance. Moreover, by evaluating the results of word embeddings models\ntrained using various context window sizes and dimensionalities, we found that\nlarge context window and dimension sizes are preferable to improve the\nperformance. Our experimental results also show that using word embeddings and\nCNN leads to statistically significant improvements over various baselines such\nas random, SVM with TF-IDF and SVM with word embeddings.", "published": "2016-06-22 16:37:55", "link": "http://arxiv.org/abs/1606.07006v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Deep Feature Fusion Network for Answer Quality Prediction in Community\n  Question Answering", "abstract": "Community Question Answering (cQA) forums have become a popular medium for\nsoliciting direct answers to specific questions of users from experts or other\nexperienced users on a given topic. However, for a given question, users\nsometimes have to sift through a large number of low-quality or irrelevant\nanswers to find out the answer which satisfies their information need. To\nalleviate this, the problem of Answer Quality Prediction (AQP) aims to predict\nthe quality of an answer posted in response to a forum question. Current AQP\nsystems either learn models using - a) various hand-crafted features (HCF) or\nb) use deep learning (DL) techniques which automatically learn the required\nfeature representations.\n  In this paper, we propose a novel approach for AQP known as - \"Deep Feature\nFusion Network (DFFN)\" which leverages the advantages of both hand-crafted\nfeatures and deep learning based systems. Given a question-answer pair along\nwith its metadata, DFFN independently - a) learns deep features using a\nConvolutional Neural Network (CNN) and b) computes hand-crafted features using\nvarious external resources and then combines them using a deep neural network\ntrained to predict the final answer quality. DFFN achieves state-of-the-art\nperformance on the standard SemEval-2015 and SemEval-2016 benchmark datasets\nand outperforms baseline approaches which individually employ either HCF or DL\nbased techniques alone.", "published": "2016-06-22 20:58:08", "link": "http://arxiv.org/abs/1606.07103v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Divergent discourse between protests and counter-protests:\n  #BlackLivesMatter and #AllLivesMatter", "abstract": "Since the shooting of Black teenager Michael Brown by White police officer\nDarren Wilson in Ferguson, Missouri, the protest hashtag #BlackLivesMatter has\namplified critiques of extrajudicial killings of Black Americans. In response\nto #BlackLivesMatter, other Twitter users have adopted #AllLivesMatter, a\ncounter-protest hashtag whose content argues that equal attention should be\ngiven to all lives regardless of race. Through a multi-level analysis of over\n860,000 tweets, we study how these protests and counter-protests diverge by\nquantifying aspects of their discourse. We find that #AllLivesMatter\nfacilitates opposition between #BlackLivesMatter and hashtags such as\n#PoliceLivesMatter and #BlueLivesMatter in such a way that historically echoes\nthe tension between Black protesters and law enforcement. In addition, we show\nthat a significant portion of #AllLivesMatter use stems from hijacking by\n#BlackLivesMatter advocates. Beyond simply injecting #AllLivesMatter with\n#BlackLivesMatter content, these hijackers use the hashtag to directly confront\nthe counter-protest notion of \"All lives matter.\" Our findings suggest that\nBlack Lives Matter movement was able to grow, exhibit diverse conversations,\nand avoid derailment on social media by making discussion of counter-protest\nopinions a central topic of #AllLivesMatter, rather than the movement itself.", "published": "2016-06-22 05:23:01", "link": "http://arxiv.org/abs/1606.06820v5", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Curriculum Learning Method for Improved Noise Robustness in Automatic\n  Speech Recognition", "abstract": "The performance of automatic speech recognition systems under noisy\nenvironments still leaves room for improvement. Speech enhancement or feature\nenhancement techniques for increasing noise robustness of these systems usually\nadd components to the recognition system that need careful optimization. In\nthis work, we propose the use of a relatively simple curriculum training\nstrategy called accordion annealing (ACCAN). It uses a multi-stage training\nschedule where samples at signal-to-noise ratio (SNR) values as low as 0dB are\nfirst added and samples at increasing higher SNR values are gradually added up\nto an SNR value of 50dB. We also use a method called per-epoch noise mixing\n(PEM) that generates noisy training samples online during training and thus\nenables dynamically changing the SNR of our training data. Both the ACCAN and\nthe PEM methods are evaluated on a end-to-end speech recognition pipeline on\nthe Wall Street Journal corpus. ACCAN decreases the average word error rate\n(WER) on the 20dB to -10dB SNR range by up to 31.4% when compared to a\nconventional multi-condition training method.", "published": "2016-06-22 09:29:40", "link": "http://arxiv.org/abs/1606.06864v2", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Study of Deep Bidirectional LSTM RNNs for Acoustic\n  Modeling in Speech Recognition", "abstract": "We present a comprehensive study of deep bidirectional long short-term memory\n(LSTM) recurrent neural network (RNN) based acoustic models for automatic\nspeech recognition (ASR). We study the effect of size and depth and train\nmodels of up to 8 layers. We investigate the training aspect and study\ndifferent variants of optimization methods, batching, truncated\nbackpropagation, different regularization techniques such as dropout and $L_2$\nregularization, and different gradient clipping variants.\n  The major part of the experimental analysis was performed on the Quaero\ncorpus. Additional experiments also were performed on the Switchboard corpus.\nOur best LSTM model has a relative improvement in word error rate of over 14\\%\ncompared to our best feed-forward neural network (FFNN) baseline on the Quaero\ntask. On this task, we get our best result with an 8 layer bidirectional LSTM\nand we show that a pretraining scheme with layer-wise construction helps for\ndeep LSTMs.\n  Finally we compare the training calculation time of many of the presented\nexperiments in relation with recognition performance.\n  All the experiments were done with RETURNN, the RWTH extensible training\nframework for universal recurrent neural networks in combination with RASR, the\nRWTH ASR toolkit.", "published": "2016-06-22 10:00:14", "link": "http://arxiv.org/abs/1606.06871v2", "categories": ["cs.NE", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.NE"}
{"title": "Toward Interpretable Topic Discovery via Anchored Correlation\n  Explanation", "abstract": "Many predictive tasks, such as diagnosing a patient based on their medical\nchart, are ultimately defined by the decisions of human experts. Unfortunately,\nencoding experts' knowledge is often time consuming and expensive. We propose a\nsimple way to use fuzzy and informal knowledge from experts to guide discovery\nof interpretable latent topics in text. The underlying intuition of our\napproach is that latent factors should be informative about both correlations\nin the data and a set of relevance variables specified by an expert.\nMathematically, this approach is a combination of the information bottleneck\nand Total Correlation Explanation (CorEx). We give a preliminary evaluation of\nAnchored CorEx, showing that it produces more coherent and interpretable topics\non two distinct corpora.", "published": "2016-06-22 19:00:38", "link": "http://arxiv.org/abs/1606.07043v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Emulating Human Conversations using Convolutional Neural Network-based\n  IR", "abstract": "Conversational agents (\"bots\") are beginning to be widely used in\nconversational interfaces. To design a system that is capable of emulating\nhuman-like interactions, a conversational layer that can serve as a fabric for\nchat-like interaction with the agent is needed. In this paper, we introduce a\nmodel that employs Information Retrieval by utilizing convolutional deep\nstructured semantic neural network-based features in the ranker to present\nhuman-like responses in ongoing conversation with a user. In conversations,\naccounting for context is critical to the retrieval model; we show that our\ncontext-sensitive approach using a Convolutional Deep Structured Semantic Model\n(cDSSM) with character trigrams significantly outperforms several conventional\nbaselines in terms of the relevance of responses retrieved.", "published": "2016-06-22 19:55:24", "link": "http://arxiv.org/abs/1606.07056v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "H.3.3; I.2.7"], "primary_category": "cs.AI"}
{"title": "Automated Extraction of Number of Subjects in Randomised Controlled\n  Trials", "abstract": "We present a simple approach for automatically extracting the number of\nsubjects involved in randomised controlled trials (RCT). Our approach first\napplies a set of rule-based techniques to extract candidate study sizes from\nthe abstracts of the articles. Supervised classification is then performed over\nthe candidates with support vector machines, using a small set of lexical,\nstructural, and contextual features. With only a small annotated training set\nof 201 RCTs, we obtained an accuracy of 88\\%. We believe that this system will\naid complex medical text processing tasks such as summarisation and question\nanswering.", "published": "2016-06-22 23:35:59", "link": "http://arxiv.org/abs/1606.07137v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
