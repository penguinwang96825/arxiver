{"title": "Impact of Corpora Quality on Neural Machine Translation", "abstract": "Large parallel corpora that are automatically obtained from the web,\ndocuments or elsewhere often exhibit many corrupted parts that are bound to\nnegatively affect the quality of the systems and models that learn from these\ncorpora. This paper describes frequent problems found in data and such data\naffects neural machine translation systems, as well as how to identify and deal\nwith them. The solutions are summarised in a set of scripts that remove\nproblematic sentences from input corpora.", "published": "2018-10-19 08:28:07", "link": "http://arxiv.org/abs/1810.08392v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STACL: Simultaneous Translation with Implicit Anticipation and\n  Controllable Latency using Prefix-to-Prefix Framework", "abstract": "Simultaneous translation, which translates sentences before they are\nfinished, is useful in many scenarios but is notoriously difficult due to\nword-order differences. While the conventional seq-to-seq framework is only\nsuitable for full-sentence translation, we propose a novel prefix-to-prefix\nframework for simultaneous translation that implicitly learns to anticipate in\na single translation model. Within this framework, we present a very simple yet\nsurprisingly effective wait-k policy trained to generate the target sentence\nconcurrently with the source sentence, but always k words behind. Experiments\nshow our strategy achieves low latency and reasonable quality (compared to\nfull-sentence translation) on 4 directions: zh<->en and de<->en.", "published": "2018-10-19 08:37:40", "link": "http://arxiv.org/abs/1810.08398v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Dependency-Guided Named Entity Recognition", "abstract": "Named entity recognition (NER), which focuses on the extraction of\nsemantically meaningful named entities and their semantic classes from text,\nserves as an indispensable component for several down-stream natural language\nprocessing (NLP) tasks such as relation extraction and event extraction.\nDependency trees, on the other hand, also convey crucial semantic-level\ninformation. It has been shown previously that such information can be used to\nimprove the performance of NER (Sasano and Kurohashi 2008, Ling and Weld 2012).\nIn this work, we investigate on how to better utilize the structured\ninformation conveyed by dependency trees to improve the performance of NER.\nSpecifically, unlike existing approaches which only exploit dependency\ninformation for designing local features, we show that certain global\nstructured information of the dependency trees can be exploited when building\nNER models where such information can provide guided learning and inference.\nThrough extensive experiments, we show that our proposed novel\ndependency-guided NER model performs competitively with models based on\nconventional semi-Markov conditional random fields, while requiring\nsignificantly less running time.", "published": "2018-10-19 10:47:12", "link": "http://arxiv.org/abs/1810.08436v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weak Semi-Markov CRFs for NP Chunking in Informal Text", "abstract": "This paper introduces a new annotated corpus based on an existing informal\ntext corpus: the NUS SMS Corpus (Chen and Kan, 2013). The new corpus includes\n76,490 noun phrases from 26,500 SMS messages, annotated by university students.\nWe then explored several graphical models, including a novel variant of the\nsemi-Markov conditional random fields (semi-CRF) for the task of noun phrase\nchunking. We demonstrated through empirical evaluations on the new dataset that\nthe new variant yielded similar accuracy but ran in significantly lower running\ntime compared to the conventional semi-CRF.", "published": "2018-10-19 16:09:35", "link": "http://arxiv.org/abs/1810.08567v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Recognize Discontiguous Entities", "abstract": "This paper focuses on the study of recognizing discontiguous entities.\nMotivated by a previous work, we propose to use a novel hypergraph\nrepresentation to jointly encode discontiguous entities of unbounded length,\nwhich can overlap with one another. To compare with existing approaches, we\nfirst formally introduce the notion of model ambiguity, which defines the\ndifficulty level of interpreting the outputs of a model, and then formally\nanalyze the theoretical advantages of our model over previous existing\napproaches based on linear-chain CRFs. Our empirical results also show that our\nmodel is able to achieve significantly better results when evaluated on\nstandard data with many discontiguous entities.", "published": "2018-10-19 16:48:25", "link": "http://arxiv.org/abs/1810.08579v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mainumby: un Ayudante para la Traducci\u00f3n Castellano-Guaran\u00ed", "abstract": "A wide range of applications play an important role in the daily work of the\nmodern human translator. However, the computational tools designed to aid in\nthe process of translation only benefit translation from or to a small minority\nof the 7,000 languages of the world, those that we may call \"privileged\nlanguages\". As for those translators who work with the remaining languages, the\nmarginalized languages in the digital world, they cannot benefit from the tools\nthat are speeding up the production of translation in the privileged languages.\nWe may ask whether it is possible to bridge the gap between what is available\nfor these languages and for the marginalized ones. This paper proposes a\nframework for computer-assisted translation into marginalized languages and its\nimplementation in a web application for Spanish-Guarani translation. The\nproposed system is based on a new theory for phrase-level translation in\ncontexts where adequate bilingual corpora are not available: Translation by\nGeneralized Segments (referred to as Minimal Dependency Translation in previous\nwork).", "published": "2018-10-19 17:55:46", "link": "http://arxiv.org/abs/1810.08603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Segmentation Granularity for Neural Machine Translation", "abstract": "In neural machine translation (NMT), it is has become standard to translate\nusing subword units to allow for an open vocabulary and improve accuracy on\ninfrequent words. Byte-pair encoding (BPE) and its variants are the predominant\napproach to generating these subwords, as they are unsupervised, resource-free,\nand empirically effective. However, the granularity of these subword units is a\nhyperparameter to be tuned for each language and task, using methods such as\ngrid search. Tuning may be done inexhaustively or skipped entirely due to\nresource constraints, leading to sub-optimal performance. In this paper, we\npropose a method to automatically tune this parameter using only one training\npass. We incrementally introduce new vocabulary online based on the held-out\nvalidation loss, beginning with smaller, general subwords and adding larger,\nmore specific units over the course of training. Our method matches the results\nfound with grid search, optimizing segmentation granularity without any\nadditional training time. We also show benefits in training efficiency and\nperformance improvements for rare words due to the way embeddings for larger\nunits are incrementally constructed by combining those from smaller units.", "published": "2018-10-19 18:47:02", "link": "http://arxiv.org/abs/1810.08641v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "pioNER: Datasets and Baselines for Armenian Named Entity Recognition", "abstract": "In this work, we tackle the problem of Armenian named entity recognition,\nproviding silver- and gold-standard datasets as well as establishing baseline\nresults on popular models. We present a 163000-token named entity corpus\nautomatically generated and annotated from Wikipedia, and another 53400-token\ncorpus of news sentences with manual annotation of people, organization and\nlocation named entities. The corpora were used to train and evaluate several\npopular named entity recognition models. Alongside the datasets, we release\n50-, 100-, 200-, 300-dimensional GloVe word embeddings trained on a collection\nof Armenian texts from Wikipedia, news, blogs, and encyclopedia.", "published": "2018-10-19 22:01:48", "link": "http://arxiv.org/abs/1810.08699v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Personas from Dialogue with Attentive Memory Networks", "abstract": "The ability to infer persona from dialogue can have applications in areas\nranging from computational narrative analysis to personalized dialogue\ngeneration. We introduce neural models to learn persona embeddings in a\nsupervised character trope classification task. The models encode dialogue\nsnippets from IMDB into representations that can capture the various categories\nof film characters. The best-performing models use a multi-level attention\nmechanism over a set of utterances. We also utilize prior knowledge in the form\nof textual descriptions of the different tropes. We apply the learned\nembeddings to find similar characters across different movies, and cluster\nmovies according to the distribution of the embeddings. The use of short\nconversational text as input, and the ability to learn from prior knowledge\nusing memory, suggests these methods could be applied to other domains.", "published": "2018-10-19 23:53:25", "link": "http://arxiv.org/abs/1810.08717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conceptual Organization is Revealed by Consumer Activity Patterns", "abstract": "Meaning may arise from an element's role or interactions within a larger\nsystem. For example, hitting nails is more central to people's concept of a\nhammer than its particular material composition or other intrinsic features.\nLikewise, the importance of a web page may result from its links with other\npages rather than solely from its content. One example of meaning arising from\nextrinsic relationships are approaches that extract the meaning of word\nconcepts from co-occurrence patterns in large, text corpora. The success of\nthese methods suggest that human activity patterns may reveal conceptual\norganization. However, texts do not directly reflect human activity, but\ninstead serve a communicative function and are usually highly curated or edited\nto suit an audience. Here, we apply methods devised for text to a data source\nthat directly reflects thousands of individuals' activity patterns, namely\nsupermarket purchases. Using product co-occurrence data from nearly 1.3m\nshopping baskets, we trained a topic model to learn 25 high-level concepts (or\n\"topics\"). These topics were found to be comprehensible and coherent by both\nretail experts and consumers. Topics ranged from specific (e.g., ingredients\nfor a stir-fry) to general (e.g., cooking from scratch). Topics tended to be\ngoal-directed and situational, consistent with the notion that human conceptual\nknowledge is tailored to support action. Individual differences in the topics\nsampled predicted basic demographic characteristics. These results suggest that\nhuman activity patterns reveal conceptual organization and may give rise to it.", "published": "2018-10-19 16:41:27", "link": "http://arxiv.org/abs/1810.08577v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A neural network to classify metaphorical violence on cable news", "abstract": "I present here an experimental system for identifying and annotating metaphor\nin corpora. It is designed to plug in to Metacorps, an experimental web app for\nannotating metaphor. As Metacorps users annotate metaphors, the system will use\nuser annotations as training data. When the system is confident, it will\nsuggest an identification and an annotation. Once approved by the user, this\nbecomes more training data. This naturally allows for transfer learning, where\nthe system can, with some known degree of reliability, classify one class of\nmetaphor after only being trained on another class of metaphor. For example, in\nour metaphorical violence project, metaphors may be classified by the network\nthey were observed on, the grammatical subject or object of the violence\nmetaphor, or the violent word used (hit, attack, beat, etc.).", "published": "2018-10-19 20:22:53", "link": "http://arxiv.org/abs/1810.08677v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Lightweight Convolutional Approaches to Reading Comprehension on SQuAD", "abstract": "Current state-of-the-art reading comprehension models rely heavily on\nrecurrent neural networks. We explored an entirely different approach to\nquestion answering: a convolutional model. By their nature, these convolutional\nmodels are fast to train and capture local dependencies well, though they can\nstruggle with longer-range dependencies and thus require augmentation to\nachieve comparable performance to RNN-based models. We conducted over two dozen\ncontrolled experiments with convolutional models and various\nkernel/attention/regularization schemes to determine the precise performance\ngains of each strategy, while maintaining a focus on speed. We ultimately\nensembled three models: crossconv (0.5398 dev F1), attnconv (0.5665), and\nmaybeconv (0.5285). The ensembled model was able to achieve a 0.6238 F1 score\nusing the official SQuAD evaluation script. Our individual convolutional model\ncrossconv was able to exceed the performance of the RNN-plus-attention baseline\nby 25% while training 6 times faster.", "published": "2018-10-19 20:32:36", "link": "http://arxiv.org/abs/1810.08680v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices\nthat provides text suggestions. It converts sequential keyboard inputs to the\ncharacters in its target language, which is indispensable for Japanese and\nChinese users. Due to critical resource constraints and limited network\nbandwidth of the target devices, applying neural models to input method is not\nwell explored. In this work, we apply a LSTM-based language model to input\nmethod and evaluate its performance for both prediction and conversion tasks\nwith Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax\ncomputation during conversion. To solve the issue, we propose incremental\nsoftmax approximation approach, which computes softmax with a selected subset\nvocabulary and fix the stale probabilities when the vocabulary is updated in\nfuture steps. We refer to this method as incremental selective softmax. The\nresults show a two order speedup for the softmax computation when converting\nJapanese input sequences with a large vocabulary, reaching real-time speed on\ncommodity CPU. We also exploit the model compressing potential to achieve a 92%\nmodel size reduction without losing accuracy.", "published": "2018-10-19 12:57:37", "link": "http://arxiv.org/abs/1810.09309v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting Distributional Correspondence Indexing: A Python\n  Reimplementation and New Experiments", "abstract": "This paper introduces PyDCI, a new implementation of Distributional\nCorrespondence Indexing (DCI) written in Python. DCI is a transfer learning\nmethod for cross-domain and cross-lingual text classification for which we had\nprovided an implementation (here called JaDCI) built on top of JaTeCS, a Java\nframework for text classification. PyDCI is a stand-alone version of DCI that\nexploits scikit-learn and the SciPy stack. We here report on new experiments\nthat we have carried out in order to test PyDCI, and in which we use as\nbaselines new high-performing methods that have appeared after DCI was\noriginally proposed. These experiments show that, thanks to a few subtle ways\nin which we have improved DCI, PyDCI outperforms both JaDCI and the\nabove-mentioned high-performing methods, and delivers the best known results on\nthe two popular benchmarks on which we had tested DCI, i.e.,\nMultiDomainSentiment (a.k.a. MDS -- for cross-domain adaptation) and\nWebis-CLS-10 (for cross-lingual adaptation). PyDCI, together with the code\nallowing to replicate our experiments, is available at\nhttps://github.com/AlexMoreo/pydci .", "published": "2018-10-19 07:27:24", "link": "http://arxiv.org/abs/1810.09311v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A database linking piano and orchestral MIDI scores with application to\n  automatic projective orchestration", "abstract": "This article introduces the Projective Orchestral Database (POD), a\ncollection of MIDI scores composed of pairs linking piano scores to their\ncorresponding orchestrations. To the best of our knowledge, this is the first\ndatabase of its kind, which performs piano or orchestral prediction, but more\nimportantly which tries to learn the correlations between piano and orchestral\nscores. Hence, we also introduce the projective orchestration task, which\nconsists in learning how to perform the automatic orchestration of a piano\nscore. We show how this task can be addressed using learning methods and also\nprovide methodological guidelines in order to properly use this database.", "published": "2018-10-19 12:50:20", "link": "http://arxiv.org/abs/1810.08611v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-Based Activities of Daily Living (ADL) Recognition with\n  Large-Scale Acoustic Embeddings from Online Videos", "abstract": "Over the years, activity sensing and recognition has been shown to play a key\nenabling role in a wide range of applications, from sustainability and\nhuman-computer interaction to health care. While many recognition tasks have\ntraditionally employed inertial sensors, acoustic-based methods offer the\nbenefit of capturing rich contextual information, which can be useful when\ndiscriminating complex activities. Given the emergence of deep learning\ntechniques and leveraging new, large-scaled multi-media datasets, this paper\nrevisits the opportunity of training audio-based classifiers without the\nonerous and time-consuming task of annotating audio data. We propose a\nframework for audio-based activity recognition that makes use of millions of\nembedding features from public online video sound clips. Based on the\ncombination of oversampling and deep learning approaches, our framework does\nnot require further feature processing or outliers filtering as in prior work.\nWe evaluated our approach in the context of Activities of Daily Living (ADL) by\nrecognizing 15 everyday activities with 14 participants in their own homes,\nachieving 64.2% and 83.6% averaged within-subject accuracy in terms of top-1\nand top-3 classification respectively. Individual class performance was also\nexamined in the paper to further study the co-occurrence characteristics of the\nactivities and the robustness of the framework.", "published": "2018-10-19 21:19:16", "link": "http://arxiv.org/abs/1810.08691v2", "categories": ["cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Mobile Sound Recognition for the Deaf and Hard of Hearing", "abstract": "Human perception of surrounding events is strongly dependent on audio cues.\nThus, acoustic insulation can seriously impact situational awareness. We\npresent an exploratory study in the domain of assistive computing, eliciting\nrequirements and presenting solutions to problems found in the development of\nan environmental sound recognition system, which aims to assist deaf and hard\nof hearing people in the perception of sounds. To take advantage of smartphones\ncomputational ubiquity, we propose a system that executes all processing on the\ndevice itself, from audio features extraction to recognition and visual\npresentation of results. Our application also presents the confidence level of\nthe classification to the user. A test of the system conducted with deaf users\nprovided important and inspiring feedback from participants.", "published": "2018-10-19 22:47:52", "link": "http://arxiv.org/abs/1810.08707v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS", "68U35, 68T37, 68T10", "H.1.2; H.5.2; H.5.5"], "primary_category": "cs.HC"}
