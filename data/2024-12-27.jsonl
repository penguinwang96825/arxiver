{"title": "Hidformer: Transformer-Style Neural Network in Stock Price Forecasting", "abstract": "This paper investigates the application of Transformer-based neural networks\nto stock price forecasting, with a special focus on the intersection of machine\nlearning techniques and financial market analysis. The evolution of Transformer\nmodels, from their inception to their adaptation for time series analysis in\nfinancial contexts, is reviewed and discussed. Central to our study is the\nexploration of the Hidformer model, which is currently recognized for its\npromising performance in time series prediction. The primary aim of this paper\nis to determine whether Hidformer will also prove itself in the task of stock\nprice prediction. This slightly modified model serves as the framework for our\nexperiments, integrating the principles of technical analysis with advanced\nmachine learning concepts to enhance stock price prediction accuracy. We\nconduct an evaluation of the Hidformer model's performance, using a set of\ncriteria to determine its efficacy. Our findings offer additional insights into\nthe practical application of Transformer architectures in financial time series\nforecasting, highlighting their potential to improve algorithmic trading\nstrategies, including human decision making.", "published": "2024-12-27 21:34:44", "link": "http://arxiv.org/abs/2412.19932v1", "categories": ["cs.CE", "cs.AI", "cs.LG", "q-fin.CP"], "primary_category": "cs.CE"}
{"title": "Assets Forecasting with Feature Engineering and Transformation Methods for LightGBM", "abstract": "Fluctuations in the stock market rapidly shape the economic world and\nconsumer markets, impacting millions of individuals. Hence, accurately\nforecasting it is essential for mitigating risks, including those associated\nwith inactivity. Although research shows that hybrid models of Deep Learning\n(DL) and Machine Learning (ML) yield promising results, their computational\nrequirements often exceed the capabilities of average personal computers,\nrendering them inaccessible to many. In order to address this challenge in this\npaper we optimize LightGBM (an efficient implementation of gradient-boosted\ndecision trees (GBDT)) for maximum performance, while maintaining low\ncomputational requirements. We introduce novel feature engineering techniques\nincluding indicator-price slope ratios and differences of close and open prices\ndivided by the corresponding 14-period Exponential Moving Average (EMA),\ndesigned to capture market dynamics and enhance predictive accuracy.\nAdditionally, we test seven different feature and target variable\ntransformation methods, including returns, logarithmic returns, EMA ratios and\ntheir standardized counterparts as well as EMA difference ratios, so as to\nidentify the most effective ones weighing in both efficiency and accuracy. The\nresults demonstrate Log Returns, Returns and EMA Difference Ratio constitute\nthe best target variable transformation methods, with EMA ratios having a lower\npercentage of correct directional forecasts, and standardized versions of\ntarget variable transformations requiring significantly more training time.\nMoreover, the introduced features demonstrate high feature importance in\npredictive performance across all target variable transformation methods. This\nstudy highlights an accessible, computationally efficient approach to stock\nmarket forecasting using LightGBM, making advanced forecasting techniques more\nwidely attainable.", "published": "2024-12-27 18:37:08", "link": "http://arxiv.org/abs/2501.07580v1", "categories": ["q-fin.ST", "econ.EM"], "primary_category": "q-fin.ST"}
{"title": "Feature Alignment-Based Knowledge Distillation for Efficient Compression\n  of Large Language Models", "abstract": "This study proposes a knowledge distillation algorithm based on large\nlanguage models and feature alignment, aiming to effectively transfer the\nknowledge of large pre-trained models into lightweight student models, thereby\nreducing computational costs while maintaining high model performance.\nDifferent from the traditional soft label distillation method, this method\nintroduces a multi-layer feature alignment strategy to deeply align the\nintermediate features and attention mechanisms of the teacher model and the\nstudent model, maximally retaining the semantic expression ability and context\nmodeling ability of the teacher model. In terms of method design, a multi-task\nloss function is constructed, including feature matching loss, attention\nalignment loss, and output distribution matching loss, to ensure multi-level\ninformation transfer through joint optimization. The experiments were\ncomprehensively evaluated on the GLUE data set and various natural language\nprocessing tasks. The results show that the proposed model performs very close\nto the state-of-the-art GPT-4 model in terms of evaluation indicators such as\nperplexity, BLEU, ROUGE, and CER. At the same time, it far exceeds baseline\nmodels such as DeBERTa, XLNet, and GPT-3, showing significant performance\nimprovements and computing efficiency advantages. Research results show that\nthe feature alignment distillation strategy is an effective model compression\nmethod that can significantly reduce computational overhead and storage\nrequirements while maintaining model capabilities. Future research can be\nfurther expanded in the directions of self-supervised learning, cross-modal\nfeature alignment, and multi-task transfer learning to provide more flexible\nand efficient solutions for the deployment and optimization of deep learning\nmodels.", "published": "2024-12-27 04:37:06", "link": "http://arxiv.org/abs/2412.19449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training, Fine-tuning and Re-ranking: A Three-Stage Framework for\n  Legal Question Answering", "abstract": "Legal question answering (QA) has attracted increasing attention from people\nseeking legal advice, which aims to retrieve the most applicable answers from a\nlarge-scale database of question-answer pairs. Previous methods mainly use a\ndual-encoder architecture to learn dense representations of both questions and\nanswers. However, these methods could suffer from lacking domain knowledge and\nsufficient labeled training data. In this paper, we propose a three-stage\n(\\underline{p}re-training, \\underline{f}ine-tuning and \\underline{r}e-ranking)\nframework for \\underline{l}egal \\underline{QA} (called PFR-LQA), which promotes\nthe fine-grained text representation learning and boosts the performance of\ndense retrieval with the dual-encoder architecture. Concretely, we first\nconduct domain-specific pre-training on legal questions and answers through a\nself-supervised training objective, allowing the pre-trained model to be\nadapted to the legal domain. Then, we perform task-specific fine-tuning of the\ndual-encoder on legal question-answer pairs by using the supervised learning\nobjective, leading to a high-quality dual-encoder for the specific downstream\nQA task. Finally, we employ a contextual re-ranking objective to further refine\nthe output representations of questions produced by the document encoder, which\nuses contextual similarity to increase the discrepancy between the anchor and\nhard negative samples for better question re-ranking. We conduct extensive\nexperiments on a manually annotated legal QA dataset. Experimental results show\nthat our PFR-LQA method achieves better performance than the strong competitors\nfor legal question answering.", "published": "2024-12-27 06:33:42", "link": "http://arxiv.org/abs/2412.19482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging", "abstract": "Fine-tuning large language models (LLMs) for downstream tasks is a widely\nadopted approach, but it often leads to safety degradation in safety-aligned\nLLMs. Currently, many solutions address this issue by incorporating additional\nsafety data, which can be impractical in many cases. In this paper, we address\nthe question: How can we improve downstream task performance while preserving\nsafety in LLMs without relying on additional safety data? We propose a simple\nand effective method that maintains the inherent safety of LLMs while enhancing\ntheir downstream task performance: merging the weights of pre- and\npost-fine-tuned safety-aligned models. Experimental results across various\ndownstream tasks, models, and merging methods demonstrate that this approach\neffectively mitigates safety degradation while improving downstream task\nperformance, offering a practical solution for adapting safety-aligned LLMs.", "published": "2024-12-27 08:03:22", "link": "http://arxiv.org/abs/2412.19512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confidence v.s. Critique: A Decomposition of Self-Correction Capability\n  for LLMs", "abstract": "Large Language Models (LLMs) can correct their self-generated responses, but\na decline in accuracy after self-correction is also witnessed. To have a deeper\nunderstanding of self-correction, we endeavor to decompose, evaluate, and\nanalyze the self-correction behaviors of LLMs. By enumerating and analyzing\nanswer correctness before and after self-correction, we decompose the\nself-correction capability into confidence (being confident to correct answers)\nand critique (turning wrong answers to correct) capabilities, and propose two\nmetrics from a probabilistic perspective to measure these 2 capabilities, along\nwith another metric for overall self-correction capability evaluation. Based on\nour decomposition and evaluation metrics, we conduct extensive experiments and\ndraw some empirical conclusions. For example, we find different models can\nexhibit distinct behaviors: some models are confident while others are more\ncritical. We also find the trade-off between the two capabilities (i.e.\nimproving one can lead to a decline in the other) when manipulating model\nself-correction behavior by prompts or in-context learning. Further, we find a\nsimple yet efficient strategy to improve self-correction capability by\ntransforming Supervision Fine-Tuning (SFT) data format, and our strategy\noutperforms vanilla SFT in both capabilities and achieves much higher accuracy\nafter self-correction. Our code will be publicly available on GitHub.", "published": "2024-12-27 08:09:11", "link": "http://arxiv.org/abs/2412.19513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Domain-Specific Parallel Data on Multilingual Language Models\n  for Low-resource Language Translation", "abstract": "Neural Machine Translation (NMT) systems built on multilingual\nsequence-to-sequence Language Models (msLMs) fail to deliver expected results\nwhen the amount of parallel data for a language, as well as the language's\nrepresentation in the model are limited. This restricts the capabilities of\ndomain-specific NMT systems for low-resource languages (LRLs). As a solution,\nparallel data from auxiliary domains can be used either to fine-tune or to\nfurther pre-train the msLM. We present an evaluation of the effectiveness of\nthese two techniques in the context of domain-specific LRL-NMT. We also explore\nthe impact of domain divergence on NMT model performance. We recommend several\nstrategies for utilizing auxiliary parallel data in building domain-specific\nNMT models for LRLs.", "published": "2024-12-27 08:25:52", "link": "http://arxiv.org/abs/2412.19522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Generated Product Advertisements: Benchmarking LLMs Against\n  Human Performance", "abstract": "This study compares the performance of AI-generated and human-written product\ndescriptions using a multifaceted evaluation model. We analyze descriptions for\n100 products generated by four AI models (Gemma 2B, LLAMA, GPT2, and ChatGPT 4)\nwith and without sample descriptions, against human-written descriptions. Our\nevaluation metrics include sentiment, readability, persuasiveness, Search\nEngine Optimization(SEO), clarity, emotional appeal, and call-to-action\neffectiveness. The results indicate that ChatGPT 4 performs the best. In\ncontrast, other models demonstrate significant shortcomings, producing\nincoherent and illogical output that lacks logical structure and contextual\nrelevance. These models struggle to maintain focus on the product being\ndescribed, resulting in disjointed sentences that do not convey meaningful\ninformation. This research provides insights into the current capabilities and\nlimitations of AI in the creation of content for e-Commerce.", "published": "2024-12-27 12:11:50", "link": "http://arxiv.org/abs/2412.19610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Right vs. Right: Can LLMs Make Tough Choices?", "abstract": "An ethical dilemma describes a choice between two \"right\" options involving\nconflicting moral values. We present a comprehensive evaluation of how LLMs\nnavigate ethical dilemmas. Specifically, we investigate LLMs on their (1)\nsensitivity in comprehending ethical dilemmas, (2) consistency in moral value\nchoice, (3) consideration of consequences, and (4) ability to align their\nresponses to a moral value preference explicitly or implicitly specified in a\nprompt. Drawing inspiration from a leading ethical framework, we construct a\ndataset comprising 1,730 ethical dilemmas involving four pairs of conflicting\nvalues. We evaluate 20 well-known LLMs from six families. Our experiments\nreveal that: (1) LLMs exhibit pronounced preferences between major value pairs,\nand prioritize truth over loyalty, community over individual, and long-term\nover short-term considerations. (2) The larger LLMs tend to support a\ndeontological perspective, maintaining their choices of actions even when\nnegative consequences are specified. (3) Explicit guidelines are more effective\nin guiding LLMs' moral choice than in-context examples. Lastly, our experiments\nhighlight the limitation of LLMs in comprehending different formulations of\nethical dilemmas.", "published": "2024-12-27 21:20:45", "link": "http://arxiv.org/abs/2412.19926v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long Context vs. RAG for LLMs: An Evaluation and Revisits", "abstract": "Extending context windows (i.e., Long Context, LC) and using retrievers to\nselectively access relevant information (i.e., Retrieval-Augmented Generation,\nRAG) are the two main strategies to enable LLMs to incorporate extremely long\nexternal contexts. This paper revisits recent studies on this topic,\nhighlighting their key insights and discrepancies. We then provide a more\ncomprehensive evaluation by filtering out questions answerable without external\ncontext, identifying the most effective retrieval methods, and expanding the\ndatasets. We show that LC generally outperforms RAG in question-answering\nbenchmarks, especially for Wikipedia-based questions. Summarization-based\nretrieval performs comparably to LC, while chunk-based retrieval lags behind.\nHowever, RAG has advantages in dialogue-based and general question queries.\nThese insights underscore the trade-offs between RAG and LC strategies,\noffering guidance for future optimization of LLMs with external knowledge\nsources. We also provide an in-depth discussion on this topic, highlighting the\noverlooked importance of context relevance in existing studies.", "published": "2024-12-27 14:34:37", "link": "http://arxiv.org/abs/2501.01880v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepSeek-V3 Technical Report", "abstract": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with\n671B total parameters with 37B activated for each token. To achieve efficient\ninference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent\nAttention (MLA) and DeepSeekMoE architectures, which were thoroughly validated\nin DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free\nstrategy for load balancing and sets a multi-token prediction training\nobjective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion\ndiverse and high-quality tokens, followed by Supervised Fine-Tuning and\nReinforcement Learning stages to fully harness its capabilities. Comprehensive\nevaluations reveal that DeepSeek-V3 outperforms other open-source models and\nachieves performance comparable to leading closed-source models. Despite its\nexcellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its\nfull training. In addition, its training process is remarkably stable.\nThroughout the entire training process, we did not experience any irrecoverable\nloss spikes or perform any rollbacks. The model checkpoints are available at\nhttps://github.com/deepseek-ai/DeepSeek-V3.", "published": "2024-12-27 04:03:16", "link": "http://arxiv.org/abs/2412.19437v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "User Willingness-aware Sales Talk Dataset", "abstract": "User willingness is a crucial element in the sales talk process that affects\nthe achievement of the salesperson's or sales system's objectives. Despite the\nimportance of user willingness, to the best of our knowledge, no previous study\nhas addressed the development of automated sales talk dialogue systems that\nexplicitly consider user willingness. A major barrier is the lack of sales talk\ndatasets with reliable user willingness data. Thus, in this study, we developed\na user willingness-aware sales talk collection by leveraging the ecological\nvalidity concept, which is discussed in the field of human-computer\ninteraction. Our approach focused on three types of user willingness essential\nin real sales interactions. We created a dialogue environment that closely\nresembles real-world scenarios to elicit natural user willingness, with\nparticipants evaluating their willingness at the utterance level from multiple\nperspectives. We analyzed the collected data to gain insights into practical\nuser willingness-aware sales talk strategies. In addition, as a practical\napplication of the constructed dataset, we developed and evaluated a sales\ndialogue system aimed at enhancing the user's intent to purchase.", "published": "2024-12-27 07:16:10", "link": "http://arxiv.org/abs/2412.19490v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "TARGA: Targeted Synthetic Data Generation for Practical Reasoning over\n  Structured Data", "abstract": "Semantic parsing, which converts natural language questions into logic forms,\nplays a crucial role in reasoning within structured environments. However,\nexisting methods encounter two significant challenges: reliance on extensive\nmanually annotated datasets and limited generalization capability to unseen\nexamples. To tackle these issues, we propose Targeted Synthetic Data Generation\n(TARGA), a practical framework that dynamically generates high-relevance\nsynthetic data without manual annotation. Starting from the pertinent entities\nand relations of a given question, we probe for the potential relevant queries\nthrough layer-wise expansion and cross-layer combination. Then we generate\ncorresponding natural language questions for these constructed queries to\njointly serve as the synthetic demonstrations for in-context learning.\nExperiments on multiple knowledge base question answering (KBQA) datasets\ndemonstrate that TARGA, using only a 7B-parameter model, substantially\noutperforms existing non-fine-tuned methods that utilize close-sourced model,\nachieving notable improvements in F1 scores on GrailQA(+7.7) and\nKBQA-Agent(+12.2). Furthermore, TARGA also exhibits superior sample efficiency,\nrobustness, and generalization capabilities under non-I.I.D. settings.", "published": "2024-12-27 09:16:39", "link": "http://arxiv.org/abs/2412.19544v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Machine Learning for Sentiment Analysis of Imported Food in Trinidad and\n  Tobago", "abstract": "This research investigates the performance of various machine learning\nalgorithms (CNN, LSTM, VADER, and RoBERTa) for sentiment analysis of Twitter\ndata related to imported food items in Trinidad and Tobago. The study addresses\nthree primary research questions: the comparative accuracy and efficiency of\nthe algorithms, the optimal configurations for each model, and the potential\napplications of the optimized models in a live system for monitoring public\nsentiment and its impact on the import bill. The dataset comprises tweets from\n2018 to 2024, divided into imbalanced, balanced, and temporal subsets to assess\nthe impact of data balancing and the COVID-19 pandemic on sentiment trends. Ten\nexperiments were conducted to evaluate the models under various configurations.\nResults indicated that VADER outperformed the other models in both multi-class\nand binary sentiment classifications. The study highlights significant changes\nin sentiment trends pre- and post-COVID-19, with implications for import\npolicies.", "published": "2024-12-27 18:25:08", "link": "http://arxiv.org/abs/2412.19781v1", "categories": ["cs.CL", "cs.LG", "62M45 (Primary) 68T50, 91C20 (Secondary)", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Enhancing Whisper's Accuracy and Speed for Indian Languages through\n  Prompt-Tuning and Tokenization", "abstract": "Automatic speech recognition has recently seen a significant advancement with\nlarge foundational models such as Whisper. However, these models often struggle\nto perform well in low-resource languages, such as Indian languages. This paper\nexplores two novel approaches to enhance Whisper's multilingual speech\nrecognition performance in Indian languages. First, we propose prompt-tuning\nwith language family information, which enhances Whisper's accuracy in\nlinguistically similar languages. Second, we introduce a novel tokenizer that\nreduces the number of generated tokens, thereby accelerating Whisper's\ninference speed. Our extensive experiments demonstrate that the tokenizer\nsignificantly reduces inference time, while prompt-tuning enhances accuracy\nacross various Whisper model sizes, including Small, Medium, and Large.\nTogether, these techniques achieve a balance between optimal WER and inference\nspeed.", "published": "2024-12-27 18:32:24", "link": "http://arxiv.org/abs/2412.19785v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluate Summarization in Fine-Granularity: Auto Evaluation with LLM", "abstract": "Due to the exponential growth of information and the need for efficient\ninformation consumption the task of summarization has gained paramount\nimportance. Evaluating summarization accurately and objectively presents\nsignificant challenges, particularly when dealing with long and unstructured\ntexts rich in content. Existing methods, such as ROUGE (Lin, 2004) and\nembedding similarities, often yield scores that have low correlation with human\njudgements and are also not intuitively understandable, making it difficult to\ngauge the true quality of the summaries. LLMs can mimic human in giving\nsubjective reviews but subjective scores are hard to interpret and justify.\nThey can be easily manipulated by altering the models and the tones of the\nprompts. In this paper, we introduce a novel evaluation methodology and tooling\ndesigned to address these challenges, providing a more comprehensive, accurate\nand interpretable assessment of summarization outputs. Our method (SumAutoEval)\nproposes and evaluates metrics at varying granularity levels, giving objective\nscores on 4 key dimensions such as completeness, correctness, Alignment and\nreadability. We empirically demonstrate, that SumAutoEval enhances the\nunderstanding of output quality with better human correlation.", "published": "2024-12-27 19:42:25", "link": "http://arxiv.org/abs/2412.19906v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing Text Classification Methods for Cyberbullying Detection on\n  Social Media Platforms", "abstract": "Cyberbullying significantly contributes to mental health issues in\ncommunities by negatively impacting the psychology of victims. It is a\nprevalent problem on social media platforms, necessitating effective, real-time\ndetection and monitoring systems to identify harmful messages. However, current\ncyberbullying detection systems face challenges related to performance, dataset\nquality, time efficiency, and computational costs. This research aims to\nconduct a comparative study by adapting and evaluating existing text\nclassification techniques within the cyberbullying detection domain. The study\nspecifically evaluates the effectiveness and performance of these techniques in\nidentifying cyberbullying instances on social media platforms. It focuses on\nleveraging and assessing large language models, including BERT, RoBERTa, XLNet,\nDistilBERT, and GPT-2.0, for their suitability in this domain. The results show\nthat BERT strikes a balance between performance, time efficiency, and\ncomputational resources: Accuracy of 95%, Precision of 95%, Recall of 95%, F1\nScore of 95%, Error Rate of 5%, Inference Time of 0.053 seconds, RAM Usage of\n35.28 MB, CPU/GPU Usage of 0.4%, and Energy Consumption of 0.000263 kWh. The\nfindings demonstrate that generative AI models, while powerful, do not\nconsistently outperform fine-tuned models on the tested benchmarks. However,\nstate-of-the-art performance can still be achieved through strategic adaptation\nand fine-tuning of existing models for specific datasets and tasks.", "published": "2024-12-27 21:22:28", "link": "http://arxiv.org/abs/2412.19928v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Cross-Linguistic Examination of Machine Translation Transfer Learning", "abstract": "This study investigates the effectiveness of transfer learning in machine\ntranslation across diverse linguistic families by evaluating five distinct\nlanguage pairs. Leveraging pre-trained models on high-resource languages, these\nmodels were fine-tuned on low-resource languages, examining variations in\nhyperparameters such as learning rate, batch size, number of epochs, and weight\ndecay. The research encompasses language pairs from different linguistic\nbackgrounds: Semitic (Modern Standard Arabic - Levantine Arabic), Bantu (Hausa\n- Zulu), Romance (Spanish - Catalan), Slavic (Slovakian - Macedonian), and\nlanguage isolates (Eastern Armenian - Western Armenian). Results demonstrate\nthat transfer learning is effective across different language families,\nalthough the impact of hyperparameters varies. A moderate batch size (e.g., 32)\nis generally more effective, while very high learning rates can disrupt model\ntraining. The study highlights the universality of transfer learning in\nmultilingual contexts and suggests that consistent hyperparameter settings can\nsimplify and enhance the efficiency of multilingual model training.", "published": "2024-12-27 16:34:56", "link": "http://arxiv.org/abs/2501.00045v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Seq2Seq Model-Based Chatbot with LSTM and Attention Mechanism for\n  Enhanced User Interaction", "abstract": "A chatbot is an intelligent software application that automates conversations\nand engages users in natural language through messaging platforms. Leveraging\nartificial intelligence (AI), chatbots serve various functions, including\ncustomer service, information gathering, and casual conversation. Existing\nvirtual assistant chatbots, such as ChatGPT and Gemini, demonstrate the\npotential of AI in Natural Language Processing (NLP). However, many current\nsolutions rely on predefined APIs, which can result in vendor lock-in and high\ncosts. To address these challenges, this work proposes a chatbot developed\nusing a Sequence-to-Sequence (Seq2Seq) model with an encoder-decoder\narchitecture that incorporates attention mechanisms and Long Short-Term Memory\n(LSTM) cells. By avoiding predefined APIs, this approach ensures flexibility\nand cost-effectiveness. The chatbot is trained, validated, and tested on a\ndataset specifically curated for the tourism sector in Draa-Tafilalet, Morocco.\nKey evaluation findings indicate that the proposed Seq2Seq model-based chatbot\nachieved high accuracies: approximately 99.58% in training, 98.03% in\nvalidation, and 94.12% in testing. These results demonstrate the chatbot's\neffectiveness in providing relevant and coherent responses within the tourism\ndomain, highlighting the potential of specialized AI applications to enhance\nuser experience and satisfaction in niche markets.", "published": "2024-12-27 23:50:54", "link": "http://arxiv.org/abs/2501.00049v1", "categories": ["cs.CL", "cs.ET"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Machine Unlearning Techniques for Image and Text\n  Classification Models", "abstract": "Machine Unlearning has emerged as a critical area in artificial intelligence,\naddressing the need to selectively remove learned data from machine learning\nmodels in response to data privacy regulations. This paper provides a\ncomprehensive comparative analysis of six state-of-theart unlearning techniques\napplied to image and text classification tasks. We evaluate their performance,\nefficiency, and compliance with regulatory requirements, highlighting their\nstrengths and limitations in practical scenarios. By systematically analyzing\nthese methods, we aim to provide insights into their applicability,\nchallenges,and tradeoffs, fostering advancements in the field of ethical and\nadaptable machine learning.", "published": "2024-12-27 10:58:55", "link": "http://arxiv.org/abs/2412.19583v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback", "abstract": "Large language models (LLMs) have been routinely used to solve various tasks\nusing step-by-step reasoning. However, the structure of intermediate reasoning\nsteps, or thoughts, is rigid and unidirectional, such as chains, trees, or\nacyclic-directed graphs. Consequently, the resulting inflexible and\nforward-only reasoning may not address challenging tasks and fail when the LLM\nfrequently gives false responses, i.e., ``hallucinations''. This paper proposes\na new reasoning framework, called Thought Rollback (TR), allowing LLMs to\nadaptively build thought structure while maintaining effective reasoning toward\nproblem-solving under ``hallucinations''. The core mechanism of TR is rolling\nback thoughts, which allows LLMs to perform error analysis on thoughts, and\nthus roll back to any previously mistaken thought for revision. Subsequently,\nby including such trial-and-error in the prompt to guide the LLM, each rollback\nleads to one more reliable reasoning path. Therefore, starting with a simple\nprompt without human annotations, LLM with TR adaptively and gradually explores\nthoughts for a correct solution. Comprehensive experiments on mathematical\nproblems and multi-task reasoning demonstrate the state-of-the-art performance\nof TR in terms of problem-solving rate and interaction cost. For instance, the\nsolving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH\ndataset.", "published": "2024-12-27 16:02:34", "link": "http://arxiv.org/abs/2412.19707v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse\n  Task Synthesis", "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models\n(VLMs) have demonstrated human-like computer control capability. Despite their\nutility in advancing digital automation, a critical bottleneck persists:\ncollecting high-quality trajectory data for training. Common practices for\ncollecting such data rely on human supervision or synthetic data generation\nthrough executing pre-defined tasks, which are either resource-intensive or\nunable to guarantee data quality. Moreover, these methods suffer from limited\ndata diversity and significant gaps between synthetic data and real-world\nenvironments. To address these challenges, we propose OS-Genesis, a novel GUI\ndata synthesis pipeline that reverses the conventional trajectory collection\nprocess. Instead of relying on pre-defined tasks, OS-Genesis enables agents\nfirst to perceive environments and perform step-wise interactions, then\nretrospectively derive high-quality tasks to enable trajectory-level\nexploration. A trajectory reward model is then employed to ensure the quality\nof the generated trajectories. We demonstrate that training GUI agents with\nOS-Genesis significantly improves their performance on highly challenging\nonline benchmarks. In-depth analysis further validates OS-Genesis's efficiency\nand its superior data quality and diversity compared to existing synthesis\nmethods. Our codes, data, and checkpoints are available at\n\\href{https://qiushisun.github.io/OS-Genesis-Home/}{OS-Genesis Homepage}.", "published": "2024-12-27 16:21:58", "link": "http://arxiv.org/abs/2412.19723v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "InfAlign: Inference-aware language model alignment", "abstract": "Language model alignment is a critical step in training modern generative\nlanguage models. Alignment targets to improve win rate of a sample from the\naligned model against the base model. Today, we are increasingly using\ninference-time algorithms (e.g., Best-of-N, controlled decoding, tree search)\nto decode from language models rather than standard sampling. We show that this\ntrain/test mismatch makes standard RLHF framework sub-optimal in view of such\ninference-time methods. To this end, we propose a framework for inference-aware\nalignment (InfAlign), which aims to optimize inference-time win rate of the\naligned policy against the base model. We prove that for any inference-time\ndecoding procedure, the optimal aligned policy is the solution to the standard\nRLHF problem with a transformation of the reward. This motivates us to provide\nthe calibrate-and-transform RL (InfAlign-CTRL) algorithm to solve this problem,\nwhich involves a reward calibration step and a KL-regularized reward\nmaximization step with a transformation of the calibrated reward. For best-of-N\nsampling and best-of-N jailbreaking, we propose specific transformations\noffering up to 3-8% improvement on inference-time win rates. Finally, we also\nshow that our proposed reward calibration method is a strong baseline for\noptimizing standard win rate.", "published": "2024-12-27 18:45:36", "link": "http://arxiv.org/abs/2412.19792v3", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "HADES: Hardware Accelerated Decoding for Efficient Speculation in Large\n  Language Models", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nby understanding and generating human-like text. However, the increasing demand\nfor more sophisticated LLMs presents significant computational challenges due\nto their scale and complexity. This paper introduces Hardware Accelerated\nDecoding (HADES), a novel approach to enhance the performance and energy\nefficiency of LLMs. We address the design of an LLM accelerator with\nhardware-level speculative decoding support, a concept not previously explored\nin existing literature. Our work demonstrates how speculative decoding can\nsignificantly improve the efficiency of LLM operations, paving the way for more\nadvanced and practical applications of these models.", "published": "2024-12-27 21:19:01", "link": "http://arxiv.org/abs/2412.19925v2", "categories": ["cs.CL", "cs.AI", "cs.AR"], "primary_category": "cs.CL"}
{"title": "Meta-Learning-Based Delayless Subband Adaptive Filter using Complex\n  Self-Attention for Active Noise Control", "abstract": "Active noise control typically employs adaptive filtering to generate\nsecondary noise, where the least mean square algorithm is the most widely used.\nHowever, traditional updating rules are linear and exhibit limited\neffectiveness in addressing nonlinear environments and nonstationary noise. To\ntackle this challenge, we reformulate the active noise control problem as a\nmeta-learning problem and propose a meta-learning-based delayless subband\nadaptive filter with deep neural networks. The core idea is to utilize a neural\nnetwork as an adaptive algorithm that can adapt to different environments and\ntypes of noise. The neural network will train under noisy observations,\nimplying that it recognizes the optimized updating rule without true labels. A\nsingle-headed attention recurrent neural network is devised with learnable\nfeature embedding to update the adaptive filter weight efficiently, enabling\naccurate computation of the secondary source to attenuate the unwanted primary\nnoise. In order to relax the time constraint on updating the adaptive filter\nweights, the delayless subband architecture is employed, which will allow the\nsystem to be updated less frequently as the downsampling factor increases. In\naddition, the delayless subband architecture does not introduce additional time\ndelays in active noise control systems. A skip updating strategy is introduced\nto decrease the updating frequency further so that machines with limited\nresources have more possibility to board our meta-learning-based model.\nExtensive multi-condition training ensures generalization and robustness\nagainst various types of noise and environments. Simulation results demonstrate\nthat our meta-learning-based model achieves superior noise reduction\nperformance compared to traditional methods.", "published": "2024-12-27 05:51:40", "link": "http://arxiv.org/abs/2412.19471v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mouth Articulation-Based Anchoring for Improved Cross-Corpus Speech\n  Emotion Recognition", "abstract": "Cross-corpus speech emotion recognition (SER) plays a vital role in numerous\npractical applications. Traditional approaches to cross-corpus emotion transfer\noften concentrate on adapting acoustic features to align with different\ncorpora, domains, or labels. However, acoustic features are inherently variable\nand error-prone due to factors like speaker differences, domain shifts, and\nrecording conditions. To address these challenges, this study adopts a novel\ncontrastive approach by focusing on emotion-specific articulatory gestures as\nthe core elements for analysis. By shifting the emphasis on the more stable and\nconsistent articulatory gestures, we aim to enhance emotion transfer learning\nin SER tasks. Our research leverages the CREMA-D and MSP-IMPROV corpora as\nbenchmarks and it reveals valuable insights into the commonality and\nreliability of these articulatory gestures. The findings highlight mouth\narticulatory gesture potential as a better constraint for improving emotion\nrecognition across different settings or domains.", "published": "2024-12-27 20:00:45", "link": "http://arxiv.org/abs/2412.19909v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
