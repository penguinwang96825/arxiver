{"title": "Combining Graph-based Dependency Features with Convolutional Neural Network for Answer Triggering", "abstract": "Answer triggering is the task of selecting the best-suited answer for a given question from a set of candidate answers if exists. In this paper, we present a hybrid deep learning model for answer triggering, which combines several dependency graph based alignment features, namely graph edit distance, graph-based similarity and dependency graph coverage, with dense vector embeddings from a Convolutional Neural Network (CNN). Our experiments on the WikiQA dataset show that such a combination can more accurately trigger a candidate answer compared to the previous state-of-the-art models. Comparative study on WikiQA dataset shows 5.86% absolute F-score improvement at the question level.", "published": "2018-08-05 16:44:25", "link": "http://arxiv.org/abs/1808.01650v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Kid on The Phone! Toward Automatic Detection of Children on Mobile Devices", "abstract": "Studies have shown that children can be exposed to smart devices at a very early age. This has important implications on research in children-computer interaction, children online safety and early education. Many systems have been built based on such research. In this work, we present multiple techniques to automatically detect the presence of a child on a smart device, which could be used as the first step on such systems. Our methods distinguish children from adults based on behavioral differences while operating a touch-enabled modern computing device. Behavioral differences are extracted from data recorded by the touchscreen and built-in sensors. To evaluate the effectiveness of the proposed methods, a new data set has been created from 50 children and adults who interacted with off-the-shelf applications on smart phones. Results show that it is possible to achieve 99% accuracy and less than 0.5% error rate after 8 consecutive touch gestures using only touch information or 5 seconds of sensor reading. If information is used from multiple sensors, then only after 3 gestures, similar performance could be achieved.", "published": "2018-08-05 19:59:35", "link": "http://arxiv.org/abs/1808.01680v1", "categories": ["cs.HC", "cs.CV"], "primary_category": "cs.HC"}
