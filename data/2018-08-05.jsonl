{"title": "Instantiation", "abstract": "In computational linguistics, a large body of work exists on distributed\nmodeling of lexical relations, focussing largely on lexical relations such as\nhypernymy (scientist -- person) that hold between two categories, as expressed\nby common nouns. In contrast, computational linguistics has paid little\nattention to entities denoted by proper nouns (Marie Curie, Mumbai, ...). These\nhave investigated in detail by the Knowledge Representation and Semantic Web\ncommunities, but generally not with regard to their linguistic properties.\n  Our paper closes this gap by investigating and modeling the lexical relation\nof instantiation, which holds between an entity-denoting and a\ncategory-denoting expression (Marie Curie -- scientist or Mumbai -- city). We\npresent a new, principled dataset for the task of instantiation detection as\nwell as experiments and analyses on this dataset. We obtain the following\nresults: (a), entities belonging to one category form a region in\ndistributional space, but the embedding for the category word is typically\nlocated outside this subspace; (b) it is easy to learn to distinguish entities\nfrom categories from distributional evidence, but due to (a), instantiation\nproper is much harder to learn when using common nouns as representations of\ncategories; (c) this problem can be alleviated by using category\nrepresentations based on entity rather than category word embeddings.", "published": "2018-08-05 17:47:18", "link": "http://arxiv.org/abs/1808.01662v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse\n  Semantic Accumulation and Example to Pattern Transformation", "abstract": "Recurrent neural networks (RNNs) are temporal networks and cumulative in\nnature that have shown promising results in various natural language processing\ntasks. Despite their success, it still remains a challenge to understand their\nhidden behavior. In this work, we analyze and interpret the cumulative nature\nof RNN via a proposed technique named as Layer-wIse-Semantic-Accumulation\n(LISA) for explaining decisions and detecting the most likely (i.e., saliency)\npatterns that the network relies on while decision making. We demonstrate (1)\nLISA: \"How an RNN accumulates or builds semantics during its sequential\nprocessing for a given text example and expected response\" (2) Example2pattern:\n\"How the saliency patterns look like for each category in the data according to\nthe network in decision making\". We analyse the sensitiveness of RNNs about\ndifferent inputs to check the increase or decrease in prediction scores and\nfurther extract the saliency patterns learned by the network. We employ two\nrelation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to\nexplain RNN predictions via the LISA and example2pattern.", "published": "2018-08-05 09:50:47", "link": "http://arxiv.org/abs/1808.01591v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simulating Raga Notes with a Markov Chain of Order 1-2", "abstract": "Semi Natural Algorithmic composition (SNCA) is the technique of using\nalgorithms to create music note sequences in computer with the understanding\nthat how to render them would be decided by the composer. In our approach we\nare proposing an SNCA2 algorithm (extension of SNCA algorithm) with an\nillustrative example in Raga Bageshree. For this, Transition probability matrix\n(tpm) was created for the note sequences of Raga Bageshree, then first order\nMarkov chain (using SNCA) and second order Markov chain (using SNCA2)\nsimulations were performed for generating arbitrary sequences of notes of Raga\nBageshree. The choice between first and second order Markov model, is best left\nto the composer who has to decide how to render these music notes sequences. We\nhave confirmed that Markov chain of order of three and above are not promising,\nas the tpm of these become sparse matrices.", "published": "2018-08-05 12:13:47", "link": "http://arxiv.org/abs/1808.01603v1", "categories": ["cs.SD", "cs.CE", "eess.AS"], "primary_category": "cs.SD"}
