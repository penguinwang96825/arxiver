{"title": "The Cross-lingual Conversation Summarization Challenge", "abstract": "We propose the shared task of cross-lingual conversation summarization,\n\\emph{ConvSumX Challenge}, opening new avenues for researchers to investigate\nsolutions that integrate conversation summarization and machine translation.\nThis task can be particularly useful due to the emergence of online meetings\nand conferences. We construct a new benchmark, covering 2 real-world scenarios\nand 3 language directions, including a low-resource language. We hope that\n\\emph{ConvSumX} can motivate researches to go beyond English and break the\nbarrier for non-English speakers to benefit from recent advances of\nconversation summarization.", "published": "2022-05-01 02:00:16", "link": "http://arxiv.org/abs/2205.00379v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELQA: A Corpus of Metalinguistic Questions and Answers about English", "abstract": "We present ELQA, a corpus of questions and answers in and about the English\nlanguage. Collected from two online forums, the >70k questions (from English\nlearners and others) cover wide-ranging topics including grammar, meaning,\nfluency, and etymology. The answers include descriptions of general properties\nof English vocabulary and grammar as well as explanations about specific\n(correct and incorrect) usage examples. Unlike most NLP datasets, this corpus\nis metalinguistic -- it consists of language about language. As such, it can\nfacilitate investigations of the metalinguistic capabilities of NLU models, as\nwell as educational applications in the language learning domain. To study\nthis, we define a free-form question answering task on our dataset and conduct\nevaluations on multiple LLMs (Large Language Models) to analyze their capacity\nto generate metalinguistic answers.", "published": "2022-05-01 04:29:50", "link": "http://arxiv.org/abs/2205.00395v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The use of Data Augmentation as a technique for improving neural network\n  accuracy in detecting fake news about COVID-19", "abstract": "This paper aims to present how the application of Natural Language Processing\n(NLP) and data augmentation techniques can improve the performance of a neural\nnetwork for better detection of fake news in the Portuguese language. Fake news\nis one of the main controversies during the growth of the internet in the last\ndecade. Verifying what is fact and what is false has proven to be a difficult\ntask, while the dissemination of false news is much faster, which leads to the\nneed for the creation of tools that, automated, assist in the process of\nverification of what is fact and what is false. In order to bring a solution,\nan experiment was developed with neural network using news, real and fake,\nwhich were never seen by artificial intelligence (AI). There was a significant\nperformance in the news classification after the application of the mentioned\ntechniques.", "published": "2022-05-01 11:52:53", "link": "http://arxiv.org/abs/2205.00452v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conceptualizing Treatment Leakage in Text-based Causal Inference", "abstract": "Causal inference methods that control for text-based confounders are becoming\nincreasingly important in the social sciences and other disciplines where text\nis readily available. However, these methods rely on a critical assumption that\nthere is no treatment leakage: that is, the text only contains information\nabout the confounder and no information about treatment assignment. When this\nassumption does not hold, methods that control for text to adjust for\nconfounders face the problem of post-treatment (collider) bias. However, the\nassumption that there is no treatment leakage may be unrealistic in real-world\nsituations involving text, as human language is rich and flexible. Language\nappearing in a public policy document or health records may refer to the future\nand the past simultaneously, and thereby reveal information about the treatment\nassignment.\n  In this article, we define the treatment-leakage problem, and discuss the\nidentification as well as the estimation challenges it raises. Second, we\ndelineate the conditions under which leakage can be addressed by removing the\ntreatment-related signal from the text in a pre-processing step we define as\ntext distillation. Lastly, using simulation, we show how treatment leakage\nintroduces a bias in estimates of the average treatment effect (ATE) and how\ntext distillation can mitigate this bias.", "published": "2022-05-01 13:13:39", "link": "http://arxiv.org/abs/2205.00465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nearest Neighbor Knowledge Distillation for Neural Machine Translation", "abstract": "k-nearest-neighbor machine translation (NN-MT), proposed by Khandelwal et al.\n(2021), has achieved many state-of-the-art results in machine translation\ntasks. Although effective, NN-MT requires conducting NN searches through the\nlarge datastore for each decoding step during inference, prohibitively\nincreasing the decoding cost and thus leading to the difficulty for the\ndeployment in real-world applications. In this paper, we propose to move the\ntime-consuming NN search forward to the preprocessing phase, and then introduce\nNearest Neighbor Knowledge Distillation (NN-KD) that trains the base NMT model\nto directly learn the knowledge of NN. Distilling knowledge retrieved by NN can\nencourage the NMT model to take more reasonable target tokens into\nconsideration, thus addressing the overcorrection problem. Extensive\nexperimental results show that, the proposed method achieves consistent\nimprovement over the state-of-the-art baselines including NN-MT, while\nmaintaining the same training and decoding speed as the standard NMT model.", "published": "2022-05-01 14:30:49", "link": "http://arxiv.org/abs/2205.00479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUP: Curriculum Learning based Prompt Tuning for Implicit Event Argument\n  Extraction", "abstract": "Implicit event argument extraction (EAE) aims to identify arguments that\ncould scatter over the document. Most previous work focuses on learning the\ndirect relations between arguments and the given trigger, while the implicit\nrelations with long-range dependency are not well studied. Moreover, recent\nneural network based approaches rely on a large amount of labeled data for\ntraining, which is unavailable due to the high labelling cost. In this paper,\nwe propose a Curriculum learning based Prompt tuning (CUP) approach, which\nresolves implicit EAE by four learning stages. The stages are defined according\nto the relations with the trigger node in a semantic graph, which well captures\nthe long-range dependency between arguments and the trigger. In addition, we\nintegrate a prompt-based encoder-decoder model to elicit related knowledge from\npre-trained language models (PLMs) in each stage, where the prompt templates\nare adapted with the learning progress to enhance the reasoning for arguments.\nExperimental results on two well-known benchmark datasets show the great\nadvantages of our proposed approach. In particular, we outperform the\nstate-of-the-art models in both fully-supervised and low-data scenarios.", "published": "2022-05-01 16:03:54", "link": "http://arxiv.org/abs/2205.00498v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Textual Stylistic Variation: Choices, Genres and Individuals", "abstract": "This chapter argues for more informed target metrics for the statistical\nprocessing of stylistic variation in text collections. Much as operationalised\nrelevance proved a useful goal to strive for in information retrieval, research\nin textual stylistics, whether application oriented or philologically inclined,\nneeds goals formulated in terms of pertinence, relevance, and utility - notions\nthat agree with reader experience of text. Differences readers are aware of are\nmostly based on utility - not on textual characteristics per se. Mostly,\nreaders report stylistic differences in terms of genres. Genres, while vague\nand undefined, are well-established and talked about: very early on, readers\nlearn to distinguish genres. This chapter discusses variation given by genre,\nand contrasts it to variation occasioned by individual choice.", "published": "2022-05-01 16:39:49", "link": "http://arxiv.org/abs/2205.00510v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conventions and Mutual Expectations -- understanding sources for web\n  genres", "abstract": "Genres can be understood in many different ways. They are often perceived as\na primarily sociological construction, or, alternatively, as a\nstylostatistically observable objective characteristic of texts. The latter\nview is more common in the research field of information and language\ntechnology. These two views can be quite compatible and can inform each other;\nthis present investigation discusses knowledge sources for studying genre\nvariation and change by observing reader and author behaviour rather than\nperforming analyses on the information objects themselves.", "published": "2022-05-01 16:44:55", "link": "http://arxiv.org/abs/2205.00512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Masked Language Models for Multiple Languages", "abstract": "Masked Language Models (MLMs) pre-trained by predicting masked tokens on\nlarge corpora have been used successfully in natural language processing tasks\nfor a variety of languages. Unfortunately, it was reported that MLMs also learn\ndiscriminative biases regarding attributes such as gender and race. Because\nmost studies have focused on MLMs in English, the bias of MLMs in other\nlanguages has rarely been investigated. Manual annotation of evaluation data\nfor languages other than English has been challenging due to the cost and\ndifficulty in recruiting annotators. Moreover, the existing bias evaluation\nmethods require the stereotypical sentence pairs consisting of the same context\nwith attribute words (e.g. He/She is a nurse). We propose Multilingual Bias\nEvaluation (MBE) score, to evaluate bias in various languages using only\nEnglish attribute word lists and parallel corpora between the target language\nand English without requiring manually annotated data. We evaluated MLMs in\neight languages using the MBE and confirmed that gender-related biases are\nencoded in MLMs for all those languages. We manually created datasets for\ngender bias in Japanese and Russian to evaluate the validity of the MBE. The\nresults show that the bias scores reported by the MBE significantly correlates\nwith that computed from the above manually created datasets and the existing\nEnglish datasets for gender bias.", "published": "2022-05-01 20:19:14", "link": "http://arxiv.org/abs/2205.00551v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting COVID-19 Conspiracy Theories with Transformers and TF-IDF", "abstract": "The sharing of fake news and conspiracy theories on social media has\nwide-spread negative effects. By designing and applying different machine\nlearning models, researchers have made progress in detecting fake news from\ntext. However, existing research places a heavy emphasis on general,\ncommon-sense fake news, while in reality fake news often involves rapidly\nchanging topics and domain-specific vocabulary. In this paper, we present our\nmethods and results for three fake news detection tasks at MediaEval benchmark\n2021 that specifically involve COVID-19 related topics. We experiment with a\ngroup of text-based models including Support Vector Machines, Random Forest,\nBERT, and RoBERTa. We find that a pre-trained transformer yields the best\nvalidation results, but a randomly initialized transformer with smart design\ncan also be trained to reach accuracies close to that of the pre-trained\ntransformer.", "published": "2022-05-01 01:48:48", "link": "http://arxiv.org/abs/2205.00377v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crude Oil-related Events Extraction and Processing: A Transfer Learning\n  Approach", "abstract": "One of the challenges in event extraction via traditional supervised learning\nparadigm is the need for a sizeable annotated dataset to achieve satisfactory\nmodel performance. It is even more challenging when it comes to event\nextraction in the finance and economics domain, a domain with considerably\nfewer resources. This paper presents a complete framework for extracting and\nprocessing crude oil-related events found in CrudeOilNews corpus, addressing\nthe issue of annotation scarcity and class imbalance by leveraging on the\neffectiveness of transfer learning. Apart from event extraction, we place\nspecial emphasis on event properties (Polarity, Modality, and Intensity)\nclassification to determine the factual certainty of each event. We build\nbaseline models first by supervised learning and then exploit Transfer Learning\nmethods to boost event extraction model performance despite the limited amount\nof annotated data and severe class imbalance. This is done via methods within\nthe transfer learning framework such as Domain Adaptive Pre-training,\nMulti-task Learning and Sequential Transfer Learning. Based on experiment\nresults, we are able to improve all event extraction sub-task models both in F1\nand MCC1-score as compared to baseline models trained via the standard\nsupervised learning. Accurate and holistic event extraction from crude oil news\nis very useful for downstream tasks such as understanding event chains and\nlearning event-event relations, which can be used for other downstream tasks\nsuch as commodity price prediction, summarisation, etc. to support a wide range\nof business decision making.", "published": "2022-05-01 03:21:18", "link": "http://arxiv.org/abs/2205.00387v1", "categories": ["cs.CL", "cs.IR", "68", "H.3; I.2"], "primary_category": "cs.CL"}
{"title": "ETMS@IITKGP at SemEval-2022 Task 10: Structured Sentiment Analysis Using\n  A Generative Approach", "abstract": "Structured Sentiment Analysis (SSA) deals with extracting opinion tuples in a\ntext, where each tuple (h, e, t, p) consists of h, the holder, who expresses a\nsentiment polarity p towards a target t through a sentiment expression e. While\nprior works explore graph-based or sequence labeling-based approaches for the\ntask, we in this paper present a novel unified generative method to solve SSA,\na SemEval2022 shared task. We leverage a BART-based encoder-decoder\narchitecture and suitably modify it to generate, given a sentence, a sequence\nof opinion tuples. Each generated tuple consists of seven integers respectively\nrepresenting the indices corresponding to the start and end positions of the\nholder, target, and expression spans, followed by the sentiment polarity class\nassociated between the target and the sentiment expression. We perform rigorous\nexperiments for both Monolingual and Cross-lingual subtasks, and achieve\ncompetitive Sentiment F1 scores on the leaderboard in both settings.", "published": "2022-05-01 10:39:53", "link": "http://arxiv.org/abs/2205.00440v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MRKL Systems: A modular, neuro-symbolic architecture that combines large\n  language models, external knowledge sources and discrete reasoning", "abstract": "Huge language models (LMs) have ushered in a new era for AI, serving as a\ngateway to natural-language-based knowledge tasks. Although an essential\nelement of modern AI, LMs are also inherently limited in a number of ways. We\ndiscuss these limitations and how they can be avoided by adopting a systems\napproach. Conceptualizing the challenge as one that involves knowledge and\nreasoning in addition to linguistic processing, we define a flexible\narchitecture with multiple neural models, complemented by discrete knowledge\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\nModular Reasoning, Knowledge and Language (MRKL, pronounced \"miracle\") system,\nsome of the technical challenges in implementing it, and Jurassic-X, AI21 Labs'\nMRKL system implementation.", "published": "2022-05-01 11:01:28", "link": "http://arxiv.org/abs/2205.00445v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "None Class Ranking Loss for Document-Level Relation Extraction", "abstract": "Document-level relation extraction (RE) aims at extracting relations among\nentities expressed across multiple sentences, which can be viewed as a\nmulti-label classification problem. In a typical document, most entity pairs do\nnot express any pre-defined relation and are labeled as \"none\" or \"no\nrelation\". For good document-level RE performance, it is crucial to distinguish\nsuch none class instances (entity pairs) from those of pre-defined classes\n(relations). However, most existing methods only estimate the probability of\npre-defined relations independently without considering the probability of \"no\nrelation\". This ignores the context of entity pairs and the label correlations\nbetween the none class and pre-defined classes, leading to sub-optimal\npredictions. To address this problem, we propose a new multi-label loss that\nencourages large margins of label confidence scores between each pre-defined\nclass and the none class, which enables captured label correlations and\ncontext-dependent thresholding for label prediction. To gain further robustness\nagainst positive-negative imbalance and mislabeled data that could appear in\nreal-world RE datasets, we propose a margin regularization and a margin\nshifting technique. Experimental results demonstrate that our method\nsignificantly outperforms existing multi-label losses for document-level RE and\nworks well in other multi-label tasks such as emotion classification when none\nclass instances are available for training.", "published": "2022-05-01 14:24:37", "link": "http://arxiv.org/abs/2205.00476v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Programming in Rank Space: Scaling Structured Inference with\n  Low-Rank HMMs and PCFGs", "abstract": "Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs)\nare widely used structured models, both of which can be represented as factor\ngraph grammars (FGGs), a powerful formalism capable of describing a wide range\nof models. Recent research found it beneficial to use large state spaces for\nHMMs and PCFGs. However, inference with large state spaces is computationally\ndemanding, especially for PCFGs. To tackle this challenge, we leverage tensor\nrank decomposition (aka.\\ CPD) to decrease inference computational complexities\nfor a subset of FGGs subsuming HMMs and PCFGs. We apply CPD on the factors of\nan FGG and then construct a new FGG defined in the rank space. Inference with\nthe new FGG produces the same result but has a lower time complexity when the\nrank size is smaller than the state size. We conduct experiments on HMM\nlanguage modeling and unsupervised PCFG parsing, showing better performance\nthan previous work. Our code is publicly available at\n\\url{https://github.com/VPeterV/RankSpace-Models}.", "published": "2022-05-01 14:58:25", "link": "http://arxiv.org/abs/2205.00484v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large-Scale Multi-Document Summarization with Information Extraction and\n  Compression", "abstract": "We develop an abstractive summarization framework independent of labeled data\nfor multiple heterogeneous documents. Unlike existing multi-document\nsummarization methods, our framework processes documents telling different\nstories instead of documents on the same topic. We also enhance an existing\nsentence fusion method with a uni-directional language model to prioritize\nfused sentences with higher sentence probability with the goal of increasing\nreadability. Lastly, we construct a total of twelve dataset variations based on\nCNN/Daily Mail and the NewsRoom datasets, where each document group contains a\nlarge and diverse collection of documents to evaluate the performance of our\nmodel in comparison with other baseline systems. Our experiments demonstrate\nthat our framework outperforms current state-of-the-art methods in this more\ngeneric setting.", "published": "2022-05-01 19:49:15", "link": "http://arxiv.org/abs/2205.00548v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Don't Blame the Annotator: Bias Already Starts in the Annotation\n  Instructions", "abstract": "In recent years, progress in NLU has been driven by benchmarks. These\nbenchmarks are typically collected by crowdsourcing, where annotators write\nexamples based on annotation instructions crafted by dataset creators. In this\nwork, we hypothesize that annotators pick up on patterns in the crowdsourcing\ninstructions, which bias them to write many similar examples that are then\nover-represented in the collected data. We study this form of bias, termed\ninstruction bias, in 14 recent NLU benchmarks, showing that instruction\nexamples often exhibit concrete patterns, which are propagated by crowdworkers\nto the collected data. This extends previous work (Geva et al., 2019) and\nraises a new concern of whether we are modeling the dataset creator's\ninstructions, rather than the task. Through a series of experiments, we show\nthat, indeed, instruction bias can lead to overestimation of model performance,\nand that models struggle to generalize beyond biases originating in the\ncrowdsourcing instructions. We further analyze the influence of instruction\nbias in terms of pattern frequency and model size, and derive concrete\nrecommendations for creating future NLU benchmarks.", "published": "2022-05-01 07:51:22", "link": "http://arxiv.org/abs/2205.00415v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bilingual End-to-End ASR with Byte-Level Subwords", "abstract": "In this paper, we investigate how the output representation of an end-to-end\nneural network affects multilingual automatic speech recognition (ASR). We\nstudy different representations including character-level, byte-level, byte\npair encoding (BPE), and byte-level byte pair encoding (BBPE) representations,\nand analyze their strengths and weaknesses. We focus on developing a single\nend-to-end model to support utterance-based bilingual ASR, where speakers do\nnot alternate between two languages in a single utterance but may change\nlanguages across utterances. We conduct our experiments on English and Mandarin\ndictation tasks, and we find that BBPE with penalty schemes can improve\nutterance-based bilingual ASR performance by 2% to 5% relative even with\nsmaller number of outputs and fewer parameters. We conclude with analysis that\nindicates directions for further improving multilingual ASR.", "published": "2022-05-01 15:01:01", "link": "http://arxiv.org/abs/2205.00485v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on\n  Toxicity Annotation", "abstract": "Machine learning models are commonly used to detect toxicity in online\nconversations. These models are trained on datasets annotated by human raters.\nWe explore how raters' self-described identities impact how they annotate\ntoxicity in online comments. We first define the concept of specialized rater\npools: rater pools formed based on raters' self-described identities, rather\nthan at random. We formed three such rater pools for this study--specialized\nrater pools of raters from the U.S. who identify as African American, LGBTQ,\nand those who identify as neither. Each of these rater pools annotated the same\nset of comments, which contains many references to these identity groups. We\nfound that rater identity is a statistically significant factor in how raters\nwill annotate toxicity for identity-related annotations. Using preliminary\ncontent analysis, we examined the comments with the most disagreement between\nrater pools and found nuanced differences in the toxicity annotations. Next, we\ntrained models on the annotations from each of the different rater pools, and\ncompared the scores of these models on comments from several test sets.\nFinally, we discuss how using raters that self-identify with the subjects of\ncomments can create more inclusive machine learning models, and provide more\nnuanced ratings than those by random raters.", "published": "2022-05-01 16:08:48", "link": "http://arxiv.org/abs/2205.00501v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Enumeration Classes Defined by Circuits", "abstract": "We refine the complexity landscape for enumeration problems by introducing\nvery low classes defined by using Boolean circuits as enumerators. We locate\nwell-known enumeration problems, e.g., from graph theory, Gray code\nenumeration, and propositional satisfiability in our classes. In this way we\nobtain a framework to distinguish between the complexity of different problems\nknown to be in $\\mathbf{DelayP}$, for which a formal way of comparison was not\npossible to this day.", "published": "2022-05-01 19:02:03", "link": "http://arxiv.org/abs/2205.00539v1", "categories": ["cs.CC", "cs.CL", "cs.DS", "F.1.1; F.1.3; F.2.2"], "primary_category": "cs.CC"}
{"title": "Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot\n  Learning", "abstract": "Medical coding (MC) is an essential pre-requisite for reliable data retrieval\nand reporting. Given a free-text reported term (RT) such as \"pain of right\nthigh to the knee\", the task is to identify the matching lowest-level term\n(LLT) - in this case \"unilateral leg pain\" - from a very large and continuously\ngrowing repository of standardized medical terms. However, automating this task\nis challenging due to a large number of LLT codes (as of writing over 80,000),\nlimited availability of training data for long tail/emerging classes, and the\ngeneral high accuracy demands of the medical domain. With this paper, we\nintroduce the MC task, discuss its challenges, and present a novel approach\ncalled xTARS that combines traditional BERT-based classification with a recent\nzero/few-shot learning approach (TARS). We present extensive experiments that\nshow that our combined approach outperforms strong baselines, especially in the\nfew-shot regime. The approach is developed and deployed at Bayer, live since\nNovember 2021. As we believe our approach potentially promising beyond MC, and\nto ensure reproducibility, we release the code to the research community.", "published": "2022-05-01 22:49:28", "link": "http://arxiv.org/abs/2206.02662v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Relation-guided acoustic scene classification aided with event\n  embeddings", "abstract": "In real life, acoustic scenes and audio events are naturally correlated.\nHumans instinctively rely on fine-grained audio events as well as the overall\nsound characteristics to distinguish diverse acoustic scenes. Yet, most\nprevious approaches treat acoustic scene classification (ASC) and audio event\nclassification (AEC) as two independent tasks. A few studies on scene and event\njoint classification either use synthetic audio datasets that hardly match the\nreal world, or simply use the multi-task framework to perform two tasks at the\nsame time. Neither of these two ways makes full use of the implicit and\ninherent relation between fine-grained events and coarse-grained scenes. To\nthis end, this paper proposes a relation-guided ASC (RGASC) model to further\nexploit and coordinate the scene-event relation for the mutual benefit of scene\nand event recognition. The TUT Urban Acoustic Scenes 2018 dataset (TUT2018) is\nannotated with pseudo labels of events by a simple and efficient audio-related\npre-trained model PANN, which is one of the state-of-the-art AEC models. Then,\na prior scene-event relation matrix is defined as the average probability of\nthe presence of each event type in each scene class. Finally, the two-tower\nRGASC model is jointly trained on the real-life dataset TUT2018 for both scene\nand event classification. The following results are achieved. 1) RGASC\neffectively coordinates the true information of coarse-grained scenes and the\npseudo information of fine-grained events. 2) The event embeddings learned from\npseudo labels under the guidance of prior scene-event relations help reduce the\nconfusion between similar acoustic scenes. 3) Compared with other\n(non-ensemble) methods, RGASC improves the scene classification accuracy on the\nreal-life dataset.", "published": "2022-05-01 16:06:35", "link": "http://arxiv.org/abs/2205.00499v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
