{"title": "Unsupervised Neural Dialect Translation with Commonality and Diversity\n  Modeling", "abstract": "As a special machine translation task, dialect translation has two main\ncharacteristics: 1) lack of parallel training corpus; and 2) possessing similar\ngrammar between two sides of the translation. In this paper, we investigate how\nto exploit the commonality and diversity between dialects thus to build\nunsupervised translation models merely accessing to monolingual data.\nSpecifically, we leverage pivot-private embedding, layer coordination, as well\nas parameter sharing to sufficiently model commonality and diversity among\nsource and target, ranging from lexical, through syntactic, to semantic levels.\nIn order to examine the effectiveness of the proposed models, we collect 20\nmillion monolingual corpus for each of Mandarin and Cantonese, which are\nofficial language and the most widely used dialect in China. Experimental\nresults reveal that our methods outperform rule-based simplified and\ntraditional Chinese conversion and conventional unsupervised translation models\nover 12 BLEU scores.", "published": "2019-12-11 06:21:16", "link": "http://arxiv.org/abs/1912.05134v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Protein-Protein Interaction Extraction with Knowledge\n  Selection", "abstract": "Protein-protein interaction (PPI) extraction from published scientific\nliterature provides additional support for precision medicine efforts.\nMeanwhile, knowledge bases (KBs) contain huge amounts of structured information\nof protein entities and their relations, which can be encoded in entity and\nrelation embeddings to help PPI extraction. However, the prior knowledge of\nprotein-protein pairs must be selectively used so that it is suitable for\ndifferent contexts. This paper proposes a Knowledge Selection Model (KSM) to\nfuse the selected prior knowledge and context information for PPI extraction.\nFirstly, two Transformers encode the context sequence of a protein pair\naccording to each protein embedding, respectively. Then, the two outputs are\nfed to a mutual attention to capture the important context features towards the\nprotein pair. Next, the context features are used to distill the relation\nembedding by a knowledge selector. Finally, the selected relation embedding and\nthe context features are concatenated for PPI extraction. Experiments on the\nBioCreative VI PPI dataset show that KSM achieves a new state-of-the-art\nperformance (38.08% F1-score) by adding knowledge selection.", "published": "2019-12-11 07:29:59", "link": "http://arxiv.org/abs/1912.05147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Spanish Translation of the SQuAD Dataset for Multilingual\n  Question Answering", "abstract": "Recently, multilingual question answering became a crucial research topic,\nand it is receiving increased interest in the NLP community. However, the\nunavailability of large-scale datasets makes it challenging to train\nmultilingual QA systems with performance comparable to the English ones. In\nthis work, we develop the Translate Align Retrieve (TAR) method to\nautomatically translate the Stanford Question Answering Dataset (SQuAD) v1.1 to\nSpanish. We then used this dataset to train Spanish QA systems by fine-tuning a\nMultilingual-BERT model. Finally, we evaluated our QA models with the recently\nproposed MLQA and XQuAD benchmarks for cross-lingual Extractive QA.\nExperimental results show that our models outperform the previous\nMultilingual-BERT baselines achieving the new state-of-the-art value of 68.1 F1\npoints on the Spanish MLQA corpus and 77.6 F1 and 61.8 Exact Match points on\nthe Spanish XQuAD corpus. The resulting, synthetically generated SQuAD-es v1.1\ncorpora, with almost 100% of data contained in the original English version, to\nthe best of our knowledge, is the first large-scale QA training resource for\nSpanish.", "published": "2019-12-11 09:33:21", "link": "http://arxiv.org/abs/1912.05200v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoSimLex: A Resource for Evaluating Graded Word Similarity in Context", "abstract": "State of the art natural language processing tools are built on\ncontext-dependent word embeddings, but no direct method for evaluating these\nrepresentations currently exists. Standard tasks and datasets for intrinsic\nevaluation of embeddings are based on judgements of similarity, but ignore\ncontext; standard tasks for word sense disambiguation take account of context\nbut do not provide continuous measures of meaning similarity. This paper\ndescribes an effort to build a new dataset, CoSimLex, intended to fill this\ngap. Building on the standard pairwise similarity task of SimLex-999, it\nprovides context-dependent similarity measures; covers not only discrete\ndifferences in word sense but more subtle, graded changes in meaning; and\ncovers not only a well-resourced language (English) but a number of\nless-resourced languages. We define the task and evaluation metrics, outline\nthe dataset collection methodology, and describe the status of the dataset so\nfar.", "published": "2019-12-11 14:02:59", "link": "http://arxiv.org/abs/1912.05320v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Quality of syntactic implication of RL-based sentence summarization", "abstract": "Work on summarization has explored both reinforcement learning (RL)\noptimization using ROUGE as a reward and syntax-aware models, such as models\nthose input is enriched with part-of-speech (POS)-tags and dependency\ninformation. However, it is not clear what is the respective impact of these\napproaches beyond the standard ROUGE evaluation metric. Especially, RL-based\nfor summarization is becoming more and more popular. In this paper, we provide\na detailed comparison of these two approaches and of their combination along\nseveral dimensions that relate to the perceived quality of the generated\nsummaries: number of repeated words, distribution of part-of-speech tags,\nimpact of sentence length, relevance and grammaticality. Using the standard\nGigaword sentence summarization task, we compare an RL self-critical sequence\ntraining (SCST) method with syntax-aware models that leverage POS tags and\nDependency information. We show that on all qualitative evaluations, the\ncombined model gives the best results, but also that only training with RL and\nwithout any syntactic information already gives nearly as good results as\nsyntax-aware models with less parameters and faster training convergence.", "published": "2019-12-11 17:47:29", "link": "http://arxiv.org/abs/1912.05493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Collaborative Ecosystem for Digital Coptic Studies", "abstract": "Scholarship on underresourced languages bring with them a variety of\nchallenges which make access to the full spectrum of source materials and their\nevaluation difficult. For Coptic in particular, large scale analyses and any\nkind of quantitative work become difficult due to the fragmentation of\nmanuscripts, the highly fusional nature of an incorporational morphology, and\nthe complications of dealing with influences from Hellenistic era Greek, among\nother concerns. Many of these challenges, however, can be addressed using\nDigital Humanities tools and standards. In this paper, we outline some of the\nlatest developments in Coptic Scriptorium, a DH project dedicated to bringing\nCoptic resources online in uniform, machine readable, and openly available\nformats. Collaborative web-based tools create online 'virtual departments' in\nwhich scholars dispersed sparsely across the globe can collaborate, and natural\nlanguage processing tools counterbalance the scarcity of trained editors by\nenabling machine processing of Coptic text to produce searchable, annotated\ncorpora.", "published": "2019-12-11 02:03:31", "link": "http://arxiv.org/abs/1912.05082v3", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Two Birds with One Stone: Investigating Invertible Neural Networks for\n  Inverse Problems in Morphology", "abstract": "Most problems in natural language processing can be approximated as inverse\nproblems such as analysis and generation at variety of levels from\nmorphological (e.g., cat+Plural <-> cats) to semantic (e.g., (call + 1 2) <->\n\"Calculate one plus two.\"). Although the tasks in both directions are closely\nrelated, general approach in the field has been to design separate models\nspecific for each task. However, having one shared model for both tasks, would\nhelp the researchers exploit the common knowledge among these problems with\nreduced time and memory requirements. We investigate a specific class of neural\nnetworks, called Invertible Neural Networks (INNs) (Ardizzone et al. 2019) that\nenable simultaneous optimization in both directions, hence allow addressing of\ninverse problems via a single model. In this study, we investigate INNs on\nmorphological problems casted as inverse problems. We apply INNs to various\nmorphological tasks with varying ambiguity and show that they provide\ncompetitive performance in both directions. We show that they are able to\nrecover the morphological input parameters, i.e., predicting the lemma (e.g.,\ncat) or the morphological tags (e.g., Plural) when run in the reverse\ndirection, without any significant performance drop in the forward direction,\ni.e., predicting the surface form (e.g., cats).", "published": "2019-12-11 12:50:48", "link": "http://arxiv.org/abs/1912.05274v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FlauBERT: Unsupervised Language Model Pre-training for French", "abstract": "Language models have become a key step to achieve state-of-the art results in\nmany different Natural Language Processing (NLP) tasks. Leveraging the huge\namount of unlabeled texts nowadays available, they provide an efficient way to\npre-train continuous word representations that can be fine-tuned for a\ndownstream task, along with their contextualization at the sentence level. This\nhas been widely demonstrated for English using contextualized representations\n(Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al.,\n2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and\nshare FlauBERT, a model learned on a very large and heterogeneous French\ncorpus. Models of different sizes are trained using the new CNRS (French\nNational Centre for Scientific Research) Jean Zay supercomputer. We apply our\nFrench language models to diverse NLP tasks (text classification, paraphrasing,\nnatural language inference, parsing, word sense disambiguation) and show that\nmost of the time they outperform other pre-training approaches. Different\nversions of FlauBERT as well as a unified evaluation protocol for the\ndownstream tasks, called FLUE (French Language Understanding Evaluation), are\nshared to the research community for further reproducible experiments in French\nNLP.", "published": "2019-12-11 14:59:32", "link": "http://arxiv.org/abs/1912.05372v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MetaMT,a MetaLearning Method Leveraging Multiple Domain Data for Low\n  Resource Machine Translation", "abstract": "Manipulating training data leads to robust neural models for MT.", "published": "2019-12-11 17:05:18", "link": "http://arxiv.org/abs/1912.05467v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Event Outcome Prediction using Sentiment Analysis and Crowd Wisdom in\n  Microblog Feeds", "abstract": "Sentiment Analysis of microblog feeds has attracted considerable interest in\nrecent times. Most of the current work focuses on tweet sentiment\nclassification. But not much work has been done to explore how reliable the\nopinions of the mass (crowd wisdom) in social network microblogs such as\ntwitter are in predicting outcomes of certain events such as election debates.\nIn this work, we investigate whether crowd wisdom is useful in predicting such\noutcomes and whether their opinions are influenced by the experts in the field.\nWe work in the domain of multi-label classification to perform sentiment\nclassification of tweets and obtain the opinion of the crowd. This learnt\nsentiment is then used to predict outcomes of events such as: US Presidential\nDebate winners, Grammy Award winners, Super Bowl Winners. We find that in most\nof the cases, the wisdom of the crowd does indeed match with that of the\nexperts, and in cases where they don't (particularly in the case of debates),\nwe see that the crowd's opinion is actually influenced by that of the experts.", "published": "2019-12-11 00:30:24", "link": "http://arxiv.org/abs/1912.05066v1", "categories": ["cs.LG", "cs.CL", "cs.SI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Small-footprint Keyword Spotting with Graph Convolutional Network", "abstract": "Despite the recent successes of deep neural networks, it remains challenging\nto achieve high precision keyword spotting task (KWS) on resource-constrained\ndevices. In this study, we propose a novel context-aware and compact\narchitecture for keyword spotting task. Based on residual connection and\nbottleneck structure, we design a compact and efficient network for KWS task.\nTo leverage the long range dependencies and global context of the convolutional\nfeature maps, the graph convolutional network is introduced to encode the\nnon-local relations. By evaluated on the Google Speech Command Dataset, the\nproposed method achieves state-of-the-art performance and outperforms the prior\nworks by a large margin with lower computational cost.", "published": "2019-12-11 05:44:04", "link": "http://arxiv.org/abs/1912.05124v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Lifelong learning for text retrieval and recognition in historical\n  handwritten document collections", "abstract": "This chapter provides an overview of the problems that need to be dealt with\nwhen constructing a lifelong-learning retrieval, recognition and indexing\nengine for large historical document collections in multiple scripts and\nlanguages, the Monk system. This application is highly variable over time,\nsince the continuous labeling by end users changes the concept of what a\n'ground truth' constitutes. Although current advances in deep learning provide\na huge potential in this application domain, the scale of the problem, i.e.,\nmore than 520 hugely diverse books, documents and manuscripts precludes the\ncurrent meticulous and painstaking human effort which is required in designing\nand developing successful deep-learning systems. The ball-park principle is\nintroduced, which describes the evolution from the sparsely-labeled stage that\ncan only be addressed by traditional methods or nearest-neighbor methods on\nembedded vectors of pre-trained neural networks, up to the other end of the\nspectrum where massive labeling allows reliable training of deep-learning\nmethods. Contents: Introduction, Expectation management, Deep learning, The\nball-park principle, Technical realization, Work flow, Quality and quantity of\nmaterial, Industrialization and scalability, Human effort, Algorithms, Object\nof recognition, Processing pipeline, Performance,Compositionality, Conclusion.", "published": "2019-12-11 07:56:31", "link": "http://arxiv.org/abs/1912.05156v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines", "abstract": "Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout \"right\" and \"wrong\" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.", "published": "2019-12-11 11:27:06", "link": "http://arxiv.org/abs/1912.05238v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Voice Conversion for Whispered Speech Synthesis", "abstract": "We present an approach to synthesize whisper by applying a handcrafted signal\nprocessing recipe and Voice Conversion (VC) techniques to convert normally\nphonated speech to whispered speech. We investigate using Gaussian Mixture\nModels (GMM) and Deep Neural Networks (DNN) to model the mapping between\nacoustic features of normal speech and those of whispered speech. We evaluate\nnaturalness and speaker similarity of the converted whisper on an internal\ncorpus and on the publicly available wTIMIT corpus. We show that applying VC\ntechniques is significantly better than using rule-based signal processing\nmethods and it achieves results that are indistinguishable from copy-synthesis\nof natural whisper recordings. We investigate the ability of the DNN model to\ngeneralize on unseen speakers, when trained with data from multiple speakers.\nWe show that excluding the target speaker from the training set has little or\nno impact on the perceived naturalness and speaker similarity of the converted\nwhisper. The proposed DNN method is used in the newly released Whisper Mode of\nAmazon Alexa.", "published": "2019-12-11 13:34:43", "link": "http://arxiv.org/abs/1912.05289v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning to Request Guidance in Emergent Communication", "abstract": "Previous research into agent communication has shown that a pre-trained guide\ncan speed up the learning process of an imitation learning agent. The guide\nachieves this by providing the agent with discrete messages in an emerged\nlanguage about how to solve the task. We extend this one-directional\ncommunication by a one-bit communication channel from the learner back to the\nguide: It is able to ask the guide for help, and we limit the guidance by\npenalizing the learner for these requests. During training, the agent learns to\ncontrol this gate based on its current observation. We find that the amount of\nrequested guidance decreases over time and guidance is requested in situations\nof high uncertainty. We investigate the agent's performance in cases of open\nand closed gates and discuss potential motives for the observed gating\nbehavior.", "published": "2019-12-11 18:48:05", "link": "http://arxiv.org/abs/1912.05525v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SpecAugment on Large Scale Datasets", "abstract": "Recently, SpecAugment, an augmentation scheme for automatic speech\nrecognition that acts directly on the spectrogram of input utterances, has\nshown to be highly effective in enhancing the performance of end-to-end\nnetworks on public datasets. In this paper, we demonstrate its effectiveness on\ntasks with large scale datasets by investigating its application to the Google\nMultidomain Dataset (Narayanan et al., 2018). We achieve improvement across all\ntest domains by mixing raw training data augmented with SpecAugment and\nnoise-perturbed training data when training the acoustic model. We also\nintroduce a modification of SpecAugment that adapts the time mask size and/or\nmultiplicity depending on the length of the utterance, which can potentially\nbenefit large scale tasks. By using adaptive masking, we are able to further\nimprove the performance of the Listen, Attend and Spell model on LibriSpeech to\n2.2% WER on test-clean and 5.2% WER on test-other.", "published": "2019-12-11 18:58:58", "link": "http://arxiv.org/abs/1912.05533v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Biases for Emergent Communication in Multi-agent Reinforcement Learning", "abstract": "We study the problem of emergent communication, in which language arises\nbecause speakers and listeners must communicate information in order to solve\ntasks. In temporally extended reinforcement learning domains, it has proved\nhard to learn such communication without centralized training of agents, due in\npart to a difficult joint exploration problem. We introduce inductive biases\nfor positive signalling and positive listening, which ease this problem. In a\nsimple one-step environment, we demonstrate how these biases ease the learning\nproblem. We also apply our methods to a more extended environment, showing that\nagents with these inductive biases achieve better performance, and analyse the\nresulting communication protocols.", "published": "2019-12-11 22:39:51", "link": "http://arxiv.org/abs/1912.05676v1", "categories": ["cs.MA", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Unwanted Advances in Higher Education: Uncovering Sexual Harassment\n  Experiences in Academia with Text Mining", "abstract": "Sexual harassment in academia is often a hidden problem because victims are\nusually reluctant to report their experiences. Recently, a web survey was\ndeveloped to provide an opportunity to share thousands of sexual harassment\nexperiences in academia. Using an efficient approach, this study collected and\ninvestigated more than 2,000 sexual harassment experiences to better understand\nthese unwanted advances in higher education. This paper utilized text mining to\ndisclose hidden topics and explore their weight across three variables:\nharasser gender, institution type, and victim's field of study. We mapped the\ntopics on five themes drawn from the sexual harassment literature and found\nthat more than 50% of the topics were assigned to the unwanted sexual attention\ntheme. Fourteen percent of the topics were in the gender harassment theme, in\nwhich insulting, sexist, or degrading comments or behavior was directed towards\nwomen. Five percent of the topics involved sexual coercion (a benefit is\noffered in exchange for sexual favors), 5% involved sex discrimination, and 7%\nof the topics discussed retaliation against the victim for reporting the\nharassment, or for simply not complying with the harasser. Findings highlight\nthe power differential between faculty and students, and the toll on students\nwhen professors abuse their power. While some topics did differ based on type\nof institution, there were no differences between the topics based on gender of\nharasser or field of study. This research can be beneficial to researchers in\nfurther investigation of this paper's dataset, and to policymakers in improving\nexisting policies to create a safe and supportive environment in academia.", "published": "2019-12-11 07:37:45", "link": "http://arxiv.org/abs/2001.11552v1", "categories": ["physics.soc-ph", "cs.CL", "cs.CY", "cs.SI", "stat.AP", "stat.ML"], "primary_category": "physics.soc-ph"}
{"title": "Learning to Model Aspects of Hearing Perception Using Neural Loss\n  Functions", "abstract": "We present a framework to model the perceived quality of audio signals by\ncombining convolutional architectures, with ideas from classical signal\nprocessing, and describe an approach to enhancing perceived acoustical quality.\nWe demonstrate the approach by transforming the sound of an inexpensive musical\nwith degraded sound quality to that of a high-quality musical instrument\nwithout the need for parallel data which is often hard to collect. We adapt the\nclassical approach of a simple adaptive EQ filtering to the objective criterion\nlearned by a neural architecture and optimize it to get the signal of our\ninterest. Since we learn adaptive masks depending on the signal of interest as\nopposed to a fixed transformation for all the inputs, we show that shallow\nneural architectures can achieve the desired result. A simple constraint on the\nobjective and the initialization helps us in avoiding adversarial examples,\nwhich otherwise would have produced noisy, unintelligible audio. We believe\nthat the current framework proposed has enormous applications, in a variety of\nproblems where one can learn a loss function depending on the problem, using a\nneural architecture and optimize it after it has been learned.", "published": "2019-12-11 23:00:13", "link": "http://arxiv.org/abs/1912.05683v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation", "abstract": "Audio data augmentation is a key step in training deep neural networks for\nsolving audio classification tasks. In this paper, we introduce Audiogmenter, a\nnovel audio data augmentation library in MATLAB. We provide 15 different\naugmentation algorithms for raw audio data and 8 for spectrograms. We\nefficiently implemented several augmentation techniques whose usefulness has\nbeen extensively proved in the literature. To the best of our knowledge, this\nis the largest MATLAB audio data augmentation library freely available. We\nvalidate the efficiency of our algorithms evaluating them on the ESC-50\ndataset. The toolbox and its documentation can be downloaded at\nhttps://github.com/LorisNanni/Audiogmenter.", "published": "2019-12-11 17:07:28", "link": "http://arxiv.org/abs/1912.05472v4", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "deepsing: Generating Sentiment-aware Visual Stories using Cross-modal\n  Music Translation", "abstract": "In this paper we propose a deep learning method for performing\nattributed-based music-to-image translation. The proposed method is applied for\nsynthesizing visual stories according to the sentiment expressed by songs. The\ngenerated images aim to induce the same feelings to the viewers, as the\noriginal song does, reinforcing the primary aim of music, i.e., communicating\nfeelings. The process of music-to-image translation poses unique challenges,\nmainly due to the unstable mapping between the different modalities involved in\nthis process. In this paper, we employ a trainable cross-modal translation\nmethod to overcome this limitation, leading to the first, to the best of our\nknowledge, deep learning method for generating sentiment-aware visual stories.\nVarious aspects of the proposed method are extensively evaluated and discussed\nusing different songs.", "published": "2019-12-11 21:46:41", "link": "http://arxiv.org/abs/1912.05654v1", "categories": ["cs.CV", "cs.AI", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Leveraging End-to-End Speech Recognition with Neural Architecture Search", "abstract": "Deep neural networks (DNNs) have been demonstrated to outperform many\ntraditional machine learning algorithms in Automatic Speech Recognition (ASR).\nIn this paper, we show that a large improvement in the accuracy of deep speech\nmodels can be achieved with effective Neural Architecture Optimization at a\nvery low computational cost. Phone recognition tests with the popular\nLibriSpeech and TIMIT benchmarks proved this fact by displaying the ability to\ndiscover and train novel candidate models within a few hours (less than a day)\nmany times faster than the attention-based seq2seq models. Our method achieves\ntest error of 7% Word Error Rate (WER) on the LibriSpeech corpus and 13% Phone\nError Rate (PER) on the TIMIT corpus, on par with state-of-the-art results.", "published": "2019-12-11 08:15:58", "link": "http://arxiv.org/abs/1912.05946v2", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
