{"title": "Through the Lens of Split Vote: Exploring Disagreement, Difficulty and\n  Calibration in Legal Case Outcome Classification", "abstract": "In legal decisions, split votes (SV) occur when judges cannot reach a\nunanimous decision, posing a difficulty for lawyers who must navigate diverse\nlegal arguments and opinions. In high-stakes domains, understanding the\nalignment of perceived difficulty between humans and AI systems is crucial to\nbuild trust. However, existing NLP calibration methods focus on a classifier's\nawareness of predictive performance, measured against the human majority class,\noverlooking inherent human label variation (HLV). This paper explores split\nvotes as naturally observable human disagreement and value pluralism. We\ncollect judges' vote distributions from the European Court of Human Rights\n(ECHR), and present SV-ECHR, a case outcome classification (COC) dataset with\nSV information. We build a taxonomy of disagreement with SV-specific\nsubcategories. We further assess the alignment of perceived difficulty between\nmodels and humans, as well as confidence- and human-calibration of COC models.\nWe observe limited alignment with the judge vote distribution. To our\nknowledge, this is the first systematic exploration of calibration to human\njudgements in legal NLP. Our study underscores the necessity for further\nresearch on measuring and enhancing model calibration considering HLV in legal\ndecision tasks.", "published": "2024-02-11 14:21:37", "link": "http://arxiv.org/abs/2402.07214v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Previously on the Stories: Recap Snippet Identification for Story\n  Reading", "abstract": "Similar to the \"previously-on\" scenes in TV shows, recaps can help book\nreading by recalling the readers' memory about the important elements in\nprevious texts to better understand the ongoing plot. Despite its usefulness,\nthis application has not been well studied in the NLP community. We propose the\nfirst benchmark on this useful task called Recap Snippet Identification with a\nhand-crafted evaluation dataset. Our experiments show that the proposed task is\nchallenging to PLMs, LLMs, and proposed methods as the task requires a deep\nunderstanding of the plot correlation between snippets.", "published": "2024-02-11 18:27:14", "link": "http://arxiv.org/abs/2402.07271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beware of Words: Evaluating the Lexical Diversity of Conversational LLMs\n  using ChatGPT as Case Study", "abstract": "The performance of conversational Large Language Models (LLMs) in general,\nand of ChatGPT in particular, is currently being evaluated on many different\ntasks, from logical reasoning or maths to answering questions on a myriad of\ntopics. Instead, much less attention is being devoted to the study of the\nlinguistic features of the texts generated by these LLMs. This is surprising\nsince LLMs are models for language, and understanding how they use the language\nis important. Indeed, conversational LLMs are poised to have a significant\nimpact on the evolution of languages as they may eventually dominate the\ncreation of new text. This means that for example, if conversational LLMs do\nnot use a word it may become less and less frequent and eventually stop being\nused altogether. Therefore, evaluating the linguistic features of the text they\nproduce and how those depend on the model parameters is the first step toward\nunderstanding the potential impact of conversational LLMs on the evolution of\nlanguages. In this paper, we consider the evaluation of the lexical richness of\nthe text generated by LLMs and how it depends on the model parameters. A\nmethodology is presented and used to conduct a comprehensive evaluation of\nlexical richness using ChatGPT as a case study. The results show how lexical\nrichness depends on the version of ChatGPT and some of its parameters, such as\nthe presence penalty, or on the role assigned to the model. The dataset and\ntools used in our analysis are released under open licenses with the goal of\ndrawing the much-needed attention to the evaluation of the linguistic features\nof LLM-generated text.", "published": "2024-02-11 13:41:17", "link": "http://arxiv.org/abs/2402.15518v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Large Language Models for Student-Code Guided Test Case Generation\n  in Computer Science Education", "abstract": "In computer science education, test cases are an integral part of programming\nassignments since they can be used as assessment items to test students'\nprogramming knowledge and provide personalized feedback on student-written\ncode. The goal of our work is to propose a fully automated approach for test\ncase generation that can accurately measure student knowledge, which is\nimportant for two reasons. First, manually constructing test cases requires\nexpert knowledge and is a labor-intensive process. Second, developing test\ncases for students, especially those who are novice programmers, is\nsignificantly different from those oriented toward professional-level software\ndevelopers. Therefore, we need an automated process for test case generation to\nassess student knowledge and provide feedback. In this work, we propose a large\nlanguage model-based approach to automatically generate test cases and show\nthat they are good measures of student knowledge, using a publicly available\ndataset that contains student-written Java code. We also discuss future\nresearch directions centered on using test cases to help students.", "published": "2024-02-11 01:37:48", "link": "http://arxiv.org/abs/2402.07081v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Generalizing Conversational Dense Retrieval via LLM-Cognition Data\n  Augmentation", "abstract": "Conversational search utilizes muli-turn natural language contexts to\nretrieve relevant passages. Existing conversational dense retrieval models\nmostly view a conversation as a fixed sequence of questions and responses,\noverlooking the severe data sparsity problem -- that is, users can perform a\nconversation in various ways, and these alternate conversations are unrecorded.\nConsequently, they often struggle to generalize to diverse conversations in\nreal-world scenarios. In this work, we propose a framework for generalizing\nConversational dense retrieval via LLM-cognition data Augmentation (ConvAug).\nConvAug first generates multi-level augmented conversations to capture the\ndiverse nature of conversational contexts. Inspired by human cognition, we\ndevise a cognition-aware process to mitigate the generation of false positives,\nfalse negatives, and hallucinations. Moreover, we develop a difficulty-adaptive\nsample filter that selects challenging samples for complex conversations,\nthereby giving the model a larger learning space. A contrastive learning\nobjective is then employed to train a better conversational context encoder.\nExtensive experiments conducted on four public datasets, under both normal and\nzero-shot settings, demonstrate the effectiveness, generalizability, and\napplicability of ConvAug. The code is released at\nhttps://github.com/haon-chen/ConvAug.", "published": "2024-02-11 03:27:22", "link": "http://arxiv.org/abs/2402.07092v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompt Perturbation in Retrieval-Augmented Generation based Large\n  Language Models", "abstract": "The robustness of large language models (LLMs) becomes increasingly important\nas their use rapidly grows in a wide range of domains. Retrieval-Augmented\nGeneration (RAG) is considered as a means to improve the trustworthiness of\ntext generation from LLMs. However, how the outputs from RAG-based LLMs are\naffected by slightly different inputs is not well studied. In this work, we\nfind that the insertion of even a short prefix to the prompt leads to the\ngeneration of outputs far away from factually correct answers. We\nsystematically evaluate the effect of such prefixes on RAG by introducing a\nnovel optimization technique called Gradient Guided Prompt Perturbation (GGPP).\nGGPP achieves a high success rate in steering outputs of RAG-based LLMs to\ntargeted wrong answers. It can also cope with instructions in the prompts\nrequesting to ignore irrelevant context. We also exploit LLMs' neuron\nactivation difference between prompts with and without GGPP perturbations to\ngive a method that improves the robustness of RAG-based LLMs through a highly\neffective detector trained on neuron activation triggered by GGPP generated\nprompts. Our evaluation on open-sourced LLMs demonstrates the effectiveness of\nour methods.", "published": "2024-02-11 12:25:41", "link": "http://arxiv.org/abs/2402.07179v3", "categories": ["cs.CL", "cs.IR", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "TransGPT: Multi-modal Generative Pre-trained Transformer for\n  Transportation", "abstract": "Natural language processing (NLP) is a key component of intelligent\ntransportation systems (ITS), but it faces many challenges in the\ntransportation domain, such as domain-specific knowledge and data, and\nmulti-modal inputs and outputs. This paper presents TransGPT, a novel\n(multi-modal) large language model for the transportation domain, which\nconsists of two independent variants: TransGPT-SM for single-modal data and\nTransGPT-MM for multi-modal data. TransGPT-SM is finetuned on a single-modal\nTransportation dataset (STD) that contains textual data from various sources in\nthe transportation domain. TransGPT-MM is finetuned on a multi-modal\nTransportation dataset (MTD) that we manually collected from three areas of the\ntransportation domain: driving tests, traffic signs, and landmarks. We evaluate\nTransGPT on several benchmark datasets for different tasks in the\ntransportation domain, and show that it outperforms baseline models on most\ntasks. We also showcase the potential applications of TransGPT for traffic\nanalysis and modeling, such as generating synthetic traffic scenarios,\nexplaining traffic phenomena, answering traffic-related questions, providing\ntraffic recommendations, and generating traffic reports. This work advances the\nstate-of-the-art of NLP in the transportation domain and provides a useful tool\nfor ITS researchers and practitioners.", "published": "2024-02-11 15:50:35", "link": "http://arxiv.org/abs/2402.07233v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "American Sign Language Video to Text Translation", "abstract": "Sign language to text is a crucial technology that can break down\ncommunication barriers for individuals with hearing difficulties. We replicate\nand try to improve on a recently published study. We evaluate models using BLEU\nand rBLEU metrics to ensure translation quality. During our ablation study, we\nfound that the model's performance is significantly influenced by optimizers,\nactivation functions, and label smoothing. Further research aims to refine\nvisual feature capturing, enhance decoder utilization, and integrate\npre-trained decoders for better translation outcomes. Our source code is\navailable to facilitate replication of our results and encourage future\nresearch.", "published": "2024-02-11 17:46:33", "link": "http://arxiv.org/abs/2402.07255v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Low-Resource Counterspeech Generation for Indic Languages: The Case of\n  Bengali and Hindi", "abstract": "With the rise of online abuse, the NLP community has begun investigating the\nuse of neural architectures to generate counterspeech that can \"counter\" the\nvicious tone of such abusive speech and dilute/ameliorate their rippling effect\nover the social network. However, most of the efforts so far have been\nprimarily focused on English. To bridge the gap for low-resource languages such\nas Bengali and Hindi, we create a benchmark dataset of 5,062 abusive\nspeech/counterspeech pairs, of which 2,460 pairs are in Bengali and 2,602 pairs\nare in Hindi. We implement several baseline models considering various\ninterlingual transfer mechanisms with different configurations to generate\nsuitable counterspeech to set up an effective benchmark. We observe that the\nmonolingual setup yields the best performance. Further, using synthetic\ntransfer, language models can generate counterspeech to some extent;\nspecifically, we notice that transferability is better when languages belong to\nthe same language family.", "published": "2024-02-11 18:09:50", "link": "http://arxiv.org/abs/2402.07262v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Summing Up the Facts: Additive Mechanisms Behind Factual Recall in LLMs", "abstract": "How do transformer-based large language models (LLMs) store and retrieve\nknowledge? We focus on the most basic form of this task -- factual recall,\nwhere the model is tasked with explicitly surfacing stored facts in prompts of\nform `Fact: The Colosseum is in the country of'. We find that the mechanistic\nstory behind factual recall is more complex than previously thought. It\ncomprises several distinct, independent, and qualitatively different mechanisms\nthat additively combine, constructively interfering on the correct attribute.\nWe term this generic phenomena the additive motif: models compute through\nsumming up multiple independent contributions. Each mechanism's contribution\nmay be insufficient alone, but summing results in constructive interfere on the\ncorrect answer. In addition, we extend the method of direct logit attribution\nto attribute an attention head's output to individual source tokens. We use\nthis technique to unpack what we call `mixed heads' -- which are themselves a\npair of two separate additive updates from different source tokens.", "published": "2024-02-11 22:58:49", "link": "http://arxiv.org/abs/2402.07321v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Using Large Language Models to Automate and Expedite Reinforcement\n  Learning with Reward Machine", "abstract": "We present LARL-RM (Large language model-generated Automaton for\nReinforcement Learning with Reward Machine) algorithm in order to encode\nhigh-level knowledge into reinforcement learning using automaton to expedite\nthe reinforcement learning. Our method uses Large Language Models (LLM) to\nobtain high-level domain-specific knowledge using prompt engineering instead of\nproviding the reinforcement learning algorithm directly with the high-level\nknowledge which requires an expert to encode the automaton. We use\nchain-of-thought and few-shot methods for prompt engineering and demonstrate\nthat our method works using these approaches. Additionally, LARL-RM allows for\nfully closed-loop reinforcement learning without the need for an expert to\nguide and supervise the learning since LARL-RM can use the LLM directly to\ngenerate the required high-level knowledge for the task at hand. We also show\nthe theoretical guarantee of our algorithm to converge to an optimal policy. We\ndemonstrate that LARL-RM speeds up the convergence by 30% by implementing our\nmethod in two case studies.", "published": "2024-02-11 00:00:05", "link": "http://arxiv.org/abs/2402.07069v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Speech Rhythm-Based Speaker Embeddings Extraction from Phonemes and\n  Phoneme Duration for Multi-Speaker Speech Synthesis", "abstract": "This paper proposes a speech rhythm-based method for speaker embeddings to\nmodel phoneme duration using a few utterances by the target speaker. Speech\nrhythm is one of the essential factors among speaker characteristics, along\nwith acoustic features such as F0, for reproducing individual utterances in\nspeech synthesis. A novel feature of the proposed method is the rhythm-based\nembeddings extracted from phonemes and their durations, which are known to be\nrelated to speaking rhythm. They are extracted with a speaker identification\nmodel similar to the conventional spectral feature-based one. We conducted\nthree experiments, speaker embeddings generation, speech synthesis with\ngenerated embeddings, and embedding space analysis, to evaluate the\nperformance. The proposed method demonstrated a moderate speaker identification\nperformance (15.2% EER), even with only phonemes and their duration\ninformation. The objective and subjective evaluation results demonstrated that\nthe proposed method can synthesize speech with speech rhythm closer to the\ntarget speaker than the conventional method. We also visualized the embeddings\nto evaluate the relationship between the distance of the embeddings and the\nperceptual similarity. The visualization of the embedding space and the\nrelation analysis between the closeness indicated that the distribution of\nembeddings reflects the subjective and objective similarity.", "published": "2024-02-11 02:26:43", "link": "http://arxiv.org/abs/2402.07085v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Natural Language Reinforcement Learning", "abstract": "Reinforcement Learning (RL) has shown remarkable abilities in learning\npolicies for decision-making tasks. However, RL is often hindered by issues\nsuch as low sample efficiency, lack of interpretability, and sparse supervision\nsignals. To tackle these limitations, we take inspiration from the human\nlearning process and introduce Natural Language Reinforcement Learning (NLRL),\nwhich innovatively combines RL principles with natural language representation.\nSpecifically, NLRL redefines RL concepts like task objectives, policy, value\nfunction, Bellman equation, and policy iteration in natural language space. We\npresent how NLRL can be practically implemented with the latest advancements in\nlarge language models (LLMs) like GPT-4. Initial experiments over tabular MDPs\ndemonstrate the effectiveness, efficiency, and also interpretability of the\nNLRL framework.", "published": "2024-02-11 11:03:04", "link": "http://arxiv.org/abs/2402.07157v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ITINERA: Integrating Spatial Optimization with Large Language Models for\n  Open-domain Urban Itinerary Planning", "abstract": "Citywalk, a recently popular form of urban travel, requires genuine\npersonalization and understanding of fine-grained requests compared to\ntraditional itinerary planning. In this paper, we introduce the novel task of\nOpen-domain Urban Itinerary Planning (OUIP), which generates personalized urban\nitineraries from user requests in natural language. We then present ITINERA, an\nOUIP system that integrates spatial optimization with large language models to\nprovide customized urban itineraries based on user needs. This involves\ndecomposing user requests, selecting candidate points of interest (POIs),\nordering the POIs based on cluster-aware spatial optimization, and generating\nthe itinerary. Experiments on real-world datasets and the performance of the\ndeployed system demonstrate our system's capacity to deliver personalized and\nspatially coherent itineraries compared to current solutions. Source codes of\nITINERA are available at https://github.com/YihongT/ITINERA.", "published": "2024-02-11 13:30:53", "link": "http://arxiv.org/abs/2402.07204v5", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Open-ended VQA benchmarking of Vision-Language models by exploiting\n  Classification datasets and their semantic hierarchy", "abstract": "The evaluation of text-generative vision-language models is a challenging yet\ncrucial endeavor. By addressing the limitations of existing Visual Question\nAnswering (VQA) benchmarks and proposing innovative evaluation methodologies,\nour research seeks to advance our understanding of these models' capabilities.\nWe propose a novel VQA benchmark based on well-known visual classification\ndatasets which allows a granular evaluation of text-generative vision-language\nmodels and their comparison with discriminative vision-language models. To\nimprove the assessment of coarse answers on fine-grained classification tasks,\nwe suggest using the semantic hierarchy of the label space to ask automatically\ngenerated follow-up questions about the ground-truth category. Finally, we\ncompare traditional NLP and LLM-based metrics for the problem of evaluating\nmodel predictions given ground-truth answers. We perform a human evaluation\nstudy upon which we base our decision on the final metric. We apply our\nbenchmark to a suite of vision-language models and show a detailed comparison\nof their abilities on object, action, and attribute classification. Our\ncontributions aim to lay the foundation for more precise and meaningful\nassessments, facilitating targeted progress in the exciting field of\nvision-language modeling.", "published": "2024-02-11 18:26:18", "link": "http://arxiv.org/abs/2402.07270v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "How do Large Language Models Navigate Conflicts between Honesty and\n  Helpfulness?", "abstract": "In day-to-day communication, people often approximate the truth - for\nexample, rounding the time or omitting details - in order to be maximally\nhelpful to the listener. How do large language models (LLMs) handle such\nnuanced trade-offs? To address this question, we use psychological models and\nexperiments designed to characterize human behavior to analyze LLMs. We test a\nrange of LLMs and explore how optimization for human preferences or\ninference-time reasoning affects these trade-offs. We find that reinforcement\nlearning from human feedback improves both honesty and helpfulness, while\nchain-of-thought prompting skews LLMs towards helpfulness over honesty.\nFinally, GPT-4 Turbo demonstrates human-like response patterns including\nsensitivity to the conversational framing and listener's decision context. Our\nfindings reveal the conversational values internalized by LLMs and suggest that\neven these abstract values can, to a degree, be steered by zero-shot prompting.", "published": "2024-02-11 19:13:26", "link": "http://arxiv.org/abs/2402.07282v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Power Transformer Fault Prediction Based on Knowledge Graphs", "abstract": "In this paper, we address the challenge of learning with limited fault data\nfor power transformers. Traditional operation and maintenance tools lack\neffective predictive capabilities for potential faults. The scarcity of\nextensive fault data makes it difficult to apply machine learning techniques\neffectively. To solve this problem, we propose a novel approach that leverages\nthe knowledge graph (KG) technology in combination with gradient boosting\ndecision trees (GBDT). This method is designed to efficiently learn from a\nsmall set of high-dimensional data, integrating various factors influencing\ntransformer faults and historical operational data. Our approach enables\naccurate safe state assessments and fault analyses of power transformers\ndespite the limited fault characteristic data. Experimental results demonstrate\nthat this method outperforms other learning approaches in prediction accuracy,\nsuch as artificial neural networks (ANN) and logistic regression (LR).\nFurthermore, it offers significant improvements in progressiveness,\npracticality, and potential for widespread application.", "published": "2024-02-11 19:14:28", "link": "http://arxiv.org/abs/2402.07283v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node\n  Classification on Text-Attributed Hypergraphs", "abstract": "Hypergraphs are characterized by complex topological structure, representing\nhigher-order interactions among multiple entities through hyperedges. Lately,\nhypergraph-based deep learning methods to learn informative data\nrepresentations for the problem of node classification on text-attributed\nhypergraphs have garnered increasing research attention. However, existing\nmethods struggle to simultaneously capture the full extent of hypergraph\nstructural information and the rich linguistic attributes inherent in the nodes\nattributes, which largely hampers their effectiveness and generalizability. To\novercome these challenges, we explore ways to further augment a pretrained BERT\nmodel with specialized hypergraph-aware layers for the task of node\nclassification. Such layers introduce higher-order structural inductive bias\ninto the language model, thus improving the model's capacity to harness both\nhigher-order context information from the hypergraph structure and semantic\ninformation present in text. In this paper, we propose a new architecture,\nHyperBERT, a mixed text-hypergraph model which simultaneously models hypergraph\nrelational structure while maintaining the high-quality text encoding\ncapabilities of a pre-trained BERT. Notably, HyperBERT presents results that\nachieve a new state-of-the-art on five challenging text-attributed hypergraph\nnode classification benchmarks.", "published": "2024-02-11 21:16:26", "link": "http://arxiv.org/abs/2402.07309v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ODIN: Disentangled Reward Mitigates Hacking in RLHF", "abstract": "In this work, we study the issue of reward hacking on the response length, a\nchallenge emerging in Reinforcement Learning from Human Feedback (RLHF) on\nLLMs. A well-formatted, verbose but less helpful response from the LLMs can\noften deceive LLMs or even human evaluators to achieve high scores. The same\nissue also holds for some reward models in RL. To address the challenges in\nboth training and evaluation, we establish a more reliable evaluation protocol\nfor comparing different training configurations, which inspects the trade-off\nbetween LLM evaluation score and response length obtained by varying training\nhyperparameters. Based on this evaluation, we conduct large-scale studies,\nwhere the results shed insights into the efficacy of hyperparameters and tricks\nused in RL on mitigating length bias. We further propose to improve the reward\nmodel by jointly training two linear heads on shared feature representations to\npredict the rewards, one trained to correlate with length, and the other\ntrained to decorrelate with length and therefore focus more on the actual\ncontent. We then discard the length head in RL to prevent reward hacking on\nlength. Experiments demonstrate that our approach almost eliminates the reward\ncorrelation with length, and improves the obtained policy by a significant\nmargin.", "published": "2024-02-11 22:40:12", "link": "http://arxiv.org/abs/2402.07319v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for\n  Large Language Models with Applications in Protein Mechanics and Molecular\n  Design", "abstract": "We report a mixture of expert strategy to create fine-tuned large language\nmodels using a deep layer-wise token-level approach based on low-rank\nadaptation (LoRA). Starting with a set of pre-trained LoRA adapters, our gating\nstrategy uses the hidden states to dynamically mix adapted layers, allowing the\nresulting X-LoRA model to draw upon different capabilities and create\nnever-before-used deep layer-wise combinations to solve tasks. The design is\ninspired by the biological principles of universality and diversity, where\nneural network building blocks are reused in different hierarchical\nmanifestations. Hence, the X-LoRA model can be easily implemented for any\nexisting large language model (LLM) without a need for modifications of the\nunderlying structure. We develop a tailored X-LoRA model that offers scientific\ncapabilities including forward/inverse analysis tasks and enhanced reasoning\ncapability, focused on biomaterial analysis, protein mechanics and design. The\nimpact of this work include access to readily expandable and adaptable models\nwith strong domain knowledge and the capability to integrate across areas of\nknowledge. Featuring experts in biology, mathematics, reasoning, bio-inspired\nmaterials, mechanics and materials, chemistry, protein biophysics, mechanics\nand quantum-mechanics based molecular properties, we conduct a series of\nphysics-focused case studies. We examine knowledge recall, protein mechanics\nforward/inverse tasks, protein design, adversarial agentic modeling including\nontological knowledge graph construction, as well as molecular design. The\nmodel is capable not only of making quantitative predictions of nanomechanical\nproperties of proteins or quantum mechanical molecular properties, but also\nreasons over the results and correctly predicts likely mechanisms that explain\ndistinct molecular behaviors.", "published": "2024-02-11 10:23:34", "link": "http://arxiv.org/abs/2402.07148v2", "categories": ["cond-mat.soft", "cond-mat.dis-nn", "cs.AI", "cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "cond-mat.soft"}
{"title": "Persian Speech Emotion Recognition by Fine-Tuning Transformers", "abstract": "Given the significance of speech emotion recognition, numerous methods have\nbeen developed in recent years to create effective and efficient systems in\nthis domain. One of these methods involves the use of pretrained transformers,\nfine-tuned to address this specific problem, resulting in high accuracy.\nDespite extensive discussions and global-scale efforts to enhance these\nsystems, the application of this innovative and effective approach has received\nless attention in the context of Persian speech emotion recognition. In this\narticle, we review the field of speech emotion recognition and its background,\nwith an emphasis on the importance of employing transformers in this context.\nWe present two models, one based on spectrograms and the other on the audio\nitself, fine-tuned using the shEMO dataset. These models significantly enhance\nthe accuracy of previous systems, increasing it from approximately 65% to 80%\non the mentioned dataset. Subsequently, to investigate the effect of\nmultilinguality on the fine-tuning process, these same models are fine-tuned\ntwice. First, they are fine-tuned using the English IEMOCAP dataset, and then\nthey are fine-tuned with the Persian shEMO dataset. This results in an improved\naccuracy of 82% for the Persian emotion recognition system. Keywords: Persian\nSpeech Emotion Recognition, shEMO, Self-Supervised Learning", "published": "2024-02-11 23:23:31", "link": "http://arxiv.org/abs/2402.07326v1", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
