{"title": "Capturing document context inside sentence-level neural machine\n  translation models with self-training", "abstract": "Neural machine translation (NMT) has arguably achieved human level parity\nwhen trained and evaluated at the sentence-level. Document-level neural machine\ntranslation has received less attention and lags behind its sentence-level\ncounterpart. The majority of the proposed document-level approaches investigate\nways of conditioning the model on several source or target sentences to capture\ndocument context. These approaches require training a specialized NMT model\nfrom scratch on parallel document-level corpora. We propose an approach that\ndoesn't require training a specialized model on parallel document-level corpora\nand is applied to a trained sentence-level NMT model at decoding time. We\nprocess the document from left to right multiple times and self-train the\nsentence-level model on pairs of source sentences and generated translations.\nOur approach reinforces the choices made by the model, thus making it more\nlikely that the same choices will be made in other sentences in the document.\nWe evaluate our approach on three document-level datasets: NIST\nChinese-English, WMT'19 Chinese-English and OpenSubtitles English-Russian. We\ndemonstrate that our approach has higher BLEU score and higher human preference\nthan the baseline. Qualitative analysis of our approach shows that choices made\nby model are consistent across the document.", "published": "2020-03-11 12:36:17", "link": "http://arxiv.org/abs/2003.05259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Precisely Xtreme-Multi Channel Hybrid Approach For Roman Urdu\n  Sentiment Analysis", "abstract": "In order to accelerate the performance of various Natural Language Processing\ntasks for Roman Urdu, this paper for the very first time provides 3 neural word\nembeddings prepared using most widely used approaches namely Word2vec,\nFastText, and Glove. The integrity of generated neural word embeddings is\nevaluated using intrinsic and extrinsic evaluation approaches. Considering the\nlack of publicly available benchmark datasets, it provides a first-ever Roman\nUrdu dataset which consists of 3241 sentiments annotated against positive,\nnegative and neutral classes. To provide benchmark baseline performance over\nthe presented dataset, we adapt diverse machine learning (Support Vector\nMachine Logistic Regression, Naive Bayes), deep learning (convolutional neural\nnetwork, recurrent neural network), and hybrid approaches. Effectiveness of\ngenerated neural word embeddings is evaluated by comparing the performance of\nmachine and deep learning based methodologies using 7, and 5 distinct feature\nrepresentation approaches respectively. Finally, it proposes a novel precisely\nextreme multi-channel hybrid methodology which outperforms state-of-the-art\nadapted machine and deep learning approaches by the figure of 9%, and 4% in\nterms of F1-score. Roman Urdu Sentiment Analysis, Pretrain word embeddings for\nRoman Urdu, Word2Vec, Glove, Fast-Text", "published": "2020-03-11 04:08:27", "link": "http://arxiv.org/abs/2003.05443v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Holism and Word Representations in Artificial Neural Networks", "abstract": "Artificial neural networks are a state-of-the-art solution for many problems\nin natural language processing. What can we learn about language and meaning\nfrom the way artificial neural networks represent it? Word representations\nobtained from the Skip-gram variant of the word2vec model exhibit interesting\nsemantic properties. This is usually explained by referring to the general\ndistributional hypothesis, which states that the meaning of the word is given\nby the contexts where it occurs. We propose a more specific approach based on\nFrege's holistic and functional approach to meaning. Taking Tugendhat's formal\nreinterpretation of Frege's work as a starting point, we demonstrate that it is\nanalogical to the process of training the Skip-gram model and offers a possible\nexplanation of its semantic properties.", "published": "2020-03-11 21:04:49", "link": "http://arxiv.org/abs/2003.05522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keyword-Attentive Deep Semantic Matching", "abstract": "Deep Semantic Matching is a crucial component in various natural language\nprocessing applications such as question and answering (QA), where an input\nquery is compared to each candidate question in a QA corpus in terms of\nrelevance. Measuring similarities between a query-question pair in an open\ndomain scenario can be challenging due to diverse word tokens in the\nqueryquestion pair. We propose a keyword-attentive approach to improve deep\nsemantic matching. We first leverage domain tags from a large corpus to\ngenerate a domain-enhanced keyword dictionary. Built upon BERT, we stack a\nkeyword-attentive transformer layer to highlight the importance of keywords in\nthe query-question pair. During model training, we propose a new negative\nsampling approach based on keyword coverage between the input pair. We evaluate\nour approach on a Chinese QA corpus using various metrics, including precision\nof retrieval candidates and accuracy of semantic matching. Experiments show\nthat our approach outperforms existing strong baselines. Our approach is\ngeneral and can be applied to other text matching tasks with little adaptation.", "published": "2020-03-11 10:18:32", "link": "http://arxiv.org/abs/2003.11516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity Extraction from Wikipedia List Pages", "abstract": "When it comes to factual knowledge about a wide range of domains, Wikipedia\nis often the prime source of information on the web. DBpedia and YAGO, as large\ncross-domain knowledge graphs, encode a subset of that knowledge by creating an\nentity for each page in Wikipedia, and connecting them through edges. It is\nwell known, however, that Wikipedia-based knowledge graphs are far from\ncomplete. Especially, as Wikipedia's policies permit pages about subjects only\nif they have a certain popularity, such graphs tend to lack information about\nless well-known entities. Information about these entities is oftentimes\navailable in the encyclopedia, but not represented as an individual page. In\nthis paper, we present a two-phased approach for the extraction of entities\nfrom Wikipedia's list pages, which have proven to serve as a valuable source of\ninformation. In the first phase, we build a large taxonomy from categories and\nlist pages with DBpedia as a backbone. With distant supervision, we extract\ntraining data for the identification of new entities in list pages that we use\nin the second phase to train a classification model. With this approach we\nextract over 700k new entities and extend DBpedia with 7.5M new type statements\nand 3.8M new facts of high precision.", "published": "2020-03-11 07:48:46", "link": "http://arxiv.org/abs/2003.05146v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Video2Commonsense: Generating Commonsense Descriptions to Enrich Video\n  Captioning", "abstract": "Captioning is a crucial and challenging task for video understanding. In\nvideos that involve active agents such as humans, the agent's actions can bring\nabout myriad changes in the scene. Observable changes such as movements,\nmanipulations, and transformations of the objects in the scene, are reflected\nin conventional video captioning. Unlike images, actions in videos are also\ninherently linked to social aspects such as intentions (why the action is\ntaking place), effects (what changes due to the action), and attributes that\ndescribe the agent. Thus for video understanding, such as when captioning\nvideos or when answering questions about videos, one must have an understanding\nof these commonsense aspects. We present the first work on generating\ncommonsense captions directly from videos, to describe latent aspects such as\nintentions, effects, and attributes. We present a new dataset\n\"Video-to-Commonsense (V2C)\" that contains $\\sim9k$ videos of human agents\nperforming various actions, annotated with 3 types of commonsense descriptions.\nAdditionally we explore the use of open-ended video-based commonsense question\nanswering (V2C-QA) as a way to enrich our captions. Both the generation task\nand the QA task can be used to enrich video captions.", "published": "2020-03-11 08:42:57", "link": "http://arxiv.org/abs/2003.05162v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Vector symbolic architectures for context-free grammars", "abstract": "Background / introduction. Vector symbolic architectures (VSA) are a viable\napproach for the hyperdimensional representation of symbolic data, such as\ndocuments, syntactic structures, or semantic frames. Methods. We present a\nrigorous mathematical framework for the representation of phrase structure\ntrees and parse trees of context-free grammars (CFG) in Fock space, i.e.\ninfinite-dimensional Hilbert space as being used in quantum field theory. We\ndefine a novel normal form for CFG by means of term algebras. Using a recently\ndeveloped software toolbox, called FockBox, we construct Fock space\nrepresentations for the trees built up by a CFG left-corner (LC) parser.\nResults. We prove a universal representation theorem for CFG term algebras in\nFock space and illustrate our findings through a low-dimensional principal\ncomponent projection of the LC parser states. Conclusions. Our approach could\nleverage the development of VSA for explainable artificial intelligence (XAI)\nby means of hyperdimensional deep neural computation. It could be of\nsignificance for the improvement of cognitive user interfaces and other\napplications of VSA in machine learning.", "published": "2020-03-11 09:07:02", "link": "http://arxiv.org/abs/2003.05171v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Investigating Entity Knowledge in BERT with Simple Neural End-To-End\n  Entity Linking", "abstract": "A typical architecture for end-to-end entity linking systems consists of\nthree steps: mention detection, candidate generation and entity disambiguation.\nIn this study we investigate the following questions: (a) Can all those steps\nbe learned jointly with a model for contextualized text-representations, i.e.\nBERT (Devlin et al., 2019)? (b) How much entity knowledge is already contained\nin pretrained BERT? (c) Does additional entity knowledge improve BERT's\nperformance in downstream tasks? To this end, we propose an extreme\nsimplification of the entity linking setup that works surprisingly well: simply\ncast it as a per token classification over the entire entity vocabulary (over\n700K classes in our case). We show on an entity linking benchmark that (i) this\nmodel improves the entity representations over plain BERT, (ii) that it\noutperforms entity linking architectures that optimize the tasks separately and\n(iii) that it only comes second to the current state-of-the-art that does\nmention detection and entity disambiguation jointly. Additionally, we\ninvestigate the usefulness of entity-aware token-representations in the\ntext-understanding benchmark GLUE, as well as the question answering benchmarks\nSQUAD V2 and SWAG and also the EN-DE WMT14 machine translation benchmark. To\nour surprise, we find that most of those benchmarks do not benefit from\nadditional entity knowledge, except for a task with very small training data,\nthe RTE task in GLUE, which improves by 2%.", "published": "2020-03-11 18:23:00", "link": "http://arxiv.org/abs/2003.05473v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Algebraic Word Problem to Program: A Formalized Approach", "abstract": "In this paper, we propose a pipeline to convert grade school level algebraic\nword problem into program of a formal languageA-IMP. Using natural language\nprocessing tools, we break the problem into sentence fragments which can then\nbe reduced to functions. The functions are categorized by the head verb of the\nsentence and its structure, as defined by (Hosseini et al., 2014). We define\nthe function signature and extract its arguments from the text using dependency\nparsing. We have a working implementation of the entire pipeline which can be\nfound on our github repository.", "published": "2020-03-11 20:55:01", "link": "http://arxiv.org/abs/2003.11517v2", "categories": ["cs.CL", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Visual Grounding in Video for Unsupervised Word Translation", "abstract": "There are thousands of actively spoken languages on Earth, but a single\nvisual world. Grounding in this visual world has the potential to bridge the\ngap between all these languages. Our goal is to use visual grounding to improve\nunsupervised word mapping between languages. The key idea is to establish a\ncommon visual representation between two languages by learning embeddings from\nunpaired instructional videos narrated in the native language. Given this\nshared embedding we demonstrate that (i) we can map words between the\nlanguages, particularly the 'visual' words; (ii) that the shared embedding\nprovides a good initialization for existing unsupervised text-based word\ntranslation techniques, forming the basis for our proposed hybrid visual-text\nmapping algorithm, MUVE; and (iii) our approach achieves superior performance\nby addressing the shortcomings of text-based methods -- it is more robust,\nhandles datasets with less commonality, and is applicable to low-resource\nlanguages. We apply these methods to translate words from English to French,\nKorean, and Japanese -- all without any parallel corpora and simply by watching\nmany videos of people speaking while doing things.", "published": "2020-03-11 02:03:37", "link": "http://arxiv.org/abs/2003.05078v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Benchmark for Systematic Generalization in Grounded Language\n  Understanding", "abstract": "Humans easily interpret expressions that describe unfamiliar situations\ncomposed from familiar parts (\"greet the pink brontosaurus by the ferris\nwheel\"). Modern neural networks, by contrast, struggle to interpret novel\ncompositions. In this paper, we introduce a new benchmark, gSCAN, for\nevaluating compositional generalization in situated language understanding.\nGoing beyond a related benchmark that focused on syntactic aspects of\ngeneralization, gSCAN defines a language grounded in the states of a grid\nworld, facilitating novel evaluations of acquiring linguistically motivated\nrules. For example, agents must understand how adjectives such as 'small' are\ninterpreted relative to the current world state or how adverbs such as\n'cautiously' combine with new verbs. We test a strong multi-modal baseline\nmodel and a state-of-the-art compositional method finding that, in most cases,\nthey fail dramatically when generalization requires systematic compositional\nrules.", "published": "2020-03-11 08:40:15", "link": "http://arxiv.org/abs/2003.05161v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Expressiveness and machine processability of Knowledge Organization\n  Systems (KOS): An analysis of concepts and relations", "abstract": "This study considers the expressiveness (that is the expressive power or\nexpressivity) of different types of Knowledge Organization Systems (KOS) and\ndiscusses its potential to be machine-processable in the context of the\nSemantic Web. For this purpose, the theoretical foundations of KOS are reviewed\nbased on conceptualizations introduced by the Functional Requirements for\nSubject Authority Data (FRSAD) and the Simple Knowledge Organization System\n(SKOS); natural language processing techniques are also implemented. Applying a\ncomparative analysis, the dataset comprises a thesaurus (Eurovoc), a subject\nheadings system (LCSH) and a classification scheme (DDC). These are compared\nwith an ontology (CIDOC-CRM) by focusing on how they define and handle concepts\nand relations. It was observed that LCSH and DDC focus on the formalism of\ncharacter strings (nomens) rather than on the modelling of semantics; their\ndefinition of what constitutes a concept is quite fuzzy, and they comprise a\nlarge number of complex concepts. By contrast, thesauri have a coherent\ndefinition of what constitutes a concept, and apply a systematic approach to\nthe modelling of relations. Ontologies explicitly define diverse types of\nrelations, and are by their nature machine-processable. The paper concludes\nthat the potential of both the expressiveness and machine processability of\neach KOS is extensively regulated by its structural rules. It is harder to\nrepresent subject headings and classification schemes as semantic networks with\nnodes and arcs, while thesauri are more suitable for such a representation. In\naddition, a paradigm shift is revealed which focuses on the modelling of\nrelations between concepts, rather than the concepts themselves.", "published": "2020-03-11 12:35:52", "link": "http://arxiv.org/abs/2003.05258v1", "categories": ["cs.DL", "cs.AI", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Hurtful Words: Quantifying Biases in Clinical Contextual Word Embeddings", "abstract": "In this work, we examine the extent to which embeddings may encode\nmarginalized populations differently, and how this may lead to a perpetuation\nof biases and worsened performance on clinical tasks. We pretrain deep\nembedding models (BERT) on medical notes from the MIMIC-III hospital dataset,\nand quantify potential disparities using two approaches. First, we identify\ndangerous latent relationships that are captured by the contextual word\nembeddings using a fill-in-the-blank method with text from real clinical notes\nand a log probability bias score quantification. Second, we evaluate\nperformance gaps across different definitions of fairness on over 50 downstream\nclinical prediction tasks that include detection of acute and chronic\nconditions. We find that classifiers trained from BERT representations exhibit\nstatistically significant differences in performance, often favoring the\nmajority group with regards to gender, language, ethnicity, and insurance\nstatus. Finally, we explore shortcomings of using adversarial debiasing to\nobfuscate subgroup information in contextual word embeddings, and recommend\nbest practices for such deep embedding models in clinical settings.", "published": "2020-03-11 23:21:14", "link": "http://arxiv.org/abs/2003.11515v1", "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Voice conversion using coefficient mapping and neural network", "abstract": "The research presents a voice conversion model using coefficient mapping and\nneural network. Most previous works on parametric speech synthesis did not\naccount for losses in spectral details causing over smoothing and invariably,\nan appreciable deviation of the converted speech from the targeted speaker. An\nimproved model that uses both linear predictive coding (LPC) and line spectral\nfrequency (LSF) coefficients to parametrize the source speech signal was\ndeveloped in this work to reveal the effect of over-smoothing. Non-linear\nmapping ability of neural network was employed in mapping the source speech\nvectors into the acoustic vector space of the target. Training LPC coefficients\nwith neural network yielded a poor result due to the instability of the LPC\nfilter poles. The LPC coefficients were converted to line spectral frequency\ncoefficients before been trained with a 3-layer neural network. The algorithm\nwas tested with noisy data with the result evaluated using Mel-Cepstral\nDistance measurement. Cepstral distance evaluation shows a 35.7 percent\nreduction in the spectral distance between the target and the converted speech.", "published": "2020-03-11 09:30:21", "link": "http://arxiv.org/abs/2003.05184v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Robust Audio Watermarking Using Graph-based Transform and Singular Value\n  Decomposition", "abstract": "Graph-based Transform (GT) has been recently leveraged successfully in the\nsignal processing domain, specifically for compression purposes. In this paper,\nwe employ the GBT, as well as the Singular Value Decomposition (SVD) with the\ngoal to improve the robustness of audio watermarking against different attacks\non the audio signals, such as noise and compression. Experimental results on\nthe NOIZEUS speech database and MIR-1k music database clearly certify that the\nproposed GBT-SVD-based method is robust against the attacks. Moreover, the\nresults exhibit a good quality after the embedding based on PSNR, PESQ, and\nSTOI measures. Also, the payload for the proposed method is 800 and 1600 for\nspeech and music signals, respectively which are higher than some robust\nwatermarking methods such as DWT-SVD and DWT-DCT.", "published": "2020-03-11 11:25:41", "link": "http://arxiv.org/abs/2003.05223v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
