{"title": "Text Modeling with Syntax-Aware Variational Autoencoders", "abstract": "Syntactic information contains structures and rules about how text sentences\nare arranged. Incorporating syntax into text modeling methods can potentially\nbenefit both representation learning and generation. Variational autoencoders\n(VAEs) are deep generative models that provide a probabilistic way to describe\nobservations in the latent space. When applied to text data, the latent\nrepresentations are often unstructured. We propose syntax-aware variational\nautoencoders (SAVAEs) that dedicate a subspace in the latent dimensions dubbed\nsyntactic latent to represent syntactic structures of sentences. SAVAEs are\ntrained to infer syntactic latent from either text inputs or parsed syntax\nresults as well as reconstruct original text with inferred latent variables.\nExperiments show that SAVAEs are able to achieve lower reconstruction loss on\nfour different data sets. Furthermore, they are capable of generating examples\nwith modified target syntax.", "published": "2019-08-27 00:25:06", "link": "http://arxiv.org/abs/1908.09964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model\n  Compression", "abstract": "Despite their ubiquity in NLP tasks, Long Short-Term Memory (LSTM) networks\nsuffer from computational inefficiencies caused by inherent unparallelizable\nrecurrences, which further aggravates as LSTMs require more parameters for\nlarger memory capacity. In this paper, we propose to apply low-rank matrix\nfactorization (MF) algorithms to different recurrences in LSTMs, and explore\nthe effectiveness on different NLP tasks and model components. We discover that\nadditive recurrence is more important than multiplicative recurrence, and\nexplain this by identifying meaningful correlations between matrix norms and\ncompression performance. We compare our approach across two settings: 1)\ncompressing core LSTM recurrences in language models, 2) compressing biLSTM\nlayers of ELMo evaluated in three downstream NLP tasks.", "published": "2019-08-27 01:52:07", "link": "http://arxiv.org/abs/1908.09982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine\n  Spoken Conversations", "abstract": "Dialog act prediction is an essential language comprehension task for both\ndialog system building and discourse analysis. Previous dialog act schemes,\nsuch as SWBD-DAMSL, are designed for human-human conversations, in which\nconversation partners have perfect language understanding ability. In this\npaper, we design a dialog act annotation scheme, MIDAS (Machine Interaction\nDialog Act Scheme), targeted on open-domain human-machine conversations. MIDAS\nis designed to assist machines which have limited ability to understand their\nhuman partners. MIDAS has a hierarchical structure and supports multi-label\nannotations. We collected and annotated a large open-domain human-machine\nspoken conversation dataset (consists of 24K utterances). To show the\napplicability of the scheme, we leverage transfer learning methods to train a\nmulti-label dialog act prediction model and reach an F1 score of 0.79.", "published": "2019-08-27 04:36:31", "link": "http://arxiv.org/abs/1908.10023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks", "abstract": "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new\nstate-of-the-art performance on sentence-pair regression tasks like semantic\ntextual similarity (STS). However, it requires that both sentences are fed into\nthe network, which causes a massive computational overhead: Finding the most\nsimilar pair in a collection of 10,000 sentences requires about 50 million\ninference computations (~65 hours) with BERT. The construction of BERT makes it\nunsuitable for semantic similarity search as well as for unsupervised tasks\nlike clustering.\n  In this publication, we present Sentence-BERT (SBERT), a modification of the\npretrained BERT network that use siamese and triplet network structures to\nderive semantically meaningful sentence embeddings that can be compared using\ncosine-similarity. This reduces the effort for finding the most similar pair\nfrom 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while\nmaintaining the accuracy from BERT.\n  We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning\ntasks, where it outperforms other state-of-the-art sentence embeddings methods.", "published": "2019-08-27 08:50:17", "link": "http://arxiv.org/abs/1908.10084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On NMT Search Errors and Model Errors: Cat Got Your Tongue?", "abstract": "We report on search errors and model errors in neural machine translation\n(NMT). We present an exact inference procedure for neural sequence models based\non a combination of beam search and depth-first search. We use our exact search\nto find the global best model scores under a Transformer base model for the\nentire WMT15 English-German test set. Surprisingly, beam search fails to find\nthese global best model scores in most cases, even with a very large beam size\nof 100. For more than 50% of the sentences, the model in fact assigns its\nglobal best score to the empty translation, revealing a massive failure of\nneural models in properly accounting for adequacy. We show by constraining\nsearch with a minimum translation length that at the root of the problem of\nempty translations lies an inherent bias towards shorter translations. We\nconclude that vanilla NMT in its current form requires just the right amount of\nbeam search errors, which, from a modelling perspective, is a highly\nunsatisfactory conclusion indeed, as the model often prefers an empty\ntranslation.", "published": "2019-08-27 09:08:12", "link": "http://arxiv.org/abs/1908.10090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Morpho-Syntactically Informed LSTM-CRF Model for Named Entity\n  Recognition", "abstract": "We propose a morphologically informed model for named entity recognition,\nwhich is based on LSTM-CRF architecture and combines word embeddings, Bi-LSTM\ncharacter embeddings, part-of-speech (POS) tags, and morphological information.\nWhile previous work has focused on learning from raw word input, using word and\ncharacter embeddings only, we show that for morphologically rich languages,\nsuch as Bulgarian, access to POS information contributes more to the\nperformance gains than the detailed morphological information. Thus, we show\nthat named entity recognition needs only coarse-grained POS tags, but at the\nsame time it can benefit from simultaneously using some POS information of\ndifferent granularity. Our evaluation results over a standard dataset show\nsizable improvements over the state-of-the-art for Bulgarian NER.", "published": "2019-08-27 15:10:24", "link": "http://arxiv.org/abs/1908.10261v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Movie Plot Analysis via Turning Point Identification", "abstract": "According to screenwriting theory, turning points (e.g., change of plans,\nmajor setback, climax) are crucial narrative moments within a screenplay: they\ndefine the plot structure, determine its progression and segment the screenplay\ninto thematic units (e.g., setup, complications, aftermath). We propose the\ntask of turning point identification in movies as a means of analyzing their\nnarrative structure. We argue that turning points and the segmentation they\nprovide can facilitate processing long, complex narratives, such as\nscreenplays, for summarization and question answering. We introduce a dataset\nconsisting of screenplays and plot synopses annotated with turning points and\npresent an end-to-end neural network model that identifies turning points in\nplot synopses and projects them onto scenes in screenplays. Our model\noutperforms strong baselines based on state-of-the-art sentence representations\nand the expected position of turning points.", "published": "2019-08-27 16:59:18", "link": "http://arxiv.org/abs/1908.10328v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Meta-Learning Algorithms for Low-Resource Natural Language\n  Understanding Tasks", "abstract": "Learning general representations of text is a fundamental problem for many\nnatural language understanding (NLU) tasks. Previously, researchers have\nproposed to use language model pre-training and multi-task learning to learn\nrobust representations. However, these methods can achieve sub-optimal\nperformance in low-resource scenarios. Inspired by the recent success of\noptimization-based meta-learning algorithms, in this paper, we explore the\nmodel-agnostic meta-learning algorithm (MAML) and its variants for low-resource\nNLU tasks. We validate our methods on the GLUE benchmark and show that our\nproposed models can outperform several strong baselines. We further empirically\ndemonstrate that the learned representations can be adapted to new tasks\nefficiently and effectively.", "published": "2019-08-27 19:26:31", "link": "http://arxiv.org/abs/1908.10423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Domain Adaptation for Neural Machine Translation with\n  Domain-Aware Feature Embeddings", "abstract": "The recent success of neural machine translation models relies on the\navailability of high quality, in-domain data. Domain adaptation is required\nwhen domain-specific data is scarce or nonexistent. Previous unsupervised\ndomain adaptation strategies include training the model with in-domain copied\nmonolingual or back-translated data. However, these methods use generic\nrepresentations for text regardless of domain shift, which makes it infeasible\nfor translation models to control outputs conditional on a specific domain. In\nthis work, we propose an approach that adapts models with domain-aware feature\nembeddings, which are learned via an auxiliary language modeling task. Our\napproach allows the model to assign domain-specific representations to words\nand output sentences in the desired domain. Our empirical results demonstrate\nthe effectiveness of the proposed strategy, achieving consistent improvements\nin multiple experimental settings. In addition, we show that combining our\nmethod with back translation can further improve the performance of the model.", "published": "2019-08-27 19:38:42", "link": "http://arxiv.org/abs/1908.10430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A survey of cross-lingual features for zero-shot cross-lingual semantic\n  parsing", "abstract": "The availability of corpora to train semantic parsers in English has lead to\nsignificant advances in the field. Unfortunately, for languages other than\nEnglish, annotation is scarce and so are developed parsers. We then ask: could\na parser trained in English be applied to language that it hasn't been trained\non? To answer this question we explore zero-shot cross-lingual semantic parsing\nwhere we train an available coarse-to-fine semantic parser (Liu et al., 2018)\nusing cross-lingual word embeddings and universal dependencies in English and\ntest it on Italian, German and Dutch. Results on the Parallel Meaning Bank - a\nmultilingual semantic graphbank, show that Universal Dependency features\nsignificantly boost performance when used in conjunction with other lexical\nfeatures but modelling the UD structure directly when encoding the input does\nnot.", "published": "2019-08-27 20:43:49", "link": "http://arxiv.org/abs/1908.10461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models", "abstract": "Financial sentiment analysis is a challenging task due to the specialized\nlanguage and lack of labeled data in that domain. General-purpose models are\nnot effective enough because of the specialized language used in a financial\ncontext. We hypothesize that pre-trained language models can help with this\nproblem because they require fewer labeled examples and they can be further\ntrained on domain-specific corpora. We introduce FinBERT, a language model\nbased on BERT, to tackle NLP tasks in the financial domain. Our results show\nimprovement in every measured metric on current state-of-the-art results for\ntwo financial sentiment analysis datasets. We find that even with a smaller\ntraining set and fine-tuning only a part of the model, FinBERT outperforms\nstate-of-the-art machine learning methods.", "published": "2019-08-27 07:40:48", "link": "http://arxiv.org/abs/1908.10063v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Layer Softmaxing during Training Neural Machine Translation for\n  Flexible Decoding with Fewer Layers", "abstract": "This paper proposes a novel procedure for training an encoder-decoder based\ndeep neural network which compresses NxM models into a single model enabling us\nto dynamically choose the number of encoder and decoder layers for decoding.\nUsually, the output of the last layer of the N-layer encoder is fed to the\nM-layer decoder, and the output of the last decoder layer is used to compute\nsoftmax loss. Instead, our method computes a single loss consisting of NxM\nlosses: the softmax loss for the output of each of the M decoder layers derived\nusing the output of each of the N encoder layers. A single model trained by our\nmethod can be used for decoding with an arbitrary fewer number of encoder and\ndecoder layers. In practical scenarios, this (a) enables faster decoding with\ninsignificant losses in translation quality and (b) alleviates the need to\ntrain NxM models, thereby saving space. We take a case study of neural machine\ntranslation and show the advantage and give a cost-benefit analysis of our\napproach.", "published": "2019-08-27 10:17:24", "link": "http://arxiv.org/abs/1908.10118v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Facet-Aware Evaluation for Extractive Summarization", "abstract": "Commonly adopted metrics for extractive summarization focus on lexical\noverlap at the token level. In this paper, we present a facet-aware evaluation\nsetup for better assessment of the information coverage in extracted summaries.\nSpecifically, we treat each sentence in the reference summary as a\n\\textit{facet}, identify the sentences in the document that express the\nsemantics of each facet as \\textit{support sentences} of the facet, and\nautomatically evaluate extractive summarization methods by comparing the\nindices of extracted sentences and support sentences of all the facets in the\nreference summary. To facilitate this new evaluation setup, we construct an\nextractive version of the CNN/Daily Mail dataset and perform a thorough\nquantitative investigation, through which we demonstrate that facet-aware\nevaluation manifests better correlation with human judgment than ROUGE, enables\nfine-grained evaluation as well as comparative analysis, and reveals valuable\ninsights of state-of-the-art summarization methods. Data can be found at\nhttps://github.com/morningmoni/FAR.", "published": "2019-08-27 18:03:12", "link": "http://arxiv.org/abs/1908.10383v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Real-world Conversational AI for Hotel Bookings", "abstract": "In this paper, we present a real-world conversational AI system to search for\nand book hotels through text messaging. Our architecture consists of a\nframe-based dialogue management system, which calls machine learning models for\nintent classification, named entity recognition, and information retrieval\nsubtasks. Our chatbot has been deployed on a commercial scale, handling tens of\nthousands of hotel searches every day. We describe the various opportunities\nand challenges of developing a chatbot in the travel industry.", "published": "2019-08-27 03:13:53", "link": "http://arxiv.org/abs/1908.10001v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Incremental Improvement of a Question Answering System by Re-ranking\n  Answer Candidates using Machine Learning", "abstract": "We implement a method for re-ranking top-10 results of a state-of-the-art\nquestion answering (QA) system. The goal of our re-ranking approach is to\nimprove the answer selection given the user question and the top-10 candidates.\nWe focus on improving deployed QA systems that do not allow re-training or\nre-training comes at a high cost. Our re-ranking approach learns a similarity\nfunction using n-gram based features using the query, the answer and the\ninitial system confidence as input. Our contributions are: (1) we generate a QA\ntraining corpus starting from 877 answers from the customer care domain of\nT-Mobile Austria, (2) we implement a state-of-the-art QA pipeline using neural\nsentence embeddings that encode queries in the same space than the answer\nindex, and (3) we evaluate the QA pipeline and our re-ranking approach using a\nseparately provided test set. The test set can be considered to be available\nafter deployment of the system, e.g., based on feedback of users. Our results\nshow that the system performance, in terms of top-n accuracy and the mean\nreciprocal rank, benefits from re-ranking using gradient boosted regression\ntrees. On average, the mean reciprocal rank improves by 9.15%.", "published": "2019-08-27 11:54:23", "link": "http://arxiv.org/abs/1908.10149v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Wiki Music dataset: A tool for computational analysis of popular\n  music", "abstract": "Is it possible use algorithms to find trends in the history of popular music?\nAnd is it possible to predict the characteristics of future music genres? In\norder to answer these questions, we produced a hand-crafted dataset with the\nintent to put together features about style, psychology, sociology and\ntypology, annotated by music genre and indexed by time and decade. We collected\na list of popular genres by decade from Wikipedia and scored music genres based\non Wikipedia descriptions. Using statistical and machine learning techniques,\nwe find trends in the musical preferences and use time series forecasting to\nevaluate the prediction of future music genres.", "published": "2019-08-27 15:30:56", "link": "http://arxiv.org/abs/1908.10275v1", "categories": ["cs.CL", "cs.CY", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual\n  Contexts", "abstract": "This work aims at modeling how the meaning of gradable adjectives of size\n(`big', `small') can be learned from visually-grounded contexts. Inspired by\ncognitive and linguistic evidence showing that the use of these expressions\nrelies on setting a threshold that is dependent on a specific context, we\ninvestigate the ability of multi-modal models in assessing whether an object is\n`big' or `small' in a given visual scene. In contrast with the standard\ncomputational approach that simplistically treats gradable adjectives as\n`fixed' attributes, we pose the problem as relational: to be successful, a\nmodel has to consider the full visual context. By means of four main tasks, we\nshow that state-of-the-art models (but not a relatively strong baseline) can\nlearn the function subtending the meaning of size adjectives, though their\nperformance is found to decrease while moving from simple to more complex\ntasks. Crucially, models fail in developing abstract representations of\ngradable adjectives that can be used compositionally.", "published": "2019-08-27 15:44:17", "link": "http://arxiv.org/abs/1908.10285v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap for Tokenizer-Free Language Models", "abstract": "Purely character-based language models (LMs) have been lagging in quality on\nlarge scale datasets, and current state-of-the-art LMs rely on word\ntokenization. It has been assumed that injecting the prior knowledge of a\ntokenizer into the model is essential to achieving competitive results. In this\npaper, we show that contrary to this conventional wisdom, tokenizer-free LMs\nwith sufficient capacity can achieve competitive performance on a large scale\ndataset. We train a vanilla transformer network with 40 self-attention layers\non the One Billion Word (lm1b) benchmark and achieve a new state of the art for\ntokenizer-free LMs, pushing these models to be on par with their word-based\ncounterparts.", "published": "2019-08-27 16:53:59", "link": "http://arxiv.org/abs/1908.10322v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Reinforcement Learning for Chatbots Using Clustered Actions and\n  Human-Likeness Rewards", "abstract": "Training chatbots using the reinforcement learning paradigm is challenging\ndue to high-dimensional states, infinite action spaces and the difficulty in\nspecifying the reward function. We address such problems using clustered\nactions instead of infinite actions, and a simple but promising reward function\nbased on human-likeness scores derived from human-human dialogue data. We train\nDeep Reinforcement Learning (DRL) agents using chitchat data in raw\ntext---without any manual annotations. Experimental results using different\nsplits of training data report the following. First, that our agents learn\nreasonable policies in the environments they get familiarised with, but their\nperformance drops substantially when they are exposed to a test set of unseen\ndialogues. Second, that the choice of sentence embedding size between 100 and\n300 dimensions is not significantly different on test data. Third, that our\nproposed human-likeness rewards are reasonable for training chatbots as long as\nthey use lengthy dialogue histories of >=10 sentences.", "published": "2019-08-27 17:06:15", "link": "http://arxiv.org/abs/1908.10331v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Hierarchical Text Classification with Reinforced Label Assignment", "abstract": "While existing hierarchical text classification (HTC) methods attempt to\ncapture label hierarchies for model training, they either make local decisions\nregarding each label or completely ignore the hierarchy information during\ninference. To solve the mismatch between training and inference as well as\nmodeling label dependencies in a more principled way, we formulate HTC as a\nMarkov decision process and propose to learn a Label Assignment Policy via deep\nreinforcement learning to determine where to place an object and when to stop\nthe assignment process. The proposed method, HiLAP, explores the hierarchy\nduring both training and inference time in a consistent manner and makes\ninter-dependent decisions. As a general framework, HiLAP can incorporate\ndifferent neural encoders as base models for end-to-end training. Experiments\non five public datasets and four base models show that HiLAP yields an average\nimprovement of 33.4% in Macro-F1 over flat classifiers and outperforms\nstate-of-the-art HTC methods by a large margin. Data and code can be found at\nhttps://github.com/morningmoni/HiLAP.", "published": "2019-08-27 19:15:26", "link": "http://arxiv.org/abs/1908.10419v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Ensemble-Based Deep Reinforcement Learning for Chatbots", "abstract": "Trainable chatbots that exhibit fluent and human-like conversations remain a\nbig challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is\npromising for addressing this challenge, but its successful application remains\nan open question. This article describes a novel ensemble-based approach\napplied to value-based DRL chatbots, which use finite action sets as a form of\nmeaning representation. In our approach, while dialogue actions are derived\nfrom sentence clustering, the training datasets in our ensemble are derived\nfrom dialogue clustering. The latter aim to induce specialised agents that\nlearn to interact in a particular style. In order to facilitate neural chatbot\ntraining using our proposed approach, we assume dialogue data in raw text only\n-- without any manually-labelled data. Experimental results using chitchat data\nreveal that (1) near human-like dialogue policies can be induced, (2)\ngeneralisation to unseen data is a difficult problem, and (3) training an\nensemble of chatbot agents is essential for improved performance over using a\nsingle agent. In addition to evaluations using held-out data, our results are\nfurther supported by a human evaluation that rated dialogues in terms of\nfluency, engagingness and consistency -- which revealed that our proposed\ndialogue rewards strongly correlate with human judgements.", "published": "2019-08-27 19:18:09", "link": "http://arxiv.org/abs/1908.10422v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Interactive Machine Comprehension with Information Seeking Agents", "abstract": "Existing machine reading comprehension (MRC) models do not scale effectively\nto real-world applications like web-level information retrieval and question\nanswering (QA). We argue that this stems from the nature of MRC datasets: most\nof these are static environments wherein the supporting documents and all\nnecessary information are fully observed. In this paper, we propose a simple\nmethod that reframes existing MRC datasets as interactive, partially observable\nenvironments. Specifically, we \"occlude\" the majority of a document's text and\nadd context-sensitive commands that reveal \"glimpses\" of the hidden text to a\nmodel. We repurpose SQuAD and NewsQA as an initial case study, and then show\nhow the interactive corpora can be used to train a model that seeks relevant\ninformation through sequential decision making. We believe that this setting\ncan contribute in scaling models to web-level QA scenarios.", "published": "2019-08-27 20:11:54", "link": "http://arxiv.org/abs/1908.10449v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Visual Question Answering using Deep Learning: A Survey and Performance\n  Analysis", "abstract": "The Visual Question Answering (VQA) task combines challenges for processing\ndata with both Visual and Linguistic processing, to answer basic `common sense'\nquestions about given images. Given an image and a question in natural\nlanguage, the VQA system tries to find the correct answer to it using visual\nelements of the image and inference gathered from textual questions. In this\nsurvey, we cover and discuss the recent datasets released in the VQA domain\ndealing with various types of question-formats and robustness of the\nmachine-learning models. Next, we discuss about new deep learning models that\nhave shown promising results over the VQA datasets. At the end, we present and\ndiscuss some of the results computed by us over the vanilla VQA model, Stacked\nAttention Network and the VQA Challenge 2017 winner model. We also provide the\ndetailed analysis along with the challenges and future research directions.", "published": "2019-08-27 07:03:03", "link": "http://arxiv.org/abs/1909.01860v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Overview of Tasks and Investigation of Subjective Evaluation Methods in\n  Environmental Sound Synthesis and Conversion", "abstract": "Synthesizing and converting environmental sounds have the potential for many\napplications such as supporting movie and game production, data augmentation\nfor sound event detection and scene classification. Conventional works on\nsynthesizing and converting environmental sounds are based on a physical\nmodeling or concatenative approach. However, there are a limited number of\nworks that have addressed environmental sound synthesis and conversion with\nstatistical generative models; thus, this research area is not yet well\norganized. In this paper, we review problem definitions, applications, and\nevaluation methods of environmental sound synthesis and conversion. We then\nreport on environmental sound synthesis using sound event labels, in which we\nfocus on the current performance of statistical environmental sound synthesis\nand investigate how we should conduct subjective experiments on environmental\nsound synthesis.", "published": "2019-08-27 07:19:37", "link": "http://arxiv.org/abs/1908.10055v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice\n  Frequency for Text-to-Speech Synthesis", "abstract": "Neural source-filter (NSF) models are deep neural networks that produce\nwaveforms given input acoustic features. They use dilated-convolution-based\nneural filter modules to filter sine-based excitation for waveform generation,\nwhich is different from WaveNet and flow-based models. One of the NSF models,\ncalled harmonic-plus-noise NSF (h-NSF) model, uses separate pairs of source and\nneural filters to generate harmonic and noise waveform components. It is close\nto WaveNet in terms of speech quality while being superior in generation speed.\n  The h-NSF model can be improved even further. While h-NSF merges the harmonic\nand noise components using pre-defined digital low- and high-pass filters, it\nis well known that the maximum voice frequency (MVF) that separates the\nperiodic and aperiodic spectral bands are time-variant. Therefore, we propose a\nnew h-NSF model with time-variant and trainable MVF. We parameterize the\ndigital low- and high-pass filters as windowed-sinc filters and predict their\ncut-off frequency (i.e., MVF) from the input acoustic features. Our experiments\ndemonstrated that the new model can predict a good trajectory of the MVF and\nproduce high-quality speech for a text-to-speech synthesis system.", "published": "2019-08-27 15:01:29", "link": "http://arxiv.org/abs/1908.10256v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VAE-based Domain Adaptation for Speaker Verification", "abstract": "Deep speaker embedding has achieved satisfactory performance in speaker\nverification. By enforcing the neural model to discriminate the speakers in the\ntraining set, deep speaker embedding (called `x-vectors`) can be derived from\nthe hidden layers. Despite its good performance, the present embedding model is\nhighly domain sensitive, which means that it often works well in domains whose\nacoustic condition matches that of the training data (in-domain), but degrades\nin mismatched domains (out-of-domain). In this paper, we present a domain\nadaptation approach based on Variational Auto-Encoder (VAE). This model\ntransforms x-vectors to a regularized latent space; within this latent space, a\nsmall amount of data from the target domain is sufficient to accomplish the\nadaptation. Our experiments demonstrated that by this VAE-adaptation approach,\nspeaker embeddings can be easily transformed to the target domain, leading to\nnoticeable performance improvement.", "published": "2019-08-27 09:09:48", "link": "http://arxiv.org/abs/1908.10092v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A hybrid parametric-deep learning approach for sound event localization\n  and detection", "abstract": "This work describes and discusses an algorithm submitted to the Sound Event\nLocalization and Detection Task of DCASE2019 Challenge. The proposed\nmethodology relies on parametric spatial audio analysis for source localization\nand detection, combined with a deep learning-based monophonic event classifier.\nThe evaluation of the proposed algorithm yields overall results comparable to\nthe baseline system. The main highlight is a reduction of the localization\nerror on the evaluation dataset by a factor of 2.6, compared with the baseline\nperformance.", "published": "2019-08-27 11:20:57", "link": "http://arxiv.org/abs/1908.10133v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
