{"title": "UG18 at SemEval-2018 Task 1: Generating Additional Training Data for\n  Predicting Emotion Intensity in Spanish", "abstract": "The present study describes our submission to SemEval 2018 Task 1: Affect in\nTweets. Our Spanish-only approach aimed to demonstrate that it is beneficial to\nautomatically generate additional training data by (i) translating training\ndata from other languages and (ii) applying a semi-supervised learning method.\nWe find strong support for both approaches, with those models outperforming our\nregular models in all subtasks. However, creating a stepwise ensemble of\ndifferent models as opposed to simply averaging did not result in an increase\nin performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and\nfifth (V-Oc) in the four Spanish subtasks we participated in.", "published": "2018-05-28 09:02:18", "link": "http://arxiv.org/abs/1805.10824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inducing Grammars with and for Neural Machine Translation", "abstract": "Machine translation systems require semantic knowledge and grammatical\nunderstanding. Neural machine translation (NMT) systems often assume this\ninformation is captured by an attention mechanism and a decoder that ensures\nfluency. Recent work has shown that incorporating explicit syntax alleviates\nthe burden of modeling both types of knowledge. However, requiring parses is\nexpensive and does not explore the question of what syntax a model needs during\ntranslation. To address both of these issues we introduce a model that\nsimultaneously translates while inducing dependency trees. In this way, we\nleverage the benefits of structure while investigating what syntax NMT must\ninduce to maximize performance. We show that our dependency trees are 1.\nlanguage pair dependent and 2. improve translation quality.", "published": "2018-05-28 10:19:38", "link": "http://arxiv.org/abs/1805.10850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Denoising Distant Supervision for Relation Extraction via Instance-Level\n  Adversarial Training", "abstract": "Existing neural relation extraction (NRE) models rely on distant supervision\nand suffer from wrong labeling problems. In this paper, we propose a novel\nadversarial training mechanism over instances for relation extraction to\nalleviate the noise issue. As compared with previous denoising methods, our\nproposed method can better discriminate those informative instances from noisy\nones. Our method is also efficient and flexible to be applied to various NRE\narchitectures. As shown in the experiments on a large-scale benchmark dataset\nin relation extraction, our denoising method can effectively filter out noisy\ninstances and achieve significant improvements as compared with the\nstate-of-the-art models.", "published": "2018-05-28 14:56:35", "link": "http://arxiv.org/abs/1805.10959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resolving Event Coreference with Supervised Representation Learning and\n  Clustering-Oriented Regularization", "abstract": "We present an approach to event coreference resolution by developing a\ngeneral framework for clustering that uses supervised representation learning.\nWe propose a neural network architecture with novel Clustering-Oriented\nRegularization (CORE) terms in the objective function. These terms encourage\nthe model to create embeddings of event mentions that are amenable to\nclustering. We then use agglomerative clustering on these embeddings to build\nevent coreference chains. For both within- and cross-document coreference on\nthe ECB+ corpus, our model obtains better results than models that require\nsignificantly more pre-annotated information. This work provides insight and\nmotivating results for a new general approach to solving coreference and\nclustering problems with representation learning.", "published": "2018-05-28 15:48:39", "link": "http://arxiv.org/abs/1805.10985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Core Conflictual Relationship: Text Mining to Discover What and When", "abstract": "Following detailed presentation of the Core Conflictual Relationship Theme\n(CCRT), there is the objective of relevant methods for what has been described\nas verbalization and visualization of data. Such is also termed data mining and\ntext mining, and knowledge discovery in data. The Correspondence Analysis\nmethodology, also termed Geometric Data Analysis, is shown in a case study to\nbe comprehensive and revealing. Computational efficiency depends on how the\nanalysis process is structured. For both illustrative and revealing aspects of\nthe case study here, relatively extensive dream reports are used. This\nGeometric Data Analysis confirms the validity of CCRT method.", "published": "2018-05-28 19:21:59", "link": "http://arxiv.org/abs/1805.11140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder\n  Models", "abstract": "Encoder-decoder models typically only employ words that are frequently used\nin the training corpus to reduce the computational costs and exclude noise.\nHowever, this vocabulary set may still include words that interfere with\nlearning in encoder-decoder models. This paper proposes a method for selecting\nmore suitable words for learning encoders by utilizing not only frequency, but\nalso co-occurrence information, which we capture using the HITS algorithm. We\napply our proposed method to two tasks: machine translation and grammatical\nerror correction. For Japanese-to-English translation, this method achieves a\nBLEU score that is 0.56 points more than that of a baseline. It also\noutperforms the baseline method for English grammatical error correction, with\nan F0.5-measure that is 1.48 points higher.", "published": "2018-05-28 22:09:49", "link": "http://arxiv.org/abs/1805.11189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Dependency Representations in Neural Relation Classification", "abstract": "We investigate the use of different syntactic dependency representations in a\nneural relation classification task and compare the CoNLL, Stanford Basic and\nUniversal Dependencies schemes. We further compare with a syntax-agnostic\napproach and perform an error analysis in order to gain a better understanding\nof the results.", "published": "2018-05-28 16:17:27", "link": "http://arxiv.org/abs/1805.11461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenNMT: Neural Machine Translation Toolkit", "abstract": "OpenNMT is an open-source toolkit for neural machine translation (NMT). The\nsystem prioritizes efficiency, modularity, and extensibility with the goal of\nsupporting NMT research into model architectures, feature representations, and\nsource modalities, while maintaining competitive performance and reasonable\ntraining requirements. The toolkit consists of modeling and translation\nsupport, as well as detailed pedagogical documentation about the underlying\ntechniques. OpenNMT has been used in several production MT systems, modified\nfor numerous research papers, and is implemented across several deep learning\nframeworks.", "published": "2018-05-28 07:58:46", "link": "http://arxiv.org/abs/1805.11462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "r-Instance Learning for Missing People Tweets Identification", "abstract": "The number of missing people (i.e., people who get lost) greatly increases in\nrecent years. It is a serious worldwide problem, and finding the missing people\nconsumes a large amount of social resources. In tracking and finding these\nmissing people, timely data gathering and analysis actually play an important\nrole. With the development of social media, information about missing people\ncan get propagated through the web very quickly, which provides a promising way\nto solve the problem. The information in online social media is usually of\nheterogeneous categories, involving both complex social interactions and\ntextual data of diverse structures. Effective fusion of these different types\nof information for addressing the missing people identification problem can be\na great challenge. Motivated by the multi-instance learning problem and\nexisting social science theory of \"homophily\", in this paper, we propose a\nnovel r-instance (RI) learning model.", "published": "2018-05-28 10:36:41", "link": "http://arxiv.org/abs/1805.10856v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Temporal Event Knowledge Acquisition via Identifying Narratives", "abstract": "Inspired by the double temporality characteristic of narrative texts, we\npropose a novel approach for acquiring rich temporal \"before/after\" event\nknowledge across sentences in narrative stories. The double temporality states\nthat a narrative story often describes a sequence of events following the\nchronological order and therefore, the temporal order of events matches with\ntheir textual order. We explored narratology principles and built a weakly\nsupervised approach that identifies 287k narrative paragraphs from three large\ntext corpora. We then extracted rich temporal event knowledge from these\nnarrative paragraphs. Such event knowledge is shown useful to improve temporal\nrelation classification and outperform several recent neural network models on\nthe narrative cloze task.", "published": "2018-05-28 14:51:27", "link": "http://arxiv.org/abs/1805.10956v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story\n  Generation", "abstract": "The task of multi-image cued story generation, such as visual storytelling\ndataset (VIST) challenge, is to compose multiple coherent sentences from a\ngiven sequence of images. The main difficulty is how to generate image-specific\nsentences within the context of overall images. Here we propose a deep learning\nnetwork model, GLAC Net, that generates visual stories by combining\nglobal-local (glocal) attention and context cascading mechanisms. The model\nincorporates two levels of attention, i.e., overall encoding level and image\nfeature level, to construct image-dependent sentences. While standard attention\nconfiguration needs a large number of parameters, the GLAC Net implements them\nin a very simple way via hard connections from the outputs of encoders or image\nfeatures onto the sentence generators. The coherency of the generated story is\nfurther improved by conveying (cascading) the information of the previous\nsentence to the next sentence serially. We evaluate the performance of the GLAC\nNet on the visual storytelling dataset (VIST) and achieve very competitive\nresults compared to the state-of-the-art techniques. Our code and pre-trained\nmodels are available here.", "published": "2018-05-28 15:30:21", "link": "http://arxiv.org/abs/1805.10973v3", "categories": ["cs.CL", "cs.CV", "68T99", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A visual approach for age and gender identification on Twitter", "abstract": "The goal of Author Profiling (AP) is to identify demographic aspects (e.g.,\nage, gender) from a given set of authors by analyzing their written texts.\nRecently, the AP task has gained interest in many problems related to computer\nforensics, psychology, marketing, but specially in those related with social\nmedia exploitation. As known, social media data is shared through a wide range\nof modalities (e.g., text, images and audio), representing valuable information\nto be exploited for extracting valuable insights from users. Nevertheless, most\nof the current work in AP using social media data has been devoted to analyze\ntextual information only, and there are very few works that have started\nexploring the gender identification using visual information. Contrastingly,\nthis paper focuses in exploiting the visual modality to perform both age and\ngender identification in social media, specifically in Twitter. Our goal is to\nevaluate the pertinence of using visual information in solving the AP task.\nAccordingly, we have extended the Twitter corpus from PAN 2014, incorporating\nposted images from all the users, making a distinction between tweeted and\nretweeted images. Performed experiments provide interesting evidence on the\nusefulness of visual information in comparison with traditional textual\nrepresentations for the AP task.", "published": "2018-05-28 20:31:18", "link": "http://arxiv.org/abs/1805.11166v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Convolutional neural network compression for natural language processing", "abstract": "Convolutional neural networks are modern models that are very efficient in\nmany classification tasks. They were originally created for image processing\npurposes. Then some trials were performed to use them in different domains like\nnatural language processing. The artificial intelligence systems (like humanoid\nrobots) are very often based on embedded systems with constraints on memory,\npower consumption etc. Therefore convolutional neural network because of its\nmemory capacity should be reduced to be mapped to given hardware. In this\npaper, results are presented of compressing the efficient convolutional neural\nnetworks for sentiment analysis. The main steps are quantization and pruning\nprocesses. The method responsible for mapping compressed network to FPGA and\nresults of this implementation are presented. The described simulations showed\nthat 5-bit width is enough to have no drop in accuracy from floating point\nversion of the network. Additionally, significant memory footprint reduction\nwas achieved (from 85% up to 93%).", "published": "2018-05-28 07:40:33", "link": "http://arxiv.org/abs/1805.10796v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Interactive Text2Pickup Network for Natural Language based Human-Robot\n  Collaboration", "abstract": "In this paper, we propose the Interactive Text2Pickup (IT2P) network for\nhuman-robot collaboration which enables an effective interaction with a human\nuser despite the ambiguity in user's commands. We focus on the task where a\nrobot is expected to pick up an object instructed by a human, and to interact\nwith the human when the given instruction is vague. The proposed network\nunderstands the command from the human user and estimates the position of the\ndesired object first. To handle the inherent ambiguity in human language\ncommands, a suitable question which can resolve the ambiguity is generated. The\nuser's answer to the question is combined with the initial command and given\nback to the network, resulting in more accurate estimation. The experiment\nresults show that given unambiguous commands, the proposed method can estimate\nthe position of the requested object with an accuracy of 98.49% based on our\ntest dataset. Given ambiguous language commands, we show that the accuracy of\nthe pick up task increases by 1.94 times after incorporating the information\nobtained from the interaction.", "published": "2018-05-28 07:52:42", "link": "http://arxiv.org/abs/1805.10799v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "A Stochastic Decoder for Neural Machine Translation", "abstract": "The process of translation is ambiguous, in that there are typically many\nvalid trans- lations for a given sentence. This gives rise to significant\nvariation in parallel cor- pora, however, most current models of machine\ntranslation do not account for this variation, instead treating the prob- lem\nas a deterministic process. To this end, we present a deep generative model of\nmachine translation which incorporates a chain of latent variables, in order to\nac- count for local lexical and syntactic varia- tion in parallel corpora. We\nprovide an in- depth analysis of the pitfalls encountered in variational\ninference for training deep generative models. Experiments on sev- eral\ndifferent language pairs demonstrate that the model consistently improves over\nstrong baselines.", "published": "2018-05-28 09:49:56", "link": "http://arxiv.org/abs/1805.10844v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Soft Layer-Specific Multi-Task Summarization with Entailment and\n  Question Generation", "abstract": "An accurate abstractive summary of a document should contain all its salient\ninformation and should be logically entailed by the input document. We improve\nthese important aspects of abstractive summarization via multi-task learning\nwith the auxiliary tasks of question generation and entailment generation,\nwhere the former teaches the summarization model how to look for salient\nquestioning-worthy details, and the latter teaches the model how to rewrite a\nsummary which is a directed-logical subset of the input document. We also\npropose novel multi-task architectures with high-level (semantic)\nlayer-specific sharing across multiple encoder and decoder layers of the three\ntasks, as well as soft-sharing mechanisms (and show performance ablations and\nanalysis examples of each contribution). Overall, we achieve statistically\nsignificant improvements over the state-of-the-art on both the CNN/DailyMail\nand Gigaword datasets, as well as on the DUC-2002 transfer setup. We also\npresent several quantitative and qualitative analysis studies of our model's\nlearned saliency and entailment skills.", "published": "2018-05-28 16:05:39", "link": "http://arxiv.org/abs/1805.11004v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Abstractive Summarization with Reinforce-Selected Sentence\n  Rewriting", "abstract": "Inspired by how humans summarize long documents, we propose an accurate and\nfast summarization model that first selects salient sentences and then rewrites\nthem abstractively (i.e., compresses and paraphrases) to generate a concise\noverall summary. We use a novel sentence-level policy gradient method to bridge\nthe non-differentiable computation between these two neural networks in a\nhierarchical way, while maintaining language fluency. Empirically, we achieve\nthe new state-of-the-art on all metrics (including human evaluation) on the\nCNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.\nMoreover, by first operating at the sentence-level and then the word-level, we\nenable parallel decoding of our neural generative model that results in\nsubstantially faster (10-20x) inference speed as well as 4x faster training\nconvergence than previous long-paragraph encoder-decoder models. We also\ndemonstrate the generalization of our model on the test-only DUC-2002 dataset,\nwhere we achieve higher scores than a state-of-the-art model.", "published": "2018-05-28 17:49:10", "link": "http://arxiv.org/abs/1805.11080v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Speaker Segmentation and Diarization using Lexical and\n  Acoustic Cues via Sequence to Sequence Neural Networks", "abstract": "While there has been substantial amount of work in speaker diarization\nrecently, there are few efforts in jointly employing lexical and acoustic\ninformation for speaker segmentation. Towards that, we investigate a speaker\ndiarization system using a sequence-to-sequence neural network trained on both\nlexical and acoustic features. We also propose a loss function that allows for\nselecting not only the speaker change points but also the best speaker at any\ntime by allowing for different speaker groupings. We incorporate Mel Frequency\nCepstral Coefficients (MFCC) as an acoustic feature alongside lexical\ninformation that are obtained from conversations from the Fisher dataset. Thus,\nwe show that acoustics provide complementary information to the lexical\nmodality. The experimental results show that sequence-to-sequence system\ntrained on both word sequences and MFCC can improve on speaker diarization\nresult compared to the system that only relies on lexical modality or the\nbaseline MFCC-based system. In addition, we test the performance of our\nproposed method with Automatic Speech Recognition (ASR) transcripts. While the\nperformance on ASR transcripts drops, the Diarization Error Rate (DER) of our\nproposed method still outperforms the traditional method based on Bayesian\nInformation Criterion (BIC).", "published": "2018-05-28 01:58:55", "link": "http://arxiv.org/abs/1805.10731v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Real-valued parametric conditioning of an RNN for interactive sound\n  synthesis", "abstract": "A Recurrent Neural Network (RNN) for audio synthesis is trained by augmenting\nthe audio input with information about signal characteristics such as pitch,\namplitude, and instrument. The result after training is an audio synthesizer\nthat is played like a musical instrument with the desired musical\ncharacteristics provided as continuous parametric control. The focus of this\npaper is on conditioning data-driven synthesis models with real-valued\nparameters, and in particular, on the ability of the system a) to generalize\nand b) to be responsive to parameter values and sequences not seen during\ntraining.", "published": "2018-05-28 08:18:51", "link": "http://arxiv.org/abs/1805.10808v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating Label Noise Sensitivity of Convolutional Neural Networks\n  for Fine Grained Audio Signal Labelling", "abstract": "We measure the effect of small amounts of systematic and random label noise\ncaused by slightly misaligned ground truth labels in a fine grained audio\nsignal labeling task. The task we choose to demonstrate these effects on is\nalso known as framewise polyphonic transcription or note quantized multi-f0\nestimation, and transforms a monaural audio signal into a sequence of note\nindicator labels. It will be shown that even slight misalignments have clearly\napparent effects, demonstrating a great sensitivity of convolutional neural\nnetworks to label noise. The implications are clear: when using convolutional\nneural networks for fine grained audio signal labeling tasks, great care has to\nbe taken to ensure that the annotations have precise timing, and are free from\nsystematic or random error as much as possible - even small misalignments will\nhave a noticeable impact.", "published": "2018-05-28 12:02:26", "link": "http://arxiv.org/abs/1805.10880v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
