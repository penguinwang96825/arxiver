{"title": "Recurrent Entity Networks with Delayed Memory Update for Targeted\n  Aspect-based Sentiment Analysis", "abstract": "While neural networks have been shown to achieve impressive results for\nsentence-level sentiment analysis, targeted aspect-based sentiment analysis\n(TABSA) --- extraction of fine-grained opinion polarity w.r.t. a pre-defined\nset of aspects --- remains a difficult task. Motivated by recent advances in\nmemory-augmented models for machine reading, we propose a novel architecture,\nutilising external \"memory chains\" with a delayed memory update mechanism to\ntrack entities. On a TABSA task, the proposed model demonstrates substantial\nimprovements over state-of-the-art approaches, including those using external\nknowledge bases.", "published": "2018-04-30 01:57:31", "link": "http://arxiv.org/abs/1804.11019v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Metric Validation for Grammatical Error Correction", "abstract": "Metric validation in Grammatical Error Correction (GEC) is currently done by\nobserving the correlation between human and metric-induced rankings. However,\nsuch correlation studies are costly, methodologically troublesome, and suffer\nfrom low inter-rater agreement. We propose MAEGE, an automatic methodology for\nGEC metric validation, that overcomes many of the difficulties with existing\npractices. Experiments with \\maege\\ shed a new light on metric quality, showing\nfor example that the standard $M^2$ metric fares poorly on corpus-level\nranking. Moreover, we use MAEGE to perform a detailed analysis of metric\nbehavior, showing that correcting some types of errors is consistently\npenalized by existing metrics.", "published": "2018-04-30 14:17:36", "link": "http://arxiv.org/abs/1804.11225v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BomJi at SemEval-2018 Task 10: Combining Vector-, Pattern- and\n  Graph-based Information to Identify Discriminative Attributes", "abstract": "This paper describes BomJi, a supervised system for capturing discriminative\nattributes in word pairs (e.g. yellow as discriminative for banana over\nwatermelon). The system relies on an XGB classifier trained on carefully\nengineered graph-, pattern- and word embedding based features. It participated\nin the SemEval- 2018 Task 10 on Capturing Discriminative Attributes, achieving\nan F1 score of 0:73 and ranking 2nd out of 26 participant systems.", "published": "2018-04-30 14:58:22", "link": "http://arxiv.org/abs/1804.11251v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inherent Biases in Reference based Evaluation for Grammatical Error\n  Correction and Text Simplification", "abstract": "The prevalent use of too few references for evaluating text-to-text\ngeneration is known to bias estimates of their quality ({\\it low coverage bias}\nor LCB). This paper shows that overcoming LCB in Grammatical Error Correction\n(GEC) evaluation cannot be attained by re-scaling or by increasing the number\nof references in any feasible range, contrary to previous suggestions. This is\ndue to the long-tailed distribution of valid corrections for a sentence.\nConcretely, we show that LCB incentivizes GEC systems to avoid correcting even\nwhen they can generate a valid correction. Consequently, existing systems\nobtain comparable or superior performance compared to humans, by making few but\ntargeted changes to the input. Similar effects on Text Simplification further\nsupport our claims.", "published": "2018-04-30 14:59:56", "link": "http://arxiv.org/abs/1804.11254v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive\n  Strategies", "abstract": "We present NEWSROOM, a summarization dataset of 1.3 million articles and\nsummaries written by authors and editors in newsrooms of 38 major news\npublications. Extracted from search and social media metadata between 1998 and\n2017, these high-quality summaries demonstrate high diversity of summarization\nstyles. In particular, the summaries combine abstractive and extractive\nstrategies, borrowing words and phrases from articles at varying rates. We\nanalyze the extraction strategies used in NEWSROOM summaries against other\ndatasets to quantify the diversity and difficulty of our new data, and train\nexisting methods on the data to evaluate its utility and challenges.", "published": "2018-04-30 15:53:05", "link": "http://arxiv.org/abs/1804.11283v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating NMT Batched Beam Decoding with LMBR Posteriors for\n  Deployment", "abstract": "We describe a batched beam decoding algorithm for NMT with LMBR n-gram\nposteriors, showing that LMBR techniques still yield gains on top of the best\nrecently reported results with Transformers. We also discuss acceleration\nstrategies for deployment, and the effect of the beam size and batching on\nmemory and speed.", "published": "2018-04-30 17:03:07", "link": "http://arxiv.org/abs/1804.11324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Portuguese Native Language Identification Dataset", "abstract": "In this paper we present NLI-PT, the first Portuguese dataset compiled for\nNative Language Identification (NLI), the task of identifying an author's first\nlanguage based on their second language writing. The dataset includes 1,868\nstudent essays written by learners of European Portuguese, native speakers of\nthe following L1s: Chinese, English, Spanish, German, Russian, French,\nJapanese, Italian, Dutch, Tetum, Arabic, Polish, Korean, Romanian, and Swedish.\nNLI-PT includes the original student text and four different types of\nannotation: POS, fine-grained POS, constituency parses, and dependency parses.\nNLI-PT can be used not only in NLI but also in research on several topics in\nthe field of Second Language Acquisition and educational NLP. We discuss\npossible applications of this dataset and present the results obtained for the\nfirst lexical baseline system for Portuguese NLI.", "published": "2018-04-30 17:52:28", "link": "http://arxiv.org/abs/1804.11346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Patterns Improve Information Extraction for Medical Search", "abstract": "Medical professionals search the published literature by specifying the type\nof patients, the medical intervention(s) and the outcome measure(s) of\ninterest. In this paper we demonstrate how features encoding syntactic patterns\nimprove the performance of state-of-the-art sequence tagging models (both\nlinear and neural) for information extraction of these medically relevant\ncategories. We present an analysis of the type of patterns exploited, and the\nsemantic space induced for these, i.e., the distributed representations learned\nfor identified multi-token patterns. We show that these learned representations\ndiffer substantially from those of the constituent unigrams, suggesting that\nthe patterns capture contextual information that is otherwise lost.", "published": "2018-04-30 21:00:03", "link": "http://arxiv.org/abs/1805.00097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast and scalable learning of neuro-symbolic representations of\n  biomedical knowledge", "abstract": "In this work we address the problem of fast and scalable learning of\nneuro-symbolic representations for general biological knowledge. Based on a\nrecently published comprehensive biological knowledge graph (Alshahrani, 2017)\nthat was used for demonstrating neuro-symbolic representation learning, we show\nhow to train fast (under 1 minute) log-linear neural embeddings of the\nentities. We utilize these representations as inputs for machine learning\nclassifiers to enable important tasks such as biological link prediction.\nClassifiers are trained by concatenating learned entity embeddings to represent\nentity relations, and training classifiers on the concatenated embeddings to\ndiscern true relations from automatically generated negative examples. Our\nsimple embedding methodology greatly improves on classification error compared\nto previously published state-of-the-art results, yielding a maximum increase\nof $+0.28$ F-measure and $+0.22$ ROC AUC scores for the most difficult\nbiological link prediction problem. Finally, our embedding approach is orders\nof magnitude faster to train ($\\leq$ 1 minute vs. hours), much more economical\nin terms of embedding dimensions ($d=50$ vs. $d=512$), and naturally encodes\nthe directionality of the asymmetric biological relations, that can be\ncontrolled by the order with which we concatenate the embeddings.", "published": "2018-04-30 09:54:12", "link": "http://arxiv.org/abs/1804.11105v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Demand-Weighted Completeness Prediction for a Knowledge Base", "abstract": "In this paper we introduce the notion of Demand-Weighted Completeness,\nallowing estimation of the completeness of a knowledge base with respect to how\nit is used. Defining an entity by its classes, we employ usage data to predict\nthe distribution over relations for that entity. For example, instances of\nperson in a knowledge base may require a birth date, name and nationality to be\nconsidered complete. These predicted relation distributions enable detection of\nimportant gaps in the knowledge base, and define the required facts for unseen\nentities. Such characterisation of the knowledge base can also quantify how\nusage and completeness change over time. We demonstrate a method to measure\nDemand-Weighted Completeness, and show that a simple neural network model\nperforms well at this prediction task.", "published": "2018-04-30 10:06:46", "link": "http://arxiv.org/abs/1804.11109v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Q-Map: Clinical Concept Mining from Clinical Documents", "abstract": "Over the past decade, there has been a steep rise in the data-driven analysis\nin major areas of medicine, such as clinical decision support system, survival\nanalysis, patient similarity analysis, image analytics etc. Most of the data in\nthe field are well-structured and available in numerical or categorical formats\nwhich can be used for experiments directly. But on the opposite end of the\nspectrum, there exists a wide expanse of data that is intractable for direct\nanalysis owing to its unstructured nature which can be found in the form of\ndischarge summaries, clinical notes, procedural notes which are in human\nwritten narrative format and neither have any relational model nor any standard\ngrammatical structure. An important step in the utilization of these texts for\nsuch studies is to transform and process the data to retrieve structured\ninformation from the haystack of irrelevant data using information retrieval\nand data mining techniques. To address this problem, the authors present Q-Map\nin this paper, which is a simple yet robust system that can sift through\nmassive datasets with unregulated formats to retrieve structured information\naggressively and efficiently. It is backed by an effective mining technique\nwhich is based on a string matching algorithm that is indexed on curated\nknowledge sources, that is both fast and configurable. The authors also briefly\nexamine its comparative performance with MetaMap, one of the most reputed tools\nfor medical concepts retrieval and present the advantages the former displays\nover the latter.", "published": "2018-04-30 12:19:03", "link": "http://arxiv.org/abs/1804.11149v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Sampling strategies in Siamese Networks for unsupervised speech\n  representation learning", "abstract": "Recent studies have investigated siamese network architectures for learning\ninvariant speech representations using same-different side information at the\nword level. Here we investigate systematically an often ignored component of\nsiamese networks: the sampling procedure (how pairs of same vs. different\ntokens are selected). We show that sampling strategies taking into account\nZipf's Law, the distribution of speakers and the proportions of same and\ndifferent pairs of words significantly impact the performance of the network.\nIn particular, we show that word frequency compression improves learning across\na large range of variations in number of training pairs. This effect does not\napply to the same extent to the fully unsupervised setting, where the pairs of\nsame-different words are obtained by spoken term discovery. We apply these\nresults to pairs of words discovered using an unsupervised algorithm and show\nan improvement on state-of-the-art in unsupervised representation learning\nusing siamese networks.", "published": "2018-04-30 16:19:51", "link": "http://arxiv.org/abs/1804.11297v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Documentation of ICD Codes with Far-Field Speech Recognition", "abstract": "Documentation errors increase healthcare costs and cause unnecessary patient\ndeaths. As the standard language for diagnoses and billing, ICD codes serve as\nthe foundation for medical documentation worldwide. Despite the prevalence of\nelectronic medical records, hospitals still witness high levels of ICD\nmiscoding. In this paper, we propose to automatically document ICD codes with\nfar-field speech recognition. Far-field speech occurs when the microphone is\nlocated several meters from the source, as is common with smart homes and\nsecurity systems. Our method combines acoustic signal processing with recurrent\nneural networks to recognize and document ICD codes in real time. To evaluate\nour model, we collected a far-field speech dataset of ICD-10 codes and found\nour model to achieve 87% accuracy with a BLEU score of 85%. By sampling from an\nunsupervised medical language model, our method is able to outperform existing\nmethods. Overall, this work shows the potential of automatic speech recognition\nto provide efficient, accurate, and cost-effective healthcare documentation.", "published": "2018-04-30 04:41:33", "link": "http://arxiv.org/abs/1804.11046v4", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Staircase Network: structural language identification via hierarchical\n  attentive units", "abstract": "Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin.", "published": "2018-04-30 07:55:55", "link": "http://arxiv.org/abs/1804.11067v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Cross-Modal Retrieval in the Cooking Context: Learning Semantic\n  Text-Image Embeddings", "abstract": "Designing powerful tools that support cooking activities has rapidly gained\npopularity due to the massive amounts of available data, as well as recent\nadvances in machine learning that are capable of analyzing them. In this paper,\nwe propose a cross-modal retrieval model aligning visual and textual data (like\npictures of dishes and their recipes) in a shared representation space. We\ndescribe an effective learning scheme, capable of tackling large-scale\nproblems, and validate it on the Recipe1M dataset containing nearly 1 million\npicture-recipe pairs. We show the effectiveness of our approach regarding\nprevious state-of-the-art models and present qualitative results over\ncomputational cooking use cases.", "published": "2018-04-30 12:14:32", "link": "http://arxiv.org/abs/1804.11146v1", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Toward Diverse Text Generation with Inverse Reinforcement Learning", "abstract": "Text generation is a crucial task in NLP. Recently, several adversarial\ngenerative models have been proposed to improve the exposure bias problem in\ntext generation. Though these models gain great success, they still suffer from\nthe problems of reward sparsity and mode collapse. In order to address these\ntwo problems, in this paper, we employ inverse reinforcement learning (IRL) for\ntext generation. Specifically, the IRL framework learns a reward function on\ntraining data, and then an optimal policy to maximum the expected total reward.\nSimilar to the adversarial models, the reward and policy function in IRL are\noptimized alternately. Our method has two advantages: (1) the reward function\ncan produce more dense reward signals. (2) the generation policy, trained by\n\"entropy regularized\" policy gradient, encourages to generate more diversified\ntexts. Experiment results demonstrate that our proposed method can generate\nhigher quality texts than the previous methods.", "published": "2018-04-30 15:04:21", "link": "http://arxiv.org/abs/1804.11258v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Adversarial Semantic Alignment for Improved Image Captions", "abstract": "In this paper we study image captioning as a conditional GAN training,\nproposing both a context-aware LSTM captioner and co-attentive discriminator,\nwhich enforces semantic alignment between images and captions. We empirically\nfocus on the viability of two training methods: Self-critical Sequence Training\n(SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more\nstable gradient behavior and improved results over Gumbel ST, even without\naccessing discriminator gradients directly. We also address the problem of\nautomatic evaluation for captioning models and introduce a new semantic score,\nand show its correlation to human judgement. As an evaluation paradigm, we\nargue that an important criterion for a captioner is the ability to generalize\nto compositions of objects that do not usually co-occur together. To this end,\nwe introduce a small captioned Out of Context (OOC) test set. The OOC set,\ncombined with our semantic score, are the proposed new diagnosis tools for the\ncaptioning community. When evaluated on OOC and MS-COCO benchmarks, we show\nthat SCST-based training has a strong performance in both semantic score and\nhuman evaluation, promising to be a valuable new approach for efficient\ndiscrete GAN training.", "published": "2018-04-30 19:10:43", "link": "http://arxiv.org/abs/1805.00063v3", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Collapsed speech segment detection and suppression for WaveNet vocoder", "abstract": "In this paper, we propose a technique to alleviate the quality degradation\ncaused by collapsed speech segments sometimes generated by the WaveNet vocoder.\nThe effectiveness of the WaveNet vocoder for generating natural speech from\nacoustic features has been proved in recent works. However, it sometimes\ngenerates very noisy speech with collapsed speech segments when only a limited\namount of training data is available or significant acoustic mismatches exist\nbetween the training and testing data. Such a limitation on the corpus and\nlimited ability of the model can easily occur in some speech generation\napplications, such as voice conversion and speech enhancement. To address this\nproblem, we propose a technique to automatically detect collapsed speech\nsegments. Moreover, to refine the detected segments, we also propose a waveform\ngeneration technique for WaveNet using a linear predictive coding constraint.\nVerification and subjective tests are conducted to investigate the\neffectiveness of the proposed techniques. The verification results indicate\nthat the detection technique can detect most collapsed segments. The subjective\nevaluations of voice conversion demonstrate that the generation technique\nsignificantly improves the speech quality while maintaining the same speaker\nsimilarity.", "published": "2018-04-30 06:26:26", "link": "http://arxiv.org/abs/1804.11055v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "WAAW Csound", "abstract": "This paper describes Web Assembly Audio Worklet (WAAW) Csound, one of the\nimplementations of WebAudio Csound. We begin by introducing the background to\nthis current implementation, stemming from the two first ports of Csound to the\nweb platform using Native Clients and asm.js. The technology of Web Assembly is\nthen introduced and discussed in its more relevant aspects. The AudioWorklet\ninterface of Web Audio API is explored, together with its use in WAAW Csound.\nWe complement this discussion by considering the overarching question of\nsupport for multiple platforms, which implement different versions of Web\nAudio. Some initial examples of the system are presented to illustrate various\npotential applications. Finally, we complement the paper by discussing current\nissues that are fundamental for this project and others that rely on the\ndevelopment of a robust support for WASM-based audio computing.", "published": "2018-04-30 10:56:57", "link": "http://arxiv.org/abs/1804.11120v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A toolbox for rendering virtual acoustic environments in the context of\n  audiology", "abstract": "A toolbox for creation and rendering of dynamic virtual acoustic environments\n(TASCAR) that allows direct user interaction was developed for application in\nhearing aid research and audiology. This technical paper describes the general\nsoftware structure and the time-domain simulation methods, i.e., transmission\nmodel, image source model, and render formats, used to produce virtual acoustic\nenvironments with moving objects. Implementation-specific properties are\ndescribed, and the computational performance of the system was measured as a\nfunction of simulation complexity. Results show that on commercially available\ncommonly used hardware the simulation of several hundred virtual sound sources\nis possible in the time domain.", "published": "2018-04-30 16:26:45", "link": "http://arxiv.org/abs/1804.11300v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OMG - Emotion Challenge Solution", "abstract": "This short paper describes our solution to the 2018 IEEE World Congress on\nComputational Intelligence One-Minute Gradual-Emotional Behavior Challenge,\nwhose goal was to estimate continuous arousal and valence values from short\nvideos. We designed four base regression models using visual and audio\nfeatures, and then used a spectral approach to fuse them to obtain improved\nperformance.", "published": "2018-04-30 10:50:30", "link": "http://arxiv.org/abs/1805.00348v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CV"}
