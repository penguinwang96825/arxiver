{"title": "Splits! A Flexible Dataset for Evaluating a Model's Demographic Social Inference", "abstract": "Understanding how people of various demographics think, feel, and express\nthemselves (collectively called group expression) is essential for social\nscience and underlies the assessment of bias in Large Language Models (LLMs).\nWhile LLMs can effectively summarize group expression when provided with\nempirical examples, coming up with generalizable theories of how a group's\nexpression manifests in real-world text is challenging. In this paper, we\ndefine a new task called Group Theorization, in which a system must write\ntheories that differentiate expression across demographic groups. We make\navailable a large dataset on this task, Splits!, constructed by splitting\nReddit posts by neutral topics (e.g. sports, cooking, and movies) and by\ndemographics (e.g. occupation, religion, and race). Finally, we suggest a\nsimple evaluation framework for assessing how effectively a method can generate\n'better' theories about group expression, backed by human validation. We\npublicly release the raw corpora and evaluation scripts for Splits! to help\nresearchers assess how methods infer--and potentially misrepresent--group\ndifferences in expression. We make Splits! and our evaluation module available\nat https://github.com/eyloncaplan/splits.", "published": "2025-04-06 23:17:07", "link": "http://arxiv.org/abs/2504.04640v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ineffectiveness for Search and Undecidability of PCSP Meta-Problems", "abstract": "It is an open question whether the search and decision versions of promise\nCSPs are equivalent. Most known algorithms for PCSPs solve only their\n\\emph{decision} variant, and it is unknown whether they can be adapted to solve\n\\emph{search} as well. The main approaches, called BLP, AIP and BLP+AIP, handle\na PCSP by finding a solution to a relaxation of some integer program. We prove\nthat rounding those solutions to a proper search certificate can be as hard as\nany problem in the class TFNP. In other words, these algorithms are ineffective\nfor search. Building on the algebraic approach to PCSPs, we find sufficient\nconditions that imply ineffectiveness for search. Our tools are tailored to\nalgorithms that are characterized by minions in a suitable way, and can also be\nused to prove undecidability results for meta-problems. This way, we show that\nthe families of templates solvable via BLP, AIP, and BLP+AIP are undecidable.\n  Using the same techniques we also analyze several algebraic conditions that\nare known to guarantee the tractability of finite-template CSPs. We prove that\nseveral meta-problems related to cyclic polymorphims and WNUs are undecidable\nfor PCSPs. In particular, there is no algorithm deciding whether a finite PCSP\ntemplate (1) admits cyclic a polymorphism, (2) admits a WNU.", "published": "2025-04-06 23:08:05", "link": "http://arxiv.org/abs/2504.04639v1", "categories": ["cs.CC", "cs.CL", "cs.DS", "cs.LO", "68Q17, 68Q25"], "primary_category": "cs.CC"}
{"title": "Steering off Course: Reliability Challenges in Steering Language Models", "abstract": "Steering methods for language models (LMs) have gained traction as\nlightweight alternatives to fine-tuning, enabling targeted modifications to\nmodel activations. However, prior studies primarily report results on a few\nmodels, leaving critical gaps in understanding the robustness of these methods.\nIn this work, we systematically examine three prominent steering methods --\nDoLa, function vectors, and task vectors. In contrast to the original studies,\nwhich evaluated a handful of models, we test up to 36 models belonging to 14\nfamilies with sizes ranging from 1.5B to 70B parameters. Our experiments reveal\nsubstantial variability in the effectiveness of the steering approaches, with a\nlarge number of models showing no improvement and at times degradation in\nsteering performance. Our analysis demonstrate fundamental flaws in the\nassumptions underlying these methods, challenging their reliability as scalable\nsteering solutions.", "published": "2025-04-06 22:19:46", "link": "http://arxiv.org/abs/2504.04635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DynClean: Training Dynamics-based Label Cleaning for Distantly-Supervised Named Entity Recognition", "abstract": "Distantly Supervised Named Entity Recognition (DS-NER) has attracted\nattention due to its scalability and ability to automatically generate labeled\ndata. However, distant annotation introduces many mislabeled instances,\nlimiting its performance. Most of the existing work attempt to solve this\nproblem by developing intricate models to learn from the noisy labels. An\nalternative approach is to attempt to clean the labeled data, thus increasing\nthe quality of distant labels. This approach has received little attention for\nNER. In this paper, we propose a training dynamics-based label cleaning\napproach, which leverages the behavior of a model as training progresses to\ncharacterize the distantly annotated samples. We also introduce an automatic\nthreshold estimation strategy to locate the errors in distant labels. Extensive\nexperimental results demonstrate that: (1) models trained on our cleaned DS-NER\ndatasets, which were refined by directly removing identified erroneous\nannotations, achieve significant improvements in F1-score, ranging from 3.18%\nto 8.95%; and (2) our method outperforms numerous advanced DS-NER approaches\nacross four datasets.", "published": "2025-04-06 20:54:42", "link": "http://arxiv.org/abs/2504.04616v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SECQUE: A Benchmark for Evaluating Real-World Financial Analysis Capabilities", "abstract": "We introduce SECQUE, a comprehensive benchmark for evaluating large language\nmodels (LLMs) in financial analysis tasks. SECQUE comprises 565 expert-written\nquestions covering SEC filings analysis across four key categories: comparison\nanalysis, ratio calculation, risk assessment, and financial insight generation.\nTo assess model performance, we develop SECQUE-Judge, an evaluation mechanism\nleveraging multiple LLM-based judges, which demonstrates strong alignment with\nhuman evaluations. Additionally, we provide an extensive analysis of various\nmodels' performance on our benchmark. By making SECQUE publicly available, we\naim to facilitate further research and advancements in financial AI.", "published": "2025-04-06 19:59:41", "link": "http://arxiv.org/abs/2504.04596v1", "categories": ["cs.AI", "cs.CE", "cs.CL"], "primary_category": "cs.AI"}
{"title": "KnowsLM: A framework for evaluation of small language models for knowledge augmentation and humanised conversations", "abstract": "In the evolving landscape of conversational AI, generating concise,\ncontext-aware, and human-like dialogue using small and medium-sized language\nmodels (LLMs) remains a complex challenge. This study investigates the\ninfluence of LoRA rank, dataset scale, and prompt prefix design on both\nknowledge retention and stylistic alignment. While fine-tuning improves fluency\nand enables stylistic customization, its ability to integrate unseen knowledge\nis constrained -- particularly with smaller datasets. Conversely, RAG-augmented\nmodels, equipped to incorporate external documents at inference, demonstrated\nsuperior factual accuracy on out-of-distribution prompts, though they lacked\nthe stylistic consistency achieved by fine-tuning. Evaluations by LLM-based\njudges across knowledge accuracy, conversational quality, and conciseness\nsuggest that fine-tuning is best suited for tone adaptation, whereas RAG excels\nat real-time knowledge augmentation.", "published": "2025-04-06 17:58:08", "link": "http://arxiv.org/abs/2504.04569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Comparison of Text Summarization: A Multi-Dimensional Evaluation of Large Language Models", "abstract": "Text summarization is crucial for mitigating information overload across\ndomains like journalism, medicine, and business. This research evaluates\nsummarization performance across 17 large language models (OpenAI, Google,\nAnthropic, open-source) using a novel multi-dimensional framework. We assessed\nmodels on seven diverse datasets (BigPatent, BillSum, CNN/DailyMail, PubMed,\nSAMSum, WikiHow, XSum) at three output lengths (50, 100, 150 tokens) using\nmetrics for factual consistency, semantic similarity, lexical overlap, and\nhuman-like quality, while also considering efficiency factors. Our findings\nreveal significant performance differences, with specific models excelling in\nfactual accuracy (deepseek-v3), human-like quality (claude-3-5-sonnet), and\nprocessing efficiency/cost-effectiveness (gemini-1.5-flash, gemini-2.0-flash).\nPerformance varies dramatically by dataset, with models struggling on technical\ndomains but performing well on conversational content. We identified a critical\ntension between factual consistency (best at 50 tokens) and perceived quality\n(best at 150 tokens). Our analysis provides evidence-based recommendations for\ndifferent use cases, from high-stakes applications requiring factual accuracy\nto resource-constrained environments needing efficient processing. This\ncomprehensive approach enhances evaluation methodology by integrating quality\nmetrics with operational considerations, incorporating trade-offs between\naccuracy, efficiency, and cost-effectiveness to guide model selection for\nspecific applications.", "published": "2025-04-06 16:24:22", "link": "http://arxiv.org/abs/2504.04534v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hessian of Perplexity for Large Language Models by PyTorch autograd (Open Source)", "abstract": "Computing the full Hessian matrix -- the matrix of second-order derivatives\nfor an entire Large Language Model (LLM) is infeasible due to its sheer size.\nIn this technical report, we aim to provide a comprehensive guide on how to\naccurately compute at least a small portion of the Hessian for LLMs using\nPyTorch autograd library. We also demonstrate how to compute the full diagonal\nof the Hessian matrix using multiple samples of vector-Hessian Products (HVPs).\nWe hope that both this guide and the accompanying GitHub code will be valuable\nresources for practitioners and researchers interested in better understanding\nthe behavior and structure of the Hessian in LLMs.", "published": "2025-04-06 15:37:04", "link": "http://arxiv.org/abs/2504.04520v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T07, 65K10, 65Y05"], "primary_category": "cs.LG"}
{"title": "Saliency-driven Dynamic Token Pruning for Large Language Models", "abstract": "Despite the recent success of large language models (LLMs), LLMs are\nparticularly challenging in long-sequence inference scenarios due to the\nquadratic computational complexity of the attention mechanism. Inspired by the\ninterpretability theory of feature attribution in neural network models, we\nobserve that not all tokens have the same contribution. Based on this\nobservation, we propose a novel token pruning framework, namely Saliency-driven\nDynamic Token Pruning (SDTP), to gradually and dynamically prune redundant\ntokens based on the input context. Specifically, a lightweight saliency-driven\nprediction module is designed to estimate the importance score of each token\nwith its hidden state, which is added to different layers of the LLM to\nhierarchically prune redundant tokens. Furthermore, a ranking-based\noptimization strategy is proposed to minimize the ranking divergence of the\nsaliency score and the predicted importance score. Extensive experiments have\nshown that our framework is generalizable to various models and datasets. By\nhierarchically pruning 65\\% of the input tokens, our method greatly reduces\n33\\% $\\sim$ 47\\% FLOPs and achieves speedup up to 1.75$\\times$ during\ninference, while maintaining comparable performance. We further demonstrate\nthat SDTP can be combined with KV cache compression method for further\ncompression.", "published": "2025-04-06 15:15:07", "link": "http://arxiv.org/abs/2504.04514v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Directed Graph-alignment Approach for Identification of Gaps in Short Answers", "abstract": "In this paper, we have presented a method for identifying missing items known\nas gaps in the student answers by comparing them against the corresponding\nmodel answer/reference answers, automatically. The gaps can be identified at\nword, phrase or sentence level. The identified gaps are useful in providing\nfeedback to the students for formative assessment. The problem of gap\nidentification has been modelled as an alignment of a pair of directed graphs\nrepresenting a student answer and the corresponding model answer for a given\nquestion. To validate the proposed approach, the gap annotated student answers\nconsidering answers from three widely known datasets in the short answer\ngrading domain, namely, University of North Texas (UNT), SciEntsBank, and\nBeetle have been developed and this gap annotated student answers' dataset is\navailable at: https://github.com/sahuarchana7/gaps-answers-dataset. Evaluation\nmetrics used in the traditional machine learning tasks have been adopted to\nevaluate the task of gap identification. Though performance of the proposed\napproach varies across the datasets and the types of the answers, overall the\nperformance is observed to be promising.", "published": "2025-04-06 13:04:28", "link": "http://arxiv.org/abs/2504.04473v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An overview of model uncertainty and variability in LLM-based sentiment analysis. Challenges, mitigation strategies and the role of explainability", "abstract": "Large Language Models (LLMs) have significantly advanced sentiment analysis,\nyet their inherent uncertainty and variability pose critical challenges to\nachieving reliable and consistent outcomes. This paper systematically explores\nthe Model Variability Problem (MVP) in LLM-based sentiment analysis,\ncharacterized by inconsistent sentiment classification, polarization, and\nuncertainty arising from stochastic inference mechanisms, prompt sensitivity,\nand biases in training data. We analyze the core causes of MVP, presenting\nillustrative examples and a case study to highlight its impact. In addition, we\ninvestigate key challenges and mitigation strategies, paying particular\nattention to the role of temperature as a driver of output randomness and\nemphasizing the crucial role of explainability in improving transparency and\nuser trust. By providing a structured perspective on stability,\nreproducibility, and trustworthiness, this study helps develop more reliable,\nexplainable, and robust sentiment analysis models, facilitating their\ndeployment in high-stakes domains such as finance, healthcare, and\npolicymaking, among others.", "published": "2025-04-06 12:20:39", "link": "http://arxiv.org/abs/2504.04462v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prot42: a Novel Family of Protein Language Models for Target-aware Protein Binder Generation", "abstract": "Unlocking the next generation of biotechnology and therapeutic innovation\ndemands overcoming the inherent complexity and resource-intensity of\nconventional protein engineering methods. Recent GenAI-powered computational\ntechniques often rely on the availability of the target protein's 3D structures\nand specific binding sites to generate high-affinity binders, constraints\nexhibited by models such as AlphaProteo and RFdiffusion. In this work, we\nexplore the use of Protein Language Models (pLMs) for high-affinity binder\ngeneration. We introduce Prot42, a novel family of Protein Language Models\n(pLMs) pretrained on vast amounts of unlabeled protein sequences. By capturing\ndeep evolutionary, structural, and functional insights through an advanced\nauto-regressive, decoder-only architecture inspired by breakthroughs in natural\nlanguage processing, Prot42 dramatically expands the capabilities of\ncomputational protein design based on language only. Remarkably, our models\nhandle sequences up to 8,192 amino acids, significantly surpassing standard\nlimitations and enabling precise modeling of large proteins and complex\nmulti-domain sequences. Demonstrating powerful practical applications, Prot42\nexcels in generating high-affinity protein binders and sequence-specific\nDNA-binding proteins. Our innovative models are publicly available, offering\nthe scientific community an efficient and precise computational toolkit for\nrapid protein engineering.", "published": "2025-04-06 11:43:12", "link": "http://arxiv.org/abs/2504.04453v1", "categories": ["q-bio.BM", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "On the Spatial Structure of Mixture-of-Experts in Transformers", "abstract": "A common assumption is that MoE routers primarily leverage semantic features\nfor expert selection. However, our study challenges this notion by\ndemonstrating that positional token information also plays a crucial role in\nrouting decisions. Through extensive empirical analysis, we provide evidence\nsupporting this hypothesis, develop a phenomenological explanation of the\nobserved behavior, and discuss practical implications for MoE-based\narchitectures.", "published": "2025-04-06 11:31:55", "link": "http://arxiv.org/abs/2504.04444v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pre-trained Language Models and Few-shot Learning for Medical Entity Extraction", "abstract": "This study proposes a medical entity extraction method based on Transformer\nto enhance the information extraction capability of medical literature.\nConsidering the professionalism and complexity of medical texts, we compare the\nperformance of different pre-trained language models (BERT, BioBERT,\nPubMedBERT, ClinicalBERT) in medical entity extraction tasks. Experimental\nresults show that PubMedBERT achieves the best performance (F1-score = 88.8%),\nindicating that a language model pre-trained on biomedical literature is more\neffective in the medical domain. In addition, we analyze the impact of\ndifferent entity extraction methods (CRF, Span-based, Seq2Seq) and find that\nthe Span-based approach performs best in medical entity extraction tasks\n(F1-score = 88.6%). It demonstrates superior accuracy in identifying entity\nboundaries. In low-resource scenarios, we further explore the application of\nFew-shot Learning in medical entity extraction. Experimental results show that\neven with only 10-shot training samples, the model achieves an F1-score of\n79.1%, verifying the effectiveness of Few-shot Learning under limited data\nconditions. This study confirms that the combination of pre-trained language\nmodels and Few-shot Learning can enhance the accuracy of medical entity\nextraction. Future research can integrate knowledge graphs and active learning\nstrategies to improve the model's generalization and stability, providing a\nmore effective solution for medical NLP research. Keywords- Natural Language\nProcessing, medical named entity recognition, pre-trained language model,\nFew-shot Learning, information extraction, deep learning", "published": "2025-04-06 06:36:33", "link": "http://arxiv.org/abs/2504.04385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning", "abstract": "Large reasoning models exhibit remarkable reasoning capabilities via long,\nelaborate reasoning trajectories. Supervised fine-tuning on such reasoning\ntraces, also known as distillation, can be a cost-effective way to boost\nreasoning capabilities of student models. However, empirical observations\nreveal that these reasoning trajectories are often suboptimal, switching\nexcessively between different lines of thought, resulting in under-thinking,\nover-thinking, and even degenerate responses. We introduce Retro-Search, an\nMCTS-inspired search algorithm, for distilling higher quality reasoning paths\nfrom large reasoning models. Retro-Search retrospectively revises reasoning\npaths to discover better, yet shorter traces, which can then lead to student\nmodels with enhanced reasoning capabilities with shorter, thus faster\ninference. Our approach can enable two use cases: self-improvement, where\nmodels are fine-tuned on their own Retro-Search-ed thought traces, and\nweak-to-strong improvement, where a weaker model revises stronger model's\nthought traces via Retro-Search. For self-improving, R1-distill-7B, fine-tuned\non its own Retro-Search-ed traces, reduces the average reasoning length by\n31.2% while improving performance by 7.7% across seven math benchmarks. For\nweak-to-strong improvement, we retrospectively revise R1-671B's traces from the\nOpenThoughts dataset using R1-distill-32B as the Retro-Search-er, a model 20x\nsmaller. Qwen2.5-32B, fine-tuned on this refined data, achieves performance\ncomparable to R1-distill-32B, yielding an 11.3% reduction in reasoning length\nand a 2.4% performance improvement compared to fine-tuning on the original\nOpenThoughts data. Our work counters recently emergent viewpoints that question\nthe relevance of search algorithms in the era of large reasoning models, by\ndemonstrating that there are still opportunities for algorithmic advancements,\neven for frontier models.", "published": "2025-04-06 06:23:27", "link": "http://arxiv.org/abs/2504.04383v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages", "abstract": "Truly multilingual safety moderation efforts for Large Language Models (LLMs)\nhave been hindered by a narrow focus on a small set of languages (e.g.,\nEnglish, Chinese) as well as a limited scope of safety definition, resulting in\nsignificant gaps in moderation capabilities. To bridge these gaps, we release\nPOLYGUARD, a new state-of-the-art multilingual safety model for safeguarding\nLLM generations, and the corresponding training and evaluation datasets.\nPOLYGUARD is trained on POLYGUARDMIX, the largest multilingual safety training\ncorpus to date containing 1.91M samples across 17 languages (e.g., Chinese,\nCzech, English, Hindi). We also introduce POLYGUARDPROMPTS, a high quality\nmultilingual benchmark with 29K samples for the evaluation of safety\nguardrails. Created by combining naturally occurring multilingual human-LLM\ninteractions and human-verified machine translations of an English-only safety\ndataset (WildGuardMix; Han et al., 2024), our datasets contain prompt-output\npairs with labels of prompt harmfulness, response harmfulness, and response\nrefusal. Through extensive evaluations across multiple safety and toxicity\nbenchmarks, we demonstrate that POLYGUARD outperforms existing state-of-the-art\nopen-weight and commercial safety classifiers by 5.5%. Our contributions\nadvance efforts toward safer multilingual LLMs for all global users.", "published": "2025-04-06 06:09:21", "link": "http://arxiv.org/abs/2504.04377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StyleRec: A Benchmark Dataset for Prompt Recovery in Writing Style Transformation", "abstract": "Prompt Recovery, reconstructing prompts from the outputs of large language\nmodels (LLMs), has grown in importance as LLMs become ubiquitous. Most users\naccess LLMs through APIs without internal model weights, relying only on\noutputs and logits, which complicates recovery. This paper explores a unique\nprompt recovery task focused on reconstructing prompts for style transfer and\nrephrasing, rather than typical question-answering. We introduce a dataset\ncreated with LLM assistance, ensuring quality through multiple techniques, and\ntest methods like zero-shot, few-shot, jailbreak, chain-of-thought,\nfine-tuning, and a novel canonical-prompt fallback for poor-performing cases.\nOur results show that one-shot and fine-tuning yield the best outcomes but\nhighlight flaws in traditional sentence similarity metrics for evaluating\nprompt recovery. Contributions include (1) a benchmark dataset, (2)\ncomprehensive experiments on prompt recovery strategies, and (3) identification\nof limitations in current evaluation metrics, all of which advance general\nprompt recovery research, where the structure of the input prompt is\nunrestricted.", "published": "2025-04-06 06:02:28", "link": "http://arxiv.org/abs/2504.04373v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code Generation", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation. However, the quality of the generated code is heavily\ndependent on the structure and composition of the prompts used. Crafting\nhigh-quality prompts is a challenging task that requires significant knowledge\nand skills of prompt engineering. To advance the automation support for the\nprompt engineering for LLM-based code generation, we propose a novel solution\nDiffusion-Driven Prompt Tuning (DDPT) that learns how to generate optimal\nprompt embedding from Gaussian Noise to automate the prompt engineering for\ncode generation. We evaluate the feasibility of diffusion-based optimization\nand abstract the optimal prompt embedding as a directional vector toward the\noptimal embedding. We use the code generation loss given by the LLMs to help\nthe diffusion model capture the distribution of optimal prompt embedding during\ntraining. The trained diffusion model can build a path from the noise\ndistribution to the optimal distribution at the sampling phrase, the evaluation\nresult demonstrates that DDPT helps improve the prompt optimization for code\ngeneration.", "published": "2025-04-06 04:19:19", "link": "http://arxiv.org/abs/2504.04351v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Compression Laws for Large Language Models", "abstract": "We introduce compression laws for language language models (LLMs). While\nrecent scaling laws have sought to understand how LLMs scale with respect to\nmodel size, pre-training data, and computational resources, we focus on\nunderstanding how model compression affects the performance of a pre-trained\nLLM on downstream tasks. We empirically examine the effects of structured model\ncompression on LLMs through over $1000$ experiments across eight models with\nsizes ranging from $0.5B$ to $14B$ parameters. Our findings indicate that the\ntest cross-entropy loss increases quadratically with the compression ratio,\nwhereas performance on downstream tasks declines only linearly. Our study\nemphasizes the importance of recovery fine-tuning in enhancing generation loss,\nshowing that the test loss of compressed LLMs can improve by up to 55% with\nrecovery fine-tuning. At higher compression ratios (up to 90%), compressed LLMs\ndemonstrate a speed increase of 60% during inference compared to their\nuncompressed counterparts, compensating for the performance degradation at this\nlevel. However, for smaller models ($\\le 7B$), the computational gains are\nlimited, peaking at just 35%. We conclude that model compression can be highly\nbeneficial for larger models, especially when a smaller model within the same\ncomputational budget is not available. These insights provide the practical\nguidelines for utilizing model compression techniques for adopting LLMs in\nreal-life applications in resource-constrained settings.", "published": "2025-04-06 03:39:34", "link": "http://arxiv.org/abs/2504.04342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Large Language Models Trained for Detecting Errors in Radiology Reports", "abstract": "In this retrospective study, a dataset was constructed with two parts. The\nfirst part included 1,656 synthetic chest radiology reports generated by GPT-4\nusing specified prompts, with 828 being error-free synthetic reports and 828\ncontaining errors. The second part included 614 reports: 307 error-free reports\nbetween 2011 and 2016 from the MIMIC-CXR database and 307 corresponding\nsynthetic reports with errors generated by GPT-4 on the basis of these\nMIMIC-CXR reports and specified prompts. All errors were categorized into four\ntypes: negation, left/right, interval change, and transcription errors. Then,\nseveral models, including Llama-3, GPT-4, and BiomedBERT, were refined using\nzero-shot prompting, few-shot prompting, or fine-tuning strategies. Finally,\nthe performance of these models was evaluated using the F1 score, 95\\%\nconfidence interval (CI) and paired-sample t-tests on our constructed dataset,\nwith the prediction results further assessed by radiologists. Using zero-shot\nprompting, the fine-tuned Llama-3-70B-Instruct model achieved the best\nperformance with the following F1 scores: 0.769 for negation errors, 0.772 for\nleft/right errors, 0.750 for interval change errors, 0.828 for transcription\nerrors, and 0.780 overall. In the real-world evaluation phase, two radiologists\nreviewed 200 randomly selected reports output by the model. Of these, 99 were\nconfirmed to contain errors detected by the models by both radiologists, and\n163 were confirmed to contain model-detected errors by at least one\nradiologist. Generative LLMs, fine-tuned on synthetic and MIMIC-CXR radiology\nreports, greatly enhanced error detection in radiology reports.", "published": "2025-04-06 03:02:36", "link": "http://arxiv.org/abs/2504.04336v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hallucination Detection using Multi-View Attention Features", "abstract": "This study tackles token-level hallucination detection in outputs of large\nlanguage models. Previous studies revealed that attention exhibits irregular\npatterns when hallucination occurs. Inspired by this, we extract features from\nthe attention matrix that provide complementary views of (a) the average\nattention each token receives, which helps identify whether certain tokens are\noverly influential or ignored, (b) the diversity of attention each token\nreceives, which reveals whether attention is biased toward specific subsets,\nand (c) the diversity of tokens a token attends to during generation, which\nindicates whether the model references a narrow or broad range of information.\nThese features are input to a Transformer-based classifier to conduct\ntoken-level classification to identify hallucinated spans. Experimental results\nindicate that the proposed method outperforms strong baselines on hallucination\ndetection with longer input contexts, i.e., data-to-text and summarization\ntasks.", "published": "2025-04-06 03:00:58", "link": "http://arxiv.org/abs/2504.04335v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IMPersona: Evaluating Individual Level LM Impersonation", "abstract": "As language models achieve increasingly human-like capabilities in\nconversational text generation, a critical question emerges: to what extent can\nthese systems simulate the characteristics of specific individuals? To evaluate\nthis, we introduce IMPersona, a framework for evaluating LMs at impersonating\nspecific individuals' writing style and personal knowledge. Using supervised\nfine-tuning and a hierarchical memory-inspired retrieval system, we demonstrate\nthat even modestly sized open-source models, such as Llama-3.1-8B-Instruct, can\nachieve impersonation abilities at concerning levels. In blind conversation\nexperiments, participants (mis)identified our fine-tuned models with memory\nintegration as human in 44.44% of interactions, compared to just 25.00% for the\nbest prompting-based approach. We analyze these results to propose detection\nmethods and defense strategies against such impersonation attempts. Our\nfindings raise important questions about both the potential applications and\nrisks of personalized language models, particularly regarding privacy,\nsecurity, and the ethical deployment of such technologies in real-world\ncontexts.", "published": "2025-04-06 02:57:58", "link": "http://arxiv.org/abs/2504.04332v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constructing the Truth: Text Mining and Linguistic Networks in Public Hearings of Case 03 of the Special Jurisdiction for Peace (JEP)", "abstract": "Case 03 of the Special Jurisdiction for Peace (JEP), focused on the so-called\nfalse positives in Colombia, represents one of the most harrowing episodes of\nthe Colombian armed conflict. This article proposes an innovative methodology\nbased on natural language analysis and semantic co-occurrence models to\nexplore, systematize, and visualize narrative patterns present in the public\nhearings of victims and appearing parties. By constructing skipgram networks\nand analyzing their modularity, the study identifies thematic clusters that\nreveal regional and procedural status differences, providing empirical evidence\non dynamics of victimization, responsibility, and acknowledgment in this case.\nThis computational approach contributes to the collective construction of both\njudicial and extrajudicial truth, offering replicable tools for other\ntransitional justice cases. The work is grounded in the pillars of truth,\njustice, reparation, and non-repetition, proposing a critical and in-depth\nreading of contested memories.", "published": "2025-04-06 02:04:27", "link": "http://arxiv.org/abs/2504.04325v1", "categories": ["cs.CL", "stat.AP", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Balancing Complexity and Informativeness in LLM-Based Clustering: Finding the Goldilocks Zone", "abstract": "The challenge of clustering short text data lies in balancing informativeness\nwith interpretability. Traditional evaluation metrics often overlook this\ntrade-off. Inspired by linguistic principles of communicative efficiency, this\npaper investigates the optimal number of clusters by quantifying the trade-off\nbetween informativeness and cognitive simplicity. We use large language models\n(LLMs) to generate cluster names and evaluate their effectiveness through\nsemantic density, information theory, and clustering accuracy. Our results show\nthat Gaussian Mixture Model (GMM) clustering on embeddings generated by a LLM,\nincreases semantic density compared to random assignment, effectively grouping\nsimilar bios. However, as clusters increase, interpretability declines, as\nmeasured by a generative LLM's ability to correctly assign bios based on\ncluster names. A logistic regression analysis confirms that classification\naccuracy depends on the semantic similarity between bios and their assigned\ncluster names, as well as their distinction from alternatives.\n  These findings reveal a \"Goldilocks zone\" where clusters remain distinct yet\ninterpretable. We identify an optimal range of 16-22 clusters, paralleling\nlinguistic efficiency in lexical categorization. These insights inform both\ntheoretical models and practical applications, guiding future research toward\noptimising cluster interpretability and usefulness.", "published": "2025-04-06 01:16:22", "link": "http://arxiv.org/abs/2504.04314v1", "categories": ["cs.CL", "cs.AI", "math.ST", "stat.TH"], "primary_category": "cs.CL"}
{"title": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization", "abstract": "Although LLM-based agents have attracted significant attention in domains\nsuch as software engineering and machine learning research, their role in\nadvancing combinatorial optimization (CO) remains relatively underexplored.\nThis gap underscores the need for a deeper understanding of their potential in\ntackling structured, constraint-intensive problems-a pursuit currently limited\nby the absence of comprehensive benchmarks for systematic investigation. To\naddress this, we introduce CO-Bench, a benchmark suite featuring 36 real-world\nCO problems drawn from a broad range of domains and complexity levels. CO-Bench\nincludes structured problem formulations and curated data to support rigorous\ninvestigation of LLM agents. We evaluate multiple agent frameworks against\nestablished human-designed algorithms, revealing key strengths and limitations\nof current approaches and identifying promising directions for future research.\nCO-Bench is publicly available at https://github.com/sunnweiwei/CO-Bench.", "published": "2025-04-06 00:47:43", "link": "http://arxiv.org/abs/2504.04310v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gating is Weighting: Understanding Gated Linear Attention through In-context Learning", "abstract": "Linear attention methods offer a compelling alternative to softmax attention\ndue to their efficiency in recurrent decoding. Recent research has focused on\nenhancing standard linear attention by incorporating gating while retaining its\ncomputational benefits. Such Gated Linear Attention (GLA) architectures include\ncompetitive models such as Mamba and RWKV. In this work, we investigate the\nin-context learning capabilities of the GLA model and make the following\ncontributions. We show that a multilayer GLA can implement a general class of\nWeighted Preconditioned Gradient Descent (WPGD) algorithms with data-dependent\nweights. These weights are induced by the gating mechanism and the input,\nenabling the model to control the contribution of individual tokens to\nprediction. To further understand the mechanics of this weighting, we introduce\na novel data model with multitask prompts and characterize the optimization\nlandscape of learning a WPGD algorithm. Under mild conditions, we establish the\nexistence and uniqueness (up to scaling) of a global minimum, corresponding to\na unique WPGD solution. Finally, we translate these findings to explore the\noptimization landscape of GLA and shed light on how gating facilitates\ncontext-aware learning and when it is provably better than vanilla linear\nattention.", "published": "2025-04-06 00:37:36", "link": "http://arxiv.org/abs/2504.04308v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.OC"], "primary_category": "cs.LG"}
{"title": "Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical Image Segmentation", "abstract": "Deep learning has been successfully applied to medical image segmentation,\nenabling accurate identification of regions of interest such as organs and\nlesions. This approach works effectively across diverse datasets, including\nthose with single-image contrast, multi-contrast, and multimodal imaging data.\nTo improve human understanding of these black-box models, there is a growing\nneed for Explainable AI (XAI) techniques for model transparency and\naccountability. Previous research has primarily focused on post hoc pixel-level\nexplanations, using methods gradient-based and perturbation-based apporaches.\nThese methods rely on gradients or perturbations to explain model predictions.\nHowever, these pixel-level explanations often struggle with the complexity\ninherent in multi-contrast magnetic resonance imaging (MRI) segmentation tasks,\nand the sparsely distributed explanations have limited clinical relevance. In\nthis study, we propose using contrast-level Shapley values to explain\nstate-of-the-art models trained on standard metrics used in brain tumor\nsegmentation. Our results demonstrate that Shapley analysis provides valuable\ninsights into different models' behavior used for tumor segmentation. We\ndemonstrated a bias for U-Net towards over-weighing T1-contrast and FLAIR,\nwhile Swin-UNETR provided a cross-contrast understanding with balanced Shapley\ndistribution.", "published": "2025-04-06 23:52:07", "link": "http://arxiv.org/abs/2504.04645v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DanceMosaic: High-Fidelity Dance Generation with Multimodal Editability", "abstract": "Recent advances in dance generation have enabled automatic synthesis of 3D\ndance motions. However, existing methods still struggle to produce\nhigh-fidelity dance sequences that simultaneously deliver exceptional realism,\nprecise dance-music synchronization, high motion diversity, and physical\nplausibility. Moreover, existing methods lack the flexibility to edit dance\nsequences according to diverse guidance signals, such as musical prompts, pose\nconstraints, action labels, and genre descriptions, significantly restricting\ntheir creative utility and adaptability. Unlike the existing approaches,\nDanceMosaic enables fast and high-fidelity dance generation, while allowing\nmultimodal motion editing. Specifically, we propose a multimodal masked motion\nmodel that fuses the text-to-motion model with music and pose adapters to learn\nprobabilistic mapping from diverse guidance signals to high-quality dance\nmotion sequences via progressive generative masking training. To further\nenhance the motion generation quality, we propose multimodal classifier-free\nguidance and inference-time optimization mechanism that further enforce the\nalignment between the generated motions and the multimodal guidance. Extensive\nexperiments demonstrate that our method establishes a new state-of-the-art\nperformance in dance generation, significantly advancing the quality and\neditability achieved by existing approaches.", "published": "2025-04-06 22:05:37", "link": "http://arxiv.org/abs/2504.04634v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "M2IV: Towards Efficient and Fine-grained Multimodal In-Context Learning in Large Vision-Language Models", "abstract": "Multimodal in-context learning (ICL) is a vital capability for Large\nVision-Language Models (LVLMs), allowing task adaptation via contextual prompts\nwithout parameter retraining. However, its application is hindered by the\ntoken-intensive nature of inputs and the high complexity of cross-modal\nfew-shot learning, which limits the expressive power of representation methods.\nTo tackle these challenges, we propose \\textbf{M2IV}, a method that substitutes\nexplicit demonstrations with learnable \\textbf{I}n-context \\textbf{V}ectors\ndirectly integrated into LVLMs. By exploiting the complementary strengths of\nmulti-head attention (\\textbf{M}HA) and multi-layer perceptrons (\\textbf{M}LP),\nM2IV achieves robust cross-modal fidelity and fine-grained semantic\ndistillation through training. This significantly enhances performance across\ndiverse LVLMs and tasks and scales efficiently to many-shot scenarios,\nbypassing the context window limitations. We also introduce \\textbf{VLibrary},\na repository for storing and retrieving M2IV, enabling flexible LVLM steering\nfor tasks like cross-modal alignment, customized generation and safety\nimprovement. Experiments across seven benchmarks and three LVLMs show that M2IV\nsurpasses Vanilla ICL and prior representation engineering approaches, with an\naverage accuracy gain of \\textbf{3.74\\%} over ICL with the same shot count,\nalongside substantial efficiency advantages.", "published": "2025-04-06 22:02:21", "link": "http://arxiv.org/abs/2504.04633v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Tool-as-Interface: Learning Robot Policies from Human Tool Usage through Imitation Learning", "abstract": "Tool use is critical for enabling robots to perform complex real-world tasks,\nand leveraging human tool-use data can be instrumental for teaching robots.\nHowever, existing data collection methods like teleoperation are slow, prone to\ncontrol delays, and unsuitable for dynamic tasks. In contrast, human natural\ndata, where humans directly perform tasks with tools, offers natural,\nunstructured interactions that are both efficient and easy to collect. Building\non the insight that humans and robots can share the same tools, we propose a\nframework to transfer tool-use knowledge from human data to robots. Using two\nRGB cameras, our method generates 3D reconstruction, applies Gaussian splatting\nfor novel view augmentation, employs segmentation models to extract\nembodiment-agnostic observations, and leverages task-space tool-action\nrepresentations to train visuomotor policies. We validate our approach on\ndiverse real-world tasks, including meatball scooping, pan flipping, wine\nbottle balancing, and other complex tasks. Our method achieves a 71\\% higher\naverage success rate compared to diffusion policies trained with teleoperation\ndata and reduces data collection time by 77\\%, with some tasks solvable only by\nour framework. Compared to hand-held gripper, our method cuts data collection\ntime by 41\\%. Additionally, our method bridges the embodiment gap, improves\nrobustness to variations in camera viewpoints and robot configurations, and\ngeneralizes effectively across objects and spatial setups.", "published": "2025-04-06 20:40:19", "link": "http://arxiv.org/abs/2504.04612v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "AI in a vat: Fundamental limits of efficient world modelling for agent sandboxing and interpretability", "abstract": "Recent work proposes using world models to generate controlled virtual\nenvironments in which AI agents can be tested before deployment to ensure their\nreliability and safety. However, accurate world models often have high\ncomputational demands that can severely restrict the scope and depth of such\nassessments. Inspired by the classic `brain in a vat' thought experiment, here\nwe investigate ways of simplifying world models that remain agnostic to the AI\nagent under evaluation. By following principles from computational mechanics,\nour approach reveals a fundamental trade-off in world model construction\nbetween efficiency and interpretability, demonstrating that no single world\nmodel can optimise all desirable characteristics. Building on this trade-off,\nwe identify procedures to build world models that either minimise memory\nrequirements, delineate the boundaries of what is learnable, or allow tracking\ncauses of undesirable outcomes. In doing so, this work establishes fundamental\nlimits in world modelling, leading to actionable guidelines that inform core\ndesign choices related to effective agent evaluation.", "published": "2025-04-06 20:35:44", "link": "http://arxiv.org/abs/2504.04608v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Capturing AI's Attention: Physics of Repetition, Hallucination, Bias and Beyond", "abstract": "We derive a first-principles physics theory of the AI engine at the heart of\nLLMs' 'magic' (e.g. ChatGPT, Claude): the basic Attention head. The theory\nallows a quantitative analysis of outstanding AI challenges such as output\nrepetition, hallucination and harmful content, and bias (e.g. from training and\nfine-tuning). Its predictions are consistent with large-scale LLM outputs. Its\n2-body form suggests why LLMs work so well, but hints that a generalized 3-body\nAttention would make such AI work even better. Its similarity to a spin-bath\nmeans that existing Physics expertise could immediately be harnessed to help\nSociety ensure AI is trustworthy and resilient to manipulation.", "published": "2025-04-06 20:10:05", "link": "http://arxiv.org/abs/2504.04600v1", "categories": ["cs.AI", "cond-mat.other", "math-ph", "math.MP", "nlin.AO", "physics.soc-ph"], "primary_category": "cs.AI"}
{"title": "\"You just can't go around killing people\" Explaining Agent Behavior to a Human Terminator", "abstract": "Consider a setting where a pre-trained agent is operating in an environment\nand a human operator can decide to temporarily terminate its operation and\ntake-over for some duration of time. These kind of scenarios are common in\nhuman-machine interactions, for example in autonomous driving, factory\nautomation and healthcare. In these settings, we typically observe a trade-off\nbetween two extreme cases -- if no take-overs are allowed, then the agent might\nemploy a sub-optimal, possibly dangerous policy. Alternatively, if there are\ntoo many take-overs, then the human has no confidence in the agent, greatly\nlimiting its usefulness. In this paper, we formalize this setup and propose an\nexplainability scheme to help optimize the number of human interventions.", "published": "2025-04-06 19:29:45", "link": "http://arxiv.org/abs/2504.04592v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Your Image Generator Is Your New Private Dataset", "abstract": "Generative diffusion models have emerged as powerful tools to synthetically\nproduce training data, offering potential solutions to data scarcity and\nreducing labelling costs for downstream supervised deep learning applications.\nHowever, effectively leveraging text-conditioned image generation for building\nclassifier training sets requires addressing key issues: constructing\ninformative textual prompts, adapting generative models to specific domains,\nand ensuring robust performance. This paper proposes the Text-Conditioned\nKnowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines\ndynamic image captioning, parameter-efficient diffusion model fine-tuning, and\nGenerative Knowledge Distillation techniques to create synthetic datasets\ntailored for image classification. The pipeline is rigorously evaluated on ten\ndiverse image classification benchmarks. The results demonstrate that models\ntrained solely on TCKR-generated data achieve classification accuracies on par\nwith (and in several cases exceeding) models trained on real images.\nFurthermore, the evaluation reveals that these synthetic-data-trained models\nexhibit substantially enhanced privacy characteristics: their vulnerability to\nMembership Inference Attacks is significantly reduced, with the membership\ninference AUC lowered by 5.49 points on average compared to using real training\ndata, demonstrating a substantial improvement in the performance-privacy\ntrade-off. These findings indicate that high-fidelity synthetic data can\neffectively replace real data for training classifiers, yielding strong\nperformance whilst simultaneously providing improved privacy protection as a\nvaluable emergent property. The code and trained models are available in the\naccompanying open-source repository.", "published": "2025-04-06 18:46:08", "link": "http://arxiv.org/abs/2504.04582v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification", "abstract": "Large Language Models (LLMs) have shown promise as robotic planners but often\nstruggle with long-horizon and complex tasks, especially in specialized\nenvironments requiring external knowledge. While hierarchical planning and\nRetrieval-Augmented Generation (RAG) address some of these challenges, they\nremain insufficient on their own and a deeper integration is required for\nachieving more reliable systems. To this end, we propose a neuro-symbolic\napproach that enhances LLMs-based planners with Knowledge Graph-based RAG for\nhierarchical plan generation. This method decomposes complex tasks into\nmanageable subtasks, further expanded into executable atomic action sequences.\nTo ensure formal correctness and proper decomposition, we integrate a Symbolic\nValidator, which also functions as a failure detector by aligning expected and\nobserved world states. Our evaluation against baseline methods demonstrates the\nconsistent significant advantages of integrating hierarchical planning,\nsymbolic verification, and RAG across tasks of varying complexity and different\nLLMs. Additionally, our experimental setup and novel metrics not only validate\nour approach for complex planning but also serve as a tool for assessing LLMs'\nreasoning and compositional capabilities.", "published": "2025-04-06 18:36:30", "link": "http://arxiv.org/abs/2504.04578v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Planning Safety Trajectories with Dual-Phase, Physics-Informed, and Transportation Knowledge-Driven Large Language Models", "abstract": "Foundation models have demonstrated strong reasoning and generalization\ncapabilities in driving-related tasks, including scene understanding, planning,\nand control. However, they still face challenges in hallucinations,\nuncertainty, and long inference latency. While existing foundation models have\ngeneral knowledge of avoiding collisions, they often lack\ntransportation-specific safety knowledge. To overcome these limitations, we\nintroduce LetsPi, a physics-informed, dual-phase, knowledge-driven framework\nfor safe, human-like trajectory planning. To prevent hallucinations and\nminimize uncertainty, this hybrid framework integrates Large Language Model\n(LLM) reasoning with physics-informed social force dynamics. LetsPi leverages\nthe LLM to analyze driving scenes and historical information, providing\nappropriate parameters and target destinations (goals) for the social force\nmodel, which then generates the future trajectory. Moreover, the dual-phase\narchitecture balances reasoning and computational efficiency through its Memory\nCollection phase and Fast Inference phase. The Memory Collection phase\nleverages the physics-informed LLM to process and refine planning results\nthrough reasoning, reflection, and memory modules, storing safe, high-quality\ndriving experiences in a memory bank. Surrogate safety measures and\nphysics-informed prompt techniques are introduced to enhance the LLM's\nknowledge of transportation safety and physical force, respectively. The Fast\nInference phase extracts similar driving experiences as few-shot examples for\nnew scenarios, while simplifying input-output requirements to enable rapid\ntrajectory planning without compromising safety. Extensive experiments using\nthe HighD dataset demonstrate that LetsPi outperforms baseline models across\nfive safety metrics.See PDF for project Github link.", "published": "2025-04-06 17:34:33", "link": "http://arxiv.org/abs/2504.04562v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Advancing Egocentric Video Question Answering with Multimodal Large Language Models", "abstract": "Egocentric Video Question Answering (QA) requires models to handle\nlong-horizon temporal reasoning, first-person perspectives, and specialized\nchallenges like frequent camera movement. This paper systematically evaluates\nboth proprietary and open-source Multimodal Large Language Models (MLLMs) on\nQaEgo4Dv2 - a refined dataset of egocentric videos derived from QaEgo4D. Four\npopular MLLMs (GPT-4o, Gemini-1.5-Pro, Video-LLaVa-7B and Qwen2-VL-7B-Instruct)\nare assessed using zero-shot and fine-tuned approaches for both OpenQA and\nCloseQA settings. We introduce QaEgo4Dv2 to mitigate annotation noise in\nQaEgo4D, enabling more reliable comparison. Our results show that fine-tuned\nVideo-LLaVa-7B and Qwen2-VL-7B-Instruct achieve new state-of-the-art\nperformance, surpassing previous benchmarks by up to +2.6% ROUGE/METEOR (for\nOpenQA) and +13% accuracy (for CloseQA). We also present a thorough error\nanalysis, indicating the model's difficulty in spatial reasoning and\nfine-grained object recognition - key areas for future improvement.", "published": "2025-04-06 16:58:23", "link": "http://arxiv.org/abs/2504.04550v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models?", "abstract": "3D Large Language Models (LLMs) leveraging spatial information in point\nclouds for 3D spatial reasoning attract great attention. Despite some promising\nresults, the role of point clouds in 3D spatial reasoning remains\nunder-explored. In this work, we comprehensively evaluate and analyze these\nmodels to answer the research question: \\textit{Does point cloud truly boost\nthe spatial reasoning capacities of 3D LLMs?} We first evaluate the spatial\nreasoning capacity of LLMs with different input modalities by replacing the\npoint cloud with the visual and text counterparts. We then propose a novel 3D\nQA (Question-answering) benchmark, ScanReQA, that comprehensively evaluates\nmodels' understanding of binary spatial relationships. Our findings reveal\nseveral critical insights: 1) LLMs without point input could even achieve\ncompetitive performance even in a zero-shot manner; 2) existing 3D LLMs\nstruggle to comprehend the binary spatial relationships; 3) 3D LLMs exhibit\nlimitations in exploiting the structural coordinates in point clouds for\nfine-grained spatial reasoning. We think these conclusions can help the next\nstep of 3D LLMs and also offer insights for foundation models in other\nmodalities. We release datasets and reproducible codes in the anonymous project\npage: https://3d-llm.xyz.", "published": "2025-04-06 16:38:48", "link": "http://arxiv.org/abs/2504.04540v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SnapPix: Efficient-Coding--Inspired In-Sensor Compression for Edge Vision", "abstract": "Energy-efficient image acquisition on the edge is crucial for enabling remote\nsensing applications where the sensor node has weak compute capabilities and\nmust transmit data to a remote server/cloud for processing. To reduce the edge\nenergy consumption, this paper proposes a sensor-algorithm co-designed system\ncalled SnapPix, which compresses raw pixels in the analog domain inside the\nsensor. We use coded exposure (CE) as the in-sensor compression strategy as it\noffers the flexibility to sample, i.e., selectively expose pixels, both\nspatially and temporally. SNAPPIX has three contributions. First, we propose a\ntask-agnostic strategy to learn the sampling/exposure pattern based on the\nclassic theory of efficient coding. Second, we co-design the downstream vision\nmodel with the exposure pattern to address the pixel-level non-uniformity\nunique to CE-compressed images. Finally, we propose lightweight augmentations\nto the image sensor hardware to support our in-sensor CE compression.\nEvaluating on action recognition and video reconstruction, SnapPix outperforms\nstate-of-the-art video-based methods at the same speed while reducing the\nenergy by up to 15.4x. We have open-sourced the code at:\nhttps://github.com/horizon-research/SnapPix.", "published": "2025-04-06 16:24:45", "link": "http://arxiv.org/abs/2504.04535v1", "categories": ["cs.CV", "cs.AI", "I.2"], "primary_category": "cs.CV"}
{"title": "A Consequentialist Critique of Binary Classification Evaluation Practices", "abstract": "ML-supported decisions, such as ordering tests or determining preventive\ncustody, often involve binary classification based on probabilistic forecasts.\nEvaluation frameworks for such forecasts typically consider whether to\nprioritize independent-decision metrics (e.g., Accuracy) or top-K metrics\n(e.g., Precision@K), and whether to focus on fixed thresholds or\nthreshold-agnostic measures like AUC-ROC. We highlight that a consequentialist\nperspective, long advocated by decision theorists, should naturally favor\nevaluations that support independent decisions using a mixture of thresholds\ngiven their prevalence, such as Brier scores and Log loss. However, our\nempirical analysis reveals a strong preference for top-K metrics or fixed\nthresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To\naddress this gap, we use this decision-theoretic framework to map evaluation\nmetrics to their optimal use cases, along with a Python package, briertools, to\npromote the broader adoption of Brier scores. In doing so, we also uncover new\ntheoretical connections, including a reconciliation between the Brier Score and\nDecision Curve Analysis, which clarifies and responds to a longstanding\ncritique by (Assel, et al. 2017) regarding the clinical utility of proper\nscoring rules.", "published": "2025-04-06 15:58:01", "link": "http://arxiv.org/abs/2504.04528v1", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Trust Region Preference Approximation: A simple and stable reinforcement learning algorithm for LLM reasoning", "abstract": "Recently, Large Language Models (LLMs) have rapidly evolved, approaching\nArtificial General Intelligence (AGI) while benefiting from large-scale\nreinforcement learning to enhance Human Alignment (HA) and Reasoning. Recent\nreward-based optimization algorithms, such as Proximal Policy Optimization\n(PPO) and Group Relative Policy Optimization (GRPO) have achieved significant\nperformance on reasoning tasks, whereas preference-based optimization\nalgorithms such as Direct Preference Optimization (DPO) significantly improve\nthe performance of LLMs on human alignment. However, despite the strong\nperformance of reward-based optimization methods in alignment tasks , they\nremain vulnerable to reward hacking. Furthermore, preference-based algorithms\n(such as Online DPO) haven't yet matched the performance of reward-based\noptimization algorithms (like PPO) on reasoning tasks, making their exploration\nin this specific area still a worthwhile pursuit. Motivated by these\nchallenges, we propose the Trust Region Preference Approximation (TRPA)\nalgorithm, which integrates rule-based optimization with preference-based\noptimization for reasoning tasks. As a preference-based algorithm, TRPA\nnaturally eliminates the reward hacking issue. TRPA constructs preference\nlevels using predefined rules, forms corresponding preference pairs, and\nleverages a novel optimization algorithm for RL training with a theoretical\nmonotonic improvement guarantee. Experimental results demonstrate that TRPA not\nonly achieves competitive performance on reasoning tasks but also exhibits\nrobust stability. The code of this paper are released and updating on\nhttps://github.com/XueruiSu/Trust-Region-Preference-Approximation.git.", "published": "2025-04-06 15:48:26", "link": "http://arxiv.org/abs/2504.04524v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection", "abstract": "Foundation models pretrained on extensive datasets, such as GroundingDINO and\nLAE-DINO, have performed remarkably in the cross-domain few-shot object\ndetection (CD-FSOD) task. Through rigorous few-shot training, we found that the\nintegration of image-based data augmentation techniques and grid-based\nsub-domain search strategy significantly enhances the performance of these\nfoundation models. Building upon GroundingDINO, we employed several widely used\nimage augmentation methods and established optimization objectives to\neffectively navigate the expansive domain space in search of optimal\nsub-domains. This approach facilitates efficient few-shot object detection and\nintroduces an approach to solving the CD-FSOD problem by efficiently searching\nfor the optimal parameter configuration from the foundation model. Our findings\nsubstantially advance the practical deployment of vision-language models in\ndata-scarce environments, offering critical insights into optimizing their\ncross-domain generalization capabilities without labor-intensive retraining.\nCode is available at https://github.com/jaychempan/ETS.", "published": "2025-04-06 15:30:35", "link": "http://arxiv.org/abs/2504.04517v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Statistical Guarantees Of False Discovery Rate In Medical Instance Segmentation Tasks Based on Conformal Risk Control", "abstract": "Instance segmentation plays a pivotal role in medical image analysis by\nenabling precise localization and delineation of lesions, tumors, and\nanatomical structures. Although deep learning models such as Mask R-CNN and\nBlendMask have achieved remarkable progress, their application in high-risk\nmedical scenarios remains constrained by confidence calibration issues, which\nmay lead to misdiagnosis. To address this challenge, we propose a robust\nquality control framework based on conformal prediction theory. This framework\ninnovatively constructs a risk-aware dynamic threshold mechanism that\nadaptively adjusts segmentation decision boundaries according to clinical\nrequirements.Specifically, we design a \\textbf{calibration-aware loss function}\nthat dynamically tunes the segmentation threshold based on a user-defined risk\nlevel $\\alpha$. Utilizing exchangeable calibration data, this method ensures\nthat the expected FNR or FDR on test data remains below $\\alpha$ with high\nprobability. The framework maintains compatibility with mainstream segmentation\nmodels (e.g., Mask R-CNN, BlendMask+ResNet-50-FPN) and datasets (PASCAL VOC\nformat) without requiring architectural modifications. Empirical results\ndemonstrate that we rigorously bound the FDR metric marginally over the test\nset via our developed calibration framework.", "published": "2025-04-06 13:31:19", "link": "http://arxiv.org/abs/2504.04482v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI2STOW: End-to-End Deep Reinforcement Learning to Construct Master Stowage Plans under Demand Uncertainty", "abstract": "The worldwide economy and environmental sustainability depend on eff icient\nand reliable supply chains, in which container shipping plays a crucial role as\nan environmentally friendly mode of transport. Liner shipping companies seek to\nimprove operational efficiency by solving the stowage planning problem. Due to\nmany complex combinatorial aspects, stowage planning is challenging and often\ndecomposed into two NP-hard subproblems: master and slot planning. This article\nproposes AI2STOW, an end-to-end deep reinforcement learning model with\nfeasibility projection and an action mask to create master plans under demand\nuncertainty with global objectives and constraints, including paired block\nstowage patterms. Our experimental results demonstrate that AI2STOW outperforms\nbaseline methods from reinforcement learning and stochastic programming in\nobjective performance and computational efficiency, based on simulated\ninstances reflecting the scale of realistic vessels and operational planning\nhorizons.", "published": "2025-04-06 12:45:25", "link": "http://arxiv.org/abs/2504.04469v1", "categories": ["math.OC", "cs.AI", "cs.LG"], "primary_category": "math.OC"}
{"title": "LoopGen: Training-Free Loopable Music Generation", "abstract": "Loops--short audio segments designed for seamless repetition--are central to\nmany music genres, particularly those rooted in dance and electronic styles.\nHowever, current generative music models struggle to produce truly loopable\naudio, as generating a short waveform alone does not guarantee a smooth\ntransition from its endpoint back to its start, often resulting in audible\ndiscontinuities.Loops--short audio segments designed for seamless\nrepetition--are central to many music genres, particularly those rooted in\ndance and electronic styles. However, current generative music models struggle\nto produce truly loopable audio, as generating a short waveform alone does not\nguarantee a smooth transition from its endpoint back to its start, often\nresulting in audible discontinuities.We address this gap by modifying a\nnon-autoregressive model (MAGNeT) to generate tokens in a circular pattern,\nletting the model attend to the beginning of the audio when creating its\nending. This inference-only approach results in generations that are aware of\nfuture context and loop naturally, without the need for any additional training\nor data. We evaluate the consistency of loop transitions by computing token\nperplexity around the seam of the loop, observing a 55% improvement. Blind\nlistening tests further confirm significant perceptual gains over baseline\nmethods, improving mean ratings by 70%. Taken together, these results highlight\nthe effectiveness of inference-only approaches in improving generative models\nand underscore the advantages of non-autoregressive methods for context-aware\nmusic generation.", "published": "2025-04-06 12:34:23", "link": "http://arxiv.org/abs/2504.04466v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "EclipseNETs: Learning Irregular Small Celestial Body Silhouettes", "abstract": "Accurately predicting eclipse events around irregular small bodies is crucial\nfor spacecraft navigation, orbit determination, and spacecraft systems\nmanagement. This paper introduces a novel approach leveraging neural implicit\nrepresentations to model eclipse conditions efficiently and reliably. We\npropose neural network architectures that capture the complex silhouettes of\nasteroids and comets with high precision. Tested on four well-characterized\nbodies - Bennu, Itokawa, 67P/Churyumov-Gerasimenko, and Eros - our method\nachieves accuracy comparable to traditional ray-tracing techniques while\noffering orders of magnitude faster performance. Additionally, we develop an\nindirect learning framework that trains these models directly from sparse\ntrajectory data using Neural Ordinary Differential Equations, removing the\nrequirement to have prior knowledge of an accurate shape model. This approach\nallows for the continuous refinement of eclipse predictions, progressively\nreducing errors and improving accuracy as new trajectory data is incorporated.", "published": "2025-04-06 11:51:44", "link": "http://arxiv.org/abs/2504.04455v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.AI", "cs.LG"], "primary_category": "astro-ph.EP"}
{"title": "Do We Need Responsible XR? Drawing on Responsible AI to Inform Ethical Research and Practice into XRAI / the Metaverse", "abstract": "This position paper for the CHI 2025 workshop \"Everyday AR through\nAI-in-the-Loop\" reflects on whether as a field HCI needs to define Responsible\nXR as a parallel to, and in conjunction with, Responsible AI, addressing the\nunique vulnerabilities posed by mass adoption of wearable AI-enabled AR glasses\nand XR devices that could enact AI-driven human perceptual augmentation.", "published": "2025-04-06 10:37:09", "link": "http://arxiv.org/abs/2504.04440v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence", "abstract": "Despite remarkable progress in machine learning, current AI systems continue\nto fall short of true human-like intelligence. While Large Language Models\n(LLMs) excel in pattern recognition and response generation, they lack genuine\nunderstanding - an essential hallmark of Artificial General Intelligence (AGI).\nExisting AGI evaluation methods fail to offer a practical, gradual, and\ninformative metric. This paper introduces the Artificial General Intelligence\nTest Bed (AGITB), comprising twelve rigorous tests that form a\nsignal-processing-level foundation for the potential emergence of cognitive\ncapabilities. AGITB evaluates intelligence through a model's ability to predict\nbinary signals across time without relying on symbolic representations or\npretraining. Unlike high-level tests grounded in language or perception, AGITB\nfocuses on core computational invariants reflective of biological intelligence,\nsuch as determinism, sensitivity, and generalisation. The test bed assumes no\nprior bias, operates independently of semantic meaning, and ensures\nunsolvability through brute force or memorization. While humans pass AGITB by\ndesign, no current AI system has met its criteria, making AGITB a compelling\nbenchmark for guiding and recognizing progress toward AGI.", "published": "2025-04-06 10:01:15", "link": "http://arxiv.org/abs/2504.04430v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Formula-Supervised Sound Event Detection: Pre-Training Without Real Data", "abstract": "In this paper, we propose a novel formula-driven supervised learning (FDSL)\nframework for pre-training an environmental sound analysis model by leveraging\nacoustic signals parametrically synthesized through formula-driven methods.\nSpecifically, we outline detailed procedures and evaluate their effectiveness\nfor sound event detection (SED). The SED task, which involves estimating the\ntypes and timings of sound events, is particularly challenged by the difficulty\nof acquiring a sufficient quantity of accurately labeled training data.\nMoreover, it is well known that manually annotated labels often contain noises\nand are significantly influenced by the subjective judgment of annotators. To\naddress these challenges, we propose a novel pre-training method that utilizes\na synthetic dataset, Formula-SED, where acoustic data are generated solely\nbased on mathematical formulas. The proposed method enables large-scale\npre-training by using the synthesis parameters applied at each time step as\nground truth labels, thereby eliminating label noise and bias. We demonstrate\nthat large-scale pre-training with Formula-SED significantly enhances model\naccuracy and accelerates training, as evidenced by our results in the DESED\ndataset used for DCASE2023 Challenge Task 4. The project page is at\nhttps://yutoshibata07.github.io/Formula-SED/", "published": "2025-04-06 09:47:26", "link": "http://arxiv.org/abs/2504.04428v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "FluentLip: A Phonemes-Based Two-stage Approach for Audio-Driven Lip Synthesis with Optical Flow Consistency", "abstract": "Generating consecutive images of lip movements that align with a given speech\nin audio-driven lip synthesis is a challenging task. While previous studies\nhave made strides in synchronization and visual quality, lip intelligibility\nand video fluency remain persistent challenges. This work proposes FluentLip, a\ntwo-stage approach for audio-driven lip synthesis, incorporating three featured\nstrategies. To improve lip synchronization and intelligibility, we integrate a\nphoneme extractor and encoder to generate a fusion of audio and phoneme\ninformation for multimodal learning. Additionally, we employ optical flow\nconsistency loss to ensure natural transitions between image frames.\nFurthermore, we incorporate a diffusion chain during the training of Generative\nAdversarial Networks (GANs) to improve both stability and efficiency. We\nevaluate our proposed FluentLip through extensive experiments, comparing it\nwith five state-of-the-art (SOTA) approaches across five metrics, including a\nproposed metric called Phoneme Error Rate (PER) that evaluates lip pose\nintelligibility and video fluency. The experimental results demonstrate that\nour FluentLip approach is highly competitive, achieving significant\nimprovements in smoothness and naturalness. In particular, it outperforms these\nSOTA approaches by approximately $\\textbf{16.3%}$ in Fr\\'echet Inception\nDistance (FID) and $\\textbf{35.2%}$ in PER.", "published": "2025-04-06 09:44:30", "link": "http://arxiv.org/abs/2504.04427v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "UniToken: Harmonizing Multimodal Understanding and Generation through Unified Visual Encoding", "abstract": "We introduce UniToken, an auto-regressive generation model that encodes\nvisual inputs through a combination of discrete and continuous representations,\nenabling seamless integration of unified visual understanding and image\ngeneration tasks. Unlike previous approaches that rely on unilateral visual\nrepresentations, our unified visual encoding framework captures both high-level\nsemantics and low-level details, delivering multidimensional information that\nempowers heterogeneous tasks to selectively assimilate domain-specific\nknowledge based on their inherent characteristics. Through in-depth\nexperiments, we uncover key principles for developing a unified model capable\nof both visual understanding and image generation. Extensive evaluations across\na diverse range of prominent benchmarks demonstrate that UniToken achieves\nstate-of-the-art performance, surpassing existing approaches. These results\nestablish UniToken as a robust foundation for future research in this domain.\nThe code and models are available at https://github.com/SxJyJay/UniToken.", "published": "2025-04-06 09:20:49", "link": "http://arxiv.org/abs/2504.04423v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Driving-RAG: Driving Scenarios Embedding, Search, and RAG Applications", "abstract": "Driving scenario data play an increasingly vital role in the development of\nintelligent vehicles and autonomous driving. Accurate and efficient scenario\ndata search is critical for both online vehicle decision-making and planning,\nand offline scenario generation and simulations, as it allows for leveraging\nthe scenario experiences to improve the overall performance. Especially with\nthe application of large language models (LLMs) and\nRetrieval-Augmented-Generation (RAG) systems in autonomous driving, urgent\nrequirements are put forward. In this paper, we introduce the Driving-RAG\nframework to address the challenges of efficient scenario data embedding,\nsearch, and applications for RAG systems. Our embedding model aligns\nfundamental scenario information and scenario distance metrics in the vector\nspace. The typical scenario sampling method combined with hierarchical\nnavigable small world can perform efficient scenario vector search to achieve\nhigh efficiency without sacrificing accuracy. In addition, the reorganization\nmechanism by graph knowledge enhances the relevance to the prompt scenarios and\naugment LLM generation. We demonstrate the effectiveness of the proposed\nframework on typical trajectory planning task for complex interactive scenarios\nsuch as ramps and intersections, showcasing its advantages for RAG\napplications.", "published": "2025-04-06 09:05:33", "link": "http://arxiv.org/abs/2504.04419v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Universal Item Tokenization for Transferable Generative Recommendation", "abstract": "Recently, generative recommendation has emerged as a promising paradigm,\nattracting significant research attention. The basic framework involves an item\ntokenizer, which represents each item as a sequence of codes serving as its\nidentifier, and a generative recommender that predicts the next item by\nautoregressively generating the target item identifier. However, in existing\nmethods, both the tokenizer and the recommender are typically domain-specific,\nlimiting their ability for effective transfer or adaptation to new domains. To\nthis end, we propose UTGRec, a Universal item Tokenization approach for\ntransferable Generative Recommendation. Specifically, we design a universal\nitem tokenizer for encoding rich item semantics by adapting a multimodal large\nlanguage model (MLLM). By devising tree-structured codebooks, we discretize\ncontent representations into corresponding codes for item tokenization. To\neffectively learn the universal item tokenizer on multiple domains, we\nintroduce two key techniques in our approach. For raw content reconstruction,\nwe employ dual lightweight decoders to reconstruct item text and images from\ndiscrete representations to capture general knowledge embedded in the content.\nFor collaborative knowledge integration, we assume that co-occurring items are\nsimilar and integrate collaborative signals through co-occurrence alignment and\nreconstruction. Finally, we present a joint learning framework to pre-train and\nadapt the transferable generative recommender across multiple domains.\nExtensive experiments on four public datasets demonstrate the superiority of\nUTGRec compared to both traditional and generative recommendation baselines.", "published": "2025-04-06 08:07:49", "link": "http://arxiv.org/abs/2504.04405v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Pre-training Generative Recommender with Multi-Identifier Item Tokenization", "abstract": "Generative recommendation autoregressively generates item identifiers to\nrecommend potential items. Existing methods typically adopt a one-to-one\nmapping strategy, where each item is represented by a single identifier.\nHowever, this scheme poses issues, such as suboptimal semantic modeling for\nlow-frequency items and limited diversity in token sequence data. To overcome\nthese limitations, we propose MTGRec, which leverages Multi-identifier item\nTokenization to augment token sequence data for Generative Recommender\npre-training. Our approach involves two key innovations: multi-identifier item\ntokenization and curriculum recommender pre-training. For multi-identifier item\ntokenization, we leverage the RQ-VAE as the tokenizer backbone and treat model\ncheckpoints from adjacent training epochs as semantically relevant tokenizers.\nThis allows each item to be associated with multiple identifiers, enabling a\nsingle user interaction sequence to be converted into several token sequences\nas different data groups. For curriculum recommender pre-training, we introduce\na curriculum learning scheme guided by data influence estimation, dynamically\nadjusting the sampling probability of each data group during recommender\npre-training. After pre-training, we fine-tune the model using a single\ntokenizer to ensure accurate item identification for recommendation. Extensive\nexperiments on three public benchmark datasets demonstrate that MTGRec\nsignificantly outperforms both traditional and generative recommendation\nbaselines in terms of effectiveness and scalability.", "published": "2025-04-06 08:03:03", "link": "http://arxiv.org/abs/2504.04400v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Future-Proof Yourself: An AI Era Survival Guide", "abstract": "Future-Proof Yourself is a practical guide that helps readers navigate the\nfast-changing world of artificial intelligence in everyday life. The book\nbegins by explaining how computers learn from data in simple, relatable terms,\nand gradually introduces the methods used in modern AI. It shows how basic\nideas in machine learning evolve into advanced systems that can recognize\nimages, understand language, and even make decisions. The guide also reviews\nthe history of AI and highlights the major breakthroughs that have shaped its\ngrowth. Looking ahead, the book explores emerging trends such as the\nintegration of AI with digital twins, wearable devices, and virtual\nenvironments. Designed for a general audience, the text avoids heavy technical\njargon and presents complex ideas in clear, straightforward language so that\nanyone can gain a solid understanding of the technology that is set to\ntransform our future.", "published": "2025-04-06 06:11:29", "link": "http://arxiv.org/abs/2504.04378v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "iADCPS: Time Series Anomaly Detection for Evolving Cyber-physical Systems via Incremental Meta-learning", "abstract": "Anomaly detection for cyber-physical systems (ADCPS) is crucial in\nidentifying faults and potential attacks by analyzing the time series of sensor\nmeasurements and actuator states. However, current methods lack adaptation to\ndata distribution shifts in both temporal and spatial dimensions as\ncyber-physical systems evolve. To tackle this issue, we propose an incremental\nmeta-learning-based approach, namely iADCPS, which can continuously update the\nmodel through limited evolving normal samples to reconcile the distribution gap\nbetween evolving and historical time series. Specifically, We first introduce a\ntemporal mixup strategy to align data for data-level generalization which is\nthen combined with the one-class meta-learning approach for model-level\ngeneralization. Furthermore, we develop a non-parametric dynamic threshold to\nadaptively adjust the threshold based on the probability density of the\nabnormal scores without any anomaly supervision. We empirically evaluate the\neffectiveness of the iADCPS using three publicly available datasets PUMP, SWaT,\nand WADI. The experimental results demonstrate that our method achieves 99.0%,\n93.1%, and 78.7% F1-Score, respectively, which outperforms the state-of-the-art\n(SOTA) ADCPS method, especially in the context of the evolving CPSs.", "published": "2025-04-06 06:02:31", "link": "http://arxiv.org/abs/2504.04374v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "How Accurately Do Large Language Models Understand Code?", "abstract": "Large Language Models (LLMs) are increasingly used in post-development tasks\nsuch as code repair and testing. A key factor in these tasks' success is the\nmodel's deep understanding of code. However, the extent to which LLMs truly\nunderstand code remains largely unevaluated. Quantifying code comprehension is\nchallenging due to its abstract nature and the lack of a standardized metric.\nPreviously, this was assessed through developer surveys, which are not feasible\nfor evaluating LLMs. Existing LLM benchmarks focus primarily on code\ngeneration, fundamentally different from code comprehension. Additionally,\nfixed benchmarks quickly become obsolete as they become part of the training\ndata. This paper presents the first large-scale empirical investigation into\nLLMs' ability to understand code. Inspired by mutation testing, we use an LLM's\nfault-finding ability as a proxy for its deep code understanding. This approach\nis based on the insight that a model capable of identifying subtle functional\ndiscrepancies must understand the code well. We inject faults in real-world\nprograms and ask the LLM to localize them, ensuring the specifications suffice\nfor fault localization. Next, we apply semantic-preserving code mutations\n(SPMs) to the faulty programs and test whether the LLMs still locate the\nfaults, verifying their confidence in code understanding. We evaluate nine\npopular LLMs on 575000 debugging tasks from 670 Java and 637 Python programs.\nWe find that LLMs lose the ability to debug the same bug in 81% of faulty\nprograms when SPMs are applied, indicating a shallow understanding of code and\nreliance on features irrelevant to semantics. We also find that LLMs understand\ncode earlier in the program better than later. This suggests that LLMs' code\ncomprehension remains tied to lexical and syntactic features due to\ntokenization designed for natural languages, which overlooks code semantics.", "published": "2025-04-06 05:59:29", "link": "http://arxiv.org/abs/2504.04372v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "WeiDetect: Weibull Distribution-Based Defense against Poisoning Attacks in Federated Learning for Network Intrusion Detection Systems", "abstract": "In the era of data expansion, ensuring data privacy has become increasingly\ncritical, posing significant challenges to traditional AI-based applications.\nIn addition, the increasing adoption of IoT devices has introduced significant\ncybersecurity challenges, making traditional Network Intrusion Detection\nSystems (NIDS) less effective against evolving threats, and privacy concerns\nand regulatory restrictions limit their deployment. Federated Learning (FL) has\nemerged as a promising solution, allowing decentralized model training while\nmaintaining data privacy to solve these issues. However, despite implementing\nprivacy-preserving technologies, FL systems remain vulnerable to adversarial\nattacks. Furthermore, data distribution among clients is not heterogeneous in\nthe FL scenario. We propose WeiDetect, a two-phase, server-side defense\nmechanism for FL-based NIDS that detects malicious participants to address\nthese challenges. In the first phase, local models are evaluated using a\nvalidation dataset to generate validation scores. These scores are then\nanalyzed using a Weibull distribution, identifying and removing malicious\nmodels. We conducted experiments to evaluate the effectiveness of our approach\nin diverse attack settings. Our evaluation included two popular datasets,\nCIC-Darknet2020 and CSE-CIC-IDS2018, tested under non-IID data distributions.\nOur findings highlight that WeiDetect outperforms state-of-the-art defense\napproaches, improving higher target class recall up to 70% and enhancing the\nglobal model's F1 score by 1% to 14%.", "published": "2025-04-06 05:31:24", "link": "http://arxiv.org/abs/2504.04367v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Solving Sokoban using Hierarchical Reinforcement Learning with Landmarks", "abstract": "We introduce a novel hierarchical reinforcement learning (HRL) framework that\nperforms top-down recursive planning via learned subgoals, successfully applied\nto the complex combinatorial puzzle game Sokoban. Our approach constructs a\nsix-level policy hierarchy, where each higher-level policy generates subgoals\nfor the level below. All subgoals and policies are learned end-to-end from\nscratch, without any domain knowledge. Our results show that the agent can\ngenerate long action sequences from a single high-level call. While prior work\nhas explored 2-3 level hierarchies and subgoal-based planning heuristics, we\ndemonstrate that deep recursive goal decomposition can emerge purely from\nlearning, and that such hierarchies can scale effectively to hard puzzle\ndomains.", "published": "2025-04-06 05:30:21", "link": "http://arxiv.org/abs/2504.04366v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "abstract": "The performance of large language models (LLMs) depends on how they are\nprompted, with choices spanning both the high-level prompting pattern (e.g.,\nZero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and\nfew-shot demonstrations). Manually tuning this combination is tedious,\nerror-prone, and non-transferable across LLMs or tasks. Therefore, this paper\nproposes AutoPDL, an automated approach to discover good LLM agent\nconfigurations. Our method frames this as a structured AutoML problem over a\ncombinatorial space of agentic and non-agentic prompting patterns and\ndemonstrations, using successive halving to efficiently navigate this space. We\nintroduce a library implementing common prompting patterns using the PDL prompt\nprogramming language. AutoPDL solutions are human-readable, editable, and\nexecutable PDL programs that use this library. This approach also enables\nsource-to-source optimization, allowing human-in-the-loop refinement and reuse.\nEvaluations across three tasks and six LLMs (ranging from 8B to 70B parameters)\nshow consistent accuracy gains ($9.5\\pm17.5$ percentage points), up to 68.9pp,\nand reveal that selected prompting strategies vary across models and tasks.", "published": "2025-04-06 05:30:10", "link": "http://arxiv.org/abs/2504.04365v1", "categories": ["cs.LG", "cs.AI", "cs.PL"], "primary_category": "cs.LG"}
{"title": "REFORMER: A ChatGPT-Driven Data Synthesis Framework Elevating Text-to-SQL Models", "abstract": "The existing Text-to-SQL models suffer from a shortage of training data,\ninhibiting their ability to fully facilitate the applications of SQL queries in\nnew domains. To address this challenge, various data synthesis techniques have\nbeen employed to generate more diverse and higher quality data. In this paper,\nwe propose REFORMER, a framework that leverages ChatGPT's prowess without the\nneed for additional training, to facilitate the synthesis of (question, SQL\nquery) pairs tailored to new domains. Our data augmentation approach is based\non a \"retrieve-and-edit\" method, where we generate new questions by filling\nmasked question using explanation of SQL queries with the help of ChatGPT.\nFurthermore, we demonstrate that cycle consistency remains a valuable method of\nvalidation when applied appropriately. Our experimental results show that\nREFORMER consistently outperforms previous data augmentation methods. To\nfurther investigate the power of ChatGPT and create a general data augmentation\nmethod, we also generate the new data by paraphrasing the question in the\ndataset and by paraphrasing the description of a new SQL query that is\ngenerated by ChatGPT as well. Our results affirm that paraphrasing questions\ngenerated by ChatGPT help augment the original data.", "published": "2025-04-06 05:27:37", "link": "http://arxiv.org/abs/2504.04363v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Crowdsourcing-Based Knowledge Graph Construction for Drug Side Effects Using Large Language Models with an Application on Semaglutide", "abstract": "Social media is a rich source of real-world data that captures valuable\npatient experience information for pharmacovigilance. However, mining data from\nunstructured and noisy social media content remains a challenging task. We\npresent a systematic framework that leverages large language models (LLMs) to\nextract medication side effects from social media and organize them into a\nknowledge graph (KG). We apply this framework to semaglutide for weight loss\nusing data from Reddit. Using the constructed knowledge graph, we perform\ncomprehensive analyses to investigate reported side effects across different\nsemaglutide brands over time. These findings are further validated through\ncomparison with adverse events reported in the FAERS database, providing\nimportant patient-centered insights into semaglutide's side effects that\ncomplement its safety profile and current knowledge base of semaglutide for\nboth healthcare professionals and patients. Our work demonstrates the\nfeasibility of using LLMs to transform social media data into structured KGs\nfor pharmacovigilance.", "published": "2025-04-06 03:47:44", "link": "http://arxiv.org/abs/2504.04346v1", "categories": ["cs.AI", "cs.SI", "J.4"], "primary_category": "cs.AI"}
{"title": "Geo-OLM: Enabling Sustainable Earth Observation Studies with Cost-Efficient Open Language Models & State-Driven Workflows", "abstract": "Geospatial Copilots hold immense potential for automating Earth observation\n(EO) and climate monitoring workflows, yet their reliance on large-scale models\nsuch as GPT-4o introduces a paradox: tools intended for sustainability studies\noften incur unsustainable costs. Using agentic AI frameworks in geospatial\napplications can amass thousands of dollars in API charges or requires\nexpensive, power-intensive GPUs for deployment, creating barriers for\nresearchers, policymakers, and NGOs. Unfortunately, when geospatial Copilots\nare deployed with open language models (OLMs), performance often degrades due\nto their dependence on GPT-optimized logic. In this paper, we present Geo-OLM,\na tool-augmented geospatial agent that leverages the novel paradigm of\nstate-driven LLM reasoning to decouple task progression from tool calling. By\nalleviating the workflow reasoning burden, our approach enables low-resource\nOLMs to complete geospatial tasks more effectively. When downsizing to small\nmodels below 7B parameters, Geo-OLM outperforms the strongest prior geospatial\nbaselines by 32.8% in successful query completion rates. Our method performs\ncomparably to proprietary models achieving results within 10% of GPT-4o, while\nreducing inference costs by two orders of magnitude from \\$500-\\$1000 to under\n\\$10. We present an in-depth analysis with geospatial downstream benchmarks,\nproviding key insights to help practitioners effectively deploy OLMs for EO\napplications.", "published": "2025-04-06 01:31:04", "link": "http://arxiv.org/abs/2504.04319v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Survey of Social Cybersecurity: Techniques for Attack Detection, Evaluations, Challenges, and Future Prospects", "abstract": "In today's digital era, the Internet, especially social media platforms,\nplays a significant role in shaping public opinions, attitudes, and beliefs.\nUnfortunately, the credibility of scientific information sources is often\nundermined by the spread of misinformation through various means, including\ntechnology-driven tools like bots, cyborgs, trolls, sock-puppets, and deep\nfakes. This manipulation of public discourse serves antagonistic business\nagendas and compromises civil society. In response to this challenge, a new\nscientific discipline has emerged: social cybersecurity.", "published": "2025-04-06 00:53:09", "link": "http://arxiv.org/abs/2504.04311v1", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "primary_category": "cs.CR"}
{"title": "Systematic Literature Review on Vehicular Collaborative Perception -- A Computer Vision Perspective", "abstract": "The effectiveness of autonomous vehicles relies on reliable perception\ncapabilities. Despite significant advancements in artificial intelligence and\nsensor fusion technologies, current single-vehicle perception systems continue\nto encounter limitations, notably visual occlusions and limited long-range\ndetection capabilities. Collaborative Perception (CP), enabled by\nVehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication, has\nemerged as a promising solution to mitigate these issues and enhance the\nreliability of autonomous systems. Beyond advancements in communication, the\ncomputer vision community is increasingly focusing on improving vehicular\nperception through collaborative approaches. However, a systematic literature\nreview that thoroughly examines existing work and reduces subjective bias is\nstill lacking. Such a systematic approach helps identify research gaps,\nrecognize common trends across studies, and inform future research directions.\nIn response, this study follows the PRISMA 2020 guidelines and includes 106\npeer-reviewed articles. These publications are analyzed based on modalities,\ncollaboration schemes, and key perception tasks. Through a comparative\nanalysis, this review illustrates how different methods address practical\nissues such as pose errors, temporal latency, communication constraints, domain\nshifts, heterogeneity, and adversarial attacks. Furthermore, it critically\nexamines evaluation methodologies, highlighting a misalignment between current\nmetrics and CP's fundamental objectives. By delving into all relevant topics\nin-depth, this review offers valuable insights into challenges, opportunities,\nand risks, serving as a reference for advancing research in vehicular\ncollaborative perception.", "published": "2025-04-06 21:56:04", "link": "http://arxiv.org/abs/2504.04631v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Targetless LiDAR-Camera Calibration with Anchored 3D Gaussians", "abstract": "We present a targetless LiDAR-camera calibration method that jointly\noptimizes sensor poses and scene geometry from arbitrary scenes, without\nrelying on traditional calibration targets such as checkerboards or spherical\nreflectors. Our approach leverages a 3D Gaussian-based scene representation. We\nfirst freeze reliable LiDAR points as anchors, then jointly optimize the poses\nand auxiliary Gaussian parameters in a fully differentiable manner using a\nphotometric loss. This joint optimization significantly reduces sensor\nmisalignment, resulting in higher rendering quality and consistently improved\nPSNR compared to the carefully calibrated poses provided in popular datasets.\nWe validate our method through extensive experiments on two real-world\nautonomous driving datasets, KITTI-360 and Waymo, each featuring distinct\nsensor configurations. Additionally, we demonstrate the robustness of our\napproach using a custom LiDAR-camera setup, confirming strong performance\nacross diverse hardware configurations.", "published": "2025-04-06 20:00:01", "link": "http://arxiv.org/abs/2504.04597v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Lengthy Videos Retrieval Framework and Evaluation Metric", "abstract": "Precise video retrieval requires multi-modal correlations to handle unseen\nvocabulary and scenes, becoming more complex for lengthy videos where models\nmust perform effectively without prior training on a specific dataset. We\nintroduce a unified framework that combines a visual matching stream and an\naural matching stream with a unique subtitles-based video segmentation\napproach. Additionally, the aural stream includes a complementary audio-based\ntwo-stage retrieval mechanism that enhances performance on long-duration\nvideos. Considering the complex nature of retrieval from lengthy videos and its\ncorresponding evaluation, we introduce a new retrieval evaluation method\nspecifically designed for long-video retrieval to support further research. We\nconducted experiments on the YouCook2 benchmark, showing promising retrieval\nperformance.", "published": "2025-04-06 18:18:09", "link": "http://arxiv.org/abs/2504.04572v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation", "abstract": "Semi-supervised learning in medical image segmentation leverages unlabeled\ndata to reduce annotation burdens through consistency learning. However,\ncurrent methods struggle with class imbalance and high uncertainty from\npathology variations, leading to inaccurate segmentation in 3D medical images.\nTo address these challenges, we present DyCON, a Dynamic Uncertainty-aware\nConsistency and Contrastive Learning framework that enhances the generalization\nof consistency methods with two complementary losses: Uncertainty-aware\nConsistency Loss (UnCL) and Focal Entropy-aware Contrastive Loss (FeCL). UnCL\nenforces global consistency by dynamically weighting the contribution of each\nvoxel to the consistency loss based on its uncertainty, preserving\nhigh-uncertainty regions instead of filtering them out. Initially, UnCL\nprioritizes learning from uncertain voxels with lower penalties, encouraging\nthe model to explore challenging regions. As training progress, the penalty\nshift towards confident voxels to refine predictions and ensure global\nconsistency. Meanwhile, FeCL enhances local feature discrimination in\nimbalanced regions by introducing dual focal mechanisms and adaptive confidence\nadjustments into the contrastive principle. These mechanisms jointly\nprioritizes hard positives and negatives while focusing on uncertain sample\npairs, effectively capturing subtle lesion variations under class imbalance.\nExtensive evaluations on four diverse medical image segmentation datasets\n(ISLES'22, BraTS'19, LA, Pancreas) show DyCON's superior performance against\nSOTA methods.", "published": "2025-04-06 17:50:22", "link": "http://arxiv.org/abs/2504.04566v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Opening the black box of deep learning: Validating the statistical association between explainable artificial intelligence (XAI) and clinical domain knowledge in fundus image-based glaucoma diagnosis", "abstract": "While deep learning has exhibited remarkable predictive capabilities in\nvarious medical image tasks, its inherent black-box nature has hindered its\nwidespread implementation in real-world healthcare settings. Our objective is\nto unveil the decision-making processes of deep learning models in the context\nof glaucoma classification by employing several Class Activation Map (CAM)\ntechniques to generate model focus regions and comparing them with clinical\ndomain knowledge of the anatomical area (optic cup, optic disk, and blood\nvessels). Four deep neural networks, including VGG-11, ResNet-18, DeiT-Tiny,\nand Swin Transformer-Tiny, were developed using binary diagnostic labels of\nglaucoma and five CAM methods (Grad-CAM, XGrad-CAM, Score-CAM, Eigen-CAM, and\nLayer-CAM) were employed to highlight the model focus area. We applied the\npaired-sample t-test to compare the percentage of anatomies in the model focus\narea to the proportion of anatomies in the entire image. After that, Pearson's\nand Spearman's correlation tests were implemented to examine the relationship\nbetween model predictive ability and the percentage of anatomical structures in\nthe model focus area. On five public glaucoma datasets, all deep learning\nmodels consistently displayed statistically significantly higher percentages of\nanatomical structures in the focus area than the proportions of anatomical\nstructures in the entire image. Also, we validated the positive relationship\nbetween the percentage of anatomical structures in the focus area and model\npredictive performance. Our study provides evidence of the convergence of\ndecision logic between deep neural networks and human clinicians through\nrigorous statistical tests. We anticipate that it can help alleviate\nclinicians' concerns regarding the trustworthiness of deep learning in\nhealthcare. For reproducibility, the code and dataset have been released at\nGitHub.", "published": "2025-04-06 16:57:34", "link": "http://arxiv.org/abs/2504.04549v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BrainMRDiff: A Diffusion Model for Anatomically Consistent Brain MRI Synthesis", "abstract": "Accurate brain tumor diagnosis relies on the assessment of multiple Magnetic\nResonance Imaging (MRI) sequences. However, in clinical practice, the\nacquisition of certain sequences may be affected by factors like motion\nartifacts or contrast agent contraindications, leading to suboptimal outcome,\nsuch as poor image quality. This can then affect image interpretation by\nradiologists. Synthesizing high quality MRI sequences has thus become a\ncritical research focus. Though recent advancements in controllable generative\nAI have facilitated the synthesis of diagnostic quality MRI, ensuring\nanatomical accuracy remains a significant challenge. Preserving critical\nstructural relationships between different anatomical regions is essential, as\neven minor structural or topological inconsistencies can compromise diagnostic\nvalidity. In this work, we propose BrainMRDiff, a novel topology-preserving,\nanatomy-guided diffusion model for synthesizing brain MRI, leveraging brain and\ntumor anatomies as conditioning inputs. To achieve this, we introduce two key\nmodules: Tumor+Structure Aggregation (TSA) and Topology-Guided Anatomy\nPreservation (TGAP). TSA integrates diverse anatomical structures with tumor\ninformation, forming a comprehensive conditioning mechanism for the diffusion\nprocess. TGAP enforces topological consistency during reverse denoising\ndiffusion process; both these modules ensure that the generated image respects\nanatomical integrity. Experimental results demonstrate that BrainMRDiff\nsurpasses existing baselines, achieving performance improvements of 23.33% on\nthe BraTS-AG dataset and 33.33% on the BraTS-Met dataset. Code will be made\npublicly available soon.", "published": "2025-04-06 16:16:50", "link": "http://arxiv.org/abs/2504.04532v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SAM2MOT: A Novel Paradigm of Multi-Object Tracking by Segmentation", "abstract": "Segment Anything 2 (SAM2) enables robust single-object tracking using\nsegmentation. To extend this to multi-object tracking (MOT), we propose\nSAM2MOT, introducing a novel Tracking by Segmentation paradigm. Unlike Tracking\nby Detection or Tracking by Query, SAM2MOT directly generates tracking boxes\nfrom segmentation masks, reducing reliance on detection accuracy. SAM2MOT has\ntwo key advantages: zero-shot generalization, allowing it to work across\ndatasets without fine-tuning, and strong object association, inherited from\nSAM2. To further improve performance, we integrate a trajectory manager system\nfor precise object addition and removal, and a cross-object interaction module\nto handle occlusions. Experiments on DanceTrack, UAVDT, and BDD100K show\nstate-of-the-art results. Notably, SAM2MOT outperforms existing methods on\nDanceTrack by +2.1 HOTA and +4.5 IDF1, highlighting its effectiveness in MOT.", "published": "2025-04-06 15:32:08", "link": "http://arxiv.org/abs/2504.04519v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Attributed Synthetic Data Generation for Zero-shot Domain-specific Image Classification", "abstract": "Zero-shot domain-specific image classification is challenging in classifying\nreal images without ground-truth in-domain training examples. Recent research\ninvolved knowledge from texts with a text-to-image model to generate in-domain\ntraining images in zero-shot scenarios. However, existing methods heavily rely\non simple prompt strategies, limiting the diversity of synthetic training\nimages, thus leading to inferior performance compared to real images. In this\npaper, we propose AttrSyn, which leverages large language models to generate\nattributed prompts. These prompts allow for the generation of more diverse\nattributed synthetic images. Experiments for zero-shot domain-specific image\nclassification on two fine-grained datasets show that training with synthetic\nimages generated by AttrSyn significantly outperforms CLIP's zero-shot\nclassification under most situations and consistently surpasses simple prompt\nstrategies.", "published": "2025-04-06 14:54:10", "link": "http://arxiv.org/abs/2504.04510v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Active Learning with a Noisy Annotator", "abstract": "Active Learning (AL) aims to reduce annotation costs by strategically\nselecting the most informative samples for labeling. However, most active\nlearning methods struggle in the low-budget regime where only a few labeled\nexamples are available. This issue becomes even more pronounced when annotators\nprovide noisy labels. A common AL approach for the low- and mid-budget regimes\nfocuses on maximizing the coverage of the labeled set across the entire\ndataset. We propose a novel framework called Noise-Aware Active Sampling (NAS)\nthat extends existing greedy, coverage-based active learning strategies to\nhandle noisy annotations. NAS identifies regions that remain uncovered due to\nthe selection of noisy representatives and enables resampling from these areas.\nWe introduce a simple yet effective noise filtering approach suitable for the\nlow-budget regime, which leverages the inner mechanism of NAS and can be\napplied for noise filtering before model training. On multiple computer vision\nbenchmarks, including CIFAR100 and ImageNet subsets, NAS significantly improves\nperformance for standard active learning methods across different noise types\nand rates.", "published": "2025-04-06 14:27:27", "link": "http://arxiv.org/abs/2504.04506v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection", "abstract": "With the increasing adoption of video anomaly detection in intelligent\nsurveillance domains, conventional visual-based detection approaches often\nstruggle with information insufficiency and high false-positive rates in\ncomplex environments. To address these limitations, we present a novel weakly\nsupervised framework that leverages audio-visual collaboration for robust video\nanomaly detection. Capitalizing on the exceptional cross-modal representation\nlearning capabilities of Contrastive Language-Image Pretraining (CLIP) across\nvisual, audio, and textual domains, our framework introduces two major\ninnovations: an efficient audio-visual fusion that enables adaptive cross-modal\nintegration through lightweight parametric adaptation while maintaining the\nfrozen CLIP backbone, and a novel audio-visual prompt that dynamically enhances\ntext embeddings with key multimodal information based on the semantic\ncorrelation between audio-visual features and textual labels, significantly\nimproving CLIP's generalization for the video anomaly detection task. Moreover,\nto enhance robustness against modality deficiency during inference, we further\ndevelop an uncertainty-driven feature distillation module that synthesizes\naudio-visual representations from visual-only inputs. This module employs\nuncertainty modeling based on the diversity of audio-visual features to\ndynamically emphasize challenging features during the distillation process. Our\nframework demonstrates superior performance across multiple benchmarks, with\naudio integration significantly boosting anomaly detection accuracy in various\nscenarios. Notably, with unimodal data enhanced by uncertainty-driven\ndistillation, our approach consistently outperforms current unimodal VAD\nmethods.", "published": "2025-04-06 13:59:16", "link": "http://arxiv.org/abs/2504.04495v1", "categories": ["cs.CV", "I.4.9; I.5.4"], "primary_category": "cs.CV"}
{"title": "Skin Color Measurement from Dermatoscopic Images: An Evaluation on a Synthetic Dataset", "abstract": "This paper presents a comprehensive evaluation of skin color measurement\nmethods from dermatoscopic images using a synthetic dataset (S-SYNTH) with\ncontrolled ground-truth melanin content, lesion shapes, hair models, and 18\ndistinct lighting conditions. This allows for rigorous assessment of the\nrobustness and invariance to lighting conditions. We assess four classes of\nimage colorimetry approaches: segmentation-based, patch-based, color\nquantization, and neural networks. We use these methods to estimate the\nIndividual Typology Angle (ITA) and Fitzpatrick types from dermatoscopic\nimages. Our results show that segmentation-based and color quantization methods\nyield robust, lighting-invariant estimates, whereas patch-based approaches\nexhibit significant lighting-dependent biases that require calibration.\nFurthermore, neural network models, particularly when combined with heavy\nblurring to reduce overfitting, can provide light-invariant Fitzpatrick\npredictions, although their generalization to real-world images remains\nunverified. We conclude with practical recommendations for designing fair and\nreliable skin color estimation methods.", "published": "2025-04-06 13:57:34", "link": "http://arxiv.org/abs/2504.04494v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Conditionally Independent Transformations using Normal Subgroups in Group Theory", "abstract": "Humans develop certain cognitive abilities to recognize objects and their\ntransformations without explicit supervision, highlighting the importance of\nunsupervised representation learning. A fundamental challenge in unsupervised\nrepresentation learning is to separate different transformations in learned\nfeature representations. Although algebraic approaches have been explored, a\ncomprehensive theoretical framework remains underdeveloped. Existing methods\ndecompose transformations based on algebraic independence, but these methods\nprimarily focus on commutative transformations and do not extend to cases where\ntransformations are conditionally independent but noncommutative. To extend\ncurrent representation learning frameworks, we draw inspiration from Galois\ntheory, where the decomposition of groups through normal subgroups provides an\napproach for the analysis of structured transformations. Normal subgroups\nnaturally extend commutativity under certain conditions and offer a foundation\nfor the categorization of transformations, even when they do not commute. In\nthis paper, we propose a novel approach that leverages normal subgroups to\nenable the separation of conditionally independent transformations, even in the\nabsence of commutativity. Through experiments on geometric transformations in\nimages, we show that our method successfully categorizes conditionally\nindependent transformations, such as rotation and translation, in an\nunsupervised manner, suggesting a close link between group decomposition via\nnormal subgroups and transformation categorization in representation learning.", "published": "2025-04-06 13:45:43", "link": "http://arxiv.org/abs/2504.04490v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Building LLM Agents by Incorporating Insights from Computer Systems", "abstract": "LLM-driven autonomous agents have emerged as a promising direction in recent\nyears. However, many of these LLM agents are designed empirically or based on\nintuition, often lacking systematic design principles, which results in diverse\nagent structures with limited generality and scalability. In this paper, we\nadvocate for building LLM agents by incorporating insights from computer\nsystems. Inspired by the von Neumann architecture, we propose a structured\nframework for LLM agentic systems, emphasizing modular design and universal\nprinciples. Specifically, this paper first provides a comprehensive review of\nLLM agents from the computer system perspective, then identifies key challenges\nand future directions inspired by computer system design, and finally explores\nthe learning mechanisms for LLM agents beyond the computer system. The insights\ngained from this comparative analysis offer a foundation for systematic LLM\nagent design and advancement.", "published": "2025-04-06 13:38:37", "link": "http://arxiv.org/abs/2504.04485v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT", "abstract": "Long video understanding has emerged as an increasingly important yet\nchallenging task in computer vision. Agent-based approaches are gaining\npopularity for processing long videos, as they can handle extended sequences\nand integrate various tools to capture fine-grained information. However,\nexisting methods still face several challenges: (1) they often rely solely on\nthe reasoning ability of large language models (LLMs) without dedicated\nmechanisms to enhance reasoning in long video scenarios; and (2) they remain\nvulnerable to errors or noise from external tools. To address these issues, we\npropose a specialized chain-of-thought (CoT) process tailored for long video\nanalysis. Our proposed CoT with plan-adjust mode enables the LLM to\nincrementally plan and adapt its information-gathering strategy. We further\nincorporate heuristic uncertainty estimation of both the LLM and external tools\nto guide the CoT process. This allows the LLM to assess the reliability of\nnewly collected information, refine its collection strategy, and make more\nrobust decisions when synthesizing final answers. Empirical experiments show\nthat our uncertainty-aware CoT effectively mitigates noise from external tools,\nleading to more reliable outputs. We implement our approach in a system called\nVideoAgent2, which also includes additional modules such as general context\nacquisition and specialized tool design. Evaluation on three dedicated long\nvideo benchmarks (and their subsets) demonstrates that VideoAgent2 outperforms\nthe previous state-of-the-art agent-based method, VideoAgent, by an average of\n13.1% and achieves leading performance among all zero-shot approaches", "published": "2025-04-06 13:03:34", "link": "http://arxiv.org/abs/2504.04471v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Domain Generalization for Face Anti-spoofing via Content-aware Composite Prompt Engineering", "abstract": "The challenge of Domain Generalization (DG) in Face Anti-Spoofing (FAS) is\nthe significant interference of domain-specific signals on subtle spoofing\nclues. Recently, some CLIP-based algorithms have been developed to alleviate\nthis interference by adjusting the weights of visual classifiers. However, our\nanalysis of this class-wise prompt engineering suffers from two shortcomings\nfor DG FAS: (1) The categories of facial categories, such as real or spoof,\nhave no semantics for the CLIP model, making it difficult to learn accurate\ncategory descriptions. (2) A single form of prompt cannot portray the various\ntypes of spoofing. In this work, instead of class-wise prompts, we propose a\nnovel Content-aware Composite Prompt Engineering (CCPE) that generates\ninstance-wise composite prompts, including both fixed template and learnable\nprompts. Specifically, our CCPE constructs content-aware prompts from two\nbranches: (1) Inherent content prompt explicitly benefits from abundant\ntransferred knowledge from the instruction-based Large Language Model (LLM).\n(2) Learnable content prompts implicitly extract the most informative visual\ncontent via Q-Former. Moreover, we design a Cross-Modal Guidance Module (CGM)\nthat dynamically adjusts unimodal features for fusion to achieve better\ngeneralized FAS. Finally, our CCPE has been validated for its effectiveness in\nmultiple cross-domain experiments and achieves state-of-the-art (SOTA) results.", "published": "2025-04-06 13:00:41", "link": "http://arxiv.org/abs/2504.04470v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatial-Geometry Enhanced 3D Dynamic Snake Convolutional Neural Network for Hyperspectral Image Classification", "abstract": "Deep neural networks face several challenges in hyperspectral image\nclassification, including complex and sparse ground object distributions, small\nclustered structures, and elongated multi-branch features that often lead to\nmissing detections. To better adapt to ground object distributions and achieve\nadaptive dynamic feature responses while skipping redundant information, this\npaper proposes a Spatial-Geometry Enhanced 3D Dynamic Snake Network (SG-DSCNet)\nbased on an improved 3D-DenseNet model. The network employs Dynamic Snake\nConvolution (DSCConv), which introduces deformable offsets to enhance kernel\nflexibility through constrained self-learning, thereby improving regional\nperception of ground objects. Additionally, we propose a multi-view feature\nfusion strategy that generates multiple morphological kernel templates from\nDSCConv to observe target structures from different perspectives and achieve\nefficient feature fusion through summarizing key characteristics. This dynamic\napproach enables the model to focus more flexibly on critical spatial\nstructures when processing different regions, rather than relying on fixed\nreceptive fields of single static kernels. The DSC module enhances model\nrepresentation capability through dynamic kernel aggregation without increasing\nnetwork depth or width. Experimental results demonstrate superior performance\non the IN, UP, and KSC datasets, outperforming mainstream hyperspectral\nclassification methods.", "published": "2025-04-06 12:21:39", "link": "http://arxiv.org/abs/2504.04463v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CALF: A Conditionally Adaptive Loss Function to Mitigate Class-Imbalanced Segmentation", "abstract": "Imbalanced datasets pose a considerable challenge in training deep learning\n(DL) models for medical diagnostics, particularly for segmentation tasks.\nImbalance may be associated with annotation quality limited annotated datasets,\nrare cases, or small-scale regions of interest (ROIs). These conditions\nadversely affect model training and performance, leading to segmentation\nboundaries which deviate from the true ROIs. Traditional loss functions, such\nas Binary Cross Entropy, replicate annotation biases and limit model\ngeneralization. We propose a novel, statistically driven, conditionally\nadaptive loss function (CALF) tailored to accommodate the conditions of\nimbalanced datasets in DL training. It employs a data-driven methodology by\nestimating imbalance severity using statistical methods of skewness and\nkurtosis, then applies an appropriate transformation to balance the training\ndataset while preserving data heterogeneity. This transformative approach\nintegrates a multifaceted process, encompassing preprocessing, dataset\nfiltering, and dynamic loss selection to achieve optimal outcomes. We benchmark\nour method against conventional loss functions using qualitative and\nquantitative evaluations. Experiments using large-scale open-source datasets\n(i.e., UPENN-GBM, UCSF, LGG, and BraTS) validate our approach, demonstrating\nsubstantial segmentation improvements. Code availability:\nhttps://anonymous.4open.science/r/MICCAI-Submission-43F9/.", "published": "2025-04-06 12:03:33", "link": "http://arxiv.org/abs/2504.04458v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "VSLAM-LAB: A Comprehensive Framework for Visual SLAM Methods and Datasets", "abstract": "Visual Simultaneous Localization and Mapping (VSLAM) research faces\nsignificant challenges due to fragmented toolchains, complex system\nconfigurations, and inconsistent evaluation methodologies. To address these\nissues, we present VSLAM-LAB, a unified framework designed to streamline the\ndevelopment, evaluation, and deployment of VSLAM systems. VSLAM-LAB simplifies\nthe entire workflow by enabling seamless compilation and configuration of VSLAM\nalgorithms, automated dataset downloading and preprocessing, and standardized\nexperiment design, execution, and evaluation--all accessible through a single\ncommand-line interface. The framework supports a wide range of VSLAM systems\nand datasets, offering broad compatibility and extendability while promoting\nreproducibility through consistent evaluation metrics and analysis tools. By\nreducing implementation complexity and minimizing configuration overhead,\nVSLAM-LAB empowers researchers to focus on advancing VSLAM methodologies and\naccelerates progress toward scalable, real-world solutions. We demonstrate the\nease with which user-relevant benchmarks can be created: here, we introduce\ndifficulty-level-based categories, but one could envision environment-specific\nor condition-specific categories.", "published": "2025-04-06 12:02:19", "link": "http://arxiv.org/abs/2504.04457v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PRISM: Probabilistic Representation for Integrated Shape Modeling and Generation", "abstract": "Despite the advancements in 3D full-shape generation, accurately modeling\ncomplex geometries and semantics of shape parts remains a significant\nchallenge, particularly for shapes with varying numbers of parts. Current\nmethods struggle to effectively integrate the contextual and structural\ninformation of 3D shapes into their generative processes. We address these\nlimitations with PRISM, a novel compositional approach for 3D shape generation\nthat integrates categorical diffusion models with Statistical Shape Models\n(SSM) and Gaussian Mixture Models (GMM). Our method employs compositional SSMs\nto capture part-level geometric variations and uses GMM to represent part\nsemantics in a continuous space. This integration enables both high fidelity\nand diversity in generated shapes while preserving structural coherence.\nThrough extensive experiments on shape generation and manipulation tasks, we\ndemonstrate that our approach significantly outperforms previous methods in\nboth quality and controllability of part-level operations. Our code will be\nmade publicly available.", "published": "2025-04-06 11:48:08", "link": "http://arxiv.org/abs/2504.04454v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Thermoxels: a voxel-based method to generate simulation-ready 3D thermal models", "abstract": "In the European Union, buildings account for 42% of energy use and 35% of\ngreenhouse gas emissions. Since most existing buildings will still be in use by\n2050, retrofitting is crucial for emissions reduction. However, current\nbuilding assessment methods rely mainly on qualitative thermal imaging, which\nlimits data-driven decisions for energy savings. On the other hand,\nquantitative assessments using finite element analysis (FEA) offer precise\ninsights but require manual CAD design, which is tedious and error-prone.\nRecent advances in 3D reconstruction, such as Neural Radiance Fields (NeRF) and\nGaussian Splatting, enable precise 3D modeling from sparse images but lack\nclearly defined volumes and the interfaces between them needed for FEA. We\npropose Thermoxels, a novel voxel-based method able to generate FEA-compatible\nmodels, including both geometry and temperature, from a sparse set of RGB and\nthermal images. Using pairs of RGB and thermal images as input, Thermoxels\nrepresents a scene's geometry as a set of voxels comprising color and\ntemperature information. After optimization, a simple process is used to\ntransform Thermoxels' models into tetrahedral meshes compatible with FEA. We\ndemonstrate Thermoxels' capability to generate RGB+Thermal meshes of 3D scenes,\nsurpassing other state-of-the-art methods. To showcase the practical\napplications of Thermoxels' models, we conduct a simple heat conduction\nsimulation using FEA, achieving convergence from an initial state defined by\nThermoxels' thermal reconstruction. Additionally, we compare Thermoxels' image\nsynthesis abilities with current state-of-the-art methods, showing competitive\nresults, and discuss the limitations of existing metrics in assessing mesh\nquality.", "published": "2025-04-06 11:37:16", "link": "http://arxiv.org/abs/2504.04448v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Evaluation framework for Image Segmentation Algorithms", "abstract": "This paper presents a comprehensive evaluation framework for image\nsegmentation algorithms, encompassing naive methods, machine learning\napproaches, and deep learning techniques. We begin by introducing the\nfundamental concepts and importance of image segmentation, and the role of\ninteractive segmentation in enhancing accuracy. A detailed background theory\nsection explores various segmentation methods, including thresholding, edge\ndetection, region growing, feature extraction, random forests, support vector\nmachines, convolutional neural networks, U-Net, and Mask R-CNN. The\nimplementation and experimental setup are thoroughly described, highlighting\nthree primary approaches: algorithm assisting user, user assisting algorithm,\nand hybrid methods. Evaluation metrics such as Intersection over Union (IoU),\ncomputation time, and user interaction time are employed to measure\nperformance. A comparative analysis presents detailed results, emphasizing the\nstrengths, limitations, and trade-offs of each method. The paper concludes with\ninsights into the practical applicability of these approaches across various\nscenarios and outlines future work, focusing on expanding datasets, developing\nmore representative approaches, integrating real-time feedback, and exploring\nweakly supervised and self-supervised learning paradigms to enhance\nsegmentation accuracy and efficiency. Keywords: Image Segmentation, Interactive\nSegmentation, Machine Learning, Deep Learning, Computer Vision", "published": "2025-04-06 10:20:26", "link": "http://arxiv.org/abs/2504.04435v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hypothesis Testing for Progressive Kernel Estimation and VCM Framework", "abstract": "Identifying an appropriate radius for unbiased kernel estimation is crucial\nfor the efficiency of radiance estimation. However, determining both the radius\nand unbiasedness still faces big challenges. In this paper, we first propose a\nstatistical model of photon samples and associated contributions for\nprogressive kernel estimation, under which the kernel estimation is unbiased if\nthe null hypothesis of this statistical model stands. Then, we present a method\nto decide whether to reject the null hypothesis about the statistical\npopulation (i.e., photon samples) by the F-test in the Analysis of Variance.\nHereby, we implement a progressive photon mapping (PPM) algorithm, wherein the\nkernel radius is determined by this hypothesis test for unbiased radiance\nestimation. Secondly, we propose VCM+, a reinforcement of Vertex Connection and\nMerging (VCM), and derive its theoretically unbiased formulation. VCM+ combines\nhypothesis testing-based PPM with bidirectional path tracing (BDPT) via\nmultiple importance sampling (MIS), wherein our kernel radius can leverage the\ncontributions from PPM and BDPT. We test our new algorithms, improved PPM and\nVCM+, on diverse scenarios with different lighting settings. The experimental\nresults demonstrate that our method can alleviate light leaks and visual blur\nartifacts of prior radiance estimate algorithms. We also evaluate the\nasymptotic performance of our approach and observe an overall improvement over\nthe baseline in all testing scenarios.", "published": "2025-04-06 08:37:35", "link": "http://arxiv.org/abs/2504.04411v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning", "abstract": "The advances in vision-language models (VLMs) have led to a growing interest\nin autonomous driving to leverage their strong reasoning capabilities. However,\nextending these capabilities from 2D to full 3D understanding is crucial for\nreal-world applications. To address this challenge, we propose OmniDrive, a\nholistic vision-language dataset that aligns agent models with 3D driving tasks\nthrough counterfactual reasoning. This approach enhances decision-making by\nevaluating potential scenarios and their outcomes, similar to human drivers\nconsidering alternative actions. Our counterfactual-based synthetic data\nannotation process generates large-scale, high-quality datasets, providing\ndenser supervision signals that bridge planning trajectories and language-based\nreasoning. Futher, we explore two advanced OmniDrive-Agent frameworks, namely\nOmni-L and Omni-Q, to assess the importance of vision-language alignment versus\n3D perception, revealing critical insights into designing effective LLM-agents.\nSignificant improvements on the DriveLM Q\\&A benchmark and nuScenes open-loop\nplanning demonstrate the effectiveness of our dataset and methods.", "published": "2025-04-06 03:54:21", "link": "http://arxiv.org/abs/2504.04348v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnomalyHybrid: A Domain-agnostic Generative Framework for General Anomaly Detection", "abstract": "Anomaly generation is an effective way to mitigate data scarcity for anomaly\ndetection task. Most existing works shine at industrial anomaly generation with\nmultiple specialists or large generative models, rarely generalizing to\nanomalies in other applications. In this paper, we present AnomalyHybrid, a\ndomain-agnostic framework designed to generate authentic and diverse anomalies\nsimply by combining the reference and target images. AnomalyHybrid is a\nGenerative Adversarial Network(GAN)-based framework having two decoders that\nintegrate the appearance of reference image into the depth and edge structures\nof target image respectively. With the help of depth decoders, AnomalyHybrid\nachieves authentic generation especially for the anomalies with depth values\nchanging, such a s protrusion and dent. More, it relaxes the fine granularity\nstructural control of the edge decoder and brings more diversity. Without using\nannotations, AnomalyHybrid is easily trained with sets of color, depth and edge\nof same images having different augmentations. Extensive experiments carried on\nHeliconiusButterfly, MVTecAD and MVTec3D datasets demonstrate that\nAnomalyHybrid surpasses the GAN-based state-of-the-art on anomaly generation\nand its downstream anomaly classification, detection and segmentation tasks. On\nMVTecAD dataset, AnomalyHybrid achieves 2.06/0.32 IS/LPIPS for anomaly\ngeneration, 52.6 Acc for anomaly classification with ResNet34, 97.3/72.9 AP for\nimage/pixel-level anomaly detection with a simple UNet.", "published": "2025-04-06 03:28:30", "link": "http://arxiv.org/abs/2504.04340v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NCL-CIR: Noise-aware Contrastive Learning for Composed Image Retrieval", "abstract": "Composed Image Retrieval (CIR) seeks to find a target image using a\nmulti-modal query, which combines an image with modification text to pinpoint\nthe target. While recent CIR methods have shown promise, they mainly focus on\nexploring relationships between the query pairs (image and text) through data\naugmentation or model design. These methods often assume perfect alignment\nbetween queries and target images, an idealized scenario rarely encountered in\npractice. In reality, pairs are often partially or completely mismatched due to\nissues like inaccurate modification texts, low-quality target images, and\nannotation errors. Ignoring these mismatches leads to numerous False Positive\nPair (FFPs) denoted as noise pairs in the dataset, causing the model to overfit\nand ultimately reducing its performance. To address this problem, we propose\nthe Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two key\ncomponents: the Weight Compensation Block (WCB) and the Noise-pair Filter Block\n(NFB). The WCB coupled with diverse weight maps can ensure more stable token\nrepresentations of multi-modal queries and target images. Meanwhile, the NFB,\nin conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs by\nevaluating loss distributions, and generates soft labels correspondingly,\nallowing for the design of the soft-label based Noise Contrastive Estimation\n(NCE) loss function. Consequently, the overall architecture helps to mitigate\nthe influence of mismatched and partially matched samples, with experimental\nresults demonstrating that NCL-CIR achieves exceptional performance on the\nbenchmark datasets.", "published": "2025-04-06 03:27:23", "link": "http://arxiv.org/abs/2504.04339v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data Scaling Laws for End-to-End Autonomous Driving", "abstract": "Autonomous vehicle (AV) stacks have traditionally relied on decomposed\napproaches, with separate modules handling perception, prediction, and\nplanning. However, this design introduces information loss during inter-module\ncommunication, increases computational overhead, and can lead to compounding\nerrors. To address these challenges, recent works have proposed architectures\nthat integrate all components into an end-to-end differentiable model, enabling\nholistic system optimization. This shift emphasizes data engineering over\nsoftware integration, offering the potential to enhance system performance by\nsimply scaling up training resources. In this work, we evaluate the performance\nof a simple end-to-end driving architecture on internal driving datasets\nranging in size from 16 to 8192 hours with both open-loop metrics and\nclosed-loop simulations. Specifically, we investigate how much additional\ntraining data is needed to achieve a target performance gain, e.g., a 5%\nimprovement in motion prediction accuracy. By understanding the relationship\nbetween model performance and training dataset size, we aim to provide insights\nfor data-driven decision-making in autonomous driving development.", "published": "2025-04-06 03:23:48", "link": "http://arxiv.org/abs/2504.04338v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "MedM-VL: What Makes a Good Medical LVLM?", "abstract": "Medical image analysis is a fundamental component. As deep learning\nprogresses, the focus has shifted from single-task applications, such as\nclassification and segmentation, to more complex multimodal tasks, including\nmedical visual question answering and report generation. Traditional shallow\nand task-specific models are increasingly limited in addressing the complexity\nand scalability required in clinical practice. The emergence of large language\nmodels (LLMs) has driven the development of medical Large Vision-Language\nModels (LVLMs), offering a unified solution for diverse vision-language tasks.\nIn this study, we investigate various architectural designs for medical LVLMs\nbased on the widely adopted LLaVA framework, which follows an\nencoder-connector-LLM paradigm. We construct two distinct models targeting 2D\nand 3D modalities, respectively. These models are designed to support both\ngeneral-purpose medical tasks and domain-specific fine-tuning, thereby serving\nas effective foundation models. To facilitate reproducibility and further\nresearch, we develop a modular and extensible codebase, MedM-VL, and release\ntwo LVLM variants: MedM-VL-2D for 2D medical image analysis and\nMedM-VL-CT-Chest for 3D CT-based applications. The code and models are\navailable at: https://github.com/MSIIP/MedM-VL", "published": "2025-04-06 01:44:46", "link": "http://arxiv.org/abs/2504.04323v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Variational Self-Supervised Learning", "abstract": "We present Variational Self-Supervised Learning (VSSL), a novel framework\nthat combines variational inference with self-supervised learning to enable\nefficient, decoder-free representation learning. Unlike traditional VAEs that\nrely on input reconstruction via a decoder, VSSL symmetrically couples two\nencoders with Gaussian outputs. A momentum-updated teacher network defines a\ndynamic, data-dependent prior, while the student encoder produces an\napproximate posterior from augmented views. The reconstruction term in the ELBO\nis replaced with a cross-view denoising objective, preserving the analytical\ntractability of Gaussian KL divergence. We further introduce cosine-based\nformulations of KL and log-likelihood terms to enhance semantic alignment in\nhigh-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and\nImageNet-100 show that VSSL achieves competitive or superior performance to\nleading self-supervised methods, including BYOL and MoCo V3. VSSL offers a\nscalable, probabilistically grounded approach to learning transferable\nrepresentations without generative reconstruction, bridging the gap between\nvariational modeling and modern self-supervised techniques.", "published": "2025-04-06 01:28:50", "link": "http://arxiv.org/abs/2504.04318v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Balanced colorings of Erd\u0151s-R\u00e9nyi hypergraphs", "abstract": "An $r$-uniform hypergraph $H = (V, E)$ is $r$-partite if there exists a\npartition of the vertex set into $r$ parts such that each edge contains exactly\none vertex from each part. We say an independent set in such a hypergraph is\nbalanced if it contains an equal number of vertices from each partition. The\nbalanced chromatic number of $H$ is the minimum value $q$ such that $H$ admits\na proper $q$-coloring where each color class is a balanced independent set. In\nthis note, we determine the asymptotic behavior of the balanced chromatic\nnumber for sparse $r$-uniform $r$-partite Erd\\H{o}s--R\\'enyi hypergraphs. A key\nstep in our proof is to show that any balanced colorable hypergraph of average\ndegree $d$ admits a proper balanced coloring with $r(r-1)d + 1$ colors. This\nextends a result of Feige and Kogan on bipartite graphs to this more general\nsetting.", "published": "2025-04-06 18:53:23", "link": "http://arxiv.org/abs/2504.04585v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Minimum Cut Representability of Stable Matching Problems", "abstract": "We introduce and study Minimum Cut Representability, a framework to solve\noptimization and feasibility problems over stable matchings by representing\nthem as minimum s-t cut problems on digraphs over rotations. We provide\nnecessary and sufficient conditions on objective functions and feasibility sets\nfor problems to be minimum cut representable. In particular, we define the\nconcepts of first and second order differentials of a function over stable\nmatchings and show that a problem is minimum cut representable if and only if,\nroughly speaking, the objective function can be expressed solely using these\ndifferentials, and the feasibility set is a sublattice of the stable matching\nlattice. To demonstrate the practical relevance of our framework, we study a\nrange of real-world applications, including problems involving school choice\nwith siblings and a two-stage stochastic stable matching problem. We show how\nour framework can be used to help solving these problems.", "published": "2025-04-06 18:35:25", "link": "http://arxiv.org/abs/2504.04577v1", "categories": ["math.OC", "cs.DM"], "primary_category": "math.OC"}
{"title": "Binary Weight Allocation for Multi-Objective Path Optimization: Efficient Earliest and Latest Path Discovery in Network Systems", "abstract": "This paper proposes earliest and latest path algorithms based on binary\nweight allocation, assigning weights of 2(i-1) and 2(m-i) to the i-th arc in a\nnetwork. While traditional shortest path algorithms optimize only distance, our\napproach leverages Binary-Addition-Tree ordering to efficiently identify\nlexicographically smallest and largest paths that establish connectivity. These\npaths partition the solution space into three regions: guaranteed\ndisconnection, transitional connectivity, and guaranteed no simple paths. Our\nweight allocation enables implicit encoding of multiple objectives directly in\nbinary representations, maintaining the O((|V|+|E|)log|V|) complexity of\nDijkstra's algorithm while allowing simultaneous optimization of competing\nfactors like reliability and cost. Experimental validation demonstrates\nsignificant computational time reduction compared to traditional\nmulti-objective methods. Applications span telecommunications, transportation\nnetworks, and supply chain management, providing efficient tools for network\nplanning and reliability analysis under multiple constraints.", "published": "2025-04-06 14:18:52", "link": "http://arxiv.org/abs/2504.04499v1", "categories": ["math.CO", "cs.DM", "cs.NA", "math.NA"], "primary_category": "math.CO"}
{"title": "COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation", "abstract": "Recent works in multimodal recommendations, which leverage diverse modal\ninformation to address data sparsity and enhance recommendation accuracy, have\ngarnered considerable interest. Two key processes in multimodal recommendations\nare modality fusion and representation learning. Previous approaches in\nmodality fusion often employ simplistic attentive or pre-defined strategies at\nearly or late stages, failing to effectively handle irrelevant information\namong modalities. In representation learning, prior research has constructed\nheterogeneous and homogeneous graph structures encapsulating user-item,\nuser-user, and item-item relationships to better capture user interests and\nitem profiles. Modality fusion and representation learning were considered as\ntwo independent processes in previous work. In this paper, we reveal that these\ntwo processes are complementary and can support each other. Specifically,\npowerful representation learning enhances modality fusion, while effective\nfusion improves representation quality. Stemming from these two processes, we\nintroduce a COmposite grapH convolutional nEtwork with dual-stage fuSION for\nthe multimodal recommendation, named COHESION. Specifically, it introduces a\ndual-stage fusion strategy to reduce the impact of irrelevant information,\nrefining all modalities using ID embedding in the early stage and fusing their\nrepresentations at the late stage. It also proposes a composite graph\nconvolutional network that utilizes user-item, user-user, and item-item graphs\nto extract heterogeneous and homogeneous latent relationships within users and\nitems. Besides, it introduces a novel adaptive optimization to ensure balanced\nand reasonable representations across modalities. Extensive experiments on\nthree widely used datasets demonstrate the significant superiority of COHESION\nover various competitive baselines.", "published": "2025-04-06 11:42:49", "link": "http://arxiv.org/abs/2504.04452v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Squeeze and Excitation: A Weighted Graph Contrastive Learning for Collaborative Filtering", "abstract": "Contrastive Learning (CL) has recently emerged as a powerful technique in\nrecommendation systems, particularly for its capability to harness\nself-supervised signals from perturbed views to mitigate the persistent\nchallenge of data sparsity. The process of constructing perturbed views of the\nuser-item bipartite graph and performing contrastive learning between perturbed\nviews in a graph convolutional network (GCN) is called graph contrastive\nlearning (GCL), which aims to enhance the robustness of representation\nlearning. Although existing GCL-based models are effective, the weight\nassignment method for perturbed views has not been fully explored. A critical\nproblem in existing GCL-based models is the irrational allocation of feature\nattention. This problem limits the model's ability to effectively leverage\ncrucial features, resulting in suboptimal performance. To address this, we\npropose a Weighted Graph Contrastive Learning framework (WeightedGCL).\nSpecifically, WeightedGCL applies a robust perturbation strategy, which\nperturbs only the view of the final GCN layer. In addition, WeightedGCL\nincorporates a squeeze and excitation network (SENet) to dynamically weight the\nfeatures of the perturbed views. Our WeightedGCL strengthens the model's focus\non crucial features and reduces the impact of less relevant information.\nExtensive experiments on widely used datasets demonstrate that our WeightedGCL\nachieves significant accuracy improvements compared to competitive baselines.", "published": "2025-04-06 11:30:59", "link": "http://arxiv.org/abs/2504.04443v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Decoding Recommendation Behaviors of In-Context Learning LLMs Through Gradient Descent", "abstract": "Recently, there has been a growing trend in utilizing large language models\n(LLMs) for recommender systems, referred to as LLMRec. A notable approach\nwithin this trend is not to fine-tune these models directly but instead to\nleverage In-Context Learning (ICL) methods tailored for LLMRec, denoted as\nLLM-ICL Rec. Many contemporary techniques focus on harnessing ICL content to\nenhance LLMRec performance.\n  However, optimizing LLMRec with ICL content presents unresolved challenges.\nSpecifically, two key issues stand out: (1) the limited understanding of why\nusing a few demonstrations without model fine-tuning can lead to better\nperformance compared to zero-shot recommendations. (2) the lack of evaluation\nmetrics for demonstrations in LLM-ICL Rec and the absence of the theoretical\nanalysis and practical design for optimizing the generation of ICL content for\nrecommendation contexts.\n  To address these two main issues, we propose a theoretical model, the LLM-ICL\nRecommendation Equivalent Gradient Descent model (LRGD) in this paper, which\nconnects recommendation generation with gradient descent dynamics. We\ndemonstrate that the ICL inference process in LLM aligns with the training\nprocedure of its dual model, producing token predictions equivalent to the dual\nmodel's testing outputs. Building on these theoretical insights, we propose an\nevaluation metric for assessing demonstration quality. We integrate\nperturbations and regularizations in LRGD to enhance the robustness of the\nrecommender system. To further improve demonstration effectiveness, prevent\nperformance collapse, and ensure long-term adaptability, we also propose a\ntwo-stage optimization process in practice. Extensive experiments and detailed\nanalysis on three Amazon datasets validate the theoretical equivalence and\nsupport the effectiveness of our theoretical analysis and practical module\ndesign.", "published": "2025-04-06 06:36:45", "link": "http://arxiv.org/abs/2504.04386v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Novel Algorithm for Personalized Federated Learning: Knowledge Distillation with Weighted Combination Loss", "abstract": "Federated learning (FL) offers a privacy-preserving framework for distributed\nmachine learning, enabling collaborative model training across diverse clients\nwithout centralizing sensitive data. However, statistical heterogeneity,\ncharacterized by non-independent and identically distributed (non-IID) client\ndata, poses significant challenges, leading to model drift and poor\ngeneralization. This paper proposes a novel algorithm, pFedKD-WCL (Personalized\nFederated Knowledge Distillation with Weighted Combination Loss), which\nintegrates knowledge distillation with bi-level optimization to address non-IID\nchallenges. pFedKD-WCL leverages the current global model as a teacher to guide\nlocal models, optimizing both global convergence and local personalization\nefficiently. We evaluate pFedKD-WCL on the MNIST dataset and a synthetic\ndataset with non-IID partitioning, using multinomial logistic regression and\nmultilayer perceptron models. Experimental results demonstrate that pFedKD-WCL\noutperforms state-of-the-art algorithms, including FedAvg, FedProx, Per-FedAvg,\nand pFedMe, in terms of accuracy and convergence speed.", "published": "2025-04-06 23:22:03", "link": "http://arxiv.org/abs/2504.04642v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Exact Unlearning of Finetuning Data via Model Merging at Scale", "abstract": "Approximate unlearning has gained popularity as an approach to efficiently\nupdate an LLM so that it behaves (roughly) as if it was not trained on a subset\nof data to begin with. However, existing methods are brittle in practice and\ncan easily be attacked to reveal supposedly unlearned information. To alleviate\nissues with approximate unlearning, we instead propose SIFT-Masks (SIgn-Fixed\nTuning-Masks), an exact unlearning method based on model merging. SIFT-Masks\naddresses two key limitations of standard model merging: (1) merging a large\nnumber of tasks can severely harm utility; and (2) methods that boost utility\nby sharing extra information across tasks make exact unlearning prohibitively\nexpensive. SIFT-Masks solves these issues by (1) applying local masks to\nrecover task-specific performance; and (2) constraining finetuning to align\nwith a global sign vector as a lightweight approach to determine masks\nindependently before merging. Across four settings where we merge up to 500\nmodels, SIFT-Masks improves accuracy by 5-80% over naive merging and uses up to\n250x less compute for exact unlearning compared to other merging baselines.", "published": "2025-04-06 21:24:29", "link": "http://arxiv.org/abs/2504.04626v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SiameseDuo++: Active Learning from Data Streams with Dual Augmented Siamese Networks", "abstract": "Data stream mining, also known as stream learning, is a growing area which\ndeals with learning from high-speed arriving data. Its relevance has surged\nrecently due to its wide range of applicability, such as, critical\ninfrastructure monitoring, social media analysis, and recommender systems. The\ndesign of stream learning methods faces significant research challenges; from\nthe nonstationary nature of the data (referred to as concept drift) and the\nfact that data streams are typically not annotated with the ground truth, to\nthe requirement that such methods should process large amounts of data in\nreal-time with limited memory. This work proposes the SiameseDuo++ method,\nwhich uses active learning to automatically select instances for a human expert\nto label according to a budget. Specifically, it incrementally trains two\nsiamese neural networks which operate in synergy, augmented by generated\nexamples. Both the proposed active learning strategy and augmentation operate\nin the latent space. SiameseDuo++ addresses the aforementioned challenges by\noperating with limited memory and limited labelling budget. Simulation\nexperiments show that the proposed method outperforms strong baselines and\nstate-of-the-art methods in terms of learning speed and/or performance. To\npromote open science we publicly release our code and datasets.", "published": "2025-04-06 20:45:25", "link": "http://arxiv.org/abs/2504.04613v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Scalable Approximate Algorithms for Optimal Transport Linear Models", "abstract": "Recently, linear regression models incorporating an optimal transport (OT)\nloss have been explored for applications such as supervised unmixing of\nspectra, music transcription, and mass spectrometry. However, these\ntask-specific approaches often do not generalize readily to a broader class of\nlinear models. In this work, we propose a novel algorithmic framework for\nsolving a general class of non-negative linear regression models with an\nentropy-regularized OT datafit term, based on Sinkhorn-like scaling iterations.\nOur framework accommodates convex penalty functions on the weights (e.g.\nsquared-$\\ell_2$ and $\\ell_1$ norms), and admits additional convex loss terms\nbetween the transported marginal and target distribution (e.g. squared error or\ntotal variation). We derive simple multiplicative updates for common penalty\nand datafit terms. This method is suitable for large-scale problems due to its\nsimplicity of implementation and straightforward parallelization.", "published": "2025-04-06 20:37:25", "link": "http://arxiv.org/abs/2504.04609v1", "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "stat.ML"}
{"title": "Modeling of AUV Dynamics with Limited Resources: Efficient Online Learning Using Uncertainty", "abstract": "Machine learning proves effective in constructing dynamics models from data,\nespecially for underwater vehicles. Continuous refinement of these models using\nincoming data streams, however, often requires storage of an overwhelming\namount of redundant data. This work investigates the use of uncertainty in the\nselection of data points to rehearse in online learning when storage capacity\nis constrained. The models are learned using an ensemble of multilayer\nperceptrons as they perform well at predicting epistemic uncertainty. We\npresent three novel approaches: the Threshold method, which excludes samples\nwith uncertainty below a specified threshold, the Greedy method, designed to\nmaximize uncertainty among the stored points, and Threshold-Greedy, which\ncombines the previous two approaches. The methods are assessed on data\ncollected by an underwater vehicle Dagon. Comparison with baselines reveals\nthat the Threshold exhibits enhanced stability throughout the learning process\nand also yields a model with the least cumulative testing loss. We also\nconducted detailed analyses on the impact of model parameters and storage size\non the performance of the models, as well as a comparison of three different\nuncertainty estimation methods.", "published": "2025-04-06 18:48:55", "link": "http://arxiv.org/abs/2504.04583v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Better Rates for Random Task Orderings in Continual Linear Models", "abstract": "We study the common continual learning setup where an overparameterized model\nis sequentially fitted to a set of jointly realizable tasks. We analyze the\nforgetting, i.e., loss on previously seen tasks, after $k$ iterations. For\nlinear models, we prove that fitting a task is equivalent to a single\nstochastic gradient descent (SGD) step on a modified objective. We develop\nnovel last-iterate SGD upper bounds in the realizable least squares setup, and\napply them to derive new results for continual learning. Focusing on random\norderings over $T$ tasks, we establish universal forgetting rates, whereas\nexisting rates depend on the problem dimensionality or complexity.\nSpecifically, in continual regression with replacement, we improve the best\nexisting rate from $O((d-r)/k)$ to $O(\\min(k^{-1/4}, \\sqrt{d-r}/k,\n\\sqrt{Tr}/k))$, where $d$ is the dimensionality and $r$ the average task rank.\nFurthermore, we establish the first rates for random task orderings without\nreplacement. The obtained rate of $O(\\min(T^{-1/4}, (d-r)/T))$ proves for the\nfirst time that randomization alone, with no task repetition, can prevent\ncatastrophic forgetting in sufficiently long task sequences. Finally, we prove\na similar $O(k^{-1/4})$ universal rate for the forgetting in continual linear\nclassification on separable data. Our universal rates apply for broader\nprojection methods, such as block Kaczmarz and POCS, illuminating their loss\nconvergence under i.i.d and one-pass orderings.", "published": "2025-04-06 18:39:45", "link": "http://arxiv.org/abs/2504.04579v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Cramer-Rao Bounds for Laplacian Matrix Estimation", "abstract": "In this paper, we analyze the performance of the estimation of Laplacian\nmatrices under general observation models. Laplacian matrix estimation involves\nstructural constraints, including symmetry and null-space properties, along\nwith matrix sparsity. By exploiting a linear reparametrization that enforces\nthe structural constraints, we derive closed-form matrix expressions for the\nCramer-Rao Bound (CRB) specifically tailored to Laplacian matrix estimation. We\nfurther extend the derivation to the sparsity-constrained case, introducing two\noracle CRBs that incorporate prior information of the support set, i.e. the\nlocations of the nonzero entries in the Laplacian matrix. We examine the\nproperties and order relations between the bounds, and provide the associated\nSlepian-Bangs formula for the Gaussian case. We demonstrate the use of the new\nCRBs in three representative applications: (i) topology identification in power\nsystems, (ii) graph filter identification in diffused models, and (iii)\nprecision matrix estimation in Gaussian Markov random fields under Laplacian\nconstraints. The CRBs are evaluated and compared with the mean-squared-errors\n(MSEs) of the constrained maximum likelihood estimator (CMLE), which integrates\nboth equality and inequality constraints along with sparsity constraints, and\nof the oracle CMLE, which knows the locations of the nonzero entries of the\nLaplacian matrix. We perform this analysis for the applications of power system\ntopology identification and graphical LASSO, and demonstrate that the MSEs of\nthe estimators converge to the CRB and oracle CRB, given a sufficient number of\nmeasurements.", "published": "2025-04-06 18:28:31", "link": "http://arxiv.org/abs/2504.04576v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "A Classification View on Meta Learning Bandits", "abstract": "Contextual multi-armed bandits are a popular choice to model sequential\ndecision-making. E.g., in a healthcare application we may perform various tests\nto asses a patient condition (exploration) and then decide on the best\ntreatment to give (exploitation). When humans design strategies, they aim for\nthe exploration to be fast, since the patient's health is at stake, and easy to\ninterpret for a physician overseeing the process. However, common bandit\nalgorithms are nothing like that: The regret caused by exploration scales with\n$\\sqrt{H}$ over $H$ rounds and decision strategies are based on opaque\nstatistical considerations. In this paper, we use an original classification\nview to meta learn interpretable and fast exploration plans for a fixed\ncollection of bandits $\\mathbb{M}$. The plan is prescribed by an interpretable\ndecision tree probing decisions' payoff to classify the test bandit. The test\nregret of the plan in the stochastic and contextual setting scales with $O\n(\\lambda^{-2} C_{\\lambda} (\\mathbb{M}) \\log^2 (MH))$, being $M$ the size of\n$\\mathbb{M}$, $\\lambda$ a separation parameter over the bandits, and $C_\\lambda\n(\\mathbb{M})$ a novel classification-coefficient that fundamentally links meta\nlearning bandits with classification. Through a nearly matching lower bound, we\nshow that $C_\\lambda (\\mathbb{M})$ inherently captures the complexity of the\nsetting.", "published": "2025-04-06 14:25:21", "link": "http://arxiv.org/abs/2504.04505v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deliberate Planning of 3D Bin Packing on Packing Configuration Trees", "abstract": "Online 3D Bin Packing Problem (3D-BPP) has widespread applications in\nindustrial automation. Existing methods usually solve the problem with limited\nresolution of spatial discretization, and/or cannot deal with complex practical\nconstraints well. We propose to enhance the practical applicability of online\n3D-BPP via learning on a novel hierarchical representation, packing\nconfiguration tree (PCT). PCT is a full-fledged description of the state and\naction space of bin packing which can support packing policy learning based on\ndeep reinforcement learning (DRL). The size of the packing action space is\nproportional to the number of leaf nodes, making the DRL model easy to train\nand well-performing even with continuous solution space. We further discover\nthe potential of PCT as tree-based planners in deliberately solving packing\nproblems of industrial significance, including large-scale packing and\ndifferent variations of BPP setting. A recursive packing method is proposed to\ndecompose large-scale packing into smaller sub-trees while a spatial ensemble\nmechanism integrates local solutions into global. For different BPP variations\nwith additional decision variables, such as lookahead, buffering, and offline\npacking, we propose a unified planning framework enabling out-of-the-box\nproblem solving. Extensive evaluations demonstrate that our method outperforms\nexisting online BPP baselines and is versatile in incorporating various\npractical constraints. The planning process excels across large-scale problems\nand diverse problem variations. We develop a real-world packing robot for\nindustrial warehousing, with careful designs accounting for constrained\nplacement and transportation stability. Our packing robot operates reliably and\nefficiently on unprotected pallets at 10 seconds per box. It achieves averagely\n19 boxes per pallet with 57.4% space utilization for relatively large-size\nboxes.", "published": "2025-04-06 09:07:10", "link": "http://arxiv.org/abs/2504.04421v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Binned Group Algebra Factorization for Differentially Private Continual Counting", "abstract": "We study memory-efficient matrix factorization for differentially private\ncounting under continual observation. While recent work by Henzinger and\nUpadhyay 2024 introduced a factorization method with reduced error based on\ngroup algebra, its practicality in streaming settings remains limited by\ncomputational constraints. We present new structural properties of the group\nalgebra factorization, enabling the use of a binning technique from Andersson\nand Pagh (2024). By grouping similar values in rows, the binning method reduces\nmemory usage and running time to $\\tilde O(\\sqrt{n})$, where $n$ is the length\nof the input stream, while maintaining a low error. Our work bridges the gap\nbetween theoretical improvements in factorization accuracy and practical\nefficiency in large-scale private learning systems.", "published": "2025-04-06 07:55:45", "link": "http://arxiv.org/abs/2504.04398v1", "categories": ["cs.DS", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Human-Level Competitive Pok\u00e9mon via Scalable Offline Reinforcement Learning with Transformers", "abstract": "Competitive Pok\\'emon Singles (CPS) is a popular strategy game where players\nlearn to exploit their opponent based on imperfect information in battles that\ncan last more than one hundred stochastic turns. AI research in CPS has been\nled by heuristic tree search and online self-play, but the game may also create\na platform to study adaptive policies trained offline on large datasets. We\ndevelop a pipeline to reconstruct the first-person perspective of an agent from\nlogs saved from the third-person perspective of a spectator, thereby unlocking\na dataset of real human battles spanning more than a decade that grows larger\nevery day. This dataset enables a black-box approach where we train large\nsequence models to adapt to their opponent based solely on their input\ntrajectory while selecting moves without explicit search of any kind. We study\na progression from imitation learning to offline RL and offline fine-tuning on\nself-play data in the hardcore competitive setting of Pok\\'emon's four oldest\n(and most partially observed) game generations. The resulting agents outperform\na recent LLM Agent approach and a strong heuristic search engine. While playing\nanonymously in online battles against humans, our best agents climb to rankings\ninside the top 10% of active players.", "published": "2025-04-06 07:35:15", "link": "http://arxiv.org/abs/2504.04395v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Novel Cholesky Kernel based Support Vector Classifier", "abstract": "Support Vector Machine (SVM) is a popular supervised classification model\nthat works by first finding the margin boundaries for the training data classes\nand then calculating the decision boundary, which is then used to classify the\ntest data. This study demonstrates limitations of traditional support vector\nclassification which uses cartesian coordinate geometry to find the margin and\ndecision boundaries in an input space using only a few support vectors, without\nconsidering data variance and correlation. Subsequently, the study proposes a\nnew Cholesky Kernel that adjusts for the effects of variance-covariance\nstructure of the data in the decision boundary equation and margin\ncalculations. The study demonstrates that SVM model is valid only in the\nEuclidean space, and the Cholesky kernel obtained by decomposing covariance\nmatrix acts as a transformation matrix, which when applied on the original data\ntransforms the data from the input space to the Euclidean space. The\neffectiveness of the Cholesky kernel based SVM classifier is demonstrated by\nclassifying the Wisconsin Breast Cancer (Diagnostic) Dataset and comparing with\ntraditional SVM approaches. The Cholesky kernel based SVM model shows marked\nimprovement in the precision, recall and F1 scores compared to linear and other\nkernel SVMs.", "published": "2025-04-06 05:57:33", "link": "http://arxiv.org/abs/2504.04371v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Extending Cox Proportional Hazards Model with Symbolic Non-Linear Log-Risk Functions for Survival Analysis", "abstract": "The Cox proportional hazards (CPH) model has been widely applied in survival\nanalysis to estimate relative risks across different subjects given multiple\ncovariates. Traditional CPH models rely on a linear combination of covariates\nweighted with coefficients as the log-risk function, which imposes a strong and\nrestrictive assumption, limiting generalization. Recent deep learning methods\nenable non-linear log-risk functions. However, they often lack interpretability\ndue to the end-to-end training mechanisms. The implementation of\nKolmogorov-Arnold Networks (KAN) offers new possibilities for extending the CPH\nmodel with fully transparent and symbolic non-linear log-risk functions. In\nthis paper, we introduce Generalized Cox Proportional Hazards (GCPH) model, a\nnovel method for survival analysis that leverages KAN to enable a non-linear\nmapping from covariates to survival outcomes in a fully symbolic manner. GCPH\nmaintains the interpretability of traditional CPH models while allowing for the\nestimation of non-linear log-risk functions. Experiments conducted on both\nsynthetic data and various public benchmarks demonstrate that GCPH achieves\ncompetitive performance in terms of prediction accuracy and exhibits superior\ninterpretability compared to current state-of-the-art methods.", "published": "2025-04-06 04:35:11", "link": "http://arxiv.org/abs/2504.04353v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Tight Regret Bounds for Fixed-Price Bilateral Trade", "abstract": "We examine fixed-price mechanisms in bilateral trade through the lens of\nregret minimization. Our main results are twofold. (i) For independent values,\na near-optimal $\\widetilde{\\Theta}(T^{2/3})$ tight bound for $\\textsf{Global\nBudget Balance}$ fixed-price mechanisms with two-bit/one-bit feedback. (ii) For\ncorrelated/adversarial values, a near-optimal $\\Omega(T^{3/4})$ lower bound for\n$\\textsf{Global Budget Balance}$ fixed-price mechanisms with two-bit/one-bit\nfeedback, which improves the best known $\\Omega(T^{5/7})$ lower bound obtained\nin the work \\cite{BCCF24} and, up to polylogarithmic factors, matches the\n$\\widetilde{\\mathcal{O}}(T^{3 / 4})$ upper bound obtained in the same work. Our\nwork in combination with the previous works \\cite{CCCFL24mor, CCCFL24jmlr,\nAFF24, BCCF24} (essentially) gives a thorough understanding of regret\nminimization for fixed-price bilateral trade.\n  En route, we have developed two technical ingredients that might be of\nindependent interest: (i) A novel algorithmic paradigm, called\n$\\textit{{fractal elimination}}$, to address one-bit feedback and independent\nvalues. (ii) A new $\\textit{lower-bound construction}$ with novel proof\ntechniques, to address the $\\textsf{Global Budget Balance}$ constraint and\ncorrelated values.", "published": "2025-04-06 03:56:42", "link": "http://arxiv.org/abs/2504.04349v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Economic Battery Storage Dispatch with Deep Reinforcement Learning from Rule-Based Demonstrations", "abstract": "The application of deep reinforcement learning algorithms to economic battery\ndispatch problems has significantly increased recently. However, optimizing\nbattery dispatch over long horizons can be challenging due to delayed rewards.\nIn our experiments we observe poor performance of popular actor-critic\nalgorithms when trained on yearly episodes with hourly resolution. To address\nthis, we propose an approach extending soft actor-critic (SAC) with learning\nfrom demonstrations. The special feature of our approach is that, due to the\nabsence of expert demonstrations, the demonstration data is generated through\nsimple, rule-based policies. We conduct a case study on a grid-connected\nmicrogrid and use if-then-else statements based on the wholesale price of\nelectricity to collect demonstrations. These are stored in a separate replay\nbuffer and sampled with linearly decaying probability along with the agent's\nown experiences. Despite these minimal modifications and the imperfections in\nthe demonstration data, the results show a drastic performance improvement\nregarding both sample efficiency and final rewards. We further show that the\nproposed method reliably outperforms the demonstrator and is robust to the\nchoice of rule, as long as the rule is sufficient to guide early training into\nthe right direction.", "published": "2025-04-06 02:16:42", "link": "http://arxiv.org/abs/2504.04326v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Causal Inference Isn't Special: Why It's Just Another Prediction Problem", "abstract": "Causal inference is often portrayed as fundamentally distinct from predictive\nmodeling, with its own terminology, goals, and intellectual challenges. But at\nits core, causal inference is simply a structured instance of prediction under\ndistribution shift. In both cases, we begin with labeled data from a source\ndomain and seek to generalize to a target domain where outcomes are not\nobserved. The key difference is that in causal inference, the labels --\npotential outcomes -- are selectively observed based on treatment assignment,\nintroducing bias that must be addressed through assumptions. This perspective\nreframes causal estimation as a familiar generalization problem and highlights\nhow techniques from predictive modeling, such as reweighting and domain\nadaptation, apply directly to causal tasks. It also clarifies that causal\nassumptions are not uniquely strong -- they are simply more explicit. By\nviewing causal inference through the lens of prediction, we demystify its\nlogic, connect it to familiar tools, and make it more accessible to\npractitioners and educators alike.", "published": "2025-04-06 01:37:50", "link": "http://arxiv.org/abs/2504.04320v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conformal Data-driven Control of Stochastic Multi-Agent Systems under Collaborative Signal Temporal Logic Specifications", "abstract": "We study the control of stochastic discrete-time linear multi-agent systems\n(MAS) subject to additive stochastic noise and collaborative signal temporal\nlogic (STL) specifications to be satisfied with a desired probability. Given\navailable disturbance datasets, we leverage conformal prediction (CP) to\naddress the underlying chance-constrained multi-agent STL synthesis problem in\na distribution-free manner. By introducing nonconformity scores as functions of\nprediction regions (PRs) of error trajectories, we develop an iterative\nPR-scaling and disturbance-feedback synthesis approach to bound training error\ntrajectory samples. These bounds are then calibrated using a separate dataset,\nproviding probabilistic guarantees via CP. Subsequently, we relax the\nunderlying stochastic optimal control problem by tightening the robustness\nfunctions of collaborative tasks based on their Lipschitz constants and the\ncomputed error bounds. To address scalability, we exploit the compositional\nstructure of the multi-agent STL formula and propose a\nmodel-predictive-control-like algorithm, where agent-level problems are solved\nin a distributed fashion. Lastly, we showcase the benefits of the proposed\nmethod in comparison with [1] via an illustrative example.", "published": "2025-04-06 20:53:49", "link": "http://arxiv.org/abs/2504.04615v1", "categories": ["eess.SY", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Lippmann-Schwinger-Lanczos approach for inverse scattering problem of Schrodinger equation in the resonance frequency domain", "abstract": "Reconstructions of potential in Schrodinger equation with data in the\ndiffusion frequency domain have been successfully obtained within\nLippmann-Schwinger-Lanczos (LSL) approach, however limited resolution away from\nthe sensor positions resulted in rather blurry images. To improve the\nreconstructions, in this work we extended the applicability of the approach to\nthe data in the resonance frequency domain. We proposed a specific data\nsampling according to Weyl's law that allows us to obtain sharp images without\noversampling and overwhelming computational complexity. Numerical results\npresented at the end illustrate the performance of the algorithm.", "published": "2025-04-06 20:35:25", "link": "http://arxiv.org/abs/2504.04607v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Note on the Stability of the Sherman-Morrison-Woodbury Formula", "abstract": "We study the numerical stability of the Sherman-Morrison-Woodbury (SMW)\nidentity. Let $B = A + UV^T$ and assume $U$ and $V$ both have full-column rank.\nWe explore error bounds for the SMW identity when we are only able to compute\napproximate inverses. For both forward and backward errors, we present upper\nbounds as a function of the two-norm error of the approximate inverses. We\nverify with numerical experiments that, in certain cases, our bounds accurately\ncapture the behavior of the errors.", "published": "2025-04-06 17:13:30", "link": "http://arxiv.org/abs/2504.04554v1", "categories": ["math.NA", "cs.NA", "65F05, 65F35, 15A23, 15A24, 15A45"], "primary_category": "math.NA"}
{"title": "Optimal Order Space-Time Discretization Methods for the Nonlinear Stochastic Elastic Wave Equations with Multiplicative Noise", "abstract": "This paper develops and analyzes an optimal-order semi-discrete scheme and\nits fully discrete finite element approximation for nonlinear stochastic\nelastic wave equations with multiplicative noise. A non-standard time-stepping\nscheme is introduced for time discretization, it is showed that the scheme\nconverges with rates $O(\\tau)$ and $O(\\tau^{\\frac32})$ respectively in the\nenergy- and $L^2$-norm, which are optimal with respect to the time regularity\nof the PDE solution. For spatial discretization, the standard finite element\nmethod is employed. It is proven that the fully discrete method converges with\noptimal rates $O(\\tau + h)$ and $O(\\tau^{\\frac{3}{2}} + h^2)$ respectively in\nthe energy- and $L^2$-norm. The cruxes of the analysis are to establish some\nhigh-moment stability results and utilize a refined error estimate for the\ntrapezoidal quadrature rule to control the nonlinearities from the drift term\nand the multiplicative noise. Numerical experiments are also provided to\nvalidate the theoretical results.", "published": "2025-04-06 16:04:30", "link": "http://arxiv.org/abs/2504.04531v1", "categories": ["math.NA", "cs.NA", "65N12, %Stability and convergence of numerical methods 65N15, %Error\n  bounds 65N30, 65N12, 65N15"], "primary_category": "math.NA"}
{"title": "Truncated Huber Penalty for Sparse Signal Recovery with Convergence Analysis", "abstract": "Sparse signal recovery from under-determined systems presents significant\nchallenges when using conventional L_0 and L_1 penalties, primarily due to\ncomputational complexity and estimation bias. This paper introduces a truncated\nHuber penalty, a non-convex metric that effectively bridges the gap between\nunbiased sparse recovery and differentiable optimization. The proposed penalty\napplies quadratic regularization to small entries while truncating large\nmagnitudes, avoiding non-differentiable points at optima. Theoretical analysis\ndemonstrates that, for an appropriately chosen threshold, any s-sparse solution\nrecoverable via conventional penalties remains a local optimum under the\ntruncated Huber function. This property allows the exact and robust recovery\ntheories developed for other penalty regularization functions to be directly\nextended to the truncated Huber function. To solve the optimization problem, we\ndevelop a block coordinate descent (BCD) algorithm with finite-step convergence\nguarantees under spark conditions. Numerical experiments are conducted to\nvalidate the effectiveness and robustness of the proposed approach.\nFurthermore, we extend the truncated Huber-penalized model to the gradient\ndomain, illustrating its applicability in signal denoising and image smoothing.", "published": "2025-04-06 14:47:21", "link": "http://arxiv.org/abs/2504.04509v1", "categories": ["math.NA", "cs.NA", "90C26, 90C90, 65K10, 49N45,"], "primary_category": "math.NA"}
{"title": "The positivity-preserving high-order semi-Lagrangian spectral volume method for Vlasov-Poisson equations", "abstract": "In this paper, a novel high order semi-Lagrangian (SL) spectral volume (SV)\nmethod is proposed and studied for nonlinear Vlasov-Poisson (VP) simulations\nvia operator splitting. The proposed algorithm combines both advantages of\nsemi-Lagrangian and spectral volume approaches, exhibiting strong stability,\nrobustness under large time steps, arbitrary high-order accuracy in space,\nlocal mass conservation, and positivity preservation. Numerical study of the\nSLSV method applied to the one-dimensional and two-dimensional transport\nequations, the Vlasov-Poisson system, the classical benchmark problems\nincluding Landau damping and two-stream instabilities is conducted, confirming\nthe effectiveness, accuracy, and robustness of our algorithm in addressing\ncomplex nonlinear phenomena.", "published": "2025-04-06 14:23:17", "link": "http://arxiv.org/abs/2504.04501v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Adaptive Approximations of Inclusions in a Semilinear Elliptic Problem Related to Cardiac Electrophysiology", "abstract": "In this work, we investigate the numerical reconstruction of inclusions in a\nsemilinear elliptic equation arising in the mathematical modeling of cardiac\nischemia. We propose an adaptive finite element method for the resulting\nconstrained minimization problem that is relaxed by a phase-field approach. The\n\\textit{a posteriori} error estimators of the adaptive algorithm consist of\nthree components, i.e., the state variable, the adjoint variable and the\ncomplementary relation. Moreover, using tools from adaptive finite element\nanalysis and nonlinear optimization, we establish the strong convergence for a\nsubsequence of adaptively generated discrete solutions to a solution of the\ncontinuous optimality system. Several numerical examples are presented to\nillustrate the convergence and efficiency of the adaptive algorithm", "published": "2025-04-06 13:33:59", "link": "http://arxiv.org/abs/2504.04483v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Sampling patterns for Zernike-like bases in non-standard geometries", "abstract": "Zernike polynomials are widely used in optics and ophthalmology due to their\ndirect connection to classical optical aberrations. While orthogonal on the\nunit disk, their application to discrete data or non-circular domains--such as\nellipses, annuli, and hexagons--presents challenges in terms of numerical\nstability and accuracy. In this work, we extend Zernike-like orthogonal\nfunctions to these non-standard geometries using diffeomorphic mappings and\nconstruct sampling patterns that preserve favorable numerical conditioning. We\nprovide theoretical bounds for the condition numbers of the resulting\ncollocation matrices and validate them through extensive numerical experiments.\nAs a practical application, we demonstrate accurate wavefront interpolation and\nreconstruction in segmented mirror telescopes composed of hexagonal facets. Our\nresults show that appropriately transferred sampling configurations, especially\nOptimal Concentric Sampling and Lebesgue points, allow stable high-order\ninterpolation and effective wavefront modeling in complex optical systems.\nMoreover, the Optimal Concentric Samplings can be computed with an explicit\nexpression, which is a significant advantage in practice.", "published": "2025-04-06 10:54:47", "link": "http://arxiv.org/abs/2504.04442v1", "categories": ["math.NA", "cs.NA", "65D05", "G.1.1; G.1.3"], "primary_category": "math.NA"}
{"title": "Error analysis of a Euler finite element scheme for Natural convection model with variable density", "abstract": "In this paper, we derive first-order Euler finite element discretization\nschemes for a time-dependent natural convection model with variable density\n(NCVD). The model is governed by the variable density Navier-Stokes equations\ncoupled with a parabolic partial differential equation that describes the\nevolution of temperature. Stability and error estimate for the velocity,\npressure, density and temperature in $L^2$-norm are proved by using finite\nelement approximations in space and finite differences in time. Finally, the\nnumerical results are showed to support the theoretical analysis.", "published": "2025-04-06 06:20:00", "link": "http://arxiv.org/abs/2504.04381v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Splitting Method for Stochastic Navier-Stokes Equations", "abstract": "This paper investigates the two-dimensional stochastic steady-state\nNavier-Stokes(NS) equations with additive random noise. We introduce an\ninnovative splitting method that decomposes the stochastic NS equations into a\ndeterministic NS component and a stochastic equation. We rigorously analyze the\nproposed splitting method from the perspectives of equivalence, stability,\nexistence and uniqueness of the solution. We also propose a modified splitting\nscheme, which simplified the stochastic equation by omitting its nonlinear\nterms. A detailed analysis of the solution properties for this modified\napproach is provided. Additionally, we discuss the statistical errors with both\nthe original splitting format and the modified scheme. Our theoretical and\nnumerical studies demonstrate that the equivalent splitting scheme exhibits\nsignificantly enhanced stability compared to the original stochastic NS\nequations, enabling more effective handling of nonlinear characteristics.\nSeveral numerical experiments were performed to compare the statistical errors\nof the splitting method and the modified splitting method. Notably, the\ndeterministic NS equation in the splitting method does not require repeated\nsolving, and the stochastic equation in the modified scheme is free of\nnonlinear terms. These features make the modified splitting method particularly\nadvantageous for large-scale computations, as it significantly improves\ncomputational efficiency without compromising accuracy.", "published": "2025-04-06 05:15:40", "link": "http://arxiv.org/abs/2504.04360v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Unconditionally optimal error Estimate of a linearized Second-order Fully Discrete Finite Element Method for the bioconvection flows with concentration dependent viscosity", "abstract": "In this paper, the coupled and decoupled BDF2 finite element discrete schemes\nare obtained for the time-dependent bioconvection flows problem with\nconcentration dependent viscosity, which consisting of the Navier-Stokes\nequation coupled with a linear convection-diffusion equation modeling the\nconcentration of microorganisms in a culture fluid. The unconditionally optimal\nerror estimate for the velocity and concentration in $L^2$-norm and $H^1$-norm\nare proved by using finite element approximations in space and finite\ndifferences in time. Finally, the numerical results for different viscosity are\nshowed to support the theoretical analysis.", "published": "2025-04-06 04:57:36", "link": "http://arxiv.org/abs/2504.04357v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Local Fourier Extension Method for Function Approximation", "abstract": "This paper presents a novel localized Fourier extension method for\napproximating non-periodic functions through domain segmentation. By\nsubdividing the computational domain into subregions and employing uniform\ndiscretization scales, the method achieves spectral accuracy with\n$\\mathcal{O}(M)$ computational complexity. Theoretical error bounds and\nparameter dependency analyses validate the robustness of the proposed method.\nThe relationship among the key parameters involved is analytically established,\naccompanied by an optimized parameter selection strategy. Numerical experiments\nfurther verify the effectiveness of the proposed method.", "published": "2025-04-06 03:38:14", "link": "http://arxiv.org/abs/2504.04341v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Estimating Coverage in Streams via a Modified CVM Method", "abstract": "When individuals in a population can be classified in classes or categories,\nthe coverage of a sample, $C$, is defined as the probability that a randomly\nselected individual from the population belongs to a class represented in the\nsample. Estimating coverage is challenging because $C$ is not a fixed\npopulation parameter, but a property of the sample, and the task becomes more\ncomplex when the number of classes is unknown. Furthermore, this problem has\nnot been addressed in scenarios where data arrive as a stream, under the\nconstraint that only $n$ elements can be stored at a time. In this paper, we\npropose a simple and efficient method to estimate $C$ in streaming settings,\nbased on a straightforward modification of the CVM algorithm, which is commonly\nused to estimate the number of distinct elements in a data stream.", "published": "2025-04-06 17:57:00", "link": "http://arxiv.org/abs/2504.04567v1", "categories": ["stat.CO", "stat.ML", "68W20"], "primary_category": "stat.CO"}
{"title": "Diff-SSL-G-Comp: Towards a Large-Scale and Diverse Dataset for Virtual Analog Modeling", "abstract": "Virtual Analog (VA) modeling aims to simulate the behavior of hardware\ncircuits via algorithms to replicate their tone digitally. Dynamic Range\nCompressor (DRC) is an audio processing module that controls the dynamics of a\ntrack by reducing and amplifying the volumes of loud and quiet sounds, which is\nessential in music production. In recent years, neural-network-based VA\nmodeling has shown great potential in producing high-fidelity models. However,\ndue to the lack of data quantity and diversity, their generalization ability in\ndifferent parameter settings and input sounds is still limited. To tackle this\nproblem, we present Diff-SSL-G-Comp, the first large-scale and diverse dataset\nfor modeling the SSL 500 G-Bus Compressor. Specifically, we manually collected\n175 unmastered songs from the Cambridge Multitrack Library. We recorded the\ncompressed audio in 220 parameter combinations, resulting in an extensive\n2528-hour dataset with diverse genres, instruments, tempos, and keys. Moreover,\nto facilitate the use of our proposed dataset, we conducted benchmark\nexperiments in various open-sourced black-box and grey-box models, as well as\nwhite-box plugins. We also conducted ablation studies in different data subsets\nto illustrate the effectiveness of improved data diversity and quantity. The\ndataset and demos are on our project page:\nhttp://www.yichenggu.com/DiffSSLGComp/.", "published": "2025-04-06 19:19:53", "link": "http://arxiv.org/abs/2504.04589v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Trainable Adaptive Score Normalization for Automatic Speaker Verification", "abstract": "Adaptive S-norm (AS-norm) calibrates automatic speaker verification (ASV)\nscores by normalizing them utilize the scores of impostors which are similar to\nthe input speaker. However, AS-norm does not involve any learning process,\nlimiting its ability to provide appropriate regularization strength for various\nevaluation utterances. To address this limitation, we propose a trainable\nAS-norm (TAS-norm) that leverages learnable impostor embeddings (LIEs), which\nare used to compose the cohort. These LIEs are initialized to represent each\nspeaker in a training dataset consisting of impostor speakers. Subsequently,\nLIEs are fine-tuned by simulating an ASV evaluation. We utilize a margin\npenalty during top-scoring IEs selection in fine-tuning to prevent non-impostor\nspeakers from being selected. In our experiments with ECAPA-TDNN, the proposed\nTAS-norm observed 4.11% and 10.62% relative improvement in equal error rate and\nminimum detection cost function, respectively, on VoxCeleb1-O trial compared\nwith standard AS-norm without using proposed LIEs. We further validated the\neffectiveness of the TAS-norm on additional ASV datasets comprising Persian and\nChinese, demonstrating its robustness across different languages.", "published": "2025-04-06 15:03:43", "link": "http://arxiv.org/abs/2504.04512v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "WaveNet-Volterra Neural Networks for Active Noise Control: A Fully Causal Approach", "abstract": "Active Noise Control (ANC) systems are challenged by nonlinear distortions,\nwhich degrade the performance of traditional adaptive filters. While deep\nlearning-based ANC algorithms have emerged to address nonlinearity, existing\napproaches often overlook critical limitations: (1) end-to-end Deep Neural\nNetwork (DNN) models frequently violate causality constraints inherent to\nreal-time ANC applications; (2) many studies compare DNN-based methods against\nsimplified or low-order adaptive filters rather than fully optimized high-order\ncounterparts. In this letter, we propose a causality-preserving time-domain ANC\nframework that synergizes WaveNet with Volterra Neural Networks (VNNs),\nexplicitly addressing system nonlinearity while ensuring strict causal\noperation. Unlike prior DNN-based approaches, our method is benchmarked against\nboth state-of-the-art deep learning architectures and rigorously optimized\nhigh-order adaptive filters, including Wiener solutions. Simulations\ndemonstrate that the proposed framework achieves superior performance over\nexisting DNN methods and traditional algorithms, revealing that prior claims of\nDNN superiority stem from incomplete comparisons with suboptimal traditional\nbaselines. Source code is available at\nhttps://github.com/Lu-Baihh/WaveNet-VNNs-for-ANC.git.", "published": "2025-04-06 11:42:01", "link": "http://arxiv.org/abs/2504.04450v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Turbocharging Fluid Antenna Multiple Access", "abstract": "We revisit the massive connectivity challenge by considering the case where\nno CSI is available at the BS and no precoding is used. In this situation,\ninter-user interference (IUI) mitigation can only be performed at the user\nterminal (UT) side. Leveraging the position flexibility of fluid antenna system\n(FAS), we adopt a fluid antenna multiple access (FAMA) approach that exploits\nthe interference signal fluctuation in the spatial domain. Specifically, we\nassume that we have N spatially correlated received signals per symbol duration\nfrom FAS. Our main approach uses a simple heuristic port shortlisting method\nthat identifies promising ports to obtain favourable received signals that can\nbe combined via maximum ratio combining (MRC) to form the received output\nsignal for final detection. On top of this, a pre-trained deep joint source\nchannel coding (JSCC) scheme is employed, which together with a diffusion-based\ndenoising model (MixDDPM) at the UT side, can improve the IUI immunity. We\nrefer to the proposed scheme as turbo FAMA. Simulation results show that with a\nphysical FAS size of 20 wavelengths at each UT transmitting quaternary phase\nshift keying (QPSK) symbols, fast FAMA can support 50 users while turbo FAMA\ncan handle up to 200 users if the required symbol error rate (SER) is 10 2. If\na higher error tolerance is acceptable, say SER at 01, turbo FAMA can even\nserve up to 1000 users but fast FAMA is only able to handle 160 users, all\nremarkably achieved without CSI at the BS.", "published": "2025-04-06 20:32:55", "link": "http://arxiv.org/abs/2504.04604v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Model-Based Deep Learning Tuning of Reconfigurable Intelligent Surface for OFDM Radar Interference Mitigation", "abstract": "This paper presents a deep learning-based framework for enhancing radar\nsystems in the presence of interference, leveraging Reconfigurable Intelligent\nSurfaces (RIS). The proposed technique uses a modified MUSIC algorithm to\nestimate the angles of the target and interference. The core of the method is a\ndeep learning model that optimizes the RIS configuration to reduce the impact\nof interference while maintaining accurate angle estimates. The model consists\nof a multi-layer perceptron (MLP) that takes estimated angles as inputs and\noutputs the configuration of the RIS. A specially designed loss function\nensures that the interference is properly suppressed and the target remains\ndetectable. To further enhance performance, a convolution technique is\nintroduced to create a notch at the interference angle, ensuring better\nseparation between the target and interference. Additionally, the method is\nextended to work over multiple subcarriers, improving robustness and\nperformance in practical scenarios. Simulation results show that the technique\nenhances the signal-to-interference-plus-noise ratio (SINR) and provides\naccurate localization estimates, demonstrating its potential for radar systems\nin complex environments.", "published": "2025-04-06 18:41:17", "link": "http://arxiv.org/abs/2504.04580v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Post-Quantum Wireless-based Key Encapsulation Mechanism via CRYSTALS-Kyber for Resource-Constrained Devices", "abstract": "We consider the problem of adapting a Post-Quantum cryptosystem to be used in\nresource-constrained devices, such as those typically used in Device-to-Device\nand Internet of Things systems. In particular, we propose leveraging the\ncharacteristics of wireless communications channels to minimize the complexity\nof implementation of a Post-Quantum public key encryption scheme, without\ndiminishing its security. To that end, we focus on the adaptation of a\nwell-known cryptosystem, namely CRYSTALS-Kyber, so as to enable its direct\nintegration into the lowest layer of the communication stack, the physical\nlayer, defining two new transport schemes for CRYSTALS-Kyber to be used in\nDevice-to-Device communications, both of which are modeled under a wireless\nchannel subject to Additive White Gaussian Noise, using a 4 Quadrature\nAmplitude Modulation constellation and a BCH-code to communicate\nCRYSTALSKyber's polynomial coefficients. Simulation results demonstrate the\nviability of the adapted Kyber algorithm due to its low key error probability,\nwhile maintaining the security reductions of the original Kyber by considering\nthe error distribution imposed by the channel on the cipher.", "published": "2025-04-06 14:57:00", "link": "http://arxiv.org/abs/2504.04511v1", "categories": ["eess.SP", "cs.CR"], "primary_category": "eess.SP"}
{"title": "ANN-Driven Adaptive Power Allocation for OWC", "abstract": "Vertical-cavity surface-emitting lasers (VCSELs) have gained popularity in\nOptical Wireless Communication (OWC) due to their high bandwidth and\ndirectional beam compared to Light-emitting diodes (LEDs). In this work, we\nexplore the deployment of VCSELs as Access Points (APs) in an indoor\nenvironment with time-varying user distributions and traffic demands. To\nenhance performance, a merged access point (MAP) topology is introduced to\nextend the serving area of each cell using Zero Forcing (ZF) for interference\nmanagement. A power allocation optimisation problem is formulated aimed at\nmaximising the sum rate of the dynamic network. Deterministic approaches can\nsolve the formulated problem but are impractical for real-time scenarios. In\nthis work, we propose an Artificial Neural Network (ANN) for adaptive power\nallocation with reduced computational complexity. Our results show that the\ndesigned ANN learns and effectively provides instantaneous solutions in dynamic\nscenarios, resulting in improved performance in terms of sum rate compared to a\nbaseline uniform power allocation scheme.", "published": "2025-04-06 08:34:18", "link": "http://arxiv.org/abs/2504.04410v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Opportunistic Beamforming and Dynamic Scheduling for Multi-User MIMO-ISAC Systems", "abstract": "This research presents a novel framework integrating Flexible-Duplex (FlexD)\nand Integrated Sensing and Communications (ISAC) technologies to address the\nchallenges of spectrum efficiency and resource optimization in next-generation\nwireless networks. We develop a unified system model for a dual-functional\nradar-communication base station with multiple-input multiple-output\ncapabilities, enabling dynamic uplink and downlink channel allocation. The\nframework maximizes network throughput while maintaining radar sensing\nperformance, subject to signal-to-clutter-plus-noise ratio (SCNR) requirements\nand power constraints. Given the non-convex and combinatorial nature of the\nresulting optimization problem, we propose an iterative algorithm that\nconverges to a locally optimal solution. Extensive simulations demonstrate the\nsuperiority of the proposed FlexD-ISAC framework compared to conventional\nhalf-duplex networks. Additionally, sensitivity analyses reveal the impact of\nSCNR requirements and power constraints on system performance, providing\nvaluable insights for practical implementation. This work establishes a\nfoundation for future research in dynamic, resource-efficient wireless systems\nthat simultaneously support sensing and communication capabilities.", "published": "2025-04-06 05:37:20", "link": "http://arxiv.org/abs/2504.04369v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "DSSR-Net for Super-Resolution Radar Range Profiles", "abstract": "High-resolution radar range profile (RRP) is crucial for accurate target\nrecognition and scene perception. To get a high-resolution RRP, many methods\nhave been developed, such as multiple signal classification (MUSIC), orthogonal\nmatching pursuit (OMP), and a few deep learning-based approaches. Although they\nbreak through the Rayleigh resolution limit determined by radar signal\nbandwidth, these methods either get limited super-resolution capability or work\nwell just in high signal to noise ratio (SNR) scenarios. To overcome these\nlimitations, in this paper, an interpretable neural network for\nsuper-resolution RRP (DSSR-Net) is proposed by integrating the advantages of\nboth model-guided and data-driven models. Specifically, DSSR-Net is designed\nbased on a sparse representation model with dimension scaling, and then trained\non a training dataset. Through dimension scaling, DSSR-Net lifts the radar\nsignal into high-dimensional space to extract subtle features of closely spaced\nobjects and suppress the noise of the high-dimensional features. It improves\nthe super-resolving power of closely spaced objects and lowers the SNR\nrequirement of radar signals compared to existing methods. The superiority of\nthe proposed algorithm for super-resolution RRP reconstruction is verified via\nexperiments with both synthetic and measured data.", "published": "2025-04-06 05:10:06", "link": "http://arxiv.org/abs/2504.04358v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "IMPersona: Evaluating Individual Level LM Impersonation", "abstract": "As language models achieve increasingly human-like capabilities in\nconversational text generation, a critical question emerges: to what extent can\nthese systems simulate the characteristics of specific individuals? To evaluate\nthis, we introduce IMPersona, a framework for evaluating LMs at impersonating\nspecific individuals' writing style and personal knowledge. Using supervised\nfine-tuning and a hierarchical memory-inspired retrieval system, we demonstrate\nthat even modestly sized open-source models, such as Llama-3.1-8B-Instruct, can\nachieve impersonation abilities at concerning levels. In blind conversation\nexperiments, participants (mis)identified our fine-tuned models with memory\nintegration as human in 44.44% of interactions, compared to just 25.00% for the\nbest prompting-based approach. We analyze these results to propose detection\nmethods and defense strategies against such impersonation attempts. Our\nfindings raise important questions about both the potential applications and\nrisks of personalized language models, particularly regarding privacy,\nsecurity, and the ethical deployment of such technologies in real-world\ncontexts.", "published": "2025-04-06 02:57:58", "link": "http://arxiv.org/abs/2504.04332v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Saliency-driven Dynamic Token Pruning for Large Language Models", "abstract": "Despite the recent success of large language models (LLMs), LLMs are\nparticularly challenging in long-sequence inference scenarios due to the\nquadratic computational complexity of the attention mechanism. Inspired by the\ninterpretability theory of feature attribution in neural network models, we\nobserve that not all tokens have the same contribution. Based on this\nobservation, we propose a novel token pruning framework, namely Saliency-driven\nDynamic Token Pruning (SDTP), to gradually and dynamically prune redundant\ntokens based on the input context. Specifically, a lightweight saliency-driven\nprediction module is designed to estimate the importance score of each token\nwith its hidden state, which is added to different layers of the LLM to\nhierarchically prune redundant tokens. Furthermore, a ranking-based\noptimization strategy is proposed to minimize the ranking divergence of the\nsaliency score and the predicted importance score. Extensive experiments have\nshown that our framework is generalizable to various models and datasets. By\nhierarchically pruning 65\\% of the input tokens, our method greatly reduces\n33\\% $\\sim$ 47\\% FLOPs and achieves speedup up to 1.75$\\times$ during\ninference, while maintaining comparable performance. We further demonstrate\nthat SDTP can be combined with KV cache compression method for further\ncompression.", "published": "2025-04-06 15:15:07", "link": "http://arxiv.org/abs/2504.04514v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constructing the Truth: Text Mining and Linguistic Networks in Public\n  Hearings of Case 03 of the Special Jurisdiction for Peace (JEP)", "abstract": "Case 03 of the Special Jurisdiction for Peace (JEP), focused on the so-called\nfalse positives in Colombia, represents one of the most harrowing episodes of\nthe Colombian armed conflict. This article proposes an innovative methodology\nbased on natural language analysis and semantic co-occurrence models to\nexplore, systematize, and visualize narrative patterns present in the public\nhearings of victims and appearing parties. By constructing skipgram networks\nand analyzing their modularity, the study identifies thematic clusters that\nreveal regional and procedural status differences, providing empirical evidence\non dynamics of victimization, responsibility, and acknowledgment in this case.\nThis computational approach contributes to the collective construction of both\njudicial and extrajudicial truth, offering replicable tools for other\ntransitional justice cases. The work is grounded in the pillars of truth,\njustice, reparation, and non-repetition, proposing a critical and in-depth\nreading of contested memories.", "published": "2025-04-06 02:04:27", "link": "http://arxiv.org/abs/2504.04325v2", "categories": ["cs.CL", "stat.AP", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Thanos: A Block-wise Pruning Algorithm for Efficient Large Language\n  Model Compression", "abstract": "This paper presents Thanos, a novel weight-pruning algorithm designed to\nreduce the memory footprint and enhance the computational efficiency of large\nlanguage models (LLMs) by removing redundant weights while maintaining\naccuracy. Thanos introduces a block-wise pruning strategy with adaptive masks\nthat dynamically adjust to weight importance, enabling flexible sparsity\npatterns and structured formats, such as $n:m$ sparsity, optimized for hardware\nacceleration. Experimental evaluations demonstrate that Thanos achieves\nstate-of-the-art performance in structured pruning and outperforms existing\nmethods in unstructured pruning. By providing an efficient and adaptable\napproach to model compression, Thanos offers a practical solution for deploying\nlarge models in resource-constrained environments.", "published": "2025-04-06 11:38:44", "link": "http://arxiv.org/abs/2504.05346v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PF", "68T07, 68Q32"], "primary_category": "cs.LG"}
{"title": "Constructing the Truth: Text Mining and Linguistic Networks in Public Hearings of Case 03 of the Special Jurisdiction for Peace (JEP)", "abstract": "Case 03 of the Special Jurisdiction for Peace (JEP), focused on the so-called\nfalse positives in Colombia, represents one of the most harrowing episodes of\nthe Colombian armed conflict. This article proposes an innovative methodology\nbased on natural language analysis and semantic co-occurrence models to\nexplore, systematize, and visualize narrative patterns present in the public\nhearings of victims and appearing parties. By constructing skipgram networks\nand analyzing their modularity, the study identifies thematic clusters that\nreveal regional and procedural status differences, providing empirical evidence\non dynamics of victimization, responsibility, and acknowledgment in this case.\nThis computational approach contributes to the collective construction of both\njudicial and extrajudicial truth, offering replicable tools for other\ntransitional justice cases. The work is grounded in the pillars of truth,\njustice, reparation, and non-repetition, proposing a critical and in-depth\nreading of contested memories.", "published": "2025-04-06 02:04:27", "link": "http://arxiv.org/abs/2504.04325v2", "categories": ["cs.CL", "stat.AP", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Your Image Generator Is Your New Private Dataset", "abstract": "Generative diffusion models have emerged as powerful tools to synthetically\nproduce training data, offering potential solutions to data scarcity and\nreducing labelling costs for downstream supervised deep learning applications.\nHowever, effectively leveraging text-conditioned image generation for building\nclassifier training sets requires addressing key issues: constructing\ninformative textual prompts, adapting generative models to specific domains,\nand ensuring robust performance. This paper proposes the Text-Conditioned\nKnowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines\ndynamic image captioning, parameter-efficient diffusion model fine-tuning, and\nGenerative Knowledge Distillation techniques to create synthetic datasets\ntailored for image classification. The pipeline is rigorously evaluated on ten\ndiverse image classification benchmarks. The results demonstrate that models\ntrained solely on TCKR-generated data achieve classification accuracies on par\nwith (and in several cases exceeding) models trained on real images.\nFurthermore, the evaluation reveals that these synthetic-data-trained models\nexhibit substantially enhanced privacy characteristics: their vulnerability to\nMembership Inference Attacks is significantly reduced, with the membership\ninference AUC lowered by 5.49 points on average compared to using real training\ndata, demonstrating a substantial improvement in the performance-privacy\ntrade-off. These findings indicate that high-fidelity synthetic data can\neffectively replace real data for training classifiers, yielding strong\nperformance whilst simultaneously providing improved privacy protection as a\nvaluable emergent property. The code and trained models are available in the\naccompanying open-source repository.", "published": "2025-04-06 18:46:08", "link": "http://arxiv.org/abs/2504.04582v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hyperflows: Pruning Reveals the Importance of Weights", "abstract": "Network pruning is used to reduce inference latency and power consumption in\nlarge neural networks. However, most existing methods struggle to accurately\nassess the importance of individual weights due to their inherent\ninterrelatedness, leading to poor performance, especially at extreme sparsity\nlevels. We introduce Hyperflows, a dynamic pruning approach that estimates each\nweight's importance by observing the network's gradient response to the\nweight's removal. A global pressure term continuously drives all weights toward\npruning, with those critical for accuracy being automatically regrown based on\ntheir flow, the aggregated gradient signal when they are absent. We explore the\nrelationship between final sparsity and pressure, deriving power-law equations\nsimilar to those found in neural scaling laws. Empirically, we demonstrate\nstate-of-the-art results with ResNet-50 and VGG-19 on CIFAR-10 and CIFAR-100.", "published": "2025-04-06 16:09:18", "link": "http://arxiv.org/abs/2504.05349v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Can SGD Select Good Fishermen? Local Convergence under Self-Selection Biases and Beyond", "abstract": "We revisit the problem of estimating $k$ linear regressors with\nself-selection bias in $d$ dimensions with the maximum selection criterion, as\nintroduced by Cherapanamjeri, Daskalakis, Ilyas, and Zampetakis [CDIZ23,\nSTOC'23]. Our main result is a $\\operatorname{poly}(d,k,1/\\varepsilon) +\n{k}^{O(k)}$ time algorithm for this problem, which yields an improvement in the\nrunning time of the algorithms of [CDIZ23] and [GM24, arXiv]. We achieve this\nby providing the first local convergence algorithm for self-selection, thus\nresolving the main open question of [CDIZ23].\n  To obtain this algorithm, we reduce self-selection to a seemingly unrelated\nstatistical problem called coarsening. Coarsening occurs when one does not\nobserve the exact value of the sample but only some set (a subset of the sample\nspace) that contains the exact value. Inference from coarse samples arises in\nvarious real-world applications due to rounding by humans and algorithms,\nlimited precision of instruments, and lag in multi-agent systems.\n  Our reduction to coarsening is intuitive and relies on the geometry of the\nself-selection problem, which enables us to bypass the limitations of previous\nanalytic approaches. To demonstrate its applicability, we provide a local\nconvergence algorithm for linear regression under another self-selection\ncriterion, which is related to second-price auction data. Further, we give the\nfirst polynomial time local convergence algorithm for coarse Gaussian mean\nestimation given samples generated from a convex partition. Previously, only a\nsample-efficient algorithm was known due to Fotakis, Kalavasis, Kontonis, and\nTzamos [FKKT21, COLT'21].", "published": "2025-04-06 20:59:12", "link": "http://arxiv.org/abs/2504.07133v1", "categories": ["stat.ML", "cs.DS", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Embedding Reliability Verification Constraints into Generation Expansion Planning", "abstract": "Generation planning approaches face challenges in managing the incompatible\nmathematical structures between stochastic production simulations for\nreliability assessment and optimization models for generation planning, which\nhinders the integration of reliability constraints. This study proposes an\napproach to embedding reliability verification constraints into generation\nexpansion planning by leveraging a weighted oblique decision tree (WODT)\ntechnique. For each planning year, a generation mix dataset, labeled with\nreliability assessment simulations, is generated. An WODT model is trained\nusing this dataset. Reliability-feasible regions are extracted via depth-first\nsearch technique and formulated as disjunctive constraints. These constraints\nare then transformed into mixed-integer linear form using a convex hull\nmodeling technique and embedded into a unit commitment-integrated generation\nexpansion planning model. The proposed approach is validated through a\nlong-term generation planning case study for the Electric Reliability Council\nof Texas (ERCOT) region, demonstrating its effectiveness in achieving reliable\nand optimal planning solutions.", "published": "2025-04-06 04:58:45", "link": "http://arxiv.org/abs/2504.07131v1", "categories": ["cs.AI", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Universal Item Tokenization for Transferable Generative Recommendation", "abstract": "Recently, generative recommendation has emerged as a promising paradigm,\nattracting significant research attention. The basic framework involves an item\ntokenizer, which represents each item as a sequence of codes serving as its\nidentifier, and a generative recommender that predicts the next item by\nautoregressively generating the target item identifier. However, in existing\nmethods, both the tokenizer and the recommender are typically domain-specific,\nlimiting their ability for effective transfer or adaptation to new domains. To\nthis end, we propose UTGRec, a Universal item Tokenization approach for\ntransferable Generative Recommendation. Specifically, we design a universal\nitem tokenizer for encoding rich item semantics by adapting a multimodal large\nlanguage model (MLLM). By devising tree-structured codebooks, we discretize\ncontent representations into corresponding codes for item tokenization. To\neffectively learn the universal item tokenizer on multiple domains, we\nintroduce two key techniques in our approach. For raw content reconstruction,\nwe employ dual lightweight decoders to reconstruct item text and images from\ndiscrete representations to capture general knowledge embedded in the content.\nFor collaborative knowledge integration, we assume that co-occurring items are\nsimilar and integrate collaborative signals through co-occurrence alignment and\nreconstruction. Finally, we present a joint learning framework to pre-train and\nadapt the transferable generative recommender across multiple domains.\nExtensive experiments on four public datasets demonstrate the superiority of\nUTGRec compared to both traditional and generative recommendation baselines.", "published": "2025-04-06 08:07:49", "link": "http://arxiv.org/abs/2504.04405v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Pre-training Generative Recommender with Multi-Identifier Item Tokenization", "abstract": "Generative recommendation autoregressively generates item identifiers to\nrecommend potential items. Existing methods typically adopt a one-to-one\nmapping strategy, where each item is represented by a single identifier.\nHowever, this scheme poses issues, such as suboptimal semantic modeling for\nlow-frequency items and limited diversity in token sequence data. To overcome\nthese limitations, we propose MTGRec, which leverages Multi-identifier item\nTokenization to augment token sequence data for Generative Recommender\npre-training. Our approach involves two key innovations: multi-identifier item\ntokenization and curriculum recommender pre-training. For multi-identifier item\ntokenization, we leverage the RQ-VAE as the tokenizer backbone and treat model\ncheckpoints from adjacent training epochs as semantically relevant tokenizers.\nThis allows each item to be associated with multiple identifiers, enabling a\nsingle user interaction sequence to be converted into several token sequences\nas different data groups. For curriculum recommender pre-training, we introduce\na curriculum learning scheme guided by data influence estimation, dynamically\nadjusting the sampling probability of each data group during recommender\npre-training. After pre-training, we fine-tune the model using a single\ntokenizer to ensure accurate item identification for recommendation. Extensive\nexperiments on three public benchmark datasets demonstrate that MTGRec\nsignificantly outperforms both traditional and generative recommendation\nbaselines in terms of effectiveness and scalability.", "published": "2025-04-06 08:03:03", "link": "http://arxiv.org/abs/2504.04400v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Splitting Method for Stochastic Navier-Stokes Equations", "abstract": "This paper investigates the two-dimensional stochastic steady-state\nNavier-Stokes(NS) equations with additive random noise. We introduce an\ninnovative splitting method that decomposes the stochastic NS equations into a\ndeterministic NS component and a stochastic equation. We rigorously analyze the\nproposed splitting method from the perspectives of equivalence, stability,\nexistence and uniqueness of the solution. We also propose a modified splitting\nscheme, which simplified the stochastic equation by omitting its nonlinear\nterms. A detailed analysis of the solution properties for this modified\napproach is provided. Additionally, we discuss the statistical errors with both\nthe original splitting format and the modified scheme. Our theoretical and\nnumerical studies demonstrate that the equivalent splitting scheme exhibits\nsignificantly enhanced stability compared to the original stochastic NS\nequations, enabling more effective handling of nonlinear characteristics.\nSeveral numerical experiments were performed to compare the statistical errors\nof the splitting method and the modified splitting method. Notably, the\ndeterministic NS equation in the splitting method does not require repeated\nsolving, and the stochastic equation in the modified scheme is free of\nnonlinear terms. These features make the modified splitting method particularly\nadvantageous for large-scale computations, as it significantly improves\ncomputational efficiency without compromising accuracy.", "published": "2025-04-06 05:15:40", "link": "http://arxiv.org/abs/2504.04360v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "WaveNet-Volterra Neural Networks for Active Noise Control: A Fully Causal Approach", "abstract": "Active Noise Control (ANC) systems are challenged by nonlinear distortions,\nwhich degrade the performance of traditional adaptive filters. While deep\nlearning-based ANC algorithms have emerged to address nonlinearity, existing\napproaches often overlook critical limitations: (1) end-to-end Deep Neural\nNetwork (DNN) models frequently violate causality constraints inherent to\nreal-time ANC applications; (2) many studies compare DNN-based methods against\nsimplified or low-order adaptive filters rather than fully optimized high-order\ncounterparts. In this letter, we propose a causality-preserving time-domain ANC\nframework that synergizes WaveNet with Volterra Neural Networks (VNNs),\nexplicitly addressing system nonlinearity while ensuring strict causal\noperation. Unlike prior DNN-based approaches, our method is benchmarked against\nboth state-of-the-art deep learning architectures and rigorously optimized\nhigh-order adaptive filters, including Wiener solutions. Simulations\ndemonstrate that the proposed framework achieves superior performance over\nexisting DNN methods and traditional algorithms, revealing that prior claims of\nDNN superiority stem from incomplete comparisons with suboptimal traditional\nbaselines. Source code is available at\nhttps://github.com/Lu-Baihh/WaveNet-VNNs-for-ANC.git.", "published": "2025-04-06 11:42:01", "link": "http://arxiv.org/abs/2504.04450v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Exploring Generative AI Techniques in Government: A Case Study", "abstract": "The swift progress of Generative Artificial intelligence (GenAI), notably\nLarge Language Models (LLMs), is reshaping the digital landscape. Recognizing\nthis transformative potential, the National Research Council of Canada (NRC)\nlaunched a pilot initiative to explore the integration of GenAI techniques into\nits daily operation for performance excellence, where 22 projects were launched\nin May 2024. Within these projects, this paper presents the development of the\nintelligent agent Pubbie as a case study, targeting the automation of\nperformance measurement, data management and insight reporting at the NRC.\nCutting-edge techniques are explored, including LLM orchestration and semantic\nembedding via RoBERTa, while strategic fine-tuning and few-shot learning\napproaches are incorporated to infuse domain knowledge at an affordable cost.\nThe user-friendly interface of Pubbie allows general government users to input\nqueries in natural language and easily upload or download files with a simple\nbutton click, greatly reducing manual efforts and accessibility barriers.", "published": "2025-04-06 06:52:38", "link": "http://arxiv.org/abs/2504.10497v1", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.IR"}
