{"title": "Dynamic Graph Representation with Contrastive Learning for Financial Market Prediction: Integrating Temporal Evolution and Static Relations", "abstract": "Temporal Graph Learning (TGL) is crucial for capturing the evolving nature of\nstock markets. Traditional methods often ignore the interplay between dynamic\ntemporal changes and static relational structures between stocks. To address\nthis issue, we propose the Dynamic Graph Representation with Contrastive\nLearning (DGRCL) framework, which integrates dynamic and static graph relations\nto improve the accuracy of stock trend prediction. Our framework introduces two\nkey components: the Embedding Enhancement (EE) module and the Contrastive\nConstrained Training (CCT) module. The EE module focuses on dynamically\ncapturing the temporal evolution of stock data, while the CCT module enforces\nstatic constraints based on stock relations, refined within contrastive\nlearning. This dual-relation approach allows for a more comprehensive\nunderstanding of stock market dynamics. Our experiments on two major U.S. stock\nmarket datasets, NASDAQ and NYSE, demonstrate that DGRCL significantly\noutperforms state-of-the-art TGL baselines. Ablation studies indicate the\nimportance of both modules. Overall, DGRCL not only enhances prediction ability\nbut also provides a robust framework for integrating temporal and relational\ndata in dynamic graphs. Code and data are available for public access.", "published": "2024-12-05 10:15:56", "link": "http://arxiv.org/abs/2412.04034v1", "categories": ["cs.LG", "cs.NE", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Inverting the Markovian projection for pure jump processes", "abstract": "Markovian projections arise in problems where we aim to mimic the\none-dimensional marginal laws of an It\\^o semimartingale by using another It\\^o\nprocess with simpler dynamics. In applications, Markovian projections are\nuseful in calibrating jump-diffusion models with both local and stochastic\nfeatures, leading to the study of the inversion problems. In this paper, we\ninvert the Markovian projections for pure jump processes, which can be used to\nconstruct calibrated local stochastic intensity (LSI) models for credit risk\napplications. Such models are jump process analogues of the notoriously hard to\nconstruct local stochastic volatility (LSV) models used in equity modeling.", "published": "2024-12-05 20:10:17", "link": "http://arxiv.org/abs/2412.04589v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Correlation without Factors in Retail Cryptocurrency Markets", "abstract": "A simple model-free and distribution-free statistic, the functional\nrelationship between the number of \"effective\" degrees of freedom and portfolio\nsize, or N*(N), is used to discriminate between two alternative models for the\ncorrelation of daily cryptocurrency returns within a retail universe of defined\nby the list of tradable assets available to account holders at the Robinhood\nbrokerage. The average pairwise correlation between daily cryptocurrency\nreturns is found to be high (of order 60%) and the data collected supports\ndescription of the cross-section of returns by a simple isotropic correlation\nmodel distinct from a decomposition into a linear factor model with additive\nnoise with high confidence. This description appears to be relatively stable\nthrough time.", "published": "2024-12-05 15:44:51", "link": "http://arxiv.org/abs/2412.04263v1", "categories": ["q-fin.PM", "q-fin.RM", "q-fin.ST", "62"], "primary_category": "q-fin.PM"}
{"title": "Detecting Redundant Health Survey Questions Using Language-agnostic BERT\n  Sentence Embedding (LaBSE)", "abstract": "The goal of this work was to compute the semantic similarity among publicly\navailable health survey questions in order to facilitate the standardization of\nsurvey-based Person-Generated Health Data (PGHD). We compiled various health\nsurvey questions authored in both English and Korean from the NIH CDE\nRepository, PROMIS, Korean public health agencies, and academic publications.\nQuestions were drawn from various health lifelog domains. A randomized question\npairing scheme was used to generate a Semantic Text Similarity (STS) dataset\nconsisting of 1758 question pairs. Similarity scores between each question pair\nwere assigned by two human experts. The tagged dataset was then used to build\nthree classifiers featuring: Bag-of-Words, SBERT with BERT-based embeddings,\nand SBRET with LaBSE embeddings. The algorithms were evaluated using\ntraditional contingency statistics. Among the three algorithms, SBERT-LaBSE\ndemonstrated the highest performance in assessing question similarity across\nboth languages, achieving an Area Under the Receiver Operating Characteristic\n(ROC) and Precision-Recall Curves of over 0.99. Additionally, it proved\neffective in identifying cross-lingual semantic similarities.The SBERT-LaBSE\nalgorithm excelled at aligning semantically equivalent sentences across both\nlanguages but encountered challenges in capturing subtle nuances and\nmaintaining computational efficiency. Future research should focus on testing\nwith larger multilingual datasets and on calibrating and normalizing scores\nacross the health lifelog domains to improve consistency. This study introduces\nthe SBERT-LaBSE algorithm for calculating semantic similarity across two\nlanguages, showing it outperforms BERT-based models and the Bag of Words\napproach, highlighting its potential to improve semantic interoperability of\nsurvey-based PGHD across language barriers.", "published": "2024-12-05 02:18:35", "link": "http://arxiv.org/abs/2412.03817v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Educational-Psychological Dialogue Robot Based on Multi-Agent\n  Collaboration", "abstract": "Intelligent dialogue systems are increasingly used in modern education and\npsychological counseling fields, but most existing systems are limited to a\nsingle domain, cannot deal with both educational and psychological issues, and\noften lack accuracy and professionalism when dealing with complex issues. To\naddress these problems, this paper proposes an intelligent dialog system that\ncombines educational and psychological counseling functions. The system\nconsists of multiple AI agent, including security detection agent, intent\nidentification agent, educational LLM agent, and psychological LLM agent, which\nwork in concert to ensure the provision of accurate educational knowledge Q\\&A\nand psychological support services. Specifically, the system recognizes\nuser-input intentions through an intention classification model and invokes a\nretrieval-enhanced educational grand model and a psychological grand model\nfine-tuned with psychological data in order to provide professional educational\nadvice and psychological support.", "published": "2024-12-05 03:27:02", "link": "http://arxiv.org/abs/2412.03847v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Marco-LLM: Bridging Languages via Massive Multilingual Training for\n  Cross-Lingual Enhancement", "abstract": "Large Language Models (LLMs) have achieved remarkable progress in recent\nyears; however, their excellent performance is still largely limited to major\nworld languages, primarily English. Many LLMs continue to face challenges with\nmultilingual tasks, especially when it comes to low-resource languages. To\naddress this issue, we introduced Marco-LLM: Massive multilingual training for\ncross-lingual enhancement LLM. We have collected a substantial amount of\nmultilingual data for several low-resource languages and conducted extensive\ncontinual pre-training using the Qwen2 models. This effort has resulted in a\nmultilingual LLM named Marco-LLM. Through comprehensive evaluations on various\nmultilingual benchmarks, including MMMLU, AGIEval, Belebele, Flores-200, XCOPA\nand many others, Marco-LLM has demonstrated substantial improvements over\nstate-of-the-art LLMs. Furthermore, Marco-LLM achieved substantial enhancements\nin any-to-any machine translation tasks, showing the effectiveness of our\nmultilingual LLM. Marco-LLM is a pioneering multilingual LLM designed to not\nonly perform exceptionally well in multilingual tasks, including low-resource\nlanguages, but also maintain strong performance in English and other major\nlanguages, closing the performance gap between high- and low-resource language\ncapabilities. By bridging languages, this effort demonstrates our dedication to\nensuring LLMs work accurately across various languages.", "published": "2024-12-05 09:26:58", "link": "http://arxiv.org/abs/2412.04003v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Influence of Label Aggregation on Minority Voices:\n  Implications for Dataset Bias and Model Training", "abstract": "Resolving disagreement in manual annotation typically consists of removing\nunreliable annotators and using a label aggregation strategy such as majority\nvote or expert opinion to resolve disagreement. These may have the side-effect\nof silencing or under-representing minority but equally valid opinions. In this\npaper, we study the impact of standard label aggregation strategies on minority\nopinion representation in sexism detection. We investigate the quality and\nvalue of minority annotations, and then examine their effect on the class\ndistributions in gold labels, as well as how this affects the behaviour of\nmodels trained on the resulting datasets. Finally, we discuss the potential\nbiases introduced by each method and how they can be amplified by the models.", "published": "2024-12-05 10:00:49", "link": "http://arxiv.org/abs/2412.04025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M$^{3}$D: A Multimodal, Multilingual and Multitask Dataset for Grounded\n  Document-level Information Extraction", "abstract": "Multimodal information extraction (IE) tasks have attracted increasing\nattention because many studies have shown that multimodal information benefits\ntext information extraction. However, existing multimodal IE datasets mainly\nfocus on sentence-level image-facilitated IE in English text, and pay little\nattention to video-based multimodal IE and fine-grained visual grounding.\nTherefore, in order to promote the development of multimodal IE, we constructed\na multimodal multilingual multitask dataset, named M$^{3}$D, which has the\nfollowing features: (1) It contains paired document-level text and video to\nenrich multimodal information; (2) It supports two widely-used languages,\nnamely English and Chinese; (3) It includes more multimodal IE tasks such as\nentity recognition, entity chain extraction, relation extraction and visual\ngrounding. In addition, our dataset introduces an unexplored theme, i.e.,\nbiography, enriching the domains of multimodal IE resources. To establish a\nbenchmark for our dataset, we propose an innovative hierarchical multimodal IE\nmodel. This model effectively leverages and integrates multimodal information\nthrough a Denoised Feature Fusion Module (DFFM). Furthermore, in non-ideal\nscenarios, modal information is often incomplete. Thus, we designed a Missing\nModality Construction Module (MMCM) to alleviate the issues caused by missing\nmodalities. Our model achieved an average performance of 53.80% and 53.77% on\nfour tasks in English and Chinese datasets, respectively, which set a\nreasonable standard for subsequent research. In addition, we conducted more\nanalytical experiments to verify the effectiveness of our proposed module. We\nbelieve that our work can promote the development of the field of multimodal\nIE.", "published": "2024-12-05 10:00:58", "link": "http://arxiv.org/abs/2412.04026v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hostility Detection in UK Politics: A Dataset on Online Abuse Targeting\n  MPs", "abstract": "Numerous politicians use social media platforms, particularly X, to engage\nwith their constituents. This interaction allows constituents to pose questions\nand offer feedback but also exposes politicians to a barrage of hostile\nresponses, especially given the anonymity afforded by social media. They are\ntypically targeted in relation to their governmental role, but the comments\nalso tend to attack their personal identity. This can discredit politicians and\nreduce public trust in the government. It can also incite anger and disrespect,\nleading to offline harm and violence. While numerous models exist for detecting\nhostility in general, they lack the specificity required for political\ncontexts. Furthermore, addressing hostility towards politicians demands\ntailored approaches due to the distinct language and issues inherent to each\ncountry (e.g., Brexit for the UK). To bridge this gap, we construct a dataset\nof 3,320 English tweets spanning a two-year period manually annotated for\nhostility towards UK MPs. Our dataset also captures the targeted identity\ncharacteristics (race, gender, religion, none) in hostile tweets. We perform\nlinguistic and topical analyses to delve into the unique content of the UK\npolitical data. Finally, we evaluate the performance of pre-trained language\nmodels and large language models on binary hostility detection and multi-class\ntargeted identity type classification tasks. Our study offers valuable data and\ninsights for future research on the prevalence and nature of politics-related\nhostility specific to the UK.", "published": "2024-12-05 10:37:38", "link": "http://arxiv.org/abs/2412.04046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GEITje 7B Ultra: A Conversational Model for Dutch", "abstract": "Language models have rapidly evolved, predominantly focusing on English while\noften neglecting extensive pretraining in other languages. This approach has\nrequired initiatives to adapt powerful, English-centric models to other\nlinguistic contexts through finetuning. For Dutch, such a recent endeavour is\n``GEITje'' a model originally derived from the English-based Mistral 7B.\nBuilding on this fundamental work, the current research extends the\ncapabilities of GEITje by supervised finetuning on newly created high-quality\nsynthetic conversational datasets, along with an additional preference\nalignment procedure on a synthetic feedback dataset. Both the developed models\nand the created datasets are openly available.", "published": "2024-12-05 11:56:48", "link": "http://arxiv.org/abs/2412.04092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice\n  Question Answering", "abstract": "Pre-trained Language Models (PLMs) have shown remarkable performances in\nrecent years, setting a new paradigm for NLP research and industry. The legal\ndomain has received some attention from the NLP community partly due to its\ntextual nature. Some tasks from this domain are represented by\nquestion-answering (QA) tasks. This work explores the legal domain\nMultiple-Choice QA (MCQA) for a low-resource language. The contribution of this\nwork is multi-fold. We first introduce JuRO, the first openly available\nRomanian legal MCQA dataset, comprising three different examinations and a\nnumber of 10,836 total questions. Along with this dataset, we introduce CROL,\nan organized corpus of laws that has a total of 93 distinct documents with\ntheir modifications from 763 time spans, that we leveraged in this work for\nInformation Retrieval (IR) techniques. Moreover, we are the first to propose\nLaw-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is\nderived from the aforementioned corpus. Lastly, we propose a novel approach for\nMCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive\nresults with generally accepted SOTA methods and even exceeds them in most\nsettings.", "published": "2024-12-05 12:37:27", "link": "http://arxiv.org/abs/2412.04119v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reducing Tool Hallucination via Reliability Alignment", "abstract": "Large Language Models (LLMs) have expanded their capabilities beyond language\ngeneration to interact with external tools, enabling automation and real-world\napplications. However, tool hallucinations, where models either select\ninappropriate tools or misuse them, pose significant challenges, leading to\nerroneous task execution, increased computational costs, and reduced system\nreliability. To systematically address this issue, we define and categorize\ntool hallucinations into two main types, tool selection hallucination and tool\nusage hallucination. To evaluate and mitigate these issues, we introduce\nRelyToolBench, which integrates specialized test cases and novel metrics to\nassess hallucination-aware task success and efficiency. Finally, we propose\nRelign, a reliability alignment framework that expands the tool-use action\nspace to include indecisive actions, allowing LLMs to defer tool use, seek\nclarification, or adjust tool selection dynamically. Through extensive\nexperiments, we demonstrate that Relign significantly reduces tool\nhallucinations, improves task reliability, and enhances the efficiency of LLM\ntool interactions.", "published": "2024-12-05 13:10:54", "link": "http://arxiv.org/abs/2412.04141v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AL-QASIDA: Analyzing LLM Quality and Accuracy Systematically in\n  Dialectal Arabic", "abstract": "Dialectal Arabic (DA) varieties are under-served by language technologies,\nparticularly large language models (LLMs). This trend threatens to exacerbate\nexisting social inequalities and limits LLM applications, yet the research\ncommunity lacks operationalized performance measurements in DA. We present a\nframework that comprehensively assesses LLMs' DA modeling capabilities across\nfour dimensions: fidelity, understanding, quality, and diglossia. We evaluate\nnine LLMs in eight DA varieties and provide practical recommendations. Our\nevaluation suggests that LLMs do not produce DA as well as they understand it,\nnot because their DA fluency is poor, but because they are reluctant to\ngenerate DA. Further analysis suggests that current post-training can\ncontribute to bias against DA, that few-shot examples can overcome this\ndeficiency, and that otherwise no measurable features of input text correlate\nwell with LLM DA performance.", "published": "2024-12-05 14:33:00", "link": "http://arxiv.org/abs/2412.04193v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Context-aware Framework for Translation-mediated Conversations", "abstract": "Effective communication is fundamental to any interaction, yet challenges\narise when participants do not share a common language. Automatic translation\nsystems offer a powerful solution to bridge language barriers in such\nscenarios, but they introduce errors that can lead to misunderstandings and\nconversation breakdown. A key issue is that current systems fail to incorporate\nthe rich contextual information necessary to resolve ambiguities and omitted\ndetails, resulting in literal, inappropriate, or misaligned translations. In\nthis work, we present a framework to improve large language model-based\ntranslation systems by incorporating contextual information in bilingual\nconversational settings. During training, we leverage context-augmented\nparallel data, which allows the model to generate translations sensitive to\nconversational history. During inference, we perform quality-aware decoding\nwith context-aware metrics to select the optimal translation from a pool of\ncandidates. We validate both components of our framework on two task-oriented\ndomains: customer chat and user-assistant interaction. Across both settings,\nour framework consistently results in better translations than state-of-the-art\nsystems like GPT-4o and TowerInstruct, as measured by multiple automatic\ntranslation quality metrics on several language pairs. We also show that the\nresulting model leverages context in an intended and interpretable way,\nimproving consistency between the conveyed message and the generated\ntranslations.", "published": "2024-12-05 14:41:05", "link": "http://arxiv.org/abs/2412.04205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing Hallucinations with RAG and NMISS in Italian Healthcare LLM\n  Chatbots", "abstract": "I combine detection and mitigation techniques to addresses hallucinations in\nLarge Language Models (LLMs). Mitigation is achieved in a question-answering\nRetrieval-Augmented Generation (RAG) framework while detection is obtained by\nintroducing the Negative Missing Information Scoring System (NMISS), which\naccounts for contextual relevance in responses. While RAG mitigates\nhallucinations by grounding answers in external data, NMISS refines the\nevaluation by identifying cases where traditional metrics incorrectly flag\ncontextually accurate responses as hallucinations. I use Italian health news\narticles as context to evaluate LLM performance. Results show that Gemma2 and\nGPT-4 outperform the other models, with GPT-4 producing answers closely aligned\nwith reference responses. Mid-tier models, such as Llama2, Llama3, and Mistral\nbenefit significantly from NMISS, highlighting their ability to provide richer\ncontextual information. This combined approach offers new insights into the\nreduction and more accurate assessment of hallucinations in LLMs, with\napplications in real-world healthcare tasks and other domains.", "published": "2024-12-05 15:11:12", "link": "http://arxiv.org/abs/2412.04235v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aya Expanse: Combining Research Breakthroughs for a New Multilingual\n  Frontier", "abstract": "We introduce the Aya Expanse model family, a new generation of 8B and 32B\nparameter multilingual language models, aiming to address the critical\nchallenge of developing highly performant multilingual models that match or\nsurpass the capabilities of monolingual models. By leveraging several years of\nresearch at Cohere For AI and Cohere, including advancements in data arbitrage,\nmultilingual preference training, and model merging, Aya Expanse sets a new\nstate-of-the-art in multilingual performance. Our evaluations on the\nArena-Hard-Auto dataset, translated into 23 languages, demonstrate that Aya\nExpanse 8B and 32B outperform leading open-weight models in their respective\nparameter classes, including Gemma 2, Qwen 2.5, and Llama 3.1, achieving up to\na 76.6% win-rate. Notably, Aya Expanse 32B outperforms Llama 3.1 70B, a model\nwith twice as many parameters, achieving a 54.0% win-rate. In this short\ntechnical report, we present extended evaluation results for the Aya Expanse\nmodel family and release their open-weights, together with a new multilingual\nevaluation dataset m-ArenaHard.", "published": "2024-12-05 15:41:06", "link": "http://arxiv.org/abs/2412.04261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Stable LM: Adapting Stable LM 2 1.6B to Arabic", "abstract": "Large Language Models (LLMs) have shown impressive results in multiple\ndomains of natural language processing (NLP) but are mainly focused on the\nEnglish language. Recently, more LLMs have incorporated a larger proportion of\nmultilingual text to represent low-resource languages. In Arabic NLP, several\nArabic-centric LLMs have shown remarkable results on multiple benchmarks in the\npast two years. However, most Arabic LLMs have more than 7 billion parameters,\nwhich increases their hardware requirements and inference latency, when\ncompared to smaller LLMs. This paper introduces Arabic Stable LM 1.6B in a base\nand chat version as a small but powerful Arabic-centric LLM. Our Arabic Stable\nLM 1.6B chat model achieves impressive results on several benchmarks beating\nmultiple models with up to 8x the parameters. In addition, we show the benefit\nof mixing in synthetic instruction tuning data by augmenting our fine-tuning\ndata with a large synthetic dialogue dataset.", "published": "2024-12-05 15:59:29", "link": "http://arxiv.org/abs/2412.04277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evolutionary Pre-Prompt Optimization for Mathematical Reasoning", "abstract": "Recent advancements have highlighted that large language models (LLMs), when\ngiven a small set of task-specific examples, demonstrate remarkable\nproficiency, a capability that extends to complex reasoning tasks. In\nparticular, the combination of few-shot learning with the chain-of-thought\n(CoT) approach has been pivotal in steering models towards more logically\nconsistent conclusions. This paper explores the optimization of example\nselection for designing effective CoT pre-prompts and shows that the choice of\nthe optimization algorithm, typically in favor of comparison-based methods such\nas evolutionary computation, significantly enhances efficacy and feasibility.\nSpecifically, thanks to a limited exploitative and overfitted optimization,\nEvolutionary Pre-Prompt Optimization (EPPO) brings an improvement over the\nnaive few-shot approach exceeding 10 absolute points in exact match scores on\nbenchmark datasets such as GSM8k and MathQA. These gains are consistent across\nvarious contexts and are further amplified when integrated with\nself-consistency (SC)", "published": "2024-12-05 16:12:06", "link": "http://arxiv.org/abs/2412.04291v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction", "abstract": "Graphical User Interfaces (GUIs) are critical to human-computer interaction,\nyet automating GUI tasks remains challenging due to the complexity and\nvariability of visual environments. Existing approaches often rely on textual\nrepresentations of GUIs, which introduce limitations in generalization,\nefficiency, and scalability. In this paper, we introduce Aguvis, a unified pure\nvision-based framework for autonomous GUI agents that operates across various\nplatforms. Our approach leverages image-based observations, and grounding\ninstructions in natural language to visual elements, and employs a consistent\naction space to ensure cross-platform generalization. To address the\nlimitations of previous work, we integrate explicit planning and reasoning\nwithin the model, enhancing its ability to autonomously navigate and interact\nwith complex digital environments. We construct a large-scale dataset of GUI\nagent trajectories, incorporating multimodal reasoning and grounding, and\nemploy a two-stage training pipeline that first focuses on general GUI\ngrounding, followed by planning and reasoning. Through comprehensive\nexperiments, we demonstrate that Aguvis surpasses previous state-of-the-art\nmethods in both offline and real-world online scenarios, achieving, to our\nknowledge, the first fully autonomous pure vision GUI agent capable of\nperforming tasks independently without collaboration with external\nclosed-source models. We open-sourced all datasets, models, and training\nrecipes to facilitate future research at https://aguvis-project.github.io/.", "published": "2024-12-05 18:58:26", "link": "http://arxiv.org/abs/2412.04454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Give me Some Hard Questions: Synthetic Data Generation for Clinical QA", "abstract": "Clinical Question Answering (QA) systems enable doctors to quickly access\npatient information from electronic health records (EHRs). However, training\nthese systems requires significant annotated data, which is limited due to the\nexpertise needed and the privacy concerns associated with clinical data. This\npaper explores generating Clinical QA data using large language models (LLMs)\nin a zero-shot setting. We find that naive prompting often results in easy\nquestions that do not reflect the complexity of clinical scenarios. To address\nthis, we propose two prompting strategies: 1) instructing the model to generate\nquestions that do not overlap with the input context, and 2) summarizing the\ninput record using a predefined schema to scaffold question generation.\nExperiments on two Clinical QA datasets demonstrate that our method generates\nmore challenging questions, significantly improving fine-tuning performance\nover baselines. We compare synthetic and gold data and find a gap between their\ntraining efficacy resulting from the quality of synthetically generated\nanswers.", "published": "2024-12-05 19:35:41", "link": "http://arxiv.org/abs/2412.04573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The broader spectrum of in-context learning", "abstract": "The ability of language models to learn a task from a few examples in context\nhas generated substantial interest. Here, we provide a perspective that\nsituates this type of supervised few-shot learning within a much broader\nspectrum of meta-learned in-context learning. Indeed, we suggest that any\ndistribution of sequences in which context non-trivially decreases loss on\nsubsequent predictions can be interpreted as eliciting a kind of in-context\nlearning. We suggest that this perspective helps to unify the broad set of\nin-context abilities that language models exhibit $\\unicode{x2014}$ such as\nadapting to tasks from instructions or role play, or extrapolating time series.\nThis perspective also sheds light on potential roots of in-context learning in\nlower-level processing of linguistic dependencies (e.g. coreference or parallel\nstructures). Finally, taking this perspective highlights the importance of\ngeneralization, which we suggest can be studied along several dimensions: not\nonly the ability to learn something novel, but also flexibility in learning\nfrom different presentations, and in applying what is learned. We discuss\nbroader connections to past literature in meta-learning and goal-conditioned\nagents, and other perspectives on learning and adaptation. We close by\nsuggesting that research on in-context learning should consider this broader\nspectrum of in-context capabilities and types of generalization.", "published": "2024-12-05 00:05:11", "link": "http://arxiv.org/abs/2412.03782v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Agent AI with LangGraph: A Modular Framework for Enhancing Machine\n  Translation Using Large Language Models", "abstract": "This paper explores the transformative role of Agent AI and LangGraph in\nadvancing the automation and effectiveness of machine translation (MT). Agents\nare modular components designed to perform specific tasks, such as translating\nbetween particular languages, with specializations like TranslateEnAgent,\nTranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese\ntranslations, respectively. These agents leverage the powerful semantic\ncapabilities of large language models (LLMs), such as GPT-4o, to ensure\naccurate, contextually relevant translations while maintaining modularity,\nscalability, and context retention.\n  LangGraph, a graph-based framework built on LangChain, simplifies the\ncreation and management of these agents and their workflows. It supports\ndynamic state management, enabling agents to maintain dialogue context and\nautomates complex workflows by linking agents and facilitating their\ncollaboration. With flexibility, open-source community support, and seamless\nintegration with LLMs, LangGraph empowers agents to deliver high-quality\ntranslations.\n  Together, Agent AI and LangGraph create a cohesive system where LangGraph\norchestrates agent interactions, ensuring that user inputs are analyzed,\nrouted, and processed efficiently. Experimental results demonstrate the\npotential of this system to enhance multilingual translation accuracy and\nscalability. By highlighting modular design and automated workflows, this paper\nsets the stage for further innovations in intelligent machine translation\nservices.", "published": "2024-12-05 01:45:12", "link": "http://arxiv.org/abs/2412.03801v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond the Binary: Capturing Diverse Preferences With Reward\n  Regularization", "abstract": "Large language models (LLMs) are increasingly deployed via public-facing\ninterfaces to interact with millions of users, each with diverse preferences.\nDespite this, preference tuning of LLMs predominantly relies on reward models\ntrained using binary judgments where annotators select the preferred choice out\nof pairs of model outputs. In this work, we argue that this reliance on binary\nchoices does not capture the broader, aggregate preferences of the target user\nin real-world tasks. We propose a taxonomy that identifies two dimensions of\nsubjectivity where different users disagree on the preferred output-namely, the\nPlurality of Responses to Prompts, where prompts allow for multiple correct\nanswers, and the Indistinguishability of Responses, where candidate outputs are\nparaphrases of each other. We show that reward models correlate weakly with\nuser preferences in these cases. As a first step to address this issue, we\nintroduce a simple yet effective method that augments existing binary\npreference datasets with synthetic preference judgments to estimate potential\nuser disagreement. Incorporating these via a margin term as a form of\nregularization during model training yields predictions that better align with\nthe aggregate user preferences.", "published": "2024-12-05 02:35:46", "link": "http://arxiv.org/abs/2412.03822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated LaTeX Code Generation from Handwritten Math Expressions Using\n  Vision Transformer", "abstract": "Transforming mathematical expressions into LaTeX poses a significant\nchallenge. In this paper, we examine the application of advanced\ntransformer-based architectures to address the task of converting handwritten\nor digital mathematical expression images into corresponding LaTeX code. As a\nbaseline, we utilize the current state-of-the-art CNN encoder and LSTM decoder.\nAdditionally, we explore enhancements to the CNN-RNN architecture by replacing\nthe CNN encoder with the pretrained ResNet50 model with modification to suite\nthe grey scale input. Further, we experiment with vision transformer model and\ncompare with Baseline and CNN-LSTM model. Our findings reveal that the vision\ntransformer architectures outperform the baseline CNN-RNN framework, delivering\nhigher overall accuracy and BLEU scores while achieving lower Levenshtein\ndistances. Moreover, these results highlight the potential for further\nimprovement through fine-tuning of model parameters. To encourage open\nresearch, we also provide the model implementation, enabling reproduction of\nour results and facilitating further research in this domain.", "published": "2024-12-05 03:58:13", "link": "http://arxiv.org/abs/2412.03853v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AyutthayaAlpha: A Thai-Latin Script Transliteration Transformer", "abstract": "This study introduces AyutthayaAlpha, an advanced transformer-based machine\nlearning model designed for the transliteration of Thai proper names into Latin\nscript. Our system achieves state-of-the-art performance with 82.32%\nfirst-token accuracy and 95.24% first-three-token accuracy, while maintaining a\nlow character error rate of 0.0047. The complexity of Thai phonology, including\ntonal features and vowel length distinctions, presents significant challenges\nfor accurate transliteration, which we address through a novel two-model\napproach: AyutthayaAlpha-Small, based on the ByT5 architecture, and\nAyutthayaAlpha-VerySmall, a computationally efficient variant that unexpectedly\noutperforms its larger counterpart. Our research combines linguistic rules with\ndeep learning, training on a carefully curated dataset of 1.2 million\nThai-Latin name pairs, augmented through strategic upsampling to 2.7 million\nexamples. Extensive evaluations against existing transliteration methods and\nhuman expert benchmarks demonstrate that AyutthayaAlpha not only achieves\nsuperior accuracy but also effectively captures personal and cultural\npreferences in name romanization. The system's practical applications extend to\ncross-lingual information retrieval, international data standardization, and\nidentity verification systems, with particular relevance for government\ndatabases, academic institutions, and global business operations. This work\nrepresents a significant advance in bridging linguistic gaps between Thai and\nLatin scripts, while respecting the cultural and personal dimensions of name\ntransliteration.", "published": "2024-12-05 05:18:09", "link": "http://arxiv.org/abs/2412.03877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uniform Discretized Integrated Gradients: An effective attribution based\n  method for explaining large language models", "abstract": "Integrated Gradients is a well-known technique for explaining deep learning\nmodels. It calculates feature importance scores by employing a gradient based\napproach computing gradients of the model output with respect to input features\nand accumulating them along a linear path. While this works well for continuous\nfeatures spaces, it may not be the most optimal way to deal with discrete\nspaces like word embeddings. For interpreting LLMs (Large Language Models),\nthere exists a need for a non-linear path where intermediate points, whose\ngradients are to be computed, lie close to actual words in the embedding space.\nIn this paper, we propose a method called Uniform Discretized Integrated\nGradients (UDIG) based on a new interpolation strategy where we choose a\nfavorable nonlinear path for computing attribution scores suitable for\npredictive language models. We evaluate our method on two types of NLP tasks-\nSentiment Classification and Question Answering against three metrics viz Log\nodds, Comprehensiveness and Sufficiency. For sentiment classification, we have\nused the SST2, IMDb and Rotten Tomatoes datasets for benchmarking and for\nQuestion Answering, we have used the fine-tuned BERT model on SQuAD dataset.\nOur approach outperforms the existing methods in almost all the metrics.", "published": "2024-12-05 05:39:03", "link": "http://arxiv.org/abs/2412.03886v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic\n  Scenarios", "abstract": "Game-theoretic scenarios have become pivotal in evaluating the social\nintelligence of Large Language Model (LLM)-based social agents. While numerous\nstudies have explored these agents in such settings, there is a lack of a\ncomprehensive survey summarizing the current progress. To address this gap, we\nsystematically review existing research on LLM-based social agents within\ngame-theoretic scenarios. Our survey organizes the findings into three core\ncomponents: Game Framework, Social Agent, and Evaluation Protocol. The game\nframework encompasses diverse game scenarios, ranging from choice-focusing to\ncommunication-focusing games. The social agent part explores agents'\npreferences, beliefs, and reasoning abilities. The evaluation protocol covers\nboth game-agnostic and game-specific metrics for assessing agent performance.\nBy reflecting on the current research and identifying future research\ndirections, this survey provides insights to advance the development and\nevaluation of social agents in game-theoretic scenarios.", "published": "2024-12-05 06:46:46", "link": "http://arxiv.org/abs/2412.03920v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIND: Effective Incorrect Assignment Detection through a Multi-Modal\n  Structure-Enhanced Language Model", "abstract": "The rapid growth of academic publications has exacerbated the issue of author\nname ambiguity in online digital libraries. Despite advances in name\ndisambiguation algorithms, cumulative errors continue to undermine the\nreliability of academic systems. It is estimated that over 10% paper-author\nassignments are rectified when constructing the million-scale WhoIsWho\nbenchmark. Existing endeavors to detect incorrect assignments are either\nsemantic-based or graph-based approaches, which fall short of making full use\nof the rich text attributes of papers and implicit structural features defined\nvia the co-occurrence of paper attributes. To this end, this paper introduces a\nstructure-enhanced language model that combines key structural features from\ngraph-based methods with fine-grained semantic features from rich paper\nattributes to detect incorrect assignments. The proposed model is trained with\na highly effective multi-modal multi-turn instruction tuning framework, which\nincorporates task-guided instruction tuning, text-attribute modality, and\nstructural modality. Experimental results demonstrate that our model\noutperforms previous approaches, achieving top performance on the leaderboard\nof KDD Cup 2024. Our code has been publicly available.", "published": "2024-12-05 07:12:53", "link": "http://arxiv.org/abs/2412.03930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Demonstration Selection for In-Context Learning via Reinforcement\n  Learning", "abstract": "Diversity in demonstration selection is crucial for enhancing model\ngeneralization, as it enables a broader coverage of structures and concepts.\nHowever, constructing an appropriate set of demonstrations has remained a focal\npoint of research. This paper presents the Relevance-Diversity Enhanced\nSelection (RDES), an innovative approach that leverages reinforcement learning\nto optimize the selection of diverse reference demonstrations for text\nclassification tasks using Large Language Models (LLMs), especially in few-shot\nprompting scenarios. RDES employs a Q-learning framework to dynamically\nidentify demonstrations that maximize both diversity and relevance to the\nclassification objective by calculating a diversity score based on label\ndistribution among selected demonstrations. This method ensures a balanced\nrepresentation of reference data, leading to improved classification accuracy.\nThrough extensive experiments on four benchmark datasets and involving 12\nclosed-source and open-source LLMs, we demonstrate that RDES significantly\nenhances classification accuracy compared to ten established baselines.\nFurthermore, we investigate the incorporation of Chain-of-Thought (CoT)\nreasoning in the reasoning process, which further enhances the model's\npredictive performance. The results underscore the potential of reinforcement\nlearning to facilitate adaptive demonstration selection and deepen the\nunderstanding of classification challenges.", "published": "2024-12-05 08:33:52", "link": "http://arxiv.org/abs/2412.03966v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MTMT: Consolidating Multiple Thinking Modes to Form a Thought Tree for\n  Strengthening LLM", "abstract": "Large language models (LLMs) have shown limitations in tasks requiring\ncomplex logical reasoning and multi-step problem-solving. To address these\nchallenges, researchers have employed carefully designed prompts and\nflowcharts, simulating human cognitive processes to enhance LLM performance,\nsuch as the Chain of Thought approach. In this paper, we introduce MTMT\n(Multi-thinking Modes Tree), a novel method that interacts with LLMs to\nconstruct a thought tree, simulating various advanced cognitive processes,\nincluding but not limited to association, counterfactual thinking, task\ndecomposition, and comparison. By breaking down the original complex task into\nsimpler sub-questions, MTMT facilitates easier problem-solving for LLMs,\nenabling more effective utilization of the latent knowledge within LLMs. We\nevaluate the performance of MTMT under different parameter configurations,\nusing GPT-4o mini as the base model. Our results demonstrate that integrating\nmultiple modes of thinking significantly enhances the ability of LLMs to handle\ncomplex tasks.", "published": "2024-12-05 09:05:30", "link": "http://arxiv.org/abs/2412.03987v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Medical Report Generation for ECG Data: Bridging Medical Text\n  and Signal Processing with Deep Learning", "abstract": "Recent advances in deep learning and natural language generation have\nsignificantly improved image captioning, enabling automated, human-like\ndescriptions for visual content. In this work, we apply these captioning\ntechniques to generate clinician-like interpretations of ECG data. This study\nleverages existing ECG datasets accompanied by free-text reports authored by\nhealthcare professionals (HCPs) as training data. These reports, while often\ninconsistent, provide a valuable foundation for automated learning. We\nintroduce an encoder-decoder-based method that uses these reports to train\nmodels to generate detailed descriptions of ECG episodes. This represents a\nsignificant advancement in ECG analysis automation, with potential applications\nin zero-shot classification and automated clinical decision support.\n  The model is tested on various datasets, including both 1- and 12-lead ECGs.\nIt significantly outperforms the state-of-the-art reference model by Qiu et\nal., achieving a METEOR score of 55.53% compared to 24.51% achieved by the\nreference model. Furthermore, several key design choices are discussed,\nproviding a comprehensive overview of current challenges and innovations in\nthis domain.\n  The source codes for this research are publicly available in our Git\nrepository https://git.zib.de/ableich/ecg-comment-generation-public", "published": "2024-12-05 11:05:12", "link": "http://arxiv.org/abs/2412.04067v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "If You Can't Use Them, Recycle Them: Optimizing Merging at Scale\n  Mitigates Performance Tradeoffs", "abstract": "Model merging has shown great promise at combining expert models, but the\nbenefit of merging is unclear when merging \"generalist\" models trained on many\ntasks. We explore merging in the context of large (~100B) models, by recycling\ncheckpoints that exhibit tradeoffs among different tasks. Such checkpoints are\noften created in the process of developing a frontier model, and the suboptimal\nones are usually discarded. Given a pool of model checkpoints obtained from\ndifferent training runs (e.g., different stages, objectives, hyperparameters,\nand data mixtures), which naturally show tradeoffs across different language\ncapabilities (e.g., instruction following vs. code generation), we investigate\nwhether merging can recycle such suboptimal models into a Pareto-optimal one.\nOur optimization algorithm tunes the weight of each checkpoint in a linear\ncombination, resulting in such an optimal model that outperforms both\nindividual models and merge-based baselines. Further analysis shows that good\nmerges tend to include almost all checkpoints with non-zero weights, indicating\nthat even seemingly bad initial checkpoints can contribute to good final\nmerges.", "published": "2024-12-05 13:12:51", "link": "http://arxiv.org/abs/2412.04144v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CLINICSUM: Utilizing Language Models for Generating Clinical Summaries\n  from Patient-Doctor Conversations", "abstract": "This paper presents ClinicSum, a novel framework designed to automatically\ngenerate clinical summaries from patient-doctor conversations. It utilizes a\ntwo-module architecture: a retrieval-based filtering module that extracts\nSubjective, Objective, Assessment, and Plan (SOAP) information from\nconversation transcripts, and an inference module powered by fine-tuned\nPre-trained Language Models (PLMs), which leverage the extracted SOAP data to\ngenerate abstracted clinical summaries. To fine-tune the PLM, we created a\ntraining dataset of consisting 1,473 conversations-summaries pair by\nconsolidating two publicly available datasets, FigShare and MTS-Dialog, with\nground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's\neffectiveness is evaluated through both automatic metrics (e.g., ROUGE,\nBERTScore) and expert human assessments. Results show that ClinicSum\noutperforms state-of-the-art PLMs, demonstrating superior precision, recall,\nand F-1 scores in automatic evaluations and receiving high preference from SMEs\nin human assessment, making it a robust solution for automated clinical\nsummarization.", "published": "2024-12-05 15:34:02", "link": "http://arxiv.org/abs/2412.04254v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ALMA: Alignment with Minimal Annotation", "abstract": "Recent approaches to large language model (LLM) alignment typically require\nmillions of human annotations or rely on external aligned models for synthetic\ndata generation. This paper introduces ALMA: Alignment with Minimal Annotation,\ndemonstrating that effective alignment can be achieved using only 9,000 labeled\nexamples -- less than 1% of conventional approaches. ALMA generates large\namounts of high-quality synthetic alignment data through new techniques:\ndiverse prompt synthesis via few-shot learning, diverse response generation\nwith multiple model checkpoints, and judge (reward model) enhancement through\nscore aggregation and self-distillation. Using only a pretrained Llama3 base\nmodel, 5,000 SFT examples, and 4,000 judge annotations, ALMA achieves\nperformance close to Llama3-Instruct across diverse alignment benchmarks (e.g.,\n0.1% difference on AlpacaEval 2.0 score). These results are achieved with a\nmulti-round, self-bootstrapped data synthesis and training recipe that\ncontinues to improve for 10 rounds, surpassing the typical 3-round ceiling of\nprevious methods. These results suggest that base models already possess\nsufficient knowledge for effective alignment, and that synthetic data\ngeneration methods can expose it.", "published": "2024-12-05 16:26:31", "link": "http://arxiv.org/abs/2412.04305v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Densing Law of LLMs", "abstract": "Large Language Models (LLMs) have emerged as a milestone in artificial\nintelligence, and their performance can improve as the model size increases.\nHowever, this scaling brings great challenges to training and inference\nefficiency, particularly for deploying LLMs in resource-constrained\nenvironments, and the scaling trend is becoming increasingly unsustainable.\nThis paper introduces the concept of ``\\textit{capacity density}'' as a new\nmetric to evaluate the quality of the LLMs across different scales and\ndescribes the trend of LLMs in terms of both effectiveness and efficiency. To\ncalculate the capacity density of a given target LLM, we first introduce a set\nof reference models and develop a scaling law to predict the downstream\nperformance of these reference models based on their parameter sizes. We then\ndefine the \\textit{effective parameter size} of the target LLM as the parameter\nsize required by a reference model to achieve equivalent performance, and\nformalize the capacity density as the ratio of the effective parameter size to\nthe actual parameter size of the target LLM. Capacity density provides a\nunified framework for assessing both model effectiveness and efficiency. Our\nfurther analysis of recent open-source base LLMs reveals an empirical law (the\ndensing law)that the capacity density of LLMs grows exponentially over time.\nMore specifically, using some widely used benchmarks for evaluation, the\ncapacity density of LLMs doubles approximately every three months. The law\nprovides new perspectives to guide future LLM development, emphasizing the\nimportance of improving capacity density to achieve optimal results with\nminimal computational overhead.", "published": "2024-12-05 16:31:13", "link": "http://arxiv.org/abs/2412.04315v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for\n  Open-Ended Text Generation", "abstract": "This paper introduces the counter-intuitive generalization results of\noverfitting pre-trained large language models (LLMs) on very small datasets. In\nthe setting of open-ended text generation, it is well-documented that LLMs tend\nto generate repetitive and dull sequences, a phenomenon that is especially\napparent when generating using greedy decoding. This issue persists even with\nstate-of-the-art LLMs containing billions of parameters, trained via next-token\nprediction on large datasets. We find that by further fine-tuning these models\nto achieve a near-zero training loss on a small set of samples -- a process we\nrefer to as hyperfitting -- the long-sequence generative capabilities are\ngreatly enhanced. Greedy decoding with these Hyperfitted models even outperform\nTop-P sampling over long-sequences, both in terms of diversity and human\npreferences. This phenomenon extends to LLMs of various sizes, different\ndomains, and even autoregressive image generation. We further find this\nphenomena to be distinctly different from that of Grokking and double descent.\nSurprisingly, our experiments indicate that hyperfitted models rarely fall into\nrepeating sequences they were trained on, and even explicitly blocking these\nsequences results in high-quality output. All hyperfitted models produce\nextremely low-entropy predictions, often allocating nearly all probability to a\nsingle token.", "published": "2024-12-05 16:34:20", "link": "http://arxiv.org/abs/2412.04318v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "abstract": "Retrieval-augmented generation (RAG) introduces additional information to\nenhance large language models (LLMs). In machine translation (MT), previous\nwork typically retrieves in-context examples from paired MT corpora, or\ndomain-specific knowledge from knowledge graphs, to enhance models' MT ability.\nHowever, a large amount of world knowledge is organized in unstructured\ndocuments, and might not be fully paired across different languages. In this\npaper, we study retrieval-augmented MT using unstructured documents.\nSpecifically, we build RAGtrans, the first benchmark to train and evaluate\nLLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples\ncollected via GPT-4o and human translators. Besides, documents from different\nlanguages are also provided to supply the knowledge to these samples. Based on\nRAGtrans, we further propose a multi-task training method to teach LLMs how to\nuse information from multilingual documents during their translation. The\nmethod uses existing multilingual corpora to create auxiliary training\nobjectives without additional labeling requirements. Extensive experiments show\nthat the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.", "published": "2024-12-05 17:00:32", "link": "http://arxiv.org/abs/2412.04342v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BhashaVerse : Translation Ecosystem for Indian Subcontinent Languages", "abstract": "This paper focuses on developing translation models and related applications\nfor 36 Indian languages, including Assamese, Awadhi, Bengali, Bhojpuri, Braj,\nBodo, Dogri, English, Konkani, Gondi, Gujarati, Hindi, Hinglish, Ho, Kannada,\nKangri, Kashmiri (Arabic and Devanagari), Khasi, Mizo, Magahi, Maithili,\nMalayalam, Marathi, Manipuri (Bengali and Meitei), Nepali, Oriya, Punjabi,\nSanskrit, Santali, Sinhala, Sindhi (Arabic and Devanagari), Tamil, Tulu,\nTelugu, and Urdu. Achieving this requires parallel and other types of corpora\nfor all 36 * 36 language pairs, addressing challenges like script variations,\nphonetic differences, and syntactic diversity. For instance, languages like\nKashmiri and Sindhi, which use multiple scripts, demand script normalization\nfor alignment, while low-resource languages such as Khasi and Santali require\nsynthetic data augmentation to ensure sufficient coverage and quality.\n  To address these challenges, this work proposes strategies for corpus\ncreation by leveraging existing resources, developing parallel datasets,\ngenerating domain-specific corpora, and utilizing synthetic data techniques.\nAdditionally, it evaluates machine translation across various dimensions,\nincluding standard and discourse-level translation, domain-specific\ntranslation, reference-based and reference-free evaluation, error analysis, and\nautomatic post-editing. By integrating these elements, the study establishes a\ncomprehensive framework to improve machine translation quality and enable\nbetter cross-lingual communication in India's linguistically diverse ecosystem.", "published": "2024-12-05 17:10:19", "link": "http://arxiv.org/abs/2412.04351v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders", "abstract": "We develop task scaling laws and model ladders to predict the individual task\nperformance of pretrained language models (LMs) in the overtrained setting.\nStandard power laws for language modeling loss cannot accurately model task\nperformance. Therefore, we leverage a two-step prediction approach: first use\nmodel and data size to predict a task-specific loss, and then use this task\nloss to predict task performance. We train a set of small-scale \"ladder\"\nmodels, collect data points to fit the parameterized functions of the two\nprediction steps, and make predictions for two target models: a 7B model\ntrained to 4T tokens and a 13B model trained to 5T tokens. Training the ladder\nmodels only costs 1% of the compute used for the target models. On four\nmultiple-choice tasks written in ranked classification format, we can predict\nthe accuracy of both target models within 2 points of absolute error. We have\nhigher prediction error on four other tasks (average absolute error 6.9) and\nfind that these are often tasks with higher variance in task metrics. We also\nfind that using less compute to train fewer ladder models tends to deteriorate\npredictions. Finally, we empirically show that our design choices and the\ntwo-step approach lead to superior performance in establishing scaling laws.", "published": "2024-12-05 18:21:49", "link": "http://arxiv.org/abs/2412.04403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay", "abstract": "Despite the remarkable performance of multimodal large language models\n(MLLMs) across diverse tasks, the substantial training and inference costs\nimpede their advancement. The majority of computation stems from the\noverwhelming volume of vision tokens processed by the transformer decoder. In\nthis paper, we propose to build efficient MLLMs by leveraging the\nMixture-of-Depths (MoD) mechanism, where each transformer decoder layer selects\nessential vision tokens to process while skipping redundant ones. However,\nintegrating MoD into MLLMs is non-trivial. To address the challenges of\ntraining and inference stability as well as limited training data, we adapt the\nMoD module with two novel designs: tanh-gated weight normalization (TanhNorm)\nand symmetric token reweighting (STRing). Moreover, we observe that vision\ntokens exhibit higher redundancy in deeper layer and thus design a progressive\nratio decay (PRD) strategy, which gradually reduces the token retention ratio\nlayer by layer, employing a shifted cosine schedule. This crucial design fully\nunleashes the potential of MoD, significantly boosting the efficiency and\nperformance of our models. To validate the effectiveness of our approach, we\nconduct extensive experiments with two baseline models across 14 benchmarks.\nOur model, p-MoD, matches or even surpasses the performance of the baseline\nmodels, with only 55.6% TFLOPs and 53.8% KV cache storage during inference, and\n77.7% GPU hours during training.", "published": "2024-12-05 18:58:03", "link": "http://arxiv.org/abs/2412.04449v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Understanding Hidden Computations in Chain-of-Thought Reasoning", "abstract": "Chain-of-Thought (CoT) prompting has significantly enhanced the reasoning\nabilities of large language models. However, recent studies have shown that\nmodels can still perform complex reasoning tasks even when the CoT is replaced\nwith filler(hidden) characters (e.g., \"...\"), leaving open questions about how\nmodels internally process and represent reasoning steps. In this paper, we\ninvestigate methods to decode these hidden characters in transformer models\ntrained with filler CoT sequences. By analyzing layer-wise representations\nusing the logit lens method and examining token rankings, we demonstrate that\nthe hidden characters can be recovered without loss of performance. Our\nfindings provide insights into the internal mechanisms of transformer models\nand open avenues for improving interpretability and transparency in language\nmodel reasoning.", "published": "2024-12-05 18:43:11", "link": "http://arxiv.org/abs/2412.04537v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Formulation of probability theory problem with subtle condition", "abstract": "Problems in probability theory prove to be one of the most challenging for\nstudents. Here, we formulate and discuss four related problems in probability\ntheory that proved difficult for first to fourth-year undergraduate students\nwhose first language was not English. These examples emphasize how crucial it\nis to understand the conditions and requirements of the problems precisely\nbefore starting to solve them. We discuss the solutions to those problems in\ndetail, complement them with numerical estimations, and link the conditions in\nthe problems to the logical statements in Python programming language. We also\ntested two widely used chatbots (GPT-4o and Claude 3.5 Sonnet) by checking\ntheir responses to these problems.", "published": "2024-12-05 20:32:23", "link": "http://arxiv.org/abs/2412.04602v1", "categories": ["cs.CL", "math.PR"], "primary_category": "cs.CL"}
{"title": "Semantic Consistency-Based Uncertainty Quantification for Factuality in\n  Radiology Report Generation", "abstract": "Radiology report generation (RRG) has shown great potential in assisting\nradiologists by automating the labor-intensive task of report writing. While\nrecent advancements have improved the quality and coherence of generated\nreports, ensuring their factual correctness remains a critical challenge.\nAlthough generative medical Vision Large Language Models (VLLMs) have been\nproposed to address this issue, these models are prone to hallucinations and\ncan produce inaccurate diagnostic information. To address these concerns, we\nintroduce a novel Semantic Consistency-Based Uncertainty Quantification\nframework that provides both report-level and sentence-level uncertainties.\nUnlike existing approaches, our method does not require modifications to the\nunderlying model or access to its inner state, such as output token logits,\nthus serving as a plug-and-play module that can be seamlessly integrated with\nstate-of-the-art models. Extensive experiments demonstrate the efficacy of our\nmethod in detecting hallucinations and enhancing the factual accuracy of\nautomatically generated radiology reports. By abstaining from high-uncertainty\nreports, our approach improves factuality scores by $10$\\%, achieved by\nrejecting $20$\\% of reports using the \\texttt{Radialog} model on the MIMIC-CXR\ndataset. Furthermore, sentence-level uncertainty flags the lowest-precision\nsentence in each report with an $82.9$\\% success rate. Our implementation is\nopen-source and available at https://github.com/BU-DEPEND-Lab/SCUQ-RRG.", "published": "2024-12-05 20:43:39", "link": "http://arxiv.org/abs/2412.04606v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Extractive Structures Learned in Pretraining Enable Generalization on\n  Finetuned Facts", "abstract": "Pretrained language models (LMs) can generalize to implications of facts that\nthey are finetuned on. For example, if finetuned on ``John Doe lives in Tokyo,\"\nLMs can correctly answer ``What language do the people in John Doe's city\nspeak?'' with ``Japanese''. However, little is known about the mechanisms that\nenable this generalization or how they are learned during pretraining. We\nintroduce extractive structures as a framework for describing how components in\nLMs (e.g., MLPs or attention heads) coordinate to enable this generalization.\nThe structures consist of informative components that store training facts as\nweight changes, and upstream and downstream extractive components that query\nand process the stored information to produce the correct implication. We\nhypothesize that extractive structures are learned during pretraining when\nencountering implications of previously known facts. This yields two\npredictions: a data ordering effect where extractive structures can be learned\nonly if facts precede their implications, and a weight grafting effect where\nextractive structures can be transferred to predict counterfactual\nimplications. We empirically demonstrate these phenomena in the OLMo-7b, Llama\n3-8b, Gemma 2-9b, and Qwen 2-7b models. Of independent interest, our results\nalso indicate that fact learning can occur at both early and late layers, which\nlead to different forms of generalization.", "published": "2024-12-05 21:00:46", "link": "http://arxiv.org/abs/2412.04614v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sometimes I am a Tree: Data Drives Unstable Hierarchical Generalization", "abstract": "Language models (LMs), like other neural networks, often favor shortcut\nheuristics based on surface-level patterns. Although LMs behave like n-gram\nmodels early in training, they must eventually learn hierarchical syntactic\nrepresentations to correctly apply grammatical rules out-of-distribution (OOD).\nIn this work, we use case studies of English grammar to explore how complex,\ndiverse training data drives models to generalize OOD. We construct a framework\nthat unifies our understanding of random variation with training dynamics, rule\nselection with memorization, and data diversity with complexity. We show that\nthese factors are nuanced, and that intermediate levels of diversity and\ncomplexity lead to inconsistent behavior across random seeds and to unstable\ntraining dynamics. Our findings emphasize the critical role of training data in\nshaping generalization patterns and illuminate how competing model strategies\nlead to inconsistent generalization outcomes across random seeds. Code is\navailable at https://github.com/sunnytqin/concept_comp.git.", "published": "2024-12-05 21:12:37", "link": "http://arxiv.org/abs/2412.04619v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BigDocs: An Open Dataset for Training Multimodal Models on Document and\n  Code Tasks", "abstract": "Multimodal AI has the potential to significantly enhance\ndocument-understanding tasks, such as processing receipts, understanding\nworkflows, extracting data from documents, and summarizing reports. Code\ngeneration tasks that require long-structured outputs can also be enhanced by\nmultimodality. Despite this, their use in commercial applications is often\nlimited due to limited access to training data and restrictive licensing, which\nhinders open access. To address these limitations, we introduce BigDocs-7.5M, a\nhigh-quality, open-access dataset comprising 7.5 million multimodal documents\nacross 30 tasks. We use an efficient data curation process to ensure our data\nis high-quality and license-permissive. Our process emphasizes accountability,\nresponsibility, and transparency through filtering rules, traceable metadata,\nand careful content analysis. Additionally, we introduce BigDocs-Bench, a\nbenchmark suite with 10 novel tasks where we create datasets that reflect\nreal-world use cases involving reasoning over Graphical User Interfaces (GUI)\nand code generation from images. Our experiments show that training with\nBigDocs-Bench improves average performance up to 25.8% over closed-source\nGPT-4o in document reasoning and structured output tasks such as\nScreenshot2HTML or Image2Latex generation. Finally, human evaluations showed a\npreference for outputs from models trained on BigDocs over GPT-4o. This\nsuggests that BigDocs can help both academics and the open-source community\nutilize and improve AI tools to enhance multimodal capabilities and document\nreasoning. The project is hosted at https://bigdocs.github.io .", "published": "2024-12-05 21:41:20", "link": "http://arxiv.org/abs/2412.04626v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "How Large Language Models (LLMs) Extrapolate: From Guided Missiles to\n  Guided Prompts", "abstract": "This paper argues that we should perceive LLMs as machines of extrapolation.\nExtrapolation is a statistical function for predicting the next value in a\nseries. Extrapolation contributes to both GPT successes and controversies\nsurrounding its hallucination. The term hallucination implies a malfunction,\nyet this paper contends that it in fact indicates the chatbot efficiency in\nextrapolation, albeit an excess of it. This article bears a historical\ndimension: it traces extrapolation to the nascent years of cybernetics. In\n1941, when Norbert Wiener transitioned from missile science to communication\nengineering, the pivotal concept he adopted was none other than extrapolation.\nSoviet mathematician Andrey Kolmogorov, renowned for his compression logic that\ninspired OpenAI, had developed in 1939 another extrapolation project that\nWiener later found rather like his own. This paper uncovers the connections\nbetween hot war science, Cold War cybernetics, and the contemporary debates on\nLLM performances.", "published": "2024-12-05 19:54:47", "link": "http://arxiv.org/abs/2501.10361v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software\n  Repository-Related Question Answering", "abstract": "Software repositories contain valuable information for gaining insights into\ntheir development process. However, extracting insights from these repository\ndata is time-consuming and requires technical expertise. While software\nengineering chatbots have been developed to facilitate natural language\ninteractions with repositories, they struggle with understanding natural\nlanguage and accurately retrieving relevant data. This study aims to improve\nthe accuracy of LLM-based chatbots in answering repository-related questions by\naugmenting them with knowledge graphs. We achieve this in a two-step approach;\n(1) constructing a knowledge graph from the repository data and (2) synergizing\nthe knowledge graph with LLM to allow for the natural language questions and\nanswers. We curated a set of 20 questions with different complexities and\nevaluated our approach on five popular open-source projects. Our approach\nachieved an accuracy of 65%. We further investigated the limitations and\nidentified six key issues, with the majority relating to the reasoning\ncapability of the LLM. We experimented with a few-shot chain-of-thought\nprompting to determine if it could enhance our approach. This technique\nimproved the overall accuracy to 84%. Our findings demonstrate the synergy\nbetween LLMs and knowledge graphs as a viable solution for making repository\ndata accessible to both technical and non-technical stakeholders.", "published": "2024-12-05 02:18:03", "link": "http://arxiv.org/abs/2412.03815v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "MISR: Measuring Instrumental Self-Reasoning in Frontier Models", "abstract": "We propose a suite of tasks to evaluate the instrumental self-reasoning\nability of large language model (LLM) agents. Instrumental self-reasoning\nability could improve adaptability and enable self-modification, but it could\nalso pose significant risks, such as enabling deceptive alignment. Prior work\nhas only evaluated self-reasoning in non-agentic settings or in limited\ndomains. In this paper, we propose evaluations for instrumental self-reasoning\nability in agentic tasks in a wide range of scenarios, including\nself-modification, knowledge seeking, and opaque self-reasoning. We evaluate\nagents built using state-of-the-art LLMs, including commercial and open source\nsystems. We find that instrumental self-reasoning ability emerges only in the\nmost capable frontier models and that it is highly context-dependent. No model\npasses the the most difficult versions of our evaluations, hence our evaluation\ncan be used to measure increases in instrumental self-reasoning ability in\nfuture models. We open-source our evaluations at\nhttps://github.com/kaifronsdal/Self-Reasoning-Evals.", "published": "2024-12-05 06:20:47", "link": "http://arxiv.org/abs/2412.03904v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Text Change Detection in Multilingual Documents Using Image Comparison", "abstract": "Document comparison typically relies on optical character recognition (OCR)\nas its core technology. However, OCR requires the selection of appropriate\nlanguage models for each document and the performance of multilingual or hybrid\nmodels remains limited. To overcome these challenges, we propose text change\ndetection (TCD) using an image comparison model tailored for multilingual\ndocuments. Unlike OCR-based approaches, our method employs word-level text\nimage-to-image comparison to detect changes. Our model generates bidirectional\nchange segmentation maps between the source and target documents. To enhance\nperformance without requiring explicit text alignment or scaling preprocessing,\nwe employ correlations among multi-scale attention features. We also construct\na benchmark dataset comprising actual printed and scanned word pairs in various\nlanguages to evaluate our model. We validate our approach using our benchmark\ndataset and public benchmarks Distorted Document Images and the LRDE Document\nBinarization Dataset. We compare our model against state-of-the-art semantic\nsegmentation and change detection models, as well as to conventional OCR-based\nmodels.", "published": "2024-12-05 13:04:10", "link": "http://arxiv.org/abs/2412.04137v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A History of Philosophy in Colombia through Topic Modelling", "abstract": "Data-driven approaches to philosophy have emerged as a valuable tool for\nstudying the history of the discipline. However, most studies in this area have\nfocused on a limited number of journals from specific regions and subfields. We\nexpand the scope of this research by applying dynamic topic modelling\ntechniques to explore the history of philosophy in Colombia and Latin America.\nOur study examines the Colombian philosophy journal Ideas y Valores, founded in\n1951 and currently one of the most influential academic philosophy journals in\nthe region. By analyzing the evolution of topics across the journal's history,\nwe identify various trends and specific dynamics in philosophical discourse\nwithin the Colombian and Latin American context. Our findings reveal that the\nmost prominent topics are value theory (including ethics, political philosophy,\nand aesthetics), epistemology, and the philosophy of science. We also trace the\nevolution of articles focusing on the historical and interpretive aspects of\nphilosophical texts, and we note a notable emphasis on German philosophers such\nas Kant, Husserl, and Hegel on various topics throughout the journal's\nlifetime. Additionally, we investigate whether articles with a historical focus\nhave decreased over time due to editorial pressures. Our analysis suggests no\nsignificant decline in such articles. Finally, we propose ideas for extending\nthis research to other Latin American journals and suggest improvements for\nnatural language processing workflows in non-English languages.", "published": "2024-12-05 15:14:16", "link": "http://arxiv.org/abs/2412.04236v1", "categories": ["cs.LG", "cs.CL", "cs.DL"], "primary_category": "cs.LG"}
{"title": "Representation Purification for End-to-End Speech Translation", "abstract": "Speech-to-text translation (ST) is a cross-modal task that involves\nconverting spoken language into text in a different language. Previous research\nprimarily focused on enhancing speech translation by facilitating knowledge\ntransfer from machine translation, exploring various methods to bridge the gap\nbetween speech and text modalities. Despite substantial progress made, factors\nin speech that are not relevant to translation content, such as timbre and\nrhythm, often limit the efficiency of knowledge transfer. In this paper, we\nconceptualize speech representation as a combination of content-agnostic and\ncontent-relevant factors. We examine the impact of content-agnostic factors on\ntranslation performance through preliminary experiments and observe a\nsignificant performance deterioration when content-agnostic perturbations are\nintroduced to speech signals. To address this issue, we propose a\n\\textbf{S}peech \\textbf{R}epresentation \\textbf{P}urification with\n\\textbf{S}upervision \\textbf{E}nhancement (SRPSE) framework, which excludes the\ncontent-agnostic components within speech representations to mitigate their\nnegative impact on ST. Experiments on MuST-C and CoVoST-2 datasets demonstrate\nthat SRPSE significantly improves translation performance across all\ntranslation directions in three settings and achieves preeminent performance\nunder a \\textit{transcript-free} setting.", "published": "2024-12-05 15:50:44", "link": "http://arxiv.org/abs/2412.04266v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CA-SSLR: Condition-Aware Self-Supervised Learning Representation for\n  Generalized Speech Processing", "abstract": "We introduce Condition-Aware Self-Supervised Learning Representation\n(CA-SSLR), a generalist conditioning model broadly applicable to various\nspeech-processing tasks. Compared to standard fine-tuning methods that optimize\nfor downstream models, CA-SSLR integrates language and speaker embeddings from\nearlier layers, making the SSL model aware of the current language and speaker\ncontext. This approach reduces the reliance on input audio features while\npreserving the integrity of the base SSLR. CA-SSLR improves the model's\ncapabilities and demonstrates its generality on unseen tasks with minimal\ntask-specific tuning. Our method employs linear modulation to dynamically\nadjust internal representations, enabling fine-grained adaptability without\nsignificantly altering the original model behavior. Experiments show that\nCA-SSLR reduces the number of trainable parameters, mitigates overfitting, and\nexcels in under-resourced and unseen tasks. Specifically, CA-SSLR achieves a\n10% relative reduction in LID errors, a 37% improvement in ASR CER on the\nML-SUPERB benchmark, and a 27% decrease in SV EER on VoxCeleb-1, demonstrating\nits effectiveness.", "published": "2024-12-05 18:51:10", "link": "http://arxiv.org/abs/2412.04425v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "abstract": "Recent advancements in vision-language models have enhanced performance by\nincreasing the length of visual tokens, making them much longer than text\ntokens and significantly raising computational costs. However, we observe that\nthe visual tokens generated by popular vision encoders, such as CLIP and\nSigLIP, contain significant redundancy. To address this, we introduce\nVisionZip, a simple yet effective method that selects a set of informative\ntokens for input to the language model, reducing visual token redundancy and\nimproving efficiency while maintaining model performance. The proposed\nVisionZip can be widely applied to image and video understanding tasks and is\nwell-suited for multi-turn dialogues in real-world scenarios, where previous\nmethods tend to underperform. Experimental results show that VisionZip\noutperforms the previous state-of-the-art method by at least 5% performance\ngains across nearly all settings. Moreover, our method significantly enhances\nmodel inference speed, improving the prefilling time by 8x and enabling the\nLLaVA-Next 13B model to infer faster than the LLaVA-Next 7B model while\nachieving better results. Furthermore, we analyze the causes of this redundancy\nand encourage the community to focus on extracting better visual features\nrather than merely increasing token length. Our code is available at\nhttps://github.com/dvlab-research/VisionZip .", "published": "2024-12-05 18:59:53", "link": "http://arxiv.org/abs/2412.04467v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Show, Don't Tell: Uncovering Implicit Character Portrayal using LLMs", "abstract": "Tools for analyzing character portrayal in fiction are valuable for writers\nand literary scholars in developing and interpreting compelling stories.\nExisting tools, such as visualization tools for analyzing fictional characters,\nprimarily rely on explicit textual indicators of character attributes. However,\nportrayal is often implicit, revealed through actions and behaviors rather than\nexplicit statements. We address this gap by leveraging large language models\n(LLMs) to uncover implicit character portrayals. We start by generating a\ndataset for this task with greater cross-topic similarity, lexical diversity,\nand narrative lengths than existing narrative text corpora such as TinyStories\nand WritingPrompts. We then introduce LIIPA (LLMs for Inferring Implicit\nPortrayal for Character Analysis), a framework for prompting LLMs to uncover\ncharacter portrayals. LIIPA can be configured to use various types of\nintermediate computation (character attribute word lists, chain-of-thought) to\ninfer how fictional characters are portrayed in the source text. We find that\nLIIPA outperforms existing approaches, and is more robust to increasing\ncharacter counts (number of unique persons depicted) due to its ability to\nutilize full narrative context. Lastly, we investigate the sensitivity of\nportrayal estimates to character demographics, identifying a fairness-accuracy\ntradeoff among methods in our LIIPA framework -- a phenomenon familiar within\nthe algorithmic fairness literature. Despite this tradeoff, all LIIPA variants\nconsistently outperform non-LLM baselines in both fairness and accuracy. Our\nwork demonstrates the potential benefits of using LLMs to analyze complex\ncharacters and to better understand how implicit portrayal biases may manifest\nin narrative texts.", "published": "2024-12-05 19:46:53", "link": "http://arxiv.org/abs/2412.04576v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "SWEPO: Simultaneous Weighted Preference Optimization for Group\n  Contrastive Alignment", "abstract": "Direct Preference Optimization (DPO) has proven effective in aligning large\nlanguage models with human preferences but is often constrained to pairwise\ncomparisons -- overlooking additional positive and negative responses that are\ncommonly available in real-world settings. We propose Simultaneous Weighted\nPreference Optimization (SWEPO), which incorporates multiple responses per\nquery and prioritizes those that deviate most from the average reward. This\ndeviation-based weighting focuses training on the most informative outliers,\nakin to a built-in curriculum. Theoretically, we prove that such\nmulti-preference sampling lowers alignment bias, bounding the expected\ndeviation from the true acceptable-response distribution at a rate of\n$\\mathcal{O}(\\tfrac{1}{\\sqrt{k}})$. Empirically, SWEPO outperforms\nstate-of-the-art baselines on the Ultra-Feedback dataset and demonstrates\nsubstantial improvements over DPO and InfoNCA, yielding boosts of up to $\\sim\n4$% on length-controlled win-rate on AlpacaEval.", "published": "2024-12-05 21:50:22", "link": "http://arxiv.org/abs/2412.04628v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Guidance is All You Need: Temperature-Guided Reasoning in Large Language\n  Models", "abstract": "We present Quasar-1, a novel architecture that introduces temperature-guided\nreasoning to large language models through the Token Temperature Mechanism\n(TTM) and Guided Sequence of Thought (GSoT). Our approach leverages the concept\nof hot and cold tokens, where hot tokens are prioritized for their contextual\nrelevance, while cold tokens provide supplementary information. This dynamic\nmodulation of token importance enables the model to achieve superior logical\nreasoning capabilities compared to traditional chain-of-thought approaches.\nThrough rigorous mathematical analysis, we prove that our temperature-guided\nattention mechanism converges to optimal reasoning paths with exponential\nguarantees. Empirical results show significant improvements in reasoning\naccuracy and computational efficiency across a wide range of tasks, making\nadvanced AI reasoning accessible to a broader range of applications.", "published": "2024-12-05 12:05:41", "link": "http://arxiv.org/abs/2412.06822v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning Enhanced LLMs: A Survey", "abstract": "Reinforcement learning (RL) enhanced large language models (LLMs),\nparticularly exemplified by DeepSeek-R1, have exhibited outstanding\nperformance. Despite the effectiveness in improving LLM capabilities, its\nimplementation remains highly complex, requiring complex algorithms, reward\nmodeling strategies, and optimization techniques. This complexity poses\nchallenges for researchers and practitioners in developing a systematic\nunderstanding of RL-enhanced LLMs. Moreover, the absence of a comprehensive\nsurvey summarizing existing research on RL-enhanced LLMs has limited progress\nin this domain, hindering further advancements.\n  In this work, we are going to make a systematic review of the most up-to-date\nstate of knowledge on RL-enhanced LLMs, attempting to consolidate and analyze\nthe rapidly growing research in this field, helping researchers understand the\ncurrent challenges and advancements. Specifically, we (1) detail the basics of\nRL; (2) introduce popular RL-enhanced LLMs; (3) review researches on two\nwidely-used reward model-based RL techniques: Reinforcement Learning from Human\nFeedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF); and (4)\nexplore Direct Preference Optimization (DPO), a set of methods that bypass the\nreward model to directly use human preference data for aligning LLM outputs\nwith human expectations. We will also point out current challenges and\ndeficiencies of existing methods and suggest some avenues for further\nimprovements. Project page of this work can be found at\nhttps://github.com/ShuheWang1998/Reinforcement-Learning-Enhanced-LLMs-A-Survey.", "published": "2024-12-05 16:10:42", "link": "http://arxiv.org/abs/2412.10400v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Early Dementia Detection Using Multiple Spontaneous Speech Prompts: The\n  PROCESS Challenge", "abstract": "Dementia is associated with various cognitive impairments and typically\nmanifests only after significant progression, making intervention at this stage\noften ineffective. To address this issue, the Prediction and Recognition of\nCognitive Decline through Spontaneous Speech (PROCESS) Signal Processing Grand\nChallenge invites participants to focus on early-stage dementia detection. We\nprovide a new spontaneous speech corpus for this challenge. This corpus\nincludes answers from three prompts designed by neurologists to better capture\nthe cognition of speakers. Our baseline models achieved an F1-score of 55.0% on\nthe classification task and an RMSE of 2.98 on the regression task.", "published": "2024-12-05 16:05:46", "link": "http://arxiv.org/abs/2412.15230v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Missing Melodies: AI Music Generation and its \"Nearly\" Complete Omission\n  of the Global South", "abstract": "Recent advances in generative AI have sparked renewed interest and expanded\npossibilities for music generation. However, the performance and versatility of\nthese systems across musical genres are heavily influenced by the availability\nof training data. We conducted an extensive analysis of over one million hours\nof audio datasets used in AI music generation research and manually reviewed\nmore than 200 papers from eleven prominent AI and music conferences and\norganizations (AAAI, ACM, EUSIPCO, EURASIP, ICASSP, ICML, IJCAI, ISMIR,\nNeurIPS, NIME, SMC) to identify a critical gap in the fair representation and\ninclusion of the musical genres of the Global South in AI research. Our\nfindings reveal a stark imbalance: approximately 86% of the total dataset hours\nand over 93% of researchers focus primarily on music from the Global North.\nHowever, around 40% of these datasets include some form of non-Western music,\ngenres from the Global South account for only 14.6% of the data. Furthermore,\napproximately 51% of the papers surveyed concentrate on symbolic music\ngeneration, a method that often fails to capture the cultural nuances inherent\nin music from regions such as South Asia, the Middle East, and Africa. As AI\nincreasingly shapes the creation and dissemination of music, the significant\nunderrepresentation of music genres in datasets and research presents a serious\nthreat to global musical diversity. We also propose some important steps to\nmitigate these risks and foster a more inclusive future for AI-driven music\ngeneration.", "published": "2024-12-05 12:10:42", "link": "http://arxiv.org/abs/2412.04100v2", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Moto: Latent Motion Token as the Bridging Language for Learning Robot\n  Manipulation from Videos", "abstract": "Recent developments in Large Language Models pre-trained on extensive corpora\nhave shown significant success in various natural language processing tasks\nwith minimal fine-tuning. This success offers new promise for robotics, which\nhas long been constrained by the high cost of action-labeled data. We ask:\ngiven the abundant video data containing interaction-related knowledge\navailable as a rich \"corpus\", can a similar generative pre-training approach be\neffectively applied to enhance robot learning? The key challenge is to identify\nan effective representation for autoregressive pre-training that benefits robot\nmanipulation tasks. Inspired by the way humans learn new skills through\nobserving dynamic environments, we propose that effective robotic learning\nshould emphasize motion-related knowledge, which is closely tied to low-level\nactions and is hardware-agnostic, facilitating the transfer of learned motions\nto actual robot actions. To this end, we introduce Moto, which converts video\ncontent into latent Motion Token sequences by a Latent Motion Tokenizer,\nlearning a bridging \"language\" of motion from videos in an unsupervised manner.\nWe pre-train Moto-GPT through motion token autoregression, enabling it to\ncapture diverse visual motion knowledge. After pre-training, Moto-GPT\ndemonstrates the promising ability to produce semantically interpretable motion\ntokens, predict plausible motion trajectories, and assess trajectory\nrationality through output likelihood. To transfer learned motion priors to\nreal robot actions, we implement a co-fine-tuning strategy that seamlessly\nbridges latent motion token prediction and real robot control. Extensive\nexperiments show that the fine-tuned Moto-GPT exhibits superior robustness and\nefficiency on robot manipulation benchmarks, underscoring its effectiveness in\ntransferring knowledge from video data to downstream visual manipulation tasks.", "published": "2024-12-05 18:57:04", "link": "http://arxiv.org/abs/2412.04445v3", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Comprehensive Audio Query Handling System with Integrated Expert Models\n  and Contextual Understanding", "abstract": "This paper presents a comprehensive chatbot system designed to handle a wide\nrange of audio-related queries by integrating multiple specialized audio\nprocessing models. The proposed system uses an intent classifier, trained on a\ndiverse audio query dataset, to route queries about audio content to expert\nmodels such as Automatic Speech Recognition (ASR), Speaker Diarization, Music\nIdentification, and Text-to-Audio generation. A 3.8 B LLM model then takes\ninputs from an Audio Context Detection (ACD) module extracting audio event\ninformation from the audio and post processes text domain outputs from the\nexpert models to compute the final response to the user. We evaluated the\nsystem on custom audio tasks and MMAU sound set benchmarks. The custom datasets\nwere motivated by target use cases not covered in industry benchmarks and\nincluded ACD-timestamp-QA (Question Answering) as well as ACD-temporal-QA\ndatasets to evaluate timestamp and temporal reasoning questions, respectively.\nFirst we determined that a BERT based Intent Classifier outperforms LLM-fewshot\nintent classifier in routing queries. Experiments further show that our\napproach significantly improves accuracy on some custom tasks compared to\nstate-of-the-art Large Audio Language Models and outperforms models in the 7B\nparameter size range on the sound testset of the MMAU benchmark, thereby\noffering an attractive option for on device deployment.", "published": "2024-12-05 08:56:54", "link": "http://arxiv.org/abs/2412.03980v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Integrated Minimum Mean Squared Error Algorithms for Combined Acoustic\n  Echo Cancellation and Noise Reduction", "abstract": "In many speech recording applications, noise and acoustic echo corrupt the\ndesired speech. Consequently, combined noise reduction (NR) and acoustic echo\ncancellation (AEC) is required. Generally, a cascade approach is followed,\ni.e., the AEC and NR are designed in isolation by selecting a separate signal\nmodel, formulating a separate cost function, and using a separate solution\nstrategy. The AEC and NR are then cascaded one after the other, not accounting\nfor their interaction. In this paper, however, an integrated approach is\nproposed to consider this interaction in a general\nmulti-microphone/multi-loudspeaker setup. Therefore, a single signal model of\neither the microphone signal vector or the extended signal vector, obtained by\nstacking microphone and loudspeaker signals, is selected, a single mean squared\nerror cost function is formulated, and a common solution strategy is used.\nUsing this microphone signal model, a multi channel Wiener filter (MWF) is\nderived. Using the extended signal model, an extended MWF (MWFext) is derived,\nand several equivalent expressions are found, which nevertheless are\ninterpretable as cascade algorithms. Specifically, the MWFext is shown to be\nequivalent to algorithms where the AEC precedes the NR (AEC NR), the NR\nprecedes the AEC (NR-AEC), and the extended NR (NRext) precedes the AEC and\npost-filter (PF) (NRext-AECPF). Under rank-deficiency conditions the MWFext is\nnon-unique, such that this equivalence amounts to the expressions being\nspecific, not necessarily minimum-norm solutions for this MWFext. The practical\nperformances nonetheless differ due to non-stationarities and imperfect\ncorrelation matrix estimation, resulting in the AEC-NR and NRext-AEC-PF\nattaining best overall performance.", "published": "2024-12-05 15:50:47", "link": "http://arxiv.org/abs/2412.04267v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speech Recognition-based Feature Extraction for Enhanced Automatic\n  Severity Classification in Dysarthric Speech", "abstract": "Due to the subjective nature of current clinical evaluation, the need for\nautomatic severity evaluation in dysarthric speech has emerged. DNN models\noutperform ML models but lack user-friendly explainability. ML models offer\nexplainable results at a feature level, but their performance is comparatively\nlower. Current ML models extract various features from raw waveforms to predict\nseverity. However, existing methods do not encompass all dysarthric features\nused in clinical evaluation. To address this gap, we propose a feature\nextraction method that minimizes information loss. We introduce an ASR\ntranscription as a novel feature extraction source. We finetune the ASR model\nfor dysarthric speech, then use this model to transcribe dysarthric speech and\nextract word segment boundary information. It enables capturing finer\npronunciation and broader prosodic features. These features demonstrated an\nimproved severity prediction performance to existing features: balanced\naccuracy of 83.72%.", "published": "2024-12-05 00:12:53", "link": "http://arxiv.org/abs/2412.03784v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Relationships between Keywords and Strong Beats in Lyrical Music", "abstract": "Artificial Intelligence (AI) song generation has emerged as a popular topic,\nyet the focus on exploring the latent correlations between specific lyrical and\nrhythmic features remains limited. In contrast, this pilot study particularly\ninvestigates the relationships between keywords and rhythmically stressed\nfeatures such as strong beats in songs. It focuses on several key elements:\nkeywords or non-keywords, stressed or unstressed syllables, and strong or weak\nbeats, with the aim of uncovering insightful correlations. Experimental results\nindicate that, on average, 80.8\\% of keywords land on strong beats, whereas\n62\\% of non-keywords fall on weak beats. The relationship between stressed\nsyllables and strong or weak beats is weak, revealing that keywords have the\nstrongest relationships with strong beats. Additionally, the lyrics-rhythm\nmatching score, a key matching metric measuring keywords on strong beats and\nnon-keywords on weak beats across various time signatures, is 0.765, while the\nmatching score for syllable types is 0.495. This study demonstrates that word\ntypes strongly align with their corresponding beat types, as evidenced by the\ndistinct patterns, whereas syllable types exhibit a much weaker alignment. This\ndisparity underscores the greater reliability of word types in capturing\nrhythmic structures in music, highlighting their crucial role in effective\nrhythmic matching and analysis. We also conclude that keywords that\nconsistently align with strong beats are more reliable indicators of\nlyrics-rhythm associations, providing valuable insights for AI-driven song\ngeneration through enhanced structural analysis. Furthermore, our development\nof tailored Lyrics-Rhythm Matching (LRM) metrics maximizes lyrical alignments\nwith corresponding beat stresses, and our novel LRM file format captures\ncritical lyrical and rhythmic information without needing original sheet music.", "published": "2024-12-05 14:40:27", "link": "http://arxiv.org/abs/2412.04202v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MoD-ART: Modal Decomposition of Acoustic Radiance Transfer", "abstract": "Modeling late reverberation at interactive speeds is a challenging task when\nmultiple sound sources and listeners are present in the same environment. This\nis especially problematic when the environment is geometrically complex and/or\nfeatures uneven energy absorption (e.g. coupled volumes), because in such cases\nthe late reverberation is dependent on the sound sources' and listeners'\npositions, and therefore must be adapted to their movements in real time. We\npresent a novel approach to the task, named modal decomposition of Acoustic\nRadiance Transfer (MoD-ART), which can handle highly complex scenarios with\nefficiency. The approach is based on the geometrical acoustics method of\nAcoustic Radiance Transfer, from which we extract a set of energy decay modes\nand their positional relationships with sources and listeners. In this paper,\nwe describe the physical and mathematical meaningfulness of MoD-ART,\nhighlighting its advantages and applicability to different scenarios. Through\nan analysis of the method's computational complexity, we show that it compares\nvery favourably with ray-tracing. We also present simulation results showing\nthat MoD-ART can capture multiple decay slopes and flutter echoes.", "published": "2024-12-05 17:44:41", "link": "http://arxiv.org/abs/2412.04534v1", "categories": ["cs.SD", "cs.SY", "eess.AS", "eess.SY"], "primary_category": "cs.SD"}
{"title": "Exploring Transformer-Based Music Overpainting for Jazz Piano Variations", "abstract": "This paper explores transformer-based models for music overpainting, focusing\non jazz piano variations. Music overpainting generates new variations while\npreserving the melodic and harmonic structure of the input. Existing approaches\nare limited by small datasets, restricting scalability and diversity. We\nintroduce VAR4000, a subset of a larger dataset for jazz piano performances,\nconsisting of 4,352 training pairs. Using a semi-automatic pipeline, we\nevaluate two transformer configurations on VAR4000, comparing their performance\nwith the smaller JAZZVAR dataset. Preliminary results show promising\nimprovements in generalisation and performance with the larger dataset\nconfiguration, highlighting the potential of transformer models to scale\neffectively for music overpainting on larger and more diverse datasets.", "published": "2024-12-05 20:48:23", "link": "http://arxiv.org/abs/2412.04610v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
