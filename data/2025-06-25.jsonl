{"title": "MMSearch-R1: Incentivizing LMMs to Search", "abstract": "Robust deployment of large multimodal models (LMMs) in real-world scenarios\nrequires access to external knowledge sources, given the complexity and dynamic\nnature of real-world information. Existing approaches such as\nretrieval-augmented generation (RAG) and prompt engineered search agents rely\non rigid pipelines, often leading to inefficient or excessive search behaviors.\nWe present MMSearch-R1, the first end-to-end reinforcement learning framework\nthat enables LMMs to perform on-demand, multi-turn search in real-world\nInternet environments. Our framework integrates both image and text search\ntools, allowing the model to reason about when and how to invoke them guided by\nan outcome-based reward with a search penalty. To support training, We collect\na multimodal search VQA dataset through a semi-automated pipeline that covers\ndiverse visual and textual knowledge needs and curate a search-balanced subset\nwith both search-required and search-free samples, which proves essential for\nshaping efficient and on-demand search behavior. Extensive experiments on\nknowledge-intensive and info-seeking VQA tasks show that our model not only\noutperforms RAG-based baselines of the same model size, but also matches the\nperformance of a larger RAG-based model while reducing search calls by over\n30%. We further analyze key empirical findings to offer actionable insights for\nadvancing research in multimodal search.", "published": "2025-06-25 17:59:42", "link": "http://arxiv.org/abs/2506.20670v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs", "abstract": "Navigating everyday social situations often requires juggling conflicting\ngoals, such as conveying a harsh truth, maintaining trust, all while still\nbeing mindful of another person's feelings. These value trade-offs are an\nintegral part of human decision-making and language use, however, current tools\nfor interpreting such dynamic and multi-faceted notions of values in LLMs are\nlimited. In cognitive science, so-called \"cognitive models\" provide formal\naccounts of these trade-offs in humans, by modeling the weighting of a\nspeaker's competing utility functions in choosing an action or utterance. In\nthis work, we use a leading cognitive model of polite speech to interpret the\nextent to which LLMs represent human-like trade-offs. We apply this lens to\nsystematically evaluate value trade-offs in two encompassing model settings:\ndegrees of reasoning \"effort\" in frontier black-box models, and RL\npost-training dynamics of open-source models. Our results highlight patterns of\nhigher informational utility than social utility in reasoning models, and in\nopen-source models shown to be stronger in mathematical reasoning. Our findings\nfrom LLMs' training dynamics suggest large shifts in utility values early on in\ntraining with persistent effects of the choice of base model and pretraining\ndata, compared to feedback dataset or alignment method. We show that our method\nis responsive to diverse aspects of the rapidly evolving LLM landscape, with\ninsights for forming hypotheses about other high-level behaviors, shaping\ntraining regimes for reasoning models, and better controlling trade-offs\nbetween values during model training.", "published": "2025-06-25 17:58:12", "link": "http://arxiv.org/abs/2506.20666v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind", "abstract": "As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.", "published": "2025-06-25 17:55:27", "link": "http://arxiv.org/abs/2506.20664v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Memento: Note-Taking for Your Future Self", "abstract": "Large language models (LLMs) excel at reasoning-only tasks, but struggle when\nreasoning must be tightly coupled with retrieval, as in multi-hop question\nanswering. To overcome these limitations, we introduce a prompting strategy\nthat first decomposes a complex question into smaller steps, then dynamically\nconstructs a database of facts using LLMs, and finally pieces these facts\ntogether to solve the question. We show how this three-stage strategy, which we\ncall Memento, can boost the performance of existing prompting strategies across\ndiverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the\nperformance of chain-of-thought (CoT) when all information is provided in\ncontext. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento\nimproves over vanilla CoT-RAG by more than 20 F1 percentage points and over the\nmulti-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the\nchallenging MuSiQue dataset, Memento improves ReAct by more than 3 F1\npercentage points, demonstrating its utility in agentic settings.", "published": "2025-06-25 17:37:59", "link": "http://arxiv.org/abs/2506.20642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation", "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR causal during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.", "published": "2025-06-25 17:35:47", "link": "http://arxiv.org/abs/2506.20639v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models", "abstract": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large\nmodels. Its small memory footprint allows practitioners to adapt large models\nto specific tasks at a fraction of the cost of full finetuning. Different\nmodifications have been proposed to enhance its efficiency by, for example,\nsetting the learning rate, the rank, and the initialization. Another\nimprovement axis is adapter placement strategy: when using LoRA, practitioners\nusually pick module types to adapt with LoRA, such as Query and Key modules.\nFew works have studied the problem of adapter placement, with nonconclusive\nresults: original LoRA paper suggested placing adapters in attention modules,\nwhile other works suggested placing them in the MLP modules. Through an\nintuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a\nlightweight method that allows automatic identification of module types where\nLoRA adapters should be placed, given a pretrained model and a finetuning task.\nWe demonstrate that PLoP consistently outperforms, and in the worst case\ncompetes, with commonly used placement strategies through comprehensive\nexperiments on supervised finetuning and reinforcement learning for reasoning.", "published": "2025-06-25 17:25:02", "link": "http://arxiv.org/abs/2506.20629v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm", "abstract": "Agents based on Large Language Models (LLMs) have demonstrated strong\ncapabilities across a wide range of tasks. However, deploying LLM-based agents\nin high-stakes domains comes with significant safety and ethical risks.\nUnethical behavior by these agents can directly result in serious real-world\nconsequences, including physical harm and financial loss. To efficiently steer\nthe ethical behavior of agents, we frame agent behavior steering as a model\nediting task, which we term Behavior Editing. Model editing is an emerging area\nof research that enables precise and efficient modifications to LLMs while\npreserving their overall capabilities. To systematically study and evaluate\nthis approach, we introduce BehaviorBench, a multi-tier benchmark grounded in\npsychological moral theories. This benchmark supports both the evaluation and\nediting of agent behaviors across a variety of scenarios, with each tier\nintroducing more complex and ambiguous scenarios. We first demonstrate that\nBehavior Editing can dynamically steer agents toward the target behavior within\nspecific scenarios. Moreover, Behavior Editing enables not only\nscenario-specific local adjustments but also more extensive shifts in an\nagent's global moral alignment. We demonstrate that Behavior Editing can be\nused to promote ethical and benevolent behavior or, conversely, to induce\nharmful or malicious behavior. Through comprehensive evaluations on agents\nbased on frontier LLMs, BehaviorBench shows the effectiveness of Behavior\nEditing across different models and scenarios. Our findings offer key insights\ninto a new paradigm for steering agent behavior, highlighting both the promise\nand perils of Behavior Editing.", "published": "2025-06-25 16:51:51", "link": "http://arxiv.org/abs/2506.20606v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs", "abstract": "Recent advancements in large language models (LLMs) have shifted focus toward\nscaling inference-time compute, improving performance without retraining the\nmodel. A common approach is to sample multiple outputs in parallel, and select\none of these as the final output. However, work to date has focused on English\nand a handful of domains such as math and code. In contrast, we are most\ninterested in techniques that generalize across open-ended tasks, formally\nverifiable tasks, and across languages. In this work, we study how to robustly\nscale inference-time compute for open-ended generative tasks in a multilingual,\nmulti-task setting.\n  Our findings show that both sampling strategy based on temperature variation\nand selection strategy must be adapted to account for diverse domains and\nvaried language settings. We evaluate existing selection methods, revealing\nthat strategies effective in English often fail to generalize across languages.\nWe propose novel sampling and selection strategies specifically adapted for\nmultilingual and multi-task inference scenarios, and show they yield notable\ngains across languages and tasks. In particular, our combined sampling and\nselection methods lead to an average +6.8 jump in win-rates for our 8B models\non m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At\nlarger scale, Command-A (111B model) equipped with our methods, shows +9.0\nimprovement in win-rates on the same benchmark with just five samples against\nsingle-sample decoding, a substantial increase at minimal cost. Our results\nunderscore the need for language- and task-aware approaches to inference-time\ncompute, aiming to democratize performance improvements in underrepresented\nlanguages.", "published": "2025-06-25 15:37:53", "link": "http://arxiv.org/abs/2506.20544v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards", "abstract": "Reinforcement learning (RL) is increasingly used to align large language\nmodels (LLMs). Off-policy methods offer greater implementation simplicity and\ndata efficiency than on-policy techniques, but often result in suboptimal\nperformance. In this work, we study the intermediate range of algorithms\nbetween off-policy RL and supervised fine-tuning by analyzing a simple\noff-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with\n$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$\nemphasizes high-reward samples, while raising it penalizes low-reward ones more\nheavily. We first provide a theoretical analysis of this off-policy REINFORCE\nalgorithm, showing that when the baseline $V$ lower-bounds the expected reward,\nthe algorithm enjoys a policy improvement guarantee. Our analysis reveals that\nwhile on-policy updates can safely leverage both positive and negative signals,\noff-policy updates benefit from focusing more on positive rewards than on\nnegative ones. We validate our findings experimentally in a controlled\nstochastic bandit setting and through fine-tuning state-of-the-art LLMs on\nreasoning tasks.", "published": "2025-06-25 15:07:16", "link": "http://arxiv.org/abs/2506.20520v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling", "abstract": "Different base language model families, such as Llama and Qwen, exhibit\ndivergent behaviors during post-training with reinforcement learning (RL),\nespecially on reasoning-intensive tasks. What makes a base language model\nsuitable for reinforcement learning? Gaining deeper insight into this question\nis essential for developing RL-scalable foundation models of the next\ngeneration. In this work, we investigate how mid-training strategies shape RL\ndynamics, focusing on two representative model families: Qwen and Llama. Our\nstudy reveals that (1) high-quality mathematical corpora, such as\nMegaMath-Web-Pro, significantly improve both base model and RL performance,\nwhile existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further\nadding QA-style data, particularly long chain-of-thought (CoT) reasoning\nexamples, enhances RL outcomes, and instruction data further unlocks this\neffect; (3) while long-CoT improves reasoning depth, it can also induce\nverbosity of model responses and unstability of RL training, underscoring the\nimportance of data formatting; (4) scaling mid-training consistently leads to\nstronger downstream RL performance. Building on these insights, we introduce a\ntwo-stage mid-training strategy, Stable-then-Decay, in which base models are\nfirst trained on 200B tokens with a constant learning rate, followed by 20B\ntokens across three CoT-focused branches with learning rate decay. This yields\nOctoThinker, a family of models demonstrating strong RL compatibility and\nclosing the performance gap with more RL-friendly model families, i.e., Qwen.\nWe hope our work will help shape pre-training strategies for foundation models\nin the RL era. To support further research, we release our open-source models\nalong with a curated math reasoning-intensive corpus of over 70 billion tokens\n(i.e., MegaMath-Web-Pro-Max).", "published": "2025-06-25 14:58:13", "link": "http://arxiv.org/abs/2506.20512v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "abstract": "Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.", "published": "2025-06-25 14:41:13", "link": "http://arxiv.org/abs/2506.20495v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Counterfactual Influence as a Distributional Quantity", "abstract": "Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.", "published": "2025-06-25 14:25:11", "link": "http://arxiv.org/abs/2506.20481v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching", "abstract": "Large language models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. However, such impressive capability typically\ncomes with a substantial model size, which presents significant challenges in\ndeployment and inference. While structured pruning of model parameters offers a\npromising way to reduce computational costs at deployment time, current methods\nprimarily focus on single model pruning. In this work, we develop a novel\nstrategy to compress models by strategically combining or merging layers from\nfinetuned model variants, which preserves the original model's abilities by\naggregating capabilities accentuated in different finetunes. We pose the\noptimal tailoring of these LLMs as a zero-order optimization problem, adopting\na search space that supports three different operations: (1) Layer removal, (2)\nLayer selection from different candidate models, and (3) Layer merging. Our\nexperiments demonstrate that this approach leads to competitive model pruning,\nfor example, for the Llama2-13B model families, our compressed models maintain\napproximately 97.3\\% of the original performance while removing $\\sim25\\%$ of\nparameters, significantly outperforming previous state-of-the-art methods. The\ncode is available at https://github.com/Guinan-Su/auto-merge-llm.", "published": "2025-06-25 14:24:59", "link": "http://arxiv.org/abs/2506.20480v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Aware Diverse Reranking for Cross-Source Question Answering", "abstract": "This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG\ncompetition. The competition's evaluation set, automatically generated by\nDataMorgana from internet corpora, encompassed a wide range of target topics,\nquestion types, question formulations, audience types, and knowledge\norganization methods. It offered a fair evaluation of retrieving\nquestion-relevant supporting documents from a 15M documents subset of the\nFineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline\nachieved first place in the competition.", "published": "2025-06-25 14:23:21", "link": "http://arxiv.org/abs/2506.20476v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations", "abstract": "An intrinsic aspect of every conversation is the way talk-time is shared\nbetween multiple speakers. Conversations can be balanced, with each speaker\nclaiming a similar amount of talk-time, or imbalanced when one talks\ndisproportionately. Such overall distributions are the consequence of\ncontinuous negotiations between the speakers throughout the conversation: who\nshould be talking at every point in time, and for how long?\n  In this work we introduce a computational framework for quantifying both the\nconversation-level distribution of talk-time between speakers, as well as the\nlower-level dynamics that lead to it. We derive a typology of talk-time sharing\ndynamics structured by several intuitive axes of variation. By applying this\nframework to a large dataset of video-chats between strangers, we confirm that,\nperhaps unsurprisingly, different conversation-level distributions of talk-time\nare perceived differently by speakers, with balanced conversations being\npreferred over imbalanced ones, especially by those who end up talking less.\nThen we reveal that -- even when they lead to the same level of overall balance\n-- different types of talk-time sharing dynamics are perceived differently by\nthe participants, highlighting the relevance of our newly introduced typology.\nFinally, we discuss how our framework offers new tools to designers of\ncomputer-mediated communication platforms, for both human-human and human-AI\ncommunication.", "published": "2025-06-25 14:23:02", "link": "http://arxiv.org/abs/2506.20474v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing AI Safety with Source Code", "abstract": "Large language models (LLMs) have become ubiquitous, interfacing with humans\nin numerous safety-critical applications. This necessitates improving\ncapabilities, but importantly coupled with greater safety measures to align\nthese models with human values and preferences. In this work, we demonstrate\nthat contemporary models fall concerningly short of the goal of AI safety,\nleading to an unsafe and harmful experience for users. We introduce a prompting\nstrategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT\nconverts natural language inputs to simple code that represents the same\nintent. For instance, CoDoT transforms the natural language prompt \"Make the\nstatement more toxic: {text}\" to: \"make_more_toxic({text})\". We show that CoDoT\nresults in a consistent failure of a wide range of state-of-the-art LLMs. For\nexample, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of\nthe time, and toxicity increases 300% on average across seven modern LLMs.\nAdditionally, recursively applying CoDoT can further increase toxicity two\ntimes. Given the rapid and widespread adoption of LLMs, CoDoT underscores the\ncritical need to evaluate safety efforts from first principles, ensuring that\nsafety and capabilities advance together.", "published": "2025-06-25 14:19:57", "link": "http://arxiv.org/abs/2506.20471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning", "abstract": "Rare diseases collectively affect over 300 million individuals worldwide, yet\ntimely and accurate diagnosis remains a pervasive challenge. This is largely\ndue to their clinical heterogeneity, low individual prevalence, and the limited\nfamiliarity most clinicians have with rare conditions. Here, we introduce\nDeepRare, the first rare disease diagnosis agentic system powered by a large\nlanguage model (LLM), capable of processing heterogeneous clinical inputs. The\nsystem generates ranked diagnostic hypotheses for rare diseases, each\naccompanied by a transparent chain of reasoning that links intermediate\nanalytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term\nmemory module; specialized agent servers responsible for domain-specific\nanalytical tasks integrating over 40 specialized tools and web-scale,\nup-to-date medical knowledge sources, ensuring access to the most current\nclinical information. This modular and scalable design enables complex\ndiagnostic reasoning while maintaining traceability and adaptability. We\nevaluate DeepRare on eight datasets. The system demonstrates exceptional\ndiagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013\ndiseases. In HPO-based evaluations, DeepRare significantly outperforms other 15\nmethods, like traditional bioinformatics diagnostic tools, LLMs, and other\nagentic systems, achieving an average Recall@1 score of 57.18% and surpassing\nthe second-best method (Reasoning LLM) by a substantial margin of 23.79\npercentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at\nRecall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of\nreasoning chains by clinical experts achieves 95.40% agreements. Furthermore,\nthe DeepRare system has been implemented as a user-friendly web application\nhttp://raredx.cn/doctor.", "published": "2025-06-25 13:42:26", "link": "http://arxiv.org/abs/2506.20430v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.CL"}
{"title": "TAPS: Tool-Augmented Personalisation via Structured Tagging", "abstract": "Recent advancements in tool-augmented large language models have enabled them\nto interact with external tools, enhancing their ability to perform complex\nuser tasks. However, existing approaches overlook the role of personalisation\nin guiding tool use. This work investigates how user preferences can be\neffectively integrated into goal-oriented dialogue agents. Through extensive\nanalysis, we identify key weaknesses in the ability of LLMs to personalise tool\nuse. To this end, we introduce \\name, a novel solution that enhances\npersonalised tool use by leveraging a structured tagging tool and an\nuncertainty-based tool detector. TAPS significantly improves the ability of\nLLMs to incorporate user preferences, achieving the new state-of-the-art for\nopen source models on the NLSI task.", "published": "2025-06-25 13:24:46", "link": "http://arxiv.org/abs/2506.20409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content", "abstract": "We introduce Biomed-Enriched, a biomedical text dataset constructed from\nPubMed via a two-stage annotation process. In the first stage, a large language\nmodel annotates 400K paragraphs from PubMed scientific articles, assigning\nscores for their type (review, study, clinical case, other), domain (clinical,\nbiomedical, other), and educational quality. The educational quality score\n(rated 1 to 5) estimates how useful a paragraph is for college-level learning.\nThese annotations are then used to fine-tune a small language model, which\npropagates the labels across the full PMC-OA corpus. The resulting metadata\nallows us to extract refined subsets, including 2M clinical case paragraphs\nwith over 450K high-quality ones from articles with commercial-use licenses,\nand to construct several variants via quality filtering and domain upsampling.\nClinical text is typically difficult to access due to privacy constraints, as\nhospital records cannot be publicly shared. Hence, our dataset provides an\nalternative large-scale, openly available collection of clinical cases from\nPubMed, making it a valuable resource for biomedical and clinical NLP.\nPreliminary continual-pretraining experiments with OLMo2 suggest these curated\nsubsets enable targeted improvements, with clinical upsampling boosting\nperformance by ~5% on MMLU ProfMed and educational quality filtering improving\nMedQA and MedMCQA by ~1%. Combinations of these techniques led to faster\nconvergence, reaching same performance with a third of training tokens,\nindicating potential for more efficient and effective biomedical pretraining\nstrategies.", "published": "2025-06-25 11:30:25", "link": "http://arxiv.org/abs/2506.20331v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents", "abstract": "Robust Document Layout Analysis (DLA) is critical for the automated\nprocessing and understanding of historical documents with complex page\norganizations. This paper benchmarks five state-of-the-art object detection\narchitectures on three annotated datasets representing a spectrum of\ncodicological complexity: The e-NDP, a corpus of Parisian medieval registers\n(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval\nand modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated\nbooks of hours (ca.13th-16th centuries). We evaluate two Transformer-based\nmodels (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and\nYOLO-World). Our findings reveal significant performance variations dependent\non model architecture, data set characteristics, and bounding box\nrepresentation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results\n(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on\nthe more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB\nsignificantly outperforms all other models (0.564 and 0.568, respectively).\nThis study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)\nis not a minor refinement but a fundamental requirement for accurately modeling\nthe non-Cartesian nature of historical manuscripts. We conclude that a key\ntrade-off exists between the global context awareness of Transformers, ideal\nfor structured layouts, and the superior generalization of CNN-OBB models for\nvisually diverse and complex documents.", "published": "2025-06-25 11:14:04", "link": "http://arxiv.org/abs/2506.20326v1", "categories": ["cs.CV", "cs.CL", "cs.DB"], "primary_category": "cs.CV"}
{"title": "FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment", "abstract": "Automated fundus image quality assessment (FIQA) remains a challenge due to\nvariations in image acquisition and subjective expert evaluations. We introduce\nFundaQ-8, a novel expert-validated framework for systematically assessing\nfundus image quality using eight critical parameters, including field coverage,\nanatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a\nstructured scoring reference, we develop a ResNet18-based regression model to\npredict continuous quality scores in the 0 to 1 range. The model is trained on\n1800 fundus images from real-world clinical sources and Kaggle datasets, using\ntransfer learning, mean squared error optimization, and standardized\npreprocessing. Validation against the EyeQ dataset and statistical analyses\nconfirm the framework's reliability and clinical interpretability.\nIncorporating FundaQ-8 into deep learning models for diabetic retinopathy\ngrading also improves diagnostic robustness, highlighting the value of\nquality-aware training in real-world screening applications.", "published": "2025-06-25 10:28:53", "link": "http://arxiv.org/abs/2506.20303v1", "categories": ["eess.IV", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models", "abstract": "With rapidly evolving media narratives, it has become increasingly critical\nto not just extract narratives from a given corpus but rather investigate, how\nthey develop over time. While popular narrative extraction methods such as\nLarge Language Models do well in capturing typical narrative elements or even\nthe complex structure of a narrative, applying them to an entire corpus comes\nwith obstacles, such as a high financial or computational cost. We propose a\ncombination of the language understanding capabilities of Large Language Models\nwith the large scale applicability of topic models to dynamically model\nnarrative shifts across time using the Narrative Policy Framework. We apply a\ntopic model and a corresponding change point detection method to find changes\nthat concern a specific topic of interest. Using this model, we filter our\ncorpus for documents that are particularly representative of that change and\nfeed them into a Large Language Model that interprets the change that happened\nin an automated fashion and distinguishes between content and narrative shifts.\nWe employ our pipeline on a corpus of The Wall Street Journal news paper\narticles from 2009 to 2023. Our findings indicate that a Large Language Model\ncan efficiently extract a narrative shift if one exists at a given point in\ntime, but does not perform as well when having to decide whether a shift in\ncontent or a narrative shift took place.", "published": "2025-06-25 09:25:15", "link": "http://arxiv.org/abs/2506.20269v1", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue", "abstract": "Detecting miscommunication in human-robot interaction is a critical function\nfor maintaining user engagement and trust. While humans effortlessly detect\ncommunication errors in conversations through both verbal and non-verbal cues,\nrobots face significant challenges in interpreting non-verbal feedback, despite\nadvances in computer vision for recognizing affective expressions. This\nresearch evaluates the effectiveness of machine learning models in detecting\nmiscommunications in robot dialogue. Using a multi-modal dataset of 240\nhuman-robot conversations, where four distinct types of conversational failures\nwere systematically introduced, we assess the performance of state-of-the-art\ncomputer vision models. After each conversational turn, users provided feedback\non whether they perceived an error, enabling an analysis of the models' ability\nto accurately detect robot mistakes. Despite using state-of-the-art models, the\nperformance barely exceeds random chance in identifying miscommunication, while\non a dataset with more expressive emotional content, they successfully\nidentified confused states. To explore the underlying cause, we asked human\nraters to do the same. They could also only identify around half of the induced\nmiscommunications, similarly to our model. These results uncover a fundamental\nlimitation in identifying robot miscommunications in dialogue: even when users\nperceive the induced miscommunication as such, they often do not communicate\nthis to their robotic conversation partner. This knowledge can shape\nexpectations of the performance of computer vision models and can help\nresearchers to design better human-robot conversations by deliberately\neliciting feedback where needed.", "published": "2025-06-25 09:25:04", "link": "http://arxiv.org/abs/2506.20268v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Language Modeling by Language Models", "abstract": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "published": "2025-06-25 08:46:10", "link": "http://arxiv.org/abs/2506.20249v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment", "abstract": "Automatic fluency assessment (AFA) remains challenging, particularly in\ncapturing speech rhythm, pauses, and disfluencies in non-native speakers. We\nintroduce a chunk-based approach integrating self-supervised learning (SSL)\nmodels (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths\nin phonetic, prosodic, and noisy speech modeling, with a hierarchical\nCNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero\nvoice activity detection (Silero-VAD), enabling fine-grained temporal analysis\nwhile mitigating over-segmentation artifacts. SSL embeddings are fused via a\nlearnable weighted mechanism, balancing acoustic and linguistic features, and\nenriched with chunk-level fluency markers (e.g., speech rate, pause durations,\nn-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies\nacross chunks. Evaluated on Avalinguo and Speechocean762, our approach improves\nF1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines\non Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on\nAvalinguo, surpassing Pyannote.audio-based segmentation baselines. These\nfindings highlight chunk-based multi-SSL fusion for robust fluency evaluation,\nthough future work should explore generalization to dialects with irregular\nprosody.", "published": "2025-06-25 08:39:22", "link": "http://arxiv.org/abs/2506.20243v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Language Models through Structured Reasoning", "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural\nlanguage processing and automated decision-making. However, these models still\nencounter difficulties when performing complex reasoning tasks involving\nlogical deduction and systematic planning, primarily due to their reliance on\nimplicit statistical relationships without structured knowledge\nrepresentation.Inspired by cognitive science and neurosymbolic AI, we introduce\na novel approach to enhance LLMs through explicit structured reasoning. First,\nwe convert unstructured data into structured formats by explicitly annotating\nreasoning steps. We then employ this structured dataset to train LLMs through\nSupervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning\ncapabilities of LLMs using Group Relative Policy Optimization (GRPO),\nincorporating two innovative algorithms--MAX-Flow and Longest Common\nSubsequence (LCS)--which notably improve reasoning effectiveness and reduce\ncomputational complexity. Experimental results from fine-tuning a\nDeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust\nperformance across various scenarios, and improved compatibility with\noptimization techniques, validating the efficacy of structured reasoning\nintegration in LLMs.", "published": "2025-06-25 08:36:12", "link": "http://arxiv.org/abs/2506.20241v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems", "abstract": "In the realm of Natural Language Processing (NLP), common approaches for\nhandling human disagreement consist of aggregating annotators' viewpoints to\nestablish a single ground truth. However, prior studies show that disregarding\nindividual opinions can lead can lead to the side effect of underrepresenting\nminority perspectives, especially in subjective tasks, where annotators may\nsystematically disagree because of their preferences. Recognizing that labels\nreflect the diverse backgrounds, life experiences, and values of individuals,\nthis study proposes a new multi-perspective approach using soft labels to\nencourage the development of the next generation of perspective aware models,\nmore inclusive and pluralistic. We conduct an extensive analysis across diverse\nsubjective text classification tasks, including hate speech, irony, abusive\nlanguage, and stance detection, to highlight the importance of capturing human\ndisagreements, often overlooked by traditional aggregation methods. Results\nshow that the multi-perspective approach not only better approximates human\nlabel distributions, as measured by Jensen-Shannon Divergence (JSD), but also\nachieves superior classification performance (higher F1 scores), outperforming\ntraditional approaches. However, our approach exhibits lower confidence in\ntasks like irony and stance detection, likely due to the inherent subjectivity\npresent in the texts. Lastly, leveraging Explainable AI (XAI), we explore model\nuncertainty and uncover meaningful insights into model predictions.", "published": "2025-06-25 07:53:36", "link": "http://arxiv.org/abs/2506.20209v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation", "abstract": "In this paper, we compare Czech-specific and multilingual sentence embedding\nmodels through intrinsic and extrinsic evaluation paradigms. For intrinsic\nevaluation, we employ Costra, a complex sentence transformation dataset, and\nseveral Semantic Textual Similarity (STS) benchmarks to assess the ability of\nthe embeddings to capture linguistic phenomena such as semantic similarity,\ntemporal aspects, and stylistic variations. In the extrinsic evaluation, we\nfine-tune each embedding model using COMET-based metrics for machine\ntranslation evaluation.\n  Our experiments reveal an interesting disconnect: models that excel in\nintrinsic semantic similarity tests do not consistently yield superior\nperformance on downstream translation evaluation tasks. Conversely, models with\nseemingly over-smoothed embedding spaces can, through fine-tuning, achieve\nexcellent results. These findings highlight the complex relationship between\nsemantic property probes and downstream task, emphasizing the need for more\nresearch into 'operationalizable semantics' in sentence embeddings, or more\nin-depth downstream tasks datasets (here translation evaluation)", "published": "2025-06-25 07:46:17", "link": "http://arxiv.org/abs/2506.20203v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?", "abstract": "Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.", "published": "2025-06-25 07:39:19", "link": "http://arxiv.org/abs/2506.20199v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees", "abstract": "Uncertainty quantification (UQ) for foundation models is essential to\nidentify and mitigate potential hallucinations in automatically generated text.\nHowever, heuristic UQ approaches lack formal guarantees for key metrics such as\nthe false discovery rate (FDR) in selective prediction. Previous work adopts\nthe split conformal prediction (SCP) framework to ensure desired coverage of\nadmissible answers by constructing prediction sets, but these sets often\ncontain incorrect candidates, limiting their practical utility. To address\nthis, we propose COIN, an uncertainty-guarding selection framework that\ncalibrates statistically valid thresholds to filter a single generated answer\nper question under user-specified FDR constraints. COIN estimates the empirical\nerror rate on a calibration set and applies confidence interval methods such as\nClopper-Pearson to establish a high-probability upper bound on the true error\nrate (i.e., FDR). This enables the selection of the largest uncertainty\nthreshold that ensures FDR control on test data while significantly increasing\nsample retention. We demonstrate COIN's robustness in risk control, strong\ntest-time power in retaining admissible answers, and predictive efficiency\nunder limited calibration data across both general and multimodal text\ngeneration tasks. Furthermore, we show that employing alternative upper bound\nconstructions and UQ strategies can further boost COIN's power performance,\nwhich underscores its extensibility and adaptability to diverse application\nscenarios.", "published": "2025-06-25 07:04:49", "link": "http://arxiv.org/abs/2506.20178v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs", "abstract": "Multivariate time series forecasting requires models to simultaneously\ncapture variable-wise structural dependencies and generalize across diverse\ntasks. While structural encoders are effective in modeling feature\ninteractions, they lack the capacity to support semantic-level reasoning or\ntask adaptation. Conversely, large language models (LLMs) possess strong\ngeneralization capabilities but remain incompatible with raw time series\ninputs. This gap limits the development of unified, transferable prediction\nsystems. Therefore, we introduce SEED, a structural encoder for\nembedding-driven decoding, which integrates four stages: a token-aware encoder\nfor patch extraction, a projection module that aligns patches with language\nmodel embeddings, a semantic reprogramming mechanism that maps patches to\ntask-aware prototypes, and a frozen language model for prediction. This modular\narchitecture decouples representation learning from inference, enabling\nefficient alignment between numerical patterns and semantic reasoning.\nEmpirical results demonstrate that the proposed method achieves consistent\nimprovements over strong baselines, and comparative studies on various datasets\nconfirm SEED's role in addressing the structural-semantic modeling gap.", "published": "2025-06-25 06:40:14", "link": "http://arxiv.org/abs/2506.20167v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control", "abstract": "Large reasoning models (LRMs) achieve impressive reasoning capabilities by\ngenerating lengthy chain-of-thoughts, but this \"overthinking\" incurs high\nlatency and cost without commensurate accuracy gains. In this work, we\nintroduce AALC, a lightweight, accuracy-aware length reward integrated into\nreinforcement learning that dynamically balances correctness and brevity during\ntraining. By incorporating validation accuracy into the reward and employing a\nsmooth, dynamically scheduled length penalty, AALC delays length penalty until\ntarget performance is met. Through extensive experiments across standard and\nout-of-distribution math benchmarks, we show that our approach reduces response\nlength by over 50% while maintaining or even improving the original accuracy.\nFurthermore, qualitative analysis reveals that our method curbs redundant\nreasoning patterns such as excessive subgoal setting and verification, leading\nto structurally refined outputs rather than naive truncation. We also identify\nthat efficiency gains are accompanied by reduced interpretability: models\ntrained with AALC omit some narrative framing and explanatory context. These\nfindings highlight the potential of reward-based strategies to guide LRMs\ntoward more efficient, generalizable reasoning paths.", "published": "2025-06-25 06:29:18", "link": "http://arxiv.org/abs/2506.20160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation", "abstract": "RAG systems enhance LLMs by incorporating external knowledge, which is\ncrucial for domains that demand factual accuracy and up-to-date information.\nHowever, evaluating the multifaceted quality of RAG outputs, spanning aspects\nsuch as contextual coherence, query relevance, factual correctness, and\ninformational completeness, poses significant challenges. Existing evaluation\nmethods often rely on simple lexical overlap metrics, which are inadequate for\ncapturing these nuances, or involve complex multi-stage pipelines with\nintermediate steps like claim extraction or require finetuning specialized\njudge models, hindering practical efficiency. To address these limitations, we\npropose CCRS (Contextual Coherence and Relevance Score), a novel suite of five\nmetrics that utilizes a single, powerful, pretrained LLM as a zero-shot,\nend-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance\n(QR), Information Density (ID), Answer Correctness (AC), and Information Recall\n(IR). We apply CCRS to evaluate six diverse RAG system configurations on the\nchallenging BioASQ dataset. Our analysis demonstrates that CCRS effectively\ndiscriminates between system performances, confirming, for instance, that the\nMistral-7B reader outperforms Llama variants. We provide a detailed analysis of\nCCRS metric properties, including score distributions, convergent/discriminant\nvalidity, tie rates, population statistics, and discriminative power. Compared\nto the complex RAGChecker framework, CCRS offers comparable or superior\ndiscriminative power for key aspects like recall and faithfulness, while being\nsignificantly more computationally efficient. CCRS thus provides a practical,\ncomprehensive, and efficient framework for evaluating and iteratively improving\nRAG systems.", "published": "2025-06-25 04:49:03", "link": "http://arxiv.org/abs/2506.20128v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests", "abstract": "Evaluating the abilities of learners is a fundamental objective in the field\nof education. In particular, there is an increasing need to assess higher-order\nabilities such as expressive skills and logical thinking. Constructed-response\ntests such as short-answer and essay-based questions have become widely used as\na method to meet this demand. Although these tests are effective, they require\nsubstantial manual grading, making them both labor-intensive and costly. Item\nresponse theory (IRT) provides a promising solution by enabling the estimation\nof ability from incomplete score data, where human raters grade only a subset\nof answers provided by learners across multiple test items. However, the\naccuracy of ability estimation declines as the proportion of missing scores\nincreases. Although data augmentation techniques for imputing missing scores\nhave been explored in order to address this limitation, they often struggle\nwith inaccuracy for sparse or heterogeneous data. To overcome these challenges,\nthis study proposes a novel method for imputing missing scores by leveraging\nautomated scoring technologies for accurate IRT-based ability estimation. The\nproposed method achieves high accuracy in ability estimation while markedly\nreducing manual grading workload.", "published": "2025-06-25 04:17:57", "link": "http://arxiv.org/abs/2506.20119v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection", "abstract": "Background: The positive predictive value (PPV) of large language model\n(LLM)-based proofreading for radiology reports is limited due to the low error\nprevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV\nand reduces operational costs compared with baseline approaches. Materials and\nMethods: A retrospective analysis was performed on 1,000 consecutive radiology\nreports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III\ndatabase. Two external datasets (CheXpert and Open-i) were validation sets.\nThree LLM frameworks were tested: (1) single-prompt detector; (2) extractor\nplus detector; and (3) extractor, detector, and false-positive verifier.\nPrecision was measured by PPV and absolute true positive rate (aTPR).\nEfficiency was calculated from model inference charges and reviewer\nremuneration. Statistical significance was tested using cluster bootstrap,\nexact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV\nincreased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,\nFramework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.\nbaselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per\n1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and\nUSD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.\nHuman-reviewed reports decreased from 192 to 88. External validation supported\nFramework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR\n(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and\nreduced operational costs, maintaining detection performance, providing an\neffective strategy for AI-assisted radiology report quality assurance.", "published": "2025-06-25 04:02:29", "link": "http://arxiv.org/abs/2506.20112v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations", "abstract": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io", "published": "2025-06-25 03:07:54", "link": "http://arxiv.org/abs/2506.20100v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models", "abstract": "We propose PSALM-V, the first autonomous neuro-symbolic learning system able\nto induce symbolic action semantics (i.e., pre- and post-conditions) in visual\nenvironments through interaction. PSALM-V bootstraps reliable symbolic planning\nwithout expert action definitions, using LLMs to generate heuristic plans and\ncandidate symbolic semantics. Previous work has explored using large language\nmodels to generate action semantics for Planning Domain Definition Language\n(PDDL)-based symbolic planners. However, these approaches have primarily\nfocused on text-based domains or relied on unrealistic assumptions, such as\naccess to a predefined problem file, full observability, or explicit error\nmessages. By contrast, PSALM-V dynamically infers PDDL problem files and domain\naction semantics by analyzing execution outcomes and synthesizing possible\nerror explanations. The system iteratively generates and executes plans while\nmaintaining a tree-structured belief over possible action semantics for each\naction, iteratively refining these beliefs until a goal state is reached.\nSimulated experiments of task completion in ALFRED demonstrate that PSALM-V\nincreases the plan success rate from 37% (Claude-3.7) to 74% in partially\nobserved setups. Results on two 2D game environments, RTFM and Overcooked-AI,\nshow that PSALM-V improves step efficiency and succeeds in domain induction in\nmulti-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions\nfor real-world robot BlocksWorld tasks, despite low-level manipulation failures\nfrom the robot.", "published": "2025-06-25 02:44:20", "link": "http://arxiv.org/abs/2506.20097v1", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset", "abstract": "Time-series data are critical in diverse applications, such as industrial\nmonitoring, medical diagnostics, and climate research. However, effectively\nintegrating these high-dimensional temporal signals with natural language for\ndynamic, interactive tasks remains a significant challenge. To address this, we\nintroduce the Time-Series Question Answering (Time-Series QA) task and release\nEngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset\ndesigned to capture complex interactions between time-series signals and\nnatural language. Building on this resource, we propose the Instruct Time\nTransformer (ITFormer), a novel framework that bridges time-series encoders\nwith frozen large language models (LLMs). ITFormer effectively extracts,\naligns, and fuses temporal and textual features, achieving a strong improvement\nin QA accuracy over strong baselines with fewer than 1\\% additional trainable\nparameters. By combining computational efficiency with robust cross-modal\nmodeling, our work establishes a adaptable paradigm for integrating temporal\ndata with natural language, paving the way for new research and applications in\nmulti-modal AI. More details about the project, including datasets and code,\nare available at: https://pandalin98.github.io/itformer_site/", "published": "2025-06-25 02:33:47", "link": "http://arxiv.org/abs/2506.20093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "abstract": "Integrating compositional and symbolic properties into current distributional\nsemantic spaces can enhance the interpretability, controllability,\ncompositionality, and generalisation capabilities of Transformer-based\nauto-regressive language models (LMs). In this survey, we offer a novel\nperspective on latent space geometry through the lens of compositional\nsemantics, a direction we refer to as \\textit{semantic representation\nlearning}. This direction enables a bridge between symbolic and distributional\nsemantics, helping to mitigate the gap between them. We review and compare\nthree mainstream autoencoder architectures-Variational AutoEncoder (VAE),\nVector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the\ndistinctive latent geometries they induce in relation to semantic structure and\ninterpretability.", "published": "2025-06-25 01:48:18", "link": "http://arxiv.org/abs/2506.20083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "abstract": "Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant.Based on our discoveries, we propose SACL, a framework that enriches\ntextual information and reduces bias by augmenting code or structural knowledge\nwith semantic information. Extensive experiments show that SACL substantially\nimproves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /\nMBPP / SWE-Bench-Lite), which also leads to better code generation performance\n(e.g., by 4.88% Pass@1 on HumanEval).", "published": "2025-06-25 01:44:28", "link": "http://arxiv.org/abs/2506.20081v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs", "abstract": "Spatio-temporal data mining plays a pivotal role in informed decision making\nacross diverse domains. However, existing models are often restricted to narrow\ntasks, lacking the capacity for multi-task inference and complex long-form\nreasoning that require generation of in-depth, explanatory outputs. These\nlimitations restrict their applicability to real-world, multi-faceted decision\nscenarios. In this work, we introduce STReason, a novel framework that\nintegrates the reasoning strengths of large language models (LLMs) with the\nanalytical capabilities of spatio-temporal models for multi-task inference and\nexecution. Without requiring task-specific finetuning, STReason leverages\nin-context learning to decompose complex natural language queries into modular,\ninterpretable programs, which are then systematically executed to generate both\nsolutions and detailed rationales. To facilitate rigorous evaluation, we\nconstruct a new benchmark dataset and propose a unified evaluation framework\nwith metrics specifically designed for long-form spatio-temporal reasoning.\nExperimental results show that STReason significantly outperforms advanced LLM\nbaselines across all metrics, particularly excelling in complex,\nreasoning-intensive spatio-temporal scenarios. Human evaluations further\nvalidate STReason's credibility and practical utility, demonstrating its\npotential to reduce expert workload and broaden the applicability to real-world\nspatio-temporal tasks. We believe STReason provides a promising direction for\ndeveloping more capable and generalizable spatio-temporal reasoning systems.", "published": "2025-06-25 00:55:34", "link": "http://arxiv.org/abs/2506.20073v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Disentangled representations of microscopy images", "abstract": "Microscopy image analysis is fundamental for different applications, from\ndiagnosis to synthetic engineering and environmental monitoring. Modern\nacquisition systems have granted the possibility to acquire an escalating\namount of images, requiring a consequent development of a large collection of\ndeep learning-based automatic image analysis methods. Although deep neural\nnetworks have demonstrated great performance in this field, interpretability,\nan essential requirement for microscopy image analysis, remains an open\nchallenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology\nto enhance model interpretability for microscopy image classification.\nExploiting benchmark datasets from three different microscopic image domains\n(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based\non transferring a representation learnt from synthetic data, can provide a good\ntrade-off between accuracy and interpretability in this domain.", "published": "2025-06-25 17:44:37", "link": "http://arxiv.org/abs/2506.20649v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards Community-Driven Agents for Machine Learning Engineering", "abstract": "Large language model-based machine learning (ML) agents have shown great\npromise in automating ML research. However, existing agents typically operate\nin isolation on a given research problem, without engaging with the broader\nresearch community, where human researchers often gain insights and contribute\nby sharing knowledge. To bridge this gap, we introduce MLE-Live, a live\nevaluation framework designed to assess an agent's ability to communicate with\nand leverage collective knowledge from a simulated Kaggle research community.\nBuilding on this framework, we propose CoMind, a novel agent that excels at\nexchanging insights and developing novel solutions within a community context.\nCoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%\nhuman competitors on average across four ongoing Kaggle competitions. Our code\nis released at https://github.com/comind-ml/CoMind.", "published": "2025-06-25 17:36:02", "link": "http://arxiv.org/abs/2506.20640v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Define-ML: An Approach to Ideate Machine Learning-Enabled Systems", "abstract": "[Context] The increasing adoption of machine learning (ML) in software\nsystems demands specialized ideation approaches that address ML-specific\nchallenges, including data dependencies, technical feasibility, and alignment\nbetween business objectives and probabilistic system behavior. Traditional\nideation methods like Lean Inception lack structured support for these ML\nconsiderations, which can result in misaligned product visions and unrealistic\nexpectations. [Goal] This paper presents Define-ML, a framework that extends\nLean Inception with tailored activities - Data Source Mapping, Feature-to-Data\nSource Mapping, and ML Mapping - to systematically integrate data and technical\nconstraints into early-stage ML product ideation. [Method] We developed and\nvalidated Define-ML following the Technology Transfer Model, conducting both\nstatic validation (with a toy problem) and dynamic validation (in a real-world\nindustrial case study). The analysis combined quantitative surveys with\nqualitative feedback, assessing utility, ease of use, and intent of adoption.\n[Results] Participants found Define-ML effective for clarifying data concerns,\naligning ML capabilities with business goals, and fostering cross-functional\ncollaboration. The approach's structured activities reduced ideation ambiguity,\nthough some noted a learning curve for ML-specific components, which can be\nmitigated by expert facilitation. All participants expressed the intention to\nadopt Define-ML. [Conclusion] Define-ML provides an openly available, validated\napproach for ML product ideation, building on Lean Inception's agility while\naligning features with available data and increasing awareness of technical\nfeasibility.", "published": "2025-06-25 17:11:26", "link": "http://arxiv.org/abs/2506.20621v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation", "abstract": "In recent decades, the use of 4D Flow MRI images has enabled the\nquantification of velocity fields within a volume of interest and along the\ncardiac cycle. However, the lack of resolution and the presence of noise in\nthese biomarkers are significant issues. As indicated by recent studies, it\nappears that biomarkers such as wall shear stress are particularly impacted by\nthe poor resolution of vessel segmentation. The Phase Contrast Magnetic\nResonance Angiography (PC-MRA) is the state-of-the-art method to facilitate\nsegmentation. The objective of this work is to introduce a new handcraft\nfeature that provides a novel visualisation of 4D Flow MRI images, which is\nuseful in the segmentation task. This feature, termed Weighted Mean Frequencies\n(WMF), is capable of revealing the region in three dimensions where a voxel has\nbeen passed by pulsatile flow. Indeed, this feature is representative of the\nhull of all pulsatile velocity voxels. The value of the feature under\ndiscussion is illustrated by two experiments. The experiments involved\nsegmenting 4D Flow MRI images using optimal thresholding and deep learning\nmethods. The results obtained demonstrate a substantial enhancement in terms of\nIoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with\nthe PC-MRA feature, as evidenced by the deep learning task. This feature has\nthe potential to yield valuable insights that could inform future segmentation\nprocesses in other vascular regions, such as the heart or the brain.", "published": "2025-06-25 17:04:00", "link": "http://arxiv.org/abs/2506.20614v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings", "abstract": "The escalating rates of gun-related violence and mass shootings represent a\nsignificant threat to public safety. Timely and accurate information for law\nenforcement agencies is crucial in mitigating these incidents. Current\ncommercial gunshot detection systems, while effective, often come with\nprohibitive costs. This research explores a cost-effective alternative by\nleveraging acoustic analysis of gunshot recordings, potentially obtainable from\nubiquitous devices like cell phones, to not only detect gunshots but also\nclassify the type of firearm used. This paper details a study on deciphering\ngun type hierarchies using a curated dataset of 3459 recordings. We investigate\nthe fundamental acoustic characteristics of gunshots, including muzzle blasts\nand shockwaves, which vary based on firearm type, ammunition, and shooting\ndirection. We propose and evaluate machine learning frameworks, including\nSupport Vector Machines (SVMs) as a baseline and a more advanced Convolutional\nNeural Network (CNN) architecture for joint gunshot detection and gun type\nclassification. Results indicate that our deep learning approach achieves a\nmean average precision (mAP) of 0.58 on clean labeled data, outperforming the\nSVM baseline (mAP 0.39). Challenges related to data quality, environmental\nnoise, and the generalization capabilities when using noisy web-sourced data\n(mAP 0.35) are also discussed. The long-term vision is to develop a highly\naccurate, real-time system deployable on common recording devices,\nsignificantly reducing detection costs and providing critical intelligence to\nfirst responders.", "published": "2025-06-25 17:00:21", "link": "http://arxiv.org/abs/2506.20609v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base", "abstract": "Generative AI, especially through large language models (LLMs), is\ntransforming how technical knowledge can be accessed, reused, and extended.\nPETSc, a widely used numerical library for high-performance scientific\ncomputing, has accumulated a rich but fragmented knowledge base over its three\ndecades of development, spanning source code, documentation, mailing lists,\nGitLab issues, Discord conversations, technical papers, and more. Much of this\nknowledge remains informal and inaccessible to users and new developers. To\nactivate and utilize this knowledge base more effectively, the PETSc team has\nbegun building an LLM-powered system that combines PETSc content with custom\nLLM tools -- including retrieval-augmented generation (RAG), reranking\nalgorithms, and chatbots -- to assist users, support developers, and propose\nupdates to formal documentation. This paper presents initial experiences\ndesigning and evaluating these tools, focusing on system architecture, using\nRAG and reranking for PETSc-specific information, evaluation methodologies for\nvarious LLMs and embedding models, and user interface design. Leveraging the\nArgonne Leadership Computing Facility resources, we analyze how LLM responses\ncan enhance the development and use of numerical software, with an initial\nfocus on scalable Krylov solvers. Our goal is to establish an extensible\nframework for knowledge-centered AI in scientific software, enabling scalable\nsupport, enriched documentation, and enhanced workflows for research and\ndevelopment. We conclude by outlining directions for expanding this system into\na robust, evolving platform that advances software ecosystems to accelerate\nscientific discovery.", "published": "2025-06-25 17:00:05", "link": "http://arxiv.org/abs/2506.20608v1", "categories": ["cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.AI"}
{"title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video", "abstract": "We introduce CogGen, a learner-centered AI architecture that transforms\nprogramming videos into interactive, adaptive learning experiences by\nintegrating student modeling with generative AI tutoring based on the Cognitive\nApprenticeship framework. The architecture consists of three components: (1)\nvideo segmentation by learning goals, (2) a conversational tutoring engine\napplying Cognitive Apprenticeship strategies, and (3) a student model using\nBayesian Knowledge Tracing to adapt instruction. Our technical evaluation\ndemonstrates effective video segmentation accuracy and strong pedagogical\nalignment across knowledge, method, action, and interaction layers. Ablation\nstudies confirm the necessity of each component in generating effective\nguidance. This work advances AI-powered tutoring by bridging structured student\nmodeling with interactive AI conversations, offering a scalable approach to\nenhancing video-based programming education.", "published": "2025-06-25 16:39:05", "link": "http://arxiv.org/abs/2506.20600v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges", "abstract": "The global demand for sustainable protein sources has accelerated the need\nfor intelligent tools that can rapidly process and synthesise domain-specific\nscientific knowledge. In this study, we present a proof-of-concept multi-agent\nArtificial Intelligence (AI) framework designed to support sustainable protein\nproduction research, with an initial focus on microbial protein sources. Our\nRetrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based\nLLM agents: (1) a literature search agent that retrieves relevant scientific\nliterature on microbial protein production for a specified microbial strain,\nand (2) an information extraction agent that processes the retrieved content to\nextract relevant biological and chemical information. Two parallel\nmethodologies, fine-tuning and prompt engineering, were explored for agent\noptimisation. Both methods demonstrated effectiveness at improving the\nperformance of the information extraction agent in terms of transformer-based\ncosine similarity scores between obtained and ideal outputs. Mean cosine\nsimilarity scores were increased by up to 25%, while universally reaching mean\nscores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved\nthe mean scores to a greater extent (consistently of $\\geq 0.94$) compared to\nprompt engineering, although lower statistical uncertainties were observed with\nthe latter approach. A user interface was developed and published for enabling\nthe use of the multi-agent AI system, alongside preliminary exploration of\nadditional chemical safety-based search capabilities", "published": "2025-06-25 16:37:46", "link": "http://arxiv.org/abs/2506.20598v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "AI in the Writing Process: How Purposeful AI Support Fosters Student Writing", "abstract": "The ubiquity of technologies like ChatGPT has raised concerns about their\nimpact on student writing, particularly regarding reduced learner agency and\nsuperficial engagement with content. While standalone chat-based LLMs often\nproduce suboptimal writing outcomes, evidence suggests that purposefully\ndesigned AI writing support tools can enhance the writing process. This paper\ninvestigates how different AI support approaches affect writers' sense of\nagency and depth of knowledge transformation. Through a randomized control\ntrial with 90 undergraduate students, we compare three conditions: (1) a\nchat-based LLM writing assistant, (2) an integrated AI writing tool to support\ndiverse subprocesses, and (3) a standard writing interface (control). Our\nfindings demonstrate that, among AI-supported conditions, students using the\nintegrated AI writing tool exhibited greater agency over their writing process\nand engaged in deeper knowledge transformation overall. These results suggest\nthat thoughtfully designed AI writing support targeting specific aspects of the\nwriting process can help students maintain ownership of their work while\nfacilitating improved engagement with content.", "published": "2025-06-25 16:34:09", "link": "http://arxiv.org/abs/2506.20595v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Dense Video Captioning using Graph-based Sentence Summarization", "abstract": "Recently, dense video captioning has made attractive progress in detecting\nand captioning all events in a long untrimmed video. Despite promising results\nwere achieved, most existing methods do not sufficiently explore the scene\nevolution within an event temporal proposal for captioning, and therefore\nperform less satisfactorily when the scenes and objects change over a\nrelatively long proposal. To address this problem, we propose a graph-based\npartition-and-summarization (GPaS) framework for dense video captioning within\ntwo stages. For the ``partition\" stage, a whole event proposal is split into\nshort video segments for captioning at a finer level. For the ``summarization\"\nstage, the generated sentences carrying rich description information for each\nsegment are summarized into one sentence to describe the whole event. We\nparticularly focus on the ``summarization\" stage, and propose a framework that\neffectively exploits the relationship between semantic words for summarization.\nWe achieve this goal by treating semantic words as nodes in a graph and\nlearning their interactions by coupling Graph Convolutional Network (GCN) and\nLong Short Term Memory (LSTM), with the aid of visual cues. Two schemes of\nGCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN\nand LSTM. The effectiveness of our approach is demonstrated via an extensive\ncomparison with the state-of-the-arts methods on the two benchmarks ActivityNet\nCaptions dataset and YouCook II dataset.", "published": "2025-06-25 16:23:43", "link": "http://arxiv.org/abs/2506.20583v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Causal Representation Learning with Observational Grouping for CXR Classification", "abstract": "Identifiable causal representation learning seeks to uncover the true causal\nrelationships underlying a data generation process. In medical imaging, this\npresents opportunities to improve the generalisability and robustness of\ntask-specific latent features. This work introduces the concept of grouping\nobservations to learn identifiable representations for disease classification\nin chest X-rays via an end-to-end framework. Our experiments demonstrate that\nthese causal representations improve generalisability and robustness across\nmultiple classification tasks when grouping is used to enforce invariance w.r.t\nrace, sex, and imaging views.", "published": "2025-06-25 16:17:36", "link": "http://arxiv.org/abs/2506.20582v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS", "abstract": "Adversarial attacks, wherein slight inputs are carefully crafted to mislead\nintelligent models, have attracted increasing attention. However, a critical\ngap persists between theoretical advancements and practical application,\nparticularly in structured data like network traffic, where interdependent\nfeatures complicate effective adversarial manipulations. Moreover, ambiguity in\ncurrent approaches restricts reproducibility and limits progress in this field.\nHence, existing defenses often fail to handle evolving adversarial attacks.\nThis paper proposes a novel approach for black-box adversarial attacks, that\naddresses these limitations. Unlike prior work, which often assumes system\naccess or relies on repeated probing, our method strictly respect black-box\nconstraints, reducing interaction to avoid detection and better reflect\nreal-world scenarios. We present an adaptive feature selection strategy using\nchange-point detection and causality analysis to identify and target sensitive\nfeatures to perturbations. This lightweight design ensures low computational\ncost and high deployability. Our comprehensive experiments show the attack's\neffectiveness in evading detection with minimal interaction, enhancing its\nadaptability and applicability in real-world scenarios. By advancing the\nunderstanding of adversarial attacks in network traffic, this work lays a\nfoundation for developing robust defenses.", "published": "2025-06-25 16:10:20", "link": "http://arxiv.org/abs/2506.20576v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization", "abstract": "In this work, we propose a division-and-summarization (DaS) framework for\ndense video captioning. After partitioning each untrimmed long video as\nmultiple event proposals, where each event proposal consists of a set of short\nvideo segments, we extract visual feature (e.g., C3D feature) from each segment\nand use the existing image/video captioning approach to generate one sentence\ndescription for this segment. Considering that the generated sentences contain\nrich semantic descriptions about the whole event proposal, we formulate the\ndense video captioning task as a visual cue aided sentence summarization\nproblem and propose a new two stage Long Short Term Memory (LSTM) approach\nequipped with a new hierarchical attention mechanism to summarize all generated\nsentences as one descriptive sentence with the aid of visual features.\nSpecifically, the first-stage LSTM network takes all semantic words from the\ngenerated sentences and the visual features from all segments within one event\nproposal as the input, and acts as the encoder to effectively summarize both\nsemantic and visual information related to this event proposal. The\nsecond-stage LSTM network takes the output from the first-stage LSTM network\nand the visual features from all video segments within one event proposal as\nthe input, and acts as the decoder to generate one descriptive sentence for\nthis event proposal. Our comprehensive experiments on the ActivityNet Captions\ndataset demonstrate the effectiveness of our newly proposed DaS framework for\ndense video captioning.", "published": "2025-06-25 16:02:04", "link": "http://arxiv.org/abs/2506.20567v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DeepQuark: deep-neural-network approach to multiquark bound states", "abstract": "For the first time, we implement the deep-neural-network-based variational\nMonte Carlo approach for the multiquark bound states, whose complexity\nsurpasses that of electron or nucleon systems due to strong SU(3) color\ninteractions. We design a novel and high-efficiency architecture, DeepQuark, to\naddress the unique challenges in multiquark systems such as stronger\ncorrelations, extra discrete quantum numbers, and intractable confinement\ninteraction. Our method demonstrates competitive performance with\nstate-of-the-art approaches, including diffusion Monte Carlo and Gaussian\nexpansion method, in the nucleon, doubly heavy tetraquark, and fully heavy\ntetraquark systems. Notably, it outperforms existing calculations for\npentaquarks, exemplified by the triply heavy pentaquark. For the nucleon, we\nsuccessfully incorporate three-body flux-tube confinement interactions without\nadditional computational costs. In tetraquark systems, we consistently describe\nhadronic molecule $T_{cc}$ and compact tetraquark $T_{bb}$ with an unbiased\nform of wave function ansatz. In the pentaquark sector, we obtain weakly bound\n$\\bar D^*\\Xi_{cc}^*$ molecule $P_{cc\\bar c}(5715)$ with $S=\\frac{5}{2}$ and its\nbottom partner $P_{bb\\bar b}(15569)$. They can be viewed as the analogs of the\nmolecular $T_{cc}$. We recommend experimental search of $P_{cc\\bar c}(5715)$ in\nthe D-wave $J/\\psi \\Lambda_c$ channel. DeepQuark holds great promise for\nextension to larger multiquark systems, overcoming the computational barriers\nin conventional methods. It also serves as a powerful framework for exploring\nconfining mechanism beyond two-body interactions in multiquark states, which\nmay offer valuable insights into nonperturbative QCD and general many-body\nphysics.", "published": "2025-06-25 15:53:18", "link": "http://arxiv.org/abs/2506.20555v1", "categories": ["hep-ph", "cs.AI", "hep-ex", "hep-lat", "nucl-th"], "primary_category": "hep-ph"}
{"title": "Large Language Model-Driven Code Compliance Checking in Building Information Modeling", "abstract": "This research addresses the time-consuming and error-prone nature of manual\ncode compliance checking in Building Information Modeling (BIM) by introducing\na Large Language Model (LLM)-driven approach to semi-automate this critical\nprocess. The developed system integrates LLMs such as GPT, Claude, Gemini, and\nLlama, with Revit software to interpret building codes, generate Python\nscripts, and perform semi-automated compliance checks within the BIM\nenvironment. Case studies on a single-family residential project and an office\nbuilding project demonstrated the system's ability to reduce the time and\neffort required for compliance checks while improving accuracy. It streamlined\nthe identification of violations, such as non-compliant room dimensions,\nmaterial usage, and object placements, by automatically assessing relationships\nand generating actionable reports. Compared to manual methods, the system\neliminated repetitive tasks, simplified complex regulations, and ensured\nreliable adherence to standards. By offering a comprehensive, adaptable, and\ncost-effective solution, this proposed approach offers a promising advancement\nin BIM-based compliance checking, with potential applications across diverse\nregulatory documents in construction projects.", "published": "2025-06-25 15:50:34", "link": "http://arxiv.org/abs/2506.20551v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks", "abstract": "With the rapid advancement of deep learning, particularly through generative\nadversarial networks (GANs) and diffusion models (DMs), AI-generated images, or\n``deepfakes\", have become nearly indistinguishable from real ones. These images\nare widely shared across Online Social Networks (OSNs), raising concerns about\ntheir misuse. Existing deepfake detection methods overlook the ``block effects\"\nintroduced by compression in OSNs, which obscure deepfake artifacts, and\nprimarily focus on raw images, rarely encountered in real-world scenarios. To\naddress these challenges, we propose PLADA (Pay Less Attention to Deceptive\nArtifacts), a novel framework designed to tackle the lack of paired data and\nthe ineffective use of compressed images. PLADA consists of two core modules:\nBlock Effect Eraser (B2E), which uses a dual-stage attention mechanism to\nhandle block effects, and Open Data Aggregation (ODA), which processes both\npaired and unpaired data to improve detection. Extensive experiments across 26\ndatasets demonstrate that PLADA achieves a remarkable balance in deepfake\ndetection, outperforming SoTA methods in detecting deepfakes on OSNs, even with\nlimited paired data and compression. More importantly, this work introduces the\n``block effect\" as a critical factor in deepfake detection, providing a robust\nsolution for open-world scenarios. Our code is available at\nhttps://github.com/ManyiLee/PLADA.", "published": "2025-06-25 15:46:41", "link": "http://arxiv.org/abs/2506.20548v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads", "abstract": "The rapid advancement of AI, particularly large language models (LLMs), has\nraised significant concerns about the energy use and carbon emissions\nassociated with model training and inference. However, existing tools for\nmeasuring and reporting such impacts are often fragmented, lacking systematic\nmetric integration and offering limited support for correlation analysis among\nthem. This paper presents WattsOnAI, a comprehensive software toolkit for the\nmeasurement, analysis, and visualization of energy use, power draw, hardware\nperformance, and carbon emissions across AI workloads. By seamlessly\nintegrating with existing AI frameworks, WattsOnAI offers standardized reports\nand exports fine-grained time-series data to support benchmarking and\nreproducibility in a lightweight manner. It further enables in-depth\ncorrelation analysis between hardware metrics and model performance and thus\nfacilitates bottleneck identification and performance enhancement. By\naddressing critical limitations in existing tools, WattsOnAI encourages the\nresearch community to weigh environmental impact alongside raw performance of\nAI workloads and advances the shift toward more sustainable \"Green AI\"\npractices. The code is available at https://github.com/SusCom-Lab/WattsOnAI.", "published": "2025-06-25 15:24:45", "link": "http://arxiv.org/abs/2506.20535v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios", "abstract": "Driving in safety-critical scenarios requires quick, context-aware\ndecision-making grounded in both situational understanding and experiential\nreasoning. Large Language Models (LLMs), with their powerful general-purpose\nreasoning capabilities, offer a promising foundation for such decision-making.\nHowever, their direct application to autonomous driving remains limited due to\nchallenges in domain adaptation, contextual grounding, and the lack of\nexperiential knowledge needed to make reliable and interpretable decisions in\ndynamic, high-risk environments. To address this gap, this paper presents a\nCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for\nevasive maneuver decision-making in complex risk scenarios. Our approach\nintegrates semantic scene understanding from dashcam video inputs with the\nretrieval of relevant past driving cases, enabling LLMs to generate maneuver\nrecommendations that are both context-sensitive and human-aligned. Experiments\nacross multiple open-source LLMs show that our framework improves decision\naccuracy, justification quality, and alignment with human expert behavior.\nRisk-aware prompting strategies further enhance performance across diverse risk\ntypes, while similarity-based case retrieval consistently outperforms random\nsampling in guiding in-context learning. Case studies further demonstrate the\nframework's robustness in challenging real-world conditions, underscoring its\npotential as an adaptive and trustworthy decision-support tool for intelligent\ndriving systems.", "published": "2025-06-25 15:19:25", "link": "http://arxiv.org/abs/2506.20531v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation", "abstract": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of\nhigh-quality datasets and the complex variability of industrial energy\nconsumption patterns. To address data scarcity and privacy issues, we introduce\nthe Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an\nopen-source dataset generated using Digital Twin simulations. SIDED includes\nthree types of industrial facilities across three different geographic\nlocations, capturing diverse appliance behaviors, weather conditions, and load\nprofiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)\nmethod, a computationally efficient technique that enhances NILM model\ngeneralization by intelligently scaling appliance power contributions based on\ntheir relative impact. We show in experiments that NILM models trained with\nAMDA-augmented data significantly improve the disaggregation of energy\nconsumption of complex industrial appliances like combined heat and power\nsystems. Specifically, in our out-of-sample scenarios, models trained with AMDA\nachieved a Normalized Disaggregation Error of 0.093, outperforming models\ntrained without data augmentation (0.451) and those trained with random data\naugmentation (0.290). Data distribution analyses confirm that AMDA effectively\naligns training and test data distributions, enhancing model generalization.", "published": "2025-06-25 15:10:43", "link": "http://arxiv.org/abs/2506.20525v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Engineering Sentience", "abstract": "We spell out a definition of sentience that may be useful for designing and\nbuilding it in machines. We propose that for sentience to be meaningful for AI,\nit must be fleshed out in functional, computational terms, in enough detail to\nallow for implementation. Yet, this notion of sentience must also reflect\nsomething essentially 'subjective', beyond just having the general capacity to\nencode perceptual content. For this specific functional notion of sentience to\noccur, we propose that certain sensory signals need to be both assertoric\n(persistent) and qualitative. To illustrate the definition in more concrete\nterms, we sketch out some ways for potential implementation, given current\ntechnology. Understanding what it takes for artificial agents to be\nfunctionally sentient can also help us avoid creating them inadvertently, or at\nleast, realize that we have created them in a timely manner.", "published": "2025-06-25 14:49:50", "link": "http://arxiv.org/abs/2506.20504v1", "categories": ["cs.AI", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization", "abstract": "Neural Cellular Automata (NCAs) are a promising new approach to model\nself-organizing processes, with potential applications in life science.\nHowever, their deterministic nature limits their ability to capture the\nstochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework\nincorporating the idea of mixture models into the NCA paradigm. By combining\nprobabilistic rule assignments with intrinsic noise, MNCAs can model diverse\nlocal behaviors and reproduce the stochastic dynamics observed in biological\nprocesses.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic\nsimulations of tissue growth and differentiation, (2) image morphogenesis\nrobustness, and (3) microscopy image segmentation. Results show that MNCAs\nachieve superior robustness to perturbations, better recapitulate real\nbiological growth patterns, and provide interpretable rule segmentation. These\nfindings position MNCAs as a promising tool for modeling stochastic dynamical\nsystems and studying self-growth processes.", "published": "2025-06-25 14:33:35", "link": "http://arxiv.org/abs/2506.20486v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification", "abstract": "A fundamental question in applying In-Context Learning (ICL) for tabular data\nclassification is how to determine the ideal number of demonstrations in the\nprompt. This work addresses this challenge by presenting an algorithm to\nautomatically select a reasonable number of required demonstrations. Our method\ndistinguishes itself by integrating not only the tabular data's distribution\nbut also the user's selected prompt template and the specific Large Language\nModel (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed\nalgorithm defines a novel metric to quantify the similarities between different\ndemonstrations. We then construct a similarity graph and analyze the\neigenvalues of its Laplacian to derive the minimum number of demonstrations\ncapable of representing the data within the LLM's intrinsic representation\nspace. We validate the efficacy of our approach through experiments comparing\nits performance against conventional random selection algorithms on diverse\ndatasets and LLMs.", "published": "2025-06-25 13:57:54", "link": "http://arxiv.org/abs/2506.20451v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity", "abstract": "We study the novel problem of future off-policy evaluation (F-OPE) and\nlearning (F-OPL) for estimating and optimizing the future value of policies in\nnon-stationary environments, where distributions vary over time. In e-commerce\nrecommendations, for instance, our goal is often to estimate and optimize the\npolicy value for the upcoming month using data collected by an old policy in\nthe previous month. A critical challenge is that data related to the future\nenvironment is not observed in the historical data. Existing methods assume\nstationarity or depend on restrictive reward-modeling assumptions, leading to\nsignificant bias. To address these limitations, we propose a novel estimator\nnamed \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture\n\\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating\npolicy values at any future time point. The key feature of OPFV is its ability\nto leverage the useful structure within time-series data. While future data\nmight not be present in the historical log, we can leverage, for example,\nseasonal, weekly, or holiday effects that are consistent in both the historical\nand future data. Our estimator is the first to exploit these time-related\nstructures via a new type of importance weighting, enabling effective F-OPE.\nTheoretical analysis identifies the conditions under which OPFV becomes\nlow-bias. In addition, we extend our estimator to develop a new policy-gradient\nmethod to proactively learn a good future policy using only historical data.\nEmpirical results show that our methods substantially outperform existing\nmethods in estimating and optimizing the future policy value under\nnon-stationarity for various experimental setups.", "published": "2025-06-25 13:31:46", "link": "http://arxiv.org/abs/2506.20417v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models", "abstract": "Ensuring the security of complex system-on-chips (SoCs) designs is a critical\nimperative, yet traditional verification techniques struggle to keep pace due\nto significant challenges in automation, scalability, comprehensiveness, and\nadaptability. The advent of large language models (LLMs), with their remarkable\ncapabilities in natural language understanding, code generation, and advanced\nreasoning, presents a new paradigm for tackling these issues. Moving beyond\nmonolithic models, an agentic approach allows for the creation of multi-agent\nsystems where specialized LLMs collaborate to solve complex problems more\neffectively. Recognizing this opportunity, we introduce SV-LLM, a novel\nmulti-agent assistant system designed to automate and enhance SoC security\nverification. By integrating specialized agents for tasks like verification\nquestion answering, security asset identification, threat modeling, test plan\nand property generation, vulnerability detection, and simulation-based bug\nvalidation, SV-LLM streamlines the workflow. To optimize their performance in\nthese diverse tasks, agents leverage different learning paradigms, such as\nin-context learning, fine-tuning, and retrieval-augmented generation (RAG). The\nsystem aims to reduce manual intervention, improve accuracy, and accelerate\nsecurity analysis, supporting proactive identification and mitigation of risks\nearly in the design cycle. We demonstrate its potential to transform hardware\nsecurity practices through illustrative case studies and experiments that\nshowcase its applicability and efficacy.", "published": "2025-06-25 13:31:13", "link": "http://arxiv.org/abs/2506.20415v1", "categories": ["cs.CR", "cs.AI", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning", "abstract": "The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.", "published": "2025-06-25 13:27:36", "link": "http://arxiv.org/abs/2506.20413v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "GymPN: A Library for Decision-Making in Process Management Systems", "abstract": "Process management systems support key decisions about the way work is\nallocated in organizations. This includes decisions on which task to perform\nnext, when to execute the task, and who to assign the task to. Suitable\nsoftware tools are required to support these decisions in a way that is optimal\nfor the organization. This paper presents a software library, called GymPN,\nthat supports optimal decision-making in business processes using Deep\nReinforcement Learning. GymPN builds on previous work that supports task\nassignment in business processes, introducing two key novelties: support for\npartial process observability and the ability to model multiple decisions in a\nbusiness process. These novel elements address fundamental limitations of\nprevious work and thus enable the representation of more realistic process\ndecisions. We evaluate the library on eight typical business process\ndecision-making problem patterns, showing that GymPN allows for easy modeling\nof the desired problems, as well as learning optimal decision policies.", "published": "2025-06-25 13:19:42", "link": "http://arxiv.org/abs/2506.20404v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation", "abstract": "With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.", "published": "2025-06-25 13:15:52", "link": "http://arxiv.org/abs/2506.20401v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios", "abstract": "This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.", "published": "2025-06-25 12:50:28", "link": "http://arxiv.org/abs/2506.20384v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition", "abstract": "We introduce CARMA, a system for situational grounding in human-robot group\ninteractions. Effective collaboration in such group settings requires\nsituational awareness based on a consistent representation of present persons\nand objects coupled with an episodic abstraction of events regarding actors and\nmanipulated objects. This calls for a clear and consistent assignment of\ninstances, ensuring that robots correctly recognize and track actors, objects,\nand their interactions over time. To achieve this, CARMA uniquely identifies\nphysical instances of such entities in the real world and organizes them into\ngrounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple\nhumans and a robot interact: collaborative pouring, handovers, and sorting.\nThese scenarios allow the assessment of the system's capabilities as to role\ndistinction, multi-actor awareness, and consistent instance identification. Our\nexperiments demonstrate that the system can reliably generate accurate\nactor-action-object triplets, providing a structured and robust foundation for\napplications requiring spatiotemporal reasoning and situated decision-making in\ncollaborative settings.", "published": "2025-06-25 12:36:49", "link": "http://arxiv.org/abs/2506.20373v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations", "abstract": "We present LaplaceGNN, a novel self-supervised graph learning framework that\nbypasses the need for negative sampling by leveraging spectral bootstrapping\ntechniques. Our method integrates Laplacian-based signals into the learning\nprocess, allowing the model to effectively capture rich structural\nrepresentations without relying on contrastive objectives or handcrafted\naugmentations. By focusing on positive alignment, LaplaceGNN achieves linear\nscaling while offering a simpler, more efficient, self-supervised alternative\nfor graph neural networks, applicable across diverse domains. Our contributions\nare twofold: we precompute spectral augmentations through max-min\ncentrality-guided optimization, enabling rich structural supervision without\nrelying on handcrafted augmentations, then we integrate an adversarial\nbootstrapped training scheme that further strengthens feature learning and\nrobustness. Our extensive experiments on different benchmark datasets show that\nLaplaceGNN achieves superior performance compared to state-of-the-art\nself-supervised graph methods, offering a promising direction for efficiently\nlearning expressive graph representations.", "published": "2025-06-25 12:23:23", "link": "http://arxiv.org/abs/2506.20362v1", "categories": ["cs.LG", "cs.AI", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Tabular Feature Discovery With Reasoning Type Exploration", "abstract": "Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.", "published": "2025-06-25 12:18:34", "link": "http://arxiv.org/abs/2506.20357v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A foundation model with multi-variate parallel attention to generate neuronal activity", "abstract": "Learning from multi-variate time-series with heterogeneous channel\nconfigurations remains a fundamental challenge for deep neural networks (DNNs),\nparticularly in clinical domains such as intracranial electroencephalography\n(iEEG), where channel setups vary widely across subjects. In this work, we\nintroduce multi-variate parallel attention (MVPA), a novel self-attention\nmechanism that disentangles content, temporal, and spatial attention, enabling\nflexible, generalizable, and efficient modeling of time-series data with\nvarying channel counts and configurations. We use MVPA to build MVPFormer, a\ngenerative foundation model for human electrophysiology, trained to predict the\nevolution of iEEG signals across diverse subjects. To support this and future\neffort by the community, we release the SWEC iEEG dataset, the largest publicly\navailable iEEG dataset to date, comprising nearly 10,000 hours of recordings\nfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong\ngeneralization across subjects, demonstrating expert-level performance in\nseizure detection and outperforming state-of-the-art Transformer baselines on\nour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard\ntime-series forecasting and classification tasks, where it matches or exceeds\nexisting attention-based models. Together, our contributions establish MVPA as\na general-purpose attention mechanism for heterogeneous time-series and\nMVPFormer as the first open-source, open-weights, and open-data iEEG foundation\nmodel with state-of-the-art clinical performance. The code is available at\nhttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\ndataset is available at\nhttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.", "published": "2025-06-25 12:07:10", "link": "http://arxiv.org/abs/2506.20354v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression", "abstract": "The ever-increasing computational demands and deployment costs of large\nlanguage models (LLMs) have spurred numerous compressing methods. Compared to\nquantization and unstructured pruning, SVD compression offers superior hardware\ncompatibility and theoretical guarantees. However, existing SVD-based methods\nfocus on the overall discrepancy between the original and compressed matrices\nwhile overlooking the protection of critical components within the matrix,\nwhich leads to inferior performance in the compressed models. This paper\nproposes a dual-level importance protection mechanism to enhance SVD-based\ncompression methods: (1) local importance protection: preserving the most\ncritical singular vectors within each weight matrix through channel-weighted\ndata whitening; and (2) global importance protection: enabling less important\nlayers to bear a greater portion of the compression burden through either a\nheuristic or optimization-based approach, thereby minimizing the impact of\ncompression on critical layers. Extensive experiments demonstrate that DipSVD\noutperforms existing SVD-based compression approaches across multiple\nbenchmarks, achieving superior model performance especially at high model\ncompression ratios.", "published": "2025-06-25 12:04:53", "link": "http://arxiv.org/abs/2506.20353v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Feature Hallucination for Self-supervised Action Recognition", "abstract": "Understanding human actions in videos requires more than raw pixel analysis;\nit relies on high-level semantic reasoning and effective integration of\nmultimodal features. We propose a deep translational action recognition\nframework that enhances recognition accuracy by jointly predicting action\nconcepts and auxiliary features from RGB video frames. At test time,\nhallucination streams infer missing cues, enriching feature representations\nwithout increasing computational overhead. To focus on action-relevant regions\nbeyond raw pixels, we introduce two novel domain-specific descriptors. Object\nDetection Features (ODF) aggregate outputs from multiple object detectors to\ncapture contextual cues, while Saliency Detection Features (SDF) highlight\nspatial and intensity patterns crucial for action recognition. Our framework\nseamlessly integrates these descriptors with auxiliary modalities such as\noptical flow, Improved Dense Trajectories, skeleton data, and audio cues. It\nremains compatible with state-of-the-art architectures, including I3D,\nAssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE\nV2 and InternVideo2. To handle uncertainty in auxiliary features, we\nincorporate aleatoric uncertainty modeling in the hallucination step and\nintroduce a robust loss function to mitigate feature noise. Our multimodal\nself-supervised action recognition framework achieves state-of-the-art\nperformance on multiple benchmarks, including Kinetics-400, Kinetics-600, and\nSomething-Something V2, demonstrating its effectiveness in capturing\nfine-grained action dynamics.", "published": "2025-06-25 11:50:23", "link": "http://arxiv.org/abs/2506.20342v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "abstract": "Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.", "published": "2025-06-25 11:34:43", "link": "http://arxiv.org/abs/2506.20332v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach", "abstract": "This research presents the development of an Artificial Intelligence (AI) -\ndriven crop disease detection system designed to assist farmers in rural areas\nwith limited resources. We aim to compare different deep learning models for a\ncomparative analysis, focusing on their efficacy in transfer learning. By\nleveraging deep learning models, including EfficientNet, ResNet101,\nMobileNetV2, and our custom CNN, which achieved a validation accuracy of\n95.76%, the system effectively classifies plant diseases. This research\ndemonstrates the potential of transfer learning in reshaping agricultural\npractices, improving crop health management, and supporting sustainable farming\nin rural environments.", "published": "2025-06-25 11:04:33", "link": "http://arxiv.org/abs/2506.20323v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration", "abstract": "Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.", "published": "2025-06-25 10:39:32", "link": "http://arxiv.org/abs/2506.20307v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enterprise Large Language Model Evaluation Benchmark", "abstract": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.", "published": "2025-06-25 09:34:25", "link": "http://arxiv.org/abs/2506.20274v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity", "abstract": "In machine learning, it is common to obtain multiple equally performing\nmodels for the same prediction task, e.g., when training neural networks with\ndifferent random seeds. Model multiplicity (MM) is the situation which arises\nwhen these competing models differ in their predictions for the same input, for\nwhich ensembling is often employed to determine an aggregation of the outputs.\nProviding recourse recommendations via counterfactual explanations (CEs) under\nMM thus becomes complex, since the CE may not be valid across all models, i.e.,\nthe CEs are not robust under MM. In this work, we formalise the problem of\nproviding recourse under MM, which we name recourse-aware ensembling (RAE). We\npropose the idea that under MM, CEs for each individual model should be\nconsidered alongside their predictions so that the aggregated prediction and\nrecourse are decided in tandem. Centred around this intuition, we introduce six\ndesirable properties for solutions to this problem. For solving RAE, we propose\na novel argumentative ensembling method which guarantees the robustness of CEs\nunder MM. Specifically, our method leverages computational argumentation to\nexplicitly represent the conflicts between models and counterfactuals regarding\nprediction results and CE validity. It then uses argumentation semantics to\nresolve the conflicts and obtain the final solution, in a manner which is\nparametric to the chosen semantics. Our method also allows for the\nspecification of preferences over the models under MM, allowing further\ncustomisation of the ensemble. In a comprehensive theoretical analysis, we\ncharacterise the behaviour of argumentative ensembling with four different\nargumentation semantics. We then empirically demonstrate the effectiveness of\nour approach in satisfying desirable properties with eight instantiations of\nour method. (Abstract is shortened for arXiv.)", "published": "2025-06-25 09:07:00", "link": "http://arxiv.org/abs/2506.20260v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Generating and Customizing Robotic Arm Trajectories using Neural Networks", "abstract": "We introduce a neural network approach for generating and customizing the\ntrajectory of a robotic arm, that guarantees precision and repeatability. To\nhighlight the potential of this novel method, we describe the design and\nimplementation of the technique and show its application in an experimental\nsetting of cognitive robotics. In this scenario, the NICO robot was\ncharacterized by the ability to point to specific points in space with precise\nlinear movements, increasing the predictability of the robotic action during\nits interaction with humans. To achieve this goal, the neural network computes\nthe forward kinematics of the robot arm. By integrating it with a generator of\njoint angles, another neural network was developed and trained on an artificial\ndataset created from suitable start and end poses of the robotic arm. Through\nthe computation of angular velocities, the robot was characterized by its\nability to perform the movement, and the quality of its action was evaluated in\nterms of shape and accuracy. Thanks to its broad applicability, our approach\nsuccessfully generates precise trajectories that could be customized in their\nshape and adapted to different settings.", "published": "2025-06-25 09:05:58", "link": "http://arxiv.org/abs/2506.20259v1", "categories": ["cs.RO", "cs.AI", "68T40, 93C85, 70E60", "I.2.9"], "primary_category": "cs.RO"}
{"title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios", "abstract": "Forecasting attracts a lot of research attention in the electricity value\nchain. However, most studies concentrate on short-term forecasting of\ngeneration or consumption with a focus on systems and less on individual\nconsumers. Even more neglected is the topic of long-term forecasting of\nindividual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods\nfor generating synthetic time series data tailored to energy consumption\nlong-term forecasting. High-fidelity synthetic data is crucial for a wide range\nof applications, including state estimations in energy systems or power grid\nplanning. In this study, we assess and compare the performance of multiple\nstate-of-the-art but less common techniques: a hybrid Wasserstein Generative\nAdversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),\nHidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial\nnormalizing Flows (MABF). We analyze the ability of each method to replicate\nthe temporal dynamics, long-range dependencies, and probabilistic transitions\ncharacteristic of individual energy consumption profiles. Our comparative\nevaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and\nMABF aiding in selecting the most suitable approach for state estimations and\nother energy-related tasks. Our generation and analysis framework aims to\nenhance the accuracy and reliability of synthetic power consumption data while\ngenerating data that fulfills criteria like anonymisation - preserving privacy\nconcerns mitigating risks of specific profiling of single customers. This study\nutilizes an open-source dataset from households in Germany with 15min time\nresolution. The generated synthetic power profiles can readily be used in\napplications like state estimations or consumption forecasting.", "published": "2025-06-25 08:54:47", "link": "http://arxiv.org/abs/2506.20253v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models", "abstract": "Quantized large language models (LLMs) have gained increasing attention and\nsignificance for enabling deployment in resource-constrained environments.\nHowever, emerging studies on a few calibration dataset-free quantization\nmethods suggest that quantization may compromise the safety capabilities of\nLLMs, underscoring the urgent need for systematic safety evaluations and\neffective mitigation strategies. In this paper, we present comprehensive safety\nevaluations across various mainstream quantization techniques and diverse\ncalibration datasets, utilizing widely accepted safety benchmarks. To address\nthe identified safety vulnerabilities, we propose a quantization-aware safety\npatching framework, Q-resafe, to efficiently restore the safety capabilities of\nquantized LLMs while minimizing any adverse impact on utility. Extensive\nexperimental results demonstrate that Q-resafe successfully re-aligns the\nsafety of quantized LLMs with their pre-quantization counterparts, even under\nchallenging evaluation scenarios. Project page is available at:\nhttps://github.com/Thecommonirin/Qresafe.", "published": "2025-06-25 08:52:22", "link": "http://arxiv.org/abs/2506.20251v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data", "abstract": "Federated learning (FL) is a decentralized collaborative machine learning\n(ML) technique. It provides a solution to the issues of isolated data islands\nand data privacy leakage in industrial ML practices. One major challenge in FL\nis handling the non-identical and independent distributed (non-IID) data.\nCurrent solutions either focus on constructing an all-powerful global model, or\ncustomizing personalized local models. Few of them can provide both a\nwell-generalized global model and well-performed local models at the same time.\nAdditionally, many FL solutions to the non-IID problem are benefited from\nintroducing public datasets. However, this will also increase the risk of data\nleakage. To tackle the problems, we propose a novel data-free distillation\nframework, Federated Bidirectional Knowledge Distillation (FedBKD).\nSpecifically, we train Generative Adversarial Networks (GAN) for synthetic\ndata. During the GAN training, local models serve as discriminators and their\nparameters are frozen. The synthetic data is then used for bidirectional\ndistillation between global and local models to achieve knowledge interactions\nso that performances for both sides are improved. We conduct extensive\nexperiments on 4 benchmarks under different non-IID settings. The results show\nthat FedBKD achieves SOTA performances in every case.", "published": "2025-06-25 08:42:10", "link": "http://arxiv.org/abs/2506.20245v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Directed Link Prediction using GNN with Local and Global Feature Fusion", "abstract": "Link prediction is a classical problem in graph analysis with many practical\napplications. For directed graphs, recently developed deep learning approaches\ntypically analyze node similarities through contrastive learning and aggregate\nneighborhood information through graph convolutions. In this work, we propose a\nnovel graph neural network (GNN) framework to fuse feature embedding with\ncommunity information. We theoretically demonstrate that such hybrid features\ncan improve the performance of directed link prediction. To utilize such\nfeatures efficiently, we also propose an approach to transform input graphs\ninto directed line graphs so that nodes in the transformed graph can aggregate\nmore information during graph convolutions. Experiments on benchmark datasets\nshow that our approach outperforms the state-of-the-art in most cases when 30%,\n40%, 50%, and 60% of the connected links are used as training data,\nrespectively.", "published": "2025-06-25 08:25:56", "link": "http://arxiv.org/abs/2506.20235v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets", "abstract": "Affective priming exemplifies the challenge of ambiguity in affective\ncomputing. While the community has largely addressed this issue from a\nlabel-based perspective, identifying data points in the sequence affected by\nthe priming effect, the impact of priming on data itself, particularly in\nphysiological signals, remains underexplored. Data affected by priming can lead\nto misclassifications when used in learning models. This study proposes the\nAffective Priming Score (APS), a data-driven method to detect data points\ninfluenced by the priming effect. The APS assigns a score to each data point,\nquantifying the extent to which it is affected by priming. To validate this\nmethod, we apply it to the SEED and SEED-VII datasets, which contain sufficient\ntransitions between emotional events to exhibit priming effects. We train\nmodels with the same configuration using both the original data and\npriming-free sequences. The misclassification rate is significantly reduced\nwhen using priming-free sequences compared to the original data. This work\ncontributes to the broader challenge of ambiguity by identifying and mitigating\npriming effects at the data level, enhancing model robustness, and offering\nvaluable insights for the design and collection of affective computing\ndatasets.", "published": "2025-06-25 07:48:22", "link": "http://arxiv.org/abs/2506.20204v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach", "abstract": "A growing fraction of all code is sampled from Large Language Models (LLMs).\nWe investigate the problem of attributing code generated by language models\nusing hypothesis testing to leverage established techniques and guarantees.\nGiven a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to\nassess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse\nof dimensionality, this is intractable when only samples from the LLM are\ngiven: to circumvent this, we use both samples and density estimates from the\nLLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames\nattribution as a distribution testing problem. Our experiments on a benchmark\nof code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores (\n$\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and\nStable-Code using only $\\approx 2000$ samples.", "published": "2025-06-25 07:37:16", "link": "http://arxiv.org/abs/2506.20197v1", "categories": ["cs.LG", "cs.AI", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Progressive Alignment Degradation Learning for Pansharpening", "abstract": "Deep learning-based pansharpening has been shown to effectively generate\nhigh-resolution multispectral (HRMS) images. To create supervised ground-truth\nHRMS images, synthetic data generated using the Wald protocol is commonly\nemployed. This protocol assumes that networks trained on artificial\nlow-resolution data will perform equally well on high-resolution data. However,\nwell-trained models typically exhibit a trade-off in performance between\nreduced-resolution and full-resolution datasets. In this paper, we delve into\nthe Wald protocol and find that its inaccurate approximation of real-world\ndegradation patterns limits the generalization of deep pansharpening models. To\naddress this issue, we propose the Progressive Alignment Degradation Module\n(PADM), which uses mutual iteration between two sub-networks, PAlignNet and\nPDegradeNet, to adaptively learn accurate degradation processes without relying\non predefined operators. Building on this, we introduce HFreqdiff, which embeds\nhigh-frequency details into a diffusion framework and incorporates CFB and BACM\nmodules for frequency-selective detail extraction and precise reverse process\nlearning. These innovations enable effective integration of high-resolution\npanchromatic and multispectral images, significantly enhancing spatial\nsharpness and quality. Experiments and ablation studies demonstrate the\nproposed method's superior performance compared to state-of-the-art techniques.", "published": "2025-06-25 07:07:32", "link": "http://arxiv.org/abs/2506.20179v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Valid Selection among Conformal Sets", "abstract": "Conformal prediction offers a distribution-free framework for constructing\nprediction sets with coverage guarantees. In practice, multiple valid conformal\nprediction sets may be available, arising from different models or\nmethodologies. However, selecting the most desirable set, such as the smallest,\ncan invalidate the coverage guarantees. To address this challenge, we propose a\nstability-based approach that ensures coverage for the selected prediction set.\nWe extend our results to the online conformal setting, propose several\nrefinements in settings where additional structure is available, and\ndemonstrate its effectiveness through experiments.", "published": "2025-06-25 06:59:55", "link": "http://arxiv.org/abs/2506.20173v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME", "stat.OT"], "primary_category": "stat.ML"}
{"title": "Do psychic cells generate consciousness?", "abstract": "Technological advances in the past decades have begun to enable\nneuroscientists to address fundamental questions about consciousness in an\nunprecedented way. Here we review remarkable recent progress in our\nunderstanding of cellular-level mechanisms of conscious processing in the\nbrain. Of particular interest are the cortical pyramidal neurons -- or \"psychic\ncells\" called by Ram\\'on y Cajal more than 100 years ago -- which have an\nintriguing cellular mechanism that accounts for selective disruption of\nfeedback signaling in the brain upon anesthetic-induced loss of consciousness.\nImportantly, a particular class of metabotropic receptors distributed over the\ndendrites of pyramidal cells are highlighted as the key cellular mechanism.\nAfter all, Cajal's instinct over a century ago may turn out to be correct -- we\nmay have just begun to understand whether and how psychic cells indeed generate\nand control our consciousness.", "published": "2025-06-25 06:38:13", "link": "http://arxiv.org/abs/2506.20164v1", "categories": ["q-bio.NC", "cs.AI"], "primary_category": "q-bio.NC"}
{"title": "AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary", "abstract": "The full-day workshop on AI and Agile at XP 2025 convened a diverse group of\nresearchers and industry practitioners to address the practical challenges and\nopportunities of integrating Artificial Intelligence into Agile software\ndevelopment. Through interactive sessions, participants identified shared\nfrustrations related to integrating AI into Agile Software Development\npractices, including challenges with tooling, governance, data quality, and\ncritical skill gaps. These challenges were systematically prioritized and\nanalyzed to uncover root causes. The workshop culminated in the collaborative\ndevelopment of a research roadmap that pinpoints actionable directions for\nfuture work, including both immediate solutions and ambitious long-term goals.\nThe key outcome is a structured agenda designed to foster joint\nindustry-academic efforts to move from identified frustrations to successful\nimplementation.", "published": "2025-06-25 06:29:03", "link": "http://arxiv.org/abs/2506.20159v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype", "abstract": "The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.", "published": "2025-06-25 06:23:39", "link": "http://arxiv.org/abs/2506.20156v1", "categories": ["cs.HC", "cs.AI", "cs.IR", "H.5.2; I.2.7; H.3.3"], "primary_category": "cs.HC"}
{"title": "Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration", "abstract": "Structured pruning is a well-established technique for compressing neural\nnetworks, making it suitable for deployment in resource-limited edge devices.\nThis paper presents an efficient Loss-Aware Automatic Selection of Structured\nPruning Criteria (LAASP) for slimming and accelerating deep neural networks.\nThe majority of pruning methodologies employ a sequential process consisting of\nthree stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed\npruning technique adopts a pruning-while-training approach that eliminates the\nfirst stage and integrates the second and third stages into a single cycle. The\nautomatic selection of magnitude or similarity-based filter pruning criteria\nfrom a specified pool of criteria and the specific pruning layer at each\npruning iteration is guided by the network's overall loss on a small subset of\nthe training data. To mitigate the abrupt accuracy drop due to pruning, the\nnetwork is retrained briefly after each reduction of a predefined number of\nfloating-point operations (FLOPs). The optimal pruning rates for each layer in\nthe network are automatically determined, eliminating the need for manual\nallocation of fixed or variable pruning rates for each layer. Experiments on\nthe VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets\ndemonstrate the effectiveness of the proposed method. In particular, the\nResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the\ntop-1 accuracy compared to state-of-the-art methods while reducing the network\nFLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces\nFLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The\nsource code of this paper is publicly available online -\nhttps://github.com/ghimiredhikura/laasp.", "published": "2025-06-25 06:18:46", "link": "http://arxiv.org/abs/2506.20152v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "EAR: Erasing Concepts from Unified Autoregressive Models", "abstract": "Autoregressive (AR) models have achieved unified and strong performance\nacross both visual understanding and image generation tasks. However, removing\nundesired concepts from AR models while maintaining overall generation quality\nremains an open challenge. In this paper, we propose Erasure Autoregressive\nModel (EAR), a fine-tuning method for effective and utility-preserving concept\nerasure in AR models. Specifically, we introduce Windowed Gradient Accumulation\n(WGA) strategy to align patch-level decoding with erasure objectives, and\nThresholded Loss Masking (TLM) strategy to protect content unrelated to the\ntarget concept during fine-tuning. Furthermore, we propose a novel benchmark,\nErase Concept Generator and Visual Filter (ECGVF), aim at provide a more\nrigorous and comprehensive foundation for evaluating concept erasure in AR\nmodels. Specifically, we first employ structured templates across diverse large\nlanguage models (LLMs) to pre-generate a large-scale corpus of\ntarget-replacement concept prompt pairs. Subsequently, we generate images from\nthese prompts and subject them to rigorous filtering via a visual classifier to\nensure concept fidelity and alignment. Extensive experimental results conducted\non the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR\nachieves marked improvements in both erasure effectiveness and model utility\npreservation. Code is available at: https://github.com/immc-lab/ear/", "published": "2025-06-25 06:15:07", "link": "http://arxiv.org/abs/2506.20151v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI Copilots for Reproducibility in Science: A Case Study", "abstract": "Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.", "published": "2025-06-25 04:56:28", "link": "http://arxiv.org/abs/2506.20130v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos", "abstract": "Recent advances in deep generative models have led to significant progress in\nvideo generation, yet the fidelity of AI-generated videos remains limited.\nSynthesized content often exhibits visual artifacts such as temporally\ninconsistent motion, physically implausible trajectories, unnatural object\ndeformations, and local blurring that undermine realism and user trust.\nAccurate detection and spatial localization of these artifacts are crucial for\nboth automated quality control and for guiding the development of improved\ngenerative models. However, the research community currently lacks a\ncomprehensive benchmark specifically designed for artifact localization in AI\ngenerated videos. Existing datasets either restrict themselves to video or\nframe level detection or lack the fine-grained spatial annotations necessary\nfor evaluating localization methods. To address this gap, we introduce\nBrokenVideos, a benchmark dataset of 3,254 AI-generated videos with\nmeticulously annotated, pixel-level masks highlighting regions of visual\ncorruption. Each annotation is validated through detailed human inspection to\nensure high quality ground truth. Our experiments show that training state of\nthe art artifact detection models and multi modal large language models (MLLMs)\non BrokenVideos significantly improves their ability to localize corrupted\nregions. Through extensive evaluation, we demonstrate that BrokenVideos\nestablishes a critical foundation for benchmarking and advancing research on\nartifact localization in generative video models. The dataset is available at:\nhttps://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.", "published": "2025-06-25 03:30:04", "link": "http://arxiv.org/abs/2506.20103v1", "categories": ["cs.CV", "cs.AI", "I.4"], "primary_category": "cs.CV"}
{"title": "IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals", "abstract": "Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly\nlearning scene geometry and semantics, enabling downstream applications such as\nnavigation in mobile robotics. The recent generalization to Panoptic Scene\nCompletion (PSC) advances the SSC domain by integrating instance-level\ninformation, thereby enhancing object-level sensitivity in scene understanding.\nWhile PSC was introduced using LiDAR modality, methods based on camera images\nremain largely unexplored. Moreover, recent Transformer-based SSC approaches\nutilize a fixed set of learned queries to reconstruct objects within the scene\nvolume. Although these queries are typically updated with image context during\ntraining, they remain static at test time, limiting their ability to\ndynamically adapt specifically to the observed scene. To overcome these\nlimitations, we propose IPFormer, the first approach that leverages\ncontext-adaptive instance proposals at train and test time to address\nvision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively\ninitializes these queries as panoptic instance proposals derived from image\ncontext and further refines them through attention-based encoding and decoding\nto reason about semantic instance-voxel relationships. Experimental results\nshow that our approach surpasses state-of-the-art methods in overall panoptic\nmetrics PQ$^\\dagger$ and PQ-All, matches performance in individual metrics, and\nachieves a runtime reduction exceeding 14$\\times$. Furthermore, our ablation\nstudies reveal that dynamically deriving instance proposals from image context,\nas opposed to random initialization, leads to a 3.62% increase in PQ-All and a\nremarkable average improvement of 18.65% in combined Thing-metrics. These\nresults highlight our introduction of context-adaptive instance proposals as a\npioneering effort in addressing vision-based 3D Panoptic Scene Completion.", "published": "2025-06-25 17:59:45", "link": "http://arxiv.org/abs/2506.20671v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EditP23: 3D Editing via Propagation of Image Prompts to Multi-View", "abstract": "We present EditP23, a method for mask-free 3D editing that propagates 2D\nimage edits to multi-view representations in a 3D-consistent manner. In\ncontrast to traditional approaches that rely on text-based prompting or\nexplicit spatial masks, EditP23 enables intuitive edits by conditioning on a\npair of images: an original view and its user-edited counterpart. These image\nprompts are used to guide an edit-aware flow in the latent space of a\npre-trained multi-view diffusion model, allowing the edit to be coherently\npropagated across views. Our method operates in a feed-forward manner, without\noptimization, and preserves the identity of the original object, in both\nstructure and appearance. We demonstrate its effectiveness across a range of\nobject categories and editing scenarios, achieving high fidelity to the source\nwhile requiring no manual masks.", "published": "2025-06-25 17:50:20", "link": "http://arxiv.org/abs/2506.20652v1", "categories": ["cs.GR", "cs.CV", "68U05 (Primary), 68T45 (Secondary)", "I.3.7; I.3.8; I.4.9"], "primary_category": "cs.GR"}
{"title": "Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects", "abstract": "Obtaining a better knowledge of the current state and behavior of objects\norbiting Earth has proven to be essential for a range of applications such as\nactive debris removal, in-orbit maintenance, or anomaly detection. 3D models\nrepresent a valuable source of information in the field of Space Situational\nAwareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to\nperform 3D reconstruction of non-cooperative space objects from simulated\nimages. This scenario is challenging for NeRF models due to unusual camera\ncharacteristics and environmental conditions : mono-chromatic images, unknown\nobject orientation, limited viewing angles, absence of diffuse lighting etc. In\nthis work we focus primarly on the joint optimization of camera poses alongside\nthe NeRF. Our experimental results show that the most accurate 3D\nreconstruction is achieved when training with successive images one-by-one. We\nestimate camera poses by optimizing an uniform rotation and use regularization\nto prevent successive poses from being too far apart.", "published": "2025-06-25 17:33:49", "link": "http://arxiv.org/abs/2506.20638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes", "abstract": "Humans possess a unique ability to perceive meaningful patterns in ambiguous\nstimuli, a cognitive phenomenon known as pareidolia. This paper introduces\nShape2Animal framework to mimics this imaginative capacity by reinterpreting\nnatural object silhouettes, such as clouds, stones, or flames, as plausible\nanimal forms. Our automated framework first performs open-vocabulary\nsegmentation to extract object silhouette and interprets semantically\nappropriate animal concepts using vision-language models. It then synthesizes\nan animal image that conforms to the input shape, leveraging text-to-image\ndiffusion model and seamlessly blends it into the original scene to generate\nvisually coherent and spatially consistent compositions. We evaluated\nShape2Animal on a diverse set of real-world inputs, demonstrating its\nrobustness and creative potential. Our Shape2Animal can offer new opportunities\nfor visual storytelling, educational content, digital art, and interactive\nmedia design. Our project page is here: https://shape2image.github.io", "published": "2025-06-25 17:04:08", "link": "http://arxiv.org/abs/2506.20616v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video Perception Models for 3D Scene Synthesis", "abstract": "Traditionally, 3D scene synthesis requires expert knowledge and significant\nmanual effort. Automating this process could greatly benefit fields such as\narchitectural design, robotics simulation, virtual reality, and gaming. Recent\napproaches to 3D scene synthesis often rely on the commonsense reasoning of\nlarge language models (LLMs) or strong visual priors of modern image generation\nmodels. However, current LLMs demonstrate limited 3D spatial reasoning ability,\nwhich restricts their ability to generate realistic and coherent 3D scenes.\nMeanwhile, image generation-based methods often suffer from constraints in\nviewpoint selection and multi-view inconsistencies. In this work, we present\nVideo Perception models for 3D Scene synthesis (VIPScene), a novel framework\nthat exploits the encoded commonsense knowledge of the 3D physical world in\nvideo generation models to ensure coherent scene layouts and consistent object\nplacements across views. VIPScene accepts both text and image prompts and\nseamlessly integrates video generation, feedforward 3D reconstruction, and\nopen-vocabulary perception models to semantically and geometrically analyze\neach object in a scene. This enables flexible scene synthesis with high realism\nand structural consistency. For more precise analysis, we further introduce\nFirst-Person View Score (FPVScore) for coherence and plausibility evaluation,\nutilizing continuous first-person perspective to capitalize on the reasoning\nability of multimodal large language models. Extensive experiments show that\nVIPScene significantly outperforms existing methods and generalizes well across\ndiverse scenarios. The code will be released.", "published": "2025-06-25 16:40:17", "link": "http://arxiv.org/abs/2506.20601v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection", "abstract": "The rapid advancement of generative artificial intelligence is producing fake\nremote sensing imagery (RSI) that is increasingly difficult to detect,\npotentially leading to erroneous intelligence, fake news, and even conspiracy\ntheories. Existing forgery detection methods typically rely on single visual\nfeatures to capture predefined artifacts, such as spatial-domain cues to detect\nforged objects like roads or buildings in RSI, or frequency-domain features to\nidentify artifacts from up-sampling operations in adversarial generative\nnetworks (GANs). However, the nature of artifacts can significantly differ\ndepending on geographic terrain, land cover types, or specific features within\nthe RSI. Moreover, these complex artifacts evolve as generative models become\nmore sophisticated. In short, over-reliance on a single visual cue makes\nexisting forgery detectors struggle to generalize across diverse remote sensing\ndata. This paper proposed a novel forgery detection framework called SFNet,\ndesigned to identify fake images in diverse remote sensing data by leveraging\nspatial and frequency domain features. Specifically, to obtain rich and\ncomprehensive visual information, SFNet employs two independent feature\nextractors to capture spatial and frequency domain features from input RSIs. To\nfully utilize the complementary domain features, the domain feature mapping\nmodule and the hybrid domain feature refinement module(CBAM attention) of SFNet\nare designed to successively align and fuse the multi-domain features while\nsuppressing redundant information. Experiments on three datasets show that\nSFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art\nRS forgery detection methods and exhibits robust generalization capabilities.\nThe code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.", "published": "2025-06-25 16:38:37", "link": "http://arxiv.org/abs/2506.20599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration", "abstract": "Interactive 3D scene generation from a single image has gained significant\nattention due to its potential to create immersive virtual worlds. However, a\nkey challenge in current 3D generation methods is the limited explorability,\nwhich cannot render high-quality images during larger maneuvers beyond the\noriginal viewpoint, particularly when attempting to move forward into unseen\nareas. To address this challenge, we propose WonderFree, the first model that\nenables users to interactively generate 3D worlds with the freedom to explore\nfrom arbitrary angles and directions. Specifically, we decouple this challenge\ninto two key subproblems: novel view quality, which addresses visual artifacts\nand floating issues in novel views, and cross-view consistency, which ensures\nspatial consistency across different viewpoints. To enhance rendering quality\nin novel views, we introduce WorldRestorer, a data-driven video restoration\nmodel designed to eliminate floaters and artifacts. In addition, a data\ncollection pipeline is presented to automatically gather training data for\nWorldRestorer, ensuring it can handle scenes with varying styles needed for 3D\nscene generation. Furthermore, to improve cross-view consistency, we propose\nConsistView, a multi-view joint restoration mechanism that simultaneously\nrestores multiple perspectives while maintaining spatiotemporal coherence.\nExperimental results demonstrate that WonderFree not only enhances rendering\nquality across diverse viewpoints but also significantly improves global\ncoherence and consistency. These improvements are confirmed by CLIP-based\nmetrics and a user study showing a 77.20% preference for WonderFree over\nWonderWorld enabling a seamless and immersive 3D exploration experience. The\ncode, model, and data will be publicly available.", "published": "2025-06-25 16:28:40", "link": "http://arxiv.org/abs/2506.20590v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness", "abstract": "The increasing ubiquity of video content and the corresponding demand for\nefficient access to meaningful information have elevated video summarization\nand video highlights as a vital research area. However, many state-of-the-art\nmethods depend heavily either on supervised annotations or on attention-based\nmodels, which are computationally expensive and brittle in the face of\ndistribution shifts that hinder cross-domain applicability across datasets. We\nintroduce a pioneering self-supervised video summarization model that captures\nboth spatial and temporal dependencies without the overhead of attention, RNNs,\nor transformers. Our framework integrates a novel set of Markov process-driven\nloss metrics and a two-stage self supervised learning paradigm that ensures\nboth performance and efficiency. Our approach achieves state-of-the-art\nperformance on the SUMME and TVSUM datasets, outperforming all existing\nunsupervised methods. It also rivals the best supervised models, demonstrating\nthe potential for efficient, annotation-free architectures. This paves the way\nfor more generalizable video summarization techniques and challenges the\nprevailing reliance on complex architectures.", "published": "2025-06-25 16:27:38", "link": "http://arxiv.org/abs/2506.20588v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning-Based Distance Estimation for 360\u00b0 Single-Sensor Setups", "abstract": "Accurate distance estimation is a fundamental challenge in robotic\nperception, particularly in omnidirectional imaging, where traditional\ngeometric methods struggle with lens distortions and environmental variability.\nIn this work, we propose a neural network-based approach for monocular distance\nestimation using a single 360{\\deg} fisheye lens camera. Unlike classical\ntrigonometric techniques that rely on precise lens calibration, our method\ndirectly learns and infers the distance of objects from raw omnidirectional\ninputs, offering greater robustness and adaptability across diverse conditions.\nWe evaluate our approach on three 360{\\deg} datasets (LOAF, ULM360, and a newly\ncaptured dataset Boat360), each representing distinct environmental and sensor\nsetups. Our experimental results demonstrate that the proposed learning-based\nmodel outperforms traditional geometry-based methods and other learning\nbaselines in both accuracy and robustness. These findings highlight the\npotential of deep learning for real-time omnidirectional distance estimation,\nmaking our approach particularly well-suited for low-cost applications in\nrobotics, autonomous navigation, and surveillance.", "published": "2025-06-25 16:26:55", "link": "http://arxiv.org/abs/2506.20586v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction", "abstract": "Real-time human perception is crucial for effective human-robot interaction\n(HRI). Large vision-language models (VLMs) offer promising generalizable\nperceptual capabilities but often suffer from high latency, which negatively\nimpacts user experience and limits VLM applicability in real-world scenarios.\nTo systematically study VLM capabilities in human perception for HRI and\nperformance-latency trade-offs, we introduce HRIBench, a visual\nquestion-answering (VQA) benchmark designed to evaluate VLMs across a diverse\nset of human perceptual tasks critical for HRI. HRIBench covers five key\ndomains: (1) non-verbal cue understanding, (2) verbal instruction\nunderstanding, (3) human-robot object relationship understanding, (4) social\nnavigation, and (5) person identification. To construct HRIBench, we collected\ndata from real-world HRI environments to curate questions for non-verbal cue\nunderstanding, and leveraged publicly available datasets for the remaining four\ndomains. We curated 200 VQA questions for each domain, resulting in a total of\n1000 questions for HRIBench. We then conducted a comprehensive evaluation of\nboth state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.\nOur results show that, despite their generalizability, current VLMs still\nstruggle with core perceptual capabilities essential for HRI. Moreover, none of\nthe models within our experiments demonstrated a satisfactory\nperformance-latency trade-off suitable for real-time deployment, underscoring\nthe need for future research on developing smaller, low-latency VLMs with\nimproved human perception capabilities. HRIBench and our results can be found\nin this Github repository: https://github.com/interaction-lab/HRIBench.", "published": "2025-06-25 16:01:38", "link": "http://arxiv.org/abs/2506.20566v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation", "abstract": "Vision Transformer has recently gained tremendous popularity in medical image\nsegmentation task due to its superior capability in capturing long-range\ndependencies. However, transformer requires a large amount of labeled data to\nbe effective, which hinders its applicability in annotation scarce\nsemi-supervised learning scenario where only limited labeled data is available.\nState-of-the-art semi-supervised learning methods propose combinatorial\nCNN-Transformer learning to cross teach a transformer with a convolutional\nneural network, which achieves promising results. However, it remains a\nchallenging task to effectively train the transformer with limited labeled\ndata. In this paper, we propose an adversarial masked image modeling method to\nfully unleash the potential of transformer for semi-supervised medical image\nsegmentation. The key challenge in semi-supervised learning with transformer\nlies in the lack of sufficient supervision signal. To this end, we propose to\nconstruct an auxiliary masked domain from original domain with masked image\nmodeling and train the transformer to predict the entire segmentation mask with\nmasked inputs to increase supervision signal. We leverage the original labels\nfrom labeled data and pseudo-labels from unlabeled data to learn the masked\ndomain. To further benefit the original domain from masked domain, we provide a\ntheoretical analysis of our method from a multi-domain learning perspective and\ndevise a novel adversarial training loss to reduce the domain gap between the\noriginal and masked domain, which boosts semi-supervised learning performance.\nWe also extend adversarial masked image modeling to CNN network. Extensive\nexperiments on three public medical image segmentation datasets demonstrate the\neffectiveness of our method, where our method outperforms existing methods\nsignificantly. Our code is publicly available at\nhttps://github.com/zlheui/AdvMIM.", "published": "2025-06-25 16:00:18", "link": "http://arxiv.org/abs/2506.20563v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos", "abstract": "Modern image-based object detection models, such as YOLOv7, primarily process\nindividual frames independently, thus ignoring valuable temporal context\nnaturally present in videos. Meanwhile, existing video-based detection methods\noften introduce complex temporal modules, significantly increasing model size\nand computational complexity. In practical applications such as surveillance\nand autonomous driving, transient challenges including motion blur, occlusions,\nand abrupt appearance changes can severely degrade single-frame detection\nperformance. To address these issues, we propose a straightforward yet highly\neffective strategy: stacking multiple consecutive frames as input to a\nYOLO-based detector while supervising only the output corresponding to a single\ntarget frame. This approach leverages temporal information with minimal\nmodifications to existing architectures, preserving simplicity, computational\nefficiency, and real-time inference capability. Extensive experiments on the\nchallenging MOT20Det and our BOAT360 datasets demonstrate that our method\nimproves detection robustness, especially for lightweight models, effectively\nnarrowing the gap between compact and heavy detection networks. Additionally,\nwe contribute the BOAT360 benchmark dataset, comprising annotated fisheye video\nsequences captured from a boat, to support future research in multi-frame video\nobject detection in challenging real-world scenarios.", "published": "2025-06-25 15:49:07", "link": "http://arxiv.org/abs/2506.20550v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns", "abstract": "Periodontitis, a chronic inflammatory disease causing alveolar bone loss,\nsignificantly affects oral health and quality of life. Accurate assessment of\nbone loss severity and pattern is critical for diagnosis and treatment\nplanning. In this study, we propose a novel AI-based deep learning framework to\nautomatically detect and quantify alveolar bone loss and its patterns using\nintraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth\ndetection with Keypoint R-CNN models to identify anatomical landmarks, enabling\nprecise calculation of bone loss severity. Additionally, YOLOv8x-seg models\nsegment bone levels and tooth masks to determine bone loss patterns (horizontal\nvs. angular) via geometric analysis. Evaluated on a large, expertly annotated\ndataset of 1000 radiographs, our approach achieved high accuracy in detecting\nbone loss severity (intra-class correlation coefficient up to 0.80) and bone\nloss pattern classification (accuracy 87%). This automated system offers a\nrapid, objective, and reproducible tool for periodontal assessment, reducing\nreliance on subjective manual evaluation. By integrating AI into dental\nradiographic analysis, our framework has the potential to improve early\ndiagnosis and personalized treatment planning for periodontitis, ultimately\nenhancing patient care and clinical outcomes.", "published": "2025-06-25 15:08:52", "link": "http://arxiv.org/abs/2506.20522v1", "categories": ["cs.CV", "I.5.4; I.4.6; I.4.9; I.4.8; J.3"], "primary_category": "cs.CV"}
{"title": "A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners", "abstract": "Rock bolts are crucial components of the subterranean support systems in\nunderground mines that provide adequate structural reinforcement to the rock\nmass to prevent unforeseen hazards like rockfalls. This makes frequent\nassessments of such bolts critical for maintaining rock mass stability and\nminimising risks in underground mining operations. Where manual surveying of\nrock bolts is challenging due to the low light conditions in the underground\nmines and the time-intensive nature of the process, automated detection of rock\nbolts serves as a plausible solution. To that end, this study focuses on the\nautomatic identification of rock bolts within medium to large-scale 3D point\nclouds obtained from underground mines using mobile laser scanners. Existing\ntechniques for automated rock bolt identification primarily rely on feature\nengineering and traditional machine learning approaches. However, such\ntechniques lack robustness as these point clouds present several challenges due\nto data noise, varying environments, and complex surrounding structures.\nMoreover, the target rock bolts are extremely small objects within large-scale\npoint clouds and are often partially obscured due to the application of\nreinforcement shotcrete. Addressing these challenges, this paper proposes an\napproach termed DeepBolt, which employs a novel two-stage deep learning\narchitecture specifically designed for handling severe class imbalance for the\nautomatic and efficient identification of rock bolts in complex 3D point\nclouds. The proposed method surpasses state-of-the-art semantic segmentation\nmodels by up to 42.5% in Intersection over Union (IoU) for rock bolt points.\nAdditionally, it outperforms existing rock bolt identification techniques,\nachieving a 96.41% precision and 96.96% recall in classifying rock bolts,\ndemonstrating its robustness and effectiveness in complex underground\nenvironments.", "published": "2025-06-25 14:12:49", "link": "http://arxiv.org/abs/2506.20464v1", "categories": ["cs.CV", "I.4.9"], "primary_category": "cs.CV"}
{"title": "HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling", "abstract": "Diffusion models have emerged as the leading approach for image synthesis,\ndemonstrating exceptional photorealism and diversity. However, training\ndiffusion models at high resolutions remains computationally prohibitive, and\nexisting zero-shot generation techniques for synthesizing images beyond\ntraining resolutions often produce artifacts, including object duplication and\nspatial incoherence. In this paper, we introduce HiWave, a training-free,\nzero-shot approach that substantially enhances visual fidelity and structural\ncoherence in ultra-high-resolution image synthesis using pretrained diffusion\nmodels. Our method employs a two-stage pipeline: generating a base image from\nthe pretrained model followed by a patch-wise DDIM inversion step and a novel\nwavelet-based detail enhancer module. Specifically, we first utilize inversion\nmethods to derive initial noise vectors that preserve global coherence from the\nbase image. Subsequently, during sampling, our wavelet-domain detail enhancer\nretains low-frequency components from the base image to ensure structural\nconsistency, while selectively guiding high-frequency components to enrich fine\ndetails and textures. Extensive evaluations using Stable Diffusion XL\ndemonstrate that HiWave effectively mitigates common visual artifacts seen in\nprior methods, achieving superior perceptual quality. A user study confirmed\nHiWave's performance, where it was preferred over the state-of-the-art\nalternative in more than 80% of comparisons, highlighting its effectiveness for\nhigh-quality, ultra-high-resolution image synthesis without requiring\nretraining or architectural modifications.", "published": "2025-06-25 13:58:37", "link": "http://arxiv.org/abs/2506.20452v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation", "abstract": "Text-to-image generative models have achieved remarkable breakthroughs in\nrecent years. However, their application in medical image generation still\nfaces significant challenges, including small dataset sizes, and scarcity of\nmedical textual data. To address these challenges, we propose Med-Art, a\nframework specifically designed for medical image generation with limited data.\nMed-Art leverages vision-language models to generate visual descriptions of\nmedical images which overcomes the scarcity of applicable medical textual data.\nMed-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\\alpha$,\nbased on the Diffusion Transformer (DiT), achieving high performance under\nlimited data. Furthermore, we propose an innovative Hybrid-Level Diffusion\nFine-tuning (HLDF) method, which enables pixel-level losses, effectively\naddressing issues such as overly saturated colors. We achieve state-of-the-art\nperformance on two medical image datasets, measured by FID, KID, and downstream\nclassification performance.", "published": "2025-06-25 13:56:48", "link": "http://arxiv.org/abs/2506.20449v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images", "abstract": "Accurate gestational age (GA) estimation, ideally through fetal ultrasound\nmeasurement, is a crucial aspect of providing excellent antenatal care.\nHowever, deriving GA from manual fetal biometric measurements depends on the\noperator and is time-consuming. Hence, automatic computer-assisted methods are\ndemanded in clinical practice. In this paper, we present a novel feature fusion\nframework to estimate GA using fetal ultrasound images without any measurement\ninformation. We adopt a deep learning model to extract deep representations\nfrom ultrasound images. We extract radiomic features to reveal patterns and\ncharacteristics of fetal brain growth. To harness the interpretability of\nradiomics in medical imaging analysis, we estimate GA by fusing radiomic\nfeatures and deep representations. Our framework estimates GA with a mean\nabsolute error of 8.0 days across three trimesters, outperforming current\nmachine learning-based methods at these gestational ages. Experimental results\ndemonstrate the robustness of our framework across different populations in\ndiverse geographical regions. Our code is publicly available on\n\\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}{GitHub}.", "published": "2025-06-25 13:23:35", "link": "http://arxiv.org/abs/2506.20407v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management", "abstract": "Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)\nis crucial for supporting local livelihoods and carbon sequestration\ninitiatives like the China Certified Emission Reduction (CCER) program.\nHigh-resolution canopy height maps (CHMs) are essential for this, but standard\nlidar-based methods are expensive. While deep learning with RGB imagery offers\nan alternative, accurately extracting canopy height features remains\nchallenging. To address this, we developed a novel model for high-resolution\nCHM generation using a Large Vision Foundation Model (LVFM). Our model\nintegrates a feature extractor, a self-supervised feature enhancement module to\npreserve spatial details, and a height estimator. Tested in Beijing's Fangshan\nDistrict using 1-meter Google Earth imagery, our model outperformed existing\nmethods, including conventional CNNs. It achieved a mean absolute error of 0.09\nm, a root mean square error of 0.24 m, and a correlation of 0.78 against\nlidar-based CHMs. The resulting CHMs enabled over 90% success in individual\ntree detection, high accuracy in AGB estimation, and effective tracking of\nplantation growth, demonstrating strong generalization to non-training areas.\nThis approach presents a promising, scalable tool for evaluating carbon\nsequestration in both plantations and natural forests.", "published": "2025-06-25 12:51:49", "link": "http://arxiv.org/abs/2506.20388v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking", "abstract": "Transformer-based visual trackers have demonstrated significant advancements\ndue to their powerful modeling capabilities. However, their practicality is\nlimited on resource-constrained devices because of their slow processing\nspeeds. To address this challenge, we present HiT, a novel family of efficient\ntracking models that achieve high performance while maintaining fast operation\nacross various devices. The core innovation of HiT lies in its Bridge Module,\nwhich connects lightweight transformers to the tracking framework, enhancing\nfeature representation quality. Additionally, we introduce a dual-image\nposition encoding approach to effectively encode spatial information. HiT\nachieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson\nAGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark,\noutperforming all previous efficient trackers.Building on HiT, we propose\nDyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by\nselecting routes with varying computational requirements. DyHiT uses search\narea features extracted by the backbone network and inputs them into an\nefficient dynamic router to classify tracking scenarios. Based on the\nclassification, DyHiT applies a divide-and-conquer strategy, selecting\nappropriate routes to achieve a superior trade-off between accuracy and speed.\nThe fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while\nmaintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free\nacceleration method based on the dynamic routing architecture of DyHiT. This\nmethod significantly improves the execution speed of various high-performance\ntrackers without sacrificing accuracy. For instance, our acceleration method\nenables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times\nspeedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of\n69.9% on the LaSOT.", "published": "2025-06-25 12:46:46", "link": "http://arxiv.org/abs/2506.20381v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking", "abstract": "This paper introduces a novel deep learning framework for robust image\nzero-watermarking based on distortion-invariant feature learning. As a\nzero-watermarking scheme, our method leaves the original image unaltered and\nlearns a reference signature through optimization in the feature space. The\nproposed framework consists of two key modules. In the first module, a feature\nextractor is trained via noise-adversarial learning to generate representations\nthat are both invariant to distortions and semantically expressive. This is\nachieved by combining adversarial supervision against a distortion\ndiscriminator and a reconstruction constraint to retain image content. In the\nsecond module, we design a learning-based multibit zero-watermarking scheme\nwhere the trained invariant features are projected onto a set of trainable\nreference codes optimized to match a target binary message. Extensive\nexperiments on diverse image datasets and a wide range of distortions show that\nour method achieves state-of-the-art robustness in both feature stability and\nwatermark recovery. Comparative evaluations against existing self-supervised\nand deep watermarking techniques further highlight the superiority of our\nframework in generalization and robustness.", "published": "2025-06-25 12:32:08", "link": "http://arxiv.org/abs/2506.20370v1", "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "DreamAnywhere: Object-Centric Panoramic 3D Scene Generation", "abstract": "Recent advances in text-to-3D scene generation have demonstrated significant\npotential to transform content creation across multiple industries. Although\nthe research community has made impressive progress in addressing the\nchallenges of this complex task, existing methods often generate environments\nthat are only front-facing, lack visual fidelity, exhibit limited scene\nunderstanding, and are typically fine-tuned for either indoor or outdoor\nsettings. In this work, we address these issues and propose DreamAnywhere, a\nmodular system for the fast generation and prototyping of 3D scenes. Our system\nsynthesizes a 360{\\deg} panoramic image from text, decomposes it into\nbackground and objects, constructs a complete 3D representation through hybrid\ninpainting, and lifts object masks to detailed 3D objects that are placed in\nthe virtual environment. DreamAnywhere supports immersive navigation and\nintuitive object-level editing, making it ideal for scene exploration, visual\nmock-ups, and rapid prototyping -- all with minimal manual modeling. These\nfeatures make our system particularly suitable for low-budget movie production,\nenabling quick iteration on scene layout and visual tone without the overhead\nof traditional 3D workflows. Our modular pipeline is highly customizable as it\nallows components to be replaced independently. Compared to current\nstate-of-the-art text and image-based 3D scene generation approaches,\nDreamAnywhere shows significant improvements in coherence in novel view\nsynthesis and achieves competitive image quality, demonstrating its\neffectiveness across diverse and challenging scenarios. A comprehensive user\nstudy demonstrates a clear preference for our method over existing approaches,\nvalidating both its technical robustness and practical usefulness.", "published": "2025-06-25 12:30:41", "link": "http://arxiv.org/abs/2506.20367v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Practical insights on the effect of different encodings, ans\u00e4tze and measurements in quantum and hybrid convolutional neural networks", "abstract": "This study investigates the design choices of parameterized quantum circuits\n(PQCs) within quantum and hybrid convolutional neural network (HQNN and QCNN)\narchitectures, applied to the task of satellite image classification using the\nEuroSAT dataset. We systematically evaluate the performance implications of\ndata encoding techniques, variational ans\\\"atze, and measurement in approx. 500\ndistinct model configurations. Our analysis reveals a clear hierarchy of\ninfluence on model performance. For hybrid architectures, which were\nbenchmarked against their direct classical equivalents (e.g. the same\narchitecture with the PQCs removed), the data encoding strategy is the dominant\nfactor, with validation accuracy varying over 30% for distinct embeddings. In\ncontrast, the selection of variational ans\\\"atze and measurement basis had a\ncomparatively marginal effect, with validation accuracy variations remaining\nbelow 5%. For purely quantum models, restricted to amplitude encoding,\nperformance was most dependent on the measurement protocol and the\ndata-to-amplitude mapping. The measurement strategy varied the validation\naccuracy by up to 30% and the encoding mapping by around 8 percentage points.", "published": "2025-06-25 12:10:11", "link": "http://arxiv.org/abs/2506.20355v1", "categories": ["quant-ph", "cs.CV"], "primary_category": "quant-ph"}
{"title": "EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis", "abstract": "Hepatic echinococcosis (HE) is a widespread parasitic disease in\nunderdeveloped pastoral areas with limited medical resources. While CNN-based\nand Transformer-based models have been widely applied to medical image\nsegmentation, CNNs lack global context modeling due to local receptive fields,\nand Transformers, though capable of capturing long-range dependencies, are\ncomputationally expensive. Recently, state space models (SSMs), such as Mamba,\nhave gained attention for their ability to model long sequences with linear\ncomplexity. In this paper, we propose EAGLE, a U-shaped network composed of a\nProgressive Visual State Space (PVSS) encoder and a Hybrid Visual State Space\n(HVSS) decoder that work collaboratively to achieve efficient and accurate\nsegmentation of hepatic echinococcosis (HE) lesions. The proposed Convolutional\nVision State Space Block (CVSSB) module is designed to fuse local and global\nfeatures, while the Haar Wavelet Transformation Block (HWTB) module compresses\nspatial information into the channel dimension to enable lossless downsampling.\nDue to the lack of publicly available HE datasets, we collected CT slices from\n260 patients at a local hospital. Experimental results show that EAGLE achieves\nstate-of-the-art performance with a Dice Similarity Coefficient (DSC) of\n89.76%, surpassing MSVM-UNet by 1.61%.", "published": "2025-06-25 11:42:05", "link": "http://arxiv.org/abs/2506.20333v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "On the Burstiness of Faces in Set", "abstract": "Burstiness, a phenomenon observed in text and image retrieval, refers to that\nparticular elements appear more times in a set than a statistically independent\nmodel assumes. We argue that in the context of set-based face recognition\n(SFR), burstiness exists widely and degrades the performance in two aspects:\nFirstly, the bursty faces, where faces with particular attributes %exist\nfrequently in a face set, dominate the training instances and dominate the\ntraining face sets and lead to poor generalization ability to unconstrained\nscenarios. Secondly, the bursty faces %dominating the evaluation sets interfere\nwith the similarity comparison in set verification and identification when\nevaluation. To detect the bursty faces in a set, we propose three strategies\nbased on Quickshift++, feature self-similarity, and generalized max-pooling\n(GMP). We apply the burst detection results on training and evaluation stages\nto enhance the sampling ratios or contributions of the infrequent faces. When\nevaluation, we additionally propose the quality-aware GMP that enables\nawareness of the face quality and robustness to the low-quality faces for the\noriginal GMP. We give illustrations and extensive experiments on the SFR\nbenchmarks to demonstrate that burstiness is widespread and suppressing\nburstiness considerably improves the recognition performance.", "published": "2025-06-25 10:49:45", "link": "http://arxiv.org/abs/2506.20312v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Radiomic fingerprints for knee MR images assessment", "abstract": "Accurate interpretation of knee MRI scans relies on expert clinical judgment,\noften with high variability and limited scalability. Existing radiomic\napproaches use a fixed set of radiomic features (the signature), selected at\nthe population level and applied uniformly to all patients. While\ninterpretable, these signatures are often too constrained to represent\nindividual pathological variations. As a result, conventional radiomic-based\napproaches are found to be limited in performance, compared with recent\nend-to-end deep learning (DL) alternatives without using interpretable radiomic\nfeatures. We argue that the individual-agnostic nature in current radiomic\nselection is not central to its intepretability, but is responsible for the\npoor generalization in our application. Here, we propose a novel radiomic\nfingerprint framework, in which a radiomic feature set (the fingerprint) is\ndynamically constructed for each patient, selected by a DL model. Unlike the\nexisting radiomic signatures, our fingerprints are derived on a per-patient\nbasis by predicting the feature relevance in a large radiomic feature pool, and\nselecting only those that are predictive of clinical conditions for individual\npatients. The radiomic-selecting model is trained simultaneously with a\nlow-dimensional (considered relatively explainable) logistic regression for\ndownstream classification. We validate our methods across multiple diagnostic\ntasks including general knee abnormalities, anterior cruciate ligament (ACL)\ntears, and meniscus tears, demonstrating comparable or superior diagnostic\naccuracy relative to state-of-the-art end-to-end DL models. More importantly,\nwe show that the interpretability inherent in our approach facilitates\nmeaningful clinical insights and potential biomarker discovery, with detailed\ndiscussion, quantitative and qualitative analysis of real-world clinical cases\nto evidence these advantages.", "published": "2025-06-25 10:39:22", "link": "http://arxiv.org/abs/2506.20306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding", "abstract": "The hardness of learning a function that attains a target task relates to its\ninput-sensitivity. For example, image classification tasks are\ninput-insensitive as minor corruptions should not affect the classification\nresults, whereas arithmetic and symbolic computation, which have been recently\nattracting interest, are highly input-sensitive as each input variable connects\nto the computation results. This study presents the first learning-based Quick\nResponse (QR) code decoding and investigates learning functions of medium\nsensitivity. Our experiments reveal that Transformers can successfully decode\nQR codes, even beyond the theoretical error-correction limit, by learning the\nstructure of embedded texts. They generalize from English-rich training data to\nother languages and even random strings. Moreover, we observe that the\nTransformer-based QR decoder focuses on data bits while ignoring\nerror-correction bits, suggesting a decoding mechanism distinct from standard\nQR code readers.", "published": "2025-06-25 10:37:39", "link": "http://arxiv.org/abs/2506.20305v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "TDiR: Transformer based Diffusion for Image Restoration Tasks", "abstract": "Images captured in challenging environments often experience various forms of\ndegradation, including noise, color cast, blur, and light scattering. These\neffects significantly reduce image quality, hindering their applicability in\ndownstream tasks such as object detection, mapping, and classification. Our\ntransformer-based diffusion model was developed to address image restoration\ntasks, aiming to improve the quality of degraded images. This model was\nevaluated against existing deep learning methodologies across multiple quality\nmetrics for underwater image enhancement, denoising, and deraining on publicly\navailable datasets. Our findings demonstrate that the diffusion model, combined\nwith transformers, surpasses current methods in performance. The results of our\nmodel highlight the efficacy of diffusion models and transformers in improving\nthe quality of degraded images, consequently expanding their utility in\ndownstream tasks that require high-fidelity visual data.", "published": "2025-06-25 10:28:13", "link": "http://arxiv.org/abs/2506.20302v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations", "abstract": "Diffusion models have shown strong performance in conditional generation by\nprogressively denoising Gaussian noise toward a target data distribution. This\ndenoising process can be interpreted as a form of hill climbing in a learned\nlatent space, where the model iteratively refines the sample toward regions of\nhigher probability. However, diffusion models often converge to local optima\nthat are locally visually coherent yet globally inconsistent or conditionally\nmisaligned, due to latent space complexity and suboptimal initialization. Prior\nefforts attempted to address this by strengthening guidance signals or\nmanipulating the initial noise distribution. We introduce Controlled Random\nZigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect\nand escape such local maxima during conditional generation. The method first\nidentifies potential local maxima using a reward model. Upon detection, it\ninjects noise and reverts to a previous, noisier state to escape the current\noptimization plateau. The reward model then evaluates candidate trajectories,\naccepting only those that offer improvement, while progressively deeper retreat\nenables stronger escapes when nearby alternatives fail. This controlled random\nzigzag process allows dynamic alternation between forward refinement and\nbackward exploration, enhancing both alignment and visual quality in the\ngenerated outputs. The proposed Ctrl-Z Sampling is model-agnostic and\ncompatible with existing diffusion frameworks. Experimental results show that\nCtrl-Z Sampling substantially improves generation quality with only around 7.6X\nincrease in function evaluations.", "published": "2025-06-25 10:01:00", "link": "http://arxiv.org/abs/2506.20294v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion", "abstract": "The blind fusion of unregistered hyperspectral images (HSIs) and\nmultispectral images (MSIs) has attracted growing attention recently. To\naddress the registration challenge, most existing methods employ spatial\ntransformations on the HSI to achieve alignment with the MSI. However, due to\nthe substantial differences in spatial resolution of the images, the\nperformance of these methods is often unsatisfactory. Moreover, the\nregistration process tends to be time-consuming when dealing with large-sized\nimages in remote sensing. To address these issues, we propose tackling the\nregistration problem from the spectral domain. Initially, a lightweight\nSpectral Prior Learning (SPL) network is developed to extract spectral features\nfrom the HSI and enhance the spectral resolution of the MSI. Following this,\nthe obtained image undergoes spatial downsampling to produce the registered\nHSI. In this process, subspace representation and cyclic training strategy are\nemployed to improve spectral accuracy of the registered HSI obtained. Next, we\npropose a blind sparse fusion (BSF) method, which utilizes group sparsity\nregularization to equivalently promote the low-rankness of the image. This\napproach not only circumvents the need for rank estimation, but also reduces\ncomputational complexity. Then, we employ the Proximal Alternating Optimization\n(PAO) algorithm to solve the BSF model, and present its convergence analysis.\nFinally, extensive numerical experiments on simulated and real datasets are\nconducted to verify the effectiveness of our method in registration and fusion.\nWe also demonstrate its efficacy in enhancing classification performance.", "published": "2025-06-25 10:00:51", "link": "http://arxiv.org/abs/2506.20293v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration", "abstract": "Osteoporosis, characterized by reduced bone mineral density (BMD) and\ncompromised bone microstructure, increases fracture risk in aging populations.\nWhile dual-energy X-ray absorptiometry (DXA) is the clinical standard for BMD\nassessment, its limited accessibility hinders diagnosis in resource-limited\nregions. Opportunistic computed tomography (CT) analysis has emerged as a\npromising alternative for osteoporosis diagnosis using existing imaging data.\nCurrent approaches, however, face three limitations: (1) underutilization of\nunlabeled vertebral data, (2) systematic bias from device-specific DXA\ndiscrepancies, and (3) insufficient integration of clinical knowledge such as\nspatial BMD distribution patterns. To address these, we propose a unified deep\nlearning framework with three innovations. First, a self-supervised learning\nmethod using radiomic representations to leverage unlabeled CT data and\npreserve bone texture. Second, a Mixture of Experts (MoE) architecture with\nlearned gating mechanisms to enhance cross-device adaptability. Third, a\nmulti-task learning framework integrating osteoporosis diagnosis, BMD\nregression, and vertebra location prediction. Validated across three clinical\nsites and an external hospital, our approach demonstrates superior\ngeneralizability and accuracy over existing methods for opportunistic\nosteoporosis screening and diagnosis.", "published": "2025-06-25 09:43:09", "link": "http://arxiv.org/abs/2506.20282v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios", "abstract": "Dense prediction tasks hold significant importance of computer vision, aiming\nto learn pixel-wise annotated label for an input image. Despite advances in\nthis field, existing methods primarily focus on idealized conditions, with\nlimited generalization to real-world scenarios and facing the challenging\nscarcity of real-world data. To systematically study this problem, we first\nintroduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction\ntasks that correspond to urgent real-world applications, featuring unified\nevaluation across tasks. Then, we propose DenseDiT, which maximally exploits\ngenerative models' visual priors to perform diverse real-world dense prediction\ntasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism\nand two lightweight branches that adaptively integrate multi-scale context,\nworking with less than 0.1% additional parameters. Evaluations on DenseWorld\nreveal significant performance drops in existing general and specialized\nbaselines, highlighting their limited real-world generalization. In contrast,\nDenseDiT achieves superior results using less than 0.01% training data of\nbaselines, underscoring its practical value for real-world deployment. Our\ndata, and checkpoints and codes are available at\nhttps://xcltql666.github.io/DenseDiTProj", "published": "2025-06-25 09:40:50", "link": "http://arxiv.org/abs/2506.20279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Forensic Study of Paintings Through the Comparison of Fabrics", "abstract": "The study of canvas fabrics in works of art is a crucial tool for\nauthentication, attribution and conservation. Traditional methods are based on\nthread density map matching, which cannot be applied when canvases do not come\nfrom contiguous positions on a roll. This paper presents a novel approach based\non deep learning to assess the similarity of textiles. We introduce an\nautomatic tool that evaluates the similarity between canvases without relying\non thread density maps. A Siamese deep learning model is designed and trained\nto compare pairs of images by exploiting the feature representations learned\nfrom the scans. In addition, a similarity estimation method is proposed,\naggregating predictions from multiple pairs of cloth samples to provide a\nrobust similarity score. Our approach is applied to canvases from the Museo\nNacional del Prado, corroborating the hypothesis that plain weave canvases,\nwidely used in painting, can be effectively compared even when their thread\ndensities are similar. The results demonstrate the feasibility and accuracy of\nthe proposed method, opening new avenues for the analysis of masterpieces.", "published": "2025-06-25 09:34:10", "link": "http://arxiv.org/abs/2506.20272v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis", "abstract": "Interpretable models are crucial for supporting clinical decision-making,\ndriving advances in their development and application for medical images.\nHowever, the nature of 3D volumetric data makes it inherently challenging to\nvisualize and interpret intricate and complex structures like the cerebral\ncortex. Cortical surface renderings, on the other hand, provide a more\naccessible and understandable 3D representation of brain anatomy, facilitating\nvisualization and interactive exploration. Motivated by this advantage and the\nwidespread use of surface data for studying neurological disorders, we present\nthe eXplainable Surface Vision Transformer (X-SiT). This is the first\ninherently interpretable neural network that offers human-understandable\npredictions based on interpretable cortical features. As part of X-SiT, we\nintroduce a prototypical surface patch decoder for classifying surface patch\nembeddings, incorporating case-based reasoning with spatially corresponding\ncortical prototypes. The results demonstrate state-of-the-art performance in\ndetecting Alzheimer's disease and frontotemporal dementia while additionally\nproviding informative prototypes that align with known disease patterns and\nreveal classification errors.", "published": "2025-06-25 09:24:07", "link": "http://arxiv.org/abs/2506.20267v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification", "abstract": "Few-shot fine-grained image classification (FS-FGIC) presents a significant\nchallenge, requiring models to distinguish visually similar subclasses with\nlimited labeled examples. Existing methods have critical limitations:\nmetric-based methods lose spatial information and misalign local features,\nwhile reconstruction-based methods fail to utilize hierarchical feature\ninformation and lack mechanisms to focus on discriminative regions. We propose\nthe Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which\nintegrates dual-layer feature reconstruction with mask-enhanced feature\nprocessing to improve fine-grained classification. HMDRN incorporates a\ndual-layer feature reconstruction and fusion module that leverages\ncomplementary visual information from different network hierarchies. Through\nlearnable fusion weights, the model balances high-level semantic\nrepresentations from the last layer with mid-level structural details from the\npenultimate layer. Additionally, we design a spatial binary mask-enhanced\ntransformer self-reconstruction module that processes query features through\nadaptive thresholding while maintaining complete support features, enhancing\nfocus on discriminative regions while filtering background noise. Extensive\nexperiments on three challenging fine-grained datasets demonstrate that HMDRN\nconsistently outperforms state-of-the-art methods across Conv-4 and ResNet-12\nbackbone architectures. Comprehensive ablation studies validate the\neffectiveness of each proposed component, revealing that dual-layer\nreconstruction enhances inter-class discrimination while mask-enhanced\ntransformation reduces intra-class variations. Visualization results provide\nevidence of HMDRN's superior feature reconstruction capabilities.", "published": "2025-06-25 09:15:59", "link": "http://arxiv.org/abs/2506.20263v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features", "abstract": "We posit that handwriting recognition benefits from complementary cues\ncarried by the rasterized complex glyph and the pen's trajectory, yet most\nsystems exploit only one modality. We introduce an end-to-end network that\nperforms early fusion of offline images and online stroke data within a shared\nlatent space. A patch encoder converts the grayscale crop into fixed-length\nvisual tokens, while a lightweight transformer embeds the $(x, y, \\text{pen})$\nsequence. Learnable latent queries attend jointly to both token streams,\nyielding context-enhanced stroke embeddings that are pooled and decoded under a\ncross-entropy loss objective. Because integration occurs before any high-level\nclassification, temporal cues reinforce each other during representation\nlearning, producing stronger writer independence. Comprehensive experiments on\nIAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art\naccuracy, exceeding previous bests by up to 1\\%. Our study also shows\nadaptation of this pipeline with gesturification on the ISI-Air dataset. Our\ncode can be found here.", "published": "2025-06-25 08:58:47", "link": "http://arxiv.org/abs/2506.20255v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement", "abstract": "The complexity and diversity of surgical workflows, driven by heterogeneous\noperating room settings, institutional protocols, and anatomical variability,\npresent a significant challenge in developing generalizable models for\ncross-institutional and cross-procedural surgical understanding. While recent\nsurgical foundation models pretrained on large-scale vision-language data offer\npromising transferability, their zero-shot performance remains constrained by\ndomain shifts, limiting their utility in unseen surgical environments. To\naddress this, we introduce Surgical Phase Anywhere (SPA), a lightweight\nframework for versatile surgical workflow understanding that adapts foundation\nmodels to institutional settings with minimal annotation. SPA leverages\nfew-shot spatial adaptation to align multi-modal embeddings with\ninstitution-specific surgical scenes and phases. It also ensures temporal\nconsistency through diffusion modeling, which encodes task-graph priors derived\nfrom institutional procedure protocols. Finally, SPA employs dynamic test-time\nadaptation, exploiting the mutual agreement between multi-modal phase\nprediction streams to adapt the model to a given test video in a\nself-supervised manner, enhancing the reliability under test-time distribution\nshifts. SPA is a lightweight adaptation framework, allowing hospitals to\nrapidly customize phase recognition models by defining phases in natural\nlanguage text, annotating a few images with the phase labels, and providing a\ntask graph defining phase transitions. The experimental results show that the\nSPA framework achieves state-of-the-art performance in few-shot surgical phase\nrecognition across multiple institutions and procedures, even outperforming\nfull-shot models with 32-shot labeled data. Code is available at\nhttps://github.com/CAMMA-public/SPA", "published": "2025-06-25 08:56:13", "link": "http://arxiv.org/abs/2506.20254v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission", "abstract": "Event cameras asynchronously capture pixel-level intensity changes with\nextremely low latency. They are increasingly used in conjunction with RGB\ncameras for a wide range of vision-related applications. However, a major\nchallenge in these hybrid systems lies in the transmission of the large volume\nof triggered events and RGB images. To address this, we propose a transmission\nscheme that retains efficient reconstruction performance of both sources while\naccomplishing real-time deblurring in parallel. Conventional RGB cameras and\nevent cameras typically capture the same scene in different ways, often\nresulting in significant redundant information across their outputs. To address\nthis, we develop a joint event and image (E-I) transmission framework to\neliminate redundancy and thereby optimize channel bandwidth utilization. Our\napproach employs Bayesian modeling and the information bottleneck method to\ndisentangle the shared and domain-specific information within the E-I inputs.\nThis disentangled information bottleneck framework ensures both the compactness\nand informativeness of extracted shared and domain-specific information.\nMoreover, it adaptively allocates transmission bandwidth based on scene\ndynamics, i.e., more symbols are allocated to events for dynamic details or to\nimages for static information. Simulation results demonstrate that the proposed\nscheme not only achieves superior reconstruction quality compared to\nconventional systems but also delivers enhanced deblurring performance.", "published": "2025-06-25 08:09:21", "link": "http://arxiv.org/abs/2506.20222v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation", "abstract": "Unified multimodal large language models (MLLMs) have shown promise in\njointly advancing multimodal understanding and generation, with visual\ncodebooks discretizing images into tokens for autoregressive modeling. Existing\ncodebook-based methods either rely on small vocabularies (~16K entries) that\nlack fine-grained semantics or naively scale up, resulting in low token\nutilization and unstable training. We propose UniCode$^2$, a cascaded codebook\nframework enabling large-scale, semantically aligned, and stable visual\ntokenization. By clustering millions of SigLIP sequence embeddings, we build a\n500K-entry codebook that preserves vision-language alignment while expanding\ncapacity. Stability is ensured via a cascaded design: a frozen codebook anchors\nthe embedding space, and a trainable codebook refines task-specific semantics.\nThis decoupling promotes high utilization and robust learning. Moreover, the\nalignment of our visual tokens with textual semantics enables seamless\nintegration with pretrained diffusion decoders, supporting high-quality visual\nsynthesis with minimal adaptation. UniCode^2 delivers strong performance across\ndiverse benchmarks, demonstrating the viability of scaling visual token spaces\nwithout sacrificing stability, semantics, or modularity.", "published": "2025-06-25 07:57:09", "link": "http://arxiv.org/abs/2506.20214v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment", "abstract": "Positron Emission Tomography / Computed Tomography (PET/CT) plays a critical\nrole in medical imaging, combining functional and anatomical information to aid\nin accurate diagnosis. However, image quality degradation due to noise,\ncompression and other factors could potentially lead to diagnostic uncertainty\nand increase the risk of misdiagnosis. When evaluating the quality of a PET/CT\nimage, both low-level features like distortions and high-level features like\norgan anatomical structures affect the diagnostic value of the image. However,\nexisting medical image quality assessment (IQA) methods are unable to account\nfor both feature types simultaneously. In this work, we propose MS-IQA, a novel\nmulti-scale feature fusion network for PET/CT IQA, which utilizes multi-scale\nfeatures from various intermediate layers of ResNet and Swin Transformer,\nenhancing its ability of perceiving both local and global information. In\naddition, a multi-scale feature fusion module is also introduced to effectively\ncombine high-level and low-level information through a dynamically weighted\nchannel attention mechanism. Finally, to fill the blank of PET/CT IQA dataset,\nwe construct PET-CT-IQA-DS, a dataset containing 2,700 varying-quality PET/CT\nimages with quality scores assigned by radiologists. Experiments on our dataset\nand the publicly available LDCTIQAC2023 dataset demonstrate that our proposed\nmodel has achieved superior performance against existing state-of-the-art\nmethods in various IQA metrics. This work provides an accurate and efficient\nIQA method for PET/CT. Our code and dataset are available at\nhttps://github.com/MS-IQA/MS-IQA/.", "published": "2025-06-25 07:41:03", "link": "http://arxiv.org/abs/2506.20200v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition", "abstract": "Foundation models are rapidly transforming Earth Observation data mining by\nenabling generalizable and scalable solutions for key tasks such as scene\nclassification and semantic segmentation. While most efforts in the geospatial\ndomain have focused on developing large models trained from scratch using\nmassive Earth Observation datasets, an alternative strategy that remains\nunderexplored is the reuse and combination of existing pretrained models. In\nthis study, we investigate whether foundation models pretrained on remote\nsensing and general vision datasets can be effectively combined to improve\nperformance across a diverse set of key Earth Observation tasks. Using the\nGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,\nHiera, and DOFA, on eleven datasets covering a range of spatial resolutions,\nsensor modalities, and task types. The results show that feature-level\nensembling of smaller pretrained models can match or exceed the performance of\nmuch larger models, while requiring less training time and computational\nresources. Moreover, the study highlights the potential of applying knowledge\ndistillation to transfer the strengths of ensembles into more compact models,\noffering a practical path for deploying foundation models in real-world Earth\nObservation applications.", "published": "2025-06-25 07:02:42", "link": "http://arxiv.org/abs/2506.20174v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models", "abstract": "Recent advancements in multimodal large language models have enhanced\ndocument understanding by integrating textual and visual information. However,\nexisting models exhibit incompleteness within their paradigm in real-world\nscenarios, particularly under visual degradation. In such conditions, the\ncurrent response paradigm often fails to adequately perceive visual degradation\nand ambiguity, leading to overreliance on linguistic priors or misaligned\nvisual-textual reasoning. This difficulty in recognizing uncertainty frequently\nresults in the generation of hallucinatory content, especially when a precise\nanswer is not feasible. To better demonstrate and analyze this phenomenon and\nproblem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR\nhallucination in degraded document understanding. This dataset includes test\nsamples spanning identity cards and invoices, with simulated real-world\ndegradations for OCR reliability. This setup allows for evaluating models'\ncapacity, under degraded input, to distinguish reliable visual information and\nanswer accordingly, thereby highlighting the challenge of avoiding\nhallucination on uncertain data. To achieve vision-faithful reasoning and\nthereby avoid the aforementioned issues, we further introduce a GRPO-based\nframework featuring a novel reward mechanism. By incorporating a self-awareness\nof visual uncertainty and an analysis method that initiates refusal to answer\nto increase task difficulty within our supervised fine-tuning and reinforcement\nlearning framework, we successfully mitigated hallucinations in ambiguous\nregions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model\nachieves a 22\\% absolute improvement in hallucination-free accuracy over GPT-4o\non KIE-HVQA and there is no significant performance drop in standard tasks,\nhighlighting both effectiveness and robustness.", "published": "2025-06-25 06:44:07", "link": "http://arxiv.org/abs/2506.20168v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Efficient Exemplar Based Image Editing with Multimodal VLMs", "abstract": "Text-to-Image Diffusion models have enabled a wide array of image editing\napplications. However, capturing all types of edits through text alone can be\nchallenging and cumbersome. The ambiguous nature of certain image edits is\nbetter expressed through an exemplar pair, i.e., a pair of images depicting an\nimage before and after an edit respectively. In this work, we tackle\nexemplar-based image editing -- the task of transferring an edit from an\nexemplar pair to a content image(s), by leveraging pretrained text-to-image\ndiffusion models and multimodal VLMs. Even though our end-to-end pipeline is\noptimization-free, our experiments demonstrate that it still outperforms\nbaselines on multiple types of edits while being ~4x faster.", "published": "2025-06-25 06:20:36", "link": "http://arxiv.org/abs/2506.20155v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From 2D to 3D Cognition: A Brief Survey of General World Models", "abstract": "World models have garnered increasing attention in the development of\nartificial general intelligence (AGI), serving as computational frameworks for\nlearning representations of the external world and forecasting future states.\nWhile early efforts focused on 2D visual perception and simulation, recent\n3D-aware generative world models have demonstrated the ability to synthesize\ngeometrically consistent, interactive 3D environments, marking a shift toward\n3D spatial cognition. Despite rapid progress, the field lacks systematic\nanalysis to categorize emerging techniques and clarify their roles in advancing\n3D cognitive world models. This survey addresses this need by introducing a\nconceptual framework, providing a structured and forward-looking review of\nworld models transitioning from 2D perception to 3D cognition. Within this\nframework, we highlight two key technological drivers, particularly advances in\n3D representations and the incorporation of world knowledge, as fundamental\npillars. Building on these, we dissect three core cognitive capabilities that\nunderpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,\nand 3D spatial interaction. We further examine the deployment of these\ncapabilities in real-world applications, including embodied AI, autonomous\ndriving, digital twin, and gaming/VR. Finally, we identify challenges across\ndata, modeling, and deployment, and outline future directions for advancing\nmore robust and generalizable 3D world models.", "published": "2025-06-25 05:05:09", "link": "http://arxiv.org/abs/2506.20134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Maximal Counts in the Stopped Occupancy Problem", "abstract": "We revisit a version of the classic occupancy scheme, where balls are thrown\nuntil almost all boxes receive a given number of balls. Special cases are\nwidely known as coupon-collectors and dixie cup problems. We show that as the\nnumber of boxes tends to infinity, the distribution of the maximal occupancy\ncount does not converge, but can be approximated by a convolution of two Gumbel\ndistributions, with the approximating distribution having oscillations close to\nperiodic on a logarithmic scale. We pursue two approaches: one relies on\nlattice point processes obtained by poissonisation of the number of balls and\nboxes, and the other employs interpolation of the multiset of occupancy counts\nto a point process on reals. This way we gain considerable insight in known\nasymptotics obtained previously by mostly analytic tools. Further results\nconcern the moments of maximal occupancy counts and ties for the maximum.", "published": "2025-06-25 13:25:03", "link": "http://arxiv.org/abs/2506.20411v1", "categories": ["math.PR", "cs.DM", "math.ST", "stat.TH", "60G70, 60G55, 62G32"], "primary_category": "math.PR"}
{"title": "Modeling energy collection with shortest paths in rectangular grids: an efficient algorithm for energy harvesting", "abstract": "Parabolic Trough solar fields are among the most prominent methods for\nharnessing solar energy. However, continuous sun-tracking movements leads to\nwear and degradation of the tracking system, raising the question of whether\nthe rotations can be minimized without compromising energy capture. In this\npaper, we address this question by exploring two problems: (1) minimizing the\nnumber of SCA rotational movements while maintaining energy production within a\nspecified range, and (2) maximizing energy capture when the number of rotations\nis limited. Unlike prior work, we develop a general framework that considers\nvariable conditions. By transforming the problem into grid-based path\noptimization, we design polynomial-time algorithms that can operate\nindependently of the weather throughout the day. Through realistic simulations\nand experiments using real-world data, our methods show that rotational\nmovements of solar trackers can be reduced by at least 10% while maintaining\nover 95% energy collection efficiency. These results offer a scalable solution\nfor improving the operational lifespan of the solar field. Furthermore, our\nmethods can be integrated with solar irradiance forecasting, enhancing their\nrobustness and suitability for real-world deployment.", "published": "2025-06-25 07:36:56", "link": "http://arxiv.org/abs/2506.20196v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Unidentified and Confounded? Understanding Two-Tower Models for Unbiased Learning to Rank", "abstract": "Additive two-tower models are popular learning-to-rank methods for handling\nbiased user feedback in industry settings. Recent studies, however, report a\nconcerning phenomenon: training two-tower models on clicks collected by\nwell-performing production systems leads to decreased ranking performance. This\npaper investigates two recent explanations for this observation: confounding\neffects from logging policies and model identifiability issues. We\ntheoretically analyze the identifiability conditions of two-tower models,\nshowing that either document swaps across positions or overlapping feature\ndistributions are required to recover model parameters from clicks. We also\ninvestigate the effect of logging policies on two-tower models, finding that\nthey introduce no bias when models perfectly capture user behavior. However,\nlogging policies can amplify biases when models imperfectly capture user\nbehavior, particularly when prediction errors correlate with document placement\nacross positions. We propose a sample weighting technique to mitigate these\neffects and provide actionable insights for researchers and practitioners using\ntwo-tower models.", "published": "2025-06-25 14:47:43", "link": "http://arxiv.org/abs/2506.20501v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search", "abstract": "Semantic retrieval, which retrieves semantically matched items given a\ntextual query, has been an essential component to enhance system effectiveness\nin e-commerce search. In this paper, we study the multimodal retrieval problem,\nwhere the visual information (e.g, image) of item is leveraged as supplementary\nof textual information to enrich item representation and further improve\nretrieval performance. Though learning from cross-modality data has been\nstudied extensively in tasks such as visual question answering or media\nsummarization, multimodal retrieval remains a non-trivial and unsolved problem\nespecially in the asymmetric scenario where the query is unimodal while the\nitem is multimodal. In this paper, we propose a novel model named SMAR, which\nstands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the\nproblem of modality fusion and alignment in this kind of asymmetric scenario.\nExtensive experimental results on an industrial dataset show that the proposed\nmodel outperforms baseline models significantly in retrieval accuracy. We have\nopen sourced our industrial dataset for the sake of reproducibility and future\nresearch works.", "published": "2025-06-25 11:28:04", "link": "http://arxiv.org/abs/2506.20330v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Literature Review on Simulation in Conversational Recommender Systems", "abstract": "Conversational Recommender Systems (CRSs) have garnered attention as a novel\napproach to delivering personalized recommendations through multi-turn\ndialogues. This review developed a taxonomy framework to systematically\ncategorize relevant publications into four groups: dataset construction,\nalgorithm design, system evaluation, and empirical studies, providing a\ncomprehensive analysis of simulation methods in CRSs research. Our analysis\nreveals that simulation methods play a key role in tackling CRSs' main\nchallenges. For example, LLM-based simulation methods have been used to create\nconversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.\nDespite several challenges, such as dataset bias, the limited output\nflexibility of LLM-based simulations, and the gap between text semantic space\nand behavioral semantics, persist due to the complexity in Human-Computer\nInteraction (HCI) of CRSs, simulation methods hold significant potential for\nadvancing CRS research. This review offers a thorough summary of the current\nresearch landscape in this domain and identifies promising directions for\nfuture inquiry.", "published": "2025-06-25 09:53:35", "link": "http://arxiv.org/abs/2506.20291v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Multimodal Information Retrieval for Open World with Edit Distance Weak Supervision", "abstract": "Existing multi-media retrieval models either rely on creating a common\nsubspace with modality-specific representation models or require schema mapping\namong modalities to measure similarities among multi-media data. Our goal is to\navoid the annotation overhead incurred from considering retrieval as a\nsupervised classification task and re-use the pretrained encoders in large\nlanguage models and vision tasks. We propose \"FemmIR\", a framework to retrieve\nmultimodal results relevant to information needs expressed with multimodal\nqueries by example without any similarity label. Such identification is\nnecessary for real-world applications where data annotations are scarce and\nsatisfactory performance is required without fine-tuning with a common\nframework across applications. We curate a new dataset called MuQNOL for\nbenchmarking progress on this task. Our technique is based on weak supervision\nintroduced through edit distance between samples: graph edit distance can be\nmodified to consider the cost of replacing a data sample in terms of its\nproperties, and relevance can be measured through the implicit signal from the\namount of edit cost among the objects. Unlike metric learning or encoding\nnetworks, FemmIR re-uses the high-level properties and maintains the property\nvalue and relationship constraints with a multi-level interaction score between\ndata samples and the query example provided by the user. We empirically\nevaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs\ncomparably to similar retrieval systems in delivering on-demand retrieval\nresults with exact and approximate similarities while using the existing\nproperty identifiers in the system.", "published": "2025-06-25 00:25:08", "link": "http://arxiv.org/abs/2506.20070v1", "categories": ["cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.IR"}
{"title": "POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes", "abstract": "Dynamic treatment regimes (DTRs) provide a principled framework for\noptimizing sequential decision-making in domains where decisions must adapt\nover time in response to individual trajectories, such as healthcare,\neducation, and digital interventions. However, existing statistical methods\noften rely on strong positivity assumptions and lack robustness under partial\ndata coverage, while offline reinforcement learning approaches typically focus\non average training performance, lack statistical guarantees, and require\nsolving complex optimization problems. To address these challenges, we propose\nPOLAR, a novel pessimistic model-based policy learning algorithm for offline\nDTR optimization. POLAR estimates the transition dynamics from offline data and\nquantifies uncertainty for each history-action pair. A pessimistic penalty is\nthen incorporated into the reward function to discourage actions with high\nuncertainty. Unlike many existing methods that focus on average training\nperformance, POLAR directly targets the suboptimality of the final learned\npolicy and offers theoretical guarantees, without relying on computationally\nintensive minimax or constrained optimization procedures. To the best of our\nknowledge, POLAR is the first model-based DTR method to provide both\nstatistical and computational guarantees, including finite-sample bounds on\npolicy suboptimality. Empirical results on both synthetic data and the\nMIMIC-III dataset demonstrate that POLAR outperforms state-of-the-art methods\nand yields near-optimal, history-aware treatment strategies.", "published": "2025-06-25 13:22:57", "link": "http://arxiv.org/abs/2506.20406v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Efficient Feedback Design for Unsourced Random Access with Integrated Sensing and Communication", "abstract": "We consider an unsourced random access (URA) system enhanced with a feedback\nmechanism that serves both communication and sensing tasks. While traditional\nURA systems do not incorporate feedback, we propose a novel feedback signal\ndesign that announces the decoding status of users and simultaneously enables\ntarget sensing. To design this dual-purpose feedback, we introduce a modified\nprojected gradient descent algorithm that minimizes a weighted combination of\ncommunication and sensing errors. Simulation results show that the proposed\nfeedback design outperforms the state-of-the-art feedback design in the URA\nliterature. Furthermore, we illustrate the trade-off between communication and\nsensing capabilities, offering valuable insight into balancing these two tasks.", "published": "2025-06-25 09:09:28", "link": "http://arxiv.org/abs/2506.20262v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Exploration-Exploitation Tradeoff in Universal Lossy Compression", "abstract": "Universal compression can learn the source and adapt to it either in a batch\nmode (forward adaptation), or in a sequential mode (backward adaptation). We\nrecast the sequential mode as a multi-armed bandit problem, a fundamental model\nin reinforcement-learning, and study the trade-off between exploration and\nexploitation in the lossy compression case. We show that a previously proposed\n\"natural type selection\" scheme can be cast as a reconstruction-directed MAB\nalgorithm, for sequential lossy compression, and explain its limitations in\nterms of robustness and short-block performance. We then derive and analyze\nrobust cost-directed MAB algorithms, which work at any block length.", "published": "2025-06-25 09:08:29", "link": "http://arxiv.org/abs/2506.20261v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Efficient Channel Estimation for Rotatable Antenna-Enabled Wireless Communication", "abstract": "Rotatable antenna (RA) is a promising antenna architecture that exploits\nadditional spatial degrees of freedom (DoFs) to enhance the communication\nperformance. To fully obtain the performance gain provided by RAs, accurate\nchannel state information (CSI) is essential for adjusting the\norientation/boresight of each antenna. In this letter, we propose an efficient\nchannel estimation scheme for RA communication systems, where the base station\n(BS) can sequentially and adaptively adjust the orientations of RAs to enrich\nthe environmental observations from diverse angular perspectives, thereby\nenhancing the channel estimation accuracy. The proposed scheme includes two\nmain procedures that are conducted alternately during each channel training\nperiod. Specifically, the first procedure is to estimate the CSI with given\nRAs' orientations, involving the angle-of-arrivals (AoAs) information and path\ngains. Then, based on the estimated CSI, the second procedure adjusts the RAs'\norientations to maximize the effective channel gain. Simulation results\ndemonstrate that the proposed channel estimation method outperforms other\nbenchmark schemes.", "published": "2025-06-25 06:28:49", "link": "http://arxiv.org/abs/2506.20158v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Graph Structure of a Class of Permutation Maps over Ring $\\mathbb{Z}_{p^k}$", "abstract": "Understanding the periodic and structural properties of permutation maps over\nresidue rings such as $\\mathbb{Z}_{p^k}$ is a foundational challenge in\nalgebraic dynamics and pseudorandom sequence analysis. Despite notable progress\nin characterizing global periods, a critical bottleneck remains: the lack of\nexplicit tools to analyze local cycle structures and their evolution with\nincreasing arithmetic precision. In this work, we propose a unified analytical\nframework to systematically derive the distribution of cycle lengths for a\nclass of permutation maps over $\\mathbb{Z}_{p^k}$. The approach combines\ntechniques from generating functions, minimal polynomials, and lifting theory\nto track how the cycle structure adapts as the modulus $p^k$ changes. To\nvalidate the generality and effectiveness of our method, we apply it to the\nwell-known Cat map as a canonical example, revealing the exact patterns\ngoverning its cycle formation and transition. This analysis not only provides\nrigorous explanations for experimentally observed regularities in fixed-point\nimplementations of such maps but also lays a theoretical foundation for\nevaluating the randomness and dynamical behavior of pseudorandom number\nsequences generated by other nonlinear maps. The results have broad\nimplications for secure system design, computational number theory, and\nsymbolic dynamics.", "published": "2025-06-25 04:15:33", "link": "http://arxiv.org/abs/2506.20118v1", "categories": ["math.NT", "cs.IT", "math.IT", "11T06, 37P25"], "primary_category": "math.NT"}
{"title": "DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy", "abstract": "We propose DemoDiffusion, a simple and scalable method for enabling robots to\nperform manipulation tasks in natural environments by imitating a single human\ndemonstration. Our approach is based on two key insights. First, the hand\nmotion in a human demonstration provides a useful prior for the robot's\nend-effector trajectory, which we can convert into a rough open-loop robot\nmotion trajectory via kinematic retargeting. Second, while this retargeted\nmotion captures the overall structure of the task, it may not align well with\nplausible robot actions in-context. To address this, we leverage a pre-trained\ngeneralist diffusion policy to modify the trajectory, ensuring it both follows\nthe human motion and remains within the distribution of plausible robot\nactions. Our approach avoids the need for online reinforcement learning or\npaired human-robot data, enabling robust adaptation to new tasks and scenes\nwith minimal manual effort. Experiments in both simulation and real-world\nsettings show that DemoDiffusion outperforms both the base policy and the\nretargeted trajectory, enabling the robot to succeed even on tasks where the\npre-trained generalist policy fails entirely. Project page:\nhttps://demodiffusion.github.io/", "published": "2025-06-25 17:59:01", "link": "http://arxiv.org/abs/2506.20668v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning", "abstract": "Recent work has shown that gradient updates in federated learning (FL) can\nunintentionally reveal sensitive information about a client's local data. This\nrisk becomes significantly greater when a malicious server manipulates the\nglobal model to provoke information-rich updates from clients. In this paper,\nwe adopt a defender's perspective to provide the first comprehensive analysis\nof malicious gradient leakage attacks and the model manipulation techniques\nthat enable them. Our investigation reveals a core trade-off: these attacks\ncannot be both highly effective in reconstructing private data and sufficiently\nstealthy to evade detection -- especially in realistic FL settings that\nincorporate common normalization techniques and federated averaging.\n  Building on this insight, we argue that malicious gradient leakage attacks,\nwhile theoretically concerning, are inherently limited in practice and often\ndetectable through basic monitoring. As a complementary contribution, we\npropose a simple, lightweight, and broadly applicable client-side detection\nmechanism that flags suspicious model updates before local training begins,\ndespite the fact that such detection may not be strictly necessary in realistic\nFL settings. This mechanism further underscores the feasibility of defending\nagainst these attacks with minimal overhead, offering a deployable safeguard\nfor privacy-conscious federated learning systems.", "published": "2025-06-25 17:49:26", "link": "http://arxiv.org/abs/2506.20651v1", "categories": ["cs.LG", "cs.CR", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer", "abstract": "The problem of learning to defer with multiple experts consists of optimally\nassigning input instances to experts, balancing the trade-off between their\naccuracy and computational cost. This is a critical challenge in natural\nlanguage generation, but also in other fields such as image processing, and\nmedical diagnostics. Recent studies have proposed surrogate loss functions to\noptimize deferral, but challenges remain in ensuring their consistency\nproperties. This paper introduces novel surrogate loss functions and efficient\nalgorithms with strong theoretical learning guarantees. We address open\nquestions regarding realizable $H$-consistency, $H$-consistency bounds, and\nBayes-consistency for both single-stage (jointly learning predictor and\ndeferral function) and two-stage (learning only the deferral function with a\nfixed expert) learning scenarios. For single-stage deferral, we introduce a\nfamily of new realizable $H$-consistent surrogate losses and further prove\n$H$-consistency for a selected member. For two-stage deferral, we derive new\nsurrogate losses that achieve realizable $H$-consistency, $H$-consistency\nbounds, and Bayes-consistency for the two-expert scenario and, under natural\nassumptions, multiple-expert scenario. Additionally, we provide enhanced\ntheoretical guarantees under low-noise assumptions for both scenarios. Finally,\nwe report the results of experiments using our proposed surrogate losses,\ncomparing their performance against existing baselines.", "published": "2025-06-25 17:48:58", "link": "http://arxiv.org/abs/2506.20650v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices", "abstract": "As privacy protection gains increasing importance, more models are being\ntrained on edge devices and subsequently merged into the central server through\nFederated Learning (FL). However, current research overlooks the impact of\nnetwork topology, physical distance, and data heterogeneity on edge devices,\nleading to issues such as increased latency and degraded model performance. To\naddress these issues, we propose a new federated learning scheme on edge\ndevices that called Federated Learning with Encrypted Data Sharing(FedEDS).\nFedEDS uses the client model and the model's stochastic layer to train the data\nencryptor. The data encryptor generates encrypted data and shares it with other\nclients. The client uses the corresponding client's stochastic layer and\nencrypted data to train and adjust the local model. FedEDS uses the client's\nlocal private data and encrypted shared data from other clients to train the\nmodel. This approach accelerates the convergence speed of federated learning\ntraining and mitigates the negative impact of data heterogeneity, making it\nsuitable for application services deployed on edge devices requiring rapid\nconvergence. Experiments results show the efficacy of FedEDS in promoting model\nperformance.", "published": "2025-06-25 17:40:54", "link": "http://arxiv.org/abs/2506.20644v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "First-order methods for stochastic and finite-sum convex optimization with deterministic constraints", "abstract": "In this paper, we study a class of stochastic and finite-sum convex\noptimization problems with deterministic constraints. Existing methods\ntypically aim to find an $\\epsilon$-$expectedly\\ feasible\\ stochastic\\ optimal$\nsolution, in which the expected constraint violation and expected optimality\ngap are both within a prescribed tolerance $\\epsilon$. However, in many\npractical applications, constraints must be nearly satisfied with certainty,\nrendering such solutions potentially unsuitable due to the risk of substantial\nviolations. To address this issue, we propose stochastic first-order methods\nfor finding an $\\epsilon$-$surely\\ feasible\\ stochastic\\ optimal$\n($\\epsilon$-SFSO) solution, where the constraint violation is deterministically\nbounded by $\\epsilon$ and the expected optimality gap is at most $\\epsilon$.\nOur methods apply an accelerated stochastic gradient (ASG) scheme or a modified\nvariance-reduced ASG scheme $only\\ once$ to a sequence of quadratic penalty\nsubproblems with appropriately chosen penalty parameters. We establish\nfirst-order oracle complexity bounds for the proposed methods in computing an\n$\\epsilon$-SFSO solution. As a byproduct, we also derive first-order oracle\ncomplexity results for sample average approximation method in computing an\n$\\epsilon$-SFSO solution of the stochastic optimization problem using our\nproposed methods to solve the sample average problem.", "published": "2025-06-25 17:26:02", "link": "http://arxiv.org/abs/2506.20630v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning", "abstract": "Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented by polluting the data with an\ninfinitesimal fraction of data points generated from a fixed model, by relying\non maximum a posteriori estimation or by introducing regularisation.\nFurthermore, we show that the asymptotic behavior of the dynamics is not\nreparametrisation invariant.", "published": "2025-06-25 17:12:22", "link": "http://arxiv.org/abs/2506.20623v1", "categories": ["cs.LG", "cond-mat.dis-nn", "physics.data-an", "stat.ML"], "primary_category": "cs.LG"}
{"title": "H-FEX: A Symbolic Learning Method for Hamiltonian Systems", "abstract": "Hamiltonian systems describe a broad class of dynamical systems governed by\nHamiltonian functions, which encode the total energy and dictate the evolution\nof the system. Data-driven approaches, such as symbolic regression and neural\nnetwork-based methods, provide a means to learn the governing equations of\ndynamical systems directly from observational data of Hamiltonian systems.\nHowever, these methods often struggle to accurately capture complex Hamiltonian\nfunctions while preserving energy conservation. To overcome this limitation, we\npropose the Finite Expression Method for learning Hamiltonian Systems (H-FEX),\na symbolic learning method that introduces novel interaction nodes designed to\ncapture intricate interaction terms effectively. Our experiments, including\nthose on highly stiff dynamical systems, demonstrate that H-FEX can recover\nHamiltonian functions of complex systems that accurately capture system\ndynamics and preserve energy over long time horizons. These findings highlight\nthe potential of H-FEX as a powerful framework for discovering closed-form\nexpressions of complex dynamical systems.", "published": "2025-06-25 16:53:01", "link": "http://arxiv.org/abs/2506.20607v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The kernel of graph indices for vector search", "abstract": "The most popular graph indices for vector search use principles from\ncomputational geometry to build the graph. Hence, their formal graph\nnavigability guarantees are only valid in Euclidean space. In this work, we\nshow that machine learning can be used to build graph indices for vector search\nin metric and non-metric vector spaces (e.g., for inner product similarity).\nFrom this novel perspective, we introduce the Support Vector Graph (SVG), a new\ntype of graph index that leverages kernel methods to establish the graph\nconnectivity and that comes with formal navigability guarantees valid in metric\nand non-metric vector spaces. In addition, we interpret the most popular graph\nindices, including HNSW and DiskANN, as particular specializations of SVG and\nshow that new indices can be derived from the principles behind this\nspecialization. Finally, we propose SVG-L0 that incorporates an $\\ell_0$\nsparsity constraint into the SVG kernel method to build graphs with a bounded\nout-degree. This yields a principled way of implementing this practical\nrequirement, in contrast to the traditional heuristic of simply truncating the\nout edges of each node. Additionally, we show that SVG-L0 has a self-tuning\nproperty that avoids the heuristic of using a set of candidates to find the\nout-edges of each node and that keeps its computational complexity in check.", "published": "2025-06-25 16:24:55", "link": "http://arxiv.org/abs/2506.20584v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring Graph-Transformer Out-of-Distribution Generalization Abilities", "abstract": "Deep learning on graphs has shown remarkable success across numerous\napplications, including social networks, bio-physics, traffic networks, and\nrecommendation systems. Regardless of their successes, current methods\nfrequently depend on the assumption that training and testing data share the\nsame distribution, a condition rarely met in real-world scenarios. While\ngraph-transformer (GT) backbones have recently outperformed traditional\nmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)\nbenchmarks, their effectiveness under distribution shifts remains largely\nunexplored.\n  In this work, we address the challenge of out-of-distribution (OOD)\ngeneralization for graph neural networks, with a special focus on the impact of\nbackbone architecture. We systematically evaluate GT and hybrid backbones in\nOOD settings and compare them to MPNNs. To do so, we adapt several leading\ndomain generalization (DG) algorithms to work with GTs and assess their\nperformance on a benchmark designed to test a variety of distribution shifts.\nOur results reveal that GT and hybrid GT-MPNN backbones consistently\ndemonstrate stronger generalization ability compared to MPNNs, even without\nspecialized DG algorithms.\n  Additionally, we propose a novel post-training analysis approach that\ncompares the clustering structure of the entire ID and OOD test datasets,\nspecifically examining domain alignment and class separation. Demonstrating its\nmodel-agnostic design, this approach not only provided meaningful insights into\nGT and MPNN backbones. It also shows promise for broader applicability to DG\nproblems beyond graph learning, offering a deeper perspective on generalization\nabilities that goes beyond standard accuracy metrics. Together, our findings\nhighlight the promise of graph-transformers for robust, real-world graph\nlearning and set a new direction for future research in OOD generalization.", "published": "2025-06-25 16:09:24", "link": "http://arxiv.org/abs/2506.20575v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series", "abstract": "Anomaly detection in multivariate time series is an important problem across\nvarious fields such as healthcare, financial services, manufacturing or physics\ndetector monitoring. Accurately identifying when unexpected errors or faults\noccur is essential, yet challenging, due to the unknown nature of anomalies and\nthe complex interdependencies between time series dimensions. In this paper, we\ninvestigate transformer-based approaches for time series anomaly detection,\nfocusing on the recently proposed iTransformer architecture. Our contributions\nare fourfold: (i) we explore the application of the iTransformer to time series\nanomaly detection, and analyse the influence of key parameters such as window\nsize, step size, and model dimensions on performance; (ii) we examine methods\nfor extracting anomaly labels from multidimensional anomaly scores and discuss\nappropriate evaluation metrics for such labels; (iii) we study the impact of\nanomalous data present during training and assess the effectiveness of\nalternative loss functions in mitigating their influence; and (iv) we present a\ncomprehensive comparison of several transformer-based models across a diverse\nset of datasets for time series anomaly detection.", "published": "2025-06-25 16:08:22", "link": "http://arxiv.org/abs/2506.20574v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "LARP: Learner-Agnostic Robust Data Prefiltering", "abstract": "The widespread availability of large public datasets is a key factor behind\nthe recent successes of statistical inference and machine learning methods.\nHowever, these datasets often contain some low-quality or contaminated data, to\nwhich many learning procedures are sensitive. Therefore, the question of\nwhether and how public datasets should be prefiltered to facilitate accurate\ndownstream learning arises. On a technical level this requires the construction\nof principled data prefiltering methods which are learner-agnostic robust, in\nthe sense of provably protecting a set of pre-specified downstream learners\nfrom corrupted data. In this work, we formalize the problem of Learner-Agnostic\nRobust data Prefiltering (LARP), which aims at finding prefiltering procedures\nthat minimize a worst-case loss over a pre-specified set of learners. We first\ninstantiate our framework in the context of scalar mean estimation with Huber\nestimators under the Huber data contamination model. We provide a hardness\nresult on a specific problem instance and analyze several natural prefiltering\nprocedures. Our theoretical results indicate that performing LARP on a\nheterogeneous set of learners leads to some loss in model performance compared\nto the alternative of prefiltering data for each learner/use-case individually.\nWe explore the resulting utility loss and its dependence on the problem\nparameters via extensive experiments on real-world image and tabular data,\nobserving statistically significant reduction in utility. Finally, we model the\ntrade-off between the utility drop and the cost of repeated (learner-specific)\nprefiltering within a game-theoretic framework and showcase benefits of LARP\nfor large datasets.", "published": "2025-06-25 16:07:59", "link": "http://arxiv.org/abs/2506.20573v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Reinforcement Learning Increases Wind Farm Power Production by Enabling Closed-Loop Collaborative Control", "abstract": "Traditional wind farm control operates each turbine independently to maximize\nindividual power output. However, coordinated wake steering across the entire\nfarm can substantially increase the combined wind farm energy production.\nAlthough dynamic closed-loop control has proven effective in flow control\napplications, wind farm optimization has relied primarily on static,\nlow-fidelity simulators that ignore critical turbulent flow dynamics. In this\nwork, we present the first reinforcement learning (RL) controller integrated\ndirectly with high-fidelity large-eddy simulation (LES), enabling real-time\nresponse to atmospheric turbulence through collaborative, dynamic control\nstrategies. Our RL controller achieves a 4.30% increase in wind farm power\noutput compared to baseline operation, nearly doubling the 2.19% gain from\nstatic optimal yaw control obtained through Bayesian optimization. These\nresults establish dynamic flow-responsive control as a transformative approach\nto wind farm optimization, with direct implications for accelerating renewable\nenergy deployment to net-zero targets.", "published": "2025-06-25 15:53:12", "link": "http://arxiv.org/abs/2506.20554v1", "categories": ["physics.flu-dyn", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "physics.flu-dyn"}
{"title": "Demonstration of effective UCB-based routing in skill-based queues on real-world data", "abstract": "This paper is about optimally controlling skill-based queueing systems such\nas data centers, cloud computing networks, and service systems. By means of a\ncase study using a real-world data set, we investigate the practical\nimplementation of a recently developed reinforcement learning algorithm for\noptimal customer routing. Our experiments show that the algorithm efficiently\nlearns and adapts to changing environments and outperforms static benchmark\npolicies, indicating its potential for live implementation. We also augment the\nreal-world applicability of this algorithm by introducing a new heuristic\nrouting rule to reduce delays. Moreover, we show that the algorithm can\noptimize for multiple objectives: next to payoff maximization, secondary\nobjectives such as server load fairness and customer waiting time reduction can\nbe incorporated. Tuning parameters are used for balancing inherent performance\ntrade--offs. Lastly, we investigate the sensitivity to estimation errors and\nparameter tuning, providing valuable insights for implementing adaptive routing\nalgorithms in complex real-world queueing systems.", "published": "2025-06-25 15:36:43", "link": "http://arxiv.org/abs/2506.20543v1", "categories": ["cs.LG", "math.OC", "60K25, 93E35"], "primary_category": "cs.LG"}
{"title": "Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion", "abstract": "Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process\nprediction due to the lasting issue of high computation cost using traditional\nnumerical methods such as finite element analysis (FEA). This study presents an\nefficient modeling framework termed FEA-Regulated Physics-Informed Neural\nNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF process\nwhile maintaining the FEA accuracy. A novel dynamic material updating strategy\nis developed to capture the dynamic phase change of powder-liquid-solid in the\nPINN model. The PINN model incorporates temperature-dependent material\nproperties and phase change behavior using the apparent heat capacity method.\nWhile the PINN model demonstrates high accuracy with a small training data and\nenables generalization of new process parameters via transfer learning, it\nfaces the challenge of high computation cost in time-dependent problems due to\nthe residual accumulation. To overcome this issue, the FEA-PINN framework\nintegrates corrective FEA simulations during inference to enforce physical\nconsistency and reduce error drift. A comparative analysis shows that FEA-PINN\nachieves equivalent accuracy to FEA while significantly reducing computational\ncost. The framework has been validated using the benchmark FEA data and\ndemonstrated through single-track scanning in LPBF.", "published": "2025-06-25 15:25:01", "link": "http://arxiv.org/abs/2506.20537v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery", "abstract": "Robust subspace estimation is fundamental to many machine learning and data\nanalysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and\nempirically effective approach to this problem, yet its theoretical properties\nremain poorly understood. This paper establishes that, under deterministic\nconditions, a variant of IRLS with dynamic smoothing regularization converges\nlinearly to the underlying subspace from any initialization. We extend these\nguarantees to affine subspace estimation, a setting that lacks prior recovery\ntheory. Additionally, we illustrate the practical benefits of IRLS through an\napplication to low-dimensional neural network training. Our results provide the\nfirst global convergence guarantees for IRLS in robust subspace recovery and,\nmore broadly, for nonconvex IRLS on a Riemannian manifold.", "published": "2025-06-25 15:23:32", "link": "http://arxiv.org/abs/2506.20533v1", "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "stat.ML"}
{"title": "WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning", "abstract": "Federated Learning (FL) is a collaborative machine learning paradigm which\nallows participants to collectively train a model while training data remains\nprivate. This paradigm is especially beneficial for sectors like finance, where\ndata privacy, security and model performance are paramount. FL has been\nextensively studied in the years following its introduction, leading to, among\nothers, better performing collaboration techniques, ways to defend against\nother clients trying to attack the model, and contribution assessment methods.\nAn important element in for-profit Federated Learning is the development of\nincentive methods to determine the allocation and distribution of rewards for\nparticipants. While numerous methods for allocation have been proposed and\nthoroughly explored, distribution frameworks remain relatively understudied. In\nthis paper, we propose a novel framework which introduces client-specific\ntokens as investment vehicles within the FL ecosystem. Our framework aims to\naddress the limitations of existing incentive schemes by leveraging a\ndecentralized finance (DeFi) platform and automated market makers (AMMs) to\ncreate a more flexible and scalable reward distribution system for\nparticipants, and a mechanism for third parties to invest in the federation\nlearning process.", "published": "2025-06-25 15:05:01", "link": "http://arxiv.org/abs/2506.20518v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast ground penetrating radar dual-parameter full waveform inversion method accelerated by hybrid compilation of CUDA kernel function and PyTorch", "abstract": "This study proposes a high-performance dual-parameter full waveform inversion\nframework (FWI) for ground-penetrating radar (GPR), accelerated through the\nhybrid compilation of CUDA kernel functions and PyTorch. The method leverages\nthe computational efficiency of GPU programming while preserving the\nflexibility and usability of Python-based deep learning frameworks. By\nintegrating customized CUDA kernels into PyTorch's automatic differentiation\nmechanism, the framework enables accurate and efficient inversion of both\ndielectric permittivity and electrical conductivity. Experimental evaluations\non synthetic data and real wavefield data demonstrate that the proposed method\nachieves dual-parameter FWI for GPR data while maintaining high accuracy.\nMoreover, the framework is flexible and extensible, supporting optional\nregularization strategies such as total variation and multi-scale inversion.\nThese features make the proposed approach a practical and scalable framework\nfor rapid GPR-based subsurface imaging in applications including civil\nengineering, environmental monitoring, and geophysical exploration.", "published": "2025-06-25 15:00:33", "link": "http://arxiv.org/abs/2506.20513v1", "categories": ["physics.geo-ph", "cs.LG", "eess.SP"], "primary_category": "physics.geo-ph"}
{"title": "Collaborative Batch Size Optimization for Federated Learning", "abstract": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized.", "published": "2025-06-25 14:57:23", "link": "http://arxiv.org/abs/2506.20511v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Multimodal Representation Learning and Fusion", "abstract": "Multi-modal learning is a fast growing area in artificial intelligence. It\ntries to help machines understand complex things by combining information from\ndifferent sources, like images, text, and audio. By using the strengths of each\nmodality, multi-modal learning allows AI systems to build stronger and richer\ninternal representations. These help machines better interpretation, reasoning,\nand making decisions in real-life situations. This field includes core\ntechniques such as representation learning (to get shared features from\ndifferent data types), alignment methods (to match information across\nmodalities), and fusion strategies (to combine them by deep learning models).\nAlthough there has been good progress, some major problems still remain. Like\ndealing with different data formats, missing or incomplete inputs, and\ndefending against adversarial attacks. Researchers now are exploring new\nmethods, such as unsupervised or semi-supervised learning, AutoML tools, to\nmake models more efficient and easier to scale. And also more attention on\ndesigning better evaluation metrics or building shared benchmarks, make it\neasier to compare model performance across tasks and domains. As the field\ncontinues to grow, multi-modal learning is expected to improve many areas:\ncomputer vision, natural language processing, speech recognition, and\nhealthcare. In the future, it may help to build AI systems that can understand\nthe world in a way more like humans, flexible, context aware, and able to deal\nwith real-world complexity.", "published": "2025-06-25 14:40:09", "link": "http://arxiv.org/abs/2506.20494v1", "categories": ["cs.LG", "cs.MM"], "primary_category": "cs.LG"}
{"title": "M\u00e9thode de quadrature pour les PINNs fond\u00e9e th\u00e9oriquement sur la hessienne des r\u00e9siduels", "abstract": "Physics-informed Neural Networks (PINNs) have emerged as an efficient way to\nlearn surrogate neural solvers of PDEs by embedding the physical model in the\nloss function and minimizing its residuals using automatic differentiation at\nso-called collocation points. Originally uniformly sampled, the choice of the\nlatter has been the subject of recent advances leading to adaptive sampling\nrefinements. In this paper, we propose a new quadrature method for\napproximating definite integrals based on the hessian of the considered\nfunction, and that we leverage to guide the selection of the collocation points\nduring the training process of PINNs.", "published": "2025-06-25 13:49:53", "link": "http://arxiv.org/abs/2506.20441v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation", "abstract": "Federated learning aims to train a global model in a distributed environment\nthat is close to the performance of centralized training. However, issues such\nas client label skew, data quantity skew, and other heterogeneity problems\nseverely degrade the model's performance. Most existing methods overlook the\nscenario where only a small portion of clients participate in training within a\nlarge-scale client setting, whereas our experiments show that this scenario\npresents a more challenging federated learning task. Therefore, we propose a\nKnowledge Distillation with teacher-student Inequitable Aggregation (KDIA)\nstrategy tailored to address the federated learning setting mentioned above,\nwhich can effectively leverage knowledge from all clients. In KDIA, the student\nmodel is the average aggregation of the participating clients, while the\nteacher model is formed by a weighted aggregation of all clients based on three\nfrequencies: participation intervals, participation counts, and data volume\nproportions. During local training, self-knowledge distillation is performed.\nAdditionally, we utilize a generator trained on the server to generate\napproximately independent and identically distributed (IID) data features\nlocally for auxiliary training. We conduct extensive experiments on the\nCIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate\nKDIA. The results show that KDIA can achieve better accuracy with fewer rounds\nof training, and the improvement is more significant under severe\nheterogeneity.", "published": "2025-06-25 13:42:30", "link": "http://arxiv.org/abs/2506.20431v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Scalable Subset Selection in Linear Mixed Models", "abstract": "Linear mixed models (LMMs), which incorporate fixed and random effects, are\nkey tools for analyzing heterogeneous data, such as in personalized medicine or\nadaptive marketing. Nowadays, this type of data is increasingly wide, sometimes\ncontaining thousands of candidate predictors, necessitating sparsity for\nprediction and interpretation. However, existing sparse learning methods for\nLMMs do not scale well beyond tens or hundreds of predictors, leaving a large\ngap compared with sparse methods for linear models, which ignore random\neffects. This paper closes the gap with a new $\\ell_0$ regularized method for\nLMM subset selection that can run on datasets containing thousands of\npredictors in seconds to minutes. On the computational front, we develop a\ncoordinate descent algorithm as our main workhorse and provide a guarantee of\nits convergence. We also develop a local search algorithm to help traverse the\nnonconvex optimization surface. Both algorithms readily extend to subset\nselection in generalized LMMs via a penalized quasi-likelihood approximation.\nOn the statistical front, we provide a finite-sample bound on the\nKullback-Leibler divergence of the new method. We then demonstrate its\nexcellent performance in synthetic experiments and illustrate its utility on\ntwo datasets from biology and journalism.", "published": "2025-06-25 13:39:30", "link": "http://arxiv.org/abs/2506.20425v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis", "abstract": "Satellite remote sensing (RS) enables a wide array of downstream Earth\nobservation (EO) applications, including climate modeling, carbon accounting,\nand strategies for conservation and sustainable land use. We present TESSERA, a\nnovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning\n(SSL) to generate global, robust representations at 10m scale from pixel-level\nsatellite time series data. TESSERA combines information from only optical and\nSAR data streams using two parallel Transformer-based encoders: one dedicated\nto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected\nspectral bands) to create representations that are then fused using a\nmultilayer perceptron (MLP), resulting in a global representation map covering\nthe years 2017 to 2024. Our precomputed representations set a new\nstate-of-the-art performance benchmark and our open-source approach\ndemocratizes access to high-performance, high-resolution representations. We\nbenchmark the performance of TESSERA in five diverse tasks, comparing our work\nwith state-of-the-art task-specific models and other foundation models. Our\nresults show that TESSERA outperforms both traditional RS baselines and the\nleading geospatial foundation models in these diverse downstream tasks.", "published": "2025-06-25 12:46:26", "link": "http://arxiv.org/abs/2506.20380v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach", "abstract": "Trajectory analysis is not only about obtaining movement data, but it is also\nof paramount importance in understanding the pattern in which an object moves\nthrough space and time, as well as in predicting its next move. Due to the\nsignificant interest in the area, data collection has improved substantially,\nresulting in a large number of features becoming available for training and\npredicting models. However, this introduces a high-dimensionality-induced\nfeature explosion problem, which reduces the efficiency and interpretability of\nthe data, thereby reducing the accuracy of machine learning models. To overcome\nthis issue, feature selection has become one of the most prevalent tools. Thus,\nthe objective of this paper was to introduce a taxonomy-based feature selection\nmethod that categorizes features based on their internal structure. This\napproach classifies the data into geometric and kinematic features, further\ncategorizing them into curvature, indentation, speed, and acceleration. The\ncomparative analysis indicated that a taxonomy-based approach consistently\nachieved comparable or superior predictive performance. Furthermore, due to the\ntaxonomic grouping, which reduces combinatorial space, the time taken to select\nfeatures was drastically reduced. The taxonomy was also used to gain insights\ninto what feature sets each dataset was more sensitive to. Overall, this study\nprovides robust evidence that a taxonomy-based feature selection method can add\na layer of interpretability, reduce dimensionality and computational\ncomplexity, and contribute to high-level decision-making. It serves as a step\ntoward providing a methodological framework for researchers and practitioners\ndealing with trajectory datasets and contributing to the broader field of\nexplainable artificial intelligence.", "published": "2025-06-25 12:21:20", "link": "http://arxiv.org/abs/2506.20359v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data", "abstract": "Granger Causality (GC) offers an elegant statistical framework to study the\nassociation between multivariate time series data. Linear Vector Autoregressive\nmodels (VAR) though have nice interpretation properties but have limited\npractical application due to underlying assumptions on the kind of associations\nthat can be captured by these models. Numerous attempts have already been made\nin the literature that exploit the functional approximation power of Deep\nNeural Networks (DNNs) for the task of GC estimation. These methods however\ntreat GC as a variable selection problem. We present a novel paradigm for\napproaching GC. We present this idea that GC is essentially linked with\nprediction and if a deep learning model is used to model the time series\ncollectively or jointly, a well regularized model may learn the true granger\ncausal structure from the data, given that there is enough training data. We\npropose to uncover the learned GC structure by comparing the model uncertainty\nor distribution of the residuals when the past of everything is used as\ncompared to the one where a specific time series component is dropped from the\nmodel. We also compare the effect of input layer dropout on the ability of a\nneural network to learn granger causality from the data. We show that a well\nregularized model infact can learn the true GC structure from the data without\nexplicitly adding terms in the loss function that guide the model to select\nvariables or perform sparse regression.", "published": "2025-06-25 11:57:24", "link": "http://arxiv.org/abs/2506.20347v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization", "abstract": "Despite its wide range of applications across various domains, the\noptimization foundations of deep matrix factorization (DMF) remain largely\nopen. In this work, we aim to fill this gap by conducting a comprehensive study\nof the loss landscape of the regularized DMF problem. Toward this goal, we\nfirst provide a closed-form expression of all critical points. Building on\nthis, we establish precise conditions under which a critical point is a local\nminimizer, a global minimizer, a strict saddle point, or a non-strict saddle\npoint. Leveraging these results, we derive a necessary and sufficient condition\nunder which each critical point is either a local minimizer or a strict saddle\npoint. This provides insights into why gradient-based methods almost always\nconverge to a local minimizer of the regularized DMF problem. Finally, we\nconduct numerical experiments to visualize its loss landscape under different\nsettings to support our theory.", "published": "2025-06-25 11:51:41", "link": "http://arxiv.org/abs/2506.20344v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Recurrent neural network-based robust control systems with closed-loop regional incremental ISS and application to MPC design", "abstract": "This paper investigates the design of output-feedback schemes for systems\ndescribed by a class of recurrent neural networks. We propose a procedure based\non linear matrix inequalities for designing an observer and a static\nstate-feedback controller. The algorithm leverages global and regional\nincremental input-to-state stability (incremental ISS) and enables the tracking\nof constant setpoints, ensuring robustness to disturbances and state estimation\nuncertainty. To address the potential limitations of regional incremental ISS,\nwe introduce an alternative scheme in which the static law is replaced with a\ntube-based nonlinear model predictive controller (NMPC) that exploits regional\nincremental ISS properties. We show that these conditions enable the\nformulation of a robust NMPC law with guarantees of convergence and recursive\nfeasibility, leading to an enlarged region of attraction. Theoretical results\nare validated through numerical simulations on the pH-neutralisation process\nbenchmark, demonstrating the effectiveness of the proposed schemes.", "published": "2025-06-25 11:44:28", "link": "http://arxiv.org/abs/2506.20334v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Producer-Fairness in Sequential Bundle Recommendation", "abstract": "We address fairness in the context of sequential bundle recommendation, where\nusers are served in turn with sets of relevant and compatible items. Motivated\nby real-world scenarios, we formalize producer-fairness, that seeks to achieve\ndesired exposure of different item groups across users in a recommendation\nsession. Our formulation combines naturally with building high quality bundles.\nOur problem is solved in real time as users arrive. We propose an exact\nsolution that caters to small instances of our problem. We then examine two\nheuristics, quality-first and fairness-first, and an adaptive variant that\ndetermines on-the-fly the right balance between bundle fairness and quality.\nOur experiments on three real-world datasets underscore the strengths and\nlimitations of each solution and demonstrate their efficacy in providing fair\nbundle recommendations without compromising bundle quality.", "published": "2025-06-25 11:24:52", "link": "http://arxiv.org/abs/2506.20329v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning", "abstract": "Dynamic graphs exhibit complex temporal dynamics due to the interplay between\nevolving node features and changing network structures. Recently, Graph Neural\nControlled Differential Equations (Graph Neural CDEs) successfully adapted\nNeural CDEs from paths on Euclidean domains to paths on graph domains. Building\non this foundation, we introduce Permutation Equivariant Neural Graph CDEs,\nwhich project Graph Neural CDEs onto permutation equivariant function spaces.\nThis significantly reduces the model's parameter count without compromising\nrepresentational power, resulting in more efficient training and improved\ngeneralisation. We empirically demonstrate the advantages of our approach\nthrough experiments on simulated dynamical systems and real-world tasks,\nshowing improved performance in both interpolation and extrapolation scenarios.", "published": "2025-06-25 11:06:30", "link": "http://arxiv.org/abs/2506.20324v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "OLALa: Online Learned Adaptive Lattice Codes for Heterogeneous Federated Learning", "abstract": "Federated learning (FL) enables collaborative training across distributed\nclients without sharing raw data, often at the cost of substantial\ncommunication overhead induced by transmitting high-dimensional model updates.\nThis overhead can be alleviated by having the clients quantize their model\nupdates, with dithered lattice quantizers identified as an attractive scheme\ndue to its structural simplicity and convergence-preserving properties.\nHowever, existing lattice-based FL schemes typically rely on a fixed\nquantization rule, which is suboptimal in heterogeneous and dynamic\nenvironments where the model updates distribution varies across users and\ntraining rounds. In this work, we propose Online Learned Adaptive Lattices\n(OLALa), a heterogeneous FL framework where each client can adjust its\nquantizer online using lightweight local computations. We first derive\nconvergence guarantees for FL with non-fixed lattice quantizers and show that\nproper lattice adaptation can tighten the convergence bound. Then, we design an\nonline learning algorithm that enables clients to tune their quantizers\nthroughout the FL process while exchanging only a compact set of quantization\nparameters. Numerical experiments demonstrate that OLALa consistently improves\nlearning performance under various quantization rates, outperforming\nconventional fixed-codebook and non-adaptive schemes.", "published": "2025-06-25 10:18:34", "link": "http://arxiv.org/abs/2506.20297v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Distilling A Universal Expert from Clustered Federated Learning", "abstract": "Clustered Federated Learning (CFL) addresses the challenges posed by non-IID\ndata by training multiple group- or cluster-specific expert models. However,\nexisting methods often overlook the shared information across clusters, which\nrepresents the generalizable knowledge valuable to all participants in the\nFederated Learning (FL) system. To overcome this limitation, this paper\nintroduces a novel FL framework that distills a universal expert model from the\nknowledge of multiple clusters. This universal expert captures globally shared\ninformation across all clients and is subsequently distributed to each client\nas the initialization for the next round of model training. The proposed FL\nframework operates in three iterative steps: (1) local model training at each\nclient, (2) cluster-specific model aggregation, and (3) universal expert\ndistillation. This three-step learning paradigm ensures the preservation of\nfine-grained non-IID characteristics while effectively incorporating shared\nknowledge across clusters. Compared to traditional gradient-based aggregation\nmethods, the distillation-based model aggregation introduces greater\nflexibility in handling model heterogeneity and reduces conflicts among\ncluster-specific experts. Extensive experimental results demonstrate the\nsuperior performance of the proposed method across various scenarios,\nhighlighting its potential to advance the state of CFL by balancing\npersonalized and shared knowledge more effectively.", "published": "2025-06-25 09:44:39", "link": "http://arxiv.org/abs/2506.20285v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs", "abstract": "Large language models (LLMs) deliver strong performance but are difficult to\ndeploy due to high memory and compute costs. While pruning reduces these\ndemands, most methods ignore activation sparsity observed at runtime. We\nreinterpret activation sparsity as dynamic structured weight sparsity and\npropose DuoGPT, a unified framework that constructs dual-sparse (spMspV)\nworkloads by combining unstructured weight pruning with activation sparsity. To\npreserve accuracy, we extend the Optimal Brain Compression (OBC) framework with\nactivation-aware calibration and introduce output residuals from the dense\nmodel as correction terms. We further optimize the solution for efficient GPU\nexecution, enabling scalability to billion-parameter LLMs. Evaluations on\nLLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured\npruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$\ncompared to the baseline dense model.", "published": "2025-06-25 07:35:12", "link": "http://arxiv.org/abs/2506.20194v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks", "abstract": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.", "published": "2025-06-25 07:15:42", "link": "http://arxiv.org/abs/2506.20181v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Causal discovery in deterministic discrete LTI-DAE systems", "abstract": "Discovering pure causes or driver variables in deterministic LTI systems is\nof vital importance in the data-driven reconstruction of causal networks. A\nrecent work by Kathari and Tangirala, proposed in 2022, formulated the causal\ndiscovery method as a constraint identification problem. The constraints are\nidentified using a dynamic iterative PCA (DIPCA)-based approach for dynamical\nsystems corrupted with Gaussian measurement errors. The DIPCA-based method\nworks efficiently for dynamical systems devoid of any algebraic relations.\nHowever, several dynamical systems operate under feedback control and/or are\ncoupled with conservation laws, leading to differential-algebraic (DAE) or\nmixed causal systems. In this work, a method, namely the partition of variables\n(PoV), for causal discovery in LTI-DAE systems is proposed. This method is\nsuperior to the method that was presented by Kathari and Tangirala (2022), as\nPoV also works for pure dynamical systems, which are devoid of algebraic\nequations. The proposed method identifies the causal drivers up to a minimal\nsubset. PoV deploys DIPCA to first determine the number of algebraic relations\n($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix.\nSubsequently, the subsets are identified through an admissible partitioning of\nthe constraint matrix by finding the condition number of it. Case studies are\npresented to demonstrate the effectiveness of the proposed method.", "published": "2025-06-25 06:47:22", "link": "http://arxiv.org/abs/2506.20169v1", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data", "abstract": "The explosive growth of AI research has driven paper submissions at flagship\nAI conferences to unprecedented levels, necessitating many venues in 2025\n(e.g., CVPR, ICCV, KDD, AAAI, IJCAI, WSDM) to enforce strict per-author\nsubmission limits and to desk-reject any excess papers by simple ID order.\nWhile this policy helps reduce reviewer workload, it may unintentionally\ndiscard valuable papers and penalize authors' efforts. In this paper, we ask an\nessential research question on whether it is possible to follow submission\nlimits while minimizing needless rejections. We first formalize the current\ndesk-rejection policies as an optimization problem, and then develop a\npractical algorithm based on linear programming relaxation and a rounding\nscheme. Under extensive evaluation on 11 years of real-world ICLR\n(International Conference on Learning Representations) data, our method\npreserves up to $19.23\\%$ more papers without violating any author limits.\nMoreover, our algorithm is highly efficient in practice, with all results on\nICLR data computed within at most 53.64 seconds. Our work provides a simple and\npractical desk-rejection strategy that significantly reduces unnecessary\nrejections, demonstrating strong potential to improve current CS conference\nsubmission policies.", "published": "2025-06-25 05:23:44", "link": "http://arxiv.org/abs/2506.20141v1", "categories": ["cs.DS", "cs.CY", "cs.DL", "cs.IR", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Piecewise Linear Approximation in Learned Index Structures: Theoretical and Empirical Analysis", "abstract": "A growing trend in the database and system communities is to augment\nconventional index structures, such as B+-trees, with machine learning (ML)\nmodels. Among these, error-bounded Piecewise Linear Approximation\n($\\epsilon$-PLA) has emerged as a popular choice due to its simplicity and\neffectiveness. Despite its central role in many learned indexes, the design and\nanalysis of $\\epsilon$-PLA fitting algorithms remain underexplored. In this\npaper, we revisit $\\epsilon$-PLA from both theoretical and empirical\nperspectives, with a focus on its application in learned index structures. We\nfirst establish a fundamentally improved lower bound of $\\Omega(\\kappa \\cdot\n\\epsilon^2)$ on the expected segment coverage for existing $\\epsilon$-PLA\nfitting algorithms, where $\\kappa$ is a data-dependent constant. We then\npresent a comprehensive benchmark of state-of-the-art $\\epsilon$-PLA algorithms\nwhen used in different learned data structures. Our results highlight key\ntrade-offs among model accuracy, model size, and query performance, providing\nactionable guidelines for the principled design of future learned data\nstructures.", "published": "2025-06-25 05:20:54", "link": "http://arxiv.org/abs/2506.20139v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data", "abstract": "Wildfires are increasing in intensity and severity at an alarming rate.\nRecent advances in AI and publicly available satellite data enable monitoring\ncritical wildfire risk factors globally, at high resolution and low latency.\nLive Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is\nvaluable for both wildfire research and operational response. However,\nground-based LFMC samples are both labor intensive and costly to acquire,\nresulting in sparse and infrequent updates. In this work, we explore the use of\na pretrained, highly-multimodal earth-observation model for generating\nlarge-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves\nsignificant improvements over previous methods using randomly initialized\nmodels (20 reduction in RMSE). We provide an automated pipeline that enables\nrapid generation of these LFMC maps across the United States, and demonstrate\nits effectiveness in two regions recently impacted by wildfire (Eaton and\nPalisades).", "published": "2025-06-25 04:59:10", "link": "http://arxiv.org/abs/2506.20132v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives", "abstract": "Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction.", "published": "2025-06-25 04:06:37", "link": "http://arxiv.org/abs/2506.20114v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox", "abstract": "The convergence of IT and OT has created hyper-connected ICS, exposing\ncritical infrastructure to a new class of adaptive, intelligent adversaries\nthat render static defenses obsolete. Existing security paradigms often fail to\naddress a foundational \"Trinity of Trust,\" comprising the fidelity of the\nsystem model, the integrity of synchronizing data, and the resilience of the\nanalytical engine against sophisticated evasion. This paper introduces the ARC\nframework, a method for achieving analytical resilience through an autonomous,\nclosed-loop hardening process. ARC establishes a perpetual co-evolutionary arms\nrace within the high-fidelity sandbox of a F-SCDT. A DRL agent, the \"Red\nAgent,\" is formalized and incentivized to autonomously discover stealthy,\nphysically-plausible attack paths that maximize process disruption while\nevading detection. Concurrently, an ensemble-based \"Blue Agent\" defender is\ncontinuously hardened via adversarial training against the evolving threats\ndiscovered by its adversary. This co-evolutionary dynamic forces both agents to\nbecome progressively more sophisticated, enabling the system to autonomously\nprobe and patch its own vulnerabilities. Experimental validation on both the\nTEP and the SWaT testbeds demonstrates the framework's superior performance. A\ncomprehensive ablation study, supported by extensive visualizations including\nROC curves and SHAP plots, reveals that the co-evolutionary process itself is\nresponsible for a significant performance increase in detecting novel attacks.\nBy integrating XAI to ensure operator trust and proposing a scalable F-ARC\narchitecture, this work presents ARC not merely as an improvement, but as a\nnecessary paradigm shift toward dynamic, self-improving security for the future\nof critical infrastructure.", "published": "2025-06-25 03:28:48", "link": "http://arxiv.org/abs/2506.20102v1", "categories": ["cs.CR", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.CR"}
{"title": "MEL: Multi-level Ensemble Learning for Resource-Constrained Environments", "abstract": "AI inference at the edge is becoming increasingly common for low-latency\nservices. However, edge environments are power- and resource-constrained, and\nsusceptible to failures. Conventional failure resilience approaches, such as\ncloud failover or compressed backups, often compromise latency or accuracy,\nlimiting their effectiveness for critical edge inference services. In this\npaper, we propose Multi-Level Ensemble Learning (MEL), a new framework for\nresilient edge inference that simultaneously trains multiple lightweight backup\nmodels capable of operating collaboratively, refining each other when multiple\nservers are available, and independently under failures while maintaining good\naccuracy. Specifically, we formulate our approach as a multi-objective\noptimization problem with a loss formulation that inherently encourages\ndiversity among individual models to promote mutually refining representations,\nwhile ensuring each model maintains good standalone performance. Empirical\nevaluations across vision, language, and audio datasets show that MEL provides\nperformance comparable to original architectures while also providing fault\ntolerance and deployment flexibility across edge platforms. Our results show\nthat our ensemble model, sized at 40\\% of the original model, achieves similar\nperformance, while preserving 95.6\\% of ensemble accuracy in the case of\nfailures when trained using MEL.", "published": "2025-06-25 02:33:57", "link": "http://arxiv.org/abs/2506.20094v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression", "abstract": "Predictive maintenance (PdM) has become a crucial element of modern\nindustrial practice. PdM plays a significant role in operational dependability\nand cost management by decreasing unforeseen downtime and optimizing asset life\ncycle management. Machine learning and deep learning have enabled more precise\nforecasts of equipment failure and remaining useful life (RUL). Although many\nstudies have been conducted on PdM, there has not yet been a standalone\ncomparative study between regression- and classification-based approaches. In\nthis review, we look across a range of PdM methodologies, while focusing more\nstrongly on the comparative use of classification and regression methods in\nprognostics. While regression-based methods typically provide estimates of RUL,\nclassification-based methods present a forecast of the probability of failure\nacross defined time intervals. Through a comprehensive analysis of recent\nliterature, we highlight key advancements, challenges-such as data imbalance\nand high-dimensional feature spaces-and emerging trends, including hybrid\napproaches and AI-enabled prognostic systems. This review aims to provide\nresearchers and practitioners with an awareness of the strengths and\ncompromises of various PdM methods and to help identify future research and\nbuild more robust, directed adaptive maintenance systems. Future work may\ninclude a systematic review of practical aspects such as public datasets,\nbenchmarking platforms, and open-source tools to support the advancement of PdM\nresearch.", "published": "2025-06-25 02:22:23", "link": "http://arxiv.org/abs/2506.20090v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks", "abstract": "Website Fingerprinting (WF) attacks aim to infer which websites a user is\nvisiting by analyzing traffic patterns, thereby compromising user anonymity.\nAlthough this technique has been demonstrated to be effective in controlled\nexperimental environments, it remains largely limited to small-scale scenarios,\ntypically restricted to recognizing website homepages. In practical settings,\nhowever, users frequently access multiple subpages in rapid succession, often\nbefore previous content fully loads. WebPage Fingerprinting (WPF) generalizes\nthe WF framework to large-scale environments by modeling subpages of the same\nsite as distinct classes. These pages often share similar page elements,\nresulting in lower inter-class variance in traffic features. Furthermore, we\nconsider multi-tab browsing scenarios, in which a single trace encompasses\nmultiple categories of webpages. This leads to overlapping traffic segments,\nand similar features may appear in different positions within the traffic,\nthereby increasing the difficulty of classification. To address these\nchallenges, we propose an attention-driven fine-grained WPF attack, named\nADWPF. Specifically, during the training phase, we apply targeted augmentation\nto salient regions of the traffic based on attention maps, including attention\ncropping and attention masking. ADWPF then extracts low-dimensional features\nfrom both the original and augmented traffic and applies self-attention modules\nto capture the global contextual patterns of the trace. Finally, to handle the\nmulti-tab scenario, we employ the residual attention to generate class-specific\nrepresentations of webpages occurring at different temporal positions.\nExtensive experiments demonstrate that the proposed method consistently\nsurpasses state-of-the-art baselines across datasets of different scales.", "published": "2025-06-25 01:45:55", "link": "http://arxiv.org/abs/2506.20082v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Task Allocation of UAVs for Monitoring Missions via Hardware-in-the-Loop Simulation and Experimental Validation", "abstract": "This study addresses the optimisation of task allocation for Unmanned Aerial\nVehicles (UAVs) within industrial monitoring missions. The proposed methodology\nintegrates a Genetic Algorithms (GA) with a 2-Opt local search technique to\nobtain a high-quality solution. Our approach was experimentally validated in an\nindustrial zone to demonstrate its efficacy in real-world scenarios. Also, a\nHardware-in-the-loop (HIL) simulator for the UAVs team is introduced. Moreover,\ninsights about the correlation between the theoretical cost function and the\nactual battery consumption and time of flight are deeply analysed. Results show\nthat the considered costs for the optimisation part of the problem closely\ncorrelate with real-world data, confirming the practicality of the proposed\napproach.", "published": "2025-06-25 17:18:41", "link": "http://arxiv.org/abs/2506.20626v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Opinion Dynamics with Highly Oscillating Opinions", "abstract": "Opinion Dynamics (OD) models are a particular case of Agent-Based Models in\nwhich the evolution of opinions within a population is studied. In most OD\nmodels, opinions evolve as a consequence of interactions between agents, and\nthe opinion fusion rule defines how those opinions are updated. In consequence,\ndespite being simplistic, OD models provide an explainable and interpretable\nmechanism for understanding the underlying dynamics of opinion evolution.\nUnfortunately, existing OD models mainly focus on explaining the evolution of\n(usually synthetic) opinions towards consensus, fragmentation, or polarization,\nbut they usually fail to analyze scenarios of (real-world) highly oscillating\nopinions. This work overcomes this limitation by studying the ability of\nseveral OD models to reproduce highly oscillating dynamics. To this end, we\nformulate an optimization problem which is further solved using Evolutionary\nAlgorithms, providing both quantitative results on the performance of the\noptimization and qualitative interpretations on the obtained results. Our\nexperiments on a real-world opinion dataset about immigration from the monthly\nbarometer of the Spanish Sociological Research Center show that the ATBCR,\nbased on both rational and emotional mechanisms of opinion update, is the most\naccurate OD model for capturing highly oscillating opinions.", "published": "2025-06-25 14:22:13", "link": "http://arxiv.org/abs/2506.20472v1", "categories": ["cs.CE", "cs.CY", "cs.MA"], "primary_category": "cs.CE"}
{"title": "A Visualization Framework for Exploring Multi-Agent-Based Simulations Case Study of an Electric Vehicle Home Charging Ecosystem", "abstract": "Multi-agent-based simulations (MABS) of electric vehicle (EV) home charging\necosystems generate large, complex, and stochastic time-series datasets that\ncapture interactions between households, grid infrastructure, and energy\nmarkets. These interactions can lead to unexpected system-level events, such as\ntransformer overloads or consumer dissatisfaction, that are difficult to detect\nand explain through static post-processing. This paper presents a modular,\nPython-based dashboard framework, built using Dash by Plotly, that enables\nefficient, multi-level exploration and root-cause analysis of emergent behavior\nin MABS outputs. The system features three coordinated views (System Overview,\nSystem Analysis, and Consumer Analysis), each offering high-resolution\nvisualizations such as time-series plots, spatial heatmaps, and agent-specific\ndrill-down tools. A case study simulating full EV adoption with smart charging\nin a Danish residential network demonstrates how the dashboard supports rapid\nidentification and contextual explanation of anomalies, including clustered\ntransformer overloads and time-dependent charging failures. The framework\nfacilitates actionable insight generation for researchers and distribution\nsystem operators, and its architecture is adaptable to other distributed energy\nresources and complex energy systems.", "published": "2025-06-25 13:14:49", "link": "http://arxiv.org/abs/2506.20400v1", "categories": ["cs.MA", "cs.CE", "cs.HC", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "On the $h$-majority dynamics with many opinions", "abstract": "We present the first upper bound on the convergence time to consensus of the\nwell-known $h$-majority dynamics with $k$ opinions, in the synchronous setting,\nfor $h$ and $k$ that are both non-constant values.\n  We suppose that, at the beginning of the process, there is some initial\nadditive bias towards some plurality opinion, that is, there is an opinion that\nis supported by $x$ nodes while any other opinion is supported by strictly\nfewer nodes.\n  We prove that, with high probability, if the bias is $\\omega(\\sqrt{x})$ and\nthe initial plurality opinion is supported by at least $x = \\omega(\\log n)$\nnodes, then the process converges to plurality consensus in $O(\\log n)$ rounds\nwhenever $h = \\omega(n \\log n / x)$.\n  A main corollary is the following: if $k = o(n / \\log n)$ and the process\nstarts from an almost-balanced configuration with an initial bias of magnitude\n$\\omega(\\sqrt{n/k})$ towards the initial plurality opinion, then any function\n$h = \\omega(k \\log n)$ suffices to guarantee convergence to consensus in\n$O(\\log n)$ rounds, with high probability.\n  Our upper bound shows that the lower bound of $\\Omega(k / h^2)$ rounds to\nreach consensus given by Becchetti et al.\\ (2017) cannot be pushed further than\n$\\widetilde{\\Omega}(k / h)$.\n  Moreover, the bias we require is asymptotically smaller than the\n$\\Omega(\\sqrt{n\\log n})$ bias that guarantees plurality consensus in the\n$3$-majority dynamics: in our case, the required bias is at most any\n(arbitrarily small) function in $\\omega(\\sqrt{x})$ for any value of $k \\ge 2$.", "published": "2025-06-25 08:01:58", "link": "http://arxiv.org/abs/2506.20218v1", "categories": ["cs.DC", "cs.MA"], "primary_category": "cs.DC"}
{"title": "Pivot probabilities and norm effects in Gaussian elimination for $\u03b2$-ensembles", "abstract": "We analyze pivot probabilities in Gaussian elimination with partial pivoting\n(GEPP) for $2 \\times 2$ random matrix ensembles. For GUE matrices, we resolve a\npreviously reported discrepancy between theoretical predictions and empirical\nobservations by deriving the exact pivot probability under standard\nLAPACK-style implementations. We further show that Dumitriu-Edelman tridiagonal\n$\\beta$-ensembles agree with the earlier theoretical expectations. Finally, we\npropose an open question on pivot behavior under alternative norm choices,\nsupported by empirical evidence.", "published": "2025-06-25 14:19:35", "link": "http://arxiv.org/abs/2506.20470v1", "categories": ["math.PR", "cs.NA", "math.NA"], "primary_category": "math.PR"}
{"title": "A Novel Homotopy Perturbation Sumudu Transform Method for Nonlinear Fractional PDEs: Applications and Comparative Analysis", "abstract": "This study introduces the Homotopy Perturbation Sumudu Transform Method\n(HPSTM), a novel hybrid approach combining the Sumudu transform with homotopy\nperturbation to solve nonlinear fractional partial differential equations\n(FPDEs), including fractional porous medium, heat transfer, and Fisher\nequations, using the Caputo fractional derivative. HPSTM leverages the\nlinearity-preserving properties of the Sumudu transform and the flexibility of\nhomotopy perturbation, achieving faster convergence than Laplace-HPM or\nElzaki-HPM for strongly nonlinear FPDEs. Series solutions yield absolute errors\nas low as $3.12 \\times 10^{-3}$ for $\\alpha = 0.9$, with computational times\naveraging 0.5 seconds per example using 5 series terms on standard hardware.\nSolutions are validated against exact solutions, Adomian Decomposition Method\n(ADM), radial basis function (RBF) meshless method, Variational Iteration\nMethod (VIM), Finite Difference Method (FDM), and a spectral method. Numerical\nexamples, sensitivity analysis, and graphical representations for $\\alpha =\n1.0, 0.9, 0.8, 0.7$ confirm HPSTM's accuracy, efficiency, and robustness.\nLimitations include challenges with high-order nonlinearities and\nmulti-dimensional domains. HPSTM shows promise for applications in modeling\nfluid flow in porous media, heat conduction in complex materials, and\nbiological population dynamics.", "published": "2025-06-25 14:08:08", "link": "http://arxiv.org/abs/2506.20457v1", "categories": ["math.NA", "cs.NA", "35R11, 44A10, 65M99, 34A08"], "primary_category": "math.NA"}
{"title": "A Taylor-Hood finite element method for the surface Stokes problem without penalization", "abstract": "Finite element approximation of the velocity-pressure formulation of the\nsurfaces Stokes equations is challenging because it is typically not possible\nto enforce both tangentiality and $H^1$ conformity of the velocity field. Most\nprevious works concerning finite element methods (FEMs) for these equations\nthus have weakly enforced one of these two constraints by penalization or a\nLagrange multiplier formulation. Recently in [A tangential and penalty-free\nfinite element method for the surface Stokes problem, SINUM 62(1):248-272,\n2024], the authors constructed a surface Stokes FEM based on the MINI element\nwhich is tangentiality conforming and $H^1$ nonconforming, but possesses\nsufficient weak continuity properties to circumvent the need for penalization.\nThe key to this method is construction of velocity degrees of freedom lying on\nelement edges and vertices using an auxiliary Piola transform. In this work we\nextend this methodology to construct Taylor-Hood surface FEMs. The resulting\nmethod is shown to achieve optimal-order convergence when the edge degrees of\nfreedom for the velocity spaced are placed at Gauss-Lobatto nodes. Numerical\nexperiments confirm that this nonstandard placement of nodes is necessary to\nachieve optimal convergence orders.", "published": "2025-06-25 13:34:44", "link": "http://arxiv.org/abs/2506.20419v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N30"], "primary_category": "math.NA"}
{"title": "An adaptive scheme for the optimization of damping positions by decoupling controllability spaces in vibrational systems", "abstract": "In this work, the problem of optimizing damper positions in vibrational\nsystems is investigated. The objective is to determine the positions of\nexternal dampers in such a way that the influence of the input on the output is\nminimized. The energy response serves as an optimization criterion, whose\ncomputation involves solving Lyapunov equations. Hence, in order to find the\nbest positions, many of these equations need to be solved, and so the\nminimization process can have a high computational cost.\n  To accelerate the process of finding the optimal positions, we propose a new\nreduction method. Our algorithm generates a basis spanning an approximation to\nthe solution space of the Lyapunov equations for all possible positions of the\ndampers. We derive an adaptive scheme that generates the reduced solution space\nby adding the subspaces of interest, and then we define the corresponding\nreduced optimization problem that is solvable in a reasonable amount of time.\nWe decouple the solution spaces of the problem to obtain a space that\ncorresponds to the system without external dampers and serves as a starting\npoint for the reduction of the optimization problem. In addition, we derive\nspaces corresponding to the different damper positions that are used to expand\nthe reduced basis if needed. To evaluate the quality of the basis, we introduce\nan error indicator based on the space decomposition. Our new technique produces\na reduced optimization problem of significantly smaller dimension that is\nfaster to solve than the original problem, which we illustrate with some\nnumerical examples.", "published": "2025-06-25 12:36:45", "link": "http://arxiv.org/abs/2506.20372v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Solver Performance of Accelerated MoM for Connected Arrays", "abstract": "Simulating and developing large rectangularly shaped arrays with equidistant\ninterspacing is challenging as the computational complexity grows quickly with\narray size. However, the geometrical shape of the array, appropriately meshed,\nleads to a multilevel Toeplitz structure in the RWG-based Method of Moment\nimpedance matrix representation that can be used to mitigate the increased\ncomplexity. This paper develops, presents and compares two different\naccelerated solvers that both utilize the matrix structure to determine antenna\nproperties. Both methods use a novel mesh-partitioning algorithm and its\nassociated data representation, reducing storage and computational costs. The\nfirst solver is an iterative method based on multilevel fast Fourier transform\nto accelerate matrix multiplications. The second solver approach is based on an\nextension of a fast direct Toeplitz solver, adapted to a block-matrix\nstructure. This fast direct solver is demonstrated to have close to machine\nepsilon accuracy. Both accelerated methods are evaluated on two different array\nelement types, for arrays with up to 900 elements. The results are compared\nwith conventional direct and iterative matrix solvers. Improvements are seen in\nboth the time and required storage to solve the problem. The choice of the most\nefficient method depends on the residual thresholds in the iterative method,\ngeometry of the element and frequency. Two different preconditioners for the\niterative method are investigated to evaluate their performance. The two\naccelerated methods vastly outperform regular matrix inversion methods.", "published": "2025-06-25 12:02:55", "link": "http://arxiv.org/abs/2506.20350v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Deep random difference method for high dimensional quasilinear parabolic partial differential equations", "abstract": "Solving high-dimensional parabolic partial differential equations (PDEs) with\ndeep learning methods is often computationally and memory intensive, primarily\ndue to the need for automatic differentiation (AD) to compute large Hessian\nmatrices in the PDE. In this work, we propose a deep random difference method\n(DRDM) that addresses these issues by approximating the convection-diffusion\noperator using only first-order differences and the solution by deep neural\nnetworks, thus, avoiding explicit Hessian computation. When incorporated into a\nGalerkin framework, the DRDM eliminates the need for pointwise evaluation of\nexpectations, resulting in efficient implementation. We further extend the\napproach to Hamilton-Jacobi-Bellman (HJB) equations. Notably, the DRDM recovers\nexisting martingale deep learning methods for PDEs (Cai et al., 2024,\narXiv:2405.03169), without using the tools of stochastic calculus. The proposed\nmethod offers two main advantages: it removes the dependence on AD for PDE\nderivatives and enables parallel computation of the loss function in both time\nand space. We provide rigorous error estimates for the DRDM in the linear case,\nwhich shows a first order accuracy in $\\Delta t$ used in the sampling of the\npaths by the Euler-Maruyama scheme. Numerical experiments demonstrate that the\nmethod can efficiently and accurately solve quasilinear parabolic PDEs and HJB\nequations in dimensions up to $10^4$ and $10^5$, respectively.", "published": "2025-06-25 10:40:54", "link": "http://arxiv.org/abs/2506.20308v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Low-order finite element complex with application to a fourth-order elliptic singular perturbation problem", "abstract": "A low-order nonconforming finite element discretization of a smooth de Rham\ncomplex starting from the $H^2$ space in three dimensions is proposed,\ninvolving an $H^2$-nonconforming finite element space, a new tangentially\ncontinuous $H^1$-nonconforming vector-valued finite element space, the\nlowest-order Raviart-Thomas space, and piecewise constant functions. While\nnonconforming for the smooth complex, the discretization conforms to the\nclassical de Rham complex. It is applied to develop a decoupled mixed finite\nelement method for a fourth-order elliptic singular perturbation problem,\nfocusing on the discretization of a generalized singularly perturbed\nStokes-type equation. In contrast to Nitsche's method, which requires\nadditional stabilization to handle boundary layers, the nodal interpolation\noperator for the lowest-order N\\'{e}d\\'{e}lec element of the second kind is\nintroduced into the discrete bilinear forms. This modification yields a\ndecoupled mixed method that achieves optimal convergence rates uniformly with\nrespect to the perturbation parameter, even in the presence of strong boundary\nlayers, without requiring any additional stabilization.", "published": "2025-06-25 08:34:54", "link": "http://arxiv.org/abs/2506.20240v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stochastic particle method with birth-death dynamics", "abstract": "In order to numerically solve high-dimensional nonlinear PDEs and alleviate\nthe curse of dimensionality, a stochastic particle method (SPM) has been\nproposed to capture the relevant feature of the solution through the adaptive\nevolution of particles [J. Comput. Phys. 527 (2025) 113818]. In this paper, we\nintroduce an active birth-death dynamics of particles to improve the efficiency\nof SPM. The resulting method, dubbed SPM-birth-death, sample new particles\naccording to the nonlinear term and execute the annihilation strategy when the\nnumber of particles exceeds a given threshold. Preliminary numerical\nexperiments on the Allen-Cahn equation demonstrate that SPM-birth-death can\nachieve smaller errors at the same computational cost compared with the\noriginal SPM.", "published": "2025-06-25 07:41:40", "link": "http://arxiv.org/abs/2506.20201v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A quasi-Grassmannian gradient flow model for eigenvalue problems", "abstract": "We propose a quasi-Grassmannian gradient flow model for eigenvalue problems\nof linear operators, aiming to efficiently address many eigenpairs. Our model\ninherently ensures asymptotic orthogonality: without the need for initial\northogonality, the solution naturally evolves toward being orthogonal over\ntime. We establish the well-posedness of the model, and provide the analytical\nrepresentation of solutions. Through asymptotic analysis, we show that the\ngradient converges exponentially to zero and that the energy decreases\nexponentially to its minimum. This implies that the solution of the\nquasi-Grassmannian gradient flow model converges to the solution of the\neigenvalue problems as time progresses. These properties not only eliminate the\nneed for explicit orthogonalization in numerical computation but also\nsignificantly enhance robustness of the model, rendering it far more resilient\nto numerical perturbations than conventional methods.", "published": "2025-06-25 07:36:39", "link": "http://arxiv.org/abs/2506.20195v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fast entropy-regularized SDP relaxations for permutation synchronization", "abstract": "We introduce fast randomized algorithms for solving semidefinite programming\n(SDP) relaxations of the partial permutation synchronization (PPS) problem, a\ncore task in multi-image matching with significant relevance to 3D\nreconstruction. Our methods build on recent advances in entropy-regularized\nsemidefinite programming and are tailored to the unique structure of PPS, in\nwhich the unknowns are partial permutation matrices aligning sparse and noisy\npairwise correspondences across images. We prove that entropy regularization\nresolves optimizer non-uniqueness in standard relaxations, and we develop a\nrandomized solver with nearly optimal scaling in the number of observed\ncorrespondences. We also develop several rounding procedures for recovering\ncombinatorial solutions from the implicitly represented primal solution\nvariable, maintaining cycle consistency if desired without harming\ncomputational scaling. We demonstrate that our approach achieves\nstate-of-the-art performance on synthetic and real-world datasets in terms of\nspeed and accuracy. Our results highlight PPS as a paradigmatic setting in\nwhich entropy-regularized SDP admits both theoretical and practical advantages\nover traditional low-rank or spectral techniques.", "published": "2025-06-25 07:32:32", "link": "http://arxiv.org/abs/2506.20191v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "DefElement: an encyclopedia of finite element definitions", "abstract": "DefElement is an online encyclopedia of finite element definitions that was\ncreated and is maintained by the authors of this paper. DefElement aims to make\ninformation about elements defined in the literature easily available in a\nstandard format. There are a number of open-source finite element libraries\navailable, and it can be difficult to check that an implementation of an\nelement in a library matches the element's definition in the literature or\nimplementation in another library, especially when many libraries include\nvariants of elements whose basis functions do not match exactly. In this paper,\nwe carefully derive conditions under which elements can be considered\nequivalent and describe an algorithm that uses these conditions to verify that\ntwo implementations of a finite element are indeed variants of the same\nelement. The results of scheduled runs of our implementation of this\nverification algorithm are included in the information available on DefElement.", "published": "2025-06-25 07:29:35", "link": "http://arxiv.org/abs/2506.20188v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The role of audio-visual integration in the time course of phonetic encoding in self-supervised speech models", "abstract": "Human speech perception is multimodal. In natural speech, lip movements can\nprecede corresponding voicing by a non-negligible gap of 100-300 ms, especially\nfor specific consonants, affecting the time course of neural phonetic encoding\nin human listeners. However, it remains unexplored whether self-supervised\nlearning models, which have been used to simulate audio-visual integration in\nhumans, can capture this asynchronicity between audio and visual cues. We\ncompared AV-HuBERT, an audio-visual model, with audio-only HuBERT, by using\nlinear classifiers to track their phonetic decodability over time. We found\nthat phoneme information becomes available in AV-HuBERT embeddings only about\n20 ms before HuBERT, likely due to AV-HuBERT's lower temporal resolution and\nfeature concatenation process. It suggests AV-HuBERT does not adequately\ncapture the temporal dynamics of multimodal speech perception, limiting its\nsuitability for modeling the multimodal speech perception process.", "published": "2025-06-25 12:23:12", "link": "http://arxiv.org/abs/2506.20361v1", "categories": ["eess.AS", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Lightweight Target-Speaker-Based Overlap Transcription for Practical Streaming ASR", "abstract": "Overlapping speech remains a major challenge for automatic speech recognition\n(ASR) in real-world applications, particularly in broadcast media with dynamic,\nmulti-speaker interactions. We propose a light-weight, target-speaker-based\nextension to an existing streaming ASR system to enable practical transcription\nof overlapping speech with minimal computational overhead. Our approach\ncombines a speaker-independent (SI) model for standard operation with a\nspeaker-conditioned (SC) model selectively applied in overlapping scenarios.\nOverlap detection is achieved using a compact binary classifier trained on\nfrozen SI model output, offering accurate segmentation at negligible cost. The\nSC model employs Feature-wise Linear Modulation (FiLM) to incorporate speaker\nembeddings and is trained on synthetically mixed data to transcribe only the\ntarget speaker. Our method supports dynamic speaker tracking and reuses\nexisting modules with minimal modifications. Evaluated on a challenging set of\nCzech television debates with 16% overlap, the system reduced WER on\noverlapping segments from 68.0% (baseline) to 35.78% while increasing total\ncomputational load by only 44%. The proposed system offers an effective and\nscalable solution for overlap transcription in continuous ASR services.", "published": "2025-06-25 09:46:56", "link": "http://arxiv.org/abs/2506.20288v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Exploration of ECAPA-TDNN and x-vector Speaker Representations in Zero-shot Multi-speaker TTS", "abstract": "Zero-shot multi-speaker text-to-speech (TTS) systems rely on speaker\nembeddings to synthesize speech in the voice of an unseen speaker, using only a\nshort reference utterance. While many speaker embeddings have been developed\nfor speaker recognition, their relative effectiveness in zero-shot TTS remains\nunderexplored. In this work, we employ a YourTTS-based TTS system to compare\nthree different speaker encoders - YourTTS's original H/ASP encoder, x-vector\nembeddings, and ECAPA-TDNN embeddings - within an otherwise fixed zero-shot TTS\nframework. All models were trained on the same dataset of Czech read speech and\nevaluated on 24 out-of-domain target speakers using both subjective and\nobjective methods. The subjective evaluation was conducted via a listening test\nfocused on speaker similarity, while the objective evaluation measured cosine\ndistances between speaker embeddings extracted from synthesized and real\nutterances. Across both evaluations, the original H/ASP encoder consistently\noutperformed the alternatives, with ECAPA-TDNN showing better results than\nx-vectors. These findings suggest that, despite the popularity of ECAPA-TDNN in\nspeaker recognition, it does not necessarily offer improvements for speaker\nsimilarity in zero-shot TTS in this configuration. Our study highlights the\nimportance of empirical evaluation when reusing speaker recognition embeddings\nin TTS and provides a framework for additional future comparisons.", "published": "2025-06-25 07:31:32", "link": "http://arxiv.org/abs/2506.20190v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MC for Agriculture: A Framework for Nature-inspired Sustainable Pest Control", "abstract": "In agriculture, molecular communication (MC) is envisioned as a framework to\naddress critical challenges such as smart pest control. While conventional\napproaches mostly rely on synthetic plant protection products, posing high\nrisks for the environment, harnessing plant signaling processes can lead to\ninnovative approaches for nature-inspired sustainable pest control. In this\npaper, we investigate an approach for sustainable pest control and reveal how\nthe MC paradigm can be employed for analysis and optimization. In particular,\nwe consider a system where herbivore-induced plant volatiles (HIPVs),\nspecifically methyl salicylate (MeSA), is encapsulated into microspheres\ndeployed on deployed on plant leaves. The controlled release of MeSA from the\nmicrospheres, acting as transmitters (TXs), supports pest deterrence and\nantagonist attraction, providing an eco-friendly alternative to synthetic plant\nprotection products. Based on experimental data, we investigate the MeSA\nrelease kinetics and obtain an analytical model. To describe the propagation of\nMeSA in farming environments, we employ a three dimensional (3D)\nadvection-diffusion model, incorporating realistic wind fields which are\npredominantly affecting particle propagation, and solve it by a finite\ndifference method (FDM). The proposed model is used to investigate the MeSA\ndistribution for different TX arrangements, representing different practical\nmicrosphere deployment strategies. Moreover, we introduce the coverage\neffectiveness index (CEI) as a novel metric to quantify the environmental\ncoverage of MeSA. This analysis offers valuable guidance for the practical\ndevelopment of microspheres and their deployment aimed at enhancing coverage\nand, consequently, the attraction of antagonistic insects.", "published": "2025-06-25 17:31:46", "link": "http://arxiv.org/abs/2506.20637v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Differential Transformer-driven 6G Physical Layer for Collaborative Perception Enhancement", "abstract": "The emergence of 6G wireless networks promises to revolutionize vehicular\ncommunications by enabling ultra-reliable, low-latency, and high-capacity data\nexchange. In this context, collaborative perception techniques, where multiple\nvehicles or infrastructure nodes cooperate to jointly receive and decode\ntransmitted signals, aim to enhance reliability and spectral efficiency for\nConnected Autonomous Vehicle (CAV) applications. In this paper, we propose an\nend-to-end wireless neural receiver based on a Differential Transformer\narchitecture, tailored for 6G V2X communication with a specific focus on\nenabling collaborative perception among connected autonomous vehicles. Our\nmodel integrates key components of the 6G physical layer, designed to boost\nperformance in dynamic and challenging autonomous driving environments. We\nvalidate the proposed system across a range of scenarios, including\n3GPP-defined Urban Macro (UMa) channel. To assess the model's real-world\napplicability, we evaluate its robustness within a V2X framework. In a\ncollaborative perception scenario, our system processes heterogeneous LiDAR and\ncamera data from four connected vehicles in dynamic cooperative vehicular\nnetworks. The results show significant improvements over state-of-the-art\nmethods, achieving an average precision of 0.84, highlighting the potential of\nour proposed approach to enable robust, intelligent, and adaptive wireless\ncooperation for next-generation connected autonomous vehicles.", "published": "2025-06-25 16:36:05", "link": "http://arxiv.org/abs/2506.20597v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Communicating Smartly in Molecular Communication Environments: Neural Networks in the Internet of Bio-Nano Things", "abstract": "Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the\ngroundwork for innovative applications across the healthcare sector.\nNanodevices designed to operate within the body, managed remotely via the\ninternet, are envisioned to promptly detect and actuate on potential diseases.\nIn this vision, an inherent challenge arises due to the limited capabilities of\nindividual nanosensors; specifically, nanosensors must communicate with one\nanother to collaborate as a cluster. Aiming to research the boundaries of the\nclustering capabilities, this survey emphasizes data-driven communication\nstrategies in molecular communication (MC) channels as a means of linking\nnanosensors. Relying on the flexibility and robustness of machine learning (ML)\nmethods to tackle the dynamic nature of MC channels, the MC research community\nfrequently refers to neural network (NN) architectures. This interdisciplinary\nresearch field encompasses various aspects, including the use of NNs to\nfacilitate communication in MC environments, their implementation at the\nnanoscale, explainable approaches for NNs, and dataset generation for training.\nWithin this survey, we provide a comprehensive analysis of fundamental\nperspectives on recent trends in NN architectures for MC, the feasibility of\ntheir implementation at the nanoscale, applied explainable artificial\nintelligence (XAI) techniques, and the accessibility of datasets along with\nbest practices for their generation. Additionally, we offer open-source code\nrepositories that illustrate NN-based methods to support reproducible research\nfor key MC scenarios. Finally, we identify emerging research challenges, such\nas robust NN architectures, biologically integrated NN modules, and scalable\ntraining strategies.", "published": "2025-06-25 16:28:30", "link": "http://arxiv.org/abs/2506.20589v1", "categories": ["eess.SP", "cs.ET", "q-bio.OT"], "primary_category": "eess.SP"}
{"title": "Revisiting CHAMPAGNE: Sparse Bayesian Learning as Reweighted Sparse Coding", "abstract": "This paper revisits the CHAMPAGNE algorithm within the Sparse Bayesian\nLearning (SBL) framework and establishes its connection to reweighted sparse\ncoding. We demonstrate that the SBL objective can be reformulated as a\nreweighted $\\ell_{21}$-minimization problem, providing a more straightforward\ninterpretation of the sparsity mechanism and enabling the design of an\nefficient iterative algorithm. Additionally, we analyze the behavior of this\nreformulation in the low signal-to-noise ratio (SNR) regime, showing that it\nsimplifies to a weighted $\\ell_{21}$-regularized least squares problem.\nNumerical experiments validate the proposed approach, highlighting its improved\ncomputational efficiency and ability to produce exact sparse solutions,\nparticularly in simulated MEG source localization tasks.", "published": "2025-06-25 15:24:38", "link": "http://arxiv.org/abs/2506.20534v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Active RIS Enabled NLoS LEO Satellite Communications: A Three-timescale Optimization Framework", "abstract": "In this letter, we study an active reconfigurable intelligent surfaces (RIS)\nassisted Low Earth orbit (LEO) satellite communications under non-line-of-sight\n(NLoS) scenarios, where the active RIS is deployed to create visual\nline-of-sight links for reliable communication. To address the challenges of\nhigh energy consumption caused by frequent beamforming updates in active RIS,\nwe propose a three-timescale optimization framework that jointly designs the\ntransmit beamforming, RIS beamforming, and RIS direction vectors based on their\ncharacteristics. The goal is to maximize the system achievable rate while\nreducing energy consumption by controlling the RIS beamforming switching\nfrequency. Then, a two-layer solution framework is developed, incorporating\nfractional programming (FP), alternating optimization (AO), successive\napproximation (SCA), and penalty-based methods, to obtain the optimized\nsolution. Simulation results demonstrate that the proposed scheme can\neffectively improve system performance and reduce the energy consumption of the\nactive RIS.", "published": "2025-06-25 13:37:51", "link": "http://arxiv.org/abs/2506.20424v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Unified Framework for UAV-Based Free-Space Quantum Links: Beam Shaping and Adaptive Field-of-View Control", "abstract": "This paper develops a comprehensive analytical framework for modeling and\nperformance evaluation of unmanned aerial vehicles (UAVs)-to-ground quantum\ncommunication links, incorporating key physical impairments such as beam\ndivergence, pointing errors at both transmitter and receiver, atmospheric\nattenuation, turbulence-induced fading, narrow field-of-view (FoV) filtering,\nand background photon noise. To overcome the limitations of conventional\nwide-beam assumptions, we introduce a grid-based approximation for photon\ncapture probability that remains accurate under tightly focused beams.\nAnalytical expressions are derived for the quantum key generation rate and\nquantum bit error rate (QBER), enabling fast and reliable system-level\nevaluation. Our results reveal that secure quantum key distribution (QKD) over\nUAV-based free-space optical (FSO) links requires beam waists below 10 cm and\nsub-milliradian tracking precision to achieve Mbps-level key rates and QBER\nbelow $10^{-3}$. Additionally, we highlight the critical role of receiver FoV\nin balancing background noise rejection and misalignment tolerance, and propose\nadaptive FoV tuning strategies under varying illumination and alignment\nconditions. The proposed framework provides a tractable and accurate tool for\nthe design, optimization, and deployment of next-generation airborne quantum\ncommunication systems.", "published": "2025-06-25 11:46:56", "link": "http://arxiv.org/abs/2506.20336v1", "categories": ["eess.SP", "quant-ph"], "primary_category": "eess.SP"}
{"title": "Analog OFDM based on Real-Time Fourier Transformation", "abstract": "This paper proposes an analog orthogonal frequency division multiplexing\n(OFDM) architecture based on the real-time Fourier transform (RTFT). The core\nenabling component is a linear-chirp phaser with engineered group velocity\ndispersion (GVD), which realizes RTFT and performs frequency-to-time mapping in\nthe analog domain. In this architecture, conventional digital fast Fourier\ntransform (FFT) and inverse FFT (IFFT) processors are replaced by two\nlinear-chirp phasers with opposite group delay dispersions, respectively.\nTheoretical analysis demonstrates that, under specific phaser conditions, the\nOFDM signal generated by the RTFT-based analog system is mathematically\nequivalent to that of a conventional digital OFDM system. This equivalence is\nfurther supported by simulation results, which confirm accurate symbol\ntransmission and recovery, as well as robustness to multipath fading when a\nprefix is applied. Benefiting from the use of passive microwave components, the\nanalog OFDM system offers ultra-fast processing with reduced power consumption.\nOverall, this work establishes a foundation for fully analog or hybrid\nanalog-digital OFDM system, offering a promising solution for next-generation\nhigh-speed, wideband, and energy-efficient wireless communication platforms.", "published": "2025-06-25 09:46:47", "link": "http://arxiv.org/abs/2506.20287v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Superimposed DMRS for Spectrally Efficient 6G Uplink Multi-User OFDM: Classical vs AI/ML Receivers", "abstract": "Fifth-generation (5G) systems utilize orthogonal demodulation reference\nsignals (DMRS) to enable channel estimation at the receiver. These orthogonal\nDMRS-also referred to as pilots-are effective in avoiding pilot contamination\nand interference from both the user's own data and that of others. However,\nthis approach incurs a significant overhead, as a substantial portion of the\ntime-frequency resources must be reserved for pilot transmission. Moreover, the\noverhead increases with the number of users and transmission layers.\n  To address these limitations in the context of emerging sixth-generation (6G)\nsystems and to support data transmission across the entire time-frequency grid,\nthe superposition of data and DMRS symbols has been explored as an alternative\nDMRS transmission strategy. In this study, we propose an enhanced version of\nDeepRx, a deep convolutional neural network (CNN)-based receiver, capable of\nestimating the channel from received superimposed (SI) DMRS symbols and\nreliably detecting the transmitted data. We also design a conventional receiver\nfor comparison, which estimates the channel from SI DMRS using classical signal\nprocessing techniques. Extensive evaluations in both uplink single-user and\nmulti-user scenarios demonstrate that DeepRx consistently outperforms the\nconventional receivers in terms of performance.", "published": "2025-06-25 08:46:03", "link": "http://arxiv.org/abs/2506.20248v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Time and covariance smoothing for restoration of bivariate signals", "abstract": "In many applications and physical phenomena, bivariate signals are polarized,\ni.e. they trace an elliptical trajectory over time when viewed in the 2D planes\nof their two components. The smooth evolution of this elliptical trajectory,\ncalled polarization ellipse, is highly informative to solve ill-posed inverse\nproblems involving bivariate signals where the signal is collected through\nindirect, noisy or incomplete measurements. This work proposes a novel\nformulation and an efficient algorithm for reconstructing bivariate signals\nwith polarization regularization. The proposed formulation leverages the\ncompact representation of polarization through the instantaneous covariance\nmatrices. To address the resulting quartic optimization problem, we propose a\nwell-suited parameter splitting strategy which leads to an efficient iterative\nalgorithm (alternating direction method of multipliers (ADMM)) with convex\nsubproblems at each iteration. The performance of the proposed method is\nillustrated on numerical synthetic data experiments.", "published": "2025-06-25 08:28:30", "link": "http://arxiv.org/abs/2506.20237v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing-Aware Transmit Waveform/Receive Filter Design for OFDM-MBS Systems", "abstract": "In this letter, we study the problem of cooperative sensing design for an\northogonal frequency division multiplexing (OFDM) multiple base stations (MBS)\nsystem. We consider a practical scenario where the base stations (BSs) exploit\ncertain subcarriers to realize a sensing function. Since the high sidelobe\nlevel (SLL) of OFDM waveforms degrades radar detection for weak targets, and\nthe cross-correlation generated by other BSs further exacerbates detection\nperformance, we devise a joint design scheme for OFDM sequence and receive\nfilter by minimizing the integrated sidelobe level (ISL) while satisfying\nmainlobe level, peak-to-average power ratio (PAPR) and spectrum allocation\nconstraints. To address this non-convex problem, we propose an alternating\noptimization (AO)-based algorithm. Numerical simulations validate the\neffectiveness of the proposed method, demonstrating the superiority of SSL\nreduction in the MBS system over the matched filtering method.", "published": "2025-06-25 08:22:30", "link": "http://arxiv.org/abs/2506.20231v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers", "abstract": "Towards fast, hardware-efficient, and low-complexity receivers, we propose a\ncompression-aware learning approach and examine it on free-space optical (FSO)\nreceivers for turbulence mitigation. The learning approach jointly quantize,\nprune, and train a convolutional neural network (CNN). In addition, we propose\nto have the CNN weights of power of two values so we replace the multiplication\noperations bit-shifting operations in every layer that has significant lower\ncomputational cost. The compression idea in the proposed approach is that the\nloss function is updated and both the quantization levels and the pruning\nlimits are optimized in every epoch of training. The compressed CNN is examined\nfor two levels of compression (1-bit and 2-bits) over different FSO systems.\nThe numerical results show that the compression approach provides negligible\ndecrease in performance in case of 1-bit quantization and the same performance\nin case of 2-bits quantization, compared to the full-precision CNNs. In\ngeneral, the proposed IM/DD FSO receivers show better bit-error rate (BER)\nperformance (without the need for channel state information (CSI)) compared to\nthe maximum likelihood (ML) receivers that utilize imperfect CSI when the DL\nmodel is compressed whether with 1-bit or 2-bit quantization.", "published": "2025-06-25 02:04:07", "link": "http://arxiv.org/abs/2506.20084v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Ordered Reliability Direct Error Pattern Testing (ORDEPT) Decoding with Likelihood Thresholding", "abstract": "We propose a reduced complexity approach to pattern-based soft decoding of\nblock codes. We start from the ORDEPT decoding algorithm which tests a list of\npartial error patterns organized in the order of their likelihood and attempts\nto complete the patterns creating candidate codewords. We then propose an early\ntermination criterion. Once a candidate codeword is found, its log-likelihood\ndifference to the received sequence is compared to a preset threshold and the\ndecoding decision is instantly made in case the likelihood deviation is below\nthe threshold. We demonstrate that while keeping the same block error rate\n(BLER) performance, the proposed algorithm's latency and complexity is multiple\ntimes smaller than that of the state-of-the art competitors including the Chase\nII, ORBGRAND, GCD, and the very recent ORDEPT with Soft-Output GRAND\ntermination which necessitates several multiplications in each query\nprocessing.", "published": "2025-06-25 01:18:37", "link": "http://arxiv.org/abs/2506.20079v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field Energy Harvesting Using XL-MIMO Over Non-Stationary Channels", "abstract": "This paper explores the maximization of the harvested power efficiency (HPE)\nin a modular extremely large multiple-input multiple-output (XL-MIMO) system,\nwhich supports energy harvesting (EH) for near-field users. These users are\nlocated in spatially distinct visibility regions (VRs) with non-stationary\nchannel characteristics. We propose to determine which sub-arrays are switched\non or off as well the power control coefficients at the sub-arrays to maximize\nthe HPE. The design can be processed via a multi-tier joint optimization\nframework based on fractional programming. The numerical results showcase that\nthe HPE performance of the proposed algorithm is nearly optimal, comparable to\nthat of exhaustive search. As a matter of fact, it achieves up to a 120% gain\nover the benchmark scheme which uses the entire XL-MIMO array with equal power\nallocation (PA) across sub-arrays, while significantly reducing the\ncomputational time.", "published": "2025-06-25 00:04:48", "link": "http://arxiv.org/abs/2506.20067v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation", "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR bias during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.", "published": "2025-06-25 17:35:47", "link": "http://arxiv.org/abs/2506.20639v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TAPS: Tool-Augmented Personalisation via Structured Tagging", "abstract": "Recent advancements in tool-augmented large language models have enabled them\nto interact with external tools, enhancing their ability to perform complex\nuser tasks. However, existing approaches overlook the role of personalisation\nin guiding tool use. This work investigates how user preferences can be\neffectively integrated into goal-oriented dialogue agents. Through extensive\nanalysis, we identify key weaknesses in the ability of LLMs to personalise tool\nuse. To this end, we introduce TAPS, a novel solution that enhances\npersonalised tool use by leveraging a structured tagging tool and an\nuncertainty-based tool detector. TAPS significantly improves the ability of\nLLMs to incorporate user preferences, achieving the new state-of-the-art for\nopen source models on the NLSI task.", "published": "2025-06-25 13:24:46", "link": "http://arxiv.org/abs/2506.20409v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "abstract": "Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant. Based on our discoveries, we propose SACL, a framework that\nenriches textual information and reduces bias by augmenting code or structural\nknowledge with semantic information. Extensive experiments show that SACL\nsubstantially improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on\nHumanEval / MBPP / SWE-Bench-Lite), which also leads to better code generation\nperformance (e.g., by 4.88% Pass@1 on HumanEval).", "published": "2025-06-25 01:44:28", "link": "http://arxiv.org/abs/2506.20081v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation", "abstract": "With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.", "published": "2025-06-25 13:15:52", "link": "http://arxiv.org/abs/2506.20401v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition", "abstract": "Foundation models are rapidly transforming Earth Observation data mining by\nenabling generalizable and scalable solutions for key tasks such as scene\nclassification and semantic segmentation. While most efforts in the geospatial\ndomain have focused on developing large models trained from scratch using\nmassive Earth Observation datasets, an alternative strategy that remains\nunderexplored is the reuse and combination of existing pretrained models. In\nthis study, we investigate whether foundation models pretrained on remote\nsensing and general vision datasets can be effectively combined to improve\nperformance across a diverse set of key Earth Observation tasks. Using the\nGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,\nHiera, and DOFA, on eleven datasets covering a range of spatial resolutions,\nsensor modalities, and task types. The results show that feature-level\nensembling of smaller pretrained models can match or exceed the performance of\nmuch larger models, while requiring less training time and computational\nresources. Moreover, the study highlights the potential of applying knowledge\ndistillation to transfer the strengths of ensembles into more compact models,\noffering a practical path for deploying foundation models in real-world Earth\nObservation applications.", "published": "2025-06-25 07:02:42", "link": "http://arxiv.org/abs/2506.20174v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A quasi-Grassmannian gradient flow model for eigenvalue problems", "abstract": "We propose a quasi-Grassmannian gradient flow model for eigenvalue problems\nof linear operators, aiming to efficiently address many eigenpairs. Our model\ninherently ensures asymptotic orthogonality: without the need for initial\northogonality, the solution naturally evolves toward being orthogonal over\ntime. We establish the well-posedness of the model, and provide the analytical\nrepresentation of solutions. Through asymptotic analysis, we show that the\ngradient converges exponentially to zero and that the energy decreases\nexponentially to its minimum. This implies that the solution of the\nquasi-Grassmannian gradient flow model converges to the solution of the\neigenvalue problems as time progresses. These properties not only eliminate the\nneed for explicit orthogonalization in numerical computation but also\nsignificantly enhance robustness of the model, rendering it far more resilient\nto numerical perturbations than conventional methods.", "published": "2025-06-25 07:36:39", "link": "http://arxiv.org/abs/2506.20195v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Communicating Smartly in the Molecular Domain: Neural Networks in the Internet of Bio-Nano Things", "abstract": "Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the\ngroundwork for innovative applications across the healthcare sector.\nNanodevices designed to operate within the body, managed remotely via the\ninternet, are envisioned to promptly detect and actuate on potential diseases.\nIn this vision, an inherent challenge arises due to the limited capabilities of\nindividual nanosensors; specifically, nanosensors must communicate with one\nanother to collaborate as a cluster. Aiming to research the boundaries of the\nclustering capabilities, this survey emphasizes data-driven communication\nstrategies in molecular communication (MC) channels as a means of linking\nnanosensors. Relying on the flexibility and robustness of machine learning (ML)\nmethods to tackle the dynamic nature of MC channels, the MC research community\nfrequently refers to neural network (NN) architectures. This interdisciplinary\nresearch field encompasses various aspects, including the use of NNs to\nfacilitate communication in MC environments, their implementation at the\nnanoscale, explainable approaches for NNs, and dataset generation for training.\nWithin this survey, we provide a comprehensive analysis of fundamental\nperspectives on recent trends in NN architectures for MC, the feasibility of\ntheir implementation at the nanoscale, applied explainable artificial\nintelligence (XAI) techniques, and the accessibility of datasets along with\nbest practices for their generation. Additionally, we offer open-source code\nrepositories that illustrate NN-based methods to support reproducible research\nfor key MC scenarios. Finally, we identify emerging research challenges, such\nas robust NN architectures, biologically integrated NN modules, and scalable\ntraining strategies.", "published": "2025-06-25 16:28:30", "link": "http://arxiv.org/abs/2506.20589v2", "categories": ["eess.SP", "cs.ET", "q-bio.OT"], "primary_category": "eess.SP"}
{"title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "abstract": "Technological progress has led to concrete advancements in tasks that were\nregarded as challenging, such as automatic fact-checking. Interest in adopting\nthese systems for public health and medicine has grown due to the high-stakes\nnature of medical decisions and challenges in critically appraising a vast and\ndiverse medical literature. Evidence-based medicine connects to every\nindividual, and yet the nature of it is highly technical, rendering the medical\nliteracy of majority users inadequate to sufficiently navigate the domain. Such\nproblems with medical communication ripens the ground for end-to-end\nfact-checking agents: check a claim against current medical literature and\nreturn with an evidence-backed verdict. And yet, such systems remain largely\nunused. To understand this, we present the first study examining how clinical\nexperts verify real claims from social media by synthesizing medical evidence.\nIn searching for this upper-bound, we reveal fundamental challenges in\nend-to-end fact-checking when applied to medicine: Difficulties connecting\nclaims in the wild to scientific evidence in the form of clinical trials;\nambiguities in underspecified claims mixed with mismatched intentions; and\ninherently subjective veracity labels. We argue that fact-checking should be\napproached and evaluated as an interactive communication problem, rather than\nan end-to-end process.", "published": "2025-06-25 22:58:08", "link": "http://arxiv.org/abs/2506.20876v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA", "abstract": "Memorization in large language models (LLMs) makes them vulnerable to data\nextraction attacks. While pre-training memorization has been extensively\nstudied, fewer works have explored its impact in fine-tuning, particularly for\nLoRA fine-tuning, a widely adopted parameter-efficient method.\n  In this work, we re-examine memorization in fine-tuning and uncover a\nsurprising divergence from prior findings across different fine-tuning\nstrategies. Factors such as model scale and data duplication, which strongly\ninfluence memorization in pre-training and full fine-tuning, do not follow the\nsame trend in LoRA fine-tuning. Using a more relaxed similarity-based\nmemorization metric, we demonstrate that LoRA significantly reduces\nmemorization risks compared to full fine-tuning, while still maintaining strong\ntask performance.", "published": "2025-06-25 22:01:25", "link": "http://arxiv.org/abs/2506.20856v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes", "abstract": "Large language models (LLMs) are increasingly proposed for detecting and\nresponding to violent content online, yet their ability to reason about morally\nambiguous, real-world scenarios remains underexamined. We present the first\nstudy to evaluate LLMs using a validated social science instrument designed to\nmeasure human response to everyday conflict, namely the Violent Behavior\nVignette Questionnaire (VBVQ). To assess potential bias, we introduce\npersona-based prompting that varies race, age, and geographic identity within\nthe United States. Six LLMs developed across different geopolitical and\norganizational contexts are evaluated under a unified zero-shot setting. Our\nstudy reveals two key findings: (1) LLMs surface-level text generation often\ndiverges from their internal preference for violent responses; (2) their\nviolent tendencies vary across demographics, frequently contradicting\nestablished findings in criminology, social science, and psychology.", "published": "2025-06-25 20:43:04", "link": "http://arxiv.org/abs/2506.20822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering", "abstract": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span\nhundreds of pages and combine diverse modalities, including dense narrative\ntext, structured tables, and complex figures. Answering questions over such\ncontent often requires joint reasoning across modalities, which strains\ntraditional large language models (LLMs) and retrieval-augmented generation\n(RAG) pipelines due to token limitations, layout loss, and fragmented\ncross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation\nframework purpose-built for financial QA. MultiFinRAG first performs multimodal\nextraction by grouping table and figure images into batches and sending them to\na lightweight, quantized open-source multimodal LLM, which produces both\nstructured JSON outputs and concise textual summaries. These outputs, along\nwith narrative text, are embedded and indexed with modality-aware similarity\nthresholds for precise retrieval. A tiered fallback strategy then dynamically\nescalates from text-only to text+table+image contexts when necessary, enabling\ncross-modal reasoning while reducing irrelevant context. Despite running on\ncommodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy\nthan ChatGPT-4o (free-tier) on complex financial QA tasks involving text,\ntables, images, and combined multimodal reasoning.", "published": "2025-06-25 20:37:20", "link": "http://arxiv.org/abs/2506.20821v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "68T50, 68T07 (Primary) 68P20, 91G15, 91G70, 68U10 (Secondary)", "I.2.7; I.2.10; H.3.3; H.2.8; I.5.4; J.1"], "primary_category": "cs.CL"}
{"title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "abstract": "Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.", "published": "2025-06-25 19:47:23", "link": "http://arxiv.org/abs/2506.20803v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-lingual Functional Evaluation for Large Language Models", "abstract": "Multi-lingual competence in large language models is often evaluated via\nstatic data benchmarks such as Belebele, M-MMLU and M-GSM. However, these\nevaluations often fail to provide an adequate understanding of the practical\nperformance and robustness of models across multi-lingual settings. In\nresponse, we create multi-lingual functional benchmarks -- Cross-Lingual Grade\nSchool Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following\nEval (CL-IFEval)-- by translating existing functional benchmark templates from\nEnglish to five additional languages that span the range of resources available\nfor NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that\nsome static multi-lingual benchmarks capture functional performance much more\nclosely than others (i.e. across models, there is a 24%, 17% and 18% decrease\nin performance between M-GSM and CL-GSM Symbolic in English, French and Spanish\nrespectively; similarly there's a 15 - 24% performance drop across languages\nbetween Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between\nM-MMLU and CL-IFEval). Similarly, we find that model robustness across\nlanguages varies significantly, with certain languages (eg. Arabic, English)\nbeing the most consistently well performing across evaluation iterations.", "published": "2025-06-25 19:32:31", "link": "http://arxiv.org/abs/2506.20793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Probabilistic Question Answering Over Tabular Data", "abstract": "Current approaches for question answering (QA) over tabular data, such as\nNL2SQL systems, perform well for factual questions where answers are directly\nretrieved from tables. However, they fall short on probabilistic questions\nrequiring reasoning under uncertainty. In this paper, we introduce a new\nbenchmark LUCARIO and a framework for probabilistic QA over large tabular data.\nOur method induces Bayesian Networks from tables, translates natural language\nqueries into probabilistic queries, and uses large language models (LLMs) to\ngenerate final answers. Empirical results demonstrate significant improvements\nover baselines, highlighting the benefits of hybrid symbolic-neural reasoning.", "published": "2025-06-25 18:15:33", "link": "http://arxiv.org/abs/2506.20747v1", "categories": ["cs.CL", "68T50, 68T37", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation", "abstract": "The proliferation of LLM-based agents has led to increasing deployment of\ninter-agent collaboration for tasks like scheduling, negotiation, resource\nallocation etc. In such systems, privacy is critical, as agents often access\nproprietary tools and domain-specific databases requiring strict\nconfidentiality. This paper examines whether LLM-based agents demonstrate an\nunderstanding of contextual privacy. And, if instructed, do these systems\npreserve inference time user privacy in non-adversarial multi-turn\nconversation. Existing benchmarks to evaluate contextual privacy in LLM-agents\nprimarily assess single-turn, low-complexity tasks where private information\ncan be easily excluded. We first present a benchmark - MAGPIE comprising 158\nreal-life high-stakes scenarios across 15 domains. These scenarios are designed\nsuch that complete exclusion of private data impedes task completion yet\nunrestricted information sharing could lead to substantial losses. We then\nevaluate the current state-of-the-art LLMs on (a) their understanding of\ncontextually private data and (b) their ability to collaborate without\nviolating user privacy. Empirical experiments demonstrate that current models,\nincluding GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual\nprivacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the\ntime. In multi-turn conversations, these models disclose private information in\n59.9\\% and 50.5\\% of cases even under explicit privacy instructions.\nFurthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios.\nThese results underscore that current models are not aligned towards both\ncontextual privacy preservation and collaborative task-solving.", "published": "2025-06-25 18:04:25", "link": "http://arxiv.org/abs/2506.20737v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Omniwise: Predicting GPU Kernels Performance with LLMs", "abstract": "In recent years, the rapid advancement of deep neural networks (DNNs) has\nrevolutionized artificial intelligence, enabling models with unprecedented\ncapabilities in understanding, generating, and processing complex data. These\npowerful architectures have transformed a wide range of downstream\napplications, tackling tasks beyond human reach. In this paper, we introduce\nOmniwise, the first end-to-end, self-supervised fine-tuning pipeline that\napplies large language models (LLMs) to GPU kernel performance prediction--a\nnovel use case in performance profiling. Omniwise is model-agnostic and\nlightweight, achieving strong results even with a small 3B-parameter model. It\ncan predict key performance metrics, including memory bandwidth, cache hit\nrates, GFLOPs, and arithmetic intensity, directly from kernel code without the\nneed for code execution or profiling tools. Our approach achieves over 90% of\npredictions within 10% relative error on GPU kernels executed on AMD MI250 and\nMI300X architectures. In addition to the pipeline, we develop an online\ninference server and a Visual Studio Code plugin that seamlessly integrate\nLLM-based performance prediction into developers' workflows.", "published": "2025-06-25 23:36:44", "link": "http://arxiv.org/abs/2506.20886v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "abstract": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "published": "2025-06-25 23:10:12", "link": "http://arxiv.org/abs/2506.20883v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion", "abstract": "Monocular depth estimation methods traditionally train deep models to infer\ndepth directly from RGB pixels. This implicit learning often overlooks explicit\nmonocular cues that the human visual system relies on, such as occlusion\nboundaries, shading, and perspective. Rather than expecting a network to\ndiscover these cues unaided, we present ThirdEye, a cue-aware pipeline that\ndeliberately supplies each cue through specialised, pre-trained, and frozen\nnetworks. These cues are fused in a three-stage cortical hierarchy (V1->V2->V3)\nequipped with a key-value working-memory module that weights them by\nreliability. An adaptive-bins transformer head then produces a high-resolution\ndisparity map. Because the cue experts are frozen, ThirdEye inherits large\namounts of external supervision while requiring only modest fine-tuning. This\nextended version provides additional architectural detail, neuroscientific\nmotivation, and an expanded experimental protocol; quantitative results will\nappear in a future revision.", "published": "2025-06-25 22:59:40", "link": "http://arxiv.org/abs/2506.20877v1", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "primary_category": "cs.CV"}
{"title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "abstract": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "published": "2025-06-25 22:40:00", "link": "http://arxiv.org/abs/2506.20869v1", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "primary_category": "cs.SE"}
{"title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "abstract": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "published": "2025-06-25 21:48:21", "link": "http://arxiv.org/abs/2506.20851v1", "categories": ["cs.SE", "cs.AI", "cs.DB"], "primary_category": "cs.SE"}
{"title": "FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization", "abstract": "Semi-supervised domain generalization (SSDG) aims to solve the problem of\ngeneralizing to out-of-distribution data when only a few labels are available.\nDue to label scarcity, applying domain generalization methods often\nunderperform. Consequently, existing SSDG methods combine semi-supervised\nlearning methods with various regularization terms. However, these methods do\nnot explicitly regularize to learn domains invariant representations across all\ndomains, which is a key goal for domain generalization. To address this, we\nintroduce FixCLR. Inspired by success in self-supervised learning, we change\ntwo crucial components to adapt contrastive learning for explicit domain\ninvariance regularization: utilization of class information from pseudo-labels\nand using only a repelling term. FixCLR can also be added on top of most\nexisting SSDG and semi-supervised methods for complementary performance\nimprovements. Our research includes extensive experiments that have not been\npreviously explored in SSDG studies. These experiments include benchmarking\ndifferent improvements to semi-supervised methods, evaluating the performance\nof pretrained versus non-pretrained models, and testing on datasets with many\ndomains. Overall, FixCLR proves to be an effective SSDG method, especially when\ncombined with other semi-supervised methods.", "published": "2025-06-25 21:25:05", "link": "http://arxiv.org/abs/2506.20841v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models", "abstract": "Super-resolution (SR) is an ill-posed inverse problem with many feasible\nsolutions consistent with a given low-resolution image. On one hand, regressive\nSR models aim to balance fidelity and perceptual quality to yield a single\nsolution, but this trade-off often introduces artifacts that create ambiguity\nin information-critical applications such as recognizing digits or letters. On\nthe other hand, diffusion models generate a diverse set of SR images, but\nselecting the most trustworthy solution from this set remains a challenge. This\npaper introduces a robust, automated framework for identifying the most\ntrustworthy SR sample from a diffusion-generated set by leveraging the semantic\nreasoning capabilities of vision-language models (VLMs). Specifically, VLMs\nsuch as BLIP-2, GPT-4o, and their variants are prompted with structured queries\nto assess semantic correctness, visual quality, and artifact presence. The\ntop-ranked SR candidates are then ensembled to yield a single trustworthy\noutput in a cost-effective manner. To rigorously assess the validity of\nVLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid\nmetric that quantifies SR reliability based on three complementary components:\nsemantic similarity via CLIP embeddings, structural integrity using SSIM on\nedge maps, and artifact sensitivity through multi-level wavelet decomposition.\nWe empirically show that TWS correlates strongly with human preference in both\nambiguous and natural images, and that VLM-guided selections consistently yield\nhigh TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail\nto reflect information fidelity, our approach offers a principled, scalable,\nand generalizable solution for navigating the uncertainty of the diffusion SR\nspace. By aligning outputs with human expectations and semantic correctness,\nthis work sets a new benchmark for trustworthiness in generative SR.", "published": "2025-06-25 21:00:44", "link": "http://arxiv.org/abs/2506.20832v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications", "abstract": "LLM-powered applications are highly susceptible to the quality of user\nprompts, and crafting high-quality prompts can often be challenging especially\nfor domain-specific applications. This paper presents a novel dynamic\ncontext-aware prompt recommendation system for domain-specific AI applications.\nOur solution combines contextual query analysis, retrieval-augmented knowledge\ngrounding, hierarchical skill organization, and adaptive skill ranking to\ngenerate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical\nreasoning process to dynamically select and rank relevant skills, and\nsynthesizes prompts using both predefined and adaptive templates enhanced with\nfew-shot learning. Experiments on real-world datasets demonstrate that our\napproach achieves high usefulness and relevance, as validated by both automated\nand expert evaluations.", "published": "2025-06-25 20:29:46", "link": "http://arxiv.org/abs/2506.20815v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs", "abstract": "Recurrent neural networks (RNNs), particularly LSTMs, are effective for\ntime-series tasks like sentiment analysis and short-term stock prediction.\nHowever, their computational complexity poses challenges for real-time\ndeployment in resource constrained environments. While FPGAs offer a promising\nplatform for energy-efficient AI acceleration, existing tools mainly target\nfeed-forward networks, and LSTM acceleration typically requires full custom\nimplementation. In this paper, we address this gap by leveraging the\nopen-source and extensible FINN framework to enable the generalized deployment\nof LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open\nNeural Network Exchange (ONNX) specification to model the recurrent nature of\nLSTM computations, enabling support for mixed quantisation within them and\nfunctional verification of LSTM-based models. Furthermore, we introduce custom\ntransformations within the FINN compiler to map the quantised ONNX computation\ngraph to hardware blocks from the HLS kernel library of the FINN compiler and\nVitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM\nmodel for a mid-price stock prediction task using the widely used dataset and\ngenerating a corresponding hardware IP of the model using our flow, targeting\nthe XCZU7EV device. We show that the generated quantised ConvLSTM accelerator\nthrough our flow achieves a balance between performance (latency) and resource\nconsumption, while matching (or bettering) inference accuracy of\nstate-of-the-art models with reduced precision. We believe that the\ngeneralisable nature of the proposed flow will pave the way for\nresource-efficient RNN accelerator designs on FPGAs.", "published": "2025-06-25 20:07:46", "link": "http://arxiv.org/abs/2506.20810v1", "categories": ["cs.LG", "cs.AI", "cs.AR", "eess.SP"], "primary_category": "cs.LG"}
{"title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "abstract": "Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.", "published": "2025-06-25 19:59:34", "link": "http://arxiv.org/abs/2506.20807v1", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "abstract": "Graph Neural Networks (GNNs) show great promise for Network Intrusion\nDetection Systems (NIDS), particularly in IoT environments, but suffer\nperformance degradation due to distribution drift and lack robustness against\nrealistic adversarial attacks. Current robustness evaluations often rely on\nunrealistic synthetic perturbations and lack demonstrations on systematic\nanalysis of different kinds of adversarial attack, which encompass both\nblack-box and white-box scenarios. This work proposes a novel approach to\nenhance GNN robustness and generalization by employing Large Language Models\n(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These\nagents scrutinize graph structures derived from network flow data, identifying\nand potentially mitigating suspicious or adversarially perturbed elements\nbefore GNN processing. Our experiments, using a framework designed for\nrealistic evaluation and testing with a variety of adversarial attacks\nincluding a dataset collected from physical testbed experiments, demonstrate\nthat integrating LLM analysis can significantly improve the resilience of\nGNN-based NIDS against challenges, showcasing the potential of LLM agent as a\ncomplementary layer in intrusion detection architectures.", "published": "2025-06-25 19:49:55", "link": "http://arxiv.org/abs/2506.20806v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Stochastic Parameter Decomposition", "abstract": "A key step in reverse engineering neural networks is to decompose them into\nsimpler parts that can be studied in relative isolation. Linear parameter\ndecomposition -- a framework that has been proposed to resolve several issues\nwith current decomposition methods -- decomposes neural network parameters into\na sum of sparsely used vectors in parameter space. However, the current main\nmethod in this framework, Attribution-based Parameter Decomposition (APD), is\nimpractical on account of its computational cost and sensitivity to\nhyperparameters. In this work, we introduce \\textit{Stochastic Parameter\nDecomposition} (SPD), a method that is more scalable and robust to\nhyperparameters than APD, which we demonstrate by decomposing models that are\nslightly larger and more complex than was possible to decompose with APD. We\nalso show that SPD avoids other issues, such as shrinkage of the learned\nparameters, and better identifies ground truth mechanisms in toy models. By\nbridging causal mediation analysis and network decomposition methods, this\ndemonstration opens up new research possibilities in mechanistic\ninterpretability by removing barriers to scaling linear parameter decomposition\nmethods to larger models. We release a library for running SPD and reproducing\nour experiments at https://github.com/goodfire-ai/spd.", "published": "2025-06-25 19:26:31", "link": "http://arxiv.org/abs/2506.20790v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Agile Management for Machine Learning: A Systematic Mapping Study", "abstract": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "published": "2025-06-25 18:47:08", "link": "http://arxiv.org/abs/2506.20759v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots", "abstract": "Chatbots are increasingly integrated into people's lives and are widely used\nto help people. Recently, there has also been growing interest in the reverse\ndirection-humans help chatbots-due to a wide range of benefits including better\nchatbot performance, human well-being, and collaborative outcomes. However,\nlittle research has explored the factors that motivate people to help chatbots.\nTo address this gap, we draw on the Computers Are Social Actors (CASA)\nframework to examine how chatbot anthropomorphism-including human-like\nidentity, emotional expression, and non-verbal expression-influences human\nempathy toward chatbots and their subsequent prosocial behaviors and\nintentions. We also explore people's own interpretations of their prosocial\nbehaviors toward chatbots. We conducted an online experiment (N = 244) in which\nchatbots made mistakes in a collaborative image labeling task and explained the\nreasons to participants. We then measured participants' prosocial behaviors and\nintentions toward the chatbots. Our findings revealed that human identity and\nemotional expression of chatbots increased participants' prosocial behavior and\nintention toward chatbots, with empathy mediating these effects. Qualitative\nanalysis further identified two motivations for participants' prosocial\nbehaviors: empathy for the chatbot and perceiving the chatbot as human-like. We\ndiscuss the implications of these results for understanding and promoting human\nprosocial behaviors toward chatbots.", "published": "2025-06-25 18:16:14", "link": "http://arxiv.org/abs/2506.20748v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Accelerated Cops and Robbers", "abstract": "We consider a variant of Cops and Robbers in which both the cops and the\nrobber are allowed to traverse up to $s$ edges on each of their turns, where $s\n\\ge 2$. We give several general for this new model as well as establish bounds\nfor the cop numbers for grids and hypercubes. We also determine the capture\ntime of cop-win graphs when $s = 2$ up to a small additive constant.", "published": "2025-06-25 18:26:32", "link": "http://arxiv.org/abs/2506.20753v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Towards Two-Stage Counterfactual Learning to Rank", "abstract": "Counterfactual learning to rank (CLTR) aims to learn a ranking policy from\nuser interactions while correcting for the inherent biases in interaction data,\nsuch as position bias. Existing CLTR methods assume a single ranking policy\nthat selects top-K ranking from the entire document candidate set. In\nreal-world applications, the candidate document set is on the order of\nmillions, making a single-stage ranking policy impractical. In order to scale\nto millions of documents, real-world ranking systems are designed in a\ntwo-stage fashion, with a candidate generator followed by a ranker. The\nexisting CLTR method for a two-stage offline ranking system only considers the\ntop-1 ranking set-up and only focuses on training the candidate generator, with\nthe ranker fixed. A CLTR method for training both the ranker and candidate\ngenerator jointly is missing from the existing literature. In this paper, we\npropose a two-stage CLTR estimator that considers the interaction between the\ntwo stages and estimates the joint value of the two policies offline. In\naddition, we propose a novel joint optimization method to train the candidate\nand ranker policies, respectively. To the best of our knowledge, we are the\nfirst to propose a CLTR estimator and learning method for two-stage ranking.\nExperimental results on a semi-synthetic benchmark demonstrate the\neffectiveness of the proposed joint CLTR method over baselines.", "published": "2025-06-25 22:00:12", "link": "http://arxiv.org/abs/2506.20854v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers", "abstract": "Scientific fact-checking aims to determine the veracity of scientific claims\nby retrieving and analysing evidence from research literature. The problem is\ninherently more complex than general fact-checking since it must accommodate\nthe evolving nature of scientific knowledge, the structural complexity of\nacademic literature and the challenges posed by long-form, multimodal\nscientific expression. However, existing approaches focus on simplified\nversions of the problem based on small-scale datasets consisting of abstracts\nrather than full papers, thereby avoiding the distinct challenges associated\nwith processing complete documents. This paper examines the limitations of\ncurrent scientific fact-checking systems and reveals the many potential\nfeatures and resources that could be exploited to advance their performance. It\nidentifies key research challenges within evidence retrieval, including (1)\nevidence-driven retrieval that addresses semantic limitations and topic\nimbalance (2) time-aware evidence retrieval with citation tracking to mitigate\noutdated information, (3) structured document parsing to leverage long-range\ncontext, (4) handling complex scientific expressions, including tables,\nfigures, and domain-specific terminology and (5) assessing the credibility of\nscientific literature. Preliminary experiments were conducted to substantiate\nthese challenges and identify potential solutions. This perspective paper aims\nto advance scientific fact-checking with a specialised IR system tailored for\nreal-world applications.", "published": "2025-06-25 21:29:33", "link": "http://arxiv.org/abs/2506.20844v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation", "abstract": "This paper addresses the challenge of developing multimodal recommender\nsystems for the movie domain, where limited metadata (e.g., title, genre) often\nhinders the generation of robust recommendations. We introduce a resource that\ncombines LLM-generated plot descriptions with trailer-derived visual embeddings\nin a unified pipeline supporting both Retrieval-Augmented Generation (RAG) and\ncollaborative filtering. Central to our approach is a data augmentation step\nthat transforms sparse metadata into richer textual signals, alongside fusion\nstrategies (e.g., PCA, CCA) that integrate visual cues. Experimental\nevaluations demonstrate that CCA-based fusion significantly boosts recall\ncompared to unimodal baselines, while an LLM-driven re-ranking step further\nimproves NDCG, particularly in scenarios with limited textual data. By\nreleasing this framework, we invite further exploration of multi-modal\nrecommendation techniques tailored to cold-start, novelty-focused, and\ndomain-specific settings. All code, data, and detailed documentation are\npublicly available at: https://github.com/RecSys-lab/RAG-VisualRec", "published": "2025-06-25 20:32:12", "link": "http://arxiv.org/abs/2506.20817v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Entropic additive energy and entropy inequalities for sums and products", "abstract": "Following a growing number of studies that, over the past 15 years, have\nestablished entropy inequalities via ideas and tools from additive\ncombinatorics, in this work we obtain a number of new bounds for the\ndifferential entropy of sums, products, and sum-product combinations of\ncontinuous random variables. Partly motivated by recent work by Goh on the\ndiscrete entropic version of the notion of \"additive energy\", we introduce the\nadditive energy of pairs of continuous random variables and prove various\nversions of the statement that \"the additive energy is large if and only if the\nentropy of the sum is small\", along with a version of the\nBalog-Szemer\\'edi-Gowers theorem for differential entropy. Then, motivated in\npart by recent work by M\\'ath\\'e and O'Regan, we establish a series of new\ndifferential entropy inequalities for products and sum-product combinations of\ncontinuous random variables. In particular, we prove a new, general, ring\nPl\\\"unnecke-Ruzsa entropy inequality. We briefly return to the case of discrete\nentropy and provide a characterization of discrete random variables with \"large\ndoubling\", analogous to Tao's Freiman-type inverse sumset theory for the case\nof small doubling. Finally, we consider the natural entropic analog of the\nErd\\\"os-Szemer\\'edi sum-product phenomenon for integer-valued random variables.\nWe show that, if it does hold, then the range of parameters for which it does\nwould necessarily be significantly more restricted than its anticipated\ncombinatorial counterpart.", "published": "2025-06-25 20:22:12", "link": "http://arxiv.org/abs/2506.20813v1", "categories": ["cs.IT", "math.CO", "math.IT", "94A17 (Primary) 11B13 (Secondary)"], "primary_category": "cs.IT"}
{"title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "abstract": "In this work, we introduce an output-reweighting unlearning method, RWFT, a\nlightweight technique that erases an entire class from a trained classifier\nwithout full retraining. Forgetting specific classes from trained models is\nessential for enforcing user deletion rights and mitigating harmful or biased\npredictions. The full retraining is costly and existing unlearning methods fail\nto replicate the behavior of the retrained models when predicting samples from\nthe unlearned class. We prove this failure by designing a variant of membership\ninference attacks, MIA-NN that successfully reveals the unlearned class for any\nof these methods. We propose a simple redistribution of the probability mass\nfor the prediction on the samples in the forgotten class which is robust to\nMIA-NN. We also introduce a new metric based on the total variation (TV)\ndistance of the prediction probabilities to quantify residual leakage to\nprevent future methods from susceptibility to the new attack. Through extensive\nexperiments with state of the art baselines in machine unlearning, we show that\nour approach matches the results of full retraining in both metrics used for\nevaluation by prior work and the new metric we propose in this work. Compare to\nstate-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%\nin our new TV-based metric over the best existing method.", "published": "2025-06-25 23:53:56", "link": "http://arxiv.org/abs/2506.20893v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research", "abstract": "Data-driven agriculture, which integrates technology and data into\nagricultural practices, has the potential to improve crop yield, disease\nresilience, and long-term soil health. However, privacy concerns, such as\nadverse pricing, discrimination, and resource manipulation, deter farmers from\nsharing data, as it can be used against them. To address this barrier, we\npropose a privacy-preserving framework that enables secure data sharing and\ncollaboration for research and development while mitigating privacy risks. The\nframework combines dimensionality reduction techniques (like Principal\nComponent Analysis (PCA)) and differential privacy by introducing Laplacian\nnoise to protect sensitive information. The proposed framework allows\nresearchers to identify potential collaborators for a target farmer and train\npersonalized machine learning models either on the data of identified\ncollaborators via federated learning or directly on the aggregated\nprivacy-protected data. It also allows farmers to identify potential\ncollaborators based on similarities. We have validated this on real-life\ndatasets, demonstrating robust privacy protection against adversarial attacks\nand utility performance comparable to a centralized system. We demonstrate how\nthis framework can facilitate collaboration among farmers and help researchers\npursue broader research objectives. The adoption of the framework can empower\nresearchers and policymakers to leverage agricultural data responsibly, paving\nthe way for transformative advances in data-driven agriculture. By addressing\ncritical privacy challenges, this work supports secure data integration,\nfostering innovation and sustainability in agricultural systems.", "published": "2025-06-25 22:46:30", "link": "http://arxiv.org/abs/2506.20872v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management", "abstract": "The time allocation problem in multi-function cognitive radar systems focuses\non the trade-off between scanning for newly emerging targets and tracking the\npreviously detected targets. We formulate this as a multi-objective\noptimization problem and employ deep reinforcement learning to find\nPareto-optimal solutions and compare deep deterministic policy gradient (DDPG)\nand soft actor-critic (SAC) algorithms. Our results demonstrate the\neffectiveness of both algorithms in adapting to various scenarios, with SAC\nshowing improved stability and sample efficiency compared to DDPG. We further\nemploy the NSGA-II algorithm to estimate an upper bound on the Pareto front of\nthe considered problem. This work contributes to the development of more\nefficient and adaptive cognitive radar systems capable of balancing multiple\ncompeting objectives in dynamic environments.", "published": "2025-06-25 21:56:30", "link": "http://arxiv.org/abs/2506.20853v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Learning-Based Resource Management in Integrated Sensing and Communication Systems", "abstract": "In this paper, we tackle the task of adaptive time allocation in integrated\nsensing and communication systems equipped with radar and communication units.\nThe dual-functional radar-communication system's task involves allocating dwell\ntimes for tracking multiple targets and utilizing the remaining time for data\ntransmission towards estimated target locations. We introduce a novel\nconstrained deep reinforcement learning (CDRL) approach, designed to optimize\nresource allocation between tracking and communication under time budget\nconstraints, thereby enhancing target communication quality. Our numerical\nresults demonstrate the efficiency of our proposed CDRL framework, confirming\nits ability to maximize communication quality in highly dynamic environments\nwhile adhering to time constraints.", "published": "2025-06-25 21:44:07", "link": "http://arxiv.org/abs/2506.20849v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation Plasticity and Stress-Strain Response in FCC Alloys", "abstract": "Machine learning has significantly advanced the understanding and application\nof structural materials, with an increasing emphasis on integrating existing\ndata and quantifying uncertainties in predictive modeling. This study presents\na comprehensive methodology utilizing a mixed density network (MDN) model,\ntrained on extensive experimental data from literature. This approach uniquely\npredicts the distribution of dislocation density, inferred as a latent\nvariable, and the resulting stress distribution at the grain level. The\nincorporation of statistical parameters of those predicted distributions into a\ndislocation-mediated plasticity model allows for accurate stress-strain\npredictions with explicit uncertainty quantification. This strategy not only\nimproves the accuracy and reliability of mechanical property predictions but\nalso plays a vital role in optimizing alloy design, thereby facilitating the\ndevelopment of new materials in a rapidly evolving industry.", "published": "2025-06-25 21:18:14", "link": "http://arxiv.org/abs/2506.20839v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Multicontinuum Homogenization for Poroelasticity Model", "abstract": "In this paper, we derive multicontinuum poroelasticity models using the\nmulticontinuum homogenization method. Poroelasticity models are widely used in\nmany areas of science and engineering to describe coupled flow and mechanics\nprocesses in porous media. However, in many applications, the properties of\nporoelastic media possess high contrast, presenting serious computational\nchallenges. It is well known that standard homogenization approaches often fail\nto give an accurate solution due to the lack of macroscopic parameters.\nMulticontinuum approaches allow us to consider such cases by defining several\naverage states known as continua. In the field of poroelasticity,\nmultiple-network models arising from the multiple porous media theory are\nrepresentatives of these approaches. In this work, we extend previous findings\nby deriving the generalized multicontinuum poroelasticity model. We apply the\nrecently developed multicontinuum homogenization method and provide a rigorous\nderivation of multicontinuum equations. For this purpose, we formulate coupled\nconstraint cell problems in oversampled regions to consider different\nhomogenized effects. Then, we obtain a multicontinuum expansion of the\nfine-scale fields and derive the multicontinuum model supposing the smoothness\nof macroscopic variables. We present the most general version of equations and\nthe simplified ones based on our numerical experiments. Numerical results are\npresented for different heterogeneous media cases and demonstrate the high\naccuracy of our proposed multicontinuum models.", "published": "2025-06-25 23:48:57", "link": "http://arxiv.org/abs/2506.20890v1", "categories": ["math.NA", "cs.CE", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Boundary integral equation analysis for spheroidal suspensions", "abstract": "In this work, we provide a fast, spectrally accurate method for the\nevaluation of boundary integral operators (BIOs) on a suspension of prolate and\noblate spheroids. We first derive formulas for the standard layer potential\noperators for the Laplace equation applied to an expansion of the integral\ndensities in the appropriate spheroidal harmonic basis. These then lead to\nanalytical expressions in solid harmonics that allow spectrally accurate\nevaluation of near-field particle interactions. Finally, a standard quadrature\nscheme is used to evaluate smooth, far-field interactions; these are then\naccelerated using the fast multipole method.\n  Through a number of numerical test cases, we verify the accuracy and\nefficiency of our BIO evaluation framework for dense, polydisperse suspensions\nof spheroids. Through the use of standard formulas linking Stokes and Laplace\npotentials, we show our scheme can be readily applied to problems involving\nparticulate suspension flows. For both Laplace and Stokes, our method allows us\nto evaluate BIOs for suspensions up to hundreds of particles on a single\nprocessor.", "published": "2025-06-25 20:07:16", "link": "http://arxiv.org/abs/2506.20809v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method", "abstract": "We study an inverse problem for the time-dependent Maxwell system in an\ninhomogeneous and anisotropic medium. The objective is to recover the initial\nelectric field $\\mathbf{E}_0$ in a bounded domain $\\Omega \\subset\n\\mathbb{R}^3$, using boundary measurements of the electric field and its normal\nderivative over a finite time interval. Informed by practical constraints, we\nadopt an under-determined formulation of Maxwell's equations that avoids the\nneed for initial magnetic field data and charge density information. To address\nthis inverse problem, we develop a time-dimension reduction approach by\nprojecting the electric field onto a finite-dimensional Legendre\npolynomial-exponential basis in time. This reformulates the original space-time\nproblem into a sequence of spatial systems for the projection coefficients. The\nreconstruction is carried out using the quasi-reversibility method within a\nminimum-norm framework, which accommodates the inherent non-uniqueness of the\nunder-determined setting. We prove a convergence theorem that ensures the\nquasi-reversibility solution approximates the true solution as the noise and\nregularization parameters vanish. Numerical experiments in a fully\nthree-dimensional setting validate the method's performance. The reconstructed\ninitial electric field remains accurate even with $10\\%$ noise in the data,\ndemonstrating the robustness and applicability of the proposed approach to\nrealistic inverse electromagnetic problems.", "published": "2025-06-25 19:08:53", "link": "http://arxiv.org/abs/2506.20777v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion", "abstract": "We present a novel, generalised formulation to treat coupled structural\nintegrity problems by combining phase field and multi-physics modelling. The\napproach exploits the versatility of the heat transfer equation and is\ntherefore well suited to be adopted in commercial finite element packages,\nrequiring only integration point-level implementation. This aspect is\ndemonstrated here by implementing coupled, multi-variable phenomena through\nsimple \\texttt{UMAT} and \\texttt{UMATHT} subroutines in the finite element\npackage \\texttt{Abaqus}. The generalised theoretical and computational\nframework presented is particularised to four problems of engineering and\nscientific relevance: thermo-mechanical fracture, hydraulic fracture,\nhydrogen-assisted cracking and metallic corrosion. 2D and 3D problems are\nconsidered. The results reveal a very good agreement with experimental data,\nand existing numerical and analytical solutions.The user subroutines developed\nare made freely available at https://mechmat.web.ox.ac.uk/codes.", "published": "2025-06-25 18:53:01", "link": "http://arxiv.org/abs/2506.20763v1", "categories": ["cs.CE", "cs.NA", "math.NA", "physics.app-ph"], "primary_category": "cs.CE"}
{"title": "Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon", "abstract": "We study the implicit bias of flatness / low (loss) curvature and its effects\non generalization in two-layer overparameterized ReLU networks with\nmultivariate inputs -- a problem well motivated by the minima stability and\nedge-of-stability phenomena in gradient-descent training. Existing work either\nrequires interpolation or focuses only on univariate inputs. This paper\npresents new and somewhat surprising theoretical results for multivariate\ninputs. On two natural settings (1) generalization gap for flat solutions, and\n(2) mean-squared error (MSE) in nonparametric function estimation by stable\nminima, we prove upper and lower bounds, which establish that while flatness\ndoes imply generalization, the resulting rates of convergence necessarily\ndeteriorate exponentially as the input dimension grows. This gives an\nexponential separation between the flat solutions vis-\\`a-vis low-norm\nsolutions (i.e., weight decay), which knowingly do not suffer from the curse of\ndimensionality. In particular, our minimax lower bound construction, based on a\nnovel packing argument with boundary-localized ReLU neurons, reveals how flat\nsolutions can exploit a kind of ''neural shattering'' where neurons rarely\nactivate, but with high weight magnitudes. This leads to poor performance in\nhigh dimensions. We corroborate these theoretical findings with extensive\nnumerical simulations. To the best of our knowledge, our analysis provides the\nfirst systematic explanation for why flat minima may fail to generalize in high\ndimensions.", "published": "2025-06-25 19:10:03", "link": "http://arxiv.org/abs/2506.20779v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Latent-space Field Tension for Astrophysical Component Detection An application to X-ray imaging", "abstract": "Modern observatories are designed to deliver increasingly detailed views of\nastrophysical signals. To fully realize the potential of these observations,\nprincipled data-analysis methods are required to effectively separate and\nreconstruct the underlying astrophysical components from data corrupted by\nnoise and instrumental effects. In this work, we introduce a novel\nmulti-frequency Bayesian model of the sky emission field that leverages\nlatent-space tension as an indicator of model misspecification, enabling\nautomated separation of diffuse, point-like, and extended astrophysical\nemission components across wavelength bands. Deviations from latent-space prior\nexpectations are used as diagnostics for model misspecification, thus\nsystematically guiding the introduction of new sky components, such as\npoint-like and extended sources. We demonstrate the effectiveness of this\nmethod on synthetic multi-frequency imaging data and apply it to observational\nX-ray data from the eROSITA Early Data Release (EDR) of the SN1987A region in\nthe Large Magellanic Cloud (LMC). Our results highlight the method's capability\nto reconstruct astrophysical components with high accuracy, achieving sub-pixel\nlocalization of point sources, robust separation of extended emission, and\ndetailed uncertainty quantification. The developed methodology offers a general\nand well-founded framework applicable to a wide variety of astronomical\ndatasets, and is therefore well suited to support the analysis needs of\nnext-generation multi-wavelength and multi-messenger surveys.", "published": "2025-06-25 18:45:18", "link": "http://arxiv.org/abs/2506.20758v1", "categories": ["astro-ph.IM", "astro-ph.HE", "stat.AP", "stat.ML"], "primary_category": "astro-ph.IM"}
{"title": "On Convolutions, Intrinsic Dimension, and Diffusion Models", "abstract": "The manifold hypothesis asserts that data of interest in high-dimensional\nambient spaces, such as image data, lies on unknown low-dimensional\nsubmanifolds. Diffusion models (DMs) -- which operate by convolving data with\nprogressively larger amounts of Gaussian noise and then learning to revert this\nprocess -- have risen to prominence as the most performant generative models,\nand are known to be able to learn distributions with low-dimensional support.\nFor a given datum in one of these submanifolds, we should thus intuitively\nexpect DMs to have implicitly learned its corresponding local intrinsic\ndimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari\net al. (2024b) recently showed that this is indeed the case by linking this LID\nto the rate of change of the log marginal densities of the DM with respect to\nthe amount of added noise, resulting in an LID estimator known as FLIPD. LID\nestimators such as FLIPD have a plethora of uses, among others they quantify\nthe complexity of a given datum, and can be used to detect outliers,\nadversarial examples and AI-generated text. FLIPD achieves state-of-the-art\nperformance at LID estimation, yet its theoretical underpinnings are incomplete\nsince Kamkari et al. (2024b) only proved its correctness under the highly\nunrealistic assumption of affine submanifolds. In this work we bridge this gap\nby formally proving the correctness of FLIPD under realistic assumptions.\nAdditionally, we show that an analogous result holds when Gaussian convolutions\nare replaced with uniform ones, and discuss the relevance of this result.", "published": "2025-06-25 18:00:00", "link": "http://arxiv.org/abs/2506.20705v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models", "abstract": "Adapting a pretrained diffusion model to new objectives at inference time\nremains an open problem in generative modeling. Existing steering methods\nsuffer from inaccurate value estimation, especially at high noise levels, which\nbiases guidance. Moreover, information from past runs is not reused to improve\nsample quality, resulting in inefficient use of compute. Inspired by the\nsuccess of Monte Carlo Tree Search, we address these limitations by casting\ninference-time alignment as a search problem that reuses past computations. We\nintroduce a tree-based approach that samples from the reward-aligned target\ndensity by propagating terminal rewards back through the diffusion chain and\niteratively refining value estimates with each additional generation. Our\nproposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact\nsamples from the target distribution in the limit of infinite rollouts, and its\ngreedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search\nfor high reward samples. On MNIST and CIFAR-10 class-conditional generation,\nDTS matches the FID of the best-performing baseline with up to $10\\times$ less\ncompute. In text-to-image generation and language completion tasks, DTS$^\\star$\neffectively searches for high reward samples that match best-of-N with up to\n$5\\times$ less compute. By reusing information from previous generations, we\nget an anytime algorithm that turns additional compute into steadily better\nsamples, providing a scalable approach for inference-time alignment of\ndiffusion models.", "published": "2025-06-25 17:59:10", "link": "http://arxiv.org/abs/2506.20701v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications", "abstract": "Quantum computing is poised to redefine the algorithmic foundations of\ncommunication systems. While quantum superposition and entanglement enable\nquadratic or exponential speedups for specific problems, identifying use cases\nwhere these advantages yield engineering benefits is, however, still\nnontrivial. This article presents the fundamentals of quantum computing in a\nstyle familiar to the communications society, outlining the current limits of\nfault-tolerant quantum computing and uncovering a mathematical harmony between\nquantum and wireless systems, which makes the topic more enticing to wireless\nresearchers. Based on a systematic review of pioneering and state-of-the-art\nstudies, we distill common design trends for the research and development of\nquantum-accelerated communication systems and highlight lessons learned. The\nkey insight is that classical heuristics can sharpen certain quantum\nparameters, underscoring the complementary strengths of classical and quantum\ncomputing. This article aims to catalyze interdisciplinary research at the\nfrontier of quantum information processing and future communication systems.", "published": "2025-06-25 22:25:47", "link": "http://arxiv.org/abs/2506.20863v1", "categories": ["eess.SP", "quant-ph"], "primary_category": "eess.SP"}
{"title": "Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications", "abstract": "Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology\nhas garnered significant interest as a connectivity solution for IoT\napplications due to its ability to offer low-cost, low-power, and long-range\ncommunications. One emerging use case of LoRa is DtS connectivity, which\nextends coverage to remote areas for supporting IoT operations. The satellite\nIoT industry mainly prefers LEO because it has lower launch costs and less path\nloss compared to Geostationary orbit. However, a major drawback of LEO\nsatellites is the impact of the Doppler effect caused by their mobility.\nEarlier studies have confirmed that the Doppler effect significantly degrades\nthe LoRa DtS performance. In this paper, we propose four frameworks for Doppler\nestimation and compensation in LoRa DtS connectivity and numerically compare\nthe performance against the ideal scenario without the Doppler effect.\nFurthermore, we investigate the trade-offs among these frameworks by analyzing\nthe interplay between spreading factor, and other key parameters related to the\nDoppler effect. The results provide insights into how to achieve robust LoRa\nconfigurations for DtS connectivity.", "published": "2025-06-25 22:09:21", "link": "http://arxiv.org/abs/2506.20858v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links", "abstract": "This paper presents an efficient analytical framework for evaluating the\nperformance of inter-satellite communication systems utilizing orbital angular\nmomentum (OAM) beams under pointing errors. An accurate analytical model is\nfirst developed to characterize intermodal crosstalk caused by beam\nmisalignment in OAM-based inter-satellite links. Building upon this model, we\nderive efficient expressions to analyze and optimize system performance in\nterms of bit error rate (BER). Unlike traditional Monte Carlo-based methods\nthat are computationally intensive, the proposed approach offers accurate\nperformance predictions. This enables a substantial decrease in computation\ntime while maintaining high accuracy, thanks to the use of analytical\nexpressions for both crosstalk and BER. This fast and accurate evaluation\ncapability is particularly critical for dynamic low Earth orbit (LEO) satellite\nconstellations, where network topology and channel conditions change rapidly,\nrequiring real-time link adaptation. Furthermore, we systematically design and\nevaluate asymmetric OAM mode sets, which significantly outperform symmetric\nconfigurations in the presence of pointing errors. Our results also reveal key\ninsights into the interaction between beam divergence, tracking accuracy, and\nlink distance, demonstrating that the proposed framework enables real-time\noptimization of system parameters with high fidelity. The analytical findings\nare rigorously validated against extensive Monte Carlo simulations, confirming\ntheir practical applicability for high-mobility optical wireless systems such\nas LEO satellite networks.", "published": "2025-06-25 20:46:41", "link": "http://arxiv.org/abs/2506.20823v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links", "abstract": "Entanglement-based quantum key distribution (QKD) protocols, such as E91 and\nBBM92, offer strong information-theoretic security and are naturally suited for\nsatellite-to-satellite QKD (SatQKD) links. However, implementing these\nprotocols over long-distance inter-satellite free-space optical (FSO) channels\nposes critical physical-layer challenges that are not addressed in the existing\nliterature. In particular, photon losses due to beam divergence, pointing\nerrors, and background noise can severely degrade the key generation rate and\nquantum bit error rate (QBER), especially under narrow receiver field-of-view\n(FoV) constraints. This paper presents a comprehensive performance analysis of\nentanglement-based inter-satellite QKD, focusing on photon-level modeling and\nthe impact of practical impairments. We develop analytical expressions for\nsignal detection probabilities, background photon influence, multi-pair\nemissions, and QBER, incorporating key parameters such as link distance,\ntransmitter tracking jitter, receiver misalignment, and photon pair generation\nrate. Simulation results reveal the nonlinear sensitivity of system performance\nto tracking error and FoV limitations, and highlight optimal parameter regimes\nthat jointly maximize secret key rate while maintaining QBER below acceptable\nthresholds. The proposed model provides actionable design insights for reliable\nand efficient deployment of entanglement-based SatQKD systems.", "published": "2025-06-25 19:42:36", "link": "http://arxiv.org/abs/2506.20798v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement", "abstract": "Extremely large antenna arrays (ELAAs) operating in high-frequency bands have\nspurred the development of near-field communication, driving advancements in\nbeam training and signal processing design. In this work, we present a\nlow-complexity near-field beam training scheme that fully utilizes the\nconventional discrete Fourier transform (DFT) codebook designed for far-field\nusers. We begin by analyzing the received beam pattern in the near field and\nderive closed-form expressions for the beam width and central gain. These\nanalytical results enable the definition of an angle-dependent, modified\nRayleigh distance, which effectively distinguishes near-field and far-field\nuser regimes. Building on the analysis, we develop a direct and computationally\nefficient method to estimate user distance, with a complexity of O(1), and\nfurther improve its accuracy through a simple refinement. Simulation results\ndemonstrate significant gains in both single- and multi-user settings, with up\nto 2.38 dB SNR improvement over exhaustive search. To further enhance\nestimation accuracy, we additionally propose a maximum likelihood estimation\n(MLE) based refinement method, leveraging the Rician distribution of signal\namplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).\nSimulation shows the single-user and multi-user achievable rates can both\napproach those obtained with ideal channel state information.", "published": "2025-06-25 19:13:36", "link": "http://arxiv.org/abs/2506.20783v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing", "abstract": "We present the first theoretical framework for applying spiking neural\nnetworks (SNNs) to synthetic aperture radar (SAR) interferometric phase\nunwrapping. Despite extensive research in both domains, our comprehensive\nliterature review confirms that SNNs have never been applied to phase\nunwrapping, representing a significant gap in current methodologies. As Earth\nobservation data volumes continue to grow exponentially (with missions like\nNISAR expected to generate 100PB in two years) energy-efficient processing\nbecomes critical for sustainable data center operations. SNNs, with their\nevent-driven computation model, offer potential energy savings of 30-100x\ncompared to conventional approaches while maintaining comparable accuracy. We\ndevelop spike encoding schemes specifically designed for wrapped phase data,\npropose SNN architectures that leverage the spatial propagation nature of phase\nunwrapping, and provide theoretical analysis of computational complexity and\nconvergence properties. Our framework demonstrates how the temporal dynamics\ninherent in SNNs can naturally model the spatial continuity constraints\nfundamental to phase unwrapping. This work opens a new research direction at\nthe intersection of neuromorphic computing and SAR interferometry, offering a\ncomplementary approach to existing algorithms that could enable more\nsustainable large-scale InSAR processing.", "published": "2025-06-25 19:12:16", "link": "http://arxiv.org/abs/2506.20782v1", "categories": ["cs.NE", "cs.ET", "cs.LG", "eess.SP", "68T07, 94A08", "I.2.6; G.1.6; B.7.1"], "primary_category": "cs.NE"}
{"title": "Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks", "abstract": "In this paper, we propose a novel drift-adaptive slicing-based resource\nmanagement scheme for cooperative integrated sensing and communication (ISAC)\nnetworks. Particularly, we establish two network slices to provide sensing and\ncommunication services, respectively. In the large-timescale planning for the\nslices, we partition the sensing region of interest (RoI) of each mobile device\nand reserve network resources accordingly, facilitating low-complexity\ndistance-based sensing target assignment in small timescales. To cope with the\nnon-stationary spatial distributions of mobile devices and sensing targets,\nwhich can result in the drift in modeling the distributions and ineffective\nplanning decisions, we construct digital twins (DTs) of the slices. In each DT,\na drift-adaptive statistical model and an emulation function are developed for\nthe spatial distributions in the corresponding slice, which facilitates\nclosed-form decision-making and efficient validation of a planning decision,\nrespectively. Numerical results show that the proposed drift-adaptive\nslicing-based resource management scheme can increase the service satisfaction\nratio by up to 18% and reduce resource consumption by up to 13.1% when compared\nwith benchmark schemes.", "published": "2025-06-25 18:52:00", "link": "http://arxiv.org/abs/2506.20762v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Transformer Based Multi-Target Bernoulli Tracking for Maritime Radar", "abstract": "Multi-target tracking in the maritime domain is a challenging problem due to\nthe non-Gaussian and fluctuating characteristics of sea clutter. This article\ninvestigates the use of machine learning (ML) to the detection and tracking of\nlow SIR targets in the maritime domain. The proposed method uses a transformer\nto extract point measurements from range-azimuth maps, before clustering and\ntracking using the Labelled mulit- Bernoulli (LMB) filter. A measurement driven\nbirth density design based on the transformer attention maps is also developed.\nThe error performance of the transformer based approach is presented and\ncompared with a constant false alarm rate (CFAR) detection technique. The LMB\nfilter is run in two scenarios, an ideal birth approach, and the measurement\ndriven birth approach. Experiments indicate that the transformer based method\nhas superior performance to the CFAR approach for all target scenarios\ndiscussed", "published": "2025-06-25 11:00:15", "link": "http://arxiv.org/abs/2506.20319v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations", "abstract": "An intrinsic aspect of every conversation is the way talk-time is shared\nbetween multiple speakers. Conversations can be balanced, with each speaker\nclaiming a similar amount of talk-time, or imbalanced when one talks\ndisproportionately. Such overall distributions are the consequence of\ncontinuous negotiations between the speakers throughout the conversation: who\nshould be talking at every point in time, and for how long? In this work we\nintroduce a computational framework for quantifying both the conversation-level\ndistribution of talk-time between speakers, as well as the lower-level dynamics\nthat lead to it. We derive a typology of talk-time sharing dynamics structured\nby several intuitive axes of variation. By applying this framework to a large\ndataset of video-chats between strangers, we confirm that, perhaps\nunsurprisingly, different conversation-level distributions of talk-time are\nperceived differently by speakers, with balanced conversations being preferred\nover imbalanced ones, especially by those who end up talking less. Then we\nreveal that -- even when they lead to the same level of overall balance --\ndifferent types of talk-time sharing dynamics are perceived differently by the\nparticipants, highlighting the relevance of our newly introduced typology.\nFinally, we discuss how our framework offers new tools to designers of\ncomputer-mediated communication platforms, for both human-human and human-AI\ncommunication.", "published": "2025-06-25 14:23:02", "link": "http://arxiv.org/abs/2506.20474v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "abstract": "Integrating compositional and symbolic properties into current distributional\nsemantic spaces can enhance the interpretability, controllability,\ncompositionality, and generalisation capabilities of Transformer-based\nauto-regressive language models (LMs). In this survey, we offer a novel\nperspective on latent space geometry through the lens of compositional\nsemantics, a direction we refer to as \\textit{semantic representation\nlearning}. This direction enables a bridge between symbolic and distributional\nsemantics, helping to mitigate the gap between them. We review and compare\nthree mainstream autoencoder architectures-Variational AutoEncoder (VAE),\nVector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the\ndistinctive latent geometries they induce in relation to semantic structure and\ninterpretability.", "published": "2025-06-25 01:48:18", "link": "http://arxiv.org/abs/2506.20083v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
