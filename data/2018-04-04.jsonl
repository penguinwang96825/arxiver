{"title": "Abstractive Tabular Dataset Summarization via Knowledge Base Semantic\n  Embeddings", "abstract": "This paper describes an abstractive summarization method for tabular data\nwhich employs a knowledge base semantic embedding to generate the summary.\nAssuming the dataset contains descriptive text in headers, columns and/or some\naugmenting metadata, the system employs the embedding to recommend a\nsubject/type for each text segment. Recommendations are aggregated into a small\ncollection of super types considered to be descriptive of the dataset by\nexploiting the hierarchy of types in a pre-specified ontology. Using February\n2015 Wikipedia as the knowledge base, and a corresponding DBpedia ontology as\ntypes, we present experimental results on open data taken from several\nsources--OpenML, CKAN and data.world--to illustrate the effectiveness of the\napproach.", "published": "2018-04-04 16:45:04", "link": "http://arxiv.org/abs/1804.01503v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Jointly Discovering Visual Objects and Spoken Words from Raw Sensory\n  Input", "abstract": "In this paper, we explore neural network models that learn to associate\nsegments of spoken audio captions with the semantically relevant portions of\nnatural images that they refer to. We demonstrate that these audio-visual\nassociative localizations emerge from network-internal representations learned\nas a by-product of training to perform an image-audio retrieval task. Our\nmodels operate directly on the image pixels and speech waveform, and do not\nrely on any conventional supervision in the form of labels, segmentations, or\nalignments between the modalities during training. We perform analysis using\nthe Places 205 and ADE20k datasets demonstrating that our models implicitly\nlearn semantically-coupled object and word detectors.", "published": "2018-04-04 15:03:08", "link": "http://arxiv.org/abs/1804.01452v1", "categories": ["cs.CV", "cs.CL", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Clinical Concept Embeddings Learned from Massive Sources of Multimodal\n  Medical Data", "abstract": "Word embeddings are a popular approach to unsupervised learning of word\nrelationships that are widely used in natural language processing. In this\narticle, we present a new set of embeddings for medical concepts learned using\nan extremely large collection of multimodal medical data. Leaning on recent\ntheoretical insights, we demonstrate how an insurance claims database of 60\nmillion members, a collection of 20 million clinical notes, and 1.7 million\nfull text biomedical journal articles can be combined to embed concepts into a\ncommon space, resulting in the largest ever set of embeddings for 108,477\nmedical concepts. To evaluate our approach, we present a new benchmark\nmethodology based on statistical power specifically designed to test embeddings\nof medical concepts. Our approach, called cui2vec, attains state-of-the-art\nperformance relative to previous methods in most instances. Finally, we provide\na downloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings", "published": "2018-04-04 16:02:54", "link": "http://arxiv.org/abs/1804.01486v3", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Classification of Vehicles Based on Audio Signals using Quadratic\n  Discriminant Analysis and High Energy Feature Vectors", "abstract": "The focus of this paper is on classification of different vehicles using\nsound emanated from the vehicles. In this paper,quadratic discriminant analysis\nclassifies audio signals of passing vehicles to bus, car, motor, and truck\ncategories based on features such as short time energy, average zero cross\nrate, and pitch frequency of periodic segments of signals. Simulation results\nshow that just by considering high energy feature vectors, better\nclassification accuracy can be achieved due to the correspondence of low energy\nregions with noises of the background. To separate these elements, short time\nenergy and average zero cross rate are used simultaneously.In our method,we\nhave used a few features which are easy to be calculated in time domain and\nenable practical implementation of efficient classifier. Although, the\ncomputation complexity is low, the classification accuracy is comparable with\nother classification methods based on long feature vectors reported in\nliterature for this problem.", "published": "2018-04-04 02:19:27", "link": "http://arxiv.org/abs/1804.01212v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
