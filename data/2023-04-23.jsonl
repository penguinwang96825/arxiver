{"title": "Lost in Translationese? Reducing Translation Effect Using Abstract\n  Meaning Representation", "abstract": "Translated texts bear several hallmarks distinct from texts originating in\nthe language. Though individual translated texts are often fluent and preserve\nmeaning, at a large scale, translated texts have statistical tendencies which\ndistinguish them from text originally written in the language\n(\"translationese\") and can affect model performance. We frame the novel task of\ntranslationese reduction and hypothesize that Abstract Meaning Representation\n(AMR), a graph-based semantic representation which abstracts away from the\nsurface form, can be used as an interlingua to reduce the amount of\ntranslationese in translated texts. By parsing English translations into an AMR\nand then generating text from that AMR, the result more closely resembles\noriginally English text across three quantitative macro-level measures, without\nseverely compromising fluency or adequacy. We compare our AMR-based approach\nagainst three other techniques based on machine translation or paraphrase\ngeneration. This work makes strides towards reducing translationese in text and\nhighlights the utility of AMR as an interlingua.", "published": "2023-04-23 00:04:14", "link": "http://arxiv.org/abs/2304.11501v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph Neural Networks for Text Classification: A Survey", "abstract": "Text Classification is the most essential and fundamental problem in Natural\nLanguage Processing. While numerous recent text classification models applied\nthe sequential deep learning technique, graph neural network-based models can\ndirectly deal with complex structured text data and exploit global information.\nMany real text classification applications can be naturally cast into a graph,\nwhich captures words, documents, and corpus global features. In this survey, we\nbring the coverage of methods up to 2023, including corpus-level and\ndocument-level graph neural networks. We discuss each of these methods in\ndetail, dealing with the graph construction mechanisms and the graph-based\nlearning process. As well as the technological survey, we look at issues behind\nand future directions addressed in text classification using graph neural\nnetworks. We also cover datasets, evaluation metrics, and experiment design and\npresent a summary of published performance on the publicly available\nbenchmarks. Note that we present a comprehensive comparison between different\ntechniques and identify the pros and cons of various evaluation metrics in this\nsurvey.", "published": "2023-04-23 04:21:50", "link": "http://arxiv.org/abs/2304.11534v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating ChatGPT's Information Extraction Capabilities: An Assessment\n  of Performance, Explainability, Calibration, and Faithfulness", "abstract": "The capability of Large Language Models (LLMs) like ChatGPT to comprehend\nuser intent and provide reasonable responses has made them extremely popular\nlately. In this paper, we focus on assessing the overall ability of ChatGPT\nusing 7 fine-grained information extraction (IE) tasks. Specially, we present\nthe systematically analysis by measuring ChatGPT's performance, explainability,\ncalibration, and faithfulness, and resulting in 15 keys from either the ChatGPT\nor domain experts. Our findings reveal that ChatGPT's performance in\nStandard-IE setting is poor, but it surprisingly exhibits excellent performance\nin the OpenIE setting, as evidenced by human evaluation. In addition, our\nresearch indicates that ChatGPT provides high-quality and trustworthy\nexplanations for its decisions. However, there is an issue of ChatGPT being\noverconfident in its predictions, which resulting in low calibration.\nFurthermore, ChatGPT demonstrates a high level of faithfulness to the original\ntext in the majority of cases. We manually annotate and release the test sets\nof 7 fine-grained IE tasks contains 14 datasets to further promote the\nresearch. The datasets and code are available at\nhttps://github.com/pkuserc/ChatGPT_for_IE.", "published": "2023-04-23 12:33:18", "link": "http://arxiv.org/abs/2304.11633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Mastery Benchmark: An Ever-Updating Benchmark for Evaluating\n  Holistic Domain Knowledge of Large Language Model--A Preliminary Release", "abstract": "Domain knowledge refers to the in-depth understanding, expertise, and\nfamiliarity with a specific subject, industry, field, or area of special\ninterest. The existing benchmarks are all lack of an overall design for domain\nknowledge evaluation. Holding the belief that the real ability of domain\nlanguage understanding can only be fairly evaluated by an comprehensive and\nin-depth benchmark, we introduces the Domma, a Domain Mastery Benchmark. DomMa\ntargets at testing Large Language Models (LLMs) on their domain knowledge\nunderstanding, it features extensive domain coverage, large data volume, and a\ncontinually updated data set based on Chinese 112 first-level subject\nclassifications. DomMa consist of 100,000 questions in both Chinese and English\nsourced from graduate entrance examinations and undergraduate exams in Chinese\ncollege. We have also propose designs to make benchmark and evaluation process\nmore suitable to LLMs.", "published": "2023-04-23 15:11:49", "link": "http://arxiv.org/abs/2304.11679v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NAIST-SIC-Aligned: an Aligned English-Japanese Simultaneous\n  Interpretation Corpus", "abstract": "It remains a question that how simultaneous interpretation (SI) data affects\nsimultaneous machine translation (SiMT). Research has been limited due to the\nlack of a large-scale training corpus. In this work, we aim to fill in the gap\nby introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel\nEnglish-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we\npropose a two-stage alignment approach to make the corpus parallel and thus\nsuitable for model training. The first stage is coarse alignment where we\nperform a many-to-many mapping between source and target sentences, and the\nsecond stage is fine-grained alignment where we perform intra- and\ninter-sentence filtering to improve the quality of aligned pairs. To ensure the\nquality of the corpus, each step has been validated either quantitatively or\nqualitatively. This is the first open-sourced large-scale parallel SI dataset\nin the literature. We also manually curated a small test set for evaluation\npurposes. Our results show that models trained with SI data lead to significant\nimprovement in translation quality and latency over baselines. We hope our work\nadvances research on SI corpora construction and SiMT. Our data can be found at\nhttps://github.com/mingzi151/AHC-SI.", "published": "2023-04-23 23:03:58", "link": "http://arxiv.org/abs/2304.11766v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Divide and Prompt: Chain of Thought Prompting for Text-to-SQL", "abstract": "Chain-of-thought (CoT) prompting combined with large language models (LLMs)\nhave achieved encouraging results on complex reasoning tasks. Text-to-SQL is a\ncritical semantic parsing task that converts natural language questions into\nSQL statements, involving a complex reasoning process. However, there is little\nwork about using CoT prompting to activate LLM's reasoning capabilities on\nText-to-SQL tasks. In this work, we propose a new paradigm for prompting\nText-to-SQL tasks, called Divide-and-Prompt, which first divides the task into\nsubtasks, and then approach each subtask through CoT. We present 3\nprompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments\nshow that these prompts guide LLMs to generate Text-to-SQL with higher\nexecution accuracy.", "published": "2023-04-23 06:52:35", "link": "http://arxiv.org/abs/2304.11556v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Differentiate ChatGPT-generated and Human-written Medical Texts", "abstract": "Background: Large language models such as ChatGPT are capable of generating\ngrammatically perfect and human-like text content, and a large number of\nChatGPT-generated texts have appeared on the Internet. However, medical texts\nsuch as clinical notes and diagnoses require rigorous validation, and erroneous\nmedical content generated by ChatGPT could potentially lead to disinformation\nthat poses significant harm to healthcare and the general public.\n  Objective: This research is among the first studies on responsible and\nethical AIGC (Artificial Intelligence Generated Content) in medicine. We focus\non analyzing the differences between medical texts written by human experts and\ngenerated by ChatGPT, and designing machine learning workflows to effectively\ndetect and differentiate medical texts generated by ChatGPT.\n  Methods: We first construct a suite of datasets containing medical texts\nwritten by human experts and generated by ChatGPT. In the next step, we analyze\nthe linguistic features of these two types of content and uncover differences\nin vocabulary, part-of-speech, dependency, sentiment, perplexity, etc. Finally,\nwe design and implement machine learning methods to detect medical text\ngenerated by ChatGPT.\n  Results: Medical texts written by humans are more concrete, more diverse, and\ntypically contain more useful information, while medical texts generated by\nChatGPT pay more attention to fluency and logic, and usually express general\nterminologies rather than effective information specific to the context of the\nproblem. A BERT-based model can effectively detect medical texts generated by\nChatGPT, and the F1 exceeds 95%.", "published": "2023-04-23 07:38:07", "link": "http://arxiv.org/abs/2304.11567v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modality-Aware Negative Sampling for Multi-modal Knowledge Graph\n  Embedding", "abstract": "Negative sampling (NS) is widely used in knowledge graph embedding (KGE),\nwhich aims to generate negative triples to make a positive-negative contrast\nduring training. However, existing NS methods are unsuitable when multi-modal\ninformation is considered in KGE models. They are also inefficient due to their\ncomplex design. In this paper, we propose Modality-Aware Negative Sampling\n(MANS) for multi-modal knowledge graph embedding (MMKGE) to address the\nmentioned problems. MANS could align structural and visual embeddings for\nentities in KGs and learn meaningful embeddings to perform better in\nmulti-modal KGE while keeping lightweight and efficient. Empirical results on\ntwo benchmarks demonstrate that MANS outperforms existing NS methods.\nMeanwhile, we make further explorations about MANS to confirm its\neffectiveness.", "published": "2023-04-23 11:22:17", "link": "http://arxiv.org/abs/2304.11618v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in\n  Large Language Models", "abstract": "Large language models (LLMs) can achieve highly effective performance on\nvarious reasoning tasks by incorporating step-by-step chain-of-thought (CoT)\nprompting as demonstrations. However, the reasoning chains of demonstrations\ngenerated by LLMs are prone to errors, which can subsequently lead to incorrect\nreasoning during inference. Furthermore, inappropriate exemplars (overly\nsimplistic or complex), can affect overall performance among varying levels of\ndifficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts\nPrompting), an iterative bootstrapping approach for selecting exemplars and\ngenerating reasoning chains. By utilizing iterative bootstrapping, our approach\nenables LLMs to autonomously rectify errors, resulting in more precise and\ncomprehensive reasoning chains. Simultaneously, our approach selects\nchallenging yet answerable questions accompanied by reasoning chains as\nexemplars with a moderate level of difficulty, which enhances the LLMs'\ngeneralizability across varying levels of difficulty. Experimental results\nindicate that Iter-CoT exhibits superiority, achieving competitive performance\nacross three distinct reasoning tasks on ten datasets.", "published": "2023-04-23 13:54:39", "link": "http://arxiv.org/abs/2304.11657v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering\n  in Islamic Text Resources", "abstract": "Nowadays, one of the main challenges for Question Answering Systems is to\nanswer complex questions using various sources of information. Multi-hop\nquestions are a type of complex questions that require multi-step reasoning to\nanswer. In this article, the IslamicPCQA dataset is introduced. This is the\nfirst Persian dataset for answering complex questions based on non-structured\ninformation sources and consists of 12,282 question-answer pairs extracted from\n9 Islamic encyclopedias. This dataset has been created inspired by the HotpotQA\nEnglish dataset approach, which was customized to suit the complexities of the\nPersian language. Answering questions in this dataset requires more than one\nparagraph and reasoning. The questions are not limited to any prior knowledge\nbase or ontology, and to provide robust reasoning ability, the dataset also\nincludes supporting facts and key sentences. The prepared dataset covers a wide\nrange of Islamic topics and aims to facilitate answering complex Persian\nquestions within this subject matter", "published": "2023-04-23 14:20:58", "link": "http://arxiv.org/abs/2304.11664v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Lightweight Constrained Generation Alternative for Query-focused\n  Summarization", "abstract": "Query-focused summarization (QFS) aims to provide a summary of a document\nthat satisfies information need of a given query and is useful in various IR\napplications, such as abstractive snippet generation. Current QFS approaches\ntypically involve injecting additional information, e.g. query-answer relevance\nor fine-grained token-level interaction between a query and document, into a\nfinetuned large language model. However, these approaches often require extra\nparameters \\& training, and generalize poorly to new dataset distributions. To\nmitigate this, we propose leveraging a recently developed constrained\ngeneration model Neurological Decoding (NLD) as an alternative to current QFS\nregimes which rely on additional sub-architectures and training. We first\nconstruct lexical constraints by identifying important tokens from the document\nusing a lightweight gradient attribution model, then subsequently force the\ngenerated summary to satisfy these constraints by directly manipulating the\nfinal vocabulary likelihood. This lightweight approach requires no additional\nparameters or finetuning as it utilizes both an off-the-shelf neural retrieval\nmodel to construct the constraints and a standard generative language model to\nproduce the QFS. We demonstrate the efficacy of this approach on two public QFS\ncollections achieving near parity with the state-of-the-art model with\nsubstantially reduced complexity.", "published": "2023-04-23 18:43:48", "link": "http://arxiv.org/abs/2304.11721v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Processing Natural Language on Embedded Devices: How Well Do Transformer\n  Models Perform?", "abstract": "This paper presents a performance study of transformer language models under\ndifferent hardware configurations and accuracy requirements and derives\nempirical observations about these resource/accuracy trade-offs. In particular,\nwe study how the most commonly used BERT-based language models (viz., BERT,\nRoBERTa, DistilBERT, and TinyBERT) perform on embedded systems. We tested them\non four off-the-shelf embedded platforms (Raspberry Pi, Jetson, UP2, and UDOO)\nwith 2 GB and 4 GB memory (i.e., a total of eight hardware configurations) and\nfour datasets (i.e., HuRIC, GoEmotion, CoNLL, WNUT17) running various NLP\ntasks. Our study finds that executing complex NLP tasks (such as \"sentiment\"\nclassification) on embedded systems is feasible even without any GPUs (e.g.,\nRaspberry Pi with 2 GB of RAM). Our findings can help designers understand the\ndeployability and performance of transformer language models, especially those\nbased on BERT architectures.", "published": "2023-04-23 03:01:39", "link": "http://arxiv.org/abs/2304.11520v4", "categories": ["cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.CL"}
{"title": "Hold the Suspect! : An Analysis on Media Framing of Itaewon Halloween\n  Crowd Crush", "abstract": "Based on the 10.9K articles from top 40 news providers of South Korea, this\npaper analyzed the media framing of Itaewon Halloween Crowd Crush during the\nfirst 72 hours after the incident. By adopting word-vector embedding and\nclustering, we figured out that conservative media focused on political\nparties' responses and the suspect's identity while the liberal media covered\nthe responsibility of the government and possible unequal spillover effect on\nthe low-income industry workers. Although the social tragedy was not directly\nconnected to institutional politics, the media clearly exhibited political bias\nin the coverage process.", "published": "2023-04-23 14:22:25", "link": "http://arxiv.org/abs/2304.11666v1", "categories": ["cs.CL", "cs.CY", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Studying the Impact of Semi-Cooperative Drivers on Overall Highway Flow", "abstract": "Semi-cooperative behaviors are intrinsic properties of human drivers and\nshould be considered for autonomous driving. In addition, new autonomous\nplanners can consider the social value orientation (SVO) of human drivers to\ngenerate socially-compliant trajectories. Yet the overall impact on traffic\nflow for this new class of planners remain to be understood. In this work, we\npresent study of implicit semi-cooperative driving where agents deploy a\ngame-theoretic version of iterative best response assuming knowledge of the\nSVOs of other agents. We simulate nominal traffic flow and investigate whether\nthe proportion of prosocial agents on the road impact individual or system-wide\ndriving performance. Experiments show that the proportion of prosocial agents\nhas a minor impact on overall traffic flow and that benefits of\nsemi-cooperation disproportionally affect egoistic and high-speed drivers.", "published": "2023-04-23 16:01:36", "link": "http://arxiv.org/abs/2304.11693v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "SAR: Self-Supervised Anti-Distortion Representation for End-To-End\n  Speech Model", "abstract": "In recent Text-to-Speech (TTS) systems, a neural vocoder often generates\nspeech samples by solely conditioning on acoustic features predicted from an\nacoustic model. However, there are always distortions existing in the predicted\nacoustic features, compared to those of the groundtruth, especially in the\ncommon case of poor acoustic modeling due to low-quality training data. To\novercome such limits, we propose a Self-supervised learning framework to learn\nan Anti-distortion acoustic Representation (SAR) to replace human-crafted\nacoustic features by introducing distortion prior to an auto-encoder\npre-training process. The learned acoustic representation from the proposed\nframework is proved anti-distortion compared to the most commonly used\nmel-spectrogram through both objective and subjective evaluation.", "published": "2023-04-23 06:10:27", "link": "http://arxiv.org/abs/2304.11547v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Order-Complexity Model for Aesthetic Quality Assessment of Homophony\n  Music Performance", "abstract": "Although computational aesthetics evaluation has made certain achievements in\nmany fields, its research of music performance remains to be explored. At\npresent, subjective evaluation is still a ultimate method of music aesthetics\nresearch, but it will consume a lot of human and material resources. In\naddition, the music performance generated by AI is still mechanical, monotonous\nand lacking in beauty. In order to guide the generation task of AI music\nperformance, and to improve the performance effect of human performers, this\npaper uses Birkhoff's aesthetic measure to propose a method of objective\nmeasurement of beauty. The main contributions of this paper are as follows:\nFirstly, we put forward an objective aesthetic evaluation method to measure the\nmusic performance aesthetic; Secondly, we propose 10 basic music features and 4\naesthetic music features. Experiments show that our method performs well on\nperformance assessment.", "published": "2023-04-23 03:02:24", "link": "http://arxiv.org/abs/2304.11521v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Controllable Audio Texture Morphing", "abstract": "In this paper, we propose a data-driven approach to train a Generative\nAdversarial Network (GAN) conditioned on \"soft-labels\" distilled from the\npenultimate layer of an audio classifier trained on a target set of audio\ntexture classes. We demonstrate that interpolation between such conditions or\ncontrol vectors provides smooth morphing between the generated audio textures,\nand shows similar or better audio texture morphing capability compared to the\nstate-of-the-art methods. The proposed approach results in a well-organized\nlatent space that generates novel audio outputs while remaining consistent with\nthe semantics of the conditioning parameters. This is a step towards a general\ndata-driven approach to designing generative audio models with customized\ncontrols capable of traversing out-of-distribution regions for novel sound\nsynthesis.", "published": "2023-04-23 13:32:24", "link": "http://arxiv.org/abs/2304.11648v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sound-based drone fault classification using multitask learning", "abstract": "The drone has been used for various purposes, including military\napplications, aerial photography, and pesticide spraying. However, the drone is\nvulnerable to external disturbances, and malfunction in propellers and motors\ncan easily occur. To improve the safety of drone operations, one should detect\nthe mechanical faults of drones in real-time. This paper proposes a sound-based\ndeep neural network (DNN) fault classifier and drone sound dataset. The dataset\nwas constructed by collecting the operating sounds of drones from microphones\nmounted on three different drones in an anechoic chamber. The dataset includes\nvarious operating conditions of drones, such as flight directions (front, back,\nright, left, clockwise, counterclockwise) and faults on propellers and motors.\nThe drone sounds were then mixed with noises recorded in five different spots\non the university campus, with a signal-to-noise ratio (SNR) varying from 10 dB\nto 15 dB. Using the acquired dataset, we train a DNN classifier, 1DCNN-ResNet,\nthat classifies the types of mechanical faults and their locations from\nshort-time input waveforms. We employ multitask learning (MTL) and incorporate\nthe direction classification task as an auxiliary task to make the classifier\nlearn more general audio features. The test over unseen data reveals that the\nproposed multitask model can successfully classify faults in drones and\noutperforms single-task models even with less training data.", "published": "2023-04-23 17:55:40", "link": "http://arxiv.org/abs/2304.11708v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Optimization design of a micro-perforated panel absorber with 8.6 octave\n  bands", "abstract": "In order to improve low-frequency characteristics of micro-perforated panel\nabsorbers, sound absorption structures composed of micro-perforated panels and\nexpansion chambers are design, and an optimization design method is constructed\nbased on the transfer function model and the simulated annealing algorithm.\nFirst, a single-chamber structure composed of a micro-perforated panel and an\nexpansion chamber is build, and the sound absorption curve is simulated by the\nfinite element method. Second, for the sake of enlarging the continuous\nabsorption bandwidth with absorption coefficients not less than 0.8, a\nthree-chamber structure is designed, which has a sound absorption bandwidth of\n1277Hz (27-1304Hz) covering 5.6 octave bands. Then, the transfer function model\nof the structure is established, and a series of theoretical formulae are\nderived to calculate the absorption coefficients. Subsequently, the sound\nabsorption bandwidths calculated by the theoretical formulae and the finite\nelement method are compared, and the relative error is 3.68%. Finally, an\noptimization design method is constructed by combining the transfer function\nmodel and the simulated annealing algorithm, where the optimization objective\nis to maximize the absorption bandwidth and the optimization variables are\nstructural parameters of the three-chamber structure. The results show, after\noptimization, the three-chamber structure exhibits an excellent sound\nabsorption performance, with a continuous bandwidth of 1591Hz (4-1595Hz),\nrealizing 8.6 octave bands.", "published": "2023-04-23 15:21:03", "link": "http://arxiv.org/abs/2305.18298v1", "categories": ["eess.AS", "eess.SP", "physics.app-ph", "physics.class-ph"], "primary_category": "eess.AS"}
{"title": "DiffVoice: Text-to-Speech with Latent Diffusion", "abstract": "In this work, we present DiffVoice, a novel text-to-speech model based on\nlatent diffusion. We propose to first encode speech signals into a phoneme-rate\nlatent representation with a variational autoencoder enhanced by adversarial\ntraining, and then jointly model the duration and the latent representation\nwith a diffusion model. Subjective evaluations on LJSpeech and LibriTTS\ndatasets demonstrate that our method beats the best publicly available systems\nin naturalness. By adopting recent generative inverse problem solving\nalgorithms for diffusion models, DiffVoice achieves the state-of-the-art\nperformance in text-based speech editing, and zero-shot adaptation.", "published": "2023-04-23 21:05:33", "link": "http://arxiv.org/abs/2304.11750v1", "categories": ["eess.AS", "cs.AI", "cs.HC", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
