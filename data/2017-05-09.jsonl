{"title": "Does William Shakespeare REALLY Write Hamlet? Knowledge Representation\n  Learning with Confidence", "abstract": "Knowledge graphs (KGs), which could provide essential relational information\nbetween entities, have been widely utilized in various knowledge-driven\napplications. Since the overall human knowledge is innumerable that still grows\nexplosively and changes frequently, knowledge construction and update\ninevitably involve automatic mechanisms with less human supervision, which\nusually bring in plenty of noises and conflicts to KGs. However, most\nconventional knowledge representation learning methods assume that all triple\nfacts in existing KGs share the same significance without any noises. To\naddress this problem, we propose a novel confidence-aware knowledge\nrepresentation learning framework (CKRL), which detects possible noises in KGs\nwhile learning knowledge representations with confidence simultaneously.\nSpecifically, we introduce the triple confidence to conventional\ntranslation-based methods for knowledge representation learning. To make triple\nconfidence more flexible and universal, we only utilize the internal structural\ninformation in KGs, and propose three kinds of triple confidences considering\nboth local and global structural information. In experiments, We evaluate our\nmodels on knowledge graph noise detection, knowledge graph completion and\ntriple classification. Experimental results demonstrate that our\nconfidence-aware models achieve significant and consistent improvements on all\ntasks, which confirms the capability of CKRL modeling confidence with\nstructural information in both KG noise detection and knowledge representation\nlearning.", "published": "2017-05-09 06:46:21", "link": "http://arxiv.org/abs/1705.03202v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Review of Hindi Prosody", "abstract": "Prosody describes both form and function of a sentence using the\nsuprasegmental features of speech. Prosody phenomena are explored in the domain\nof higher phonological constituents such as word, phonological phrase and\nintonational phrase. The study of prosody at the word level is called word\nprosody and above word level is called sentence prosody. Word Prosody describes\nstress pattern by comparing the prosodic features of its constituent syllables.\nSentence Prosody involves the study on phrasing pattern and intonatonal pattern\nof a language. The aim of this study is to summarize the existing works on\nHindi prosody carried out in different domain of language and speech\nprocessing. The review is presented in a systematic fashion so that it could be\na useful resource for one who wants to build on the existing works.", "published": "2017-05-09 09:35:22", "link": "http://arxiv.org/abs/1705.03247v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Drug-drug Interaction Extraction via Recurrent Neural Network with\n  Multiple Attention Layers", "abstract": "Drug-drug interaction (DDI) is a vital information when physicians and\npharmacists intend to co-administer two or more drugs. Thus, several DDI\ndatabases are constructed to avoid mistakenly combined use. In recent years,\nautomatically extracting DDIs from biomedical text has drawn researchers'\nattention. However, the existing work utilize either complex feature\nengineering or NLP tools, both of which are insufficient for sentence\ncomprehension. Inspired by the deep learning approaches in natural language\nprocessing, we propose a recur- rent neural network model with multiple\nattention layers for DDI classification. We evaluate our model on 2013 SemEval\nDDIExtraction dataset. The experiments show that our model classifies most of\nthe drug pairs into correct DDI categories, which outperforms the existing NLP\nor deep learning methods.", "published": "2017-05-09 10:22:48", "link": "http://arxiv.org/abs/1705.03261v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logical Parsing from Natural Language Based on a Neural Translation\n  Model", "abstract": "Semantic parsing has emerged as a significant and powerful paradigm for\nnatural language interface and question answering systems. Traditional methods\nof building a semantic parser rely on high-quality lexicons, hand-crafted\ngrammars and linguistic features which are limited by applied domain or\nrepresentation. In this paper, we propose a general approach to learn from\ndenotations based on Seq2Seq model augmented with attention mechanism. We\nencode input sequence into vectors and use dynamic programming to infer\ncandidate logical forms. We utilize the fact that similar utterances should\nhave similar logical forms to help reduce the searching space. Under our\nlearning policy, the Seq2Seq model can learn mappings gradually with noises.\nCurriculum learning is adopted to make the learning smoother. We test our\nmethod on the arithmetic domain which shows our model can successfully infer\nthe correct logical forms and learn the word meanings, compositionality and\noperation orders simultaneously.", "published": "2017-05-09 15:35:25", "link": "http://arxiv.org/abs/1705.03389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for\n  Reading Comprehension", "abstract": "We present TriviaQA, a challenging reading comprehension dataset containing\nover 650K question-answer-evidence triples. TriviaQA includes 95K\nquestion-answer pairs authored by trivia enthusiasts and independently gathered\nevidence documents, six per question on average, that provide high quality\ndistant supervision for answering the questions. We show that, in comparison to\nother recently introduced large-scale datasets, TriviaQA (1) has relatively\ncomplex, compositional questions, (2) has considerable syntactic and lexical\nvariability between questions and corresponding answer-evidence sentences, and\n(3) requires more cross sentence reasoning to find answers. We also present two\nbaseline algorithms: a feature-based classifier and a state-of-the-art neural\nnetwork, that performs well on SQuAD reading comprehension. Neither approach\ncomes close to human performance (23% and 40% vs. 80%), suggesting that\nTriviaQA is a challenging testbed that is worth significant future study. Data\nand code available at -- http://nlp.cs.washington.edu/triviaqa/", "published": "2017-05-09 21:35:07", "link": "http://arxiv.org/abs/1705.03551v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word and Phrase Translation with word2vec", "abstract": "Word and phrase tables are key inputs to machine translations, but costly to\nproduce. New unsupervised learning methods represent words and phrases in a\nhigh-dimensional vector space, and these monolingual embeddings have been shown\nto encode syntactic and semantic relationships between language elements. The\ninformation captured by these embeddings can be exploited for bilingual\ntranslation by learning a transformation matrix that allows matching relative\npositions across two monolingual vector spaces. This method aims to identify\nhigh-quality candidates for word and phrase translation more cost-effectively\nfrom unlabeled data.\n  This paper expands the scope of previous attempts of bilingual translation to\nfour languages (English, German, Spanish, and French). It shows how to process\nthe source data, train a neural network to learn the high-dimensional\nembeddings for individual languages and expands the framework for testing their\nquality beyond the English language. Furthermore, it shows how to learn\nbilingual transformation matrices and obtain candidates for word and phrase\ntranslation, and assess their quality.", "published": "2017-05-09 00:09:38", "link": "http://arxiv.org/abs/1705.03127v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeepTingle", "abstract": "DeepTingle is a text prediction and classification system trained on the\ncollected works of the renowned fantastic gay erotica author Chuck Tingle.\nWhereas the writing assistance tools you use everyday (in the form of\npredictive text, translation, grammar checking and so on) are trained on\ngeneric, purportedly \"neutral\" datasets, DeepTingle is trained on a very\nspecific, internally consistent but externally arguably eccentric dataset. This\nallows us to foreground and confront the norms embedded in data-driven\ncreativity and productivity assistance tools. As such tools effectively\nfunction as extensions of our cognition into technology, it is important to\nidentify the norms they embed within themselves and, by extension, us.\nDeepTingle is realized as a web application based on LSTM networks and the\nGloVe word embedding, implemented in JavaScript with Keras-JS.", "published": "2017-05-09 22:12:19", "link": "http://arxiv.org/abs/1705.03557v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Phonetic Temporal Neural Model for Language Identification", "abstract": "Deep neural models, particularly the LSTM-RNN model, have shown great\npotential for language identification (LID). However, the use of phonetic\ninformation has been largely overlooked by most existing neural LID methods,\nalthough this information has been used very successfully in conventional\nphonetic LID systems. We present a phonetic temporal neural model for LID,\nwhich is an LSTM-RNN LID system that accepts phonetic features produced by a\nphone-discriminative DNN as the input, rather than raw acoustic features. This\nnew model is similar to traditional phonetic LID methods, but the phonetic\nknowledge here is much richer: it is at the frame level and involves compacted\ninformation of all phones. Our experiments conducted on the Babel database and\nthe AP16-OLR database demonstrate that the temporal phonetic neural approach is\nvery effective, and significantly outperforms existing acoustic neural models.\nIt also outperforms the conventional i-vector approach on short utterances and\nin noisy conditions.", "published": "2017-05-09 02:46:21", "link": "http://arxiv.org/abs/1705.03151v3", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Phone-aware Neural Language Identification", "abstract": "Pure acoustic neural models, particularly the LSTM-RNN model, have shown\ngreat potential in language identification (LID). However, the phonetic\ninformation has been largely overlooked by most of existing neural LID models,\nalthough this information has been used in the conventional phonetic LID\nsystems with a great success. We present a phone-aware neural LID architecture,\nwhich is a deep LSTM-RNN LID system but accepts output from an RNN-based ASR\nsystem. By utilizing the phonetic knowledge, the LID performance can be\nsignificantly improved. Interestingly, even if the test language is not\ninvolved in the ASR training, the phonetic knowledge still presents a large\ncontribution. Our experiments conducted on four languages within the Babel\ncorpus demonstrated that the phone-aware approach is highly effective.", "published": "2017-05-09 02:47:22", "link": "http://arxiv.org/abs/1705.03152v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Relevance-based Word Embedding", "abstract": "Learning a high-dimensional dense representation for vocabulary terms, also\nknown as a word embedding, has recently attracted much attention in natural\nlanguage processing and information retrieval tasks. The embedding vectors are\ntypically learned based on term proximity in a large corpus. This means that\nthe objective in well-known word embedding algorithms, e.g., word2vec, is to\naccurately predict adjacent word(s) for a given word or context. However, this\nobjective is not necessarily equivalent to the goal of many information\nretrieval (IR) tasks. The primary objective in various IR tasks is to capture\nrelevance instead of term proximity, syntactic, or even semantic similarity.\nThis is the motivation for developing unsupervised relevance-based word\nembedding models that learn word representations based on query-document\nrelevance information. In this paper, we propose two learning models with\ndifferent objective functions; one learns a relevance distribution over the\nvocabulary set for each query, and the other classifies each term as belonging\nto the relevant or non-relevant class for each query. To train our models, we\nused over six million unique queries and the top ranked documents retrieved in\nresponse to each query, which are assumed to be relevant to the query. We\nextrinsically evaluate our learned word representation models using two IR\ntasks: query expansion and query classification. Both query expansion\nexperiments on four TREC collections and query classification experiments on\nthe KDD Cup 2005 dataset suggest that the relevance-based word embedding models\nsignificantly outperform state-of-the-art proximity-based embedding models,\nsuch as word2vec and GloVe.", "published": "2017-05-09 22:09:01", "link": "http://arxiv.org/abs/1705.03556v2", "categories": ["cs.IR", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.IR"}
