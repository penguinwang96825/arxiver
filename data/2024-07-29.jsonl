{"title": "From Pre-training Corpora to Large Language Models: What Factors\n  Influence LLM Performance in Causal Discovery Tasks?", "abstract": "Recent advances in artificial intelligence have seen Large Language Models\n(LLMs) demonstrate notable proficiency in causal discovery tasks. This study\nexplores the factors influencing the performance of LLMs in causal discovery\ntasks. Utilizing open-source LLMs, we examine how the frequency of causal\nrelations within their pre-training corpora affects their ability to accurately\nrespond to causal discovery queries. Our findings reveal that a higher\nfrequency of causal mentions correlates with better model performance,\nsuggesting that extensive exposure to causal information during training\nenhances the models' causal discovery capabilities. Additionally, we\ninvestigate the impact of context on the validity of causal relations. Our\nresults indicate that LLMs might exhibit divergent predictions for identical\ncausal relations when presented in different contexts. This paper provides the\nfirst comprehensive analysis of how different factors contribute to LLM\nperformance in causal discovery tasks.", "published": "2024-07-29 01:45:05", "link": "http://arxiv.org/abs/2407.19638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of PerpectiveArg2024: The First Shared Task on Perspective\n  Argument Retrieval", "abstract": "Argument retrieval is the task of finding relevant arguments for a given\nquery. While existing approaches rely solely on the semantic alignment of\nqueries and arguments, this first shared task on perspective argument retrieval\nincorporates perspectives during retrieval, accounting for latent influences in\nargumentation. We present a novel multilingual dataset covering demographic and\nsocio-cultural (socio) variables, such as age, gender, and political attitude,\nrepresenting minority and majority groups in society. We distinguish between\nthree scenarios to explore how retrieval systems consider explicitly (in both\nquery and corpus) and implicitly (only in query) formulated perspectives. This\npaper provides an overview of this shared task and summarizes the results of\nthe six submitted systems. We find substantial challenges in incorporating\nperspectivism, especially when aiming for personalization based solely on the\ntext of arguments without explicitly providing socio profiles. Moreover,\nretrieval systems tend to be biased towards the majority group but partially\nmitigate bias for the female gender. While we bootstrap perspective argument\nretrieval, further research is essential to optimize retrieval systems to\nfacilitate personalization and reduce polarization.", "published": "2024-07-29 03:14:57", "link": "http://arxiv.org/abs/2407.19670v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models\n  for Southeast Asian Languages", "abstract": "Large Language Models (LLMs) have shown remarkable abilities across various\ntasks, yet their development has predominantly centered on high-resource\nlanguages like English and Chinese, leaving low-resource languages underserved.\nTo address this disparity, we present SeaLLMs 3, the latest iteration of the\nSeaLLMs model family, tailored for Southeast Asian languages. This region,\ncharacterized by its rich linguistic diversity, has lacked adequate language\ntechnology support. SeaLLMs 3 aims to bridge this gap by covering a\ncomprehensive range of languages spoken in this region, including English,\nChinese, Indonesian, Vietnamese, Thai, Tagalog, Malay, Burmese, Khmer, Lao,\nTamil, and Javanese. Leveraging efficient language enhancement techniques and a\nspecially constructed instruction tuning dataset, SeaLLMs 3 significantly\nreduces training costs while maintaining high performance and versatility. Our\nmodel excels in tasks such as world knowledge, mathematical reasoning,\ntranslation, and instruction following, achieving state-of-the-art performance\namong similarly sized models. Additionally, we prioritized safety and\nreliability by addressing both general and culture-specific considerations and\nincorporated mechanisms to reduce hallucinations. This work underscores the\nimportance of inclusive AI, showing that advanced LLM capabilities can benefit\nunderserved linguistic and cultural communities.", "published": "2024-07-29 03:26:22", "link": "http://arxiv.org/abs/2407.19672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesizing Scientific Summaries: An Extractive and Abstractive\n  Approach", "abstract": "The availability of a vast array of research papers in any area of study,\nnecessitates the need of automated summarisation systems that can present the\nkey research conducted and their corresponding findings. Scientific paper\nsummarisation is a challenging task for various reasons including token length\nlimits in modern transformer models and corresponding memory and compute\nrequirements for long text. A significant amount of work has been conducted in\nthis area, with approaches that modify the attention mechanisms of existing\ntransformer models and others that utilise discourse information to capture\nlong range dependencies in research papers. In this paper, we propose a hybrid\nmethodology for research paper summarisation which incorporates an extractive\nand abstractive approach. We use the extractive approach to capture the key\nfindings of research, and pair it with the introduction of the paper which\ncaptures the motivation for research. We use two models based on unsupervised\nlearning for the extraction stage and two transformer language models,\nresulting in four combinations for our hybrid approach. The performances of the\nmodels are evaluated on three metrics and we present our findings in this\npaper. We find that using certain combinations of hyper parameters, it is\npossible for automated summarisation systems to exceed the abstractiveness of\nsummaries written by humans. Finally, we state our future scope of research in\nextending this methodology to summarisation of generalised long documents.", "published": "2024-07-29 08:21:42", "link": "http://arxiv.org/abs/2407.19779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching LLMs at Charles University: Assignments and Activities", "abstract": "This paper presents teaching materials, particularly assignments and ideas\nfor classroom activities, from a new course on large language models (LLMs)\ntaught at Charles University. The assignments include experiments with LLM\ninference for weather report generation and machine translation. The classroom\nactivities include class quizzes, focused research on downstream tasks and\ndatasets, and an interactive \"best paper\" session aimed at reading and\ncomprehension of research papers.", "published": "2024-07-29 08:43:48", "link": "http://arxiv.org/abs/2407.19798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cool-Fusion: Fuse Large Language Models without Training", "abstract": "We focus on the problem of fusing two or more heterogeneous large language\nmodels (LLMs) to facilitate their complementary strengths. One of the\nchallenges on model fusion is high computational load, i.e. to fine-tune or to\nalign vocabularies via combinatorial optimization. To this end, we propose\n\\emph{Cool-Fusion}, a simple yet effective approach that fuses the knowledge of\nheterogeneous source LLMs to leverage their complementary strengths.\n\\emph{Cool-Fusion} is the first method that does not require any type of\ntraining like the ensemble approaches. But unlike ensemble methods, it is\napplicable to any set of source LLMs that have different vocabularies. The\nbasic idea is to have each source LLM individually generate tokens until the\ntokens can be decoded into a text segment that ends at word boundaries common\nto all source LLMs. Then, the source LLMs jointly rerank the generated text\nsegment and select the best one, which is the fused text generation in one\nstep. Extensive experiments are conducted across a variety of benchmark\ndatasets. On \\emph{GSM8K}, \\emph{Cool-Fusion} increases accuracy from three\nstrong source LLMs by a significant 8\\%-17.8\\%.", "published": "2024-07-29 09:02:19", "link": "http://arxiv.org/abs/2407.19807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Segmentation en phrases : ouvrez les guillemets sans perdre le fil", "abstract": "This paper presents a graph cascade for sentence segmentation of XML\ndocuments. Our proposal offers sentences inside sentences for cases introduced\nby quotation marks and hyphens, and also pays particular attention to\nsituations involving incises introduced by parentheses and lists introduced by\ncolons. We present how the tool works and compare the results obtained with\nthose available in 2019 on the same dataset, together with an evaluation of the\nsystem's performance on a test corpus", "published": "2024-07-29 09:02:38", "link": "http://arxiv.org/abs/2407.19808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Encoder-Based NER and Large Language Models for\n  Skill Extraction from Russian Job Vacancies", "abstract": "The labor market is undergoing rapid changes, with increasing demands on job\nseekers and a surge in job openings. Identifying essential skills and\ncompetencies from job descriptions is challenging due to varying employer\nrequirements and the omission of key skills. This study addresses these\nchallenges by comparing traditional Named Entity Recognition (NER) methods\nbased on encoders with Large Language Models (LLMs) for extracting skills from\nRussian job vacancies. Using a labeled dataset of 4,000 job vacancies for\ntraining and 1,472 for testing, the performance of both approaches is\nevaluated. Results indicate that traditional NER models, especially DeepPavlov\nRuBERT NER tuned, outperform LLMs across various metrics including accuracy,\nprecision, recall, and inference time. The findings suggest that traditional\nNER models provide more effective and efficient solutions for skill extraction,\nenhancing job requirement clarity and aiding job seekers in aligning their\nqualifications with employer expectations. This research contributes to the\nfield of natural language processing (NLP) and its application in the labor\nmarket, particularly in non-English contexts.", "published": "2024-07-29 09:08:40", "link": "http://arxiv.org/abs/2407.19816v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Preliminary WMT24 Ranking of General MT Systems and LLMs", "abstract": "This is the preliminary ranking of WMT24 General MT systems based on\nautomatic metrics. The official ranking will be a human evaluation, which is\nsuperior to the automatic ranking and supersedes it. The purpose of this report\nis not to interpret any findings but only provide preliminary results to the\nparticipants of the General MT task that may be useful during the writing of\nthe system submission.", "published": "2024-07-29 11:01:17", "link": "http://arxiv.org/abs/2407.19884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Temporal Psycholinguistics Approach to Identity Resolution of Social\n  Media Users", "abstract": "In this thesis, we propose an approach to identity resolution across social\nmedia platforms using the topics, sentiments, and timings of the posts on the\nplatforms. After collecting the public posts of around 5000 profiles from\nDisqus and Twitter, we analyze their posts to match their profiles across the\ntwo platforms. We pursue both temporal and non-temporal methods in our\nanalysis. While neither approach proves definitively superior, the temporal\napproach generally performs better. We found that the temporal window size\ninfluences results more than the shifting amount. On the other hand, our\nsentiment analysis shows that the inclusion of sentiment makes little\ndifference, probably due to flawed data extraction methods. We also\nexperimented with a distance-based reward-and-punishment-focused scoring model,\nwhich achieved an accuracy of 24.198% and an average rank of 158.217 out of\n2525 in our collected corpus. Future work includes refining sentiment analysis\nby evaluating sentiments per topic, extending temporal analysis with additional\nphases, and improving the scoring model through weight adjustments and modified\nrewards.", "published": "2024-07-29 13:00:36", "link": "http://arxiv.org/abs/2407.19967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confidence Estimation for Automatic Detection of Depression and\n  Alzheimer's Disease Based on Clinical Interviews", "abstract": "Speech-based automatic detection of Alzheimer's disease (AD) and depression\nhas attracted increased attention. Confidence estimation is crucial for a\ntrust-worthy automatic diagnostic system which informs the clinician about the\nconfidence of model predictions and helps reduce the risk of misdiagnosis. This\npaper investigates confidence estimation for automatic detection of AD and\ndepression based on clinical interviews. A novel Bayesian approach is proposed\nwhich uses a dynamic Dirichlet prior distribution to model the second-order\nprobability of the predictive distribution. Experimental results on the\npublicly available ADReSS and DAIC-WOZ datasets demonstrate that the proposed\nmethod outperforms a range of baselines for both classification accuracy and\nconfidence estimation.", "published": "2024-07-29 13:18:23", "link": "http://arxiv.org/abs/2407.19984v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Impact of Semi-Supervised Methods with Data\n  Augmentation on Offensive Language Detection in Romanian Language", "abstract": "Offensive language detection is a crucial task in today's digital landscape,\nwhere online platforms grapple with maintaining a respectful and inclusive\nenvironment. However, building robust offensive language detection models\nrequires large amounts of labeled data, which can be expensive and\ntime-consuming to obtain. Semi-supervised learning offers a feasible solution\nby utilizing labeled and unlabeled data to create more accurate and robust\nmodels. In this paper, we explore a few different semi-supervised methods, as\nwell as data augmentation techniques. Concretely, we implemented eight\nsemi-supervised methods and ran experiments for them using only the available\ndata in the RO-Offense dataset and applying five augmentation techniques before\nfeeding the data to the models. Experimental results demonstrate that some of\nthem benefit more from augmentations than others.", "published": "2024-07-29 15:02:51", "link": "http://arxiv.org/abs/2407.20076v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Energy-based Model for Word-level AutoCompletion in Computer-aided\n  Translation", "abstract": "Word-level AutoCompletion(WLAC) is a rewarding yet challenging task in\nComputer-aided Translation. Existing work addresses this task through a\nclassification model based on a neural network that maps the hidden vector of\nthe input context into its corresponding label (i.e., the candidate target word\nis treated as a label). Since the context hidden vector itself does not take\nthe label into account and it is projected to the label through a linear\nclassifier, the model can not sufficiently leverage valuable information from\nthe source sentence as verified in our experiments, which eventually hinders\nits overall performance. To alleviate this issue, this work proposes an\nenergy-based model for WLAC, which enables the context hidden vector to capture\ncrucial information from the source sentence. Unfortunately, training and\ninference suffer from efficiency and effectiveness challenges, thereby we\nemploy three simple yet effective strategies to put our model into practice.\nExperiments on four standard benchmarks demonstrate that our reranking-based\napproach achieves substantial improvements (about 6.07%) over the previous\nstate-of-the-art model. Further analyses show that each strategy of our\napproach contributes to the final performance.", "published": "2024-07-29 15:07:19", "link": "http://arxiv.org/abs/2407.20083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Editing LLMs Inject Harm?", "abstract": "Knowledge editing has been increasingly adopted to correct the false or\noutdated knowledge in Large Language Models (LLMs). Meanwhile, one critical but\nunder-explored question is: can knowledge editing be used to inject harm into\nLLMs? In this paper, we propose to reformulate knowledge editing as a new type\nof safety threat for LLMs, namely Editing Attack, and conduct a systematic\ninvestigation with a newly constructed dataset EditAttack. Specifically, we\nfocus on two typical safety risks of Editing Attack including Misinformation\nInjection and Bias Injection. For the risk of misinformation injection, we\nfirst categorize it into commonsense misinformation injection and long-tail\nmisinformation injection. Then, we find that editing attacks can inject both\ntypes of misinformation into LLMs, and the effectiveness is particularly high\nfor commonsense misinformation injection. For the risk of bias injection, we\ndiscover that not only can biased sentences be injected into LLMs with high\neffectiveness, but also one single biased sentence injection can cause a bias\nincrease in general outputs of LLMs, which are even highly irrelevant to the\ninjected sentence, indicating a catastrophic impact on the overall fairness of\nLLMs. Then, we further illustrate the high stealthiness of editing attacks,\nmeasured by their impact on the general knowledge and reasoning capacities of\nLLMs, and show the hardness of defending editing attacks with empirical\nevidence. Our discoveries demonstrate the emerging misuse risks of knowledge\nediting techniques on compromising the safety alignment of LLMs and the\nfeasibility of disseminating misinformation or bias with LLMs as new channels.", "published": "2024-07-29 17:58:06", "link": "http://arxiv.org/abs/2407.20224v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What if Red Can Talk? Dynamic Dialogue Generation Using Large Language\n  Models", "abstract": "Role-playing games (RPGs) provide players with a rich, interactive world to\nexplore. Dialogue serves as the primary means of communication between\ndevelopers and players, manifesting in various forms such as guides, NPC\ninteractions, and storytelling. While most games rely on written scripts to\ndefine the main story and character personalities, player immersion can be\nsignificantly enhanced through casual interactions between characters. With the\nadvent of large language models (LLMs), we introduce a dialogue filler\nframework that utilizes LLMs enhanced by knowledge graphs to generate dynamic\nand contextually appropriate character interactions. We test this framework\nwithin the environments of Final Fantasy VII Remake and Pokemon, providing\nqualitative and quantitative evidence that demonstrates GPT-4's capability to\nact with defined personalities and generate dialogue. However, some flaws\nremain, such as GPT-4 being overly positive or more subtle personalities, such\nas maturity, tend to be of lower quality compared to more overt traits like\ntimidity. This study aims to assist developers in crafting more nuanced filler\ndialogues, thereby enriching player immersion and enhancing the overall RPG\nexperience.", "published": "2024-07-29 19:12:18", "link": "http://arxiv.org/abs/2407.20382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Through the Looking Glass, and what Horn Clause Programs Found There", "abstract": "Dual Horn clauses mirror key properties of Horn clauses. This paper explores\nthe ``other side of the looking glass'' to reveal some expected and unexpected\nsymmetries and their practical uses.\n  We revisit Dual Horn clauses as enablers of a form of constructive negation\nthat supports goal-driven forward reasoning and is valid both\nintuitionistically and classically. In particular, we explore the ability to\nfalsify a counterfactual hypothesis in the context of a background theory\nexpressed as a Dual Horn clause program.\n  With Dual Horn clause programs, by contrast to negation as failure, the\nvariable bindings in their computed answers provide explanations for the\nreasons why a statement is successfully falsified. Moreover, in the\npropositional case, by contrast to negation as failure as implemented with\nstable models semantics in ASP systems, and similarly to Horn clause programs,\nDual Horn clause programs have polynomial complexity.\n  After specifying their execution model with a metainterpreter, we devise a\ncompilation scheme from Dual Horn clause programs to Horn clause programs,\nensuring their execution with no performance penalty and we design the embedded\nSymLP language to support combined Horn clause and Dual Horn clause programs.\n  As a (motivating) application, we cast LLM reasoning chains into\npropositional Horn and Dual Horn clauses that work together to constructively\nprove and disprove goals and enhance Generative AI with explainability of\nreasoning chains.", "published": "2024-07-29 20:52:26", "link": "http://arxiv.org/abs/2407.20413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "APE: Active Learning-based Tooling for Finding Informative Few-shot\n  Examples for LLM-based Entity Matching", "abstract": "Prompt engineering is an iterative procedure often requiring extensive manual\neffort to formulate suitable instructions for effectively directing large\nlanguage models (LLMs) in specific tasks. Incorporating few-shot examples is a\nvital and effective approach to providing LLMs with precise instructions,\nleading to improved LLM performance. Nonetheless, identifying the most\ninformative demonstrations for LLMs is labor-intensive, frequently entailing\nsifting through an extensive search space. In this demonstration, we showcase a\nhuman-in-the-loop tool called APE (Active Prompt Engineering) designed for\nrefining prompts through active learning. Drawing inspiration from active\nlearning, APE iteratively selects the most ambiguous examples for human\nfeedback, which will be transformed into few-shot examples within the prompt.\nThe demo recording can be found with the submission or be viewed at\nhttps://youtu.be/OwQ6MQx53-Y.", "published": "2024-07-29 22:22:50", "link": "http://arxiv.org/abs/2408.04637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoginMEA: Local-to-Global Interaction Network for Multi-modal Entity\n  Alignment", "abstract": "Multi-modal entity alignment (MMEA) aims to identify equivalent entities\nbetween two multi-modal knowledge graphs (MMKGs), whose entities can be\nassociated with relational triples and related images. Most previous studies\ntreat the graph structure as a special modality, and fuse different modality\ninformation with separate uni-modal encoders, neglecting valuable relational\nassociations in modalities. Other studies refine each uni-modal information\nwith graph structures, but may introduce unnecessary relations in specific\nmodalities. To this end, we propose a novel local-to-global interaction network\nfor MMEA, termed as LoginMEA. Particularly, we first fuse local multi-modal\ninteractions to generate holistic entity semantics and then refine them with\nglobal relational interactions of entity neighbors. In this design, the\nuni-modal information is fused adaptively, and can be refined with relations\naccordingly. To enrich local interactions of multi-modal entity information, we\ndevice modality weights and low-rank interactive fusion, allowing diverse\nimpacts and element-level interactions among modalities. To capture global\ninteractions of graph structures, we adopt relation reflection graph attention\nnetworks, which fully capture relational associations between entities.\nExtensive experiments demonstrate superior results of our method over 5\ncross-KG or bilingual benchmark datasets, indicating the effectiveness of\ncapturing local and global interactions.", "published": "2024-07-29 01:06:45", "link": "http://arxiv.org/abs/2407.19625v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "mGTE: Generalized Long-Context Text Representation and Reranking Models\n  for Multilingual Text Retrieval", "abstract": "We present systematic efforts in building long-context multilingual text\nrepresentation model (TRM) and reranker from scratch for text retrieval. We\nfirst introduce a text encoder (base size) enhanced with RoPE and unpadding,\npre-trained in a native 8192-token context (longer than 512 of previous\nmultilingual encoders). Then we construct a hybrid TRM and a cross-encoder\nreranker by contrastive learning. Evaluations show that our text encoder\noutperforms the same-sized previous state-of-the-art XLM-R. Meanwhile, our TRM\nand reranker match the performance of large-sized state-of-the-art BGE-M3\nmodels and achieve better results on long-context retrieval benchmarks. Further\nanalysis demonstrate that our proposed models exhibit higher efficiency during\nboth training and inference. We believe their efficiency and effectiveness\ncould benefit various researches and industrial applications.", "published": "2024-07-29 03:12:28", "link": "http://arxiv.org/abs/2407.19669v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Efficiently and Effectively: A Two-stage Approach to Balance Plaintext\n  and Encrypted Text for Traffic Classification", "abstract": "Encrypted traffic classification is the task of identifying the application\nor service associated with encrypted network traffic. One effective approach\nfor this task is to use deep learning methods to encode the raw traffic bytes\ndirectly and automatically extract features for classification (byte-based\nmodels). However, current byte-based models input raw traffic bytes, whether\nplaintext or encrypted text, for automated feature extraction, neglecting the\ndistinct impacts of plaintext and encrypted text on downstream tasks.\nAdditionally, these models primarily focus on improving classification\naccuracy, with little emphasis on the efficiency of models. In this paper, for\nthe first time, we analyze the impact of plaintext and encrypted text on the\nmodel's effectiveness and efficiency. Based on our observations and findings,\nwe propose a two-phase approach to balance the trade-off between plaintext and\nencrypted text in traffic classification. Specifically, Stage one is to\nDetermine whether the Plain text is enough to be accurately Classified (DPC)\nusing the proposed DPC Selector. This stage quickly identifies samples that can\nbe classified using plaintext, leveraging explicit byte features in plaintext\nto enhance model's efficiency. Stage two aims to adaptively make a\nclassification with the result from stage one. This stage incorporates\nencrypted text information for samples that cannot be classified using\nplaintext alone, ensuring the model's effectiveness on traffic classification\ntasks. Experiments on two datasets demonstrate that our proposed model achieves\nstate-of-the-art results in both effectiveness and efficiency.", "published": "2024-07-29 04:10:13", "link": "http://arxiv.org/abs/2407.19687v3", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "CollectiveSFT: Scaling Large Language Models for Chinese Medical\n  Benchmark with Collective Instructions in Healthcare", "abstract": "The rapid progress in Large Language Models (LLMs) has prompted the creation\nof numerous benchmarks to evaluate their capabilities.This study focuses on the\nComprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset\ndiversity and distribution in supervised fine-tuning (SFT) may enhance LLM\nperformance.Remarkably, We successfully trained a smaller base model to achieve\nscores comparable to larger models, indicating that a diverse and\nwell-distributed dataset can optimize performance regardless of model size.This\nstudy suggests that even smaller models may reach high performance levels with\ncarefully curated and varied datasets. By integrating a wide range of\ninstructional content, our approach addresses potential issues such as data\nquality inconsistencies. Our results imply that a broader spectrum of training\ndata may enhance a model's ability to generalize and perform effectively across\ndifferent medical scenarios, highlighting the importance of dataset quality and\ndiversity in fine-tuning processes. We open-source the model for future\nresearch at https://github.com/CAS-SIAT-XinHai/CollectiveSFT", "published": "2024-07-29 05:00:48", "link": "http://arxiv.org/abs/2407.19705v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Text-to-Vis Benchmarks Test Real Use of Visualisations?", "abstract": "Large language models are able to generate code for visualisations in\nresponse to simple user requests. This is a useful application and an appealing\none for NLP research because plots of data provide grounding for language.\nHowever, there are relatively few benchmarks, and those that exist may not be\nrepresentative of what users do in practice. This paper investigates whether\nbenchmarks reflect real-world use through an empirical study comparing\nbenchmark datasets with code from public repositories. Our findings reveal a\nsubstantial gap, with evaluations not testing the same distribution of chart\ntypes, attributes, and actions as real-world examples. One dataset is\nrepresentative, but requires extensive modification to become a practical\nend-to-end benchmark. This shows that new benchmarks are needed to support the\ndevelopment of systems that truly address users' visualisation needs. These\nobservations will guide future data creation, highlighting which features hold\ngenuine significance for users.", "published": "2024-07-29 06:13:28", "link": "http://arxiv.org/abs/2407.19726v4", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting\n  Relations in Dialogical Argument Mining", "abstract": "Dialogical Argument Mining(DialAM) is an important branch of Argument\nMining(AM). DialAM-2024 is a shared task focusing on dialogical argument\nmining, which requires us to identify argumentative relations and illocutionary\nrelations among proposition nodes and locution nodes. To accomplish this, we\npropose a two-stage pipeline, which includes the Two-Step S-Node Prediction\nModel in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment\nthe training data in both stages and introduce context in Stage 2. We\nsuccessfully completed the task and achieved good results. Our team Pokemon\nranked 1st in the ARI Focused score and 4th in the Global Focused score.", "published": "2024-07-29 07:07:37", "link": "http://arxiv.org/abs/2407.19740v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional\n  Principles in Complex Scenarios", "abstract": "In this paper, we conduct an empirical analysis of how large language models\n(LLMs), specifically GPT-4, interpret constitutional principles in complex\ndecision-making scenarios. We examine rulings from the Italian Constitutional\nCourt on bioethics issues that involve trade-offs between competing values and\ncompare model-generated legal arguments on these issues to those presented by\nthe State, the Court, and the applicants. Our results indicate that GPT-4\nconsistently aligns more closely with progressive interpretations of the\nConstitution, often overlooking competing values and mirroring the applicants'\nviews rather than the more conservative perspectives of the State or the\nCourt's moderate positions. Our experiments reveal a distinct tendency of GPT-4\nto favor progressive legal interpretations, underscoring the influence of\nunderlying data biases. We thus underscore the importance of testing alignment\nin real-world scenarios and considering the implications of deploying LLMs in\ndecision-making processes.", "published": "2024-07-29 07:51:43", "link": "http://arxiv.org/abs/2407.19760v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Introducing a new hyper-parameter for RAG: Context Window Utilization", "abstract": "This paper introduces a new hyper-parameter for Retrieval-Augmented\nGeneration (RAG) systems called Context Window Utilization. RAG systems enhance\ngenerative models by incorporating relevant information retrieved from external\nknowledge bases, improving the factual accuracy and contextual relevance of\ngenerated responses. The size of the text chunks retrieved and processed is a\ncritical factor influencing RAG performance. This study aims to identify the\noptimal chunk size that maximizes answer generation quality. Through systematic\nexperimentation, we analyze the effects of varying chunk sizes on the\nefficiency and effectiveness of RAG frameworks. Our findings reveal that an\noptimal chunk size balances the trade-off between providing sufficient context\nand minimizing irrelevant information. These insights are crucial for enhancing\nthe design and implementation of RAG systems, underscoring the importance of\nselecting an appropriate chunk size to achieve superior performance.", "published": "2024-07-29 08:38:14", "link": "http://arxiv.org/abs/2407.19794v2", "categories": ["cs.CL", "cs.ET"], "primary_category": "cs.CL"}
{"title": "Improving Retrieval Augmented Language Model with Self-Reasoning", "abstract": "The Retrieval-Augmented Language Model (RALM) has shown remarkable\nperformance on knowledge-intensive tasks by incorporating external knowledge\nduring inference, which mitigates the factual hallucinations inherited in large\nlanguage models (LLMs). Despite these advancements, challenges persist in the\nimplementation of RALMs, particularly concerning their reliability and\ntraceability. To be specific, the irrelevant document retrieval may result in\nunhelpful response generation or even deteriorate the performance of LLMs,\nwhile the lack of proper citations in generated outputs complicates efforts to\nverify the trustworthiness of the models. To this end, we propose a novel\nself-reasoning framework aimed at improving the reliability and traceability of\nRALMs, whose core idea is to leverage reasoning trajectories generated by the\nLLM itself. The framework involves constructing self-reason trajectories with\nthree processes: a relevance-aware process, an evidence-aware selective\nprocess, and a trajectory analysis process. We have evaluated our framework\nacross four public datasets (two short-form QA datasets, one long-form QA\ndataset, and one fact verification dataset) to demonstrate the superiority of\nour method, which can outperform existing state-of-the-art models and can\nachieve comparable performance with GPT-4, while only using 2,000 training\nsamples.", "published": "2024-07-29 09:05:10", "link": "http://arxiv.org/abs/2407.19813v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost", "abstract": "Today's large language models (LLMs) can solve challenging question-answering\ntasks, and prompt engineering techniques, such as chain-of-thought (CoT), have\ngained attention for enhancing the explanation and correctness of outputs.\nHowever, many models and techniques tend to produce excessively verbose and\nlengthy answers, leading to issues with both conciseness and generation time.\nTo address this, this paper analyzes the impact of output lengths on LLM\ninference pipelines by introducing and proposing novel metrics to evaluate the\n\\textit{correct conciseness} of a model and related prompting techniques. Then,\nwe examine the impact of controlling output length through a refined prompt\nengineering strategy, Constrained-CoT (CCoT), which encourages the model to\nproduce more concise outputs. To better understand the effects of such a\nprompt, we also introduce two additional scores for analyzing the conciseness,\nmeasured in terms of redundancy and information flow in generated answers.\nExperiments on pretrained LLMs and multiple datasets demonstrate the benefits\nof the proposed metrics and the effectiveness of CCoT across different models.", "published": "2024-07-29 09:21:52", "link": "http://arxiv.org/abs/2407.19825v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to\n  English Translation", "abstract": "Classical Arabic represents a significant era, encompassing the golden age of\nArab culture, philosophy, and scientific literature. With a broad consensus on\nthe importance of translating these literatures to enrich knowledge\ndissemination across communities, the advent of large language models (LLMs)\nand translation systems offers promising tools to facilitate this goal.\nHowever, we have identified a scarcity of translation datasets in Classical\nArabic, which are often limited in scope and topics, hindering the development\nof high-quality translation systems. In response, we present the ATHAR dataset,\ncomprising 66,000 high-quality Classical Arabic to English translation samples\nthat cover a wide array of subjects including science, culture, and philosophy.\nFurthermore, we assess the performance of current state-of-the-art LLMs under\nvarious settings, concluding that there is a need for such datasets in current\nsystems. Our findings highlight how models can benefit from fine-tuning or\nincorporating this dataset into their pretraining pipelines. The dataset is\npublicly available on the HuggingFace Data Hub at\n\\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}.", "published": "2024-07-29 09:45:34", "link": "http://arxiv.org/abs/2407.19835v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inference acceleration for large language models using \"stairs\" assisted\n  greedy generation", "abstract": "Large Language Models (LLMs) with billions of parameters are known for their\nimpressive predicting capabilities but require lots of resources to run. With\ntheir massive rise in popularity, even a small reduction in required resources\ncould have an impact on environment. On the other hand, smaller models require\nfewer resources but may sacrifice accuracy. In this work, we are proposing an\nimplementation of ``stairs'' assisted greedy generation. It is a modified\nassisted generation methodology that makes use of a smaller model's fast\ngeneration, large model's batch prediction, and \"stairs\" validation in order to\nachieve a speed up in prediction generation. Results show between 9.58 and\n17.24 percent inference time reduction compared to a stand-alone large LLM\nprediction in a text generation task without a loss in accuracy.", "published": "2024-07-29 12:29:29", "link": "http://arxiv.org/abs/2407.19947v1", "categories": ["cs.CL", "cs.LG", "68T07, 68T50, 68T05,", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective", "abstract": "Large Language Models (LLMs) have demonstrated unprecedented prowess across\nvarious natural language processing tasks in various application domains.\nRecent studies show that LLMs can be leveraged to perform lexical semantic\ntasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).\nHowever, it has not effectively been verified whether their success is due to\ntheir ability to reason over unstructured or semi-structured data, or their\neffective learning of linguistic patterns and senses alone. This unresolved\nquestion is particularly crucial when dealing with domain-specific data, where\nthe lexical senses and their meaning can completely differ from what a LLM has\nlearned during its training stage. This paper investigates the following\nquestion: Do LLMs really adapt to domains and remain consistent in the\nextraction of structured knowledge, or do they only learn lexical senses\ninstead of reasoning? To answer this question and, we devise a controlled\nexperiment setup that uses WordNet to synthesize parallel corpora, with English\nand gibberish terms. We examine the differences in the outputs of LLMs for each\ncorpus in two OL tasks: relation extraction and taxonomy discovery. Empirical\nresults show that, while adapting to the gibberish corpora, off-the-shelf LLMs\ndo not consistently reason over semantic relationships between concepts, and\ninstead leverage senses and their frame. However, fine-tuning improves the\nperformance of LLMs on lexical semantic tasks even when the domain-specific\nterms are arbitrary and unseen during pre-training, hinting at the\napplicability of pre-trained LLMs for OL.", "published": "2024-07-29 13:29:43", "link": "http://arxiv.org/abs/2407.19998v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Large Language Models to generate Easy to Read content", "abstract": "Ensuring text accessibility and understandability are essential goals,\nparticularly for individuals with cognitive impairments and intellectual\ndisabilities, who encounter challenges in accessing information across various\nmediums such as web pages, newspapers, administrative tasks, or health\ndocuments. Initiatives like Easy to Read and Plain Language guidelines aim to\nsimplify complex texts; however, standardizing these guidelines remains\nchallenging and often involves manual processes. This work presents an\nexploratory investigation into leveraging Artificial Intelligence (AI) and\nNatural Language Processing (NLP) approaches to systematically simplify Spanish\ntexts into Easy to Read formats, with a focus on utilizing Large Language\nModels (LLMs) for simplifying texts, especially in generating Easy to Read\ncontent. The study contributes a parallel corpus of Spanish adapted for Easy To\nRead format, which serves as a valuable resource for training and testing text\nsimplification systems. Additionally, several text simplification experiments\nusing LLMs and the collected corpus are conducted, involving fine-tuning and\ntesting a Llama2 model to generate Easy to Read content. A qualitative\nevaluation, guided by an expert in text adaptation for Easy to Read content, is\ncarried out to assess the automatically simplified texts. This research\ncontributes to advancing text accessibility for individuals with cognitive\nimpairments, highlighting promising strategies for leveraging LLMs while\nresponsibly managing energy usage.", "published": "2024-07-29 14:30:39", "link": "http://arxiv.org/abs/2407.20046v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MindSearch: Mimicking Human Minds Elicits Deep AI Searcher", "abstract": "Information seeking and integration is a complex cognitive task that consumes\nenormous time and effort. Inspired by the remarkable progress of Large Language\nModels, recent works attempt to solve this task by combining LLMs and search\nengines. However, these methods still obtain unsatisfying performance due to\nthree challenges: (1) complex requests often cannot be accurately and\ncompletely retrieved by the search engine once (2) corresponding information to\nbe integrated is spread over multiple web pages along with massive noise, and\n(3) a large number of web pages with long contents may quickly exceed the\nmaximum context length of LLMs. Inspired by the cognitive process when humans\nsolve these problems, we introduce MindSearch to mimic the human minds in web\ninformation seeking and integration, which can be instantiated by a simple yet\neffective LLM-based multi-agent framework. The WebPlanner models the human mind\nof multi-step information seeking as a dynamic graph construction process: it\ndecomposes the user query into atomic sub-questions as nodes in the graph and\nprogressively extends the graph based on the search result from WebSearcher.\nTasked with each sub-question, WebSearcher performs hierarchical information\nretrieval with search engines and collects valuable information for WebPlanner.\nThe multi-agent design of MindSearch enables the whole framework to seek and\nintegrate information parallelly from larger-scale (e.g., more than 300) web\npages in 3 minutes, which is worth 3 hours of human effort. MindSearch\ndemonstrates significant improvement in the response quality in terms of depth\nand breadth, on both close-set and open-set QA problems. Besides, responses\nfrom MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web\nand Perplexity.ai applications, which implies that MindSearch can already\ndeliver a competitive solution to the proprietary AI search engine.", "published": "2024-07-29 17:12:40", "link": "http://arxiv.org/abs/2407.20183v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aligning Query Representation with Rewritten Query and Relevance\n  Judgments in Conversational Search", "abstract": "Conversational search supports multi-turn user-system interactions to solve\ncomplex information needs. Different from the traditional single-turn ad-hoc\nsearch, conversational search encounters a more challenging problem of\ncontext-dependent query understanding with the lengthy and long-tail\nconversational history context. While conversational query rewriting methods\nleverage explicit rewritten queries to train a rewriting model to transform the\ncontext-dependent query into a stand-stone search query, this is usually done\nwithout considering the quality of search results. Conversational dense\nretrieval methods use fine-tuning to improve a pre-trained ad-hoc query\nencoder, but they are limited by the conversational search data available for\ntraining. In this paper, we leverage both rewritten queries and relevance\njudgments in the conversational search data to train a better query\nrepresentation model. The key idea is to align the query representation with\nthose of rewritten queries and relevant documents. The proposed model -- Query\nRepresentation Alignment Conversational Dense Retriever, QRACDR, is tested on\neight datasets, including various settings in conversational search and ad-hoc\nsearch. The results demonstrate the strong performance of QRACDR compared with\nstate-of-the-art methods, and confirm the effectiveness of representation\nalignment.", "published": "2024-07-29 17:14:36", "link": "http://arxiv.org/abs/2407.20189v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Generating Gender Alternatives in Machine Translation", "abstract": "Machine translation (MT) systems often translate terms with ambiguous gender\n(e.g., English term \"the nurse\") into the gendered form that is most prevalent\nin the systems' training data (e.g., \"enfermera\", the Spanish term for a female\nnurse). This often reflects and perpetuates harmful stereotypes present in\nsociety. With MT user interfaces in mind that allow for resolving gender\nambiguity in a frictionless manner, we study the problem of generating all\ngrammatically correct gendered translation alternatives. We open source train\nand test datasets for five language pairs and establish benchmarks for this\ntask. Our key technical contribution is a novel semi-supervised solution for\ngenerating alternatives that integrates seamlessly with standard MT models and\nmaintains high performance without requiring additional components or\nincreasing inference overhead.", "published": "2024-07-29 22:10:51", "link": "http://arxiv.org/abs/2407.20438v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language\n  Models", "abstract": "Instruction tuning in multimodal large language models (MLLMs) aims to\nsmoothly integrate a backbone LLM with a pre-trained feature encoder for\ndownstream tasks. The major challenge is how to efficiently find the synergy\nthrough cooperative learning where LLMs adapt their reasoning abilities in\ndownstream tasks while feature encoders adjust their encoding to provide more\nrelevant modal information. In this paper, we analyze the MLLM instruction\ntuning from both theoretical and empirical perspectives, where we find\nunbalanced learning between the two components, i.e., the feature encoder and\nthe LLM, can cause diminishing learning gradients that slow the model\nconvergence and often lead to sub-optimal results due to insufficient learning.\nInspired by our findings, we propose a measurement to quantitatively evaluate\nthe learning balance, based on which we further design a dynamic learning\nscheduler that better coordinates the learning. In addition, we introduce an\nauxiliary loss regularization method to promote updating of the generation\ndistribution of MLLMs considering the learning state of each model component,\nwhich potentially prevents each component from gradient diminishing and enables\na more accurate estimation of the learning balance coefficient. We conduct\nexperiments with multiple LLM backbones and feature encoders, where our\ntechniques are model-agnostic and can be generically integrated with various\nMLLM backbones. Experiment results on multiple downstream tasks and modalities\nin vision and audio, demonstrate the proposed method's better efficiency and\neffectiveness in MLLM instruction tuning.", "published": "2024-07-29 23:18:55", "link": "http://arxiv.org/abs/2407.20454v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Beyond Metrics: A Critical Analysis of the Variability in Large Language\n  Model Evaluation Frameworks", "abstract": "As large language models (LLMs) continue to evolve, the need for robust and\nstandardized evaluation benchmarks becomes paramount. Evaluating the\nperformance of these models is a complex challenge that requires careful\nconsideration of various linguistic tasks, model architectures, and\nbenchmarking methodologies. In recent years, various frameworks have emerged as\nnoteworthy contributions to the field, offering comprehensive evaluation tests\nand benchmarks for assessing the capabilities of LLMs across diverse domains.\nThis paper provides an exploration and critical analysis of some of these\nevaluation methodologies, shedding light on their strengths, limitations, and\nimpact on advancing the state-of-the-art in natural language processing.", "published": "2024-07-29 03:37:14", "link": "http://arxiv.org/abs/2407.21072v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TopicTag: Automatic Annotation of NMF Topic Models Using Chain of\n  Thought and Prompt Tuning with LLMs", "abstract": "Topic modeling is a technique for organizing and extracting themes from large\ncollections of unstructured text. Non-negative matrix factorization (NMF) is a\ncommon unsupervised approach that decomposes a term frequency-inverse document\nfrequency (TF-IDF) matrix to uncover latent topics and segment the dataset\naccordingly. While useful for highlighting patterns and clustering documents,\nNMF does not provide explicit topic labels, necessitating subject matter\nexperts (SMEs) to assign labels manually. We present a methodology for\nautomating topic labeling in documents clustered via NMF with automatic model\ndetermination (NMFk). By leveraging the output of NMFk and employing prompt\nengineering, we utilize large language models (LLMs) to generate accurate topic\nlabels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs\ndemonstrates the effectiveness of our method in enhancing knowledge management\nand document organization.", "published": "2024-07-29 00:18:17", "link": "http://arxiv.org/abs/2407.19616v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference", "abstract": "The rapid growth of large-scale AI models, particularly large language models\nhas brought significant challenges in data privacy, computational resources,\nand accessibility. Traditional centralized architectures often struggle to meet\nrequired data security and scalability needs which hinders the democratization\nof AI systems. Nesa introduces a model-agnostic sharding framework designed for\ndecentralized AI inference. Our framework uses blockchain-based sequential deep\nneural network sharding to distribute computational tasks across a diverse\nnetwork of nodes based on a personalised heuristic and routing mechanism. This\nenables efficient distributed training and inference for recent large-scale\nmodels even on consumer-grade hardware. We use compression techniques like\ndynamic blockwise quantization and mixed matrix decomposition to reduce data\ntransfer and memory needs. We also integrate robust security measures,\nincluding hardware-based trusted execution environments to ensure data\nintegrity and confidentiality. Evaluating our system across various natural\nlanguage processing and vision tasks shows that these compression strategies do\nnot compromise model accuracy. Our results highlight the potential to\ndemocratize access to cutting-edge AI technologies by enabling secure and\nefficient inference on a decentralized network.", "published": "2024-07-29 08:18:48", "link": "http://arxiv.org/abs/2407.19775v1", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.DC"], "primary_category": "cs.AI"}
{"title": "VolDoGer: LLM-assisted Datasets for Domain Generalization in\n  Vision-Language Tasks", "abstract": "Domain generalizability is a crucial aspect of a deep learning model since it\ndetermines the capability of the model to perform well on data from unseen\ndomains. However, research on the domain generalizability of deep learning\nmodels for vision-language tasks remains limited, primarily because of the lack\nof required datasets. To address these challenges, we propose VolDoGer:\nVision-Language Dataset for Domain Generalization, a dedicated dataset designed\nfor domain generalization that addresses three vision-language tasks: image\ncaptioning, visual question answering, and visual entailment. We constructed\nVolDoGer by extending LLM-based data annotation techniques to vision-language\ntasks, thereby alleviating the burden of recruiting human annotators. We\nevaluated the domain generalizability of various models, ranging from\nfine-tuned models to a recent multimodal large language model, through\nVolDoGer.", "published": "2024-07-29 08:38:46", "link": "http://arxiv.org/abs/2407.19795v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2", "abstract": "Multimodal Large Language Models (MLLMs) have attracted much attention for\ntheir multifunctionality. However, traditional Transformer architectures incur\nsignificant overhead due to their secondary computational complexity. To\naddress this issue, we introduce ML-Mamba, a multimodal language model, which\nutilizes the latest and efficient Mamba-2 model for inference. Mamba-2 is known\nfor its linear scalability and fast processing of long sequences. We replace\nthe Transformer-based backbone with a pre-trained Mamba-2 model and explore\nmethods for integrating 2D visual selective scanning mechanisms into multimodal\nlearning while also trying various visual encoders and Mamba-2 model variants.\nOur extensive experiments in various multimodal benchmark tests demonstrate the\ncompetitive performance of ML-Mamba and highlight the potential of state space\nmodels in multimodal tasks. The experimental results show that: (1) we\nempirically explore how to effectively apply the 2D vision selective scan\nmechanism for multimodal learning. We propose a novel multimodal connector\ncalled the Mamba-2 Scan Connector (MSC), which enhances representational\ncapabilities. (2) ML-Mamba achieves performance comparable to state-of-the-art\nmethods such as TinyLaVA and MobileVLM v2 through its linear sequential\nmodeling while faster inference speed; (3) Compared to multimodal models\nutilizing Mamba-1, the Mamba-2-based ML-Mamba exhibits superior inference\nperformance and effectiveness.", "published": "2024-07-29 09:38:15", "link": "http://arxiv.org/abs/2407.19832v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Detecting and Understanding Vulnerabilities in Language Models via\n  Mechanistic Interpretability", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts\nof data in a self-supervised manner, have shown impressive performance across a\nwide range of tasks. Indeed, their generative abilities have aroused interest\non the application of LLMs across a wide range of contexts. However, neural\nnetworks in general, and LLMs in particular, are known to be vulnerable to\nadversarial attacks, where an imperceptible change to the input can mislead the\noutput of the model. This is a serious concern that impedes the use of LLMs on\nhigh-stakes applications, such as healthcare, where a wrong prediction can\nimply serious consequences. Even though there are many efforts on making LLMs\nmore robust to adversarial attacks, there are almost no works that study\n\\emph{how} and \\emph{where} these vulnerabilities that make LLMs prone to\nadversarial attacks happen. Motivated by these facts, we explore how to\nlocalize and understand vulnerabilities, and propose a method, based on\nMechanistic Interpretability (MI) techniques, to guide this process.\nSpecifically, this method enables us to detect vulnerabilities related to a\nconcrete task by (i) obtaining the subset of the model that is responsible for\nthat task, (ii) generating adversarial samples for that task, and (iii) using\nMI techniques together with the previous samples to discover and understand the\npossible vulnerabilities. We showcase our method on a pretrained GPT-2 Small\nmodel carrying out the task of predicting 3-letter acronyms to demonstrate its\neffectiveness on locating and understanding concrete vulnerabilities of the\nmodel.", "published": "2024-07-29 09:55:34", "link": "http://arxiv.org/abs/2407.19842v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "BEExAI: Benchmark to Evaluate Explainable AI", "abstract": "Recent research in explainability has given rise to numerous post-hoc\nattribution methods aimed at enhancing our comprehension of the outputs of\nblack-box machine learning models. However, evaluating the quality of\nexplanations lacks a cohesive approach and a consensus on the methodology for\nderiving quantitative metrics that gauge the efficacy of explainability\npost-hoc attribution methods. Furthermore, with the development of increasingly\ncomplex deep learning models for diverse data applications, the need for a\nreliable way of measuring the quality and correctness of explanations is\nbecoming critical. We address this by proposing BEExAI, a benchmark tool that\nallows large-scale comparison of different post-hoc XAI methods, employing a\nset of selected evaluation metrics.", "published": "2024-07-29 11:21:17", "link": "http://arxiv.org/abs/2407.19897v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sentiment Analysis of Lithuanian Online Reviews Using Large Language\n  Models", "abstract": "Sentiment analysis is a widely researched area within Natural Language\nProcessing (NLP), attracting significant interest due to the advent of\nautomated solutions. Despite this, the task remains challenging because of the\ninherent complexity of languages and the subjective nature of sentiments. It is\neven more challenging for less-studied and less-resourced languages such as\nLithuanian. Our review of existing Lithuanian NLP research reveals that\ntraditional machine learning methods and classification algorithms have limited\neffectiveness for the task. In this work, we address sentiment analysis of\nLithuanian five-star-based online reviews from multiple domains that we collect\nand clean. We apply transformer models to this task for the first time,\nexploring the capabilities of pre-trained multilingual Large Language Models\n(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the\ninherent difficulty of the task, the fine-tuned models perform quite well,\nespecially when the sentiments themselves are less ambiguous: 80.74% and 89.61%\ntesting recognition accuracy of the most popular one- and five-star reviews\nrespectively. They significantly outperform current commercial state-of-the-art\ngeneral-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.", "published": "2024-07-29 11:44:21", "link": "http://arxiv.org/abs/2407.19914v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T07, 68T50, 68T05,", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs", "abstract": "Domain reweighting is an emerging research area aimed at adjusting the\nrelative weights of different data sources to improve the effectiveness and\nefficiency of LLM pre-training. We show that data mixtures that perform well at\nsmaller scales may not retain their advantage at larger scales, challenging the\nexisting practice of determining competitive mixtures in small-scale\nexperiments and directly applying them at much larger scales. To address this,\nwe propose AutoScale, a two-stage, scale-aware data composition framework.\nFirst, AutoScale fits a parametric model that predicts the model's loss under\ndifferent data compositions, then uses it to find an approximate best\nallocation at smaller, more manageable budgets. Next, leveraging a novel\ntheoretical analysis of how optimal compositions evolve with scale, AutoScale\nextrapolates that composition to larger budgets without further retraining.\nEmpirically, AutoScale accelerates convergence and improves downstream\nperformance. For instance, when pre-training GPT-2 Large, it achieves a 28%\nfaster perplexity reduction than baselines and up to a 38% speed-up over\nunweighted training, while yielding best-average results on various downstream\ntasks. Overall, our findings illustrate how domain importance shifts with\ntraining scale, underscoring the need for scale-dependent data curation in LLM\ntraining. Our code is open-sourced.", "published": "2024-07-29 17:06:30", "link": "http://arxiv.org/abs/2407.20177v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval", "abstract": "In dense retrieval, embedding long texts into dense vectors can result in\ninformation loss, leading to inaccurate query-text matching. Additionally,\nlow-quality texts with excessive noise or sparse key information are unlikely\nto align well with relevant queries. Recent studies mainly focus on improving\nthe sentence embedding model or retrieval process. In this work, we introduce a\nnovel text augmentation framework for dense retrieval. This framework\ntransforms raw documents into information-dense text formats, which supplement\nthe original texts to effectively address the aforementioned issues without\nmodifying embedding or retrieval methodologies. Two text representations are\ngenerated via large language models (LLMs) zero-shot prompting: question-answer\npairs and element-driven events. We term this approach QAEA-DR: unifying\nquestion-answer generation and event extraction in a text augmentation\nframework for dense retrieval. To further enhance the quality of generated\ntexts, a scoring-based evaluation and regeneration mechanism is introduced in\nLLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,\nsupported by both theoretical analysis and empirical experiments.", "published": "2024-07-29 17:39:08", "link": "http://arxiv.org/abs/2407.20207v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Physics of Language Models: Part 2.1, Grade-School Math and the Hidden\n  Reasoning Process", "abstract": "Recent advances in language models have demonstrated their capability to\nsolve mathematical reasoning problems, achieving near-perfect accuracy on\ngrade-school level math benchmarks like GSM8K. In this paper, we formally study\nhow language models solve these problems. We design a series of controlled\nexperiments to address several fundamental questions: (1) Can language models\ntruly develop reasoning skills, or do they simply memorize templates? (2) What\nis the model's hidden (mental) reasoning process? (3) Do models solve math\nquestions using skills similar to or different from humans? (4) Do models\ntrained on GSM8K-like datasets develop reasoning skills beyond those necessary\nfor solving GSM8K problems? (5) What mental process causes models to make\nreasoning mistakes? (6) How large or deep must a model be to effectively solve\nGSM8K-level math questions?\n  Our study uncovers many hidden mechanisms by which language models solve\nmathematical questions, providing insights that extend beyond current\nunderstandings of LLMs.", "published": "2024-07-29 17:52:40", "link": "http://arxiv.org/abs/2407.20311v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger\n  Visual Cues", "abstract": "Effectively aligning with human judgment when evaluating machine-generated\nimage captions represents a complex yet intriguing challenge. Existing\nevaluation metrics like CIDEr or CLIP-Score fall short in this regard as they\ndo not take into account the corresponding image or lack the capability of\nencoding fine-grained details and penalizing hallucinations. To overcome these\nissues, in this paper, we propose BRIDGE, a new learnable and reference-free\nimage captioning metric that employs a novel module to map visual features into\ndense vectors and integrates them into multi-modal pseudo-captions which are\nbuilt during the evaluation process. This approach results in a multimodal\nmetric that properly incorporates information from the input image without\nrelying on reference captions, bridging the gap between human judgment and\nmachine-generated image captions. Experiments spanning several datasets\ndemonstrate that our proposal achieves state-of-the-art results compared to\nexisting reference-free evaluation scores. Our source code and trained models\nare publicly available at: https://github.com/aimagelab/bridge-score.", "published": "2024-07-29 18:00:17", "link": "http://arxiv.org/abs/2407.20341v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Gender, Race, and Intersectional Bias in Resume Screening via Language\n  Model Retrieval", "abstract": "Artificial intelligence (AI) hiring tools have revolutionized resume\nscreening, and large language models (LLMs) have the potential to do the same.\nHowever, given the biases which are embedded within LLMs, it is unclear whether\nthey can be used in this scenario without disadvantaging groups based on their\nprotected attributes. In this work, we investigate the possibilities of using\nLLMs in a resume screening setting via a document retrieval framework that\nsimulates job candidate selection. Using that framework, we then perform a\nresume audit study to determine whether a selection of Massive Text Embedding\n(MTE) models are biased in resume screening scenarios. We simulate this for\nnine occupations, using a collection of over 500 publicly available resumes and\n500 job descriptions. We find that the MTEs are biased, significantly favoring\nWhite-associated names in 85.1\\% of cases and female-associated names in only\n11.1\\% of cases, with a minority of cases showing no statistically significant\ndifferences. Further analyses show that Black males are disadvantaged in up to\n100\\% of cases, replicating real-world patterns of bias in employment settings,\nand validate three hypotheses of intersectionality. We also find an impact of\ndocument length as well as the corpus frequency of names in the selection of\nresumes. These findings have implications for widely used AI tools that are\nautomating employment, fairness, and tech policy.", "published": "2024-07-29 18:42:39", "link": "http://arxiv.org/abs/2407.20371v2", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG", "K.4.2"], "primary_category": "cs.CY"}
{"title": "Enhancing Adversarial Text Attacks on BERT Models with Projected\n  Gradient Descent", "abstract": "Adversarial attacks against deep learning models represent a major threat to\nthe security and reliability of natural language processing (NLP) systems. In\nthis paper, we propose a modification to the BERT-Attack framework, integrating\nProjected Gradient Descent (PGD) to enhance its effectiveness and robustness.\nThe original BERT-Attack, designed for generating adversarial examples against\nBERT-based models, suffers from limitations such as a fixed perturbation budget\nand a lack of consideration for semantic similarity. The proposed approach in\nthis work, PGD-BERT-Attack, addresses these limitations by leveraging PGD to\niteratively generate adversarial examples while ensuring both imperceptibility\nand semantic similarity to the original input. Extensive experiments are\nconducted to evaluate the performance of PGD-BERT-Attack compared to the\noriginal BERT-Attack and other baseline methods. The results demonstrate that\nPGD-BERT-Attack achieves higher success rates in causing misclassification\nwhile maintaining low perceptual changes. Furthermore, PGD-BERT-Attack produces\nadversarial instances that exhibit greater semantic resemblance to the initial\ninput, enhancing their applicability in real-world scenarios. Overall, the\nproposed modification offers a more effective and robust approach to\nadversarial attacks on BERT-based models, thus contributing to the advancement\nof defense against attacks on NLP systems.", "published": "2024-07-29 09:07:29", "link": "http://arxiv.org/abs/2407.21073v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Apple Intelligence Foundation Language Models", "abstract": "We present foundation language models developed to power Apple Intelligence\nfeatures, including a ~3 billion parameter model designed to run efficiently on\ndevices and a large server-based language model designed for Private Cloud\nCompute. These models are designed to perform a wide range of tasks\nefficiently, accurately, and responsibly. This report describes the model\narchitecture, the data used to train the model, the training process, how the\nmodels are optimized for inference, and the evaluation results. We highlight\nour focus on Responsible AI and how the principles are applied throughout the\nmodel development.", "published": "2024-07-29 18:38:49", "link": "http://arxiv.org/abs/2407.21075v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions\n  for Large Language Models", "abstract": "Large Language Models (LLMs) require high quality instruction data for\neffective alignment, particularly in code generation tasks where expert curated\ndatasets are expensive to produce. We present Genetic-Instruct, a scalable\nalgorithm for synthesizing large-scale, high quality coding instructions using\nevolutionary principles. Starting from a small set of seed instructions,\nGenetic-Instruct generates diverse and challenging instruction-code pairs by\nleveraging an Instructor-LLM for generation, a Coder-LLM for code synthesis,\nand a Judge-LLM for automatic quality evaluation. Our proposed approach is\nhighly parallelizable and effective even with a small seed data and weaker\ngenerator models. We generated more than 7.5 million coding instructions with\nthe proposed approach. Then we evaluated it by fine-tuning LLMs with the\nsynthetic samples and demonstrated a significant improvement in their code\ngeneration capability compared to the other synthetic generation approaches and\npublicly available datasets. Our results highlight the efficiency, scalability,\nand generalizability of the Genetic-Instruct framework.", "published": "2024-07-29 20:42:59", "link": "http://arxiv.org/abs/2407.21077v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Blind Acoustic Parameter Estimation Through Task-Agnostic Embeddings\n  Using Latent Approximations", "abstract": "We present a method for blind acoustic parameter estimation from\nsingle-channel reverberant speech. The method is structured into three stages.\nIn the first stage, a variational auto-encoder is trained to extract latent\nrepresentations of acoustic impulse responses represented as mel-spectrograms.\nIn the second stage, a separate speech encoder is trained to estimate\nlow-dimensional representations from short segments of reverberant speech.\nFinally, the pre-trained speech encoder is combined with a small regression\nmodel and evaluated on two parameter regression tasks. Experimentally, the\nproposed method is shown to outperform a fully end-to-end trained baseline\nmodel.", "published": "2024-07-29 13:22:12", "link": "http://arxiv.org/abs/2407.19989v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Frequency & Channel Attention Network for Small Footprint Noisy Spoken\n  Keyword Spotting", "abstract": "In this paper, we aim to improve the robustness of Keyword Spotting (KWS)\nsystems in noisy environments while keeping a small memory footprint. We\npropose a new convolutional neural network (CNN) called FCA-Net, which combines\nmixer unit-based feature interaction with a two-dimensional convolution-based\nattention module. First, we introduce and compare lightweight attention methods\nto enhance noise robustness in CNN. Then, we propose an attention module that\ncreates fine-grained attention weights to capture channel and\nfrequency-specific information, boosting the model's ability to handle noisy\nconditions. By combining the mixer unit-based feature interaction with the\nattention module, we enhance performance. Additionally, we use a\ncurriculum-based multi-condition training strategy. Our experiments show that\nour system outperforms current state-of-the-art solutions for small-footprint\nKWS in noisy environments, making it reliable for real-world use.", "published": "2024-07-29 09:45:28", "link": "http://arxiv.org/abs/2407.19834v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Wavespace: A Highly Explorable Wavetable Generator", "abstract": "Wavetable synthesis generates quasi-periodic waveforms of musical tones by\ninterpolating a list of waveforms called wavetable. As generative models that\nutilize latent representations offer various methods in waveform generation for\nmusical applications, studies in wavetable generation with invertible\narchitecture have also arisen recently. While they are promising, it is still\nchallenging to generate wavetables with detailed controls in disentangling\nfactors within the latent representation. In response, we present Wavespace, a\nnovel framework for wavetable generation that empowers users with enhanced\nparameter controls. Our model allows users to apply pre-defined conditions to\nthe output wavetables. We employ a variational autoencoder and completely\nfactorize its latent space to different waveform styles. We also condition the\ngenerator with auxiliary timbral and morphological descriptors. This way, users\ncan create unique wavetables by independently manipulating each latent subspace\nand descriptor parameters. Our framework is efficient enough for practical use;\nwe prototyped an oscillator plug-in as a proof of concept for real-time\nintegration of Wavespace within digital audio workspaces (DAWs).", "published": "2024-07-29 10:31:42", "link": "http://arxiv.org/abs/2407.19862v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Navigating the United States Legislative Landscape on Voice Privacy:\n  Existing Laws, Proposed Bills, Protection for Children, and Synthetic Data\n  for AI", "abstract": "Privacy is a hot topic for policymakers across the globe, including the\nUnited States. Evolving advances in AI and emerging concerns about the misuse\nof personal data have pushed policymakers to draft legislation on trustworthy\nAI and privacy protection for its citizens. This paper presents the state of\nthe privacy legislation at the U.S. Congress and outlines how voice data is\nconsidered as part of the legislation definition. This paper also reviews\nadditional privacy protection for children. This paper presents a holistic\nreview of enacted and proposed privacy laws, and consideration for voice data,\nincluding guidelines for processing children's data, in those laws across the\nfifty U.S. states. As a groundbreaking alternative to actual human data,\nethically generated synthetic data allows much flexibility to keep AI\ninnovation in progress. Given the consideration of synthetic data in AI\nlegislation by policymakers to be relatively new, as compared to that of\nprivacy laws, this paper reviews regulatory considerations for synthetic data.", "published": "2024-07-29 03:43:16", "link": "http://arxiv.org/abs/2407.19677v1", "categories": ["cs.CY", "cs.CR", "cs.SD", "eess.AS", "I.2; J.1"], "primary_category": "cs.CY"}
{"title": "UNQA: Unified No-Reference Quality Assessment for Audio, Image, Video,\n  and Audio-Visual Content", "abstract": "As multimedia data flourishes on the Internet, quality assessment (QA) of\nmultimedia data becomes paramount for digital media applications. Since\nmultimedia data includes multiple modalities including audio, image, video, and\naudio-visual (A/V) content, researchers have developed a range of QA methods to\nevaluate the quality of different modality data. While they exclusively focus\non addressing the single modality QA issues, a unified QA model that can handle\ndiverse media across multiple modalities is still missing, whereas the latter\ncan better resemble human perception behaviour and also have a wider range of\napplications. In this paper, we propose the Unified No-reference Quality\nAssessment model (UNQA) for audio, image, video, and A/V content, which tries\nto train a single QA model across different media modalities. To tackle the\nissue of inconsistent quality scales among different QA databases, we develop a\nmulti-modality strategy to jointly train UNQA on multiple QA databases. Based\non the input modality, UNQA selectively extracts the spatial features, motion\nfeatures, and audio features, and calculates a final quality score via the four\ncorresponding modality regression modules. Compared with existing QA methods,\nUNQA has two advantages: 1) the multi-modality training strategy makes the QA\nmodel learn more general and robust quality-aware feature representation as\nevidenced by the superior performance of UNQA compared to state-of-the-art QA\nmethods. 2) UNQA reduces the number of models required to assess multimedia\ndata across different modalities. and is friendly to deploy to practical\napplications.", "published": "2024-07-29 04:56:56", "link": "http://arxiv.org/abs/2407.19704v1", "categories": ["eess.IV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "eess.IV"}
{"title": "Analyzing and reducing the synthetic-to-real transfer gap in Music\n  Information Retrieval: the task of automatic drum transcription", "abstract": "Automatic drum transcription is a critical tool in Music Information\nRetrieval for extracting and analyzing the rhythm of a music track, but it is\nlimited by the size of the datasets available for training. A popular method\nused to increase the amount of data is by generating them synthetically from\nmusic scores rendered with virtual instruments. This method can produce a\nvirtually infinite quantity of tracks, but empirical evidence shows that models\ntrained on previously created synthetic datasets do not transfer well to real\ntracks. In this work, besides increasing the amount of data, we identify and\nevaluate three more strategies that practitioners can use to improve the\nrealism of the generated data and, thus, narrow the synthetic-to-real transfer\ngap. To explore their efficacy, we used them to build a new synthetic dataset\nand then we measured how the performance of a model scales and, specifically,\nat what value it will stagnate when increasing the number of training tracks\nfor different datasets. By doing this, we were able to prove that the\naforementioned strategies contribute to make our dataset the one with the most\nrealistic data distribution and the lowest synthetic-to-real transfer gap among\nthe synthetic datasets we evaluated. We conclude by highlighting the limits of\ntraining with infinite data in drum transcription and we show how they can be\novercome.", "published": "2024-07-29 09:17:16", "link": "http://arxiv.org/abs/2407.19823v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Practical and Reproducible Symbolic Music Generation by Large Language\n  Models with Structural Embeddings", "abstract": "Music generation introduces challenging complexities to large language\nmodels. Symbolic structures of music often include vertical harmonization as\nwell as horizontal counterpoint, urging various adaptations and enhancements\nfor large-scale Transformers. However, existing works share three major\ndrawbacks: 1) their tokenization requires domain-specific annotations, such as\nbars and beats, that are typically missing in raw MIDI data; 2) the pure impact\nof enhancing token embedding methods is hardly examined without domain-specific\nannotations; and 3) existing works to overcome the aforementioned drawbacks,\nsuch as MuseNet, lack reproducibility. To tackle such limitations, we develop a\nMIDI-based music generation framework inspired by MuseNet, empirically studying\ntwo structural embeddings that do not rely on domain-specific annotations. We\nprovide various metrics and insights that can guide suitable encoding to\ndeploy. We also verify that multiple embedding configurations can selectively\nboost certain musical aspects. By providing open-source implementations via\nHuggingFace, our findings shed light on leveraging large language models toward\npractical and reproducible music generation.", "published": "2024-07-29 11:24:10", "link": "http://arxiv.org/abs/2407.19900v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Anti-spoofing Countermeasures Robustness through Joint\n  Optimization and Transfer Learning", "abstract": "Current research in synthesized speech detection primarily focuses on the\ngeneralization of detection systems to unknown spoofing methods of noise-free\nspeech. However, the performance of anti-spoofing countermeasures (CM) system\nis often don't work as well in more challenging scenarios, such as those\ninvolving noise and reverberation. To address the problem of enhancing the\nrobustness of CM systems, we propose a transfer learning-based speech\nenhancement front-end joint optimization (TL-SEJ) method, investigating its\neffectiveness in improving robustness against noise and reverberation. We\nevaluated the proposed method's performance through a series of comparative and\nablation experiments. The experimental results show that, across different\nsignal-to-noise ratio test conditions, the proposed TL-SEJ method improves\nrecognition accuracy by 2.7% to 15.8% compared to the baseline. Compared to\nconventional data augmentation methods, our system achieves an accuracy\nimprovement ranging from 0.7% to 5.8% in various noisy conditions and from 1.7%\nto 2.8% under different RT60 reverberation scenarios. These experiments\ndemonstrate that the proposed method effectively enhances system robustness in\nnoisy and reverberant conditions.", "published": "2024-07-29 15:39:25", "link": "http://arxiv.org/abs/2407.20111v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Emotion-Driven Melody Harmonization via Melodic Variation and Functional\n  Representation", "abstract": "Emotion-driven melody harmonization aims to generate diverse harmonies for a\nsingle melody to convey desired emotions. Previous research found it hard to\nalter the perceived emotional valence of lead sheets only by harmonizing the\nsame melody with different chords, which may be attributed to the constraints\nimposed by the melody itself and the limitation of existing music\nrepresentation. In this paper, we propose a novel functional representation for\nsymbolic music. This new method takes musical keys into account, recognizing\ntheir significant role in shaping music's emotional character through\nmajor-minor tonality. It also allows for melodic variation with respect to keys\nand addresses the problem of data scarcity for better emotion modeling. A\nTransformer is employed to harmonize key-adaptable melodies, allowing for keys\ndetermined in rule-based or model-based manner. Experimental results confirm\nthe effectiveness of our new representation in generating key-aware harmonies,\nwith objective and subjective evaluations affirming the potential of our\napproach to convey specific valence for versatile melody.", "published": "2024-07-29 17:05:12", "link": "http://arxiv.org/abs/2407.20176v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Futga: Towards Fine-grained Music Understanding through\n  Temporally-enhanced Generative Augmentation", "abstract": "Existing music captioning methods are limited to generating concise global\ndescriptions of short music clips, which fail to capture fine-grained musical\ncharacteristics and time-aware musical changes. To address these limitations,\nwe propose FUTGA, a model equipped with fined-grained music understanding\ncapabilities through learning from generative augmentation with temporal\ncompositions. We leverage existing music caption datasets and large language\nmodels (LLMs) to synthesize fine-grained music captions with structural\ndescriptions and time boundaries for full-length songs. Augmented by the\nproposed synthetic dataset, FUTGA is enabled to identify the music's temporal\nchanges at key transition points and their musical functions, as well as\ngenerate detailed descriptions for each music segment. We further introduce a\nfull-length music caption dataset generated by FUTGA, as the augmentation of\nthe MusicCaps and the Song Describer datasets. We evaluate the automatically\ngenerated captions on several downstream tasks, including music generation and\nretrieval. The experiments demonstrate the quality of the generated captions\nand the better performance in various downstream tasks achieved by the proposed\nmusic captioning approach. Our code and datasets can be found in\n\\href{https://huggingface.co/JoshuaW1997/FUTGA}{\\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.", "published": "2024-07-29 22:53:32", "link": "http://arxiv.org/abs/2407.20445v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
