{"title": "BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles", "abstract": "A riddle is a question or statement with double or veiled meanings, followed\nby an unexpected answer. Solving riddle is a challenging task for both machine\nand human, testing the capability of understanding figurative, creative natural\nlanguage and reasoning with commonsense knowledge. We introduce BiRdQA, a\nbilingual multiple-choice question answering dataset with 6614 English riddles\nand 8751 Chinese riddles. For each riddle-answer pair, we provide four\ndistractors with additional information from Wikipedia. The distractors are\nautomatically generated at scale with minimal bias. Existing monolingual and\nmultilingual QA models fail to perform well on our dataset, indicating that\nthere is a long way to go before machine can beat human on solving tricky\nriddles. The dataset has been released to the community.", "published": "2021-09-23 00:46:47", "link": "http://arxiv.org/abs/2109.11087v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distiller: A Systematic Study of Model Distillation Methods in Natural\n  Language Processing", "abstract": "We aim to identify how different components in the KD pipeline affect the\nresulting performance and how much the optimal KD pipeline varies across\ndifferent datasets/tasks, such as the data augmentation policy, the loss\nfunction, and the intermediate representation for transferring the knowledge\nbetween teacher and student. To tease apart their effects, we propose\nDistiller, a meta KD framework that systematically combines a broad range of\ntechniques across different stages of the KD pipeline, which enables us to\nquantify each component's contribution. Within Distiller, we unify commonly\nused objectives for distillation of intermediate representations under a\nuniversal mutual information (MI) objective and propose a class of MI-$\\alpha$\nobjective functions with better bias/variance trade-off for estimating the MI\nbetween the teacher and the student. On a diverse set of NLP datasets, the best\nDistiller configurations are identified via large-scale hyperparameter\noptimization. Our experiments reveal the following: 1) the approach used to\ndistill the intermediate representations is the most important factor in KD\nperformance, 2) among different objectives for intermediate distillation,\nMI-$\\alpha$ performs the best, and 3) data augmentation provides a large boost\nfor small training datasets or small student networks. Moreover, we find that\ndifferent datasets/tasks prefer different KD algorithms, and thus propose a\nsimple AutoDistiller algorithm that can recommend a good KD pipeline for a new\ndataset.", "published": "2021-09-23 02:12:28", "link": "http://arxiv.org/abs/2109.11105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Language Model Meta-Pretraining", "abstract": "The success of pretrained cross-lingual language models relies on two\nessential abilities, i.e., generalization ability for learning downstream tasks\nin a source language, and cross-lingual transferability for transferring the\ntask knowledge to other languages. However, current methods jointly learn the\ntwo abilities in a single-phase cross-lingual pretraining process, resulting in\na trade-off between generalization and cross-lingual transfer. In this paper,\nwe propose cross-lingual language model meta-pretraining, which learns the two\nabilities in different training phases. Our method introduces an additional\nmeta-pretraining phase before cross-lingual pretraining, where the model learns\ngeneralization ability on a large-scale monolingual corpus. Then, the model\nfocuses on learning cross-lingual transfer on a multilingual corpus.\nExperimental results show that our method improves both generalization and\ncross-lingual transfer, and produces better-aligned representations across\ndifferent languages.", "published": "2021-09-23 03:47:44", "link": "http://arxiv.org/abs/2109.11129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-Parametric Online Learning from Human Feedback for Neural Machine\n  Translation", "abstract": "We study the problem of online learning with human feedback in the\nhuman-in-the-loop machine translation, in which the human translators revise\nthe machine-generated translations and then the corrected translations are used\nto improve the neural machine translation (NMT) system. However, previous\nmethods require online model updating or additional translation memory networks\nto achieve high-quality performance, making them inflexible and inefficient in\npractice. In this paper, we propose a novel non-parametric online learning\nmethod without changing the model structure. This approach introduces two\nk-nearest-neighbor (knn) modules: one module memorizes the human feedback,\nwhich is the correct sentences provided by human translators, while the other\nbalances the usage of the history human feedback and original NMT models\nadaptively. Experiments conducted on EMEA and JRC-Acquis benchmarks demonstrate\nthat our proposed method obtains substantial improvements on translation\naccuracy and achieves better adaptation performance with less repeating human\ncorrection operations.", "published": "2021-09-23 04:26:15", "link": "http://arxiv.org/abs/2109.11136v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Curriculum Learning in Unsupervised Neural Machine\n  Translation", "abstract": "Back-translation (BT) has become one of the de facto components in\nunsupervised neural machine translation (UNMT), and it explicitly makes UNMT\nhave translation ability. However, all the pseudo bi-texts generated by BT are\ntreated equally as clean data during optimization without considering the\nquality diversity, leading to slow convergence and limited translation\nperformance. To address this problem, we propose a curriculum learning method\nto gradually utilize pseudo bi-texts based on their quality from multiple\ngranularities. Specifically, we first apply cross-lingual word embedding to\ncalculate the potential translation difficulty (quality) for the monolingual\nsentences. Then, the sentences are fed into UNMT from easy to hard batch by\nbatch. Furthermore, considering the quality of sentences/tokens in a particular\nbatch are also diverse, we further adopt the model itself to calculate the\nfine-grained quality scores, which are served as learning factors to balance\nthe contributions of different parts when computing loss and encourage the UNMT\nmodel to focus on pseudo data with higher quality. Experimental results on WMT\n14 En-Fr, WMT 16 En-De, WMT 16 En-Ro, and LDC En-Zh translation tasks\ndemonstrate that the proposed method achieves consistent improvements with\nfaster convergence speed.", "published": "2021-09-23 07:18:06", "link": "http://arxiv.org/abs/2109.11177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency Structure for News Document Summarization", "abstract": "In this work, we develop a neural network based model which leverages\ndependency parsing to capture cross-positional dependencies and grammatical\nstructures. With the help of linguistic signals, sentence-level relations can\nbe correctly captured, thus improving news documents summarization performance.\nEmpirical studies demonstrate that this simple but effective method outperforms\nexisting works on the benchmark dataset. Extensive analyses examine different\nsettings and configurations of the proposed model which provide a good\nreference to the community.", "published": "2021-09-23 08:13:35", "link": "http://arxiv.org/abs/2109.11199v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fuzzy Generalised Quantifiers for Natural Language in Categorical\n  Compositional Distributional Semantics", "abstract": "Recent work on compositional distributional models shows that bialgebras over\nfinite dimensional vector spaces can be applied to treat generalised\nquantifiers for natural language. That technique requires one to construct the\nvector space over powersets, and therefore is computationally costly. In this\npaper, we overcome this problem by considering fuzzy versions of quantifiers\nalong the lines of Zadeh, within the category of many valued relations. We show\nthat this category is a concrete instantiation of the compositional\ndistributional model. We show that the semantics obtained in this model is\nequivalent to the semantics of the fuzzy quantifiers of Zadeh. As a result, we\nare now able to treat fuzzy quantification without requiring a powerset\nconstruction.", "published": "2021-09-23 09:15:15", "link": "http://arxiv.org/abs/2109.11227v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Pregroup Grammars, their Syntax and Semantics", "abstract": "Pregroup grammars were developed in 1999 and stayed Lambek's preferred\nalgebraic model of grammar. The set-theoretic semantics of pregroups, however,\nfaces an ambiguity problem. In his latest book, Lambek suggests that this\nproblem might be overcome using finite dimensional vector spaces rather than\nsets. What is the right notion of composition in this setting, direct sum or\ntensor product of spaces?", "published": "2021-09-23 09:26:05", "link": "http://arxiv.org/abs/2109.11237v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21", "abstract": "This paper describes the Volctrans' submission to the WMT21 news translation\nshared task for German->English translation. We build a parallel (i.e.,\nnon-autoregressive) translation system using the Glancing Transformer, which\nenables fast and accurate parallel decoding in contrast to the currently\nprevailing autoregressive models. To the best of our knowledge, this is the\nfirst parallel translation system that can be scaled to such a practical\nscenario like WMT competition. More importantly, our parallel translation\nsystem achieves the best BLEU score (35.0) on German->English translation task,\noutperforming all strong autoregressive counterparts.", "published": "2021-09-23 09:41:44", "link": "http://arxiv.org/abs/2109.11247v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't be Contradicted with Anything! CI-ToD: Towards Benchmarking\n  Consistency for Task-oriented Dialogue System", "abstract": "Consistency Identification has obtained remarkable success on open-domain\ndialogue, which can be used for preventing inconsistent response generation.\nHowever, in contrast to the rapid development in open-domain dialogue, few\nefforts have been made to the task-oriented dialogue direction. In this paper,\nwe argue that consistency problem is more urgent in task-oriented domain. To\nfacilitate the research, we introduce CI-ToD, a novel dataset for Consistency\nIdentification in Task-oriented Dialog system. In addition, we not only\nannotate the single label to enable the model to judge whether the system\nresponse is contradictory, but also provide more fine-grained labels (i.e.,\nDialogue History Inconsistency, User Query Inconsistency and Knowledge Base\nInconsistency) to encourage model to know what inconsistent sources lead to it.\nEmpirical results show that state-of-the-art methods only achieve 51.3%, which\nis far behind the human performance of 93.2%, indicating that there is ample\nroom for improving consistency identification ability. Finally, we conduct\nexhaustive experiments and qualitative analysis to comprehend key challenges\nand provide guidance for future directions. All datasets and models are\npublicly available at \\url{https://github.com/yizhen20133868/CI-ToD}.", "published": "2021-09-23 10:56:31", "link": "http://arxiv.org/abs/2109.11292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParaShoot: A Hebrew Question Answering Dataset", "abstract": "NLP research in Hebrew has largely focused on morphology and syntax, where\nrich annotated datasets in the spirit of Universal Dependencies are available.\nSemantic datasets, however, are in short supply, hindering crucial advances in\nthe development of NLP technology in Hebrew. In this work, we present\nParaShoot, the first question answering dataset in modern Hebrew. The dataset\nfollows the format and crowdsourcing methodology of SQuAD, and contains\napproximately 3000 annotated examples, similar to other question-answering\ndatasets in low-resource languages. We provide the first baseline results using\nrecently-released BERT-style models for Hebrew, showing that there is\nsignificant room for improvement on this task.", "published": "2021-09-23 11:59:38", "link": "http://arxiv.org/abs/2109.11314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transferring Knowledge from Vision to Language: How to Achieve it and\n  how to Measure it?", "abstract": "Large language models are known to suffer from the hallucination problem in\nthat they are prone to output statements that are false or inconsistent,\nindicating a lack of knowledge. A proposed solution to this is to provide the\nmodel with additional data modalities that complements the knowledge obtained\nthrough text. We investigate the use of visual data to complement the knowledge\nof large language models by proposing a method for evaluating visual knowledge\ntransfer to text for uni- or multimodal language models. The method is based on\ntwo steps, 1) a novel task querying for knowledge of memory colors, i.e.\ntypical colors of well-known objects, and 2) filtering of model training data\nto clearly separate knowledge contributions. Additionally, we introduce a model\narchitecture that involves a visual imagination step and evaluate it with our\nproposed method. We find that our method can successfully be used to measure\nvisual knowledge transfer capabilities in models and that our novel model\narchitecture shows promising results for leveraging multimodal knowledge in a\nunimodal setting.", "published": "2021-09-23 12:11:23", "link": "http://arxiv.org/abs/2109.11321v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Current State of Finnish NLP", "abstract": "There are a lot of tools and resources available for processing Finnish. In\nthis paper, we survey recent papers focusing on Finnish NLP related to many\ndifferent subcategories of NLP such as parsing, generation, semantics and\nspeech. NLP research is conducted in many different research groups in Finland,\nand it is frequently the case that NLP tools and models resulting from academic\nresearch are made available for others to use on platforms such as Github.", "published": "2021-09-23 12:19:56", "link": "http://arxiv.org/abs/2109.11326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cluster-based Mention Typing for Named Entity Disambiguation", "abstract": "An entity mention in text such as \"Washington\" may correspond to many\ndifferent named entities such as the city \"Washington D.C.\" or the newspaper\n\"Washington Post.\" The goal of named entity disambiguation is to identify the\nmentioned named entity correctly among all possible candidates. If the type\n(e.g. location or person) of a mentioned entity can be correctly predicted from\nthe context, it may increase the chance of selecting the right candidate by\nassigning low probability to the unlikely ones. This paper proposes\ncluster-based mention typing for named entity disambiguation. The aim of\nmention typing is to predict the type of a given mention based on its context.\nGenerally, manually curated type taxonomies such as Wikipedia categories are\nused. We introduce cluster-based mention typing, where named entities are\nclustered based on their contextual similarities and the cluster ids are\nassigned as types. The hyperlinked mentions and their context in Wikipedia are\nused in order to obtain these cluster-based types. Then, mention typing models\nare trained on these mentions, which have been labeled with their cluster-based\ntypes through distant supervision. At the named entity disambiguation phase,\nfirst the cluster-based types of a given mention are predicted and then, these\ntypes are used as features in a ranking model to select the best entity among\nthe candidates. We represent entities at multiple contextual levels and obtain\ndifferent clusterings (and thus typing models) based on each level. As each\nclustering breaks the entity space differently, mention typing based on each\nclustering discriminates the mention differently. When predictions from all\ntyping models are used together, our system achieves better or comparable\nresults based on randomization tests with respect to the state-of-the-art\nlevels on four defacto test sets.", "published": "2021-09-23 14:19:20", "link": "http://arxiv.org/abs/2109.11389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Fact-Checking: A Survey", "abstract": "As online false information continues to grow, automated fact-checking has\ngained an increasing amount of attention in recent years. Researchers in the\nfield of Natural Language Processing (NLP) have contributed to the task by\nbuilding fact-checking datasets, devising automated fact-checking pipelines and\nproposing NLP methods to further research in the development of different\ncomponents. This paper reviews relevant research on automated fact-checking\ncovering both the claim detection and claim validation components.", "published": "2021-09-23 15:13:48", "link": "http://arxiv.org/abs/2109.11427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corpus and Models for Lemmatisation and POS-tagging of Old French", "abstract": "Old French is a typical example of an under-resourced historic languages,\nthat furtherly displays animportant amount of linguistic variation. In this\npaper, we present the current results of a long going project (2015-...) and\ndescribe how we broached the difficult question of providing lemmatisation\nandPOS models for Old French with the help of neural taggers and the\nprogressive constitution of dedicated corpora.", "published": "2021-09-23 15:32:41", "link": "http://arxiv.org/abs/2109.11442v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces\n  with Pseudowords", "abstract": "We present a method for exploring regions around individual points in a\ncontextualized vector space (particularly, BERT space), as a way to investigate\nhow these regions correspond to word senses. By inducing a contextualized\n\"pseudoword\" as a stand-in for a static embedding in the input layer, and then\nperforming masked prediction of a word in the sentence, we are able to\ninvestigate the geometry of the BERT-space in a controlled manner around\nindividual instances. Using our method on a set of carefully constructed\nsentences targeting ambiguous English words, we find substantial regularity in\nthe contextualized space, with regions that correspond to distinct word senses;\nbut between these regions there are occasionally \"sense voids\" -- regions that\ndo not correspond to any intelligible sense.", "published": "2021-09-23 16:42:44", "link": "http://arxiv.org/abs/2109.11491v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "iFacetSum: Coreference-based Interactive Faceted Summarization for\n  Multi-Document Exploration", "abstract": "We introduce iFacetSum, a web application for exploring topical document\nsets. iFacetSum integrates interactive summarization together with faceted\nsearch, by providing a novel faceted navigation scheme that yields abstractive\nsummaries for the user's selections. This approach offers both a comprehensive\noverview as well as concise details regarding subtopics of choice. Fine-grained\nfacets are automatically produced based on cross-document coreference\npipelines, rendering generic concepts, entities and statements surfacing in the\nsource texts. We analyze the effectiveness of our application through\nsmall-scale user studies, which suggest the usefulness of our approach.", "published": "2021-09-23 20:01:11", "link": "http://arxiv.org/abs/2109.11621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the Uniform Information Density Hypothesis", "abstract": "The uniform information density (UID) hypothesis posits a preference among\nlanguage users for utterances structured such that information is distributed\nuniformly across a signal. While its implications on language production have\nbeen well explored, the hypothesis potentially makes predictions about language\ncomprehension and linguistic acceptability as well. Further, it is unclear how\nuniformity in a linguistic signal -- or lack thereof -- should be measured, and\nover which linguistic unit, e.g., the sentence or language level, this\nuniformity should hold. Here we investigate these facets of the UID hypothesis\nusing reading time and acceptability data. While our reading time results are\ngenerally consistent with previous work, they are also consistent with a weakly\nsuper-linear effect of surprisal, which would be compatible with UID's\npredictions. For acceptability judgments, we find clearer evidence that\nnon-uniformity in information density is predictive of lower acceptability. We\nthen explore multiple operationalizations of UID, motivated by different\ninterpretations of the original hypothesis, and analyze the scope over which\nthe pressure towards uniformity is exerted. The explanatory power of a subset\nof the proposed operationalizations suggests that the strongest trend may be a\nregression towards a mean surprisal across the language, rather than the\nphrase, sentence, or document -- a finding that supports a typical\ninterpretation of UID, namely that it is the byproduct of language users\nmaximizing the use of a (hypothetical) communication channel.", "published": "2021-09-23 20:41:47", "link": "http://arxiv.org/abs/2109.11635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Universal Dense Retrieval for Open-domain Question Answering", "abstract": "In open-domain question answering, a model receives a text question as input\nand searches for the correct answer using a large evidence corpus. The\nretrieval step is especially difficult as typical evidence corpora have\n\\textit{millions} of documents, each of which may or may not have the correct\nanswer to the question. Very recently, dense models have replaced sparse\nmethods as the de facto retrieval method. Rather than focusing on lexical\noverlap to determine similarity, dense methods build an encoding function that\ncaptures semantic similarity by learning from a small collection of\nquestion-answer or question-context pairs. In this paper, we investigate dense\nretrieval models in the context of open-domain question answering across\ndifferent input distributions. To do this, first we introduce an entity-rich\nquestion answering dataset constructed from Wikidata facts and demonstrate\ndense models are unable to generalize to unseen input question distributions.\nSecond, we perform analyses aimed at better understanding the source of the\nproblem and propose new training techniques to improve out-of-domain\nperformance on a wide variety of datasets. We encourage the field to further\ninvestigate the creation of a single, universal dense retrieval model that\ngeneralizes well across all input distributions.", "published": "2021-09-23 00:43:01", "link": "http://arxiv.org/abs/2109.11085v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Can Question Generation Debias Question Answering Models? A Case Study\n  on Question-Context Lexical Overlap", "abstract": "Question answering (QA) models for reading comprehension have been\ndemonstrated to exploit unintended dataset biases such as question-context\nlexical overlap. This hinders QA models from generalizing to under-represented\nsamples such as questions with low lexical overlap. Question generation (QG), a\nmethod for augmenting QA datasets, can be a solution for such performance\ndegradation if QG can properly debias QA datasets. However, we discover that\nrecent neural QG models are biased towards generating questions with high\nlexical overlap, which can amplify the dataset bias. Moreover, our analysis\nreveals that data augmentation with these QG models frequently impairs the\nperformance on questions with low lexical overlap, while improving that on\nquestions with high lexical overlap. To address this problem, we use a synonym\nreplacement-based approach to augment questions with low lexical overlap. We\ndemonstrate that the proposed data augmentation approach is simple yet\neffective to mitigate the degradation problem with only 70k synthetic examples.\nOur data is publicly available at\nhttps://github.com/KazutoshiShinoda/Synonym-Replacement.", "published": "2021-09-23 09:53:54", "link": "http://arxiv.org/abs/2109.11256v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic Knowledge Distillation for Pre-trained Language Models", "abstract": "Knowledge distillation~(KD) has been proved effective for compressing\nlarge-scale pre-trained language models. However, existing methods conduct KD\nstatically, e.g., the student model aligns its output distribution to that of a\nselected teacher model on the pre-defined training dataset. In this paper, we\nexplore whether a dynamic knowledge distillation that empowers the student to\nadjust the learning procedure according to its competency, regarding the\nstudent performance and learning efficiency. We explore the dynamical\nadjustments on three aspects: teacher model adoption, data selection, and KD\nobjective adaptation. Experimental results show that (1) proper selection of\nteacher model can boost the performance of student model; (2) conducting KD\nwith 10% informative instances achieves comparable performance while greatly\naccelerates the training; (3) the student performance can be boosted by\nadjusting the supervision contribution of different alignment objective. We\nfind dynamic knowledge distillation is promising and provide discussions on\npotential future directions towards more efficient KD methods. Our code is\navailable at https://github.com/lancopku/DynamicKD.", "published": "2021-09-23 11:02:24", "link": "http://arxiv.org/abs/2109.11295v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Breaking BERT: Understanding its Vulnerabilities for Named Entity\n  Recognition through Adversarial Attack", "abstract": "Both generic and domain-specific BERT models are widely used for natural\nlanguage processing (NLP) tasks. In this paper we investigate the vulnerability\nof BERT models to variation in input data for Named Entity Recognition (NER)\nthrough adversarial attack. Experimental results show that BERT models are\nvulnerable to variation in the entity context with 20.2 to 45.0% of entities\npredicted completely wrong and another 29.3 to 53.3% of entities predicted\nwrong partially. BERT models seem most vulnerable to changes in the local\ncontext of entities and often a single change is sufficient to fool the model.\nThe domain-specific BERT model trained from scratch (SciBERT) is more\nvulnerable than the original BERT model or the domain-specific model that\nretains the BERT vocabulary (BioBERT). We also find that BERT models are\nparticularly vulnerable to emergent entities. Our results chart the\nvulnerabilities of BERT models for NER and emphasize the importance of further\nresearch into uncovering and reducing these weaknesses.", "published": "2021-09-23 11:47:27", "link": "http://arxiv.org/abs/2109.11308v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Integrating Pattern- and Fact-based Fake News Detection via Model\n  Preference Learning", "abstract": "To defend against fake news, researchers have developed various methods based\non texts. These methods can be grouped as 1) pattern-based methods, which focus\non shared patterns among fake news posts rather than the claim itself; and 2)\nfact-based methods, which retrieve from external sources to verify the claim's\nveracity without considering patterns. The two groups of methods, which have\ndifferent preferences of textual clues, actually play complementary roles in\ndetecting fake news. However, few works consider their integration. In this\npaper, we study the problem of integrating pattern- and fact-based models into\none framework via modeling their preference differences, i.e., making the\npattern- and fact-based models focus on respective preferred parts in a post\nand mitigate interference from non-preferred parts as possible. To this end, we\nbuild a Preference-aware Fake News Detection Framework (Pref-FEND), which\nlearns the respective preferences of pattern- and fact-based models for joint\ndetection. We first design a heterogeneous dynamic graph convolutional network\nto generate the respective preference maps, and then use these maps to guide\nthe joint learning of pattern- and fact-based models for final prediction.\nExperiments on two real-world datasets show that Pref-FEND effectively captures\nmodel preferences and improves the performance of models based on patterns,\nfacts, or both.", "published": "2021-09-23 12:28:55", "link": "http://arxiv.org/abs/2109.11333v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition and Classification on Historical Documents: A\n  Survey", "abstract": "After decades of massive digitisation, an unprecedented amount of historical\ndocuments is available in digital format, along with their machine-readable\ntexts. While this represents a major step forward with respect to preservation\nand accessibility, it also opens up new opportunities in terms of content\nmining and the next fundamental challenge is to develop appropriate\ntechnologies to efficiently search, retrieve and explore information from this\n'big data of the past'. Among semantic indexing opportunities, the recognition\nand classification of named entities are in great demand among humanities\nscholars. Yet, named entity recognition (NER) systems are heavily challenged\nwith diverse, historical and noisy inputs. In this survey, we present the array\nof challenges posed by historical documents to NER, inventory existing\nresources, describe the main approaches deployed so far, and identify key\npriorities for future developments.", "published": "2021-09-23 14:37:40", "link": "http://arxiv.org/abs/2109.11406v1", "categories": ["cs.CL", "cs.LG", "A.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "Finding a Balanced Degree of Automation for Summary Evaluation", "abstract": "Human evaluation for summarization tasks is reliable but brings in issues of\nreproducibility and high costs. Automatic metrics are cheap and reproducible\nbut sometimes poorly correlated with human judgment. In this work, we propose\nflexible semiautomatic to automatic summary evaluation metrics, following the\nPyramid human evaluation method. Semi-automatic Lite2Pyramid retains the\nreusable human-labeled Summary Content Units (SCUs) for reference(s) but\nreplaces the manual work of judging SCUs' presence in system summaries with a\nnatural language inference (NLI) model. Fully automatic Lite3Pyramid further\nsubstitutes SCUs with automatically extracted Semantic Triplet Units (STUs) via\na semantic role labeling (SRL) model. Finally, we propose in-between metrics,\nLite2.xPyramid, where we use a simple regressor to predict how well the STUs\ncan simulate SCUs and retain SCUs that are more difficult to simulate, which\nprovides a smooth transition and balance between automation and manual\nevaluation. Comparing to 15 existing metrics, we evaluate human-metric\ncorrelations on 3 existing meta-evaluation datasets and our newly-collected\nPyrXSum (with 100/10 XSum examples/systems). It shows that Lite2Pyramid\nconsistently has the best summary-level correlations; Lite3Pyramid works better\nthan or comparable to other automatic metrics; Lite2.xPyramid trades off small\ncorrelation drops for larger manual effort reduction, which can reduce costs\nfor future data collection. Our code and data are publicly available at:\nhttps://github.com/ZhangShiyue/Lite2-3Pyramid", "published": "2021-09-23 17:12:35", "link": "http://arxiv.org/abs/2109.11503v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Document Automation Architectures and Technologies: A Survey", "abstract": "This paper surveys the current state of the art in document automation (DA).\nThe objective of DA is to reduce the manual effort during the generation of\ndocuments by automatically integrating input from different sources and\nassembling documents conforming to defined templates. There have been reviews\nof commercial solutions of DA, particularly in the legal domain, but to date\nthere has been no comprehensive review of the academic research on DA\narchitectures and technologies. The current survey of DA reviews the academic\nliterature and provides a clearer definition and characterization of DA and its\nfeatures, identifies state-of-the-art DA architectures and technologies in\nacademic research, and provides ideas that can lead to new research\nopportunities within the DA field in light of recent advances in artificial\nintelligence and deep neural networks.", "published": "2021-09-23 19:12:26", "link": "http://arxiv.org/abs/2109.11603v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.7.0; I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "Joint speaker diarisation and tracking in switching state-space model", "abstract": "Speakers may move around while diarisation is being performed. When a\nmicrophone array is used, the instantaneous locations of where the sounds\noriginated from can be estimated, and previous investigations have shown that\nsuch information can be complementary to speaker embeddings in the diarisation\ntask. However, these approaches often assume that speakers are fairly\nstationary throughout a meeting. This paper relaxes this assumption, by\nproposing to explicitly track the movements of speakers while jointly\nperforming diarisation within a unified model. A state-space model is proposed,\nwhere the hidden state expresses the identity of the current active speaker and\nthe predicted locations of all speakers. The model is implemented as a particle\nfilter. Experiments on a Microsoft rich meeting transcription task show that\nthe proposed joint location tracking and diarisation approach is able to\nperform comparably with other methods that use location information.", "published": "2021-09-23 04:43:58", "link": "http://arxiv.org/abs/2109.11140v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Zero-Shot Information Extraction as a Unified Text-to-Triple Translation", "abstract": "We cast a suite of information extraction tasks into a text-to-triple\ntranslation framework. Instead of solving each task relying on task-specific\ndatasets and models, we formalize the task as a translation between\ntask-specific input text and output triples. By taking the task-specific input,\nwe enable a task-agnostic translation by leveraging the latent knowledge that a\npre-trained language model has about the task. We further demonstrate that a\nsimple pre-training task of predicting which relational information corresponds\nto which input text is an effective way to produce task-specific outputs. This\nenables the zero-shot transfer of our framework to downstream tasks. We study\nthe zero-shot performance of this framework on open information extraction\n(OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and\nfactual probe (Google-RE and T-REx). The model transfers non-trivially to most\ntasks and is often competitive with a fully supervised method without the need\nfor any task-specific training. For instance, we significantly outperform the\nF1 score of the supervised open information extraction without needing to use\nits training set.", "published": "2021-09-23 06:54:19", "link": "http://arxiv.org/abs/2109.11171v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Active Learning for Argument Strength Estimation", "abstract": "High-quality arguments are an essential part of decision-making.\nAutomatically predicting the quality of an argument is a complex task that\nrecently got much attention in argument mining. However, the annotation effort\nfor this task is exceptionally high. Therefore, we test uncertainty-based\nactive learning (AL) methods on two popular argument-strength data sets to\nestimate whether sample-efficient learning can be enabled. Our extensive\nempirical evaluation shows that uncertainty-based acquisition functions can not\nsurpass the accuracy reached with the random acquisition on these data sets.", "published": "2021-09-23 12:05:16", "link": "http://arxiv.org/abs/2109.11319v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WRENCH: A Comprehensive Benchmark for Weak Supervision", "abstract": "Recent Weak Supervision (WS) approaches have had widespread success in easing\nthe bottleneck of labeling training data for machine learning by synthesizing\nlabels from multiple potentially noisy supervision sources. However, proper\nmeasurement and analysis of these approaches remain a challenge. First,\ndatasets used in existing works are often private and/or custom, limiting\nstandardization. Second, WS datasets with the same name and base data often\nvary in terms of the labels and weak supervision sources used, a significant\n\"hidden\" source of evaluation variance. Finally, WS studies often diverge in\nterms of the evaluation protocol and ablations used. To address these problems,\nwe introduce a benchmark platform, WRENCH, for thorough and standardized\nevaluation of WS approaches. It consists of 22 varied real-world datasets for\nclassification and sequence tagging; a range of real, synthetic, and\nprocedurally-generated weak supervision sources; and a modular, extensible\nframework for WS evaluation, including implementations for popular WS methods.\nWe use WRENCH to conduct extensive comparisons over more than 120 method\nvariants to demonstrate its efficacy as a benchmark platform. The code is\navailable at https://github.com/JieyuZ2/wrench.", "published": "2021-09-23 13:47:16", "link": "http://arxiv.org/abs/2109.11377v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CSAGN: Conversational Structure Aware Graph Network for Conversational\n  Semantic Role Labeling", "abstract": "Conversational semantic role labeling (CSRL) is believed to be a crucial step\ntowards dialogue understanding. However, it remains a major challenge for\nexisting CSRL parser to handle conversational structural information. In this\npaper, we present a simple and effective architecture for CSRL which aims to\naddress this problem. Our model is based on a conversational structure-aware\ngraph network which explicitly encodes the speaker dependent information. We\nalso propose a multi-task learning method to further improve the model.\nExperimental results on benchmark datasets show that our model with our\nproposed training objectives significantly outperforms previous baselines.", "published": "2021-09-23 07:47:28", "link": "http://arxiv.org/abs/2109.11541v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simple and Effective Zero-shot Cross-lingual Phoneme Recognition", "abstract": "Recent progress in self-training, self-supervised pretraining and\nunsupervised learning enabled well performing speech recognition systems\nwithout any labeled data. However, in many cases there is labeled data\navailable for related languages which is not utilized by these methods. This\npaper extends previous work on zero-shot cross-lingual transfer learning by\nfine-tuning a multilingually pretrained wav2vec 2.0 model to transcribe unseen\nlanguages. This is done by mapping phonemes of the training languages to the\ntarget language using articulatory features. Experiments show that this simple\nmethod significantly outperforms prior work which introduced task-specific\narchitectures and used only part of a monolingually pretrained model.", "published": "2021-09-23 22:50:32", "link": "http://arxiv.org/abs/2109.11680v1", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Findings of the NLP4IF-2021 Shared Tasks on Fighting the COVID-19\n  Infodemic and Censorship Detection", "abstract": "We present the results and the main findings of the NLP4IF-2021 shared tasks.\nTask 1 focused on fighting the COVID-19 infodemic in social media, and it was\noffered in Arabic, Bulgarian, and English. Given a tweet, it asked to predict\nwhether that tweet contains a verifiable claim, and if so, whether it is likely\nto be false, is of general interest, is likely to be harmful, and is worthy of\nmanual fact-checking; also, whether it is harmful to society, and whether it\nrequires the attention of policy makers. Task~2 focused on censorship\ndetection, and was offered in Chinese. A total of ten teams submitted systems\nfor task 1, and one team participated in task 2; nine teams also submitted a\nsystem description paper. Here, we present the tasks, analyze the results, and\ndiscuss the system submissions and the methods they used. Most submissions\nachieved sizable improvements over several baselines, and the best systems used\npre-trained Transformers and ensembles. The data, the scorers and the\nleaderboards for the tasks are available at\nhttp://gitlab.com/NLP4IF/nlp4if-2021.", "published": "2021-09-23 06:38:03", "link": "http://arxiv.org/abs/2109.12986v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Overview of the CLEF--2021 CheckThat! Lab on Detecting Check-Worthy\n  Claims, Previously Fact-Checked Claims, and Fake News", "abstract": "We describe the fourth edition of the CheckThat! Lab, part of the 2021\nConference and Labs of the Evaluation Forum (CLEF). The lab evaluates\ntechnology supporting tasks related to factuality, and covers Arabic,\nBulgarian, English, Spanish, and Turkish. Task 1 asks to predict which posts in\na Twitter stream are worth fact-checking, focusing on COVID-19 and politics (in\nall five languages). Task 2 asks to determine whether a claim in a tweet can be\nverified using a set of previously fact-checked claims (in Arabic and English).\nTask 3 asks to predict the veracity of a news article and its topical domain\n(in English). The evaluation is based on mean average precision or precision at\nrank k for the ranking tasks, and macro-F1 for the classification tasks. This\nwas the most popular CLEF-2021 lab in terms of team registrations: 132 teams.\nNearly one-third of them participated: 15, 5, and 25 teams submitted official\nruns for tasks 1, 2, and 3, respectively.", "published": "2021-09-23 06:10:36", "link": "http://arxiv.org/abs/2109.12987v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "MARMOT: A Deep Learning Framework for Constructing Multimodal\n  Representations for Vision-and-Language Tasks", "abstract": "Political activity on social media presents a data-rich window into political\nbehavior, but the vast amount of data means that almost all content analyses of\nsocial media require a data labeling step. However, most automated machine\nclassification methods ignore the multimodality of posted content, focusing\neither on text or images. State-of-the-art vision-and-language models are\nunusable for most political science research: they require all observations to\nhave both image and text and require computationally expensive pretraining.\nThis paper proposes a novel vision-and-language framework called multimodal\nrepresentations using modality translation (MARMOT). MARMOT presents two\nmethodological contributions: it can construct representations for observations\nmissing image or text, and it replaces the computationally expensive\npretraining with modality translation. MARMOT outperforms an ensemble text-only\nclassifier in 19 of 20 categories in multilabel classifications of tweets\nreporting election incidents during the 2016 U.S. general election. Moreover,\nMARMOT shows significant improvements over the results of benchmark multimodal\nmodels on the Hateful Memes dataset, improving the best result set by\nVisualBERT in terms of accuracy from 0.6473 to 0.6760 and area under the\nreceiver operating characteristic curve (AUC) from 0.7141 to 0.7530.", "published": "2021-09-23 17:48:48", "link": "http://arxiv.org/abs/2109.11526v1", "categories": ["cs.CV", "cs.CL", "cs.CY", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Masks Fusion with Multi-Target Learning For Speech Enhancement", "abstract": "Recently, deep neural network (DNN) based time-frequency (T-F) mask\nestimation has shown remarkable effectiveness for speech enhancement.\nTypically, a single T-F mask is first estimated based on DNN and then used to\nmask the spectrogram of noisy speech in an order to suppress the noise. This\nwork proposes a multi-mask fusion method for speech enhancement. It\nsimultaneously estimates two complementary masks, e.g., ideal ratio mask (IRM)\nand target binary mask (TBM), and then fuse them to obtain a refined mask for\nspeech enhancement. The advantage of the new method is twofold. First,\nsimultaneously estimating multiple complementary masks brings benefit endowed\nby multi-target learning. Second, multi-mask fusion can exploit the\ncomplementarity of multiple masks to boost the performance of speech\nenhancement. Experimental results show that the proposed method can achieve\nsignificant PESQ improvement and reduce the recognition error rate of back-end\nover traditional masking-based methods. Code is available at\nhttps://github.com/lc-zhou/mask-fusion.", "published": "2021-09-23 06:44:56", "link": "http://arxiv.org/abs/2109.11164v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Lightweight dynamic filter for keyword spotting", "abstract": "Keyword Spotting (KWS) from speech signals is widely applied to perform fully\nhands-free speech recognition. The KWS network is designed as a small-footprint\nmodel so it can continuously be active. Recent efforts have explored dynamic\nfilter-based models in deep learning frameworks to enhance the system's\nrobustness or accuracy. However, as a dynamic filter framework requires high\ncomputational costs, the implementation is limited to the computational\ncondition of the device. In this paper, we propose a lightweight dynamic filter\nto improve the performance of KWS. Our proposed model divides the dynamic\nfilter into two branches to reduce computational complexity: pixel level and\ninstance level. The proposed lightweight dynamic filter is applied to the front\nend of KWS to enhance the separability of the input data. The experimental\nresults show that our model is robustly working on unseen noise and small\ntraining data environments by using a small computational resource.", "published": "2021-09-23 06:47:09", "link": "http://arxiv.org/abs/2109.11165v4", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Unet-TTS: Improving Unseen Speaker and Style Transfer in One-shot Voice\n  Cloning", "abstract": "One-shot voice cloning aims to transform speaker voice and speaking style in\nspeech synthesized from a text-to-speech (TTS) system, where only a shot\nrecording from the target reference speech can be used. Out-of-domain transfer\nis still a challenging task, and one important aspect that impacts the accuracy\nand similarity of synthetic speech is the conditional representations carrying\nspeaker or style cues extracted from the limited references. In this paper, we\npresent a novel one-shot voice cloning algorithm called Unet-TTS that has good\ngeneralization ability for unseen speakers and styles. Based on a\nskip-connected U-net structure, the new model can efficiently discover\nspeaker-level and utterance-level spectral feature details from the reference\naudio, enabling accurate inference of complex acoustic characteristics as well\nas imitation of speaking styles into the synthetic speech. According to both\nsubjective and objective evaluations of similarity, the new model outperforms\nboth speaker embedding and unsupervised style modeling (GST) approaches on an\nunseen emotional corpus.", "published": "2021-09-23 03:04:34", "link": "http://arxiv.org/abs/2109.11115v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ChannelAugment: Improving generalization of multi-channel ASR by\n  training with input channel randomization", "abstract": "End-to-end (E2E) multi-channel ASR systems show state-of-the-art performance\nin far-field ASR tasks by joint training of a multi-channel front-end along\nwith the ASR model. The main limitation of such systems is that they are\nusually trained with data from a fixed array geometry, which can lead to\ndegradation in accuracy when a different array is used in testing. This makes\nit challenging to deploy these systems in practice, as it is costly to retrain\nand deploy different models for various array configurations. To address this,\nwe present a simple and effective data augmentation technique, which is based\non randomly dropping channels in the multi-channel audio input during training,\nin order to improve the robustness to various array configurations at test\ntime. We call this technique ChannelAugment, in contrast to SpecAugment (SA)\nwhich drops time and/or frequency components of a single channel input audio.\nWe apply ChannelAugment to the Spatial Filtering (SF) and Minimum Variance\nDistortionless Response (MVDR) neural beamforming approaches. For SF, we\nobserve 10.6% WER improvement across various array configurations employing\ndifferent numbers of microphones. For MVDR, we achieve a 74% reduction in\ntraining time without causing degradation of recognition accuracy.", "published": "2021-09-23 09:13:47", "link": "http://arxiv.org/abs/2109.11225v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Scenario Aware Speech Recognition: Advancements for Apollo Fearless\n  Steps & CHiME-4 Corpora", "abstract": "In this study, we propose to investigate triplet loss for the purpose of an\nalternative feature representation for ASR. We consider a general non-semantic\nspeech representation, which is trained with a self-supervised criteria based\non triplet loss called TRILL, for acoustic modeling to represent the acoustic\ncharacteristics of each audio. This strategy is then applied to the CHiME-4\ncorpus and CRSS-UTDallas Fearless Steps Corpus, with emphasis on the 100-hour\nchallenge corpus which consists of 5 selected NASA Apollo-11 channels. An\nanalysis of the extracted embeddings provides the foundation needed to\ncharacterize training utterances into distinct groups based on acoustic\ndistinguishing properties. Moreover, we also demonstrate that triplet-loss\nbased embedding performs better than i-Vector in acoustic modeling, confirming\nthat the triplet loss is more effective than a speaker feature. With additional\ntechniques such as pronunciation and silence probability modeling, plus\nmulti-style training, we achieve a +5.42% and +3.18% relative WER improvement\nfor the development and evaluation sets of the Fearless Steps Corpus. To\nexplore generalization, we further test the same technique on the 1 channel\ntrack of CHiME-4 and observe a +11.90% relative WER improvement for real test\ndata.", "published": "2021-09-23 00:43:32", "link": "http://arxiv.org/abs/2109.11086v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unified Signal Compression Using a GAN with Iterative Latent\n  Representation Optimization", "abstract": "We propose a unified signal compression framework that uses a generative\nadversarial network (GAN) to compress heterogeneous signals. The compressed\nsignal is represented as a latent vector and fed into a generator network that\nis trained to produce high quality realistic signals that minimize a target\nobjective function. To efficiently quantize the compressed signal,\nnon-uniformly quantized optimal latent vectors are identified by iterative\nback-propagation with alternating direction method of multipliers (ADMM)\noptimization performed for each iteration. The performance of the proposed\nsignal compression method is assessed using multiple metrics including PSNR and\nMS-SSIM for image compression and also PESR, Kaldi, LSTM, and MLP performance\nfor speech compression. Test results show that the proposed work outperforms\nrecent state-of-the-art hand-crafted and deep learning-based signal compression\nmethods.", "published": "2021-09-23 06:50:09", "link": "http://arxiv.org/abs/2109.11168v1", "categories": ["eess.SP", "eess.AS", "eess.IV"], "primary_category": "eess.SP"}
{"title": "Physics-informed neural networks for one-dimensional sound field\n  predictions with parameterized sources and impedance boundaries", "abstract": "Realistic sound is essential in virtual environments, such as computer games\nand mixed reality. Efficient and accurate numerical methods for pre-calculating\nacoustics have been developed over the last decade; however, pre-calculating\nacoustics makes handling dynamic scenes with moving sources challenging,\nrequiring intractable memory storage. A physics-informed neural network (PINN)\nmethod in 1D is presented, which learns a compact and efficient surrogate model\nwith parameterized moving Gaussian sources and impedance boundaries, and\nsatisfies a system of coupled equations. The model shows relative mean errors\nbelow 2%/0.2 dB and proposes a first step in developing PINNs for realistic 3D\nscenes.", "published": "2021-09-23 11:59:26", "link": "http://arxiv.org/abs/2109.11313v5", "categories": ["cs.SD", "eess.AS", "physics.comp-ph"], "primary_category": "cs.SD"}
{"title": "Implementation of interactive tools for investigating fundamental\n  frequency response of voiced sounds to auditory stimulation", "abstract": "We introduced a measurement procedure for the involuntary response of voice\nfundamental-frequency to frequency modulated auditory stimulation. This\ninvoluntary response plays an essential role in voice fundamental frequency\ncontrol while less investigated due to technical difficulties. This article\nintroduces an interactive and real-time tool for investigating this response\nand supporting tools adopting our new measurement method. The method enables\nsimultaneous measurement of multiple system properties based on a novel set of\nextended time-stretched pulses combined with orthogonalization. We made MATLAB\nimplementation of these tools available as an open-source repository. This\narticle also provides the detailed measurement procedure using the interactive\ntool followed by offline measurement tools for conducting subjective\nexperiments and statistical analyses. It also provides technical descriptions\nof constituent signal processing subsystems as appendices. This application\nserves as an example for adopting our method to biological system analysis.", "published": "2021-09-23 18:55:54", "link": "http://arxiv.org/abs/2109.11594v1", "categories": ["cs.SD", "cs.HC", "eess.AS", "eess.SP", "91E45, 92-04, 94A11"], "primary_category": "cs.SD"}
{"title": "Turn-to-Diarize: Online Speaker Diarization Constrained by Transformer\n  Transducer Speaker Turn Detection", "abstract": "In this paper, we present a novel speaker diarization system for streaming\non-device applications. In this system, we use a transformer transducer to\ndetect the speaker turns, represent each speaker turn by a speaker embedding,\nthen cluster these embeddings with constraints from the detected speaker turns.\nCompared with conventional clustering-based diarization systems, our system\nlargely reduces the computational cost of clustering due to the sparsity of\nspeaker turns. Unlike other supervised speaker diarization systems which\nrequire annotations of time-stamped speaker labels for training, our system\nonly requires including speaker turn tokens during the transcribing process,\nwhich largely reduces the human efforts involved in data collection.", "published": "2021-09-23 20:47:57", "link": "http://arxiv.org/abs/2109.11641v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
