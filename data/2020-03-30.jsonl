{"title": "Learning Contextualized Sentence Representations for Document-Level\n  Neural Machine Translation", "abstract": "Document-level machine translation incorporates inter-sentential dependencies\ninto the translation of a source sentence. In this paper, we propose a new\nframework to model cross-sentence dependencies by training neural machine\ntranslation (NMT) to predict both the target translation and surrounding\nsentences of a source sentence. By enforcing the NMT model to predict source\ncontext, we want the model to learn \"contextualized\" source sentence\nrepresentations that capture document-level dependencies on the source side. We\nfurther propose two different methods to learn and integrate such\ncontextualized sentence embeddings into NMT: a joint training method that\njointly trains an NMT model with the source context prediction model and a\npre-training & fine-tuning method that pretrains the source context prediction\nmodel on a large-scale monolingual document corpus and then fine-tunes it with\nthe NMT model. Experiments on Chinese-English and English-German translation\nshow that both methods can substantially improve the translation quality over a\nstrong document-level Transformer baseline.", "published": "2020-03-30 03:38:01", "link": "http://arxiv.org/abs/2003.13205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Language Impact in Bilingual Approaches for Computational\n  Language Documentation", "abstract": "For endangered languages, data collection campaigns have to accommodate the\nchallenge that many of them are from oral tradition, and producing\ntranscriptions is costly. Therefore, it is fundamental to translate them into a\nwidely spoken language to ensure interpretability of the recordings. In this\npaper we investigate how the choice of translation language affects the\nposterior documentation work and potential automatic approaches which will work\non top of the produced bilingual corpus. For answering this question, we use\nthe MaSS multilingual speech corpus (Boito et al., 2020) for creating 56\nbilingual pairs that we apply to the task of low-resource unsupervised word\nsegmentation and alignment. Our results highlight that the choice of language\nfor translation influences the word segmentation performance, and that\ndifferent lexicons are learned by using different aligned translations. Lastly,\nthis paper proposes a hybrid approach for bilingual word segmentation,\ncombining boundary clues extracted from a non-parametric Bayesian model\n(Goldwater et al., 2009a) with the attentional word segmentation neural model\nfrom Godard et al. (2018). Our results suggest that incorporating these clues\ninto the neural models' input representation increases their translation and\nalignment quality, specially for challenging language pairs.", "published": "2020-03-30 10:30:34", "link": "http://arxiv.org/abs/2003.13325v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions\n  for Training Neural Conversation Models", "abstract": "Fully data driven Chatbots for non-goal oriented dialogues are known to\nsuffer from inconsistent behaviour across their turns, stemming from a general\ndifficulty in controlling parameters like their assumed background personality\nand knowledge of facts. One reason for this is the relative lack of labeled\ndata from which personality consistency and fact usage could be learned\ntogether with dialogue behaviour. To address this, we introduce a new labeled\ndialogue dataset in the domain of movie discussions, where every dialogue is\nbased on pre-specified facts and opinions. We thoroughly validate the collected\ndialogue for adherence of the participants to their given fact and opinion\nprofile, and find that the general quality in this respect is high. This\nprocess also gives us an additional layer of annotation that is potentially\nuseful for training models. We introduce as a baseline an end-to-end trained\nself-attention decoder model trained on this data and show that it is able to\ngenerate opinionated responses that are judged to be natural and knowledgeable\nand show attentiveness.", "published": "2020-03-30 11:17:31", "link": "http://arxiv.org/abs/2003.13342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions\n  in Medical Discharge Reports", "abstract": "Bayesian modelling and statistical text analysis rely on informed probability\npriors to encourage good solutions. This paper empirically analyses whether\ntext in medical discharge reports follow Zipf's law, a commonly assumed\nstatistical property of language where word frequency follows a discrete power\nlaw distribution. We examined 20,000 medical discharge reports from the\nMIMIC-III dataset. Methods included splitting the discharge reports into\ntokens, counting token frequency, fitting power law distributions to the data,\nand testing whether alternative distributions--lognormal, exponential,\nstretched exponential, and truncated power law--provided superior fits to the\ndata. Results show that discharge reports are best fit by the truncated power\nlaw and lognormal distributions. Our findings suggest that Bayesian modelling\nand statistical text analysis of discharge report text would benefit from using\ntruncated power law and lognormal probability priors.", "published": "2020-03-30 11:34:53", "link": "http://arxiv.org/abs/2003.13352v3", "categories": ["cs.CL", "J.3; I.2.7; G.3"], "primary_category": "cs.CL"}
{"title": "European Language Grid: An Overview", "abstract": "With 24 official EU and many additional languages, multilingualism in Europe\nand an inclusive Digital Single Market can only be enabled through Language\nTechnologies (LTs). European LT business is dominated by hundreds of SMEs and a\nfew large players. Many are world-class, with technologies that outperform the\nglobal players. However, European LT business is also fragmented, by nation\nstates, languages, verticals and sectors, significantly holding back its\nimpact. The European Language Grid (ELG) project addresses this fragmentation\nby establishing the ELG as the primary platform for LT in Europe. The ELG is a\nscalable cloud platform, providing, in an easy-to-integrate way, access to\nhundreds of commercial and non-commercial LTs for all European languages,\nincluding running tools and services as well as data sets and resources. Once\nfully operational, it will enable the commercial and non-commercial European LT\ncommunity to deposit and upload their technologies and data sets into the ELG,\nto deploy them through the grid, and to connect with other resources. The ELG\nwill boost the Multilingual Digital Single Market towards a thriving European\nLT community, creating new jobs and opportunities. Furthermore, the ELG project\norganises two open calls for up to 20 pilot projects. It also sets up 32\nNational Competence Centres (NCCs) and the European LT Council (LTC) for\noutreach and coordination purposes.", "published": "2020-03-30 15:25:34", "link": "http://arxiv.org/abs/2003.13551v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Span-based discontinuous constituency parsing: a family of exact\n  chart-based algorithms with time complexities from O(n^6) down to O(n^3)", "abstract": "We introduce a novel chart-based algorithm for span-based parsing of\ndiscontinuous constituency trees of block degree two, including ill-nested\nstructures. In particular, we show that we can build variants of our parser\nwith smaller search spaces and time complexities ranging from $\\mathcal O(n^6)$\ndown to $\\mathcal O(n^3)$. The cubic time variant covers 98\\% of constituents\nobserved in linguistic treebanks while having the same complexity as continuous\nconstituency parsers. We evaluate our approach on German and English treebanks\n(Negra, Tiger and Discontinuous PTB) and report state-of-the-art results in the\nfully supervised setting. We also experiment with pre-trained word embeddings\nand \\bert{}-based neural networks.", "published": "2020-03-30 19:54:20", "link": "http://arxiv.org/abs/2003.13785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low resource language dataset creation, curation and classification:\n  Setswana and Sepedi -- Extended Abstract", "abstract": "The recent advances in Natural Language Processing have only been a boon for\nwell represented languages, negating research in lesser known global languages.\nThis is in part due to the availability of curated data and research resources.\nOne of the current challenges concerning low-resourced languages are clear\nguidelines on the collection, curation and preparation of datasets for\ndifferent use-cases. In this work, we take on the task of creating two datasets\nthat are focused on news headlines (i.e short text) for Setswana and Sepedi and\nthe creation of a news topic classification task from these datasets. In this\nstudy, we document our work, propose baselines for classification, and\ninvestigate an approach on data augmentation better suited to low-resourced\nlanguages in order to improve the performance of the classifiers.", "published": "2020-03-30 18:03:15", "link": "http://arxiv.org/abs/2004.13842v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining", "abstract": "Multi-modal pretraining for learning high-level multi-modal representation is\na further step towards deep learning and artificial intelligence. In this work,\nwe propose a novel model, namely InterBERT (BERT for Interaction), which is the\nfirst model of our series of multimodal pretraining methods M6\n(MultiModality-to-MultiModality Multitask Mega-transformer). The model owns\nstrong capability of modeling interaction between the information flows of\ndifferent modalities. The single-stream interaction module is capable of\neffectively processing information of multiple modalilties, and the two-stream\nmodule on top preserves the independence of each modality to avoid performance\ndowngrade in single-modal tasks. We pretrain the model with three pretraining\ntasks, including masked segment modeling (MSM), masked region modeling (MRM)\nand image-text matching (ITM); and finetune the model on a series of\nvision-and-language downstream tasks. Experimental results demonstrate that\nInterBERT outperforms a series of strong baselines, including the most recent\nmulti-modal pretraining methods, and the analysis shows that MSM and MRM are\neffective for pretraining and our method can achieve performances comparable to\nBERT in single-modal tasks. Besides, we propose a large-scale dataset for\nmulti-modal pretraining in Chinese, and we develop the Chinese InterBERT which\nis the first Chinese multi-modal pretrained model. We pretrain the Chinese\nInterBERT on our proposed dataset of 3.1M image-text pairs from the mobile\nTaobao, the largest Chinese e-commerce platform. We finetune the model for\ntext-based image retrieval, and recently we deployed the model online for\ntopic-based recommendation.", "published": "2020-03-30 03:13:22", "link": "http://arxiv.org/abs/2003.13198v4", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "AliCoCo: Alibaba E-commerce Cognitive Concept Net", "abstract": "One of the ultimate goals of e-commerce platforms is to satisfy various\nshopping needs for their customers. Much efforts are devoted to creating\ntaxonomies or ontologies in e-commerce towards this goal. However, user needs\nin e-commerce are still not well defined, and none of the existing ontologies\nhas the enough depth and breadth for universal user needs understanding. The\nsemantic gap in-between prevents shopping experience from being more\nintelligent. In this paper, we propose to construct a large-scale e-commerce\ncognitive concept net named \"AliCoCo\", which is practiced in Alibaba, the\nlargest Chinese e-commerce platform in the world. We formally define user needs\nin e-commerce, then conceptualize them as nodes in the net. We present details\non how AliCoCo is constructed semi-automatically and its successful, ongoing\nand potential applications in e-commerce.", "published": "2020-03-30 05:42:03", "link": "http://arxiv.org/abs/2003.13230v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Making Metadata Fit for Next Generation Language Technology Platforms:\n  The Metadata Schema of the European Language Grid", "abstract": "The current scientific and technological landscape is characterised by the\nincreasing availability of data resources and processing tools and services. In\nthis setting, metadata have emerged as a key factor facilitating management,\nsharing and usage of such digital assets. In this paper we present ELG-SHARE, a\nrich metadata schema catering for the description of Language Resources and\nTechnologies (processing and generation services and tools, models, corpora,\nterm lists, etc.), as well as related entities (e.g., organizations, projects,\nsupporting documents, etc.). The schema powers the European Language Grid\nplatform that aims to be the primary hub and marketplace for industry-relevant\nLanguage Technology in Europe. ELG-SHARE has been based on various metadata\nschemas, vocabularies, and ontologies, as well as related recommendations and\nguidelines.", "published": "2020-03-30 06:46:35", "link": "http://arxiv.org/abs/2003.13236v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "How human judgment impairs automated deception detection performance", "abstract": "Background: Deception detection is a prevalent problem for security\npractitioners. With a need for more large-scale approaches, automated methods\nusing machine learning have gained traction. However, detection performance\nstill implies considerable error rates. Findings from other domains suggest\nthat hybrid human-machine integrations could offer a viable path in deception\ndetection tasks. Method: We collected a corpus of truthful and deceptive\nanswers about participants' autobiographical intentions (n=1640) and tested\nwhether a combination of supervised machine learning and human judgment could\nimprove deception detection accuracy. Human judges were presented with the\noutcome of the automated credibility judgment of truthful and deceptive\nstatements. They could either fully overrule it (hybrid-overrule condition) or\nadjust it within a given boundary (hybrid-adjust condition). Results: The data\nsuggest that in neither of the hybrid conditions did the human judgment add a\nmeaningful contribution. Machine learning in isolation identified truth-tellers\nand liars with an overall accuracy of 69%. Human involvement through\nhybrid-overrule decisions brought the accuracy back to the chance level. The\nhybrid-adjust condition did not deception detection performance. The\ndecision-making strategies of humans suggest that the truth bias - the tendency\nto assume the other is telling the truth - could explain the detrimental\neffect. Conclusion: The current study does not support the notion that humans\ncan meaningfully add to the deception detection performance of a machine\nlearning system.", "published": "2020-03-30 10:06:36", "link": "http://arxiv.org/abs/2003.13316v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "QRMine: A python package for triangulation in Grounded Theory", "abstract": "Grounded theory (GT) is a qualitative research method for building theory\ngrounded in data. GT uses textual and numeric data and follows various stages\nof coding or tagging data for sense-making, such as open coding and selective\ncoding. Machine Learning (ML) techniques, including natural language processing\n(NLP), can assist the researchers in the coding process. Triangulation is the\nprocess of combining various types of data. ML can facilitate deriving insights\nfrom numerical data for corroborating findings from the textual interview\ntranscripts. We present an open-source python package (QRMine) that\nencapsulates various ML and NLP libraries to support coding and triangulation\nin GT. QRMine enables researchers to use these methods on their data with\nminimal effort. Researchers can install QRMine from the python package index\n(PyPI) and can contribute to its development. We believe that the concept of\ncomputational triangulation will make GT relevant in the realm of big data.", "published": "2020-03-30 14:45:51", "link": "http://arxiv.org/abs/2003.13519v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AriEL: volume coding for sentence generation", "abstract": "Mapping sequences of discrete data to a point in a continuous space makes it\ndifficult to retrieve those sequences via random sampling. Mapping the input to\na volume would make it easier to retrieve at test time, and that's the strategy\nfollowed by the family of approaches based on Variational Autoencoder. However\nthe fact that they are at the same time optimizing for prediction and for\nsmoothness of representation, forces them to trade-off between the two. We\nimprove on the performance of some of the standard methods in deep learning to\ngenerate sentences by uniformly sampling a continuous space. We do it by\nproposing AriEL, that constructs volumes in a continuous space, without the\nneed of encouraging the creation of volumes through the loss function. We first\nbenchmark on a toy grammar, that allows to automatically evaluate the language\nlearned and generated by the models. Then, we benchmark on a real dataset of\nhuman dialogues. Our results indicate that the random access to the stored\ninformation is dramatically improved, and our method AriEL is able to generate\na wider variety of correct language by randomly sampling the latent space. VAE\nfollows in performance for the toy dataset while, AE and Transformer follow for\nthe real dataset. This partially supports to the hypothesis that encoding\ninformation into volumes instead of into points, can lead to improved retrieval\nof learned information with random sampling. This can lead to better generators\nand we also discuss potential disadvantages.", "published": "2020-03-30 16:30:47", "link": "http://arxiv.org/abs/2003.13600v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analysing the Extent of Misinformation in Cancer Related Tweets", "abstract": "Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.", "published": "2020-03-30 17:44:42", "link": "http://arxiv.org/abs/2003.13657v3", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Amharic Abstractive Text Summarization", "abstract": "Text Summarization is the task of condensing long text into just a handful of\nsentences. Many approaches have been proposed for this task, some of the very\nfirst were building statistical models (Extractive Methods) capable of\nselecting important words and copying them to the output, however these models\nlacked the ability to paraphrase sentences, as they simply select important\nwords without actually understanding their contexts nor understanding their\nmeaning, here comes the use of Deep Learning based architectures (Abstractive\nMethods), which effectively tries to understand the meaning of sentences to\nbuild meaningful summaries. In this work we discuss one of these new novel\napproaches which combines curriculum learning with Deep Learning, this model is\ncalled Scheduled Sampling. We apply this work to one of the most widely spoken\nAfrican languages which is the Amharic Language, as we try to enrich the\nAfrican NLP community with top-notch Deep Learning architectures.", "published": "2020-03-30 18:15:32", "link": "http://arxiv.org/abs/2003.13721v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Transformer for Unsupervised Parsing", "abstract": "The underlying structure of natural language is hierarchical; words combine\ninto phrases, which in turn form clauses. An awareness of this hierarchical\nstructure can aid machine learning models in performing many linguistic tasks.\nHowever, most such models just process text sequentially and there is no bias\ntowards learning hierarchical structure encoded into their architecture. In\nthis paper, we extend the recent transformer model (Vaswani et al., 2017) by\nenabling it to learn hierarchical representations. To achieve this, we adapt\nthe ordering mechanism introduced in Shen et al., 2018, to the self-attention\nmodule of the transformer architecture. We train our new model on language\nmodelling and then apply it to the task of unsupervised parsing. We achieve\nreasonable results on the freely available subset of the WSJ10 dataset with an\nF1-score of about 50%.", "published": "2020-03-30 22:07:22", "link": "http://arxiv.org/abs/2003.13841v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TREC CAsT 2019: The Conversational Assistance Track Overview", "abstract": "The Conversational Assistance Track (CAsT) is a new track for TREC 2019 to\nfacilitate Conversational Information Seeking (CIS) research and to create a\nlarge-scale reusable test collection for conversational search systems. The\ndocument corpus is 38,426,252 passages from the TREC Complex Answer Retrieval\n(CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty\ninformation seeking dialogues (30 train, 50 test) are an average of 9 to 10\nquestions long. Relevance assessments are provided for 30 training topics and\n20 test topics. This year 21 groups submitted a total of 65 runs using varying\nmethods for conversational query understanding and ranking. Methods include\ntraditional retrieval based methods, feature based learning-to-rank, neural\nmodels, and knowledge enhanced methods. A common theme through the runs is the\nuse of BERT-based neural reranking methods. Leading methods also employed\ndocument expansion, conversational query expansion, and generative language\nmodels for conversational query rewriting (GPT-2). The results show a gap\nbetween automatic systems and those using the manually resolved utterances,\nwith a 35% relative improvement of manual rewrites over the best automatic\nsystem.", "published": "2020-03-30 16:58:04", "link": "http://arxiv.org/abs/2003.13624v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Sign Language Transformers: Joint End-to-end Sign Language Recognition\n  and Translation", "abstract": "Prior work on Sign Language Translation has shown that having a mid-level\nsign gloss representation (effectively recognizing the individual signs)\nimproves the translation performance drastically. In fact, the current\nstate-of-the-art in translation requires gloss level tokenization in order to\nwork. We introduce a novel transformer based architecture that jointly learns\nContinuous Sign Language Recognition and Translation while being trainable in\nan end-to-end manner. This is achieved by using a Connectionist Temporal\nClassification (CTC) loss to bind the recognition and translation problems into\na single unified architecture. This joint approach does not require any\nground-truth timing information, simultaneously solving two co-dependant\nsequence-to-sequence learning problems and leads to significant performance\ngains.\n  We evaluate the recognition and translation performances of our approaches on\nthe challenging RWTH-PHOENIX-Weather-2014T (PHOENIX14T) dataset. We report\nstate-of-the-art sign language recognition and translation results achieved by\nour Sign Language Transformers. Our translation networks outperform both sign\nvideo to spoken language and gloss to spoken language translation models, in\nsome cases more than doubling the performance (9.58 vs. 21.80 BLEU-4 Score). We\nalso share new baseline translation results using transformer networks for\nseveral other text-to-text sign language translation tasks.", "published": "2020-03-30 21:35:09", "link": "http://arxiv.org/abs/2003.13830v1", "categories": ["cs.CV", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The European Language Technology Landscape in 2020: Language-Centric and\n  Human-Centric AI for Cross-Cultural Communication in Multilingual Europe", "abstract": "Multilingualism is a cultural cornerstone of Europe and firmly anchored in\nthe European treaties including full language equality. However, language\nbarriers impacting business, cross-lingual and cross-cultural communication are\nstill omnipresent. Language Technologies (LTs) are a powerful means to break\ndown these barriers. While the last decade has seen various initiatives that\ncreated a multitude of approaches and technologies tailored to Europe's\nspecific needs, there is still an immense level of fragmentation. At the same\ntime, AI has become an increasingly important concept in the European\nInformation and Communication Technology area. For a few years now, AI,\nincluding many opportunities, synergies but also misconceptions, has been\novershadowing every other topic. We present an overview of the European LT\nlandscape, describing funding programmes, activities, actions and challenges in\nthe different countries with regard to LT, including the current state of play\nin industry and the LT market. We present a brief overview of the main\nLT-related activities on the EU level in the last ten years and develop\nstrategic guidance with regard to four key dimensions.", "published": "2020-03-30 21:42:45", "link": "http://arxiv.org/abs/2003.13833v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Pruned Wasserstein Index Generation Model and wigpy Package", "abstract": "Recent proposal of Wasserstein Index Generation model (WIG) has shown a new\ndirection for automatically generating indices. However, it is challenging in\npractice to fit large datasets for two reasons. First, the Sinkhorn distance is\nnotoriously expensive to compute and suffers from dimensionality severely.\nSecond, it requires to compute a full $N\\times N$ matrix to be fit into memory,\nwhere $N$ is the dimension of vocabulary. When the dimensionality is too large,\nit is even impossible to compute at all. I hereby propose a Lasso-based\nshrinkage method to reduce dimensionality for the vocabulary as a\npre-processing step prior to fitting the WIG model. After we get the word\nembedding from Word2Vec model, we could cluster these high-dimensional vectors\nby $k$-means clustering, and pick most frequent tokens within each cluster to\nform the \"base vocabulary\". Non-base tokens are then regressed on the vectors\nof base token to get a transformation weight and we could thus represent the\nwhole vocabulary by only the \"base tokens\". This variant, called pruned WIG\n(pWIG), will enable us to shrink vocabulary dimension at will but could still\nachieve high accuracy. I also provide a \\textit{wigpy} module in Python to\ncarry out computation in both flavor. Application to Economic Policy\nUncertainty (EPU) index is showcased as comparison with existing methods of\ngenerating time-series sentiment indices.", "published": "2020-03-30 18:26:24", "link": "http://arxiv.org/abs/2004.00999v3", "categories": ["cs.LG", "cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.LG"}
{"title": "Deep Residual Neural Networks for Image in Speech Steganography", "abstract": "Steganography is the art of hiding a secret message inside a publicly visible\ncarrier message. Ideally, it is done without modifying the carrier, and with\nminimal loss of information in the secret message. Recently, various deep\nlearning based approaches to steganography have been applied to different\nmessage types. We propose a deep learning based technique to hide a source RGB\nimage message inside finite length speech segments without perceptual loss. To\nachieve this, we train three neural networks; an encoding network to hide the\nmessage in the carrier, a decoding network to reconstruct the message from the\ncarrier and an additional image enhancer network to further improve the\nreconstructed message. We also discuss future improvements to the algorithm\nproposed.", "published": "2020-03-30 04:49:45", "link": "http://arxiv.org/abs/2003.13217v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "VaPar Synth -- A Variational Parametric Model for Audio Synthesis", "abstract": "With the advent of data-driven statistical modeling and abundant computing\npower, researchers are turning increasingly to deep learning for audio\nsynthesis. These methods try to model audio signals directly in the time or\nfrequency domain. In the interest of more flexible control over the generated\nsound, it could be more useful to work with a parametric representation of the\nsignal which corresponds more directly to the musical attributes such as pitch,\ndynamics and timbre. We present VaPar Synth - a Variational Parametric\nSynthesizer which utilizes a conditional variational autoencoder (CVAE) trained\non a suitable parametric representation. We demonstrate our proposed model's\ncapabilities via the reconstruction and generation of instrumental tones with\nflexible control over their pitch.", "published": "2020-03-30 16:05:47", "link": "http://arxiv.org/abs/2004.00001v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
