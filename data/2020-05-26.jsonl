{"title": "Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational\n  Machine Reading", "abstract": "The goal of conversational machine reading is to answer user questions given\na knowledge base text which may require asking clarification questions.\nExisting approaches are limited in their decision making due to struggles in\nextracting question-related rules and reasoning about them. In this paper, we\npresent a new framework of conversational machine reading that comprises a\nnovel Explicit Memory Tracker (EMT) to track whether conditions listed in the\nrule text have already been satisfied to make a decision. Moreover, our\nframework generates clarification questions by adopting a coarse-to-fine\nreasoning strategy, utilizing sentence-level entailment scores to weight\ntoken-level distributions. On the ShARC benchmark (blind, held-out) testset,\nEMT achieves new state-of-the-art results of 74.6% micro-averaged decision\naccuracy and 49.5 BLEU4. We also show that EMT is more interpretable by\nvisualizing the entailment-oriented reasoning process as the conversation\nflows. Code and models are released at\nhttps://github.com/Yifan-Gao/explicit_memory_tracker.", "published": "2020-05-26 02:21:31", "link": "http://arxiv.org/abs/2005.12484v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParsBERT: Transformer-based Model for Persian Language Understanding", "abstract": "The surge of pre-trained language models has begun a new era in the field of\nNatural Language Processing (NLP) by allowing us to build powerful language\nmodels. Among these models, Transformer-based models such as BERT have become\nincreasingly popular due to their state-of-the-art performance. However, these\nmodels are usually focused on English, leaving other languages to multilingual\nmodels with limited resources. This paper proposes a monolingual BERT for the\nPersian language (ParsBERT), which shows its state-of-the-art performance\ncompared to other architectures and multilingual models. Also, since the amount\nof data available for NLP tasks in Persian is very restricted, a massive\ndataset for different NLP tasks as well as pre-training the model is composed.\nParsBERT obtains higher scores in all datasets, including existing ones as well\nas composed ones and improves the state-of-the-art performance by outperforming\nboth multilingual BERT and other prior works in Sentiment Analysis, Text\nClassification and Named Entity Recognition tasks.", "published": "2020-05-26 05:05:32", "link": "http://arxiv.org/abs/2005.12515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Are People Asking About COVID-19? A Question Classification Dataset", "abstract": "We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources,\nwhich we annotate into 15 question categories and 207 question clusters. The\nmost common questions in our dataset asked about transmission, prevention, and\nsocietal effects of COVID, and we found that many questions that appeared in\nmultiple sources were not answered by any FAQ websites of reputable\norganizations such as the CDC and FDA. We post our dataset publicly at\nhttps://github.com/JerryWeiAI/COVID-Q. For classifying questions into 15\ncategories, a BERT baseline scored 58.1% accuracy when trained on 20 examples\nper category, and for a question clustering task, a BERT + triplet loss\nbaseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct\nuse in developing applied systems or as a domain-specific resource for model\nevaluation.", "published": "2020-05-26 05:41:58", "link": "http://arxiv.org/abs/2005.12522v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Semantically Valid Adversarial Questions for TableQA", "abstract": "Adversarial attack on question answering systems over tabular data (TableQA)\ncan help evaluate to what extent they can understand natural language questions\nand reason with tables. However, generating natural language adversarial\nquestions is difficult, because even a single character swap could lead to huge\nsemantic difference in human perception. In this paper, we propose SAGE\n(Semantically valid Adversarial GEnerator), a Wasserstein sequence-to-sequence\nmodel for TableQA white-box attack. To preserve meaning of original questions,\nwe apply minimum risk training with SIMILE and entity delexicalization. We use\nGumbel-Softmax to incorporate adversarial loss for end-to-end training. Our\nexperiments show that SAGE outperforms existing local attack models on semantic\nvalidity and fluency while achieving a good attack success rate. Finally, we\ndemonstrate that adversarial training with SAGE augmented data can improve\nperformance and robustness of TableQA systems.", "published": "2020-05-26 13:17:36", "link": "http://arxiv.org/abs/2005.12696v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Refining Implicit Argument Annotation for UCCA", "abstract": "Predicate-argument structure analysis is a central component in meaning\nrepresentations of text. The fact that some arguments are not explicitly\nmentioned in a sentence gives rise to ambiguity in language understanding, and\nrenders it difficult for machines to interpret text correctly. However, only\nfew resources represent implicit roles for NLU, and existing studies in NLP\nonly make coarse distinctions between categories of arguments omitted from\nlinguistic form. This paper proposes a typology for fine-grained implicit\nargument annotation on top of Universal Conceptual Cognitive Annotation's\nfoundational layer. The proposed implicit argument categorisation is driven by\ntheories of implicit role interpretation and consists of six types: Deictic,\nGeneric, Genre-based, Type-identifiable, Non-specific, and Iterated-set. We\nexemplify our design by revisiting part of the UCCA EWT corpus, providing a new\ndataset annotated with the refinement layer, and making a comparative analysis\nwith other schemes.", "published": "2020-05-26 17:24:15", "link": "http://arxiv.org/abs/2005.12889v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of the Penn Korean Universal Dependency Treebank (PKT-UD):\n  Manual Revision to Build Robust Parsing Model in Korean", "abstract": "In this paper, we first open on important issues regarding the Penn Korean\nUniversal Treebank (PKT-UD) and address these issues by revising the entire\ncorpus manually with the aim of producing cleaner UD annotations that are more\nfaithful to Korean grammar. For compatibility to the rest of UD corpora, we\nfollow the UDv2 guidelines, and extensively revise the part-of-speech tags and\nthe dependency relations to reflect morphological features and flexible\nword-order aspects in Korean. The original and the revised versions of PKT-UD\nare experimented with transformer-based parsing models using biaffine\nattention. The parsing model trained on the revised corpus shows a significant\nimprovement of 3.0% in labeled attachment score over the model trained on the\nprevious corpus. Our error analysis demonstrates that this revision allows the\nparsing model to learn relations more robustly, reducing several critical\nerrors that used to be made by the previous model.", "published": "2020-05-26 17:46:46", "link": "http://arxiv.org/abs/2005.12898v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "English Intermediate-Task Training Improves Zero-Shot Cross-Lingual\n  Transfer Too", "abstract": "Intermediate-task training---fine-tuning a pretrained model on an\nintermediate task before fine-tuning again on the target task---often improves\nmodel performance substantially on language understanding tasks in monolingual\nEnglish settings. We investigate whether English intermediate-task training is\nstill helpful on non-English target tasks. Using nine intermediate\nlanguage-understanding tasks, we evaluate intermediate-task transfer in a\nzero-shot cross-lingual setting on the XTREME benchmark. We see large\nimprovements from intermediate training on the BUCC and Tatoeba sentence\nretrieval tasks and moderate improvements on question-answering target tasks.\nMNLI, SQuAD and HellaSwag achieve the best overall results as intermediate\ntasks, while multi-task intermediate offers small additional improvements.\nUsing our best intermediate-task models for each target task, we obtain a 5.4\npoint improvement over XLM-R Large on the XTREME benchmark, setting the state\nof the art as of June 2020. We also investigate continuing multilingual MLM\nduring intermediate-task training and using machine-translated\nintermediate-task data, but neither consistently outperforms simply performing\nEnglish intermediate-task training.", "published": "2020-05-26 20:17:29", "link": "http://arxiv.org/abs/2005.13013v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning with Weak Supervision for Email Intent Detection", "abstract": "Email remains one of the most frequently used means of online communication.\nPeople spend a significant amount of time every day on emails to exchange\ninformation, manage tasks and schedule events. Previous work has studied\ndifferent ways for improving email productivity by prioritizing emails,\nsuggesting automatic replies or identifying intents to recommend appropriate\nactions. The problem has been mostly posed as a supervised learning problem\nwhere models of different complexities were proposed to classify an email\nmessage into a predefined taxonomy of intents or classes. The need for labeled\ndata has always been one of the largest bottlenecks in training supervised\nmodels. This is especially the case for many real-world tasks, such as email\nintent classification, where large scale annotated examples are either hard to\nacquire or unavailable due to privacy or data access constraints. Email users\noften take actions in response to intents expressed in an email (e.g., setting\nup a meeting in response to an email with a scheduling request). Such actions\ncan be inferred from user interaction logs. In this paper, we propose to\nleverage user actions as a source of weak supervision, in addition to a limited\nset of annotated examples, to detect intents in emails. We develop an\nend-to-end robust deep neural network model for email intent identification\nthat leverages both clean annotated data and noisy weak supervision along with\na self-paced learning mechanism. Extensive experiments on three different\nintent detection tasks show that our approach can effectively leverage the\nweakly supervised data to improve intent detection in emails.", "published": "2020-05-26 23:41:05", "link": "http://arxiv.org/abs/2005.13084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The 'Letter' Distribution in the Chinese Language", "abstract": "Corpus-based statistical analysis plays a significant role in linguistic\nresearch, and ample evidence has shown that different languages exhibit some\ncommon laws. Studies have found that letters in some alphabetic writing\nlanguages have strikingly similar statistical usage frequency distributions.\nDoes this hold for Chinese, which employs ideogram writing? We obtained letter\nfrequency data of some alphabetic writing languages and found the common law of\nthe letter distributions. In addition, we collected Chinese literature corpora\nfor different historical periods from the Tang Dynasty to the present, and we\ndismantled the Chinese written language into three kinds of basic particles:\ncharacters, strokes and constructive parts. The results of the statistical\nanalysis showed that, in different historical periods, the intensity of the use\nof basic particles in Chinese writing varied, but the form of the distribution\nwas consistent. In particular, the distributions of the Chinese constructive\nparts are certainly consistent with those alphabetic writing languages. This\nstudy provides new evidence of the consistency of human languages.", "published": "2020-05-26 05:18:56", "link": "http://arxiv.org/abs/2006.01210v1", "categories": ["cs.CL", "62P25, 97M80"], "primary_category": "cs.CL"}
{"title": "BEEP! Korean Corpus of Online News Comments for Toxic Speech Detection", "abstract": "Toxic comments in online platforms are an unavoidable social issue under the\ncloak of anonymity. Hate speech detection has been actively done for languages\nsuch as English, German, or Italian, where manually labeled corpus has been\nreleased. In this work, we first present 9.4K manually labeled entertainment\nnews comments for identifying Korean toxic speech, collected from a widely used\nonline news platform in Korea. The comments are annotated regarding social bias\nand hate speech since both aspects are correlated. The inter-annotator\nagreement Krippendorff's alpha score is 0.492 and 0.496, respectively. We\nprovide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the\nhighest score on all tasks. The models generally display better performance on\nbias identification, since the hate speech detection is a more subjective\nissue. Additionally, when BERT is trained with bias label for hate speech\ndetection, the prediction score increases, implying that bias and hate are\nintertwined. We make our dataset publicly available and open competitions with\nthe corpus and benchmarks.", "published": "2020-05-26 03:34:01", "link": "http://arxiv.org/abs/2005.12503v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Policy-Driven Neural Response Generation for Knowledge-Grounded Dialogue\n  Systems", "abstract": "Open-domain dialogue systems aim to generate relevant, informative and\nengaging responses. Seq2seq neural response generation approaches do not have\nexplicit mechanisms to control the content or style of the generated response,\nand frequently result in uninformative utterances. In this paper, we propose\nusing a dialogue policy to plan the content and style of target responses in\nthe form of an action plan, which includes knowledge sentences related to the\ndialogue context, targeted dialogue acts, topic information, etc. The\nattributes within the action plan are obtained by automatically annotating the\npublicly released Topical-Chat dataset. We condition neural response generators\non the action plan which is then realized as target utterances at the turn and\nsentence levels. We also investigate different dialogue policy models to\npredict an action plan given the dialogue context. Through automated and human\nevaluation, we measure the appropriateness of the generated responses and check\nif the generation models indeed learn to realize the given action plans. We\ndemonstrate that a basic dialogue policy that operates at the sentence level\ngenerates better responses in comparison to turn level generation as well as\nbaseline models with no action plan. Additionally the basic dialogue policy has\nthe added effect of controllability.", "published": "2020-05-26 06:09:57", "link": "http://arxiv.org/abs/2005.12529v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Guiding Symbolic Natural Language Grammar Induction via\n  Transformer-Based Sequence Probabilities", "abstract": "A novel approach to automated learning of syntactic rules governing natural\nlanguages is proposed, based on using probabilities assigned to sentences (and\npotentially longer word sequences) by transformer neural network language\nmodels to guide symbolic learning processes like clustering and rule induction.\nThis method exploits the learned linguistic knowledge in transformers, without\nany reference to their inner representations; hence, the technique is readily\nadaptable to the continuous appearance of more powerful language models. We\nshow a proof-of-concept example of our proposed technique, using it to guide\nunsupervised symbolic link-grammar induction methods drawn from our prior\nresearch.", "published": "2020-05-26 06:18:47", "link": "http://arxiv.org/abs/2005.12533v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Embedding Vector Differences Can Be Aligned With Uncertain Intensional\n  Logic Differences", "abstract": "The DeepWalk algorithm is used to assign embedding vectors to nodes in the\nAtomspace weighted, labeled hypergraph that is used to represent knowledge in\nthe OpenCog AGI system, in the context of an application to probabilistic\ninference regarding the causes of longevity based on data from biological\nontologies and genomic analyses. It is shown that vector difference operations\nbetween embedding vectors are, in appropriate conditions, approximately\nalignable with \"intensional difference\" operations between the hypergraph nodes\ncorresponding to the embedding vectors. This relationship hints at a broader\nfunctorial mapping between uncertain intensional logic and vector arithmetic,\nand opens the door for using embedding vector algebra to guide intensional\ninference control.", "published": "2020-05-26 06:20:32", "link": "http://arxiv.org/abs/2005.12535v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Multi-Staged Cross-Lingual Acoustic Model Adaption for Robust Speech\n  Recognition in Real-World Applications -- A Case Study on German Oral History\n  Interviews", "abstract": "While recent automatic speech recognition systems achieve remarkable\nperformance when large amounts of adequate, high quality annotated speech data\nis used for training, the same systems often only achieve an unsatisfactory\nresult for tasks in domains that greatly deviate from the conditions\nrepresented by the training data. For many real-world applications, there is a\nlack of sufficient data that can be directly used for training robust speech\nrecognition systems. To address this issue, we propose and investigate an\napproach that performs a robust acoustic model adaption to a target domain in a\ncross-lingual, multi-staged manner. Our approach enables the exploitation of\nlarge-scale training data from other domains in both the same and other\nlanguages. We evaluate our approach using the challenging task of German oral\nhistory interviews, where we achieve a relative reduction of the word error\nrate by more than 30% compared to a model trained from scratch only on the\ntarget domain, and 6-7% relative compared to a model trained robustly on 1000\nhours of same-language out-of-domain training data.", "published": "2020-05-26 08:05:25", "link": "http://arxiv.org/abs/2005.12562v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "A Data-driven Approach for Noise Reduction in Distantly Supervised\n  Biomedical Relation Extraction", "abstract": "Fact triples are a common form of structured knowledge used within the\nbiomedical domain. As the amount of unstructured scientific texts continues to\ngrow, manual annotation of these texts for the task of relation extraction\nbecomes increasingly expensive. Distant supervision offers a viable approach to\ncombat this by quickly producing large amounts of labeled, but considerably\nnoisy, data. We aim to reduce such noise by extending an entity-enriched\nrelation classification BERT model to the problem of multiple instance\nlearning, and defining a simple data encoding scheme that significantly reduces\nnoise, reaching state-of-the-art performance for distantly-supervised\nbiomedical relation extraction. Our approach further encodes knowledge about\nthe direction of relation triples, allowing for increased focus on relation\nlearning by reducing noise and alleviating the need for joint learning with\nknowledge graph completion.", "published": "2020-05-26 08:15:32", "link": "http://arxiv.org/abs/2005.12565v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GECToR -- Grammatical Error Correction: Tag, Not Rewrite", "abstract": "In this paper, we present a simple and efficient GEC sequence tagger using a\nTransformer encoder. Our system is pre-trained on synthetic data and then\nfine-tuned in two stages: first on errorful corpora, and second on a\ncombination of errorful and error-free parallel corpora. We design custom\ntoken-level transformations to map input tokens to target corrections. Our best\nsingle-model/ensemble GEC tagger achieves an $F_{0.5}$ of 65.3/66.5 on\nCoNLL-2014 (test) and $F_{0.5}$ of 72.4/73.6 on BEA-2019 (test). Its inference\nspeed is up to 10 times as fast as a Transformer-based seq2seq GEC system. The\ncode and trained models are publicly available.", "published": "2020-05-26 09:33:02", "link": "http://arxiv.org/abs/2005.12592v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring aspects of similarity between spoken personal narratives by\n  disentangling them into narrative clause types", "abstract": "Sharing personal narratives is a fundamental aspect of human social behavior\nas it helps share our life experiences. We can tell stories and rely on our\nbackground to understand their context, similarities, and differences. A\nsubstantial effort has been made towards developing storytelling machines or\ninferring characters' features. However, we don't usually find models that\ncompare narratives. This task is remarkably challenging for machines since\nthey, as sometimes we do, lack an understanding of what similarity means. To\naddress this challenge, we first introduce a corpus of real-world spoken\npersonal narratives comprising 10,296 narrative clauses from 594 video\ntranscripts. Second, we ask non-narrative experts to annotate those clauses\nunder Labov's sociolinguistic model of personal narratives (i.e., action,\norientation, and evaluation clause types) and train a classifier that reaches\n84.7% F-score for the highest-agreed clauses. Finally, we match stories and\nexplore whether people implicitly rely on Labov's framework to compare\nnarratives. We show that actions followed by the narrator's evaluation of these\nare the aspects non-experts consider the most. Our approach is intended to help\ninform machine learning methods aimed at studying or representing personal\nnarratives.", "published": "2020-05-26 14:34:07", "link": "http://arxiv.org/abs/2005.12762v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Predicting Entity Popularity to Improve Spoken Entity Recognition by\n  Virtual Assistants", "abstract": "We focus on improving the effectiveness of a Virtual Assistant (VA) in\nrecognizing emerging entities in spoken queries. We introduce a method that\nuses historical user interactions to forecast which entities will gain in\npopularity and become trending, and it subsequently integrates the predictions\nwithin the Automated Speech Recognition (ASR) component of the VA. Experiments\nshow that our proposed approach results in a 20% relative reduction in errors\non emerging entity name utterances without degrading the overall recognition\nquality of the system.", "published": "2020-05-26 15:47:42", "link": "http://arxiv.org/abs/2005.12816v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Study of Neural Matching Models for Cross-lingual IR", "abstract": "In this study, we investigate interaction-based neural matching models for\nad-hoc cross-lingual information retrieval (CLIR) using cross-lingual word\nembeddings (CLWEs). With experiments conducted on the CLEF collection over four\nlanguage pairs, we evaluate and provide insight into different neural model\narchitectures, different ways to represent query-document interactions and\nword-pair similarity distributions in CLIR. This study paves the way for\nlearning an end-to-end CLIR system using CLWEs.", "published": "2020-05-26 19:21:57", "link": "http://arxiv.org/abs/2005.12994v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Examining Racial Bias in an Online Abuse Corpus with Structural Topic\n  Modeling", "abstract": "We use structural topic modeling to examine racial bias in data collected to\ntrain models to detect hate speech and abusive language in social media posts.\nWe augment the abusive language dataset by adding an additional feature\nindicating the predicted probability of the tweet being written in\nAfrican-American English. We then use structural topic modeling to examine the\ncontent of the tweets and how the prevalence of different topics is related to\nboth abusiveness annotation and dialect prediction. We find that certain topics\nare disproportionately racialized and considered abusive. We discuss how topic\nmodeling may be a useful approach for identifying bias in annotated data.", "published": "2020-05-26 21:02:43", "link": "http://arxiv.org/abs/2005.13041v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "History-Aware Question Answering in a Blocks World Dialogue System", "abstract": "It is essential for dialogue-based spatial reasoning systems to maintain\nmemory of historical states of the world. In addition to conveying that the\ndialogue agent is mentally present and engaged with the task, referring to\nhistorical states may be crucial for enabling collaborative planning (e.g., for\nplanning to return to a previous state, or diagnosing a past misstep). In this\npaper, we approach the problem of spatial memory in a multi-modal spoken\ndialogue system capable of answering questions about interaction history in a\nphysical blocks world setting. This work builds upon a full spatial\nquestion-answering pipeline consisting of a vision system, speech input and\noutput mediated by an animated avatar, a dialogue system that robustly\ninterprets spatial queries, and a constraint solver that derives answers based\non 3-D spatial modelling. The contributions of this work include a symbolic\ndialogue context registering knowledge about discourse history and changes in\nthe world, as well as a natural language understanding module capable of\ninterpreting free-form historical questions and querying the dialogue context\nto form an answer.", "published": "2020-05-26 03:16:11", "link": "http://arxiv.org/abs/2005.12501v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Noise Robust TTS for Low Resource Speakers using Pre-trained Model and\n  Speech Enhancement", "abstract": "With the popularity of deep neural network, speech synthesis task has\nachieved significant improvements based on the end-to-end encoder-decoder\nframework in the recent days. More and more applications relying on speech\nsynthesis technology have been widely used in our daily life. Robust speech\nsynthesis model depends on high quality and customized data which needs lots of\ncollecting efforts. It is worth investigating how to take advantage of\nlow-quality and low resource voice data which can be easily obtained from the\nInternet for usage of synthesizing personalized voice. In this paper, the\nproposed end-to-end speech synthesis model uses both speaker embedding and\nnoise representation as conditional inputs to model speaker and noise\ninformation respectively. Firstly, the speech synthesis model is pre-trained\nwith both multi-speaker clean data and noisy augmented data; then the\npre-trained model is adapted on noisy low-resource new speaker data; finally,\nby setting the clean speech condition, the model can synthesize the new\nspeaker's clean voice. Experimental results show that the speech generated by\nthe proposed approach has better subjective evaluation results than the method\ndirectly fine-tuning pre-trained multi-speaker speech synthesis model with\ndenoised new speaker data.", "published": "2020-05-26 06:14:06", "link": "http://arxiv.org/abs/2005.12531v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Verification and Validation of Convex Optimization Algorithms for Model\n  Predictive Control", "abstract": "Advanced embedded algorithms are growing in complexity and they are an\nessential contributor to the growth of autonomy in many areas. However, the\npromise held by these algorithms cannot be kept without proper attention to the\nconsiderably stronger design constraints that arise when the applications of\ninterest, such as aerospace systems, are safety-critical. Formal verification\nis the process of proving or disproving the ''correctness'' of an algorithm\nwith respect to a certain mathematical description of it by means of a\ncomputer. This article discusses the formal verification of the Ellipsoid\nmethod, a convex optimization algorithm, and its code implementation as it\napplies to receding horizon control. Options for encoding code properties and\ntheir proofs are detailed. The applicability and limitations of those code\nproperties and proofs are presented as well. Finally, floating-point errors are\ntaken into account in a numerical analysis of the Ellipsoid algorithm.\nModifications to the algorithm are presented which can be used to control its\nnumerical stability.", "published": "2020-05-26 09:18:14", "link": "http://arxiv.org/abs/2005.12588v1", "categories": ["cs.CL", "cs.FL", "math.OC"], "primary_category": "cs.CL"}
{"title": "Active Imitation Learning with Noisy Guidance", "abstract": "Imitation learning algorithms provide state-of-the-art results on many\nstructured prediction tasks by learning near-optimal search policies. Such\nalgorithms assume training-time access to an expert that can provide the\noptimal action at any queried state; unfortunately, the number of such queries\nis often prohibitive, frequently rendering these approaches impractical. To\ncombat this query complexity, we consider an active learning setting in which\nthe learning algorithm has additional access to a much cheaper noisy heuristic\nthat provides noisy guidance. Our algorithm, LEAQI, learns a difference\nclassifier that predicts when the expert is likely to disagree with the\nheuristic, and queries the expert only when necessary. We apply LEAQI to three\nsequence labeling tasks, demonstrating significantly fewer queries to the\nexpert and comparable (or better) accuracies over a passive approach.", "published": "2020-05-26 15:35:46", "link": "http://arxiv.org/abs/2005.12801v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Twitter discussions and emotions about COVID-19 pandemic: a machine\n  learning approach", "abstract": "The objective of the study is to examine coronavirus disease (COVID-19)\nrelated discussions, concerns, and sentiments that emerged from tweets posted\nby Twitter users. We analyze 4 million Twitter messages related to the COVID-19\npandemic using a list of 25 hashtags such as \"coronavirus,\" \"COVID-19,\"\n\"quarantine\" from March 1 to April 21 in 2020. We use a machine learning\napproach, Latent Dirichlet Allocation (LDA), to identify popular unigram,\nbigrams, salient topics and themes, and sentiments in the collected Tweets.\nPopular unigrams include \"virus,\" \"lockdown,\" and \"quarantine.\" Popular bigrams\ninclude \"COVID-19,\" \"stay home,\" \"corona virus,\" \"social distancing,\" and \"new\ncases.\" We identify 13 discussion topics and categorize them into five\ndifferent themes, such as \"public health measures to slow the spread of\nCOVID-19,\" \"social stigma associated with COVID-19,\" \"coronavirus news cases\nand deaths,\" \"COVID-19 in the United States,\" and \"coronavirus cases in the\nrest of the world\". Across all identified topics, the dominant sentiments for\nthe spread of coronavirus are anticipation that measures that can be taken,\nfollowed by a mixed feeling of trust, anger, and fear for different topics. The\npublic reveals a significant feeling of fear when they discuss the coronavirus\nnew cases and deaths than other topics. The study shows that Twitter data and\nmachine learning approaches can be leveraged for infodemiology study by\nstudying the evolving public discussions and sentiments during the COVID-19.\nReal-time monitoring and assessment of the Twitter discussion and concerns can\nbe promising for public health emergency responses and planning. Already\nemerged pandemic fear, stigma, and mental health concerns may continue to\ninfluence public trust when there occurs a second wave of COVID-19 or a new\nsurge of the imminent pandemic.", "published": "2020-05-26 16:10:02", "link": "http://arxiv.org/abs/2005.12830v2", "categories": ["cs.SI", "cs.CL", "cs.CY", "stat.ML"], "primary_category": "cs.SI"}
{"title": "A comparison of Vietnamese Statistical Parametric Speech Synthesis\n  Systems", "abstract": "In recent years, statistical parametric speech synthesis (SPSS) systems have\nbeen widely utilized in many interactive speech-based systems (e.g.~Amazon's\nAlexa, Bose's headphones). To select a suitable SPSS system, both speech\nquality and performance efficiency (e.g.~decoding time) must be taken into\naccount. In the paper, we compared four popular Vietnamese SPSS techniques\nusing: 1) hidden Markov models (HMM), 2) deep neural networks (DNN), 3)\ngenerative adversarial networks (GAN), and 4) end-to-end (E2E) architectures,\nwhich consists of Tacontron~2 and WaveGlow vocoder in terms of speech quality\nand performance efficiency. We showed that the E2E systems accomplished the\nbest quality, but required the power of GPU to achieve real-time performance.\nWe also showed that the HMM-based system had inferior speech quality, but it\nwas the most efficient system. Surprisingly, the E2E systems were more\nefficient than the DNN and GAN in inference on GPU. Surprisingly, the GAN-based\nsystem did not outperform the DNN in term of quality.", "published": "2020-05-26 18:32:03", "link": "http://arxiv.org/abs/2005.12962v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Comparing BERT against traditional machine learning text classification", "abstract": "The BERT model has arisen as a popular state-of-the-art machine learning\nmodel in the recent years that is able to cope with multiple NLP tasks such as\nsupervised text classification without human supervision. Its flexibility to\ncope with any type of corpus delivering great results has make this approach\nvery popular not only in academia but also in the industry. Although, there are\nlots of different approaches that have been used throughout the years with\nsuccess. In this work, we first present BERT and include a little review on\nclassical NLP approaches. Then, we empirically test with a suite of experiments\ndealing different scenarios the behaviour of BERT against the traditional\nTF-IDF vocabulary fed to machine learning algorithms. Our purpose of this work\nis to add empirical evidence to support or refuse the use of BERT as a default\non NLP tasks. Experiments show the superiority of BERT and its independence of\nfeatures of the NLP problem such as the language of the text adding empirical\nevidence to use BERT as a default technique to be used in NLP problems.", "published": "2020-05-26 20:14:39", "link": "http://arxiv.org/abs/2005.13012v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Do All Good Actors Look The Same? Exploring News Veracity Detection\n  Across The U.S. and The U.K", "abstract": "A major concern with text-based news veracity detection methods is that they\nmay not generalize across countries and cultures. In this short paper, we\nexplicitly test news veracity models across news data from the United States\nand the United Kingdom, demonstrating there is reason for concern of\ngeneralizabilty. Through a series of testing scenarios, we show that text-based\nclassifiers perform poorly when trained on one country's news data and tested\non another. Furthermore, these same models have trouble classifying unseen,\nunreliable news sources. In conclusion, we discuss implications of these\nresults and avenues for future work.", "published": "2020-05-26 22:45:28", "link": "http://arxiv.org/abs/2006.01211v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining", "abstract": "Clinical interactions are initially recorded and documented in free text\nmedical notes. ICD coding is the task of classifying and coding all diagnoses,\nsymptoms and procedures associated with a patient's visit. The process is often\nmanual and extremely time-consuming and expensive for hospitals. In this paper,\nwe propose a machine learning model, BERT-XML, for large scale automated ICD\ncoding from EHR notes, utilizing recently developed unsupervised pretraining\nthat have achieved state of the art performance on a variety of NLP tasks. We\ntrain a BERT model from scratch on EHR notes, learning with vocabulary better\nsuited for EHR tasks and thus outperform off-the-shelf models. We adapt the\nBERT architecture for ICD coding with multi-label attention. While other works\nfocus on small public medical datasets, we have produced the first large scale\nICD-10 classification model using millions of EHR notes to predict thousands of\nunique ICD codes.", "published": "2020-05-26 21:12:43", "link": "http://arxiv.org/abs/2006.03685v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "An open-source voice type classifier for child-centered daylong\n  recordings", "abstract": "Spontaneous conversations in real-world settings such as those found in\nchild-centered recordings have been shown to be amongst the most challenging\naudio files to process. Nevertheless, building speech processing models\nhandling such a wide variety of conditions would be particularly useful for\nlanguage acquisition studies in which researchers are interested in the\nquantity and quality of the speech that children hear and produce, as well as\nfor early diagnosis and measuring effects of remediation. In this paper, we\npresent our approach to designing an open-source neural network to classify\naudio segments into vocalizations produced by the child wearing the recording\ndevice, vocalizations produced by other children, adult male speech, and adult\nfemale speech. To this end, we gathered diverse child-centered corpora which\nsums up to a total of 260 hours of recordings and covers 10 languages. Our\nmodel can be used as input for downstream tasks such as estimating the number\nof words produced by adult speakers, or the number of linguistic units produced\nby children. Our architecture combines SincNet filters with a stack of\nrecurrent layers and outperforms by a large margin the state-of-the-art system,\nthe Language ENvironment Analysis (LENA) that has been used in numerous child\nlanguage studies.", "published": "2020-05-26 12:25:08", "link": "http://arxiv.org/abs/2005.12656v3", "categories": ["eess.AS", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Sound Context Classification Basing on Join Learning Model and\n  Multi-Spectrogram Features", "abstract": "In this paper, we present a deep learning framework applied for Acoustic\nScene Classification (ASC), the task of classifying scene contexts from\nenvironmental input sounds. An ASC system generally comprises of two main\nsteps, referred to as front-end feature extraction and back-end classification.\nIn the first step, an extractor is used to extract low-level features from raw\naudio signals. Next, the discriminative features extracted are fed into and\nclassified by a classifier, reporting accuracy results. Aim to develop a robust\nframework applied for ASC, we address exited issues of both the front-end and\nback-end components in an ASC system, thus present three main contributions:\nFirstly, we carry out a comprehensive analysis of spectrogram representation\nextracted from sound scene input, thus propose the best multi-spectrogram\ncombinations. In terms of back-end classification, we propose a novel join\nlearning architecture using parallel convolutional recurrent networks, which is\neffective to learn spatial features and temporal sequences of spectrogram\ninput. Finally, good experimental results obtained over benchmark datasets of\nIEEE AASP Challenge on Detection and Classification of Acoustic Scenes and\nEvents (DCASE) 2016 Task 1, 2017 Task 1, 2018 Task 1A & 1B, LITIS Rouen prove\nour proposed framework general and robust for ASC task.", "published": "2020-05-26 15:01:25", "link": "http://arxiv.org/abs/2005.12779v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Contrastive Predictive Coding Supported Factorized Variational\n  Autoencoder for Unsupervised Learning of Disentangled Speech Representations", "abstract": "In this work we address disentanglement of style and content in speech\nsignals. We propose a fully convolutional variational autoencoder employing two\nencoders: a content encoder and a style encoder. To foster disentanglement, we\npropose adversarial contrastive predictive coding. This new disentanglement\nmethod does neither need parallel data nor any supervision. We show that the\nproposed technique is capable of separating speaker and content traits into the\ntwo different representations and show competitive speaker-content\ndisentanglement performance compared to other unsupervised approaches. We\nfurther demonstrate an increased robustness of the content representation\nagainst a train-test mismatch compared to spectral features, when used for\nphone recognition.", "published": "2020-05-26 18:35:56", "link": "http://arxiv.org/abs/2005.12963v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
