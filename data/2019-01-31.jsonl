{"title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text\n  Classification Tasks", "abstract": "We present EDA: easy data augmentation techniques for boosting performance on\ntext classification tasks. EDA consists of four simple but powerful operations:\nsynonym replacement, random insertion, random swap, and random deletion. On\nfive text classification tasks, we show that EDA improves performance for both\nconvolutional and recurrent neural networks. EDA demonstrates particularly\nstrong results for smaller datasets; on average, across five datasets, training\nwith EDA while using only 50% of the available training set achieved the same\naccuracy as normal training with all available data. We also performed\nextensive ablation studies and suggest parameters for practical use.", "published": "2019-01-31 03:20:52", "link": "http://arxiv.org/abs/1901.11196v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adding Interpretable Attention to Neural Translation Models Improves\n  Word Alignment", "abstract": "Multi-layer models with multiple attention heads per layer provide superior\ntranslation quality compared to simpler and shallower models, but determining\nwhat source context is most relevant to each target word is more challenging as\na result. Therefore, deriving high-accuracy word alignments from the\nactivations of a state-of-the-art neural machine translation model is an open\nchallenge. We propose a simple model extension to the Transformer architecture\nthat makes use of its hidden representations and is restricted to attend solely\non encoder information to predict the next word. It can be trained on bilingual\ndata without word-alignment information. We further introduce a novel alignment\ninference procedure which applies stochastic gradient descent to directly\noptimize the attention activations towards a given target word. The resulting\nalignments dramatically outperform the naive approach to interpreting\nTransformer attention activations, and are comparable to Giza++ on two publicly\navailable data sets.", "published": "2019-01-31 14:05:02", "link": "http://arxiv.org/abs/1901.11359v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decomposing Generalization: Models of Generic, Habitual, and Episodic\n  Statements", "abstract": "We present a novel semantic framework for modeling linguistic expressions of\ngeneralization---generic, habitual, and episodic statements---as combinations\nof simple, real-valued referential properties of predicates and their\narguments. We use this framework to construct a dataset covering the entirety\nof the Universal Dependencies English Web Treebank. We use this dataset to\nprobe the efficacy of type-level and token-level information---including\nhand-engineered features and static (GloVe) and contextual (ELMo) word\nembeddings---for predicting expressions of generalization. Data and code are\navailable at decomp.io.", "published": "2019-01-31 15:30:37", "link": "http://arxiv.org/abs/1901.11429v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Deep Neural Networks for Natural Language Understanding", "abstract": "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for\nlearning representations across multiple natural language understanding (NLU)\ntasks. MT-DNN not only leverages large amounts of cross-task data, but also\nbenefits from a regularization effect that leads to more general\nrepresentations in order to adapt to new tasks and domains. MT-DNN extends the\nmodel proposed in Liu et al. (2015) by incorporating a pre-trained\nbidirectional transformer language model, known as BERT (Devlin et al., 2018).\nMT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI,\nSciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7%\n(2.2% absolute improvement). We also demonstrate using the SNLI and SciTail\ndatasets that the representations learned by MT-DNN allow domain adaptation\nwith substantially fewer in-domain labels than the pre-trained BERT\nrepresentations. The code and pre-trained models are publicly available at\nhttps://github.com/namisan/mt-dnn.", "published": "2019-01-31 18:07:25", "link": "http://arxiv.org/abs/1901.11504v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Riconoscimento ortografico per apostrofo ed espressioni polirematiche", "abstract": "The work presents two algorithms of manipulation and comparison between\nstrings whose purpose is the orthographic recognition of the apostrophe and of\nthe compound expressions. The theory supporting general reasoning refers to the\nbasic concept of EditDistance, the improvements that ensure the achievement of\nthe objective are achieved with the aid of tools borrowed from the use of\ntechniques for processing large amounts of data on distributed platforms.", "published": "2019-01-31 16:12:14", "link": "http://arxiv.org/abs/1902.00555v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Generalized Language Model in Tensor Space", "abstract": "In the literature, tensors have been effectively used for capturing the\ncontext information in language models. However, the existing methods usually\nadopt relatively-low order tensors, which have limited expressive power in\nmodeling language. Developing a higher-order tensor representation is\nchallenging, in terms of deriving an effective solution and showing its\ngenerality. In this paper, we propose a language model named Tensor Space\nLanguage Model (TSLM), by utilizing tensor networks and tensor decomposition.\nIn TSLM, we build a high-dimensional semantic space constructed by the tensor\nproduct of word vectors. Theoretically, we prove that such tensor\nrepresentation is a generalization of the n-gram language model. We further\nshow that this high-order tensor representation can be decomposed to a\nrecursive calculation of conditional probability for language modeling. The\nexperimental results on Penn Tree Bank (PTB) dataset and WikiText benchmark\ndemonstrate the effectiveness of TSLM.", "published": "2019-01-31 01:46:35", "link": "http://arxiv.org/abs/1901.11167v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Efficient Lexically-Constrained Neural Machine Translation with\n  External Memory", "abstract": "Recent years has witnessed dramatic progress of neural machine translation\n(NMT), however, the method of manually guiding the translation procedure\nremains to be better explored. Previous works proposed to handle such problem\nthrough lexcially-constrained beam search in the decoding phase. Unfortunately,\nthese lexically-constrained beam search methods suffer two fatal disadvantages:\nhigh computational complexity and hard beam search which generates unexpected\ntranslations. In this paper, we propose to learn the ability of\nlexically-constrained translation with external memory, which can overcome the\nabove mentioned disadvantages. For the training process, automatically\nextracted phrase pairs are extracted from alignment and sentence parsing, then\nfurther be encoded into an external memory. This memory is then used to provide\nlexically-constrained information for training through a memory-attention\nmachanism. Various experiments are conducted on WMT Chinese to English and\nEnglish to German tasks. All the results can demonstrate the effectiveness of\nour method.", "published": "2019-01-31 13:26:28", "link": "http://arxiv.org/abs/1901.11344v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the context of recurrent neural network based conversational\n  agents", "abstract": "Conversational agents have begun to rise both in the academic (in terms of\nresearch) and commercial (in terms of applications) world. This paper\ninvestigates the task of building a non-goal driven conversational agent, using\nneural network generative models and analyzes how the conversation context is\nhandled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent\nEncoder-Decoder architecture, which includes an additional module to model the\ncontext of the conversation using previous utterances information. We found\nthat the hierarchical model was able to extract relevant context information\nand include them in the generation of the output. However, it performed worse\n(35-40%) than the simple Encoder-Decoder model regarding both grammatically\ncorrect output and meaningful response. Despite these results, experiments\ndemonstrate how conversations about similar topics appear close to each other\nin the context space due to the increased frequency of specific topic-related\nwords, thus leaving promising directions for future research and how the\ncontext of a conversation can be exploited.", "published": "2019-01-31 16:40:26", "link": "http://arxiv.org/abs/1901.11462v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Controlled Transformation of Sentiment in Sentences", "abstract": "An obstacle to the development of many natural language processing products\nis the vast amount of training examples necessary to get satisfactory results.\nThe generation of these examples is often a tedious and time-consuming task.\nThis paper this paper proposes a method to transform the sentiment of sentences\nin order to limit the work necessary to generate more training data. This means\nthat one sentence can be transformed to an opposite sentiment sentence and\nshould reduce by half the work required in the generation of text. The proposed\npipeline consists of a sentiment classifier with an attention mechanism to\nhighlight the short phrases that determine the sentiment of a sentence. Then,\nthese phrases are changed to phrases of the opposite sentiment using a baseline\nmodel and an autoencoder approach. Experiments are run on both the separate\nparts of the pipeline as well as on the end-to-end model. The sentiment\nclassifier is tested on its accuracy and is found to perform adequately. The\nautoencoder is tested on how well it is able to change the sentiment of an\nencoded phrase and it was found that such a task is possible. We use human\nevaluation to judge the performance of the full (end-to-end) pipeline and that\nreveals that a model using word vectors outperforms the encoder model.\nNumerical evaluation shows that a success rate of 54.7% is achieved on the\nsentiment change.", "published": "2019-01-31 16:51:49", "link": "http://arxiv.org/abs/1901.11467v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Machine-assisted Meta-Studies: The Hubble Constant", "abstract": "We present an approach for automatic extraction of measured values from the\nastrophysical literature, using the Hubble constant for our pilot study. Our\nrules-based model -- a classical technique in natural language processing --\nhas successfully extracted 298 measurements of the Hubble constant, with\nuncertainties, from the 208,541 available arXiv astrophysics papers. We have\nalso created an artificial neural network classifier to identify papers in\narXiv which report novel measurements. From the analysis of our results we find\nthat reporting measurements with uncertainties and the correct units is\ncritical information when distinguishing novel measurements in free text. Our\nresults correctly highlight the current tension for measurements of the Hubble\nconstant and recover the $3.5\\sigma$ discrepancy -- demonstrating that the tool\npresented in this paper is useful for meta-studies of astrophysical\nmeasurements from a large number of publications.", "published": "2019-01-31 19:00:07", "link": "http://arxiv.org/abs/1902.00027v2", "categories": ["astro-ph.IM", "cs.CL"], "primary_category": "astro-ph.IM"}
{"title": "Conversational Networks for Automatic Online Moderation", "abstract": "Moderation of user-generated content in an online community is a challenge\nthat has great socio-economical ramifications. However, the costs incurred by\ndelegating this work to human agents are high. For this reason, an automatic\nsystem able to detect abuse in user-generated content is of great interest.\nThere are a number of ways to tackle this problem, but the most commonly seen\nin practice are word filtering or regular expression matching. The main\nlimitations are their vulnerability to intentional obfuscation on the part of\nthe users, and their context-insensitive nature. Moreover, they are\nlanguage-dependent and may require appropriate corpora for training. In this\npaper, we propose a system for automatic abuse detection that completely\ndisregards message content. We first extract a conversational network from raw\nchat logs and characterize it through topological measures. We then use these\nas features to train a classifier on our abuse detection task. We thoroughly\nassess our system on a dataset of user comments originating from a French\nMassively Multiplayer Online Game. We identify the most appropriate network\nextraction parameters and discuss the discriminative power of our features,\nrelatively to their topological and temporal nature. Our method reaches an\nF-measure of 83.89 when using the full feature set, improving on existing\napproaches. With a selection of the most discriminative features, we\ndramatically cut computing time while retaining most of the performance\n(82.65).", "published": "2019-01-31 09:23:57", "link": "http://arxiv.org/abs/1901.11281v1", "categories": ["cs.IR", "cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.IR"}
{"title": "IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and\n  Translation", "abstract": "Text attribute transfer aims to automatically rewrite sentences such that\nthey possess certain linguistic attributes, while simultaneously preserving\ntheir semantic content. This task remains challenging due to a lack of\nsupervised parallel data. Existing approaches try to explicitly disentangle\ncontent and attribute information, but this is difficult and often results in\npoor content-preservation and ungrammaticality. In contrast, we propose a\nsimpler approach, Iterative Matching and Translation (IMaT), which: (1)\nconstructs a pseudo-parallel corpus by aligning a subset of semantically\nsimilar sentences from the source and the target corpora; (2) applies a\nstandard sequence-to-sequence model to learn the attribute transfer; (3)\niteratively improves the learned transfer function by refining imperfections in\nthe alignment. In sentiment modification and formality transfer tasks, our\nmethod outperforms complex state-of-the-art systems by a large margin. As an\nauxiliary contribution, we produce a publicly-available test set with\nhuman-generated transfer references.", "published": "2019-01-31 12:41:57", "link": "http://arxiv.org/abs/1901.11333v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning and Evaluating General Linguistic Intelligence", "abstract": "We define general linguistic intelligence as the ability to reuse previously\nacquired knowledge about a language's lexicon, syntax, semantics, and pragmatic\nconventions to adapt to new tasks quickly. Using this definition, we analyze\nstate-of-the-art natural language understanding models and conduct an extensive\nempirical investigation to evaluate them against these criteria through a\nseries of experiments that assess the task-independence of the knowledge being\nacquired by the learning process. In addition to task performance, we propose a\nnew evaluation metric based on an online encoding of the test data that\nquantifies how quickly an existing agent (model) learns a new task. Our results\nshow that while the field has made impressive progress in terms of model\narchitectures that generalize to many tasks, these models still require a lot\nof in-domain training examples (e.g., for fine tuning, training task-specific\nmodules), and are prone to catastrophic forgetting. Moreover, we find that far\nfrom solving general tasks (e.g., document question answering), our models are\noverfitting to the quirks of particular datasets (e.g., SQuAD). We discuss\nmissing components and conjecture on how to make progress toward general\nlinguistic intelligence.", "published": "2019-01-31 14:29:35", "link": "http://arxiv.org/abs/1901.11373v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Shaping the Narrative Arc: An Information-Theoretic Approach to\n  Collaborative Dialogue", "abstract": "We consider the problem of designing an artificial agent capable of\ninteracting with humans in collaborative dialogue to produce creative, engaging\nnarratives. In this task, the goal is to establish universe details, and to\ncollaborate on an interesting story in that universe, through a series of\nnatural dialogue exchanges. Our model can augment any probabilistic\nconversational agent by allowing it to reason about universe information\nestablished and what potential next utterances might reveal. Ideally, with each\nutterance, agents would reveal just enough information to add specificity and\nreduce ambiguity without limiting the conversation. We empirically show that\nour model allows control over the rate at which the agent reveals information\nand that doing so significantly improves accuracy in predicting the next line\nof dialogues from movies. We close with a case-study with four professional\ntheatre performers, who preferred interactions with our model-augmented agent\nover an unaugmented agent.", "published": "2019-01-31 18:48:19", "link": "http://arxiv.org/abs/1901.11528v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "The Second Conversational Intelligence Challenge (ConvAI2)", "abstract": "We describe the setting and results of the ConvAI2 NeurIPS competition that\naims to further the state-of-the-art in open-domain chatbots. Some key\ntakeaways from the competition are: (i) pretrained Transformer variants are\ncurrently the best performing models on this task, (ii) but to improve\nperformance on multi-turn conversations with humans, future systems must go\nbeyond single word metrics like perplexity to measure the performance across\nsequences of utterances (conversations) -- in terms of repetition, consistency\nand balance of dialogue acts (e.g. how many questions asked vs. answered).", "published": "2019-01-31 22:14:34", "link": "http://arxiv.org/abs/1902.00098v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Rhythm Zone Theory: Speech Rhythms are Physical after all", "abstract": "Speech rhythms have been dealt with in three main ways: from the\nintrospective analyses of rhythm as a correlate of syllable and foot timing in\nlinguistics and applied linguistics, through analyses of durations of segments\nof utterances associated with consonantal and vocalic properties, syllables,\nfeet and words, to models of rhythms in speech production and perception as\nphysical oscillations. The present study avoids introspection and\nhuman-filtered annotation methods and extends the signal processing paradigm of\namplitude envelope spectrum analysis by adding an additional analytic step of\nedge detection, and postulating the co-existence of multiple speech rhythms in\nrhythm zones marked by identifiable edges (Rhythm Zone Theory, RZT). An\nexploratory investigation of the utility of RZT is conducted, suggesting that\nnative and non-native readings of the same text are distinct sub-genres of read\nspeech: a reading by a US native speaker and non-native readings by relatively\nlow-performing Cantonese adult learners of English. The study concludes by\nnoting that with the methods used, RZT can distinguish between the speech\nrhythms of well-defined sub-genres of native speaker reading vs. non-native\nlearner reading, but needs further refinement in order to be applied to the\nparadoxically more complex speech of low-performing language learners, whose\nspeech rhythms are co-determined by non-fluency and disfluency factors in\naddition to well-known linguistic factors of grammar, vocabulary and discourse\nconstraints.", "published": "2019-01-31 20:49:17", "link": "http://arxiv.org/abs/1902.01267v2", "categories": ["q-bio.NC", "cs.CL", "cs.SD"], "primary_category": "q-bio.NC"}
{"title": "Learning Taxonomies of Concepts and not Words using Contextualized Word\n  Representations: A Position Paper", "abstract": "Taxonomies are semantic hierarchies of concepts. One limitation of current\ntaxonomy learning systems is that they define concepts as single words. This\nposition paper argues that contextualized word representations, which recently\nachieved state-of-the-art results on many competitive NLP tasks, are a\npromising method to address this limitation. We outline a novel approach for\ntaxonomy learning that (1) defines concepts as synsets, (2) learns\ndensity-based approximations of contextualized word representations, and (3)\ncan measure similarity and hypernymy among them.", "published": "2019-01-31 17:18:42", "link": "http://arxiv.org/abs/1902.02169v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Discriminate natural versus loudspeaker emitted speech", "abstract": "In this work, we address a novel, but potentially emerging, problem of\ndiscriminating the natural human voices and those played back by any kind of\naudio devices in the context of interactions with in-house voice user\ninterface. The tackled problem may find relevant applications in (1) the\nfar-field voice interactions of vocal interfaces such as Amazon Echo, Google\nHome, Facebook Portal, etc, and (2) the replay spoofing attack detection. The\ndetection of loudspeaker emitted speech will help avoid false wake-ups or\nunintended interactions with the devices in the first application, while\neliminating attacks involve the replay of recordings collected from enrolled\nspeakers in the second one. At first we collect a real-world dataset under\nwell-controlled conditions containing two classes: recorded speeches directly\nspoken by numerous people (considered as the natural speech), and recorded\nspeeches played back from various loudspeakers (considered as the loudspeaker\nemitted speech). Then from this dataset, we build prediction models based on\nDeep Neural Network (DNN) for which different combination of audio features\nhave been considered. Experiment results confirm the feasibility of the task\nwhere the combination of audio embeddings extracted from SoundNet and VGGish\nnetwork yields the classification accuracy up to about 90%.", "published": "2019-01-31 09:49:54", "link": "http://arxiv.org/abs/1901.11291v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Optimization of the Area Under the ROC Curve using Neural Network\n  Supervectors for Text-Dependent Speaker Verification", "abstract": "This paper explores two techniques to improve the performance of\ntext-dependent speaker verification systems based on deep neural networks.\nFirstly, we propose a general alignment mechanism to keep the temporal\nstructure of each phrase and obtain a supervector with the speaker and phrase\ninformation, since both are relevant for a text-dependent verification. As we\nshow, it is possible to use different alignment techniques to replace the\nglobal average pooling providing significant gains in performance. Moreover, we\nalso present a novel back-end approach to train a neural network for detection\ntasks by optimizing the Area Under the Curve (AUC) as an alternative to the\nusual triplet loss function, so the system is end-to-end, with a cost function\nclose to our desired measure of performance. As we can see in the experimental\nsection, this approach improves the system performance, since our triplet\nneural network based on an approximation of the AUC (aAUC) learns how to\ndiscriminate between pairs of examples from the same identity and pairs of\ndifferent identities. The different alignment techniques to produce\nsupervectors in addition to the new back-end approach were tested on the\nRSR2015-Part I database for text-dependent speaker verification, providing\ncompetitive results compared to similar size networks using the global average\npooling to extract supervectors and using a simple back-end or triplet loss\ntraining.", "published": "2019-01-31 12:37:57", "link": "http://arxiv.org/abs/1901.11332v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "End-to-End Probabilistic Inference for Nonstationary Audio Analysis", "abstract": "A typical audio signal processing pipeline includes multiple disjoint\nanalysis stages, including calculation of a time-frequency representation\nfollowed by spectrogram-based feature analysis. We show how time-frequency\nanalysis and nonnegative matrix factorisation can be jointly formulated as a\nspectral mixture Gaussian process model with nonstationary priors over the\namplitude variance parameters. Further, we formulate this nonlinear model's\nstate space representation, making it amenable to infinite-horizon Gaussian\nprocess regression with approximate inference via expectation propagation,\nwhich scales linearly in the number of time steps and quadratically in the\nstate dimensionality. By doing so, we are able to process audio signals with\nhundreds of thousands of data points. We demonstrate, on various tasks with\nempirical data, how this inference scheme outperforms more standard techniques\nthat rely on extended Kalman filtering.", "published": "2019-01-31 15:47:47", "link": "http://arxiv.org/abs/1901.11436v5", "categories": ["stat.ML", "cs.LG", "cs.SD", "eess.AS", "eess.SP"], "primary_category": "stat.ML"}
