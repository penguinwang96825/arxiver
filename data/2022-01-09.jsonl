{"title": "Indian Language Wordnets and their Linkages with Princeton WordNet", "abstract": "Wordnets are rich lexico-semantic resources. Linked wordnets are extensions\nof wordnets, which link similar concepts in wordnets of different languages.\nSuch resources are extremely useful in many Natural Language Processing (NLP)\napplications, primarily those based on knowledge-based approaches. In such\napproaches, these resources are considered as gold standard/oracle. Thus, it is\ncrucial that these resources hold correct information. Thereby, they are\ncreated by human experts. However, human experts in multiple languages are hard\nto come by. Thus, the community would benefit from sharing of such manually\ncreated resources. In this paper, we release mappings of 18 Indian language\nwordnets linked with Princeton WordNet. We believe that availability of such\nresources will have a direct impact on the progress in NLP for these languages.", "published": "2022-01-09 10:12:31", "link": "http://arxiv.org/abs/2201.02977v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Ensemble Approach to Acronym Extraction using Transformers", "abstract": "Acronyms are abbreviated units of a phrase constructed by using initial\ncomponents of the phrase in a text. Automatic extraction of acronyms from a\ntext can help various Natural Language Processing tasks like machine\ntranslation, information retrieval, and text summarisation. This paper\ndiscusses an ensemble approach for the task of Acronym Extraction, which\nutilises two different methods to extract acronyms and their corresponding long\nforms. The first method utilises a multilingual contextual language model and\nfine-tunes the model to perform the task. The second method relies on a\nconvolutional neural network architecture to extract acronyms and append them\nto the output of the previous method. We also augment the official training\ndataset with additional training samples extracted from several open-access\njournals to help improve the task performance. Our dataset analysis also\nhighlights the noise within the current task dataset. Our approach achieves the\nfollowing macro-F1 scores on test data released with the task: Danish (0.74),\nEnglish-Legal (0.72), English-Scientific (0.73), French (0.63), Persian (0.57),\nSpanish (0.65), Vietnamese (0.65). We release our code and models publicly.", "published": "2022-01-09 14:49:46", "link": "http://arxiv.org/abs/2201.03026v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Projection: A Mixed-Initiative Research Process", "abstract": "Communication of dense information between humans and machines is relatively\nlow bandwidth. Many modern search and recommender systems operate as machine\nlearning black boxes, giving little insight as to how they represent\ninformation or why they take certain actions. We present Projection, a\nmixed-initiative interface that aims to increase the bandwidth of communication\nbetween humans and machines throughout the research process. The interface\nsupports adding context to searches and visualizing information in multiple\ndimensions with techniques such as hierarchical clustering and spatial\nprojections. Potential customers have shown interest in the application\nintegrating their research outlining and search processes, enabling them to\nstructure their searches in hierarchies, and helping them visualize related\nspaces of knowledge.", "published": "2022-01-09 23:25:12", "link": "http://arxiv.org/abs/2201.03107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot and Few-Shot Classification of Biomedical Articles in Context\n  of the COVID-19 Pandemic", "abstract": "MeSH (Medical Subject Headings) is a large thesaurus created by the National\nLibrary of Medicine and used for fine-grained indexing of publications in the\nbiomedical domain. In the context of the COVID-19 pandemic, MeSH descriptors\nhave emerged in relation to articles published on the corresponding topic.\nZero-shot classification is an adequate response for timely labeling of the\nstream of papers with MeSH categories. In this work, we hypothesise that rich\nsemantic information available in MeSH has potential to improve BioBERT\nrepresentations and make them more suitable for zero-shot/few-shot tasks. We\nframe the problem as determining if MeSH term definitions, concatenated with\npaper abstracts are valid instances or not, and leverage multi-task learning to\ninduce the MeSH hierarchy in the representations thanks to a seq2seq task.\nResults establish a baseline on the MedLine and LitCovid datasets, and probing\nshows that the resulting representations convey the hierarchical relations\npresent in MeSH.", "published": "2022-01-09 14:12:48", "link": "http://arxiv.org/abs/2201.03017v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Medication Error Detection Using Contextual Language Models", "abstract": "Medication errors most commonly occur at the ordering or prescribing stage,\npotentially leading to medical complications and poor health outcomes. While it\nis possible to catch these errors using different techniques; the focus of this\nwork is on textual and contextual analysis of prescription information to\ndetect and prevent potential medication errors. In this paper, we demonstrate\nhow to use BERT-based contextual language models to detect anomalies in written\nor spoken text based on a data set extracted from real-world medical data of\nthousands of patient records. The proposed models are able to learn patterns of\ntext dependency and predict erroneous output based on contextual information\nsuch as patient data. The experimental results yield accuracy up to 96.63% for\ntext input and up to 79.55% for speech input, which is satisfactory for most\nreal-world applications.", "published": "2022-01-09 15:21:54", "link": "http://arxiv.org/abs/2201.03035v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards the Next 1000 Languages in Multilingual Machine Translation:\n  Exploring the Synergy Between Supervised and Self-Supervised Learning", "abstract": "Achieving universal translation between all human language pairs is the\nholy-grail of machine translation (MT) research. While recent progress in\nmassively multilingual MT is one step closer to reaching this goal, it is\nbecoming evident that extending a multilingual MT system simply by training on\nmore parallel data is unscalable, since the availability of labeled data for\nlow-resource and non-English-centric language pairs is forbiddingly limited. To\nthis end, we present a pragmatic approach towards building a multilingual MT\nmodel that covers hundreds of languages, using a mixture of supervised and\nself-supervised objectives, depending on the data availability for different\nlanguage pairs. We demonstrate that the synergy between these two training\nparadigms enables the model to produce high-quality translations in the\nzero-resource setting, even surpassing supervised translation quality for low-\nand mid-resource languages. We conduct a wide array of experiments to\nunderstand the effect of the degree of multilingual supervision, domain\nmismatches and amounts of parallel and monolingual data on the quality of our\nself-supervised multilingual models. To demonstrate the scalability of the\napproach, we train models with over 200 languages and demonstrate high\nperformance on zero-resource translation on several previously under-studied\nlanguages. We hope our findings will serve as a stepping stone towards enabling\ntranslation for the next thousand languages.", "published": "2022-01-09 23:36:44", "link": "http://arxiv.org/abs/2201.03110v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic and sentiment analysis of selected Bhagavad Gita translations\n  using BERT-based language framework", "abstract": "It is well known that translations of songs and poems not only break rhythm\nand rhyming patterns, but can also result in loss of semantic information. The\nBhagavad Gita is an ancient Hindu philosophical text originally written in\nSanskrit that features a conversation between Lord Krishna and Arjuna prior to\nthe Mahabharata war. The Bhagavad Gita is also one of the key sacred texts in\nHinduism and is known as the forefront of the Vedic corpus of Hinduism. In the\nlast two centuries, there has been a lot of interest in Hindu philosophy from\nwestern scholars; hence, the Bhagavad Gita has been translated in a number of\nlanguages. However, there is not much work that validates the quality of the\nEnglish translations. Recent progress of language models powered by deep\nlearning has enabled not only translations but a better understanding of\nlanguage and texts with semantic and sentiment analysis. Our work is motivated\nby the recent progress of language models powered by deep learning methods. In\nthis paper, we present a framework that compares selected translations (from\nSanskrit to English) of the Bhagavad Gita using semantic and sentiment\nanalyses. We use hand-labelled sentiment dataset for tuning state-of-art deep\nlearning-based language model known as bidirectional encoder representations\nfrom transformers (BERT). We provide sentiment and semantic analysis for\nselected chapters and verses across translations. Our results show that\nalthough the style and vocabulary in the respective translations vary widely,\nthe sentiment analysis and semantic similarity shows that the message conveyed\nare mostly similar.", "published": "2022-01-09 23:59:11", "link": "http://arxiv.org/abs/2201.03115v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethink the Evaluation for Attack Strength of Backdoor Attacks in\n  Natural Language Processing", "abstract": "It has been shown that natural language processing (NLP) models are\nvulnerable to a kind of security threat called the Backdoor Attack, which\nutilizes a `backdoor trigger' paradigm to mislead the models. The most\nthreatening backdoor attack is the stealthy backdoor, which defines the\ntriggers as text style or syntactic. Although they have achieved an incredible\nhigh attack success rate (ASR), we find that the principal factor contributing\nto their ASR is not the `backdoor trigger' paradigm. Thus the capacity of these\nstealthy backdoor attacks is overestimated when categorized as backdoor\nattacks. Therefore, to evaluate the real attack power of backdoor attacks, we\npropose a new metric called attack successful rate difference (ASRD), which\nmeasures the ASR difference between clean state and poison state models.\nBesides, since the defenses against stealthy backdoor attacks are absent, we\npropose Trigger Breaker, consisting of two too simple tricks that can defend\nagainst stealthy backdoor attacks effectively. Experiments show that our method\nachieves significantly better performance than state-of-the-art defense methods\nagainst stealthy backdoor attacks.", "published": "2022-01-09 12:34:12", "link": "http://arxiv.org/abs/2201.02993v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The relationship between sentiment score and COVID-19 cases in the\n  United States", "abstract": "The coronavirus disease (COVID-19) continues to have devastating effects\nacross the globe. No nation has been free from the uncertainty brought by this\npandemic. The health, social and economic tolls associated with it are causing\nstrong emotions and spreading fear in people of all ages, genders, and races.\nSince the beginning of the COVID-19 pandemic, many have expressed their\nfeelings and opinions related to a wide range of aspects of their lives via\nTwitter. In this study, we consider a framework for extracting sentiment scores\nand opinions from COVID-19 related tweets. We connect users' sentiment with\nCOVID-19 cases across the USA and investigate the effect of specific COVID-19\nmilestones on public sentiment. The results of this work may help with the\ndevelopment of pandemic-related legislation, serve as a guide for scientific\nwork, as well as inform and educate the public on core issues related to the\npandemic.", "published": "2022-01-09 01:07:13", "link": "http://arxiv.org/abs/2202.01708v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Emotional Speaker Identification using a Novel Capsule Nets Model", "abstract": "Speaker recognition systems are widely used in various applications to\nidentify a person by their voice; however, the high degree of variability in\nspeech signals makes this a challenging task. Dealing with emotional variations\nis very difficult because emotions alter the voice characteristics of a person;\nthus, the acoustic features differ from those used to train models in a neutral\nenvironment. Therefore, speaker recognition models trained on neutral speech\nfail to correctly identify speakers under emotional stress. Although\nconsiderable advancements in speaker identification have been made using\nconvolutional neural networks (CNN), CNNs cannot exploit the spatial\nassociation between low-level features. Inspired by the recent introduction of\ncapsule networks (CapsNets), which are based on deep learning to overcome the\ninadequacy of CNNs in preserving the pose relationship between low-level\nfeatures with their pooling technique, this study investigates the performance\nof using CapsNets in identifying speakers from emotional speech recordings. A\nCapsNet-based speaker identification model is proposed and evaluated using\nthree distinct speech databases, i.e., the Emirati Speech Database, SUSAS\nDataset, and RAVDESS (open-access). The proposed model is also compared to\nbaseline systems. Experimental results demonstrate that the novel proposed\nCapsNet model trains faster and provides better results over current\nstate-of-the-art schemes. The effect of the routing algorithm on speaker\nidentification performance was also studied by varying the number of\niterations, both with and without a decoder network.", "published": "2022-01-09 12:37:51", "link": "http://arxiv.org/abs/2201.02994v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Ensemble of Deep Learning Frameworks Applied For Predicting\n  Respiratory Anomalies", "abstract": "In this paper, we evaluate various deep learning frameworks for detecting\nrespiratory anomalies from input audio recordings. To this end, we firstly\ntransform audio respiratory cycles collected from patients into spectrograms\nwhere both temporal and spectral features are presented, referred to as the\nfront-end feature extraction. We then feed the spectrograms into back-end deep\nlearning networks for classifying these respiratory cycles into certain\ncategories. Finally, results from high-performed deep learning frameworks are\nfused to obtain the best score. Our experiments on ICBHI benchmark dataset\nachieve the highest ICBHI score of 57.3 from a late fusion of inception based\nand transfer learning based deep learning frameworks, which outperforms the\nstate-of-the-art systems.", "published": "2022-01-09 16:59:48", "link": "http://arxiv.org/abs/2201.03054v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
