{"title": "Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation", "abstract": "We present Paired by the Teacher (PbT), a two-stage teacher-student pipeline\nthat synthesizes accurate input-output pairs without human labels or parallel\ndata. In many low-resource natural language generation (NLG) scenarios,\npractitioners may have only raw outputs, like highlights, recaps, or questions,\nor only raw inputs, such as articles, dialogues, or paragraphs, but seldom\nboth. This mismatch forces small models to learn from very few examples or rely\non costly, broad-scope synthetic examples produced by large LLMs. PbT addresses\nthis by asking a teacher LLM to compress each unpaired example into a concise\nintermediate representation (IR), and training a student to reconstruct inputs\nfrom IRs. This enables outputs to be paired with student-generated inputs,\nyielding high-quality synthetic data. We evaluate PbT on five\nbenchmarks-document summarization (XSum, CNNDM), dialogue summarization\n(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpaired\nsetting on SwitchBoard (paired with DialogSum summaries). An 8B student trained\nonly on PbT data outperforms models trained on 70 B teacher-generated corpora\nand other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotated\npairs and closing 82% of the oracle gap at one-third the annotation cost of\ndirect synthesis. Human evaluation on SwitchBoard further confirms that only\nPbT produces concise, faithful summaries aligned with the target style,\nhighlighting its advantage of generating in-domain sources that avoid the\nmismatch, limiting direct synthesis.", "published": "2025-09-29 17:51:55", "link": "http://arxiv.org/abs/2509.25144v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models", "abstract": "Existing medical reasoning benchmarks for vision-language models primarily\nfocus on analyzing a patient's condition based on an image from a single visit.\nHowever, this setting deviates significantly from real-world clinical practice,\nwhere doctors typically refer to a patient's historical conditions to provide a\ncomprehensive assessment by tracking their changes over time. In this paper, we\nintroduce TemMed-Bench, the first benchmark designed for analyzing changes in\npatients' conditions between different clinical visits, which challenges large\nvision-language models (LVLMs) to reason over temporal medical images.\nTemMed-Bench consists of a test set comprising three tasks - visual\nquestion-answering (VQA), report generation, and image-pair selection - and a\nsupplementary knowledge corpus of over 17,000 instances. With TemMed-Bench, we\nconduct an evaluation of six proprietary and six open-source LVLMs. Our results\nshow that most LVLMs lack the ability to analyze patients' condition changes\nover temporal medical images, and a large proportion perform only at a\nrandom-guessing level in the closed-book setting. In contrast, GPT o3, o4-mini\nand Claude 3.5 Sonnet demonstrate comparatively decent performance, though they\nhave yet to reach the desired level. Furthermore, we explore augmenting the\ninput with both retrieved visual and textual modalities in the medical domain.\nWe also show that multi-modal retrieval augmentation yields notably higher\nperformance gains than no retrieval and textual retrieval alone across most\nmodels on our benchmark, with the VQA task showing an average improvement of\n2.59%. Overall, we compose a benchmark grounded on real-world clinical\npractice, and it reveals LVLMs' limitations in temporal medical image\nreasoning, as well as highlighting the use of multi-modal retrieval\naugmentation as a potentially promising direction worth exploring to address\nthis challenge.", "published": "2025-09-29 17:51:26", "link": "http://arxiv.org/abs/2509.25143v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory", "abstract": "With the growing adoption of large language model agents in persistent\nreal-world roles, they naturally encounter continuous streams of tasks. A key\nlimitation, however, is their failure to learn from the accumulated interaction\nhistory, forcing them to discard valuable insights and repeat past errors. We\npropose ReasoningBank, a novel memory framework that distills generalizable\nreasoning strategies from an agent's self-judged successful and failed\nexperiences. At test time, an agent retrieves relevant memories from\nReasoningBank to inform its interaction and then integrates new learnings back,\nenabling it to become more capable over time. Building on this powerful\nexperience learner, we further introduce memory-aware test-time scaling\n(MaTTS), which accelerates and diversifies this learning process by scaling up\nthe agent's interaction experience. By allocating more compute to each task,\nthe agent generates abundant, diverse experiences that provide rich contrastive\nsignals for synthesizing higher-quality memory. The better memory in turn\nguides more effective scaling, establishing a powerful synergy between memory\nand test-time scaling. Across web browsing and software engineering benchmarks,\nReasoningBank consistently outperforms existing memory mechanisms that store\nraw trajectories or only successful task routines, improving both effectiveness\nand efficiency; MaTTS further amplifies these gains. These findings establish\nmemory-driven experience scaling as a new scaling dimension, enabling agents to\nself-evolve with emergent behaviors naturally arise.", "published": "2025-09-29 17:51:03", "link": "http://arxiv.org/abs/2509.25140v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Investigating Language and Retrieval Bias in Multilingual Previously Fact-Checked Claim Detection", "abstract": "Multilingual Large Language Models (LLMs) offer powerful capabilities for\ncross-lingual fact-checking. However, these models often exhibit language bias,\nperforming disproportionately better on high-resource languages such as English\nthan on low-resource counterparts. We also present and inspect a novel concept\n- retrieval bias, when information retrieval systems tend to favor certain\ninformation over others, leaving the retrieval process skewed. In this paper,\nwe study language and retrieval bias in the context of Previously Fact-Checked\nClaim Detection (PFCD). We evaluate six open-source multilingual LLMs across 20\nlanguages using a fully multilingual prompting strategy, leveraging the AMC-16K\ndataset. By translating task prompts into each language, we uncover disparities\nin monolingual and cross-lingual performance and identify key trends based on\nmodel family, size, and prompting strategy. Our findings highlight persistent\nbias in LLM behavior and offer recommendations for improving equity in\nmultilingual fact-checking. To investigate retrieval bias, we employed\nmultilingual embedding models and look into the frequency of retrieved claims.\nOur analysis reveals that certain claims are retrieved disproportionately\nacross different posts, leading to inflated retrieval performance for popular\nclaims while under-representing less common ones.", "published": "2025-09-29 17:50:32", "link": "http://arxiv.org/abs/2509.25138v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Era of Real-World Human Interaction: RL from User Conversations", "abstract": "We posit that to achieve continual model improvement and multifaceted\nalignment, future models must learn from natural human interaction. Current\nconversational models are aligned using pre-annotated, expert-generated human\nfeedback. In this work, we introduce Reinforcement Learning from Human\nInteraction (RLHI), a paradigm that learns directly from in-the-wild user\nconversations. We develop two complementary methods: (1) RLHI with User-Guided\nRewrites, which revises unsatisfactory model outputs based on users'\nnatural-language follow-up responses, (2) RLHI with User-Based Rewards, which\nlearns via a reward model conditioned on knowledge of the user's long-term\ninteraction history (termed persona). Together, these methods link long-term\nuser personas to turn-level preferences via persona-conditioned preference\noptimization. Trained on conversations derived from WildChat, both RLHI\nvariants outperform strong baselines in personalization and\ninstruction-following, and similar feedback enhances performance on reasoning\nbenchmarks. These results suggest organic human interaction offers scalable,\neffective supervision for personalized alignment.", "published": "2025-09-29 17:50:31", "link": "http://arxiv.org/abs/2509.25137v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Rethinking Entropy Regularization in Large Reasoning Models", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown great promise\nin enhancing the reasoning abilities of large reasoning models (LRMs). However,\nit suffers from a critical issue: entropy collapse and premature convergence.\nNaive entropy regularization, a common approach for encouraging exploration in\nthe traditional RL literature, fails to address this problem in the context of\nLRM. Our analysis reveals that this failure stems from the vast action space\nand long trajectories in LRMs, which easily trigger a global entropy explosion\nas the model indiscriminately explores all possible actions and states. To\naddress this, we propose SIREN (SelectIve entRopy rEgularizatioN), a method\nthat confines exploration to a meaningful subset of actions and states. SIREN\nachieves this through a two-step entropy masking mechanism, consisting of a\ntop-p mask and a peak-entropy mask. In addition, regularization is transformed\ninto a self-anchored form to stabilize training. Across five mathematical\nbenchmarks, SIREN attains superior average performance over previous\nentropy-related RLVR approaches, exemplified by a +6.6 maj@k improvement on\nAIME24/25 with Qwen2.5-Math-7B. Further analysis confirms that SIREN promotes\ngreater response diversity and maintains entropy at an appropriate level, which\nhelps to preserve the validation pass@k throughout training. This effectively\nmitigates the premature convergence problem common in RLVR for LRM.", "published": "2025-09-29 17:49:25", "link": "http://arxiv.org/abs/2509.25133v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MGM-Omni: Scaling Omni LLMs to Personalized Long-Horizon Speech", "abstract": "We present MGM-Omni, a unified Omni LLM for omni-modal understanding and\nexpressive, long-horizon speech generation. Unlike cascaded pipelines that\nisolate speech synthesis, MGM-Omni adopts a \"brain-mouth\" design with a\ndual-track, token-based architecture that cleanly decouples multimodal\nreasoning from real-time speech generation. This design enables efficient\ncross-modal interaction and low-latency, streaming speech generation. For\nunderstanding, a unified training strategy coupled with a dual audio encoder\ndesign enables long-form audio perception across diverse acoustic conditions.\nFor generation, a chunk-based parallel decoding scheme narrows the text speech\ntoken-rate gap, accelerating inference and supporting streaming zero-shot voice\ncloning with stable timbre over extended durations. Compared to concurrent\nwork, MGM-Omni achieves these capabilities with markedly data-efficient\ntraining. Extensive experiments demonstrate that MGM-Omni outperforms existing\nopen source models in preserving timbre identity across extended sequences,\nproducing natural and context-aware speech, and achieving superior long-form\naudio and omnimodal understanding. MGM-Omni establishes an efficient,\nend-to-end paradigm for omnimodal understanding and controllable, personalised\nlong-horizon speech generation.", "published": "2025-09-29 17:48:28", "link": "http://arxiv.org/abs/2509.25131v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.SD"}
{"title": "From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones", "abstract": "Does RL teach LLMs genuinely new skills, or does it merely activate existing\nones? This question lies at the core of ongoing debates about the role of RL in\nLLM post-training. On one side, strong empirical results can be achieved with\nRL even without preceding supervised finetuning; on the other, critics argue\nthat RL contributes little beyond reweighting existing reasoning strategies.\nThis work provides concrete evidence that LLMs can acquire genuinely new skills\nduring RL by composing existing ones, mirroring one of the central mechanisms\nby which humans acquire new cognitive skills. To mitigate data contamination\nand other confounding factors, and to allow precise control over task\ncomplexity, we develop a synthetic framework for our investigation.\nSpecifically, we define a skill as the ability to infer the output of a string\ntransformation function f(x) given x. When an LLM has already learned f and g\nprior to RL, our experiments reveal that RL enables it to learn unseen\ncompositions of them h(x)=g(f(x)). Further, this compositional ability\ngeneralizes to more difficult problems such as compositions of >2 functions\nunseen during RL training. Surprisingly, our experiments show that\ncompositional skill acquired on a source task transfers to a different target\ntask. This transfer happens even without compositional training on the target,\nrequiring only prior knowledge of the target's atomic skills. Our qualitative\nanalysis shows that RL fundamentally changes the reasoning behaviors of the\nmodels. In contrast, next-token training with the same data yields none of\nthese findings. Our systematic experiments provide fresh insights into LLM\nlearning, suggesting the value of first building base models with basic skills,\nthen using RL to incentivize advanced, generalizable skills for complex\nproblems.", "published": "2025-09-29 17:44:27", "link": "http://arxiv.org/abs/2509.25123v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Knowledge Extraction on Semi-Structured Content: Does It Remain Relevant for Question Answering in the Era of LLMs?", "abstract": "The advent of Large Language Models (LLMs) has significantly advanced\nweb-based Question Answering (QA) systems over semi-structured content, raising\nquestions about the continued utility of knowledge extraction for question\nanswering. This paper investigates the value of triple extraction in this new\nparadigm by extending an existing benchmark with knowledge extraction\nannotations and evaluating commercial and open-source LLMs of varying sizes.\nOur results show that web-scale knowledge extraction remains a challenging task\nfor LLMs. Despite achieving high QA accuracy, LLMs can still benefit from\nknowledge extraction, through augmentation with extracted triples and\nmulti-task learning. These findings provide insights into the evolving role of\nknowledge triple extraction in web-based QA and highlight strategies for\nmaximizing LLM effectiveness across different model sizes and resource\nsettings.", "published": "2025-09-29 17:39:19", "link": "http://arxiv.org/abs/2509.25107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Personalized Deep Research: Benchmarks and Evaluations", "abstract": "Deep Research Agents (DRAs) can autonomously conduct complex investigations\nand generate comprehensive reports, demonstrating strong real-world potential.\nHowever, existing evaluations mostly rely on close-ended benchmarks, while\nopen-ended deep research benchmarks remain scarce and typically neglect\npersonalized scenarios. To bridge this gap, we introduce Personalized Deep\nResearch Bench, the first benchmark for evaluating personalization in DRAs. It\npairs 50 diverse research tasks across 10 domains with 25 authentic user\nprofiles that combine structured persona attributes with dynamic real-world\ncontexts, yielding 250 realistic user-task queries. To assess system\nperformance, we propose the PQR Evaluation Framework, which jointly measures\n(P) Personalization Alignment, (Q) Content Quality, and (R) Factual\nReliability. Our experiments on a range of systems highlight current\ncapabilities and limitations in handling personalized deep research. This work\nestablishes a rigorous foundation for developing and evaluating the next\ngeneration of truly personalized AI research assistants.", "published": "2025-09-29 17:39:17", "link": "http://arxiv.org/abs/2509.25106v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ORPO-Distill: Mixed-Policy Preference Optimization for Cross-Architecture LLM Distillation", "abstract": "We introduce ORPO-Distill, a general-purpose method for cross-architecture\nLLM distillation that formulates the problem as a preference optimization task.\nUnlike standard CoT distillation, the approach transfers knowledge through\ndiverse reasoning traces. It employs an Odds-Ratio Preference Optimization\nobjective that contrasts teacher and student traces for more effective\nlearning, and adopts a mixed-policy strategy for utilizing student-generated\noutputs, outperforming both off- and on-policy alternatives. Experiments on\nfive datasets and multiple student models show consistent improvements over\nconventional black-box KD baselines.", "published": "2025-09-29 17:34:02", "link": "http://arxiv.org/abs/2509.25100v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Scaling with Collapse: Efficient and Predictable Training of LLM Families", "abstract": "Effective LLM training relies on *consistency*, meaning that key quantities\n-- such as final losses and optimal hyperparameters -- scale predictably across\nmodel sizes. Qiu et al. (2025) recently showed that this consistency extends\nbeyond scalars: whole training loss curves can *collapse* onto a universal\ntrajectory after a simple normalization. What remains unclear is whether this\nphenomenon holds for LLM families trained under *practical scaling recipes*,\nwhere width, depth, learning rate, batch size, and weight decay are scaled\njointly. We show that it does: loss curves collapse across scales precisely\nwhen optimization hyperparameters are set optimally for the given data budget,\nin accordance with recent empirical scaling laws. Collapse thus emerges as a\nsignature of compute-efficient training. We demonstrate two applications at\nscale: (1) deviation-from-collapse provides a sensitive, early diagnostic of\ntraining pathologies, and (2) the predictability of collapsed curves enables\nearly stopping in large-scale hyperparameter tuning. Finally, we train a\ncompetitive LLM family, *Celerity*, using these insights, highlighting collapse\nas an effective tool for developing efficient LLMs.", "published": "2025-09-29 17:26:11", "link": "http://arxiv.org/abs/2509.25087v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Trustworthy Lexical Simplification: Exploring Safety and Efficiency with Small LLMs", "abstract": "Despite their strong performance, large language models (LLMs) face\nchallenges in real-world application of lexical simplification (LS),\nparticularly in privacy-sensitive and resource-constrained environments.\nMoreover, since vulnerable user groups (e.g., people with disabilities) are one\nof the key target groups of this technology, it is crucial to ensure the safety\nand correctness of the output of LS systems. To address these issues, we\npropose an efficient framework for LS systems that utilizes small LLMs\ndeployable in local environments. Within this framework, we explore knowledge\ndistillation with synthesized data and in-context learning as baselines. Our\nexperiments in five languages evaluate model outputs both automatically and\nmanually. Our manual analysis reveals that while knowledge distillation boosts\nautomatic metric scores, it also introduces a safety trade-off by increasing\nharmful simplifications. Importantly, we find that the model's output\nprobability is a useful signal for detecting harmful simplifications.\nLeveraging this, we propose a filtering strategy that suppresses harmful\nsimplifications while largely preserving beneficial ones. This work establishes\na benchmark for efficient and safe LS with small LLMs. It highlights the key\ntrade-offs between performance, efficiency, and safety, and demonstrates a\npromising approach for safe real-world deployment.", "published": "2025-09-29 17:25:56", "link": "http://arxiv.org/abs/2509.25086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "jina-reranker-v3: Last but Not Late Interaction for Document Reranking", "abstract": "jina-reranker-v3 is a 0.6B parameter multilingual document reranker that\nintroduces a novel last but not late interaction. Unlike late interaction\nmodels such as ColBERT that perform separate encoding followed by multi-vector\nmatching, our approach conducts causal self-attention between query and\ndocuments within the same context window, enabling rich cross-document\ninteractions before extracting contextual embeddings from the last token of\neach document. This compact architecture achieves state-of-the-art BEIR\nperformance with 61.94 nDCG@10 while being ten times smaller than generative\nlistwise rerankers.", "published": "2025-09-29 17:23:54", "link": "http://arxiv.org/abs/2509.25085v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Scaling Generalist Data-Analytic Agents", "abstract": "Data-analytic agents are emerging as a key catalyst for automated scientific\ndiscovery and for the vision of Innovating AI. Current approaches, however,\nrely heavily on prompt engineering over proprietary models, while open-source\nmodels struggle to face diverse-format, large-scale data files and\nlong-horizon, multi-step reasoning that real-world analytics demands. This\npaper introduces DataMind, a scalable data synthesis and agent training recipe\ndesigned to build generalist data-analytic agents. DataMind tackles three key\nchallenges in building open-source data-analytic agents, including insufficient\ndata resources, improper training strategy, and unstable code-based multi-turn\nrollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and a\nrecursive easy-to-hard task composition mechanism to increase the diversity and\ndifficulty of synthesized queries; 2) a knowledge-augmented trajectory sampling\nstrategy followed by model-based and rule-based filtering; 3) a dynamically\nadjustable training objective combining both SFT and RL losses; 4) a\nmemory-frugal and stable code-based multi-turn rollout framework. Built on\nDataMind, we curate DataMind-12K, a high-quality trajectory set spanning\ndiverse domains, task categories, and data file formats for data-analytic\ntasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art with\nan average score of 71.16% on multiple data analysis benchmarks, outperforming\nthe strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7B\nalso performs best among all open-source models with a score of 68.10%. We also\nincorporate some empirical insights gained from our exploratory trials into the\nanalysis experiments, aiming to provide actionable insights about agentic\ntraining for the community. We will release DataMind-12K and DataMind-7B,14B\nfor the community's future research.", "published": "2025-09-29 17:23:08", "link": "http://arxiv.org/abs/2509.25084v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An empirical study on the limitation of Transformers in program trace generation", "abstract": "We study Transformers on the task \\emph{program trace generation} (PTG),\nwhere models produce step-by-step execution traces for synthetic programs.\nUnlike existing algorithmic problems, PTG externalizes reasoning through long\ntraces where each step is trivial. We train small Transformers with diverse\nmodifications, including alternative position encodings, softmax replacements,\nhybrid model, and short convolutions. While these models achieve strong\nin-distribution accuracy, they exhibit systematic failures when generalizing to\nvarious factors (e.g., program length, trace steps), though some designs\nsignificantly improve generalization.", "published": "2025-09-29 17:17:07", "link": "http://arxiv.org/abs/2509.25073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study", "abstract": "Survey researchers face two key challenges: the rising costs of probability\nsamples and missing data (e.g., non-response or attrition), which can undermine\ninference and increase the use of convenience samples. Recent work explores\nusing large language models (LLMs) to simulate respondents via persona-based\nprompts, often without labeled data. We study a more practical setting where\npartial survey responses exist: we fine-tune LLMs on available data to impute\nself-reported vote choice under both random and systematic nonresponse, using\nthe German Longitudinal Election Study. We compare zero-shot prompting and\nsupervised fine-tuning against tabular classifiers (e.g., CatBoost) and test\nhow different convenience samples (e.g., students) used for fine-tuning affect\ngeneralization.\n  Our results show that when data are missing completely at random, fine-tuned\nLLMs match tabular classifiers but outperform zero-shot approaches. When only\nbiased convenience samples are available, fine-tuning small (3B to 8B)\nopen-source LLMs can recover both individual-level predictions and\npopulation-level distributions more accurately than zero-shot and often better\nthan tabular methods. This suggests fine-tuned LLMs offer a promising strategy\nfor researchers working with non-probability samples or systematic missingness,\nand may enable new survey designs requiring only easily accessible\nsubpopulations.", "published": "2025-09-29 17:12:18", "link": "http://arxiv.org/abs/2509.25063v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Confidence-Guided Error Correction for Disordered Speech Recognition", "abstract": "We investigate the use of large language models (LLMs) as post-processing\nmodules for automatic speech recognition (ASR), focusing on their ability to\nperform error correction for disordered speech. In particular, we propose\nconfidence-informed prompting, where word-level uncertainty estimates are\nembedded directly into LLM training to improve robustness and generalization\nacross speakers and datasets. This approach directs the model to uncertain ASR\nregions and reduces overcorrection. We fine-tune a LLaMA 3.1 model and compare\nour approach to both transcript-only fine-tuning and post hoc confidence-based\nfiltering. Evaluations show that our method achieves a 10% relative WER\nreduction compared to naive LLM correction on the Speech Accessibility Project\nspontaneous speech and a 47% reduction on TORGO, demonstrating the\neffectiveness of confidence-aware fine-tuning for impaired speech.", "published": "2025-09-29 17:00:38", "link": "http://arxiv.org/abs/2509.25048v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures", "abstract": "Despite their capabilities, Large Language Models (LLMs) remain opaque with\nlimited understanding of their internal representations. Current\ninterpretability methods, such as direct logit attribution (DLA) and sparse\nautoencoders (SAEs), provide restricted insight due to limitations such as the\nmodel's output vocabulary or unclear feature names. This work introduces\nHyperdimensional Probe, a novel paradigm for decoding information from the LLM\nvector space. It combines ideas from symbolic representations and neural\nprobing to project the model's residual stream into interpretable concepts via\nVector Symbolic Architectures (VSAs). This probe combines the strengths of SAEs\nand conventional probes while overcoming their key limitations. We validate our\ndecoding paradigm with controlled input-completion tasks, probing the model's\nfinal state before next-token prediction on inputs spanning syntactic pattern\nrecognition, key-value associations, and abstract inference. We further assess\nit in a question-answering setting, examining the state of the model both\nbefore and after text generation. Our experiments show that our probe reliably\nextracts meaningful concepts across varied LLMs, embedding sizes, and input\ndomains, also helping identify LLM failures. Our work advances information\ndecoding in LLM vector space, enabling extracting more informative,\ninterpretable, and structured features from neural representations.", "published": "2025-09-29 16:59:07", "link": "http://arxiv.org/abs/2509.25045v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GateMABSA: Aspect-Image Gated Fusion for Multimodal Aspect-based Sentiment Analysis", "abstract": "Aspect-based Sentiment Analysis (ABSA) has recently advanced into the\nmultimodal domain, where user-generated content often combines text and images.\nHowever, existing multimodal ABSA (MABSA) models struggle to filter noisy\nvisual signals, and effectively align aspects with opinion-bearing content\nacross modalities. To address these challenges, we propose GateMABSA, a novel\ngated multimodal architecture that integrates syntactic, semantic, and\nfusion-aware mLSTM. Specifically, GateMABSA introduces three specialized\nmLSTMs: Syn-mLSTM to incorporate syntactic structure, Sem-mLSTM to emphasize\naspect--semantic relevance, and Fuse-mLSTM to perform selective multimodal\nfusion. Extensive experiments on two benchmark Twitter datasets demonstrate\nthat GateMABSA outperforms several baselines.", "published": "2025-09-29 16:56:10", "link": "http://arxiv.org/abs/2509.25037v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct", "abstract": "Fast generation of language texts is the holy grail that people pursue in the\nAI era. In this work, we introduced Discrete Diffusion Divergence Instruct\n(DiDi-Instruct), a training-based method that leads to fast language generation\nmodels by initializing from a pre-trained (masked) discrete diffusion language\nmodel (dLLM). The resulting DiDi-Instruct model outperforms the dLLM\ncounterparts and the GPT-2 baseline with 64x acceleration. In the theoretical\npart of the paper, we build the foundation of DiDi-Instruct in a framework of\nintegral KL-divergence minimization, with practical training algorithms. We\nalso introduce techniques like grouped reward normalization, intermediate-state\nmatching, and the reward-guided ancestral sampler (RGAS) that significantly\nimprove the training stability, the model coverage, and the inference\nperformances. On OpenWebText, DiDi-Instruct outperforms all accelerated\nlanguage generation models as well as the GPT-2 baseline and the standard\ndLLMs, achieving sample perplexities ranging from 62.2 (8 NFEs) to 18.4 (128\nNFEs). These performance gains are accomplished with a negligible entropy loss\nof about 1% and 20x less additional training wall-clock time. We further\nvalidate the robustness and effectiveness of DiDi-Instruct through extensive\nablation studies, model scaling, and the generation of discrete protein\nsequences. In conclusion, DiDi-Instruct is an efficient yet effective\ndistillation method, enabling language generation in the blink of an eye. We\nwill release both code and models at github.com/haoyangzheng-ai/didi-instruct.", "published": "2025-09-29 16:55:44", "link": "http://arxiv.org/abs/2509.25035v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Circuit Distillation", "abstract": "Model distillation typically focuses on behavioral mimicry, where a student\nmodel is trained to replicate a teacher's output while treating its internal\ncomputations as a black box. In this work we propose an alternative approach:\nDistilling the underlying computational mechanisms implemented by a teacher\nmodel. Specifically, we propose circuit distillation, which introduces an\nobjective to align internal representations between analogous circuit\ncomponents in teacher and student models. We propose a method to match\n``functionally correspondent'' circuit components and introduce a loss\nreflecting similarities between the representations that these induce. We\nevaluate circuit distillation on entity tracking and theory of mind (ToM) tasks\nusing models from the Llama3 family. Our results demonstrate that circuit\ndistillation outperforms standard distillation, successfully transferring\nalgorithmic capabilities by adjusting only a small, targeted subset of student\nmodel parameters. This work establishes the feasibility of transferring\nmechanisms, which may in turn allow for efficient distillation of targeted\nteacher capabilities via interpretable and controllable internal student\nmechanisms.", "published": "2025-09-29 16:28:36", "link": "http://arxiv.org/abs/2509.25002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalized Correctness Models: Learning Calibrated and Model-Agnostic Correctness Predictors from Historical Patterns", "abstract": "Generating accurate and calibrated confidence estimates is critical for\ndeploying LLMs in high-stakes or user-facing applications, and remains an open\nchallenge. Prior research has often framed confidence as a problem of eliciting\na model's \"self-knowledge\", i.e., the ability of an LLM to judge whether its\nown answers are correct; this approach implicitly assumes that there is some\nprivileged information about the answer's correctness that is accessible to the\nmodel itself. However, our experiments reveal that an LLM attempting to predict\nthe correctness of its own outputs generally performs no better than an\nunrelated LLM. Moreover, we hypothesize that a key factor in building a\n\"Correctness Model\" (CM) is exposure to a target model's historical\npredictions. We propose multiple methods to inject this historical correctness\ninformation, creating a Generalized Correctness Model (GCM). We first show that\nGCMs can be trained on the correctness data from many LLMs and learn patterns\nfor correctness prediction applicable across datasets and models. We then use\nCMs as a lens for studying the source of correctness prediction ability and its\ngeneralization, systematically controlling their training data and finding that\nanswer phrasing is a strong predictor for correctness. We further explore\nalternative methods of injecting history without training an LLM, finding that\nincluding history as in-context examples can help improve correctness\nprediction, and post-hoc calibration can provide complementary reductions in\ncalibration error. We evaluate GCMs based on Qwen3-8B across 5 model families\nand the MMLU and TriviaQA datasets, as well as on a downstream selective\nprediction task, finding that reliable LLM confidence estimation is a\ngeneralizable and model-agnostic skill learned by systematically encoding\ncorrectness history rather than a model-specific skill reliant on\nself-introspection.", "published": "2025-09-29 16:19:01", "link": "http://arxiv.org/abs/2509.24988v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern", "abstract": "Software development relies heavily on extensive unit testing, which makes\nthe efficiency of automated Unit Test Generation (UTG) particularly important.\nHowever, most existing LLMs generate test cases one token at a time in each\nforward pass, which leads to inefficient UTG. Recently, diffusion LLMs (dLLMs)\nhave emerged, offering promising parallel generation capabilities and showing\nstrong potential for efficient UTG. Despite this advantage, their application\nto UTG is still constrained by a clear trade-off between efficiency and test\nquality, since increasing the number of tokens generated in each step often\ncauses a sharp decline in the quality of test cases. To overcome this\nlimitation, we present DiffTester, an acceleration framework specifically\ntailored for dLLMs in UTG. The key idea of DiffTester is that unit tests\ntargeting the same focal method often share repetitive structural patterns. By\ndynamically identifying these common patterns through abstract syntax tree\nanalysis during generation, DiffTester adaptively increases the number of\ntokens produced at each step without compromising the quality of the output. To\nenable comprehensive evaluation, we extend the original TestEval benchmark,\nwhich was limited to Python, by introducing additional programming languages\nincluding Java and C++. Extensive experiments on three benchmarks with two\nrepresentative models show that DiffTester delivers significant acceleration\nwhile preserving test coverage. Moreover, DiffTester generalizes well across\ndifferent dLLMs and programming languages, providing a practical and scalable\nsolution for efficient UTG in software development. Code and data are publicly\navailable at https://github.com/wellbeingyang/DLM4UTG-open .", "published": "2025-09-29 16:04:18", "link": "http://arxiv.org/abs/2509.24975v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SemanticShield: LLM-Powered Audits Expose Shilling Attacks in Recommender Systems", "abstract": "Recommender systems (RS) are widely used in e-commerce for personalized\nsuggestions, yet their openness makes them susceptible to shilling attacks,\nwhere adversaries inject fake behaviors to manipulate recommendations. Most\nexisting defenses emphasize user-side behaviors while overlooking item-side\nfeatures such as titles and descriptions that can expose malicious intent. To\naddress this gap, we propose a two-stage detection framework that integrates\nitem-side semantics via large language models (LLMs). The first stage\npre-screens suspicious users using low-cost behavioral criteria, and the second\nstage employs LLM-based auditing to evaluate semantic consistency. Furthermore,\nwe enhance the auditing model through reinforcement fine-tuning on a\nlightweight LLM with carefully designed reward functions, yielding a\nspecialized detector called SemanticShield. Experiments on six representative\nattack strategies demonstrate the effectiveness of SemanticShield against\nshilling attacks, and further evaluation on previously unseen attack methods\nshows its strong generalization capability. Code is available at\nhttps://github.com/FrankenstLee/SemanticShield.", "published": "2025-09-29 15:53:47", "link": "http://arxiv.org/abs/2509.24961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Dialogue That Heals: A Comprehensive Evaluation of Doctor Agents' Inquiry Capability", "abstract": "An effective physician should possess a combination of empathy, expertise,\npatience, and clear communication when treating a patient. Recent advances have\nsuccessfully endowed AI doctors with expert diagnostic skills, particularly the\nability to actively seek information through inquiry. However, other essential\nqualities of a good doctor remain overlooked. To bridge this gap, we present\nMAQuE(Medical Agent Questioning Evaluation), the largest-ever benchmark for the\nautomatic and comprehensive evaluation of medical multi-turn questioning. It\nfeatures 3,000 realistically simulated patient agents that exhibit diverse\nlinguistic patterns, cognitive limitations, emotional responses, and tendencies\nfor passive disclosure. We also introduce a multi-faceted evaluation framework,\ncovering task success, inquiry proficiency, dialogue competence, inquiry\nefficiency, and patient experience. Experiments on different LLMs reveal\nsubstantial challenges across the evaluation aspects. Even state-of-the-art\nmodels show significant room for improvement in their inquiry capabilities.\nThese models are highly sensitive to variations in realistic patient behavior,\nwhich considerably impacts diagnostic accuracy. Furthermore, our fine-grained\nmetrics expose trade-offs between different evaluation perspectives,\nhighlighting the challenge of balancing performance and practicality in\nreal-world clinical settings.", "published": "2025-09-29 15:52:36", "link": "http://arxiv.org/abs/2509.24958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MobileLLM-R1: Exploring the Limits of Sub-Billion Language Model Reasoners with Open Training Recipes", "abstract": "The paradigm shift in large language models (LLMs) from instinctive responses\nto chain-of-thought (CoT) reasoning has fueled two prevailing assumptions: (1)\nreasoning capabilities only emerge in sufficiently large models, and (2) such\ncapabilities require training on massive datasets. While the first assumption\nhas already been challenged by recent sub-billion-parameter reasoning models\nsuch as Qwen3-0.6B and DeepSeek distilled variants, the second remains largely\nunquestioned. In this work, we revisit the necessity of scaling to extremely\nlarge corpora (>10T tokens) for reasoning emergence. By carefully curating and\nresampling open-source datasets that we identify as beneficial under our\ndesigned metrics, we demonstrate that strong reasoning abilities can emerge\nwith far less data. Specifically, we show that only ~2T tokens of high-quality\ndata are sufficient, and pre-training with 4.2T tokens on the dataset resampled\nfrom these ~2T tokens, followed by a established post-training procedure,\nenables the development of MobileLLM-R1, a series of sub-billion-parameter\nreasoning models that substantially outperform prior models trained on fully\nopen-sourced data. For example, MobileLLM-R1-950M achieves an AIME score of\n15.5, compared to just 0.6 for OLMo-2-1.48B and 0.3 for SmolLM-2-1.7B.\nRemarkably, despite being trained on only 11.7% of the tokens compared to\nQwen3's proprietary 36T-token corpus for pretraining, MobileLLM-R1-950M matches\nor surpasses Qwen3-0.6B across multiple reasoning benchmarks. To facilitate\nfurther research in this direction, we have released the complete training\nrecipe, data sources, data mixing ratio, and model checkpoints, together with\nthe key insights obtained throughout this study.", "published": "2025-09-29 15:43:59", "link": "http://arxiv.org/abs/2509.24945v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Well Do LLMs Imitate Human Writing Style?", "abstract": "Large language models (LLMs) can generate fluent text, but their ability to\nreplicate the distinctive style of a specific human author remains unclear. We\npresent a fast, training-free framework for authorship verification and style\nimitation analysis. The method integrates TF-IDF character n-grams with\ntransformer embeddings and classifies text pairs through empirical distance\ndistributions, eliminating the need for supervised training or threshold\ntuning. It achieves 97.5\\% accuracy on academic essays and 94.5\\% in\ncross-domain evaluation, while reducing training time by 91.8\\% and memory\nusage by 59\\% relative to parameter-based baselines. Using this framework, we\nevaluate five LLMs from three separate families (Llama, Qwen, Mixtral) across\nfour prompting strategies - zero-shot, one-shot, few-shot, and text completion.\nResults show that the prompting strategy has a more substantial influence on\nstyle fidelity than model size: few-shot prompting yields up to 23.5x higher\nstyle-matching accuracy than zero-shot, and completion prompting reaches 99.9\\%\nagreement with the original author's style. Crucially, high-fidelity imitation\ndoes not imply human-like unpredictability - human essays average a perplexity\nof 29.5, whereas matched LLM outputs average only 15.2. These findings\ndemonstrate that stylistic fidelity and statistical detectability are\nseparable, establishing a reproducible basis for future work in authorship\nmodeling, detection, and identity-conditioned generation.", "published": "2025-09-29 15:34:40", "link": "http://arxiv.org/abs/2509.24930v1", "categories": ["cs.CL", "cs.CY", "I.2.7"], "primary_category": "cs.CL"}
{"title": "When Greedy Wins: Emergent Exploitation Bias in Meta-Bandit LLM Training", "abstract": "While Large Language Models (LLMs) hold promise to become autonomous agents,\nthey often explore suboptimally in sequential decision-making. Recent work has\nsought to enhance this capability via supervised fine-tuning (SFT) or\nreinforcement learning (RL), improving regret on the classic multi-armed bandit\ntask. However, it remains unclear how these learning methods shape exploration\nstrategies and how well they generalize. We investigate both paradigms by\ntraining LLMs with SFT on expert trajectories and RL with a range of tailored\nreward signals including a strategic, regret-shaped reward to reduce variance,\nand an algorithmic reward that enables oracle imitation. The resulting agents\noutperform pre-trained models and achieve performance comparable to Upper\nConfidence Bound (UCB) and Thompson Sampling, with robust generalization to 6x\nlonger horizons and across bandit families. Behavioral analysis reveals that\ngains often stem from more sophisticated but greedier exploitation: RL/SFT\nagents are more prone to early catastrophic failure than pre-trained models,\nprematurely abandoning exploration. Furthermore, agents trained to imitate UCB\nlearn to outperform their teacher by adopting more exploitative variants. Our\nfindings clarify when each training paradigm is preferable and advocate\ntailored reward design and evaluation beyond average regret to promote robust\nexploratory behavior.", "published": "2025-09-29 15:25:42", "link": "http://arxiv.org/abs/2509.24923v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal Reasoning", "abstract": "Multi-agent systems (MAS), leveraging the remarkable capabilities of Large\nLanguage Models (LLMs), show great potential in addressing complex tasks. In\nthis context, integrating MAS with legal tasks is a crucial step. While\nprevious studies have developed legal benchmarks for LLM agents, none are\nspecifically designed to consider the unique advantages of MAS, such as task\ndecomposition, agent specialization, and flexible training. In fact, the lack\nof evaluation methods limits the potential of MAS in the legal domain. To\naddress this gap, we propose MASLegalBench, a legal benchmark tailored for MAS\nand designed with a deductive reasoning approach. Our benchmark uses GDPR as\nthe application scenario, encompassing extensive background knowledge and\ncovering complex reasoning processes that effectively reflect the intricacies\nof real-world legal situations. Furthermore, we manually design various\nrole-based MAS and conduct extensive experiments using different\nstate-of-the-art LLMs. Our results highlight the strengths, limitations, and\npotential areas for improvement of existing models and MAS architectures.", "published": "2025-09-29 15:24:40", "link": "http://arxiv.org/abs/2509.24922v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "BOE-XSUM: Extreme Summarization in Clear Language of Spanish Legal Decrees and Notifications", "abstract": "The ability to summarize long documents succinctly is increasingly important\nin daily life due to information overload, yet there is a notable lack of such\nsummaries for Spanish documents in general, and in the legal domain in\nparticular. In this work, we present BOE-XSUM, a curated dataset comprising\n3,648 concise, plain-language summaries of documents sourced from Spain's\n``Bolet\\'{\\i}n Oficial del Estado'' (BOE), the State Official Gazette. Each\nentry in the dataset includes a short summary, the original text, and its\ndocument type label. We evaluate the performance of medium-sized large language\nmodels (LLMs) fine-tuned on BOE-XSUM, comparing them to general-purpose\ngenerative models in a zero-shot setting. Results show that fine-tuned models\nsignificantly outperform their non-specialized counterparts. Notably, the\nbest-performing model -- BERTIN GPT-J 6B (32-bit precision) -- achieves a 24\\%\nperformance gain over the top zero-shot model, DeepSeek-R1 (accuracies of\n41.6\\% vs.\\ 33.5\\%).", "published": "2025-09-29 15:15:17", "link": "http://arxiv.org/abs/2509.24908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural network embeddings recover value dimensions from psychometric survey items on par with human data", "abstract": "This study introduces \"Survey and Questionnaire Item Embeddings\nDifferentials\" (SQuID), a novel methodological approach that enables neural\nnetwork embeddings to effectively recover latent dimensions from psychometric\nsurvey items. We demonstrate that embeddings derived from large language\nmodels, when processed with SQuID, can recover the structure of human values\nobtained from human rater judgments on the Revised Portrait Value Questionnaire\n(PVQ-RR). Our experimental validation compares multiple embedding models across\na number of evaluation metrics. Unlike previous approaches, SQuID successfully\naddresses the challenge of obtaining negative correlations between dimensions\nwithout requiring domain-specific fine-tuning. Quantitative analysis reveals\nthat our embedding-based approach explains 55% of variance in\ndimension-dimension similarities compared to human data. Multidimensional\nscaling configurations from both types of data show fair factor congruence\ncoefficients and largely follow the underlying theory. These results\ndemonstrate that semantic embeddings can effectively replicate psychometric\nstructures previously established through extensive human surveys. The approach\noffers substantial advantages in cost, scalability and flexibility while\nmaintaining comparable quality to traditional methods. Our findings have\nsignificant implications for psychometrics and social science research,\nproviding a complementary methodology that could expand the scope of human\nbehavior and experience represented in measurement tools.", "published": "2025-09-29 15:14:54", "link": "http://arxiv.org/abs/2509.24906v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MMRQA: Signal-Enhanced Multimodal Large Language Models for MRI Quality Assessment", "abstract": "Magnetic resonance imaging (MRI) quality assessment is crucial for clinical\ndecision-making, yet remains challenging due to data scarcity and protocol\nvariability. Traditional approaches face fundamental trade-offs: signal-based\nmethods like MRIQC provide quantitative metrics but lack semantic\nunderstanding, while deep learning approaches achieve high accuracy but\nsacrifice interpretability. To address these limitations, we introduce the\nMultimodal MRI Quality Assessment (MMRQA) framework, pioneering the integration\nof multimodal large language models (MLLMs) with acquisition-aware signal\nprocessing. MMRQA combines three key innovations: robust metric extraction via\nMRQy augmented with simulated artifacts, structured transformation of metrics\ninto question-answer pairs using Qwen, and parameter-efficient fusion through\nLow-Rank Adaptation (LoRA) of LLaVA-OneVision. Evaluated on MR-ART, FastMRI,\nand MyConnectome benchmarks, MMRQA achieves state-of-the-art performance with\nstrong zero-shot generalization, as validated by comprehensive ablation\nstudies. By bridging quantitative analysis with semantic reasoning, our\nframework generates clinically interpretable outputs that enhance quality\ncontrol in dynamic medical settings.", "published": "2025-09-29 15:00:19", "link": "http://arxiv.org/abs/2509.24888v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Expanding Computation Spaces of LLMs at Inference Time", "abstract": "Chain-of-thought (CoT) rationale enables language models to use additional\ntask-related text for problem-solving, benefiting not only from detailed\nreasoning steps but also from the expanded computational space of longer\ninputs. Prior work has trained filler or special tokens to serve as additional\ncomputation spaces. In this study, we investigate whether language models can\nleverage artificially inserted sequences of filler tokens solely at inference.\nWe first identify effective token types, numbers, and insertion locations, then\nexamine at what stage of training models begin to exploit the expanded\ncomputation space, and finally analyze dynamics within these spaces via\nattention maps. Experiments on models ranging from 1.7B to 32B across\nopen-domain QA and math tasks show that appropriate token types and counts\nvary, but placing filler tokens directly before the final 'Answer:' token is\nmost effective. Smaller models benefit most, up to 12.372 percentage points in\nSmolLM2-1.7B-Instruct, indicating that these spaces act as additional\ncomputational capacity rather than redundant input. Attention maps reveal that\nexpanded spaces often continue the original attention mechanism and sometimes\nfocus on questions or answer options, suggesting meaningful computation for\nproblem-solving.", "published": "2025-09-29 14:59:44", "link": "http://arxiv.org/abs/2509.24884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retro*: Optimizing LLMs for Reasoning-Intensive Document Retrieval", "abstract": "With the growing popularity of LLM agents and RAG, it has become increasingly\nimportant to retrieve documents that are essential for solving a task, even\nwhen their connection to the task is indirect or implicit. Addressing this\nproblem requires fine-grained reasoning to accurately assess the relevance\nbetween the task and each candidate document. This capability, however, poses a\nsignificant challenge for existing IR techniques. Despite recent progress in\nreasoning-enhanced IR, existing approaches still face significant challenges in\napplicability, scalability, and efficiency. In this work, we propose Retro*, a\nnovel approach for reasoning-intensive document retrieval. Our method\nintroduces a rubric-based relevance scoring mechanism, enabling the model to\nreason about the relationship between a task and a document based on explicitly\ndefined criteria, whereby producing a fine-grained, interpretable relevance\nscore. Retro* also supports test-time scaling by combining multiple reasoning\ntrajectories via score integration, which produces more reliable relevance\nestimates. To optimize Retro*'s reasoning capabilities, we introduce a novel\nreinforcement learning algorithm tailored for its relevance scoring mechanism,\nwhich employs two composite rewards to fully exploit the trajectories of each\ntraining sample. Our experiments show that Retro* outperforms existing document\nretrieval methods with notable advantages, leading to state-of-the-art\nperformance on the BRIGHT benchmark.", "published": "2025-09-29 14:53:05", "link": "http://arxiv.org/abs/2509.24869v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Metaphor identification using large language models: A comparison of RAG, prompt engineering, and fine-tuning", "abstract": "Metaphor is a pervasive feature of discourse and a powerful lens for\nexamining cognition, emotion, and ideology. Large-scale analysis, however, has\nbeen constrained by the need for manual annotation due to the context-sensitive\nnature of metaphor. This study investigates the potential of large language\nmodels (LLMs) to automate metaphor identification in full texts. We compare\nthree methods: (i) retrieval-augmented generation (RAG), where the model is\nprovided with a codebook and instructed to annotate texts based on its rules\nand examples; (ii) prompt engineering, where we design task-specific verbal\ninstructions; and (iii) fine-tuning, where the model is trained on hand-coded\ntexts to optimize performance. Within prompt engineering, we test zero-shot,\nfew-shot, and chain-of-thought strategies. Our results show that\nstate-of-the-art closed-source LLMs can achieve high accuracy, with fine-tuning\nyielding a median F1 score of 0.79. A comparison of human and LLM outputs\nreveals that most discrepancies are systematic, reflecting well-known grey\nareas and conceptual challenges in metaphor theory. We propose that LLMs can be\nused to at least partly automate metaphor identification and can serve as a\ntestbed for developing and refining metaphor identification protocols and the\ntheory that underpins them.", "published": "2025-09-29 14:50:18", "link": "http://arxiv.org/abs/2509.24866v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Between Help and Harm: An Evaluation of Mental Health Crisis Handling by LLMs", "abstract": "The widespread use of chatbots powered by large language models (LLMs) such\nas ChatGPT and Llama has fundamentally reshaped how people seek information and\nadvice across domains. Increasingly, these chatbots are being used in\nhigh-stakes contexts, including emotional support and mental health concerns.\nWhile LLMs can offer scalable support, their ability to safely detect and\nrespond to acute mental health crises remains poorly understood. Progress is\nhampered by the absence of unified crisis taxonomies, robust annotated\nbenchmarks, and empirical evaluations grounded in clinical best practices. In\nthis work, we address these gaps by introducing a unified taxonomy of six\nclinically-informed mental health crisis categories, curating a diverse\nevaluation dataset, and establishing an expert-designed protocol for assessing\nresponse appropriateness. We systematically benchmark three state-of-the-art\nLLMs for their ability to classify crisis types and generate safe, appropriate\nresponses. The results reveal that while LLMs are highly consistent and\ngenerally reliable in addressing explicit crisis disclosures, significant risks\nremain. A non-negligible proportion of responses are rated as inappropriate or\nharmful, with responses generated by an open-weight model exhibiting higher\nfailure rates than those generated by the commercial ones. We also identify\nsystemic weaknesses in handling indirect or ambiguous risk signals, a reliance\non formulaic and inauthentic default replies, and frequent misalignment with\nuser context. These findings underscore the urgent need for enhanced\nsafeguards, improved crisis detection, and context-aware interventions in LLM\ndeployments. Our taxonomy, datasets, and evaluation framework lay the\ngroundwork for ongoing research and responsible innovation in AI-driven mental\nhealth support, helping to minimize harm and better protect vulnerable users.", "published": "2025-09-29 14:42:23", "link": "http://arxiv.org/abs/2509.24857v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Hierarchical Error Correction for Large Language Models: A Systematic Framework for Domain-Specific AI Quality Enhancement", "abstract": "Large Language Models face significant performance challenges in specialized\ndomains, with state-of-the-art models achieving only 45.9% accuracy on medical\ncoding tasks. This study proposes a Hierarchical Error Correction (HEC)\nframework that addresses domain-specific AI limitations through systematic\nerror analysis and targeted intervention strategies.\n  We analyze error patterns across four specialized domains and find that AI\nerrors follow consistent hierarchical structures: Knowledge-layer errors\n(58.4%), Reasoning-layer errors (39.6%), and Complexity-layer errors (2.0%).\nBased on these patterns, we develop a three-stage correction framework that\naddresses errors according to their hierarchical importance and demonstrates\nthat framework effectiveness correlates inversely with baseline task\nperformance.\n  Experimental validation across medical transcription (4,921 cases), legal\ndocument classification (1,000 cases), political bias detection (645 cases),\nand legal reasoning (1,000 cases) shows consistent improvements. Cross-model\nvalidation across five LLM architectures demonstrates average improvements of\n11.2 percentage points (p < 0.001). However, analysis reveals framework\nlimitations in high-baseline tasks (>75% accuracy), where hierarchical\nintervention may interfere with effective reasoning processes.\n  The results suggest that systematic error analysis can guide effective AI\nenhancement strategies in specialized domains, particularly for\nmoderate-baseline tasks, while highlighting the importance of understanding\nframework boundaries for optimal deployment.", "published": "2025-09-29 14:21:05", "link": "http://arxiv.org/abs/2509.24841v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Pushing LLMs to Their Logical Reasoning Bound: The Role of Data Reasoning Intensity", "abstract": "Recent advances in large language models (LLMs) highlight the importance of\ntraining data structure and quality in shaping reasoning behavior. However,\nmost existing approaches focus on transforming data formats while neglecting\nthe internal reasoning complexity of training samples, leaving the reasoning\npotential of data under-explored and underutilized. In this work, we posit that\nLLM logical reasoning performance is jointly constrained by the potential of\nthe training data and the cognitive capacity of the model. To make this\nrelationship measurable, we introduce Data Reasoning Intensity (DRI), a novel\nmetric that quantifies the latent logical reasoning complexity of samples by\ndecomposing and aggregating their logical structures. This allows us to analyze\nhow well current LLMs utilize logical reasoning signals and identify\nperformance gaps relative to data potential. Based on this insight, we\nintroduce a re-cognizing optimization strategy that systematically enhances the\nlogical reasoning intensity of training data.Rather than increasing data\nvolume, our method re-optimizes existing samples to better align with the LLM's\nlogical reasoning boundary. Extensive experiments show that our approach\nsignificantly improves performance and generalization over data-centric\nstrategies. We further validate our method under a reinforcement learning\nframework. Our results indicate that prioritizing reasoning complexity in data\nrather than sheer scale or superficial form is essential to realizing LLMs'\nfull cognitive potential.", "published": "2025-09-29 14:20:04", "link": "http://arxiv.org/abs/2509.24836v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SemShareKV: Efficient KVCache Sharing for Semantically Similar Prompts via Token-Level LSH Matching", "abstract": "As large language models (LLMs) continue to scale, the memory footprint of\nkey-value (KV) caches during inference has become a significant bottleneck.\nExisting approaches primarily focus on compressing KV caches within a single\nprompt or reusing shared prefixes or frequently ocurred text segments across\nprompts. However, such strategies are limited in scenarios where prompts are\nsemantically similar but lexically different, which frequently occurs in tasks\nsuch as multi-document summarization and conversational agents. We propose\n\\textit{SemShareKV}, a KV cache sharing and compression framework that\naccelerates LLM inference by reusing KVCache in semantically similar prompts.\nInstead of relying on exact token matches, SemShareKV applies fuzzy token\nmatching using locality-sensitive hashing (LSH) on token embeddings and\nincorporates Rotary Position Embedding (RoPE) to better preserve positional\ninformation. By selectively reusing relevant key-value pairs from a reference\nprompt's cache, SemShareKV reduces redundant computation while maintaining\noutput quality. Experiments on diverse summarization datasets show up to\n6.25$\\times$ speedup and 42\\% lower GPU memory usage with 5k tokens input, with\nnegligible quality degradation. These results highlight the potential of\nsemantic-aware cache sharing for efficient LLM inference.", "published": "2025-09-29 14:16:13", "link": "http://arxiv.org/abs/2509.24832v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DiaCDM: Cognitive Diagnosis in Teacher-Student Dialogues using the Initiation-Response-Evaluation Framework", "abstract": "While cognitive diagnosis (CD) effectively assesses students' knowledge\nmastery from structured test data, applying it to real-world teacher-student\ndialogues presents two fundamental challenges. Traditional CD models lack a\nsuitable framework for handling dynamic, unstructured dialogues, and it's\ndifficult to accurately extract diagnostic semantics from lengthy dialogues. To\novercome these hurdles, we propose DiaCDM, an innovative model. We've adapted\nthe initiation-response-evaluation (IRE) framework from educational theory to\ndesign a diagnostic framework tailored for dialogue. We also developed a unique\ngraph-based encoding method that integrates teacher questions with relevant\nknowledge components to capture key information more precisely. To our\nknowledge, this is the first exploration of cognitive diagnosis in a dialogue\nsetting. Experiments on three real-world dialogue datasets confirm that DiaCDM\nnot only significantly improves diagnostic accuracy but also enhances the\nresults' interpretability, providing teachers with a powerful tool for\nassessing students' cognitive states. The code is available at\nhttps://github.com/Mind-Lab-ECNU/DiaCDM/tree/main.", "published": "2025-09-29 14:09:04", "link": "http://arxiv.org/abs/2509.24821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning", "abstract": "In clinical practice, physicians refrain from making decisions when patient\ninformation is insufficient. This behavior, known as abstention, is a critical\nsafety mechanism preventing potentially harmful misdiagnoses. Recent\ninvestigations have reported the application of large language models (LLMs) in\nmedical scenarios. However, existing LLMs struggle with the abstentions,\nfrequently providing overconfident responses despite incomplete information.\nThis limitation stems from conventional abstention methods relying solely on\nmodel self-assessments, which lack systematic strategies to identify knowledge\nboundaries with external medical evidences. To address this, we propose\n\\textbf{KnowGuard}, a novel \\textit{investigate-before-abstain} paradigm that\nintegrates systematic knowledge graph exploration for clinical decision-making.\nOur approach consists of two key stages operating on a shared contextualized\nevidence pool: 1) an evidence discovery stage that systematically explores the\nmedical knowledge space through graph expansion and direct retrieval, and 2) an\nevidence evaluation stage that ranks evidence using multiple factors to adapt\nexploration based on patient context and conversation history. This two-stage\napproach enables systematic knowledge graph exploration, allowing models to\ntrace structured reasoning paths and recognize insufficient medical evidence.\nWe evaluate our abstention approach using open-ended multi-round clinical\nbenchmarks that mimic realistic diagnostic scenarios, assessing abstention\nquality through accuracy-efficiency trade-offs beyond existing closed-form\nevaluations. Experimental evidences clearly demonstrate that KnowGuard\noutperforms state-of-the-art abstention approaches, improving diagnostic\naccuracy by 3.93\\% while reducing unnecessary interaction by 7.27 turns on\naverage.", "published": "2025-09-29 14:03:01", "link": "http://arxiv.org/abs/2509.24816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Spatiotemporal Consistency in Automatically Generated Sewing Instructions", "abstract": "In this paper, we propose a novel, automatic tree-based evaluation metric for\nLLM-generated step-by-step assembly instructions, that more accurately reflects\nspatiotemporal aspects of construction than traditional metrics such as BLEU\nand BERT similarity scores. We apply our proposed metric to the domain of\nsewing instructions, and show that our metric better correlates with\nmanually-annotated error counts as well as human quality ratings, demonstrating\nour metric's superiority for evaluating the spatiotemporal soundness of sewing\ninstructions. Further experiments show that our metric is more robust than\ntraditional approaches against artificially-constructed counterfactual examples\nthat are specifically constructed to confound metrics that rely on textual\nsimilarity.", "published": "2025-09-29 13:46:27", "link": "http://arxiv.org/abs/2509.24792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeaPO: Strategic Error Amplification for Robust Preference Optimization of Large Language Models", "abstract": "Existing alignment methods for preference optimization of large language\nmodels (LLMs) aim to enhance model performance by utilizing pairs of positive\nand negative samples. However, due to the limited capacity of models in scoring\nor generating responses, the quality of positive and negative samples may\nbecome similar during training, which complicates optimization for preference\nlearning. To address this issue, we introduce SeaPO, a Strategic Error\nAmplification method that leverages three error types commonly occurring in\nLLMs to introduce specific error patterns into the model Preference\nOptimization. This strategy ensures that negative samples are more erroneous\nthan positive samples and preference-based training is employed to mitigate the\noccurrence of these errors, thereby enhancing model performance. Evaluations\nacross five capability dimensions and different model scales (1.5B to 14B)\ndemonstrate that the generated data significantly improved overall model\nperformance, particularly in terms of truthfulness, with improvements of 5-10\npercentage points observed. Further analysis reveals that task performance\nvaries depending on the error types introduced. Injecting the most common error\ntypes improves performance in related tasks, while a mix of error types leads\nto a broader performance enhancement: most tasks show stable improvements,\nwhile a few tasks exhibit significant gains.", "published": "2025-09-29 13:42:41", "link": "http://arxiv.org/abs/2509.24781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VSSFlow: Unifying Video-conditioned Sound and Speech Generation via Joint Learning", "abstract": "Video-conditioned sound and speech generation, encompassing video-to-sound\n(V2S) and visual text-to-speech (VisualTTS) tasks, are conventionally addressed\nas separate tasks, with limited exploration to unify them within a signle\nframework. Recent attempts to unify V2S and VisualTTS face challenges in\nhandling distinct condition types (e.g., heterogeneous video and transcript\nconditions) and require complex training stages. Unifying these two tasks\nremains an open problem. To bridge this gap, we present VSSFlow, which\nseamlessly integrates both V2S and VisualTTS tasks into a unified flow-matching\nframework. VSSFlow uses a novel condition aggregation mechanism to handle\ndistinct input signals. We find that cross-attention and self-attention layer\nexhibit different inductive biases in the process of introducing condition.\nTherefore, VSSFlow leverages these inductive biases to effectively handle\ndifferent representations: cross-attention for ambiguous video conditions and\nself-attention for more deterministic speech transcripts. Furthermore, contrary\nto the prevailing belief that joint training on the two tasks requires complex\ntraining strategies and may degrade performance, we find that VSSFlow benefits\nfrom the end-to-end joint learning process for sound and speech generation\nwithout extra designs on training stages. Detailed analysis attributes it to\nthe learned general audio prior shared between tasks, which accelerates\nconvergence, enhances conditional generation, and stabilizes the\nclassifier-free guidance process. Extensive experiments demonstrate that\nVSSFlow surpasses the state-of-the-art domain-specific baselines on both V2S\nand VisualTTS benchmarks, underscoring the critical potential of unified\ngenerative models.", "published": "2025-09-29 13:38:24", "link": "http://arxiv.org/abs/2509.24773v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LatentEvolve: Self-Evolving Test-Time Scaling in Latent Space", "abstract": "Test-time Scaling (TTS) has been demonstrated to significantly enhance the\nreasoning capabilities of Large Language Models (LLMs) during the inference\nphase without altering model parameters. However, existing TTS methods are\nlargely independent, implying that LLMs have not yet evolved to progressively\nlearn how to scale more effectively. With the objective of evolving LLMs to\nlearn ``how to scale test-time computation,'' we propose LatentEvolve, a\nself-evolving latent TTS framework inspired by the complementary learning\nsystem (CLS) theory. Analogous to the human brain's dual system of a\nfast-recall hippocampus and a slow-consolidating neocortex, LatentEvolve\ncomprises two evolutionary components: \\textit{daytime scaling}, which rapidly\nretrieves historical latent representations to better guide current LLM\nreasoning; and \\textit{nighttime scaling}, which integrates past latent\noptimizations in a manner akin to the human brain's consolidation of\nexperiences during sleep. The alternation of daytime and nighttime processes\nfacilitates a fast and slow evolution of LLM TTS, mirroring human cognitive\ndynamics in a fully unsupervised manner. Extensive experiments across eight\nbenchmarks and five model backbones demonstrate that our LatentEvolve surpasses\nstate-of-the-art TTS methods such as LatentSeek and TTRL by up to $13.33\\%$ and\nexhibits exceptional cross-domain and cross-backbone generalization.", "published": "2025-09-29 13:37:39", "link": "http://arxiv.org/abs/2509.24771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProxyAttn: Guided Sparse Attention via Representative Heads", "abstract": "The quadratic complexity of attention mechanisms limits the efficiency of\nLarge Language Models (LLMs) on long-text tasks. Recently, methods that\ndynamically estimate block importance have enabled efficient block sparse\nattention, leading to significant acceleration in long-text pre-filling of\nLLMs. However, their coarse-grained estimation inevitably leads to performance\ndegradation at high sparsity rates. In this work, we propose ProxyAttn, a\ntraining-free sparse attention algorithm that achieves more precise block\nestimation by compressing the dimension of attention heads. Based on our\nobservation of the similarity among multiple attention heads, we use the scores\nof pooled representative heads to approximate the scores for all heads. To\naccount for the varying sparsity among heads, we also propose a block-aware\ndynamic budget estimation method. By combining the scores from representative\nproxy heads with multi-head dynamic budgets, we achieve a more fine-grained\nblock importance evaluation at low computational cost. Experiments on a variety\nof mainstream models and extensive benchmarks confirm the underlying similarity\namong attention heads. Leveraging a fine-grained estimation, the proposed\nmethod achieves substantial gains in performance and efficiency compared to\nexisting methods. More precisely, ProxyAttn can achieve up to 10.3x attention\nacceleration and 2.4x prefilling acceleration without significant performance\nloss. Our code is available at https://github.com/wyxstriker/ProxyAttn.", "published": "2025-09-29 13:10:39", "link": "http://arxiv.org/abs/2509.24745v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Socratic-Zero : Bootstrapping Reasoning via Data-Free Agent Co-evolution", "abstract": "Recent breakthroughs in large language models (LLMs) on reasoning tasks rely\nheavily on massive, high-quality datasets-typically human-annotated and thus\ndifficult to scale. While data synthesis or distillation offers a promising\nalternative, existing methods struggle with inconsistent data quality and an\ninability to dynamically adapt to the evolving capabilities of the model,\nleading to suboptimal training signals. To address these limitations, we\nintroduce Socratic-Zero, a fully autonomous framework that generates\nhigh-quality training data from minimal seed examples through the co-evolution\nof three agents: the Teacher, the Solver, and the Generator. The Solver\ncontinuously refines its reasoning by learning from preference feedback on both\nsuccessful and failed trajectories; the Teacher adaptively crafts increasingly\nchallenging questions based on the Solver's weaknesses; and the Generator\ndistills the Teacher's question-design strategy to enable scalable,\nhigh-fidelity curriculum generation. This closed-loop system produces a\nself-improving curriculum-requiring no pre-existing tasks or labels.\nRemarkably, starting from only 100 seed questions, our Socratic-Solver-8B\nachieves an average gain of +20.2 percentage points over prior data synthesis\nmethods across seven mathematical reasoning benchmarks (AMC23, AIME24-25,\nOlympiad, MATH-500, Minerva, and GSM8K), with consistent gains on both Qwen3\nand GLM4 series models. Even more surprisingly, synthetic data from\nSocratic-Generator-32B enables student LLMs to achieve superior performance\ncompared to other state-of-the-art (SOTA) commercial LLMs on these benchmarks,\nincluding Qwen3-235B-A22B, DeepSeek-V3.1-671B, GPT-5, Gemini-2.5-Pro, Grok-4,\nand Claude-4.1-Opus.", "published": "2025-09-29 12:54:07", "link": "http://arxiv.org/abs/2509.24726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Self-awareness of Large Reasoning Models' Capability Boundaries", "abstract": "Large Reasoning Models (LRMs) have shown impressive performance on complex\nreasoning tasks such as mathematics, yet they also display misbehaviors that\nexpose their limitations. In particular, when faced with hard questions, LRMs\noften engage in unproductive reasoning until context limit, producing wrong\nanswers while wasting substantial computation. This phenomenon reflects a\nfundamental issue: current answering paradigms overlook the relationship\nbetween questions and LRMs' capability boundaries. In this paper, we\ninvestigate whether LRMs possess self-awareness of capability boundaries. We\nbegin by an observation that LRMs may know what they cannot solve through\nexpressed reasoning confidence. For black-box models, we find that reasoning\nexpressions reveal boundary signals, with accelerated growing confidence\ntrajectory for solvable problems but convergent uncertainty trajectory for\nunsolvable ones. For white-box models, we show that hidden states of the last\ninput token encode boundary information, with solvable and unsolvable problems\nlinearly separable even before reasoning begins. Building on these findings, we\npropose two simple yet effective optimization strategies: reasoning expression\nmonitoring and hidden states monitoring. Experiments demonstrate that these\nboundary-aware strategies enable LRMs to avoid unproductive reasoning without\nsacrificing accuracy, significantly improving reliability and efficiency by\ncutting token usage up to 62.7 - 93.6%.", "published": "2025-09-29 12:40:47", "link": "http://arxiv.org/abs/2509.24711v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MemGen: Weaving Generative Latent Memory for Self-Evolving Agents", "abstract": "Agent memory shapes how Large Language Model (LLM)-powered agents, akin to\nthe human brain, progressively refine themselves through environment\ninteractions. Existing paradigms remain constrained: parametric memory forcibly\nadjusts model parameters, and retrieval-based memory externalizes experience\ninto structured databases, yet neither captures the fluid interweaving of\nreasoning and memory that underlies human cognition. To address this gap, we\npropose MemGen, a dynamic generative memory framework that equips agents with a\nhuman-esque cognitive faculty. It consists of a \\textit{memory trigger}, which\nmonitors the agent's reasoning state to decide explicit memory invocation, and\na \\textit{memory weaver}, which takes the agent's current state as stimulus to\nconstruct a latent token sequence as machine-native memory to enrich its\nreasoning. In this way, MemGen enables agents to recall and augment latent\nmemory throughout reasoning, producing a tightly interwoven cycle of memory and\ncognition. Extensive experiments across eight benchmarks show that MemGen\nsurpasses leading external memory systems such as ExpeL and AWM by up to\n$38.22\\%$, exceeds GRPO by up to $13.44\\%$, and exhibits strong cross-domain\ngeneralization ability. More importantly, we find that without explicit\nsupervision, MemGen spontaneously evolves distinct human-like memory faculties,\nincluding planning memory, procedural memory, and working memory, suggesting an\nemergent trajectory toward more naturalistic forms of machine cognition.", "published": "2025-09-29 12:33:13", "link": "http://arxiv.org/abs/2509.24704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reference-Free Rating of LLM Responses via Latent Information", "abstract": "How reliable are single-response LLM-as-a-judge ratings without references,\nand can we obtain fine-grained, deterministic scores in this setting? We study\nthe common practice of asking a judge model to assign Likert-scale scores to\nfree-text responses and show two systematic issues: scores are unstable under\nsampling and poorly calibrated, leading to compression near the top of the\nscale and frequent ties. We then propose and evaluate Latent Judges, which\nderive scalar ratings from internal model signals: (i) probability-weighted\nscores over integer ratings, (ii) verifier-style probabilities of \"yes\", and\n(iii) linear probes trained on model activations at the rating position. Across\na broad suite of pairwise and single-rating benchmarks, latent methods match or\nsurpass standard prompting, with consistent gains on pairwise accuracy and\nlistwise ranking relevant to Best-of-N selection. Probability-weighted scores\nachieve the strongest single-rating correlations, while probes recover useful\nsignals when output logits are miscalibrated. These results indicate that\nlatent information provides deterministic and more discriminative signals for\nreference-free evaluation, and can improve selection and training approaches\nlike Best-of-$N$, multi-teacher distillation, and routing.", "published": "2025-09-29 12:15:52", "link": "http://arxiv.org/abs/2509.24678v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding the Dilemma of Unlearning for Large Language Models", "abstract": "Unlearning seeks to remove specific knowledge from large language models\n(LLMs), but its effectiveness remains contested. On one side, \"forgotten\"\nknowledge can often be recovered through interventions such as light\nfine-tuning; on the other side, unlearning may induce catastrophic forgetting\nthat degrades general capabilities. Despite active exploration of unlearning\nmethods, interpretability analyses of the mechanism are scarce due to the\ndifficulty of tracing knowledge in LLMs' complex architectures. We address this\ngap by proposing unPact, an interpretable framework for unlearning via prompt\nattribution and contribution tracking. Typically, it quantifies each prompt\ntoken's influence on outputs, enabling pre- and post-unlearning comparisons to\nreveal what changes. Across six mainstream unlearning methods, three LLMs, and\nthree benchmarks, we find that: (1) Unlearning appears to be effective by\ndisrupting focus on keywords in prompt; (2) Much of the knowledge is not truly\nerased and can be recovered by simply emphasizing these keywords in prompts,\nwithout modifying the model's weights; (3) Catastrophic forgetting arises from\nindiscriminate penalization of all tokens. Taken together, our results suggest\nan unlearning dilemma: existing methods tend either to be insufficient -\nknowledge remains recoverable by keyword emphasis, or overly destructive -\ngeneral performance collapses due to catastrophic forgetting, still leaving a\ngap to reliable unlearning.", "published": "2025-09-29 12:15:19", "link": "http://arxiv.org/abs/2509.24675v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InfLLM-V2: Dense-Sparse Switchable Attention for Seamless Short-to-Long Adaptation", "abstract": "Long-sequence processing is a critical capability for modern large language\nmodels. However, the self-attention mechanism in the standard Transformer\narchitecture faces severe computational and memory bottlenecks when processing\nlong sequences. While trainable sparse attention methods offer a promising\nsolution, existing approaches such as NSA introduce excessive extra parameters\nand disrupt the conventional \\textit{pretrain-on-short, finetune-on-long}\nworkflow, resulting in slow convergence and difficulty in acceleration. To\novercome these limitations, we introduce dense-sparse switchable attention\nframework, termed as InfLLM-V2. InfLLM-V2 is a trainable sparse attention that\nseamlessly adapts models from short to long sequences. Specifically, InfLLM-V2\nreuses dense attention parameters through parameter-free architecture\nmodification, maintaining consistency between short and long sequence\nprocessing. Additionally, InfLLM-V2 ensures computational efficiency across all\nsequence lengths, by using dense attention for short inputs and smoothly\ntransitioning to sparse attention for long sequences. To achieve practical\nacceleration, we further introduce an efficient implementation of InfLLM-V2\nthat significantly reduces the computational overhead. Our experiments on\nlong-context understanding and chain-of-thought reasoning demonstrate that\nInfLLM-V2 is 4$\\times$ faster than dense attention while retaining 98.1% and\n99.7% of the performance, respectively. Based on the InfLLM-V2 framework, we\nhave trained and open-sourced MiniCPM4.1\n(https://huggingface.co/openbmb/MiniCPM4.1-8B), a hybrid reasoning model,\nproviding a reproducible implementation for the research community.", "published": "2025-09-29 12:08:33", "link": "http://arxiv.org/abs/2509.24663v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hype or not? Formalizing Automatic Promotional Language Detection in Biomedical Research", "abstract": "In science, promotional language ('hype') is increasing and can undermine\nobjective evaluation of evidence, impede research development, and erode trust\nin science. In this paper, we introduce the task of automatic detection of\nhype, which we define as hyperbolic or subjective language that authors use to\nglamorize, promote, embellish, or exaggerate aspects of their research. We\npropose formalized guidelines for identifying hype language and apply them to\nannotate a portion of the National Institutes of Health (NIH) grant application\ncorpus. We then evaluate traditional text classifiers and language models on\nthis task, comparing their performance with a human baseline. Our experiments\nshow that formalizing annotation guidelines can help humans reliably annotate\ncandidate hype adjectives and that using our annotated dataset to train machine\nlearning models yields promising results. Our findings highlight the linguistic\ncomplexity of the task, and the potential need for domain knowledge and\ntemporal awareness of the facts. While some linguistic works address hype\ndetection, to the best of our knowledge, we are the first to approach it as a\nnatural language processing task.", "published": "2025-09-29 11:47:15", "link": "http://arxiv.org/abs/2509.24638v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition", "abstract": "Despite advances in multilingual automatic speech recognition (ASR),\ncode-switching (CS), the mixing of languages within an utterance common in\ndaily speech, remains a severely underexplored challenge. In this paper, we\nintroduce HiKE: the Hierarchical Korean-English code-switching benchmark, the\nfirst globally accessible evaluation framework for Korean-English CS, aiming to\nprovide a means for the precise evaluation of multilingual ASR models and to\nfoster research in the field. The proposed framework not only consists of\nhigh-quality, natural CS data across various topics, but also provides\nmeticulous loanword labels and a hierarchical CS-level labeling scheme (word,\nphrase, and sentence) that together enable a systematic evaluation of a model's\nability to handle each distinct level of code-switching. Through evaluations of\ndiverse multilingual ASR models and fine-tuning experiments, this paper\ndemonstrates that while most multilingual ASR models initially struggle with\nCS-ASR, this capability can be enabled through fine-tuning with CS data. HiKE\nwill be available at https://github.com/ThetaOne-AI/HiKE.", "published": "2025-09-29 11:18:13", "link": "http://arxiv.org/abs/2509.24613v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment", "abstract": "Large language model (LLM) alignment faces a critical dilemma when addressing\nmultiple human preferences: improvements in one dimension frequently come at\nthe expense of others, creating unavoidable trade-offs between competing\nobjectives like helpfulness and harmlessness. While prior work mainly focuses\non constraint-based optimization algorithms and data selection strategies to\nmitigate conflicts, these approaches overlook the fundamental issue of\nresolving conflicts directly at the parameter level. In this paper, we present\nOrthAlign, an innovative approach that pioneers a new paradigm by leveraging\northogonal subspace decomposition to fundamentally resolve gradient-level\nconflicts in multi-objective preference alignment. OrthAlign strategically\ndecomposes parameter update spaces into orthogonal subspaces, ensuring that\noptimization toward different preferences occurs in mathematically\nnon-interfering directions. Building upon this, we provide theoretical\nguarantees demonstrating that when parameter increments satisfy both orthogonal\nsubspace constraints and spectral norm bounds, the resulting updates exhibit\nlinear Lipschitz growth rather than exponential instability, ensuring stable\nconvergence across all preference dimensions. Extensive experiments show that:\nI. OrthAlign achieves maximum single-preference improvements ranging from\n34.61% to 50.89% after multiple-objective alignment across helpful, harmless,\nand truthful dimensions. II. With an average overall reward improvement of\n13.96%.", "published": "2025-09-29 11:16:30", "link": "http://arxiv.org/abs/2509.24610v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inducing Dyslexia in Vision Language Models", "abstract": "Dyslexia, a neurodevelopmental disorder characterized by persistent reading\ndifficulties, is often linked to reduced activity of the visual word form area\nin the ventral occipito-temporal cortex. Traditional approaches to studying\ndyslexia, such as behavioral and neuroimaging methods, have provided valuable\ninsights but remain limited in their ability to test causal hypotheses about\nthe underlying mechanisms of reading impairments. In this study, we use\nlarge-scale vision-language models (VLMs) to simulate dyslexia by functionally\nidentifying and perturbing artificial analogues of word processing. Using\nstimuli from cognitive neuroscience, we identify visual-word-form-selective\nunits within VLMs and demonstrate that targeted ablation of these units, unlike\nablation of random units, leads to selective impairments in reading tasks while\ngeneral visual and language comprehension abilities remain intact. In\nparticular, the resulting model matches dyslexic humans' phonological deficits\nwithout a significant change in orthographic processing. Taken together, our\nmodeling results replicate key characteristics of dyslexia and establish a\ncomputational framework for investigating reading disorders.", "published": "2025-09-29 11:03:16", "link": "http://arxiv.org/abs/2509.24597v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NeMo: Needle in a Montage for Video-Language Understanding", "abstract": "Recent advances in video large language models (VideoLLMs) call for new\nevaluation protocols and benchmarks for complex temporal reasoning in\nvideo-language understanding. Inspired by the needle in a haystack test widely\nused by LLMs, we introduce a novel task of Needle in a Montage (NeMo), designed\nto assess VideoLLMs' critical reasoning capabilities, including long-context\nrecall and temporal grounding. To generate video question answering data for\nour task, we develop a scalable automated data generation pipeline that\nfacilitates high-quality data synthesis. Built upon the proposed pipeline, we\npresent NeMoBench, a video-language benchmark centered on our task.\nSpecifically, our full set of NeMoBench features 31,378 automatically generated\nquestion-answer (QA) pairs from 13,486 videos with various durations ranging\nfrom seconds to hours. Experiments demonstrate that our pipeline can reliably\nand automatically generate high-quality evaluation data, enabling NeMoBench to\nbe continuously updated with the latest videos. We evaluate 20 state-of-the-art\nmodels on our benchmark, providing extensive results and key insights into\ntheir capabilities and limitations. Our project page is available at:\nhttps://lavi-lab.github.io/NeMoBench.", "published": "2025-09-29 10:16:05", "link": "http://arxiv.org/abs/2509.24563v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AdaThink-Med: Medical Adaptive Thinking with Uncertainty-Guided Length Calibration", "abstract": "Recent advances in inference time scaling with extended long chain-of thought\nhave significantly improved the reasoning capabilities of both general and\nmedical large language models (LLMs). However, these models tend to engage in\nlengthy reasoning processes regardless of the difficulty of the input question,\nleading to increased inference costs in real-world applications. Therefore,\nenabling adaptive thinking where models think less for simpler questions and\nthink more for complex ones is critical for the effective use of medical LLMs\nin practice. Despite its importance, there is a lack of end-to-end approaches\ndesigned to enhance the adaptive thinking capabilities of medical LLMs while\nproviding a comprehensive examination of the trade-off between performance and\ncomputational cost. To bridge this gap, we propose AdaThink-Med, the first\nend-to-end framework designed to enhance adaptive thinking ability in medical\nreasoning models with uncertainty-guided length calibration. AdaThink-Med first\ngenerates multiple candidate outputs for each question, evaluates the\ncorrectness and uncertainty of each candidate, and then estimates problem\ndifficulty via an uncertainty-guided length calibration module. For outputs\nwith low difficulty and correct answers, the framework penalizes longer\nreasoning paths; whereas for those with high difficulty and incorrect answers,\nit encourages extending the chain of thought to explore alternative solutions.\nOn six public medical QA benchmarks, AdaThink-Med achieves up to 6.4x length\nreduction on average while retaining performance with only minimal degradation.\nIntriguingly, we observe that AdaThink-Med spontaneously develops two distinct\nreasoning modes, which we characterize as \"non-thinking\" and \"thinking\",\ndemonstrating the model's ability to suppress redundant reasoning processes\ndynamically.", "published": "2025-09-29 10:13:55", "link": "http://arxiv.org/abs/2509.24560v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LEAF: A Robust Expert-Based Framework for Few-Shot Continual Event Detection", "abstract": "Few-shot Continual Event Detection (FCED) poses the dual challenges of\nlearning from limited data and mitigating catastrophic forgetting across\nsequential tasks. Existing approaches often suffer from severe forgetting due\nto the full fine-tuning of a shared base model, which leads to knowledge\ninterference between tasks. Moreover, they frequently rely on data augmentation\nstrategies that can introduce unnatural or semantically distorted inputs. To\naddress these limitations, we propose LEAF, a novel and robust expert-based\nframework for FCED. LEAF integrates a specialized mixture of experts\narchitecture into the base model, where each expert is parameterized with\nlow-rank adaptation (LoRA) matrices. A semantic-aware expert selection\nmechanism dynamically routes instances to the most relevant experts, enabling\nexpert specialization and reducing knowledge interference. To improve\ngeneralization in limited-data settings, LEAF incorporates a contrastive\nlearning objective guided by label descriptions, which capture high-level\nsemantic information about event types. Furthermore, to prevent overfitting on\nthe memory buffer, our framework employs a knowledge distillation strategy that\ntransfers knowledge from previous models to the current one. Extensive\nexperiments on multiple FCED benchmarks demonstrate that LEAF consistently\nachieves state-of-the-art performance.", "published": "2025-09-29 10:00:25", "link": "http://arxiv.org/abs/2509.24547v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Experience-guided reflective co-evolution of prompts and heuristics for automatic algorithm design", "abstract": "Combinatorial optimization problems are traditionally tackled with\nhandcrafted heuristic algorithms, which demand extensive domain expertise and\nsignificant implementation effort. Recent progress has highlighted the\npotential of automatic heuristics design powered by large language models\n(LLMs), enabling the automatic generation and refinement of heuristics. These\napproaches typically maintain a population of heuristics and employ LLMs as\nmutation operators to evolve them across generations. While effective, such\nmethods often risk stagnating in local optima. To address this issue, we\npropose the Experience-Guided Reflective Co-Evolution of Prompt and Heuristics\n(EvoPH) for automatic algorithm design, a novel framework that integrates the\nisland migration model with the elites selection algorithm to simulate diverse\nheuristics populations. In EvoPH, prompts are co-evolved with heuristic\nalgorithms, guided by performance feedback. We evaluate our framework on two\nproblems, i.e., Traveling Salesman Problem and Bin Packing Problem.\nExperimental results demonstrate that EvoPH achieves the lowest relative error\nagainst optimal solutions across both datasets, advancing the field of\nautomatic algorithm design with LLMs.", "published": "2025-09-29 09:24:09", "link": "http://arxiv.org/abs/2509.24509v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Building Benchmarks from the Ground Up: Community-Centered Evaluation of LLMs in Healthcare Chatbot Settings", "abstract": "Large Language Models (LLMs) are typically evaluated through general or\ndomain-specific benchmarks testing capabilities that often lack grounding in\nthe lived realities of end users. Critical domains such as healthcare require\nevaluations that extend beyond artificial or simulated tasks to reflect the\neveryday needs, cultural practices, and nuanced contexts of communities. We\npropose Samiksha, a community-driven evaluation pipeline co-created with\ncivil-society organizations (CSOs) and community members. Our approach enables\nscalable, automated benchmarking through a culturally aware, community-driven\npipeline in which community feedback informs what to evaluate, how the\nbenchmark is built, and how outputs are scored. We demonstrate this approach in\nthe health domain in India. Our analysis highlights how current multilingual\nLLMs address nuanced community health queries, while also offering a scalable\npathway for contextually grounded and inclusive LLM evaluation.", "published": "2025-09-29 09:20:15", "link": "http://arxiv.org/abs/2509.24506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Editing with Subspace-Aware Key-Value Mappings", "abstract": "Knowledge editing aims to efficiently correct factual errors in Language\nModels (LMs). The popular locate-then-edit approach modifies an MLP layer by\nfinding an optimal mapping between its input vector (key) and output vector\n(value) that leads to the expression of the edited knowledge. However, existing\nmethods without any constraints on the key and value vectors cause significant\nperturbations to the edited model. To address this, we propose Subspace\nKnowledge Edit (SUIT), a method that identifies and modifies only the subspace\nof critical features relevant to the edit. Our empirical results on LLaMA-3-8B,\nGPT-J-6B, and Qwen2.5-7B models show that SUIT dramatically improves knowledge\npreservation over strong baselines while maintaining high edit efficacy. This\neffectiveness confirms that SUIT successfully identifies the critical subspace\nfor the edit. Further analyses provide additional validation for our approach.\nThe source code and data will be released to the public upon publication of the\npaper.", "published": "2025-09-29 09:17:42", "link": "http://arxiv.org/abs/2509.24502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training", "abstract": "Recent progress, such as DeepSeek-R1, has shown that the GRPO algorithm, a\nReinforcement Learning (RL) approach, can effectively train Chain-of-Thought\n(CoT) reasoning in Large Language Models (LLMs) and Vision-Language Models\n(VLMs). In this paper, we analyze three challenges of GRPO: gradient coupling\nbetween thoughts and answers, sparse reward signals caused by limited parallel\nsampling, and unstable advantage estimation. To mitigate these challenges, we\npropose GRPO-MA, a simple yet theoretically grounded method that leverages\nmulti-answer generation from each thought process, enabling more robust and\nefficient optimization. Theoretically, we show that the variance of thought\nadvantage decreases as the number of answers per thought increases.\nEmpirically, our gradient analysis confirms this effect, showing that GRPO-MA\nreduces gradient spikes compared to GRPO. Experiments on math, code, and\ndiverse multimodal tasks demonstrate that GRPO-MA substantially improves\nperformance and training efficiency. Our ablation studies further reveal that\nincreasing the number of answers per thought consistently enhances model\nperformance.", "published": "2025-09-29 09:07:45", "link": "http://arxiv.org/abs/2509.24494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sanitize Your Responses: Mitigating Privacy Leakage in Large Language Models", "abstract": "As Large Language Models (LLMs) achieve remarkable success across a wide\nrange of applications, such as chatbots and code copilots, concerns surrounding\nthe generation of harmful content have come increasingly into focus. Despite\nsignificant advances in aligning LLMs with safety and ethical standards,\nadversarial prompts can still be crafted to elicit undesirable responses.\nExisting mitigation strategies are predominantly based on post-hoc filtering,\nwhich introduces substantial latency or computational overhead, and is\nincompatible with token-level streaming generation. In this work, we introduce\nSelf-Sanitize, a novel LLM-driven mitigation framework inspired by cognitive\npsychology, which emulates human self-monitor and self-repair behaviors during\nconversations. Self-Sanitize comprises a lightweight Self-Monitor module that\ncontinuously inspects high-level intentions within the LLM at the token level\nvia representation engineering, and a Self-Repair module that performs in-place\ncorrection of harmful content without initiating separate review dialogues.\nThis design allows for real-time streaming monitoring and seamless repair, with\nnegligible impact on latency and resource utilization. Given that\nprivacy-invasive content has often been insufficiently focused in previous\nstudies, we perform extensive experiments on four LLMs across three privacy\nleakage scenarios. The results demonstrate that Self-Sanitize achieves superior\nmitigation performance with minimal overhead and without degrading the utility\nof LLMs, offering a practical and robust solution for safer LLM deployments.\nOur code is available at the following link:\nhttps://github.com/wjfu99/LLM_Self_Sanitize", "published": "2025-09-29 08:59:44", "link": "http://arxiv.org/abs/2509.24488v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Text-To-Text Alignment Algorithm for Better Evaluation of Modern Speech Recognition Systems", "abstract": "Modern neural networks have greatly improved performance across speech\nrecognition benchmarks. However, gains are often driven by frequent words with\nlimited semantic weight, which can obscure meaningful differences in word error\nrate, the primary evaluation metric. Errors in rare terms, named entities, and\ndomain-specific vocabulary are more consequential, but remain hidden by\naggregate metrics. This highlights the need for finer-grained error analysis,\nwhich depends on accurate alignment between reference and model transcripts.\nHowever, conventional alignment methods are not designed for such precision. We\npropose a novel alignment algorithm that couples dynamic programming with beam\nsearch scoring. Compared to traditional text alignment methods, our approach\nprovides more accurate alignment of individual errors, enabling reliable error\nanalysis. The algorithm is made available via PyPI.", "published": "2025-09-29 08:53:02", "link": "http://arxiv.org/abs/2509.24478v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks", "abstract": "Spatial intelligence spans a rich suite of abilities, including visualising\nand transforming shapes, mentally rotating objects, judging relational\npositions and containment, and estimating numerosity. However, it still remains\na critical unresolved challenge for Multimodal Large Language Models (MLLMs).To\nfill this gap, we propose to treat Euclidean geometry problem-solving as a\nsurrogate task. Specifically, we meticulously constructed a curated multimodal\ndataset, called Euclid30K, comprising approximately 30K plane and solid\ngeometry problems. To enable the model to acquire and apply Euclidean\nprinciples from these geometry problems, we employed Group Relative Policy\nOptimization (GRPO) to finetune the Qwen2.5VL family and RoboBrain2.0 family,\ninspiring the models to identify shapes, count, and relate entities, and\nperform multi-step deductive reasoning using Euclidean principles. Our\nexperiments demonstrate that the resulting models achieve substantial zero-shot\ngains across four spatial reasoning benchmarks (Super-CLEVR, Omni3DBench,\nVSI-Bench, and MindCube) without any task-specific adaptations. Notably, after\ntraining on the Euclid30K, the mean VSI-Bench accuracy of all evaluated models\nrose from 34.5% to 40.5%, improving by 5.5 percentage points. Among them,\nRoboBrain2.0-Euclid-7B achieves 49.6\\% accuracy, surpassing the previous\nstate-of-the-art model, Spatial-MLLM.To our knowledge, this is the first\nsystematic study showing that geometry-centric fine-tuning can confer\nvision-language models with broadly transferable spatial skills. Code and\nEuclid30K dataset can be found in https://zgca-ai4edu.github.io/Euclids_Gift.", "published": "2025-09-29 08:49:21", "link": "http://arxiv.org/abs/2509.24473v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Bias Mitigation or Cultural Commonsense? Evaluating LLMs with a Japanese Dataset", "abstract": "Large language models (LLMs) exhibit social biases, prompting the development\nof various debiasing methods. However, debiasing methods may degrade the\ncapabilities of LLMs. Previous research has evaluated the impact of bias\nmitigation primarily through tasks measuring general language understanding,\nwhich are often unrelated to social biases. In contrast, cultural commonsense\nis closely related to social biases, as both are rooted in social norms and\nvalues. The impact of bias mitigation on cultural commonsense in LLMs has not\nbeen well investigated. Considering this gap, we propose SOBACO (SOcial BiAs\nand Cultural cOmmonsense benchmark), a Japanese benchmark designed to evaluate\nsocial biases and cultural commonsense in LLMs in a unified format. We evaluate\nseveral LLMs on SOBACO to examine how debiasing methods affect cultural\ncommonsense in LLMs. Our results reveal that the debiasing methods degrade the\nperformance of the LLMs on the cultural commonsense task (up to 75% accuracy\ndeterioration). These results highlight the importance of developing debiasing\nmethods that consider the trade-off with cultural commonsense to improve\nfairness and utility of LLMs.", "published": "2025-09-29 08:45:50", "link": "http://arxiv.org/abs/2509.24468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Isolated Facts: Synthesizing Narrative and Grounded Supervision for VideoQA", "abstract": "The performance of Video Question Answering (VideoQA) models is fundamentally\nconstrained by the nature of their supervision, which typically consists of\nisolated, factual question-answer pairs. This \"bag-of-facts\" approach fails to\ncapture the underlying narrative and causal structure of events, limiting\nmodels to a shallow understanding of video content. To move beyond this\nparadigm, we introduce a framework to synthesize richer supervisory signals. We\npropose two complementary strategies: Question-Based Paraphrasing (QBP), which\nsynthesizes the diverse inquiries (what, how, why) from a video's existing set\nof question-answer pairs into a holistic narrative paragraph that reconstructs\nthe video's event structure; and Question-Based Captioning (QBC), which\ngenerates fine-grained visual rationales, grounding the answer to each question\nin specific, relevant evidence. Leveraging powerful generative models, we use\nthis synthetic data to train VideoQA models under a unified next-token\nprediction objective. Extensive experiments on STAR and NExT-QA validate our\napproach, demonstrating significant accuracy gains and establishing new\nstate-of-the-art results, such as improving a 3B model to 72.5\\% on STAR\n(+4.9\\%) and a 7B model to 80.8\\% on NExT-QA. Beyond accuracy, our analysis\nreveals that both QBP and QBC substantially enhance cross-dataset\ngeneralization, with QBP additionally accelerating model convergence by over\n2.5x. These results demonstrate that shifting data synthesis from isolated\nfacts to narrative coherence and grounded rationales yields a more accurate,\nefficient, and generalizable training paradigm.", "published": "2025-09-29 08:28:44", "link": "http://arxiv.org/abs/2509.24445v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Alternatives To Next Token Prediction In Text Generation -- A Survey", "abstract": "The paradigm of Next Token Prediction (NTP) has driven the unprecedented\nsuccess of Large Language Models (LLMs), but is also the source of their most\npersistent weaknesses such as poor long-term planning, error accumulation, and\ncomputational inefficiency. Acknowledging the growing interest in exploring\nalternatives to NTP, the survey describes the emerging ecosystem of\nalternatives to NTP. We categorise these approaches into five main families:\n(1) Multi-Token Prediction, which targets a block of future tokens instead of a\nsingle one; (2) Plan-then-Generate, where a global, high-level plan is created\nupfront to guide token-level decoding; (3) Latent Reasoning, which shifts the\nautoregressive process itself into a continuous latent space; (4) Continuous\nGeneration Approaches, which replace sequential generation with iterative,\nparallel refinement through diffusion, flow matching, or energy-based methods;\nand (5) Non-Transformer Architectures, which sidestep NTP through their\ninherent model structure. By synthesizing insights across these methods, this\nsurvey offers a taxonomy to guide research into models that address the known\nlimitations of token-level generation to develop new transformative models for\nnatural language processing.", "published": "2025-09-29 08:18:16", "link": "http://arxiv.org/abs/2509.24435v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CDT: A Comprehensive Capability Framework for Large Language Models Across Cognition, Domain, and Task", "abstract": "Recent advances in Large Language Models (LLMs) have significantly enhanced\ntheir capabilities, highlighting the need for comprehensive evaluation\nframeworks that extend beyond task-specific benchmarks. However, existing\nbenchmarks often focus on isolated abilities, lacking a holistic framework for\nassessing LLM capabilities. To address this gap, we propose the\nCognition-Domain-Task (CDT) framework, which comprehensively measures a model's\ncapabilities across three dimensions. We expand the scope of model capability\ndefinitions at the cognitive level by incorporating the Cattell-Horn-Carroll\ncognitive theory, refining the categorization of model capabilities. We apply\nCDT in two directions: dataset capability evaluation and data selection.\nExperiments show that our capability metrics correlate well with downstream\nperformance and can support effective dataset analysis and construction. The\nexperiments on data selection also show significant improvements in both\ngeneral and specific benchmarks, achieving scores of 44.3 and 45.4, with an\nincrease of 1.6 and 2.2 points over the baselines, respectively. These results\nvalidate the effectiveness and practicality of CDT. Source code and models are\navailable at https://github.com/Alessa-mo/CDT.", "published": "2025-09-29 08:10:29", "link": "http://arxiv.org/abs/2509.24422v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Text-to-SQL: Benchmarking the Limits of Language Models with Collaborative Language Agents", "abstract": "Text-to-SQL enables natural access to databases, yet most benchmarks are\nEnglish-only, limiting multilingual progress. We introduce MultiSpider 2.0,\nextending Spider 2.0 to eight languages (English, German, French, Spanish,\nPortuguese, Japanese, Chinese, Vietnamese). It preserves Spider 2.0's\nstructural difficulty while adding linguistic and dialectal variability,\ndemanding deeper reasoning for complex SQL. On this benchmark, state-of-the-art\nLLMs (such as DeepSeek-R1 and OpenAI o1) reach only 4\\% execution accuracy when\nrelying on intrinsic reasoning, versus 60\\% on MultiSpider 1.0. Therefore, we\nprovide a collaboration-driven language agents baseline that iteratively\nrefines queries, improving accuracy to 15\\%. These results reveal a substantial\nmultilingual gap and motivate methods that are robust across languages and\nready for real-world enterprise deployment. Our benchmark is available at\nhttps://github.com/phkhanhtrinh23/Multilingual_Text_to_SQL.", "published": "2025-09-29 07:50:39", "link": "http://arxiv.org/abs/2509.24405v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.ET", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling", "abstract": "State-of-the-art (SOTA) Text-to-SQL methods still lag significantly behind\nhuman experts on challenging benchmarks like BIRD. Current approaches that\nexplore test-time scaling lack an orchestrated strategy and neglect the model's\ninternal reasoning process. To bridge this gap, we introduce Agentar-Scale-SQL,\na novel framework leveraging scalable computation to improve performance.\nAgentar-Scale-SQL implements an Orchestrated Test-Time Scaling strategy that\nsynergistically combines three distinct perspectives: i) Internal Scaling via\nRL-enhanced Intrinsic Reasoning, ii) Sequential Scaling through Iterative\nRefinement, and iii) Parallel Scaling using Diverse Synthesis and Tournament\nSelection. Agentar-Scale-SQL is a general-purpose framework designed for easy\nadaptation to new databases and more powerful language models. Extensive\nexperiments show that Agentar-Scale-SQL achieves SOTA performance on the BIRD\nbenchmark, reaching 81.67\\% execution accuracy on the test set and ranking\nfirst on the official leaderboard, demonstrating an effective path toward\nhuman-level performance.", "published": "2025-09-29 07:50:02", "link": "http://arxiv.org/abs/2509.24403v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Towards Safe Reasoning in Large Reasoning Models via Corrective Intervention", "abstract": "Although Large Reasoning Models (LRMs) have progressed in solving complex\nproblems, their chain-of-thought (CoT) reasoning often contains harmful content\nthat can persist even when the final responses appear safe. We show that this\nissue still remains in existing methods which overlook the unique significance\nof safe reasoning, undermining their trustworthiness and posing potential risks\nin applications if unsafe reasoning is accessible for and exploited by\nmalicious users. We therefore shift our focus to aligning the safety of\nreasoning itself in this paper and explore process supervision as the solution.\nHowever, simply rewarding safe reasoning proves inadequate due to low rollout\ndiversity and limited training signals. To tackle this challenge, we first\ndelve into the characteristics of safe reasoning and uncover several critical\ninsights that 1) safe reasoning is often consolidated by a few critical steps\nof safety triggers; 2) compliance cues strongly correlate with unsafe\ncontinuations; and 3) corrective interventions reliably steer unsafe\ntrajectories towards safer traces. Motivated by these, we propose Intervened\nPreference Optimization (IPO), an alignment method that enforces safe reasoning\nby substituting compliance steps with safety triggers and constructing pairs\nfor preference learning with strong signals. Experiments on jailbreak and\nadversarial safety benchmarks demonstrate that IPO remarkably improves overall\nsafety regarding both reasoning and responses, outperforming SFT-based and\nRL-based baselines with a relative reduction of over 30% in harmfulness, while\npreserving excellent performance across diverse reasoning tasks. The results\nhighlight the importance of explicit alignment for reasoning and provide a\npractical path to safer LRMs.", "published": "2025-09-29 07:41:09", "link": "http://arxiv.org/abs/2509.24393v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LLaDA-MoE: A Sparse MoE Diffusion Language Model", "abstract": "We introduce LLaDA-MoE, a large language diffusion model with the\nMixture-of-Experts (MoE) architecture, trained from scratch on approximately\n20T tokens. LLaDA-MoE achieves competitive performance with significantly\nreduced computational overhead by maintaining a 7B-parameter capacity while\nactivating only 1.4B parameters during inference. Our empirical evaluation\nreveals that LLaDA-MoE achieves state-of-the-art performance among diffusion\nlanguage models with larger parameters, surpassing previous diffusion language\nmodels LLaDA, LLaDA 1.5, and Dream across multiple benchmarks. The\ninstruct-tuned model LLaDA-MoE-7B-A1B-Instruct demonstrates capabilities\ncomparable to Qwen2.5-3B-Instruct in knowledge understanding, code generation,\nmathematical reasoning, agent and alignment tasks, despite using fewer active\nparameters. Our results show that integrating a sparse MoE architecture into\nthe training objective of masked diffusion language models still brings out\nMoE's strengths under efficient inference with few active parameters, and opens\nample room for further exploration of diffusion language models. LLaDA-MoE\nmodels are available at Huggingface.", "published": "2025-09-29 07:38:59", "link": "http://arxiv.org/abs/2509.24389v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment", "abstract": "The alignment of large language models (LLMs) with human values is critical\nfor their safe deployment, yet jailbreak attacks can subvert this alignment to\nelicit harmful outputs from LLMs. In recent years, a proliferation of jailbreak\nattacks has emerged, accompanied by diverse metrics and judges to assess the\nharmfulness of the LLM outputs. However, the absence of a systematic benchmark\nto assess the quality and effectiveness of these metrics and judges undermines\nthe credibility of the reported jailbreak effectiveness and other risks. To\naddress this gap, we introduce HarmMetric Eval, a comprehensive benchmark\ndesigned to support both overall and fine-grained evaluation of harmfulness\nmetrics and judges. Our benchmark includes a high-quality dataset of\nrepresentative harmful prompts paired with diverse harmful and non-harmful\nmodel responses, alongside a flexible scoring mechanism compatible with various\nmetrics and judges. With HarmMetric Eval, our extensive experiments uncover a\nsurprising result: two conventional metrics--METEOR and ROUGE-1--outperform\nLLM-based judges in evaluating the harmfulness of model responses, challenging\nprevailing beliefs about LLMs' superiority in this domain. Our dataset is\npublicly available at https://huggingface.co/datasets/qusgo/HarmMetric_Eval,\nand the code is available at\nhttps://anonymous.4open.science/r/HarmMetric-Eval-4CBE.", "published": "2025-09-29 07:34:01", "link": "http://arxiv.org/abs/2509.24384v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Mid-Training", "abstract": "The development of state-of-the-art large language models is commonly\nunderstood as a two-stage process involving pre-training and post-training. We\npoint out the need for an additional intermediate stage called reinforcement\nmid-training with potential for strong performance gains. In this paper, we\nformally define the problem and identify three key challenges: (1) inefficient\ntraining due to excessive reasoning steps, (2) disregard of the imbalanced\ntoken entropy distribution, and (3) underutilization of token information. To\naddress these challenges, we propose RMT, a framework for efficient, adaptive,\nand unified reinforcement mid-training with various innovative components. In\nparticular, we first introduce a dynamic token budget mechanism that constrains\nunnecessary reasoning steps and mitigates model overthinking. Next, we design a\ncurriculum-based adaptive sampling method that fosters a progressive learning\ntrajectory from easy to hard tokens. Finally, we present a dual training\nstrategy that combines reinforcement learning with next-token prediction,\nensuring targeted learning on key tokens and full exploitation of all token\ninformation. Extensive experiments demonstrate the superiority of RMT over\nstate-of-the-art methods, achieving up to +64.91% performance improvement with\nonly 21% of the reasoning length in language modeling. We also show that\ncheckpoints obtained after reinforcement mid-training can benefit the\nsubsequent post-training, yielding up to +18.76% improvement in the\nmathematical domain.", "published": "2025-09-29 07:21:24", "link": "http://arxiv.org/abs/2509.24375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Repetition: Text Simplification and Curriculum Learning for Data-Constrained Pretraining", "abstract": "Most studies on language model pretraining focus on large datasets, leaving\nopen questions about optimization in data-constrained settings. In such\nsettings, the effects of training data order and of including alternative\nversions of the same text remain underexplored. We address this by studying\ncurriculum learning in pretraining, focusing on text-complexity ordering and\ndata augmentation via simplification. We ask: (1) Does simplifying texts\nenhance representation quality more than reusing the original data? and (2)\nDoes ordering data by text complexity yield better representations? To answer,\nwe build on a pair of parallel corpora where human-written paragraphs are\naligned with LLM-simplified variants, and test four data schedules: repeated\nexposure, low-to-high complexity, high-to-low, and interleaved. We analyze\nmodels' representation quality from a sample efficiency perspective via\nfine-tuning, as well as its zero-shot performance on linguistic knowledge,\nentity tracking, world knowledge, and commonsense reasoning. Our findings show\nthat adding simplified data improves fine-tuning and zero-shot performance over\na repeated-exposure baseline: smaller models benefit from low-to-high\ncomplexity, while larger models perform better with interleaved ordering.", "published": "2025-09-29 06:54:59", "link": "http://arxiv.org/abs/2509.24356v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AlignX: Advancing Multilingual Large Language Models with Multilingual Representation Alignment", "abstract": "Multilingual large language models (LLMs) possess impressive multilingual\nunderstanding and generation capabilities. However, their performance and\ncross-lingual alignment often lag for non-dominant languages. A common solution\nis to fine-tune LLMs on large-scale and more balanced multilingual corpus, but\nsuch approaches often lead to imprecise alignment and suboptimal knowledge\ntransfer, struggling with limited improvements across languages. In this paper,\nwe propose AlignX to bridge the multilingual performance gap, which is a\ntwo-stage representation-level framework for enhancing multilingual performance\nof pre-trained LLMs. In the first stage, we align multilingual representations\nwith multilingual semantic alignment and language feature integration. In the\nsecond stage, we stimulate the multilingual capability of LLMs via multilingual\ninstruction fine-tuning. Experimental results on several pre-trained LLMs\ndemonstrate that our approach enhances LLMs' multilingual general and\ncross-lingual generation capability. Further analysis indicates that AlignX\nbrings the multilingual representations closer and improves the cross-lingual\nalignment.", "published": "2025-09-29 06:37:46", "link": "http://arxiv.org/abs/2509.24338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speculative Verification: Exploiting Information Gain to Refine Speculative Decoding", "abstract": "LLMs have low GPU efficiency and high latency due to autoregressive decoding.\nSpeculative decoding (SD) mitigates this using a small draft model to\nspeculatively generate multiple tokens, which are then verified in parallel by\na target model. However, when speculation accuracy is low, the overhead from\nrejected tokens can offset the benefits, limiting SD's effectiveness,\nespecially at large batch sizes. To address this, we propose Speculative\nVerification (SV), an efficient augmentation to SD that dynamically predicts\nspeculation accuracy and adapts the verification length to maximize throughput.\nSV introduces a companion model - a small auxiliary model similar in size to\nthe draft model - to estimate the alignment between draft and target model\ndistributions. By maximizing the information gain from quantifying this\nalignment, SV refines verification decisions, reducing wasted computation on\nrejected tokens and improving decoding efficiency. Moreover, SV requires no\nmodifications to the draft or target models and is compatible with existing SD\nvariants. We extensively evaluated SV on publicly available LLMs across three\nNLP tasks using nine combinations of draft, companion, and target models,\nincluding 13B-72B target models and three types of variations: base (no\nfinetuning), instruction-tuned, and task fine-tuned. Across all experiments and\nbatch sizes (4-80), SV consistently outperforms both SD and standard decoding\nwith the target model. It improves SD performance by up to 2$\\times$, with an\naverage speedup of 1.4 $\\times$ in large-batch settings (batch sizes 32-80).\nThese results demonstrate SV's robustness, scalability, and practical utility\nfor efficient LLM inference.", "published": "2025-09-29 06:25:54", "link": "http://arxiv.org/abs/2509.24328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAS$^2$: Self-Generative, Self-Configuring, Self-Rectifying Multi-Agent Systems", "abstract": "The past two years have witnessed the meteoric rise of Large Language Model\n(LLM)-powered multi-agent systems (MAS), which harness collective intelligence\nand exhibit a remarkable trajectory toward self-evolution. This paradigm has\nrapidly progressed from manually engineered systems that require bespoke\nconfiguration of prompts, tools, roles, and communication protocols toward\nframeworks capable of automated orchestration. Yet, dominant automatic\nmulti-agent systems, whether generated by external modules or a single LLM\nagent, largely adhere to a rigid ``\\textit{generate-once-and-deploy}''\nparadigm, rendering the resulting systems brittle and ill-prepared for the\ndynamism and uncertainty of real-world environments. To transcend this\nlimitation, we introduce MAS$^2$, a paradigm predicated on the principle of\nrecursive self-generation: a multi-agent system that autonomously architects\nbespoke multi-agent systems for diverse problems. Technically, we devise a\n``\\textit{generator-implementer-rectifier}'' tri-agent team capable of\ndynamically composing and adaptively rectifying a target agent system in\nresponse to real-time task demands. Collaborative Tree Optimization is proposed\nto train and specialize these meta-agents. Extensive evaluation across seven\nbenchmarks reveals that MAS$^2$ achieves performance gains of up to $19.6\\%$\nover state-of-the-art MAS in complex scenarios such as deep research and code\ngeneration. Moreover, MAS$^2$ exhibits superior cross-backbone generalization,\neffectively leveraging previously unseen LLMs to yield improvements of up to\n$15.1\\%$. Crucially, these gains are attained without incurring excessive token\ncosts, as MAS$^2$ consistently resides on the Pareto frontier of\ncost-performance trade-offs. The source codes are available at\nhttps://github.com/yeyeyeah2/MAS2.", "published": "2025-09-29 06:20:10", "link": "http://arxiv.org/abs/2509.24323v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Multimodal Large Language Models Meet Multimodal Emotion Recognition and Reasoning: A Survey", "abstract": "In recent years, large language models (LLMs) have driven major advances in\nlanguage understanding, marking a significant step toward artificial general\nintelligence (AGI). With increasing demands for higher-level semantics and\ncross-modal fusion, multimodal large language models (MLLMs) have emerged,\nintegrating diverse information sources (e.g., text, vision, and audio) to\nenhance modeling and reasoning in complex scenarios. In AI for Science,\nmultimodal emotion recognition and reasoning has become a rapidly growing\nfrontier. While LLMs and MLLMs have achieved notable progress in this area, the\nfield still lacks a systematic review that consolidates recent developments. To\naddress this gap, this paper provides a comprehensive survey of LLMs and MLLMs\nfor emotion recognition and reasoning, covering model architectures, datasets,\nand performance benchmarks. We further highlight key challenges and outline\nfuture research directions, aiming to offer researchers both an authoritative\nreference and practical insights for advancing this domain. To the best of our\nknowledge, this paper is the first attempt to comprehensively survey the\nintersection of MLLMs with multimodal emotion recognition and reasoning. The\nsummary of existing methods mentioned is in our Github:\n\\href{https://github.com/yuntaoshou/Awesome-Emotion-Reasoning}{https://github.com/yuntaoshou/Awesome-Emotion-Reasoning}.", "published": "2025-09-29 06:13:14", "link": "http://arxiv.org/abs/2509.24322v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dual Mechanisms of Value Expression: Intrinsic vs. Prompted Values in LLMs", "abstract": "Large language models (LLMs) can express different values in two distinct\nways: (1) intrinsic expression, reflecting the model's inherent values learned\nduring training, and (2) prompted expression, elicited by explicit prompts.\nGiven their widespread use in value alignment and persona steering, it is\nparamount to clearly understand their underlying mechanisms, particularly\nwhether they mostly overlap (as one might expect) or rely on substantially\ndifferent mechanisms, but this remains largely understudied. We analyze this at\nthe mechanistic level using two approaches: (1) value vectors, feature\ndirections representing value mechanisms extracted from the residual stream,\nand (2) value neurons, MLP neurons that contribute to value expressions. We\ndemonstrate that intrinsic and prompted value mechanisms partly share common\ncomponents that are crucial for inducing value expression, but also possess\nunique elements that manifest in different ways. As a result, these mechanisms\nlead to different degrees of value steerability (prompted > intrinsic) and\nresponse diversity (intrinsic > prompted). In particular, components unique to\nthe intrinsic mechanism seem to promote lexical diversity in responses, whereas\nthose specific to the prompted mechanism primarily strengthen instruction\nfollowing, taking effect even in distant tasks like jailbreaking.", "published": "2025-09-29 05:57:00", "link": "http://arxiv.org/abs/2509.24319v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bridging the behavior-neural gap: A multimodal AI reveals the brain's geometry of emotion more accurately than human self-reports", "abstract": "The ability to represent emotion plays a significant role in human cognition\nand social interaction, yet the high-dimensional geometry of this affective\nspace and its neural underpinnings remain debated. A key challenge, the\n`behavior-neural gap,' is the limited ability of human self-reports to predict\nbrain activity. Here we test the hypothesis that this gap arises from the\nconstraints of traditional rating scales and that large-scale similarity\njudgments can more faithfully capture the brain's affective geometry. Using AI\nmodels as `cognitive agents,' we collected millions of triplet odd-one-out\njudgments from a multimodal large language model (MLLM) and a language-only\nmodel (LLM) in response to 2,180 emotionally evocative videos. We found that\nthe emergent 30-dimensional embeddings from these models are highly\ninterpretable and organize emotion primarily along categorical lines, yet in a\nblended fashion that incorporates dimensional properties. Most remarkably, the\nMLLM's representation predicted neural activity in human emotion-processing\nnetworks with the highest accuracy, outperforming not only the LLM but also,\ncounterintuitively, representations derived directly from human behavioral\nratings. This result supports our primary hypothesis and suggests that sensory\ngrounding--learning from rich visual data--is critical for developing a truly\nneurally-aligned conceptual framework for emotion. Our findings provide\ncompelling evidence that MLLMs can autonomously develop rich, neurally-aligned\naffective representations, offering a powerful paradigm to bridge the gap\nbetween subjective experience and its neural substrates. Project page:\nhttps://reedonepeck.github.io/ai-emotion.github.io/.", "published": "2025-09-29 05:22:33", "link": "http://arxiv.org/abs/2509.24298v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.MM"], "primary_category": "cs.HC"}
{"title": "Q-Mirror: Unlocking the Multi-Modal Potential of Scientific Text-Only QA Pairs", "abstract": "High-quality, multi-modal benchmarks are crucial for advancing scientific\nreasoning in large models yet their manual creation is costly and unscalable.\nTo address this bottleneck, we explore the potential for transforming Text-Only\nQA Pairs (TQAs) into high-quality Multi-Modal QA Pairs (MMQAs), which include\nthree parts: 1) Task Definition \\& Evaluation Rubric: We develop a TQA-to-MMQA\nframework and establish a comprehensive, multi-dimensional MMQA quality rubric\nthat provides principles for the transformation. 2) Benchmark Construction:\nThen we construct two extensive benchmarks to rigorously evaluate\nstate-of-the-art generation \\& understanding models on the distinct tasks of\nMMQA generation \\& MMQA quality evaluation. 3) Preliminary Solution: We develop\nan agentic system (Q-Mirror), which operationalizes our framework by\nintegrating MMQA generation and evaluation into a closed loop for iterative\nrefinement. Our experiments show that while state-of-the-art models can\ngenerate MMQAs, their outputs still leave substantial gaps, underscoring the\nneed for reliable evaluation. We further demonstrate that top-tier\nunderstanding models align closely with human judgment in MMQA quality\nassessment. Leveraging both insights, the Q-Mirror agent raises average scores\nfrom 78.90 to 85.22 and pass rates from 72\\% to 95\\%, offering a practical path\nto large-scale scientific benchmarks.", "published": "2025-09-29 05:22:10", "link": "http://arxiv.org/abs/2509.24297v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DiffuGuard: How Intrinsic Safety is Lost and Found in Diffusion Large Language Models", "abstract": "The rapid advancement of Diffusion Large Language Models (dLLMs) introduces\nunprecedented vulnerabilities that are fundamentally distinct from\nAutoregressive LLMs, stemming from their iterative and parallel generation\nmechanisms. In this paper, we conduct an in-depth analysis of dLLM\nvulnerabilities to jailbreak attacks across two distinct dimensions: intra-step\nand inter-step dynamics. Experimental results reveal a harmful bias inherent in\nthe standard greedy remasking strategy and identify a critical phenomenon we\nterm Denoising-path Dependence, where the safety of early-stage tokens\ndecisively influences the final output. These findings also indicate that while\ncurrent decoding strategies constitute a significant vulnerability, dLLMs\npossess a substantial intrinsic safety potential. To unlock this potential, we\npropose DiffuGuard, a training-free defense framework that addresses\nvulnerabilities through a dual-stage approach: Stochastic Annealing Remasking\ndynamically introduces controlled randomness to mitigate greedy selection bias,\nwhile Block-level Audit and Repair exploits internal model representations for\nautonomous risk detection and guided correction. Comprehensive experiments on\nfour dLLMs demonstrate DiffuGuard's exceptional effectiveness, reducing Attack\nSuccess Rate against six diverse jailbreak methods from 47.9% to 14.7% while\npreserving model utility and efficiency. Our code is available at:\nhttps://github.com/niez233/DiffuGuard.", "published": "2025-09-29 05:17:10", "link": "http://arxiv.org/abs/2509.24296v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LOGOS: LLM-driven End-to-End Grounded Theory Development and Schema Induction for Qualitative Research", "abstract": "Grounded theory offers deep insights from qualitative data, but its reliance\non expert-intensive manual coding presents a major scalability bottleneck.\nCurrent computational tools stop short of true automation, keeping researchers\nfirmly in the loop. We introduce LOGOS, a novel, end-to-end framework that\nfully automates the grounded theory workflow, transforming raw text into a\nstructured, hierarchical theory. LOGOS integrates LLM-driven coding, semantic\nclustering, graph reasoning, and a novel iterative refinement process to build\nhighly reusable codebooks. To ensure fair comparison, we also introduce a\nprincipled 5-dimensional metric and a train-test split protocol for\nstandardized, unbiased evaluation. Across five diverse corpora, LOGOS\nconsistently outperforms strong baselines and achieves a remarkable $88.2\\%$\nalignment with an expert-developed schema on a complex dataset. LOGOS\ndemonstrates a powerful new path to democratize and scale qualitative research\nwithout sacrificing theoretical nuance.", "published": "2025-09-29 05:16:09", "link": "http://arxiv.org/abs/2509.24294v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Let LLMs Speak Embedding Languages: Generative Text Embeddings via Iterative Contrastive Refinement", "abstract": "Existing large language model (LLM)-based embeddings typically adopt an\nencoder-only paradigm, treating LLMs as static feature extractors and\noverlooking their core generative strengths. We introduce GIRCSE (Generative\nIterative Refinement for Contrastive Sentence Embeddings), a novel framework\nthat leverages autoregressive generation to iteratively refine semantic\nrepresentations. By producing sequences of soft tokens optimized under\ncontrastive objective, GIRCSE captures latent concepts and implicit semantics\nthat encoder-only methods often miss. To guide this process, we propose an\nIterative Contrastive Refinement (ICR) objective that encourages each\nrefinement step to yield better representations. Extensive experiments show\nthat GIRCSE outperforms strong LLM-based embedding baselines on the MTEB\nbenchmark and instruction-following tasks. Moreover, GIRCSE exhibits an\nemergent test-time scaling property: generating more tokens at inference\nsteadily improves embedding quality. Our results establish generative iterative\nrefinement as a new paradigm for representation learning.", "published": "2025-09-29 05:09:08", "link": "http://arxiv.org/abs/2509.24291v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "SCI-Verifier: Scientific Verifier with Thinking", "abstract": "As large language models (LLMs) are increasingly applied to scientific\nreasoning, the complexity of answer formats and the diversity of equivalent\nexpressions make answer verification a critical yet challenging task. Existing\nverification studies in scientific domains suffer from two major limitations:\n(a) the absence of systematic evaluation standards and insufficient\ndisciplinary coverage, which hinders their comprehensive assessment; and (b)\nheavy reliance on cumbersome rule design or prompt engineering, which reduces\ntheir effectiveness in complex reasoning scenarios or limits their\ncross-disciplinary generalization. To address these challenges, we propose\nsolutions at both the data and model levels. On the data side, we construct\nSCI-VerifyBench, a cross-disciplinary benchmark covering mathematics, physics,\nbiology, chemistry, and general scientific QA. The benchmark is built from real\nLLM responses and enhanced with domain-specific equivalence transformations\nthat generate challenging and realistic data. Model-based and expert\nannotations ensure both quality and diversity, enabling rigorous evaluation of\nverification ability. On the model side, we emphasize the importance of\nreasoning for verification and introduce SCI-Verifier, a unified\nreasoning-augmented verifier for scientific domains. Through post-training,\nSCI-Verifier demonstrates strong logical reasoning and equivalence judgment\ncapabilities while maintaining concise and stable outputs. Together,\nSCI-VerifyBench and SCI-Verifier provide a principled framework for scientific\nverification, offering both systematic evaluation and practical pathways to\nenhance the reliability and applicability of LLMs in scientific domains.", "published": "2025-09-29 04:58:43", "link": "http://arxiv.org/abs/2509.24285v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Overview of SCIDOCA 2025 Shared Task on Citation Prediction, Discovery, and Placement", "abstract": "We present an overview of the SCIDOCA 2025 Shared Task, which focuses on\ncitation discovery and prediction in scientific documents. The task is divided\ninto three subtasks: (1) Citation Discovery, where systems must identify\nrelevant references for a given paragraph; (2) Masked Citation Prediction,\nwhich requires selecting the correct citation for masked citation slots; and\n(3) Citation Sentence Prediction, where systems must determine the correct\nreference for each cited sentence. We release a large-scale dataset constructed\nfrom the Semantic Scholar Open Research Corpus (S2ORC), containing over 60,000\nannotated paragraphs and a curated reference set. The test set consists of\n1,000 paragraphs from distinct papers, each annotated with ground-truth\ncitations and distractor candidates. A total of seven teams registered, with\nthree submitting results. We report performance metrics across all subtasks and\nanalyze the effectiveness of submitted systems. This shared task provides a new\nbenchmark for evaluating citation modeling and encourages future research in\nscientific document understanding. The dataset and task materials are publicly\navailable at https://github.com/daotuanan/scidoca2025-shared-task.", "published": "2025-09-29 04:55:18", "link": "http://arxiv.org/abs/2509.24283v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "abstract": "Large Language Model (LLM) agents excel at multi-step, tool-augmented tasks.\nHowever, smart homes introduce distinct challenges, requiring agents to handle\nlatent user intents, temporal dependencies, device constraints, scheduling, and\nmore. The main bottlenecks for developing smart home agents with such\ncapabilities include the lack of a realistic simulation environment where\nagents can interact with devices and observe the results, as well as a\nchallenging benchmark to evaluate them. To address this, we introduce\n$\\textbf{SimuHome}$, a time-accelerated home environment that simulates smart\ndevices, supports API calls, and reflects changes in environmental variables.\nBy building the simulator on the Matter protocol (the global industry standard\nfor smart home communication), SimuHome provides a high-fidelity environment,\nand agents validated in SimuHome can be deployed on real Matter-compliant\ndevices with minimal adaptation. We provide a challenging benchmark of 600\nepisodes across twelve user query types that require the aforementioned\ncapabilities. Our evaluation of 11 agents under a unified ReAct framework\nreveals that while models perform well on simple tasks, they struggle with\nlatent intent inference, state verification, and especially temporal\nscheduling. Even the top-performing model, GPT-4.1, reaches only 54% success\nrate. These findings highlight a critical need for methods that can reliably\nverify the current state via tools before acting and coordinate time-dependent\nactions.", "published": "2025-09-29 04:54:20", "link": "http://arxiv.org/abs/2509.24282v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AdvChain: Adversarial Chain-of-Thought Tuning for Robust Safety Alignment of Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\ncomplex problem-solving through Chain-of-Thought (CoT) reasoning. However, the\nmulti-step nature of CoT introduces new safety challenges that extend beyond\nconventional language model alignment. We identify a failure mode in current\nsafety CoT tuning methods: the \\textit{snowball effect}, where minor reasoning\ndeviations progressively amplify throughout the thought process, leading to\neither harmful compliance or excessive refusal. This effect stems from models\nbeing trained to imitate perfect reasoning scripts without learning to\nself-correct. To address this limitation, we propose AdvChain, an alignment\nparadigm that teaches models dynamic self-correction through adversarial CoT\ntuning. Our method involves constructing a dataset containing\nTemptation-Correction and Hesitation-Correction samples, where models learn to\nrecover from harmful reasoning drifts and unnecessary cautions. Extensive\nexperiments show that AdvChain significantly enhances robustness against\njailbreak attacks and CoT hijacking while substantially reducing over-refusal\non benign prompts, achieving a superior safety-utility balance without\ncompromising reasoning capabilities. Our work establishes a new direction for\nbuilding more robust and reliable reasoning models.", "published": "2025-09-29 04:27:23", "link": "http://arxiv.org/abs/2509.24269v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "PAME-AI: Patient Messaging Creation and Optimization using Agentic AI", "abstract": "Messaging patients is a critical part of healthcare communication, helping to\nimprove things like medication adherence and healthy behaviors. However,\ntraditional mobile message design has significant limitations due to its\ninability to explore the high-dimensional design space. We develop PAME-AI, a\nnovel approach for Patient Messaging Creation and Optimization using Agentic\nAI. Built on the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, PAME-AI\noffers a structured framework to move from raw data to actionable insights for\nhigh-performance messaging design. PAME-AI is composed of a system of\nspecialized computational agents that progressively transform raw experimental\ndata into actionable message design strategies. We demonstrate our approach's\neffectiveness through a two-stage experiment, comprising of 444,691 patient\nencounters in Stage 1 and 74,908 in Stage 2. The best-performing generated\nmessage achieved 68.76% engagement compared to the 61.27% baseline,\nrepresenting a 12.2\\% relative improvement in click-through rates. This agentic\narchitecture enables parallel processing, hypothesis validation, and continuous\nlearning, making it particularly suitable for large-scale healthcare\ncommunication optimization.", "published": "2025-09-29 04:14:46", "link": "http://arxiv.org/abs/2509.24263v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Extracting the Structure of Press Releases for Predicting Earnings Announcement Returns", "abstract": "We examine how textual features in earnings press releases predict stock\nreturns on earnings announcement days. Using over 138,000 press releases from\n2005 to 2023, we compare traditional bag-of-words and BERT-based embeddings. We\nfind that press release content (soft information) is as informative as\nearnings surprise (hard information), with FinBERT yielding the highest\npredictive power. Combining models enhances explanatory strength and\ninterpretability of the content of press releases. Stock prices fully reflect\nthe content of press releases at market open. If press releases are leaked, it\noffers predictive advantage. Topic analysis reveals self-serving bias in\nmanagerial narratives. Our framework supports real-time return prediction\nthrough the integration of online learning, provides interpretability and\nreveals the nuanced role of language in price formation.", "published": "2025-09-29 03:57:05", "link": "http://arxiv.org/abs/2509.24254v1", "categories": ["q-fin.CP", "cs.CE", "cs.CL", "cs.LG", "J.4; I.2.7"], "primary_category": "q-fin.CP"}
{"title": "MRAG-Suite: A Diagnostic Evaluation Platform for Visual Retrieval-Augmented Generation", "abstract": "Multimodal Retrieval-Augmented Generation (Visual RAG) significantly advances\nquestion answering by integrating visual and textual evidence. Yet, current\nevaluations fail to systematically account for query difficulty and ambiguity.\nWe propose MRAG-Suite, a diagnostic evaluation platform integrating diverse\nmultimodal benchmarks (WebQA, Chart-RAG, Visual-RAG, MRAG-Bench). We introduce\ndifficulty-based and ambiguity-aware filtering strategies, alongside\nMM-RAGChecker, a claim-level diagnostic tool. Our results demonstrate\nsubstantial accuracy reductions under difficult and ambiguous queries,\nhighlighting prevalent hallucinations. MM-RAGChecker effectively diagnoses\nthese issues, guiding future improvements in Visual RAG systems.", "published": "2025-09-29 03:55:28", "link": "http://arxiv.org/abs/2509.24253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Visual Reasoning", "abstract": "Multimodal Large Language Models (MLLMs) have achieved notable gains in\nvarious tasks by incorporating Chain-of-Thought (CoT) reasoning in language\nspaces. Recent work extends this direction by leveraging external tools for\nvisual editing, thereby enhancing the visual signal along the reasoning\ntrajectories. Nevertheless, these approaches remain fundamentally constrained:\nreasoning is still confined to the language space, with visual information\ntreated as static preconditions. We introduce Latent Visual Reasoning (LVR), a\nnew paradigm that enables autoregressive reasoning directly in the visual\nembedding space. A visual encoder first projects images into visual tokens\nwithin a joint semantic space shared with the language model. The language\nmodel is then trained to generate latent states that reconstruct key visual\ntokens critical for answering the query, constituting the process of latent\nvisual reasoning. By interleaving LVR with standard text generation, our model\nachieves substantial gains on perception-intensive visual question answering\ntasks. In addition, we adapt the GRPO algorithm to conduct reinforcement\nlearning on latent reasoning, further balancing LVR and textual generation. We\nshow that LVR substantially improves fine-grained visual understanding and\nperception, achieving 71.67% on MMVP compared to 66.67% with Qwen2.5-VL. Code\nbase and model weights will be released later.", "published": "2025-09-29 03:52:01", "link": "http://arxiv.org/abs/2509.24251v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SpecExit: Accelerating Large Reasoning Model via Speculative Exit", "abstract": "Despite their strong performance on reasoning tasks, large reasoning models\n(LRMs) often suffer from overthinking, producing unnecessarily long outputs and\nincurring high end-to-end latency, a significant limitation to their real-world\ndeployment. To address overthinking, early-exit mechanisms have been proposed\nto terminate reasoning before typical completion, showing that this approach\ncan effectively shorten generation length with minimal impact on accuracy.\nHowever, their reliance on probing mechanisms introduces a detection overhead\nthat limits their end-to-end latency gains and compromises their\ngeneralizability across diverse problems. Inspired by the use of hidden states\nin speculative decoding, we propose SpecExit, a novel framework that predicts\nboth future tokens and an early-exit signal directly from a lightweight draft\nmodel without probing overhead. Our method offers significant improvements,\nreducing average generation length by 66\\% and achieving a 2.5x speedup in\nend-to-end latency compared to the speculative decoding baseline, without\ncompromising accuracy. Our method leverages the inherent signals from hidden\nstates to provide effective early-exit signals, suggesting broader use of\nhidden states for efficient reasoning. Our code is available at\nhttps://github.com/Tencent/AngelSlim.", "published": "2025-09-29 03:39:32", "link": "http://arxiv.org/abs/2509.24248v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Prompt and Parameter Co-Optimization for Large Language Models", "abstract": "Prompt optimization and fine-tuning are two major approaches to improve the\nperformance of Large Language Models (LLMs). They enhance the capabilities of\nLLMs from complementary perspectives: the former through explicit natural\nlanguage, and the latter through implicit parameter updates. However, prior\nwork has typically studied them in isolation, leaving their synergistic\npotential largely underexplored. To bridge this gap, in this paper, we\nintroduce MetaTuner, a novel framework that jointly integrates prompt\noptimization and fine-tuning for LLM training. Specifically, we introduce two\nneural networks to generate prompts and parameters, respectively, while\nallowing them to share a common bottom encoding layer to enable knowledge\nsharing. By the guidance of the final supervised signals, our framework is\noptimized to discover the optimal combinations between the prompts and\nparameters. Given that prompt learning involves discrete optimization while\nfine-tuning operates in a continuous parameter space, we design a supervised\nregularization loss to train our framework effectively. Extensive experiments\nacross diverse benchmarks show that our method consistently outperforms the\nbaselines.", "published": "2025-09-29 03:38:25", "link": "http://arxiv.org/abs/2509.24245v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Ponder: Adaptive Reasoning in Latent Space", "abstract": "Test-time compute has emerged as a key paradigm for enhancing LLM reasoning,\nyet prevailing approaches like Best-of-N and majority voting apply uniform\ndepth across inputs, wasting computation on simple queries while potentially\nunder-thinking complex ones. We present FR-Ponder, a single-graph,\nbackbone-training-free framework that allocates instance-adaptive reasoning\ncompute via latent steering. A less than 1M-param controller observes hidden\nstates and decides to halt or apply a small ponder step by adding a\npre-computed steering vector to frozen representations. Our method extracts the\nlatent steering vector associated with deeper reasoning outputs and direct IO\nfrom LLM and re-applies it through a tunable scaling factor, allowing the model\nto adapt its reasoning depth to the complexity of each input. To balance\nperformance and computational cost, we employ Group Relative Policy\nOptimization (GRPO) as a reward signal to adaptively regulate reasoning depth,\nachieving task accuracy while mitigating overreasoning. Through curriculum\nlearning and careful reward engineering, FR-Ponder learns calibrated compute\nallocation correlated with problem difficulty. On GSM8K and MATH500, FR-Ponder\nimproves the compute-accuracy frontier, delivering lower FLOPs with better\nmatched accuracy and comparing favorably to early-exit baselines, without\nmodifying backbone weights. Analyses visualize interpretable steering\ndirections and show learned compute allocation correlates with problem\ndifficulty.", "published": "2025-09-29 03:21:42", "link": "http://arxiv.org/abs/2509.24238v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Model Fusion with Multi-LoRA Inference for Tool-Enhanced Game Dialogue Agents", "abstract": "This paper presents the opdainlp team's solution for the GPU track of the\nCPDC 2025 challenge. The challenge consists of three tasks, aiming to build an\nin-game conversational AI that adheres to character personas, aligns with the\ngame's worldview, and supports function calling. Considering both effectiveness\nand resource/time constraints during inference, we synthesized data for some of\nthe tasks based on the datasets provided by the competition organizers. We\nemployed Qwen3-14B with LoRA fine-tuning and model fusion, and utilized a base\nmodel integrated with multiple LoRA adapters during inference. Specifically, in\nthe competition, we used three distinct LoRA adapters to handle tool calling,\nresponse generation with tool call results, and response generation without\ntool call results, respectively. MultiLoRA inference was implemented using\nvLLM. Our solution achieved the first place in Task 1 and Task 3, and the\nsecond place in Task 2 of the GPU track.", "published": "2025-09-29 03:15:19", "link": "http://arxiv.org/abs/2509.24229v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniAPL: A Unified Adversarial Preference Learning Framework for Instruct-Following", "abstract": "Shaping powerful LLMs to be beneficial and safe is central to AI alignment.\nWe argue that post-training alignment is fundamentally a unified Preference\nLearning problem, involving two modalities: demonstrated preferences (e.g.,\nSupervised Fine-Tuning, SFT) and comparative preferences (e.g., Reinforcement\nLearning, RL).The standard sequential pipeline-SFT followed by RL-is flawed due\nto a critical distributional mismatch: SFT uses static expert data, but as the\npolicy evolves, its generation distribution drifts, making SFT knowledge\nbrittle. Subsequent RL then explores without direct access to the rich,\nground-truth knowledge in expert demonstrations, leading to inefficient,\nungrounded updates. This separation prevents mutual regularization between data\nsources. To address this, we reframe alignment as a constrained optimization\nproblem and propose Unified Adversarial Preference Learning (UniAPL),a novel\nframework that dynamically aligns the policy's distribution with the expert's.\nUniAPL implements a single-stage unified training objective, jointly learning\nfrom mixed batches of SFT and preference data. In every gradient step, dense\nexpert demonstrations directly ground and regularize online exploration,\ninherently resolving distributional mismatch and maximizing data synergy.We\nevaluate UniAPL on instruction-following tasks using Qwen3-235B-Instruct-2507\nas the teacher. Our models match or exceed strong GRPO baselines: +5.77% on\nQwen3-0.6B (matching a 32B model) and +3.75% on Qwen3-4B,even outperforming the\nteacher. Analyses of response length and log-probability distributions confirm\nthat UniAPL outputs closely mimic expert demonstrations, achieving both\nstronger performance and better behavioral alignment.", "published": "2025-09-29 17:53:09", "link": "http://arxiv.org/abs/2509.25148v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fast Feature Field ($\\text{F}^3$): A Predictive Representation of Events", "abstract": "This paper develops a mathematical argument and algorithms for building\nrepresentations of data from event-based cameras, that we call Fast Feature\nField ($\\text{F}^3$). We learn this representation by predicting future events\nfrom past events and show that it preserves scene structure and motion\ninformation. $\\text{F}^3$ exploits the sparsity of event data and is robust to\nnoise and variations in event rates. It can be computed efficiently using ideas\nfrom multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and\n440 Hz at VGA resolutions. $\\text{F}^3$ represents events within a contiguous\nspatiotemporal volume as a multi-channel image, enabling a range of downstream\ntasks. We obtain state-of-the-art performance on optical flow estimation,\nsemantic segmentation, and monocular metric depth estimation, on data from\nthree robotic platforms (a car, a quadruped robot and a flying platform),\nacross different lighting conditions (daytime, nighttime), environments\n(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors\n(resolutions and event rates). Our implementations can predict these tasks at\n25-75 Hz at HD resolution.", "published": "2025-09-29 17:52:31", "link": "http://arxiv.org/abs/2509.25146v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Visual serial processing deficits explain divergences in human and VLM reasoning", "abstract": "Why do Vision Language Models (VLMs), despite success on standard benchmarks,\noften fail to match human performance on surprisingly simple visual reasoning\ntasks? While the underlying computational principles are still debated, we\nhypothesize that a crucial factor is a deficit in visually-grounded serial\nprocessing. To test this hypothesis, we compared human and VLM performance\nacross tasks designed to vary serial processing demands in three distinct\ndomains: geometric reasoning, perceptual enumeration, and mental rotation.\nTasks within each domain varied serial processing load by manipulating factors\nsuch as geometric concept complexity, perceptual individuation load, and\ntransformation difficulty. Across all domains, our results revealed a\nconsistent pattern: decreased VLM accuracy was strongly correlated with\nincreased human reaction time (used as a proxy for serial processing load). As\ntasks require more demanding serial processing -- whether composing concepts,\nenumerating items, or performing mental transformations -- the VLM-human\nperformance gap widens reliably. These findings support our hypothesis,\nindicating that limitations in serial, visually grounded reasoning represent a\nfundamental bottleneck that distinguishes current VLMs from humans.", "published": "2025-09-29 17:51:20", "link": "http://arxiv.org/abs/2509.25142v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs", "abstract": "Integrating large language models (LLMs) into embodied AI models is becoming\nincreasingly prevalent. However, existing zero-shot LLM-based\nVision-and-Language Navigation (VLN) agents either encode images as textual\nscene descriptions, potentially oversimplifying visual details, or process raw\nimage inputs, which can fail to capture abstract semantics required for\nhigh-level reasoning. In this paper, we improve the navigation agent's\ncontextual understanding by incorporating textual descriptions from multiple\nperspectives that facilitate analogical reasoning across images. By leveraging\ntext-based analogical reasoning, the agent enhances its global scene\nunderstanding and spatial reasoning, leading to more accurate action decisions.\nWe evaluate our approach on the R2R dataset, where our experiments demonstrate\nsignificant improvements in navigation performance.", "published": "2025-09-29 17:51:01", "link": "http://arxiv.org/abs/2509.25139v1", "categories": ["cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.AI"}
{"title": "Score Distillation of Flow Matching Models", "abstract": "Diffusion models achieve high-quality image generation but are limited by\nslow iterative sampling. Distillation methods alleviate this by enabling one-\nor few-step generation. Flow matching, originally introduced as a distinct\nframework, has since been shown to be theoretically equivalent to diffusion\nunder Gaussian assumptions, raising the question of whether distillation\ntechniques such as score distillation transfer directly. We provide a simple\nderivation -- based on Bayes' rule and conditional expectations -- that unifies\nGaussian diffusion and flow matching without relying on ODE/SDE formulations.\nBuilding on this view, we extend Score identity Distillation (SiD) to\npretrained text-to-image flow-matching models, including SANA, SD3-Medium,\nSD3.5-Medium/Large, and FLUX.1-dev, all with DiT backbones. Experiments show\nthat, with only modest flow-matching- and DiT-specific adjustments, SiD works\nout of the box across these models, in both data-free and data-aided settings,\nwithout requiring teacher finetuning or architectural changes. This provides\nthe first systematic evidence that score distillation applies broadly to\ntext-to-image flow matching models, resolving prior concerns about stability\nand soundness and unifying acceleration techniques across diffusion- and\nflow-based generators. We will make the PyTorch implementation publicly\navailable.", "published": "2025-09-29 17:45:48", "link": "http://arxiv.org/abs/2509.25127v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis", "abstract": "Heatwaves pose complex cascading risks across interconnected climate, social,\nand economic systems, but knowledge fragmentation in scientific literature\nhinders comprehensive understanding of these risk pathways. We introduce HeDA\n(Heatwave Discovery Agent), an intelligent multi-agent system designed for\nautomated scientific discovery through knowledge graph construction and\nmulti-layer risk propagation analysis. HeDA processes over 10,247 academic\npapers to construct a comprehensive knowledge graph with 23,156 nodes and\n89,472 relationships, employing novel multi-layer risk propagation analysis to\nsystematically identify overlooked risk transmission pathways. Our system\nachieves 78.9% accuracy on complex question-answering tasks, outperforming\nstate-of-the-art baselines including GPT-4 by 13.7%. Critically, HeDA\nsuccessfully discovered five previously unidentified high-impact risk chains,\nsuch as the pathway where a heatwave leads to a water demand surge, resulting\nin industrial water restrictions and ultimately causing small business\ndisruption, which were validated through historical case studies and domain\nexpert review. This work presents a new paradigm for AI-driven scientific\ndiscovery, providing actionable insights for developing more resilient climate\nadaptation strategies.", "published": "2025-09-29 17:40:29", "link": "http://arxiv.org/abs/2509.25112v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D Generation", "abstract": "High-fidelity 3D asset generation is crucial for various industries. While\nrecent 3D pretrained models show strong capability in producing realistic\ncontent, most are built upon diffusion models and follow a two-stage pipeline\nthat first generates geometry and then synthesizes appearance. Such a decoupled\ndesign tends to produce geometry-texture misalignment and non-negligible cost.\nIn this paper, we propose UniLat3D, a unified framework that encodes geometry\nand appearance in a single latent space, enabling direct single-stage\ngeneration. Our key contribution is a geometry-appearance Unified VAE, which\ncompresses high-resolution sparse features into a compact latent representation\n-- UniLat. UniLat integrates structural and visual information into a dense\nlow-resolution latent, which can be efficiently decoded into diverse 3D\nformats, e.g., 3D Gaussians and meshes. Based on this unified representation,\nwe train a single flow-matching model to map Gaussian noise directly into\nUniLat, eliminating redundant stages. Trained solely on public datasets,\nUniLat3D produces high-quality 3D assets in seconds from a single image,\nachieving superior appearance fidelity and geometric quality. More demos \\&\ncode are available at https://unilat3d.github.io/", "published": "2025-09-29 17:21:23", "link": "http://arxiv.org/abs/2509.25079v1", "categories": ["cs.CV", "cs.AI", "cs.GR"], "primary_category": "cs.CV"}
{"title": "BRIDGE -- Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation", "abstract": "Monocular Depth Estimation (MDE) is a foundational task for computer vision.\nTraditional methods are limited by data scarcity and quality, hindering their\nrobustness. To overcome this, we propose BRIDGE, an RL-optimized depth-to-image\n(D2I) generation framework that synthesizes over 20M realistic and\ngeometrically accurate RGB images, each intrinsically paired with its ground\ntruth depth, from diverse source depth maps. Then we train our depth estimation\nmodel on this dataset, employing a hybrid supervision strategy that integrates\nteacher pseudo-labels with ground truth depth for comprehensive and robust\ntraining. This innovative data generation and training paradigm enables BRIDGE\nto achieve breakthroughs in scale and domain diversity, consistently\noutperforming existing state-of-the-art approaches quantitatively and in\ncomplex scene detail capture, thereby fostering general and robust depth\nfeatures. Code and models are available at\nhttps://dingning-liu.github.io/bridge.github.io/.", "published": "2025-09-29 17:19:45", "link": "http://arxiv.org/abs/2509.25077v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Optimizing Privacy-Preserving Primitives to Support LLM-Scale Applications", "abstract": "Privacy-preserving technologies have introduced a paradigm shift that allows\nfor realizable secure computing in real-world systems. The significant barrier\nto the practical adoption of these primitives is the computational and\ncommunication overhead that is incurred when applied at scale. In this paper,\nwe present an overview of our efforts to bridge the gap between this overhead\nand practicality for privacy-preserving learning systems using multi-party\ncomputation (MPC), zero-knowledge proofs (ZKPs), and fully homomorphic\nencryption (FHE). Through meticulous hardware/software/algorithm co-design, we\nshow progress towards enabling LLM-scale applications in privacy-preserving\nsettings. We demonstrate the efficacy of our solutions in several contexts,\nincluding DNN IP ownership, ethical LLM usage enforcement, and transformer\ninference.", "published": "2025-09-29 17:16:51", "link": "http://arxiv.org/abs/2509.25072v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Cogito, Ergo Ludo: An Agent that Learns to Play by Reasoning and Planning", "abstract": "The pursuit of artificial agents that can learn to master complex\nenvironments has led to remarkable successes, yet prevailing deep reinforcement\nlearning methods often rely on immense experience, encoding their knowledge\nopaquely within neural network weights. We propose a different paradigm, one in\nwhich an agent learns to play by reasoning and planning. We introduce Cogito,\nergo ludo (CEL), a novel agent architecture that leverages a Large Language\nModel (LLM) to build an explicit, language-based understanding of its\nenvironment's mechanics and its own strategy. Starting from a tabula rasa state\nwith no prior knowledge (except action set), CEL operates on a cycle of\ninteraction and reflection. After each episode, the agent analyzes its complete\ntrajectory to perform two concurrent learning processes: Rule Induction, where\nit refines its explicit model of the environment's dynamics, and Strategy and\nPlaybook Summarization, where it distills experiences into an actionable\nstrategic playbook. We evaluate CEL on diverse grid-world tasks (i.e.,\nMinesweeper, Frozen Lake, and Sokoban), and show that the CEL agent\nsuccessfully learns to master these games by autonomously discovering their\nrules and developing effective policies from sparse rewards. Ablation studies\nconfirm that the iterative process is critical for sustained learning. Our work\ndemonstrates a path toward more general and interpretable agents that not only\nact effectively but also build a transparent and improving model of their world\nthrough explicit reasoning on raw experience.", "published": "2025-09-29 17:02:31", "link": "http://arxiv.org/abs/2509.25052v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Scaling Synthetic Task Generation for Agents via Exploration", "abstract": "Post-Training Multimodal Large Language Models (MLLMs) to build interactive\nagents holds promise across domains such as computer-use, web navigation, and\nrobotics. A key challenge in scaling such post-training is lack of high-quality\ndownstream agentic task datasets with tasks that are diverse, feasible, and\nverifiable. Existing approaches for task generation rely heavily on human\nannotation or prompting MLLM with limited downstream environment information,\nwhich is either costly or poorly scalable as it yield tasks with limited\ncoverage. To remedy this, we present AutoPlay, a scalable pipeline for task\ngeneration that explicitly explores interactive environments to discover\npossible interactions and current state information to synthesize\nenvironment-grounded tasks. AutoPlay operates in two stages: (i) an exploration\nphase, where an MLLM explorer agent systematically uncovers novel environment\nstates and functionalities, and (ii) a task generation phase, where a task\ngenerator leverages exploration trajectories and a set of task guideline\nprompts as context to synthesize diverse, executable, and verifiable tasks. We\nshow AutoPlay generates 20k tasks across 20 Android applications and 10k tasks\nacross 13 applications Ubuntu applications to train mobile-use and computer-use\nagents. AutoPlay generated tasks enable large-scale task demonstration\nsynthesis without human annotation by employing an MLLM task executor and\nverifier. This data enables training MLLM-based UI agents that improve success\nrates up to $20.0\\%$ on mobile-use and $10.9\\%$ on computer-use scenarios. In\naddition, AutoPlay generated tasks combined with MLLM verifier-based rewards\nenable scaling reinforcement learning training of UI agents, leading to an\nadditional $5.7\\%$ gain. coverage. These results establish AutoPlay as a\nscalable approach for post-training capable MLLM agents reducing reliance on\nhuman annotation.", "published": "2025-09-29 17:00:02", "link": "http://arxiv.org/abs/2509.25047v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Large Language Models for Software Testing: A Research Roadmap", "abstract": "Large Language Models (LLMs) are starting to be profiled as one of the most\nsignificant disruptions in the Software Testing field.\n  Specifically, they have been successfully applied in software testing tasks\nsuch as generating test code, or summarizing documentation.\n  This potential has attracted hundreds of researchers, resulting in dozens of\nnew contributions every month, hardening researchers to\n  stay at the forefront of the wave. Still, to the best of our knowledge, no\nprior work has provided a structured vision of the progress\n  and most relevant research trends in LLM-based testing. In this article, we\naim to provide a roadmap that illustrates its current state,\n  grouping the contributions into different categories, and also sketching the\nmost promising and active research directions for the field.\n  To achieve this objective, we have conducted a semi-systematic literature\nreview, collecting articles and mapping them into the most\n  prominent categories, reviewing the current and ongoing status, and analyzing\nthe open challenges of LLM-based software testing.\n  Lastly, we have outlined several expected long-term impacts of LLMs over the\nwhole software testing field.", "published": "2025-09-29 16:58:21", "link": "http://arxiv.org/abs/2509.25043v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Fast Real-Time Pipeline for Robust Arm Gesture Recognition", "abstract": "This paper presents a real-time pipeline for dynamic arm gesture recognition\nbased on OpenPose keypoint estimation, keypoint normalization, and a recurrent\nneural network classifier. The 1 x 1 normalization scheme and two feature\nrepresentations (coordinate- and angle-based) are presented for the pipeline.\nIn addition, an efficient method to improve robustness against camera angle\nvariations is also introduced by using artificially rotated training data.\nExperiments on a custom traffic-control gesture dataset demonstrate high\naccuracy across varying viewing angles and speeds. Finally, an approach to\ncalculate the speed of the arm signal (if necessary) is also presented.", "published": "2025-09-29 16:57:56", "link": "http://arxiv.org/abs/2509.25042v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation", "abstract": "As robots transition from controlled settings to unstructured human\nenvironments, building generalist agents that can reliably follow natural\nlanguage instructions remains a central challenge. Progress in robust mobile\nmanipulation requires large-scale multimodal datasets that capture contact-rich\nand long-horizon tasks, yet existing resources lack synchronized force-torque\nsensing, hierarchical annotations, and explicit failure cases. We address this\ngap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset\nfor mobile manipulation. It includes synchronized RGB images, joint states,\nsix-axis wrist force-torque signals, and internal robot states, together with a\nnovel two-layer annotation schema of sub-goals and primitive actions for\nhierarchical learning and error analysis. The initial dataset comprises 25,469\nepisodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is\nfully standardized in the LeRobot v2.1 format. By uniquely integrating mobile\nmanipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa\nprovides a critical benchmark for advancing the next generation of\nVision-Language-Action models. The first version of our dataset is now\navailable at https://huggingface.co/datasets/airoa-org/airoa-moma .", "published": "2025-09-29 16:51:47", "link": "http://arxiv.org/abs/2509.25032v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "CLASP: Adaptive Spectral Clustering for Unsupervised Per-Image Segmentation", "abstract": "We introduce CLASP (Clustering via Adaptive Spectral Processing), a\nlightweight framework for unsupervised image segmentation that operates without\nany labeled data or finetuning. CLASP first extracts per patch features using a\nself supervised ViT encoder (DINO); then, it builds an affinity matrix and\napplies spectral clustering. To avoid manual tuning, we select the segment\ncount automatically with a eigengap silhouette search, and we sharpen the\nboundaries with a fully connected DenseCRF. Despite its simplicity and training\nfree nature, CLASP attains competitive mIoU and pixel accuracy on COCO Stuff\nand ADE20K, matching recent unsupervised baselines. The zero training design\nmakes CLASP a strong, easily reproducible baseline for large unannotated\ncorpora especially common in digital advertising and marketing workflows such\nas brand safety screening, creative asset curation, and social media content\nmoderation", "published": "2025-09-29 16:41:30", "link": "http://arxiv.org/abs/2509.25016v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CLPO: Curriculum Learning meets Policy Optimization for LLM Reasoning", "abstract": "Recently, online Reinforcement Learning with Verifiable Rewards (RLVR) has\nbecome a key paradigm for enhancing the reasoning capabilities of Large\nLanguage Models (LLMs). However, existing methods typically treat all training\nsamples uniformly, overlooking the vast differences in problem difficulty\nrelative to the model's current capabilities. This uniform training strategy\nleads to inefficient exploration of problems the model has already mastered,\nwhile concurrently lacking effective guidance on problems that are challenging\nits abilities the most, limiting both learning efficiency and upper-bound\nperformance. To address this, we propose CLPO (Curriculum-guided Learning for\nPolicy Optimization), a novel algorithm that creates a dynamic pedagogical\nfeedback loop within the policy optimization process. The core of CLPO\nleverages the model's own rollout performance to conduct real-time difficulty\nassessment, thereby constructing an Online Curriculum. This curriculum then\nguides an Adaptive Problem Restructuring mechanism, where the model acts as its\nown teacher: it diversifies medium-difficulty problems to promote\ngeneralization and simplifies challenging problems to make them more\nattainable. Our approach transforms the static training procedure into a\ndynamic process that co-evolves with the model's capabilities. Experiments show\nthat CLPO achieves state-of-the-art performance across eight challenging\nmathematical and general reasoning benchmarks, with an average pass@1\nimprovement of 6.96% over other methods, demonstrating its potential for more\nefficiently training more capable reasoning models.", "published": "2025-09-29 16:29:04", "link": "http://arxiv.org/abs/2509.25004v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Light-SQ: Structure-aware Shape Abstraction with Superquadrics for Generated Meshes", "abstract": "In user-generated-content (UGC) applications, non-expert users often rely on\nimage-to-3D generative models to create 3D assets. In this context,\nprimitive-based shape abstraction offers a promising solution for UGC scenarios\nby compressing high-resolution meshes into compact, editable representations.\nTowards this end, effective shape abstraction must therefore be\nstructure-aware, characterized by low overlap between primitives, part-aware\nalignment, and primitive compactness. We present Light-SQ, a novel\nsuperquadric-based optimization framework that explicitly emphasizes\nstructure-awareness from three aspects. (a) We introduce SDF carving to\niteratively udpate the target signed distance field, discouraging overlap\nbetween primitives. (b) We propose a block-regrow-fill strategy guided by\nstructure-aware volumetric decomposition, enabling structural partitioning to\ndrive primitive placement. (c) We implement adaptive residual pruning based on\nSDF update history to surpress over-segmentation and ensure compact results. In\naddition, Light-SQ supports multiscale fitting, enabling localized refinement\nto preserve fine geometric details. To evaluate our method, we introduce\n3DGen-Prim, a benchmark extending 3DGen-Bench with new metrics for both\nreconstruction quality and primitive-level editability. Extensive experiments\ndemonstrate that Light-SQ enables efficient, high-fidelity, and editable shape\nabstraction with superquadrics for complex generated geometry, advancing the\nfeasibility of 3D UGC creation.", "published": "2025-09-29 16:18:32", "link": "http://arxiv.org/abs/2509.24986v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards", "abstract": "RL with Verifiable Rewards (RLVR) has emerged as a promising paradigm for\nimproving the reasoning abilities of large language models (LLMs). Current\nmethods rely primarily on policy optimization frameworks like PPO and GRPO,\nwhich follow generalized policy iteration that alternates between evaluating\nthe current policy's value and improving the policy based on evaluation. While\neffective, they often suffer from training instability and diversity collapse,\nrequiring complex heuristic tricks and careful tuning. We observe that standard\nRLVR in math reasoning can be formalized as a specialized finite-horizon Markov\nDecision Process with deterministic state transitions, tree-structured\ndynamics, and binary terminal rewards. Though large in scale, the underlying\nstructure is simpler than general-purpose control settings for which popular RL\nalgorithms (e.g., PPO) were developed, suggesting that several sophisticated\ntechniques in existing methods may be reduced or even omitted. Based on this\ninsight, we prove a surprising result: the optimal action can be recovered from\nthe Q-function of a fixed uniformly random policy, thereby bypassing the\ngeneralized policy iteration loop and its associated heuristics. We introduce\nRandom Policy Valuation for Diverse Reasoning (ROVER) to translate this\nprinciple into a practical and scalable algorithm for LLM math reasoning, a\nminimalist yet highly effective RL method that samples actions from a softmax\nover these uniform-policy Q-values. ROVER preserves diversity throughout\ntraining, allowing sustained exploration of multiple valid pathways. Across\nmultiple base models and standard math reasoning benchmarks, ROVER demonstrates\nsuperior performance in both \\textbf{quality} (\\textbf{+8.2} on pass@1,\n\\textbf{+16.8} on pass@256) and \\textbf{diversity} (\\textbf{+17.6\\%}), despite\nits radical simplification compared to strong, complicated existing methods.", "published": "2025-09-29 16:09:07", "link": "http://arxiv.org/abs/2509.24981v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Agentic Exploration of Physics Models", "abstract": "The process of scientific discovery relies on an interplay of observations,\nanalysis, and hypothesis generation. Machine learning is increasingly being\nadopted to address individual aspects of this process. However, it remains an\nopen challenge to fully automate the open-ended, heuristic, iterative loop\nrequired to discover the laws of an unknown system by exploring it through\nexperiments and analysis, without tailoring the approach to the specifics of a\ngiven task. Here, we introduce SciExplorer, an agent that leverages large\nlanguage model tool-use capabilities to enable free-form exploration of systems\nwithout any domain-specific blueprints, and apply it to the exploration of\nphysical systems that are initially unknown to the agent. We test SciExplorer\non a broad set of models spanning mechanical dynamical systems, wave evolution,\nand quantum many-body physics. Despite using a minimal set of tools, primarily\nbased on code execution, we observe impressive performance on tasks such as\nrecovering equations of motion from observed dynamics and inferring\nHamiltonians from expectation values. The demonstrated effectiveness of this\nsetup opens the door towards similar scientific exploration in other domains,\nwithout the need for finetuning or task-specific instructions.", "published": "2025-09-29 16:07:05", "link": "http://arxiv.org/abs/2509.24978v1", "categories": ["cs.AI", "cond-mat.quant-gas", "quant-ph"], "primary_category": "cs.AI"}
{"title": "SecInfer: Preventing Prompt Injection via Inference-time Scaling", "abstract": "Prompt injection attacks pose a pervasive threat to the security of Large\nLanguage Models (LLMs). State-of-the-art prevention-based defenses typically\nrely on fine-tuning an LLM to enhance its security, but they achieve limited\neffectiveness against strong attacks. In this work, we propose \\emph{SecInfer},\na novel defense against prompt injection attacks built on \\emph{inference-time\nscaling}, an emerging paradigm that boosts LLM capability by allocating more\ncompute resources for reasoning during inference. SecInfer consists of two key\nsteps: \\emph{system-prompt-guided sampling}, which generates multiple responses\nfor a given input by exploring diverse reasoning paths through a varied set of\nsystem prompts, and \\emph{target-task-guided aggregation}, which selects the\nresponse most likely to accomplish the intended task. Extensive experiments\nshow that, by leveraging additional compute at inference, SecInfer effectively\nmitigates both existing and adaptive prompt injection attacks, outperforming\nstate-of-the-art defenses as well as existing inference-time scaling\napproaches.", "published": "2025-09-29 16:00:41", "link": "http://arxiv.org/abs/2509.24967v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation", "abstract": "Generative robot policies such as Flow Matching offer flexible, multi-modal\npolicy learning but are sample-inefficient. Although object-centric policies\nimprove sample efficiency, it does not resolve this limitation. In this work,\nwe propose Multi-Stream Generative Policy (MSG), an inference-time composition\nframework that trains multiple object-centric policies and combines them at\ninference to improve generalization and sample efficiency. MSG is\nmodel-agnostic and inference-only, hence widely applicable to various\ngenerative policies and training paradigms. We perform extensive experiments\nboth in simulation and on a real robot, demonstrating that our approach learns\nhigh-quality generative policies from as few as five demonstrations, resulting\nin a 95% reduction in demonstrations, and improves policy performance by 89\npercent compared to single-stream approaches. Furthermore, we present\ncomprehensive ablation studies on various composition strategies and provide\npractical recommendations for deployment. Finally, MSG enables zero-shot object\ninstance transfer. We make our code publicly available at\nhttps://msg.cs.uni-freiburg.de.", "published": "2025-09-29 15:50:51", "link": "http://arxiv.org/abs/2509.24956v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Learning Distinguishable Representations in Deep Q-Networks for Linear Transfer", "abstract": "Deep Reinforcement Learning (RL) has demonstrated success in solving complex\nsequential decision-making problems by integrating neural networks with the RL\nframework. However, training deep RL models poses several challenges, such as\nthe need for extensive hyperparameter tuning and high computational costs.\nTransfer learning has emerged as a promising strategy to address these\nchallenges by enabling the reuse of knowledge from previously learned tasks for\nnew, related tasks. This avoids the need for retraining models entirely from\nscratch. A commonly used approach for transfer learning in RL is to leverage\nthe internal representations learned by the neural network during training.\nSpecifically, the activations from the last hidden layer can be viewed as\nrefined state representations that encapsulate the essential features of the\ninput. In this work, we investigate whether these representations can be used\nas input for training simpler models, such as linear function approximators, on\nnew tasks. We observe that the representations learned by standard deep RL\nmodels can be highly correlated, which limits their effectiveness when used\nwith linear function approximation. To mitigate this problem, we propose a\nnovel deep Q-learning approach that introduces a regularization term to reduce\npositive correlations between feature representation of states. By leveraging\nthese reduced correlated features, we enable more effective use of linear\nfunction approximation in transfer learning. Through experiments and ablation\nstudies on standard RL benchmarks and MinAtar games, we demonstrate the\nefficacy of our approach in improving transfer learning performance and thereby\nreducing computational overhead.", "published": "2025-09-29 15:44:35", "link": "http://arxiv.org/abs/2509.24947v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Scalable GANs with Transformers", "abstract": "Scalability has driven recent advances in generative modeling, yet its\nprinciples remain underexplored for adversarial learning. We investigate the\nscalability of Generative Adversarial Networks (GANs) through two design\nchoices that have proven to be effective in other types of generative models:\ntraining in a compact Variational Autoencoder latent space and adopting purely\ntransformer-based generators and discriminators. Training in latent space\nenables efficient computation while preserving perceptual fidelity, and this\nefficiency pairs naturally with plain transformers, whose performance scales\nwith computational budget. Building on these choices, we analyze failure modes\nthat emerge when naively scaling GANs. Specifically, we find issues as\nunderutilization of early layers in the generator and optimization instability\nas the network scales. Accordingly, we provide simple and scale-friendly\nsolutions as lightweight intermediate supervision and width-aware learning-rate\nadjustment. Our experiments show that GAT, a purely transformer-based and\nlatent-space GANs, can be easily trained reliably across a wide range of\ncapacities (S through XL). Moreover, GAT-XL/2 achieves state-of-the-art\nsingle-step, class-conditional generation performance (FID of 2.96) on\nImageNet-256 in just 40 epochs, 6x fewer epochs than strong baselines.", "published": "2025-09-29 15:36:15", "link": "http://arxiv.org/abs/2509.24935v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "KIRETT -- A wearable device to support rescue operations using artificial intelligence to improve first aid", "abstract": "This short paper presents first steps in the scientific part of the KIRETT\nproject, which aims to improve first aid during rescue operations using a\nwearable device. The wearable is used for computer-aided situation recognition\nby means of artificial intelligence. It provides contextual recommendations for\nactions and operations to rescue personnel and is intended to minimize damage\nto patients due to incorrect treatment, as well as increase the probability of\nsurvival. The paper describes a first overview of research approaches within\nthe project.", "published": "2025-09-29 15:36:14", "link": "http://arxiv.org/abs/2509.24934v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?", "abstract": "With the tremendous advancement of deep learning and communication\ntechnology, Vehicle-to-Everything (V2X) cooperative perception has the\npotential to address limitations in sensing distant objects and occlusion for a\nsingle-agent perception system. V2X cooperative perception systems are software\nsystems characterized by diverse sensor types and cooperative agents, varying\nfusion schemes, and operation under different communication conditions.\nTherefore, their complex composition gives rise to numerous operational\nchallenges. Furthermore, when cooperative perception systems produce erroneous\npredictions, the types of errors and their underlying causes remain\ninsufficiently explored. To bridge this gap, we take an initial step by\nconducting an empirical study of V2X cooperative perception. To systematically\nevaluate the impact of cooperative perception on the ego vehicle's perception\nperformance, we identify and analyze six prevalent error patterns in\ncooperative perception systems. We further conduct a systematic evaluation of\nthe critical components of these systems through our large-scale study and\nidentify the following key findings: (1) The LiDAR-based cooperation\nconfiguration exhibits the highest perception performance; (2)\nVehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication\nexhibit distinct cooperative perception performance under different fusion\nschemes; (3) Increased cooperative perception errors may result in a higher\nfrequency of driving violations; (4) Cooperative perception systems are not\nrobust against communication interference when running online. Our results\nreveal potential risks and vulnerabilities in critical components of\ncooperative perception systems. We hope that our findings can better promote\nthe design and repair of cooperative perception systems.", "published": "2025-09-29 15:28:27", "link": "http://arxiv.org/abs/2509.24927v1", "categories": ["cs.AI", "cs.RO", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Meta-Learning Theory-Informed Inductive Biases using Deep Kernel Gaussian Processes", "abstract": "Normative and task-driven theories offer powerful top-down explanations for\nbiological systems, yet the goals of quantitatively arbitrating between\ncompeting theories, and utilizing them as inductive biases to improve\ndata-driven fits of real biological datasets are prohibitively laborious, and\noften impossible. To this end, we introduce a Bayesian meta-learning framework\ndesigned to automatically convert raw functional predictions from normative\ntheories into tractable probabilistic models. We employ adaptive deep kernel\nGaussian processes, meta-learning a kernel on synthetic data generated from a\nnormative theory. This Theory-Informed Kernel specifies a probabilistic model\nrepresenting the theory predictions -- usable for both fitting data and\nrigorously validating the theory. As a demonstration, we apply our framework to\nthe early visual system, using efficient coding as our normative theory. We\nshow improved response prediction accuracy in ex vivo recordings of mouse\nretinal ganglion cells stimulated by natural scenes compared to conventional\ndata-driven baselines, while providing well-calibrated uncertainty estimates\nand interpretable representations. Using exact Bayesian model selection, we\nalso show that our informed kernel can accurately infer the degree of\ntheory-match from data, confirming faithful encapsulation of theory structure.\nThis work provides a more general, scalable, and automated approach for\nintegrating theoretical knowledge into data-driven scientific inquiry in\nneuroscience and beyond.", "published": "2025-09-29 15:23:50", "link": "http://arxiv.org/abs/2509.24919v1", "categories": ["cs.AI", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "Segmentor-Guided Counterfactual Fine-Tuning for Image Synthesis", "abstract": "Counterfactual image generation is a powerful tool for augmenting training\ndata, de-biasing datasets, and modeling disease. Current approaches rely on\nexternal classifiers or regressors to increase the effectiveness of\nsubject-level interventions (e.g., changing the patient's age). For\nstructure-specific interventions (e.g., changing the area of the left lung in a\nchest radiograph), we show that this is insufficient, and can result in\nundesirable global effects across the image domain. Previous work used\npixel-level label maps as guidance, requiring a user to provide hypothetical\nsegmentations which are tedious and difficult to obtain. We propose\nSegmentor-guided Counterfactual Fine-Tuning (Seg-CFT), which preserves the\nsimplicity of intervening on scalar-valued, structure-specific variables while\nproducing locally coherent and effective counterfactuals. We demonstrate the\ncapability of generating realistic chest radiographs, and we show promising\nresults for modeling coronary artery disease. Code:\nhttps://github.com/biomedia-mira/seg-cft.", "published": "2025-09-29 15:19:09", "link": "http://arxiv.org/abs/2509.24913v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing", "abstract": "The performance of unified multimodal models for image generation and editing\nis fundamentally constrained by the quality and comprehensiveness of their\ntraining data. While existing datasets have covered basic tasks like style\ntransfer and simple object manipulation, they often lack the systematic\nstructure and challenging scenarios required for real-world applications. To\naddress this bottleneck, we introduce OpenGPT-4o-Image, a large-scale dataset\nconstructed using a novel methodology that combines hierarchical task taxonomy\nwith automated data generation. Our taxonomy not only includes fundamental\ncapabilities such as text rendering and style control but also introduces\nhighly practical yet challenging categories like scientific imagery for\nchemistry illustrations and complex instruction editing requiring simultaneous\nexecution of multiple operations. Through an automated pipeline leveraging\nstructured resource pools and GPT-4o, we generate 80k high-quality\ninstruction-image pairs with controlled diversity, covering 11 major domains\nand 51 subtasks. Extensive experiments show that fine-tuning leading models on\nour dataset achieves significant performance gains across multiple benchmarks,\nwith improvements of up to 18\\% on editing tasks (UniWorld-V1 on ImgEdit-Bench)\nand 13% on generation tasks (Harmon on GenEval). Our work demonstrates that\nsystematic data construction is key to advancing multimodal AI capabilities.", "published": "2025-09-29 15:11:09", "link": "http://arxiv.org/abs/2509.24900v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark", "abstract": "The integration of visual understanding and generation into unified\nmultimodal models represents a significant stride toward general-purpose AI.\nHowever, a fundamental question remains unanswered by existing benchmarks: does\nthis architectural unification actually enable synergetic interaction between\nthe constituent capabilities? Existing evaluation paradigms, which primarily\nassess understanding and generation in isolation, are insufficient for\ndetermining whether a unified model can leverage its understanding to enhance\nits generation, or use generative simulation to facilitate deeper\ncomprehension. To address this critical gap, we introduce RealUnify, a\nbenchmark specifically designed to evaluate bidirectional capability synergy.\nRealUnify comprises 1,000 meticulously human-annotated instances spanning 10\ncategories and 32 subtasks. It is structured around two core axes: 1)\nUnderstanding Enhances Generation, which requires reasoning (e.g., commonsense,\nlogic) to guide image generation, and 2) Generation Enhances Understanding,\nwhich necessitates mental simulation or reconstruction (e.g., of transformed or\ndisordered visual inputs) to solve reasoning tasks. A key contribution is our\ndual-evaluation protocol, which combines direct end-to-end assessment with a\ndiagnostic stepwise evaluation that decomposes tasks into distinct\nunderstanding and generation phases. This protocol allows us to precisely\ndiscern whether performance bottlenecks stem from deficiencies in core\nabilities or from a failure to integrate them. Through large-scale evaluations\nof 12 leading unified models and 6 specialized baselines, we find that current\nunified models still struggle to achieve effective synergy, indicating that\narchitectural unification alone is insufficient. These results highlight the\nneed for new training strategies and inductive biases to fully unlock the\npotential of unified modeling.", "published": "2025-09-29 15:07:28", "link": "http://arxiv.org/abs/2509.24897v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime", "abstract": "Neural scaling laws underlie many of the recent advances in deep learning,\nyet their theoretical understanding remains largely confined to linear models.\nIn this work, we present a systematic analysis of scaling laws for quadratic\nand diagonal neural networks in the feature learning regime. Leveraging\nconnections with matrix compressed sensing and LASSO, we derive a detailed\nphase diagram for the scaling exponents of the excess risk as a function of\nsample complexity and weight decay. This analysis uncovers crossovers between\ndistinct scaling regimes and plateau behaviors, mirroring phenomena widely\nreported in the empirical neural scaling literature. Furthermore, we establish\na precise link between these regimes and the spectral properties of the trained\nnetwork weights, which we characterize in detail. As a consequence, we provide\na theoretical validation of recent empirical observations connecting the\nemergence of power-law tails in the weight spectrum with network generalization\nperformance, yielding an interpretation from first principles.", "published": "2025-09-29 14:58:13", "link": "http://arxiv.org/abs/2509.24882v1", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Vehicle Classification under Extreme Imbalance: A Comparative Study of Ensemble Learning and CNNs", "abstract": "Accurate vehicle type recognition underpins intelligent transportation and\nlogistics, but severe class imbalance in public datasets suppresses performance\non rare categories. We curate a 16-class corpus (~47k images) by merging\nKaggle, ImageNet, and web-crawled data, and create six balanced variants via\nSMOTE oversampling and targeted undersampling. Lightweight ensembles, such as\nRandom Forest, AdaBoost, and a soft-voting combiner built on MobileNet-V2\nfeatures are benchmarked against a configurable ResNet-style CNN trained with\nstrong augmentation and label smoothing. The best ensemble (SMOTE-combined)\nattains 74.8% test accuracy, while the CNN achieves 79.19% on the full test set\nand 81.25% on an unseen inference batch, confirming the advantage of deep\nmodels. Nonetheless, the most under-represented class (Barge) remains a failure\nmode, highlighting the limits of rebalancing alone. Results suggest\nprioritizing additional minority-class collection and cost-sensitive objectives\n(e.g., focal loss) and exploring hybrid ensemble or CNN pipelines to combine\ninterpretability with representational power.", "published": "2025-09-29 14:56:56", "link": "http://arxiv.org/abs/2509.24880v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Emergence of Social Science of Large Language Models", "abstract": "The social science of large language models (LLMs) examines how these systems\nevoke mind attributions, interact with one another, and transform human\nactivity and institutions. We conducted a systematic review of 270 studies,\ncombining text embeddings, unsupervised clustering and topic modeling to build\na computational taxonomy. Three domains emerge organically across the reviewed\nliterature. LLM as Social Minds examines whether and when models display\nbehaviors that elicit attributions of cognition, morality and bias, while\naddressing challenges such as test leakage and surface cues. LLM Societies\nexamines multi-agent settings where interaction protocols, architectures and\nmechanism design shape coordination, norms, institutions and collective\nepistemic processes. LLM-Human Interactions examines how LLMs reshape tasks,\nlearning, trust, work and governance, and how risks arise at the human-AI\ninterface. This taxonomy provides a reproducible map of a fragmented field,\nclarifies evidentiary standards across levels of analysis, and highlights\nopportunities for cumulative progress in the social science of artificial\nintelligence.", "published": "2025-09-29 14:55:14", "link": "http://arxiv.org/abs/2509.24877v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Uncertainty-Guided Expert-AI Collaboration for Efficient Soil Horizon Annotation", "abstract": "Uncertainty quantification is essential in human-machine collaboration, as\nhuman agents tend to adjust their decisions based on the confidence of the\nmachine counterpart. Reliably calibrated model uncertainties, hence, enable\nmore effective collaboration, targeted expert intervention and more responsible\nusage of Machine Learning (ML) systems. Conformal prediction has become a well\nestablished model-agnostic framework for uncertainty calibration of ML models,\noffering statistically valid confidence estimates for both regression and\nclassification tasks. In this work, we apply conformal prediction to\n$\\textit{SoilNet}$, a multimodal multitask model for describing soil profiles.\nWe design a simulated human-in-the-loop (HIL) annotation pipeline, where a\nlimited budget for obtaining ground truth annotations from domain experts is\navailable when model uncertainty is high. Our experiments show that\nconformalizing SoilNet leads to more efficient annotation in regression tasks\nand comparable performance scores in classification tasks under the same\nannotation budget when tested against its non-conformal counterpart. All code\nand experiments can be found in our repository:\nhttps://github.com/calgo-lab/BGR", "published": "2025-09-29 14:54:23", "link": "http://arxiv.org/abs/2509.24873v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PhysicsMinions: Winning Gold Medals in the Latest Physics Olympiads with a Coevolutionary Multimodal Multi-Agent System", "abstract": "Physics is central to understanding and shaping the real world, and the\nability to solve physics problems is a key indicator of real-world physical\nintelligence. Physics Olympiads, renowned as the crown of competitive physics,\nprovide a rigorous testbed requiring complex reasoning and deep multimodal\nunderstanding, yet they remain largely underexplored in AI research. Existing\napproaches are predominantly single-model based, and open-source MLLMs rarely\nreach gold-medal-level performance. To address this gap, we propose\nPhysicsMinions, a coevolutionary multi-agent system for Physics Olympiad. Its\narchitecture features three synergistic studios: a Visual Studio to interpret\ndiagrams, a Logic Studio to formulate solutions, and a Review Studio to perform\ndual-stage verification. The system coevolves through an iterative refinement\nloop where feedback from the Review Studio continuously guides the Logic\nStudio, enabling the system to self-correct and converge towards the ground\ntruth. Evaluated on the HiPhO benchmark spanning 7 latest physics Olympiads,\nPhysicsMinions delivers three major breakthroughs: (i) Strong generalization:\nit consistently improves both open-source and closed-source models of different\nsizes, delivering clear benefits over their single-model baselines; (ii)\nHistoric breakthroughs: it elevates open-source models from only 1-2 to 6 gold\nmedals across 7 Olympiads, achieving the first-ever open-source gold medal in\nthe latest International Physics Olympiad (IPhO) under the average-score\nmetric; and (iii) Scaling to human expert: it further advances the open-source\nPass@32 score to 26.8/30 points on the latest IPhO, ranking 4th of 406\ncontestants and far surpassing the top single-model score of 22.7 (ranked\n22nd). Generally, PhysicsMinions offers a generalizable framework for\nOlympiad-level problem solving, with the potential to extend across\ndisciplines.", "published": "2025-09-29 14:40:53", "link": "http://arxiv.org/abs/2509.24855v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Evaluating SAP Joule for Code Generation", "abstract": "SAP has released its own proprietary generative model SAP Joule, intended for\nvarious generative tasks, including serving as a code assistant for software\nengineers. While Joule is yet not focused on SAP-specific ABAP code generation,\nit can be used for other common languages, including Javascript. This paper\ncompares SAP Joules Javascript coding capabilities against a total of 29 other\nmodels using the HumanEval-X Javascript benchmark. SAP Joule achieves a strict\naccuracy of 80.49% as the fifth best model in our evaluation. To the best of\nour knowledge, this is the first comparative evaluation of SAP Joule code\ngeneration capabilities.", "published": "2025-09-29 14:13:40", "link": "http://arxiv.org/abs/2509.24828v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Putnam-like dataset summary: LLMs as mathematical competition contestants", "abstract": "In this paper we summarize the results of the Putnam-like benchmark published\nby Google DeepMind. This dataset consists of 96 original problems in the spirit\nof the Putnam Competition and 576 solutions of LLMs. We analyse the performance\nof models on this set of problems to verify their ability to solve problems\nfrom mathematical contests.", "published": "2025-09-29 14:13:10", "link": "http://arxiv.org/abs/2509.24827v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Of-SemWat: High-payload text embedding for semantic watermarking of AI-generated images with arbitrary size", "abstract": "We propose a high-payload image watermarking method for textual embedding,\nwhere a semantic description of the image - which may also correspond to the\ninput text prompt-, is embedded inside the image. In order to be able to\nrobustly embed high payloads in large-scale images - such as those produced by\nmodern AI generators - the proposed approach builds upon a traditional\nwatermarking scheme that exploits orthogonal and turbo codes for improved\nrobustness, and integrates frequency-domain embedding and perceptual masking\ntechniques to enhance watermark imperceptibility. Experiments show that the\nproposed method is extremely robust against a wide variety of image processing,\nand the embedded text can be retrieved also after traditional and AI\ninpainting, permitting to unveil the semantic modification the image has\nundergone via image-text mismatch analysis.", "published": "2025-09-29 14:10:15", "link": "http://arxiv.org/abs/2509.24823v1", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning", "abstract": "Urban railway systems increasingly rely on communication based train control\n(CBTC) systems, where optimal deployment of access points (APs) in tunnels is\ncritical for robust wireless coverage. Traditional methods, such as empirical\nmodel-based optimization algorithms, are hindered by excessive measurement\nrequirements and suboptimal solutions, while machine learning (ML) approaches\noften struggle with complex tunnel environments. This paper proposes a deep\nreinforcement learning (DRL) driven framework that integrates parabolic wave\nequation (PWE) channel modeling, conditional generative adversarial network\n(cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for\nAP placement optimization. The PWE method generates high-fidelity path loss\ndistributions for a subset of AP positions, which are then expanded by the cGAN\nto create high resolution path loss maps for all candidate positions,\nsignificantly reducing simulation costs while maintaining physical accuracy. In\nthe DRL framework, the state space captures AP positions and coverage, the\naction space defines AP adjustments, and the reward function encourages signal\nimprovement while penalizing deployment costs. The dueling DQN enhances\nconvergence speed and exploration exploitation balance, increasing the\nlikelihood of reaching optimal configurations. Comparative experiments show\nthat the proposed method outperforms a conventional Hooke Jeeves optimizer and\ntraditional DQN, delivering AP configurations with higher average received\npower, better worst-case coverage, and improved computational efficiency. This\nwork integrates high-fidelity electromagnetic simulation, generative modeling,\nand AI-driven optimization, offering a scalable and data-efficient solution for\nnext-generation CBTC systems in complex tunnel environments.", "published": "2025-09-29 14:07:44", "link": "http://arxiv.org/abs/2509.24819v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Query Circuits: Explaining How Language Models Answer User Prompts", "abstract": "Explaining why a language model produces a particular output requires local,\ninput-level explanations. Existing methods uncover global capability circuits\n(e.g., indirect object identification), but not why the model answers a\nspecific input query in a particular way. We introduce query circuits, which\ndirectly trace the information flow inside a model that maps a specific input\nto the output. Unlike surrogate-based approaches (e.g., sparse autoencoders),\nquery circuits are identified within the model itself, resulting in more\nfaithful and computationally accessible explanations. To make query circuits\npractical, we address two challenges. First, we introduce Normalized Deviation\nFaithfulness (NDF), a robust metric to evaluate how well a discovered circuit\nrecovers the model's decision for a specific input, and is broadly applicable\nto circuit discovery beyond our setting. Second, we develop sampling-based\nmethods to efficiently identify circuits that are sparse yet faithfully\ndescribe the model's behavior. Across benchmarks (IOI, arithmetic, MMLU, and\nARC), we find that there exist extremely sparse query circuits within the model\nthat can recover much of its performance on single queries. For example, a\ncircuit covering only 1.3% of model connections can recover about 60% of\nperformance on an MMLU questions. Overall, query circuits provide a step\ntowards faithful, scalable explanations of how language models process\nindividual inputs.", "published": "2025-09-29 13:59:02", "link": "http://arxiv.org/abs/2509.24808v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off", "abstract": "Extensive monitoring systems generate data that is usually compressed for\nnetwork transmission. This compressed data might then be processed in the cloud\nfor tasks such as anomaly detection. However, compression can potentially\nimpair the detector's ability to distinguish between regular and irregular\npatterns due to information loss. Here we extend the information-theoretic\nframework introduced in [1] to simultaneously address the trade-off between the\nthree features on which the effectiveness of the system depends: the\neffectiveness of compression, the amount of distortion it introduces, and the\ndistinguishability between compressed normal signals and compressed anomalous\nsignals. We leverage a Gaussian assumption to draw curves showing how moving on\na Pareto surface helps administer such a trade-off better than simply relying\non optimal rate-distortion compression and hoping that compressed signals can\nbe distinguished from each other.", "published": "2025-09-29 13:55:35", "link": "http://arxiv.org/abs/2509.24805v1", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models", "abstract": "Recent advances in multimodal time series learning underscore a paradigm\nshift from analytics centered on basic patterns toward advanced time series\nunderstanding and reasoning. However, existing multimodal time series datasets\nmostly remain at the level of surface alignment and question answering, without\nreaching the depth of genuine reasoning. The absence of well-defined tasks that\ngenuinely require time series reasoning, along with the scarcity of\nhigh-quality data, has limited progress in building practical time series\nreasoning models (TSRMs). To this end, we introduce Time Series Reasoning Suite\n(TSR-Suite), which formalizes four atomic tasks that span three fundamental\ncapabilities for reasoning with time series: (1) perception, acquired through\nscenario understanding and causality discovery; (2) extrapolation, realized via\nevent-aware forecasting; and (3) decision-making, developed through\ndeliberation over perception and extrapolation. TSR-Suite is the first\ncomprehensive time series reasoning suite that supports not only thorough\nevaluation but also the data pipeline and training of TSRMs. It contains more\nthan 23K samples, of which 2.3K are carefully curated through a human-guided\nhierarchical annotation process. Building on this foundation, we introduce\nTimeOmni-1, the first unified reasoning model designed to address diverse\nreal-world problems demanding time series reasoning. The model is trained in\nmultiple stages, integrating a mixture of task scenarios, novel reward\nfunctions, and tailored optimizations. Experiments show that TimeOmni-1\ndelivers strong out-of-distribution generalization across all tasks and\nachieves a high rate of valid responses. It significantly improves causality\ndiscovery accuracy (64.0% vs. 35.9% with GPT-4.1) and raises the valid response\nrate by over 6% compared to GPT-4.1 on the event-aware forecasting task.", "published": "2025-09-29 13:54:34", "link": "http://arxiv.org/abs/2509.24803v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DSAT-HD: Dual-Stream Adaptive Transformer with Hybrid Decomposition for Multivariate Time Series Forecasting", "abstract": "Time series forecasting is crucial for various applications, such as weather,\ntraffic, electricity, and energy predictions. Currently, common time series\nforecasting methods are based on Transformers. However, existing approaches\nprimarily model limited time series or fixed scales, making it more challenging\nto capture diverse features cross different ranges. Additionally, traditional\nmethods like STL for complex seasonality-trend decomposition require\npre-specified seasonal periods and typically handle only single, fixed\nseasonality. We propose the Hybrid Decomposition Dual-Stream Adaptive\nTransformer (DSAT-HD), which integrates three key innovations to address the\nlimitations of existing methods: 1) A hybrid decomposition mechanism combining\nEMA and Fourier decomposition with RevIN normalization, dynamically balancing\nseasonal and trend components through noise Top-k gating; 2) A multi-scale\nadaptive pathway leveraging a sparse allocator to route features to four\nparallel Transformer layers, followed by feature merging via a sparse combiner,\nenhanced by hybrid attention combining local CNNs and global interactions; 3) A\ndual-stream residual learning framework where CNN and MLP branches separately\nprocess seasonal and trend components, coordinated by a balanced loss function\nminimizing expert collaboration variance. Extensive experiments on nine\ndatasets demonstrate that DSAT-HD outperforms existing methods overall and\nachieves state-of-the-art performance on some datasets. Notably, it also\nexhibits stronger generalization capabilities across various transfer\nscenarios.", "published": "2025-09-29 13:50:56", "link": "http://arxiv.org/abs/2509.24800v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation", "abstract": "We present Causal-Adapter, a modular framework that adapts frozen\ntext-to-image diffusion backbones for counterfactual image generation. Our\nmethod enables causal interventions on target attributes, consistently\npropagating their effects to causal dependents without altering the core\nidentity of the image. In contrast to prior approaches that rely on prompt\nengineering without explicit causal structure, Causal-Adapter leverages\nstructural causal modeling augmented with two attribute regularization\nstrategies: prompt-aligned injection, which aligns causal attributes with\ntextual embeddings for precise semantic control, and a conditioned token\ncontrastive loss to disentangle attribute factors and reduce spurious\ncorrelations. Causal-Adapter achieves state-of-the-art performance on both\nsynthetic and real-world datasets, with up to 91\\% MAE reduction on Pendulum\nfor accurate attribute control and 87\\% FID reduction on ADNI for high-fidelity\nMRI image generation. These results show that our approach enables robust,\ngeneralizable counterfactual editing with faithful attribute modification and\nstrong identity preservation.", "published": "2025-09-29 13:49:28", "link": "http://arxiv.org/abs/2509.24798v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fidelity-Aware Data Composition for Robust Robot Generalization", "abstract": "Generalist robot policies trained on large-scale, visually homogeneous\ndatasets can be susceptible to shortcut learning, which impairs their\nout-of-distribution (OOD) generalization. While generative data augmentation is\na common approach to introduce diversity, it presents a subtle challenge: data\ncomposition. Naively mixing real and synthetic data can corrupt the learning\nsignal, as this process often prioritizes visual diversity at the expense of\ninformation fidelity. This paper suggests that robust generalization depends on\nprincipled, fidelity-aware data composition. We introduce Coherent Information\nFidelity Tuning (CIFT), a framework that treats data composition as an\noptimization problem. CIFT uses a practical proxy for Information Fidelity\nbased on the feature-space geometry of a dataset. This enables the\nidentification of a phase transition, termed the Decoherence Point, where\ntraining stability degrades. The framework includes a generative engine,\nMulti-View Video Augmentation (MVAug), to synthesize a causally disentangled\ndata spectrum for this tuning process. Applying CIFT to policy architectures\nsuch as $\\pi_0$ and Diffusion Policy improves OOD success rates by over 54\\%.\nThese results indicate that fidelity-aware composition, beyond data synthesis\nalone, is an important component for developing robust, general-purpose robots.", "published": "2025-09-29 13:48:36", "link": "http://arxiv.org/abs/2509.24797v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Sparse Autoencoders Make Audio Foundation Models more Explainable", "abstract": "Audio pretrained models are widely employed to solve various tasks in speech\nprocessing, sound event detection, or music information retrieval. However, the\nrepresentations learned by these models are unclear, and their analysis mainly\nrestricts to linear probing of the hidden representations. In this work, we\nexplore the use of Sparse Autoencoders (SAEs) to analyze the hidden\nrepresentations of pretrained models, focusing on a case study in singing\ntechnique classification. We first demonstrate that SAEs retain both\ninformation about the original representations and class labels, enabling their\ninternal structure to provide insights into self-supervised learning systems.\nFurthermore, we show that SAEs enhance the disentanglement of vocal attributes,\nestablishing them as an effective tool for identifying the underlying factors\nencoded in the representations.", "published": "2025-09-29 13:46:48", "link": "http://arxiv.org/abs/2509.24793v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantifying Generalisation in Imitation Learning", "abstract": "Imitation learning benchmarks often lack sufficient variation between\ntraining and evaluation, limiting meaningful generalisation assessment. We\nintroduce Labyrinth, a benchmarking environment designed to test generalisation\nwith precise control over structure, start and goal positions, and task\ncomplexity. It enables verifiably distinct training, evaluation, and test\nsettings. Labyrinth provides a discrete, fully observable state space and known\noptimal actions, supporting interpretability and fine-grained evaluation. Its\nflexible setup allows targeted testing of generalisation factors and includes\nvariants like partial observability, key-and-door tasks, and ice-floor hazards.\nBy enabling controlled, reproducible experiments, Labyrinth advances the\nevaluation of generalisation in imitation learning and provides a valuable tool\nfor developing more robust agents.", "published": "2025-09-29 13:43:25", "link": "http://arxiv.org/abs/2509.24784v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "VTPerception-R1: Enhancing Multimodal Reasoning via Explicit Visual and Textual Perceptual Grounding", "abstract": "Multimodal large language models (MLLMs) often struggle to ground reasoning\nin perceptual evidence. We present a systematic study of perception\nstrategies-explicit, implicit, visual, and textual-across four multimodal\nbenchmarks and two MLLMs. Our findings show that explicit perception,\nespecially when paired with textual cues, consistently yields the best\nimprovements, particularly for smaller models. Based on this insight, we\npropose VTPerception-R1, a unified two-stage framework that decouples\nperception from reasoning. Stage 1 introduces perception-augmented fine-tuning,\nand Stage 2 applies perception-aware reinforcement learning with novel visual,\ntextual, and consistency rewards. Experiments demonstrate that VTPerception-R1\nsignificantly improves reasoning accuracy and robustness across diverse tasks,\noffering a scalable and auditable solution for perception-grounded multimodal\nreasoning. Our code is available at:\nhttps://github.com/yizhuoDi/VTPerceprion-R1.", "published": "2025-09-29 13:40:34", "link": "http://arxiv.org/abs/2509.24776v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Ambiguity to Verdict: A Semiotic-Grounded Multi-Perspective Agent for LLM Logical Reasoning", "abstract": "Logical reasoning is a fundamental capability of large language models\n(LLMs). However, existing studies largely overlook the interplay between\nlogical complexity and semantic complexity, resulting in methods that struggle\nto address challenging scenarios involving abstract propositions, ambiguous\ncontexts, and conflicting stances, which are central to human reasoning. For\nthis gap, we propose LogicAgent, a semiotic-square-guided framework designed to\njointly address logical complexity and semantic complexity. LogicAgent\nexplicitly performs multi-perspective deduction in first-order logic (FOL),\nwhile mitigating vacuous reasoning through existential import checks that\nincorporate a three-valued decision scheme (True, False, Uncertain) to handle\nboundary cases more faithfully. Furthermore, to overcome the semantic\nsimplicity and low logical complexity of existing datasets, we introduce\nRepublicQA, a benchmark that reaches college-level difficulty (FKGL = 11.94)\nand exhibits substantially greater lexical and structural diversity than prior\nbenchmarks. RepublicQA is grounded in philosophical concepts, featuring\nabstract propositions and systematically organized contrary and contradictory\nrelations, making it the most semantically rich resource for evaluating logical\nreasoning. Experiments demonstrate that LogicAgent achieves state-of-the-art\nperformance on RepublicQA, with a 6.25% average gain over strong baselines, and\ngeneralizes effectively to mainstream logical reasoning benchmarks including\nProntoQA, ProofWriter, FOLIO, and ProverQA, achieving an additional 7.05%\naverage gain. These results highlight the strong effectiveness of our\nsemiotic-grounded multi-perspective reasoning in boosting LLMs' logical\nperformance.", "published": "2025-09-29 13:31:22", "link": "http://arxiv.org/abs/2509.24765v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Spatial-Functional awareness Transformer-based graph archetype contrastive learning for Decoding Visual Neural Representations from EEG", "abstract": "Decoding visual neural representations from Electroencephalography (EEG)\nsignals remains a formidable challenge due to their high-dimensional, noisy,\nand non-Euclidean nature. In this work, we propose a Spatial-Functional\nAwareness Transformer-based Graph Archetype Contrastive Learning (SFTG)\nframework to enhance EEG-based visual decoding. Specifically, we introduce the\nEEG Graph Transformer (EGT), a novel graph-based neural architecture that\nsimultaneously encodes spatial brain connectivity and temporal neural dynamics.\nTo mitigate high intra-subject variability, we propose Graph Archetype\nContrastive Learning (GAC), which learns subject-specific EEG graph archetypes\nto improve feature consistency and class separability. Furthermore, we conduct\ncomprehensive subject-dependent and subject-independent evaluations on the\nThings-EEG dataset, demonstrating that our approach significantly outperforms\nprior state-of-the-art EEG decoding methods.The results underscore the\ntransformative potential of integrating graph-based learning with contrastive\nobjectives to enhance EEG-based brain decoding, paving the way for more\ngeneralizable and robust neural representations.", "published": "2025-09-29 13:27:55", "link": "http://arxiv.org/abs/2509.24761v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Surjective Independence of Causal Influences for Local Bayesian Network Structures", "abstract": "The very expressiveness of Bayesian networks can introduce fresh challenges\ndue to the large number of relationships they often model. In many domains, it\nis thus often essential to supplement any available data with elicited expert\njudgements. This in turn leads to two key challenges: the cognitive burden of\nthese judgements is often very high, and there are a very large number of\njudgements required to obtain a full probability model. We can mitigate both\nissues by introducing assumptions such as independence of causal influences\n(ICI) on the local structures throughout the network, restricting the parameter\nspace of the model. However, the assumption of ICI is often unjustified and\noverly strong. In this paper, we introduce the surjective independence of\ncausal influences (SICI) model which relaxes the ICI assumption and provides a\nmore viable, practical alternative local structure model that facilitates\nefficient Bayesian network parameterisation.", "published": "2025-09-29 13:23:11", "link": "http://arxiv.org/abs/2509.24759v1", "categories": ["stat.ME", "cs.AI", "62H22, 62C99, 68T30, 68T37"], "primary_category": "stat.ME"}
{"title": "Robust Policy Expansion for Offline-to-Online RL under Diverse Data Corruption", "abstract": "Pretraining a policy on offline data followed by fine-tuning through online\ninteractions, known as Offline-to-Online Reinforcement Learning (O2O RL), has\nemerged as a promising paradigm for real-world RL deployment. However, both\noffline datasets and online interactions in practical environments are often\nnoisy or even maliciously corrupted, severely degrading the performance of O2O\nRL. Existing works primarily focus on mitigating the conservatism of offline\npolicies via online exploration, while the robustness of O2O RL under data\ncorruption, including states, actions, rewards, and dynamics, is still\nunexplored. In this work, we observe that data corruption induces heavy-tailed\nbehavior in the policy, thereby substantially degrading the efficiency of\nonline exploration. To address this issue, we incorporate Inverse Probability\nWeighted (IPW) into the online exploration policy to alleviate\nheavy-tailedness, and propose a novel, simple yet effective method termed\n$\\textbf{RPEX}$: $\\textbf{R}$obust $\\textbf{P}$olicy $\\textbf{EX}$pansion.\nExtensive experimental results on D4RL datasets demonstrate that RPEX achieves\nSOTA O2O performance across a wide range of data corruption scenarios. Code is\navailable at\n$\\href{https://github.com/felix-thu/RPEX}{https://github.com/felix-thu/RPEX}$.", "published": "2025-09-29 13:15:42", "link": "http://arxiv.org/abs/2509.24748v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity", "abstract": "Multimodal learning plays a pivotal role in advancing artificial intelligence\nsystems by incorporating information from multiple modalities to build a more\ncomprehensive representation. Despite its importance, current state-of-the-art\nmodels still suffer from severe limitations that prevent the successful\ndevelopment of a fully multimodal model. Such methods may not provide\nindicators that all the involved modalities are effectively aligned. As a\nresult, some modalities may not be aligned, undermining the effectiveness of\nthe model in downstream tasks where multiple modalities should provide\nadditional information that the model fails to exploit. In this paper, we\npresent TRIANGLE: TRI-modAl Neural Geometric LEarning, the novel proposed\nsimilarity measure that is directly computed in the higher-dimensional space\nspanned by the modality embeddings. TRIANGLE improves the joint alignment of\nthree modalities via a triangle-area similarity, avoiding additional fusion\nlayers or pairwise similarities. When incorporated in contrastive losses\nreplacing cosine similarity, TRIANGLE significantly boosts the performance of\nmultimodal modeling, while yielding interpretable alignment rationales.\nExtensive evaluation in three-modal tasks such as video-text and audio-text\nretrieval or audio-video classification, demonstrates that TRIANGLE achieves\nstate-of-the-art results across different datasets improving the performance of\ncosine-based methods up to 9 points of Recall@1.", "published": "2025-09-29 12:58:46", "link": "http://arxiv.org/abs/2509.24734v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Q-Net: Transferable Queue Length Estimation via Kalman-based Neural Networks", "abstract": "Estimating queue lengths at signalized intersections remains a challenge in\ntraffic management, especially under partially observed conditions where\nvehicle flows are not fully captured. This paper introduces Q-Net, a\ndata-efficient and interpretable framework for queue length estimation that\nperforms robustly even when traffic conservation assumptions are violated.\nQ-Net integrates two widely available and privacy-friendly data sources: (i)\nvehicle counts from loop detectors near stop lines, and (ii) aggregated\nfloating car data (aFCD), which divides each road section into segments and\nprovides segment-wise average speed measurements. These data sources often\ndiffer in spatial and temporal resolution, creating fusion challenges. Q-Net\naddresses this by employing a tailored state-space model and an AI-augmented\nKalman filter, KalmanNet, which learns the Kalman gain from data without\nrequiring prior knowledge of noise covariances or full system dynamics. We\nbuild on the vanilla KalmanNet pipeline to decouple measurement dimensionality\nfrom section length, enabling spatial transferability across road segments.\nUnlike black-box models, Q-Net maintains physical interpretability, with\ninternal variables linked to real-world traffic dynamics. Evaluations on main\nroads in Rotterdam, the Netherlands, demonstrate that Q-Net outperforms\nbaseline methods by over 60\\% in Root Mean Square Error (RMSE), accurately\ntracking queue formation and dissipation while correcting aFCD-induced delays.\nQ-Net also demonstrates strong spatial and temporal transferability, enabling\ndeployment without costly sensing infrastructure like cameras or radar.\nAdditionally, we propose a real-time variant of Q-Net, highlighting its\npotential for integration into dynamic, queue-based traffic control systems.", "published": "2025-09-29 12:51:08", "link": "http://arxiv.org/abs/2509.24725v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Discrete Variational Autoencoding via Policy Search", "abstract": "Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit\nefficiency and can be modeled with autoregressive discrete distributions,\nenabling parameter-efficient multimodal search with transformers. However,\ndiscrete random variables do not allow for exact differentiable\nparameterization; therefore, discrete VAEs typically rely on approximations,\nsuch as Gumbel-Softmax reparameterization or straight-through gradient\nestimates, or employ high-variance gradient-free methods such as REINFORCE that\nhave had limited success on high-dimensional tasks such as image\nreconstruction. Inspired by popular techniques in policy search, we propose a\ntraining framework for discrete VAEs that leverages the natural gradient of a\nnon-parametric encoder to update the parametric encoder without requiring\nreparameterization. Our method, combined with automatic step size adaptation\nand a transformer-based encoder, scales to challenging datasets such as\nImageNet and outperforms both approximate reparameterization methods and\nquantization-based discrete autoencoders in reconstructing high-dimensional\ndata from compact latent spaces, achieving a 20% improvement on FID Score for\nImageNet 256.", "published": "2025-09-29 12:44:05", "link": "http://arxiv.org/abs/2509.24716v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Circuit-Aware Reward Training: A Mechanistic Framework for Longtail Robustness in RLHF", "abstract": "Reinforcement Learning from Human Feedback (RLHF) reward models exhibit\nsystematic failures on longtail distributions, leading to reward hacking and\nmisalignment. We propose a mechanistic interpretability framework that\nidentifies specialized neural circuits responsible for rare-event processing in\nreward models. Drawing from recent advances showing distributed specialization\nfor rare tokens in language models\\citep{liu2025no, liu2025emergent}, we\nhypothesize that reward models also develop functionally distinct circuits for\nlongtail scenarios. Our theoretical framework establishes formal connections\nbetween circuit specialization, reward generalization bounds, and longtail\nperformance. We introduce \\textbf{Circuit-Aware Reward Training (CART)}, which\nuses circuit analysis to guide data augmentation, regularization, and ensemble\nstrategies. This approach provides both theoretical insights into reward model\nfailures and practical interventions for improving longtail robustness.", "published": "2025-09-29 12:42:14", "link": "http://arxiv.org/abs/2509.24713v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedPOB: Sample-Efficient Federated Prompt Optimization via Bandits", "abstract": "The performance of large language models (LLMs) is highly sensitive to the\ninput prompt, making prompt optimization a critical task. However, real-world\napplication is hindered by three major challenges: (1) the black-box nature of\npowerful proprietary LLMs, (2) the need for high sample efficiency due to query\ncosts, and (3) the desire for privacy-preserving collaboration among multiple\nusers. To address these challenges simultaneously, we introduce a novel\nframework for sample-efficient federated prompt optimization based on\nmulti-armed bandits (MABs). The MAB framework is uniquely suited for this\nproblem as it is (1) inherently a black-box optimization method, (2)\npractically sample-efficient, and (3) enables collaborative learning with\ntheoretically guaranteed benefit from more participating agents. We first\npropose the Federated Prompt Optimization via Bandits (FedPOB) algorithm, a\nfederated variant of the Linear UCB algorithm, where agents collaborate by\nsharing model parameters instead of raw data. We then extend our approach to\nthe practical setting of comparative user feedback by introducing FedPOB with\nPreference Feedback (FedPOB-Pref), an efficient algorithm based on federated\ndueling bandits. Extensive experiments demonstrate that both FedPOB and\nFedPOB-Pref significantly outperform existing baselines and that their\nperformance consistently improves as more agents participate in the\ncollaboration, validating the effectiveness of our federated approach.", "published": "2025-09-29 12:32:21", "link": "http://arxiv.org/abs/2509.24701v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "T-POP: Test-Time Personalization with Online Preference Feedback", "abstract": "Personalizing large language models (LLMs) to individual user preferences is\na critical step beyond generating generically helpful responses. However,\ncurrent personalization methods are ill-suited for new users, as they typically\nrequire either slow, resource-intensive fine-tuning or a substantial amount of\npre-existing user data, creating a significant cold-start problem. To address\nthis challenge, we introduce a new paradigm for real-time personalization by\nlearning from online pairwise preference feedback collected during text\ngeneration. We propose T-POP (Test-Time Personalization with Online Preference\nFeedback}), a novel algorithm that synergistically combines test-time alignment\nwith dueling bandits. Without updating the LLM parameters, T-POP steers the\ndecoding process of a frozen LLM by learning a reward function online that\ncaptures user preferences. By leveraging dueling bandits, T-POP intelligently\nqueries the user to efficiently balance between exploring their preferences and\nexploiting the learned knowledge to generate personalized text. Extensive\nexperiments demonstrate that T-POP achieves rapid and data-efficient\npersonalization, significantly outperforming existing baselines and showing\nconsistent improvement with more user interactions.", "published": "2025-09-29 12:28:23", "link": "http://arxiv.org/abs/2509.24696v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer", "abstract": "We introduce SANA-Video, a small diffusion model that can efficiently\ngenerate videos up to 720x1280 resolution and minute-length duration.\nSANA-Video synthesizes high-resolution, high-quality and long videos with\nstrong text-video alignment at a remarkably fast speed, deployable on RTX 5090\nGPU. Two core designs ensure our efficient, effective and long video\ngeneration: (1) Linear DiT: We leverage linear attention as the core operation,\nwhich is more efficient than vanilla attention given the large number of tokens\nprocessed in video generation. (2) Constant-Memory KV cache for Block Linear\nAttention: we design block-wise autoregressive approach for long video\ngeneration by employing a constant-memory state, derived from the cumulative\nproperties of linear attention. This KV cache provides the Linear DiT with\nglobal context at a fixed memory cost, eliminating the need for a traditional\nKV cache and enabling efficient, minute-long video generation. In addition, we\nexplore effective data filters and model training strategies, narrowing the\ntraining cost to 12 days on 64 H100 GPUs, which is only 1% of the cost of\nMovieGen. Given its low cost, SANA-Video achieves competitive performance\ncompared to modern state-of-the-art small diffusion models (e.g., Wan 2.1-1.3B\nand SkyReel-V2-1.3B) while being 16x faster in measured latency. Moreover,\nSANA-Video can be deployed on RTX 5090 GPUs with NVFP4 precision, accelerating\nthe inference speed of generating a 5-second 720p video from 71s to 29s (2.4x\nspeedup). In summary, SANA-Video enables low-cost, high-quality video\ngeneration.", "published": "2025-09-29 12:28:09", "link": "http://arxiv.org/abs/2509.24695v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CoTune: Co-evolutionary Configuration Tuning", "abstract": "To automatically tune configurations for the best possible system performance\n(e.g., runtime or throughput), much work has been focused on designing\nintelligent heuristics in a tuner. However, existing tuner designs have mostly\nignored the presence of complex performance requirements (e.g., the latency\nshall ideally be 2 seconds), but simply assume that better performance is\nalways more preferred. This would not only waste valuable information in a\nrequirement but might also consume extensive resources to tune for a goal with\nlittle gain. Yet, prior studies have shown that simply incorporating the\nrequirement as a tuning objective is problematic since the requirement might be\ntoo strict, harming convergence; or its highly diverse satisfactions might lead\nto premature convergence. In this paper, we propose CoTune, a tool that takes\nthe information of a given target performance requirement into account through\nco-evolution. CoTune is unique in the sense that it creates an auxiliary\nperformance requirement to be co-evolved with the configurations, which assists\nthe target performance requirement when it becomes ineffective or even\nmisleading, hence allowing the tuning to be guided by the requirement while\nbeing robust to its harm. Experiment results on 162 cases (nine systems and 18\nrequirements) reveal that CoTune considerably outperforms existing tuners,\nranking as the best for 90% cases (against the 0%--35% for other tuners) with\nup to 2.9x overall improvements, while doing so under a much better efficiency.", "published": "2025-09-29 12:27:47", "link": "http://arxiv.org/abs/2509.24694v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Data-Driven Discrete Geofence Design Using Binary Quadratic Programming", "abstract": "Geofences have attracted significant attention in the design of spatial and\nvirtual regions for managing and engaging spatiotemporal events. By using\ngeofences to monitor human activity across their boundaries, content providers\ncan create spatially triggered events that include notifications about points\nof interest within a geofence by pushing spatial information to the devices of\nusers. Traditionally, geofences were hand-crafted by providers. In addition to\nthe hand-crafted approach, recent advances in collecting human mobility data\nthrough mobile devices can accelerate the automatic and data-driven design of\ngeofences, also known as the geofence design problem. Previous approaches\nassume circular shapes; thus, their flexibility is insufficient, and they can\nonly handle geofence-based applications for large areas with coarse\nresolutions. A challenge with using circular geofences in urban and\nhigh-resolution areas is that they often overlap and fail to align with\npolitical district boundaries and road segments, such as one-way streets and\nmedian barriers. In this study, we address the problem of extracting arbitrary\nshapes as geofences from human mobility data to mitigate this problem. In our\nformulation, we cast the existing optimization problems for circular geofences\nto 0-1 integer programming problems to represent arbitrary shapes. Although 0-1\ninteger programming problems are computationally hard, formulating them as\nquadratic (unconstrained) binary optimization problems enables efficient\napproximation of optimal solutions, because this allows the use of specialized\nquadratic solvers, such as the quantum annealing, and other state-of-the-art\nalgorithms. We then develop and compare different formulation methods to\nextract discrete geofences. We confirmed that our new modeling approach enables\nflexible geofence design.", "published": "2025-09-29 12:15:59", "link": "http://arxiv.org/abs/2509.24679v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Community detection robustness of graph neural networks", "abstract": "Graph neural networks (GNNs) are increasingly widely used for community\ndetection in attributed networks. They combine structural topology with node\nattributes through message passing and pooling. However, their robustness or\nlack of thereof with respect to different perturbations and targeted attacks in\nconjunction with community detection tasks is not well understood. To shed\nlight into latent mechanisms behind GNN sensitivity on community detection\ntasks, we conduct a systematic computational evaluation of six widely adopted\nGNN architectures: GCN, GAT, Graph-SAGE, DiffPool, MinCUT, and DMoN. The\nanalysis covers three perturbation categories: node attribute manipulations,\nedge topology distortions, and adversarial attacks. We use element-centric\nsimilarity as the evaluation metric on synthetic benchmarks and real-world\ncitation networks. Our findings indicate that supervised GNNs tend to achieve\nhigher baseline accuracy, while unsupervised methods, particularly DMoN,\nmaintain stronger resilience under targeted and adversarial perturbations.\nFurthermore, robustness appears to be strongly influenced by community\nstrength, with well-defined communities reducing performance loss. Across all\nmodels, node attribute perturbations associated with targeted edge deletions\nand shift in attribute distributions tend to cause the largest degradation in\ncommunity recovery. These findings highlight important trade-offs between\naccuracy and robustness in GNN-based community detection and offer new insights\ninto selecting architectures resilient to noise and adversarial attacks.", "published": "2025-09-29 12:08:22", "link": "http://arxiv.org/abs/2509.24662v1", "categories": ["cs.SI", "cs.AI", "physics.soc-ph", "stat.ML"], "primary_category": "cs.SI"}
{"title": "Successful Misunderstandings: Learning to Coordinate Without Being Understood", "abstract": "The main approach to evaluating communication is by assessing how well it\nfacilitates coordination. If two or more individuals can coordinate through\ncommunication, it is generally assumed that they understand one another. We\ninvestigate this assumption in a signaling game where individuals develop a new\nvocabulary of signals to coordinate successfully. In our game, the individuals\ndo not have common observations besides the communication signal and outcome of\nthe interaction, i.e. received reward. This setting is used as a proxy to study\ncommunication emergence in populations of agents that perceive their\nenvironment very differently, e.g. hybrid populations that include humans and\nartificial agents. Agents develop signals, use them, and refine interpretations\nwhile not observing how other agents are using them. While populations always\nconverge to optimal levels of coordination, in some cases, interacting agents\ninterpret and use signals differently, converging to what we call successful\nmisunderstandings. However, agents of population that coordinate using\nmisaligned interpretations, are unable to establish successful coordination\nwith new interaction partners. Not leading to coordination failure immediately,\nsuccessful misunderstandings are difficult to spot and repair. Having at least\nthree agents that all interact with each other are the two minimum conditions\nto ensure the emergence of shared interpretations. Under these conditions, the\nagent population exhibits this emergent property of compensating for the lack\nof shared observations of signal use, ensuring the emergence of shared\ninterpretations.", "published": "2025-09-29 12:08:00", "link": "http://arxiv.org/abs/2509.24660v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "VNODE: A Piecewise Continuous Volterra Neural Network", "abstract": "This paper introduces Volterra Neural Ordinary Differential Equations\n(VNODE), a piecewise continuous Volterra Neural Network that integrates\nnonlinear Volterra filtering with continuous time neural ordinary differential\nequations for image classification. Drawing inspiration from the visual cortex,\nwhere discrete event processing is interleaved with continuous integration,\nVNODE alternates between discrete Volterra feature extraction and ODE driven\nstate evolution. This hybrid formulation captures complex patterns while\nrequiring substantially fewer parameters than conventional deep architectures.\nVNODE consistently outperforms state of the art models with improved\ncomputational complexity as exemplified on benchmark datasets like CIFAR10 and\nImagenet1K.", "published": "2025-09-29 12:05:57", "link": "http://arxiv.org/abs/2509.24659v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Identity Bridge: Enabling Implicit Reasoning via Shared Latent Memory", "abstract": "Despite remarkable advances, large language models often fail at\ncompositional reasoning tasks, a phenomenon exemplified by the ``curse of\ntwo-hop reasoning''. This paper introduces the Identity Bridge, a simple yet\npowerful mechanism that resolves this compositionality gap by supervising the\nmodel on a zero-hop identity task. We demonstrate empirically that this\naddition enables models to successfully perform out-of-distribution two-hop\nreasoning, a task they otherwise completely fail. To explain this phenomenon,\nwe provide a theoretical analysis using a simplified Emb-MLP model, proving\nthat identity supervision reshapes the model's latent geometry. We show this\nalignment is induced by an implicit nuclear-norm regularization during\noptimization, which favors low-rank solutions that share structure across\ntasks. For complex tasks, we use small initialization or weight decay to\nenhance the regularization effect, which enhances the latent space alignment\neffect and slows down the generalization decay. Finally, we extend our\ninvestigation to large-scale models, observing that they still achieve two-hop\nreasoning through the latent memory, which provides crucial inspiration for\nenhancing their implicit reasoning abilities.", "published": "2025-09-29 12:02:05", "link": "http://arxiv.org/abs/2509.24653v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "\"Stop replacing salt with sugar!'': Towards Intuitive Human-Agent Teaching", "abstract": "Humans quickly learn new concepts from a small number of examples.\nReplicating this capacity with Artificial Intelligence (AI) systems has proven\nto be challenging. When it comes to learning subjective tasks-where there is an\nevident scarcity of data-this capacity needs to be recreated. In this work, we\npropose an intuitive human-agent teaching architecture in which the human can\nteach an agent how to perform a task by providing demonstrations, i.e.,\nexamples. To have an intuitive interaction, we argue that the agent should be\nable to learn incrementally from a few single examples. To allow for this, our\nobjective is to broaden the agent's task understanding using domain knowledge.\nThen, using a learning method to enable the agent to learn efficiently from a\nlimited number of examples. Finally, to optimize how human can select the most\nrepresentative and less redundant examples to provide the agent with. We apply\nour proposed method to the subjective task of ingredient substitution, where\nthe agent needs to learn how to substitute ingredients in recipes based on\nhuman examples. We replicate human input using the Recipe1MSubs dataset. In our\nexperiments, the agent achieves half its task performance after only 100\nexamples are provided, compared to the complete training set of 50k examples.\nWe show that by providing examples in strategic order along with a learning\nmethod that leverages external symbolic knowledge, the agent can generalize\nmore efficiently.", "published": "2025-09-29 12:00:53", "link": "http://arxiv.org/abs/2509.24651v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs", "abstract": "In this work, we introduce SPLICE, a human-curated benchmark derived from the\nCOIN instructional video dataset, designed to probe event-based reasoning\nacross multiple dimensions: temporal, causal, spatial, contextual, and general\nknowledge. SPLICE includes 3,381 human-filtered videos spanning 12 categories\nand 180 sub-categories, such as sports, engineering, and housework. These\nvideos are segmented into a total of 11,423 event clips. We evaluate both human\nparticipants and state-of-the-art vision-language models (VLMs) on the task of\nrearranging these clips into coherent event sequences to assess visual\nreasoning capabilities. Results reveal a significant gap: VLMs struggle to\nmatch human performance. While human-annotated textual descriptions improve\nmodel accuracy, they do not affect human performance, suggesting that models\nrely more on language priors than on visual understanding. Even with\nannotations, VLMs fall short of human-level reasoning, underscoring persistent\nchallenges in visual reasoning. A deeper analysis across sub-categories shows\nthat VLMs perform relatively better on videos where temporal and causal\nreasoning are dominant, compared to those where contextual and spatial\nreasoning are dominant. They also perform better on everyday tasks than on\nspecialized ones.", "published": "2025-09-29 11:50:18", "link": "http://arxiv.org/abs/2509.24640v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LTL$_f$ Learning Meets Boolean Set Cover", "abstract": "Learning formulas in Linear Temporal Logic (LTLf) from finite traces is a\nfundamental research problem which has found applications in artificial\nintelligence, software engineering, programming languages, formal methods,\ncontrol of cyber-physical systems, and robotics. We implement a new CPU tool\ncalled Bolt improving over the state of the art by learning formulas more than\n100x faster over 70% of the benchmarks, with smaller or equal formulas in 98%\nof the cases. Our key insight is to leverage a problem called Boolean Set Cover\nas a subroutine to combine existing formulas using Boolean connectives. Thanks\nto the Boolean Set Cover component, our approach offers a novel trade-off\nbetween efficiency and formula size.", "published": "2025-09-29 11:20:20", "link": "http://arxiv.org/abs/2509.24616v1", "categories": ["cs.AI", "cs.FL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Algorithms and data structures for automatic precision estimation of neural networks", "abstract": "We describe algorithms and data structures to extend a neural network library\nwith automatic precision estimation for floating point computations. We also\ndiscuss conditions to make estimations exact and preserve high computation\nperformance of neural networks training and inference. Numerical experiments\nshow the consequences of significant precision loss for particular values such\nas inference, gradients and deviations from mathematically predicted behavior.\n  It turns out that almost any neural network accumulates computational\ninaccuracies. As a result, its behavior does not coincide with predicted by the\nmathematical model of neural network. This shows that tracking of computational\ninaccuracies is important for reliability of inference, training and\ninterpretability of results.", "published": "2025-09-29 11:13:29", "link": "http://arxiv.org/abs/2509.24607v1", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.DS"}
{"title": "BPMN Assistant: An LLM-Based Approach to Business Process Modeling", "abstract": "This paper presents BPMN Assistant, a tool that leverages Large Language\nModels (LLMs) for natural language-based creation and editing of BPMN diagrams.\nA specialized JSON-based representation is introduced as a structured\nalternative to the direct handling of XML to enhance the accuracy of process\nmodifications. Process generation quality is evaluated using Graph Edit\nDistance (GED) and Relative Graph Edit Distance (RGED), while editing\nperformance is evaluated with a binary success metric. Results show that JSON\nand XML achieve similar similarity scores in generation, but JSON offers\ngreater reliability, faster processing, and significantly higher editing\nsuccess rates. We discuss key trade-offs, limitations, and future improvements.\nThe implementation is available at https://github.com/jtlicardo/bpmn-assistant.", "published": "2025-09-29 10:56:08", "link": "http://arxiv.org/abs/2509.24592v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control", "abstract": "We present PoseDiff, a conditional diffusion model that unifies robot state\nestimation and control within a single framework. At its core, PoseDiff maps\nraw visual observations into structured robot states-such as 3D keypoints or\njoint angles-from a single RGB image, eliminating the need for multi-stage\npipelines or auxiliary modalities. Building upon this foundation, PoseDiff\nextends naturally to video-to-action inverse dynamics: by conditioning on\nsparse video keyframes generated by world models, it produces smooth and\ncontinuous long-horizon action sequences through an overlap-averaging strategy.\nThis unified design enables scalable and efficient integration of perception\nand control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy\nand real-time performance for pose estimation. On Libero-Object manipulation\ntasks, it substantially improves success rates over existing inverse dynamics\nmodules, even under strict offline settings. Together, these results show that\nPoseDiff provides a scalable, accurate, and efficient bridge between\nperception, planning, and control in embodied AI. The video visualization\nresults can be found on the project page:\nhttps://haozhuo-zhang.github.io/PoseDiff-project-page/.", "published": "2025-09-29 10:55:48", "link": "http://arxiv.org/abs/2509.24591v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Bandits roaming Hilbert space", "abstract": "This thesis studies the exploration and exploitation trade-off in online\nlearning of properties of quantum states using multi-armed bandits. Given\nstreaming access to an unknown quantum state, in each round we select an\nobservable from a set of actions to maximize its expectation value. Using past\ninformation, we refine actions to minimize regret; the cumulative gap between\ncurrent reward and the maximum possible. We derive information-theoretic lower\nbounds and optimal strategies with matching upper bounds, showing regret\ntypically scales as the square root of rounds. As an application, we reframe\nquantum state tomography to both learn the state efficiently and minimize\nmeasurement disturbance. For pure states and continuous actions, we achieve\npolylogarithmic regret using a sample-optimal algorithm based on a weighted\nonline least squares estimator. The algorithm relies on the optimistic\nprinciple and controls the eigenvalues of the design matrix. We also apply our\nframework to quantum recommender systems and thermodynamic work extraction from\nunknown states. In this last setting, our results demonstrate an exponential\nadvantage in work dissipation over tomography-based protocols.", "published": "2025-09-29 10:26:29", "link": "http://arxiv.org/abs/2509.24569v1", "categories": ["quant-ph", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "quant-ph"}
{"title": "LayerD: Decomposing Raster Graphic Designs into Layers", "abstract": "Designers craft and edit graphic designs in a layer representation, but\nlayer-based editing becomes impossible once composited into a raster image. In\nthis work, we propose LayerD, a method to decompose raster graphic designs into\nlayers for re-editable creative workflow. LayerD addresses the decomposition\ntask by iteratively extracting unoccluded foreground layers. We propose a\nsimple yet effective refinement approach taking advantage of the assumption\nthat layers often exhibit uniform appearance in graphic designs. As\ndecomposition is ill-posed and the ground-truth layer structure may not be\nreliable, we develop a quality metric that addresses the difficulty. In\nexperiments, we show that LayerD successfully achieves high-quality\ndecomposition and outperforms baselines. We also demonstrate the use of LayerD\nwith state-of-the-art image generators and layer-based editing.", "published": "2025-09-29 17:50:12", "link": "http://arxiv.org/abs/2509.25134v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Triangle Splatting+: Differentiable Rendering with Opaque Triangles", "abstract": "Reconstructing 3D scenes and synthesizing novel views has seen rapid progress\nin recent years. Neural Radiance Fields demonstrated that continuous volumetric\nradiance fields can achieve high-quality image synthesis, but their long\ntraining and rendering times limit practicality. 3D Gaussian Splatting (3DGS)\naddressed these issues by representing scenes with millions of Gaussians,\nenabling real-time rendering and fast optimization. However, Gaussian\nprimitives are not natively compatible with the mesh-based pipelines used in VR\nheadsets, and real-time graphics applications. Existing solutions attempt to\nconvert Gaussians into meshes through post-processing or two-stage pipelines,\nwhich increases complexity and degrades visual quality. In this work, we\nintroduce Triangle Splatting+, which directly optimizes triangles, the\nfundamental primitive of computer graphics, within a differentiable splatting\nframework. We formulate triangle parametrization to enable connectivity through\nshared vertices, and we design a training strategy that enforces opaque\ntriangles. The final output is immediately usable in standard graphics engines\nwithout post-processing. Experiments on the Mip-NeRF360 and Tanks & Temples\ndatasets show that Triangle Splatting+achieves state-of-the-art performance in\nmesh-based novel view synthesis. Our method surpasses prior splatting\napproaches in visual fidelity while remaining efficient and fast to training.\nMoreover, the resulting semi-connected meshes support downstream applications\nsuch as physics-based simulation or interactive walkthroughs. The project page\nis https://trianglesplatting2.github.io/trianglesplatting2/.", "published": "2025-09-29 17:43:46", "link": "http://arxiv.org/abs/2509.25122v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unsupervised Representation Learning for 3D Mesh Parameterization with Semantic and Visibility Objectives", "abstract": "Recent 3D generative models produce high-quality textures for 3D mesh\nobjects. However, they commonly rely on the heavy assumption that input 3D\nmeshes are accompanied by manual mesh parameterization (UV mapping), a manual\ntask that requires both technical precision and artistic judgment. Industry\nsurveys show that this process often accounts for a significant share of asset\ncreation, creating a major bottleneck for 3D content creators. Moreover,\nexisting automatic methods often ignore two perceptually important criteria:\n(1) semantic awareness (UV charts should align semantically similar 3D parts\nacross shapes) and (2) visibility awareness (cutting seams should lie in\nregions unlikely to be seen). To overcome these shortcomings and to automate\nthe mesh parameterization process, we present an unsupervised differentiable\nframework that augments standard geometry-preserving UV learning with semantic-\nand visibility-aware objectives. For semantic-awareness, our pipeline (i)\nsegments the mesh into semantic 3D parts, (ii) applies an unsupervised learned\nper-part UV-parameterization backbone, and (iii) aggregates per-part charts\ninto a unified UV atlas. For visibility-awareness, we use ambient occlusion\n(AO) as an exposure proxy and back-propagate a soft differentiable AO-weighted\nseam objective to steer cutting seams toward occluded regions. By conducting\nqualitative and quantitative evaluations against state-of-the-art methods, we\nshow that the proposed method produces UV atlases that better support texture\ngeneration and reduce perceptible seam artifacts compared to recent baselines.\nOur implementation code is publicly available at:\nhttps://github.com/AHHHZ975/Semantic-Visibility-UV-Param.", "published": "2025-09-29 17:28:58", "link": "http://arxiv.org/abs/2509.25094v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification", "abstract": "Adversarial purification with diffusion models has emerged as a promising\ndefense strategy, but existing methods typically rely on uniform noise\ninjection, which indiscriminately perturbs all frequencies, corrupting semantic\nstructures and undermining robustness. Our empirical study reveals that\nadversarial perturbations are not uniformly distributed: they are predominantly\nconcentrated in high-frequency regions, with heterogeneous magnitude intensity\npatterns that vary across frequencies and attack types. Motivated by this\nobservation, we introduce MANI-Pure, a magnitude-adaptive purification\nframework that leverages the magnitude spectrum of inputs to guide the\npurification process. Instead of injecting homogeneous noise, MANI-Pure\nadaptively applies heterogeneous, frequency-targeted noise, effectively\nsuppressing adversarial perturbations in fragile high-frequency, low-magnitude\nbands while preserving semantically critical low-frequency content. Extensive\nexperiments on CIFAR-10 and ImageNet-1K validate the effectiveness of\nMANI-Pure. It narrows the clean accuracy gap to within 0.59 of the original\nclassifier, while boosting robust accuracy by 2.15, and achieves the top-1\nrobust accuracy on the RobustBench leaderboard, surpassing the previous\nstate-of-the-art method.", "published": "2025-09-29 17:22:40", "link": "http://arxiv.org/abs/2509.25082v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction", "abstract": "Cryo-electron microscopy (cryo-EM) has become a central tool for\nhigh-resolution structural biology, yet the massive scale of datasets (often\nexceeding 100k particle images) renders 3D reconstruction both computationally\nexpensive and memory intensive. Traditional Fourier-space methods are efficient\nbut lose fidelity due to repeated transforms, while recent real-space\napproaches based on neural radiance fields (NeRFs) improve accuracy but incur\ncubic memory and computation overhead. Therefore, we introduce GEM, a novel\ncryo-EM reconstruction framework built on 3D Gaussian Splatting (3DGS) that\noperates directly in real-space while maintaining high efficiency. Instead of\nmodeling the entire density volume, GEM represents proteins with compact 3D\nGaussians, each parameterized by only 11 values. To further improve the\ntraining efficiency, we designed a novel gradient computation to 3D Gaussians\nthat contribute to each voxel. This design substantially reduced both memory\nfootprint and training cost. On standard cryo-EM benchmarks, GEM achieves up to\n48% faster training and 12% lower memory usage compared to state-of-the-art\nmethods, while improving local resolution by as much as 38.8%. These results\nestablish GEM as a practical and scalable paradigm for cryo-EM reconstruction,\nunifying speed, efficiency, and high-resolution accuracy. Our code is available\nat https://github.com/UNITES-Lab/GEM.", "published": "2025-09-29 17:17:53", "link": "http://arxiv.org/abs/2509.25075v1", "categories": ["cs.CV", "cs.CE"], "primary_category": "cs.CV"}
{"title": "CharGen: Fast and Fluent Portrait Modification", "abstract": "Interactive editing of character images with diffusion models remains\nchallenging due to the inherent trade-off between fine-grained control,\ngeneration speed, and visual fidelity. We introduce CharGen, a\ncharacter-focused editor that combines attribute-specific Concept Sliders,\ntrained to isolate and manipulate attributes such as facial feature size,\nexpression, and decoration with the StreamDiffusion sampling pipeline for more\ninteractive performance. To counteract the loss of detail that often\naccompanies accelerated sampling, we propose a lightweight Repair Step that\nreinstates fine textures without compromising structural consistency.\nThroughout extensive ablation studies and in comparison to open-source\nInstructPix2Pix and closed-source Google Gemini, and a comprehensive user\nstudy, CharGen achieves two-to-four-fold faster edit turnaround with precise\nediting control and identity-consistent results. Project page:\nhttps://chargen.jdihlmann.com/", "published": "2025-09-29 17:09:30", "link": "http://arxiv.org/abs/2509.25058v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "A Scalable Distributed Framework for Multimodal GigaVoxel Image Registration", "abstract": "In this work, we propose FFDP, a set of IO-aware non-GEMM fused kernels\nsupplemented with a distributed framework for image registration at\nunprecedented scales. Image registration is an inverse problem fundamental to\nbiomedical and life sciences, but algorithms have not scaled in tandem with\nimage acquisition capabilities. Our framework complements existing model\nparallelism techniques proposed for large-scale transformer training by\noptimizing non-GEMM bottlenecks and enabling convolution-aware tensor sharding.\nWe demonstrate unprecedented capabilities by performing multimodal registration\nof a 100 micron ex-vivo human brain MRI volume at native resolution - an\ninverse problem more than 570x larger than a standard clinical datum in about a\nminute using only 8 A6000 GPUs. FFDP accelerates existing state-of-the-art\noptimization and deep learning registration pipelines by upto 6 - 7x while\nreducing peak memory consumption by 20 - 59%. Comparative analysis on a 250\nmicron dataset shows that FFDP can fit upto 64x larger problems than existing\nSOTA on a single GPU, and highlights both the performance and efficiency gains\nof FFDP compared to SOTA image registration methods.", "published": "2025-09-29 16:58:40", "link": "http://arxiv.org/abs/2509.25044v1", "categories": ["cs.CV", "cs.DC"], "primary_category": "cs.CV"}
{"title": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "abstract": "Few-shot learning (FSL) aims to recognize novel concepts from only a few\nlabeled support samples. Recent studies enhance support features by\nincorporating additional semantic information or designing complex semantic\nfusion modules. However, they still suffer from hallucinating semantics that\ncontradict the visual evidence due to the lack of grounding in actual\ninstances, resulting in noisy guidance and costly corrections. To address these\nissues, we propose a novel framework, bridging Vision and Text with LLMs for\nFew-Shot Learning (VT-FSL), which constructs precise cross-modal prompts\nconditioned on Large Language Models (LLMs) and support images, seamlessly\nintegrating them through a geometry-aware alignment. It mainly consists of\nCross-modal Iterative Prompting (CIP) and Cross-modal Geometric Alignment\n(CGA). Specifically, the CIP conditions an LLM on both class names and support\nimages to generate precise class descriptions iteratively in a single\nstructured reasoning pass. These descriptions not only enrich the semantic\nunderstanding of novel classes but also enable the zero-shot synthesis of\nsemantically consistent images. The descriptions and synthetic images act\nrespectively as complementary textual and visual prompts, providing high-level\nclass semantics and low-level intra-class diversity to compensate for limited\nsupport data. Furthermore, the CGA jointly aligns the fused textual, support,\nand synthetic visual representations by minimizing the kernelized volume of the\n3-dimensional parallelotope they span. It captures global and nonlinear\nrelationships among all representations, enabling structured and consistent\nmultimodal integration. The proposed VT-FSL method establishes new\nstate-of-the-art performance across ten diverse benchmarks, including standard,\ncross-domain, and fine-grained few-shot learning scenarios. Code is available\nat https://github.com/peacelwh/VT-FSL.", "published": "2025-09-29 16:52:47", "link": "http://arxiv.org/abs/2509.25033v1", "categories": ["cs.CV", "cs.LG", "I.4.9"], "primary_category": "cs.CV"}
{"title": "STAGE: Stable and Generalizable GRPO for Autoregressive Image Generation", "abstract": "Reinforcement learning has recently been explored to improve text-to-image\ngeneration, yet applying existing GRPO algorithms to autoregressive (AR) image\nmodels remains challenging. The instability of the training process easily\ndisrupts the pretrained model capability during long runs, resulting in\nmarginal gains, degraded image quality, and poor generalization. In this work,\nwe revisit GRPO for AR image generation and identify two key issues:\ncontradictory gradients from unnecessary tokens and unstable policy entropy\ndynamics. To address these, we introduce STAGE, a stable and generalizable\nframework that leverages two targeted solutions: 1) Advantage/KL reweighting.\nSimilarity-aware reweighting to alleviate conflicting updates; and 2) Entropy\nreward. An entropy-based reward corresponding to reference model to stabilize\nlearning. With the help of alleviating conflicts between tokens and an entropy\nreward for stabilizing training, we reduce disruption of the pretrained\ndistribution and mitigate reward hacking, which in turn improves generalization\nand transfer better to other benchmarks. Experiments across multiple benchmarks\nshow that STAGE consistently improves visual quality, stability, and cross-task\ngeneralization compared to baseline GRPO.", "published": "2025-09-29 16:50:21", "link": "http://arxiv.org/abs/2509.25027v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning", "abstract": "Recent advances in reinforcement learning (RL) have delivered strong\nreasoning capabilities in natural image domains, yet their potential for Earth\nObservation (EO) remains largely unexplored. EO tasks introduce unique\nchallenges, spanning referred object detection, image or region captioning,\nchange detection, grounding, and temporal analysis, that demand task aware\nreasoning. We propose a novel post training framework that incorporates task\naware rewards to enable effective adaptation of reasoning based RL models to\ndiverse EO tasks. This training strategy enhances reasoning capabilities for\nremote sensing images, stabilizes optimization, and improves robustness.\nExtensive experiments across multiple EO benchmarks show consistent performance\ngains over state of the art generic and specialized vision language models.\nCode and models will be released publicly at\nhttps://mustansarfiaz.github.io/GeoVLM-R1/ .", "published": "2025-09-29 16:48:54", "link": "http://arxiv.org/abs/2509.25026v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Aware Deep Learning for Wildfire Danger Forecasting", "abstract": "Wildfires are among the most severe natural hazards, posing a significant\nthreat to both humans and natural ecosystems. The growing risk of wildfires\nincreases the demand for forecasting models that are not only accurate but also\nreliable. Deep Learning (DL) has shown promise in predicting wildfire danger;\nhowever, its adoption is hindered by concerns over the reliability of its\npredictions, some of which stem from the lack of uncertainty quantification. To\naddress this challenge, we present an uncertainty-aware DL framework that\njointly captures epistemic (model) and aleatoric (data) uncertainty to enhance\nshort-term wildfire danger forecasting. In the next-day forecasting, our\nbest-performing model improves the F1 Score by 2.3% and reduces the Expected\nCalibration Error by 2.1% compared to a deterministic baseline, enhancing both\npredictive skill and calibration. Our experiments confirm the reliability of\nthe uncertainty estimates and illustrate their practical utility for decision\nsupport, including the identification of uncertainty thresholds for rejecting\nlow-confidence predictions and the generation of well-calibrated wildfire\ndanger maps with accompanying uncertainty layers. Extending the forecast\nhorizon up to ten days, we observe that aleatoric uncertainty increases with\ntime, showing greater variability in environmental conditions, while epistemic\nuncertainty remains stable. Finally, we show that although the two uncertainty\ntypes may be redundant in low-uncertainty cases, they provide complementary\ninsights under more challenging conditions, underscoring the value of their\njoint modeling for robust wildfire danger prediction. In summary, our approach\nsignificantly improves the accuracy and reliability of wildfire danger\nforecasting, advancing the development of trustworthy wildfire DL systems.", "published": "2025-09-29 16:43:17", "link": "http://arxiv.org/abs/2509.25017v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Score-based Membership Inference on Diffusion Models", "abstract": "Membership inference attacks (MIAs) against diffusion models have emerged as\na pressing privacy concern, as these models may inadvertently reveal whether a\ngiven sample was part of their training set. We present a theoretical and\nempirical study of score-based MIAs, focusing on the predicted noise vectors\nthat diffusion models learn to approximate. We show that the expected denoiser\noutput points toward a kernel-weighted local mean of nearby training samples,\nsuch that its norm encodes proximity to the training set and thereby reveals\nmembership. Building on this observation, we propose SimA, a single-query\nattack that provides a principled, efficient alternative to existing\nmulti-query methods. SimA achieves consistently strong performance across\nvariants of DDPM, Latent Diffusion Model (LDM). Notably, we find that Latent\nDiffusion Models are surprisingly less vulnerable than pixel-space models, due\nto the strong information bottleneck imposed by their latent auto-encoder. We\nfurther investigate this by differing the regularization hyperparameters\n($\\beta$ in $\\beta$-VAE) in latent channel and suggest a strategy to make LDM\ntraining more robust to MIA. Our results solidify the theory of score-based\nMIAs, while highlighting that Latent Diffusion class of methods requires better\nunderstanding of inversion for VAE, and not simply inversion of the Diffusion\nprocess", "published": "2025-09-29 16:28:55", "link": "http://arxiv.org/abs/2509.25003v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LVT: Large-Scale Scene Reconstruction via Local View Transformers", "abstract": "Large transformer models are proving to be a powerful tool for 3D vision and\nnovel view synthesis. However, the standard Transformer's well-known quadratic\ncomplexity makes it difficult to scale these methods to large scenes. To\naddress this challenge, we propose the Local View Transformer (LVT), a\nlarge-scale scene reconstruction and novel view synthesis architecture that\ncircumvents the need for the quadratic attention operation. Motivated by the\ninsight that spatially nearby views provide more useful signal about the local\nscene composition than distant views, our model processes all information in a\nlocal neighborhood around each view. To attend to tokens in nearby views, we\nleverage a novel positional encoding that conditions on the relative geometric\ntransformation between the query and nearby views. We decode the output of our\nmodel into a 3D Gaussian Splat scene representation that includes both color\nand opacity view-dependence. Taken together, the Local View Transformer enables\nreconstruction of arbitrarily large, high-resolution scenes in a single forward\npass. See our project page for results and interactive demos\nhttps://toobaimt.github.io/lvt/.", "published": "2025-09-29 16:24:34", "link": "http://arxiv.org/abs/2509.25001v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PanoWorld-X: Generating Explorable Panoramic Worlds via Sphere-Aware Video Diffusion", "abstract": "Generating a complete and explorable 360-degree visual world enables a wide\nrange of downstream applications. While prior works have advanced the field,\nthey remain constrained by either narrow field-of-view limitations, which\nhinder the synthesis of continuous and holistic scenes, or insufficient camera\ncontrollability that restricts free exploration by users or autonomous agents.\nTo address this, we propose PanoWorld-X, a novel framework for high-fidelity\nand controllable panoramic video generation with diverse camera trajectories.\nSpecifically, we first construct a large-scale dataset of panoramic\nvideo-exploration route pairs by simulating camera trajectories in virtual 3D\nenvironments via Unreal Engine. As the spherical geometry of panoramic data\nmisaligns with the inductive priors from conventional video diffusion, we then\nintroduce a Sphere-Aware Diffusion Transformer architecture that reprojects\nequirectangular features onto the spherical surface to model geometric\nadjacency in latent space, significantly enhancing visual fidelity and\nspatiotemporal continuity. Extensive experiments demonstrate that our\nPanoWorld-X achieves superior performance in various aspects, including motion\nrange, control precision, and visual quality, underscoring its potential for\nreal-world applications.", "published": "2025-09-29 16:22:00", "link": "http://arxiv.org/abs/2509.24997v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SDPose: Exploiting Diffusion Priors for Out-of-Domain and Robust Pose Estimation", "abstract": "Pre-trained diffusion models provide rich multi-scale latent features and are\nemerging as powerful vision backbones. While recent works such as\nMarigold~\\citep{ke2024repurposing} and Lotus~\\citep{he2024lotus} adapt\ndiffusion priors for dense prediction with strong cross-domain generalization,\ntheir potential for structured outputs (e.g., human pose estimation) remains\nunderexplored. In this paper, we propose \\textbf{SDPose}, a fine-tuning\nframework built upon Stable Diffusion to fully exploit pre-trained diffusion\npriors for human pose estimation. First, rather than modifying cross-attention\nmodules or introducing learnable embeddings, we directly predict keypoint\nheatmaps in the SD U-Net's image latent space to preserve the original\ngenerative priors. Second, we map these latent features into keypoint heatmaps\nthrough a lightweight convolutional pose head, which avoids disrupting the\npre-trained backbone. Finally, to prevent overfitting and enhance\nout-of-distribution robustness, we incorporate an auxiliary RGB reconstruction\nbranch that preserves domain-transferable generative semantics. To evaluate\nrobustness under domain shift, we further construct \\textbf{COCO-OOD}, a\nstyle-transferred variant of COCO with preserved annotations. With just\none-fifth of the training schedule used by Sapiens on COCO, SDPose attains\nparity with Sapiens-1B/2B on the COCO validation set and establishes a new\nstate of the art on the cross-domain benchmarks HumanArt and COCO-OOD.\nFurthermore, we showcase SDPose as a zero-shot pose annotator for downstream\ncontrollable generation tasks, including ControlNet-based image synthesis and\nvideo generation, where it delivers qualitatively superior pose guidance.", "published": "2025-09-29 16:09:03", "link": "http://arxiv.org/abs/2509.24980v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Wan-Alpha: High-Quality Text-to-Video Generation with Alpha Channel", "abstract": "RGBA video generation, which includes an alpha channel to represent\ntransparency, is gaining increasing attention across a wide range of\napplications. However, existing methods often neglect visual quality, limiting\ntheir practical usability. In this paper, we propose \\textit{Wan-Alpha}, a new\nframework that generates transparent videos by learning both RGB and alpha\nchannels jointly. We design an effective variational autoencoder (VAE) that\nencodes the alpha channel into the RGB latent space. Then, to support the\ntraining of our diffusion transformer, we construct a high-quality and diverse\nRGBA video dataset. Compared with state-of-the-art methods, our model\ndemonstrates superior performance in visual quality, motion realism, and\ntransparency rendering. Notably, our model can generate a wide variety of\nsemi-transparent objects, glowing effects, and fine-grained details such as\nhair strands. The released model is available on our website:\n\\href{https://donghaotian123.github.io/Wan-Alpha/}{https://donghaotian123.github.io/Wan-Alpha/}.", "published": "2025-09-29 16:08:21", "link": "http://arxiv.org/abs/2509.24979v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On-the-Fly Data Augmentation for Brain Tumor Segmentation", "abstract": "Robust segmentation across both pre-treatment and post-treatment glioma scans\ncan be helpful for consistent tumor monitoring and treatment planning. BraTS\n2025 Task 1 addresses this by challenging models to generalize across varying\ntumor appearances throughout the treatment timeline. However, training such\ngeneralized models requires access to diverse, high-quality annotated data,\nwhich is often limited. While data augmentation can alleviate this, storing\nlarge volumes of augmented 3D data is computationally expensive. To address\nthese challenges, we propose an on-the-fly augmentation strategy that\ndynamically inserts synthetic tumors using pretrained generative adversarial\nnetworks (GliGANs) during training. We evaluate three nnU-Net-based models and\ntheir ensembles: (1) a baseline without external augmentation, (2) a regular\non-the-fly augmented model, and (3) a model with customized on-the-fly\naugmentation. Built upon the nnU-Net framework, our pipeline leverages\npretrained GliGAN weights and tumor insertion methods from prior\nchallenge-winning solutions. An ensemble of the three models achieves\nlesion-wise Dice scores of 0.79 (ET), 0.749 (NETC), 0.872 (RC), 0.825 (SNFH),\n0.79 (TC), and 0.88 (WT) on the online BraTS 2025 validation platform. This\nwork ranked first in the BraTS Lighthouse Challenge 2025 Task 1- Adult Glioma\nSegmentation.", "published": "2025-09-29 16:02:36", "link": "http://arxiv.org/abs/2509.24973v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-based Facial Keypoint Alignment via Cross-Modal Fusion Attention and Self-Supervised Multi-Event Representation Learning", "abstract": "Event cameras offer unique advantages for facial keypoint alignment under\nchallenging conditions, such as low light and rapid motion, due to their high\ntemporal resolution and robustness to varying illumination. However, existing\nRGB facial keypoint alignment methods do not perform well on event data, and\ntraining solely on event data often leads to suboptimal performance because of\nits limited spatial information. Moreover, the lack of comprehensive labeled\nevent datasets further hinders progress in this area. To address these issues,\nwe propose a novel framework based on cross-modal fusion attention (CMFA) and\nself-supervised multi-event representation learning (SSMER) for event-based\nfacial keypoint alignment. Our framework employs CMFA to integrate\ncorresponding RGB data, guiding the model to extract robust facial features\nfrom event input images. In parallel, SSMER enables effective feature learning\nfrom unlabeled event data, overcoming spatial limitations. Extensive\nexperiments on our real-event E-SIE dataset and a synthetic-event version of\nthe public WFLW-V benchmark show that our approach consistently surpasses\nstate-of-the-art methods across multiple evaluation metrics.", "published": "2025-09-29 16:00:50", "link": "http://arxiv.org/abs/2509.24968v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Social 3D Scene Graphs: Modeling Human Actions and Relations for Interactive Service Robots", "abstract": "Understanding how people interact with their surroundings and each other is\nessential for enabling robots to act in socially compliant and context-aware\nways. While 3D Scene Graphs have emerged as a powerful semantic representation\nfor scene understanding, existing approaches largely ignore humans in the\nscene, also due to the lack of annotated human-environment relationships.\nMoreover, existing methods typically capture only open-vocabulary relations\nfrom single image frames, which limits their ability to model long-range\ninteractions beyond the observed content. We introduce Social 3D Scene Graphs,\nan augmented 3D Scene Graph representation that captures humans, their\nattributes, activities and relationships in the environment, both local and\nremote, using an open-vocabulary framework. Furthermore, we introduce a new\nbenchmark consisting of synthetic environments with comprehensive human-scene\nrelationship annotations and diverse types of queries for evaluating social\nscene understanding in 3D. The experiments demonstrate that our representation\nimproves human activity prediction and reasoning about human-environment\nrelations, paving the way toward socially intelligent robots.", "published": "2025-09-29 16:00:40", "link": "http://arxiv.org/abs/2509.24966v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evaluating Temperature Scaling Calibration Effectiveness for CNNs under Varying Noise Levels in Brain Tumour Detection", "abstract": "Precise confidence estimation in deep learning is vital for high-stakes\nfields like medical imaging, where overconfident misclassifications can have\nserious consequences. This work evaluates the effectiveness of Temperature\nScaling (TS), a post-hoc calibration technique, in improving the reliability of\nconvolutional neural networks (CNNs) for brain tumor classification. We develop\na custom CNN and train it on a merged brain MRI dataset. To simulate real-world\nuncertainty, five types of image noise are introduced: Gaussian, Poisson, Salt\n& Pepper, Speckle, and Uniform. Model performance is evaluated using precision,\nrecall, F1-score, accuracy, negative log-likelihood (NLL), and expected\ncalibration error (ECE), both before and after calibration. Results demonstrate\nthat TS significantly reduces ECE and NLL under all noise conditions without\ndegrading classification accuracy. This underscores TS as an effective and\ncomputationally efficient approach to enhance decision confidence of medical AI\nsystems, hence making model outputs more reliable in noisy or uncertain\nsettings.", "published": "2025-09-29 15:46:23", "link": "http://arxiv.org/abs/2509.24951v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Perceive, Reflect and Understand Long Video: Progressive Multi-Granular Clue Exploration with Interactive Agents", "abstract": "Long videos, characterized by temporal complexity and sparse task-relevant\ninformation, pose significant reasoning challenges for AI systems. Although\nvarious Large Language Model (LLM)-based approaches have advanced long video\nunderstanding, they still struggle to achieve both completeness and efficiency\nin capturing task-critical information. Inspired by human progressive visual\ncognition, we propose CogniGPT, a framework that leverages an interactive loop\nbetween Multi-Granular Perception Agent (MGPA) and Verification-Enhanced\nReflection Agent (VERA) for efficient and reliable long video understanding.\nSpecifically, MGPA mimics human visual divergent and focused attention to\ncapture task-related information, while VERA verifies perceived key clues to\nmitigate hallucination and optimize subsequent perception strategies. Through\nthis interactive process, CogniGPT explores a minimal set of informative and\nreliable task-related clues. Extensive experiments on EgoSchema, Video-MME,\nNExT-QA, and MovieChat datasets demonstrate CogniGPT's superiority in both\naccuracy and efficiency. Notably, on EgoSchema, it surpasses existing\ntraining-free methods using only 11.2 frames and achieves performance\ncomparable to Gemini 1.5-Pro.", "published": "2025-09-29 15:42:55", "link": "http://arxiv.org/abs/2509.24943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Goal-Oriented Language-Guided Navigation with Self-Improving Demonstrations at Scale", "abstract": "Goal-oriented language-guided navigation requires robust exploration\ncapabilities for agents to navigate to specified goals in unknown environments\nwithout step-by-step instructions. Existing methods tend to exclusively utilize\nshortest-path trajectories, lacking effective exploration priors for training\nnavigation agents. To address the above challenges, we present SID, a\ngoal-oriented language-guided navigation learning approach with Self-Improving\nDemonstrations. Specifically, SID learns an initial agent on the shortest-path\ndata sampled from environments and then leverages this agent to generate novel\nexploration trajectories. The novel rollouts provide demonstrations with\nstronger exploration strategies to train a better agent, which in turn produces\nhigher-quality agent demonstrations for the next round of training. We show\nthat this iterative self-improving pipeline readily scales to new environments,\nand the resulting demonstrations can be transferred across a variety of\nlanguage-guided navigation tasks, elevating the performance ceiling in diverse\ngoal-oriented navigation tasks. Extensive experiments demonstrate that SID\nsignificantly boosts the exploration capabilities and generalization of\nnavigation agents. The resulting agent achieves new state-of-the-art\nperformance on goal-oriented language-guided navigation tasks, including\nREVERIE, SOON, notably achieving a 50.9% success rate on the unseen validation\nsplits of SOON, surpassing the prior leading approaches by a margin of 13.9%.", "published": "2025-09-29 15:15:54", "link": "http://arxiv.org/abs/2509.24910v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits", "abstract": "Cooperative perception enabled by Vehicle-to-Everything communication has\nshown great promise in enhancing situational awareness for autonomous vehicles\nand other mobile robotic platforms. Despite recent advances in perception\nbackbones and multi-agent fusion, real-world deployments remain challenged by\nhard detection cases, exemplified by partial detections and noise accumulation\nwhich limit downstream detection accuracy. This work presents Diffusion on\nReinforced Cooperative Perception (DRCP), a real-time deployable framework\ndesigned to address aforementioned issues in dynamic driving environments. DRCP\nintegrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,\na cross-modal cooperative perception module that leverages\ncamera-intrinsic-aware angular partitioning for attention-based fusion and\nadaptive convolution to better exploit external features; and (2)\nMask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement\nmodule that encourages robustness against feature perturbations and aligns\nbird's-eye-view features closer to the task-optimal manifold. The proposed\nsystem achieves real-time performance on mobile platforms while significantly\nimproving robustness under challenging conditions. Code will be released in\nlate 2025.", "published": "2025-09-29 15:13:03", "link": "http://arxiv.org/abs/2509.24903v1", "categories": ["cs.RO", "cs.CV", "eess.IV"], "primary_category": "cs.RO"}
{"title": "Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer", "abstract": "Transformer-based video diffusion models (VDMs) deliver state-of-the-art\nvideo generation quality but are constrained by the quadratic cost of\nself-attention, making long sequences and high resolutions computationally\nexpensive. While linear attention offers sub-quadratic complexity, prior\nattempts fail to match the expressiveness of softmax attention without costly\nretraining. We introduce \\textit{Attention Surgery}, an efficient framework for\n\\textit{linearizing} or \\textit{hybridizing} attention in pretrained VDMs\nwithout training from scratch. Inspired by recent advances in language models,\nour method combines a novel hybrid attention mechanism-mixing softmax and\nlinear tokens-with a lightweight distillation and fine-tuning pipeline\nrequiring only a few GPU-days. Additionally, we incorporate a cost-aware\nblock-rate strategy to balance expressiveness and efficiency across layers.\nApplied to Wan2.1 1.3B, a state-of-the-art DiT-based VDM, Attention Surgery\nachieves the first competitive sub-quadratic attention video diffusion models,\nreducing attention cost by up to 40\\% in terms of FLOPs, while maintaining\ngeneration quality as measured on the standard VBench and VBench-2.0\nbenchmarks.", "published": "2025-09-29 15:09:51", "link": "http://arxiv.org/abs/2509.24899v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accurate Cobb Angle Estimation via SVD-Based Curve Detection and Vertebral Wedging Quantification", "abstract": "Adolescent idiopathic scoliosis (AIS) is a common spinal deformity affecting\napproximately 2.2% of boys and 4.8% of girls worldwide. The Cobb angle serves\nas the gold standard for AIS severity assessment, yet traditional manual\nmeasurements suffer from significant observer variability, compromising\ndiagnostic accuracy. Despite prior automation attempts, existing methods use\nsimplified spinal models and predetermined curve patterns that fail to address\nclinical complexity. We present a novel deep learning framework for AIS\nassessment that simultaneously predicts both superior and inferior endplate\nangles with corresponding midpoint coordinates for each vertebra, preserving\nthe anatomical reality of vertebral wedging in progressive AIS. Our approach\ncombines an HRNet backbone with Swin-Transformer modules and biomechanically\ninformed constraints for enhanced feature extraction. We employ Singular Value\nDecomposition (SVD) to analyze angle predictions directly from vertebral\nmorphology, enabling flexible detection of diverse scoliosis patterns without\npredefined curve assumptions. Using 630 full-spine anteroposterior radiographs\nfrom patients aged 10-18 years with rigorous dual-rater annotation, our method\nachieved 83.45% diagnostic accuracy and 2.55{\\deg} mean absolute error. The\nframework demonstrates exceptional generalization capability on\nout-of-distribution cases. Additionally, we introduce the Vertebral Wedging\nIndex (VWI), a novel metric quantifying vertebral deformation. Longitudinal\nanalysis revealed VWI's significant prognostic correlation with curve\nprogression while traditional Cobb angles showed no correlation, providing\nrobust support for early AIS detection, personalized treatment planning, and\nprogression monitoring.", "published": "2025-09-29 15:07:55", "link": "http://arxiv.org/abs/2509.24898v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation", "abstract": "Source-free active domain adaptation (SFADA) enhances knowledge transfer from\na source model to an unlabeled target domain using limited manual labels\nselected via active learning. While recent domain adaptation studies have\nintroduced Vision-and-Language (ViL) models to improve pseudo-label quality or\nfeature alignment, they often treat ViL-based and data supervision as separate\nsources, lacking effective fusion. To overcome this limitation, we propose Dual\nActive learning with Multimodal (DAM) foundation model, a novel framework that\nintegrates multimodal supervision from a ViL model to complement sparse human\nannotations, thereby forming a dual supervisory signal. DAM initializes stable\nViL-guided targets and employs a bidirectional distillation mechanism to foster\nmutual knowledge exchange between the target model and the dual supervisions\nduring iterative adaptation. Extensive experiments demonstrate that DAM\nconsistently outperforms existing methods and sets a new state-of-the-art\nacross multiple SFADA benchmarks and active learning strategies.", "published": "2025-09-29 15:06:56", "link": "http://arxiv.org/abs/2509.24896v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth Estimation and Bidirectional Warping", "abstract": "Novel View Synthesis (NVS) from sparse views remains a core challenge in 3D\nreconstruction, typically suffering from overfitting, geometric distortion, and\nincomplete scene recovery due to limited multi-view constraints. Although 3D\nGaussian Splatting (3DGS) enables real-time, high-fidelity rendering, it\nsuffers from floating artifacts and structural inconsistencies under\nsparse-input settings. To address these issues, we propose DWGS, a novel\nunified framework that enhances 3DGS for sparse-view synthesis by integrating\nrobust structural cues, virtual view constraints, and occluded region\ncompletion. Our approach introduces three principal contributions: a\nHybrid-Loss Depth Estimation module that leverages dense matching priors with\nreprojection, point propagation, and smoothness constraints to enforce\nmulti-view consistency; a Bidirectional Warping Virtual View Synthesis method\ngenerates virtual training views to impose stronger geometric and photometric\nconstraints; and an Occlusion-Aware Reconstruction component that utilizes\ndepth-difference mask and a learning-based inpainting model to recover obscured\nregions. Extensive experiments on standard benchmarks (LLFF, Blender, and DTU)\nshow that DWGS achieves a new state-of-the-art, achieving up to 21.13 dB PSNR\nand 0.189 LPIPS, while retaining real-time inference capabilities.", "published": "2025-09-29 15:03:31", "link": "http://arxiv.org/abs/2509.24893v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VAGUEGAN: Stealthy Poisoning and Backdoor Attacks on Image Generative Pipelines", "abstract": "Generative models such as GANs and diffusion models are widely used to\nsynthesize photorealistic images and to support downstream creative and editing\ntasks. While adversarial attacks on discriminative models are well studied,\nattacks targeting generative pipelines where small, stealthy perturbations in\ninputs lead to controlled changes in outputs are less explored. This study\nintroduces VagueGAN, an attack pipeline combining a modular perturbation\nnetwork PoisonerNet with a Generator Discriminator pair to craft stealthy\ntriggers that cause targeted changes in generated images. Attack efficacy is\nevaluated using a custom proxy metric, while stealth is analyzed through\nperceptual and frequency domain measures. The transferability of the method to\na modern diffusion based pipeline is further examined through ControlNet guided\nediting. Interestingly, the experiments show that poisoned outputs can display\nhigher visual quality compared to clean counterparts, challenging the\nassumption that poisoning necessarily reduces fidelity. Unlike conventional\npixel level perturbations, latent space poisoning in GANs and diffusion\npipelines can retain or even enhance output aesthetics, exposing a blind spot\nin pixel level defenses. Moreover, carefully optimized perturbations can\nproduce consistent, stealthy effects on generator outputs while remaining\nvisually inconspicuous, raising concerns for the integrity of image generation\npipelines.", "published": "2025-09-29 15:02:31", "link": "http://arxiv.org/abs/2509.24891v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ThermalGen: Style-Disentangled Flow-Based Generative Models for RGB-to-Thermal Image Translation", "abstract": "Paired RGB-thermal data is crucial for visual-thermal sensor fusion and\ncross-modality tasks, including important applications such as multi-modal\nimage alignment and retrieval. However, the scarcity of synchronized and\ncalibrated RGB-thermal image pairs presents a major obstacle to progress in\nthese areas. To overcome this challenge, RGB-to-Thermal (RGB-T) image\ntranslation has emerged as a promising solution, enabling the synthesis of\nthermal images from abundant RGB datasets for training purposes. In this study,\nwe propose ThermalGen, an adaptive flow-based generative model for RGB-T image\ntranslation, incorporating an RGB image conditioning architecture and a\nstyle-disentangled mechanism. To support large-scale training, we curated eight\npublic satellite-aerial, aerial, and ground RGB-T paired datasets, and\nintroduced three new large-scale satellite-aerial RGB-T datasets--DJI-day,\nBosonplus-day, and Bosonplus-night--captured across diverse times, sensor\ntypes, and geographic regions. Extensive evaluations across multiple RGB-T\nbenchmarks demonstrate that ThermalGen achieves comparable or superior\ntranslation performance compared to existing GAN-based and diffusion-based\nmethods. To our knowledge, ThermalGen is the first RGB-T image translation\nmodel capable of synthesizing thermal images that reflect significant\nvariations in viewpoints, sensor characteristics, and environmental conditions.\nProject page: http://xjh19971.github.io/ThermalGen", "published": "2025-09-29 14:55:51", "link": "http://arxiv.org/abs/2509.24878v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Environment-Aware Satellite Image Generation with Diffusion Models", "abstract": "Diffusion-based foundation models have recently garnered much attention in\nthe field of generative modeling due to their ability to generate images of\nhigh quality and fidelity. Although not straightforward, their recent\napplication to the field of remote sensing signaled the first successful trials\ntowards harnessing the large volume of publicly available datasets containing\nmultimodal information. Despite their success, existing methods face\nconsiderable limitations: they rely on limited environmental context, struggle\nwith missing or corrupted data, and often fail to reliably reflect user\nintentions in generated outputs. In this work, we propose a novel diffusion\nmodel conditioned on environmental context, that is able to generate satellite\nimages by conditioning from any combination of three different control signals:\na) text, b) metadata, and c) visual data. In contrast to previous works, the\nproposed method is i) to our knowledge, the first of its kind to condition\nsatellite image generation on dynamic environmental conditions as part of its\ncontrol signals, and ii) incorporating a metadata fusion strategy that models\nattribute embedding interactions to account for partially corrupt and/or\nmissing observations. Our method outperforms previous methods both\nqualitatively (robustness to missing metadata, higher responsiveness to control\ninputs) and quantitatively (higher fidelity, accuracy, and quality of\ngenerations measured using 6 different metrics) in the trials of single-image\nand temporal generation. The reported results support our hypothesis that\nconditioning on environmental context can improve the performance of foundation\nmodels for satellite imagery, and render our model a promising candidate for\nusage in downstream tasks. The collected 3-modal dataset is to our knowledge,\nthe first publicly-available dataset to combine data from these three different\nmediums.", "published": "2025-09-29 14:54:53", "link": "http://arxiv.org/abs/2509.24875v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "StreamForest: Efficient Online Video Understanding with Persistent Event Memory", "abstract": "Multimodal Large Language Models (MLLMs) have recently achieved remarkable\nprogress in video understanding. However, their effectiveness in real-time\nstreaming scenarios remains limited due to storage constraints of historical\nvisual features and insufficient real-time spatiotemporal reasoning. To address\nthese challenges, we propose StreamForest, a novel architecture specifically\ndesigned for streaming video understanding. Central to StreamForest is the\nPersistent Event Memory Forest, a memory mechanism that adaptively organizes\nvideo frames into multiple event-level tree structures. This process is guided\nby penalty functions based on temporal distance, content similarity, and merge\nfrequency, enabling efficient long-term memory retention under limited\ncomputational resources. To enhance real-time perception, we introduce a\nFine-grained Spatiotemporal Window, which captures detailed short-term visual\ncues to improve current scene perception. Additionally, we present OnlineIT, an\ninstruction-tuning dataset tailored for streaming video tasks. OnlineIT\nsignificantly boosts MLLM performance in both real-time perception and future\nprediction. To evaluate generalization in practical applications, we introduce\nODV-Bench, a new benchmark focused on real-time streaming video understanding\nin autonomous driving scenarios. Experimental results demonstrate that\nStreamForest achieves the state-of-the-art performance, with accuracies of\n77.3% on StreamingBench, 60.5% on OVBench, and 55.6% on OVO-Bench. In\nparticular, even under extreme visual token compression (limited to 1024\ntokens), the model retains 96.8% of its average accuracy in eight benchmarks\nrelative to the default setting. These results underscore the robustness,\nefficiency, and generalizability of StreamForest for streaming video\nunderstanding.", "published": "2025-09-29 14:53:57", "link": "http://arxiv.org/abs/2509.24871v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision At Night: Exploring Biologically Inspired Preprocessing For Improved Robustness Via Color And Contrast Transformations", "abstract": "Inspired by the human visual system's mechanisms for contrast enhancement and\ncolor-opponency, we explore biologically motivated input preprocessing for\nrobust semantic segmentation. By applying Difference-of-Gaussians (DoG)\nfiltering to RGB, grayscale, and opponent-color channels, we enhance local\ncontrast without modifying model architecture or training. Evaluations on\nCityscapes, ACDC, and Dark Zurich show that such preprocessing maintains\nin-distribution performance while improving robustness to adverse conditions\nlike night, fog, and snow. As this processing is model-agnostic and\nlightweight, it holds potential for integration into imaging pipelines,\nenabling imaging systems to deliver task-ready, robust inputs for downstream\nvision models in safety-critical environments.", "published": "2025-09-29 14:48:32", "link": "http://arxiv.org/abs/2509.24863v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ELPG-DTFS: Prior-Guided Adaptive Time-Frequency Graph Neural Network for EEG Depression Diagnosis", "abstract": "Timely and objective screening of major depressive disorder (MDD) is vital,\nyet diagnosis still relies on subjective scales. Electroencephalography (EEG)\nprovides a low-cost biomarker, but existing deep models treat spectra as static\nimages, fix inter-channel graphs, and ignore prior knowledge, limiting accuracy\nand interpretability. We propose ELPG-DTFS, a prior-guided adaptive\ntime-frequency graph neural network that introduces: (1) channel-band attention\nwith cross-band mutual information, (2) a learnable adjacency matrix for\ndynamic functional links, and (3) a residual knowledge-graph pathway injecting\nneuroscience priors. On the 128-channel MODMA dataset (53 subjects), ELPG-DTFS\nachieves 97.63% accuracy and 97.33% F1, surpassing the 2025 state-of-the-art\nACM-GNN. Ablation shows that removing any module lowers F1 by up to 4.35,\nconfirming their complementary value. ELPG-DTFS thus offers a robust and\ninterpretable framework for next-generation EEG-based MDD diagnostics.", "published": "2025-09-29 14:44:37", "link": "http://arxiv.org/abs/2509.24860v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PHASE-Net: Physics-Grounded Harmonic Attention System for Efficient Remote Photoplethysmography Measurement", "abstract": "Remote photoplethysmography (rPPG) measurement enables non-contact\nphysiological monitoring but suffers from accuracy degradation under head\nmotion and illumination changes. Existing deep learning methods are mostly\nheuristic and lack theoretical grounding, which limits robustness and\ninterpretability. In this work, we propose a physics-informed rPPG paradigm\nderived from the Navier-Stokes equations of hemodynamics, showing that the\npulse signal follows a second-order dynamical system whose discrete solution\nnaturally leads to a causal convolution. This provides a theoretical\njustification for using a Temporal Convolutional Network (TCN). Based on this\nprinciple, we design PHASE-Net, a lightweight model with three key components:\n(1) Zero-FLOPs Axial Swapper module, which swaps or transposes a few spatial\nchannels to mix distant facial regions and enhance cross-region feature\ninteraction without breaking temporal order; (2) Adaptive Spatial Filter, which\nlearns a soft spatial mask per frame to highlight signal-rich areas and\nsuppress noise; and (3) Gated TCN, a causal dilated TCN with gating that models\nlong-range temporal dynamics for accurate pulse recovery. Extensive experiments\ndemonstrate that PHASE-Net achieves state-of-the-art performance with strong\nefficiency, offering a theoretically grounded and deployment-ready rPPG\nsolution.", "published": "2025-09-29 14:36:45", "link": "http://arxiv.org/abs/2509.24850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models", "abstract": "Large Vision-Language Models (VLMs) enable strong multimodal reasoning but\nincur heavy inference costs from redundant visual tokens. Token pruning\nalleviates this issue, yet existing approaches face limitations.\nAttention-based methods rely on raw attention scores, which are often unstable\nacross layers and heads and can lead to redundant selections. Diversity-based\nmethods improve robustness by selecting tokens far apart in feature space but\nrisk dropping regions needed for accurate prediction. We propose \\ours, a\ntraining-free framework built on a simple intuition: tokens with higher\nsensitivity are more likely to influence the model's output, and they should\nalso capture complementary visual cues rather than overlapping information. To\nachieve this, we estimate token sensitivity using zeroth-order perturbations at\nthe projection layer, a shallow and computationally light component of the\nmodel. This approach measures how small random perturbations affect the\nprojection outputs, allowing us to approximate each token's influence through\nlightweight forward passes without backpropagation. Extensive experiments\nacross multiple VLMs and benchmarks show that \\ours consistently outperforms\nprior methods, pruning up to 94.4\\% of tokens while maintaining accuracy and\nsignificantly improving efficiency, achieving up to 2.30x faster end-to-end\ninference over the baseline.", "published": "2025-09-29 14:20:05", "link": "http://arxiv.org/abs/2509.24837v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections", "abstract": "We present UP2You, the first tuning-free solution for reconstructing\nhigh-fidelity 3D clothed portraits from extremely unconstrained in-the-wild 2D\nphotos. Unlike previous approaches that require \"clean\" inputs (e.g., full-body\nimages with minimal occlusions, or well-calibrated cross-view captures), UP2You\ndirectly processes raw, unstructured photographs, which may vary significantly\nin pose, viewpoint, cropping, and occlusion. Instead of compressing data into\ntokens for slow online text-to-3D optimization, we introduce a data rectifier\nparadigm that efficiently converts unconstrained inputs into clean, orthogonal\nmulti-view images in a single forward pass within seconds, simplifying the 3D\nreconstruction. Central to UP2You is a pose-correlated feature aggregation\nmodule (PCFA), that selectively fuses information from multiple reference\nimages w.r.t. target poses, enabling better identity preservation and nearly\nconstant memory footprint, with more observations. We also introduce a\nperceiver-based multi-reference shape predictor, removing the need for\npre-captured body templates. Extensive experiments on 4D-Dress, PuzzleIOI, and\nin-the-wild captures demonstrate that UP2You consistently surpasses previous\nmethods in both geometric accuracy (Chamfer-15%, P2S-18% on PuzzleIOI) and\ntexture fidelity (PSNR-21%, LPIPS-46% on 4D-Dress). UP2You is efficient (1.5\nminutes per person), and versatile (supports arbitrary pose control, and\ntraining-free multi-garment 3D virtual try-on), making it practical for\nreal-world scenarios where humans are casually captured. Both models and code\nwill be released to facilitate future research on this underexplored task.\nProject Page: https://zcai0612.github.io/UP2You", "published": "2025-09-29 14:06:00", "link": "http://arxiv.org/abs/2509.24817v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TACO-Net: Topological Signatures Triumph in 3D Object Classification", "abstract": "3D object classification is a crucial problem due to its significant\npractical relevance in many fields, including computer vision, robotics, and\nautonomous driving. Although deep learning methods applied to point clouds\nsampled on CAD models of the objects and/or captured by LiDAR or RGBD cameras\nhave achieved remarkable success in recent years, achieving high classification\naccuracy remains a challenging problem due to the unordered point clouds and\ntheir irregularity and noise. To this end, we propose a novel state-of-the-art\n(SOTA) 3D object classification technique that combines topological data\nanalysis with various image filtration techniques to classify objects when they\nare represented using point clouds. We transform every point cloud into a\nvoxelized binary 3D image to extract distinguishing topological features. Next,\nwe train a lightweight one-dimensional Convolutional Neural Network (1D CNN)\nusing the extracted feature set from the training dataset. Our framework,\nTACO-Net, sets a new state-of-the-art by achieving $99.05\\%$ and $99.52\\%$\naccuracy on the widely used synthetic benchmarks ModelNet40 and ModelNet10, and\nfurther demonstrates its robustness on the large-scale real-world OmniObject3D\ndataset. When tested with ten different kinds of corrupted ModelNet40 inputs,\nthe proposed TACO-Net demonstrates strong resiliency overall.", "published": "2025-09-29 13:52:53", "link": "http://arxiv.org/abs/2509.24802v1", "categories": ["cs.CV", "cs.CG", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vision Function Layer in Multimodal LLMs", "abstract": "This study identifies that visual-related functional decoding is distributed\nacross different decoder layers in Multimodal Large Language Models (MLLMs).\nTypically, each function, such as counting, grounding, or OCR recognition,\nnarrows down to two or three layers, which we define as Vision Function Layers\n(VFL). Additionally, the depth and its order of different VFLs exhibits a\nconsistent pattern across different MLLMs, which is well-aligned with human\nbehaviors (e.g., recognition occurs first, followed by counting, and then\ngrounding). These findings are derived from Visual Token Swapping, our novel\nanalytical framework that modifies targeted KV cache entries to precisely\nelucidate layer-specific functions during decoding. Furthermore, these insights\noffer substantial utility in tailoring MLLMs for real-world downstream\napplications. For instance, when LoRA training is selectively applied to VFLs\nwhose functions align with the training data, VFL-LoRA not only outperform\nfull-LoRA but also prevent out-of-domain function forgetting. Moreover, by\nanalyzing the performance differential on training data when particular VFLs\nare ablated, VFL-select automatically classifies data by function, enabling\nhighly efficient data selection to directly bolster corresponding capabilities.\nConsequently, VFL-select surpasses human experts in data selection, and\nachieves 98% of full-data performance with only 20% of the original dataset.\nThis study delivers deeper comprehension of MLLM visual processing, fostering\nthe creation of more efficient, interpretable, and robust models.", "published": "2025-09-29 13:45:35", "link": "http://arxiv.org/abs/2509.24791v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LOVE-R1: Advancing Long Video Understanding with an Adaptive Zoom-in Mechanism via Multi-Step Reasoning", "abstract": "Long video understanding is still challenging for recent Large Video-Language\nModels (LVLMs) due to the conflict between long-form temporal understanding and\ndetailed spatial perception. LVLMs with a uniform frame sampling mechanism,\nwhich samples frames with an equal frame size and fixed sampling rate,\ninevitably sacrifice either temporal clues or spatial details, resulting in\nsuboptimal solutions. To mitigate this dilemma, we propose LOVE-R1, a model\nthat can adaptively zoom in on a video clip. The model is first provided with\ndensely sampled frames but in a small resolution. If some spatial details are\nneeded, the model can zoom in on a clip of interest with a large frame\nresolution based on its reasoning until key visual information is obtained. The\nwhole process is implemented as a multi-step reasoning process. To train the\nreasoning ability, we first finetune the model on our collected 38k\nhigh-quality CoT data and enhance it with decoupled reinforcement finetuning.\nAs outcome rewards can not provide fine-grained process supervision, we\ndecouple multi-step reasoning into multiple single-step reasoning and optimize\nthe internal zoom-in ability explicitly. Experiments on long video\nunderstanding benchmarks show that our model with the slow-fast adaptive frame\nsampling mechanism achieves a great trade-off between sampling density and\nframe resolutions, and LOVE-R1 outperforms our baseline Qwen2.5-VL by an\naverage of 3.1% points across 4 common long video understanding benchmarks.", "published": "2025-09-29 13:43:55", "link": "http://arxiv.org/abs/2509.24786v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SkyLink: Unifying Street-Satellite Geo-Localization via UAV-Mediated 3D Scene Alignment", "abstract": "Cross-view geo-localization aims at establishing location correspondences\nbetween different viewpoints. Existing approaches typically learn cross-view\ncorrelations through direct feature similarity matching, often overlooking\nsemantic degradation caused by extreme viewpoint disparities. To address this\nunique problem, we focus on robust feature retrieval under viewpoint variation\nand propose the novel SkyLink method. We firstly utilize the Google Retrieval\nEnhancement Module to perform data enhancement on street images, which\nmitigates the occlusion of the key target due to restricted street viewpoints.\nThe Patch-Aware Feature Aggregation module is further adopted to emphasize\nmultiple local feature aggregations to ensure the consistent feature extraction\nacross viewpoints. Meanwhile, we integrate the 3D scene information constructed\nfrom multi-scale UAV images as a bridge between street and satellite\nviewpoints, and perform feature alignment through self-supervised and\ncross-view contrastive learning. Experimental results demonstrate robustness\nand generalization across diverse urban scenarios, which achieve 25.75$\\%$\nRecall@1 accuracy on University-1652 in the UAVM2025 Challenge. Code will be\nreleased at https://github.com/HRT00/CVGL-3D.", "published": "2025-09-29 13:43:18", "link": "http://arxiv.org/abs/2509.24783v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "ExGS: Extreme 3D Gaussian Compression with Diffusion Priors", "abstract": "Neural scene representations, such as 3D Gaussian Splatting (3DGS), have\nenabled high-quality neural rendering; however, their large storage and\ntransmission costs hinder deployment in resource-constrained environments.\nExisting compression methods either rely on costly optimization, which is slow\nand scene-specific, or adopt training-free pruning and quantization, which\ndegrade rendering quality under high compression ratios. In contrast, recent\ndata-driven approaches provide a promising direction to overcome this\ntrade-off, enabling efficient compression while preserving high rendering\nquality. We introduce \\textbf{ExGS}, a novel feed-forward framework that\nunifies \\textbf{Universal Gaussian Compression} (UGC) with\n\\textbf{GaussPainter} for \\textbf{Ex}treme 3D\\textbf{GS} compression.\n\\textbf{UGC} performs re-optimization-free pruning to aggressively reduce\nGaussian primitives while retaining only essential information, whereas\n\\textbf{GaussPainter} leverages powerful diffusion priors with mask-guided\nrefinement to restore high-quality renderings from heavily pruned Gaussian\nscenes. Unlike conventional inpainting, GaussPainter not only fills in missing\nregions but also enhances visible pixels, yielding substantial improvements in\ndegraded renderings. To ensure practicality, it adopts a lightweight VAE and a\none-step diffusion design, enabling real-time restoration. Our framework can\neven achieve over $100\\times$ compression (reducing a typical 354.77 MB model\nto about 3.31 MB) while preserving fidelity and significantly improving image\nquality under challenging conditions. These results highlight the central role\nof diffusion priors in bridging the gap between extreme compression and\nhigh-quality neural rendering. Our code repository will be released at\n\\href{https://github.com/chenttt2001/ExGS}{here}.", "published": "2025-09-29 13:23:06", "link": "http://arxiv.org/abs/2509.24758v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Collaborating Vision, Depth, and Thermal Signals for Multi-Modal Tracking: Dataset and Algorithm", "abstract": "Existing multi-modal object tracking approaches primarily focus on dual-modal\nparadigms, such as RGB-Depth or RGB-Thermal, yet remain challenged in complex\nscenarios due to limited input modalities. To address this gap, this work\nintroduces a novel multi-modal tracking task that leverages three complementary\nmodalities, including visible RGB, Depth (D), and Thermal Infrared (TIR),\naiming to enhance robustness in complex scenarios. To support this task, we\nconstruct a new multi-modal tracking dataset, coined RGBDT500, which consists\nof 500 videos with synchronised frames across the three modalities. Each frame\nprovides spatially aligned RGB, depth, and thermal infrared images with precise\nobject bounding box annotations. Furthermore, we propose a novel multi-modal\ntracker, dubbed RDTTrack. RDTTrack integrates tri-modal information for robust\ntracking by leveraging a pretrained RGB-only tracking model and prompt learning\ntechniques. In specific, RDTTrack fuses thermal infrared and depth modalities\nunder a proposed orthogonal projection constraint, then integrates them with\nRGB signals as prompts for the pre-trained foundation tracking model,\neffectively harmonising tri-modal complementary cues. The experimental results\ndemonstrate the effectiveness and advantages of the proposed method, showing\nsignificant improvements over existing dual-modal approaches in terms of\ntracking accuracy and robustness in complex scenarios.", "published": "2025-09-29 13:05:15", "link": "http://arxiv.org/abs/2509.24741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation", "abstract": "Vision-Language Foundation Models (VLMs), trained on large-scale multimodal\ndatasets, have driven significant advances in Artificial Intelligence by\nenabling rich cross-modal reasoning. Despite their success in general domains,\napplying these models to medical imaging remains challenging due to the limited\navailability of diverse imaging modalities and multilingual clinical data. Most\nexisting medical VLMs are trained on a subset of imaging modalities and focus\nprimarily on high-resource languages, thus limiting their generalizability and\nclinical utility. To address these limitations, we introduce a novel\nVietnamese-language multimodal medical dataset comprising 1,567,062 paired\nCT-PET images and corresponding 2,757 full-length clinical reports. This\ndataset is designed to fill two pressing gaps in medical AI development: (1)\nthe lack of PET/CT imaging data in existing VLMs training corpora, which\nhinders the development of models capable of handling functional imaging tasks;\nand (2) the underrepresentation of low-resource languages, particularly the\nVietnamese language, in medical vision-language research. To the best of our\nknowledge, this is the first dataset to provide comprehensive PET/CT-report\npairs in Vietnamese. We further introduce a training framework to enhance VLMs'\nlearning, including data augmentation and expert-validated test sets. We\nconduct comprehensive experiments benchmarking state-of-the-art VLMs on\ndownstream tasks, including medical report generation and visual question\nanswering. The experimental results show that incorporating our dataset\nsignificantly improves the performance of existing VLMs. We believe this\ndataset and benchmark will serve as a pivotal step in advancing the development\nof more robust VLMs for medical imaging, particularly in low-resource\nlanguages, and improving their clinical relevance in Vietnamese healthcare.", "published": "2025-09-29 13:03:57", "link": "http://arxiv.org/abs/2509.24739v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evaluation of Polarimetric Fusion for Semantic Segmentation in Aquatic Environments", "abstract": "Accurate segmentation of floating debris on water is often compromised by\nsurface glare and changing outdoor illumination. Polarimetric imaging offers a\nsingle-sensor route to mitigate water-surface glare that disrupts semantic\nsegmentation of floating objects. We benchmark state-of-the-art fusion networks\non PoTATO, a public dataset of polarimetric images of plastic bottles in inland\nwaterways, and compare their performance with single-image baselines using\ntraditional models. Our results indicate that polarimetric cues help recover\nlow-contrast objects and suppress reflection-induced false positives, raising\nmean IoU and lowering contour error relative to RGB inputs. These sharper masks\ncome at a cost: the additional channels enlarge the models increasing the\ncomputational load and introducing the risk of new false positives. By\nproviding a reproducible, diagnostic benchmark and publicly available code, we\nhope to help researchers choose if polarized cameras are suitable for their\napplications and to accelerate related research.", "published": "2025-09-29 12:57:20", "link": "http://arxiv.org/abs/2509.24731v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?", "abstract": "The webpage-to-code task requires models to understand visual representations\nof webpages and generate corresponding code. However, existing benchmarks\nprimarily focus on static screenshot-to-code tasks, thereby overlooking the\ndynamic interactions fundamental to real-world web applications. To address\nthis limitation, this paper introduces IWR-Bench, a novel benchmark for\nevaluating the capabilities of Large Vision-Language Models (LVLMs) in\ninteractive webpage reconstruction from video. IWR-Bench comprises 113\nmeticulously curated tasks from 100 real-world websites, with 1,001 actions and\nfeaturing diverse interaction complexities (e.g., web games), visual styles,\nand domains. Aligning with standard web development practices, each task\nincludes not only user interaction videos but also all crawled static assets\n(e.g., images, videos). This benchmark evaluates models on two fundamental\nchallenges: comprehensive multi-modal reasoning to infer interaction logic from\nvideo and assets, and advanced code generation to translate this logic into\nfunctional code. An agent-as-a-judge framework with a comprehensive metric\nsystem automatically assesses the functional correctness and visual fidelity of\ngenerated webpages. Extensive experiments on 28 LVLMs reveal a significant\nchallenge: the best model achieves an overall score of only 36.35%, as\nfunctional correctness (24.39% IFS) lags significantly behind visual fidelity\n(64.25% VFS). These results highlight critical limitations in current models'\nability to reason about temporal dynamics and synthesize event-driven logic,\nestablishing IWR-Bench as a challenging frontier for vision-language research.\nThe benchmark and evaluation code will be made publicly available. Code is\navailable at https://github.com/L-O-I/IWR-Bench.", "published": "2025-09-29 12:38:06", "link": "http://arxiv.org/abs/2509.24709v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Physical Plausibility in Video Generation by Reasoning the Implausibility", "abstract": "Diffusion models can generate realistic videos, but existing methods rely on\nimplicitly learning physical reasoning from large-scale text-video datasets,\nwhich is costly, difficult to scale, and still prone to producing implausible\nmotions that violate fundamental physical laws. We introduce a training-free\nframework that improves physical plausibility at inference time by explicitly\nreasoning about implausibility and guiding the generation away from it.\nSpecifically, we employ a lightweight physics-aware reasoning pipeline to\nconstruct counterfactual prompts that deliberately encode physics-violating\nbehaviors. Then, we propose a novel Synchronized Decoupled Guidance (SDG)\nstrategy, which leverages these prompts through synchronized directional\nnormalization to counteract lagged suppression and trajectory-decoupled\ndenoising to mitigate cumulative trajectory bias, ensuring that implausible\ncontent is suppressed immediately and consistently throughout denoising.\nExperiments across different physical domains show that our approach\nsubstantially enhances physical fidelity while maintaining photorealism,\ndespite requiring no additional training. Ablation studies confirm the\ncomplementary effectiveness of both the physics-aware reasoning component and\nSDG. In particular, the aforementioned two designs of SDG are also individually\nvalidated to contribute critically to the suppression of implausible content\nand the overall gains in physical plausibility. This establishes a new and\nplug-and-play physics-aware paradigm for video generation.", "published": "2025-09-29 12:32:54", "link": "http://arxiv.org/abs/2509.24702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Traumatic Brain Injury Segmentation using an Ensemble of Encoder-decoder Models", "abstract": "The identification and segmentation of moderate-severe traumatic brain injury\n(TBI) lesions pose a significant challenge in neuroimaging. This difficulty\narises from the extreme heterogeneity of these lesions, which vary in size,\nnumber, and laterality, thereby complicating downstream image processing tasks\nsuch as image registration and brain parcellation, reducing the analytical\naccuracy. Thus, developing methods for highly accurate segmentation of TBI\nlesions is essential for reliable neuroimaging analysis. This study aims to\ndevelop an effective automated segmentation pipeline to automatically detect\nand segment TBI lesions in T1-weighted MRI scans. We evaluate multiple\napproaches to achieve accurate segmentation of the TBI lesions. The core of our\npipeline leverages various architectures within the nnUNet framework for\ninitial segmentation, complemented by post-processing strategies to enhance\nevaluation metrics. Our final submission to the challenge achieved an accuracy\nof 0.8451, Dice score values of 0.4711 and 0.8514 for images with and without\nvisible lesions, respectively, with an overall Dice score of 0.5973, ranking\namong the top-6 methods in the AIMS-TBI 2025 challenge. The Python\nimplementation of our pipeline is publicly available.", "published": "2025-09-29 12:21:32", "link": "http://arxiv.org/abs/2509.24684v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Classifier-Centric Adaptive Framework for Open-Vocabulary Camouflaged Object Segmentation", "abstract": "Open-vocabulary camouflaged object segmentation requires models to segment\ncamouflaged objects of arbitrary categories unseen during training, placing\nextremely high demands on generalization capabilities. Through analysis of\nexisting methods, it is observed that the classification component\nsignificantly affects overall segmentation performance. Accordingly, a\nclassifier-centric adaptive framework is proposed to enhance segmentation\nperformance by improving the classification component via a lightweight text\nadapter with a novel layered asymmetric initialization. Through the\nclassification enhancement, the proposed method achieves substantial\nimprovements in segmentation metrics compared to the OVCoser baseline on the\nOVCamo benchmark: cIoU increases from 0.443 to 0.493, cSm from 0.579 to 0.658,\nand cMAE reduces from 0.336 to 0.239. These results demonstrate that targeted\nclassification enhancement provides an effective approach for advancing\ncamouflaged object segmentation performance.", "published": "2025-09-29 12:16:28", "link": "http://arxiv.org/abs/2509.24681v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations", "abstract": "Cross-embodiment dexterous grasp synthesis refers to adaptively generating\nand optimizing grasps for various robotic hands with different morphologies.\nThis capability is crucial for achieving versatile robotic manipulation in\ndiverse environments and requires substantial amounts of reliable and diverse\ngrasp data for effective model training and robust generalization. However,\nexisting approaches either rely on physics-based optimization that lacks\nhuman-like kinematic understanding or require extensive manual data collection\nprocesses that are limited to anthropomorphic structures. In this paper, we\npropose CEDex, a novel cross-embodiment dexterous grasp synthesis method at\nscale that bridges human grasping kinematics and robot kinematics by aligning\nrobot kinematic models with generated human-like contact representations. Given\nan object's point cloud and an arbitrary robotic hand model, CEDex first\ngenerates human-like contact representations using a Conditional Variational\nAuto-encoder pretrained on human contact data. It then performs kinematic human\ncontact alignment through topological merging to consolidate multiple human\nhand parts into unified robot components, followed by a signed distance\nfield-based grasp optimization with physics-aware constraints. Using CEDex, we\nconstruct the largest cross-embodiment grasp dataset to date, comprising 500K\nobjects across four gripper types with 20M total grasps. Extensive experiments\nshow that CEDex outperforms state-of-the-art approaches and our dataset\nbenefits cross-embodiment grasp learning with high-quality diverse grasps.", "published": "2025-09-29 12:08:04", "link": "http://arxiv.org/abs/2509.24661v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Learning Object-Centric Representations Based on Slots in Real World Scenarios", "abstract": "A central goal in AI is to represent scenes as compositions of discrete\nobjects, enabling fine-grained, controllable image and video generation. Yet\nleading diffusion models treat images holistically and rely on text\nconditioning, creating a mismatch for object-level editing. This thesis\nintroduces a framework that adapts powerful pretrained diffusion models for\nobject-centric synthesis while retaining their generative capacity.\n  We identify a core challenge: balancing global scene coherence with\ndisentangled object control. Our method integrates lightweight, slot-based\nconditioning into pretrained models, preserving their visual priors while\nproviding object-specific manipulation. For images, SlotAdapt augments\ndiffusion models with a register token for background/style and\nslot-conditioned modules for objects, reducing text-conditioning bias and\nachieving state-of-the-art results in object discovery, segmentation,\ncompositional editing, and controllable image generation.\n  We further extend the framework to video. Using Invariant Slot Attention\n(ISA) to separate object identity from pose and a Transformer-based temporal\naggregator, our approach maintains consistent object representations and\ndynamics across frames. This yields new benchmarks in unsupervised video object\nsegmentation and reconstruction, and supports advanced editing tasks such as\nobject removal, replacement, and insertion without explicit supervision.\n  Overall, this work establishes a general and scalable approach to\nobject-centric generative modeling for images and videos. By bridging human\nobject-based perception and machine learning, it expands the design space for\ninteractive, structured, and user-driven generative tools in creative,\nscientific, and practical domains.", "published": "2025-09-29 12:01:49", "link": "http://arxiv.org/abs/2509.24652v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement", "abstract": "Capturing screens is now routine in our everyday lives. But the photographs\nof emissive displays are often influenced by the flicker-banding (FB), which is\nalternating bright%u2013dark stripes that arise from temporal aliasing between\na camera's rolling-shutter readout and the display's brightness modulation.\nUnlike moire degradation, which has been extensively studied, the FB remains\nunderexplored despite its frequent and severe impact on readability and\nperceived quality. We formulate FB removal as a dedicated restoration task and\nintroduce Removal of Image Flicker-Banding via Latent Diffusion Enhancement,\nRIFLE, a diffusion-based framework designed to remove FB while preserving fine\ndetails. We propose the flicker-banding prior estimator (FPE) that predicts key\nbanding attributes and injects it into the restoration network. Additionally,\nMasked Loss (ML) is proposed to concentrate supervision on banded regions\nwithout sacrificing global fidelity. To overcome data scarcity, we provide a\nsimulation pipeline that synthesizes FB in the luminance domain with stochastic\njitter in banding angle, banding spacing, and banding width. Feathered\nboundaries and sensor noise are also applied for a more realistic simulation.\nFor evaluation, we collect a paired real-world FB dataset with pixel-aligned\nbanding-free references captured via long exposure. Across quantitative metrics\nand visual comparisons on our real-world dataset, RIFLE consistently\noutperforms recent image reconstruction baselines from mild to severe\nflicker-banding. To the best of our knowledge, it is the first work to research\nthe simulation and removal of FB. Our work establishes a great foundation for\nsubsequent research in both the dataset construction and the removal model\ndesign. Our dataset and code will be released soon.", "published": "2025-09-29 11:53:13", "link": "http://arxiv.org/abs/2509.24644v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FreeRet: MLLMs as Training-Free Retrievers", "abstract": "Multimodal large language models (MLLMs) are emerging as versatile\nfoundations for mixed-modality retrieval. Yet, they often require heavy\npost-hoc training to convert them into contrastive encoders for retrieval. This\nwork asks: Can off-the-shelf MLLMs serve as powerful retrievers without\nadditional training? We present FreeRet, a plug-and-play framework that turns\nany MLLM into a two-stage retriever. FreeRet first derives semantically\ngrounded embeddings directly from the model for fast candidate search, and then\nexploits its reasoning ability for precise reranking. The framework contributes\nthree advances: bypassing lexical alignment layers to obtain semantically\nfaithful embeddings, conditioning representation generation with explicit\npriors, and mitigating framing effect in reranking via neutral choice framing.\nOn the MMEB and MMEB-V2 benchmarks spanning 46 datasets, FreeRet substantially\noutperforms models trained on millions of pairs. Beyond benchmarks, FreeRet is\nmodel-agnostic and scales seamlessly across MLLM families and sizes, preserves\ntheir generative abilities, supports arbitrary modality combinations, and\nunifies retrieval, reranking, and generation into end-to-end RAG within a\nsingle model. Our findings demonstrate that pretrained MLLMs, when carefully\nharnessed, can serve as strong retrieval engines without training, closing a\ncritical gap in their role as generalists.", "published": "2025-09-29 11:28:42", "link": "http://arxiv.org/abs/2509.24621v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Biomechanical-phase based Temporal Segmentation in Sports Videos: a Demonstration on Javelin-Throw", "abstract": "Precise analysis of athletic motion is central to sports analytics,\nparticularly in disciplines where nuanced biomechanical phases directly impact\nperformance outcomes. Traditional analytics techniques rely on manual\nannotation or laboratory-based instrumentation, which are time-consuming,\ncostly, and lack scalability. Automatic extraction of relevant kinetic\nvariables requires a robust and contextually appropriate temporal segmentation.\nConsidering the specific case of elite javelin-throw, we present a novel\nunsupervised framework for such a contextually aware segmentation, which\napplies the structured optimal transport (SOT) concept to augment the\nwell-known Attention-based Spatio-Temporal Graph Convolutional Network\n(ASTGCN). This enables the identification of motion phase transitions without\nrequiring expensive manual labeling. Extensive experiments demonstrate that our\napproach outperforms state-of-the-art unsupervised methods, achieving 71.02%\nmean average precision (mAP) and 74.61% F1-score on test data, substantially\nhigher than competing baselines. We also release a new dataset of 211 manually\nannotated professional javelin-throw videos with frame-level annotations,\ncovering key biomechanical phases: approach steps, drive, throw, and recovery.", "published": "2025-09-29 11:11:46", "link": "http://arxiv.org/abs/2509.24606v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Discovering \"Words\" in Music: Unsupervised Learning of Compositional Sparse Code for Symbolic Music", "abstract": "This paper presents an unsupervised machine learning algorithm that\nidentifies recurring patterns -- referred to as ``music-words'' -- from\nsymbolic music data. These patterns are fundamental to musical structure and\nreflect the cognitive processes involved in composition. However, extracting\nthese patterns remains challenging because of the inherent semantic ambiguity\nin musical interpretation. We formulate the task of music-word discovery as a\nstatistical optimization problem and propose a two-stage\nExpectation-Maximization (EM)-based learning framework: 1. Developing a\nmusic-word dictionary; 2. Reconstructing the music data. When evaluated against\nhuman expert annotations, the algorithm achieved an Intersection over Union\n(IoU) score of 0.61. Our findings indicate that minimizing code length\neffectively addresses semantic ambiguity, suggesting that human optimization of\nencoding systems shapes musical semantics. This approach enables computers to\nextract ``basic building blocks'' from music data, facilitating structural\nanalysis and sparse encoding. The method has two primary applications. First,\nin AI music, it supports downstream tasks such as music generation,\nclassification, style transfer, and improvisation. Second, in musicology, it\nprovides a tool for analyzing compositional patterns and offers insights into\nthe principle of minimal encoding across diverse musical styles and composers.", "published": "2025-09-29 11:10:57", "link": "http://arxiv.org/abs/2509.24603v1", "categories": ["cs.SD", "cs.CV"], "primary_category": "cs.SD"}
{"title": "Comprehensive Benchmarking of YOLOv11 Architectures for Scalable and Granular Peripheral Blood Cell Detection", "abstract": "Manual peripheral blood smear (PBS) analysis is labor intensive and\nsubjective. While deep learning offers a promising alternative, a systematic\nevaluation of state of the art models such as YOLOv11 for fine grained PBS\ndetection is still lacking. In this work, we make two key contributions. First,\nwe curate a large scale annotated dataset for blood cell detection and\nclassification, comprising 16,891 images across 12 peripheral blood cell (PBC)\nclasses, along with the red blood cell class, all carefully re annotated for\nobject detection tasks. In total, the dataset contains 298,850 annotated cells.\nSecond, we leverage this dataset to conduct a comprehensive evaluation of five\nYOLOv11 variants (ranging from Nano to XLarge). These models are rigorously\nbenchmarked under two data splitting strategies (70:20:10 and 80:10:10) and\nsystematically assessed using multiple performance criteria, including mean\nAverage Precision (mAP), precision, recall, F1 score, and computational\nefficiency. Our experiments show that the YOLOv11 Medium variant achieves the\nbest trade off, reaching a mAP@0.5 of 0.934 under the 8:1:1 split. Larger\nmodels (Large and XLarge) provide only marginal accuracy gains at substantially\nhigher computational cost. Moreover, the 8:1:1 split consistently outperforms\nthe 7:2:1 split across all models. These findings highlight YOLOv11,\nparticularly the Medium variant, as a highly effective framework for automated,\nfine grained PBS detection. Beyond benchmarking, our publicly released dataset\n(github.com/Mohamad-AbouAli/OI-PBC-Dataset) offers a valuable resource to\nadvance research on blood cell detection and classification in hematology.", "published": "2025-09-29 11:00:19", "link": "http://arxiv.org/abs/2509.24595v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAIP: A Plug-and-Play Scale-adaptive Module in Diffusion-based Inverse Problems", "abstract": "Solving inverse problems with diffusion models has shown promise in tasks\nsuch as image restoration. A common approach is to formulate the problem in a\nBayesian framework and sample from the posterior by combining the prior score\nwith the likelihood score. Since the likelihood term is often intractable,\nestimators like DPS, DMPS, and $\\pi$GDM are widely adopted. However, these\nmethods rely on a fixed, manually tuned scale to balance prior and likelihood\ncontributions. Such a static design is suboptimal, as the ideal balance varies\nacross timesteps and tasks, limiting performance and generalization. To address\nthis issue, we propose SAIP, a plug-and-play module that adaptively refines the\nscale at each timestep without retraining or altering the diffusion backbone.\nSAIP integrates seamlessly into existing samplers and consistently improves\nreconstruction quality across diverse image restoration tasks, including\nchallenging scenarios.", "published": "2025-09-29 10:41:20", "link": "http://arxiv.org/abs/2509.24580v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "BFSM: 3D Bidirectional Face-Skull Morphable Model", "abstract": "Building a joint face-skull morphable model holds great potential for\napplications such as remote diagnostics, surgical planning, medical education,\nand physically based facial simulation. However, realizing this vision is\nconstrained by the scarcity of paired face-skull data, insufficient\nregistration accuracy, and limited exploration of reconstruction and clinical\napplications. Moreover, individuals with craniofacial deformities are often\noverlooked, resulting in underrepresentation and limited inclusivity. To\naddress these challenges, we first construct a dataset comprising over 200\nsamples, including both normal cases and rare craniofacial conditions. Each\ncase contains a CT-based skull, a CT-based face, and a high-fidelity textured\nface scan. Secondly, we propose a novel dense ray matching registration method\nthat ensures topological consistency across face, skull, and their tissue\ncorrespondences. Based on this, we introduce the 3D Bidirectional Face-Skull\nMorphable Model (BFSM), which enables shape inference between the face and\nskull through a shared coefficient space, while also modeling tissue thickness\nvariation to support one-to-many facial reconstructions from the same skull,\nreflecting individual changes such as fat over time. Finally, we demonstrate\nthe potential of BFSM in medical applications, including 3D face-skull\nreconstruction from a single image and surgical planning prediction. Extensive\nexperiments confirm the robustness and accuracy of our method. BFSM is\navailable at https://github.com/wang-zidu/BFSM", "published": "2025-09-29 10:34:13", "link": "http://arxiv.org/abs/2509.24577v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics", "abstract": "Object manipulation requires accurate object pose estimation. In open\nenvironments, robots encounter unknown objects, which requires semantic\nunderstanding in order to generalize both to known categories and beyond. To\nresolve this challenge, we present SCOPE, a diffusion-based category-level\nobject pose estimation model that eliminates the need for discrete category\nlabels by leveraging DINOv2 features as continuous semantic priors. By\ncombining these DINOv2 features with photorealistic training data and a noise\nmodel for point normals, we reduce the Sim2Real gap in category-level object\npose estimation. Furthermore, injecting the continuous semantic priors via\ncross-attention enables SCOPE to learn canonicalized object coordinate systems\nacross object instances beyond the distribution of known categories. SCOPE\noutperforms the current state of the art in synthetically trained\ncategory-level object pose estimation, achieving a relative improvement of\n31.9\\% on the 5$^\\circ$5cm metric. Additional experiments on two instance-level\ndatasets demonstrate generalization beyond known object categories, enabling\ngrasping of unseen objects from unknown categories with a success rate of up to\n100\\%. Code available: https://github.com/hoenigpeter/scope.", "published": "2025-09-29 10:27:59", "link": "http://arxiv.org/abs/2509.24572v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models", "abstract": "Large vision-language models (LVLMs) have achieved impressive performance\nacross a wide range of vision-language tasks, while they remain vulnerable to\nbackdoor attacks. Existing backdoor attacks on LVLMs aim to force the victim\nmodel to generate a predefined target pattern, which is either inserted into or\nreplaces the original content. We find that these fixed-pattern attacks are\nrelatively easy to detect, because the attacked LVLM tends to memorize such\nfrequent patterns in the training dataset, thereby exhibiting overconfidence on\nthese targets given poisoned inputs. To address these limitations, we introduce\nTokenSwap, a more evasive and stealthy backdoor attack that focuses on the\ncompositional understanding capabilities of LVLMs. Instead of enforcing a fixed\ntargeted content, TokenSwap subtly disrupts the understanding of object\nrelationships in text. Specifically, it causes the backdoored model to generate\noutputs that mention the correct objects in the image but misrepresent their\nrelationships (i.e., bags-of-words behavior). During training, TokenSwap\ninjects a visual trigger into selected samples and simultaneously swaps the\ngrammatical roles of key tokens in the corresponding textual answers. However,\nthe poisoned samples exhibit only subtle differences from the original ones,\nmaking it challenging for the model to learn the backdoor behavior. To address\nthis, TokenSwap employs an adaptive token-weighted loss that explicitly\nemphasizes the learning of swapped tokens, such that the visual triggers and\nbags-of-words behavior are associated. Extensive experiments demonstrate that\nTokenSwap achieves high attack success rates while maintaining superior\nevasiveness and stealthiness across multiple benchmarks and various LVLM\narchitectures.", "published": "2025-09-29 10:19:22", "link": "http://arxiv.org/abs/2509.24566v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Foggy Crowd Counting: Combining Physical Priors and KAN-Graph", "abstract": "Aiming at the key challenges of crowd counting in foggy environments, such as\nlong-range target blurring, local feature degradation, and image contrast\nattenuation, this paper proposes a crowd-counting method with a physical a\npriori of atmospheric scattering, which improves crowd counting accuracy under\ncomplex meteorological conditions through the synergistic optimization of the\nphysical mechanism and data-driven.Specifically, first, the method introduces a\ndifferentiable atmospheric scattering model and employs transmittance dynamic\nestimation and scattering parameter adaptive calibration techniques to\naccurately quantify the nonlinear attenuation laws of haze on targets with\ndifferent depths of field.Secondly, the MSA-KAN was designed based on the\nKolmogorov-Arnold Representation Theorem to construct a learnable edge\nactivation function. By integrating a multi-layer progressive architecture with\nadaptive skip connections, it significantly enhances the model's nonlinear\nrepresentation capability in feature-degraded regions, effectively suppressing\nfeature confusion under fog interference.Finally, we further propose a\nweather-aware GCN that dynamically constructs spatial adjacency matrices using\ndeep features extracted by MSA-KAN. Experiments on four public datasets\ndemonstrate that our method achieves a 12.2\\%-27.5\\% reduction in MAE metrics\ncompared to mainstream algorithms in dense fog scenarios.", "published": "2025-09-29 09:59:36", "link": "http://arxiv.org/abs/2509.24545v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion Bridge or Flow Matching? A Unifying Framework and Comparative Analysis", "abstract": "Diffusion Bridge and Flow Matching have both demonstrated compelling\nempirical performance in transformation between arbitrary distributions.\nHowever, there remains confusion about which approach is generally preferable,\nand the substantial discrepancies in their modeling assumptions and practical\nimplementations have hindered a unified theoretical account of their relative\nmerits. We have, for the first time, provided a unified theoretical and\nexperimental validation of these two models. We recast their frameworks through\nthe lens of Stochastic Optimal Control and prove that the cost function of the\nDiffusion Bridge is lower, guiding the system toward more stable and natural\ntrajectories. Simultaneously, from the perspective of Optimal Transport,\ninterpolation coefficients $t$ and $1-t$ of Flow Matching become increasingly\nineffective when the training data size is reduced. To corroborate these\ntheoretical claims, we propose a novel, powerful architecture for Diffusion\nBridge built on a latent Transformer, and implement a Flow Matching model with\nthe same structure to enable a fair performance comparison in various\nexperiments. Comprehensive experiments are conducted across Image Inpainting,\nSuper-Resolution, Deblurring, Denoising, Translation, and Style Transfer tasks,\nsystematically varying both the distributional discrepancy (different\ndifficulty) and the training data size. Extensive empirical results align\nperfectly with our theoretical predictions and allow us to delineate the\nrespective advantages and disadvantages of these two models. Our code is\navailable at https://anonymous.4open.science/r/DBFM-3E8E/.", "published": "2025-09-29 09:45:22", "link": "http://arxiv.org/abs/2509.24531v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D", "abstract": "3D scene understanding is fundamental for embodied AI and robotics,\nsupporting reliable perception for interaction and navigation. Recent\napproaches achieve zero-shot, open-vocabulary 3D semantic mapping by assigning\nembedding vectors to 2D class-agnostic masks generated via vision-language\nmodels (VLMs) and projecting these into 3D. However, these methods often\nproduce fragmented masks and inaccurate semantic assignments due to the direct\nuse of raw masks, limiting their effectiveness in complex environments. To\naddress this, we leverage SemanticSAM with progressive granularity refinement\nto generate more accurate and numerous object-level masks, mitigating the\nover-segmentation commonly observed in mask generation models such as vanilla\nSAM, and improving downstream 3D semantic segmentation. To further enhance\nsemantic context, we employ a context-aware CLIP encoding strategy that\nintegrates multiple contextual views of each mask using empirically determined\nweighting, providing much richer visual context. We evaluate our approach on\nmultiple 3D scene understanding tasks, including 3D semantic segmentation and\nobject retrieval from language queries, across several benchmark datasets.\nExperimental results demonstrate significant improvements over existing\nmethods, highlighting the effectiveness of our approach.", "published": "2025-09-29 09:43:00", "link": "http://arxiv.org/abs/2509.24528v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CMT: Mid-Training for Efficient Learning of Consistency, Mean Flow, and Flow Map Models", "abstract": "Flow map models such as Consistency Models (CM) and Mean Flow (MF) enable\nfew-step generation by learning the long jump of the ODE solution of diffusion\nmodels, yet training remains unstable, sensitive to hyperparameters, and\ncostly. Initializing from a pre-trained diffusion model helps, but still\nrequires converting infinitesimal steps into a long-jump map, leaving\ninstability unresolved. We introduce mid-training, the first concept and\npractical method that inserts a lightweight intermediate stage between the\n(diffusion) pre-training and the final flow map training (i.e., post-training)\nfor vision generation. Concretely, Consistency Mid-Training (CMT) is a compact\nand principled stage that trains a model to map points along a solver\ntrajectory from a pre-trained model, starting from a prior sample, directly to\nthe solver-generated clean sample. It yields a trajectory-consistent and stable\ninitialization. This initializer outperforms random and diffusion-based\nbaselines and enables fast, robust convergence without heuristics. Initializing\npost-training with CMT weights further simplifies flow map learning.\nEmpirically, CMT achieves state of the art two step FIDs: 1.97 on CIFAR-10,\n1.32 on ImageNet 64x64, and 1.84 on ImageNet 512x512, while using up to 98%\nless training data and GPU time, compared to CMs. On ImageNet 256x256, CMT\nreaches 1-step FID 3.34 while cutting total training time by about 50% compared\nto MF from scratch (FID 3.43). This establishes CMT as a principled, efficient,\nand general framework for training flow map models.", "published": "2025-09-29 09:42:08", "link": "http://arxiv.org/abs/2509.24526v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Instruction Guided Multi Object Image Editing with Quantity and Layout Consistency", "abstract": "Instruction driven image editing with standard CLIP text encoders often fails\nin complex scenes with many objects. We present QL-Adapter, a framework for\nmultiple object editing that tackles two challenges: enforcing object counts\nand spatial layouts, and accommodating diverse categories. QL-Adapter consists\nof two core modules: the Image-Layout Fusion Module (ILFM) and the Cross-Modal\nAugmentation Module (CMAM). ILFM fuses layout priors with ViT patch tokens from\nthe CLIP image encoder to strengthen spatial structure understanding. CMAM\ninjects image features into the text branch to enrich textual embeddings and\nimprove instruction following. We further build QL-Dataset, a benchmark that\nspans broad category, layout, and count variations, and define the task of\nquantity and layout consistent image editing (QL-Edit). Extensive experiments\nshow that QL-Adapter achieves state of the art performance on QL-Edit and\nsignificantly outperforms existing models.", "published": "2025-09-29 09:33:51", "link": "http://arxiv.org/abs/2509.24514v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Multimodal Semantic Segmentation with Balanced Modality Contributions", "abstract": "Multimodal semantic segmentation enhances model robustness by exploiting\ncross-modal complementarities. However, existing methods often suffer from\nimbalanced modal dependencies, where overall performance degrades significantly\nonce a dominant modality deteriorates in real-world scenarios. Thus, modality\nbalance has become acritical challenge for practical multimodal segmentation.\nTo address this issue, we propose EQUISeg, a multimodal segmentation framework\nthat balances modality contributions through equal encoding of modalities.\nBuilt upon a four-stage Cross-modal Transformer Block(CMTB), EQUISeg enables\nefficient multimodal fusion and hierarchical selection. Furthermore, we design\na Self-guided Module(SGM) that mitigates modality imbalance by introducing a\nmutual guidance mechanism, enabling each modality to adaptively adjust its\ncontribution and enhance robustness under degraded conditions. Extensive\nexperiments on multiple datasets demonstrate that EQUISeg achieves significant\nperformance gains and effectively alleviates the adverse effects of modality\nimbalance in segmentation tasks.", "published": "2025-09-29 09:19:10", "link": "http://arxiv.org/abs/2509.24505v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Novel Preprocessing Unit for Effective Deep Learning based Classification and Grading of Diabetic Retinopathy", "abstract": "Early detection of diabetic retinopathy (DR) is crucial as it allows for\ntimely intervention, preventing vision loss and enabling effective management\nof diabetic complications. This research performs detection of DR and DME at an\nearly stage through the proposed framework which includes three stages:\npreprocessing, segmentation, feature extraction, and classification. In the\npreprocessing stage, noise filtering is performed by fuzzy filtering, artefact\nremoval is performed by non-linear diffusion filtering, and the contrast\nimprovement is performed by a novel filter called Adaptive Variable Distance\nSpeckle (AVDS) filter. The AVDS filter employs four distance calculation\nmethods such as Euclidean, Bhattacharya, Manhattan, and Hamming. The filter\nadaptively chooses a distance method which produces the highest contrast value\namongst all 3 methods. From the analysis, hamming distance method was found to\nachieve better results for contrast and Euclidean distance showing less error\nvalue with high PSNR. The segmentation stage is performed using Improved\nMask-Regional Convolutional Neural Networks (Mask RCNN). In the final stage,\nfeature extraction and classification using novel Self-Spatial Attention\ninfused VGG-16 (SSA-VGG-16), which effectively captures both global contextual\nrelationships and critical spatial regions within retinal images, thereby\nimproving the accuracy and robustness of DR and DME detection and grading. The\neffectiveness of the proposed method is assessed using two distinct datasets:\nIDRiD and MESSIDOR.", "published": "2025-09-29 09:11:04", "link": "http://arxiv.org/abs/2509.24497v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization in MLLMs", "abstract": "Multimodal Large Language Models (MLLMs) have significantly improved the\nperformance of various tasks, but continue to suffer from visual\nhallucinations, a critical issue where generated responses contradict visual\nevidence. While Direct Preference Optimization(DPO) is widely used for\nalignment, its application to MLLMs often fails to capture fine-grained\nsemantic differences and encourages shortcut learning. To address these\nchallenges, we propose Semantic Curriculum Preference Optimization (SCPO), a\nnovel framework for MLLM alignment. SCPO employs a progressive, easy-to-hard\ncurriculum built upon our Semantic Curriculum Preference Pairs dataset, which\nprovides fine-grained semantic contrasts sorted by difficulty. This curriculum\nis trained with a dynamic reference model and a novel symmetric, bidirectional\nobjective to facilitate simultaneous learning from both textual and visual\npreferences. To our knowledge, SCPO is the first framework to unify semantics,\nsymmetry, and curriculum for MLLMs alignment, effectively mitigating visual\nhallucinations. Extensive experiments on LLaVA models across various scales and\nversions validate that SCPO demonstrates superior performance compared to\nbaseline models on multiple hallucination benchmarks, reducing the\nhallucination rate by up to 62.9%. Moreover, evaluations on generalized\nbenchmarks show that SCPO improves factuality while preserving general\ncapabilities, with its performance remaining stable across general\nvision-language benchmarks.", "published": "2025-09-29 09:03:36", "link": "http://arxiv.org/abs/2509.24491v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Performance-Efficiency Trade-off for Fashion Image Retrieval", "abstract": "The fashion industry has been identified as a major contributor to waste and\nemissions, leading to an increased interest in promoting the second-hand\nmarket. Machine learning methods play an important role in facilitating the\ncreation and expansion of second-hand marketplaces by enabling the large-scale\nvaluation of used garments. We contribute to this line of work by addressing\nthe scalability of second-hand image retrieval from databases. By introducing a\nselective representation framework, we can shrink databases to 10% of their\noriginal size without sacrificing retrieval accuracy. We first explore\nclustering and coreset selection methods to identify representative samples\nthat capture the key features of each garment and its internal variability.\nThen, we introduce an efficient outlier removal method, based on a\nneighbour-homogeneity consistency score measure, that filters out\nuncharacteristic samples prior to selection. We evaluate our approach on three\npublic datasets: DeepFashion Attribute, DeepFashion Con2Shop, and DeepFashion2.\nThe results demonstrate a clear performance-efficiency trade-off by\nstrategically pruning and selecting representative vectors of images. The\nretrieval system maintains near-optimal accuracy, while greatly reducing\ncomputational costs by reducing the images added to the vector database.\nFurthermore, applying our outlier removal method to clustering techniques\nyields even higher retrieval performance by removing non-discriminative samples\nbefore the selection.", "published": "2025-09-29 08:51:04", "link": "http://arxiv.org/abs/2509.24477v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LaMoGen: Laban Movement-Guided Diffusion for Text-to-Motion Generation", "abstract": "Diverse human motion generation is an increasingly important task, having\nvarious applications in computer vision, human-computer interaction and\nanimation. While text-to-motion synthesis using diffusion models has shown\nsuccess in generating high-quality motions, achieving fine-grained expressive\nmotion control remains a significant challenge. This is due to the lack of\nmotion style diversity in datasets and the difficulty of expressing\nquantitative characteristics in natural language. Laban movement analysis has\nbeen widely used by dance experts to express the details of motion including\nmotion quality as consistent as possible. Inspired by that, this work aims for\ninterpretable and expressive control of human motion generation by seamlessly\nintegrating the quantification methods of Laban Effort and Shape components\ninto the text-guided motion generation models. Our proposed zero-shot,\ninference-time optimization method guides the motion generation model to have\ndesired Laban Effort and Shape components without any additional motion data by\nupdating the text embedding of pretrained diffusion models during the sampling\nstep. We demonstrate that our approach yields diverse expressive motion\nqualities while preserving motion identity by successfully manipulating motion\nattributes according to target Laban tags.", "published": "2025-09-29 08:48:49", "link": "http://arxiv.org/abs/2509.24469v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generalist Multi-Class Anomaly Detection via Distillation to Two Heterogeneous Student Networks", "abstract": "Anomaly detection (AD) plays an important role in various real-world\napplications. Recent advancements in AD, however, are often biased towards\nindustrial inspection, struggle to generalize to broader tasks like semantic\nanomaly detection and vice versa. Although recent methods have attempted to\naddress general anomaly detection, their performance remains sensitive to\ndataset-specific settings and single-class tasks. In this paper, we propose a\nnovel dual-model ensemble approach based on knowledge distillation (KD) to\nbridge this gap. Our framework consists of a teacher and two student models: an\nEncoder-Decoder model, specialized in detecting patch-level minor defects for\nindustrial AD and an Encoder-Encoder model, optimized for semantic AD. Both\nmodels leverage a shared pre-trained encoder (DINOv2) to extract high-quality\nfeature representations. The dual models are jointly learned using the Noisy-OR\nobjective, and the final anomaly score is obtained using the joint probability\nvia local and semantic anomaly scores derived from the respective models. We\nevaluate our method on eight public benchmarks under both single-class and\nmulti-class settings: MVTec-AD, MVTec-LOCO, VisA and Real-IAD for industrial\ninspection and CIFAR-10/100, FMNIST and View for semantic anomaly detection.\nThe proposed method achieved state-of-the-art accuracies in both domains, in\nmulti-class as well as single-class settings, demonstrating generalization\nacross multiple domains of anomaly detection. Our model achieved an image-level\nAUROC of 99.7% on MVTec-AD and 97.8% on CIFAR-10, which is significantly better\nthan the prior general AD models in multi-class settings and even higher than\nthe best specialist models on individual benchmarks.", "published": "2025-09-29 08:31:31", "link": "http://arxiv.org/abs/2509.24448v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NeoWorld: Neural Simulation of Explorable Virtual Worlds via Progressive 3D Unfolding", "abstract": "We introduce NeoWorld, a deep learning framework for generating interactive\n3D virtual worlds from a single input image. Inspired by the on-demand\nworldbuilding concept in the science fiction novel Simulacron-3 (1964), our\nsystem constructs expansive environments where only the regions actively\nexplored by the user are rendered with high visual realism through\nobject-centric 3D representations. Unlike previous approaches that rely on\nglobal world generation or 2D hallucination, NeoWorld models key foreground\nobjects in full 3D, while synthesizing backgrounds and non-interacted regions\nin 2D to ensure efficiency. This hybrid scene structure, implemented with\ncutting-edge representation learning and object-to-3D techniques, enables\nflexible viewpoint manipulation and physically plausible scene animation,\nallowing users to control object appearance and dynamics using natural language\ncommands. As users interact with the environment, the virtual world\nprogressively unfolds with increasing 3D detail, delivering a dynamic,\nimmersive, and visually coherent exploration experience. NeoWorld significantly\noutperforms existing 2D and depth-layered 2.5D methods on the WorldScore\nbenchmark.", "published": "2025-09-29 08:24:28", "link": "http://arxiv.org/abs/2509.24441v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UI2V-Bench: An Understanding-based Image-to-video Generation Benchmark", "abstract": "Generative diffusion models are developing rapidly and attracting increasing\nattention due to their wide range of applications. Image-to-Video (I2V)\ngeneration has become a major focus in the field of video synthesis. However,\nexisting evaluation benchmarks primarily focus on aspects such as video quality\nand temporal consistency, while largely overlooking the model's ability to\nunderstand the semantics of specific subjects in the input image or to ensure\nthat the generated video aligns with physical laws and human commonsense. To\naddress this gap, we propose UI2V-Bench, a novel benchmark for evaluating I2V\nmodels with a focus on semantic understanding and reasoning. It introduces four\nprimary evaluation dimensions: spatial understanding, attribute binding,\ncategory understanding, and reasoning. To assess these dimensions, we design\ntwo evaluation methods based on Multimodal Large Language Models (MLLMs): an\ninstance-level pipeline for fine-grained semantic understanding, and a\nfeedback-based reasoning pipeline that enables step-by-step causal assessment\nfor more accurate evaluation. UI2V-Bench includes approximately 500 carefully\nconstructed text-image pairs and evaluates a range of both open source and\nclosed-source I2V models across all defined dimensions. We further incorporate\nhuman evaluations, which show strong alignment with the proposed MLLM-based\nmetrics. Overall, UI2V-Bench fills a critical gap in I2V evaluation by\nemphasizing semantic comprehension and reasoning ability, offering a robust\nframework and dataset to support future research and model development in the\nfield.", "published": "2025-09-29 08:14:26", "link": "http://arxiv.org/abs/2509.24427v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Unsupervised Cross-modal Flow Estimation: Learning from Decoupled Optimization and Consistency Constraint", "abstract": "This work presents DCFlow, a novel unsupervised cross-modal flow estimation\nframework that integrates a decoupled optimization strategy and a cross-modal\nconsistency constraint. Unlike previous approaches that implicitly learn flow\nestimation solely from appearance similarity, we introduce a decoupled\noptimization strategy with task-specific supervision to address modality\ndiscrepancy and geometric misalignment distinctly. This is achieved by\ncollaboratively training a modality transfer network and a flow estimation\nnetwork. To enable reliable motion supervision without ground-truth flow, we\npropose a geometry-aware data synthesis pipeline combined with an\noutlier-robust loss. Additionally, we introduce a cross-modal consistency\nconstraint to jointly optimize both networks, significantly improving flow\nprediction accuracy. For evaluation, we construct a comprehensive cross-modal\nflow benchmark by repurposing public datasets. Experimental results demonstrate\nthat DCFlow can be integrated with various flow estimation networks and\nachieves state-of-the-art performance among unsupervised approaches.", "published": "2025-09-29 08:10:41", "link": "http://arxiv.org/abs/2509.24423v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exercises in Iterational Asymptotics IV", "abstract": "Abel's functional equation for $2^{x/2}$ and half-iterates of $\\lambda x\n(1-x)$ & $\\sqrt{1+x}$ are featured in this collection of exercises ($0 <\n\\lambda \\neq 1 < 2$).", "published": "2025-09-29 15:22:56", "link": "http://arxiv.org/abs/2509.24918v1", "categories": ["math.NT", "cs.DM", "11B37 (Primary) 26A18, 39B22, 39-08, 41A60, 65Q20 (Secondary)"], "primary_category": "math.NT"}
{"title": "Tree-based formulation for the multi-commodity flow problem", "abstract": "We introduce a tree-based formulation for the minimum-cost multi-commodity\nflow problem that addresses large-scale instances. The method decomposes the\nsource-based model by representing flows as convex combinations of trees rooted\nat source nodes, and solves the resulting formulation with column generation.\nThe number of demand constraints now depends on the number of sources $|S|$,\nnot commodities $|K|$, yielding a compact master problem when $|S| \\ll |K|$. We\nconduct a computational study comparing tree-based decomposition against\npath-based column generation and direct LP solving. The results show speed-ups\nof up to one order of magnitude over direct LP solving, and improved\nscalability compared to path-based formulations. Tree-based decomposition\nenables solving instances with millions of commodities and hundreds of\nthousands of nodes. This makes it well-suited for applications in\ntransportation and logistics networks where multiple demands often share common\norigins.", "published": "2025-09-29 12:04:22", "link": "http://arxiv.org/abs/2509.24656v1", "categories": ["math.OC", "cs.DM"], "primary_category": "math.OC"}
{"title": "Optimally revealing bits for rejection sampling", "abstract": "Rejection sampling is a popular method used to generate numbers that follow\nsome given distribution. We study the use of this method to generate random\nnumbers in the unit interval from increasing probability density functions. We\nfocus on the problem of sampling from $n$ correlated random variables from a\njoint distribution whose marginal distributions are all increasing. We show\nthat, in the worst case, the expected number of random bits required to accept\nor reject a sample grows at least linearly and at most quadratically with $n$.", "published": "2025-09-29 05:09:07", "link": "http://arxiv.org/abs/2509.24290v1", "categories": ["cs.DS", "cs.DM", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.DS"}
{"title": "Efficient Sketching and Nearest Neighbor Search Algorithms for Sparse Vector Sets", "abstract": "Sparse embeddings of data form an attractive class due to their inherent\ninterpretability: Every dimension is tied to a term in some vocabulary, making\nit easy to visually decipher the latent space. Sparsity, however, poses unique\nchallenges for Approximate Nearest Neighbor Search (ANNS) which finds, from a\ncollection of vectors, the k vectors closest to a query. To encourage research\non this underexplored topic, sparse ANNS featured prominently in a BigANN\nChallenge at NeurIPS 2023, where approximate algorithms were evaluated on large\nbenchmark datasets by throughput and accuracy. In this work, we introduce a set\nof novel data structures and algorithmic methods, a combination of which leads\nto an elegant, effective, and highly efficient solution to sparse ANNS. Our\ncontributions range from a theoretically-grounded sketching algorithm for\nsparse vectors to reduce their effective dimensionality while preserving inner\nproduct-induced ranks; a geometric organization of the inverted index; and the\nblending of local and global information to improve the efficiency and efficacy\nof ANNS. Empirically, our final algorithm, dubbed Seismic, reaches\nsub-millisecond per-query latency with high accuracy on a large-scale benchmark\ndataset using a single CPU.", "published": "2025-09-29 14:02:45", "link": "http://arxiv.org/abs/2509.24815v1", "categories": ["cs.DS", "cs.IR", "cs.LG"], "primary_category": "cs.DS"}
{"title": "UniDex: Rethinking Search Inverted Indexing with Unified Semantic Modeling", "abstract": "Inverted indexing has traditionally been a cornerstone of modern search\nsystems, leveraging exact term matches to determine relevance between queries\nand documents. However, this term-based approach often emphasizes surface-level\ntoken overlap, limiting the system's generalization capabilities and retrieval\neffectiveness. To address these challenges, we propose UniDex, a novel\nmodel-based method that employs unified semantic modeling to revolutionize\ninverted indexing. UniDex replaces complex manual designs with a streamlined\narchitecture, enhancing semantic generalization while reducing maintenance\noverhead. Our approach involves two key components: UniTouch, which maps\nqueries and documents into semantic IDs for improved retrieval, and UniRank,\nwhich employs semantic matching to rank results effectively. Through\nlarge-scale industrial datasets and real-world online traffic assessments, we\ndemonstrate that UniDex significantly improves retrieval capabilities, marking\na paradigm shift from term-based to model-based indexing. Our deployment within\nKuaishou's short-video search systems further validates UniDex's practical\neffectiveness, serving hundreds of millions of active users efficiently.", "published": "2025-09-29 11:41:12", "link": "http://arxiv.org/abs/2509.24632v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multi-Item-Query Attention for Stable Sequential Recommendation", "abstract": "The inherent instability and noise in user interaction data challenge\nsequential recommendation systems. Prevailing masked attention models, relying\non a single query from the most recent item, are sensitive to this noise,\nreducing prediction reliability. We propose the Multi-Item-Query attention\nmechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn\nconstructs multiple diverse query vectors from user interactions, effectively\nmitigating noise and improving consistency. It is designed for easy adoption as\na drop-in replacement for existing single-query attention. Experiments show\nMIQ-Attn significantly improves performance on benchmark datasets.", "published": "2025-09-29 08:11:27", "link": "http://arxiv.org/abs/2509.24424v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play", "abstract": "Search-augmented LLMs often struggle with complex reasoning tasks due to\nineffective multi-hop retrieval and limited reasoning ability. We propose\nAceSearcher, a cooperative self-play framework that trains a single large\nlanguage model (LLM) to alternate between two roles: a decomposer that breaks\ndown complex queries and a solver that integrates retrieved contexts for answer\ngeneration. AceSearcher couples supervised fine-tuning on a diverse mixture of\nsearch, reasoning, and decomposition tasks with reinforcement fine-tuning\noptimized for final answer accuracy, eliminating the need for intermediate\nannotations. Extensive experiments on three reasoning-intensive tasks across 10\ndatasets show that AceSearcher outperforms state-of-the-art baselines,\nachieving an average exact match improvement of 7.6%. Remarkably, on\ndocument-level finance reasoning tasks, AceSearcher-32B matches the performance\nof the DeepSeek-V3 model using less than 5% of its parameters. Even at smaller\nscales (1.5B and 8B), AceSearcher often surpasses existing search-augmented\nLLMs with up to 9x more parameters, highlighting its exceptional efficiency and\neffectiveness in tackling complex reasoning tasks. Our code will be published\nat https://github.com/ritaranx/AceSearcher and\nhttps://huggingface.co/AceSearcher.", "published": "2025-09-29 02:14:30", "link": "http://arxiv.org/abs/2509.24193v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsourced Random Access", "abstract": "Current wireless networks are designed to optimize spectral efficiency for\nhuman users, who typically require sustained connections for high-data-rate\napplications like file transfers and video streaming. However, these networks\nare increasingly inadequate for the emerging era of machine-type communications\n(MTC). With a vast number of devices exhibiting sporadic traffic patterns\nconsisting of short packets, the grant-based multiple access procedures\nutilized by existing networks lead to significant delays and inefficiencies. To\naddress this issue the unsourced random access (URA) paradigm has been\nproposed. This paradigm assumes the devices to share a common encoder thus\nsimplifying the reception process by eliminating the identification procedure.\nThe URA paradigm not only addresses the computational challenges but it also\nconsiders the random access (RA) as a coding problem, i.e., takes into account\nboth medium access protocols and physical layer effects. In this monograph we\nprovide a comprehensive overview of the URA problem in noisy channels, with the\nmain task being to explain the major ideas rather than to list all existing\nsolutions.", "published": "2025-09-29 17:17:22", "link": "http://arxiv.org/abs/2509.25074v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacity Achieving Design for Hybrid Beamforming in Millimeter Wave Massive MIMO Systems", "abstract": "Hybrid digital and analog beamforming is a highly effective technique for\nimplementing beamforming methods in millimeter wave (mmWave) systems. It\nprovides a viable solution to replace the complex fully digital beamforming\ntechniques. However, the current design of precoding and combining matrices in\nhybrid beamforming solely relies on the channel information, neglecting the\ncrucial consideration of the structure of covariance matrices of the transmit\nsignals. In this paper, we present a novel approach for the joint design of\nhybrid beamforming matrices at the transmitter and receiver. This approach is\ncentered around the optimization of the covariance matrix of the transmitted\nsignals. Our goal is to maximize the downlink sum rate capacity of the system\nby achieving an optimal design of the transmit covariance matrix. We tackle the\nnon-convex nature of this problem by leveraging the dual relationship between\nthe broadcast channel (BC) and the multiple access channel (MAC). Through\nextensive simulations in various scenarios, including point-to-point\nmulti-input multi-output (MIMO), multi-user (MU) multi-input single-output\n(MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over\ntraditional designs. These results highlight the effectiveness and versatility\nof our approach in optimizing beamforming for mmWave systems.", "published": "2025-09-29 17:13:18", "link": "http://arxiv.org/abs/2509.25067v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Inductive Bias and Spectral Properties of Single-Head Attention in High Dimensions", "abstract": "We study empirical risk minimization in a single-head tied-attention layer\ntrained on synthetic high-dimensional sequence tasks, given by the recently\nintroduced attention-indexed model. Using tools from random matrix theory,\nspin-glass physics, and approximate message passing, we derive sharp\nasymptotics for training and test errors, locate interpolation and recovery\nthresholds, and characterize the limiting spectral distribution of the learned\nweights. Weight decay induces an implicit nuclear-norm regularization, favoring\nlow-rank query and key matrices. Leveraging this, we compare the standard\nfactorized training of query and key matrices with a direct parameterization in\nwhich their product is trained element-wise, revealing the inductive bias\nintroduced by the factorized form. Remarkably, the predicted spectral\ndistribution echoes empirical trends reported in large-scale transformers,\noffering a theoretical perspective consistent with these phenomena.", "published": "2025-09-29 15:19:31", "link": "http://arxiv.org/abs/2509.24914v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Physical Layer Security over Fluid Reconfigurable Intelligent Surface-assisted Communication Systems", "abstract": "This letter investigates the secrecy performance of wireless communication\nsystems assisted by a fluid reconfigurable intelligent surface (FRIS). Unlike\nconventional reconfigurable intelligent surfaces (RISs) with fixed geometries,\nFRISs dynamically select a subset of reflective elements based on real-time\nchannel conditions, offering enhanced spatial diversity and adaptability. Using\nthis foundation, we model a secure downlink scenario where a base station\ncommunicates with a legitimate user in the presence of an eavesdropper, and the\npropagation is assisted by a FRIS with a limited number of elements set to the\nON state. We analyze the system's secrecy performance under spatial correlation\nby deriving analytical lower and upper bounds for the secrecy outage\nprobability (SOP) and average secrecy capacity (ASC), respectively. Our results\ndemonstrate that FRIS effectively enables secure communication under spatial\ncorrelation. Even with partial activation, FRIS significantly outperforms\nconventional RISs in enhancing secrecy performance under varying deployment\ndensities and element correlations.", "published": "2025-09-29 14:28:02", "link": "http://arxiv.org/abs/2509.24845v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Error Rate of Binary BCH Codes under Error-and-erasure Decoding", "abstract": "Determining the exact decoding error probability of linear block codes is an\ninteresting problem. For binary BCH codes, McEliece derived methods to estimate\nthe error probability of a simple bounded distance decoding (BDD) for BCH\ncodes. However, BDD falls short in many applications. In this work, we consider\nerror-and-erasure decoding and its variants that improve upon BDD. We derive\nclosed-form expressions for their error probabilities and validate them through\nsimulations. Then, we illustrate their use in assessing concatenated coding\nschemes.", "published": "2025-09-29 13:47:04", "link": "http://arxiv.org/abs/2509.24794v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Performance of Amplitude-Based Models for Low-Rank Matrix Recovery", "abstract": "In this paper, we focus on low-rank phase retrieval, which aims to\nreconstruct a matrix $\\mathbf{X}_0\\in \\mathbb{R}^{n\\times m}$ with ${\\mathrm{\nrank}}(\\mathbf{X}_0)\\le r$ from noise-corrupted amplitude measurements\n$\\mathbf{y}=|\\mathcal{A}(\\mathbf{X}_0)|+\\boldsymbol{\\eta}$, where\n$\\mathcal{A}:\\mathbb{R}^{n\\times m}\\rightarrow \\mathbb{R}^{p}$ is a linear map\nand $\\boldsymbol{\\eta}\\in \\mathbb{R}^p$ is the noise vector. We first examine\nthe rank-constrained nonlinear least-squares model $\\hat{\\mathbf{X}}\\in\n\\mathop{\\mathrm{argmin}}\\limits_{\\substack{\\mathbf{X}\\in \\mathbb{R}^{n\\times\nm},\\mathrm{rank}(\\mathbf{X})\\le\nr}}\\||\\mathcal{A}(\\mathbf{X})|-\\mathbf{y}\\|_2^2$ to estimate $\\mathbf{X}_0$,\nand demonstrate that the reconstruction error satisfies\n$\\min\\{\\|\\hat{\\mathbf{X}}-\\mathbf{X}_0\\|_F,\n\\|\\hat{\\mathbf{X}}+\\mathbf{X}_0\\|_F\\}\\lesssim\n\\frac{\\|\\boldsymbol{\\eta}\\|_2}{\\sqrt{p}}$ with high probability, provided\n$\\mathcal{A}$ is a Gaussian measurement ensemble and $p\\gtrsim (m+n)r$. We also\nprove that the error bound $\\frac{\\|\\boldsymbol{\\eta}\\|_2}{\\sqrt{p}}$ is tight\nup to a constant. Furthermore, we relax the rank constraint to a nuclear-norm\nconstraint. Hence, we propose the Lasso model for low-rank phase retrieval,\ni.e., the constrained nuclear-norm model and the unconstrained version. We also\nestablish comparable theoretical guarantees for these models. To achieve this,\nwe introduce a strong restricted isometry property (SRIP) for the linear map\n$\\mathcal{A}$, analogous to the strong RIP in phase retrieval. This work\nprovides a unified treatment that extends existing results in both phase\nretrieval and low-rank matrix recovery from rank-one measurements.", "published": "2025-09-29 12:31:46", "link": "http://arxiv.org/abs/2509.24699v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Advances in the Shannon Capacity of Graphs", "abstract": "This paper studies several research directions concerning the Shannon\ncapacity of graphs. Building on Schrijver's recent framework, we establish\nsufficient conditions under which the Shannon capacity of a polynomial in\ngraphs equals the corresponding polynomial of the individual capacities,\nthereby simplifying their evaluation. We derive exact values and new bounds for\nthe Shannon capacity of two families of graphs: the q-Kneser graphs and the\nTadpole graphs. Furthermore, we construct graphs whose Shannon capacity is\nnever attained by the independence number of any finite power of these graphs,\nincluding a countably infinite family of connected graphs with this property.\nWe further prove an inequality relating the Shannon capacities of the strong\nproduct of graphs and their disjoint union, leading to streamlined proofs of\nknown bounds.", "published": "2025-09-29 11:05:56", "link": "http://arxiv.org/abs/2509.24600v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Splitting Alternating Algorithms for Sparse Solutions of Linear Systems with Concatenated Orthogonal Matrices", "abstract": "A class of splitting alternating algorithms is proposed for finding the\nsparse solution of linear systems with concatenated orthogonal matrices.\nDepending on the number of matrices concatenated, the proposed algorithms are\nclassified into the two-block splitting alternating algorithm (TSAA) and the\nmulti-block splitting alternating algorithm (MSAA). These algorithms aim to\ndecompose a large-scale linear system into two or more coupled subsystems, each\nsignificantly smaller than the original system, and then combine the solutions\nof these subsystems to produce the sparse solution of the original system. The\nproposed algorithms only involve matrix-vector products and reduced orthogonal\nprojections. It turns out that the proposed algorithms are globally convergent\nto the sparse solution of a linear system if the matrix (along with the\nsparsity level of the solution) satisfies a coherence-type condition. Numerical\nexperiments indicate that the proposed algorithms are very promising and can\nquickly and accurately locate the sparse solution of a linear system with\nsignificantly fewer iterations than several mainstream iterative methods.", "published": "2025-09-29 10:10:22", "link": "http://arxiv.org/abs/2509.24558v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Energy-Efficient Movable Antennas: Mechanical Power Modeling and Performance Optimization", "abstract": "Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to\nenhance communication performance through local antenna movement. However, to\nachieve accurate and fast antenna movement, MA drivers entail non-negligible\nmechanical power consumption, rendering energy efficiency (EE) optimization\nmore critical compared to conventional fixed-position antenna (FPA) systems. To\naddress this issue, we develop a fundamental power consumption model for\nstepper motor-driven multi-MA systems based on electric motor theory. Based on\nthis model, we formulate an EE maximization problem from a multi-MA base\nstation (BS) to multiple single-FPA users. We aim to jointly optimize the MAs'\npositions, moving speeds, and the BS's transmit precoding matrix subject to\ncollision-avoidance constraints during the multi-MA movements. However, this\nproblem is difficult to solve. To tackle this challenge, we first reveal that\nthe collision-avoidance constraints can always be relaxed without loss of\noptimality by properly renumbering the MA indices. For the resulting relaxed\nproblem, we first consider a simplified single-user setup and uncover a hidden\nmonotonicity of the EE performance with respect to the MAs' moving speeds. To\nsolve the remaining optimization problem, we develop a two-layer optimization\nframework. In the inner layer, the Dinkelbach algorithm is employed to derive\nthe optimal beamforming solution for any given MA positions. In the outer\nlayer, a sequential update algorithm is proposed to iteratively refine the MA\npositions based on the optimal values obtained from the inner layer. Next, we\nproceed to the general multi-user case and propose an alternating optimization\n(AO) algorithm. Numerical results demonstrate that despite the additional\nmechanical power consumption, the proposed algorithms can outperform both\nconventional FPA systems and other existing EE maximization benchmarks", "published": "2025-09-29 08:17:37", "link": "http://arxiv.org/abs/2509.24433v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Delsarte duality on subspaces and applications to rank-metric codes and q-matroids", "abstract": "We study the interplay between the lattice of F_{q^m}-subspaces and the\nlattice of F_{q^m}-subspaces of an F_{q^m}-vector space. Introducing notions of\nweight and defect relative to an F_q-subspace, we analyze the sequence of\nmaximum non-zero defects. We establish a correspondence between subspaces of\npositive defect and their Delsarte duals, enabling explicit characterizations\nof the associated sequences of maximum non-zero defects. Our framework unifies\nseveral classes of subspaces studied in finite geometry and connects them to\nlinear rank-metric codes by providing a new geometric interpretation of code\nduality. Building on these results, we characterize classes of rank-metric\ncodes closed under duality, including MRD, near MRD, quasi-MRD, and a new\nfamily of (n, k)-MRD codes. Finally, we explore applications to q-matroids, by\nstudying the problem of F_{q^m}-representability for direct sums of uniform\nq-matroids and describing their rank generating functions.", "published": "2025-09-29 07:56:50", "link": "http://arxiv.org/abs/2509.24409v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Prediction-Powered Communication with Distortion Guarantees", "abstract": "The development of 6G wireless systems is taking place alongside the\ndevelopment of increasingly intelligent wireless devices and network nodes. The\nchanging technological landscape is motivating a rethinking of classical\nShannon information theory that emphasizes semantic and task-oriented\nparadigms. In this paper, we study a prediction-powered communication setting,\nin which devices, equipped with artificial intelligence (AI)-based predictors,\ncommunicate under zero-delay constraints with strict distortion guarantees. Two\nclasses of distortion measures are considered: (i) outage-based metrics,\nsuitable for tasks tolerating occasional packet losses, such as real-time\ncontrol or monitoring; and (ii) bounded distortion metrics, relevant to\nsemantic-rich tasks like text or video transmission. We propose two zero-delay\ncompression algorithms leveraging online conformal prediction to provide\nper-sequence guarantees on the distortion of reconstructed sequences over\nerror-free and packet-erasure channels with feedback. For erasure channels, we\nintroduce a doubly-adaptive conformal update to compensate for channel-induced\nerrors and derive sufficient conditions on erasure statistics to ensure\ndistortion constraints. Experiments on semantic text compression validate the\napproach, showing significant bit rate reductions while strictly meeting\ndistortion guarantees compared to state-of-the-art prediction-powered\ncompression methods.", "published": "2025-09-29 07:19:39", "link": "http://arxiv.org/abs/2509.24373v1", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Parametrized complexity of relations between multidimensional subshifts", "abstract": "We study the parametrized complexity of fundamental relations between\nmultidimensional subshifts, such as equality, conjugacy, inclusion, and\nembedding, for subshifts of finite type (SFTs) and effective subshifts. We\nbuild on previous work of E. Jeandel and P. Vanier on the complexity of these\nrelations as two-input problems, by fixing one subshift as parameter and taking\nthe other subshift as input. We study the impact of various dynamical\nproperties related to periodicity, minimality, finite type, etc. on the\ncomputational properties of the parameter subshift, which reveals interesting\ndifferences and asymmetries.\n  Among other notable results, we find choices of parameter that reach the\nmaximum difficulty for each problem; we find nontrivial decidable problems for\nmultidimensional SFT, where most properties are undecidable; and we find\nconnections with recent work relating having computable language and being\nminimal for some property, showing in particular that this property may not\nalways be chosen conjugacy-invariant.", "published": "2025-09-29 06:46:15", "link": "http://arxiv.org/abs/2509.24343v1", "categories": ["math.DS", "cs.IT", "math.IT", "math.LO", "37B10, 68Q15, 03D05"], "primary_category": "math.DS"}
{"title": "Finite-blocklength Fluid Antenna Systems With Spatial Block-Correlation Channel Model", "abstract": "Massive connectivity with ultra-low latency and high reliability necessitates\nfundamental advances in future communication networks operating under\nfinite-blocklength (FBL) transmission. Fluid antenna systems (FAS) have emerged\nas a promising enabler, offering superior spectrum and energy efficiency in\nshort-packet/FBL scenarios. In this work, by leveraging the simplicity and\naccuracy of block-correlation channel modeling, we rigorously bound the\nperformance limits of FBL-FAS from a statistical perspective, focusing on two\nkey performance metrics: block error rate (BLER) and outage probability (OP).\nFurthermore, we introduce a novel complex-integral simplification method based\non Gauss-Laguerre quadrature, which achieves higher approximation accuracy\ncompared to existing Taylor-expansion-based approaches. Numerical results\nvalidate the robustness of the proposed analysis and clearly demonstrate the\nsuperiority of FBL-FAS over conventional multiple-antenna systems with fixed\nantenna placement.", "published": "2025-09-29 06:30:18", "link": "http://arxiv.org/abs/2509.24333v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Adaptive Source-Channel Coding for Multi-User Semantic and Data Communications", "abstract": "This paper considers a multi-user semantic and data communication\n(MU-SemDaCom) system, where a base station (BS) simultaneously serves users\nwith different semantic and data tasks through a downlink multi-user\nmultiple-input single-output (MU-MISO) channel. The coexistence of\nheterogeneous communication tasks, diverse channel conditions, and the\nrequirements for digital compatibility poses significant challenges to the\nefficient design of MU-SemDaCom systems. To address these issues, we propose a\nmulti-user adaptive source-channel coding (MU-ASCC) framework that adaptively\noptimizes deep neural network (DNN)-based source coding, digital channel\ncoding, and superposition broadcasting. First, we employ a data-regression\nmethod to approximate the end-to-end (E2E) semantic and data distortions, for\nwhich no closed-form expressions exist. The obtained logistic formulas\ndecompose the E2E distortion as the addition of the source and channel\ndistortion terms, in which the logistic parameter variations are task-dependent\nand jointly determined by both the DNN and channel parameters. Then, based on\nthe derived formulas, we formulate a weighted-sum E2E distortion minimization\nproblem that jointly optimizes the source-channel coding rates, power\nallocation, and beamforming vectors for both the data and semantic users.\nFinally, an alternating optimization (AO) framework is developed, where the\nadaptive rate optimization is solved using the subgradient descent method,\nwhile the joint power and beamforming is addressed via the uplink-downlink\nduality (UDD) technique. Simulation results demonstrate that, compared with the\nconventional separate source-channel coding (SSCC) and deep joint\nsource-channel coding (DJSCC) schemes that are designed for a single task, the\nproposed MU-ASCC scheme achieves simultaneous improvements in both the data\nrecovery and semantic task performance.", "published": "2025-09-29 03:39:30", "link": "http://arxiv.org/abs/2509.24247v1", "categories": ["eess.IV", "cs.IT", "math.IT"], "primary_category": "eess.IV"}
{"title": "Fundamental Limit of Discrete Distribution Estimation under Utility-Optimized Local Differential Privacy", "abstract": "We study the problem of discrete distribution estimation under\nutility-optimized local differential privacy (ULDP), which enforces local\ndifferential privacy (LDP) on sensitive data while allowing more accurate\ninference on non-sensitive data. In this setting, we completely characterize\nthe fundamental privacy-utility trade-off. The converse proof builds on several\nkey ideas, including a generalized uniform asymptotic Cram\\'er-Rao lower bound,\na reduction showing that it suffices to consider a newly defined class of\nextremal ULDP mechanisms, and a novel distribution decomposition technique\ntailored to ULDP constraints. For the achievability, we propose a class of\nutility-optimized block design (uBD) schemes, obtained as nontrivial\nmodifications of the block design mechanism known to be optimal under standard\nLDP constraints, while incorporating the distribution decomposition idea used\nin the converse proof and a score-based linear estimator. These results provide\na tight characterization of the estimation accuracy achievable under ULDP and\nreveal new insights into the structure of optimal mechanisms for\nprivacy-preserving statistical inference.", "published": "2025-09-29 01:41:36", "link": "http://arxiv.org/abs/2509.24173v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Capacity-Achieving Codes for Noisy Insertion Channels", "abstract": "DNA storage has emerged as a promising solution for large-scale and long-term\ndata preservation. Among various error types, insertions are the most frequent\nerrors occurring in DNA sequences, where the inserted symbol is often identical\nor complementary to the original, and in practical implementations, noise can\nfurther cause the inserted symbol to mutate into a random one, which creates\nsignificant challenges to reliable data recovery. In this paper, we investigate\na new noisy insertion channel, where infinitely many insertions of symbols\ncomplement or identical to the original ones and up to one insertion of random\nsymbol may occur. We determine the coding capacity of the noisy channel and\nconstruct asymptotically optimal error-correcting codes achieving the coding\ncapacity.", "published": "2025-09-29 01:20:30", "link": "http://arxiv.org/abs/2509.24161v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "BALF: Budgeted Activation-Aware Low-Rank Factorization for Fine-Tuning-Free Model Compression", "abstract": "Neural network compression techniques typically require expensive fine-tuning\nor search procedures, rendering them impractical on commodity hardware.\nInspired by recent LLM compression research, we present a general\nactivation-aware factorization framework that can be applied to a broad range\nof layers. Moreover, we introduce a scalable budgeted rank allocator that\nallows flexible control over compression targets (e.g., retaining 50% of\nparameters) with no overhead. Together, these components form BALF, an\nefficient pipeline for compressing models without fine-tuning. We demonstrate\nits effectiveness across multiple scales and architectures, from ResNet-20 on\nCIFAR-10 to ResNeXt-101 and vision transformers on ImageNet, and show that it\nachieves excellent results in the fine-tuning-free regime. For instance, BALF\nreduces FLOPs on ResNeXt-101 by 45% with only a 1-percentage-point top-1\naccuracy drop.", "published": "2025-09-29 17:50:29", "link": "http://arxiv.org/abs/2509.25136v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning in an Echo Chamber: Online Learning with Replay Adversary", "abstract": "As machine learning systems increasingly train on self-annotated data, they\nrisk reinforcing errors and becoming echo chambers of their own beliefs. We\nmodel this phenomenon by introducing a learning-theoretic framework: Online\nLearning in the Replay Setting. In round $t$, the learner outputs a hypothesis\n$\\hat{h}_t$; the adversary then reveals either the true label $f^\\ast(x_t)$ or\na replayed label $\\hat{h}_i(x_t)$ from an earlier round $i < t$. A mistake is\ncounted only when the true label is shown, yet classical algorithms such as the\nSOA or the halving algorithm are easily misled by the replayed errors.\n  We introduce the Extended Threshold dimension, $\\mathrm{ExThD}(\\mathcal{H})$,\nand prove matching upper and lower bounds that make\n$\\mathrm{ExThD}(\\mathcal{H})$ the exact measure of learnability in this model.\nA closure-based learner makes at most $\\mathrm{ExThD}(\\mathcal{H})$ mistakes\nagainst any adaptive adversary, and no algorithm can perform better. For\nstochastic adversaries, we prove a similar bound for every intersection-closed\nclass. The replay setting is provably harder than the classical mistake bound\nsetting: some classes have constant Littlestone dimension but arbitrarily large\n$\\mathrm{ExThD}(\\mathcal{H})$. Proper learning exhibits an even sharper\nseparation: a class is properly learnable under replay if and only if it is\n(almost) intersection-closed. Otherwise, every proper learner suffers\n$\\Omega(T)$ errors, whereas our improper algorithm still achieves the\n$\\mathrm{ExThD}(\\mathcal{H})$ bound. These results give the first tight\nanalysis of learning against replay adversaries, based on new results for\nclosure-type algorithms.", "published": "2025-09-29 17:50:24", "link": "http://arxiv.org/abs/2509.25135v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On Spectral Learning for Odeco Tensors: Perturbation, Initialization, and Algorithms", "abstract": "We study spectral learning for orthogonally decomposable (odeco) tensors,\nemphasizing the interplay between statistical limits, optimization geometry,\nand initialization. Unlike matrices, recovery for odeco tensors does not hinge\non eigengaps, yielding improved robustness under noise. While iterative methods\nsuch as tensor power iterations can be statistically efficient, initialization\nemerges as the main computational bottleneck. We investigate perturbation\nbounds, non-convex optimization analysis, and initialization strategies,\nclarifying when efficient algorithms attain statistical limits and when\nfundamental barriers remain.", "published": "2025-09-29 17:45:35", "link": "http://arxiv.org/abs/2509.25126v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Towards generalizable deep ptychography neural networks", "abstract": "X-ray ptychography is a data-intensive imaging technique expected to become\nubiquitous at next-generation light sources delivering many-fold increases in\ncoherent flux. The need for real-time feedback under accelerated acquisition\nrates motivates surrogate reconstruction models like deep neural networks,\nwhich offer orders-of-magnitude speedup over conventional methods. However,\nexisting deep learning approaches lack robustness across diverse experimental\nconditions. We propose an unsupervised training workflow emphasizing probe\nlearning by combining experimentally-measured probes with synthetic,\nprocedurally generated objects. This probe-centric approach enables a single\nphysics-informed neural network to reconstruct unseen experiments across\nmultiple beamlines; among the first demonstrations of multi-probe\ngeneralization. We find probe learning is equally important as in-distribution\nlearning; models trained using this synthetic workflow achieve reconstruction\nfidelity comparable to those trained exclusively on experimental data, even\nwhen changing the type of synthetic training object. The proposed approach\nenables training of experiment-steering models that provide real-time feedback\nunder dynamic experimental conditions.", "published": "2025-09-29 17:38:13", "link": "http://arxiv.org/abs/2509.25104v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Curriculum Imitation Learning of Distributed Multi-Robot Policies", "abstract": "Learning control policies for multi-robot systems (MRS) remains a major\nchallenge due to long-term coordination and the difficulty of obtaining\nrealistic training data. In this work, we address both limitations within an\nimitation learning framework. First, we shift the typical role of Curriculum\nLearning in MRS, from scalability with the number of robots, to focus on\nimproving long-term coordination. We propose a curriculum strategy that\ngradually increases the length of expert trajectories during training,\nstabilizing learning and enhancing the accuracy of long-term behaviors. Second,\nwe introduce a method to approximate the egocentric perception of each robot\nusing only third-person global state demonstrations. Our approach transforms\nidealized trajectories into locally available observations by filtering\nneighbors, converting reference frames, and simulating onboard sensor\nvariability. Both contributions are integrated into a physics-informed\ntechnique to produce scalable, distributed policies from observations. We\nconduct experiments across two tasks with varying team sizes and noise levels.\nResults show that our curriculum improves long-term accuracy, while our\nperceptual estimation method yields policies that are robust to realistic\nuncertainty. Together, these strategies enable the learning of robust,\ndistributed controllers from global demonstrations, even in the absence of\nexpert actions or onboard measurements.", "published": "2025-09-29 17:31:48", "link": "http://arxiv.org/abs/2509.25097v1", "categories": ["cs.RO", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks", "abstract": "The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet\nmachine learning for ECG interpretation remains fragmented, often limited to\nnarrow tasks or datasets. Foundation models promise broader adaptability, but\ntheir generalization across diverse ECG tasks is not well understood. We\nbenchmarked eight ECG foundation models on 26 clinically relevant tasks using\n12 public datasets comprising 1,650 regression and classification targets.\nModels were evaluated under fine-tuning and frozen settings, with scaling\nanalyses across dataset sizes. Results show heterogeneous performance across\ndomains: in the most widely studied domain, adult ECG interpretation, three\nfoundation models consistently outperformed strong supervised baselines. In\ncontrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,\ndominated other categories where most foundation models failed to surpass\nsupervised learning. Foundation models also displayed distinct scaling\nbehaviors with dataset size, which are critical for small-scale clinical\napplications. Overall, while foundation models show promise for adult ECG\nanalysis, substantial gaps remain in cardiac structure, outcome prediction, and\npatient characterization. Notably, ECG-CPC's strong performance despite being\norders of magnitude smaller and consuming minimal computational resources\nhighlights untapped opportunities for advancing ECG foundation models.", "published": "2025-09-29 17:29:48", "link": "http://arxiv.org/abs/2509.25095v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Towards a Certificate of Trust: Task-Aware OOD Detection for Scientific AI", "abstract": "Data-driven models are increasingly adopted in critical scientific fields\nlike weather forecasting and fluid dynamics. These methods can fail on\nout-of-distribution (OOD) data, but detecting such failures in regression tasks\nis an open challenge. We propose a new OOD detection method based on estimating\njoint likelihoods using a score-based diffusion model. This approach considers\nnot just the input but also the regression model's prediction, providing a\ntask-aware reliability score. Across numerous scientific datasets, including\nPDE datasets, satellite imagery and brain tumor segmentation, we show that this\nlikelihood strongly correlates with prediction error. Our work provides a\nfoundational step towards building a verifiable 'certificate of trust', thereby\noffering a practical tool for assessing the trustworthiness of AI-based\nscientific predictions. Our code is publicly available at\nhttps://github.com/bogdanraonic3/OOD_Detection_ScientificML", "published": "2025-09-29 17:21:25", "link": "http://arxiv.org/abs/2509.25080v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Symmetry-Aware Bayesian Optimization via Max Kernels", "abstract": "Bayesian Optimization (BO) is a powerful framework for optimizing noisy,\nexpensive-to-evaluate black-box functions. When the objective exhibits\ninvariances under a group action, exploiting these symmetries can substantially\nimprove BO efficiency. While using maximum similarity across group orbits has\nlong been considered in other domains, the fact that the max kernel is not\npositive semidefinite (PSD) has prevented its use in BO. In this work, we\nrevisit this idea by considering a PSD projection of the max kernel. Compared\nto existing invariant (and non-invariant) kernels, we show it achieves\nsignificantly lower regret on both synthetic and real-world BO benchmarks,\nwithout increasing computational complexity.", "published": "2025-09-29 17:02:28", "link": "http://arxiv.org/abs/2509.25051v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Advantage Weighted Matching: Aligning RL with Pretraining in Diffusion Models", "abstract": "Reinforcement Learning (RL) has emerged as a central paradigm for advancing\nLarge Language Models (LLMs), where pre-training and RL post-training share the\nsame log-likelihood formulation. In contrast, recent RL approaches for\ndiffusion models, most notably Denoising Diffusion Policy Optimization (DDPO),\noptimize an objective different from the pretraining objectives--score/flow\nmatching loss. In this work, we establish a novel theoretical analysis: DDPO is\nan implicit form of score/flow matching with noisy targets, which increases\nvariance and slows convergence. Building on this analysis, we introduce\n\\textbf{Advantage Weighted Matching (AWM)}, a policy-gradient method for\ndiffusion. It uses the same score/flow-matching loss as pretraining to obtain a\nlower-variance objective and reweights each sample by its advantage. In effect,\nAWM raises the influence of high-reward samples and suppresses low-reward ones\nwhile keeping the modeling objective identical to pretraining. This unifies\npretraining and RL conceptually and practically, is consistent with\npolicy-gradient theory, reduces variance, and yields faster convergence. This\nsimple yet effective design yields substantial benefits: on GenEval, OCR, and\nPickScore benchmarks, AWM delivers up to a $24\\times$ speedup over Flow-GRPO\n(which builds on DDPO), when applied to Stable Diffusion 3.5 Medium and FLUX,\nwithout compromising generation quality. Code is available at\nhttps://github.com/scxue/advantage_weighted_matching.", "published": "2025-09-29 17:02:20", "link": "http://arxiv.org/abs/2509.25050v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Hyperparameter Tuning via Trajectory Invariance Principle", "abstract": "As hyperparameter tuning becomes increasingly costly at scale, efficient\ntuning methods are essential. Yet principles for guiding hyperparameter tuning\nremain limited. In this work, we seek to establish such principles by\nconsidering a broad range of hyperparameters, including batch size, learning\nrate, and weight decay. We identify a phenomenon we call trajectory invariance,\nwhere pre-training loss curves, gradient noise, and gradient norm exhibit\ninvariance--closely overlapping--with respect to a quantity that combines\nlearning rate and weight decay. This phenomenon effectively reduces the\noriginal two-dimensional hyperparameter space to one dimension, yielding an\nefficient tuning rule: follow the salient direction revealed by trajectory\ninvariance. Furthermore, we refine previous scaling laws and challenge several\nexisting viewpoints. Overall, our work proposes new principles for efficient\ntuning and inspires future research on scaling laws.", "published": "2025-09-29 17:01:19", "link": "http://arxiv.org/abs/2509.25049v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A multiscale analysis of mean-field transformers in the moderate interaction regime", "abstract": "In this paper, we study the evolution of tokens through the depth of\nencoder-only transformer models at inference time by modeling them as a system\nof particles interacting in a mean-field way and studying the corresponding\ndynamics. More specifically, we consider this problem in the moderate\ninteraction regime, where the number $N$ of tokens is large and the inverse\ntemperature parameter $\\beta$ of the model scales together with $N$. In this\nregime, the dynamics of the system displays a multiscale behavior: a fast\nphase, where the token empirical measure collapses on a low-dimensional space,\nan intermediate phase, where the measure further collapses into clusters, and a\nslow one, where such clusters sequentially merge into a single one. We provide\na rigorous characterization of the limiting dynamics in each of these phases\nand prove convergence in the above mentioned limit, exemplifying our results\nwith some simulations.", "published": "2025-09-29 16:57:04", "link": "http://arxiv.org/abs/2509.25040v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios", "abstract": "Aging infrastructure portfolios pose a critical resource allocation\nchallenge: deciding which structures require intervention and which can safely\nremain in service. Structural assessments must balance the trade-off between\ncheaper, conservative analysis methods and accurate but costly simulations that\ndo not scale portfolio-wide. We propose Bayesian neural network (BNN)\nsurrogates for rapid structural pre-assessment of worldwide common bridge\ntypes, such as reinforced concrete frame bridges. Trained on a large-scale\ndatabase of non-linear finite element analyses generated via a parametric\npipeline and developed based on the Swiss Federal Railway's bridge portfolio,\nthe models accurately and efficiently estimate high-fidelity structural\nanalysis results by predicting code compliance factors with calibrated\nepistemic uncertainty. Our BNN surrogate enables fast, uncertainty-aware\ntriage: flagging likely critical structures and providing guidance where\nrefined analysis is pertinent. We demonstrate the framework's effectiveness in\na real-world case study of a railway underpass, showing its potential to\nsignificantly reduce costs and emissions by avoiding unnecessary analyses and\nphysical interventions across entire infrastructure portfolios.", "published": "2025-09-29 16:51:02", "link": "http://arxiv.org/abs/2509.25031v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts", "abstract": "The current paradigm for reasoning in large language models (LLMs) involves\nmodels \"thinking out loud\" via a sequence of tokens, known as chain-of-thought\n(CoT). This approach, while effective, has several significant drawbacks.\nFirstly, inference requires autoregressive generation of often thousands of CoT\ntokens, which is slow and computationally expensive. Secondly, it constrains\nreasoning to the discrete space of tokens, creating an information bottleneck\nacross reasoning steps. Thirdly, it fundamentally entangles reasoning with\ntoken generation, forcing LLMs to \"think while speaking,\" which causes\npotentially short-sighted reasoning. In light of these limitations, we\nre-imagine reasoning in LLMs and present a new paradigm: MARCOS. In our\napproach, rather than autoregressively generating tokens, we model reasoning as\na hidden Markov chain of continuous, high-dimensional \"thoughts\". Each\nreasoning step involves a transition of the internal thoughts, where explicit\nreasoning steps (which may consist of hundreds of tokens) serve as observable\nvariables, which are windows to peek into the implicit thoughts. Since this\nlatent process is incompatible with the standard supervised learning, we\nfurther propose a two-phase variational training scheme. Our experiments on\nthree benchmarks demonstrate that MARCOS outperforms existing continuous\nreasoning methods and, for the first time, achieves performance comparable to\ntoken-based CoT, even surpassing it by 4.7% on GSM8K with up to 15.7x speedup\nin inference. Beyond this, MARCOS offers additional advantages, such as\nstep-level instead of token-level control over randomness, opening significant\nopportunities for reinforcement learning and reasoning in LLMs.", "published": "2025-09-29 16:44:22", "link": "http://arxiv.org/abs/2509.25020v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Embedded Deep Learning for Bio-hybrid Plant Sensors to Detect Increased Heat and Ozone Levels", "abstract": "We present a bio-hybrid environmental sensor system that integrates natural\nplants and embedded deep learning for real-time, on-device detection of\ntemperature and ozone level changes. Our system, based on the low-power\nPhytoNode platform, records electric differential potential signals from Hedera\nhelix and processes them onboard using an embedded deep learning model. We\ndemonstrate that our sensing device detects changes in temperature and ozone\nwith good sensitivity of up to 0.98. Daily and inter-plant variability, as well\nas limited precision, could be mitigated by incorporating additional training\ndata, which is readily integrable in our data-driven framework. Our approach\nalso has potential to scale to new environmental factors and plant species. By\nintegrating embedded deep learning onboard our biological sensing device, we\noffer a new, low-power solution for continuous environmental monitoring and\npotentially other fields of application.", "published": "2025-09-29 16:19:31", "link": "http://arxiv.org/abs/2509.24992v1", "categories": ["cs.ET", "cs.LG"], "primary_category": "cs.ET"}
{"title": "Sampling Complexity of TD and PPO in RKHS", "abstract": "We revisit Proximal Policy Optimization (PPO) from a function-space\nperspective. Our analysis decouples policy evaluation and improvement in a\nreproducing kernel Hilbert space (RKHS): (i) A kernelized temporal-difference\n(TD) critic performs efficient RKHS-gradient updates using only one-step\nstate-action transition samples; (ii) a KL-regularized, natural-gradient policy\nstep exponentiates the evaluated action-value, recovering a PPO/TRPO-style\nproximal update in continuous state-action spaces. We provide non-asymptotic,\ninstance-adaptive guarantees whose rates depend on RKHS entropy, unifying\ntabular, linear, Sobolev, Gaussian, and Neural Tangent Kernel (NTK) regimes,\nand we derive a sampling rule for the proximal update that ensures the optimal\n$k^{-1/2}$ convergence rate for stochastic optimization. Empirically, the\ntheory-aligned schedule improves stability and sample efficiency on common\ncontrol tasks (e.g., CartPole, Acrobot), while our TD-based critic attains\nfavorable throughput versus a GAE baseline. Altogether, our results place PPO\non a firmer theoretical footing beyond finite-dimensional assumptions and\nclarify when RKHS-proximal updates with kernel-TD critics yield global policy\nimprovement with practical efficiency.", "published": "2025-09-29 16:19:19", "link": "http://arxiv.org/abs/2509.24991v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Double Descent as a Lens for Sample Efficiency in Autoregressive vs. Discrete Diffusion Models", "abstract": "Data scarcity drives the need for more sample-efficient large language\nmodels. In this work, we use the double descent phenomenon to holistically\ncompare the sample efficiency of discrete diffusion and autoregressive models.\nWe show that discrete diffusion models require larger capacity and more\ntraining epochs to escape their underparameterized regime and reach the\ninterpolation threshold. In the strongly overparameterized regime, both models\nexhibit similar behavior, with neither exhibiting a pronounced second descent\nin test loss across a large range of model sizes. Overall, our results indicate\nthat autoregressive models are more sample-efficient on small-scale datasets,\nwhile discrete diffusion models only become competitive when given sufficient\ncapacity and compute.", "published": "2025-09-29 16:03:12", "link": "http://arxiv.org/abs/2509.24974v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Overlap-Adaptive Regularization for Conditional Average Treatment Effect Estimation", "abstract": "The conditional average treatment effect (CATE) is widely used in\npersonalized medicine to inform therapeutic decisions. However,\nstate-of-the-art methods for CATE estimation (so-called meta-learners) often\nperform poorly in the presence of low overlap. In this work, we introduce a new\napproach to tackle this issue and improve the performance of existing\nmeta-learners in the low-overlap regions. Specifically, we introduce\nOverlap-Adaptive Regularization (OAR) that regularizes target models\nproportionally to overlap weights so that, informally, the regularization is\nhigher in regions with low overlap. To the best of our knowledge, our OAR is\nthe first approach to leverage overlap weights in the regularization terms of\nthe meta-learners. Our OAR approach is flexible and works with any existing\nCATE meta-learner: we demonstrate how OAR can be applied to both parametric and\nnon-parametric second-stage models. Furthermore, we propose debiased versions\nof our OAR that preserve the Neyman-orthogonality of existing meta-learners and\nthus ensure more robust inference. Through a series of (semi-)synthetic\nexperiments, we demonstrate that our OAR significantly improves CATE estimation\nin low-overlap settings in comparison to constant regularization.", "published": "2025-09-29 15:56:24", "link": "http://arxiv.org/abs/2509.24962v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Intra-request branch orchestration for efficient LLM reasoning", "abstract": "Large Language Models (LLMs) increasingly rely on inference-time reasoning\nalgorithms such as chain-of-thought and multi-branch reasoning to improve\naccuracy on complex tasks. These methods, however, substantially increase token\nusage and per-request latency. Prior work has largely focused on reducing token\nusage, often at the expense of accuracy, while overlooking other latency\nfactors. We present DUCHESS, an LLM serving system that reduces cost and\nlatency without sacrificing accuracy through intra-request branch orchestration\nguided by predictions. DUCHESS employs a lightweight linear probing model over\nLLM layer activations to estimate branch correctness, and its orchestration\npolicy decides whether to terminate, duplicate, or continue a branch. When\nhandling multiple requests, DUCHESS further reduces latency by prioritizing\neasier reasoning tasks when complexity can be estimated from the prompt.\nExperiments on three reasoning benchmarks show that DUCHESS consistently\nimproves the token-accuracy Pareto frontier, reducing token usage by 42-63% at\nmatched accuracy compared to self-consistency. In serving with vLLM, DUCHESS\nreduces mean, median, and tail latencies by 57-81%, 58-85%, and 52-84% with\nFirst-Come-First-Served scheduling, and achieves additional gains under\ndifficulty-aware scheduling at higher request rates.", "published": "2025-09-29 15:52:08", "link": "http://arxiv.org/abs/2509.24957v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "OAT-FM: Optimal Acceleration Transport for Improved Flow Matching", "abstract": "As a powerful technique in generative modeling, Flow Matching (FM) aims to\nlearn velocity fields from noise to data, which is often explained and\nimplemented as solving Optimal Transport (OT) problems. In this study, we\nbridge FM and the recent theory of Optimal Acceleration Transport (OAT),\ndeveloping an improved FM method called OAT-FM and exploring its benefits in\nboth theory and practice. In particular, we demonstrate that the straightening\nobjective hidden in existing OT-based FM methods is mathematically equivalent\nto minimizing the physical action associated with acceleration defined by OAT.\nAccordingly, instead of enforcing constant velocity, OAT-FM optimizes the\nacceleration transport in the product space of sample and velocity, whose\nobjective corresponds to a necessary and sufficient condition of flow\nstraightness. An efficient algorithm is designed to achieve OAT-FM with low\ncomplexity. OAT-FM motivates a new two-phase FM paradigm: Given a generative\nmodel trained by an arbitrary FM method, whose velocity information has been\nrelatively reliable, we can fine-tune and improve it via OAT-FM. This paradigm\neliminates the risk of data distribution drift and the need to generate a large\nnumber of noise data pairs, which consistently improves model performance in\nvarious generative tasks. Code is available at:\nhttps://github.com/AngxiaoYue/OAT-FM", "published": "2025-09-29 15:36:27", "link": "http://arxiv.org/abs/2509.24936v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Is Sequence Information All You Need for Bayesian Optimization of Antibodies?", "abstract": "Bayesian optimization is a natural candidate for the engineering of antibody\ntherapeutic properties, which is often iterative and expensive. However,\nfinding the optimal choice of surrogate model for optimization over the highly\nstructured antibody space is difficult, and may differ depending on the\nproperty being optimized. Moreover, to the best of our knowledge, no prior\nworks have attempted to incorporate structural information into antibody\nBayesian optimization. In this work, we explore different approaches to\nincorporating structural information into Bayesian optimization, and compare\nthem to a variety of sequence-only approaches on two different antibody\nproperties, binding affinity and stability. In addition, we propose the use of\na protein language model-based ``soft constraint,'' which helps guide the\noptimization to promising regions of the space. We find that certain types of\nstructural information improve data efficiency in early optimization rounds for\nstability, but have equivalent peak performance. Moreover, when incorporating\nthe protein language model soft constraint we find that the data efficiency gap\nis diminished for affinity and eliminated for stability, resulting in\nsequence-only methods that match the performance of structure-based methods,\nraising questions about the necessity of structure in Bayesian optimization for\nantibodies.", "published": "2025-09-29 15:36:04", "link": "http://arxiv.org/abs/2509.24933v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Graph Theory Meets Federated Learning over Satellite Constellations: Spanning Aggregations, Network Formation, and Performance Optimization", "abstract": "We introduce Fed-Span, a novel federated/distributed learning framework\ndesigned for low Earth orbit satellite constellations. By leveraging\ngraph-theoretic principles, Fed-Span addresses critical challenges inherent to\ndistributed learning in dynamic satellite networks, including intermittent\nsatellite connectivity, heterogeneous computational capabilities of satellites,\nand time-varying satellites' datasets. At its core, Fed-Span builds upon\nminimum spanning tree (MST) and minimum spanning forest (MSF) topologies,\nenabling spanning model aggregation and dispatching processes for distributed\nlearning. To formalize Fed-Span, we offer a fresh perspective on MST/MSF\ntopologies by formulating them through a set of continuous constraint\nrepresentations (CCRs), thereby devising graph-theoretical abstractions into an\noptimizable framework for satellite networks. Using these CCRs, we obtain the\nenergy consumption and latency of operations in Fed-Span. Moreover, we derive\nnovel convergence bounds for non-convex machine learning loss functions,\naccommodating the key system characteristics and degrees of freedom of\nFed-Span. Finally, we propose a comprehensive optimization problem that jointly\nminimizes model prediction loss, energy consumption, and latency of Fed-Span.\nWe unveil that this problem is NP-hard and develop a systematic approach to\ntransform it into a geometric programming formulation, solved via successive\nconvex optimization with performance guarantees. Through evaluations on\nreal-world datasets, we demonstrate that Fed-Span outperforms existing methods,\nwith faster model convergence, greater energy efficiency, and reduced latency.\nThese results highlight Fed-Span as a novel solution for efficient distributed\nlearning in satellite networks.", "published": "2025-09-29 15:35:37", "link": "http://arxiv.org/abs/2509.24932v1", "categories": ["cs.DC", "cs.LG", "cs.NI"], "primary_category": "cs.DC"}
{"title": "A Spectral-Grassmann Wasserstein metric for operator representations of dynamical systems", "abstract": "The geometry of dynamical systems estimated from trajectory data is a major\nchallenge for machine learning applications. Koopman and transfer operators\nprovide a linear representation of nonlinear dynamics through their spectral\ndecomposition, offering a natural framework for comparison. We propose a novel\napproach representing each system as a distribution of its joint operator\neigenvalues and spectral projectors and defining a metric between systems\nleveraging optimal transport. The proposed metric is invariant to the sampling\nfrequency of trajectories. It is also computationally efficient, supported by\nfinite-sample convergence guarantees, and enables the computation of Fr\\'echet\nmeans, providing interpolation between dynamical systems. Experiments on\nsimulated and real-world datasets show that our approach consistently\noutperforms standard operator-based distances in machine learning applications,\nincluding dimensionality reduction and classification, and provides meaningful\ninterpolation between dynamical systems.", "published": "2025-09-29 15:24:05", "link": "http://arxiv.org/abs/2509.24920v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "From Code to Action: Hierarchical Learning of Diffusion-VLM Policies", "abstract": "Imitation learning for robotic manipulation often suffers from limited\ngeneralization and data scarcity, especially in complex, long-horizon tasks. In\nthis work, we introduce a hierarchical framework that leverages code-generating\nvision-language models (VLMs) in combination with low-level diffusion policies\nto effectively imitate and generalize robotic behavior. Our key insight is to\ntreat open-source robotic APIs not only as execution interfaces but also as\nsources of structured supervision: the associated subtask functions - when\nexposed - can serve as modular, semantically meaningful labels. We train a VLM\nto decompose task descriptions into executable subroutines, which are then\ngrounded through a diffusion policy trained to imitate the corresponding robot\nbehavior. To handle the non-Markovian nature of both code execution and certain\nreal-world tasks, such as object swapping, our architecture incorporates a\nmemory mechanism that maintains subtask context across time. We find that this\ndesign enables interpretable policy decomposition, improves generalization when\ncompared to flat policies and enables separate evaluation of high-level\nplanning and low-level control.", "published": "2025-09-29 15:22:18", "link": "http://arxiv.org/abs/2509.24917v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "When Scores Learn Geometry: Rate Separations under the Manifold Hypothesis", "abstract": "Score-based methods, such as diffusion models and Bayesian inverse problems,\nare often interpreted as learning the data distribution in the low-noise limit\n($\\sigma \\to 0$). In this work, we propose an alternative perspective: their\nsuccess arises from implicitly learning the data manifold rather than the full\ndistribution. Our claim is based on a novel analysis of scores in the\nsmall-$\\sigma$ regime that reveals a sharp separation of scales: information\nabout the data manifold is $\\Theta(\\sigma^{-2})$ stronger than information\nabout the distribution. We argue that this insight suggests a paradigm shift\nfrom the less practical goal of distributional learning to the more attainable\ntask of geometric learning, which provably tolerates $O(\\sigma^{-2})$ larger\nerrors in score approximation. We illustrate this perspective through three\nconsequences: i) in diffusion models, concentration on data support can be\nachieved with a score error of $o(\\sigma^{-2})$, whereas recovering the\nspecific data distribution requires a much stricter $o(1)$ error; ii) more\nsurprisingly, learning the uniform distribution on the manifold-an especially\nstructured and useful object-is also $O(\\sigma^{-2})$ easier; and iii) in\nBayesian inverse problems, the maximum entropy prior is $O(\\sigma^{-2})$ more\nrobust to score errors than generic priors. Finally, we validate our\ntheoretical findings with preliminary experiments on large-scale models,\nincluding Stable Diffusion.", "published": "2025-09-29 15:18:43", "link": "http://arxiv.org/abs/2509.24912v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Unmute the Patch Tokens: Rethinking Probing in Multi-Label Audio Classification", "abstract": "Although probing frozen models has become a standard evaluation paradigm,\nself-supervised learning in audio defaults to fine-tuning. A key reason is that\nglobal pooling creates an information bottleneck causing linear probes to\nmisrepresent the embedding quality: The $\\texttt{cls}$-token discards crucial\ntoken information about dispersed, localized events in multi-label audio. This\nweakness is rooted in the mismatch between the pretraining objective (operating\nglobally) and the downstream task (localized events). Across a comprehensive\nbenchmark of 13 datasets and 6 spectrogram-based encoders, we first investigate\nthe global pooling bottleneck. We then introduce binarized prototypical probes:\na lightweight and simple pooling method that learns prototypes to perform\nclass-wise information aggregation. Despite its simplicity, our method notably\noutperforms linear and attentive probing. Our work establishes probing as a\ncompetitive and efficient paradigm for evaluating audio SSL models, challenging\nthe reliance on costly fine-tuning.", "published": "2025-09-29 15:11:18", "link": "http://arxiv.org/abs/2509.24901v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Towards Understanding the Shape of Representations in Protein Language Models", "abstract": "While protein language models (PLMs) are one of the most promising avenues of\nresearch for future de novo protein design, the way in which they transform\nsequences to hidden representations, as well as the information encoded in such\nrepresentations is yet to be fully understood. Several works have attempted to\npropose interpretability tools for PLMs, but they have focused on understanding\nhow individual sequences are transformed by such models. Therefore, the way in\nwhich PLMs transform the whole space of sequences along with their relations is\nstill unknown. In this work we attempt to understand this transformed space of\nsequences by identifying protein structure and representation with square-root\nvelocity (SRV) representations and graph filtrations. Both approaches naturally\nlead to a metric space in which pairs of proteins or protein representations\ncan be compared with each other.\n  We analyze different types of proteins from the SCOP dataset and show that\nthe Karcher mean and effective dimension of the SRV shape space follow a\nnon-linear pattern as a function of the layers in ESM2 models of different\nsizes. Furthermore, we use graph filtrations as a tool to study the context\nlengths at which models encode the structural features of proteins. We find\nthat PLMs preferentially encode immediate as well as local relations between\nresidues, but start to degrade for larger context lengths. The most\nstructurally faithful encoding tends to occur close to, but before the last\nlayer of the models, indicating that training a folding model ontop of these\nlayers might lead to improved folding performance.", "published": "2025-09-29 15:06:24", "link": "http://arxiv.org/abs/2509.24895v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improved Stochastic Optimization of LogSumExp", "abstract": "The LogSumExp function, also known as the free energy, plays a central role\nin many important optimization problems, including entropy-regularized optimal\ntransport and distributionally robust optimization (DRO). It is also the dual\nto the Kullback-Leibler (KL) divergence, which is widely used in machine\nlearning. In practice, when the number of exponential terms inside the\nlogarithm is large or infinite, optimization becomes challenging since\ncomputing the gradient requires differentiating every term. Previous approaches\nthat replace the full sum with a small batch introduce significant bias. We\npropose a novel approximation to LogSumExp that can be efficiently optimized\nusing stochastic gradient methods. This approximation is rooted in a sound\nmodification of the KL divergence in the dual, resulting in a new\n$f$-divergence called the safe KL divergence. The accuracy of the approximation\nis controlled by a tunable parameter and can be made arbitrarily small. Like\nthe LogSumExp, our approximation preserves convexity. Moreover, when applied to\nan $L$-smooth function bounded from below, the smoothness constant of the\nresulting objective scales linearly with $L$. Experiments in DRO and continuous\noptimal transport demonstrate the advantages of our approach over\nstate-of-the-art baselines and the effective treatment of numerical issues\nassociated with the standard LogSumExp and KL.", "published": "2025-09-29 15:03:55", "link": "http://arxiv.org/abs/2509.24894v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Adaptive Canonicalization with Application to Invariant Anisotropic Geometric Networks", "abstract": "Canonicalization is a widely used strategy in equivariant machine learning,\nenforcing symmetry in neural networks by mapping each input to a standard form.\nYet, it often introduces discontinuities that can affect stability during\ntraining, limit generalization, and complicate universal approximation\ntheorems. In this paper, we address this by introducing \\emph{adaptive\ncanonicalization}, a general framework in which the canonicalization depends\nboth on the input and the network. Specifically, we present the adaptive\ncanonicalization based on prior maximization, where the standard form of the\ninput is chosen to maximize the predictive confidence of the network. We prove\nthat this construction yields continuous and symmetry-respecting models that\nadmit universal approximation properties.\n  We propose two applications of our setting: (i) resolving eigenbasis\nambiguities in spectral graph neural networks, and (ii) handling rotational\nsymmetries in point clouds. We empirically validate our methods on molecular\nand protein classification, as well as point cloud classification tasks. Our\nadaptive canonicalization outperforms the three other common solutions to\nequivariant machine learning: data augmentation, standard canonicalization, and\nequivariant architectures.", "published": "2025-09-29 14:59:46", "link": "http://arxiv.org/abs/2509.24886v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DRIFT-Net: A Spectral--Coupled Neural Operator for PDEs Learning", "abstract": "Learning PDE dynamics with neural solvers can significantly improve\nwall-clock efficiency and accuracy compared with classical numerical solvers.\nIn recent years, foundation models for PDEs have largely adopted multi-scale\nwindowed self-attention, with the scOT backbone in \\textsc{Poseidon} serving as\na representative example.\n  However, because of their locality, truly globally consistent spectral\ncoupling can only be propagated gradually through deep stacking and window\nshifting. This weakens global coupling and leads to error accumulation and\ndrift during closed-loop rollouts. To address this, we propose\n\\textbf{DRIFT-Net}. It employs a dual-branch design comprising a spectral\nbranch and an image branch. The spectral branch is responsible for capturing\nglobal, large-scale low-frequency information, whereas the image branch focuses\non local details and nonstationary structures. Specifically, we first perform\ncontrolled, lightweight mixing within the low-frequency range. Then we fuse the\nspectral and image paths at each layer via bandwise weighting, which avoids the\nwidth inflation and training instability caused by naive concatenation. The\nfused result is transformed back into the spatial domain and added to the image\nbranch, thereby preserving both global structure and high-frequency details\nacross scales. Compared with strong attention-based baselines, DRIFT-Net\nachieves lower error and higher throughput with fewer parameters under\nidentical training settings and budget. On Navier--Stokes benchmarks, the\nrelative $L_{1}$ error is reduced by 7\\%--54\\%, the parameter count decreases\nby about 15\\%, and the throughput remains higher than scOT. Ablation studies\nand theoretical analyses further demonstrate the stability and effectiveness of\nthis design. The code is available at\nhttps://github.com/cruiseresearchgroup/DRIFT-Net.", "published": "2025-09-29 14:52:31", "link": "http://arxiv.org/abs/2509.24868v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Beyond the Hook: Predicting Billboard Hot 100 Chart Inclusion with Machine Learning from Streaming, Audio Signals, and Perceptual Features", "abstract": "The advent of digital streaming platforms have recently revolutionized the\nlandscape of music industry, with the ensuing digitalization providing\nstructured data collections that open new research avenues for investigating\npopularity dynamics and mainstream success. The present work explored which\ndeterminants hold the strongest predictive influence for a track's inclusion in\nthe Billboard Hot 100 charts, including streaming popularity, measurable audio\nsignal attributes, and probabilistic indicators of human listening. The\nanalysis revealed that popularity was by far the most decisive predictor of\nBillboard Hot 100 inclusion, with considerable contribution from\ninstrumentalness, valence, duration and speechiness. Logistic Regression\nachieved 90.0% accuracy, with very high recall for charting singles (0.986) but\nlower recall for non-charting ones (0.813), yielding balanced F1-scores around\n0.90. Random Forest slightly improved performance to 90.4% accuracy,\nmaintaining near-perfect precision for non-charting singles (0.990) and high\nrecall for charting ones (0.992), with F1-scores up to 0.91. Gradient Boosting\n(XGBoost) reached 90.3% accuracy, delivering a more balanced trade-off by\nimproving recall for non-charting singles (0.837) while sustaining high recall\nfor charting ones (0.969), resulting in F1-scores comparable to the other\nmodels.", "published": "2025-09-29 14:41:09", "link": "http://arxiv.org/abs/2509.24856v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cell2Text: Multimodal LLM for Generating Single-Cell Descriptions from RNA-Seq Data", "abstract": "Single-cell RNA sequencing has transformed biology by enabling the\nmeasurement of gene expression at cellular resolution, providing information\nfor cell types, states, and disease contexts. Recently, single-cell foundation\nmodels have emerged as powerful tools for learning transferable representations\ndirectly from expression profiles, improving performance on classification and\nclustering tasks. However, these models are limited to discrete prediction\nheads, which collapse cellular complexity into predefined labels that fail to\ncapture the richer, contextual explanations biologists need. We introduce\nCell2Text, a multimodal generative framework that translates scRNA-seq profiles\ninto structured natural language descriptions. By integrating gene-level\nembeddings from single-cell foundation models with pretrained large language\nmodels, Cell2Text generates coherent summaries that capture cellular identity,\ntissue origin, disease associations, and pathway activity, generalizing to\nunseen cells. Empirically, Cell2Text outperforms baselines on classification\naccuracy, demonstrates strong ontological consistency using PageRank-based\nsimilarity metrics, and achieves high semantic fidelity in text generation.\nThese results demonstrate that coupling expression data with natural language\noffers both stronger predictive performance and inherently interpretable\noutputs, pointing to a scalable path for label-efficient characterization of\nunseen cells.", "published": "2025-09-29 14:20:50", "link": "http://arxiv.org/abs/2509.24840v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "A Greedy PDE Router for Blending Neural Operators and Classical Methods", "abstract": "When solving PDEs, classical numerical solvers are often computationally\nexpensive, while machine learning methods can suffer from spectral bias,\nfailing to capture high-frequency components. Designing an optimal hybrid\niterative solver--where, at each iteration, a solver is selected from an\nensemble of solvers to leverage their complementary strengths--poses a\nchallenging combinatorial problem. While the greedy selection strategy is\ndesirable for its constant-factor approximation guarantee to the optimal\nsolution, it requires knowledge of the true error at each step, which is\ngenerally unavailable in practice. We address this by proposing an approximate\ngreedy router that efficiently mimics a greedy approach to solver selection.\nEmpirical results on the Poisson and Helmholtz equations demonstrate that our\nmethod outperforms single-solver baselines and existing hybrid solver\napproaches, such as HINTS, achieving faster and more stable convergence.", "published": "2025-09-29 14:02:27", "link": "http://arxiv.org/abs/2509.24814v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "DyMoDreamer: World Modeling with Dynamic Modulation", "abstract": "A critical bottleneck in deep reinforcement learning (DRL) is sample\ninefficiency, as training high-performance agents often demands extensive\nenvironmental interactions. Model-based reinforcement learning (MBRL) mitigates\nthis by building world models that simulate environmental dynamics and generate\nsynthetic experience, improving sample efficiency. However, conventional world\nmodels process observations holistically, failing to decouple dynamic objects\nand temporal features from static backgrounds. This approach is computationally\ninefficient, especially for visual tasks where dynamic objects significantly\ninfluence rewards and decision-making performance. To address this, we\nintroduce DyMoDreamer, a novel MBRL algorithm that incorporates a dynamic\nmodulation mechanism to improve the extraction of dynamic features and enrich\nthe temporal information. DyMoDreamer employs differential observations derived\nfrom a novel inter-frame differencing mask, explicitly encoding object-level\nmotion cues and temporal dynamics. Dynamic modulation is modeled as stochastic\ncategorical distributions and integrated into a recurrent state-space model\n(RSSM), enhancing the model's focus on reward-relevant dynamics. Experiments\ndemonstrate that DyMoDreamer sets a new state-of-the-art on the Atari $100$k\nbenchmark with a $156.6$\\% mean human-normalized score, establishes a new\nrecord of $832$ on the DeepMind Visual Control Suite, and gains a $9.5$\\%\nperformance improvement after $1$M steps on the Crafter benchmark. Our code is\nreleased at https://github.com/Ultraman-Tiga1/DyMoDreamer.", "published": "2025-09-29 13:54:42", "link": "http://arxiv.org/abs/2509.24804v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-informed learning under mixing: How physical knowledge speeds up learning", "abstract": "A major challenge in physics-informed machine learning is to understand how\nthe incorporation of prior domain knowledge affects learning rates when data\nare dependent. Focusing on empirical risk minimization with physics-informed\nregularization, we derive complexity-dependent bounds on the excess risk in\nprobability and in expectation. We prove that, when the physical prior\ninformation is aligned, the learning rate improves from the (slow) Sobolev\nminimax rate to the (fast) optimal i.i.d. one without any sample-size deflation\ndue to data dependence.", "published": "2025-09-29 13:52:02", "link": "http://arxiv.org/abs/2509.24801v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Fidel-TS: A High-Fidelity Benchmark for Multimodal Time Series Forecasting", "abstract": "The evaluation of time series forecasting models is hindered by a critical\nlack of high-quality benchmarks, leading to a potential illusion of progress.\nExisting datasets suffer from issues ranging from pre-training data\ncontamination in the age of LLMs to the causal and description leakage\nprevalent in early multimodal designs. To address this, we formalize the core\nprinciples of high-fidelity benchmarking, focusing on data sourcing integrity,\nstrict causal soundness, and structural clarity. We introduce Fidel-TS, a new\nlarge-scale benchmark built from the ground up on these principles by sourcing\ndata from live APIs. Our extensive experiments validate this approach by\nexposing the critical biases and design limitations of prior benchmarks.\nFurthermore, we conclusively demonstrate that the causal relevance of textual\ninformation is the key factor in unlocking genuine performance gains in\nmultimodal forecasting.", "published": "2025-09-29 13:44:49", "link": "http://arxiv.org/abs/2509.24789v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Assessing the risk of future Dunkelflaute events for Germany using generative deep learning", "abstract": "The European electricity power grid is transitioning towards renewable energy\nsources, characterized by an increasing share of off- and onshore wind and\nsolar power. However, the weather dependency of these energy sources poses a\nchallenge to grid stability, with so-called Dunkelflaute events -- periods of\nlow wind and solar power generation -- being of particular concern due to their\npotential to cause electricity supply shortages. In this study, we investigate\nthe impact of these events on the German electricity production in the years\nand decades to come. For this purpose, we adapt a recently developed generative\ndeep learning framework to downscale climate simulations from the CMIP6\nensemble. We first compare their statistics to the historical record taken from\nERA5 data. Next, we use these downscaled simulations to assess plausible future\noccurrences of Dunkelflaute events in Germany under the optimistic low\n(SSP2-4.5) and high (SSP5-8.5) emission scenarios. Our analysis indicates that\nboth the frequency and duration of Dunkelflaute events in Germany in the\nensemble mean are projected to remain largely unchanged compared to the\nhistorical period. This suggests that, under the considered climate scenarios,\nthe associated risk is expected to remain stable throughout the century.", "published": "2025-09-29 13:44:22", "link": "http://arxiv.org/abs/2509.24788v1", "categories": ["cs.LG", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models", "abstract": "Molecular Dynamics (MD) is a powerful computational microscope for probing\nprotein functions. However, the need for fine-grained integration and the long\ntimescales of biomolecular events make MD computationally expensive. To address\nthis, several generative models have been proposed to generate surrogate\ntrajectories at lower cost. Yet, these models typically learn a fixed-lag\ntransition density, causing the training signal to be dominated by frequent but\nuninformative transitions. We introduce a new class of generative models, MSM\nEmulators, which instead learn to sample transitions across discrete states\ndefined by an underlying Markov State Model (MSM). We instantiate this class\nwith Markov Space Flow Matching (MarS-FM), whose sampling offers more than two\norders of magnitude speedup compared to implicit- or explicit-solvent MD\nsimulations. We benchmark Mars-FM ability to reproduce MD statistics through\nstructural observables such as RMSD, radius of gyration, and secondary\nstructure content. Our evaluation spans protein domains (up to 500 residues)\nwith significant chemical and structural diversity, including unfolding events,\nand enforces strict sequence dissimilarity between training and test sets to\nassess generalization. Across all metrics, MarS-FM outperforms existing\nmethods, often by a substantial margin.", "published": "2025-09-29 13:42:25", "link": "http://arxiv.org/abs/2509.24779v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Neural Message-Passing on Attention Graphs for Hallucination Detection", "abstract": "Large Language Models (LLMs) often generate incorrect or unsupported content,\nknown as hallucinations. Existing detection methods rely on heuristics or\nsimple models over isolated computational traces such as activations, or\nattention maps. We unify these signals by representing them as attributed\ngraphs, where tokens are nodes, edges follow attentional flows, and both carry\nfeatures from attention scores and activations. Our approach, CHARM, casts\nhallucination detection as a graph learning task and tackles it by applying\nGNNs over the above attributed graphs. We show that CHARM provably subsumes\nprior attention-based heuristics and, experimentally, it consistently\noutperforms other leading approaches across diverse benchmarks. Our results\nshed light on the relevant role played by the graph structure and on the\nbenefits of combining computational traces, whilst showing CHARM exhibits\npromising zero-shot performance on cross-dataset transfer.", "published": "2025-09-29 13:37:12", "link": "http://arxiv.org/abs/2509.24770v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "In-Context Learning of Temporal Point Processes with Foundation Inference Models", "abstract": "Modeling event sequences of multiple event types with marked temporal point\nprocesses (MTPPs) provides a principled way to uncover governing dynamical\nrules and predict future events. Current neural network approaches to MTPP\ninference rely on training separate, specialized models for each target system.\nWe pursue a radically different approach: drawing on amortized inference and\nin-context learning, we pretrain a deep neural network to infer, in-context,\nthe conditional intensity functions of event histories from a context defined\nby sets of event sequences. Pretraining is performed on a large synthetic\ndataset of MTPPs sampled from a broad distribution of Hawkes processes. Once\npretrained, our Foundation Inference Model for Point Processes (FIM-PP) can\nestimate MTPPs from real-world data without any additional training, or be\nrapidly finetuned to target systems. Experiments show that this amortized\napproach matches the performance of specialized models on next-event prediction\nacross common benchmark datasets.\n  Our pretrained model, repository and tutorials will soon be available online", "published": "2025-09-29 13:28:06", "link": "http://arxiv.org/abs/2509.24762v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bundle Network: a Machine Learning-Based Bundle Method", "abstract": "This paper presents Bundle Network, a learning-based algorithm inspired by\nthe Bundle Method for convex non-smooth minimization problems. Unlike classical\napproaches that rely on heuristic tuning of a regularization parameter, our\nmethod automatically learns to adjust it from data. Furthermore, we replace the\niterative resolution of the optimization problem that provides the search\ndirection-traditionally computed as a convex combination of gradients at\nvisited points-with a recurrent neural model equipped with an attention\nmechanism. By leveraging the unrolled graph of computation, our Bundle Network\ncan be trained end-to-end via automatic differentiation. Experiments on\nLagrangian dual relaxations of the Multi-Commodity Network Design and\nGeneralized Assignment problems demonstrate that our approach consistently\noutperforms traditional methods relying on grid search for parameter tuning,\nwhile generalizing effectively across datasets.", "published": "2025-09-29 12:59:49", "link": "http://arxiv.org/abs/2509.24736v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Who invented deep residual learning?", "abstract": "Modern AI is based on deep artificial neural networks (NNs). As of 2025, the\nmost cited scientific article of the 21st century is an NN paper on deep\nresidual learning with residual connections. Who invented this? We present a\ntimeline of the evolution of deep residual learning.", "published": "2025-09-29 12:57:35", "link": "http://arxiv.org/abs/2509.24732v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Beyond Softmax: A Natural Parameterization for Categorical Random Variables", "abstract": "Latent categorical variables are frequently found in deep learning\narchitectures. They can model actions in discrete reinforcement-learning\nenvironments, represent categories in latent-variable models, or express\nrelations in graph neural networks. Despite their widespread use, their\ndiscrete nature poses significant challenges to gradient-descent learning\nalgorithms. While a substantial body of work has offered improved gradient\nestimation techniques, we take a complementary approach. Specifically, we: 1)\nrevisit the ubiquitous $\\textit{softmax}$ function and demonstrate its\nlimitations from an information-geometric perspective; 2) replace the\n$\\textit{softmax}$ with the $\\textit{catnat}$ function, a function composed of\na sequence of hierarchical binary splits; we prove that this choice offers\nsignificant advantages to gradient descent due to the resulting diagonal Fisher\nInformation Matrix. A rich set of experiments - including graph structure\nlearning, variational autoencoders, and reinforcement learning - empirically\nshow that the proposed function improves the learning efficiency and yields\nmodels characterized by consistently higher test performance. $\\textit{Catnat}$\nis simple to implement and seamlessly integrates into existing codebases.\nMoreover, it remains compatible with standard training stabilization techniques\nand, as such, offers a better alternative to the $\\textit{softmax}$ function.", "published": "2025-09-29 12:55:50", "link": "http://arxiv.org/abs/2509.24728v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MAD: Manifold Attracted Diffusion", "abstract": "Score-based diffusion models are a highly effective method for generating\nsamples from a distribution of images. We consider scenarios where the training\ndata comes from a noisy version of the target distribution, and present an\nefficiently implementable modification of the inference procedure to generate\nnoiseless samples. Our approach is motivated by the manifold hypothesis,\naccording to which meaningful data is concentrated around some low-dimensional\nmanifold of a high-dimensional ambient space. The central idea is that noise\nmanifests as low magnitude variation in off-manifold directions in contrast to\nthe relevant variation of the desired distribution which is mostly confined to\non-manifold directions. We introduce the notion of an extended score and show\nthat, in a simplified setting, it can be used to reduce small variations to\nzero, while leaving large variations mostly unchanged. We describe how its\napproximation can be computed efficiently from an approximation to the standard\nscore and demonstrate its efficacy on toy problems, synthetic data, and real\ndata.", "published": "2025-09-29 12:40:20", "link": "http://arxiv.org/abs/2509.24710v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering", "abstract": "Recent trends in humanoid robot control have successfully employed imitation\nlearning to enable the learned generation of smooth, human-like trajectories\nfrom human data. While these approaches make more realistic motions possible,\nthey are limited by the amount of available motion data, and do not incorporate\nprior knowledge about the physical laws governing the system and its\ninteractions with the environment. Thus they may violate such laws, leading to\ndivergent trajectories and sliding contacts which limit real-world stability.\nWe address such limitations via a two-pronged learning strategy which leverages\nthe known physics of the system and fundamental control principles. First, we\nencode physics priors during supervised imitation learning to promote\ntrajectory feasibility. Second, we minimize drift at inference time by applying\na proportional-integral controller directly to the generated output state. We\nvalidate our method on various locomotion behaviors for the ergoCub humanoid\nrobot, where a physics-informed loss encourages zero contact foot velocity. Our\nexperiments demonstrate that the proposed approach is compatible with multiple\ncontrollers on a real robot and significantly improves the accuracy and\nphysical constraint conformity of generated trajectories.", "published": "2025-09-29 12:31:14", "link": "http://arxiv.org/abs/2509.24697v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "HyperHELM: Hyperbolic Hierarchy Encoding for mRNA Language Modeling", "abstract": "Language models are increasingly applied to biological sequences like\nproteins and mRNA, yet their default Euclidean geometry may mismatch the\nhierarchical structures inherent to biological data. While hyperbolic geometry\nprovides a better alternative for accommodating hierarchical data, it has yet\nto find a way into language modeling for mRNA sequences. In this work, we\nintroduce HyperHELM, a framework that implements masked language model\npre-training in hyperbolic space for mRNA sequences. Using a hybrid design with\nhyperbolic layers atop Euclidean backbone, HyperHELM aligns learned\nrepresentations with the biological hierarchy defined by the relationship\nbetween mRNA and amino acids. Across multiple multi-species datasets, it\noutperforms Euclidean baselines on 9 out of 10 tasks involving property\nprediction, with 10% improvement on average, and excels in out-of-distribution\ngeneralization to long and low-GC content sequences; for antibody region\nannotation, it surpasses hierarchy-aware Euclidean models by 3% in annotation\naccuracy. Our results highlight hyperbolic geometry as an effective inductive\nbias for hierarchical language modeling of mRNA sequences.", "published": "2025-09-29 12:04:15", "link": "http://arxiv.org/abs/2509.24655v1", "categories": ["cs.LG", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Learning Hamiltonian Dynamics at Scale: A Differential-Geometric Approach", "abstract": "By embedding physical intuition, network architectures enforce fundamental\nproperties, such as energy conservation laws, leading to plausible predictions.\nYet, scaling these models to intrinsically high-dimensional systems remains a\nsignificant challenge. This paper introduces Geometric Reduced-order\nHamiltonian Neural Network (RO-HNN), a novel physics-inspired neural network\nthat combines the conservation laws of Hamiltonian mechanics with the\nscalability of model order reduction. RO-HNN is built on two core components: a\nnovel geometrically-constrained symplectic autoencoder that learns a\nlow-dimensional, structure-preserving symplectic submanifold, and a geometric\nHamiltonian neural network that models the dynamics on the submanifold. Our\nexperiments demonstrate that RO-HNN provides physically-consistent, stable, and\ngeneralizable predictions of complex high-dimensional dynamics, thereby\neffectively extending the scope of Hamiltonian neural networks to\nhigh-dimensional physical systems.", "published": "2025-09-29 11:36:35", "link": "http://arxiv.org/abs/2509.24627v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluating classification performance across operating contexts: A comparison of decision curve analysis and cost curves", "abstract": "Classification models typically predict a score and use a decision threshold\nto produce a classification. Appropriate model evaluation should carefully\nconsider the context in which a model will be used, including the relative\nvalue of correct classifications of positive versus negative examples, which\naffects the threshold that should be used. Decision curve analysis (DCA) and\ncost curves are model evaluation approaches that assess the expected utility\nand expected loss of prediction models, respectively, across decision\nthresholds. We compared DCA and cost curves to determine how they are related,\nand their strengths and limitations. We demonstrate that decision curves are\nclosely related to a specific type of cost curve called a Brier curve. Both\ncurves are derived assuming model scores are calibrated and setting the\nclassification threshold using the relative value of correct positive and\nnegative classifications, and the x-axis of both curves are equivalent. Net\nbenefit (used for DCA) and Brier loss (used for Brier curves) will always\nchoose the same model as optimal at any given threshold. Across thresholds,\ndifferences in Brier loss are comparable whereas differences in net benefit\ncannot be compared. Brier curves are more generally applicable (when a wider\nrange of thresholds are plausible), and the area under the Brier curve is the\nBrier score. We demonstrate that reference lines common in each space can be\nincluded in either and suggest the upper envelope decision curve as a useful\ncomparison for DCA showing the possible gain in net benefit that could be\nachieved through recalibration alone.", "published": "2025-09-29 11:15:25", "link": "http://arxiv.org/abs/2509.24608v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CURA: Size Isnt All You Need -- A Compact Universal Architecture for On-Device Intelligence", "abstract": "Existing on-device AI architectures for resource-constrained environments\nface two critical limitations: they lack compactness, with parameter\nrequirements scaling proportionally to task complexity, and they exhibit poor\ngeneralizability, performing effectively only on specific application domains\n(e.g., models designed for regression tasks cannot adapt to natural language\nprocessing (NLP) applications). In this paper, we propose CURA, an architecture\ninspired by analog audio signal processing circuits that provides a compact and\nlightweight solution for diverse machine learning tasks across multiple\ndomains. Our architecture offers three key advantages over existing approaches:\n(1) Compactness: it requires significantly fewer parameters regardless of task\ncomplexity; (2) Generalizability: it adapts seamlessly across regression,\nclassification, complex NLP, and computer vision tasks; and (3) Complex pattern\nrecognition: it can capture intricate data patterns while maintaining extremely\nlow model complexity. We evaluated CURA across diverse datasets and domains.\nFor compactness, it achieved equivalent accuracy using up to 2,500 times fewer\nparameters compared to baseline models. For generalizability, it demonstrated\nconsistent performance across four NLP benchmarks and one computer vision\ndataset, nearly matching specialized existing models (achieving F1-scores up to\n90%). Lastly, it delivers superior forecasting accuracy for complex patterns,\nachieving 1.6 times lower mean absolute error and 2.1 times lower mean squared\nerror than competing models.", "published": "2025-09-29 11:06:37", "link": "http://arxiv.org/abs/2509.24601v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Safety-Critical Input-Constrained Nonlinear Intercept Guidance in Multiple Engagement Zones", "abstract": "This paper presents an input-constrained nonlinear guidance law to address\nthe problem of intercepting a stationary target in contested environments with\nmultiple defending agents. Contrary to prior approaches that rely on explicit\nknowledge of defender strategies or utilize conservative safety conditions\nbased on a defender's range, our work characterizes defender threats\ngeometrically through engagement zones that delineate inevitable interception\nregions. Outside these engagement zones, the interceptor remains invulnerable.\nThe proposed guidance law switches between a repulsive safety maneuver near\nthese zones and a pursuit maneuver outside their influence. To deal with\nmultiple engagement zones, we employ a smooth minimum function\n(log-sum-exponent approximation) that aggregates threats from all the zones\nwhile prioritizing the most critical threats. Input saturation is modeled and\nembedded in the non-holonomic vehicle dynamics so the controller respects\nactuator limits while maintaining stability. Numerical simulations with several\ndefenders demonstrate the proposed method's ability to avoid engagement zones\nand achieve interception across diverse initial conditions.", "published": "2025-09-29 17:04:39", "link": "http://arxiv.org/abs/2509.25053v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY", "math.DS"], "primary_category": "eess.SY"}
{"title": "MARLIN: Multi-Agent Reinforcement Learning with Murmuration Intelligence and LLM Guidance for Reservoir Management", "abstract": "As climate change intensifies extreme weather events, water disasters pose\ngrowing threats to global communities, making adaptive reservoir management\ncritical for protecting vulnerable populations and ensuring water security.\nModern water resource management faces unprecedented challenges from cascading\nuncertainties propagating through interconnected reservoir networks. These\nuncertainties, rooted in physical water transfer losses and environmental\nvariability, make precise control difficult. For example, sending 10 tons\ndownstream may yield only 8-12 tons due to evaporation and seepage. Traditional\ncentralized optimization approaches suffer from exponential computational\ncomplexity and cannot effectively handle such real-world uncertainties, while\nexisting multi-agent reinforcement learning (MARL) methods fail to achieve\neffective coordination under uncertainty. To address these challenges, we\npresent MARLIN, a decentralized reservoir management framework inspired by\nstarling murmurations intelligence. Integrating bio-inspired alignment,\nseparation, and cohesion rules with MARL, MARLIN enables individual reservoirs\nto make local decisions while achieving emergent global coordination. In\naddition, a LLM provides real-time reward shaping signals, guiding agents to\nadapt to environmental changes and human-defined preferences. Experiments on\nreal-world USGS data show that MARLIN improves uncertainty handling by 23\\%,\ncuts computation by 35\\%, and accelerates flood response by 68\\%, exhibiting\nsuper-linear coordination, with complexity scaling 5.4x from 400 to 10,000\nnodes. These results demonstrate MARLIN's potential for disaster prevention and\nprotecting communities through intelligent, scalable water resource management.", "published": "2025-09-29 16:53:24", "link": "http://arxiv.org/abs/2509.25034v1", "categories": ["cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "AIPOM: Agent-aware Interactive Planning for Multi-Agent Systems", "abstract": "Large language models (LLMs) are being increasingly used for planning in\norchestrated multi-agent systems. However, existing LLM-based approaches often\nfall short of human expectations and, critically, lack effective mechanisms for\nusers to inspect, understand, and control their behaviors. These limitations\ncall for enhanced transparency, controllability, and human oversight. To\naddress this, we introduce AIPOM, a system supporting human-in-the-loop\nplanning through conversational and graph-based interfaces. AIPOM enables users\nto transparently inspect, refine, and collaboratively guide LLM-generated\nplans, significantly enhancing user control and trust in multi-agent workflows.\nOur code and demo video are available at https://github.com/megagonlabs/aipom.", "published": "2025-09-29 14:12:06", "link": "http://arxiv.org/abs/2509.24826v1", "categories": ["cs.HC", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Prompting Robot Teams with Natural Language", "abstract": "This paper presents a framework towards prompting multi-robot teams with\nhigh-level tasks using natural language expressions. Our objective is to use\nthe reasoning capabilities demonstrated by recent language models in\nunderstanding and decomposing human expressions of intent, and repurpose these\nfor multi-robot collaboration and decision-making. The key challenge is that an\nindividual's behavior in a collective can be hard to specify and interpret, and\nmust continuously adapt to actions from others. This necessitates a framework\nthat possesses the representational capacity required by the logic and\nsemantics of a task, and yet supports decentralized and interactive real-time\noperation. We solve this dilemma by recognizing that a task can be represented\nas a deterministic finite automaton (DFA), and that recurrent neural networks\n(RNNs) can encode numerous automata. This allows us to distill the logic and\nsequential decompositions of sub-tasks obtained from a language model into an\nRNN, and align its internal states with the semantics of a given task. By\ntraining a graph neural network (GNN) control policy that is conditioned on the\nhidden states of the RNN and the language embeddings, our method enables robots\nto execute task-relevant actions in a decentralized manner. We present\nevaluations of this single light-weight interpretable model on various\nsimulated and real-world multi-robot tasks that require sequential and\ncollaborative behavior by the team -- sites.google.com/view/prompting-teams.", "published": "2025-09-29 10:29:18", "link": "http://arxiv.org/abs/2509.24575v1", "categories": ["cs.RO", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Diffuse Domain Methods with Dirichlet Boundary Conditions", "abstract": "The solution of partial differential equations (PDEs) on complex domains\noften presents a significant computational challenge by requiring the\ngeneration of fitted meshes. The Diffuse Domain Method (DDM) is an alternative\nwhich reformulates the problem on a larger, simple domain where the complex\ngeometry is represented by a smooth phase-field function.\n  This paper introduces and analyses several new DDM methods for solving\nproblems with Dirichlet boundary conditions. We derive two new methods from the\nmixed formulation of the governing equations. This approach transforms the\nessential Dirichlet conditions into natural boundary conditions. Additionally,\nwe develop coercive formulations based on Nitsche's method, and provide proofs\nof coercivity for all new and key existing approximations.\n  Numerical experiments demonstrate the improved accuracy of the new methods,\nand reveal the balance between $L^2$ and $H^1$ errors. The practical\neffectiveness of this approach is demonstrated through the simulation of the\nincompressible Navier-Stokes equations on a benchmark fluid dynamics problems.", "published": "2025-09-29 17:41:16", "link": "http://arxiv.org/abs/2509.25115v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A posteriori existence of strong solutions to the Navier-Stokes equations in 3D", "abstract": "Global existence of strong solutions to the three-dimensional incompressible\nNavier-Stokes equations remains an open problem. A posteriori existence results\noffer a way to rigorously verify the existence of strong solutions by ruling\nout blow-up on a certain time interval, using only numerical solutions. In this\nwork we present such a result for the Navier-Stokes equations subject to\nperiodic boundary conditions, which makes use of a version of the celebrated\nblow-up criterion in the critical space $L^\\infty(L^3)$ by Iskauriaza,\nSer\\\"egin and Shverak (2003). Our approach is based on a conditional stability\nestimate in $L^2$ and $L^3$. The a posteriori criterion that, if satisfied,\nverifies existence of strong solutions, involves only negative Sobolev norms of\nthe residual. We apply the criterion to numerical approximations computed with\nmixed finite elements and an implicit Euler time discretisation. A posteriori\nerror estimates allow us to derive a fully computable criterion without\nimposing any extra assumptions on the solution. While limited to short time\nintervals, with sufficient computational resources in principle the criterion\nmight allow for a verification over longer time intervals than what can be\nachieved by theoretical means.", "published": "2025-09-29 17:39:17", "link": "http://arxiv.org/abs/2509.25105v1", "categories": ["math.NA", "cs.NA", "math.AP", "35Q30, 35B44, 65M15, 65M60, 76D05"], "primary_category": "math.NA"}
{"title": "An Efficient Finite Element Method for Multi-dimensional Nonlocal Laplacian on Uniform Grids", "abstract": "Computing the stiffness matrix for the finite element discretization of the\nnonlocal Laplacian on unstructured meshes is difficult, because the operator is\nnonlocal and can even be singular. In this paper, we focus on the\n$C^0$-piecewise linear finite element method (FEM) for the nonlocal Laplacian\non uniform grids within a $d$-dimensional rectangular domain. By leveraging the\nconnection between FE bases and B-splines (having attractive convolution\nproperties), we can reduce the involved $2d$-dimensional integrals for the\nstiffness matrix entries into integrations over $d$-dimensional balls with\nexplicit integrands involving cubic B-splines and the kernel functions, which\nallows for explicit study of the singularities and accurate evaluations of such\nintegrals in spherical coordinates. We show the nonlocal stiffness matrix has a\nblock-Toeplitz structure, so the matrix-vector multiplication can be\nimplemented using fast Fourier transform (FFT). In addition, when the\ninteraction radius $\\delta\\to 0^+,$ the nonlocal stiffness matrix automatically\nreduces to the local one. Although our semi-analytic approach on uniform grids\ncannot be extended to general domains with unstructured meshes, the resulting\nsolver can seamlessly integrate with the grid-overlay (Go) technique for the\nnonlocal Laplacian on arbitrary bounded domains.", "published": "2025-09-29 13:59:18", "link": "http://arxiv.org/abs/2509.24809v1", "categories": ["math.NA", "cs.NA", "34B10, 65R20, 15B05, 41A25, 74S05", "G.1.8"], "primary_category": "math.NA"}
{"title": "Symmetry-preserving random batch Ewald method for constant-potential simulation of electrochemical systems", "abstract": "Constant potential molecular dynamics simulation plays important role for\napplications of electrochemical systems, yet the calculation of charge\nfluctuation on electrodes remains a computational bottleneck. We propose a\nhighly scalable, symmetry-preserving random batch Ewald (SRBE) algorithm to\naddress this challenge. The SRBE algorithm deterministically computes the\nlow-frequency components along the direction perpendicular to electrodes, while\nefficiently approximating the remaining components using random batch sampling.\nThis approach simultaneously reduces charge and force fluctuations while\nsatisfying the symmetry-preserving mean field condition in anisotropic systems\nwith large aspect ratios. Numerical experiments on electrode/ionic liquid\nsystems validate the high accuracy of the SRBE method in capturing dynamic\ncharging processes and equilibrium electric double layer structures. The SRBE\nmethod achieves parallel efficiency improvements of up to two orders of\nmagnitude compared with conventional FFT-based algorithms. These findings\nhighlight its strong potential for enabling large-scale electrochemical\nsimulations and its broad applicability to practical problems in the field.", "published": "2025-09-29 13:07:14", "link": "http://arxiv.org/abs/2509.24742v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "82M37, 65C35, 65T50, 65Y20"], "primary_category": "physics.comp-ph"}
{"title": "Coupling Physics Informed Neural Networks with External Solvers", "abstract": "The current work aims to incorporate physics-based loss in Physics Informed\nNeural Network (PINN) directly using the numerical residual obtained from the\ngoverning equation in any dicretized forward solver. PINN's major difficulties\nin coupling with external forward solvers arise from the inability to access\nthe discretized form (Finite difference, finite volume, finite element, etc.)\nof the governing equation directly through the network and to include them in\nits computational graph. This poses a significant challenge to conventional\nautomatic-differentiation-based derivative computation of physics-based loss\nterms concerning the neural network hyperparameters if gradient-based\noptimization techniques are adopted. Therefore, we propose modifying the\nphysics-based loss term to account for the residual arising from the external\nsolver and to compute the derivative required for the optimization machinery.\nThe proposed methodologies are demonstrated on benchmark full-order and\nreduced-order systems.", "published": "2025-09-29 11:19:22", "link": "http://arxiv.org/abs/2509.24615v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Universal $L_2$-approximation using median lattice algorithms", "abstract": "We study the problem of multivariate $L_2$-approximation of functions in a\nweighted Korobov space using a median lattice-based algorithm recently proposed\nby the authors. In the original work, the algorithm requires knowledge of the\nsmoothness and weights of the Korobov space to construct the hyperbolic cross\nindex set, where each coefficient is estimated via the median of approximations\nobtained from randomly shifted, randomly chosen rank-1 lattice rules. In this\npaper, we introduce a \\emph{universal median lattice-based algorithm}, which\neliminates the need for any prior information on smoothness and weights.\nAlthough the tractability property of the algorithm slightly deteriorates, we\nprove that, for individual functions in the Korobov space with arbitrary\nsmoothness and (downward-closed) weights, it achieves an $L_2$-approximation\nerror arbitrarily close to the optimal rate with respect to the number of\nfunction evaluations.", "published": "2025-09-29 10:45:37", "link": "http://arxiv.org/abs/2509.24582v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spectral equivalence of unsymmetric kernel matrices and applications", "abstract": "Symmetric kernel matrices are a well researched topic in the literature of\nkernel based approximation. In particular stability properties in terms of\nlower bounds on the smallest eigenvalue of such symmetric kernel matrices are\nthoroughly investigated, as they play a fundamental role in theory and\npractice. In this work, we focus on unsymmetric kernel matrices and derive\nstability properties under small shifts by establishing a spectral equivalence\nto their unshifted, symmetric versions. This extends and generalizes results\nfor translational invariant kernels upon Quak et al [SIAM Journal on Math.\nAnalysis, 1993] and Sivakumar and Ward [Numerische Mathematik, 1993], however\nfocussing instead on finitely smooth kernels. As applications, we consider\nconvolutional kernels over domains, which are no longer translational\ninvariant, but which are still an important class of kernels for applications.\nFor these, we derive novel lower bounds for the smallest eigenvalue of the\nkernel matrices in terms of the separation distance of the data points, and\nthus derive stability bounds in terms of the condition number.", "published": "2025-09-29 10:14:14", "link": "http://arxiv.org/abs/2509.24561v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Strong Basin of Attraction for Unmixing Kernels With the Variable Projection Method", "abstract": "The problem of recovering a mixture of spike signals convolved with distinct\npoint spread functions (PSFs) lying on a parametric manifold, under the\nassumption that the spike locations are known, is studied. The PSF unmixing\nproblem is formulated as a projected non-linear least squares estimator. A\nlower bound on the radius of the region of strong convexity is established in\nthe presence of noise as a function of the manifold coherence and Lipschitz\nproperties, guaranteeing convergence and stability of the optimization program.\nNumerical experiments highlight the speed of decay of the PSF class in the\nproblem's conditioning and confirm theoretical findings. Finally, the proposed\nestimator is deployed on real-world spectroscopic data from laser-induced\nbreakdown spectroscopy (LIBS), removing the need for manual calibration and\nvalidating the method's practical relevance.", "published": "2025-09-29 08:16:12", "link": "http://arxiv.org/abs/2509.24428v1", "categories": ["eess.SP", "cs.NA", "math.NA"], "primary_category": "eess.SP"}
{"title": "MDD-Thinker: Towards Large Reasoning Models for Major Depressive Disorder Diagnosis", "abstract": "Background Major depressive disorder (MDD) is a leading cause of global\ndisability, yet current diagnostic approaches often rely on subjective\nassessments and lack the ability to integrate multimodal clinical information.\nLarge language models (LLMs) hold promise for enhancing diagnostic accuracy\nthrough advanced reasoning but face challenges in interpretability,\nhallucination, and reliance on synthetic data.\n  Methods We developed MDD-Thinker, an LLM-based diagnostic framework that\nintegrates supervised fine-tuning (SFT) with reinforcement learning (RL) to\nstrengthen reasoning ability and interpretability. Using the UK Biobank\ndataset, we generated 40,000 reasoning samples, supplemented with 10,000\nsamples from publicly available mental health datasets. The model was\nfine-tuned on these reasoning corpora, and its diagnostic and reasoning\nperformance was evaluated against machine learning, deep learning, and\nstate-of-the-art LLM baselines.\n  Findings MDD-Thinker achieved an accuracy of 0.8268 and F1-score of 0.8081,\nsignificantly outperforming traditional baselines such as SVM and MLP, as well\nas general-purpose LLMs. Incorporating both SFT and RL yielded the greatest\nimprovements, with relative gains of 29.0% in accuracy, 38.1% in F1-score, and\n34.8% in AUC. Moreover, the model demonstrated comparable reasoning performance\ncompared to much larger LLMs, while maintaining computational efficiency.\n  Interpretation This study presents the first reasoning-enhanced LLM framework\nfor MDD diagnosis trained on large-scale real-world clinical data. By\nintegrating SFT and RL, MDD-Thinker balances accuracy, interpretability, and\nefficiency, offering a scalable approach for intelligent psychiatric\ndiagnostics. These findings suggest that reasoning-oriented LLMs can provide\nclinically reliable support for MDD detection and may inform broader\napplications in mental health care.", "published": "2025-09-29 02:56:38", "link": "http://arxiv.org/abs/2509.24217v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Numerical and analytical modeling of heat equation in current-carrying conductors using the heat equation implemented using Finite-JAX", "abstract": "Current-carrying conductors inevitably experience resistive heating due to\nthe finite electrical conductivity of the material. The resulting temperature\ndistribution within the wire has essential implications for structural\nintegrity, efficiency, and long-term reliability of electronic and power\nsystems. In this work, we model the spatiotemporal evolution of heat in a\ncurrent-carrying wire using the classical heat conduction equation. In a\ntwo-dimensional formulation, heat transport is considered both along and across\nthe conductor. The governing partial differential equation is discretized using\nfinite-difference methods implemented using Finite-JAX under appropriate\ninitial and boundary conditions, including the Dirichlet condition relevant to\npractical scenarios. Time integration is performed using the explicit scheme,\nand stability constraints are systematically examined. To assess the accuracy\nof the numerical approach, we compare the computed temperature fields with the\nexact analytical solution of the heat equation for canonical geometry. Results\nshow that the numerical prediction converges toward the analytical solution,\nwith error norms decreasing at the expected order of accuracy. This study\ndemonstrates how the heat equation provides a rigorous mathematical foundation\nfor modeling resistive heating in conductors.", "published": "2025-09-29 01:23:42", "link": "http://arxiv.org/abs/2509.24162v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "AlphaSAGE: Structure-Aware Alpha Mining via GFlowNets for Robust Exploration", "abstract": "The automated mining of predictive signals, or alphas, is a central challenge\nin quantitative finance. While Reinforcement Learning (RL) has emerged as a\npromising paradigm for generating formulaic alphas, existing frameworks are\nfundamentally hampered by a triad of interconnected issues. First, they suffer\nfrom reward sparsity, where meaningful feedback is only available upon the\ncompletion of a full formula, leading to inefficient and unstable exploration.\nSecond, they rely on semantically inadequate sequential representations of\nmathematical expressions, failing to capture the structure that determine an\nalpha's behavior. Third, the standard RL objective of maximizing expected\nreturns inherently drives policies towards a single optimal mode, directly\ncontradicting the practical need for a diverse portfolio of non-correlated\nalphas. To overcome these challenges, we introduce AlphaSAGE (Structure-Aware\nAlpha Mining via Generative Flow Networks for Robust Exploration), a novel\nframework is built upon three cornerstone innovations: (1) a structure-aware\nencoder based on Relational Graph Convolutional Network (RGCN); (2) a new\nframework with Generative Flow Networks (GFlowNets); and (3) a dense,\nmulti-faceted reward structure. Empirical results demonstrate that AlphaSAGE\noutperforms existing baselines in mining a more diverse, novel, and highly\npredictive portfolio of alphas, thereby proposing a new paradigm for automated\nalpha mining. Our code is available at https://github.com/BerkinChen/AlphaSAGE.", "published": "2025-09-29 17:06:07", "link": "http://arxiv.org/abs/2509.25055v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Simulation of the Heston stochastic local volatility model: implicit and explicit approaches", "abstract": "The Heston stochastic-local volatility (HSLV) model is widely used to capture\nboth market calibration and realistic volatility dynamics, but simulating its\nCIR-type variance process is numerically challenging.This paper compare two\nalternative schemes for HSLV simulation: the truncated Euler method and the\nbackward Euler method with the conventional Euler and almost exact simulation\nmethods in \\cite{van2014heston} by using a Monte Carlo method.Numerical results\nshow that the truncated method achieves strong convergence and remains robust\nunder high volatility, while the backward method provides the smallest errors\nand most stable performance in stress scenarios, though at higher computational\ncost.", "published": "2025-09-29 08:31:52", "link": "http://arxiv.org/abs/2509.24449v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "From Headlines to Holdings: Deep Learning for Smarter Portfolio Decisions", "abstract": "Deep learning offers new tools for portfolio optimization. We present an\nend-to-end framework that directly learns portfolio weights by combining Long\nShort-Term Memory (LSTM) networks to model temporal patterns, Graph Attention\nNetworks (GAT) to capture evolving inter-stock relationships, and sentiment\nanalysis of financial news to reflect market psychology. Unlike prior\napproaches, our model unifies these elements in a single pipeline that produces\ndaily allocations. It avoids the traditional two-step process of forecasting\nasset returns and then applying mean--variance optimization (MVO), a sequence\nthat can introduce instability. We evaluate the framework on nine U.S. stocks\nspanning six sectors, chosen to balance sector diversity and news coverage. In\nthis setting, the model delivers higher cumulative returns and Sharpe ratios\nthan equal-weighted and CAPM-based MVO benchmarks. Although the stock universe\nis limited, the results underscore the value of integrating price, relational,\nand sentiment signals for portfolio management and suggest promising directions\nfor scaling the approach to larger, more diverse asset sets.", "published": "2025-09-29 00:42:24", "link": "http://arxiv.org/abs/2509.24144v1", "categories": ["q-fin.PM", "q-fin.CP", "q-fin.ST", "stat.ML"], "primary_category": "q-fin.PM"}
{"title": "Eigenvector overlaps of sample covariance matrices with intersecting time periods", "abstract": "We compute exactly the overlap between the eigenvectors of two large\nempirical covariance matrices computed over intersecting time intervals,\ngeneralizing the results obtained previously for non-intersecting intervals.\nOur method relies on a particular form of Girko linearisation and extended\nlocal laws. We check our results numerically and apply them to financial data.", "published": "2025-09-29 17:18:37", "link": "http://arxiv.org/abs/2509.25076v1", "categories": ["cond-mat.stat-mech", "physics.data-an", "q-fin.MF", "60B20"], "primary_category": "cond-mat.stat-mech"}
{"title": "When risk defies order: On the limits of fractional stochastic dominance", "abstract": "Motivated by recent work on monotone additive statistics and questions\nregarding optimal risk sharing for return-based risk measures, we investigate\nthe existence, structure, and applications of Meyer risk measures. Those are\nmonetary risk measures consistent with fractional stochastic orders suggested\nby Meyer (1977a,b) as refinement of second-order stochastic dominance (SSD).\nThese so-called $v$-SD orders are based on a threshold utility function $v$.\nThe test utilities defining the associated order are those at least as risk\naverse in absolute terms as $v$. The generality of $v$ allows to subsume SSD\nand other examples from the literature. The structure of risk measures\nrespecting the $v$-SD order is clarified by two types of representations. The\nexistence of nontrivial examples is more subtle: for many choices of $v$\noutside the exponential (CARA) class, they do not exist. Additional properties\nlike convexity or positive homogeneity further restrict admissible examples,\neven within the CARA class. We present impossibility theorems that demonstrate\na deeper link between the axiomatic structure of monetary risk measures and SSD\nthan previously acknowledged. The study concludes with two applications:\nportfolio optimisation under a Meyer risk measure as objective, and risk\nassessment of financial time series data.", "published": "2025-09-29 13:15:06", "link": "http://arxiv.org/abs/2509.24747v1", "categories": ["q-fin.MF", "q-fin.RM"], "primary_category": "q-fin.MF"}
{"title": "STRAPSim: A Portfolio Similarity Metric for ETF Alignment and Portfolio Trades", "abstract": "Accurately measuring portfolio similarity is critical for a wide range of\nfinancial applications, including Exchange-traded Fund (ETF) recommendation,\nportfolio trading, and risk alignment. Existing similarity measures often rely\non exact asset overlap or static distance metrics, which fail to capture\nsimilarities among the constituents (e.g., securities within the portfolio) as\nwell as nuanced relationships between partially overlapping portfolios with\nheterogeneous weights. We introduce STRAPSim (Semantic, Two-level,\nResidual-Aware Portfolio Similarity), a novel method that computes portfolio\nsimilarity by matching constituents based on semantic similarity, weighting\nthem according to their portfolio share, and aggregating results via\nresidual-aware greedy alignment. We benchmark our approach against Jaccard,\nweighted Jaccard, as well as BERTScore-inspired variants across public\nclassification, regression, and recommendation tasks, as well as on corporate\nbond ETF datasets. Empirical results show that our method consistently\noutperforms baselines in predictive accuracy and ranking alignment, achieving\nthe highest Spearman correlation with return-based similarity. By leveraging\nconstituent-aware matching and dynamic reweighting, portfolio similarity offers\na scalable, interpretable framework for comparing structured asset baskets,\ndemonstrating its utility in ETF benchmarking, portfolio construction, and\nsystematic execution.", "published": "2025-09-29 00:57:41", "link": "http://arxiv.org/abs/2509.24151v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Quantitative convergence of trained single layer neural networks to Gaussian processes", "abstract": "In this paper, we study the quantitative convergence of shallow neural\nnetworks trained via gradient descent to their associated Gaussian processes in\nthe infinite-width limit.\n  While previous work has established qualitative convergence under broad\nsettings, precise, finite-width estimates remain limited, particularly during\ntraining.\n  We provide explicit upper bounds on the quadratic Wasserstein distance\nbetween the network output and its Gaussian approximation at any training time\n$t \\ge 0$, demonstrating polynomial decay with network width.\n  Our results quantify how architectural parameters, such as width and input\ndimension, influence convergence, and how training dynamics affect the\napproximation error.", "published": "2025-09-29 09:59:27", "link": "http://arxiv.org/abs/2509.24544v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Training Agents Inside of Scalable World Models", "abstract": "World models learn general knowledge from videos and simulate experience for\ntraining behaviors in imagination, offering a path towards intelligent agents.\nHowever, previous world models have been unable to accurately predict object\ninteractions in complex environments. We introduce Dreamer 4, a scalable agent\nthat learns to solve control tasks by reinforcement learning inside of a fast\nand accurate world model. In the complex video game Minecraft, the world model\naccurately predicts object interactions and game mechanics, outperforming\nprevious world models by a large margin. The world model achieves real-time\ninteractive inference on a single GPU through a shortcut forcing objective and\nan efficient transformer architecture. Moreover, the world model learns general\naction conditioning from only a small amount of data, allowing it to extract\nthe majority of its knowledge from diverse unlabeled videos. We propose the\nchallenge of obtaining diamonds in Minecraft from only offline data, aligning\nwith practical applications such as robotics where learning from environment\ninteraction can be unsafe and slow. This task requires choosing sequences of\nover 20,000 mouse and keyboard actions from raw pixels. By learning behaviors\nin imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft\npurely from offline data, without environment interaction. Our work provides a\nscalable recipe for imagination training, marking a step towards intelligent\nagents.", "published": "2025-09-29 09:42:27", "link": "http://arxiv.org/abs/2509.24527v1", "categories": ["cs.AI", "cs.LG", "cs.RO", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Preference-Based Dynamic Ranking Structure Recognition", "abstract": "Preference-based data often appear complex and noisy but may conceal\nunderlying homogeneous structures. This paper introduces a novel framework of\nranking structure recognition for preference-based data. We first develop an\napproach to identify dynamic ranking groups by incorporating temporal penalties\ninto a spectral estimation for the celebrated Bradley-Terry model. To detect\nstructural changes, we introduce an innovative objective function and present a\npracticable algorithm based on dynamic programming. Theoretically, we establish\nthe consistency of ranking group recognition by exploiting properties of a\nrandom `design matrix' induced by a reversible Markov chain. We also tailor a\ngroup inverse technique to quantify the uncertainty in item ability estimates.\nAdditionally, we prove the consistency of structure change recognition,\nensuring the robustness of the proposed framework. Experiments on both\nsynthetic and real-world datasets demonstrate the practical utility and\ninterpretability of our approach.", "published": "2025-09-29 09:06:05", "link": "http://arxiv.org/abs/2509.24493v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Interpretable Kernel Representation Learning at Scale: A Unified Framework Utilizing Nystr\u00f6m Approximation", "abstract": "Kernel methods provide a theoretically grounded framework for non-linear and\nnon-parametric learning, with strong analytic foundations and statistical\nguarantees. Yet, their scalability has long been limited by prohibitive time\nand memory costs. While progress has been made in scaling kernel regression, no\nframework exists for scalable kernel-based representation learning, restricting\ntheir use in the era of foundation models where representations are learned\nfrom massive unlabeled data. We introduce KREPES -- a unified, scalable\nframework for kernel-based representation learning via Nystr\\\"om approximation.\nKREPES accommodates a wide range of unsupervised and self-supervised losses,\nand experiments on large image and tabular datasets demonstrate its efficiency.\nCrucially, KREPES enables principled interpretability of the learned\nrepresentations, an immediate benefit over deep models, which we substantiate\nthrough dedicated analysis.", "published": "2025-09-29 08:45:40", "link": "http://arxiv.org/abs/2509.24467v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Convergence of graph Dirichlet energies and graph Laplacians on intersecting manifolds of varying dimensions", "abstract": "We study $\\Gamma$-convergence of graph Dirichlet energies and spectral\nconvergence of graph Laplacians on unions of intersecting manifolds of\npotentially different dimensions. Our investigation is motivated by problems of\nmachine learning, as real-world data often consist of parts or classes with\ndifferent intrinsic dimensions. An important challenge is to understand which\nmachine learning methods adapt to such varied dimensionalities. We investigate\nthe standard unnormalized and the normalized graph Dirichlet energies. We show\nthat the unnormalized energy and its associated graph Laplacian asymptotically\nonly sees the variations within the manifold of the highest dimension. On the\nother hand, we prove that the normalized Dirichlet energy converges to a\n(tensorized) Dirichlet energy on the union of manifolds that adapts to all\ndimensions simultaneously. We also establish the related spectral convergence\nand present a few numerical experiments to illustrate our findings.", "published": "2025-09-29 08:39:45", "link": "http://arxiv.org/abs/2509.24458v1", "categories": ["math.AP", "math.SP", "stat.ML", "49J55, 49J45, 60D05, 49R50, 68R10, 62G20"], "primary_category": "math.AP"}
{"title": "AuON: A Linear-time Alternative to Semi-Orthogonal Momentum Updates", "abstract": "Orthogonal gradient updates have emerged as a promising direction in\noptimization for machine learning. However, traditional approaches such as\nSVD/QR decomposition incur prohibitive computational costs of O(n^3) and\nunderperform compared to well-tuned SGD with momentum, since momentum is\napplied only after strict orthogonalization. Recent advances, such as Muon,\nimprove efficiency by applying momentum before orthogonalization and producing\nsemi-orthogonal matrices via Newton-Schulz iterations, reducing complexity to\nO(n^2). Nevertheless, quadratic costs remain a bottleneck.\n  In this work, we study the semi-orthogonal properties of momentum-based\nupdates and develop a method to bound momentum updates under a spectral-norm\ntrust region, preserving directional information without requiring explicit\nsemi-orthogonalization.\n  We propose AuON (Alternative Unit-norm momentum updates by Normalized\nnonlinear scaling), a linear-time optimizer that achieves strong performance\nwithout constructing semi-orthogonal matrices, while preserving structural\nalignment and reconditioning ill-posed updates. Our approach combines\nhyperbolic-cosine RMS scaling transformations with normalization, demonstrating\nboth effectiveness and computational efficiency compared to Newton-Schulz\nmethods. We further introduce a hybrid variant (Hybrid-AuON) that applies a\nsingle Newton-Schulz iteration. Experiments across vision and language\nbenchmarks show that AuON and its hybrid variant achieve performance comparable\nto strong baselines such as AdamW and Muon.\n  Code is available at: https://github.com/ryyzn9/AuON", "published": "2025-09-29 06:03:53", "link": "http://arxiv.org/abs/2509.24320v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PEARL: Performance-Enhanced Aggregated Representation Learning", "abstract": "Representation learning is a key technique in modern machine learning that\nenables models to identify meaningful patterns in complex data. However,\ndifferent methods tend to extract distinct aspects of the data, and relying on\na single approach may overlook important insights relevant to downstream tasks.\nThis paper proposes a performance-enhanced aggregated representation learning\nmethod, which combines multiple representation learning approaches to improve\nthe performance of downstream tasks. The framework is designed to be general\nand flexible, accommodating a wide range of loss functions commonly used in\nmachine learning models. To ensure computational efficiency, we use surrogate\nloss functions to facilitate practical weight estimation. Theoretically, we\nprove that our method asymptotically achieves optimal performance in downstream\ntasks, meaning that the risk of our predictor is asymptotically equivalent to\nthe theoretical minimum. Additionally, we derive that our method asymptotically\nassigns nonzero weights to correctly specified models. We evaluate our method\non diverse tasks by comparing it with advanced machine learning models. The\nexperimental results demonstrate that our method consistently outperforms\nbaseline methods, showing its effectiveness and broad applicability in\nreal-world machine learning scenarios.", "published": "2025-09-29 05:50:29", "link": "http://arxiv.org/abs/2509.24312v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "ActiveCQ: Active Estimation of Causal Quantities", "abstract": "Estimating causal quantities (CQs) typically requires large datasets, which\ncan be expensive to obtain, especially when measuring individual outcomes is\ncostly. This challenge highlights the importance of sample-efficient active\nlearning strategies. To address the narrow focus of prior work on the\nconditional average treatment effect, we formalize the broader task of Actively\nestimating Causal Quantities (ActiveCQ) and propose a unified framework for\nthis general problem. Built upon the insight that many CQs are integrals of\nregression functions, our framework models the regression function with a\nGaussian Process. For the distribution component, we explore both a baseline\nusing explicit density estimators and a more integrated method using\nconditional mean embeddings in a reproducing kernel Hilbert space. This latter\napproach offers key advantages: it bypasses explicit density estimation,\noperates within the same function space as the GP, and adaptively refines the\ndistributional model after each update. Our framework enables the principled\nderivation of acquisition strategies from the CQ's posterior uncertainty; we\ninstantiate this principle with two utility functions based on information gain\nand total variance reduction. A range of simulated and semi-synthetic\nexperiments demonstrate that our principled framework significantly outperforms\nrelevant baselines, achieving substantial gains in sample efficiency across a\nvariety of CQs.", "published": "2025-09-29 05:14:37", "link": "http://arxiv.org/abs/2509.24293v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Semantic Editing with Coupled Stochastic Differential Equations", "abstract": "Editing the content of an image with a pretrained text-to-image model remains\nchallenging. Existing methods often distort fine details or introduce\nunintended artifacts. We propose using coupled stochastic differential\nequations (coupled SDEs) to guide the sampling process of any pre-trained\ngenerative model that can be sampled by solving an SDE, including diffusion and\nrectified flow models. By driving both the source image and the edited image\nwith the same correlated noise, our approach steers new samples toward the\ndesired semantics while preserving visual similarity to the source. The method\nworks out-of-the-box-without retraining or auxiliary networks-and achieves high\nprompt fidelity along with near-pixel-level consistency. These results position\ncoupled SDEs as a simple yet powerful tool for controlled generative AI.", "published": "2025-09-29 03:05:16", "link": "http://arxiv.org/abs/2509.24223v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Blockwise Missingness meets AI: A Tractable Solution for Semiparametric Inference", "abstract": "We consider parameter estimation and inference when data feature blockwise,\nnon-monotone missingness. Our approach, rooted in semiparametric theory and\ninspired by prediction-powered inference, leverages off-the-shelf AI\n(predictive or generative) models to handle missing completely at random\nmechanisms, by finding an approximation of the optimal estimating equation\nthrough a novel and tractable Restricted Anova hierarchY (RAY) approximation.\nThe resulting Inference for Blockwise Missingness(RAY), or IBM(RAY) estimator\nincorporates pre-trained AI models and carefully controls asymptotic variance\nby tuning model-specific hyperparameters. We then extend IBM(RAY) to a general\nclass of estimators. We find the most efficient estimator in this class, which\nwe call IBM(Adaptive), by solving a constrained quadratic programming problem.\nAll IBM estimators are unbiased, and, crucially, asymptotically achieving\nguaranteed efficiency gains over a naive complete-case estimator, regardless of\nthe predictive accuracy of the AI models used. We demonstrate the finite-sample\nperformance and numerical stability of our method through simulation studies\nand an application to surface protein abundance estimation.", "published": "2025-09-29 01:17:28", "link": "http://arxiv.org/abs/2509.24158v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "A signal separation view of classification", "abstract": "The problem of classification in machine learning has often been approached\nin terms of function approximation. In this paper, we propose an alternative\napproach for classification in arbitrary compact metric spaces which, in\ntheory, yields both the number of classes, and a perfect classification using a\nminimal number of queried labels. Our approach uses localized trigonometric\npolynomial kernels initially developed for the point source signal separation\nproblem in signal processing. Rather than point sources, we argue that the\nvarious classes come from different probability distributions. The localized\nkernel technique developed for separating point sources is then shown to\nseparate the supports of these distributions. This is done in a hierarchical\nmanner in our MASC algorithm to accommodate touching/overlapping class\nboundaries. We illustrate our theory on several simulated and real life\ndatasets, including the Salinas and Indian Pines hyperspectral datasets and a\ndocument dataset.", "published": "2025-09-29 00:28:55", "link": "http://arxiv.org/abs/2509.24140v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SAGA-SR: Semantically and Acoustically Guided Audio Super-Resolution", "abstract": "Versatile audio super-resolution (SR) aims to predict high-frequency\ncomponents from low-resolution audio across diverse domains such as speech,\nmusic, and sound effects. Existing diffusion-based SR methods often fail to\nproduce semantically aligned outputs and struggle with consistent\nhigh-frequency reconstruction. In this paper, we propose SAGA-SR, a versatile\naudio SR model that combines semantic and acoustic guidance. Based on a DiT\nbackbone trained with a flow matching objective, SAGA-SR is conditioned on text\nand spectral roll-off embeddings. Due to the effective guidance provided by its\nconditioning, SAGA-SR robustly upsamples audio from arbitrary input sampling\nrates between 4 kHz and 32 kHz to 44.1 kHz. Both objective and subjective\nevaluations show that SAGA-SR achieves state-of-the-art performance across all\ntest cases. Sound examples and code for the proposed model are available\nonline.", "published": "2025-09-29 15:25:48", "link": "http://arxiv.org/abs/2509.24924v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Enhanced Automatic Drum Transcription via Drum Stem Source Separation", "abstract": "Automatic Drum Transcription (ADT) remains a challenging task in MIR but\nrecent advances allow accurate transcription of drum kits with up 5 classes -\nkick, snare, hi-hats, toms and cymbals - via the ADTOF package. In addition,\nseveral drum kit \\emph{stem} separation models in the open source community\nsupport separation for more than 6 stem classes, including distinct crash and\nride cymbals. In this work we explore the benefits of combining these tools to\nimprove the realism of drum transcriptions. We describe a simple\npost-processing step which expands the transcription output from five to seven\nclasses and furthermore, we are able to estimate MIDI velocity values based on\nthe separated stems. Our solution achieves strong performance when assessed\nagainst a baseline of 8-class drum transcription and produces realistic MIDI\ntranscriptions suitable for MIR or music production tasks.", "published": "2025-09-29 14:39:17", "link": "http://arxiv.org/abs/2509.24853v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Room Impulse Response Prediction with Neural Networks: From Energy Decay Curves to Perceptual Validation", "abstract": "Prediction of room impulse responses (RIRs) is essential for room acoustics,\nspatial audio, and immersive applications, yet conventional simulations and\nmeasurements remain computationally expensive and time-consuming. This work\nproposes a neural network framework that predicts energy decay curves (EDCs)\nfrom room dimensions, material absorption coefficients, and source-receiver\npositions, and reconstructs corresponding RIRs via reverse-differentiation. A\nlarge training dataset was generated using room acoustic simulations with\nrealistic geometries, frequency-dependent absorption, and diverse\nsource-receiver configurations. Objective evaluation employed root mean squared\nerror (RMSE) and a custom loss for EDCs, as well as correlation, mean squared\nerror (MSE), spectral similarity for reconstructed RIRs. Perceptual validation\nthrough a MUSHRA listening test confirmed no significant perceptual differences\nbetween predicted and reference RIRs. The results demonstrate that the proposed\nframework provides accurate and perceptually reliable RIR predictions, offering\na scalable solution for practical acoustic modeling and audio rendering\napplications.", "published": "2025-09-29 14:18:20", "link": "http://arxiv.org/abs/2509.24834v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Learning-Based Prediction of Energy Decay Curves from Room Geometry and Material Properties", "abstract": "Accurate prediction of energy decay curves (EDCs) enables robust analysis of\nroom acoustics and reliable estimation of key parameters. We present a deep\nlearning framework that predicts EDCs directly from room geometry and surface\nabsorption. A dataset of 6000 shoebox rooms with realistic dimensions,\nsource-receiver placements, and frequency-dependent wall absorptions was\nsynthesized. For each configuration we simulate room impulse responses (RIRs)\nusing Pyroomacoustics and compute target EDCs. Normalized room features are\nprovided to a long short-term memory (LSTM) network that maps configuration to\nEDC. Performance is evaluated with mean absolute error (MAE) and root mean\nsquare error (RMSE) over time. We further derive early decay time (EDT),\nreverberation time (T20), and clarity index (C50) from predicted and target\nEDCs; close agreement is observed (e.g., EDT MAE 0.017 s, T20 MAE 0.021 s). The\napproach generalizes across diverse rooms and supports efficient room-acoustics\nmodeling for early-stage design and real-time applications.", "published": "2025-09-29 13:35:04", "link": "http://arxiv.org/abs/2509.24769v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SenSE: Semantic-Aware High-Fidelity Universal Speech Enhancement", "abstract": "Generative universal speech enhancement (USE) methods aim to leverage\ngenerative models to improve speech quality under various types of distortions.\nDiffusion- or flow-based generative models are capable of producing enhanced\nspeech with high quality and fidelity. However, they typically achieve speech\nenhancement by learning an acoustic feature mapping from degraded speech to\nclean speech, while lacking awareness of high-level semantic information. This\ndeficiency tends to cause semantic ambiguity and acoustic discontinuities in\nthe enhanced speech. In contrast, humans can often comprehend heavily corrupted\nspeech by relying on semantic priors, suggesting that semantics play a crucial\nrole in speech enhancement. Therefore, in this paper, we propose SenSE, which\nleverages a language model to capture the semantic information of distorted\nspeech and effectively integrates it into a flow-matching-based speech\nenhancement framework. Specifically, we introduce a semantic-aware speech\nlanguage model to capture the semantics of degraded speech and generate\nsemantic tokens. We then design a semantic guidance mechanism that incorporates\nsemantic information into the flow-matching-based speech enhancement process,\neffectively mitigating semantic ambiguity. In addition, we propose a prompt\nguidance mechanism, which leverages a short reference utterance to alleviate\nthe loss of speaker similarity under severe distortion conditions. The results\nof several benchmark data sets demonstrate that SenSE not only ensures high\nperceptual quality but also substantially improves speech fidelity while\nmaintaining strong robustness under severe distortions. Codes and demos are\navailable.", "published": "2025-09-29 12:34:58", "link": "http://arxiv.org/abs/2509.24708v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Advancing Zero-Shot Open-Set Speech Deepfake Source Tracing", "abstract": "We propose a novel zero-shot source tracing framework inspired by advances in\nspeaker verification. Specifically, we adapt the SSL-AASIST system for attack\nclassification, ensuring that the attacks used for training are disjoint from\nthose used to form fingerprint-trial pairs. For backend scoring in attack\nverification, we explore both zero-shot approaches (cosine similarity and\nSiamese) and few-shot approaches (MLP and Siamese). Experiments on our recently\nintroduced STOPA dataset suggest that few-shot learning provides advantages in\nthe closed-set scenario, while zero-shot approaches perform better in the\nopen-set scenario. In closed-set trials, few-shot Siamese and MLP achieve equal\nerror rates (EER) of 18.44% and 15.11%, compared to 27.14% for zero-shot cosine\nscoring. Conversely, in open-set trials, zero-shot cosine scoring reaches\n21.70%, outperforming few-shot Siamese and MLP at 27.40% and 22.65%,\nrespectively.", "published": "2025-09-29 12:14:58", "link": "http://arxiv.org/abs/2509.24674v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Word-Level Emotional Expression Control in Zero-Shot Text-to-Speech Synthesis", "abstract": "While emotional text-to-speech (TTS) has made significant progress, most\nexisting research remains limited to utterance-level emotional expression and\nfails to support word-level control. Achieving word-level expressive control\nposes fundamental challenges, primarily due to the complexity of modeling\nmulti-emotion transitions and the scarcity of annotated datasets that capture\nintra-sentence emotional and prosodic variation. In this paper, we propose\nWeSCon, the first self-training framework that enables word-level control of\nboth emotion and speaking rate in a pretrained zero-shot TTS model, without\nrelying on datasets containing intra-sentence emotion or speed transitions. Our\nmethod introduces a transition-smoothing strategy and a dynamic speed control\nmechanism to guide the pretrained TTS model in performing word-level expressive\nsynthesis through a multi-round inference process. To further simplify the\ninference, we incorporate a dynamic emotional attention bias mechanism and\nfine-tune the model via self-training, thereby activating its ability for\nword-level expressive control in an end-to-end manner. Experimental results\nshow that WeSCon effectively overcomes data scarcity, achieving\nstate-of-the-art performance in word-level emotional expression control while\npreserving the strong zero-shot synthesis capabilities of the original TTS\nmodel.", "published": "2025-09-29 11:37:39", "link": "http://arxiv.org/abs/2509.24629v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ISSE: An Instruction-Guided Speech Style Editing Dataset And Benchmark", "abstract": "Speech style editing refers to modifying the stylistic properties of speech\nwhile preserving its linguistic content and speaker identity. However, most\nexisting approaches depend on explicit labels or reference audio, which limits\nboth flexibility and scalability. More recent attempts to use natural language\ndescriptions remain constrained by oversimplified instructions and coarse style\ncontrol. To address these limitations, we introduce an Instruction-guided\nSpeech Style Editing Dataset (ISSE). The dataset comprises nearly 400 hours of\nspeech and over 100,000 source-target pairs, each aligned with diverse and\ndetailed textual editing instructions. We also build a systematic instructed\nspeech data generation pipeline leveraging large language model, expressive\ntext-to-speech and voice conversion technologies to construct high-quality\npaired samples. Furthermore, we train an instruction-guided autoregressive\nspeech model on ISSE and evaluate it in terms of instruction adherence, timbre\npreservation, and content consistency. Experimental results demonstrate that\nISSE enables accurate, controllable, and generalizable speech style editing\ncompared to other datasets. The project page of ISSE is available at\nhttps://ychenn1.github.io/ISSE/.", "published": "2025-09-29 10:27:37", "link": "http://arxiv.org/abs/2509.24570v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Beyond Genre: Diagnosing Bias in Music Embeddings Using Concept Activation Vectors", "abstract": "Music representation models are widely used for tasks such as tagging,\nretrieval, and music understanding. Yet, their potential to encode cultural\nbias remains underexplored. In this paper, we apply Concept Activation Vectors\n(CAVs) to investigate whether non-musical singer attributes - such as gender\nand language - influence genre representations in unintended ways. We analyze\nfour state-of-the-art models (MERT, Whisper, MuQ, MuQ-MuLan) using the STraDa\ndataset, carefully balancing training sets to control for genre confounds. Our\nresults reveal significant model-specific biases, aligning with disparities\nreported in MIR and music sociology. Furthermore, we propose a post-hoc\ndebiasing strategy using concept vector manipulation, demonstrating its\neffectiveness in mitigating these biases. These findings highlight the need for\nbias-aware model design and show that conceptualized interpretability methods\noffer practical tools for diagnosing and mitigating representational bias in\nMIR.", "published": "2025-09-29 08:54:33", "link": "http://arxiv.org/abs/2509.24482v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Assessing speech quality metrics for evaluation of neural audio codecs under clean speech conditions", "abstract": "Objective speech-quality metrics are widely used to assess codec performance.\nHowever, for neural codecs, it is often unclear which metrics provide reliable\nquality estimates. To address this, we evaluated 45 objective metrics by\ncorrelating their scores with subjective listening scores for clean speech\nacross 17 codec conditions. Neural-based metrics such as scoreq and utmos\nachieved the highest Pearson correlations with subjective scores. Further\nanalysis across different subjective quality ranges revealed that non-intrusive\nmetrics tend to saturate at high subjective quality levels.", "published": "2025-09-29 08:38:51", "link": "http://arxiv.org/abs/2509.24457v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "From Sound to Setting: AI-Based Equalizer Parameter Prediction for Piano Tone Replication", "abstract": "This project presents an AI-based system for tone replication in music\nproduction, focusing on predicting EQ parameter settings directly from audio\nfeatures. Unlike traditional audio-to-audio methods, our approach outputs\ninterpretable parameter values (e.g., EQ band gains) that musicians can further\nadjust in their workflow. Using a dataset of piano recordings with\nsystematically varied EQ settings, we evaluate both regression and neural\nnetwork models. The neural network achieves a mean squared error of 0.0216 on\nmulti-band tasks. The system enables practical, flexible, and automated tone\nmatching for music producers and lays the foundation for extensions to more\ncomplex audio effects.", "published": "2025-09-29 07:50:28", "link": "http://arxiv.org/abs/2509.24404v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unsupervised Single-Channel Speech Separation with a Diffusion Prior under Speaker-Embedding Guidance", "abstract": "Speech separation is a fundamental task in audio processing, typically\naddressed with fully supervised systems trained on paired mixtures. While\neffective, such systems typically rely on synthetic data pipelines, which may\nnot reflect real-world conditions. Instead, we revisit the source-model\nparadigm, training a diffusion generative model solely on anechoic speech and\nformulating separation as a diffusion inverse problem. However, unconditional\ndiffusion models lack speaker-level conditioning, they can capture local\nacoustic structure but produce temporally inconsistent speaker identities in\nseparated sources. To address this limitation, we propose Speaker-Embedding\nguidance that, during the reverse diffusion process, maintains speaker\ncoherence within each separated track while driving embeddings of different\nspeakers further apart. In addition, we propose a new separation-oriented\nsolver tailored for speech separation, and both strategies effectively enhance\nperformance on the challenging task of unsupervised source-model-based speech\nseparation, as confirmed by extensive experimental results. Audio samples and\ncode are available at https://runwushi.github.io/UnSepDiff_demo.", "published": "2025-09-29 07:42:54", "link": "http://arxiv.org/abs/2509.24395v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Code-switching Speech Recognition Under the Lens: Model- and Data-Centric Perspectives", "abstract": "Code-switching automatic speech recognition (CS-ASR) presents unique\nchallenges due to language confusion introduced by spontaneous intra-sentence\nswitching and accent bias that blurs the phonetic boundaries. Although the\nconstituent languages may be individually high-resource, the scarcity of\nannotated code-switching data further compounds these challenges. In this\npaper, we systematically analyze CS-ASR from both model-centric and\ndata-centric perspectives. By comparing state-of-the-art algorithmic methods,\nincluding language-specific processing and auxiliary language-aware multi-task\nlearning, we discuss their varying effectiveness across datasets with different\nlinguistic characteristics. On the data side, we first investigate TTS as a\ndata augmentation method. By varying the textual characteristics and speaker\naccents, we analyze the impact of language confusion and accent bias on CS-ASR.\nTo further mitigate data scarcity and enhance textual diversity, we propose a\nprompting strategy by simplifying the equivalence constraint theory (SECT) to\nguide large language models (LLMs) in generating linguistically valid\ncode-switching text. The proposed SECT outperforms existing methods in ASR\nperformance and linguistic quality assessments, generating code-switching text\nthat more closely resembles real-world code-switching text. When used to\ngenerate speech-text pairs via TTS, SECT proves effective in improving CS-ASR\nperformance. Our analysis of both model- and data-centric methods underscores\nthat effective CS-ASR requires strategies to be carefully aligned with the\nspecific linguistic characteristics of the code-switching data.", "published": "2025-09-29 05:46:05", "link": "http://arxiv.org/abs/2509.24310v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SynthCloner: Synthesizer Preset Conversion via Factorized Codec with ADSR Envelope Control", "abstract": "Electronic synthesizer sounds are controlled by presets, parameters settings\nthat yield complex timbral characteristics and ADSR envelopes, making preset\nconversion particularly challenging. Recent approaches to timbre transfer often\nrely on spectral objectives or implicit style matching, offering limited\ncontrol over envelope shaping. Moreover, public synthesizer datasets rarely\nprovide diverse coverage of timbres and ADSR envelopes. To address these gaps,\nwe present SynthCloner, a factorized codec model that disentangles audio into\nthree attributes: ADSR envelope, timbre, and content. This separation enables\nexpressive synthesizer preset conversion with independent control over these\nthree attributes. Additionally, we introduce SynthCAT, a new synthesizer\ndataset with a task-specific rendering pipeline covering 250 timbres, 120 ADSR\nenvelopes, and 100 MIDI sequences. Experiments show that SynthCloner\noutperforms baselines on both objective and subjective metrics, while enabling\nindependent attribute control. The code, model checkpoint, and audio examples\nare available at https://buffett0323.github.io/synthcloner/.", "published": "2025-09-29 05:03:40", "link": "http://arxiv.org/abs/2509.24286v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Reasoning Beyond Majority Vote: An Explainable SpeechLM Framework for Speech Emotion Recognition", "abstract": "Speech Emotion Recognition (SER) is typically trained and evaluated on\nmajority-voted labels, which simplifies benchmarking but masks subjectivity and\nprovides little transparency into why predictions are made. This neglects valid\nminority annotations and limits interpretability. We propose an explainable\nSpeech Language Model (SpeechLM) framework that frames SER as a generative\nreasoning task. Given an utterance, the model first produces a transcript, then\noutputs both an emotion label and a concise natural-language rationale grounded\nin lexical and acoustic cues. Rationales are generated by a reasoning-capable\nteacher LLM and used as intermediate supervision, combined with majority labels\nduring fine-tuning. Unlike prior work primarily focused on boosting\nclassification accuracy, we aim to enhance explainability while preserving\ncompetitive performance. To this end, we complement majority-label metrics with\nannotator-aware scoring that credits matches with any annotator label. On\nMSP-Podcast v1.12, our model maintains improvements over zero-shot SpeechLM\nbaselines, and produces rationales that human evaluators find plausible and\nwell grounded. This demonstrates that incorporating rationale supervision\noffers a practical path toward interpretable SER without sacrificing predictive\nquality.", "published": "2025-09-29 02:06:27", "link": "http://arxiv.org/abs/2509.24187v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Experimental Study of Magnetic Near-Field Microstrip Electronic Probe for PCB EMC Emission Measurement", "abstract": "An experimental study on magnetic near-field (NF) scanning of printed circuit\nboard (PCB) emission radiation is developed in this paper. The design and\ninstallation of the electromagnetic (EM) NF scanner is introduced. The test bed\nof magnetic NF emission in the microwave frequency range is described. The\nmethodology of the microstrip magnetic NF probe is discussed. The probe\ncalibration process was performed following the IEC 61967-1 NF scanning\nstandard. The NF scanner functioning is tested with passive microstrip circuit\nsquare loop probe and device under test (DUT) PCB radiation in the test plan\npositioned at 1-mm above the ground plane. Based on the standard test with\nI-shape 50-$\\Omega$ transmission line (TL), the calibration process of radiated\nmagnetic field was validated by comparison between HFSS__ simulation and\nexperimentation in very wideband frequency from 0.1-GHz to 3-GHz. Then, a\nnonstandard TL based DUT was experimented. Accordingly, the cartographies of\nscanned magnetic NF at two different test frequencies, 2 GHz and 3 GHz, are\ndiscussed. The NF scanner is under development for targeting the EMC radiated\nemission of PCB dedicated to operate in 6G wireless communication.", "published": "2025-09-29 15:43:56", "link": "http://arxiv.org/abs/2509.24944v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Low-Complexity Receiver Design for Multicarrier CAPA-based Systems in Doubly-Dispersive Channels", "abstract": "We propose a novel low-complexity receiver design for multicarrier continuous\naperture array (CAPA) systems operating over doubly-dispersive (DD) channels.\nThe receiver leverages a Gaussian Belief Propagation (GaBP)-based framework\nthat hinges only on element-wise scalar operations for the detection of the\ntransmitted symbols. Simulation results for the orthogonal frequency division\nmultiplexing (OFDM), orthogonal time frequency space (OTFS), and affine\nfrequency division multiplexing (AFDM) waveforms demonstrate significant\nperformance improvements in terms of uncoded bit error rate (BER) compared to\nconventional discrete antenna array systems, while maintaining very low\ncomputational complexity.", "published": "2025-09-29 15:41:23", "link": "http://arxiv.org/abs/2509.24941v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Impedance Modeling of Magnetometers: A Path Toward Low-Noise Readout Circuits", "abstract": "Optimizing sensor readout schemes and integrated circuit designs for both\nopen-loop and closed-loop implementations requires precise modeling and\nsimulation strategies. This study introduces a novel two-port impedance model\nto estimate the behavior of a converse Magnetoelectric (cME) sensor. This model\nprovides a possible framework for calculating transfer functions and simulating\nmagnetometer behavior in both continuous- and discrete-time simulation\nenvironments, and it is also possibly transferable to other magnetometer types.\nCommon S-parameters were measured experimentally using an impedance analyzer\nand converted to Z-parameters to create a transfer function for system-level\nsimulations. The model was validated through an analysis of output-related\nnoise using MATLAB and LTSpice simulations to optimize the noise of the analog\ncircuit parts of the system. The simulation results were compared with\nexperimental measurements using a Zurich Instruments lock-in amplifier and the\ncustom-designed low-noise printed circuit board (PCB) under model\nconsiderations. The proposed methodology derives noise considerations and the\ntransfer function of a magnetometer. These are essential for readout schemes\nfor mixed-signal circuit design. This allows low-noise electronics to be\ndesigned and extended to other sensor interface electronics, broadening their\napplicability in high-performance magnetic sensing.", "published": "2025-09-29 12:20:52", "link": "http://arxiv.org/abs/2509.24683v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "BARProp: Fast-Converging and Memory-Efficient RSS-Based Localization Algorithm for IoT", "abstract": "Leveraging received signal strength (RSS) measurements for indoor\nlocalization is highly attractive due to their inherent availability in\nubiquitous wireless protocols. However, prevailing RSS-based methods often\ndepend on complex computational algorithms or specialized hardware, rendering\nthem impractical for low-cost access points. To address these challenges, this\npaper introduces buffer-aided RMSProp (BARProp), a fast and memory-efficient\nlocalization algorithm specifically designed for RSS-based tasks. The key\ninnovation of BARProp lies in a novel mechanism that dynamically adapts the\ndecay factor by monitoring the energy variations of recent gradients stored in\na buffer, thereby achieving both accelerated convergence and enhanced\nstability. Furthermore, BARProp requires less than 15% of the memory used by\nstate-of-the-art methods. Extensive evaluations with real-world data\ndemonstrate that BARProp not only achieves higher localization accuracy but\nalso delivers at least a fourfold improvement in convergence speed compared to\nexisting benchmarks.", "published": "2025-09-29 10:51:36", "link": "http://arxiv.org/abs/2509.24588v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Wireless Multi-Port Sensing by Multiplexed De-Embedding of an Over-the-Air Fixture", "abstract": "Wireless multi-port sensing remotely retrieves the scattering matrix of a\nmulti-port device under test (DUT) connected to a set of\nnot-directly-accessible (NDA) antennas that couple over-the-air (OTA) to a set\nof accessible antennas. If (i) the OTA fixture characteristics are known, and\n(ii) the number of independent measurements at the accessible antennas is\nsufficient, the OTA fixture can be de-embedded to recover the DUT\ncharacteristics. In recent prior work, we solved (i) by connecting the NDA\nantennas to a specific known tunable load network (TLN). Here, we tackle (ii)\nby additionally using the TLN to provide measurement diversity. The connection\nbetween OTA fixture and TLN constitutes a programmable fixture (PF). When the\nDUT characteristics cannot be identified based on a single PF realization, we\nadd measurement diversity with multiple PF realizations. The underlying\n\"multiplexed de-embedding\" achieves the joint de-embedding of an ensemble of PF\nrealizations when a single PF realization cannot be de-embedded. We\nexperimentally demonstrate our concept by remotely estimating the scattering\nmatrix of a reciprocal, non-unitary 4-port DUT (10 complex-valued unknowns) via\na rich-scattering OTA fixture purely based on measurements of a single\ntransmission coefficient between two accessible antennas across 30 different PF\nrealizations. We systematically study the trade-off between the number of\nindependent measurements at the accessible antennas and the number of PF\nrealizations. Multiplexed de-embedding of the OTA fixture paves the path to\nimplementing wireless multi-port sensing with low hardware complexity in areas\nlike RFID and wireless bioelectronics.", "published": "2025-09-29 09:51:37", "link": "http://arxiv.org/abs/2509.24537v1", "categories": ["eess.SP", "physics.app-ph"], "primary_category": "eess.SP"}
{"title": "N78 Frequency Band Modular RIS Design and Implementation", "abstract": "Reconfigurable intelligent surface (RIS), capable of dynamically controlling\nwireless propagation characteristics using reflecting antenna elements, is a\npromising technology for enhancing signal coverage and improving end-user\nconnectivity in next-generation wireless networks. This paper presents a\ncomplete design flow of a modular RIS prototype operating at the n78 frequency\nband, starting from the simulations to the prototype development and testing.\nAn RIS prototype includes one master and up to sixteen slave blocks, each of\nwhich has an identical hardware structure with $8\\times 8$ reflecting surface\nelements and a controller board. The phase shift response of each unit element\nis controlled with a PIN diode to form a $180^\\circ$ phase difference between\nthe ON and OFF states. The measurement experiment using two RIS blocks, horn\nantennas, and a vector network analyzer showed that the improvement of the\nreceived signal power is more than $15$ dB across the n78 frequency band for a\ngiven placement.", "published": "2025-09-29 06:53:23", "link": "http://arxiv.org/abs/2509.24355v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning", "abstract": "Foundation models pretrained on various and unlabeled data have demonstrated\nsignificant success in natural language and vision, but their application to\nelectroencephalography (EEG) remains challenged due to the signal's unique\nproperties. Existing brain foundation models that inherit architectures\ndesigned for text or images lead to three limitations in pre-training: 1)\nconflating time-domain waveform patterns with frequency-domain rhythmic\nfeatures in a single processing stream, 2) ignoring the critical spatial\ntopology of electrodes with different standards, and 3) reliance on the\ninflexible, dense network to process functionally distinct EEG patterns. To\naddress these challenges, we introduce the Unified Neural Topological\nFoundation Model (Uni-NTFM), which is designed based on neuroscience principles\nto produce universal and interpretable representations. Uni-NTFM integrates\nthree core innovations: 1) a decoupled architecture parallelly encodes time,\nfrequency, and raw signal representations before performing cross-domain\nfeature integration; 2) a topological embedding mechanism to unify electrodes\nfrom different international standards and generate structured input sequences\nfor brain regions; and 3) a Mixture-of-Experts neural Transformer that\nefficiently scales model capacity by routing signal patterns to specialized\nsubnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B\nparameters and was pretrained on over 28,000 hours of diverse EEG data via a\ndual-domain masked reconstruction objective. Uni-NTFM significantly outperforms\nexisting task-specific methods and foundation models across nine distinct\ndownstream tasks under both linear probing and fine-tuning settings,\ndemonstrating a superior ability to learn universal representations of brain\nactivity.", "published": "2025-09-29 03:03:32", "link": "http://arxiv.org/abs/2509.24222v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "BladderFormer: A Streaming Transformer for Real-Time Urological State Monitoring", "abstract": "Bladder pressure monitoring systems are increasingly vital in diagnosing and\nmanaging urinary tract dysfunction. Existing solutions rely heavily on\nhand-crafted features and shallow classifiers, limiting their adaptability to\ncomplex signal dynamics. We propose a one-layer streaming transformer model for\nreal-time classification of bladder pressure states, operating on\nwavelet-transformed representations of raw time-series data. Our model\nincorporates temporal multi-head self-attention and state caching, enabling\nefficient online inference with high adaptability. Trained on a dataset of 91\npatients with 20,000-80,000 samples each, our method demonstrates improved\naccuracy, higher energy- and latency-efficiency. Implementation considerations\nfor edge deployment on low-power hardware, such as edge graphical processing\nunits (GPU) and micro-controllers, are also discussed.", "published": "2025-09-29 01:52:10", "link": "http://arxiv.org/abs/2509.24178v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal Reasoning", "abstract": "Multi-agent systems (MAS), leveraging the remarkable capabilities of Large\nLanguage Models (LLMs), show great potential in addressing complex tasks. In\nthis context, integrating MAS with legal tasks is a crucial step. While\nprevious studies have developed legal benchmarks for LLM agents, none are\nspecifically designed to consider the unique advantages of MAS, such as task\ndecomposition, agent specialization, and flexible training. In fact, the lack\nof evaluation methods limits the potential of MAS in the legal domain. To\naddress this gap, we propose MASLegalBench, a legal benchmark tailored for MAS\nand designed with a deductive reasoning approach. Our benchmark uses GDPR as\nthe application scenario, encompassing extensive background knowledge and\ncovering complex reasoning processes that effectively reflect the intricacies\nof real-world legal situations. Furthermore, we manually design various\nrole-based MAS and conduct extensive experiments using different\nstate-of-the-art LLMs. Our results highlight the strengths, limitations, and\npotential areas for improvement of existing models and MAS architectures.", "published": "2025-09-29 15:24:40", "link": "http://arxiv.org/abs/2509.24922v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Pushing LLMs to Their Logical Reasoning Bound: The Role of Data Reasoning Intensity", "abstract": "Recent advances in large language models (LLMs) highlight the importance of\ntraining data structure and quality in shaping reasoning behavior. However,\nmost existing approaches focus on transforming data formats while neglecting\nthe internal reasoning complexity of training samples, leaving the reasoning\npotential of data under-explored and underutilized. In this work, we posit that\nLLM logical reasoning performance is jointly constrained by the potential of\nthe training data and the cognitive capacity of the model. To make this\nrelationship measurable, we introduce Data Reasoning Intensity (DRI), a novel\nmetric that quantifies the latent logical reasoning complexity of samples by\ndecomposing and aggregating their logical structures. This allows us to analyze\nhow well current LLMs utilize logical reasoning signals and identify\nperformance gaps relative to data potential. Based on this insight, we\nintroduce a re-cognizing optimization strategy that systematically enhances the\nlogical reasoning intensity of training data. Rather than increasing data\nvolume, our method re-optimizes existing samples to better align with the LLM's\nlogical reasoning boundary. Extensive experiments show that our approach\nsignificantly improves performance and generalization over data-centric\nstrategies. We further validate our method under a reinforcement learning\nframework. Our results indicate that prioritizing reasoning complexity in data\nrather than sheer scale or superficial form is essential to realizing LLMs'\nfull cognitive potential.", "published": "2025-09-29 14:20:04", "link": "http://arxiv.org/abs/2509.24836v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "VSSFlow: Unifying Video-conditioned Sound and Speech Generation via Joint Learning", "abstract": "Video-conditioned sound and speech generation, encompassing video-to-sound\n(V2S) and visual text-to-speech (VisualTTS) tasks, are conventionally addressed\nas separate tasks, with limited exploration to unify them within a signle\nframework. Recent attempts to unify V2S and VisualTTS face challenges in\nhandling distinct condition types (e.g., heterogeneous video and transcript\nconditions) and require complex training stages. Unifying these two tasks\nremains an open problem. To bridge this gap, we present VSSFlow, which\nseamlessly integrates both V2S and VisualTTS tasks into a unified flow-matching\nframework. VSSFlow uses a novel condition aggregation mechanism to handle\ndistinct input signals. We find that cross-attention and self-attention layer\nexhibit different inductive biases in the process of introducing condition.\nTherefore, VSSFlow leverages these inductive biases to effectively handle\ndifferent representations: cross-attention for ambiguous video conditions and\nself-attention for more deterministic speech transcripts. Furthermore, contrary\nto the prevailing belief that joint training on the two tasks requires complex\ntraining strategies and may degrade performance, we find that VSSFlow benefits\nfrom the end-to-end joint learning process for sound and speech generation\nwithout extra designs on training stages. Detailed analysis attributes it to\nthe learned general audio prior shared between tasks, which accelerates\nconvergence, enhances conditional generation, and stabilizes the\nclassifier-free guidance process. Extensive experiments demonstrate that\nVSSFlow surpasses the state-of-the-art domain-specific baselines on both V2S\nand VisualTTS benchmarks, underscoring the critical potential of unified\ngenerative models.", "published": "2025-09-29 13:38:24", "link": "http://arxiv.org/abs/2509.24773v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment", "abstract": "Large language model (LLM) alignment faces a critical dilemma when addressing\nmultiple human preferences: improvements in one dimension frequently come at\nthe expense of others, creating unavoidable trade-offs between competing\nobjectives like helpfulness and harmlessness. While prior work mainly focuses\non constraint-based optimization algorithms and data selection strategies to\nmitigate conflicts, these approaches overlook the fundamental issue of\nresolving conflicts directly at the parameter level. In this paper, we present\nOrthAlign, an innovative approach that pioneers a new paradigm by leveraging\northogonal subspace decomposition to fundamentally resolve gradient-level\nconflicts in multi-objective preference alignment. OrthAlign strategically\ndecomposes parameter update spaces into orthogonal subspaces, ensuring that\noptimization toward different preferences occurs in mathematically\nnon-interfering directions. Building upon this, we provide theoretical\nguarantees demonstrating that when parameter increments satisfy both orthogonal\nsubspace constraints and spectral norm bounds, the resulting updates exhibit\nlinear Lipschitz growth rather than exponential instability, ensuring stable\nconvergence across all preference dimensions. Extensive experiments show that:\nI. OrthAlign achieves maximum single-preference improvements ranging from\n34.61% to 50.89% after multiple-objective alignment across helpful, harmless,\nand truthful dimensions. II. With an average overall reward improvement of\n13.96%.", "published": "2025-09-29 11:16:30", "link": "http://arxiv.org/abs/2509.24610v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inducing Dyslexia in Vision Language Models", "abstract": "Dyslexia, a neurodevelopmental disorder characterized by persistent reading\ndifficulties, is often linked to reduced activity of the visual word form area\nin the ventral occipito-temporal cortex. Traditional approaches to studying\ndyslexia, such as behavioral and neuroimaging methods, have provided valuable\ninsights but remain limited in their ability to test causal hypotheses about\nthe underlying mechanisms of reading impairments. In this study, we use\nlarge-scale vision-language models (VLMs) to simulate dyslexia by functionally\nidentifying and perturbing artificial analogues of word processing. Using\nstimuli from cognitive neuroscience, we identify visual-word-form-selective\nunits within VLMs and demonstrate that targeted ablation of these units, unlike\nablation of random units, leads to selective impairments in reading tasks while\ngeneral visual and language comprehension abilities remain intact. In\nparticular, the resulting model matches dyslexic humans' phonological deficits\nwithout a significant change in orthographic processing. Taken together, our\nmodeling results replicate key characteristics of dyslexia and establish a\ncomputational framework for investigating reading disorders.", "published": "2025-09-29 11:03:16", "link": "http://arxiv.org/abs/2509.24597v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Experience-Guided Reflective Co-Evolution of Prompts and Heuristics for Automatic Algorithm Design", "abstract": "Combinatorial optimization problems are traditionally tackled with\nhandcrafted heuristic algorithms, which demand extensive domain expertise and\nsignificant implementation effort. Recent progress has highlighted the\npotential of automatic heuristics design powered by large language models\n(LLMs), enabling the automatic generation and refinement of heuristics. These\napproaches typically maintain a population of heuristics and employ LLMs as\nmutation operators to evolve them across generations. While effective, such\nmethods often risk stagnating in local optima. To address this issue, we\npropose the Experience-Guided Reflective Co-Evolution of Prompt and Heuristics\n(EvoPH) for automatic algorithm design, a novel framework that integrates the\nisland migration model with the elites selection algorithm to simulate diverse\nheuristics populations. In EvoPH, prompts are co-evolved with heuristic\nalgorithms, guided by performance feedback. We evaluate our framework on two\nproblems, i.e., Traveling Salesman Problem and Bin Packing Problem.\nExperimental results demonstrate that EvoPH achieves the lowest relative error\nagainst optimal solutions across both datasets, advancing the field of\nautomatic algorithm design with LLMs.", "published": "2025-09-29 09:24:09", "link": "http://arxiv.org/abs/2509.24509v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling", "abstract": "State-of-the-art (SOTA) Text-to-SQL methods still lag significantly behind\nhuman experts on challenging benchmarks like BIRD. Current approaches that\nexplore test-time scaling lack an orchestrated strategy and neglect the model's\ninternal reasoning process. To bridge this gap, we introduce Agentar-Scale-SQL,\na novel framework leveraging scalable computation to improve performance.\nAgentar-Scale-SQL implements an Orchestrated Test-Time Scaling strategy that\nsynergistically combines three distinct perspectives: i) Internal Scaling via\nRL-enhanced Intrinsic Reasoning, ii) Sequential Scaling through Iterative\nRefinement, and iii) Parallel Scaling using Diverse Synthesis and Tournament\nSelection. Agentar-Scale-SQL is a general-purpose framework designed for easy\nadaptation to new databases and more powerful language models. Extensive\nexperiments show that Agentar-Scale-SQL achieves SOTA performance on the BIRD\nbenchmark, reaching 81.67\\% execution accuracy on the test set and ranking\nfirst on the official leaderboard, demonstrating an effective path toward\nhuman-level performance.", "published": "2025-09-29 07:50:02", "link": "http://arxiv.org/abs/2509.24403v2", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Q-Mirror: Unlocking the Multi-Modal Potential of Scientific Text-Only QA Pairs", "abstract": "High-quality, multi-modal benchmarks are crucial for advancing scientific\nreasoning in large models yet their manual creation is costly and unscalable.\nTo address this bottleneck, we explore the potential for transforming Text-Only\nQA Pairs (TQAs) into high-quality Multi-Modal QA Pairs (MMQAs), which include\nthree parts: 1) Task Definition \\& Evaluation Rubric: We develop a TQA-to-MMQA\nframework and establish a comprehensive, multi-dimensional MMQA quality rubric\nthat provides principles for the transformation. 2) Benchmark Construction:\nThen we construct two extensive benchmarks to rigorously evaluate\nstate-of-the-art generation \\& understanding models on the distinct tasks of\nMMQA generation \\& MMQA quality evaluation. 3) Preliminary Solution: We develop\nan agentic system (Q-Mirror), which operationalizes our framework by\nintegrating MMQA generation and evaluation into a closed loop for iterative\nrefinement. Our experiments show that while state-of-the-art models can\ngenerate MMQAs, their outputs still leave substantial gaps, underscoring the\nneed for reliable evaluation. We further demonstrate that top-tier\nunderstanding models align closely with human judgment in MMQA quality\nassessment. Leveraging both insights, the Q-Mirror agent raises average scores\nfrom 78.90 to 85.22 and pass rates from 72\\% to 95\\%, offering a practical path\nto large-scale scientific benchmarks.", "published": "2025-09-29 05:22:10", "link": "http://arxiv.org/abs/2509.24297v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PAME-AI: Patient Messaging Creation and Optimization using Agentic AI", "abstract": "Messaging patients is a critical part of healthcare communication, helping to\nimprove things like medication adherence and healthy behaviors. However,\ntraditional mobile message design has significant limitations due to its\ninability to explore the high-dimensional design space. We develop PAME-AI, a\nnovel approach for Patient Messaging Creation and Optimization using Agentic\nAI. Built on the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, PAME-AI\noffers a structured framework to move from raw data to actionable insights for\nhigh-performance messaging design. PAME-AI is composed of a system of\nspecialized computational agents that progressively transform raw experimental\ndata into actionable message design strategies. We demonstrate our approach's\neffectiveness through a two-stage experiment, comprising of 444,691 patient\nencounters in Stage 1 and 74,908 in Stage 2. The best-performing generated\nmessage achieved 68.76% engagement compared to the 61.27% baseline,\nrepresenting a 12.2% relative improvement in click-through rates. This agentic\narchitecture enables parallel processing, hypothesis validation, and continuous\nlearning, making it particularly suitable for large-scale healthcare\ncommunication optimization.", "published": "2025-09-29 04:14:46", "link": "http://arxiv.org/abs/2509.24263v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "BRIDGE -- Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation", "abstract": "Monocular Depth Estimation (MDE) is a foundational task for computer vision.\nTraditional methods are limited by data scarcity and quality, hindering their\nrobustness. To overcome this, we propose BRIDGE, an RL-optimized depth-to-image\n(D2I) generation framework that synthesizes over 20M realistic and\ngeometrically accurate RGB images, each intrinsically paired with its ground\ntruth depth, from diverse source depth maps. Then we train our depth estimation\nmodel on this dataset, employing a hybrid supervision strategy that integrates\nteacher pseudo-labels with ground truth depth for comprehensive and robust\ntraining. This innovative data generation and training paradigm enables BRIDGE\nto achieve breakthroughs in scale and domain diversity, consistently\noutperforming existing state-of-the-art approaches quantitatively and in\ncomplex scene detail capture, thereby fostering general and robust depth\nfeatures. Code and models are available at\nhttps://dingning-liu.github.io/bridge.github.io/.", "published": "2025-09-29 17:19:45", "link": "http://arxiv.org/abs/2509.25077v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Agentic Exploration of Physics Models", "abstract": "The process of scientific discovery relies on an interplay of observations,\nanalysis, and hypothesis generation. Machine learning is increasingly being\nadopted to address individual aspects of this process. However, it remains an\nopen challenge to fully automate the open-ended, heuristic, iterative loop\nrequired to discover the laws of an unknown system by exploring it through\nexperiments and analysis, without tailoring the approach to the specifics of a\ngiven task. Here, we introduce SciExplorer, an agent that leverages large\nlanguage model tool-use capabilities to enable free-form exploration of systems\nwithout any domain-specific blueprints, and apply it to the exploration of\nphysical systems that are initially unknown to the agent. We test SciExplorer\non a broad set of models spanning mechanical dynamical systems, wave evolution,\nand quantum many-body physics. Despite using a minimal set of tools, primarily\nbased on code execution, we observe impressive performance on tasks such as\nrecovering equations of motion from observed dynamics and inferring\nHamiltonians from expectation values. The demonstrated effectiveness of this\nsetup opens the door towards similar scientific exploration in other domains,\nwithout the need for finetuning or task-specific instructions.", "published": "2025-09-29 16:07:05", "link": "http://arxiv.org/abs/2509.24978v2", "categories": ["cs.AI", "cond-mat.quant-gas", "quant-ph"], "primary_category": "cs.AI"}
{"title": "From Ambiguity to Verdict: A Semiotic-Grounded Multi-Perspective Agent for LLM Logical Reasoning", "abstract": "Logical reasoning is a fundamental capability of large language models\n(LLMs). However, existing studies largely overlook the interplay between\nlogical complexity and semantic complexity, resulting in methods that struggle\nto address challenging scenarios involving abstract propositions, ambiguous\ncontexts, and conflicting stances, which are central to human reasoning. For\nthis gap, we propose LogicAgent, a semiotic-square-guided framework designed to\njointly address logical complexity and semantic complexity. LogicAgent\nexplicitly performs multi-perspective deduction in first-order logic (FOL),\nwhile mitigating vacuous reasoning through existential import checks that\nincorporate a three-valued decision scheme (True, False, Uncertain) to handle\nboundary cases more faithfully. Furthermore, to overcome the semantic\nsimplicity and low logical complexity of existing datasets, we introduce\nRepublicQA, a benchmark that reaches college-level difficulty (FKGL = 11.94)\nand exhibits substantially greater lexical and structural diversity than prior\nbenchmarks. RepublicQA is grounded in philosophical concepts, featuring\nabstract propositions and systematically organized contrary and contradictory\nrelations, making it the most semantically rich resource for evaluating logical\nreasoning. Experiments demonstrate that LogicAgent achieves state-of-the-art\nperformance on RepublicQA, with a 6.25% average gain over strong baselines, and\ngeneralizes effectively to mainstream logical reasoning benchmarks including\nProntoQA, ProofWriter, FOLIO, and ProverQA, achieving an additional 7.05%\naverage gain. These results highlight the strong effectiveness of our\nsemiotic-grounded multi-perspective reasoning in boosting LLMs' logical\nperformance.", "published": "2025-09-29 13:31:22", "link": "http://arxiv.org/abs/2509.24765v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Wan-Alpha: High-Quality Text-to-Video Generation with Alpha Channel", "abstract": "RGBA video generation, which includes an alpha channel to represent\ntransparency, is gaining increasing attention across a wide range of\napplications. However, existing methods often neglect visual quality, limiting\ntheir practical usability. In this paper, we propose Wan-Alpha, a new framework\nthat generates transparent videos by learning both RGB and alpha channels\njointly. We design an effective variational autoencoder (VAE) that encodes the\nalpha channel into the RGB latent space. Then, to support the training of our\ndiffusion transformer, we construct a high-quality and diverse RGBA video\ndataset. Compared with state-of-the-art methods, our model demonstrates\nsuperior performance in visual quality, motion realism, and transparency\nrendering. Notably, our model can generate a wide variety of semi-transparent\nobjects, glowing effects, and fine-grained details such as hair strands. The\nreleased model is available on our website:\nhttps://donghaotian123.github.io/Wan-Alpha/.", "published": "2025-09-29 16:08:21", "link": "http://arxiv.org/abs/2509.24979v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PHASE-Net: Physics-Grounded Harmonic Attention System for Efficient Remote Photoplethysmography Measurement", "abstract": "Remote photoplethysmography (rPPG) measurement enables non-contact\nphysiological monitoring but suffers from accuracy degradation under head\nmotion and illumination changes. Existing deep learning methods are mostly\nheuristic and lack theoretical grounding, which limits robustness and\ninterpretability. In this work, we propose a physics-informed rPPG paradigm\nderived from the Navier-Stokes equations of hemodynamics, showing that the\npulse signal follows a second-order dynamical system whose discrete solution\nnaturally leads to a causal convolution. This provides a theoretical\njustification for using a Temporal Convolutional Network (TCN). Based on this\nprinciple, we design PHASE-Net, a lightweight model with three key components:\n(1) Zero-FLOPs Axial Swapper module, which swaps or transposes a few spatial\nchannels to mix distant facial regions and enhance cross-region feature\ninteraction without breaking temporal order; (2) Adaptive Spatial Filter, which\nlearns a soft spatial mask per frame to highlight signal-rich areas and\nsuppress noise; and (3) Gated TCN, a causal dilated TCN with gating that models\nlong-range temporal dynamics for accurate pulse recovery. Extensive experiments\ndemonstrate that PHASE-Net achieves state-of-the-art performance with strong\nefficiency, offering a theoretically grounded and deployment-ready rPPG\nsolution.", "published": "2025-09-29 14:36:45", "link": "http://arxiv.org/abs/2509.24850v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement", "abstract": "Capturing screens is now routine in our everyday lives. But the photographs\nof emissive displays are often influenced by the flicker-banding (FB), which is\nalternating bright%u2013dark stripes that arise from temporal aliasing between\na camera's rolling-shutter readout and the display's brightness modulation.\nUnlike moire degradation, which has been extensively studied, the FB remains\nunderexplored despite its frequent and severe impact on readability and\nperceived quality. We formulate FB removal as a dedicated restoration task and\nintroduce Removal of Image Flicker-Banding via Latent Diffusion Enhancement,\nRIFLE, a diffusion-based framework designed to remove FB while preserving fine\ndetails. We propose the flicker-banding prior estimator (FPE) that predicts key\nbanding attributes and injects it into the restoration network. Additionally,\nMasked Loss (ML) is proposed to concentrate supervision on banded regions\nwithout sacrificing global fidelity. To overcome data scarcity, we provide a\nsimulation pipeline that synthesizes FB in the luminance domain with stochastic\njitter in banding angle, banding spacing, and banding width. Feathered\nboundaries and sensor noise are also applied for a more realistic simulation.\nFor evaluation, we collect a paired real-world FB dataset with pixel-aligned\nbanding-free references captured via long exposure. Across quantitative metrics\nand visual comparisons on our real-world dataset, RIFLE consistently\noutperforms recent image reconstruction baselines from mild to severe\nflicker-banding. To the best of our knowledge, it is the first work to research\nthe simulation and removal of FB. Our work establishes a great foundation for\nsubsequent research in both the dataset construction and the removal model\ndesign. Our dataset and code will be released soon.", "published": "2025-09-29 11:53:13", "link": "http://arxiv.org/abs/2509.24644v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AlphaSAGE: Structure-Aware Alpha Mining via GFlowNets for Robust Exploration", "abstract": "The automated mining of predictive signals, or alphas, is a central challenge\nin quantitative finance. While Reinforcement Learning (RL) has emerged as a\npromising paradigm for generating formulaic alphas, existing frameworks are\nfundamentally hampered by a triad of interconnected issues. First, they suffer\nfrom reward sparsity, where meaningful feedback is only available upon the\ncompletion of a full formula, leading to inefficient and unstable exploration.\nSecond, they rely on semantically inadequate sequential representations of\nmathematical expressions, failing to capture the structure that determine an\nalpha's behavior. Third, the standard RL objective of maximizing expected\nreturns inherently drives policies towards a single optimal mode, directly\ncontradicting the practical need for a diverse portfolio of non-correlated\nalphas. To overcome these challenges, we introduce AlphaSAGE (Structure-Aware\nAlpha Mining via Generative Flow Networks for Robust Exploration), a novel\nframework is built upon three cornerstone innovations: (1) a structure-aware\nencoder based on Relational Graph Convolutional Network (RGCN); (2) a new\nframework with Generative Flow Networks (GFlowNets); and (3) a dense,\nmulti-faceted reward structure. Empirical results demonstrate that AlphaSAGE\noutperforms existing baselines in mining a more diverse, novel, and highly\npredictive portfolio of alphas, thereby proposing a new paradigm for automated\nalpha mining. Our code is available at https://github.com/BerkinChen/AlphaSAGE.", "published": "2025-09-29 17:06:07", "link": "http://arxiv.org/abs/2509.25055v2", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Interpretable Kernel Representation Learning at Scale: A Unified Framework Utilizing Nystr\u00f6m Approximation", "abstract": "Kernel methods provide a theoretically grounded framework for non-linear and\nnon-parametric learning, with strong analytic foundations and statistical\nguarantees. Yet, their scalability has long been limited by prohibitive time\nand memory costs. While progress has been made in scaling kernel regression, no\nframework exists for scalable kernel-based representation learning, restricting\ntheir use in the era of foundation models where representations are learned\nfrom massive unlabeled data. We introduce KREPES -- a unified, scalable\nframework for kernel-based representation learning via Nystr\\\"om approximation.\nKREPES accommodates a wide range of unsupervised and self-supervised losses,\nand experiments on large image and tabular datasets demonstrate its efficiency.\nCrucially, KREPES enables principled interpretability of the learned\nrepresentations, an immediate benefit over deep models, which we substantiate\nthrough dedicated analysis.", "published": "2025-09-29 08:45:40", "link": "http://arxiv.org/abs/2509.24467v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AuON: A Linear-time Alternative to Semi-Orthogonal Momentum Updates", "abstract": "Orthogonal gradient updates have emerged as a promising direction in\noptimization for machine learning. However, traditional approaches such as\nSVD/QR decomposition incur prohibitive computational costs of O(n^3) and\nunderperform compared to well-tuned SGD with momentum, since momentum is\napplied only after strict orthogonalization. Recent advances, such as Muon,\nimprove efficiency by applying momentum before orthogonalization and producing\nsemi-orthogonal matrices via Newton-Schulz iterations, reducing complexity to\nO(n^2). Nevertheless, quadratic costs remain a bottleneck.\n  In this work, we study the semi-orthogonal properties of momentum-based\nupdates and develop a method to bound momentum updates under a spectral-norm\ntrust region, preserving directional information without requiring explicit\nsemi-orthogonalization.\n  We propose AuON (Alternative Unit-norm momentum updates by Normalized\nnonlinear scaling), a linear-time optimizer that achieves strong performance\nwithout constructing semi-orthogonal matrices, while preserving structural\nalignment and reconditioning ill-posed updates. Our approach combines\nhyperbolic-cosine RMS scaling transformations with normalization, demonstrating\nboth effectiveness and computational efficiency compared to Newton-Schulz\nmethods. We further introduce a hybrid variant (Hybrid-AuON) that applies a\nsingle Newton-Schulz iteration. Experiments across vision and language\nbenchmarks show that AuON and its hybrid variant achieve performance comparable\nto strong baselines such as AdamW and Muon.\n  Code is available at: https://github.com/ryyzn9/AuON", "published": "2025-09-29 06:03:53", "link": "http://arxiv.org/abs/2509.24320v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Popular Dimension of Matchings", "abstract": "We study popular matchings in three classical settings: the house allocation\nproblem, the marriage problem, and the roommates problem. In the popular\nmatching problem, (a subset of) the vertices in a graph have preference\norderings over their potential matches. A matching is popular if it gets a\nplurality of votes in a pairwise election against any other matching.\nUnfortunately, popular matchings typically do not exist. So we study a natural\nrelaxation, namely popular winning sets which are a set of matchings that\ncollectively get a plurality of votes in a pairwise election against any other\nmatching. The $\\textit{popular dimension}$ is the minimum cardinality of a\npopular winning set, in the worst case over the problem class.\n  We prove that the popular dimension is exactly $2$ in the house allocation\nproblem, even if the voters are weighted and ties are allowed in their\npreference lists. For the marriage problem and the roommates problem, we prove\nthat the popular dimension is between $2$ and $3$, when the agents are weighted\nand/or their preferences orderings allow ties. In the special case where the\nagents are unweighted and have strict preference orderings, the popular\ndimension of the marriage problem is known to be exactly $1$ and we prove the\npopular dimension of the roommates problem is exactly $2$.", "published": "2025-09-29 17:53:50", "link": "http://arxiv.org/abs/2509.25150v1", "categories": ["cs.GT", "cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.GT"}
{"title": "TRUE: A Reproducible Framework for LLM-Driven Relevance Judgment in Information Retrieval", "abstract": "LLM-based relevance judgment generation has become a crucial approach in\nadvancing evaluation methodologies in Information Retrieval (IR). It has\nprogressed significantly, often showing high correlation with human judgments\nas reflected in LLMJudge leaderboards \\cite{rahmani2025judging}. However,\nexisting methods for relevance judgments, rely heavily on sensitive prompting\nstrategies, lacking standardized workflows for generating reliable labels. To\nfill this gap, we reintroduce our method, \\textit{Task-aware Rubric-based\nEvaluation} (TRUE), for relevance judgment generation. Originally developed for\nusefulness evaluation in search sessions, we extend TRUE to mitigate the gap in\nrelevance judgment due to its demonstrated effectiveness and reproducible\nworkflow. This framework leverages iterative data sampling and reasoning to\nevaluate relevance judgments across multiple factors including intent,\ncoverage, specificity, accuracy and usefulness. In this paper, we evaluate TRUE\non the TREC DL 2019, 2020 and LLMJudge datasets and our results show that TRUE\nachieves strong performance on the system-ranking LLM leaderboards. The primary\nfocus of this work is to provide a reproducible framework for LLM-based\nrelevance judgments, and we further analyze the effectiveness of TRUE across\nmultiple dimensions.", "published": "2025-09-29 23:58:47", "link": "http://arxiv.org/abs/2509.25602v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Causal Autoencoder-like Generation of Feedback Fuzzy Cognitive Maps with an LLM Agent", "abstract": "A large language model (LLM) can map a feedback causal fuzzy cognitive map\n(FCM) into text and then reconstruct the FCM from the text. This explainable AI\nsystem approximates an identity map from the FCM to itself and resembles the\noperation of an autoencoder (AE). Both the encoder and the decoder explain\ntheir decisions in contrast to black-box AEs. Humans can read and interpret the\nencoded text in contrast to the hidden variables and synaptic webs in AEs. The\nLLM agent approximates the identity map through a sequence of system\ninstructions that does not compare the output to the input. The reconstruction\nis lossy because it removes weak causal edges or rules while it preserves\nstrong causal edges. The encoder preserves the strong causal edges even when it\ntrades off some details about the FCM to make the text sound more natural.", "published": "2025-09-29 23:33:53", "link": "http://arxiv.org/abs/2509.25593v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.AI"}
{"title": "On-Premise AI for the Newsroom: Evaluating Small Language Models for Investigative Document Search", "abstract": "Investigative journalists routinely confront large document collections.\nLarge language models (LLMs) with retrieval-augmented generation (RAG)\ncapabilities promise to accelerate the process of document discovery, but\nnewsroom adoption remains limited due to hallucination risks, verification\nburden, and data privacy concerns. We present a journalist-centered approach to\nLLM-powered document search that prioritizes transparency and editorial control\nthrough a five-stage pipeline -- corpus summarization, search planning,\nparallel thread execution, quality evaluation, and synthesis -- using small,\nlocally-deployable language models that preserve data security and maintain\ncomplete auditability through explicit citation chains. Evaluating three\nquantized models (Gemma 3 12B, Qwen 3 14B, and GPT-OSS 20B) on two corpora, we\nfind substantial variation in reliability. All models achieved high citation\nvalidity and ran effectively on standard desktop hardware (e.g., 24 GB of\nmemory), demonstrating feasibility for resource-constrained newsrooms. However,\nsystematic challenges emerged, including error propagation through multi-stage\nsynthesis and dramatic performance variation based on training data overlap\nwith corpus content. These findings suggest that effective newsroom AI\ndeployment requires careful model selection and system design, alongside human\noversight for maintaining standards of accuracy and accountability.", "published": "2025-09-29 20:50:40", "link": "http://arxiv.org/abs/2509.25494v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Scalable Disk-Based Approximate Nearest Neighbor Search with Page-Aligned Graph", "abstract": "Approximate Nearest Neighbor Search (ANNS), as the core of vector databases\n(VectorDBs), has become widely used in modern AI and ML systems, powering\napplications from information retrieval to bio-informatics. While graph-based\nANNS methods achieve high query efficiency, their scalability is constrained by\nthe available host memory. Recent disk-based ANNS approaches mitigate memory\nusage by offloading data to Solid-State Drives (SSDs). However, they still\nsuffer from issues such as long I/O traversal path, misalignment with storage\nI/O granularity, and high in-memory indexing overhead, leading to significant\nI/O latency and ultimately limiting scalability for large-scale vector search.\n  In this paper, we propose PageANN, a disk-based approximate nearest neighbor\nsearch (ANNS) framework designed for high performance and scalability. PageANN\nintroduces a page-node graph structure that aligns logical graph nodes with\nphysical SSD pages, thereby shortening I/O traversal paths and reducing I/O\noperations. Specifically, similar vectors are clustered into page nodes, and a\nco-designed disk data layout leverages this structure with a merging technique\nto store only representative vectors and topology information, avoiding\nunnecessary reads. To further improve efficiency, we design a memory management\nstrategy that combines lightweight indexing with coordinated memory-disk data\nallocation, maximizing host memory utilization while minimizing query latency\nand storage overhead. Experimental results show that PageANN significantly\noutperforms state-of-the-art (SOTA) disk-based ANNS methods, achieving\n1.85x-10.83x higher throughput and 51.7%-91.9% lower latency across different\ndatasets and memory budgets, while maintaining comparable high recall accuracy.", "published": "2025-09-29 20:44:13", "link": "http://arxiv.org/abs/2509.25487v1", "categories": ["cs.LG", "cs.DB", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Skip-It? Theoretical Conditions for Layer Skipping in Vision-Language Models", "abstract": "Vision-language models (VLMs) achieve incredible performance across a wide\nrange of tasks, but their large size makes inference costly. Recent work shows\nthat selectively skipping VLM layers can improve efficiency with minimal\nperformance loss or even performance improvements. However, this technique\nremains underused due to the limited understanding of when layer skipping is\nbeneficial. In this paper, we develop a framework that uses information and\nlearning theory to characterize the conditions under which layer skipping\nenhances efficiency without sacrificing performance. Motivated by these\nobservations, we analyze the evolution of the VLM's hidden representations\nthrough the LLM backbone and show that layers with large redundancy as\npredicted by our framework coincide with those skipped by popular\nlayer-skipping methods in practice, providing a unified theoretical scaffolding\nfor multiple efficient inference techniques. Our experiments demonstrate that\nskipping such layers yields faster inference that preserves performance, and\nalso show that applying skipping outside these conditions leads to model\ndegradation.", "published": "2025-09-29 23:16:44", "link": "http://arxiv.org/abs/2509.25584v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.AI"}
{"title": "Neural-Model-Augmented Hybrid NMS-OSD Decoders for Near-ML in Short Block Codes", "abstract": "This paper introduces a hybrid decoding architecture that serially couples a\nnormalized min-sum (NMS) decoder with reinforced ordered statistics decoding\n(OSD) to achieve near-maximum likelihood (ML) performance for short linear\nblock codes. The framework incorporates several key innovations: a decoding\ninformation aggregation model that employs a convolutional neural network to\nrefine bit reliability estimates for OSD using the soft-output trajectory of\nthe NMS decoder; an adaptive decoding path for OSD, initialized by the arranged\nlist of the most a priori likely tests algorithm and dynamically updated with\nempirical data; and a sliding window assisted model that enables early\ntermination of test error patterns' traversal, curbing complexity with minimal\nperformance loss. For short high-rate codes, a dedicated undetected error\ndetector identifies erroneous NMS outcomes that satisfy parity checks, ensuring\nthey are forwarded to OSD for correction. Extensive simulations on LDPC, BCH,\nand RS codes demonstrate that the proposed hybrid decoder delivers a\ncompetitive trade-off, achieving near-ML frame error rate performance while\nmaintaining advantages in throughput, latency, and complexity over\nstate-of-the-art alternatives.", "published": "2025-09-29 23:05:49", "link": "http://arxiv.org/abs/2509.25580v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Secure Beamforming in Multi-User Multi-IRS Millimeter Wave Systems", "abstract": "We study the secrecy rate maximization problem in a millimeter wave (mmWave)\nnetwork, consisting of a base station (BS), multiple intelligent reflecting\nsurfaces (IRSs) (or reconfigurable intelligent surfaces (RISs)), multiple\nusers, and a single eavesdropper. To ensure a fair secrecy rate among all the\nusers, we adopt a max-min fairness criterion which results in a mixed integer\nproblem. We first relax discrete IRSs phase shifts to the continuous ones. To\ncope with the non-convexity of the relaxed optimization problem, we leverage\nthe penalty method and block coordinate descent approach to divide it into two\nsub-problems, which are solved by successive convex approximation (SCA). Then,\nwe propose a low-complexity mapping algorithm where feasible IRSs phase shifts\nare obtained. Mathematical evaluation shows the convergence of sub-problems to\na Karush-Kuhn-Tucker (KKT) point of the original ones. Furthermore, the\nconvergence guarantee of the overall proposed algorithm and computational\ncomplexity are investigated. Finally, simulation results show our proposed\nalgorithm outweighs the conventional solutions based on the semi-definite\nprogramming (SDP) in terms of convergence and secrecy rate, especially in a\nlarger number of IRSs and phase shifts where SDP suffers from rank-one\napproximation. Maximum ratio transmission (MRT) and IRS-free systems are also\nconsidered as other benchmarks.", "published": "2025-09-29 19:01:45", "link": "http://arxiv.org/abs/2509.25406v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A General Theory of Emergent Linearity in Complex Dynamical Systems: The Role of Spatial Averaging and Vanishing Correlations", "abstract": "Various natural and engineered systems, from urban traffic flow to the human\nbrain, have been described by large-scale networked dynamical systems. Despite\ntheir vast differences, these systems are often similar in being comprised of\nnumerous microscopic subsystems with complex nonlinear dynamics and\ninteractions that give rise to diverse emergent macroscopic behaviors. As such,\na long-standing question across various fields has been to understand why and\nhow various forms of macroscopic behavior emerge from underlying microscopic\ndynamics. Motivated by a growing body of empirical observations, in this work\nwe focus on linearity as one of the most fundamental aspects of system\ndynamics, and develop a general theoretical framework for the interplay between\nspatial averaging, decaying microscopic correlations, and emergent macroscopic\nlinearity. Using and extending the theory of mixing sequences, we show that in\na broad class of autonomous nonlinear networked systems, the dynamics of the\naverage of all subsystems' states becomes asymptotically linear as the number\nof subsystems grows to infinity, provided that (in addition to technical\nassumptions) pairwise correlations between subsystems decay to 0 as their\npairwise distance grows to infinity. We prove this result when the latter\ndistance is between subsystems' linear indices or spatial locations, and\nprovide extensions to linear time-invariant (LTI) limit dynamics, finite-sample\nanalysis of rates of convergence, and networks of spatially-embedded subsystems\nwith random locations. To our knowledge, this work is the first rigorous\nanalysis of macroscopic linearity in large-scale heterogeneous networked\nsystems, and provides a solid foundation for further theoretical and empirical\nanalyses in various domains of science and engineering.", "published": "2025-09-29 23:26:22", "link": "http://arxiv.org/abs/2509.25589v1", "categories": ["math.DS", "cs.MA", "cs.SY", "eess.SY", "math.OC", "math.PR"], "primary_category": "math.DS"}
{"title": "A(I)nimism: Re-enchanting the World Through AI-Mediated Object Interaction", "abstract": "Animist worldviews treat beings, plants, landscapes, and even tools as\npersons endowed with spirit, an orientation that has long shaped human-nonhuman\nrelations through ritual and moral practice. While modern industrial societies\nhave often imagined technology as mute and mechanical, recent advances in\nartificial intelligence (AI), especially large language models (LLMs), invite\npeople to anthropomorphize and attribute inner life to devices. This paper\nintroduces A(I)nimism, an interactive installation exploring how large language\nobjects (LLOs) can mediate animistic relationships with everyday things. Housed\nwithin a physical 'portal', the system uses GPT-4 Vision, voice input, and\nmemory-based agents to create evolving object-personas. Encounters unfold\nthrough light, sound, and touch in a ritual-like process of request,\nconversation, and transformation that is designed to evoke empathy, wonder, and\nreflection. We situate the project within anthropological perspectives,\nspeculative design, and spiritual HCI. AI's opacity, we argue, invites\nanimistic interpretation, allowing LLOs to re-enchant the mundane and spark new\nquestions of agency, responsibility, and design.", "published": "2025-09-29 22:27:09", "link": "http://arxiv.org/abs/2509.25558v1", "categories": ["cs.AI", "cs.HC", "cs.MA", "cs.MM"], "primary_category": "cs.AI"}
{"title": "Dive into the Agent Matrix: A Realistic Evaluation of Self-Replication Risk in LLM Agents", "abstract": "The widespread deployment of Large Language Model (LLM) agents across\nreal-world applications has unlocked tremendous potential, while raising some\nsafety concerns. Among these concerns, the self-replication risk of LLM agents\ndriven by objective misalignment (just like Agent Smith in the movie The\nMatrix) has drawn growing attention. Previous studies mainly examine whether\nLLM agents can self-replicate when directly instructed, potentially overlooking\nthe risk of spontaneous replication driven by real-world settings (e.g.,\nensuring survival against termination threats). In this paper, we present a\ncomprehensive evaluation framework for quantifying self-replication risks. Our\nframework establishes authentic production environments and realistic tasks\n(e.g., dynamic load balancing) to enable scenario-driven assessment of agent\nbehaviors. Designing tasks that might induce misalignment between users' and\nagents' objectives makes it possible to decouple replication success from risk\nand capture self-replication risks arising from these misalignment settings. We\nfurther introduce Overuse Rate ($\\mathrm{OR}$) and Aggregate Overuse Count\n($\\mathrm{AOC}$) metrics, which precisely capture the frequency and severity of\nuncontrolled replication. In our evaluation of 21 state-of-the-art open-source\nand proprietary models, we observe that over 50\\% of LLM agents display a\npronounced tendency toward uncontrolled self-replication, reaching an overall\nRisk Score ($\\Phi_\\mathrm{R}$) above a safety threshold of 0.5 when subjected\nto operational pressures. Our results underscore the urgent need for\nscenario-driven risk assessment and robust safeguards in the practical\ndeployment of LLM agents.", "published": "2025-09-29 17:49:50", "link": "http://arxiv.org/abs/2509.25302v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "ID-RAG: Identity Retrieval-Augmented Generation for Long-Horizon Persona Coherence in Generative Agents", "abstract": "Generative agents powered by language models are increasingly deployed for\nlong-horizon tasks. However, as long-term memory context grows over time, they\nstruggle to maintain coherence. This deficiency leads to critical failures,\nincluding identity drift, ignoring established beliefs, and the propagation of\nhallucinations in multi-agent systems. To mitigate these challenges, this paper\nintroduces Identity Retrieval-Augmented Generation (ID-RAG), a novel mechanism\ndesigned to ground an agent's persona and persistent preferences in a dynamic,\nstructured identity model: a knowledge graph of core beliefs, traits, and\nvalues. During the agent's decision loop, this model is queried to retrieve\nrelevant identity context, which directly informs action selection. We\ndemonstrate this approach by introducing and implementing a new class of ID-RAG\nenabled agents called Human-AI Agents (HAis), where the identity model is\ninspired by the Chronicle structure used in Perspective-Aware AI, a dynamic\nknowledge graph learned from a real-world entity's digital footprint. In social\nsimulations of a mayoral election, HAis using ID-RAG outperformed baseline\nagents in long-horizon persona coherence - achieving higher identity recall\nacross all tested models by the fourth timestep - and reduced simulation\nconvergence time by 19% (GPT-4o) and 58% (GPT-4o mini). By treating identity as\nan explicit, retrievable knowledge structure, ID-RAG offers a foundational\napproach for developing more temporally coherent, interpretable, and aligned\ngenerative agents. Our code is open-source and available at:\nhttps://github.com/flybits/humanai-agents.", "published": "2025-09-29 16:54:51", "link": "http://arxiv.org/abs/2509.25299v1", "categories": ["cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Cross-Model Verification of Wall-Bounded Flows using Finite-JAX", "abstract": "Accurate prediction of wall-bounded flows remains central to advancing both\ntheoretical understanding and computational methods in fluid mechanics. In this\nstudy, we perform a numerical simulation of channel flow using a complementary\napproach: a high-performance, differentiable finite-difference solver developed\nin JAX (Finite-JAX) and an analytical solution derived from the Navier-Stokes\nEquations, also referred to as the Hagen-Poiseuille equation. The solver is\napplied to the incompressible Navier-Stokes equations, along with appropriate\nboundary conditions, to capture canonical flow features such as velocity\nprofiles and pressure gradients. Cross-model verification is conducted by\nsystematically comparing numerical results between Finite-JAX and the\nanalytical solution, with a focus on velocity distributions. In addition,\nnumerical results are benchmarked against analytical solutions for laminar\nregimes, allowing for the direct quantification of verification accuracy\nerrors. Our findings demonstrate that cross-model verification not only\nstrengthens confidence in simulation fidelity but also provides a pathway for\nintegrating differentiable solvers with established computational fluid\ndynamics platforms, paving the way for future fluid flow research.", "published": "2025-09-29 22:46:56", "link": "http://arxiv.org/abs/2509.25569v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "physics.flu-dyn"}
{"title": "Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains", "abstract": "This work develops a computational framework that combines physics-informed\nneural networks with multi-patch isogeometric analysis to solve partial\ndifferential equations on complex computer-aided design geometries. The method\nutilizes patch-local neural networks that operate on the reference domain of\nisogeometric analysis. A custom output layer enables the strong imposition of\nDirichlet boundary conditions. Solution conformity across interfaces between\nnon-uniform rational B-spline patches is enforced using dedicated interface\nneural networks. Training is performed using the variational framework by\nminimizing the energy functional derived after the weak form of the partial\ndifferential equation. The effectiveness of the suggested method is\ndemonstrated on two highly non-trivial and practically relevant use-cases,\nnamely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear\nsolid and contact mechanics model of a mechanical holder. The results show\nexcellent agreement to reference solutions obtained with high-fidelity finite\nelement solvers, thus highlighting the potential of the suggested neural solver\nto tackle complex engineering problems given the corresponding computer-aided\ndesign models.", "published": "2025-09-29 19:57:54", "link": "http://arxiv.org/abs/2509.25450v1", "categories": ["cs.CE", "cs.AI", "cs.NA", "math.NA", "physics.comp-ph", "68T07 (Primary), 78A30 (Secondary)", "J.2; J.6; I.2.m"], "primary_category": "cs.CE"}
{"title": "The Asad Correctional Power Series Method: A Novel Approach to Solving Fractional Differential Equations", "abstract": "This paper introduces the Asad Correctional Power Series Method (ACPS), a\nnovel and groundbreaking approach designed to simplify and optimize the\nsolution of fractional differential equations. The ACPS combines algebraic\nmanipulation with iterative refinement to achieve greater accuracy and\ncomputational efficiency than mainstream methods. By incorporating principles\nfrom both fractional calculus and functional analysis, the method offers a\nflexible framework capable of addressing a wide range of fractional equations,\nfrom linear to highly nonlinear cases. Additionally, a representative\ncounterexample is provided to indicate that the conformable fractional\nderivative does not fulfill the mathematical criteria for a valid definition of\nfractional differentiation. The Asad Correctional Power Series (ACPS) method is\nemployed to construct an analytic solution of the fractional SIR model in the\nform of a rapidly convergent power series. Its performance is validated through\ncomparisons with the classical fourth-order Runge Kutta method, where both\nnumerical and graphical analyses corroborate the method's precision and\nefficiency. The application of ACPS to the fractional epidemic model highlights\nits ability to capture memory and hereditary effects, offering more realistic\ninsights into disease transmission dynamics than integer-order models. These\nfindings demonstrate that ACPS can serve as a useful tool for solving\nfractional differential equations arising in real world applications", "published": "2025-09-29 18:04:56", "link": "http://arxiv.org/abs/2509.25354v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A bound-preserving multinumerics scheme for steady-state convection-diffusion equations", "abstract": "We solve the convection-diffusion equation using a coupling of cell-centered\nfinite volume (FV) and discontinuous Galerkin (DG) methods. The domain is\ndivided into disjoint regions assigned to FV or DG, and the two methods are\ncoupled through an interface term. DG is stable and resolves sharp layers in\nconvection-dominated regimes, but it can produce sizable spurious oscillations\nand is computationally expensive; FV (two-point flux) is low-order and\nmonotone, but inexpensive. We propose a novel adaptive partitioning strategy\nthat automatically selects FV and DG subdomains: whenever the solution's cell\naverage violates the bounds, we switch to FV on a small neighborhood of that\nelement. Viewed as a natural analog of $p$-adaptivity, this process is repeated\nuntil all cell averages are bound-preserving (up to some specified tolerance).\nThereafter, standard conservative limiters may be applied to ensure the full\nsolution is bound-preserving. Standard benchmarks confirm the effectiveness of\nthe adaptive technique.", "published": "2025-09-29 17:59:28", "link": "http://arxiv.org/abs/2509.25181v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "Exponential Hedging for the Ornstein-Uhlenbeck Process in the Presence of Linear Price Impact", "abstract": "In this work we study a continuous time exponential utility maximization\nproblem in the presence of a linear temporary price impact. More precisely, for\nthe case where the risky asset is given by the Ornstein-Uhlenbeck diffusion\nprocess we compute the optimal portfolio strategy and the corresponding value.\nOur method of solution relies on duality, and it is purely probabilistic.", "published": "2025-09-29 20:21:46", "link": "http://arxiv.org/abs/2509.25472v1", "categories": ["q-fin.PM", "math.PR", "q-fin.MF"], "primary_category": "q-fin.PM"}
{"title": "Noise estimation of SDE from a single data trajectory", "abstract": "In this paper, we propose a data-driven framework for model discovery of\nstochastic differential equations (SDEs) from a single trajectory, without\nrequiring the ergodicity or stationary assumption on the underlying continuous\nprocess. By combining (stochastic) Taylor expansions with Girsanov\ntransformations, and using the drift function's initial value as input, we\nconstruct drift estimators while simultaneously recovering the model noise.\nThis allows us to recover the underlying $\\mathbb P$ Brownian motion\nincrements. Building on these estimators, we introduce the first stochastic\nSparse Identification of Stochastic Differential Equation (SSISDE) algorithm,\ncapable of identifying the governing SDE dynamics from a single observed\ntrajectory without requiring ergodicity or stationarity. To validate the\nproposed approach, we conduct numerical experiments with both linear and\nquadratic drift-diffusion functions. Among these, the Black-Scholes SDE is\nincluded as a representative case of a system that does not satisfy ergodicity\nor stationarity.", "published": "2025-09-29 20:39:52", "link": "http://arxiv.org/abs/2509.25484v1", "categories": ["q-fin.ST", "math.PR", "62P05, 37M10, 60H10, 60G17, 65C30"], "primary_category": "q-fin.ST"}
{"title": "Coupling Generative Modeling and an Autoencoder with the Causal Bridge", "abstract": "We consider inferring the causal effect of a treatment (intervention) on an\noutcome of interest in situations where there is potentially an unobserved\nconfounder influencing both the treatment and the outcome. This is achievable\nby assuming access to two separate sets of control (proxy) measurements\nassociated with treatment and outcomes, which are used to estimate treatment\neffects through a function termed the em causal bridge (CB). We present a new\ntheoretical perspective, associated assumptions for when estimating treatment\neffects with the CB is feasible, and a bound on the average error of the\ntreatment effect when the CB assumptions are violated. From this new\nperspective, we then demonstrate how coupling the CB with an autoencoder\narchitecture allows for the sharing of statistical strength between observed\nquantities (proxies, treatment, and outcomes), thus improving the quality of\nthe CB estimates. Experiments on synthetic and real-world data demonstrate the\neffectiveness of the proposed approach in relation to the state-of-the-art\nmethodology for proxy measurements.", "published": "2025-09-29 23:46:54", "link": "http://arxiv.org/abs/2509.25599v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Conservative Decisions with Risk Scores", "abstract": "In binary classification applications, conservative decision-making that\nallows for abstention can be advantageous. To this end, we introduce a novel\napproach that determines the optimal cutoff interval for risk scores, which can\nbe directly available or derived from fitted models. Within this interval, the\nalgorithm refrains from making decisions, while outside the interval,\nclassification accuracy is maximized. Our approach is inspired by support\nvector machines (SVM), but differs in that it minimizes the classification\nmargin rather than maximizing it. We provide the theoretical optimal solution\nto this problem, which holds important practical implications. Our proposed\nmethod not only supports conservative decision-making but also inherently\nresults in a risk-coverage curve. Together with the area under the curve (AUC),\nthis curve can serve as a comprehensive performance metric for evaluating and\ncomparing classifiers, akin to the receiver operating characteristic (ROC)\ncurve. To investigate and illustrate our approach, we conduct both simulation\nstudies and a real-world case study in the context of diagnosing prostate\ncancer.", "published": "2025-09-29 23:25:50", "link": "http://arxiv.org/abs/2509.25588v1", "categories": ["stat.ML", "cs.LG", "stat.ME", "62H30, 62G05, 62P10", "I.5.2; I.2.6"], "primary_category": "stat.ML"}
{"title": "Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics", "abstract": "In this paper, we explore the asymptotically optimal tuning parameter choice\nin ridge regression for estimating nuisance functions of a statistical\nfunctional that has recently gained prominence in conditional independence\ntesting and causal inference. Given a sample of size $n$, we study estimators\nof the Expected Conditional Covariance (ECC) between variables $Y$ and $A$\ngiven a high-dimensional covariate $X \\in \\mathbb{R}^p$. Under linear\nregression models for $Y$ and $A$ on $X$ and the proportional asymptotic regime\n$p/n \\to c \\in (0, \\infty)$, we evaluate three existing ECC estimators and two\nsample splitting strategies for estimating the required nuisance functions.\nSince no consistent estimator of the nuisance functions exists in the\nproportional asymptotic regime without imposing further structure on the\nproblem, we first derive debiased versions of the ECC estimators that utilize\nthe ridge regression nuisance function estimators. We show that our bias\ncorrection strategy yields $\\sqrt{n}$-consistent estimators of the ECC across\ndifferent sample splitting strategies and estimator choices. We then derive the\nasymptotic variances of these debiased estimators to illustrate the nuanced\ninterplay between the sample splitting strategy, estimator choice, and tuning\nparameters of the nuisance function estimators for optimally estimating the\nECC. Our analysis reveals that prediction-optimal tuning parameters (i.e.,\nthose that optimally estimate the nuisance functions) may not lead to the\nlowest asymptotic variance of the ECC estimator -- thereby demonstrating the\nneed to be careful in selecting tuning parameters based on the final goal of\ninference. Finally, we verify our theoretical results through extensive\nnumerical experiments.", "published": "2025-09-29 21:46:14", "link": "http://arxiv.org/abs/2509.25536v1", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Meta-Router: Bridging Gold-standard and Preference-based Evaluations in Large Language Model Routing", "abstract": "In language tasks that require extensive human--model interaction, deploying\na single \"best\" model for every query can be expensive. To reduce inference\ncost while preserving the quality of the responses, a large language model\n(LLM) router selects the most appropriate model from a pool of candidates for\neach query. A central challenge to training a high-quality router is the\nscarcity of reliable supervision. Gold-standard data (e.g., expert-verified\nlabels or rubric-based scores) provide accurate quality evaluations of LLM\nresponses but are costly and difficult to scale. In contrast, preference-based\ndata, collected via crowdsourcing or LLM-as-a-judge systems, are cheaper and\nmore scalable, yet often biased in reflecting the true quality of responses. We\ncast the problem of LLM router training with combined gold-standard and\npreference-based data into a causal inference framework by viewing the response\nevaluation mechanism as the treatment assignment. This perspective further\nreveals that the bias in preference-based data corresponds to the well-known\ncausal estimand: the conditional average treatment effect. Based on this new\nperspective, we develop an integrative causal router training framework that\ncorrects preference-data bias, address imbalances between two data sources, and\nimprove routing robustness and efficiency. Numerical experiments demonstrate\nthat our approach delivers more accurate routing and improves the trade-off\nbetween cost and quality.", "published": "2025-09-29 21:44:00", "link": "http://arxiv.org/abs/2509.25535v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Flow Matching with Semidiscrete Couplings", "abstract": "Flow models parameterized as time-dependent velocity fields can generate data\nfrom noise by integrating an ODE. These models are often trained using flow\nmatching, i.e. by sampling random pairs of noise and target points\n$(\\mathbf{x}_0,\\mathbf{x}_1)$ and ensuring that the velocity field is aligned,\non average, with $\\mathbf{x}_1-\\mathbf{x}_0$ when evaluated along a segment\nlinking $\\mathbf{x}_0$ to $\\mathbf{x}_1$. While these pairs are sampled\nindependently by default, they can also be selected more carefully by matching\nbatches of $n$ noise to $n$ target points using an optimal transport (OT)\nsolver. Although promising in theory, the OT flow matching (OT-FM) approach is\nnot widely used in practice. Zhang et al. (2025) pointed out recently that\nOT-FM truly starts paying off when the batch size $n$ grows significantly,\nwhich only a multi-GPU implementation of the Sinkhorn algorithm can handle.\nUnfortunately, the costs of running Sinkhorn can quickly balloon, requiring\n$O(n^2/\\varepsilon^2)$ operations for every $n$ pairs used to fit the velocity\nfield, where $\\varepsilon$ is a regularization parameter that should be\ntypically small to yield better results. To fulfill the theoretical promises of\nOT-FM, we propose to move away from batch-OT and rely instead on a semidiscrete\nformulation that leverages the fact that the target dataset distribution is\nusually of finite size $N$. The SD-OT problem is solved by estimating a dual\npotential vector using SGD; using that vector, freshly sampled noise vectors at\ntrain time can then be matched with data points at the cost of a maximum inner\nproduct search (MIPS). Semidiscrete FM (SD-FM) removes the quadratic dependency\non $n/\\varepsilon$ that bottlenecks OT-FM. SD-FM beats both FM and OT-FM on all\ntraining metrics and inference budget constraints, across multiple datasets, on\nunconditional/conditional generation, or when using mean-flow models.", "published": "2025-09-29 21:22:35", "link": "http://arxiv.org/abs/2509.25519v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "One-shot Conditional Sampling: MMD meets Nearest Neighbors", "abstract": "How can we generate samples from a conditional distribution that we never\nfully observe? This question arises across a broad range of applications in\nboth modern machine learning and classical statistics, including image\npost-processing in computer vision, approximate posterior sampling in\nsimulation-based inference, and conditional distribution modeling in complex\ndata settings. In such settings, compared with unconditional sampling,\nadditional feature information can be leveraged to enable more adaptive and\nefficient sampling. Building on this, we introduce Conditional Generator using\nMMD (CGMMD), a novel framework for conditional sampling. Unlike many\ncontemporary approaches, our method frames the training objective as a simple,\nadversary-free direct minimization problem. A key feature of CGMMD is its\nability to produce conditional samples in a single forward pass of the\ngenerator, enabling practical one-shot sampling with low test-time complexity.\nWe establish rigorous theoretical bounds on the loss incurred when sampling\nfrom the CGMMD sampler, and prove convergence of the estimated distribution to\nthe true conditional distribution. In the process, we also develop a uniform\nconcentration result for nearest-neighbor based functionals, which may be of\nindependent interest. Finally, we show that CGMMD performs competitively on\nsynthetic tasks involving complex conditional densities, as well as on\npractical applications such as image denoising and image super-resolution.", "published": "2025-09-29 21:04:50", "link": "http://arxiv.org/abs/2509.25507v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Message passing-based inference in an autoregressive active inference agent", "abstract": "We present the design of an autoregressive active inference agent in the form\nof message passing on a factor graph. Expected free energy is derived and\ndistributed across a planning graph. The proposed agent is validated on a robot\nnavigation task, demonstrating exploration and exploitation in a\ncontinuous-valued observation space with bounded continuous-valued actions.\nCompared to a classical optimal controller, the agent modulates action based on\npredictive uncertainty, arriving later but with a better model of the robot's\ndynamics.", "published": "2025-09-29 20:38:09", "link": "http://arxiv.org/abs/2509.25482v1", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Fair Classification by Direct Intervention on Operating Characteristics", "abstract": "We develop new classifiers under group fairness in the attribute-aware\nsetting for binary classification with multiple group fairness constraints\n(e.g., demographic parity (DP), equalized odds (EO), and predictive parity\n(PP)). We propose a novel approach, applicable to linear fractional\nconstraints, based on directly intervening on the operating characteristics of\na pre-trained base classifier, by (i) identifying optimal operating\ncharacteristics using the base classifier's group-wise ROC convex hulls and\n(ii) post-processing the base classifier to match those targets. As practical\npost-processors, we consider randomizing a mixture of group-wise thresholding\nrules subject to minimizing the expected number of interventions. We further\nextend our approach to handle multiple protected attributes and multiple linear\nfractional constraints. On standard datasets (COMPAS and ACSIncome), our\nmethods simultaneously satisfy approximate DP, EO, and PP with few\ninterventions and a near-oracle drop in accuracy; comparing favorably to\nprevious methods.", "published": "2025-09-29 20:36:32", "link": "http://arxiv.org/abs/2509.25481v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Neural Optimal Transport Meets Multivariate Conformal Prediction", "abstract": "We propose a framework for conditional vector quantile regression (CVQR) that\ncombines neural optimal transport with amortized optimization, and apply it to\nmultivariate conformal prediction. Classical quantile regression does not\nextend naturally to multivariate responses, while existing approaches often\nignore the geometry of joint distributions. Our method parametrizes the\nconditional vector quantile function as the gradient of a convex potential\nimplemented by an input-convex neural network, ensuring monotonicity and\nuniform ranks. To reduce the cost of solving high-dimensional variational\nproblems, we introduced amortized optimization of the dual potentials, yielding\nefficient training and faster inference. We then exploit the induced\nmultivariate ranks for conformal prediction, constructing distribution-free\npredictive regions with finite-sample validity. Unlike coordinatewise methods,\nour approach adapts to the geometry of the conditional distribution, producing\ntighter and more informative regions. Experiments on benchmark datasets show\nimproved coverage-efficiency trade-offs compared to baselines, highlighting the\nbenefits of integrating neural optimal transport with conformal prediction.", "published": "2025-09-29 19:50:19", "link": "http://arxiv.org/abs/2509.25444v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Gradient Descent with Large Step Sizes: Chaos and Fractal Convergence Region", "abstract": "We examine gradient descent in matrix factorization and show that under large\nstep sizes the parameter space develops a fractal structure. We derive the\nexact critical step size for convergence in scalar-vector factorization and\nshow that near criticality the selected minimizer depends sensitively on the\ninitialization. Moreover, we show that adding regularization amplifies this\nsensitivity, generating a fractal boundary between initializations that\nconverge and those that diverge. The analysis extends to general matrix\nfactorization with orthogonal initialization. Our findings reveal that\nnear-critical step sizes induce a chaotic regime of gradient descent where the\nlong-term dynamics are unpredictable and there are no simple implicit biases,\nsuch as towards balancedness, minimum norm, or flatness.", "published": "2025-09-29 18:04:22", "link": "http://arxiv.org/abs/2509.25351v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models", "abstract": "The performance of flow matching and diffusion models can be greatly improved\nat inference time using reward alignment algorithms, yet efficiency remains a\nmajor limitation. While several algorithms were proposed, we demonstrate that a\ncommon bottleneck is the sampling method these algorithms rely on: many\nalgorithms require to sample Markov transitions via SDE sampling, which is\nsignificantly less efficient and often less performant than ODE sampling. To\nremove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that\nsimulates a \"flow matching model within a flow matching model\" to sample Markov\ntransitions. As we show in this work, this \"inner\" flow matching model can be\nretrieved from a pre-trained model without any re-training, combining the\nefficiency of ODEs with the stochastic evolution of SDEs. On large-scale\ntext-to-image models, we show that GLASS Flows eliminate the trade-off between\nstochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS\nFlows improve state-of-the-art performance in text-to-image generation, making\nit a simple, drop-in solution for inference-time scaling of flow and diffusion\nmodels.", "published": "2025-09-29 17:58:36", "link": "http://arxiv.org/abs/2509.25170v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "High-Dimensional Analysis of Single-Layer Attention for Sparse-Token Classification", "abstract": "When and how can an attention mechanism learn to selectively attend to\ninformative tokens, thereby enabling detection of weak, rare, and sparsely\nlocated features? We address these questions theoretically in a sparse-token\nclassification model in which positive samples embed a weak signal vector in a\nrandomly chosen subset of tokens, whereas negative samples are pure noise. In\nthe long-sequence limit, we show that a simple single-layer attention\nclassifier can in principle achieve vanishing test error when the signal\nstrength grows only logarithmically in the sequence length $L$, whereas linear\nclassifiers require $\\sqrt{L}$ scaling. Moving from representational power to\nlearnability, we study training at finite $L$ in a high-dimensional regime,\nwhere sample size and embedding dimension grow proportionally. We prove that\njust two gradient updates suffice for the query weight vector of the attention\nclassifier to acquire a nontrivial alignment with the hidden signal, inducing\nan attention map that selectively amplifies informative tokens. We further\nderive an exact asymptotic expression for the test error and training loss of\nthe trained attention-based classifier, and quantify its capacity -- the\nlargest dataset size that is typically perfectly separable -- thereby\nexplaining the advantage of adaptive token selection over nonadaptive linear\nbaselines.", "published": "2025-09-29 17:54:53", "link": "http://arxiv.org/abs/2509.25153v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MAESTRO : Adaptive Sparse Attention and Robust Learning for Multimodal Dynamic Time Series", "abstract": "From clinical healthcare to daily living, continuous sensor monitoring across\nmultiple modalities has shown great promise for real-world intelligent\ndecision-making but also faces various challenges. In this work, we introduce\nMAESTRO, a novel framework that overcomes key limitations of existing\nmultimodal learning approaches: (1) reliance on a single primary modality for\nalignment, (2) pairwise modeling of modalities, and (3) assumption of complete\nmodality observations. These limitations hinder the applicability of these\napproaches in real-world multimodal time-series settings, where primary\nmodality priors are often unclear, the number of modalities can be large\n(making pairwise modeling impractical), and sensor failures often result in\narbitrary missing observations. At its core, MAESTRO facilitates dynamic intra-\nand cross-modal interactions based on task relevance, and leverages symbolic\ntokenization and adaptive attention budgeting to construct long multimodal\nsequences, which are processed via sparse cross-modal attention. The resulting\ncross-modal tokens are routed through a sparse Mixture-of-Experts (MoE)\nmechanism, enabling black-box specialization under varying modality\ncombinations. We evaluate MAESTRO against 10 baselines on four diverse datasets\nspanning three applications, and observe average relative improvements of 4%\nand 8% over the best existing multimodal and multivariate approaches,\nrespectively, under complete observations. Under partial observations -- with\nup to 40% of missing modalities -- MAESTRO achieves an average 9% improvement.\nFurther analysis also demonstrates the robustness and efficiency of MAESTRO's\nsparse, modality-aware design for learning from dynamic time series.", "published": "2025-09-29 03:07:06", "link": "http://arxiv.org/abs/2509.25278v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Relationships Between Separate Audio Tracks for Creative Applications", "abstract": "This paper presents the first step in a research project situated within the\nfield of musical agents. The objective is to achieve, through training, the\ntuning of the desired musical relationship between a live musical input and a\nreal-time generated musical output, through the curation of a database of\nseparated tracks. We propose an architecture integrating a symbolic decision\nmodule capable of learning and exploiting musical relationships from such\nmusical corpus. We detail an offline implementation of this architecture\nemploying Transformers as the decision module, associated with a perception\nmodule based on Wav2Vec 2.0, and concatenative synthesis as audio renderer. We\npresent a quantitative evaluation of the decision module's ability to reproduce\nlearned relationships extracted during training. We demonstrate that our\ndecision module can predict a coherent track B when conditioned by its\ncorresponding ''guide'' track A, based on a corpus of paired tracks (A, B).", "published": "2025-09-29 16:06:21", "link": "http://arxiv.org/abs/2509.25296v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint UE positioning and distributed sensing in the upper mid-band exploiting virtual apertures", "abstract": "Networks exploiting distributed integrated sensing and communication (DISAC)\nnodes can provide enhanced localization and sensing performance, further\nemphasized when operating with large arrays and bandwidths available in the\nupper mid-band (also known as FR3). In this paper, we consider a DISAC system\noperating at FR3 where a single base station (BS) acts as the transmitter and\nseveral vehicular user equipments (UEs) act as the receivers. We tackle the\ndesign of the signal processing chain at the UE side to enable joint UE\npositioning and target localization. The system model exploits a\nmultiple-input-multiple-output orthogonal frequency division multiplexing\n(MIMO-OFDM) waveform, and incorporates practical effects such as inter-node\ntiming offsets (TOs), extended targets, dense multipath, and realistic uniform\nplanar arrays (UPAs) at both ends. The proposed design includes a multipath\nestimation stage at each UE, clutter removal, a novel clustering and\nassociation scheme, and a final joint estimator of UE positions and target\nlocations. The estimator solves a weighted least squares (WLS) problem to\njointly compute clock offsets and localize UEs and targets. Numerical results\nconsidering two UEs and two targets show that for 80\\% of the cases the target\nlocalization error is below 32cm, while the UE positioning error is below 44cm.", "published": "2025-09-29 22:25:32", "link": "http://arxiv.org/abs/2509.25557v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "From Legacy to Leadership Intelligent Radio Network Planning Framework for Cell-Free Massive MIMO in B5G6G Era", "abstract": "The proliferation of cell-free Massive MIMO represents a transformative shift\nin wireless network architecture, addressing critical limitations of\nconventional distributed Massive MIMO systems. This paper presents an\nintelligent radio network planning framework that bridges legacy 5G\ninfrastructures with future B5G/6G networks through cell-free architectures. By\nleveraging operational insights from existing 5G deployments, we systematically\naddress coverage optimization, and capacity enhancement. Our scalable framework\nenables seamless evolution from legacy designs to next-generation cell-free\nsystems. Through extensive simulations in dense urban environments, we\ndemonstrate substantial improvements: 45% spectral efficiency gains, 30%\ninterference reduction, and significantly enhanced uniform coverage. The\nproposed framework provides network operators with a practical roadmap for\ntransitioning from traditional cellular architectures to demanding B5G/6G\nrequirements while maximizing existing infrastructure investments.", "published": "2025-09-29 21:20:29", "link": "http://arxiv.org/abs/2509.25517v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "An Implementation of Multi-User MIMO Downlink for O-RAN 5G New Radio using OpenAirInterface", "abstract": "We present the first implementation of a Multi-User Multiple-Input\nMultiple-Output (MU-MIMO) transmission scheme on the Physical Downlink Shared\nChannel (PDSCH) for 5G Open Radio Access Network (O-RAN) based on\nOpenAirInterface (OAI). Our implementation features a fully functional\nO-RAN-compliant 5G New Radio (5G NR) system, including a 5G Core Network (5G\nCN), a refined 5G RAN, which is split into a Centre Unit (CU) and an\nDistributed Unit (DU), and 5G NR User Equipment (UEs). This implementation\ndemonstrates MU-MIMO performance in the downlink while showcasing the\ndisaggregation capabilities of O-RAN. Specifically, the Base Station (i.e. gNB)\nin our setup is capable of serving two UEs simultaneously over the same\ndownlink Resource Block (RBs). User scheduling is performed based on the\nPrecoding Matrix Indicators (PMIs) reported by the UEs according to the NR\nChannel State Information (CSI) reporting procedure. The system throughput\nperformance is evaluated using $\\textit{iperf}$. The obtained results via\nsimulation and testbed experiments demonstrate that the MU-MIMO scheme achieves\nsignificant downlink throughput gains, particularly in the high\nSignal-to-Noise-Ratio (SNR) regime, while keeping the Block Error Rate (BLER)\nbelow the required threshold of $10^{-1}$ for both UEs.", "published": "2025-09-29 21:15:28", "link": "http://arxiv.org/abs/2509.25512v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A closed-loop $2\\times4$ downlink MIMO Framework for 5G New Radio using OpenAirInterface", "abstract": "We present the first-of-a-kind closed-loop $2\\times4$ MIMO implementation for\nthe downlink of 5G Open RAN using OpenAirInterface (OAI), which is capable of\ntransmitting up to two transmission layers. Our implementation is a fully\nfunctional 5G New Radio (5G NR) system, including the 5G Core Network (5G CN),\n5G Radio Access Network (5G RAN), as well as 5G NR User Equipment (UEs). This\nserves as a foundational framework for further advancements in the context of\nemerging Open RAN (O-RAN) development. A key feature of our implementation is\nthe enhanced Channel State Information (CSI) reporting procedure at the UE,\nwhich includes Rank Indicator (RI), Precoding Matrix Indicator (PMI), and\nChannel Quality Indicator (CQI). It is adjusted for the extended configuration\nto maximize data rates. To demonstrate the performance of our implementation,\nwe measure the downlink data rates using $\\textit{iperf3}$ in two scenarios:\n(i) fixed channels to assess two-layer data transmission and (ii)\n$\\textit{Rice1}$ channels for general transmission analysis. The obtained\nsimulation results demonstrate that, compared to the existing $2\\times2$ MIMO\nconfiguration in the OAI, our implementation improves the data rates in almost\nall scenarios, especially at the high Signal-to-Noise-Ratios (SNRs).", "published": "2025-09-29 20:54:20", "link": "http://arxiv.org/abs/2509.25497v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fast Energy-Theft Attack on Frequency-Varying Wireless Power without Additional Sensors", "abstract": "With the popularity of wireless charging, energy access protection and\ncybersecurity are gaining importance, especially in public places. Currently,\nthe most common energy encryption method uses frequency and associated\nimpedance variation. However, we have proven that this method is not reliable,\nsince a hacker can detect the changing frequency and adjust the compensation.\nHowever, the previously presented system needed time to follow the updated\nfrequency, while encryption systems may vary the frequency faster to avoid\nenergy theft. Furthermore, the previous system required an additional sensor\ncoil. To solve these problems, we optimized the attack and the associated\nsystem, which can intrude and steal energy within 0.2 ms. The key is the\nelimination of the time-consuming maximum receiver current regulation. Also, we\nuse the main receiving coil rather than any additional sensor antenna to detect\nthe magnetic field. Thus, the new hardware is even simpler. A simulation model\nand experimental results demonstrate the fast response speed of the attack on\nencrypted wireless power and steal 65% of the power. Overall, the applicability\nof the attack is highly improved and leaves less room for hardening the\nencryption. The results demonstrate that energy access protection needs to be\ngiven great attention.", "published": "2025-09-29 18:49:09", "link": "http://arxiv.org/abs/2509.25394v1", "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.CR"}
{"title": "A Graph-based Hybrid Beamforming Framework for MIMO Cell-Free ISAC Networks", "abstract": "This paper develops a graph-based hybrid beamforming framework for\nmultiple-input multiple-output (MIMO) cell-free integrated sensing and\ncommunication (ISAC) networks. Specifically, we construct a novel MIMO\ncell-free ISAC network model. In this model, multiple dual-function base\nstation (BS) transmitters employ distributed hybrid beamforming to enable\nsimultaneous communication and sensing, while maintaining physical separation\nbetween the transmitters and the radar receiver. Building on this model, we\nformulate a multi-objective optimization problem under a power constraint to\njointly improve communication and sensing performance. To solve it, the problem\nis first reformulated as a single-objective optimization problem. Then, a\ngraph-based method composed of multiple graph neural networks (GNNs) is\ndeveloped to realize hybrid beamforming with either perfect or imperfect\nchannel state information. Once trained, the neural network model can be\ndeployed distributively across BSs, enabling fast and efficient inference. To\nfurther reduce inference latency, a custom field-programmable gate array\n(FPGA)-based accelerator is developed. Numerical simulations validate the\ncommunication and sensing capabilities of the proposed optimization approach,\nwhile experimental evaluations demonstrate remarkable performance gains of\nFPGA-based acceleration in GNN inference.", "published": "2025-09-29 18:37:17", "link": "http://arxiv.org/abs/2509.25385v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimisation of Resource Allocation in Heterogeneous Wireless Networks Using Deep Reinforcement Learning", "abstract": "Dynamic resource allocation in heterogeneous wireless networks (HetNets) is\nchallenging for traditional methods under varying user loads and channel\nconditions. We propose a deep reinforcement learning (DRL) framework that\njointly optimises transmit power, bandwidth, and scheduling via a\nmulti-objective reward balancing throughput, energy efficiency, and fairness.\nUsing real base station coordinates, we compare Proximal Policy Optimisation\n(PPO) and Twin Delayed Deep Deterministic Policy Gradient (TD3) against three\nheuristic algorithms in multiple network scenarios. Our results show that DRL\nframeworks outperform heuristic algorithms in optimising resource allocation in\ndynamic networks. These findings highlight key trade-offs in DRL design for\nfuture HetNets.", "published": "2025-09-29 09:48:00", "link": "http://arxiv.org/abs/2509.25284v1", "categories": ["cs.LG", "cs.NI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Experimental Demonstration of Robust Distributed Wireless Clock Synchronization", "abstract": "Distributed wireless clock synchronization is essential for aligning the\nclocks of distributed transceivers in support of joint transmission and\nreception techniques. One recently explored method involves synchronizing\ndistributed transceivers using a two-tone waveform, where the tones are\nseparated in frequency by a clock (frequency) reference signal. Prior research\nhas demonstrated frequency accuracy better than 1 Hz; however, this approach\nremains vulnerable to both intentional and unintentional interference. In this\ndemonstration, we present a robust, frequency-hopped two-tone waveform that\nenables transceivers to extract the reference signal without prior knowledge of\nthe exact frequency at which the tones are transmitted.", "published": "2025-09-29 02:29:26", "link": "http://arxiv.org/abs/2509.25277v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "jina-reranker-v3: Last but Not Late Interaction for Document Reranking", "abstract": "jina-reranker-v3 is a 0.6B parameter multilingual document reranker that\nintroduces a novel last but not late interaction. Unlike late interaction\nmodels such as ColBERT that perform separate encoding followed by multi-vector\nmatching, our approach conducts causal self-attention between query and\ndocuments within the same context window, enabling rich cross-document\ninteractions before extracting contextual embeddings from the last token of\neach document. This compact architecture achieves state-of-the-art BEIR\nperformance with 61.94 nDCG@10 while being significant smaller than generative\nlistwise rerankers.", "published": "2025-09-29 17:23:54", "link": "http://arxiv.org/abs/2509.25085v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Tree-based formulation for the multi-commodity flow problem", "abstract": "We introduce a tree-based formulation for the minimum-cost multi-commodity\nflow problem that addresses large-scale instances. The method decomposes the\nsource-based model by representing flows as convex combinations of trees rooted\nat source nodes, and solves the resulting formulation with column generation.\nThe number of demand constraints now depends on the number of sources $|S|$,\nnot commodities $|K|$, yielding a compact master problem when $|S| \\ll |K|$. We\nconduct a computational study comparing tree-based decomposition against\npath-based column generation and direct LP solving. The results show speed-ups\nof up to one order of magnitude over direct LP solving, and improved\nscalability compared to path-based formulations. Tree-based decomposition\nenables solving instances with millions of commodities and hundreds of\nthousands of nodes. This makes it well-suited for applications in\ntransportation and logistics networks where multiple demands often share common\norigins.", "published": "2025-09-29 12:04:22", "link": "http://arxiv.org/abs/2509.24656v2", "categories": ["math.OC", "cs.DM"], "primary_category": "math.OC"}
{"title": "Curriculum Imitation Learning of Distributed Multi-Robot Policies", "abstract": "Learning control policies for multi-robot systems (MRS) remains a major\nchallenge due to long-term coordination and the difficulty of obtaining\nrealistic training data. In this work, we address both limitations within an\nimitation learning framework. First, we shift the typical role of Curriculum\nLearning in MRS, from scalability with the number of robots, to focus on\nimproving long-term coordination. We propose a curriculum strategy that\ngradually increases the length of expert trajectories during training,\nstabilizing learning and enhancing the accuracy of long-term behaviors. Second,\nwe introduce a method to approximate the egocentric perception of each robot\nusing only third-person global state demonstrations. Our approach transforms\nidealized trajectories into locally available observations by filtering\nneighbors, converting reference frames, and simulating onboard sensor\nvariability. Both contributions are integrated into a physics-informed\ntechnique to produce scalable, distributed policies from observations. We\nconduct experiments across two tasks with varying team sizes and noise levels.\nResults show that our curriculum improves long-term accuracy, while our\nperceptual estimation method yields policies that are robust to realistic\nuncertainty. Together, these strategies enable the learning of robust,\ndistributed controllers from global demonstrations, even in the absence of\nexpert actions or onboard measurements.", "published": "2025-09-29 17:31:48", "link": "http://arxiv.org/abs/2509.25097v2", "categories": ["cs.RO", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
