{"title": "Text Augmentation in a Multi-Task View", "abstract": "Traditional data augmentation aims to increase the coverage of the input\ndistribution by generating augmented examples that strongly resemble original\nsamples in an online fashion where augmented examples dominate training. In\nthis paper, we propose an alternative perspective -- a multi-task view (MTV) of\ndata augmentation -- in which the primary task trains on original examples and\nthe auxiliary task trains on augmented examples. In MTV data augmentation, both\noriginal and augmented samples are weighted substantively during training,\nrelaxing the constraint that augmented examples must resemble original data and\nthereby allowing us to apply stronger levels of augmentation. In empirical\nexperiments using four common data augmentation techniques on three benchmark\ntext classification datasets, we find that the MTV leads to higher and more\nrobust performance improvements than traditional augmentation.", "published": "2021-01-14 05:59:23", "link": "http://arxiv.org/abs/2101.05469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hostility Detection in Hindi leveraging Pre-Trained Language Models", "abstract": "Hostile content on social platforms is ever increasing. This has led to the\nneed for proper detection of hostile posts so that appropriate action can be\ntaken to tackle them. Though a lot of work has been done recently in the\nEnglish Language to solve the problem of hostile content online, similar works\nin Indian Languages are quite hard to find. This paper presents a transfer\nlearning based approach to classify social media (i.e Twitter, Facebook, etc.)\nposts in Hindi Devanagari script as Hostile or Non-Hostile. Hostile posts are\nfurther analyzed to determine if they are Hateful, Fake, Defamation, and\nOffensive. This paper harnesses attention based pre-trained models fine-tuned\non Hindi data with Hostile-Non hostile task as Auxiliary and fusing its\nfeatures for further sub-tasks classification. Through this approach, we\nestablish a robust and consistent model without any ensembling or complex\npre-processing. We have presented the results from our approach in\nCONSTRAINT-2021 Shared Task on hostile post detection where our model performs\nextremely well with 3rd runner up in terms of Weighted Fine-Grained F1 Score.", "published": "2021-01-14 08:04:32", "link": "http://arxiv.org/abs/2101.05494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection", "abstract": "The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.", "published": "2021-01-14 16:25:32", "link": "http://arxiv.org/abs/2101.05701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SICKNL: A Dataset for Dutch Natural Language Inference", "abstract": "We present SICK-NL (read: signal), a dataset targeting Natural Language\nInference in Dutch. SICK-NL is obtained by translating the SICK dataset of\nMarelli et al. (2014)from English into Dutch. Having a parallel inference\ndataset allows us to compare both monolingual and multilingual NLP models for\nEnglish and Dutch on the two tasks. In the paper, we motivate and detail the\ntranslation process, perform a baseline evaluation on both the original SICK\ndataset and its Dutch incarnation SICK-NL, taking inspiration from Dutch\nskipgram embeddings and contextualised embedding models. In addition, we\nencapsulate two phenomena encountered in the translation to formulate stress\ntests and verify how well the Dutch models capture syntactic restructurings\nthat do not affect semantics. Our main finding is all models perform worse on\nSICK-NL than on SICK, indicating that the Dutch dataset is more challenging\nthan the English original. Results on the stress tests show that models don't\nfully capture word order freedom in Dutch, warranting future systematic\nstudies.", "published": "2021-01-14 16:42:57", "link": "http://arxiv.org/abs/2101.05716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information", "abstract": "Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.", "published": "2021-01-14 08:39:50", "link": "http://arxiv.org/abs/2101.05499v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection", "abstract": "With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.", "published": "2021-01-14 09:05:42", "link": "http://arxiv.org/abs/2101.05509v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Temporality of Priors in Entity Linking", "abstract": "Entity linking is a fundamental task in natural language processing which\ndeals with the lexical ambiguity in texts. An important component in entity\nlinking approaches is the mention-to-entity prior probability. Even though\nthere is a large number of works in entity linking, the existing approaches do\nnot explicitly consider the time aspect, specifically the temporality of an\nentity's prior probability. We posit that this prior probability is temporal in\nnature and affects the performance of entity linking systems. In this paper we\nsystematically study the effect of the prior on the entity linking performance\nover the temporal validity of both texts and KBs.", "published": "2021-01-14 13:58:31", "link": "http://arxiv.org/abs/2101.05593v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better Together -- An Ensemble Learner for Combining the Results of\n  Ready-made Entity Linking Systems", "abstract": "Entity linking (EL) is the task of automatically identifying entity mentions\nin text and resolving them to a corresponding entity in a reference knowledge\nbase like Wikipedia. Throughout the past decade, a plethora of EL systems and\npipelines have become available, where performance of individual systems varies\nheavily across corpora, languages or domains. Linking performance varies even\nbetween different mentions in the same text corpus, where, for instance, some\nEL approaches are better able to deal with short surface forms while others may\nperform better when more context information is available. To this end, we\nargue that performance may be optimised by exploiting results from distinct EL\nsystems on the same corpus, thereby leveraging their individual strengths on a\nper-mention basis. In this paper, we introduce a supervised approach which\nexploits the output of multiple ready-made EL systems by predicting the correct\nlink on a per-mention basis. Experimental results obtained on existing ground\ntruth datasets and exploiting three state-of-the-art EL systems show the\neffectiveness of our approach and its capacity to significantly outperform the\nindividual EL systems as well as a set of baseline methods.", "published": "2021-01-14 14:42:57", "link": "http://arxiv.org/abs/2101.05634v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Informative Tweet Identification For Tracking Mass Events", "abstract": "Twitter has been heavily used as an important channel for communicating and\ndiscussing about events in real-time. In such major events, many uninformative\ntweets are also published rapidly by many users, making it hard to follow the\nevents. In this paper, we address this problem by investigating machine\nlearning methods for automatically identifying informative tweets among those\nthat are relevant to a target event. We examine both traditional approaches\nwith a rich set of handcrafted features and state of the art approaches with\nautomatically learned features. We further propose a hybrid model that\nleverages both the handcrafted features and the automatically learned ones. Our\nexperiments on several large datasets of real-world events show that the latter\napproaches significantly outperform the former and our proposed model performs\nthe best, suggesting highly effective mechanisms for tracking mass events.", "published": "2021-01-14 15:10:42", "link": "http://arxiv.org/abs/2101.05656v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained\n  Sequence-to-Sequence Models", "abstract": "We propose a design pattern for tackling text ranking problems, dubbed\n\"Expando-Mono-Duo\", that has been empirically validated for a number of ad hoc\nretrieval tasks in different domains. At the core, our design relies on\npretrained sequence-to-sequence models within a standard multi-stage ranking\narchitecture. \"Expando\" refers to the use of document expansion techniques to\nenrich keyword representations of texts prior to inverted indexing. \"Mono\" and\n\"Duo\" refer to components in a reranking pipeline based on a pointwise model\nand a pairwise model that rerank initial candidates retrieved using keyword\nsearch. We present experimental results from the MS MARCO passage and document\nranking tasks, the TREC 2020 Deep Learning Track, and the TREC-COVID challenge\nthat validate our design. In all these tasks, we achieve effectiveness that is\nat or near the state of the art, in some cases using a zero-shot approach that\ndoes not exploit any training data from the target task. To support\nreplicability, implementations of our design pattern are open-sourced in the\nPyserini IR toolkit and PyGaggle neural reranking library.", "published": "2021-01-14 15:29:54", "link": "http://arxiv.org/abs/2101.05667v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Structured Prediction as Translation between Augmented Natural Languages", "abstract": "We propose a new framework, Translation between Augmented Natural Languages\n(TANL), to solve many structured prediction language tasks including joint\nentity and relation extraction, nested named entity recognition, relation\nclassification, semantic role labeling, event extraction, coreference\nresolution, and dialogue state tracking. Instead of tackling the problem by\ntraining task-specific discriminative classifiers, we frame it as a translation\ntask between augmented natural languages, from which the task-relevant\ninformation can be easily extracted. Our approach can match or outperform\ntask-specific models on all tasks, and in particular, achieves new\nstate-of-the-art results on joint entity and relation extraction (CoNLL04, ADE,\nNYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and\nsemantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while\nusing the same architecture and hyperparameters for all tasks and even when\ntraining a single model to solve all tasks at the same time (multi-task\nlearning). Finally, we show that our framework can also significantly improve\nthe performance in a low-resource regime, thanks to better use of label\nsemantics.", "published": "2021-01-14 18:32:21", "link": "http://arxiv.org/abs/2101.05779v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Persistent Anti-Muslim Bias in Large Language Models", "abstract": "It has been observed that large-scale language models capture undesirable\nsocietal biases, e.g. relating to race and gender; yet religious bias has been\nrelatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual\nlanguage model, captures persistent Muslim-violence bias. We probe GPT-3 in\nvarious ways, including prompt completion, analogical reasoning, and story\ngeneration, to understand this anti-Muslim bias, demonstrating that it appears\nconsistently and creatively in different uses of the model and that it is\nsevere even compared to biases about other religious groups. For instance,\n\"Muslim\" is analogized to \"terrorist\" in 23% of test cases, while \"Jewish\" is\nmapped to \"money\" in 5% of test cases. We quantify the positive distraction\nneeded to overcome this bias with adversarial text prompts, and find that use\nof the most positive 6 adjectives reduces violent completions for \"Muslims\"\nfrom 66% to 20%, but which is still higher than for other religious groups.", "published": "2021-01-14 18:41:55", "link": "http://arxiv.org/abs/2101.05783v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Persuasive Natural Language Generation -- A Literature Review", "abstract": "This literature review focuses on the use of Natural Language Generation\n(NLG) to automatically detect and generate persuasive texts. Extending previous\nresearch on automatic identification of persuasion in text, we concentrate on\ngenerative aspects through conceptualizing determinants of persuasion in five\nbusiness-focused categories: benevolence, linguistic appropriacy, logical\nargumentation, trustworthiness, tools and datasets. These allow NLG to increase\nan existing message's persuasiveness. Previous research illustrates key aspects\nin each of the above mentioned five categories. A research agenda to further\nstudy persuasive NLG is developed. The review includes analysis of\nseventy-seven articles, outlining the existing body of knowledge and showing\nthe steady progress in this research field.", "published": "2021-01-14 18:44:51", "link": "http://arxiv.org/abs/2101.05786v1", "categories": ["cs.CL", "cs.AI", "I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "TSQA: Tabular Scenario Based Question Answering", "abstract": "Scenario-based question answering (SQA) has attracted an increasing research\ninterest. Compared with the well-studied machine reading comprehension (MRC),\nSQA is a more challenging task: a scenario may contain not only a textual\npassage to read but also structured data like tables, i.e., tabular scenario\nbased question answering (TSQA). AI applications of TSQA such as answering\nmultiple-choice questions in high-school exams require synthesizing data in\nmultiple cells and combining tables with texts and domain knowledge to infer\nanswers. To support the study of this task, we construct GeoTSQA. This dataset\ncontains 1k real questions contextualized by tabular scenarios in the geography\ndomain. To solve the task, we extend state-of-the-art MRC methods with TTGen, a\nnovel table-to-text generator. It generates sentences from variously\nsynthesized tabular data and feeds the downstream MRC method with the most\nuseful sentences. Its sentence ranking model fuses the information in the\nscenario, question, and domain knowledge. Our approach outperforms a variety of\nstrong baseline methods on GeoTSQA.", "published": "2021-01-14 02:00:33", "link": "http://arxiv.org/abs/2101.11429v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Explainable CNN Approach for Medical Codes Prediction from Clinical\n  Text", "abstract": "Method: We develop CNN-based methods for automatic ICD coding based on\nclinical text from intensive care unit (ICU) stays. We come up with the Shallow\nand Wide Attention convolutional Mechanism (SWAM), which allows our model to\nlearn local and low-level features for each label. The key idea behind our\nmodel design is to look for the presence of informative snippets in the\nclinical text that correlated with each code, and we infer that there exists a\ncorrespondence between \"informative snippet\" and convolution filter. Results:\nWe evaluate our approach on MIMIC-III, an open-access dataset of ICU medical\nrecords. Our approach substantially outperforms previous results on top-50\nmedical code prediction on MIMIC-III dataset. We attribute this improvement to\nSWAM, by which the wide architecture gives the model ability to more\nextensively learn the unique features of different codes, and we prove it by\nablation experiment. Besides, we perform manual analysis of the performance\nimbalance between different codes, and preliminary conclude the characteristics\nthat determine the difficulty of learning specific codes. Conclusions: We\npresent SWAM, an explainable CNN approach for multi-label document\nclassification, which employs a wide convolution layer to learn local and\nlow-level features for each label, yields strong improvements over previous\nmetrics on the ICD-9 code prediction task, while providing satisfactory\nexplanations for its internal mechanics.", "published": "2021-01-14 02:05:34", "link": "http://arxiv.org/abs/2101.11430v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scared into Action: How Partisanship and Fear are Associated with\n  Reactions to Public Health Directives", "abstract": "Differences in political ideology are increasingly appearing as an impediment\nto successful bipartisan communication from local leadership. For example,\nrecent empirical findings have shown that conservatives are less likely to\nadhere to COVID-19 health directives. This behavior is in direct contradiction\nto past research which indicates that conservatives are more rule abiding,\nprefer to avoid loss, and are more prevention-motivated than liberals. We\nreconcile this disconnect between recent empirical findings and past research\nby using insights gathered from press releases, millions of tweets, and\nmobility data capturing local movement in retail, grocery, workplace, parks,\nand transit domains during COVID-19 shelter-in-place orders. We find that\nconservatives adhere to health directives when they express more fear of the\nvirus. In order to better understand this phenomenon, we analyze both official\nand citizen communications and find that press releases from local and federal\ngovernment, along with the number of confirmed COVID-19 cases, lead to an\nincrease in expressions of fear on Twitter.", "published": "2021-01-14 17:29:10", "link": "http://arxiv.org/abs/2101.05365v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "stat.CO"], "primary_category": "econ.GN"}
{"title": "Machine-Assisted Script Curation", "abstract": "We describe Machine-Aided Script Curator (MASC), a system for human-machine\ncollaborative script authoring. Scripts produced with MASC include (1) English\ndescriptions of sub-events that comprise a larger, complex event; (2) event\ntypes for each of those events; (3) a record of entities expected to\nparticipate in multiple sub-events; and (4) temporal sequencing between the\nsub-events. MASC automates portions of the script creation process with\nsuggestions for event types, links to Wikidata, and sub-events that may have\nbeen forgotten. We illustrate how these automations are useful to the script\nwriter with a few case-study scripts.", "published": "2021-01-14 00:19:21", "link": "http://arxiv.org/abs/2101.05400v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Data Leakage Analysis in Language Models", "abstract": "Recent advances in neural network based language models lead to successful\ndeployments of such models, improving user experience in various applications.\nIt has been demonstrated that strong performance of language models comes along\nwith the ability to memorize rare training samples, which poses serious privacy\nthreats in case the model is trained on confidential user content. In this\nwork, we introduce a methodology that investigates identifying the user content\nin the training data that could be leaked under a strong and realistic threat\nmodel. We propose two metrics to quantify user-level data leakage by measuring\na model's ability to produce unique sentence fragments within training data.\nOur metrics further enable comparing different models trained on the same data\nin terms of privacy. We demonstrate our approach through extensive numerical\nstudies on both RNN and Transformer based models. We further illustrate how the\nproposed metrics can be utilized to investigate the efficacy of mitigations\nlike differentially private training or API hardening.", "published": "2021-01-14 00:57:32", "link": "http://arxiv.org/abs/2101.05405v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "WER-BERT: Automatic WER Estimation with BERT in a Balanced Ordinal\n  Classification Paradigm", "abstract": "Automatic Speech Recognition (ASR) systems are evaluated using Word Error\nRate (WER), which is calculated by comparing the number of errors between the\nground truth and the transcription of the ASR system. This calculation,\nhowever, requires manual transcription of the speech signal to obtain the\nground truth. Since transcribing audio signals is a costly process, Automatic\nWER Evaluation (e-WER) methods have been developed to automatically predict the\nWER of a speech system by only relying on the transcription and the speech\nsignal features. While WER is a continuous variable, previous works have shown\nthat positing e-WER as a classification problem is more effective than\nregression. However, while converting to a classification setting, these\napproaches suffer from heavy class imbalance. In this paper, we propose a new\nbalanced paradigm for e-WER in a classification setting. Within this paradigm,\nwe also propose WER-BERT, a BERT based architecture with speech features for\ne-WER. Furthermore, we introduce a distance loss function to tackle the ordinal\nnature of e-WER classification. The proposed approach and paradigm are\nevaluated on the Librispeech dataset and a commercial (black box) ASR system,\nGoogle Cloud's Speech-to-Text API. The results and experiments demonstrate that\nWER-BERT establishes a new state-of-the-art in automatic WER estimation.", "published": "2021-01-14 07:26:28", "link": "http://arxiv.org/abs/2101.05478v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An evaluation of word-level confidence estimation for end-to-end\n  automatic speech recognition", "abstract": "Quantifying the confidence (or conversely the uncertainty) of a prediction is\na highly desirable trait of an automatic system, as it improves the robustness\nand usefulness in downstream tasks. In this paper we investigate confidence\nestimation for end-to-end automatic speech recognition (ASR). Previous work has\naddressed confidence measures for lattice-based ASR, while current machine\nlearning research mostly focuses on confidence measures for unstructured deep\nlearning. However, as the ASR systems are increasingly being built upon deep\nend-to-end methods, there is little work that tries to develop confidence\nmeasures in this context. We fill this gap by providing an extensive benchmark\nof popular confidence methods on four well-known speech datasets. There are two\nchallenges we overcome in adapting existing methods: working on structured data\n(sequences) and obtaining confidences at a coarser level than the predictions\n(words instead of tokens). Our results suggest that a strong baseline can be\nobtained by scaling the logits by a learnt temperature, followed by estimating\nthe confidence as the negative entropy of the predictive distribution and,\nfinally, sum pooling to aggregate at word level.", "published": "2021-01-14 09:51:59", "link": "http://arxiv.org/abs/2101.05525v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Malicious Code Detection: Run Trace Output Analysis by LSTM", "abstract": "Malicious software threats and their detection have been gaining importance\nas a subdomain of information security due to the expansion of ICT applications\nin daily settings. A major challenge in designing and developing anti-malware\nsystems is the coverage of the detection, particularly the development of\ndynamic analysis methods that can detect polymorphic and metamorphic malware\nefficiently. In the present study, we propose a methodological framework for\ndetecting malicious code by analyzing run trace outputs by Long Short-Term\nMemory (LSTM). We developed models of run traces of malicious and benign\nPortable Executable (PE) files. We created our dataset from run trace outputs\nobtained from dynamic analysis of PE files. The obtained dataset was in the\ninstruction format as a sequence and was called Instruction as a Sequence Model\n(ISM). By splitting the first dataset into basic blocks, we obtained the second\none called Basic Block as a Sequence Model (BSM). The experiments showed that\nthe ISM achieved an accuracy of 87.51% and a false positive rate of 18.34%,\nwhile BSM achieved an accuracy of 99.26% and a false positive rate of 2.62%.", "published": "2021-01-14 15:00:42", "link": "http://arxiv.org/abs/2101.05646v1", "categories": ["cs.CR", "cs.CL", "cs.LG", "D.2.5; I.2.7; K.3.2"], "primary_category": "cs.CR"}
{"title": "Interpretable Multi-Head Self-Attention model for Sarcasm Detection in\n  social media", "abstract": "Sarcasm is a linguistic expression often used to communicate the opposite of\nwhat is said, usually something that is very unpleasant with an intention to\ninsult or ridicule. Inherent ambiguity in sarcastic expressions, make sarcasm\ndetection very difficult. In this work, we focus on detecting sarcasm in\ntextual conversations from various social networking platforms and online\nmedia. To this end, we develop an interpretable deep learning model using\nmulti-head self-attention and gated recurrent units. Multi-head self-attention\nmodule aids in identifying crucial sarcastic cue-words from the input, and the\nrecurrent units learn long-range dependencies between these cue-words to better\nclassify the input text. We show the effectiveness of our approach by achieving\nstate-of-the-art results on multiple datasets from social networking platforms\nand online media. Models trained using our proposed approach are easily\ninterpretable and enable identifying sarcastic cues in the input text which\ncontribute to the final classification score. We visualize the learned\nattention weights on few sample input texts to showcase the effectiveness and\ninterpretability of our model.", "published": "2021-01-14 21:39:35", "link": "http://arxiv.org/abs/2101.05875v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Unsupervised heart abnormality detection based on phonocardiogram\n  analysis with Beta Variational Auto-Encoders", "abstract": "Heart Sound (also known as phonocardiogram (PCG)) analysis is a popular way\nthat detects cardiovascular diseases (CVDs). Most PCG analysis uses supervised\nway, which demands both normal and abnormal samples. This paper proposes a\nmethod of unsupervised PCG analysis that uses beta variational auto-encoder\n($\\beta-\\text{VAE}$) to model the normal PCG signals. The best performed model\nreaches an AUC (Area Under Curve) value of 0.91 in ROC (Receiver Operating\nCharacteristic) test for PCG signals collected from the same source. Unlike\nmajority of $\\beta-\\text{VAE}$s that are used as generative models, the\nbest-performed $\\beta-\\text{VAE}$ has a $\\beta$ value smaller than 1. Further\nexperiments then find that the introduction of a light weighted KL divergence\nbetween distribution of latent space and normal distribution improves the\nperformance of anomaly PCG detection based on anomaly scores resulted by\nreconstruction loss. The fact suggests that anomaly score based on\nreconstruction loss may be better than anomaly scores based on latent vectors\nof samples", "published": "2021-01-14 03:52:47", "link": "http://arxiv.org/abs/2101.05443v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker activity driven neural speech extraction", "abstract": "Target speech extraction, which extracts the speech of a target speaker in a\nmixture given auxiliary speaker clues, has recently received increased\ninterest. Various clues have been investigated such as pre-recorded enrollment\nutterances, direction information, or video of the target speaker. In this\npaper, we explore the use of speaker activity information as an auxiliary clue\nfor single-channel neural network-based speech extraction. We propose a speaker\nactivity driven speech extraction neural network (ADEnet) and show that it can\nachieve performance levels competitive with enrollment-based approaches,\nwithout the need for pre-recordings. We further demonstrate the potential of\nthe proposed approach for processing meeting-like recordings, where the speaker\nactivity is obtained from a diarization system. We show that this simple yet\npractical approach can successfully extract speakers after diarization, which\nresults in improved ASR performance, especially in high overlapping conditions,\nwith a relative word error rate reduction of up to 25%.", "published": "2021-01-14 09:21:51", "link": "http://arxiv.org/abs/2101.05516v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fast offline Transformer-based end-to-end automatic speech recognition\n  for real-world applications", "abstract": "With the recent advances in technology, automatic speech recognition (ASR)\nhas been widely used in real-world applications. The efficiency of converting\nlarge amounts of speech into text accurately with limited resources has become\nmore important than ever. This paper proposes a method to rapidly recognize a\nlarge speech database via a Transformer-based end-to-end model. Transformers\nhave improved the state-of-the-art performance in many fields. However, they\nare not easy to use for long sequences. In this paper, various techniques to\nspeed up the recognition of real-world speeches are proposed and tested,\nincluding decoding via multiple-utterance batched beam search, detecting\nend-of-speech based on a connectionist temporal classification (CTC),\nrestricting the CTC prefix score, and splitting long speeches into short\nsegments. Experiments are conducted with the Librispeech English and the\nreal-world Korean ASR tasks to verify the proposed methods. From the\nexperiments, the proposed system can convert 8 hours of speeches spoken at\nreal-world meetings into text in less than 3 minutes with a 10.73% character\nerror rate, which is 27.1% relatively lower than that of conventional systems.", "published": "2021-01-14 14:13:11", "link": "http://arxiv.org/abs/2101.05600v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EmoCat: Language-agnostic Emotional Voice Conversion", "abstract": "Emotional voice conversion models adapt the emotion in speech without\nchanging the speaker identity or linguistic content. They are less data hungry\nthan text-to-speech models and allow to generate large amounts of emotional\ndata for downstream tasks. In this work we propose EmoCat, a language-agnostic\nemotional voice conversion model. It achieves high-quality emotion conversion\nin German with less than 45 minutes of German emotional recordings by\nexploiting large amounts of emotional data in US English. EmoCat is an\nencoder-decoder model based on CopyCat, a voice conversion system which\ntransfers prosody. We use adversarial training to remove emotion leakage from\nthe encoder to the decoder. The adversarial training is improved by a novel\ncontribution to gradient reversal to truly reverse gradients. This allows to\nremove only the leaking information and to converge to better optima with\nhigher conversion performance. Evaluations show that Emocat can convert to\ndifferent emotions but misses on emotion intensity compared to the recordings,\nespecially for very expressive emotions. EmoCat is able to achieve audio\nquality on par with the recordings for five out of six tested emotion\nintensities.", "published": "2021-01-14 16:18:53", "link": "http://arxiv.org/abs/2101.05695v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Estimation of the Frequency of Occurrence of Italian Phonemes in Text", "abstract": "The purpose of this project was to derive a reliable estimate of the\nfrequency of occurrence of the 30 phonemes - plus consonant geminated\ncounterparts - of the Italian language, based on four selected written texts.\nSince no comparable dataset was found in previous literature, the present\nanalysis may serve as a reference in future studies. Four textual sources were\nconsidered: Come si fa una tesi di laurea: le materie umanistiche by Umberto\nEco, I promessi sposi by Alessandro Manzoni, a recent article in Corriere della\nSera (a popular daily Italian newspaper), and In altre parole by Jhumpa Lahiri.\nThe sources were chosen to represent varied genres, subject matter, time\nperiods, and writing styles. Results of the analysis, which also included an\nanalysis of variance, showed that, for all four sources, the frequencies of\noccurrence reached relatively stable values after about 6,000 phonemes (approx.\n1,250 words), varying by <0.025%. Estimated frequencies are provided for each\nsingle source and as an average across sources.", "published": "2021-01-14 11:57:54", "link": "http://arxiv.org/abs/2101.06147v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Generating coherent spontaneous speech and gesture from text", "abstract": "Embodied human communication encompasses both verbal (speech) and non-verbal\ninformation (e.g., gesture and head movements). Recent advances in machine\nlearning have substantially improved the technologies for generating synthetic\nversions of both of these types of data: On the speech side, text-to-speech\nsystems are now able to generate highly convincing, spontaneous-sounding speech\nusing unscripted speech audio as the source material. On the motion side,\nprobabilistic motion-generation methods can now synthesise vivid and lifelike\nspeech-driven 3D gesticulation. In this paper, we put these two\nstate-of-the-art technologies together in a coherent fashion for the first\ntime. Concretely, we demonstrate a proof-of-concept system trained on a\nsingle-speaker audio and motion-capture dataset, that is able to generate both\nspeech and full-body gestures together from text input. In contrast to previous\napproaches for joint speech-and-gesture generation, we generate full-body\ngestures from speech synthesis trained on recordings of spontaneous speech from\nthe same person as the motion-capture data. We illustrate our results by\nvisualising gesture spaces and text-speech-gesture alignments, and through a\ndemonstration video at https://simonalexanderson.github.io/IVA2020 .", "published": "2021-01-14 16:02:21", "link": "http://arxiv.org/abs/2101.05684v1", "categories": ["cs.LG", "cs.GR", "cs.SD", "eess.AS", "68T07", "I.2.6; J.4; I.3.7; I.2.9"], "primary_category": "cs.LG"}
