{"title": "Adversarial Attacks on Deep Learning Models in Natural Language\n  Processing: A Survey", "abstract": "With the development of high computational devices, deep neural networks\n(DNNs), in recent years, have gained significant popularity in many Artificial\nIntelligence (AI) applications. However, previous efforts have shown that DNNs\nwere vulnerable to strategically modified samples, named adversarial examples.\nThese samples are generated with some imperceptible perturbations but can fool\nthe DNNs to give false predictions. Inspired by the popularity of generating\nadversarial examples for image DNNs, research efforts on attacking DNNs for\ntextual applications emerges in recent years. However, existing perturbation\nmethods for images cannotbe directly applied to texts as text data is discrete.\nIn this article, we review research works that address this difference and\ngeneratetextual adversarial examples on DNNs. We collect, select, summarize,\ndiscuss and analyze these works in a comprehensive way andcover all the related\ninformation to make the article self-contained. Finally, drawing on the\nreviewed literature, we provide further discussions and suggestions on this\ntopic.", "published": "2019-01-21 05:55:42", "link": "http://arxiv.org/abs/1901.06796v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chemical Names Standardization using Neural Sequence to Sequence Model", "abstract": "Chemical information extraction is to convert chemical knowledge in text into\ntrue chemical database, which is a text processing task heavily relying on\nchemical compound name identification and standardization. Once a systematic\nname for a chemical compound is given, it will naturally and much simply\nconvert the name into the eventually required molecular formula. However, for\nmany chemical substances, they have been shown in many other names besides\ntheir systematic names which poses a great challenge for this task. In this\npaper, we propose a framework to do the auto standardization from the\nnon-systematic names to the corresponding systematic names by using the\nspelling error correction, byte pair encoding tokenization and neural sequence\nto sequence model. Our framework is trained end to end and is fully\ndata-driven. Our standardization accuracy on the test dataset achieves 54.04%\nwhich has a great improvement compared to previous state-of-the-art result.", "published": "2019-01-21 17:24:54", "link": "http://arxiv.org/abs/1901.07003v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AD3: Attentive Deep Document Dater", "abstract": "Knowledge of the creation date of documents facilitates several tasks such as\nsummarization, event extraction, temporally focused information extraction etc.\nUnfortunately, for most of the documents on the Web, the time-stamp metadata is\neither missing or can't be trusted. Thus, predicting creation time from\ndocument content itself is an important task. In this paper, we propose\nAttentive Deep Document Dater (AD3), an attention-based neural document dating\nsystem which utilizes both context and temporal information in documents in a\nflexible and principled manner. We perform extensive experimentation on\nmultiple real-world datasets to demonstrate the effectiveness of AD3 over\nneural and non-neural baselines.", "published": "2019-01-21 07:02:52", "link": "http://arxiv.org/abs/1902.02161v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Development of verification system of socio-demographic data of virtual\n  community member", "abstract": "The important task of developing verification system of data of virtual\ncommunity member on the basis of computer-linguistic analysis of the content of\na large sample of Ukrainian virtual communities is solved. The subject of\nresearch is methods and tools for verification of web-members socio-demographic\ncharacteristics based on computer-linguistic analysis of their communicative\ninteraction results. The aim of paper is to verifying web-user personal data on\nthe basis of computer-linguistic analysis of web-members information tracks.\nThe structure of verification software for web-user profile is designed for a\npractical implementation of assigned tasks. The method of personal data\nverification of web-members by analyzing information track of virtual community\nmember is conducted. For the first time the method for checking the\nauthenticity of web members personal data, which helped to design of\nverification tool for socio-demographic characteristics of web-member is\ndeveloped. The verification system of data of web-members, which forms the\nverified socio-demographic profiles of web-members, is developed as a result of\nconducted experiments. Also the user interface of the developed verification\nsystem web-members data is presented. Effectiveness and efficiency of use of\nthe developed methods and means for solving tasks in web-communities\nadministration is proved by their approbation. The number of false results of\nverification system is 18%.", "published": "2019-01-21 20:21:05", "link": "http://arxiv.org/abs/1901.07067v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Error-Correcting Neural Sequence Prediction", "abstract": "We propose a novel neural sequence prediction method based on\n\\textit{error-correcting output codes} that avoids exact softmax normalization\nand allows for a tradeoff between speed and performance. Instead of minimizing\nmeasures between the predicted probability distribution and true distribution,\nwe use error-correcting codes to represent both predictions and outputs.\nSecondly, we propose multiple ways to improve accuracy and convergence rates by\nmaximizing the separability between codes that correspond to classes\nproportional to word embedding similarities. Lastly, we introduce our main\ncontribution called \\textit{Latent Variable Mixture Sampling}, a technique that\nis used to mitigate exposure bias, which can be integrated into training latent\nvariable-based neural sequence predictors such as ECOC. This involves mixing\nthe latent codes of past predictions and past targets in one of two ways: (1)\naccording to a predefined sampling schedule or (2) a differentiable sampling\nprocedure whereby the mixing probability is learned throughout training by\nreplacing the greedy argmax operation with a smooth approximation. ECOC-NSP\nleads to consistent improvements on language modelling datasets and the\nproposed Latent Variable mixture sampling methods are found to perform well for\ntext generation tasks such as image captioning.", "published": "2019-01-21 17:17:06", "link": "http://arxiv.org/abs/1901.07002v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "DLocRL: A Deep Learning Pipeline for Fine-Grained Location Recognition\n  and Linking in Tweets", "abstract": "In recent years, with the prevalence of social media and smart devices,\npeople causally reveal their locations such as shops, hotels, and restaurants\nin their tweets. Recognizing and linking such fine-grained location mentions to\nwell-defined location profiles are beneficial for retrieval and recommendation\nsystems. In this paper, we propose DLocRL, a new deep learning pipeline for\nfine-grained location recognition and linking in tweets, and verify its\neffectiveness on a real-world Twitter dataset.", "published": "2019-01-21 17:36:19", "link": "http://arxiv.org/abs/1901.07005v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning sound representations using trainable COPE feature extractors", "abstract": "Sound analysis research has mainly been focused on speech and music\nprocessing. The deployed methodologies are not suitable for analysis of sounds\nwith varying background noise, in many cases with very low signal-to-noise\nratio (SNR). In this paper, we present a method for the detection of patterns\nof interest in audio signals. We propose novel trainable feature extractors,\nwhich we call COPE (Combination of Peaks of Energy). The structure of a COPE\nfeature extractor is determined using a single prototype sound pattern in an\nautomatic configuration process, which is a type of representation learning. We\nconstruct a set of COPE feature extractors, configured on a number of training\npatterns. Then we take their responses to build feature vectors that we use in\ncombination with a classifier to detect and classify patterns of interest in\naudio signals. We carried out experiments on four public data sets: MIVIA audio\nevents, MIVIA road events, ESC-10 and TU Dortmund data sets. The results that\nwe achieved (recognition rate equal to 91.71% on the MIVIA audio events, 94% on\nthe MIVIA road events, 81.25% on the ESC-10 and 94.27% on the TU Dortmund)\ndemonstrate the effectiveness of the proposed method and are higher than the\nones obtained by other existing approaches. The COPE feature extractors have\nhigh robustness to variations of SNR. Real-time performance is achieved even\nwhen the value of a large number of features is computed.", "published": "2019-01-21 12:18:41", "link": "http://arxiv.org/abs/1901.06904v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
