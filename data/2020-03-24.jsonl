{"title": "Felix: Flexible Text Editing Through Tagging and Insertion", "abstract": "We present Felix --- a flexible text-editing approach for generation,\ndesigned to derive the maximum benefit from the ideas of decoding with\nbi-directional contexts and self-supervised pre-training. In contrast to\nconventional sequence-to-sequence (seq2seq) models, Felix is efficient in\nlow-resource settings and fast at inference time, while being capable of\nmodeling flexible input-output transformations. We achieve this by decomposing\nthe text-editing task into two sub-tasks: tagging to decide on the subset of\ninput tokens and their order in the output text and insertion to in-fill the\nmissing tokens in the output not present in the input. The tagging model\nemploys a novel Pointer mechanism, while the insertion model is based on a\nMasked Language Model. Both of these models are chosen to be non-autoregressive\nto guarantee faster inference. Felix performs favourably when compared to\nrecent text-editing methods and strong seq2seq baselines when evaluated on four\nNLG tasks: Sentence Fusion, Machine Translation Automatic Post-Editing,\nSummarization, and Text Simplification.", "published": "2020-03-24 07:01:09", "link": "http://arxiv.org/abs/2003.10687v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Neural Machine Translation for Edoid Languages", "abstract": "Many Nigerian languages have relinquished their previous prestige and purpose\nin modern society to English and Nigerian Pidgin. For the millions of L1\nspeakers of indigenous languages, there are inequalities that manifest\nthemselves as unequal access to information, communications, health care,\nsecurity as well as attenuated participation in political and civic life. To\nminimize exclusion and promote socio-linguistic and economic empowerment, this\nwork explores the feasibility of Neural Machine Translation (NMT) for the Edoid\nlanguage family of Southern Nigeria. Using the new JW300 public dataset, we\ntrained and evaluated baseline translation models for four widely spoken\nlanguages in this group: \\`Ed\\'o, \\'Es\\'an, Urhobo and Isoko. Trained models,\ncode and datasets have been open-sourced to advance future research efforts on\nEdoid language technology.", "published": "2020-03-24 07:53:41", "link": "http://arxiv.org/abs/2003.10704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Adaptation Using Universal Dependencies", "abstract": "We describe a cross-lingual adaptation method based on syntactic parse trees\nobtained from the Universal Dependencies (UD), which are consistent across\nlanguages, to develop classifiers in low-resource languages. The idea of UD\nparsing is to capture similarities as well as idiosyncrasies among\ntypologically different languages. In this paper, we show that models trained\nusing UD parse trees for complex NLP tasks can characterize very different\nlanguages. We study two tasks of paraphrase identification and semantic\nrelation extraction as case studies. Based on UD parse trees, we develop\nseveral models using tree kernels and show that these models trained on the\nEnglish dataset can correctly classify data of other languages e.g. French,\nFarsi, and Arabic. The proposed approach opens up avenues for exploiting UD\nparsing in solving similar cross-lingual tasks, which is very useful for\nlanguages that no labeled data is available for them.", "published": "2020-03-24 13:04:06", "link": "http://arxiv.org/abs/2003.10816v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forensic Authorship Analysis of Microblogging Texts Using N-Grams and\n  Stylometric Features", "abstract": "In recent years, messages and text posted on the Internet are used in\ncriminal investigations. Unfortunately, the authorship of many of them remains\nunknown. In some channels, the problem of establishing authorship may be even\nharder, since the length of digital texts is limited to a certain number of\ncharacters. In this work, we aim at identifying authors of tweet messages,\nwhich are limited to 280 characters. We evaluate popular features employed\ntraditionally in authorship attribution which capture properties of the writing\nstyle at different levels. We use for our experiments a self-captured database\nof 40 users, with 120 to 200 tweets per user. Results using this small set are\npromising, with the different features providing a classification accuracy\nbetween 92% and 98.5%. These results are competitive in comparison to existing\nstudies which employ short texts such as tweets or SMS.", "published": "2020-03-24 19:32:11", "link": "http://arxiv.org/abs/2003.11545v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Video Object Grounding using Semantic Roles in Language Description", "abstract": "We explore the task of Video Object Grounding (VOG), which grounds objects in\nvideos referred to in natural language descriptions. Previous methods apply\nimage grounding based algorithms to address VOG, fail to explore the object\nrelation information and suffer from limited generalization. Here, we\ninvestigate the role of object relations in VOG and propose a novel framework\nVOGNet to encode multi-modal object relations via self-attention with relative\nposition encoding. To evaluate VOGNet, we propose novel contrasting sampling\nmethods to generate more challenging grounding input samples, and construct a\nnew dataset called ActivityNet-SRL (ASRL) based on existing caption and\ngrounding datasets. Experiments on ASRL validate the need of encoding object\nrelations in VOG, and our VOGNet outperforms competitive baselines by a\nsignificant margin.", "published": "2020-03-24 01:31:14", "link": "http://arxiv.org/abs/2003.10606v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Investigating Software Usage in the Social Sciences: A Knowledge Graph\n  Approach", "abstract": "Knowledge about the software used in scientific investigations is necessary\nfor different reasons, including provenance of the results, measuring software\nimpact to attribute developers, and bibliometric software citation analysis in\ngeneral. Additionally, providing information about whether and how the software\nand the source code are available allows an assessment about the state and role\nof open source software in science in general. While such analyses can be done\nmanually, large scale analyses require the application of automated methods of\ninformation extraction and linking. In this paper, we present SoftwareKG - a\nknowledge graph that contains information about software mentions from more\nthan 51,000 scientific articles from the social sciences. A silver standard\ncorpus, created by a distant and weak supervision approach, and a gold standard\ncorpus, created by manual annotation, were used to train an LSTM based neural\nnetwork to identify software mentions in scientific articles. The model\nachieves a recognition rate of .82 F-score in exact matches. As a result, we\nidentified more than 133,000 software mentions. For entity disambiguation, we\nused the public domain knowledge base DBpedia. Furthermore, we linked the\nentities of the knowledge graph to other knowledge bases such as the Microsoft\nAcademic Knowledge Graph, the Software Ontology, and Wikidata. Finally, we\nillustrate, how SoftwareKG can be used to assess the role of software in the\nsocial sciences.", "published": "2020-03-24 08:38:36", "link": "http://arxiv.org/abs/2003.10715v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Generating Chinese Poetry from Images via Concrete and Abstract\n  Information", "abstract": "In recent years, the automatic generation of classical Chinese poetry has\nmade great progress. Besides focusing on improving the quality of the generated\npoetry, there is a new topic about generating poetry from an image. However,\nthe existing methods for this topic still have the problem of topic drift and\nsemantic inconsistency, and the image-poem pairs dataset is hard to be built\nwhen training these models. In this paper, we extract and integrate the\nConcrete and Abstract information from images to address those issues. We\nproposed an infilling-based Chinese poetry generation model which can infill\nthe Concrete keywords into each line of poems in an explicit way, and an\nabstract information embedding to integrate the Abstract information into\ngenerated poems. In addition, we use non-parallel data during training and\nconstruct separate image datasets and poem datasets to train the different\ncomponents in our framework. Both automatic and human evaluation results show\nthat our approach can generate poems which have better consistency with images\nwithout losing the quality.", "published": "2020-03-24 11:17:20", "link": "http://arxiv.org/abs/2003.10773v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning Compact Reward for Image Captioning", "abstract": "Adversarial learning has shown its advances in generating natural and diverse\ndescriptions in image captioning. However, the learned reward of existing\nadversarial methods is vague and ill-defined due to the reward ambiguity\nproblem. In this paper, we propose a refined Adversarial Inverse Reinforcement\nLearning (rAIRL) method to handle the reward ambiguity problem by disentangling\nreward for each word in a sentence, as well as achieve stable adversarial\ntraining by refining the loss function to shift the generator towards Nash\nequilibrium. In addition, we introduce a conditional term in the loss function\nto mitigate mode collapse and to increase the diversity of the generated\ndescriptions. Our experiments on MS COCO and Flickr30K show that our method can\nlearn compact reward for image captioning.", "published": "2020-03-24 15:31:05", "link": "http://arxiv.org/abs/2003.10925v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating\n  Cross-lingual Generalization", "abstract": "Much recent progress in applications of machine learning models to NLP has\nbeen driven by benchmarks that evaluate models across a wide variety of tasks.\nHowever, these broad-coverage benchmarks have been mostly limited to English,\nand despite an increasing interest in multilingual models, a benchmark that\nenables the comprehensive evaluation of such methods on a diverse range of\nlanguages and tasks is still missing. To this end, we introduce the\nCross-lingual TRansfer Evaluation of Multilingual Encoders XTREME benchmark, a\nmulti-task benchmark for evaluating the cross-lingual generalization\ncapabilities of multilingual representations across 40 languages and 9 tasks.\nWe demonstrate that while models tested on English reach human performance on\nmany tasks, there is still a sizable gap in the performance of cross-lingually\ntransferred models, particularly on syntactic and sentence retrieval tasks.\nThere is also a wide spread of results across languages. We release the\nbenchmark to encourage research on cross-lingual learning methods that transfer\nlinguistic knowledge across a diverse and representative set of languages and\ntasks.", "published": "2020-03-24 19:09:37", "link": "http://arxiv.org/abs/2003.11080v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension", "abstract": "Image descriptions can help visually impaired people to quickly understand\nthe image content. While we made significant progress in automatically\ndescribing images and optical character recognition, current approaches are\nunable to include written text in their descriptions, although text is\nomnipresent in human environments and frequently critical to understand our\nsurroundings. To study how to comprehend text in the context of an image we\ncollect a novel dataset, TextCaps, with 145k captions for 28k images. Our\ndataset challenges a model to recognize text, relate it to its visual context,\nand decide what part of the text to copy or paraphrase, requiring spatial,\nsemantic, and visual reasoning between multiple text tokens and visual\nentities, such as objects. We study baselines and adapt existing approaches to\nthis new task, which we refer to as image captioning with reading\ncomprehension. Our analysis with automatic and human studies shows that our new\nTextCaps dataset provides many new technical challenges over previous datasets.", "published": "2020-03-24 02:38:35", "link": "http://arxiv.org/abs/2003.12462v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Can Embeddings Adequately Represent Medical Terminology? New Large-Scale\n  Medical Term Similarity Datasets Have the Answer!", "abstract": "A large number of embeddings trained on medical data have emerged, but it\nremains unclear how well they represent medical terminology, in particular\nwhether the close relationship of semantically similar medical terms is encoded\nin these embeddings. To date, only small datasets for testing medical term\nsimilarity are available, not allowing to draw conclusions about the\ngeneralisability of embeddings to the enormous amount of medical terms used by\ndoctors. We present multiple automatically created large-scale medical term\nsimilarity datasets and confirm their high quality in an annotation study with\ndoctors. We evaluate state-of-the-art word and contextual embeddings on our new\ndatasets, comparing multiple vector similarity metrics and word vector\naggregation techniques. Our results show that current embeddings are limited in\ntheir ability to adequately encode medical terms. The novel datasets thus form\na challenging new benchmark for the development of medical embeddings able to\naccurately represent the whole medical terminology.", "published": "2020-03-24 19:18:34", "link": "http://arxiv.org/abs/2003.11082v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COVID-19 and Computer Audition: An Overview on What Speech & Sound\n  Analysis Could Contribute in the SARS-CoV-2 Corona Crisis", "abstract": "At the time of writing, the world population is suffering from more than\n10,000 registered COVID-19 disease epidemic induced deaths since the outbreak\nof the Corona virus more than three months ago now officially known as\nSARS-CoV-2. Since, tremendous efforts have been made worldwide to counter-steer\nand control the epidemic by now labelled as pandemic. In this contribution, we\nprovide an overview on the potential for computer audition (CA), i.e., the\nusage of speech and sound analysis by artificial intelligence to help in this\nscenario. We first survey which types of related or contextually significant\nphenomena can be automatically assessed from speech or sound. These include the\nautomatic recognition and monitoring of breathing, dry and wet coughing or\nsneezing sounds, speech under cold, eating behaviour, sleepiness, or pain to\nname but a few. Then, we consider potential use-cases for exploitation. These\ninclude risk assessment and diagnosis based on symptom histograms and their\ndevelopment over time, as well as monitoring of spread, social distancing and\nits effects, treatment and recovery, and patient wellbeing. We quickly guide\nfurther through challenges that need to be faced for real-life usage. We come\nto the conclusion that CA appears ready for implementation of (pre-)diagnosis\nand monitoring tools, and more generally provides rich and significant, yet so\nfar untapped potential in the fight against COVID-19 spread.", "published": "2020-03-24 21:17:44", "link": "http://arxiv.org/abs/2003.11117v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS", "A.1"], "primary_category": "cs.SD"}
{"title": "Machine learning as a model for cultural learning: Teaching an algorithm\n  what it means to be fat", "abstract": "As we navigate our cultural environment, we learn cultural biases, like those\naround gender, social class, health, and body weight. It is unclear, however,\nexactly how public culture becomes private culture. In this paper, we provide a\ntheoretical account of such cultural learning. We propose that neural word\nembeddings provide a parsimonious and cognitively plausible model of the\nrepresentations learned from natural language. Using neural word embeddings, we\nextract cultural schemata about body weight from New York Times articles. We\nidentify several cultural schemata that link obesity to gender, immorality,\npoor health, and low socioeconomic class. Such schemata may be subtly but\npervasively activated in public culture; thus, language can chronically\nreproduce biases. Our findings reinforce ongoing concerns that machine learning\ncan also encode, and reproduce, harmful human biases.", "published": "2020-03-24 00:47:51", "link": "http://arxiv.org/abs/2003.12133v2", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Evaluation of Error and Correlation-Based Loss Functions For Multitask\n  Learning Dimensional Speech Emotion Recognition", "abstract": "The choice of a loss function is a critical part of machine learning. This\npaper evaluated two different loss functions commonly used in regression-task\ndimensional speech emotion recognition, an error-based and a correlation-based\nloss functions. We found that using a correlation-based loss function with a\nconcordance correlation coefficient (CCC) loss resulted in better performance\nthan an error-based loss function with mean squared error (MSE) loss and mean\nabsolute error (MAE), in terms of the averaged CCC score. The results are\nconsistent with two input feature sets and two datasets. The scatter plots of\ntest prediction by those two loss functions also confirmed the results measured\nby CCC scores.", "published": "2020-03-24 09:09:49", "link": "http://arxiv.org/abs/2003.10724v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Bulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato", "abstract": "On average the lack of biological markers causes a one year diagnostic delay\nto detect amyotrophic lateral sclerosis (ALS). To improve the diagnostic\nprocess an automatic voice assessment based on acoustic analysis can be used.\nThe purpose of this work was to verify the sutability of the sustain vowel\nphonation test for automatic detection of patients with ALS. We proposed\nenhanced procedure for separation of voice signal into fundamental periods that\nrequires for calculation of perturbation measurements (such as jitter and\nshimmer). Also we proposed method for quantitative assessment of pathological\nvibrato manifestations in sustain vowel phonation. The study's experiments show\nthat using the proposed acoustic analysis methods, the classifier based on\nlinear discriminant analysis attains 90.7\\% accuracy with 86.7\\% sensitivity\nand 92.2\\% specificity.", "published": "2020-03-24 12:49:25", "link": "http://arxiv.org/abs/2003.10806v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
