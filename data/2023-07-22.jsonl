{"title": "Explainable Topic-Enhanced Argument Mining from Heterogeneous Sources", "abstract": "Given a controversial target such as ``nuclear energy'', argument mining aims\nto identify the argumentative text from heterogeneous sources. Current\napproaches focus on exploring better ways of integrating the target-associated\nsemantic information with the argumentative text. Despite their empirical\nsuccesses, two issues remain unsolved: (i) a target is represented by a word or\na phrase, which is insufficient to cover a diverse set of target-related\nsubtopics; (ii) the sentence-level topic information within an argument, which\nwe believe is crucial for argument mining, is ignored. To tackle the above\nissues, we propose a novel explainable topic-enhanced argument mining approach.\nSpecifically, with the use of the neural topic model and the language model,\nthe target information is augmented by explainable topic representations.\nMoreover, the sentence-level topic information within the argument is captured\nby minimizing the distance between its latent topic distribution and its\nsemantic representation through mutual learning. Experiments have been\nconducted on the benchmark dataset in both the in-target setting and the\ncross-target setting. Results demonstrate the superiority of the proposed model\nagainst the state-of-the-art baselines.", "published": "2023-07-22 17:26:55", "link": "http://arxiv.org/abs/2307.12131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Misinformation on YouTube through Transcript Contextual\n  Analysis with Transformer Models", "abstract": "Misinformation on YouTube is a significant concern, necessitating robust\ndetection strategies. In this paper, we introduce a novel methodology for video\nclassification, focusing on the veracity of the content. We convert the\nconventional video classification task into a text classification task by\nleveraging the textual content derived from the video transcripts. We employ\nadvanced machine learning techniques like transfer learning to solve the\nclassification challenge. Our approach incorporates two forms of transfer\nlearning: (a) fine-tuning base transformer models such as BERT, RoBERTa, and\nELECTRA, and (b) few-shot learning using sentence-transformers MPNet and\nRoBERTa-large. We apply the trained models to three datasets: (a) YouTube\nVaccine-misinformation related videos, (b) YouTube Pseudoscience videos, and\n(c) Fake-News dataset (a collection of articles). Including the Fake-News\ndataset extended the evaluation of our approach beyond YouTube videos. Using\nthese datasets, we evaluated the models distinguishing valid information from\nmisinformation. The fine-tuned models yielded Matthews Correlation\nCoefficient>0.81, accuracy>0.90, and F1 score>0.90 in two of three datasets.\nInterestingly, the few-shot models outperformed the fine-tuned ones by 20% in\nboth Accuracy and F1 score for the YouTube Pseudoscience dataset, highlighting\nthe potential utility of this approach -- especially in the context of limited\ntraining data.", "published": "2023-07-22 19:59:16", "link": "http://arxiv.org/abs/2307.12155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Vision-and-Language Navigation from YouTube Videos", "abstract": "Vision-and-language navigation (VLN) requires an embodied agent to navigate\nin realistic 3D environments using natural language instructions. Existing VLN\nmethods suffer from training on small-scale environments or unreasonable\npath-instruction datasets, limiting the generalization to unseen environments.\nThere are massive house tour videos on YouTube, providing abundant real\nnavigation experiences and layout information. However, these videos have not\nbeen explored for VLN before. In this paper, we propose to learn an agent from\nthese videos by creating a large-scale dataset which comprises reasonable\npath-instruction pairs from house tour videos and pre-training the agent on it.\nTo achieve this, we have to tackle the challenges of automatically constructing\npath-instruction pairs and exploiting real layout knowledge from raw and\nunlabeled videos. To address these, we first leverage an entropy-based method\nto construct the nodes of a path trajectory. Then, we propose an action-aware\ngenerator for generating instructions from unlabeled trajectories. Last, we\ndevise a trajectory judgment pretext task to encourage the agent to mine the\nlayout knowledge. Experimental results show that our method achieves\nstate-of-the-art performance on two popular benchmarks (R2R and REVERIE). Code\nis available at https://github.com/JeremyLinky/YouTube-VLN", "published": "2023-07-22 05:26:50", "link": "http://arxiv.org/abs/2307.11984v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Psy-LLM: Scaling up Global Mental Health Psychological Services with\n  AI-based Large Language Models", "abstract": "The demand for psychological counselling has grown significantly in recent\nyears, particularly with the global outbreak of COVID-19, which has heightened\nthe need for timely and professional mental health support. Online\npsychological counselling has emerged as the predominant mode of providing\nservices in response to this demand. In this study, we propose the Psy-LLM\nframework, an AI-based assistive tool leveraging Large Language Models (LLMs)\nfor question-answering in psychological consultation settings to ease the\ndemand for mental health professions. Our framework combines pre-trained LLMs\nwith real-world professional Q\\&A from psychologists and extensively crawled\npsychological articles. The Psy-LLM framework serves as a front-end tool for\nhealthcare professionals, allowing them to provide immediate responses and\nmindfulness activities to alleviate patient stress. Additionally, it functions\nas a screening tool to identify urgent cases requiring further assistance. We\nevaluated the framework using intrinsic metrics, such as perplexity, and\nextrinsic evaluation metrics, with human participant assessments of response\nhelpfulness, fluency, relevance, and logic. The results demonstrate the\neffectiveness of the Psy-LLM framework in generating coherent and relevant\nanswers to psychological questions. This article discusses the potential and\nlimitations of using large language models to enhance mental health support\nthrough AI technologies.", "published": "2023-07-22 06:21:41", "link": "http://arxiv.org/abs/2307.11991v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Imitation Game: Detecting Human and AI-Generated Texts in the Era of\n  ChatGPT and BARD", "abstract": "The potential of artificial intelligence (AI)-based large language models\n(LLMs) holds considerable promise in revolutionizing education, research, and\npractice. However, distinguishing between human-written and AI-generated text\nhas become a significant task. This paper presents a comparative study,\nintroducing a novel dataset of human-written and LLM-generated texts in\ndifferent genres: essays, stories, poetry, and Python code. We employ several\nmachine learning models to classify the texts. Results demonstrate the efficacy\nof these models in discerning between human and AI-generated text, despite the\ndataset's limited sample size. However, the task becomes more challenging when\nclassifying GPT-generated text, particularly in story writing. The results\nindicate that the models exhibit superior performance in binary classification\ntasks, such as distinguishing human-generated text from a specific LLM,\ncompared to the more complex multiclass tasks that involve discerning among\nhuman-generated and multiple LLMs. Our findings provide insightful implications\nfor AI text detection while our dataset paves the way for future research in\nthis evolving area.", "published": "2023-07-22 21:00:14", "link": "http://arxiv.org/abs/2307.12166v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting Distillation for Continual Learning on Visual Question\n  Localized-Answering in Robotic Surgery", "abstract": "The visual-question localized-answering (VQLA) system can serve as a\nknowledgeable assistant in surgical education. Except for providing text-based\nanswers, the VQLA system can highlight the interested region for better\nsurgical scene understanding. However, deep neural networks (DNNs) suffer from\ncatastrophic forgetting when learning new knowledge. Specifically, when DNNs\nlearn on incremental classes or tasks, their performance on old tasks drops\ndramatically. Furthermore, due to medical data privacy and licensing issues, it\nis often difficult to access old data when updating continual learning (CL)\nmodels. Therefore, we develop a non-exemplar continual surgical VQLA framework,\nto explore and balance the rigidity-plasticity trade-off of DNNs in a\nsequential learning paradigm. We revisit the distillation loss in CL tasks, and\npropose rigidity-plasticity-aware distillation (RP-Dist) and self-calibrated\nheterogeneous distillation (SH-Dist) to preserve the old knowledge. The weight\naligning (WA) technique is also integrated to adjust the weight bias between\nold and new tasks. We further establish a CL framework on three public surgical\ndatasets in the context of surgical settings that consist of overlapping\nclasses between old and new surgical VQLA tasks. With extensive experiments, we\ndemonstrate that our proposed method excellently reconciles learning and\nforgetting on the continual surgical VQLA over conventional CL methods. Our\ncode is publicly accessible.", "published": "2023-07-22 10:35:25", "link": "http://arxiv.org/abs/2307.12045v1", "categories": ["cs.CV", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language\n  Models Applied to Clinical and Biomedical Tasks", "abstract": "We evaluate four state-of-the-art instruction-tuned large language models\n(LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13\nreal-world clinical and biomedical natural language processing (NLP) tasks in\nEnglish, such as named-entity recognition (NER), question-answering (QA),\nrelation extraction (RE), etc. Our overall results demonstrate that the\nevaluated LLMs begin to approach performance of state-of-the-art models in\nzero- and few-shot scenarios for most tasks, and particularly well for the QA\ntask, even though they have never seen examples from these tasks before.\nHowever, we observed that the classification and RE tasks perform below what\ncan be achieved with a specifically trained model for the medical field, such\nas PubMedBERT. Finally, we noted that no LLM outperforms all the others on all\nthe studied tasks, with some models being better suited for certain tasks than\nothers.", "published": "2023-07-22 15:58:17", "link": "http://arxiv.org/abs/2307.12114v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modality Confidence Aware Training for Robust End-to-End Spoken Language\n  Understanding", "abstract": "End-to-end (E2E) spoken language understanding (SLU) systems that generate a\nsemantic parse from speech have become more promising recently. This approach\nuses a single model that utilizes audio and text representations from\npre-trained speech recognition models (ASR), and outperforms traditional\npipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems\nstill show weakness when text representation quality is low due to ASR\ntranscription errors. To overcome this issue, we propose a novel E2E SLU system\nthat enhances robustness to ASR errors by fusing audio and text representations\nbased on the estimated modality confidence of ASR hypotheses. We introduce two\nnovel techniques: 1) an effective method to encode the quality of ASR\nhypotheses and 2) an effective approach to integrate them into E2E SLU models.\nWe show accuracy improvements on STOP dataset and share the analysis to\ndemonstrate the effectiveness of our approach.", "published": "2023-07-22 17:47:31", "link": "http://arxiv.org/abs/2307.12134v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Extracting Molecular Properties from Natural Language with Multimodal\n  Contrastive Learning", "abstract": "Deep learning in computational biochemistry has traditionally focused on\nmolecular graphs neural representations; however, recent advances in language\nmodels highlight how much scientific knowledge is encoded in text. To bridge\nthese two modalities, we investigate how molecular property information can be\ntransferred from natural language to graph representations. We study property\nprediction performance gains after using contrastive learning to align neural\ngraph representations with representations of textual descriptions of their\ncharacteristics. We implement neural relevance scoring strategies to improve\ntext retrieval, introduce a novel chemically-valid molecular graph augmentation\nstrategy inspired by organic reactions, and demonstrate improved performance on\ndownstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC\ngain versus models pre-trained on the graph modality alone, and a +1.54% gain\ncompared to recently proposed molecular graph/text contrastively trained MoMu\nmodel (Su et al. 2022).", "published": "2023-07-22 10:32:58", "link": "http://arxiv.org/abs/2307.12996v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "FinPT: Financial Risk Prediction with Profile Tuning on Pretrained\n  Foundation Models", "abstract": "Financial risk prediction plays a crucial role in the financial sector.\nMachine learning methods have been widely applied for automatically detecting\npotential risks and thus saving the cost of labor. However, the development in\nthis field is lagging behind in recent years by the following two facts: 1) the\nalgorithms used are somewhat outdated, especially in the context of the fast\nadvance of generative AI and large language models (LLMs); 2) the lack of a\nunified and open-sourced financial benchmark has impeded the related research\nfor years. To tackle these issues, we propose FinPT and FinBench: the former is\na novel approach for financial risk prediction that conduct Profile Tuning on\nlarge pretrained foundation models, and the latter is a set of high-quality\ndatasets on financial risks such as default, fraud, and churn. In FinPT, we\nfill the financial tabular data into the pre-defined instruction template,\nobtain natural-language customer profiles by prompting LLMs, and fine-tune\nlarge foundation models with the profile text to make predictions. We\ndemonstrate the effectiveness of the proposed FinPT by experimenting with a\nrange of representative strong baselines on FinBench. The analytical studies\nfurther deepen the understanding of LLMs for financial risk prediction.", "published": "2023-07-22 09:27:05", "link": "http://arxiv.org/abs/2308.00065v1", "categories": ["q-fin.RM", "cs.CE", "cs.CL", "cs.LG", "q-fin.ST"], "primary_category": "q-fin.RM"}
{"title": "Estimating speaker direction on a humanoid robot with binaural acoustic\n  signals", "abstract": "To achieve human-like behaviour during speech interactions, it is necessary\nfor a humanoid robot to estimate the location of a human talker. Here, we\npresent a method to optimize the parameters used for the direction of arrival\n(DOA) estimation, while also considering real-time applications for human-robot\ninteraction scenarios. This method is applied to binaural sound source\nlocalization framework on a humanoid robotic head. Real data is collected and\nannotated for this work. Optimizations are performed via a brute force method\nand a Bayesian model based method, results are validated and discussed, and\neffects on latency for real-time use are also explored.", "published": "2023-07-22 17:11:46", "link": "http://arxiv.org/abs/2307.12129v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
