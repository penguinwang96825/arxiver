{"title": "Coloring of the dth power of the face-centered cubic grid", "abstract": "The face-centered cubic grid is a three dimensional 12-regular infinite grid. This graph represents an optimal way to pack spheres in the three-dimensional space. In this grid, the vertices represent the spheres and the edges represent the contact between spheres. We give lower and upper bounds on the chromatic number of the d th power of the face-centered cubic grid. In particular, in the case d = 2 we prove that the chromatic number of this grid is 13. We also determine sharper bounds for d = 3 and for subgraphs of of the face-centered cubic grid.", "published": "2018-06-21 09:37:20", "link": "http://arxiv.org/abs/1806.08136v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "How Many Random Seeds? Statistical Power Analysis in Deep Reinforcement Learning Experiments", "abstract": "Consistently checking the statistical significance of experimental results is one of the mandatory methodological steps to address the so-called \"reproducibility crisis\" in deep reinforcement learning. In this tutorial paper, we explain how the number of random seeds relates to the probabilities of statistical errors. For both the t-test and the bootstrap confidence interval test, we recall theoretical guidelines to determine the number of random seeds one should use to provide a statistically significant comparison of the performance of two algorithms. Finally, we discuss the influence of deviations from the assumptions usually made by statistical tests. We show that they can lead to inaccurate evaluations of statistical errors and provide guidelines to counter these negative effects. We make our code available to perform the tests.", "published": "2018-06-21 15:39:19", "link": "http://arxiv.org/abs/1806.08295v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Interpretable Discovery in Large Image Data Sets", "abstract": "Automated detection of new, interesting, unusual, or anomalous images within large data sets has great value for applications from surveillance (e.g., airport security) to science (observations that don't fit a given theory can lead to new discoveries). Many image data analysis systems are turning to convolutional neural networks (CNNs) to represent image content due to their success in achieving high classification accuracy rates. However, CNN representations are notoriously difficult for humans to interpret. We describe a new strategy that combines novelty detection with CNN image features to achieve rapid discovery with interpretable explanations of novel image content. We applied this technique to familiar images from ImageNet as well as to a scientific image collection from planetary science.", "published": "2018-06-21 17:30:26", "link": "http://arxiv.org/abs/1806.08340v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
