{"title": "SusGen-GPT: A Data-Centric LLM for Financial NLP and Sustainability Report Generation", "abstract": "The rapid growth of the financial sector and the rising focus on\nEnvironmental, Social, and Governance (ESG) considerations highlight the need\nfor advanced NLP tools. However, open-source LLMs proficient in both finance\nand ESG domains remain scarce. To address this gap, we introduce SusGen-30K, a\ncategory-balanced dataset comprising seven financial NLP tasks and ESG report\ngeneration, and propose TCFD-Bench, a benchmark for evaluating sustainability\nreport generation. Leveraging this dataset, we developed SusGen-GPT, a suite of\nmodels achieving state-of-the-art performance across six adapted and two\noff-the-shelf tasks, trailing GPT-4 by only 2% despite using 7-8B parameters\ncompared to GPT-4's 1,700B. Based on this, we propose the SusGen system,\nintegrated with Retrieval-Augmented Generation (RAG), to assist in\nsustainability report generation. This work demonstrates the efficiency of our\napproach, advancing research in finance and ESG.", "published": "2024-12-14 17:30:33", "link": "http://arxiv.org/abs/2412.10906v1", "categories": ["cs.CL", "cs.CE", "cs.LG", "q-fin.CP"], "primary_category": "cs.CL"}
{"title": "FinGPT: Enhancing Sentiment-Based Stock Movement Prediction with Dissemination-Aware and Context-Enriched LLMs", "abstract": "Financial sentiment analysis is crucial for understanding the influence of\nnews on stock prices. Recently, large language models (LLMs) have been widely\nadopted for this purpose due to their advanced text analysis capabilities.\nHowever, these models often only consider the news content itself, ignoring its\ndissemination, which hampers accurate prediction of short-term stock movements.\nAdditionally, current methods often lack sufficient contextual data and\nexplicit instructions in their prompts, limiting LLMs' ability to interpret\nnews. In this paper, we propose a data-driven approach that enhances\nLLM-powered sentiment-based stock movement predictions by incorporating news\ndissemination breadth, contextual data, and explicit instructions. We cluster\nrecent company-related news to assess its reach and influence, enriching\nprompts with more specific data and precise instructions. This data is used to\nconstruct an instruction tuning dataset to fine-tune an LLM for predicting\nshort-term stock price movements. Our experimental results show that our\napproach improves prediction accuracy by 8\\% compared to existing methods.", "published": "2024-12-14 13:04:42", "link": "http://arxiv.org/abs/2412.10823v1", "categories": ["cs.CL", "cs.LG", "q-fin.CP", "q-fin.TR"], "primary_category": "cs.CL"}
{"title": "Continuous-time optimal investment with portfolio constraints: a reinforcement learning approach", "abstract": "In a reinforcement learning (RL) framework, we study the exploratory version\nof the continuous time expected utility (EU) maximization problem with a\nportfolio constraint that includes widely-used financial regulations such as\nshort-selling constraints and borrowing prohibition. The optimal feedback\npolicy of the exploratory unconstrained classical EU problem is shown to be\nGaussian. In the case where the portfolio weight is constrained to a given\ninterval, the corresponding constrained optimal exploratory policy follows a\ntruncated Gaussian distribution. We verify that the closed form optimal\nsolution obtained for logarithmic utility and quadratic utility for both\nunconstrained and constrained situations converge to the non-exploratory\nexpected utility counterpart when the exploration weight goes to zero. Finally,\nwe establish a policy improvement theorem and devise an implementable\nreinforcement learning algorithm by casting the optimal problem in a martingale\nframework. Our numerical examples show that exploration leads to an optimal\nwealth process that is more dispersedly distributed with heavier tail compared\nto that of the case without exploration. This effect becomes less significant\nas the exploration parameter is smaller. Moreover, the numerical implementation\nalso confirms the intuitive understanding that a broader domain of investment\nopportunities necessitates a higher exploration cost. Notably, when subjected\nto both short-selling and money borrowing constraints, the exploration cost\nbecomes negligible compared to the unconstrained case.", "published": "2024-12-14 05:35:44", "link": "http://arxiv.org/abs/2412.10692v1", "categories": ["q-fin.MF", "34D20, 60H10, 92D25, 93D05, 93D20"], "primary_category": "q-fin.MF"}
{"title": "Classification of Financial Data Using Quantum Support Vector Machine", "abstract": "Quantum Support Vector Machine is a kernel-based approach to classification\nproblems. We study the applicability of quantum kernels to financial data,\nspecifically our self-curated Dhaka Stock Exchange (DSEx) Broad Index dataset.\nTo the best of our knowledge, this is the very first systematic research work\non this dataset on the application of quantum kernel. We report empirical\nquantum advantage in our work, using several quantum kernels and proposing the\nbest one for this dataset while verifying the Phase Space Terrain Ruggedness\nIndex metric. We estimate the resources needed to carry out these\ninvestigations on a larger scale for future practitioners.", "published": "2024-12-14 15:17:11", "link": "http://arxiv.org/abs/2412.10860v1", "categories": ["quant-ph", "cs.LG", "q-fin.ST"], "primary_category": "quant-ph"}
{"title": "Stochastic Gradient Descent in the Optimal Control of Execution Costs", "abstract": "Bertsimas and Lo's seminal work laid the groundwork for addressing the\nimplementation shortfall dilemma in institutional investing, emphasizing the\nsignificance of market microstructure and price dynamics in minimizing\nexecution costs. However, the ability to derive a theoretical Optimum market\norder policy is an unrealistic assumption for many investors. This study aims\nto bridge this gap by proposing an approach that leverages stochastic gradient\ndescent (SGD) to derive alternative solutions for optimizing execution cost\npolicies in dynamic markets where explicit mathematical solutions may not yet\nexist. The proposed methodology assumes the existence of a mathematically\nderived optimal solution that is a function of the underlying market dynamics.\nBy iteratively refining strategies using SGD, economists can adapt their\napproaches over time based on evolving execution strategies. While these\nSGD-based solutions may not achieve optimality, they offer valuable insights\ninto optimizing policies under complex market frameworks. These results serve\nas a bridge for economists and mathematicians, facilitating the study of the\nOptimum policy volatile markets while offering SGD driven implementable\npolicies that closely approximate optimal outcomes within shorter time frames.", "published": "2024-12-14 19:54:59", "link": "http://arxiv.org/abs/2412.12199v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Auto-Regressive Control of Execution Costs", "abstract": "Bertsimas and Lo's seminal work established a foundational framework for\naddressing the implementation shortfall dilemma faced by large institutional\ninvestors. Their models emphasized the critical role of accurate knowledge of\nmarket microstructure and price/information dynamics in optimizing trades to\nminimize execution costs. However, this paper recognizes that perfect initial\nknowledge may not be a realistic assumption for new investors entering the\nmarket. Therefore, this study aims to bridge this gap by proposing an approach\nthat iteratively derives OLS estimates of the market parameters from period to\nperiod. This methodology enables uninformed investors to engage in the market\ndynamically, adjusting their strategies over time based on evolving estimates,\nthus offering a practical solution for navigating the complexities of execution\ncost optimization without perfect initial knowledge.", "published": "2024-12-14 19:52:58", "link": "http://arxiv.org/abs/2412.10947v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Inference Scaling for Bridging Retrieval and Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) has emerged as a popular approach to\nsteering the output of a large language model (LLM) by incorporating retrieved\ncontexts as inputs. However, existing work observed the generator bias, such\nthat improving the retrieval results may negatively affect the outcome. In this\nwork, we show such bias can be mitigated, from inference scaling, aggregating\ninference calls from the permuted order of retrieved contexts. The proposed\nMixture-of-Intervention (MOI) explicitly models the debiased utility of each\npassage with multiple forward passes to construct a new ranking. We also show\nthat MOI can leverage the retriever's prior knowledge to reduce the\ncomputational cost by minimizing the number of permutations considered and\nlowering the cost per LLM call. We showcase the effectiveness of MOI on diverse\nRAG tasks, improving ROUGE-L on MS MARCO and EM on HotpotQA benchmarks by ~7\npoints.", "published": "2024-12-14 05:06:43", "link": "http://arxiv.org/abs/2412.10684v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal\n  Retrieval-Augmented Generation", "abstract": "Understanding information from a collection of multiple documents,\nparticularly those with visually rich elements, is important for\ndocument-grounded question answering. This paper introduces VisDoMBench, the\nfirst comprehensive benchmark designed to evaluate QA systems in multi-document\nsettings with rich multimodal content, including tables, charts, and\npresentation slides. We propose VisDoMRAG, a novel multimodal Retrieval\nAugmented Generation (RAG) approach that simultaneously utilizes visual and\ntextual RAG, combining robust visual retrieval capabilities with sophisticated\nlinguistic reasoning. VisDoMRAG employs a multi-step reasoning process\nencompassing evidence curation and chain-of-thought reasoning for concurrent\ntextual and visual RAG pipelines. A key novelty of VisDoMRAG is its\nconsistency-constrained modality fusion mechanism, which aligns the reasoning\nprocesses across modalities at inference time to produce a coherent final\nanswer. This leads to enhanced accuracy in scenarios where critical information\nis distributed across modalities and improved answer verifiability through\nimplicit context attribution. Through extensive experiments involving\nopen-source and proprietary large language models, we benchmark\nstate-of-the-art document QA methods on VisDoMBench. Extensive results show\nthat VisDoMRAG outperforms unimodal and long-context LLM baselines for\nend-to-end multimodal document QA by 12-20%.", "published": "2024-12-14 06:24:55", "link": "http://arxiv.org/abs/2412.10704v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Effective, Efficient and Unsupervised Social Event Detection in\n  the Hyperbolic Space", "abstract": "The vast, complex, and dynamic nature of social message data has posed\nchallenges to social event detection (SED). Despite considerable effort, these\nchallenges persist, often resulting in inadequately expressive message\nrepresentations (ineffective) and prolonged learning durations (inefficient).\nIn response to the challenges, this work introduces an unsupervised framework,\nHyperSED (Hyperbolic SED). Specifically, the proposed framework first models\nsocial messages into semantic-based message anchors, and then leverages the\nstructure of the anchor graph and the expressiveness of the hyperbolic space to\nacquire structure- and geometry-aware anchor representations. Finally, HyperSED\nbuilds the partitioning tree of the anchor message graph by incorporating\ndifferentiable structural information as the reflection of the detected events.\nExtensive experiments on public datasets demonstrate HyperSED's competitive\nperformance, along with a substantial improvement in efficiency compared to the\ncurrent state-of-the-art unsupervised paradigm. Statistically, HyperSED boosts\nincremental SED by an average of 2%, 2%, and 25% in NMI, AMI, and ARI,\nrespectively; enhancing efficiency by up to 37.41 times and at least 12.10\ntimes, illustrating the advancement of the proposed framework. Our code is\npublicly available at https://github.com/XiaoyanWork/HyperSED.", "published": "2024-12-14 06:55:27", "link": "http://arxiv.org/abs/2412.10712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WEPO: Web Element Preference Optimization for LLM-based Web Navigation", "abstract": "The rapid advancement of autonomous web navigation has significantly\nbenefited from grounding pretrained Large Language Models (LLMs) as agents.\nHowever, current research has yet to fully leverage the redundancy of HTML\nelements for contrastive training. This paper introduces a novel approach to\nLLM-based web navigation tasks, called Web Element Preference Optimization\n(WEPO). WEPO utilizes unsupervised preference learning by sampling\ndistance-based non-salient web elements as negative samples, optimizing maximum\nlikelihood objective within Direct Preference Optimization (DPO). We evaluate\nWEPO on the Mind2Web benchmark and empirically demonstrate that WEPO aligns\nuser high-level intent with output actions more effectively. The results show\nthat our method achieved the state-of-the-art, with an improvement of 13.8%\nover WebAgent and 5.3% over the visual language model CogAgent baseline. Our\nfindings underscore the potential of preference optimization to enhance web\nnavigation and other web page based tasks, suggesting a promising direction for\nfuture research.", "published": "2024-12-14 08:25:28", "link": "http://arxiv.org/abs/2412.10742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Language Models Agnostic to Linguistically Grounded Perturbations? A\n  Case Study of Indic Languages", "abstract": "Pre-trained language models (PLMs) are known to be susceptible to\nperturbations to the input text, but existing works do not explicitly focus on\nlinguistically grounded attacks, which are subtle and more prevalent in nature.\nIn this paper, we study whether PLMs are agnostic to linguistically grounded\nattacks or not. To this end, we offer the first study addressing this,\ninvestigating different Indic languages and various downstream tasks. Our\nfindings reveal that although PLMs are susceptible to linguistic perturbations,\nwhen compared to non-linguistic attacks, PLMs exhibit a slightly lower\nsusceptibility to linguistic attacks. This highlights that even constrained\nattacks are effective. Moreover, we investigate the implications of these\noutcomes across a range of languages, encompassing diverse language families\nand different scripts.", "published": "2024-12-14 12:10:38", "link": "http://arxiv.org/abs/2412.10805v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Novel End-To-End Event Geolocation Method Leveraging Hyperbolic Space\n  and Toponym Hierarchies", "abstract": "Timely detection and geolocation of events based on social data can provide\ncritical information for applications such as crisis response and resource\nallocation. However, most existing methods are greatly affected by event\ndetection errors, leading to insufficient geolocation accuracy. To this end,\nthis paper proposes a novel end-to-end event geolocation method (GTOP)\nleveraging Hyperbolic space and toponym hierarchies. Specifically, the proposed\nmethod contains one event detection module and one geolocation module. The\nevent detection module constructs a heterogeneous information networks based on\nsocial data, and then constructs a homogeneous message graph and combines it\nwith the text and time feature of the message to learning initial features of\nnodes. Node features are updated in Hyperbolic space and then fed into a\nclassifier for event detection. To reduce the geolocation error, this paper\nproposes a noise toponym filtering algorithm (HIST) based on the hierarchical\nstructure of toponyms. HIST analyzes the hierarchical structure of toponyms\nmentioned in the event cluster, taking the highly frequent city-level locations\nas the coarse-grained locations for events. By comparing the hierarchical\nstructure of the toponyms within the cluster against those of the\ncoarse-grained locations of events, HIST filters out noisy toponyms. To further\nimprove the geolocation accuracy, we propose a fine-grained pseudo toponyms\ngeneration algorithm (FIT) based on the output of HIST, and combine generated\npseudo toponyms with filtered toponyms to locate events based on the geographic\ncenter points of the combined toponyms. Extensive experiments are conducted on\nthe Chinese dataset constructed in this paper and another public English\ndataset. The experimental results show that the proposed method is superior to\nthe state-of-the-art baselines.", "published": "2024-12-14 15:43:58", "link": "http://arxiv.org/abs/2412.10870v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Discoverability in Enterprise Conversational Systems with\n  Proactive Question Suggestions", "abstract": "Enterprise conversational AI systems are becoming increasingly popular to\nassist users in completing daily tasks such as those in marketing and customer\nmanagement. However, new users often struggle to ask effective questions,\nespecially in emerging systems with unfamiliar or evolving capabilities. This\npaper proposes a framework to enhance question suggestions in conversational\nenterprise AI systems by generating proactive, context-aware questions that try\nto address immediate user needs while improving feature discoverability. Our\napproach combines periodic user intent analysis at the population level with\nchat session-based question generation. We evaluate the framework using\nreal-world data from the AI Assistant for Adobe Experience Platform (AEP),\ndemonstrating the improved usefulness and system discoverability of the AI\nAssistant.", "published": "2024-12-14 19:04:16", "link": "http://arxiv.org/abs/2412.10933v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Help Create Grammar?: Automating Grammar Creation for\n  Endangered Languages with In-Context Learning", "abstract": "Yes! In the present-day documenting and preserving endangered languages, the\napplication of Large Language Models (LLMs) presents a promising approach. This\npaper explores how LLMs, particularly through in-context learning, can assist\nin generating grammatical information for low-resource languages with limited\namount of data. We takes Moklen as a case study to evaluate the efficacy of\nLLMs in producing coherent grammatical rules and lexical entries using only\nbilingual dictionaries and parallel sentences of the unknown language without\nbuilding the model from scratch. Our methodology involves organising the\nexisting linguistic data and prompting to efficiently enable to generate formal\nXLE grammar. Our results demonstrate that LLMs can successfully capture key\ngrammatical structures and lexical information, although challenges such as the\npotential for English grammatical biases remain. This study highlights the\npotential of LLMs to enhance language documentation efforts, providing a\ncost-effective solution for generating linguistic data and contributing to the\npreservation of endangered languages.", "published": "2024-12-14 20:43:12", "link": "http://arxiv.org/abs/2412.10960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through\n  Structured Data", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation. However, they often struggle\nwith complex reasoning tasks and are prone to hallucination. Recent research\nhas shown promising results in leveraging knowledge graphs (KGs) to enhance LLM\nperformance. KGs provide a structured representation of entities and their\nrelationships, offering a rich source of information that can enhance the\nreasoning capabilities of LLMs. For this work, we have developed different\ntechniques that tightly integrate KG structures and semantics into LLM\nrepresentations. Our results show that we are able to significantly improve the\nperformance of LLMs in complex reasoning scenarios, and ground the reasoning\nprocess with KGs. We are the first to represent KGs with programming language\nand fine-tune pretrained LLMs with KGs. This integration facilitates more\naccurate and interpretable reasoning processes, paving the way for more\nadvanced reasoning capabilities of LLMs.", "published": "2024-12-14 02:51:47", "link": "http://arxiv.org/abs/2412.10654v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End\n  LLM Plan Generation", "abstract": "The capability of Large Language Models (LLMs) to plan remains a topic of\ndebate. Some critics argue that strategies to boost LLMs' reasoning skills are\nineffective in planning tasks, while others report strong outcomes merely from\ntraining models on a planning corpus. This study reassesses recent strategies\nby developing an end-to-end LLM planner and employing diverse metrics for a\nthorough evaluation. We find that merely fine-tuning LLMs on a corpus of\nplanning instances does not lead to robust planning skills, as indicated by\npoor performance on out-of-distribution test sets. At the same time, we find\nthat various strategies, including Chain-of-Thought, do enhance the probability\nof a plan being executable. This indicates progress towards better plan\nquality, despite not directly enhancing the final validity rate. Among the\nstrategies we evaluated, reinforcement learning with our novel `Longest\nContiguous Common Subsequence' reward emerged as the most effective,\ncontributing to both plan validity and executability. Overall, our research\naddresses key misconceptions in the LLM-planning literature; we validate\nincremental progress in plan executability, although plan validity remains a\nchallenge. Hence, future strategies should focus on both these aspects, drawing\ninsights from our findings.", "published": "2024-12-14 04:23:14", "link": "http://arxiv.org/abs/2412.10675v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Verify Summary Facts with Fine-Grained LLM Feedback", "abstract": "Training automatic summary fact verifiers often faces the challenge of a lack\nof human-labeled data. In this paper, we explore alternative way of leveraging\nLarge Language Model (LLM) generated feedback to address the inherent\nlimitation of using human-labeled data. We introduce FineSumFact, a large-scale\ndataset containing fine-grained factual feedback on summaries. We employ 10\ndistinct LLMs for diverse summary generation and Llama-3-70B-Instruct for\nfeedback. We utilize this dataset to fine-tune the lightweight open-source\nmodel Llama-3-8B-Instruct, optimizing resource efficiency while maintaining\nhigh performance. Our experimental results reveal that the model trained on\nextensive LLM-generated datasets surpasses that trained on smaller\nhuman-annotated datasets when evaluated using human-generated test sets.\nFine-tuning fact verification models with LLM feedback can be more effective\nand cost-efficient than using human feedback. The dataset is available at\nhttps://github.com/DISL-Lab/FineSumFact.", "published": "2024-12-14 05:28:44", "link": "http://arxiv.org/abs/2412.10689v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HITgram: A Platform for Experimenting with n-gram Language Models", "abstract": "Large language models (LLMs) are powerful but resource intensive, limiting\naccessibility. HITgram addresses this gap by offering a lightweight platform\nfor n-gram model experimentation, ideal for resource-constrained environments.\nIt supports unigrams to 4-grams and incorporates features like context\nsensitive weighting, Laplace smoothing, and dynamic corpus management to\ne-hance prediction accuracy, even for unseen word sequences. Experiments\ndemonstrate HITgram's efficiency, achieving 50,000 tokens/second and generating\n2-grams from a 320MB corpus in 62 seconds. HITgram scales efficiently,\nconstructing 4-grams from a 1GB file in under 298 seconds on an 8 GB RAM\nsystem. Planned enhancements include multilingual support, advanced smoothing,\nparallel processing, and model saving, further broadening its utility.", "published": "2024-12-14 07:20:35", "link": "http://arxiv.org/abs/2412.10717v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking Chain-of-Thought from the Perspective of Self-Training", "abstract": "Chain-of-thought (CoT) reasoning has emerged as an effective approach for\nactivating latent capabilities in LLMs. Interestingly, we observe that both CoT\nreasoning and self-training share the core objective: iteratively leveraging\nmodel-generated information to progressively reduce prediction uncertainty.\nBuilding on this insight, we propose a novel CoT framework to improve reasoning\nperformance. Our framework integrates two key components: (i) a task-specific\nprompt module that optimizes the initial reasoning process, and (ii) an\nadaptive reasoning iteration module that dynamically refines the reasoning\nprocess and addresses the limitations of previous CoT approaches, \\ie\nover-reasoning and high similarity between consecutive reasoning iterations.\nExtensive experiments demonstrate that the proposed method achieves significant\nadvantages in both performance and computational efficiency.", "published": "2024-12-14 13:12:50", "link": "http://arxiv.org/abs/2412.10827v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Superhuman performance of a large language model on the reasoning tasks\n  of a physician", "abstract": "Performance of large language models (LLMs) on medical tasks has\ntraditionally been evaluated using multiple choice question benchmarks.\nHowever, such benchmarks are highly constrained, saturated with repeated\nimpressive performance by LLMs, and have an unclear relationship to performance\nin real clinical scenarios. Clinical reasoning, the process by which physicians\nemploy critical thinking to gather and synthesize clinical data to diagnose and\nmanage medical problems, remains an attractive benchmark for model performance.\nPrior LLMs have shown promise in outperforming clinicians in routine and\ncomplex diagnostic scenarios. We sought to evaluate OpenAI's o1-preview model,\na model developed to increase run-time via chain of thought processes prior to\ngenerating a response. We characterize the performance of o1-preview with five\nexperiments including differential diagnosis generation, display of diagnostic\nreasoning, triage differential diagnosis, probabilistic reasoning, and\nmanagement reasoning, adjudicated by physician experts with validated\npsychometrics. Our primary outcome was comparison of the o1-preview output to\nidentical prior experiments that have historical human controls and benchmarks\nof previous LLMs. Significant improvements were observed with differential\ndiagnosis generation and quality of diagnostic and management reasoning. No\nimprovements were observed with probabilistic reasoning or triage differential\ndiagnosis. This study highlights o1-preview's ability to perform strongly on\ntasks that require complex critical thinking such as diagnosis and management\nwhile its performance on probabilistic reasoning tasks was similar to past\nmodels. New robust benchmarks and scalable evaluation of LLM capabilities\ncompared to human physicians are needed along with trials evaluating AI in real\nclinical settings.", "published": "2024-12-14 14:46:18", "link": "http://arxiv.org/abs/2412.10849v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "CRENER: A Character Relation Enhanced Chinese NER Model", "abstract": "Chinese Named Entity Recognition (NER) is an important task in information\nextraction, which has a significant impact on downstream applications. Due to\nthe lack of natural separators in Chinese, previous NER methods mostly relied\non external dictionaries to enrich the semantic and boundary information of\nChinese words. However, such methods may introduce noise that affects the\naccuracy of named entity recognition. To this end, we propose a character\nrelation enhanced Chinese NER model (CRENER). This model defines four types of\ntags that reflect the relationships between characters, and proposes a\nfine-grained modeling of the relationships between characters based on three\ntypes of relationships: adjacency relations between characters, relations\nbetween characters and tags, and relations between tags, to more accurately\nidentify entity boundaries and improve Chinese NER accuracy. Specifically, we\ntransform the Chinese NER task into a character-character relationship\nclassification task, ensuring the accuracy of entity boundary recognition\nthrough joint modeling of relation tags. To enhance the model's ability to\nunderstand contextual information, WRENER further constructed an adapted\ntransformer encoder that combines unscaled direction-aware and distance-aware\nmasked self-attention mechanisms. Moreover, a relationship representation\nenhancement module was constructed to model predefined relationship tags,\neffectively mining the relationship representations between characters and\ntags. Experiments conducted on four well-known Chinese NER benchmark datasets\nhave shown that the proposed model outperforms state-of-the-art baselines. The\nablation experiment also demonstrated the effectiveness of the proposed model.", "published": "2024-12-14 15:14:39", "link": "http://arxiv.org/abs/2412.10858v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Quantifying Extreme Opinions on Reddit Amidst the 2023\n  Israeli-Palestinian Conflict", "abstract": "This study investigates the dynamics of extreme opinions on social media\nduring the 2023 Israeli-Palestinian conflict, utilising a comprehensive dataset\nof over 450,000 posts from four Reddit subreddits (r/Palestine, r/Judaism,\nr/IsraelPalestine, and r/worldnews). A lexicon-based, unsupervised methodology\nwas developed to measure \"extreme opinions\" by considering factors such as\nanger, polarity, and subjectivity. The analysis identifies significant peaks in\nextremism scores that correspond to pivotal real-life events, such as the IDF's\nbombings of Al Quds Hospital and the Jabalia Refugee Camp, and the end of a\nceasefire following a terrorist attack. Additionally, this study explores the\ndistribution and correlation of these scores across different subreddits and\nover time, providing insights into the propagation of polarised sentiments in\nresponse to conflict events. By examining the quantitative effects of each\nscore on extremism and analysing word cloud similarities through Jaccard\nindices, the research offers a nuanced understanding of the factors driving\nextreme online opinions. This approach underscores the potential of social\nmedia analytics in capturing the complex interplay between real-world events\nand online discourse, while also highlighting the limitations and challenges of\nmeasuring extremism in social media contexts.", "published": "2024-12-14 17:52:28", "link": "http://arxiv.org/abs/2412.10913v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and\n  De-identification of PHI Across Multiple Languages", "abstract": "The rise of chronic diseases and pandemics like COVID-19 has emphasized the\nneed for effective patient data processing while ensuring privacy through\nanonymization and de-identification of protected health information (PHI).\nAnonymized data facilitates research without compromising patient\nconfidentiality. This paper introduces expert small AI models developed using\nthe LLM-in-the-loop methodology to meet the demand for domain-specific\nde-identification NER models. These models overcome the privacy risks\nassociated with large language models (LLMs) used via APIs by eliminating the\nneed to transmit or store sensitive data. More importantly, they consistently\noutperform LLMs in de-identification tasks, offering superior performance and\nreliability. Our de-identification NER models, developed in eight languages\n(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)\nachieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,\n0.978, and 0.953 respectively. These results establish them as the most\naccurate healthcare anonymization solutions, surpassing existing small models\nand even general-purpose LLMs such as GPT-4o. While Part-1 of this series\nintroduced the LLM-in-the-loop methodology for bio-medical document\ntranslation, this second paper showcases its success in developing\ncost-effective expert small NER models in de-identification tasks. Our findings\nlay the groundwork for future healthcare AI innovations, including biomedical\nentity and relation extraction, demonstrating the value of specialized models\nfor domain-specific challenges.", "published": "2024-12-14 18:10:29", "link": "http://arxiv.org/abs/2412.10918v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tokens, the oft-overlooked appetizer: Large language models, the\n  distributional hypothesis, and meaning", "abstract": "Tokenization is a necessary component within the current architecture of many\nlanguage models, including the transformer-based large language models (LLMs)\nof Generative AI, yet its impact on the model's cognition is often overlooked.\nWe argue that LLMs demonstrate that the Distributional Hypothesis (DH) is\nsufficient for reasonably human-like language performance, and that the\nemergence of human-meaningful linguistic units among tokens motivates\nlinguistically-informed interventions in existing, linguistically-agnostic\ntokenization techniques, particularly with respect to their roles as (1)\nsemantic primitives and as (2) vehicles for conveying salient distributional\npatterns from human language to the model. We explore tokenizations from a BPE\ntokenizer; extant model vocabularies obtained from Hugging Face and tiktoken;\nand the information in exemplar token vectors as they move through the layers\nof a RoBERTa (large) model. Besides creating sub-optimal semantic building\nblocks and obscuring the model's access to the necessary distributional\npatterns, we describe how tokenization pretraining can be a backdoor for bias\nand other unwanted content, which current alignment practices may not\nremediate. Additionally, we relay evidence that the tokenization algorithm's\nobjective function impacts the LLM's cognition, despite being meaningfully\ninsulated from the main system intelligence.", "published": "2024-12-14 18:18:52", "link": "http://arxiv.org/abs/2412.10924v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Streamlining Systematic Reviews: A Novel Application of Large Language\n  Models", "abstract": "Systematic reviews (SRs) are essential for evidence-based guidelines but are\noften limited by the time-consuming nature of literature screening. We propose\nand evaluate an in-house system based on Large Language Models (LLMs) for\nautomating both title/abstract and full-text screening, addressing a critical\ngap in the literature. Using a completed SR on Vitamin D and falls (14,439\narticles), the LLM-based system employed prompt engineering for title/abstract\nscreening and Retrieval-Augmented Generation (RAG) for full-text screening. The\nsystem achieved an article exclusion rate (AER) of 99.5%, specificity of 99.6%,\na false negative rate (FNR) of 0%, and a negative predictive value (NPV) of\n100%. After screening, only 78 articles required manual review, including all\n20 identified by traditional methods, reducing manual screening time by 95.5%.\nFor comparison, Rayyan, a commercial tool for title/abstract screening,\nachieved an AER of 72.1% and FNR of 5% when including articles Rayyan\nconsidered as undecided or likely to include. Lowering Rayyan's inclusion\nthresholds improved FNR to 0% but increased screening time. By addressing both\nscreening phases, the LLM-based system significantly outperformed Rayyan and\ntraditional methods, reducing total screening time to 25.5 hours while\nmaintaining high accuracy. These findings highlight the transformative\npotential of LLMs in SR workflows by offering a scalable, efficient, and\naccurate solution, particularly for the full-text screening phase, which has\nlacked automation tools.", "published": "2024-12-14 17:08:34", "link": "http://arxiv.org/abs/2412.15247v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "RoundTripOCR: A Data Generation Technique for Enhancing Post-OCR Error\n  Correction in Low-Resource Devanagari Languages", "abstract": "Optical Character Recognition (OCR) technology has revolutionized the\ndigitization of printed text, enabling efficient data extraction and analysis\nacross various domains. Just like Machine Translation systems, OCR systems are\nprone to errors. In this work, we address the challenge of data generation and\npost-OCR error correction, specifically for low-resource languages. We propose\nan approach for synthetic data generation for Devanagari languages,\nRoundTripOCR, that tackles the scarcity of the post-OCR Error Correction\ndatasets for low-resource languages. We release post-OCR text correction\ndatasets for Hindi, Marathi, Bodo, Nepali, Konkani and Sanskrit. We also\npresent a novel approach for OCR error correction by leveraging techniques from\nmachine translation. Our method involves translating erroneous OCR output into\na corrected form by treating the OCR errors as mistranslations in a parallel\ntext corpus, employing pre-trained transformer models to learn the mapping from\nerroneous to correct text pairs, effectively correcting OCR errors.", "published": "2024-12-14 19:59:41", "link": "http://arxiv.org/abs/2412.15248v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Efficient Adaptation of Multilingual Models for Japanese ASR", "abstract": "This study explores fine-tuning multilingual ASR (Automatic Speech\nRecognition) models, specifically OpenAI's Whisper-Tiny, to improve performance\nin Japanese. While multilingual models like Whisper offer versatility, they\noften lack precision in specific languages. Conversely, monolingual models like\nReazonSpeech excel in language-specific tasks but are less adaptable. Using\nJapanese-specific datasets and Low-Rank Adaptation (LoRA) along with end-to-end\n(E2E) training, we fine-tuned Whisper-Tiny to bridge this gap. Our results show\nthat fine-tuning reduced Whisper-Tiny's Character Error Rate (CER) from 32.7 to\n20.8 with LoRA and to 14.7 with end-to-end fine-tuning, surpassing\nWhisper-Base's CER of 20.2. However, challenges with domain-specific terms\nremain, highlighting the need for specialized datasets. These findings\ndemonstrate that fine-tuning multilingual models can achieve strong\nlanguage-specific performance while retaining their flexibility. This approach\nprovides a scalable solution for improving ASR in resource-constrained\nenvironments and languages with complex writing systems like Japanese.", "published": "2024-12-14 06:32:16", "link": "http://arxiv.org/abs/2412.10705v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Medical Forecasting -- Foresight 2", "abstract": "Foresight 2 (FS2) is a large language model fine-tuned on hospital data for\nmodelling patient timelines (GitHub 'removed for anon'). It can understand\npatients' clinical notes and predict SNOMED codes for a wide range of\nbiomedical use cases, including diagnosis suggestions, risk forecasting, and\nprocedure and medication recommendations. FS2 is trained on the free text\nportion of the MIMIC-III dataset, firstly through extracting biomedical\nconcepts and then creating contextualised patient timelines, upon which the\nmodel is then fine-tuned. The results show significant improvement over the\nprevious state-of-the-art for the next new biomedical concept prediction (P/R -\n0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new\ndisorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of\nrisk forecast, we compare our model to GPT-4-turbo (and a range of open-source\nbiomedical LLMs) and show that FS2 performs significantly better on such tasks\n(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data\ninto LLMs and shows that small models outperform much larger ones when\nfine-tuned on high-quality, specialised data.", "published": "2024-12-14 14:45:28", "link": "http://arxiv.org/abs/2412.10848v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BgGPT 1.0: Extending English-centric LLMs to other languages", "abstract": "We present BgGPT-Gemma-2-27B-Instruct and BgGPT-Gemma-2-9B-Instruct:\ncontinually pretrained and fine-tuned versions of Google's Gemma-2 models,\nspecifically optimized for Bulgarian language understanding and generation.\nLeveraging Gemma-2's multilingual capabilities and over 100 billion tokens of\nBulgarian and English text data, our models demonstrate strong performance in\nBulgarian language tasks, setting a new standard for language-specific AI\nmodels. Our approach maintains the robust capabilities of the original Gemma-2\nmodels, ensuring that the English language performance remains intact. To\npreserve the base model capabilities, we incorporate continual learning\nstrategies based on recent Branch-and-Merge techniques as well as thorough\ncuration and selection of training data. We provide detailed insights into our\nmethodology, including the release of model weights with a commercial-friendly\nlicense, enabling broader adoption by researchers, companies, and hobbyists.\nFurther, we establish a comprehensive set of benchmarks based on non-public\neducational data sources to evaluate models on Bulgarian language tasks as well\nas safety and chat capabilities. Our findings demonstrate the effectiveness of\nfine-tuning state-of-the-art models like Gemma 2 to enhance language-specific\nAI applications while maintaining cross-lingual capabilities.", "published": "2024-12-14 16:49:52", "link": "http://arxiv.org/abs/2412.10893v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human-Centric NLP or AI-Centric Illusion?: A Critical Investigation", "abstract": "Human-Centric NLP often claims to prioritise human needs and values, yet many\nimplementations reveal an underlying AI-centric focus. Through an analysis of\ncase studies in language modelling, behavioural testing, and multi-modal\nalignment, this study identifies a significant gap between the ideas of\nhuman-centricity and actual practices. Key issues include misalignment with\nhuman-centred design principles, the reduction of human factors to mere\nbenchmarks, and insufficient consideration of real-world impacts. The\ndiscussion explores whether Human-Centric NLP embodies true human-centred\ndesign, emphasising the need for interdisciplinary collaboration and ethical\nconsiderations. The paper advocates for a redefinition of Human-Centric NLP,\nurging a broader focus on real-world utility and societal implications to\nensure that language technologies genuinely serve and empower users.", "published": "2024-12-14 19:16:53", "link": "http://arxiv.org/abs/2412.10939v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Navigating Dialectal Bias and Ethical Complexities in Levantine Arabic\n  Hate Speech Detection", "abstract": "Social media platforms have become central to global communication, yet they\nalso facilitate the spread of hate speech. For underrepresented dialects like\nLevantine Arabic, detecting hate speech presents unique cultural, ethical, and\nlinguistic challenges. This paper explores the complex sociopolitical and\nlinguistic landscape of Levantine Arabic and critically examines the\nlimitations of current datasets used in hate speech detection. We highlight the\nscarcity of publicly available, diverse datasets and analyze the consequences\nof dialectal bias within existing resources. By emphasizing the need for\nculturally and contextually informed natural language processing (NLP) tools,\nwe advocate for a more nuanced and inclusive approach to hate speech detection\nin the Arab world.", "published": "2024-12-14 23:02:46", "link": "http://arxiv.org/abs/2412.10991v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Accelerating Retrieval-Augmented Generation", "abstract": "An evolving solution to address hallucination and enhance accuracy in large\nlanguage models (LLMs) is Retrieval-Augmented Generation (RAG), which involves\naugmenting LLMs with information retrieved from an external knowledge source,\nsuch as the web. This paper profiles several RAG execution pipelines and\ndemystifies the complex interplay between their retrieval and generation\nphases. We demonstrate that while exact retrieval schemes are expensive, they\ncan reduce inference time compared to approximate retrieval variants because an\nexact retrieval model can send a smaller but more accurate list of documents to\nthe generative model while maintaining the same end-to-end accuracy. This\nobservation motivates the acceleration of the exact nearest neighbor search for\nRAG.\n  In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL\ndevice that implements a scale-out near-memory acceleration architecture with a\nnovel cache-coherent interface between the host CPU and near-memory\naccelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a\n512GB vector database compared with executing the search on Intel Sapphire\nRapids CPUs. This higher search performance translates to 1.7-26.3x lower\nend-to-end inference time for representative RAG applications. IKS is\ninherently a memory expander; its internal DRAM can be disaggregated and used\nfor other applications running on the server to prevent DRAM, which is the most\nexpensive component in today's servers, from being stranded.", "published": "2024-12-14 06:47:56", "link": "http://arxiv.org/abs/2412.15246v1", "categories": ["cs.CL", "cs.AI", "cs.AR", "cs.DC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MASV: Speaker Verification with Global and Local Context Mamba", "abstract": "Deep learning models like Convolutional Neural Networks and transformers have\nshown impressive capabilities in speech verification, gaining considerable\nattention in the research community. However, CNN-based approaches struggle\nwith modeling long-sequence audio effectively, resulting in suboptimal\nverification performance. On the other hand, transformer-based methods are\noften hindered by high computational demands, limiting their practicality. This\npaper presents the MASV model, a novel architecture that integrates the Mamba\nmodule into the ECAPA-TDNN framework. By introducing the Local Context\nBidirectional Mamba and Tri-Mamba block, the model effectively captures both\nglobal and local context within audio sequences. Experimental results\ndemonstrate that the MASV model substantially enhances verification\nperformance, surpassing existing models in both accuracy and efficiency.", "published": "2024-12-14 22:44:38", "link": "http://arxiv.org/abs/2412.10989v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hidden Echoes Survive Training in Audio To Audio Generative Instrument\n  Models", "abstract": "As generative techniques pervade the audio domain, there has been increasing\ninterest in tracing back through these complicated models to understand how\nthey draw on their training data to synthesize new examples, both to ensure\nthat they use properly licensed data and also to elucidate their black box\nbehavior. In this paper, we show that if imperceptible echoes are hidden in the\ntraining data, a wide variety of audio to audio architectures (differentiable\ndigital signal processing (DDSP), Realtime Audio Variational autoEncoder\n(RAVE), and ``Dance Diffusion'') will reproduce these echoes in their outputs.\nHiding a single echo is particularly robust across all architectures, but we\nalso show promising results hiding longer time spread echo patterns for an\nincreased information capacity. We conclude by showing that echoes make their\nway into fine tuned models, that they survive mixing/demixing, and that they\nsurvive pitch shift augmentation during training. Hence, this simple, classical\nidea in watermarking shows significant promise for tagging generative audio\nmodels.", "published": "2024-12-14 02:36:45", "link": "http://arxiv.org/abs/2412.10649v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS", "I.2; I.5.4; J.5"], "primary_category": "cs.SD"}
{"title": "VinTAGe: Joint Video and Text Conditioning for Holistic Audio Generation", "abstract": "Recent advances in audio generation have focused on text-to-audio (T2A) and\nvideo-to-audio (V2A) tasks. However, T2A or V2A methods cannot generate\nholistic sounds (onscreen and off-screen). This is because T2A cannot generate\nsounds aligning with onscreen objects, while V2A cannot generate semantically\ncomplete (offscreen sounds missing). In this work, we address the task of\nholistic audio generation: given a video and a text prompt, we aim to generate\nboth onscreen and offscreen sounds that are temporally synchronized with the\nvideo and semantically aligned with text and video. Previous approaches for\njoint text and video-to-audio generation often suffer from modality bias,\nfavoring one modality over the other. To overcome this limitation, we introduce\nVinTAGe, a flow-based transformer model that jointly considers text and video\nto guide audio generation. Our framework comprises two key components: a\nVisual-Text Encoder and a Joint VT-SiT model. To reduce modality bias and\nimprove generation quality, we employ pretrained uni-modal text-to-audio and\nvideo-to-audio generation models for additional guidance. Due to the lack of\nappropriate benchmarks, we also introduce VinTAGe-Bench, a dataset of 636\nvideo-text-audio pairs containing both onscreen and offscreen sounds. Our\ncomprehensive experiments on VinTAGe-Bench demonstrate that joint text and\nvisual interaction is necessary for holistic audio generation. Furthermore,\nVinTAGe achieves state-of-the-art results on the VGGSound benchmark. Our source\ncode and pre-trained models will be released. Demo is available at:\nhttps://www.youtube.com/watch?v=QmqWhUjPkJI.", "published": "2024-12-14 09:36:10", "link": "http://arxiv.org/abs/2412.10768v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Audio-based Anomaly Detection in Industrial Machines Using Deep\n  One-Class Support Vector Data Description", "abstract": "The frequent breakdowns and malfunctions of industrial equipment have driven\nincreasing interest in utilizing cost-effective and easy-to-deploy sensors,\nsuch as microphones, for effective condition monitoring of machinery.\nMicrophones offer a low-cost alternative to widely used condition monitoring\nsensors with their high bandwidth and capability to detect subtle anomalies\nthat other sensors might have less sensitivity. In this study, we investigate\nmalfunctioning industrial machines to evaluate and compare anomaly detection\nperformance across different machine types and fault conditions. Log-Mel\nspectrograms of machinery sound are used as input, and the performance is\nevaluated using the area under the curve (AUC) score for two different methods:\nbaseline dense autoencoder (AE) and one-class deep Support Vector Data\nDescription (deep SVDD) with different subspace dimensions. Our results over\nthe MIMII sound dataset demonstrate that the deep SVDD method with a subspace\ndimension of 2 provides superior anomaly detection performance, achieving\naverage AUC scores of 0.84, 0.80, and 0.69 for 6 dB, 0 dB, and -6 dB\nsignal-to-noise ratios (SNRs), respectively, compared to 0.82, 0.72, and 0.64\nfor the baseline model. Moreover, deep SVDD requires 7.4 times fewer trainable\nparameters than the baseline dense AE, emphasizing its advantage in both\neffectiveness and computational efficiency.", "published": "2024-12-14 11:05:06", "link": "http://arxiv.org/abs/2412.10792v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Persian Digit Recognition in Noisy Environments Using Hybrid\n  CNN-BiGRU Model", "abstract": "Artificial intelligence (AI) has significantly advanced speech recognition\napplications. However, many existing neural network-based methods struggle with\nnoise, reducing accuracy in real-world environments. This study addresses\nisolated spoken Persian digit recognition (zero to nine) under noisy\nconditions, particularly for phonetically similar numbers. A hybrid model\ncombining residual convolutional neural networks and bidirectional gated\nrecurrent units (BiGRU) is proposed, utilizing word units instead of phoneme\nunits for speaker-independent recognition. The FARSDIGIT1 dataset, augmented\nwith various approaches, is processed using Mel-Frequency Cepstral Coefficients\n(MFCC) for feature extraction. Experimental results demonstrate the model's\neffectiveness, achieving 98.53%, 96.10%, and 95.92% accuracy on training,\nvalidation, and test sets, respectively. In noisy conditions, the proposed\napproach improves recognition by 26.88% over phoneme unit-based LSTM models and\nsurpasses the Mel-scale Two Dimension Root Cepstrum Coefficients (MTDRCC)\nfeature extraction technique along with MLP model (MTDRCC+MLP) by 7.61%.", "published": "2024-12-14 15:11:42", "link": "http://arxiv.org/abs/2412.10857v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Composers' Evaluations of an AI Music Tool: Insights for Human-Centred\n  Design", "abstract": "We present a study that explores the role of user-centred design in\ndeveloping Generative AI (GenAI) tools for music composition. Through\nsemi-structured interviews with professional composers, we gathered insights on\na novel generative model for creating variations, highlighting concerns around\ntrust, transparency, and ethical design. The findings helped form a feedback\nloop, guiding improvements to the model that emphasised traceability,\ntransparency and explainability. They also revealed new areas for innovation,\nincluding novel features for controllability and research questions on the\nethical and practical implementation of GenAI models.", "published": "2024-12-14 20:56:23", "link": "http://arxiv.org/abs/2412.10968v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
