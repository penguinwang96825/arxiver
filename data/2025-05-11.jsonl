{"title": "LLM-Augmented Chemical Synthesis and Design Decision Programs", "abstract": "Retrosynthesis, the process of breaking down a target molecule into simpler\nprecursors through a series of valid reactions, stands at the core of organic\nchemistry and drug development. Although recent machine learning (ML) research\nhas advanced single-step retrosynthetic modeling and subsequent route searches,\nthese solutions remain restricted by the extensive combinatorial space of\npossible pathways. Concurrently, large language models (LLMs) have exhibited\nremarkable chemical knowledge, hinting at their potential to tackle complex\ndecision-making tasks in chemistry. In this work, we explore whether LLMs can\nsuccessfully navigate the highly constrained, multi-step retrosynthesis\nplanning problem. We introduce an efficient scheme for encoding reaction\npathways and present a new route-level search strategy, moving beyond the\nconventional step-by-step reactant prediction. Through comprehensive\nevaluations, we show that our LLM-augmented approach excels at retrosynthesis\nplanning and extends naturally to the broader challenge of synthesizable\nmolecular design.", "published": "2025-05-11 15:43:00", "link": "http://arxiv.org/abs/2505.07027v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "physics.chem-ph"], "primary_category": "cs.AI"}
{"title": "Towards the Three-Phase Dynamics of Generalization Power of a DNN", "abstract": "This paper proposes a new perspective for analyzing the generalization power\nof deep neural networks (DNNs), i.e., directly disentangling and analyzing the\ndynamics of generalizable and non-generalizable interaction encoded by a DNN\nthrough the training process. Specifically, this work builds upon the recent\ntheoretical achievement in explainble AI, which proves that the detailed\ninference logic of DNNs can be can be strictly rewritten as a small number of\nAND-OR interaction patterns. Based on this, we propose an efficient method to\nquantify the generalization power of each interaction, and we discover a\ndistinct three-phase dynamics of the generalization power of interactions\nduring training. In particular, the early phase of training typically removes\nnoisy and non-generalizable interactions and learns simple and generalizable\nones. The second and the third phases tend to capture increasingly complex\ninteractions that are harder to generalize. Experimental results verify that\nthe learning of non-generalizable interactions is the the direct cause for the\ngap between the training and testing losses.", "published": "2025-05-11 14:37:30", "link": "http://arxiv.org/abs/2505.06993v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Convert Language Model into a Value-based Strategic Planner", "abstract": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Q-learning on LLMs, and propose a framework called straQ*. Our\nframework allows a plug-and-play LLM to bootstrap the planning during ESC,\ndetermine the optimal strategy based on long-term returns, and finally guide\nthe LLM to response. Substantial experiments on ESC datasets suggest that\nstraQ* outperforms many baselines, including direct inference, self-refine,\nchain of thought, finetuning, and finite state machines.", "published": "2025-05-11 14:13:58", "link": "http://arxiv.org/abs/2505.06987v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CNN-based Image Models Verify a Hypothesis that The Writers of Cuneiform Texts Improved Their Writing Skills When Studying at the Age of Hittite Empire", "abstract": "A cuneiform tablet KBo 23.1 ++/KUB 30.38, which is known to represent a text\nof Kizzuwatna rituals, was written by two writers with almost identical content\nin two iterations. Unlike other cuneiform tablets that contained information\nsuch as myths, essays, or business records, the reason why ancient people left\nsuch tablets for posterity remains unclear. To study this problem, we develop a\nnew methodology by analyzing images of a tablet quantitatively using CNN\n(Convolutional Neural Network)-based image models, without segmenting\ncuneiforms one-by-one. Our data-driven methodology implies that the writer\nwriting the first half was a `teacher' and the other writer was a `student' who\nwas training his skills of writing cuneiforms. This result has not been reached\nby classical linguistics. We also discuss related conclusions and possible\nfurther directions for applying our method and its generalizations.", "published": "2025-05-11 13:17:44", "link": "http://arxiv.org/abs/2505.06974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Web Page Classification using LLMs for Crawling Support", "abstract": "A web crawler is a system designed to collect web pages, and efficient\ncrawling of new pages requires appropriate algorithms. While website features\nsuch as XML sitemaps and the frequency of past page updates provide important\nclues for accessing new pages, their universal application across diverse\nconditions is challenging. In this study, we propose a method to efficiently\ncollect new pages by classifying web pages into two types, \"Index Pages\" and\n\"Content Pages,\" using a large language model (LLM), and leveraging the\nclassification results to select index pages as starting points for accessing\nnew pages. We construct a dataset with automatically annotated web page types\nand evaluate our approach from two perspectives: the page type classification\nperformance and coverage of new pages. Experimental results demonstrate that\nthe LLM-based method outperformed baseline methods in both evaluation metrics.", "published": "2025-05-11 13:07:15", "link": "http://arxiv.org/abs/2505.06972v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A digital perspective on the role of a stemma in material-philological transmission studies", "abstract": "Taking its point of departure in the recent developments in the field of\ndigital humanities and the increasing automatisation of scholarly workflows,\nthis study explores the implications of digital approaches to textual\ntraditions for the broader field of textual scholarship. It argues that the\nrelative simplicity of creating computergenerated stemmas allows us to view the\nstemma codicum as a research tool rather than the final product of our\nscholarly investigation. Using the Old Norse saga of Hr\\'omundur as a case\nstudy, this article demonstrates that stemmas can serve as a starting point for\nexploring textual traditions further. In doing so, they enable us to address\nresearch questions that otherwise remain unanswered. The article is accompanied\nby datasets used to generate stemmas for the Hr\\'omundar saga tradition as well\nas two custom Python scripts. The scripts are designed to convert XML-based\ntextual data, encoded according to the TEI Guidelines, into the input format\nused for the analysis in the PHYLIP package to generate unrooted trees of\nrelationships between texts.", "published": "2025-05-11 11:05:16", "link": "http://arxiv.org/abs/2505.06938v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "The Distracting Effect: Understanding Irrelevant Passages in RAG", "abstract": "A well-known issue with Retrieval Augmented Generation (RAG) is that\nretrieved passages that are irrelevant to the query sometimes distract the\nanswer-generating LLM, causing it to provide an incorrect response. In this\npaper, we shed light on this core issue and formulate the distracting effect of\na passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the\ndistracting effect of a passage and demonstrate its robustness across LLMs.\n  Our research introduces novel methods for identifying and using hard\ndistracting passages to improve RAG systems. By fine-tuning LLMs with these\ncarefully selected distracting passages, we achieve up to a 7.5% increase in\nanswering accuracy compared to counterparts fine-tuned on conventional RAG\ndatasets. Our contribution is two-fold: first, we move beyond the simple binary\nclassification of irrelevant passages as either completely unrelated vs.\ndistracting, and second, we develop and analyze multiple methods for finding\nhard distracting passages. To our knowledge, no other research has provided\nsuch a comprehensive framework for identifying and utilizing hard distracting\npassages.", "published": "2025-05-11 09:25:05", "link": "http://arxiv.org/abs/2505.06914v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation", "abstract": "Large language models (LLMs) have demonstrated an impressive ability to\nrole-play humans and replicate complex social dynamics. While large-scale\nsocial simulations are gaining increasing attention, they still face\nsignificant challenges, particularly regarding high time and computation costs.\nExisting solutions, such as distributed mechanisms or hybrid agent-based model\n(ABM) integrations, either fail to address inference costs or compromise\naccuracy and generalizability. To this end, we propose EcoLANG: Efficient and\nEffective Agent Communication Language Induction for Social Simulation. EcoLANG\noperates in two stages: (1) language evolution, where we filter synonymous\nwords and optimize sentence-level rules through natural selection, and (2)\nlanguage utilization, where agents in social simulations communicate using the\nevolved language. Experimental results demonstrate that EcoLANG reduces token\nconsumption by over 20%, enhancing efficiency without sacrificing simulation\naccuracy.", "published": "2025-05-11 08:51:56", "link": "http://arxiv.org/abs/2505.06904v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration", "abstract": "Generalist Medical AI (GMAI) systems have demonstrated expert-level\nperformance in biomedical perception tasks, yet their clinical utility remains\nlimited by inadequate multi-modal explainability and suboptimal prognostic\ncapabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI\nassistant that integrates textual and visual interpretability to support\ntransparent and trustworthy medical decision-making. XMedGPT not only produces\naccurate diagnostic and descriptive outputs, but also grounds referenced\nanatomical sites within medical images, bridging critical gaps in\ninterpretability and enhancing clinician usability. To support real-world\ndeployment, we introduce a reliability indexing mechanism that quantifies\nuncertainty through consistency-based assessment via interactive\nquestion-answering. We validate XMedGPT across four pillars: multi-modal\ninterpretability, uncertainty quantification, and prognostic modeling, and\nrigorous benchmarking. The model achieves an IoU of 0.703 across 141 anatomical\nregions, and a Kendall's tau-b of 0.479, demonstrating strong alignment between\nvisual rationales and clinical outcomes. For uncertainty estimation, it attains\nan AUC of 0.862 on visual question answering and 0.764 on radiology report\ngeneration. In survival and recurrence prediction for lung and glioma cancers,\nit surpasses prior leading models by 26.9%, and outperforms GPT-4o by 25.0%.\nRigorous benchmarking across 347 datasets covers 40 imaging modalities and\nexternal validation spans 4 anatomical systems confirming exceptional\ngeneralizability, with performance gains surpassing existing GMAI by 20.7% for\nin-domain evaluation and 16.7% on 11,530 in-house data evaluation. Together,\nXMedGPT represents a significant leap forward in clinician-centric AI\nintegration, offering trustworthy and scalable support for diverse healthcare\napplications.", "published": "2025-05-11 08:32:01", "link": "http://arxiv.org/abs/2505.06898v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method", "abstract": "Pre-trained Language Models (PLMs) have achieved remarkable performance on\ndiverse NLP tasks through pre-training and fine-tuning. However, fine-tuning\nthe model with a large number of parameters on limited downstream datasets\noften leads to vulnerability to adversarial attacks, causing overfitting of the\nmodel on standard datasets.\n  To address these issues, we propose IM-BERT from the perspective of a dynamic\nsystem by conceptualizing a layer of BERT as a solution of Ordinary\nDifferential Equations (ODEs). Under the situation of initial value\nperturbation, we analyze the numerical stability of two main numerical ODE\nsolvers: the explicit and implicit Euler approaches.\n  Based on these analyses, we introduce a numerically robust IM-connection\nincorporating BERT's layers. This strategy enhances the robustness of PLMs\nagainst adversarial attacks, even in low-resource scenarios, without\nintroducing additional parameters or adversarial training strategies.\n  Experimental results on the adversarial GLUE (AdvGLUE) dataset validate the\nrobustness of IM-BERT under various conditions. Compared to the original BERT,\nIM-BERT exhibits a performance improvement of approximately 8.3\\%p on the\nAdvGLUE dataset. Furthermore, in low-resource scenarios, IM-BERT outperforms\nBERT by achieving 5.9\\%p higher accuracy.", "published": "2025-05-11 07:54:33", "link": "http://arxiv.org/abs/2505.06889v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Split-then-Join Approach to Abstractive Summarization for Very Long Documents in a Low Resource Setting", "abstract": "$\\texttt{BIGBIRD-PEGASUS}$ model achieves $\\textit{state-of-the-art}$ on\nabstractive text summarization for long documents. However it's capacity still\nlimited to maximum of $4,096$ tokens, thus caused performance degradation on\nsummarization for very long documents. Common method to deal with the issue is\nto truncate the documents. In this reasearch, we'll use different approach.\nWe'll use the pretrained $\\texttt{BIGBIRD-PEGASUS}$ model by fine tuned the\nmodel on other domain dataset. First, we filter out all documents which length\nless than $20,000$ tokens to focus on very long documents. To prevent domain\nshifting problem and overfitting on transfer learning due to small dataset, we\naugment the dataset by splitting document-summary training pair into parts, to\nfit the document into $4,096$ tokens. Source code available on\n$\\href{https://github.com/lhfazry/SPIN-summ}{https://github.com/lhfazry/SPIN-summ}$.", "published": "2025-05-11 06:14:39", "link": "http://arxiv.org/abs/2505.06862v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety", "abstract": "Recent studies have uncovered a troubling vulnerability in the fine-tuning\nstage of large language models (LLMs): even fine-tuning on entirely benign\ndatasets can lead to a significant increase in the harmfulness of LLM outputs.\nBuilding on this finding, our red teaming study takes this threat one step\nfurther by developing a more effective attack. Specifically, we analyze and\nidentify samples within benign datasets that contribute most to safety\ndegradation, then fine-tune LLMs exclusively on these samples. We approach this\nproblem from an outlier detection perspective and propose Self-Inf-N, to detect\nand extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs\non 100 outlier samples selected by Self-Inf-N in the benign datasets severely\ncompromises LLM safety alignment. Extensive experiments across seven mainstream\nLLMs demonstrate that our attack exhibits high transferability across different\narchitectures and remains effective in practical scenarios. Alarmingly, our\nresults indicate that most existing mitigation strategies fail to defend\nagainst this attack, underscoring the urgent need for more robust alignment\nsafeguards. Codes are available at\nhttps://github.com/GuanZihan/Benign-Samples-Matter.", "published": "2025-05-11 04:59:20", "link": "http://arxiv.org/abs/2505.06843v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge", "abstract": "Following the successful hosts of the 1-st (NLPCC 2023 Foshan) CMIVQA and the\n2-rd (NLPCC 2024 Hangzhou) MMIVQA challenges, this year, a new task has been\nintroduced to further advance research in multi-modal, multilingual, and\nmulti-hop medical instructional question answering (M4IVQA) systems, with a\nspecific focus on medical instructional videos. The M4IVQA challenge focuses on\nevaluating models that integrate information from medical instructional videos,\nunderstand multiple languages, and answer multi-hop questions requiring\nreasoning over various modalities. This task consists of three tracks:\nmulti-modal, multilingual, and multi-hop Temporal Answer Grounding in Single\nVideo (M4TAGSV), multi-modal, multilingual, and multi-hop Video Corpus\nRetrieval (M4VCR) and multi-modal, multilingual, and multi-hop Temporal Answer\nGrounding in Video Corpus (M4TAGVC). Participants in M4IVQA are expected to\ndevelop algorithms capable of processing both video and text data,\nunderstanding multilingual queries, and providing relevant answers to multi-hop\nmedical questions. We believe the newly introduced M4IVQA challenge will drive\ninnovations in multimodal reasoning systems for healthcare scenarios,\nultimately contributing to smarter emergency response systems and more\neffective medical education platforms in multilingual communities. Our official\nwebsite is https://cmivqa.github.io/", "published": "2025-05-11 02:15:14", "link": "http://arxiv.org/abs/2505.06814v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Bridging Ears and Eyes: Analyzing Audio and Visual Large Language Models to Humans in Visible Sound Recognition and Reducing Their Sensory Gap via Cross-Modal Distillation", "abstract": "Audio large language models (LLMs) are considered experts at recognizing\nsound objects, yet their performance relative to LLMs in other sensory\nmodalities, such as visual or audio-visual LLMs, and to humans using their\nears, eyes, or both remains unexplored. To investigate this, we systematically\nevaluate audio, visual, and audio-visual LLMs, specifically Qwen2-Audio,\nQwen2-VL, and Qwen2.5-Omni, against humans in recognizing sound objects of\ndifferent classes from audio-only, silent video, or sounded video inputs. We\nuncover a performance gap between Qwen2-Audio and Qwen2-VL that parallels the\nsensory discrepancy between human ears and eyes. To reduce this gap, we\nintroduce a cross-modal distillation framework, where an LLM in one modality\nserves as the teacher and another as the student, with knowledge transfer in\nsound classes predicted as more challenging to the student by a heuristic\nmodel. Distillation in both directions, from Qwen2-VL to Qwen2-Audio and vice\nversa, leads to notable improvements, particularly in challenging classes. This\nwork highlights the sensory gap in LLMs from a human-aligned perspective and\nproposes a principled approach to enhancing modality-specific perception in\nmultimodal LLMs.", "published": "2025-05-11 01:01:44", "link": "http://arxiv.org/abs/2505.06803v1", "categories": ["cs.SD", "cs.CL", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression", "abstract": "Visual Anomaly Detection (VAD) is a key task in industrial settings, where\nminimizing waste and operational costs is essential. Deploying deep learning\nmodels within Internet of Things (IoT) environments introduces specific\nchallenges due to the limited computational power and bandwidth of edge\ndevices. This study investigates how to perform VAD effectively under such\nconstraints by leveraging compact and efficient processing strategies. We\nevaluate several data compression techniques, examining the trade-off between\nsystem latency and detection accuracy. Experiments on the MVTec AD benchmark\ndemonstrate that significant compression can be achieved with minimal loss in\nanomaly detection performance compared to uncompressed data.", "published": "2025-05-11 21:05:33", "link": "http://arxiv.org/abs/2505.07119v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real", "abstract": "Human videos offer a scalable way to train robot manipulation policies, but\nlack the action labels needed by standard imitation learning algorithms.\nExisting cross-embodiment approaches try to map human motion to robot actions,\nbut often fail when the embodiments differ significantly. We propose X-Sim, a\nreal-to-sim-to-real framework that uses object motion as a dense and\ntransferable signal for learning robot policies. X-Sim starts by reconstructing\na photorealistic simulation from an RGBD human video and tracking object\ntrajectories to define object-centric rewards. These rewards are used to train\na reinforcement learning (RL) policy in simulation. The learned policy is then\ndistilled into an image-conditioned diffusion policy using synthetic rollouts\nrendered with varied viewpoints and lighting. To transfer to the real world,\nX-Si introduces an online domain adaptation technique that aligns real and\nsimulated observations during deployment. Importantly, X-Sim does not require\nany robot teleoperation data. We evaluate it across 5 manipulation tasks in 2\nenvironments and show that it: (1) improves task progress by 30% on average\nover hand-tracking and sim-to-real baselines, (2) matches behavior cloning with\n10x less data collection time, and (3) generalizes to new camera viewpoints and\ntest-time changes. Code and videos are available at\nhttps://portal-cornell.github.io/X-Sim/.", "published": "2025-05-11 19:04:00", "link": "http://arxiv.org/abs/2505.07096v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models", "abstract": "Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\nintrinsic knowledge of LLMs. However, existing LLM-based AutoPT frameworks\noften underperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sighted planning\nin the planning process, and hallucinations during command generation. In\naddition, the penetration testing (PT) process, with its trial-and-error\nnature, is limited by existing frameworks that lack mechanisms to learn from\nprevious failed operations, restricting adaptive improvement of PT strategies.\nTo address these limitations, we propose a knowledge-informed self-reflective\nPT framework powered by LLMs, called RefPentester, which is an AutoPT framework\ndesigned to assist human operators in identifying the current stage of the PT\nprocess, selecting appropriate tactic and technique for the stage, choosing\nsuggested action, providing step-by-step operational guidance, and learning\nfrom previous failed operations. We also modeled the PT process as a\nseven-state Stage Machine to integrate the proposed framework effectively. The\nevaluation shows that RefPentester can successfully reveal credentials on Hack\nThe Box's Sau machine, outperforming the baseline GPT-4o model by 16.7\\%.\nAcross PT stages, RefPentester also demonstrates superior success rates on PT\nstage transitions.", "published": "2025-05-11 18:38:00", "link": "http://arxiv.org/abs/2505.07089v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Architectural Precedents for General Agents using Large Language Models", "abstract": "One goal of AI (and AGI) is to identify and understand specific mechanisms\nand representations sufficient for general intelligence. Often, this work\nmanifests in research focused on architectures and many cognitive architectures\nhave been explored in AI/AGI. However, different research groups and even\ndifferent research traditions have somewhat independently identified\nsimilar/common patterns of processes and representations or cognitive design\npatterns that are manifest in existing architectures. Today, AI systems\nexploiting large language models (LLMs) offer a relatively new combination of\nmechanism and representation available for exploring the possibilities of\ngeneral intelligence. In this paper, we summarize a few recurring cognitive\ndesign patterns that have appeared in various pre-transformer AI architectures.\nWe then explore how these patterns are evident in systems using LLMs,\nespecially for reasoning and interactive (\"agentic\") use cases. By examining\nand applying these recurring patterns, we can also predict gaps or deficiencies\nin today's Agentic LLM Systems and identify likely subjects of future research\ntowards general intelligence using LLMs and other generative foundation models.", "published": "2025-05-11 18:29:54", "link": "http://arxiv.org/abs/2505.07087v1", "categories": ["cs.AI", "I.2.11; I.2.7"], "primary_category": "cs.AI"}
{"title": "Arbitrarily Applicable Same/Opposite Relational Responding with NARS", "abstract": "Same/opposite relational responding, a fundamental aspect of human symbolic\ncognition, allows the flexible generalization of stimulus relationships based\non minimal experience. In this study, we demonstrate the emergence of\n\\textit{arbitrarily applicable} same/opposite relational responding within the\nNon-Axiomatic Reasoning System (NARS), a computational cognitive architecture\ndesigned for adaptive reasoning under uncertainty. Specifically, we extend NARS\nwith an implementation of \\textit{acquired relations}, enabling the system to\nexplicitly derive both symmetric (mutual entailment) and novel relational\ncombinations (combinatorial entailment) from minimal explicit training in a\ncontextually controlled matching-to-sample (MTS) procedure. Experimental\nresults show that NARS rapidly internalizes explicitly trained relational rules\nand robustly demonstrates derived relational generalizations based on arbitrary\ncontextual cues. Importantly, derived relational responding in critical test\nphases inherently combines both mutual and combinatorial entailments, such as\nderiving same-relations from multiple explicitly trained opposite-relations.\nInternal confidence metrics illustrate strong internalization of these\nrelational principles, closely paralleling phenomena observed in human\nrelational learning experiments. Our findings underscore the potential for\nintegrating nuanced relational learning mechanisms inspired by learning\npsychology into artificial general intelligence frameworks, explicitly\nhighlighting the arbitrary and context-sensitive relational capabilities\nmodeled within NARS.", "published": "2025-05-11 18:03:37", "link": "http://arxiv.org/abs/2505.07079v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing\ntasks and stock trading applications, enabling AI agents to generate investment\ndecisions from unstructured financial data. However, most evaluations of LLM\ntiming-based investing strategies are conducted on narrow timeframes and\nlimited stock universes, overstating effectiveness due to survivorship and\ndata-snooping biases. We critically assess their generalizability and\nrobustness by proposing FINSABER, a backtesting framework evaluating\ntiming-based strategies across longer periods and a larger universe of symbols.\nSystematic backtests over two decades and 100+ symbols reveal that previously\nreported LLM advantages deteriorate significantly under broader cross-section\nand over a longer-term evaluation. Our market regime analysis further\ndemonstrates that LLM strategies are overly conservative in bull markets,\nunderperforming passive benchmarks, and overly aggressive in bear markets,\nincurring heavy losses. These findings highlight the need to develop LLM\nstrategies that are able to prioritise trend detection and regime-aware risk\ncontrols over mere scaling of framework complexity.", "published": "2025-05-11 18:02:21", "link": "http://arxiv.org/abs/2505.07078v1", "categories": ["q-fin.TR", "cs.AI", "cs.CE"], "primary_category": "q-fin.TR"}
{"title": "ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use", "abstract": "While powerful and well-established, tools like ParaView present a steep\nlearning curve that discourages many potential users. This work introduces\nParaView-MCP, an autonomous agent that integrates modern multimodal large\nlanguage models (MLLMs) with ParaView to not only lower the barrier to entry\nbut also augment ParaView with intelligent decision support. By leveraging the\nstate-of-the-art reasoning, command execution, and vision capabilities of\nMLLMs, ParaView-MCP enables users to interact with ParaView through natural\nlanguage and visual inputs. Specifically, our system adopted the Model Context\nProtocol (MCP) - a standardized interface for model-application communication -\nthat facilitates direct interaction between MLLMs with ParaView's Python API to\nallow seamless information exchange between the user, the language model, and\nthe visualization tool itself. Furthermore, by implementing a visual feedback\nmechanism that allows the agent to observe the viewport, we unlock a range of\nnew capabilities, including recreating visualizations from examples,\nclosed-loop visualization parameter updates based on user-defined goals, and\neven cross-application collaboration involving multiple tools. Broadly, we\nbelieve such an agent-driven visualization paradigm can profoundly change the\nway we interact with visualization tools. We expect a significant uptake in the\ndevelopment of such visualization tools, in both visualization research and\nindustry.", "published": "2025-05-11 17:30:08", "link": "http://arxiv.org/abs/2505.07064v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Seed1.5-VL Technical Report", "abstract": "We present Seed1.5-VL, a vision-language foundation model designed to advance\ngeneral-purpose multimodal understanding and reasoning. Seed1.5-VL is composed\nwith a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B\nactive parameters. Despite its relatively compact architecture, it delivers\nstrong performance across a wide spectrum of public VLM benchmarks and internal\nevaluation suites, achieving the state-of-the-art performance on 38 out of 60\npublic benchmarks. Moreover, in agent-centric tasks such as GUI control and\ngameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI\nCUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates\nstrong reasoning abilities, making it particularly effective for multimodal\nreasoning challenges such as visual puzzles. We believe these capabilities will\nempower broader applications across diverse tasks. In this report, we mainly\nprovide a comprehensive review of our experiences in building Seed1.5-VL across\nmodel design, data construction, and training at various stages, hoping that\nthis report can inspire further research. Seed1.5-VL is now accessible at\nhttps://www.volcengine.com/ (Volcano Engine Model ID:\ndoubao-1-5-thinking-vision-pro-250428)", "published": "2025-05-11 17:28:30", "link": "http://arxiv.org/abs/2505.07062v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unlocking Non-Block-Structured Decisions: Inductive Mining with Choice Graphs", "abstract": "Process discovery aims to automatically derive process models from event\nlogs, enabling organizations to analyze and improve their operational\nprocesses. Inductive mining algorithms, while prioritizing soundness and\nefficiency through hierarchical modeling languages, often impose a strict\nblock-structured representation. This limits their ability to accurately\ncapture the complexities of real-world processes. While recent advancements\nlike the Partially Ordered Workflow Language (POWL) have addressed the\nblock-structure limitation for concurrency, a significant gap remains in\neffectively modeling non-block-structured decision points. In this paper, we\nbridge this gap by proposing an extension of POWL to handle\nnon-block-structured decisions through the introduction of choice graphs.\nChoice graphs offer a structured yet flexible approach to model complex\ndecision logic within the hierarchical framework of POWL. We present an\ninductive mining discovery algorithm that uses our extension and preserves the\nquality guarantees of the inductive mining framework. Our experimental\nevaluation demonstrates that the discovered models, enriched with choice\ngraphs, more precisely represent the complex decision-making behavior found in\nreal-world processes, without compromising the high scalability inherent in\ninductive mining techniques.", "published": "2025-05-11 16:50:25", "link": "http://arxiv.org/abs/2505.07052v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs", "abstract": "We propose DialogueReason, a reasoning paradigm that uncovers the lost roles\nin monologue-style reasoning models, aiming to boost diversity and coherency of\nthe reasoning process. Recent advances in RL-based large reasoning models have\nled to impressive long CoT capabilities and high performance on math and\nscience benchmarks. However, these reasoning models rely mainly on\nmonologue-style reasoning, which often limits reasoning diversity and\ncoherency, frequently recycling fixed strategies or exhibiting unnecessary\nshifts in attention. Our work consists of an analysis of monologue reasoning\npatterns and the development of a dialogue-based reasoning approach. We first\nintroduce the Compound-QA task, which concatenates multiple problems into a\nsingle prompt to assess both diversity and coherency of reasoning. Our analysis\nshows that Compound-QA exposes weaknesses in monologue reasoning, evidenced by\nboth quantitative metrics and qualitative reasoning traces. Building on the\nanalysis, we propose a dialogue-based reasoning, named DialogueReason,\nstructured around agents, environment, and interactions. Using PPO with\nrule-based rewards, we train open-source LLMs (Qwen-QWQ and Qwen-Base) to adopt\ndialogue reasoning. We evaluate trained models on MATH, AIME, and GPQA\ndatasets, showing that the dialogue reasoning model outperforms monologue\nmodels under more complex compound questions. Additionally, we discuss how\ndialogue-based reasoning helps enhance interpretability, facilitate more\nintuitive human interaction, and inspire advances in multi-agent system design.", "published": "2025-05-11 16:39:58", "link": "http://arxiv.org/abs/2505.07049v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Empirical Analysis of Asynchronous Federated Learning on Heterogeneous Devices: Efficiency, Fairness, and Privacy Trade-offs", "abstract": "Device heterogeneity poses major challenges in Federated Learning (FL), where\nresource-constrained clients slow down synchronous schemes that wait for all\nupdates before aggregation. Asynchronous FL addresses this by incorporating\nupdates as they arrive, substantially improving efficiency. While its\nefficiency gains are well recognized, its privacy costs remain largely\nunexplored, particularly for high-end devices that contribute updates more\nfrequently, increasing their cumulative privacy exposure. This paper presents\nthe first comprehensive analysis of the efficiency-fairness-privacy trade-off\nin synchronous vs. asynchronous FL under realistic device heterogeneity. We\nempirically compare FedAvg and staleness-aware FedAsync using a physical\ntestbed of five edge devices spanning diverse hardware tiers, integrating Local\nDifferential Privacy (LDP) and the Moments Accountant to quantify per-client\nprivacy loss. Using Speech Emotion Recognition (SER) as a privacy-critical\nbenchmark, we show that FedAsync achieves up to 10x faster convergence but\nexacerbates fairness and privacy disparities: high-end devices contribute 6-10x\nmore updates and incur up to 5x higher privacy loss, while low-end devices\nsuffer amplified accuracy degradation due to infrequent, stale, and\nnoise-perturbed updates. These findings motivate the need for adaptive FL\nprotocols that jointly optimize aggregation and privacy mechanisms based on\nclient capacity and participation dynamics, moving beyond static,\none-size-fits-all solutions.", "published": "2025-05-11 16:25:06", "link": "http://arxiv.org/abs/2505.07041v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "DeepSORT-Driven Visual Tracking Approach for Gesture Recognition in Interactive Systems", "abstract": "Based on the DeepSORT algorithm, this study explores the application of\nvisual tracking technology in intelligent human-computer interaction,\nespecially in the field of gesture recognition and tracking. With the rapid\ndevelopment of artificial intelligence and deep learning technology,\nvisual-based interaction has gradually replaced traditional input devices and\nbecome an important way for intelligent systems to interact with users. The\nDeepSORT algorithm can achieve accurate target tracking in dynamic environments\nby combining Kalman filters and deep learning feature extraction methods. It is\nespecially suitable for complex scenes with multi-target tracking and fast\nmovements. This study experimentally verifies the superior performance of\nDeepSORT in gesture recognition and tracking. It can accurately capture and\ntrack the user's gesture trajectory and is superior to traditional tracking\nmethods in terms of real-time and accuracy. In addition, this study also\ncombines gesture recognition experiments to evaluate the recognition ability\nand feedback response of the DeepSORT algorithm under different gestures (such\nas sliding, clicking, and zooming). The experimental results show that DeepSORT\ncan not only effectively deal with target occlusion and motion blur but also\ncan stably track in a multi-target environment, achieving a smooth user\ninteraction experience. Finally, this paper looks forward to the future\ndevelopment direction of intelligent human-computer interaction systems based\non visual tracking and proposes future research focuses such as algorithm\noptimization, data fusion, and multimodal interaction in order to promote a\nmore intelligent and personalized interactive experience. Keywords-DeepSORT,\nvisual tracking, gesture recognition, human-computer interaction", "published": "2025-05-11 20:35:11", "link": "http://arxiv.org/abs/2505.07110v1", "categories": ["cs.HC", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Privacy of Groups in Dense Street Imagery", "abstract": "Spatially and temporally dense street imagery (DSI) datasets have grown\nunbounded. In 2024, individual companies possessed around 3 trillion unique\nimages of public streets. DSI data streams are only set to grow as companies\nlike Lyft and Waymo use DSI to train autonomous vehicle algorithms and analyze\ncollisions. Academic researchers leverage DSI to explore novel approaches to\nurban analysis. Despite good-faith efforts by DSI providers to protect\nindividual privacy through blurring faces and license plates, these measures\nfail to address broader privacy concerns. In this work, we find that increased\ndata density and advancements in artificial intelligence enable harmful group\nmembership inferences from supposedly anonymized data. We perform a penetration\ntest to demonstrate how easily sensitive group affiliations can be inferred\nfrom obfuscated pedestrians in 25,232,608 dashcam images taken in New York\nCity. We develop a typology of identifiable groups within DSI and analyze\nprivacy implications through the lens of contextual integrity. Finally, we\ndiscuss actionable recommendations for researchers working with data from DSI\nproviders.", "published": "2025-05-11 18:16:08", "link": "http://arxiv.org/abs/2505.07085v1", "categories": ["cs.CY", "cs.CV", "cs.ET"], "primary_category": "cs.CY"}
{"title": "Discovering Concept Directions from Diffusion-based Counterfactuals via Latent Clustering", "abstract": "Concept-based explanations have emerged as an effective approach within\nExplainable Artificial Intelligence, enabling interpretable insights by\naligning model decisions with human-understandable concepts. However, existing\nmethods rely on computationally intensive procedures and struggle to\nefficiently capture complex, semantic concepts. Recently, the Concept Discovery\nthrough Latent Diffusion-based Counterfactual Trajectories (CDCT) framework,\nintroduced by Varshney et al. (2025), attempts to identify concepts via\ndimension-wise traversal of the latent space of a Variational Autoencoder\ntrained on counterfactual trajectories. Extending the CDCT framework, this work\nintroduces Concept Directions via Latent Clustering (CDLC), which extracts\nglobal, class-specific concept directions by clustering latent difference\nvectors derived from factual and diffusion-generated counterfactual image\npairs. CDLC substantially reduces computational complexity by eliminating the\nexhaustive latent dimension traversal required in CDCT and enables the\nextraction of multidimensional semantic concepts encoded across the latent\ndimensions. This approach is validated on a real-world skin lesion dataset,\ndemonstrating that the extracted concept directions align with clinically\nrecognized dermoscopic features and, in some cases, reveal dataset-specific\nbiases or unknown biomarkers. These results highlight that CDLC is\ninterpretable, scalable, and applicable across high-stakes domains and diverse\ndata modalities.", "published": "2025-05-11 17:53:02", "link": "http://arxiv.org/abs/2505.07073v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Semantic-Guided Diffusion Model for Single-Step Image Super-Resolution", "abstract": "Diffusion-based image super-resolution (SR) methods have demonstrated\nremarkable performance. Recent advancements have introduced deterministic\nsampling processes that reduce inference from 15 iterative steps to a single\nstep, thereby significantly improving the inference speed of existing diffusion\nmodels. However, their efficiency remains limited when handling complex\nsemantic regions due to the single-step inference. To address this limitation,\nwe propose SAMSR, a semantic-guided diffusion framework that incorporates\nsemantic segmentation masks into the sampling process. Specifically, we\nintroduce the SAM-Noise Module, which refines Gaussian noise using segmentation\nmasks to preserve spatial and semantic features. Furthermore, we develop a\npixel-wise sampling strategy that dynamically adjusts the residual transfer\nrate and noise strength based on pixel-level semantic weights, prioritizing\nsemantically rich regions during the diffusion process. To enhance model\ntraining, we also propose a semantic consistency loss, which aligns pixel-wise\nsemantic weights between predictions and ground truth. Extensive experiments on\nboth real-world and synthetic datasets demonstrate that SAMSR significantly\nimproves perceptual quality and detail recovery, particularly in semantically\ncomplex images. Our code is released at https://github.com/Liu-Zihang/SAMSR.", "published": "2025-05-11 17:45:05", "link": "http://arxiv.org/abs/2505.07071v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models", "abstract": "Video generation based on diffusion models presents a challenging multimodal\ntask, with video editing emerging as a pivotal direction in this field. Recent\nvideo editing approaches primarily fall into two categories: training-required\nand training-free methods. While training-based methods incur high\ncomputational costs, training-free alternatives often yield suboptimal\nperformance. To address these limitations, we propose DAPE, a high-quality yet\ncost-effective two-stage parameter-efficient fine-tuning (PEFT) framework for\nvideo editing. In the first stage, we design an efficient norm-tuning method to\nenhance temporal consistency in generated videos. The second stage introduces a\nvision-friendly adapter to improve visual quality. Additionally, we identify\ncritical shortcomings in existing benchmarks, including limited category\ndiversity, imbalanced object distribution, and inconsistent frame counts. To\nmitigate these issues, we curate a large dataset benchmark comprising 232\nvideos with rich annotations and 6 editing prompts, enabling objective and\ncomprehensive evaluation of advanced methods. Extensive experiments on existing\ndatasets (BalanceCC, LOVEU-TGVE, RAVE) and our proposed benchmark demonstrate\nthat DAPE significantly improves temporal coherence and text-video alignment\nwhile outperforming previous state-of-the-art approaches.", "published": "2025-05-11 17:08:50", "link": "http://arxiv.org/abs/2505.07057v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Depth-Sensitive Soft Suppression with RGB-D Inter-Modal Stylization Flow for Domain Generalization Semantic Segmentation", "abstract": "Unsupervised Domain Adaptation (UDA) aims to align source and target domain\ndistributions to close the domain gap, but still struggles with obtaining the\ntarget data. Fortunately, Domain Generalization (DG) excels without the need\nfor any target data. Recent works expose that depth maps contribute to improved\ngeneralized performance in the UDA tasks, but they ignore the noise and holes\nin depth maps due to device and environmental factors, failing to sufficiently\nand effectively learn domain-invariant representation. Although\nhigh-sensitivity region suppression has shown promising results in learning\ndomain-invariant features, existing methods cannot be directly applicable to\ndepth maps due to their unique characteristics. Hence, we propose a novel\nframework, namely Depth-Sensitive Soft Suppression with RGB-D inter-modal\nstylization flow (DSSS), focusing on learning domain-invariant features from\ndepth maps for the DG semantic segmentation. Specifically, we propose the RGB-D\ninter-modal stylization flow to generate stylized depth maps for sensitivity\ndetection, cleverly utilizing RGB information as the stylization source. Then,\na class-wise soft spatial sensitivity suppression is designed to identify and\nemphasize non-sensitive depth features that contain more domain-invariant\ninformation. Furthermore, an RGB-D soft alignment loss is proposed to ensure\nthat the stylized depth maps only align part of the RGB features while still\nretaining the unique depth information. To our best knowledge, our DSSS\nframework is the first work to integrate RGB and Depth information in the\nmulti-class DG semantic segmentation task. Extensive experiments over multiple\nbackbone networks show that our framework achieves remarkable performance\nimprovement.", "published": "2025-05-11 16:47:42", "link": "http://arxiv.org/abs/2505.07050v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Differentiable NMS via Sinkhorn Matching for End-to-End Fabric Defect Detection", "abstract": "Fabric defect detection confronts two fundamental challenges. First,\nconventional non-maximum suppression disrupts gradient flow, which hinders\ngenuine end-to-end learning. Second, acquiring pixel-level annotations at\nindustrial scale is prohibitively costly. Addressing these limitations, we\npropose a differentiable NMS framework for fabric defect detection that\nachieves superior localization precision through end-to-end optimization. We\nreformulate NMS as a differentiable bipartite matching problem solved through\nthe Sinkhorn-Knopp algorithm, maintaining uninterrupted gradient flow\nthroughout the network. This approach specifically targets the irregular\nmorphologies and ambiguous boundaries of fabric defects by integrating proposal\nquality, feature similarity, and spatial relationships. Our entropy-constrained\nmask refinement mechanism further enhances localization precision through\nprincipled uncertainty modeling. Extensive experiments on the Tianchi fabric\ndefect dataset demonstrate significant performance improvements over existing\nmethods while maintaining real-time speeds suitable for industrial deployment.\nThe framework exhibits remarkable adaptability across different architectures\nand generalizes effectively to general object detection tasks.", "published": "2025-05-11 16:22:58", "link": "http://arxiv.org/abs/2505.07040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MarkMatch: Same-Hand Stuffing Detection", "abstract": "We present MarkMatch, a retrieval system for detecting whether two paper\nballot marks were filled by the same hand. Unlike the previous SOTA method\nBubbleSig, which used binary classification on isolated mark pairs, MarkMatch\nranks stylistic similarity between a query mark and a mark in the database\nusing contrastive learning. Our model is trained with a dense batch similarity\nmatrix and a dual loss objective. Each sample is contrasted against many\nnegatives within each batch, enabling the model to learn subtle handwriting\ndifference and improve generalization under handwriting variation and visual\nnoise, while diagonal supervision reinforces high confidence on true matches.\nThe model achieves an F1 score of 0.943, surpassing BubbleSig's best\nperformance. MarkMatch also integrates Segment Anything Model for flexible mark\nextraction via box- or point-based prompts. The system offers election auditors\na practical tool for visual, non-biometric investigation of suspicious ballots.", "published": "2025-05-11 16:05:07", "link": "http://arxiv.org/abs/2505.07032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Vision-Language Foundation Model for Leaf Disease Identification", "abstract": "Leaf disease identification plays a pivotal role in smart agriculture.\nHowever, many existing studies still struggle to integrate image and textual\nmodalities to compensate for each other's limitations. Furthermore, many of\nthese approaches rely on pretraining with constrained datasets such as\nImageNet, which lack domain-specific information. We propose SCOLD (Soft-target\nCOntrastive learning for Leaf Disease identification), a context-aware\nvision-language foundation model tailored to address these challenges for\nagricultural tasks. SCOLD is developed using a diverse corpus of plant leaf\nimages and corresponding symptom descriptions, comprising over 186,000\nimage-caption pairs aligned with 97 unique concepts. Through task-agnostic\npretraining, SCOLD leverages contextual soft targets to mitigate overconfidence\nin contrastive learning by smoothing labels, thereby improving model\ngeneralization and robustness on fine-grained classification tasks.\nExperimental results demonstrate that SCOLD outperforms existing\nvision-language models such as OpenAI-CLIP-L, BioCLIP, and SigLIP2 across\nseveral benchmarks, including zero-shot and few-shot classification, image-text\nretrieval, and image classification, while maintaining a competitive parameter\nfootprint. Ablation studies further highlight SCOLD's effectiveness in contrast\nto its counterparts. The proposed approach significantly advances the\nagricultural vision-language foundation model, offering strong performance with\nminimal or no supervised fine-tuning. This work lays a solid groundwork for\nfuture research on models trained with long-form and simplified contexts, tasks\ninvolving class ambiguity, and multi-modal systems for intelligent plant\ndisease diagnostics. The code for this study is available at\nhttps://huggingface.co/enalis/scold", "published": "2025-05-11 15:30:06", "link": "http://arxiv.org/abs/2505.07019v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization", "abstract": "Remote physiological sensing using camera-based technologies offers\ntransformative potential for non-invasive vital sign monitoring across\nhealthcare and human-computer interaction domains. Although deep learning\napproaches have advanced the extraction of physiological signals from video\ndata, existing methods have not been sufficiently assessed for their robustness\nto domain shifts. These shifts in remote physiological sensing include\nvariations in ambient conditions, camera specifications, head movements, facial\nposes, and physiological states which often impact real-world performance\nsignificantly. Cross-dataset evaluation provides an objective measure to assess\ngeneralization capabilities across these domain shifts. We introduce Target\nSignal Constrained Factorization module (TSFM), a novel multidimensional\nattention mechanism that explicitly incorporates physiological signal\ncharacteristics as factorization constraints, allowing more precise feature\nextraction. Building on this innovation, we present MMRPhys, an efficient\ndual-branch 3D-CNN architecture designed for simultaneous multitask estimation\nof photoplethysmography (rPPG) and respiratory (rRSP) signals from multimodal\nRGB and thermal video inputs. Through comprehensive cross-dataset evaluation on\nfive benchmark datasets, we demonstrate that MMRPhys with TSFM significantly\noutperforms state-of-the-art methods in generalization across domain shifts for\nrPPG and rRSP estimation, while maintaining a minimal inference latency\nsuitable for real-time applications. Our approach establishes new benchmarks\nfor robust multitask and multimodal physiological sensing and offers a\ncomputationally efficient framework for practical deployment in unconstrained\nenvironments. The web browser-based application featuring on-device real-time\ninference of MMRPhys model is available at\nhttps://physiologicailab.github.io/mmrphys-live", "published": "2025-05-11 15:20:45", "link": "http://arxiv.org/abs/2505.07013v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception", "abstract": "Micro-expressions (MEs) are crucial psychological responses with significant\npotential for affective computing. However, current automatic micro-expression\nrecognition (MER) research primarily focuses on discrete emotion\nclassification, neglecting a convincing analysis of the subtle dynamic\nmovements and inherent emotional cues. The rapid progress in multimodal large\nlanguage models (MLLMs), known for their strong multimodal comprehension and\nlanguage generation abilities, offers new possibilities. MLLMs have shown\nsuccess in various vision-language tasks, indicating their potential to\nunderstand MEs comprehensively, including both fine-grained motion patterns and\nunderlying emotional semantics. Nevertheless, challenges remain due to the\nsubtle intensity and short duration of MEs, as existing MLLMs are not designed\nto capture such delicate frame-level facial dynamics. In this paper, we propose\na novel Micro-Expression Large Language Model (MELLM), which incorporates a\nsubtle facial motion perception strategy with the strong inference capabilities\nof MLLMs, representing the first exploration of MLLMs in the domain of ME\nanalysis. Specifically, to explicitly guide the MLLM toward motion-sensitive\nregions, we construct an interpretable motion-enhanced color map by fusing\nonset-apex optical flow dynamics with the corresponding grayscale onset frame\nas the model input. Additionally, specialized fine-tuning strategies are\nincorporated to further enhance the model's visual perception of MEs.\nFurthermore, we construct an instruction-description dataset based on Facial\nAction Coding System (FACS) annotations and emotion labels to train our MELLM.\nComprehensive evaluations across multiple benchmark datasets demonstrate that\nour model exhibits superior robustness and generalization capabilities in ME\nunderstanding (MEU). Code is available at https://github.com/zyzhangUstc/MELLM.", "published": "2025-05-11 15:08:23", "link": "http://arxiv.org/abs/2505.07007v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation", "abstract": "Recently, 3D generation methods have shown their powerful ability to automate\n3D model creation. However, most 3D generation methods only rely on an input\nimage or a text prompt to generate a 3D model, which lacks the control of each\ncomponent of the generated 3D model. Any modifications of the input image lead\nto an entire regeneration of the 3D models. In this paper, we introduce a new\nmethod called CMD that generates a 3D model from an input image while enabling\nflexible local editing of each component of the 3D model. In CMD, we formulate\nthe 3D generation as a conditional multiview diffusion model, which takes the\nexisting or known parts as conditions and generates the edited or added\ncomponents. This conditional multiview diffusion model not only allows the\ngeneration of 3D models part by part but also enables local editing of 3D\nmodels according to the local revision of the input image without changing\nother 3D parts. Extensive experiments are conducted to demonstrate that CMD\ndecomposes a complex 3D generation task into multiple components, improving the\ngeneration quality. Meanwhile, CMD enables efficient and flexible local editing\nof a 3D model by just editing one rendered image.", "published": "2025-05-11 14:54:26", "link": "http://arxiv.org/abs/2505.07003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models", "abstract": "Vision-Language Models (VLMs) are becoming increasingly popular in the\nmedical domain, bridging the gap between medical images and clinical language.\nExisting VLMs demonstrate an impressive ability to comprehend medical images\nand text queries to generate detailed, descriptive diagnostic medical reports.\nHowever, hallucination--the tendency to generate descriptions that are\ninconsistent with the visual content--remains a significant issue in VLMs, with\nparticularly severe implications in the medical field. To facilitate VLM\nresearch on gastrointestinal (GI) image analysis and study hallucination, we\ncurate a multimodal image-text GI dataset: Gut-VLM. This dataset is created\nusing a two-stage pipeline: first, descriptive medical reports of Kvasir-v2\nimages are generated using ChatGPT, which introduces some hallucinated or\nincorrect texts. In the second stage, medical experts systematically review\nthese reports, and identify and correct potential inaccuracies to ensure\nhigh-quality, clinically reliable annotations. Unlike traditional datasets that\ncontain only descriptive texts, our dataset also features tags identifying\nhallucinated sentences and their corresponding corrections. A common approach\nto reducing hallucination in VLM is to finetune the model on a small-scale,\nproblem-specific dataset. However, we take a different strategy using our\ndataset. Instead of finetuning the VLM solely for generating textual reports,\nwe finetune it to detect and correct hallucinations, an approach we call\nhallucination-aware finetuning. Our results show that this approach is better\nthan simply finetuning for descriptive report generation. Additionally, we\nconduct an extensive evaluation of state-of-the-art VLMs across several\nmetrics, establishing a benchmark. GitHub Repo:\nhttps://github.com/bhattarailab/Hallucination-Aware-VLM.", "published": "2025-05-11 14:54:11", "link": "http://arxiv.org/abs/2505.07001v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Replay-Based Continual Learning with Dual-Layered Distillation and a Streamlined U-Net for Efficient Text-to-Image Generation", "abstract": "Recent advancements in text-to-image diffusion models are hindered by high\ncomputational demands, limiting accessibility and scalability. This paper\nintroduces KDC-Diff, a novel stable diffusion framework that enhances\nefficiency while maintaining image quality. KDC-Diff features a streamlined\nU-Net architecture with nearly half the parameters of the original U-Net\n(482M), significantly reducing model complexity. We propose a dual-layered\ndistillation strategy to ensure high-fidelity generation, transferring semantic\nand structural insights from a teacher to a compact student model while\nminimizing quality degradation. Additionally, replay-based continual learning\nis integrated to mitigate catastrophic forgetting, allowing the model to retain\nprior knowledge while adapting to new data. Despite operating under extremely\nlow computational resources, KDC-Diff achieves state-of-the-art performance on\nthe Oxford Flowers and Butterflies & Moths 100 Species datasets, demonstrating\ncompetitive metrics such as FID, CLIP, and LPIPS. Moreover, it significantly\nreduces inference time compared to existing models. These results establish\nKDC-Diff as a highly efficient and adaptable solution for text-to-image\ngeneration, particularly in computationally constrained environments.", "published": "2025-05-11 14:40:51", "link": "http://arxiv.org/abs/2505.06995v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Leveraging Color Shift Correction, RoPE-Swin Backbone, and Quantile-based Label Denoising Strategy for Robust Outdoor Scene Understanding", "abstract": "This report presents our semantic segmentation framework developed by team\nACVLAB for the ICRA 2025 GOOSE 2D Semantic Segmentation Challenge, which\nfocuses on parsing outdoor scenes into nine semantic categories under\nreal-world conditions. Our method integrates a Swin Transformer backbone\nenhanced with Rotary Position Embedding (RoPE) for improved spatial\ngeneralization, alongside a Color Shift Estimation-and-Correction module\ndesigned to compensate for illumination inconsistencies in natural\nenvironments. To further improve training stability, we adopt a quantile-based\ndenoising strategy that downweights the top 2.5\\% of highest-error pixels,\ntreating them as noise and suppressing their influence during optimization.\nEvaluated on the official GOOSE test set, our approach achieved a mean\nIntersection over Union (mIoU) of 0.848, demonstrating the effectiveness of\ncombining color correction, positional encoding, and error-aware denoising in\nrobust semantic segmentation.", "published": "2025-05-11 14:35:06", "link": "http://arxiv.org/abs/2505.06991v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BridgeIV: Bridging Customized Image and Video Generation through Test-Time Autoregressive Identity Propagation", "abstract": "Both zero-shot and tuning-based customized text-to-image (CT2I) generation\nhave made significant progress for storytelling content creation. In contrast,\nresearch on customized text-to-video (CT2V) generation remains relatively\nlimited. Existing zero-shot CT2V methods suffer from poor generalization, while\nanother line of work directly combining tuning-based T2I models with temporal\nmotion modules often leads to the loss of structural and texture information.\nTo bridge this gap, we propose an autoregressive structure and texture\npropagation module (STPM), which extracts key structural and texture features\nfrom the reference subject and injects them autoregressively into each video\nframe to enhance consistency. Additionally, we introduce a test-time reward\noptimization (TTRO) method to further refine fine-grained details. Quantitative\nand qualitative experiments validate the effectiveness of STPM and TTRO,\ndemonstrating improvements of 7.8 and 13.1 in CLIP-I and DINO consistency\nmetrics over the baseline, respectively.", "published": "2025-05-11 14:11:12", "link": "http://arxiv.org/abs/2505.06985v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Federated Learning with LoRA Optimized DeiT and Multiscale Patch Embedding for Secure Eye Disease Recognition", "abstract": "Recent progress in image-based medical disease detection encounters\nchallenges such as limited annotated data sets, inadequate spatial feature\nanalysis, data security issues, and inefficient training frameworks. This study\nintroduces a data-efficient image transformer (DeIT)-based approach that\novercomes these challenges by utilizing multiscale patch embedding for better\nfeature extraction and stratified weighted random sampling to address class\nimbalance. The model also incorporates a LoRA-enhanced transformer encoder, a\ndistillation framework, and federated learning for decentralized training,\nimproving both efficiency and data security. Consequently, it achieves\nstate-of-the-art performance, with the highest AUC, F1 score, precision,\nminimal loss, and Top-5 accuracy. Additionally, Grad-CAM++ visualizations\nimprove interpretability by highlighting critical pathological regions,\nenhancing the model's clinical relevance. These results highlight the potential\nof this approach to advance AI-powered medical imaging and disease detection.", "published": "2025-05-11 13:51:56", "link": "http://arxiv.org/abs/2505.06982v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving", "abstract": "Perception is a core capability of automated vehicles and has been\nsignificantly advanced through modern sensor technologies and artificial\nintelligence. However, perception systems still face challenges in complex\nreal-world scenarios. To improve robustness against various external factors,\nmulti-sensor fusion techniques are essential, combining the strengths of\ndifferent sensor modalities. With recent developments in Vehicle-to-Everything\n(V2X communication, sensor fusion can now extend beyond a single vehicle to a\ncooperative multi-agent system involving Connected Automated Vehicle (CAV) and\nintelligent infrastructure. This paper presents VALISENS, an innovative\nmulti-sensor system distributed across multiple agents. It integrates onboard\nand roadside LiDARs, radars, thermal cameras, and RGB cameras to enhance\nsituational awareness and support cooperative automated driving. The thermal\ncamera adds critical redundancy for perceiving Vulnerable Road User (VRU),\nwhile fusion with roadside sensors mitigates visual occlusions and extends the\nperception range beyond the limits of individual vehicles. We introduce the\ncorresponding perception module built on this sensor system, which includes\nobject detection, tracking, motion forecasting, and high-level data fusion. The\nproposed system demonstrates the potential of cooperative perception in\nreal-world test environments and lays the groundwork for future Cooperative\nIntelligent Transport Systems (C-ITS) applications.", "published": "2025-05-11 13:41:37", "link": "http://arxiv.org/abs/2505.06980v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "High-Frequency Prior-Driven Adaptive Masking for Accelerating Image Super-Resolution", "abstract": "The primary challenge in accelerating image super-resolution lies in reducing\ncomputation while maintaining performance and adaptability. Motivated by the\nobservation that high-frequency regions (e.g., edges and textures) are most\ncritical for reconstruction, we propose a training-free adaptive masking module\nfor acceleration that dynamically focuses computation on these challenging\nareas. Specifically, our method first extracts high-frequency components via\nGaussian blur subtraction and adaptively generates binary masks using K-means\nclustering to identify regions requiring intensive processing. Our method can\nbe easily integrated with both CNNs and Transformers. For CNN-based\narchitectures, we replace standard $3 \\times 3$ convolutions with an unfold\noperation followed by $1 \\times 1$ convolutions, enabling pixel-wise sparse\ncomputation guided by the mask. For Transformer-based models, we partition the\nmask into non-overlapping windows and selectively process tokens based on their\naverage values. During inference, unnecessary pixels or windows are pruned,\nsignificantly reducing computation. Moreover, our method supports\ndilation-based mask adjustment to control the processing scope without\nretraining, and is robust to unseen degradations (e.g., noise, compression).\nExtensive experiments on benchmarks demonstrate that our method reduces FLOPs\nby 24--43% for state-of-the-art models (e.g., CARN, SwinIR) while achieving\ncomparable or better quantitative metrics. The source code is available at\nhttps://github.com/shangwei5/AMSR", "published": "2025-05-11 13:18:03", "link": "http://arxiv.org/abs/2505.06975v1", "categories": ["cs.CV", "I.4.3"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning-Based Monocular Vision Approach for Autonomous UAV Landing", "abstract": "This paper introduces an innovative approach for the autonomous landing of\nUnmanned Aerial Vehicles (UAVs) using only a front-facing monocular camera,\ntherefore obviating the requirement for depth estimation cameras. Drawing on\nthe inherent human estimating process, the proposed method reframes the landing\ntask as an optimization problem. The UAV employs variations in the visual\ncharacteristics of a specially designed lenticular circle on the landing pad,\nwhere the perceived color and form provide critical information for estimating\nboth altitude and depth. Reinforcement learning algorithms are utilized to\napproximate the functions governing these estimations, enabling the UAV to\nascertain ideal landing settings via training. This method's efficacy is\nassessed by simulations and experiments, showcasing its potential for robust\nand accurate autonomous landing without dependence on complex sensor setups.\nThis research contributes to the advancement of cost-effective and efficient\nUAV landing solutions, paving the way for wider applicability across various\nfields.", "published": "2025-05-11 12:23:37", "link": "http://arxiv.org/abs/2505.06963v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Boosting Cross-spectral Unsupervised Domain Adaptation for Thermal Semantic Segmentation", "abstract": "In autonomous driving, thermal image semantic segmentation has emerged as a\ncritical research area, owing to its ability to provide robust scene\nunderstanding under adverse visual conditions. In particular, unsupervised\ndomain adaptation (UDA) for thermal image segmentation can be an efficient\nsolution to address the lack of labeled thermal datasets. Nevertheless, since\nthese methods do not effectively utilize the complementary information between\nRGB and thermal images, they significantly decrease performance during domain\nadaptation. In this paper, we present a comprehensive study on cross-spectral\nUDA for thermal image semantic segmentation. We first propose a novel masked\nmutual learning strategy that promotes complementary information exchange by\nselectively transferring results between each spectral model while masking out\nuncertain regions. Additionally, we introduce a novel prototypical\nself-supervised loss designed to enhance the performance of the thermal\nsegmentation model in nighttime scenarios. This approach addresses the\nlimitations of RGB pre-trained networks, which cannot effectively transfer\nknowledge under low illumination due to the inherent constraints of RGB\nsensors. In experiments, our method achieves higher performance over previous\nUDA methods and comparable performance to state-of-the-art supervised methods.", "published": "2025-05-11 11:45:44", "link": "http://arxiv.org/abs/2505.06951v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Unsupervised Learning for Class Distribution Mismatch", "abstract": "Class distribution mismatch (CDM) refers to the discrepancy between class\ndistributions in training data and target tasks. Previous methods address this\nby designing classifiers to categorize classes known during training, while\ngrouping unknown or new classes into an \"other\" category. However, they focus\non semi-supervised scenarios and heavily rely on labeled data, limiting their\napplicability and performance. To address this, we propose Unsupervised\nLearning for Class Distribution Mismatch (UCDM), which constructs\npositive-negative pairs from unlabeled data for classifier training. Our\napproach randomly samples images and uses a diffusion model to add or erase\nsemantic classes, synthesizing diverse training pairs. Additionally, we\nintroduce a confidence-based labeling mechanism that iteratively assigns\npseudo-labels to valuable real-world data and incorporates them into the\ntraining process. Extensive experiments on three datasets demonstrate UCDM's\nsuperiority over previous semi-supervised methods. Specifically, with a 60%\nmismatch proportion on Tiny-ImageNet dataset, our approach, without relying on\nlabeled data, surpasses OpenMatch (with 40 labels per class) by 35.1%, 63.7%,\nand 72.5% in classifying known, unknown, and new classes.", "published": "2025-05-11 11:29:48", "link": "http://arxiv.org/abs/2505.06948v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models", "abstract": "Ensuring the products displayed in e-commerce search results are relevant to\nusers queries is crucial for improving the user experience. With their advanced\nsemantic understanding, deep learning models have been widely used for\nrelevance matching in search tasks. While large language models (LLMs) offer\nsuperior ranking capabilities, it is challenging to deploy LLMs in real-time\nsystems due to the high-latency requirements. To leverage the ranking power of\nLLMs while meeting the low-latency demands of production systems, we propose a\nnovel framework that distills a high performing LLM into a more efficient,\nlow-latency student model. To help the student model learn more effectively\nfrom the teacher model, we first train the teacher LLM as a classification\nmodel with soft targets. Then, we train the student model to capture the\nrelevance margin between pairs of products for a given query using mean squared\nerror loss. Instead of using the same training data as the teacher model, we\nsignificantly expand the student model dataset by generating unlabeled data and\nlabeling it with the teacher model predictions. Experimental results show that\nthe student model performance continues to improve as the size of the augmented\ntraining data increases. In fact, with enough augmented data, the student model\ncan outperform the teacher model. The student model has been successfully\ndeployed in production at Walmart.com with significantly positive metrics.", "published": "2025-05-11 20:00:00", "link": "http://arxiv.org/abs/2505.07105v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Reinforcement Learning Framework for Application-Specific TCP Congestion-Control", "abstract": "The Congestion Control (CC) module plays a critical role in the Transmission\nControl Protocol (TCP), ensuring the stability and efficiency of network data\ntransmission. The CC approaches that are commonly used these days employ\nheuristics-based rules to adjust the sending rate. Due to their\nheuristics-based nature, these approaches are not only unable to adapt to\nchanging network conditions but are also agnostic to the diverse requirements\nthat different applications often have. Recently, several learning-based CC\napproaches have been proposed to adapt to changing network conditions.\nUnfortunately, they are not designed to take application requirements into\naccount. Prior heuristics-based as well as learning-based CC approaches focus\non achieving a singular objective, which is often to maximize throughput, even\nthough a lot of applications care more about latency, packet losses, jitter,\nand different combinations of various network metrics. Motivated by this, we\npropose a Deep Reinforcement Learning (DRL) based CC framework, namely ASC,\nwhich allows any application to specify any arbitrary objectives that the\nnetwork traffic of that application should achieve and is able to swiftly adapt\nto the changes in the objectives of the applications as well as to the changes\nin the network conditions. Our ASC framework further employs a client-server\narchitecture that serves two purposes: 1) it makes ASC highly scalable in terms\nof the arrival and departure of TCP connections, and 2) it makes ASC very\nlightweight for the nodes maintaining the TCP connections. We implemented and\nextensively evaluated ASC in a variety of settings. Our results show that it\ncan not only achieve various objectives but also outperforms prior approaches\neven in the specific objectives that those approaches were designed to achieve.", "published": "2025-05-11 16:27:19", "link": "http://arxiv.org/abs/2505.07042v1", "categories": ["cs.NI", "cs.IR"], "primary_category": "cs.NI"}
{"title": "NetSight: Graph Attention Based Traffic Forecasting in Computer Networks", "abstract": "The traffic in today's networks is increasingly influenced by the\ninteractions among network nodes as well as by the temporal fluctuations in the\ndemands of the nodes. Traditional statistical prediction methods are becoming\nobsolete due to their inability to address the non-linear and dynamic\nspatio-temporal dependencies present in today's network traffic. The most\npromising direction of research today is graph neural networks (GNNs) based\nprediction approaches that are naturally suited to handle graph-structured\ndata. Unfortunately, the state-of-the-art GNN approaches separate the modeling\nof spatial and temporal information, resulting in the loss of important\ninformation about joint dependencies. These GNN based approaches further do not\nmodel information at both local and global scales simultaneously, leaving\nsignificant room for improvement. To address these challenges, we propose\nNetSight. NetSight learns joint spatio-temporal dependencies simultaneously at\nboth global and local scales from the time-series of measurements of any given\nnetwork metric collected at various nodes in a network. Using the learned\ninformation, NetSight can then accurately predict the future values of the\ngiven network metric at those nodes in the network. We propose several new\nconcepts and techniques in the design of NetSight, such as spatio-temporal\nadjacency matrix and node normalization. Through extensive evaluations and\ncomparison with prior approaches using data from two large real-world networks,\nwe show that NetSight significantly outperforms all prior state-of-the-art\napproaches. We will release the source code and data used in the evaluation of\nNetSight on the acceptance of this paper.", "published": "2025-05-11 16:10:37", "link": "http://arxiv.org/abs/2505.07034v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Incremental Analysis of Legacy Applications Using Knowledge Graphs for Application Modernization", "abstract": "Industries such as banking, telecom, and airlines - o6en have large so6ware\nsystems that are several decades old. Many of these systems are written in old\nprogramming languages such as COBOL, PL/1, Assembler, etc. In many cases, the\ndocumentation is not updated, and those who developed/designed these systems\nare no longer around. Understanding these systems for either modernization or\neven regular maintenance has been a challenge. An extensive application may\nhave natural boundaries based on its code dependencies and architecture. There\nare also other logical boundaries in an enterprise setting driven by business\nfunctions, data domains, etc. Due to these complications, the system architects\ngenerally plan their modernization across these logical boundaries in parts,\nthereby adopting an incremental approach for the modernization journey of the\nentire system. In this work, we present a so6ware system analysis tool that\nallows a subject ma=er expert (SME) or system architect to analyze a large\nso6ware system incrementally. We analyze the source code and other artifacts\n(such as data schema) to create a knowledge graph using a customizable\nontology/schema. Entities and relations in our ontology can be defined for any\ncombination of programming languages and platforms. Using this knowledge graph,\nthe analyst can then define logical boundaries around dependent Entities (e.g.\nPrograms, Transactions, Database Tables etc.). Our tool then presents different\nviews showcasing the dependencies from the newly defined boundary to/from the\nother logical groups of the system. This exercise is repeated interactively to\n1) Identify the Entities and groupings of interest for a modernization task and\n2) Understand how a change in one part of the system may affect the other\nparts. To validate the efficacy of our tool, we provide an initial study of our\nsystem on two client applications.", "published": "2025-05-11 07:33:31", "link": "http://arxiv.org/abs/2505.06885v1", "categories": ["cs.SE", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Optimizing Recommendations using Fine-Tuned LLMs", "abstract": "As digital media platforms strive to meet evolving user expectations,\ndelivering highly personalized and intuitive movies and media recommendations\nhas become essential for attracting and retaining audiences. Traditional\nsystems often rely on keyword-based search and recommendation techniques, which\nlimit users to specific keywords and a combination of keywords. This paper\nproposes an approach that generates synthetic datasets by modeling real-world\nuser interactions, creating complex chat-style data reflective of diverse\npreferences. This allows users to express more information with complex\npreferences, such as mood, plot details, and thematic elements, in addition to\nconventional criteria like genre, title, and actor-based searches. In today's\nsearch space, users cannot write queries like ``Looking for a fantasy movie\nfeaturing dire wolves, ideally set in a harsh frozen world with themes of\nloyalty and survival.''\n  Building on these contributions, we evaluate synthetic datasets for diversity\nand effectiveness in training and benchmarking models, particularly in areas\noften absent from traditional datasets. This approach enhances personalization\nand accuracy by enabling expressive and natural user queries. It establishes a\nfoundation for the next generation of conversational AI-driven search and\nrecommendation systems in digital entertainment.", "published": "2025-05-11 04:53:34", "link": "http://arxiv.org/abs/2505.06841v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Minimal Linear Codes Violating the Ashikhmin-Barg Condition from Arbitrary Projective Linear Codes", "abstract": "In recent years, there have been many constructions of minimal linear codes\nviolating the Ashikhmin-Barg condition from Boolean functions, linear codes\nwith few nonzero weights or partial difference sets. In this paper, we first\ngive a general method to transform a minimal code satisfying the Ashikhmin-Barg\ncondition to a minimal code violating the Ashikhmin-Barg condition. Then we\ngive a construction of a minimal code satisfying the Ashikhmin-Barg condition\nfrom an arbitrary projective linear code. Hence an arbitrary projective linear\ncode can be transformed to a minimal codes violating the Ashikhmin-Barg\ncondition. Then we give infinite many families of minimal codes violating the\nAshikhamin-Barg condition. Weight distributions of constructed minimal codes\nviolating the Ashikhmin-Barg condition in this paper are determined. Many\nminimal linear codes violating the Ashikhmin-Barg condition with their minimum\nweights close to the optimal or the best known minimum weights of linear codes\nare constructed in this paper. Moreover, many infinite families of\nself-orthogonal binary minimal codes violating the Ashikhmin-Barg condition are\nalso given.", "published": "2025-05-11 22:02:40", "link": "http://arxiv.org/abs/2505.07130v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust Movable-Antenna Position Optimization with Imperfect CSI for MISO Systems", "abstract": "Movable antenna (MA) technology has emerged as a promising solution for\nreconfiguring wireless channel conditions through local antenna movement within\nconfined regions. Unlike previous works assuming perfect channel state\ninformation (CSI), this letter addresses the robust MA position optimization\nproblem under imperfect CSI conditions for a multiple-input single-output\n(MISO) MA system. Specifically, we consider two types of CSI errors:\nnorm-bounded and randomly distributed errors, aiming to maximize the worst-case\nand non-outage received signal power, respectively. For norm-bounded CSI\nerrors, we derive the worst-case received signal power in closed-form. For\nrandomly distributed CSI errors, due to the intractability of the probabilistic\nconstraints, we apply the Bernstein-type inequality to obtain a closed-form\nlower bound for the non-outage received signal power. Based on these results,\nwe show the optimality of the maximum-ratio transmission for imperfect CSI in\nboth scenarios and employ a graph-based algorithm to obtain the optimal MA\npositions. Numerical results show that our proposed scheme can even outperform\nother benchmark schemes implemented under perfect CSI conditions.", "published": "2025-05-11 16:13:28", "link": "http://arxiv.org/abs/2505.07035v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-Terminal Remote Generation and Estimation Over a Broadcast Channel With Correlated Priors", "abstract": "We study the multi-terminal remote estimation problem under a rate\nconstraint, in which the goal of the encoder is to help each decoder estimate a\nfunction over a certain distribution -- while the distribution is known only to\nthe encoder, the function to be estimated is known only to the decoders, and\ncan also be different for each decoder. The decoders can observe correlated\nsamples from prior distributions, instantiated through shared randomness with\nthe encoder. To achieve this, we employ remote generation, where the encoder\nhelps decoders generate samples from the underlying distribution by using the\nsamples from the prior through importance sampling. While methods such as\nminimal random coding can be used to efficiently transmit samples to each\ndecoder individually using their importance scores, it is unknown if the\ncorrelation among the samples from the priors can reduce the communication cost\nusing the availability of a broadcast link. We propose a hierarchical\nimportance sampling strategy that facilitates, in the case of non-zero\nG\\'acs-K\\\"orner common information among the priors of the decoders, a common\nsampling step leveraging the availability of a broadcast channel. This is\nfollowed by a refinement step for the individual decoders. We present upper\nbounds on the bias and the estimation error for unicast transmission, which is\nof independent interest. We then introduce a method that splits into two\nphases, dedicated to broadcast and unicast transmission, respectively, and show\nthe reduction in communication cost.", "published": "2025-05-11 15:22:29", "link": "http://arxiv.org/abs/2505.07016v1", "categories": ["cs.IT", "math.IT", "math.ST", "stat.TH"], "primary_category": "cs.IT"}
{"title": "Source Anonymity for Private Random Walk Decentralized Learning", "abstract": "This paper considers random walk-based decentralized learning, where at each\niteration of the learning process, one user updates the model and sends it to a\nrandomly chosen neighbor until a convergence criterion is met. Preserving data\nprivacy is a central concern and open problem in decentralized learning. We\npropose a privacy-preserving algorithm based on public-key cryptography and\nanonymization. In this algorithm, the user updates the model and encrypts the\nresult using a distant user's public key. The encrypted result is then\ntransmitted through the network with the goal of reaching that specific user.\nThe key idea is to hide the source's identity so that, when the destination\nuser decrypts the result, it does not know who the source was. The challenge is\nto design a network-dependent probability distribution (at the source) over the\npotential destinations such that, from the receiver's perspective, all users\nhave a similar likelihood of being the source. We introduce the problem and\nconstruct a scheme that provides anonymity with theoretical guarantees. We\nfocus on random regular graphs to establish rigorous guarantees.", "published": "2025-05-11 15:13:34", "link": "http://arxiv.org/abs/2505.07011v1", "categories": ["cs.CR", "cs.DC", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Radio Map-Enabled 3D Trajectory and Communication Optimization for Low-Altitude Air-Ground Cooperation", "abstract": "Low-altitude economy includes the application of unmanned aerial vehicles\n(UAVs) serving ground robots. This paper investigates the 3-dimensional (3D)\ntrajectory and communication optimization for low-altitude air-ground\ncooperation systems, where mobile unmanned ground vehicles (UGVs) upload data\nto UAVs. We propose a joint optimization algorithm to maximize the minimal\nsum-rate of UGVs while ensuring quality of service and navigation constraints.\nThe proposed algorithm integrates a successive convex approximation\n(SCA)-penalty method for UGV-UAV scheduling, an SCA-based approach for UGV\ntransmit power control, and a novel warm-start particle swarm optimization with\ncross mutation (WS-PSO-CM). The WS-PSO-CM leverages convex optimization results\nfrom a statistical channel model to initialize particle swarm, significantly\nimproving the performance, compared with celebrated PSO-CM. Simulation results\ndemonstrate that the proposed algorithm achieves a $45.8$\\% higher minimal\nsum-rate compared to the baseline PSO-CM under the same iterations. This gain\ncan be translated to reducing computational time by $46.7$\\% of PSO-CM.\nFurthermore, our simulation results reveal that UAVs dynamically adjust\ntrajectories to avoid interference by buildings, and maintain proximity to UGVs\nto mitigate path-loss.", "published": "2025-05-11 11:18:22", "link": "http://arxiv.org/abs/2505.06944v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Near-Field Channel Estimation for XL-MIMO: A Deep Generative Model Guided by Side Information", "abstract": "This paper investigates the near-field (NF) channel estimation (CE) for\nextremely large-scale multiple-input multiple-output (XL-MIMO) systems.\nConsidering the pronounced NF effects in XL-MIMO communications, we first\nestablish a joint angle-distance (AD) domain-based spherical-wavefront physical\nchannel model that captures the inherent sparsity of XL-MIMO channels.\nLeveraging the channel's sparsity in the joint AD domain, the CE is approached\nas a task of reconstructing sparse signals. Anchored in this framework, we\nfirst propose a compressed sensing algorithm to acquire a preliminary channel\nestimate. Harnessing the powerful implicit prior learning capability of\ngenerative artificial intelligence (GenAI), we further propose a GenAI-based\napproach to refine the estimated channel. Specifically, we introduce the\npreliminary estimated channel as side information, and derive the evidence\nlower bound (ELBO) of the log-marginal distribution of the target NF channel\nconditioned on the preliminary estimated channel, which serves as the\noptimization objective for the proposed generative diffusion model (GDM).\nAdditionally, we introduce a more generalized version of the GDM, the\nnon-Markovian GDM (NM-GDM), to accelerate the sampling process, achieving an\napproximately tenfold enhancement in sampling efficiency. Experimental results\nindicate that the proposed approach is capable of offering substantial\nperformance gain in CE compared to existing benchmark schemes within NF XL-MIMO\nsystems. Furthermore, our approach exhibits enhanced generalization\ncapabilities in both the NF or far-field (FF) regions.", "published": "2025-05-11 08:35:36", "link": "http://arxiv.org/abs/2505.06900v1", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.SP"}
{"title": "Rate-Matching Deep Polar Codes via Polar Coded Extension", "abstract": "Deep polar codes are pre-transformed polar codes that employ a multi-layered\npolar kernel transformation strategy to enhance code performance in short\nblocklength regimes. However, like conventional polar codes, their block length\nis constrained to powers of two, as the final transformation layer uses a\nconventional polar kernel matrix. This paper introduces a novel rate-matching\ntechnique for deep polar codes using code extension, particularly effective\nwhen the desired code length slightly exceeds a power of two. The key idea is\nto exploit the layered structure of deep polar codes by concatenating polar\ncodewords generated at each transformation layer. Based on this structure, we\nalso develop an efficient decoding algorithm leveraging soft-output successive\ncancellation list decoding and provide comprehensive error probability analysis\nsupporting our code design algorithms. Additionally, we propose a\ncomputationally efficient greedy algorithm for multi-layer configurations.\nExtensive simulations confirm that our approach delivers substantial coding\ngains over conventional rate-matching methods, especially in medium to high\ncode-rate regimes.", "published": "2025-05-11 06:32:29", "link": "http://arxiv.org/abs/2505.06867v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation", "abstract": "Traditional machine learning (ML) raises serious privacy concerns, while\nfederated learning (FL) mitigates the risk of data leakage by keeping data on\nlocal devices. However, the training process of FL can still leak sensitive\ninformation, which adversaries may exploit to infer private data. One of the\nmost prominent threats is the membership inference attack (MIA), where the\nadversary aims to determine whether a particular data record was part of the\ntraining set.\n  This paper addresses this problem through a two-stage defense called\nAugMixCloak. The core idea is to apply data augmentation and principal\ncomponent analysis (PCA)-based information fusion to query images, which are\ndetected by perceptual hashing (pHash) as either identical to or highly similar\nto images in the training set. Experimental results show that AugMixCloak\nsuccessfully defends against both binary classifier-based MIA and metric-based\nMIA across five datasets and various decentralized FL (DFL) topologies.\nCompared with regularization-based defenses, AugMixCloak demonstrates stronger\nprotection. Compared with confidence score masking, AugMixCloak exhibits better\ngeneralization.", "published": "2025-05-11 23:38:44", "link": "http://arxiv.org/abs/2505.07149v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Triangulating PL functions and the existence of efficient ReLU DNNs", "abstract": "We show that every piecewise linear function $f:R^d \\to R$ with compact\nsupport a polyhedron $P$ has a representation as a sum of so-called `simplex\nfunctions'. Such representations arise from degree 1 triangulations of the\nrelative homology class (in $R^{d+1}$) bounded by $P$ and the graph of $f$, and\ngive a short elementary proof of the existence of efficient universal ReLU\nneural networks that simultaneously compute all such functions $f$ of bounded\ncomplexity.", "published": "2025-05-11 22:20:16", "link": "http://arxiv.org/abs/2505.07137v1", "categories": ["cs.LG", "math.GT"], "primary_category": "cs.LG"}
{"title": "Learning from Samples: Inverse Problems over measures via Sharpened Fenchel-Young Losses", "abstract": "Estimating parameters from samples of an optimal probability distribution is\nessential in applications ranging from socio-economic modeling to biological\nsystem analysis. In these settings, the probability distribution arises as the\nsolution to an optimization problem that captures either static interactions\namong agents or the dynamic evolution of a system over time. Our approach\nrelies on minimizing a new class of loss functions, called sharpened\nFenchel-Young losses, which measure the sub-optimality gap of the optimization\nproblem over the space of measures. We study the stability of this estimation\nmethod when only a finite number of sample is available. The parameters to be\nestimated typically correspond to a cost function in static problems and to a\npotential function in dynamic problems. To analyze stability, we introduce a\ngeneral methodology that leverages the strong convexity of the loss function\ntogether with the sample complexity of the forward optimization problem. Our\nanalysis emphasizes two specific settings in the context of optimal transport,\nwhere our method provides explicit stability guarantees: The first is inverse\nunbalanced optimal transport (iUOT) with entropic regularization, where the\nparameters to estimate are cost functions that govern transport computations;\nthis method has applications such as link prediction in machine learning. The\nsecond is inverse gradient flow (iJKO), where the objective is to recover a\npotential function that drives the evolution of a probability distribution via\nthe Jordan-Kinderlehrer-Otto (JKO) time-discretization scheme; this is\nparticularly relevant for understanding cell population dynamics in single-cell\ngenomics. Finally, we validate our approach through numerical experiments on\nGaussian distributions, where closed-form solutions are available, to\ndemonstrate the practical performance of our methods", "published": "2025-05-11 21:26:44", "link": "http://arxiv.org/abs/2505.07124v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Constrained Online Decision-Making with Density Estimation Oracles", "abstract": "Contextual online decision-making problems with constraints appear in a wide\nrange of real-world applications, such as personalized recommendation with\nresource limits, adaptive experimental design, and decision-making under safety\nor fairness requirements. In this paper, we investigate a general formulation\nof sequential decision-making with stage-wise feasibility constraints, where at\neach round, the learner must select an action based on observed context while\nensuring that a problem-specific feasibility criterion is satisfied. We propose\na unified algorithmic framework that captures many existing constrained\nlearning problems, including constrained bandits, active learning with label\nbudgets, online hypothesis testing with Type I error control, and model\ncalibration. Central to our approach is the concept of upper counterfactual\nconfidence bounds, which enables the design of practically efficient online\nalgorithms with strong theoretical guarantee using any offline conditional\ndensity estimation oracle. Technically, to handle feasibility constraints in\ncomplex environments, we introduce a generalized notion of the eluder dimension\n- extending it from the classical setting based on square loss to a broader\nclass of metric-like probability divergences. This allows us to capture the\ncomplexity of various density function classes and characterize the utility\nregret incurred due to feasibility constraint uncertainty. Our result offers a\nprincipled foundation for constrained sequential decision-making in both theory\nand practice.", "published": "2025-05-11 19:22:04", "link": "http://arxiv.org/abs/2505.07101v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users", "abstract": "The Rashomon effect describes the observation that in machine learning (ML)\nmultiple models often achieve similar predictive performance while explaining\nthe underlying relationships in different ways. This observation holds even for\nintrinsically interpretable models, such as Generalized Additive Models (GAMs),\nwhich offer users valuable insights into the model's behavior. Given the\nexistence of multiple GAM configurations with similar predictive performance, a\nnatural question is whether we can personalize these configurations based on\nusers' needs for interpretability. In our study, we developed an approach to\npersonalize models based on contextual bandits. In an online experiment with\n108 users in a personalized treatment and a non-personalized control group, we\nfound that personalization led to individualized rather than one-size-fits-all\nconfigurations. Despite these individual adjustments, the interpretability\nremained high across both groups, with users reporting a strong understanding\nof the models. Our research offers initial insights into the potential for\npersonalizing interpretable ML.", "published": "2025-05-11 19:13:35", "link": "http://arxiv.org/abs/2505.07100v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Physics-informed Multiple-Input Operators for efficient dynamic response prediction of structures", "abstract": "Finite element (FE) modeling is essential for structural analysis but remains\ncomputationally intensive, especially under dynamic loading. While operator\nlearning models have shown promise in replicating static structural responses\nat FEM level accuracy, modeling dynamic behavior remains more challenging. This\nwork presents a Multiple Input Operator Network (MIONet) that incorporates a\nsecond trunk network to explicitly encode temporal dynamics, enabling accurate\nprediction of structural responses under moving loads. Traditional DeepONet\narchitectures using recurrent neural networks (RNNs) are limited by fixed time\ndiscretization and struggle to capture continuous dynamics. In contrast, MIONet\npredicts responses continuously over both space and time, removing the need for\nstep wise modeling. It maps scalar inputs including load type, velocity,\nspatial mesh, and time steps to full field structural responses. To improve\nefficiency and enforce physical consistency, we introduce a physics informed\nloss based on dynamic equilibrium using precomputed mass, damping, and\nstiffness matrices, without solving the governing PDEs directly. Further, a\nSchur complement formulation reduces the training domain, significantly cutting\ncomputational costs while preserving global accuracy. The model is validated on\nboth a simple beam and the KW-51 bridge, achieving FEM level accuracy within\nseconds. Compared to GRU based DeepONet, our model offers comparable accuracy\nwith improved temporal continuity and over 100 times faster inference, making\nit well suited for real-time structural monitoring and digital twin\napplications.", "published": "2025-05-11 18:45:58", "link": "http://arxiv.org/abs/2505.07090v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Objective-Guided Discrete Flow Matching for Controllable Biological Sequence Design", "abstract": "Designing biological sequences that satisfy multiple, often conflicting,\nfunctional and biophysical criteria remains a central challenge in biomolecule\nengineering. While discrete flow matching models have recently shown promise\nfor efficient sampling in high-dimensional sequence spaces, existing approaches\naddress only single objectives or require continuous embeddings that can\ndistort discrete distributions. We present Multi-Objective-Guided Discrete Flow\nMatching (MOG-DFM), a general framework to steer any pretrained discrete-time\nflow matching generator toward Pareto-efficient trade-offs across multiple\nscalar objectives. At each sampling step, MOG-DFM computes a hybrid\nrank-directional score for candidate transitions and applies an adaptive\nhypercone filter to enforce consistent multi-objective progression. We also\ntrained two unconditional discrete flow matching models, PepDFM for diverse\npeptide generation and EnhancerDFM for functional enhancer DNA generation, as\nbase generation models for MOG-DFM. We demonstrate MOG-DFM's effectiveness in\ngenerating peptide binders optimized across five properties (hemolysis,\nnon-fouling, solubility, half-life, and binding affinity), and in designing DNA\nsequences with specific enhancer classes and DNA shapes. In total, MOG-DFM\nproves to be a powerful tool for multi-property-guided biomolecule sequence\ndesign.", "published": "2025-05-11 18:17:44", "link": "http://arxiv.org/abs/2505.07086v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "COMRECGC: Global Graph Counterfactual Explainer through Common Recourse", "abstract": "Graph neural networks (GNNs) have been widely used in various domains such as\nsocial networks, molecular biology, or recommendation systems. Concurrently,\ndifferent explanations methods of GNNs have arisen to complement its black-box\nnature. Explanations of the GNNs' predictions can be categorized into two\ntypes--factual and counterfactual. Given a GNN trained on binary classification\ninto ''accept'' and ''reject'' classes, a global counterfactual explanation\nconsists in generating a small set of ''accept'' graphs relevant to all of the\ninput ''reject'' graphs. The transformation of a ''reject'' graph into an\n''accept'' graph is called a recourse. A common recourse explanation is a small\nset of recourse, from which every ''reject'' graph can be turned into an\n''accept'' graph. Although local counterfactual explanations have been studied\nextensively, the problem of finding common recourse for global counterfactual\nexplanation remains unexplored, particularly for GNNs. In this paper, we\nformalize the common recourse explanation problem, and design an effective\nalgorithm, COMRECGC, to solve it. We benchmark our algorithm against strong\nbaselines on four different real-world graphs datasets and demonstrate the\nsuperior performance of COMRECGC against the competitors. We also compare the\ncommon recourse explanations to the graph counterfactual explanation, showing\nthat common recourse explanations are either comparable or superior, making\nthem worth considering for applications such as drug discovery or computational\nbiology.", "published": "2025-05-11 18:09:48", "link": "http://arxiv.org/abs/2505.07081v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures", "abstract": "How do neural language models acquire a language's structure when trained for\nnext-token prediction? We address this question by deriving theoretical scaling\nlaws for neural network performance on synthetic datasets generated by the\nRandom Hierarchy Model (RHM) -- an ensemble of probabilistic context-free\ngrammars designed to capture the hierarchical structure of natural language\nwhile remaining analytically tractable. Previously, we developed a theory of\nrepresentation learning based on data correlations that explains how deep\nlearning models capture the hierarchical structure of the data sequentially,\none layer at a time. Here, we extend our theoretical framework to account for\narchitectural differences. In particular, we predict and empirically validate\nthat convolutional networks, whose structure aligns with that of the generative\nprocess through locality and weight sharing, enjoy a faster scaling of\nperformance compared to transformer models, which rely on global self-attention\nmechanisms. This finding clarifies the architectural biases underlying neural\nscaling laws and highlights how representation learning is shaped by the\ninteraction between model architecture and the statistical properties of data.", "published": "2025-05-11 17:44:14", "link": "http://arxiv.org/abs/2505.07070v1", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Sparse Bayesian Learning Algorithm for Estimation of Interaction Kernels in Motsch-Tadmor Model", "abstract": "In this paper, we investigate the data-driven identification of asymmetric\ninteraction kernels in the Motsch-Tadmor model based on observed trajectory\ndata. The model under consideration is governed by a class of semilinear\nevolution equations, where the interaction kernel defines a normalized,\nstate-dependent Laplacian operator that governs collective dynamics. To address\nthe resulting nonlinear inverse problem, we propose a variational framework\nthat reformulates kernel identification using the implicit form of the\ngoverning equations, reducing it to a subspace identification problem. We\nestablish an identifiability result that characterizes conditions under which\nthe interaction kernel can be uniquely recovered up to scale. To solve the\ninverse problem robustly, we develop a sparse Bayesian learning algorithm that\nincorporates informative priors for regularization, quantifies uncertainty, and\nenables principled model selection. Extensive numerical experiments on\nrepresentative interacting particle systems demonstrate the accuracy,\nrobustness, and interpretability of the proposed framework across a range of\nnoise levels and data regimes.", "published": "2025-05-11 17:43:32", "link": "http://arxiv.org/abs/2505.07068v1", "categories": ["stat.ML", "cs.LG", "math.DS"], "primary_category": "stat.ML"}
{"title": "Learning curves theory for hierarchically compositional data with power-law distributed features", "abstract": "Recent theories suggest that Neural Scaling Laws arise whenever the task is\nlinearly decomposed into power-law distributed units. Alternatively, scaling\nlaws also emerge when data exhibit a hierarchically compositional structure, as\nis thought to occur in language and images. To unify these views, we consider\nclassification and next-token prediction tasks based on probabilistic\ncontext-free grammars -- probabilistic models that generate data via a\nhierarchy of production rules. For classification, we show that having\npower-law distributed production rules results in a power-law learning curve\nwith an exponent depending on the rules' distribution and a large\nmultiplicative constant that depends on the hierarchical structure. By\ncontrast, for next-token prediction, the distribution of production rules\ncontrols the local details of the learning curve, but not the exponent\ndescribing the large-scale behaviour.", "published": "2025-05-11 17:38:40", "link": "http://arxiv.org/abs/2505.07067v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Constant-Memory Strategies in Stochastic Games: Best Responses and Equilibria", "abstract": "(Here is a short version, see our paper for the complete abstract.)\n  In this work, we comprehensively investigate the concept of constant-memory\nstrategies in stochastic games. We first establish some results on best\nresponses and Nash equilibria for behavioral constant-memory strategies,\nfollowed by a discussion on the computational hardness of best responding to\nmixed constant-memory strategies. Those theoretic insights later empower a\ngenerative framework for studying generalizability of single-agent RL\nalgorithms.", "published": "2025-05-11 15:09:46", "link": "http://arxiv.org/abs/2505.07008v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "The Wisdom of Agent Crowds: A Human-AI Interaction Innovation Ignition Framework", "abstract": "With the widespread application of large AI models in various fields, the\nautomation level of multi-agent systems has been continuously improved.\nHowever, in high-risk decision-making scenarios such as healthcare and finance,\nhuman participation and the alignment of intelligent systems with human\nintentions remain crucial. This paper focuses on the financial scenario and\nconstructs a multi-agent brainstorming framework based on the BDI theory. A\nhuman-computer collaborative multi-agent financial analysis process is built\nusing Streamlit. The system plans tasks according to user intentions, reduces\nusers' cognitive load through real-time updated structured text summaries and\nthe interactive Cothinker module, and reasonably integrates general and\nreasoning large models to enhance the ability to handle complex problems. By\ndesigning a quantitative analysis algorithm for the sentiment tendency of\ninterview content based on LLMs and a method for evaluating the diversity of\nideas generated by LLMs in brainstorming based on k-means clustering and\ninformation entropy, the system is comprehensively evaluated. The results of\nhuman factors testing show that the system performs well in terms of usability\nand user experience. Although there is still room for improvement, it can\neffectively support users in completing complex financial tasks. The research\nshows that the system significantly improves the efficiency of human-computer\ninteraction and the quality of decision-making in financial decision-making\nscenarios, providing a new direction for the development of related fields.", "published": "2025-05-11 11:29:09", "link": "http://arxiv.org/abs/2505.06947v1", "categories": ["cs.HC", "cs.MA", "I.2.7; J.4"], "primary_category": "cs.HC"}
{"title": "On optimal recovery of unbounded operators from inaccurate data", "abstract": "The problems of optimal recovery of unbounded operators are studied.\nOptimality means the highest possible accuracy and the minimal amount of\ndiscrete information involved. It is established that the truncation method,\nwhen certain conditions are met, realizes the optimal values of the studied\nquantities. As an illustration of the general results, problems of numerical\ndifferentiation and the backward parabolic equation are considered.", "published": "2025-05-11 21:26:37", "link": "http://arxiv.org/abs/2505.07123v1", "categories": ["math.NA", "cs.NA", "47A52, 65D25, 35R30"], "primary_category": "math.NA"}
{"title": "Streaming Krylov-Accelerated Stochastic Gradient Descent", "abstract": "We present SKA-SGD (Streaming Krylov-Accelerated Stochastic Gradient\nDescent), a novel optimization approach that accelerates convergence for\nill-conditioned problems by projecting stochastic gradients onto a\nlow-dimensional Krylov subspace. Directly inspired by recent advances in s-step\nConjugate Gradient methods with streaming Gauss-Seidel Gram solvers\n\\cite{dambra2025sstep}, our method extends these techniques to the stochastic\noptimization domain. Our approach combines three key innovations: (1)\nprojection coefficients computed via a single streaming Gauss-Seidel iteration,\nwhich is mathematically equivalent to Modified Gram-Schmidt orthogonalization;\n(2) a Chebyshev polynomial basis for constructing the Krylov subspace,\nproviding superior numerical stability; and (3) efficient implementation for\nAMD GPUs using HIP. We prove that our streaming approach achieves a backward\nerror near machine precision with $O(s^2)$ complexity rather than $O(s^3)$,\nwhere $s$ is the Krylov subspace dimension. Experimental results demonstrate\nthat SKA-SGD significantly outperforms standard SGD and Adam in convergence\nrate and final error, particularly for problems with condition numbers\nexceeding $10^3$. GPU performance analysis reveals a crossover point where\ncommunication-avoiding benefits outweigh computational overhead, typically\noccurring at moderate scale ($p \\approx 64$ processors) for problem sizes $n\n\\geq 10^6$.", "published": "2025-05-11 16:36:20", "link": "http://arxiv.org/abs/2505.07046v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rate of Convergence for a Nonlocal-to-local Limit in One Dimension", "abstract": "We consider a nonlocal approximation of the quadratic porous medium equation\nwhere the pressure is given by a convolution with a mollification kernel. It is\nknown that when the kernel concentrates around the origin, the nonlocal\nequation converges to the local one. In one spatial dimension, for a particular\nchoice of the kernel, and under mere assumptions on the initial condition, we\nquantify the rate of convergence in the 2-Wasserstein distance. Our proof is\nvery simple, exploiting the so-called Evolutionary Variational Inequality for\nboth the nonlocal and local equations as well as a priori estimates. We also\npresent numerical simulations using the finite volume method, which suggests\nthat the obtained rate can be improved - this will be addressed in a\nforthcoming work.", "published": "2025-05-11 15:21:40", "link": "http://arxiv.org/abs/2505.07015v1", "categories": ["math.AP", "cs.NA", "math.NA", "35A15, 35Q70, 35B40, 65M08"], "primary_category": "math.AP"}
{"title": "On the permanent of random tensors", "abstract": "The exact computation of permanent for high-dimensional tensors is a hard\nproblem. Having in mind the applications of permanents in other fields,\nproviding an algorithm for the approximation of tensor permanents is an\nattractive subject. In this paper, we design a deterministic quasi-polynomial\ntime algorithm and a PTAS that computes the permanent of complex random tensors\nthat its module of the mean is at least 1/polylog(n).", "published": "2025-05-11 14:52:02", "link": "http://arxiv.org/abs/2505.07000v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Optimal pressure approximation for the nonstationary Stokes problem by a variational method in time with post-processing", "abstract": "We provide an error analysis for the solution of the nonstationary Stokes\nproblem by a variational method in space and time. We use finite elements of\nhigher order for the approximation in space and a Galerkin-Petrov method with\nfirst order polynomials for the approximation in time. We require global\ncontinuity of the discrete velocity trajectory in time, while allowing the\ndiscrete pressure trajectory to be discontinuous at the endpoints of the time\nintervals. We show existence and uniqueness of the discrete velocity solution,\ncharacterize the set of all discrete pressure solutions and prove an optimal\nsecond order estimate in time for the pressure error in the midpoints of the\ntime intervals. The key result and innovation is the construction of\napproximations to the pressure trajectory by means of post-processing together\nwith the proof of optimal order error estimates. We propose two variants for a\npost-processed pressure within the set of pressure solutions based on\ncollocation techniques or interpolation. Both variants guarantee that the\npressure error measured in the L2-norm converges with optimal second order in\ntime and optimal order in space. For the discrete velocity solution, we prove\nerror estimates of optimal order in time and space. We present some numerical\ntests to support our theoretical results.", "published": "2025-05-11 10:38:24", "link": "http://arxiv.org/abs/2505.06933v1", "categories": ["math.NA", "cs.NA", "65M60, 65M12, 35Q30"], "primary_category": "math.NA"}
{"title": "Quantum preconditioning method for linear systems problems via Schr\u00f6dingerization", "abstract": "We present a quantum computational framework that systematically converts\nclassical linear iterative algorithms with fixed iteration operators into their\nquantum counterparts using the Schr\\\"odingerization technique [Shi Jin, Nana\nLiu and Yue Yu, Phys. Rev. Lett., vol. 133 No. 230602,2024]. This is achieved\nby capturing the steady state of the associated differential equations. The\nSchr\\\"odingerization technique transforms linear partial and ordinary\ndifferential equations into Schr\\\"odinger-type systems, making them suitable\nfor quantum computing. This is accomplished through the so-called warped phase\ntransformation, which maps the equation into a higher-dimensional space.\nBuilding on this framework, we develop a quantum preconditioning algorithm that\nleverages the well-known BPX multilevel preconditioner for the finite element\ndiscretization of the Poisson equation. The algorithm achieves a near-optimal\ndependence on the number of queries to our established input models, with a\ncomplexity of $\\mathscr{O}(\\text{polylog} \\frac{1}{\\varepsilon})$ for a target\naccuracy of $\\varepsilon$ when the dimension $d\\geq 2$. This improvement\nresults from the Hamiltonian simulation strategy applied to the\nSchr\\\"odingerized preconditioning dynamics, coupled with the smoothing of\ninitial data in the extended space.", "published": "2025-05-11 06:32:07", "link": "http://arxiv.org/abs/2505.06866v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Copula Analysis of Risk: A Multivariate Risk Analysis for VaR and CoVaR using Copulas and DCC-GARCH", "abstract": "A multivariate risk analysis for VaR and CVaR using different copula families\nis performed on historical financial time series fitted with DCC-GARCH models.\nA theoretical background is provided alongside a comparison of goodness-of-fit\nacross different copula families to estimate the validity and effectiveness of\napproaches discussed.", "published": "2025-05-11 11:45:23", "link": "http://arxiv.org/abs/2505.06950v1", "categories": ["q-fin.RM", "q-fin.CP", "q-fin.ST", "60G70, 62H05, 91G70", "G.3; I.5.1; I.2.6"], "primary_category": "q-fin.RM"}
{"title": "Outperformance Score: A Universal Standardization Method for Confusion-Matrix-Based Classification Performance Metrics", "abstract": "Many classification performance metrics exist, each suited to a specific\napplication. However, these metrics often differ in scale and can exhibit\nvarying sensitivity to class imbalance rates in the test set. As a result, it\nis difficult to use the nominal values of these metrics to interpret and\nevaluate classification performances, especially when imbalance rates vary. To\naddress this problem, we introduce the outperformance score function, a\nuniversal standardization method for confusion-matrix-based classification\nperformance (CMBCP) metrics. It maps any given metric to a common scale of\n$[0,1]$, while providing a clear and consistent interpretation. Specifically,\nthe outperformance score represents the percentile rank of the observed\nclassification performance within a reference distribution of possible\nperformances. This unified framework enables meaningful comparison and\nmonitoring of classification performance across test sets with differing\nimbalance rates. We illustrate how the outperformance scores can be applied to\na variety of commonly used classification performance metrics and demonstrate\nthe robustness of our method through experiments on real-world datasets\nspanning multiple classification applications.", "published": "2025-05-11 16:07:14", "link": "http://arxiv.org/abs/2505.07033v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Efficient Machine Unlearning by Model Splitting and Core Sample Selection", "abstract": "Machine unlearning is essential for meeting legal obligations such as the\nright to be forgotten, which requires the removal of specific data from machine\nlearning models upon request. While several approaches to unlearning have been\nproposed, existing solutions often struggle with efficiency and, more\ncritically, with the verification of unlearning - particularly in the case of\nweak unlearning guarantees, where verification remains an open challenge. We\nintroduce a generalized variant of the standard unlearning metric that enables\nmore efficient and precise unlearning strategies. We also present an\nunlearning-aware training procedure that, in many cases, allows for exact\nunlearning. We term our approach MaxRR. When exact unlearning is not feasible,\nMaxRR still supports efficient unlearning with properties closely matching\nthose achieved through full retraining.", "published": "2025-05-11 15:42:11", "link": "http://arxiv.org/abs/2505.07026v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Incremental Uncertainty-aware Performance Monitoring with Active Labeling Intervention", "abstract": "We study the problem of monitoring machine learning models under gradual\ndistribution shifts, where circumstances change slowly over time, often leading\nto unnoticed yet significant declines in accuracy. To address this, we propose\nIncremental Uncertainty-aware Performance Monitoring (IUPM), a novel label-free\nmethod that estimates performance changes by modeling gradual shifts using\noptimal transport. In addition, IUPM quantifies the uncertainty in the\nperformance prediction and introduces an active labeling procedure to restore a\nreliable estimate under a limited labeling budget. Our experiments show that\nIUPM outperforms existing performance estimation baselines in various gradual\nshift scenarios and that its uncertainty awareness guides label acquisition\nmore effectively compared to other strategies.", "published": "2025-05-11 15:35:55", "link": "http://arxiv.org/abs/2505.07023v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A systematic review of challenges and proposed solutions in modeling multimodal data", "abstract": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.", "published": "2025-05-11 11:23:51", "link": "http://arxiv.org/abs/2505.06945v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Stability Regularized Cross-Validation", "abstract": "We revisit the problem of ensuring strong test-set performance via\ncross-validation. Motivated by the generalization theory literature, we propose\na nested k-fold cross-validation scheme that selects hyperparameters by\nminimizing a weighted sum of the usual cross-validation metric and an empirical\nmodel-stability measure. The weight on the stability term is itself chosen via\na nested cross-validation procedure. This reduces the risk of strong validation\nset performance and poor test set performance due to instability. We benchmark\nour procedure on a suite of 13 real-world UCI datasets, and find that, compared\nto k-fold cross-validation over the same hyperparameters, it improves the\nout-of-sample MSE for sparse ridge regression and CART by 4% on average, but\nhas no impact on XGBoost. This suggests that for interpretable and unstable\nmodels, such as sparse regression and CART, our approach is a viable and\ncomputationally affordable method for improving test-set performance.", "published": "2025-05-11 10:06:59", "link": "http://arxiv.org/abs/2505.06927v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Improving Random Forests by Smoothing", "abstract": "Gaussian process regression is a popular model in the small data regime due\nto its sound uncertainty quantification and the exploitation of the smoothness\nof the regression function that is encountered in a wide range of practical\nproblems. However, Gaussian processes perform sub-optimally when the degree of\nsmoothness is non-homogeneous across the input domain. Random forest regression\npartially addresses this issue by providing local basis functions of variable\nsupport set sizes that are chosen in a data-driven way. However, they do so at\nthe expense of forgoing any degree of smoothness, which often results in poor\nperformance in the small data regime. Here, we aim to combine the advantages of\nboth models by applying a kernel-based smoothing mechanism to a learned random\nforest or any other piecewise constant prediction function. As we demonstrate\nempirically, the resulting model consistently improves the predictive\nperformance of the underlying random forests and, in almost all test cases,\nalso improves the log loss of the usual uncertainty quantification based on\ninter-tree variance. The latter advantage can be attributed to the ability of\nthe smoothing model to take into account the uncertainty over the exact\ntree-splitting locations.", "published": "2025-05-11 05:39:08", "link": "http://arxiv.org/abs/2505.06852v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts", "abstract": "Mixture-of-Experts (MoE) layers are increasingly central to frontier model\narchitectures. By selectively activating parameters, they reduce computational\ncost while scaling total parameter count. This paper investigates the impact of\nthe number of active experts, termed granularity, comparing architectures with\nmany (e.g., 8 per layer in DeepSeek) to those with fewer (e.g., 1 per layer in\nLlama-4 models). We prove an exponential separation in network expressivity\nbased on this design parameter, suggesting that models benefit from higher\ngranularity. Experimental results corroborate our theoretical findings and\nillustrate this separation.", "published": "2025-05-11 04:35:40", "link": "http://arxiv.org/abs/2505.06839v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Streaming Sliced Optimal Transport", "abstract": "Sliced optimal transport (SOT) or sliced Wasserstein (SW) distance is widely\nrecognized for its statistical and computational scalability. In this work, we\nfurther enhance the computational scalability by proposing the first method for\ncomputing SW from sample streams, called \\emph{streaming sliced Wasserstein}\n(Stream-SW). To define Stream-SW, we first introduce the streaming computation\nof the one-dimensional Wasserstein distance. Since the one-dimensional\nWasserstein (1DW) distance has a closed-form expression, given by the absolute\ndifference between the quantile functions of the compared distributions, we\nleverage quantile approximation techniques for sample streams to define the\nstreaming 1DW distance. By applying streaming 1DW to all projections, we obtain\nStream-SW. The key advantage of Stream-SW is its low memory complexity while\nproviding theoretical guarantees on the approximation error. We demonstrate\nthat Stream-SW achieves a more accurate approximation of SW than random\nsubsampling, with lower memory consumption, in comparing Gaussian distributions\nand mixtures of Gaussians from streaming samples. Additionally, we conduct\nexperiments on point cloud classification, point cloud gradient flows, and\nstreaming change point detection to further highlight the favorable performance\nof Stream-SW.", "published": "2025-05-11 04:09:24", "link": "http://arxiv.org/abs/2505.06835v1", "categories": ["cs.LG", "stat.CO", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Kernel Dynamic Mode Decomposition For Sparse Reconstruction of Closable Koopman Operators", "abstract": "Spatial temporal reconstruction of dynamical system is indeed a crucial\nproblem with diverse applications ranging from climate modeling to numerous\nchaotic and physical processes. These reconstructions are based on the\nharmonious relationship between the Koopman operators and the choice of\ndictionary, determined implicitly by a kernel function. This leads to the\napproximation of the Koopman operators in a reproducing kernel Hilbert space\n(RKHS) associated with that kernel function. Data-driven analysis of Koopman\noperators demands that Koopman operators be closable over the underlying RKHS,\nwhich still remains an unsettled, unexplored, and critical operator-theoretic\nchallenge. We aim to address this challenge by investigating the embedding of\nthe Laplacian kernel in the measure-theoretic sense, giving rise to a rich\nenough RKHS to settle the closability of the Koopman operators. We leverage\nKernel Extended Dynamic Mode Decomposition with the Laplacian kernel to\nreconstruct the dominant spatial temporal modes of various diverse dynamical\nsystems. After empirical demonstration, we concrete such results by providing\nthe theoretical justification leveraging the closability of the Koopman\noperators on the RKHS generated by the Laplacian kernel on the avenues of\nKoopman mode decomposition and the Koopman spectral measure. Such results were\nexplored from both grounds of operator theory and data-driven science, thus\nmaking the Laplacian kernel a robust choice for spatial-temporal\nreconstruction.", "published": "2025-05-11 01:16:56", "link": "http://arxiv.org/abs/2505.06806v1", "categories": ["math.DS", "stat.ML", "86A08, 47N60, 47N70, 46E22, 47B32, 46E20, 46E22, 70G60, 76F20"], "primary_category": "math.DS"}
{"title": "A stochastic gradient method for trilevel optimization", "abstract": "With the success that the field of bilevel optimization has seen in recent\nyears, similar methodologies have started being applied to solving more\ndifficult applications that arise in trilevel optimization. At the helm of\nthese applications are new machine learning formulations that have been\nproposed in the trilevel context and, as a result, efficient and theoretically\nsound stochastic methods are required. In this work, we propose the first-ever\nstochastic gradient descent method for solving unconstrained trilevel\noptimization problems and provide a convergence theory that covers all forms of\ninexactness of the trilevel adjoint gradient, such as the inexact solutions of\nthe middle-level and lower-level problems, inexact computation of the trilevel\nadjoint formula, and noisy estimates of the gradients, Hessians, Jacobians, and\ntensors of third-order derivatives involved. We also demonstrate the promise of\nour approach by providing numerical results on both synthetic trilevel problems\nand trilevel formulations for hyperparameter adversarial tuning.", "published": "2025-05-11 01:05:29", "link": "http://arxiv.org/abs/2505.06805v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Topology Guidance: Controlling the Outputs of Generative Models via Vector Field Topology", "abstract": "For domains that involve numerical simulation, it can be computationally\nexpensive to run an ensemble of simulations spanning a parameter space of\ninterest to a user. To this end, an attractive surrogate for simulation is the\ngenerative modeling of fields produced by an ensemble, allowing one to\nsynthesize fields in a computationally cheap, yet accurate, manner. However,\nfor the purposes of visual analysis, a limitation of generative models is their\nlack of control, as it is unclear what one should expect when sampling a field\nfrom a model. In this paper we study how to make generative models of fields\nmore controllable, so that users can specify features of interest, in\nparticular topological features, that they wish to see in the output. We\npropose topology guidance, a method for guiding the sampling process of a\ngenerative model, specifically a diffusion model, such that a topological\ndescription specified as input is satisfied in the generated output. Central to\nour method, we couple a coordinate-based neural network used to represent\nfields, with a diffusion model used for generation. We show how to use\ntopologically-relevant signals provided by the coordinate-based network to help\nguide the denoising process of a diffusion model. This enables us to faithfully\nrepresent a user's specified topology, while ensuring that the output field\nremains within the generative data distribution. Specifically, we study 2D\nvector field topology, evaluating our method over an ensemble of fluid flows,\nwhere we show that generated vector fields faithfully adhere to the location,\nand type, of critical points over the spatial domain. We further show the\nbenefits of our method in aiding the comparison of ensembles, allowing one to\nexplore commonalities and differences in distributions along prescribed\ntopological features.", "published": "2025-05-11 01:02:01", "link": "http://arxiv.org/abs/2505.06804v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reverse-BSDE Monte Carlo", "abstract": "Recently, there has been a growing interest in generative models based on\ndiffusions driven by the empirical robustness of these methods in generating\nhigh-dimensional photorealistic images and the possibility of using the vast\nexisting toolbox of stochastic differential equations. %This remarkable ability\nmay stem from their capacity to model and generate multimodal distributions. In\nthis work, we offer a novel perspective on the approach introduced in Song et\nal. (2021), shifting the focus from a \"learning\" problem to a \"sampling\"\nproblem. To achieve this, we reformulate the equations governing\ndiffusion-based generative models as a Forward-Backward Stochastic Differential\nEquation (FBSDE), which avoids the well-known issue of pre-estimating the\ngradient of the log target density. The solution of this FBSDE is proved to be\nunique using non-standard techniques. Additionally, we propose a numerical\nsolution to this problem, leveraging on Deep Learning techniques. This\nreformulation opens new pathways for sampling multidimensional distributions\nwith densities known up to a normalization constant, a problem frequently\nencountered in Bayesian statistics.", "published": "2025-05-11 00:42:07", "link": "http://arxiv.org/abs/2505.06800v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Collection: Datasets from AFAR Challenge", "abstract": "This paper presents a comprehensive real-world and Digital Twin (DT) dataset\ncollected as part of the Find A Rover (AFAR) Challenge, organized by the NSF\nAerial Experimentation and Research Platform for Advanced Wireless (AERPAW)\ntestbed and hosted at the Lake Wheeler Field in Raleigh, North Carolina. The\nAFAR Challenge was a competition involving five finalist university teams,\nfocused on promoting innovation in UAV-assisted radio frequency (RF) source\nlocalization. Participating teams were tasked with designing UAV flight\ntrajectories and localization algorithms to detect the position of a hidden\nunmanned ground vehicle (UGV), also referred to as a rover, emitting wireless\nprobe signals generated by GNU Radio. The competition was structured to\nevaluate solutions in a DT environment first, followed by deployment and\ntesting in AERPAW's outdoor wireless testbed. For each team, the UGV was placed\nat three different positions, resulting in a total of 30 datasets, 15 collected\nin a DT simulation environment and 15 in a physical outdoor testbed. Each\ndataset contains time-synchronized measurements of received signal strength\n(RSS), received signal quality (RSQ), GPS coordinates, UAV velocity, and UAV\norientation (roll, pitch, and yaw). Data is organized into structured folders\nby team, environment (DT and real-world), and UGV location. The dataset\nsupports research in UAV-assisted RF source localization, air-to-ground (A2G)\nwireless propagation modeling, trajectory optimization, signal prediction,\nautonomous navigation, and DT validation. With approximately 300k\ntime-synchronized samples collected from real-world experiments, the dataset\nprovides a substantial foundation for training and evaluating deep learning\n(DL) models. Overall, the AFAR dataset serves as a valuable resource for\nadvancing robust, real-world solutions in UAV-enabled wireless communications\nand sensing systems.", "published": "2025-05-11 03:22:48", "link": "http://arxiv.org/abs/2505.06823v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "AI-Driven Optimization of Wave-Controlled Reconfigurable Intelligent Surfaces", "abstract": "A promising type of Reconfigurable Intelligent Surface (RIS) employs tunable\ncontrol of its varactors using biasing transmission lines below the RIS\nreflecting elements. Biasing standing waves (BSWs) are excited by a\ntime-periodic signal and sampled at each RIS element to create a desired\nbiasing voltage and control the reflection coefficients of the elements. A\nsimple rectifier can be used to sample the voltages and capture the peaks of\nthe BSWs over time. Like other types of RIS, attempting to model and accurately\nconfigure a wave-controlled RIS is extremely challenging due to factors such as\ndevice non-linearities, frequency dependence, element coupling, etc., and thus\nsignificant differences will arise between the actual and assumed performance.\nAn alternative approach to solving this problem is data-driven: Using training\ndata obtained by sampling the reflected radiation pattern of the RIS for a set\nof BSWs, a neural network (NN) is designed to create an input-output map\nbetween the BSW amplitudes and the resulting sampled radiation pattern. This is\nthe approach discussed in this paper. In the proposed approach, the NN is\noptimized using a genetic algorithm (GA) to minimize the error between the\npredicted and measured radiation patterns. The BSW amplitudes are then designed\nvia Simulated Annealing (SA) to optimize a signal-to-leakage-plus-noise ratio\nmeasure by iteratively forward-propagating the BSW amplitudes through the NN\nand using its output as feedback to determine convergence. The resulting\noptimal solutions are stored in a lookup table to be used both as settings to\ninstantly configure the RIS and as a basis for determining more complex\nradiation patterns.", "published": "2025-05-11 21:33:43", "link": "http://arxiv.org/abs/2505.07126v1", "categories": ["cs.ET", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.ET"}
{"title": "OPTIKS: Optimized Gradient Properties Through Timing in K-Space", "abstract": "A customizable method (OPTIKS) for designing fast trajectory-constrained\ngradient waveforms with optimized time domain properties was developed. Given a\nspecified multidimensional k-space trajectory, the method optimizes traversal\nspeed (and therefore timing) with position along the trajectory. OPTIKS\nfacilitates optimization of objectives dependent on the time domain gradient\nwaveform and the arc-length domain k-space speed. OPTIKS is applied to design\nwaveforms which limit peripheral nerve stimulation (PNS), minimize mechanical\nresonance excitation, and reduce acoustic noise. A variety of trajectory\nexamples are presented including spirals, circular echo-planar-imaging, and\nrosettes. Design performance is evaluated based on duration, standardized PNS\nmodels, field measurements, gradient coil back-EMF measurements, and calibrated\nacoustic measurements. We show reductions in back-EMF of up to 94% and field\noscillations up to 91.1%, acoustic noise decreases of up to 9.22 dB, and with\nefficient use of PNS models speed increases of up to 11.4%. The design method\nimplementation is made available as an open source Python package through\nGitHub.", "published": "2025-05-11 21:02:59", "link": "http://arxiv.org/abs/2505.07117v1", "categories": ["eess.SY", "cs.SY", "eess.SP", "physics.med-ph"], "primary_category": "eess.SY"}
{"title": "Efficient Fault Detection in WSN Based on PCA-Optimized Deep Neural Network Slicing Trained with GOA", "abstract": "Fault detection in Wireless Sensor Networks (WSNs) is crucial for reliable\ndata transmission and network longevity. Traditional fault detection methods\noften struggle with optimizing deep neural networks (DNNs) for efficient\nperformance, especially in handling high-dimensional data and capturing\nnonlinear relationships. Additionally, these methods typically suffer from slow\nconvergence and difficulty in finding optimal network architectures using\ngradient-based optimization. This study proposes a novel hybrid method\ncombining Principal Component Analysis (PCA) with a DNN optimized by the\nGrasshopper Optimization Algorithm (GOA) to address these limitations. Our\napproach begins by computing eigenvalues from the original 12-dimensional\ndataset and sorting them in descending order. The cumulative sum of these\nvalues is calculated, retaining principal components until 99.5% variance is\nachieved, effectively reducing dimensionality to 4 features while preserving\ncritical information. This compressed representation trains a six-layer DNN\nwhere GOA optimizes the network architecture, overcoming backpropagation's\nlimitations in discovering nonlinear relationships. This hybrid PCA-GOA-DNN\nframework compresses the data and trains a six-layer DNN that is optimized by\nGOA, enhancing both training efficiency and fault detection accuracy. The\ndataset used in this study is a real-world WSNs dataset developed by the\nUniversity of North Carolina, which was used to evaluate the proposed method's\nperformance. Extensive simulations demonstrate that our approach achieves a\nremarkable 99.72% classification accuracy, with exceptional precision and\nrecall, outperforming conventional methods. The method is computationally\nefficient, making it suitable for large-scale WSN deployments, and represents a\nsignificant advancement in fault detection for resource-constrained WSNs.", "published": "2025-05-11 15:51:56", "link": "http://arxiv.org/abs/2505.07030v1", "categories": ["cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.AI"}
{"title": "Cross-Link Interference Mitigation With Over-the-Air Pilot Forwarding for Dynamic TDD", "abstract": "Dynamic time-division duplex (D-TDD) aided mobile communication systems bear\nthe potential to achieve significantly higher spectral efficiency than\ntraditional static TDD based systems. However, strong cross-link interference\n(CLI) may be caused by different transmission directions between adjacent cells\nin D-TDD systems, thus degrading the performance. Most existing CLI mitigation\nschemes require sharing certain information among base stations (BSs) via\nbackhaul links. This strategy is usually expensive and suffers high latency.\nAlternatively, we propose a pilot information sharing scheme based on\nover-the-air forwarding of the downlink pilot of the interfering BS to the\ninterfered BS via a wireless terminal, along with a dedicated CLI channel\nestimation method. Simulation results demonstrate that thanks to the proposed\npilot information sharing scheme the classic interference rejection combining\n(IRC) receiver achieves a signal detection performance highly comparable to\nthat of the IRC detector with perfect pilot information, necessitating no\ninformation sharing among BSs via backhaul links. Furthermore, the proposed CLI\nchannel estimation scheme reduces the impact of errors introduced by pilot\nforwarding, thereby improving the performance of both CLI channel estimation\nand signal detection.", "published": "2025-05-11 02:44:44", "link": "http://arxiv.org/abs/2505.06816v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "COMRECGC: Global Graph Counterfactual Explainer through Common Recourse", "abstract": "Graph neural networks (GNNs) have been widely used in various domains such as\nsocial networks, molecular biology, or recommendation systems. Concurrently,\ndifferent explanations methods of GNNs have arisen to complement its black-box\nnature. Explanations of the GNNs' predictions can be categorized into two\ntypes--factual and counterfactual. Given a GNN trained on binary classification\ninto ''accept'' and ''reject'' classes, a global counterfactual explanation\nconsists in generating a small set of ''accept'' graphs relevant to all of the\ninput ''reject'' graphs. The transformation of a ''reject'' graph into an\n''accept'' graph is called a recourse. A common recourse explanation is a small\nset of recourse, from which every ''reject'' graph can be turned into an\n''accept'' graph. Although local counterfactual explanations have been studied\nextensively, the problem of finding common recourse for global counterfactual\nexplanation remains unexplored, particularly for GNNs. In this paper, we\nformalize the common recourse explanation problem, and design an effective\nalgorithm, COMRECGC, to solve it. We benchmark our algorithm against strong\nbaselines on four different real-world graphs datasets and demonstrate the\nsuperior performance of COMRECGC against the competitors. We also compare the\ncommon recourse explanations to the graph counterfactual explanation, showing\nthat common recourse explanations are either comparable or superior, making\nthem worth considering for applications such as drug discovery or computational\nbiology.", "published": "2025-05-11 18:09:48", "link": "http://arxiv.org/abs/2505.07081v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A systematic review of challenges and proposed solutions in modeling multimodal data", "abstract": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.", "published": "2025-05-11 11:23:51", "link": "http://arxiv.org/abs/2505.06945v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Joint Source-Channel Noise Adding with Adaptive Denoising for Diffusion-Based Semantic Communications", "abstract": "Semantic communication (SemCom) aims to convey the intended meaning of\nmessages rather than merely transmitting bits, thereby offering greater\nefficiency and robustness, particularly in resource-constrained or noisy\nenvironments. In this paper, we propose a novel framework which is referred to\nas joint source-channel noise adding with adaptive denoising (JSCNA-AD) for\nSemCom based on a diffusion model (DM). Unlike conventional encoder-decoder\ndesigns, our approach intentionally incorporates the channel noise during\ntransmission, effectively transforming the harmful channel noise into a\nconstructive component of the diffusion-based semantic reconstruction process.\nBesides, we introduce an attention-based adaptive denoising mechanism, in which\ntransmitted images are divided into multiple regions, and the number of\ndenoising steps is dynamically allocated based on the semantic importance of\neach region. This design effectively balances the reception quality and the\ninference latency by prioritizing the critical semantic information. Extensive\nexperiments demonstrate that our method significantly outperforms existing\nSemCom schemes under various noise conditions, underscoring the potential of\ndiffusion-based models in next-generation communication systems.", "published": "2025-05-11 02:02:22", "link": "http://arxiv.org/abs/2505.09644v1", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
