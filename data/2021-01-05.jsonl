{"title": "I-BERT: Integer-only BERT Quantization", "abstract": "Transformer based models, like BERT and RoBERTa, have achieved\nstate-of-the-art results in many Natural Language Processing tasks. However,\ntheir memory footprint, inference latency, and power consumption are\nprohibitive efficient inference at the edge, and even at the data center. While\nquantization can be a viable solution for this, previous work on quantizing\nTransformer based models use floating-point arithmetic during inference, which\ncannot efficiently utilize integer-only logical units such as the recent Turing\nTensor Cores, or traditional integer-only ARM processors. In this work, we\npropose I-BERT, a novel quantization scheme for Transformer based models that\nquantizes the entire inference with integer-only arithmetic. Based on\nlightweight integer-only approximation methods for nonlinear operations, e.g.,\nGELU, Softmax, and Layer Normalization, I-BERT performs an end-to-end\ninteger-only BERT inference without any floating point calculation. We evaluate\nour approach on GLUE downstream tasks using RoBERTa-Base/Large. We show that\nfor both cases, I-BERT achieves similar (and slightly higher) accuracy as\ncompared to the full-precision baseline. Furthermore, our preliminary\nimplementation of I-BERT shows a speedup of 2.4-4.0x for INT8 inference on a T4\nGPU system as compared to FP32 inference. The framework has been developed in\nPyTorch and has been open-sourced.", "published": "2021-01-05 02:42:58", "link": "http://arxiv.org/abs/2101.01321v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Empathetic Chatbots in Customer Service Settings", "abstract": "Customer service is a setting that calls for empathy in live human agent\nresponses. Recent advances have demonstrated how open-domain chatbots can be\ntrained to demonstrate empathy when responding to live human utterances. We\nshow that a blended skills chatbot model that responds to customer queries is\nmore likely to resemble actual human agent response if it is trained to\nrecognize emotion and exhibit appropriate empathy, than a model without such\ntraining. For our analysis, we leverage a Twitter customer service dataset\ncontaining several million customer<->agent dialog examples in customer service\ncontexts from 20 well-known brands.", "published": "2021-01-05 03:34:35", "link": "http://arxiv.org/abs/2101.01334v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PhoNLP: A joint multi-task learning model for Vietnamese part-of-speech\n  tagging, named entity recognition and dependency parsing", "abstract": "We present the first multi-task learning model -- named PhoNLP -- for joint\nVietnamese part-of-speech (POS) tagging, named entity recognition (NER) and\ndependency parsing. Experiments on Vietnamese benchmark datasets show that\nPhoNLP produces state-of-the-art results, outperforming a single-task learning\napproach that fine-tunes the pre-trained Vietnamese language model PhoBERT\n(Nguyen and Nguyen, 2020) for each task independently. We publicly release\nPhoNLP as an open-source toolkit under the Apache License 2.0. Although we\nspecify PhoNLP for Vietnamese, our PhoNLP training and evaluation command\nscripts in fact can directly work for other languages that have a pre-trained\nBERT-based language model and gold annotated corpora available for the three\ntasks of POS tagging, NER and dependency parsing. We hope that PhoNLP can serve\nas a strong baseline and useful toolkit for future NLP research and\napplications to not only Vietnamese but also the other languages. Our PhoNLP is\navailable at: https://github.com/VinAIResearch/PhoNLP", "published": "2021-01-05 12:13:09", "link": "http://arxiv.org/abs/2101.01476v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the interaction of automatic evaluation and task framing in headline\n  style transfer", "abstract": "An ongoing debate in the NLG community concerns the best way to evaluate\nsystems, with human evaluation often being considered the most reliable method,\ncompared to corpus-based metrics. However, tasks involving subtle textual\ndifferences, such as style transfer, tend to be hard for humans to perform. In\nthis paper, we propose an evaluation method for this task based on\npurposely-trained classifiers, showing that it better reflects system\ndifferences than traditional metrics such as BLEU and ROUGE.", "published": "2021-01-05 16:36:26", "link": "http://arxiv.org/abs/2101.01634v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Hybrid Relation Network for Cross-Domain Context-Dependent\n  Semantic Parsing", "abstract": "Semantic parsing has long been a fundamental problem in natural language\nprocessing. Recently, cross-domain context-dependent semantic parsing has\nbecome a new focus of research. Central to the problem is the challenge of\nleveraging contextual information of both natural language utterance and\ndatabase schemas in the interaction history. In this paper, we present a\ndynamic graph framework that is capable of effectively modelling contextual\nutterances, tokens, database schemas, and their complicated interaction as the\nconversation proceeds. The framework employs a dynamic memory decay mechanism\nthat incorporates inductive bias to integrate enriched contextual relation\nrepresentation, which is further enhanced with a powerful reranking model. At\nthe time of writing, we demonstrate that the proposed framework outperforms all\nexisting models by large margins, achieving new state-of-the-art performance on\ntwo large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the\nmodel attains a 55.8% question-match and 30.8% interaction-match accuracy on\nSParC, and a 46.8% question-match and 17.0% interaction-match accuracy on\nCoSQL.", "published": "2021-01-05 18:11:29", "link": "http://arxiv.org/abs/2101.01686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized Food Recommendation as Constrained Question Answering over\n  a Large-scale Food Knowledge Graph", "abstract": "Food recommendation has become an important means to help guide users to\nadopt healthy dietary habits. Previous works on food recommendation either i)\nfail to consider users' explicit requirements, ii) ignore crucial health\nfactors (e.g., allergies and nutrition needs), or iii) do not utilize the rich\nfood knowledge for recommending healthy recipes. To address these limitations,\nwe propose a novel problem formulation for food recommendation, modeling this\ntask as constrained question answering over a large-scale food knowledge\nbase/graph (KBQA). Besides the requirements from the user query, personalized\nrequirements from the user's dietary preferences and health guidelines are\nhandled in a unified way as additional constraints to the QA system. To\nvalidate this idea, we create a QA style dataset for personalized food\nrecommendation based on a large-scale food knowledge graph and health\nguidelines. Furthermore, we propose a KBQA-based personalized food\nrecommendation framework which is equipped with novel techniques for handling\nnegations and numerical comparisons in the queries. Experimental results on the\nbenchmark show that our approach significantly outperforms non-personalized\ncounterparts (average 59.7% absolute improvement across various evaluation\nmetrics), and is able to recommend more relevant and healthier recipes.", "published": "2021-01-05 20:38:16", "link": "http://arxiv.org/abs/2101.01775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "edATLAS: An Efficient Disambiguation Algorithm for Texting in Languages\n  with Abugida Scripts", "abstract": "Abugida refers to a phonogram writing system where each syllable is\nrepresented using a single consonant or typographic ligature, along with a\ndefault vowel or optional diacritic(s) to denote other vowels. However, texting\nin these languages has some unique challenges in spite of the advent of devices\nwith soft keyboard supporting custom key layouts. The number of characters in\nthese languages is large enough to require characters to be spread over\nmultiple views in the layout. Having to switch between views many times to type\na single word hinders the natural thought process. This prevents popular usage\nof native keyboard layouts. On the other hand, supporting romanized scripts\n(native words transcribed using Latin characters) with language model based\nsuggestions is also set back by the lack of uniform romanization rules.\n  To this end, we propose a disambiguation algorithm and showcase its\nusefulness in two novel mutually non-exclusive input methods for languages\nnatively using the abugida writing system: (a) disambiguation of ambiguous\ninput for abugida scripts, and (b) disambiguation of word variants in romanized\nscripts. We benchmark these approaches using public datasets, and show an\nimprovement in typing speed by 19.49%, 25.13%, and 14.89%, in Hindi, Bengali,\nand Thai, respectively, using Ambiguous Input, owing to the human ease of\nlocating keys combined with the efficiency of our inference method. Our Word\nVariant Disambiguation (WDA) maps valid variants of romanized words, previously\ntreated as Out-of-Vocab, to a vocabulary of 100k words with high accuracy,\nleading to an increase in Error Correction F1 score by 10.03% and Next Word\nPrediction (NWP) by 62.50% on average.", "published": "2021-01-05 03:16:34", "link": "http://arxiv.org/abs/2101.03916v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integration of Domain Knowledge using Medical Knowledge Graph Deep\n  Learning for Cancer Phenotyping", "abstract": "A key component of deep learning (DL) for natural language processing (NLP)\nis word embeddings. Word embeddings that effectively capture the meaning and\ncontext of the word that they represent can significantly improve the\nperformance of downstream DL models for various NLP tasks. Many existing word\nembeddings techniques capture the context of words based on word co-occurrence\nin documents and text; however, they often cannot capture broader\ndomain-specific relationships between concepts that may be crucial for the NLP\ntask at hand. In this paper, we propose a method to integrate external\nknowledge from medical terminology ontologies into the context captured by word\nembeddings. Specifically, we use a medical knowledge graph, such as the unified\nmedical language system (UMLS), to find connections between clinical terms in\ncancer pathology reports. This approach aims to minimize the distance between\nconnected clinical concepts. We evaluate the proposed approach using a\nMultitask Convolutional Neural Network (MT-CNN) to extract six cancer\ncharacteristics -- site, subsite, laterality, behavior, histology, and grade --\nfrom a dataset of ~900K cancer pathology reports. The results show that the\nMT-CNN model which uses our domain informed embeddings outperforms the same\nMT-CNN using standard word2vec embeddings across all tasks, with an improvement\nin the overall micro- and macro-F1 scores by 4.97\\%and 22.5\\%, respectively.", "published": "2021-01-05 03:59:43", "link": "http://arxiv.org/abs/2101.01337v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning based Collective Entity Alignment with Adaptive\n  Features", "abstract": "Entity alignment (EA) is the task of identifying the entities that refer to\nthe same real-world object but are located in different knowledge graphs (KGs).\nFor entities to be aligned, existing EA solutions treat them separately and\ngenerate alignment results as ranked lists of entities on the other side.\nNevertheless, this decision-making paradigm fails to take into account the\ninterdependence among entities. Although some recent efforts mitigate this\nissue by imposing the 1-to-1 constraint on the alignment process, they still\ncannot adequately model the underlying interdependence and the results tend to\nbe sub-optimal. To fill in this gap, in this work, we delve into the dynamics\nof the decision-making process, and offer a reinforcement learning (RL) based\nmodel to align entities collectively. Under the RL framework, we devise the\ncoherence and exclusiveness constraints to characterize the interdependence and\nrestrict collective alignment. Additionally, to generate more precise inputs to\nthe RL framework, we employ representative features to capture different\naspects of the similarity between entities in heterogeneous KGs, which are\nintegrated by an adaptive feature fusion strategy. Our proposal is evaluated on\nboth cross-lingual and mono-lingual EA benchmarks and compared against\nstate-of-the-art solutions. The empirical results verify its effectiveness and\nsuperiority.", "published": "2021-01-05 05:04:09", "link": "http://arxiv.org/abs/2101.01353v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Political Depolarization of News Articles Using Attribute-aware Word\n  Embeddings", "abstract": "Political polarization in the US is on the rise. This polarization negatively\naffects the public sphere by contributing to the creation of ideological echo\nchambers. In this paper, we focus on addressing one of the factors that\ncontributes to this polarity, polarized media. We introduce a framework for\ndepolarizing news articles. Given an article on a certain topic with a\nparticular ideological slant (eg., liberal or conservative), the framework\nfirst detects polar language in the article and then generates a new article\nwith the polar language replaced with neutral expressions. To detect polar\nwords, we train a multi-attribute-aware word embedding model that is aware of\nideology and topics on 360k full-length media articles. Then, for text\ngeneration, we propose a new algorithm called Text Annealing Depolarization\nAlgorithm (TADA). TADA retrieves neutral expressions from the word embedding\nmodel that not only decrease ideological polarity but also preserve the\noriginal argument of the text, while maintaining grammatical correctness. We\nevaluate our framework by comparing the depolarized output of our model in two\nmodes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics.\nBased on feedback from 161 human testers, our framework successfully\ndepolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs\nin fully-automatic mode. Furthermore, 81.2% of the testers agree that the\nnon-polar content information is well-preserved and 79% agree that\ndepolarization does not harm semantic correctness when they compare the\noriginal text and the depolarized text. Our work shows that data-driven methods\ncan help to locate political polarity and aid in the depolarization of\narticles.", "published": "2021-01-05 07:39:12", "link": "http://arxiv.org/abs/2101.01391v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Local Translation Services for Neglected Languages", "abstract": "Taking advantage of computationally lightweight, but high-quality translators\nprompt consideration of new applications that address neglected languages.\nLocally run translators for less popular languages may assist data projects\nwith protected or personal data that may require specific compliance checks\nbefore posting to a public translation API, but which could render reasonable,\ncost-effective solutions if done with an army of local, small-scale pair\ntranslators. Like handling a specialist's dialect, this research illustrates\ntranslating two historically interesting, but obfuscated languages: 1)\nhacker-speak (\"l33t\") and 2) reverse (or \"mirror\") writing as practiced by\nLeonardo da Vinci. The work generalizes a deep learning architecture to\ntranslatable variants of hacker-speak with lite, medium, and hard vocabularies.\nThe original contribution highlights a fluent translator of hacker-speak in\nunder 50 megabytes and demonstrates a generator for augmenting future datasets\nwith greater than a million bilingual sentence pairs. The long short-term\nmemory, recurrent neural network (LSTM-RNN) extends previous work demonstrating\nan English-to-foreign translation service built from as little as 10,000\nbilingual sentence pairs. This work further solves the equivalent translation\nproblem in twenty-six additional (non-obfuscated) languages and rank orders\nthose models and their proficiency quantitatively with Italian as the most\nsuccessful and Mandarin Chinese as the most challenging. For neglected\nlanguages, the method prototypes novel services for smaller niche translations\nsuch as Kabyle (Algerian dialect) which covers between 5-7 million speakers but\none which for most enterprise translators, has not yet reached development. One\nanticipates the extension of this approach to other important dialects, such as\ntranslating technical (medical or legal) jargon and processing health records.", "published": "2021-01-05 16:25:51", "link": "http://arxiv.org/abs/2101.01628v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-End Video Question-Answer Generation with Generator-Pretester\n  Network", "abstract": "We study a novel task, Video Question-Answer Generation (VQAG), for\nchallenging Video Question Answering (Video QA) task in multimedia. Due to\nexpensive data annotation costs, many widely used, large-scale Video QA\ndatasets such as Video-QA, MSVD-QA and MSRVTT-QA are automatically annotated\nusing Caption Question Generation (CapQG) which inputs captions instead of the\nvideo itself. As captions neither fully represent a video, nor are they always\npractically available, it is crucial to generate question-answer pairs based on\na video via Video Question-Answer Generation (VQAG). Existing video-to-text\n(V2T) approaches, despite taking a video as the input, only generate a question\nalone. In this work, we propose a novel model Generator-Pretester Network that\nfocuses on two components: (1) The Joint Question-Answer Generator (JQAG) which\ngenerates a question with its corresponding answer to allow Video Question\n\"Answering\" training. (2) The Pretester (PT) verifies a generated question by\ntrying to answer it and checks the pretested answer with both the model's\nproposed answer and the ground truth answer. We evaluate our system with the\nonly two available large-scale human-annotated Video QA datasets and achieves\nstate-of-the-art question generation performances. Furthermore, using our\ngenerated QA pairs only on the Video QA task, we can surpass some supervised\nbaselines. We apply our generated questions to Video QA applications and\nsurpasses some supervised baselines using generated questions only. As a\npre-training strategy, we outperform both CapQG and transfer learning\napproaches when employing semi-supervised (20%) or fully supervised learning\nwith annotated data. These experimental results suggest the novel perspectives\nfor Video QA training.", "published": "2021-01-05 10:46:06", "link": "http://arxiv.org/abs/2101.01447v1", "categories": ["cs.MM", "cs.CL", "cs.CV"], "primary_category": "cs.MM"}
{"title": "AutoDropout: Learning Dropout Patterns to Regularize Deep Networks", "abstract": "Neural networks are often over-parameterized and hence benefit from\naggressive regularization. Conventional regularization methods, such as Dropout\nor weight decay, do not leverage the structures of the network's inputs and\nhidden states. As a result, these conventional methods are less effective than\nmethods that leverage the structures, such as SpatialDropout and DropBlock,\nwhich randomly drop the values at certain contiguous areas in the hidden states\nand setting them to zero. Although the locations of dropout areas random, the\npatterns of SpatialDropout and DropBlock are manually designed and fixed. Here\nwe propose to learn the dropout patterns. In our method, a controller learns to\ngenerate a dropout pattern at every channel and layer of a target network, such\nas a ConvNet or a Transformer. The target network is then trained with the\ndropout pattern, and its resulting validation performance is used as a signal\nfor the controller to learn from. We show that this method works well for both\nimage recognition on CIFAR-10 and ImageNet, as well as language modeling on\nPenn Treebank and WikiText-2. The learned dropout patterns also transfers to\ndifferent tasks and datasets, such as from language model on Penn Treebank to\nEngligh-French translation on WMT 2014. Our code will be available.", "published": "2021-01-05 19:54:22", "link": "http://arxiv.org/abs/2101.01761v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Domain-aware Neural Language Models for Speech Recognition", "abstract": "As voice assistants become more ubiquitous, they are increasingly expected to\nsupport and perform well on a wide variety of use-cases across different\ndomains. We present a domain-aware rescoring framework suitable for achieving\ndomain-adaptation during second-pass rescoring in production settings. In our\nframework, we fine-tune a domain-general neural language model on several\ndomains, and use an LSTM-based domain classification model to select the\nappropriate domain-adapted model to use for second-pass rescoring. This\ndomain-aware rescoring improves the word error rate by up to 2.4% and slot word\nerror rate by up to 4.1% on three individual domains -- shopping, navigation,\nand music -- compared to domain general rescoring. These improvements are\nobtained while maintaining accuracy for the general use case.", "published": "2021-01-05 00:08:32", "link": "http://arxiv.org/abs/2101.03229v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Development of a Respiratory Sound Labeling Software for Training a Deep\n  Learning-Based Respiratory Sound Analysis Model", "abstract": "Respiratory auscultation can help healthcare professionals detect abnormal\nrespiratory conditions if adventitious lung sounds are heard. The\nstate-of-the-art artificial intelligence technologies based on deep learning\nshow great potential in the development of automated respiratory sound\nanalysis. To train a deep learning-based model, a huge number of accurate\nlabels of normal breath sounds and adventitious sounds are needed. In this\npaper, we demonstrate the work of developing a respiratory sound labeling\nsoftware to help annotators identify and label the inhalation, exhalation, and\nadventitious respiratory sound more accurately and quickly. Our labeling\nsoftware integrates six features from MATLAB Audio Labeler, and one commercial\naudio editor, RX7. As of October, 2019, we have labeled 9,765 15-second-long\naudio files of breathing lung sounds, and accrued 34,095 inhalation\nlabels,18,349 exhalation labels, 13,883 continuous adventitious sounds (CASs)\nlabels and 15,606 discontinuous adventitious sounds (DASs) labels, which are\nsignificantly larger than previously published studies. The trained\nconvolutional recurrent neural networks based on these labels showed good\nperformance with F1-scores of 86.0% on inhalation event detection, 51.6% on\nCASs event detection and 71.4% on DASs event detection. In conclusion, our\nresults show that our proposed respiratory sound labeling software could easily\npre-define a label, perform one-click labeling, and overall facilitate the\nprocess of accurately labeling. This software helps develop deep learning-based\nmodels that require a huge amount of labeled acoustic data.", "published": "2021-01-05 04:59:04", "link": "http://arxiv.org/abs/2101.01352v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fixed-MAML for Few Shot Classification in Multilingual Speech Emotion\n  Recognition", "abstract": "In this paper, we analyze the feasibility of applying few-shot learning to\nspeech emotion recognition task (SER). The current speech emotion recognition\nmodels work exceptionally well but fail when then input is multilingual.\nMoreover, when training such models, the models' performance is suitable only\nwhen the training corpus is vast. This availability of a big training corpus is\na significant problem when choosing a language that is not much popular or\nobscure. We attempt to solve this challenge of multilingualism and lack of\navailable data by turning this problem into a few-shot learning problem. We\nsuggest relaxing the assumption that all N classes in an N-way K-shot problem\nbe new and define an N+F way problem where N and F are the number of emotion\nclasses and predefined fixed classes, respectively. We propose this\nmodification to the Model-Agnostic MetaLearning (MAML) algorithm to solve the\nproblem and call this new model F-MAML. This modification performs better than\nthe original MAML and outperforms on EmoFilm dataset.", "published": "2021-01-05 05:51:50", "link": "http://arxiv.org/abs/2101.01356v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T10"], "primary_category": "cs.SD"}
