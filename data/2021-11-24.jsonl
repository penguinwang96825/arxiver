{"title": "A Self-Supervised Automatic Post-Editing Data Generation Tool", "abstract": "Data building for automatic post-editing (APE) requires extensive and\nexpert-level human effort, as it contains an elaborate process that involves\nidentifying errors in sentences and providing suitable revisions. Hence, we\ndevelop a self-supervised data generation tool, deployable as a web\napplication, that minimizes human supervision and constructs personalized APE\ndata from a parallel corpus for several language pairs with English as the\ntarget language. Data-centric APE research can be conducted using this tool,\ninvolving many language pairs that have not been studied thus far owing to the\nlack of suitable data.", "published": "2021-11-24 05:56:36", "link": "http://arxiv.org/abs/2111.12284v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Handling tree-structured text: parsing directory pages", "abstract": "The determination of the reading sequence of text is fundamental to document\nunderstanding. This problem is easily solved in pages where the text is\norganized into a sequence of lines and vertical alignment runs the height of\nthe page (producing multiple columns which can be read from left to right). We\npresent a situation -- the directory page parsing problem -- where information\nis presented on the page in an irregular, visually-organized, two-dimensional\nformat. Directory pages are fairly common in financial prospectuses and carry\ninformation about organizations, their addresses and relationships that is key\nto business tasks in client onboarding. Interestingly, directory pages\nsometimes have hierarchical structure, motivating the need to generalize the\nreading sequence to a reading tree. We present solutions to the problem of\nidentifying directory pages and constructing the reading tree, using (learnt)\nclassifiers for text segments and a bottom-up (right to left, bottom-to-top)\ntraversal of segments. The solution is a key part of a production service\nsupporting automatic extraction of organization, address and relationship\ninformation from client onboarding documents.", "published": "2021-11-24 07:58:47", "link": "http://arxiv.org/abs/2111.12317v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Contextual Toxicity Detection in Conversations", "abstract": "Understanding toxicity in user conversations is undoubtedly an important\nproblem. Addressing \"covert\" or implicit cases of toxicity is particularly hard\nand requires context. Very few previous studies have analysed the influence of\nconversational context in human perception or in automated detection models. We\ndive deeper into both these directions. We start by analysing existing\ncontextual datasets and come to the conclusion that toxicity labelling by\nhumans is in general influenced by the conversational structure, polarity and\ntopic of the context. We then propose to bring these findings into\ncomputational detection models by introducing and evaluating (a) neural\narchitectures for contextual toxicity detection that are aware of the\nconversational structure, and (b) data augmentation strategies that can help\nmodel contextual toxicity detection. Our results have shown the encouraging\npotential of neural architectures that are aware of the conversation structure.\nWe have also demonstrated that such models can benefit from synthetic data,\nespecially in the social media domain.", "published": "2021-11-24 11:50:37", "link": "http://arxiv.org/abs/2111.12447v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "For the Purpose of Curry: A UD Treebank for Ashokan Prakrit", "abstract": "We present the first linguistically annotated treebank of Ashokan Prakrit, an\nearly Middle Indo-Aryan dialect continuum attested through Emperor Ashoka\nMaurya's 3rd century BCE rock and pillar edicts. For annotation, we used the\nmultilingual Universal Dependencies (UD) formalism, following recent UD work on\nSanskrit and other Indo-Aryan languages. We touch on some interesting\nlinguistic features that posed issues in annotation: regnal names and other\nnominal compounds, \"proto-ergative\" participial constructions, and possible\ngrammaticalizations evidenced by sandhi (phonological assimilation across\nmorpheme boundaries). Eventually, we plan for a complete annotation of all\nattested Ashokan texts, towards the larger goals of improving UD coverage of\ndifferent diachronic stages of Indo-Aryan and studying language change in\nIndo-Aryan using computational methods.", "published": "2021-11-24 20:30:09", "link": "http://arxiv.org/abs/2111.12783v2", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Temporal Effects on Pre-trained Models for Language Processing Tasks", "abstract": "Keeping the performance of language technologies optimal as time passes is of\ngreat practical interest. We study temporal effects on model performance on\ndownstream language tasks, establishing a nuanced terminology for such\ndiscussion and identifying factors essential to conduct a robust study. We\npresent experiments for several tasks in English where the label correctness is\nnot dependent on time and demonstrate the importance of distinguishing between\ntemporal model deterioration and temporal domain adaptation for systems using\npre-trained representations. We find that depending on the task, temporal model\ndeterioration is not necessarily a concern. Temporal domain adaptation however\nis beneficial in all cases, with better performance for a given time period\npossible when the system is trained on temporally more recent data. Therefore,\nwe also examine the efficacy of two approaches for temporal domain adaptation\nwithout human annotations on new data. Self-labeling shows consistent\nimprovement and notably, for named entity recognition, leads to better temporal\nadaptation than even human annotations.", "published": "2021-11-24 20:44:12", "link": "http://arxiv.org/abs/2111.12790v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Up Vision-Language Pre-training for Image Captioning", "abstract": "In recent years, we have witnessed significant performance boost in the image\ncaptioning task based on vision-language pre-training (VLP). Scale is believed\nto be an important factor for this advance. However, most existing work only\nfocuses on pre-training transformers with moderate sizes (e.g., 12 or 24\nlayers) on roughly 4 million images. In this paper, we present LEMON, a\nLargE-scale iMage captiONer, and provide the first empirical study on the\nscaling behavior of VLP for image captioning. We use the state-of-the-art VinVL\nmodel as our reference model, which consists of an image feature extractor and\na transformer model, and scale the transformer both up and down, with model\nsizes ranging from 13 to 675 million parameters. In terms of data, we conduct\nexperiments with up to 200 million image-text pairs which are automatically\ncollected from web based on the alt attribute of the image (dubbed as ALT200M).\nExtensive analysis helps to characterize the performance trend as the model\nsize and the pre-training data size increase. We also compare different\ntraining recipes, especially for training on large-scale noisy data. As a\nresult, LEMON achieves new state of the arts on several major image captioning\nbenchmarks, including COCO Caption, nocaps, and Conceptual Captions. We also\nshow LEMON can generate captions with long-tail visual concepts when used in a\nzero-shot manner.", "published": "2021-11-24 02:30:22", "link": "http://arxiv.org/abs/2111.12233v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Selection of pseudo-annotated data for adverse drug reaction\n  classification across drug groups", "abstract": "Automatic monitoring of adverse drug events (ADEs) or reactions (ADRs) is\ncurrently receiving significant attention from the biomedical community. In\nrecent years, user-generated data on social media has become a valuable\nresource for this task. Neural models have achieved impressive performance on\nautomatic text classification for ADR detection. Yet, training and evaluation\nof these methods are carried out on user-generated texts about a targeted drug.\nIn this paper, we assess the robustness of state-of-the-art neural\narchitectures across different drug groups. We investigate several strategies\nto use pseudo-labeled data in addition to a manually annotated train set.\nOut-of-dataset experiments diagnose the bottleneck of supervised models in\nterms of breakdown performance, while additional pseudo-labeled data improves\noverall results regardless of the text selection strategy.", "published": "2021-11-24 13:11:05", "link": "http://arxiv.org/abs/2111.12477v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Enhanced Sports Game Summarization", "abstract": "Sports game summarization aims at generating sports news from live\ncommentaries. However, existing datasets are all constructed through automated\ncollection and cleaning processes, resulting in a lot of noise. Besides,\ncurrent works neglect the knowledge gap between live commentaries and sports\nnews, which limits the performance of sports game summarization. In this paper,\nwe introduce K-SportsSum, a new dataset with two characteristics: (1)\nK-SportsSum collects a large amount of data from massive games. It has 7,854\ncommentary-news pairs. To improve the quality, K-SportsSum employs a manual\ncleaning process; (2) Different from existing datasets, to narrow the knowledge\ngap, K-SportsSum further provides a large-scale knowledge corpus that contains\nthe information of 523 sports teams and 14,724 sports players. Additionally, we\nalso introduce a knowledge-enhanced summarizer that utilizes both live\ncommentaries and the knowledge to generate sports news. Extensive experiments\non K-SportsSum and SportsSum datasets show that our model achieves new\nstate-of-the-art performances. Qualitative analysis and human study further\nverify that our model generates more informative sports news.", "published": "2021-11-24 15:06:20", "link": "http://arxiv.org/abs/2111.12535v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse is Enough in Scaling Transformers", "abstract": "Large Transformer models yield impressive results on many tasks, but are\nexpensive to train, or even fine-tune, and so slow at decoding that their use\nand study becomes out of reach. We address this problem by leveraging sparsity.\nWe study sparse variants for all layers in the Transformer and propose Scaling\nTransformers, a family of next generation Transformer models that use sparse\nlayers to scale efficiently and perform unbatched decoding much faster than the\nstandard Transformer as we scale up the model size. Surprisingly, the sparse\nlayers are enough to obtain the same perplexity as the standard Transformer\nwith the same number of parameters. We also integrate with prior sparsity\napproaches to attention and enable fast inference on long sequences even with\nlimited memory. This results in performance competitive to the state-of-the-art\non long text summarization.", "published": "2021-11-24 19:53:46", "link": "http://arxiv.org/abs/2111.12763v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Rule-based/BPSO Approach to Produce Low-dimensional Semantic Basis\n  Vectors Set", "abstract": "We intend to generate low-dimensional explicit distributional semantic\nvectors. In explicit semantic vectors, each dimension corresponds to a word, so\nword vectors are interpretable. In this research, we propose a new approach to\nobtain low-dimensional explicit semantic vectors. First, the proposed approach\nconsiders the three criteria Word Similarity, Number of Zero, and Word\nFrequency as features for the words in a corpus. Then, we extract some rules\nfor obtaining the initial basis words using a decision tree that is drawn based\non the three features. Second, we propose a binary weighting method based on\nthe Binary Particle Swarm Optimization algorithm that obtains N_B = 1000\ncontext words. We also use a word selection method that provides N_S = 1000\ncontext words. Third, we extract the golden words of the corpus based on the\nbinary weighting method. Then, we add the extracted golden words to the context\nwords that are selected by the word selection method as the golden context\nwords. We use the ukWaC corpus for constructing the word vectors. We use MEN,\nRG-65, and SimLex-999 test sets to evaluate the word vectors. We report the\nresults compared to a baseline that uses 5k most frequent words in the corpus\nas context words. The baseline method uses a fixed window to count the\nco-occurrences. We obtain the word vectors using the 1000 selected context\nwords together with the golden context words. Our approach compared to the\nBaseline method increases the Spearman correlation coefficient for the MEN,\nRG-65, and SimLex-999 test sets by 4.66%, 14.73%, and 1.08%, respectively.", "published": "2021-11-24 21:23:43", "link": "http://arxiv.org/abs/2111.12802v1", "categories": ["cs.CL", "math.OC"], "primary_category": "cs.CL"}
{"title": "Few-shot Named Entity Recognition with Cloze Questions", "abstract": "Despite the huge and continuous advances in computational linguistics, the\nlack of annotated data for Named Entity Recognition (NER) is still a\nchallenging issue, especially in low-resource languages and when domain\nknowledge is required for high-quality annotations. Recent findings in NLP show\nthe effectiveness of cloze-style questions in enabling language models to\nleverage the knowledge they acquired during the pre-training phase. In our\nwork, we propose a simple and intuitive adaptation of Pattern-Exploiting\nTraining (PET), a recent approach which combines the cloze-questions mechanism\nand fine-tuning for few-shot learning: the key idea is to rephrase the NER task\nwith patterns. Our approach achieves considerably better performance than\nstandard fine-tuning and comparable or improved results with respect to other\nfew-shot baselines without relying on manually annotated data or distant\nsupervision on three benchmark datasets: NCBI-disease, BC2GM and a private\nItalian biomedical corpus.", "published": "2021-11-24 11:08:59", "link": "http://arxiv.org/abs/2111.12421v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Generating More Pertinent Captions by Leveraging Semantics and Style on\n  Multi-Source Datasets", "abstract": "This paper addresses the task of generating fluent descriptions by training\non a non-uniform combination of data sources, containing both human-annotated\nand web-collected captions. Large-scale datasets with noisy image-text pairs,\nindeed, provide a sub-optimal source of supervision because of their\nlow-quality descriptive style, while human-annotated datasets are cleaner but\nsmaller in scale. To get the best of both worlds, we propose to leverage and\nseparate semantics and descriptive style through the incorporation of a style\ntoken and keywords extracted through a retrieval component. The proposed model\navoids the need of object detectors, is trained with a single objective of\nprompt language modeling, and can replicate the style of human-collected\ncaptions while training on sources with different input styles. Experimentally,\nthe model shows a strong capability of recognizing real-world concepts and\nproducing high-quality captions. Extensive experiments are performed on\ndifferent image captioning datasets, including CC3M, nocaps, and the\ncompetitive COCO dataset, where our model consistently outperforms baselines\nand state-of-the-art approaches.", "published": "2021-11-24 19:00:05", "link": "http://arxiv.org/abs/2111.12727v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Out-of-Category Document Identification Using Target-Category Names as\n  Weak Supervision", "abstract": "Identifying outlier documents, whose content is different from the majority\nof the documents in a corpus, has played an important role to manage a large\ntext collection. However, due to the absence of explicit information about the\ninlier (or target) distribution, existing unsupervised outlier detectors are\nlikely to make unreliable results depending on the density or diversity of the\noutliers in the corpus. To address this challenge, we introduce a new task\nreferred to as out-of-category detection, which aims to distinguish the\ndocuments according to their semantic relevance to the inlier (or target)\ncategories by using the category names as weak supervision. In practice, this\ntask can be widely applicable in that it can flexibly designate the scope of\ntarget categories according to users' interests while requiring only the\ntarget-category names as minimum guidance. In this paper, we present an\nout-of-category detection framework, which effectively measures how confidently\neach document belongs to one of the target categories based on its\ncategory-specific relevance score. Our framework adopts a two-step approach;\n(i) it first generates the pseudo-category label of all unlabeled documents by\nexploiting the word-document similarity encoded in a text embedding space, then\n(ii) it trains a neural classifier by using the pseudo-labels in order to\ncompute the confidence from its target-category prediction. The experiments on\nreal-world datasets demonstrate that our framework achieves the best detection\nperformance among all baseline methods in various scenarios specifying\ndifferent target categories.", "published": "2021-11-24 21:01:25", "link": "http://arxiv.org/abs/2111.12796v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "KUIELab-MDX-Net: A Two-Stream Neural Network for Music Demixing", "abstract": "Recently, many methods based on deep learning have been proposed for music\nsource separation. Some state-of-the-art methods have shown that stacking many\nlayers with many skip connections improve the SDR performance. Although such a\ndeep and complex architecture shows outstanding performance, it usually\nrequires numerous computing resources and time for training and evaluation.\nThis paper proposes a two-stream neural network for music demixing, called\nKUIELab-MDX-Net, which shows a good balance of performance and required\nresources. The proposed model has a time-frequency branch and a time-domain\nbranch, where each branch separates stems, respectively. It blends results from\ntwo streams to generate the final estimation. KUIELab-MDX-Net took second place\non leaderboard A and third place on leaderboard B in the Music Demixing\nChallenge at ISMIR 2021. This paper also summarizes experimental results on\nanother benchmark, MUSDB18. Our source code is available online.", "published": "2021-11-24 00:10:35", "link": "http://arxiv.org/abs/2111.12203v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "One-shot Voice Conversion For Style Transfer Based On Speaker Adaptation", "abstract": "One-shot style transfer is a challenging task, since training on one\nutterance makes model extremely easy to over-fit to training data and causes\nlow speaker similarity and lack of expressiveness. In this paper, we build on\nthe recognition-synthesis framework and propose a one-shot voice conversion\napproach for style transfer based on speaker adaptation. First, a speaker\nnormalization module is adopted to remove speaker-related information in\nbottleneck features extracted by ASR. Second, we adopt weight regularization in\nthe adaptation process to prevent over-fitting caused by using only one\nutterance from target speaker as training data. Finally, to comprehensively\ndecouple the speech factors, i.e., content, speaker, style, and transfer source\nstyle to the target, a prosody module is used to extract prosody\nrepresentation. Experiments show that our approach is superior to the\nstate-of-the-art one-shot VC systems in terms of style and speaker similarity;\nadditionally, our approach also maintains good speech quality.", "published": "2021-11-24 05:30:47", "link": "http://arxiv.org/abs/2111.12277v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "How Speech is Recognized to Be Emotional - A Study Based on Information\n  Decomposition", "abstract": "The way that humans encode their emotion into speech signals is complex. For\ninstance, an angry man may increase his pitch and speaking rate, and use\nimpolite words. In this paper, we present a preliminary study on various\nemotional factors and investigate how each of them impacts modern emotion\nrecognition systems. The key tool of our study is the SpeechFlow model\npresented recently, by which we are able to decompose speech signals into\nseparate information factors (content, pitch, rhythm). Based on this\ndecomposition, we carefully studied the performance of each information\ncomponent and their combinations. We conducted the study on three different\nspeech emotion corpora and chose an attention-based convolutional RNN as the\nemotion classifier. Our results show that rhythm is the most important\ncomponent for emotional expression. Moreover, the cross-corpus results are very\nbad (even worse than guess), demonstrating that the present speech emotion\nrecognition model is rather weak. Interestingly, by removing one or several\nunimportant components, the cross-corpus results can be improved. This\ndemonstrates the potential of the decomposition approach towards a\ngeneralizable emotion recognition.", "published": "2021-11-24 08:15:53", "link": "http://arxiv.org/abs/2111.12324v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Study on Decoupled Probabilistic Linear Discriminant Analysis", "abstract": "Probabilistic linear discriminant analysis (PLDA) has broad application in\nopen-set verification tasks, such as speaker verification. A key concern for\nPLDA is that the model is too simple (linear Gaussian) to deal with complicated\ndata; however, the simplicity by itself is a major advantage of PLDA, as it\nleads to desirable generalization. An interesting research therefore is how to\nimprove modeling capacity of PLDA while retaining the simplicity. This paper\npresents a decoupling approach, which involves a global model that is simple\nand generalizable, and a local model that is complex and expressive. While the\nglobal model holds a bird view on the entire data, the local model represents\nthe details of individual classes. We conduct a preliminary study towards this\ndirection and investigate a simple decoupling model including both the global\nand local models. The new model, which we call decoupled PLDA, is tested on a\nspeaker verification task. Experimental results show that it consistently\noutperforms the vanilla PLDA when the model is based on raw speaker vectors.\nHowever, when the speaker vectors are processed by length normalization, the\nadvantage of decoupled PLDA will be largely lost, suggesting future research on\nnon-linear local models.", "published": "2021-11-24 08:22:01", "link": "http://arxiv.org/abs/2111.12326v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An MAP Estimation for Between-Class Variance", "abstract": "Probabilistic linear discriminant analysis (PLDA) has been widely used in\nopen-set verification tasks, such as speaker verification. A potential issue of\nthis model is that the training set often contains limited number of classes,\nwhich makes the estimation for the between-class variance unreliable. This\nunreliable estimation often leads to degraded generalization. In this paper, we\npresent an MAP estimation for the between-class variance, by employing an\nInverse-Wishart prior. A key problem is that with hierarchical models such as\nPLDA, the prior is placed on the variance of class means while the likelihood\nis based on class members, which makes the posterior inference intractable. We\nderive a simple MAP estimation for such a model, and test it in both PLDA\nscoring and length normalization. In both cases, the MAP-based estimation\ndelivers interesting performance improvement.", "published": "2021-11-24 08:26:21", "link": "http://arxiv.org/abs/2111.12331v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semi-Supervised Audio Classification with Partially Labeled Data", "abstract": "Audio classification has seen great progress with the increasing availability\nof large-scale datasets. These large datasets, however, are often only\npartially labeled as collecting full annotations is a tedious and expensive\nprocess. This paper presents two semi-supervised methods capable of learning\nwith missing labels and evaluates them on two publicly available, partially\nlabeled datasets. The first method relies on label enhancement by a two-stage\nteacher-student learning process, while the second method utilizes the mean\nteacher semi-supervised learning algorithm. Our results demonstrate the impact\nof improperly handling missing labels and compare the benefits of using\ndifferent strategies leveraging data with few labels. Methods capable of\nlearning with partially labeled data have the potential to improve models for\naudio classification by utilizing even larger amounts of data without the need\nfor complete annotations.", "published": "2021-11-24 19:48:18", "link": "http://arxiv.org/abs/2111.12761v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LightSAFT: Lightweight Latent Source Aware Frequency Transform for\n  Source Separation", "abstract": "Conditioned source separations have attracted significant attention because\nof their flexibility, applicability and extensionality. Their performance was\nusually inferior to the existing approaches, such as the single source\nseparation model. However, a recently proposed method called LaSAFT-Net has\nshown that conditioned models can show comparable performance against existing\nsingle-source separation models. This paper presents LightSAFT-Net, a\nlightweight version of LaSAFT-Net. As a baseline, it provided a sufficient SDR\nperformance for comparison during the Music Demixing Challenge at ISMIR 2021.\nThis paper also enhances the existing LightSAFT-Net by replacing the LightSAFT\nblocks in the encoder with TFC-TDF blocks. Our enhanced LightSAFT-Net\noutperforms the previous one with fewer parameters.Conditioned source\nseparations have attracted significant attention because of their flexibility,\napplicability and extensionality. Their performance was usually inferior to the\nexisting approaches, such as the single source separation model. However, a\nrecently proposed method called LaSAFT-Net has shown that conditioned models\ncan show comparable performance against existing single-source separation\nmodels. This paper presents LightSAFT-Net, a lightweight version of LaSAFT-Net.\nAs a baseline, it provided a sufficient SDR performance for comparison during\nthe Music Demixing Challenge at ISMIR 2021.", "published": "2021-11-24 14:25:13", "link": "http://arxiv.org/abs/2111.12516v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Non-Intrusive Binaural Speech Intelligibility Prediction from Discrete\n  Latent Representations", "abstract": "Non-intrusive speech intelligibility (SI) prediction from binaural signals is\nuseful in many applications. However, most existing signal-based measures are\ndesigned to be applied to single-channel signals. Measures specifically\ndesigned to take into account the binaural properties of the signal are often\nintrusive - characterised by requiring access to a clean speech signal - and\ntypically rely on combining both channels into a single-channel signal before\nmaking predictions. This paper proposes a non-intrusive SI measure that\ncomputes features from a binaural input signal using a combination of vector\nquantization (VQ) and contrastive predictive coding (CPC) methods. VQ-CPC\nfeature extraction does not rely on any model of the auditory system and is\ninstead trained to maximise the mutual information between the input signal and\noutput features. The computed VQ-CPC features are input to a predicting\nfunction parameterized by a neural network. Two predicting functions are\nconsidered in this paper. Both feature extractor and predicting functions are\ntrained on simulated binaural signals with isotropic noise. They are tested on\nsimulated signals with isotropic and real noise. For all signals, the ground\ntruth scores are the (intrusive) deterministic binaural STOI. Results are\npresented in terms of correlations and MSE and demonstrate that VQ-CPC features\nare able to capture information relevant to modelling SI and outperform all the\nconsidered benchmarks - even when evaluating on data comprising of different\nnoise field types.", "published": "2021-11-24 14:55:04", "link": "http://arxiv.org/abs/2111.12531v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Cross-Cultural Analysis using Music Information Dynamics", "abstract": "A music piece is both comprehended hierarchically, from sonic events to\nmelodies, and sequentially, in the form of repetition and variation. Music from\ndifferent cultures establish different aesthetics by having different style\nconventions on these two aspects. We propose a framework that could be used to\nquantitatively compare music from different cultures by looking at these two\naspects.\n  The framework is based on an Music Information Dynamics model, a Variable\nMarkov Oracle (VMO), and is extended with a variational representation learning\nof audio. A variational autoencoder (VAE) is trained to map audio fragments\ninto a latent representation. The latent representation is fed into a VMO. The\nVMO then learns a clustering of the latent representation via a threshold that\nmaximizes the information rate of the quantized latent representation sequence.\nThis threshold effectively controls the sensibility of the predictive step to\nacoustic changes, which determines the framework's ability to track repetitions\non longer time scales. This approach allows characterization of the overall\ninformation contents of a musical signal at each level of acoustic sensibility.\n  Our findings under this framework show that sensibility to subtle acoustic\nchanges is higher for East-Asian musical traditions, while the Western works\nexhibit longer motivic structures at higher thresholds of differences in the\nlatent space. This suggests that a profile of information contents, analyzed as\na function of the level of acoustic detail can serve as a possible cultural\ncharacteristic.", "published": "2021-11-24 16:05:29", "link": "http://arxiv.org/abs/2111.12588v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
