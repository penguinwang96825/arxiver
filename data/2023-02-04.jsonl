{"title": "Lived Experience Matters: Automatic Detection of Stigma on Social Media\n  Toward People Who Use Substances", "abstract": "Stigma toward people who use substances (PWUS) is a leading barrier to\nseeking treatment.Further, those in treatment are more likely to drop out if\nthey experience higher levels of stigmatization. While related concepts of hate\nspeech and toxicity, including those targeted toward vulnerable populations,\nhave been the focus of automatic content moderation research, stigma and, in\nparticular, people who use substances have not. This paper explores stigma\ntoward PWUS using a data set of roughly 5,000 public Reddit posts. We performed\na crowd-sourced annotation task where workers are asked to annotate each post\nfor the presence of stigma toward PWUS and answer a series of questions related\nto their experiences with substance use. Results show that workers who use\nsubstances or know someone with a substance use disorder are more likely to\nrate a post as stigmatizing. Building on this, we use a supervised machine\nlearning framework that centers workers with lived substance use experience to\nlabel each Reddit post as stigmatizing. Modeling person-level demographics in\naddition to comment-level language results in a classification accuracy (as\nmeasured by AUC) of 0.69 -- a 17% increase over modeling language alone.\nFinally, we explore the linguist cues which distinguish stigmatizing content:\nPWUS substances and those who don't agree that language around othering\n(\"people\", \"they\") and terms like \"addict\" are stigmatizing, while PWUS (as\nopposed to those who do not) find discussions around specific substances more\nstigmatizing. Our findings offer insights into the nature of perceived stigma\nin substance use. Additionally, these results further establish the subjective\nnature of such machine learning tasks, highlighting the need for understanding\ntheir social contexts.", "published": "2023-02-04 02:26:08", "link": "http://arxiv.org/abs/2302.02064v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Prediction Backward-Compatiblility in NLP Model Upgrade with\n  Gated Fusion", "abstract": "When upgrading neural models to a newer version, new errors that were not\nencountered in the legacy version can be introduced, known as regression\nerrors. This inconsistent behavior during model upgrade often outweighs the\nbenefits of accuracy gain and hinders the adoption of new models. To mitigate\nregression errors from model upgrade, distillation and ensemble have proven to\nbe viable solutions without significant compromise in performance. Despite the\nprogress, these approaches attained an incremental reduction in regression\nwhich is still far from achieving backward-compatible model upgrade. In this\nwork, we propose a novel method, Gated Fusion, that promotes backward\ncompatibility via learning to mix predictions between old and new models.\nEmpirical results on two distinct model upgrade scenarios show that our method\nreduces the number of regression errors by 62% on average, outperforming the\nstrongest baseline by an average of 25%.", "published": "2023-02-04 03:40:35", "link": "http://arxiv.org/abs/2302.02080v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Completion Method Combined With Adaptive Enhanced\n  Semantic Information", "abstract": "Translation models tend to ignore the rich semantic information in triads in\nthe process of knowledge graph complementation. To remedy this shortcoming,\nthis paper constructs a knowledge graph complementation method that\nincorporates adaptively enhanced semantic information. The hidden semantic\ninformation inherent in the triad is obtained by fine-tuning the BERT model,\nand the attention feature embedding method is used to calculate the semantic\nattention scores between relations and entities in positive and negative triads\nand incorporate them into the structural information to form a soft constraint\nrule for semantic information. The rule is added to the original translation\nmodel to realize the adaptive enhancement of semantic information. In addition,\nthe method takes into account the effect of high-dimensional vectors on the\neffect, and uses the BERT-whitening method to reduce the dimensionality and\ngenerate a more efficient semantic vector representation. After experimental\ncomparison, the proposed method performs better on both FB15K and WIN18\ndatasets, with a numerical improvement of about 2.6% compared with the original\ntranslation model, which verifies the reasonableness and effectiveness of the\nmethod.", "published": "2023-02-04 07:01:02", "link": "http://arxiv.org/abs/2302.02116v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Construction Grammar Provides Unique Insight into Neural Language Models", "abstract": "Construction Grammar (CxG) has recently been used as the basis for probing\nstudies that have investigated the performance of large pretrained language\nmodels (PLMs) with respect to the structure and meaning of constructions. In\nthis position paper, we make suggestions for the continuation and augmentation\nof this line of research. We look at probing methodology that was not designed\nwith CxG in mind, as well as probing methodology that was designed for specific\nconstructions. We analyse selected previous work in detail, and provide our\nview of the most important challenges and research questions that this\npromising new field faces.", "published": "2023-02-04 15:06:26", "link": "http://arxiv.org/abs/2302.02178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Benchmark and Scoring Algorithm for Enriching Arabic Synonyms", "abstract": "This paper addresses the task of extending a given synset with additional\nsynonyms taking into account synonymy strength as a fuzzy value. Given a\nmono/multilingual synset and a threshold (a fuzzy value [0-1]), our goal is to\nextract new synonyms above this threshold from existing lexicons. We present\ntwofold contributions: an algorithm and a benchmark dataset. The dataset\nconsists of 3K candidate synonyms for 500 synsets. Each candidate synonym is\nannotated with a fuzzy value by four linguists. The dataset is important for\n(i) understanding how much linguists (dis/)agree on synonymy, in addition to\n(ii) using the dataset as a baseline to evaluate our algorithm. Our proposed\nalgorithm extracts synonyms from existing lexicons and computes a fuzzy value\nfor each candidate. Our evaluations show that the algorithm behaves like a\nlinguist and its fuzzy values are close to those proposed by linguists (using\nRMSE and MAE). The dataset and a demo page are publicly available at\nhttps://portal.sina.birzeit.edu/synonyms.", "published": "2023-02-04 20:30:32", "link": "http://arxiv.org/abs/2302.02232v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis on YouTube Smart Phone Unboxing Video Reviews in Sri\n  Lanka", "abstract": "Product-related reviews are based on users' experiences that are mostly\nshared on videos in YouTube. It is the second most popular website globally in\n2021. People prefer to watch videos on recently released products prior to\npurchasing, in order to gather overall feedback and make worthy decisions.\nThese videos are created by vloggers who are enthusiastic about technical\nmaterials and feedback is usually placed by experienced users of the product or\nits brand. Analyzing the sentiment of the user reviews gives useful insights\ninto the product in general. This study is focused on three smartphone reviews,\nnamely, Apple iPhone 13, Google Pixel 6, and Samsung Galaxy S21 which were\nreleased in 2021. VADER, which is a lexicon and rule-based sentiment analysis\ntool was used to classify each comment to its appropriate positive or negative\norientation. All three smartphones show a positive sentiment from the users'\nperspective and iPhone 13 has the highest number of positive reviews. The\nresulting models have been tested using N\\\"aive Bayes, Decision Tree, and\nSupport Vector Machine. Among these three classifiers, Support Vector Machine\nshows higher accuracies and F1-scores.", "published": "2023-02-04 06:55:24", "link": "http://arxiv.org/abs/2302.03496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation Deficiency in Masked Language Modeling", "abstract": "Masked Language Modeling (MLM) has been one of the most prominent approaches\nfor pretraining bidirectional text encoders due to its simplicity and\neffectiveness. One notable concern about MLM is that the special\n$\\texttt{[MASK]}$ symbol causes a discrepancy between pretraining data and\ndownstream data as it is present only in pretraining but not in fine-tuning. In\nthis work, we offer a new perspective on the consequence of such a discrepancy:\nWe demonstrate empirically and theoretically that MLM pretraining allocates\nsome model dimensions exclusively for representing $\\texttt{[MASK]}$ tokens,\nresulting in a representation deficiency for real tokens and limiting the\npretrained model's expressiveness when it is adapted to downstream data without\n$\\texttt{[MASK]}$ tokens. Motivated by the identified issue, we propose MAE-LM,\nwhich pretrains the Masked Autoencoder architecture with MLM where\n$\\texttt{[MASK]}$ tokens are excluded from the encoder. Empirically, we show\nthat MAE-LM improves the utilization of model dimensions for real token\nrepresentations, and MAE-LM consistently outperforms MLM-pretrained models\nacross different pretraining settings and model sizes when fine-tuned on the\nGLUE and SQuAD benchmarks.", "published": "2023-02-04 01:54:17", "link": "http://arxiv.org/abs/2302.02060v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Heterogeneous Federated Knowledge Graph Embedding Learning and\n  Unlearning", "abstract": "Federated Learning (FL) recently emerges as a paradigm to train a global\nmachine learning model across distributed clients without sharing raw data.\nKnowledge Graph (KG) embedding represents KGs in a continuous vector space,\nserving as the backbone of many knowledge-driven applications. As a promising\ncombination, federated KG embedding can fully take advantage of knowledge\nlearned from different clients while preserving the privacy of local data.\nHowever, realistic problems such as data heterogeneity and knowledge forgetting\nstill remain to be concerned. In this paper, we propose FedLU, a novel FL\nframework for heterogeneous KG embedding learning and unlearning. To cope with\nthe drift between local optimization and global convergence caused by data\nheterogeneity, we propose mutual knowledge distillation to transfer local\nknowledge to global, and absorb global knowledge back. Moreover, we present an\nunlearning method based on cognitive neuroscience, which combines retroactive\ninterference and passive decay to erase specific knowledge from local clients\nand propagate to the global model by reusing knowledge distillation. We\nconstruct new datasets for assessing realistic performance of the\nstate-of-the-arts. Extensive experiments show that FedLU achieves superior\nresults in both link prediction and knowledge forgetting.", "published": "2023-02-04 02:44:48", "link": "http://arxiv.org/abs/2302.02069v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FGSI: Distant Supervision for Relation Extraction method based on\n  Fine-Grained Semantic Information", "abstract": "The main purpose of relation extraction is to extract the semantic\nrelationships between tagged pairs of entities in a sentence, which plays an\nimportant role in the semantic understanding of sentences and the construction\nof knowledge graphs. In this paper, we propose that the key semantic\ninformation within a sentence plays a key role in the relationship extraction\nof entities. We propose the hypothesis that the key semantic information inside\nthe sentence plays a key role in entity relationship extraction. And based on\nthis hypothesis, we split the sentence into three segments according to the\nlocation of the entity from the inside of the sentence, and find the\nfine-grained semantic features inside the sentence through the intra-sentence\nattention mechanism to reduce the interference of irrelevant noise information.\nThe proposed relational extraction model can make full use of the available\npositive semantic information. The experimental results show that the proposed\nrelation extraction model improves the accuracy-recall curves and P@N values\ncompared with existing methods, which proves the effectiveness of this model.", "published": "2023-02-04 03:30:07", "link": "http://arxiv.org/abs/2302.02078v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A New cross-domain strategy based XAI models for fake news detection", "abstract": "In this study, we presented a four-level cross-domain strategy for fake news\ndetection on pre-trained models. Cross-domain text classification is a task of\na model adopting a target domain by using the knowledge of the source domain.\nExplainability is crucial in understanding the behaviour of these complex\nmodels. A fine-tune BERT model is used to. perform cross-domain classification\nwith several experiments using datasets from different domains. Explanatory\nmodels like Anchor, ELI5, LIME and SHAP are used to design a novel explainable\napproach to cross-domain levels. The experimental analysis has given an ideal\npair of XAI models on different levels of cross-domain.", "published": "2023-02-04 07:36:17", "link": "http://arxiv.org/abs/2302.02122v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Science of Detecting LLM-Generated Texts", "abstract": "The emergence of large language models (LLMs) has resulted in the production\nof LLM-generated texts that is highly sophisticated and almost\nindistinguishable from texts written by humans. However, this has also sparked\nconcerns about the potential misuse of such texts, such as spreading\nmisinformation and causing disruptions in the education system. Although many\ndetection approaches have been proposed, a comprehensive understanding of the\nachievements and challenges is still lacking. This survey aims to provide an\noverview of existing LLM-generated text detection techniques and enhance the\ncontrol and regulation of language generation models. Furthermore, we emphasize\ncrucial considerations for future research, including the development of\ncomprehensive evaluation metrics and the threat posed by open-source LLMs, to\ndrive progress in the area of LLM-generated text detection.", "published": "2023-02-04 04:49:17", "link": "http://arxiv.org/abs/2303.07205v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models in Theory of Mind Tasks", "abstract": "Eleven Large Language Models (LLMs) were assessed using a custom-made battery\nof false-belief tasks, considered a gold standard in testing Theory of Mind\n(ToM) in humans. The battery included 640 prompts spread across 40 diverse\ntasks, each one including a false-belief scenario, three closely matched\ntrue-belief control scenarios, and the reversed versions of all four. To solve\na single task, a model needed to correctly answer 16 prompts across all eight\nscenarios. Smaller and older models solved no tasks; GPT-3-davinci-003 (from\nNovember 2022) and ChatGPT-3.5-turbo (from March 2023) solved 20% of the tasks;\nChatGPT-4 (from June 2023) solved 75% of the tasks, matching the performance of\nsix-year-old children observed in past studies. We explore the potential\ninterpretation of these findings, including the intriguing possibility that\nToM, previously considered exclusive to humans, may have spontaneously emerged\nas a byproduct of LLMs' improving language skills.", "published": "2023-02-04 03:50:01", "link": "http://arxiv.org/abs/2302.02083v7", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Greedy Ordering of Layer Weight Matrices in Transformers Improves\n  Translation", "abstract": "Prior work has attempted to understand the internal structures and\nfunctionalities of Transformer-based encoder-decoder architectures on the level\nof multi-head attention and feed-forward sublayers. Interpretations have\nfocused on the encoder and decoder, along with the combinatorial possibilities\nof the self-attention, cross-attention, and feed-forward sublayers. However,\nwithout examining the low-level structures, one gains limited understanding of\nthe motivation behind sublayer reordering. Could we dive into the sublayer\nabstraction and permute layer weight matrices to improve the quality of\ntranslation? We propose AEIUOrder to greedily reorder layer weight matrices in\nthe encoder by their well-trainedness, as measured by Heavy-Tailed\nSelf-Regularization (HT-SR) metrics, and order the decoder matrices\ncorrespondingly. Our results suggest that greedily reordering layer weight\nmatrices to maximize Total well-trainedness facilitates the model to learn\nrepresentations and generate translations more effectively.", "published": "2023-02-04 07:44:23", "link": "http://arxiv.org/abs/2302.02123v3", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Interaction Order Prediction for Temporal Graphs", "abstract": "Link prediction in graphs is a task that has been widely investigated. It has\nbeen applied in various domains such as knowledge graph completion,\ncontent/item recommendation, social network recommendations and so on. The\ninitial focus of most research was on link prediction in static graphs.\nHowever, there has recently been abundant work on modeling temporal graphs, and\nconsequently one of the tasks that has been researched is link prediction in\ntemporal graphs. However, most of the existing work does not focus on the order\nof link formation, and only predicts the existence of links. In this study, we\naim to predict the order of node interactions.", "published": "2023-02-04 08:19:13", "link": "http://arxiv.org/abs/2302.02128v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "LipFormer: Learning to Lipread Unseen Speakers based on Visual-Landmark\n  Transformers", "abstract": "Lipreading refers to understanding and further translating the speech of a\nspeaker in the video into natural language. State-of-the-art lipreading methods\nexcel in interpreting overlap speakers, i.e., speakers appear in both training\nand inference sets. However, generalizing these methods to unseen speakers\nincurs catastrophic performance degradation due to the limited number of\nspeakers in training bank and the evident visual variations caused by the\nshape/color of lips for different speakers. Therefore, merely depending on the\nvisible changes of lips tends to cause model overfitting. To address this\nproblem, we propose to use multi-modal features across visual and landmarks,\nwhich can describe the lip motion irrespective to the speaker identities. Then,\nwe develop a sentence-level lipreading framework based on visual-landmark\ntransformers, namely LipFormer. Specifically, LipFormer consists of a lip\nmotion stream, a facial landmark stream, and a cross-modal fusion. The\nembeddings from the two streams are produced by self-attention, which are fed\nto the cross-attention module to achieve the alignment between visuals and\nlandmarks. Finally, the resulting fused features can be decoded to output texts\nby a cascade seq2seq model. Experiments demonstrate that our method can\neffectively enhance the model generalization to unseen speakers.", "published": "2023-02-04 10:22:18", "link": "http://arxiv.org/abs/2302.02141v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Invariants for neural automata", "abstract": "Computational modeling of neurodynamical systems often deploys neural\nnetworks and symbolic dynamics. A particular way for combining these approaches\nwithin a framework called vector symbolic architectures leads to neural\nautomata. An interesting research direction we have pursued under this\nframework has been to consider mapping symbolic dynamics onto neurodynamics,\nrepresented as neural automata. This representation theory, enables us to ask\nquestions, such as, how does the brain implement Turing computations.\nSpecifically, in this representation theory, neural automata result from the\nassignment of symbols and symbol strings to numbers, known as G\\\"odel encoding.\nUnder this assignment symbolic computation becomes represented by trajectories\nof state vectors in a real phase space, that allows for statistical correlation\nanalyses with real-world measurements and experimental data. However, these\nassignments are usually completely arbitrary. Hence, it makes sense to address\nthe problem question of, which aspects of the dynamics observed under such a\nrepresentation is intrinsic to the dynamics and which are not. In this study,\nwe develop a formally rigorous mathematical framework for the investigation of\nsymmetries and invariants of neural automata under different encodings. As a\ncentral concept we define patterns of equality for such systems. We consider\ndifferent macroscopic observables, such as the mean activation level of the\nneural network, and ask for their invariance properties. Our main result shows\nthat only step functions that are defined over those patterns of equality are\ninvariant under recodings, while the mean activation is not. Our work could be\nof substantial importance for related regression studies of real-world\nmeasurements with neurosymbolic processors for avoiding confounding results\nthat are dependant on a particular encoding and not intrinsic to the dynamics.", "published": "2023-02-04 11:40:40", "link": "http://arxiv.org/abs/2302.02149v1", "categories": ["cs.NE", "cs.CL", "cs.FL", "cs.SC"], "primary_category": "cs.NE"}
{"title": "How Many and Which Training Points Would Need to be Removed to Flip this\n  Prediction?", "abstract": "We consider the problem of identifying a minimal subset of training data\n$\\mathcal{S}_t$ such that if the instances comprising $\\mathcal{S}_t$ had been\nremoved prior to training, the categorization of a given test point $x_t$ would\nhave been different. Identifying such a set may be of interest for a few\nreasons. First, the cardinality of $\\mathcal{S}_t$ provides a measure of\nrobustness (if $|\\mathcal{S}_t|$ is small for $x_t$, we might be less confident\nin the corresponding prediction), which we show is correlated with but\ncomplementary to predicted probabilities. Second, interrogation of\n$\\mathcal{S}_t$ may provide a novel mechanism for contesting a particular model\nprediction: If one can make the case that the points in $\\mathcal{S}_t$ are\nwrongly labeled or irrelevant, this may argue for overturning the associated\nprediction. Identifying $\\mathcal{S}_t$ via brute-force is intractable. We\npropose comparatively fast approximation methods to find $\\mathcal{S}_t$ based\non influence functions, and find that -- for simple convex text classification\nmodels -- these approaches can often successfully identify relatively small\nsets of training examples which, if removed, would flip the prediction.", "published": "2023-02-04 13:55:12", "link": "http://arxiv.org/abs/2302.02169v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene\n  Synthesis", "abstract": "Can machines recording an audio-visual scene produce realistic, matching\naudio-visual experiences at novel positions and novel view directions? We\nanswer it by studying a new task -- real-world audio-visual scene synthesis --\nand a first-of-its-kind NeRF-based approach for multimodal learning.\nConcretely, given a video recording of an audio-visual scene, the task is to\nsynthesize new videos with spatial audios along arbitrary novel camera\ntrajectories in that scene. We propose an acoustic-aware audio generation\nmodule that integrates prior knowledge of audio propagation into NeRF, in which\nwe implicitly associate audio generation with the 3D geometry and material\nproperties of a visual environment. Furthermore, we present a coordinate\ntransformation module that expresses a view direction relative to the sound\nsource, enabling the model to learn sound source-centric acoustic fields. To\nfacilitate the study of this new task, we collect a high-quality Real-World\nAudio-Visual Scene (RWAVS) dataset. We demonstrate the advantages of our method\non this real-world dataset and the simulation-based SoundSpaces dataset.", "published": "2023-02-04 04:17:19", "link": "http://arxiv.org/abs/2302.02088v3", "categories": ["cs.CV", "cs.GR", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Multi-Source Diffusion Models for Simultaneous Music Generation and\n  Separation", "abstract": "In this work, we define a diffusion-based generative model capable of both\nmusic synthesis and source separation by learning the score of the joint\nprobability density of sources sharing a context. Alongside the classic total\ninference tasks (i.e., generating a mixture, separating the sources), we also\nintroduce and experiment on the partial generation task of source imputation,\nwhere we generate a subset of the sources given the others (e.g., play a piano\ntrack that goes well with the drums). Additionally, we introduce a novel\ninference method for the separation task based on Dirac likelihood functions.\nWe train our model on Slakh2100, a standard dataset for musical source\nseparation, provide qualitative results in the generation settings, and\nshowcase competitive quantitative results in the source separation setting. Our\nmethod is the first example of a single model that can handle both generation\nand separation tasks, thus representing a step toward general audio models.", "published": "2023-02-04 23:18:36", "link": "http://arxiv.org/abs/2302.02257v4", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
