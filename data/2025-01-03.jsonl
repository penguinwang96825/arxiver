{"title": "On consistency of optimal portfolio choice for state-dependent exponential utilities", "abstract": "In an arbitrage-free simple market, we demonstrate that for a class of\nstate-dependent exponential utilities, there exists a unique prediction of the\nrandom risk aversion that ensures the consistency of optimal strategies across\nany time horizon. Our solution aligns with the theory of forward performances,\nwith the added distinction of identifying, among the infinite possible\nsolutions, the one for which the profile remains optimal at all times for the\nmarket-adjusted system of preferences adopted.", "published": "2025-01-03 10:25:53", "link": "http://arxiv.org/abs/2501.01748v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "MIRAGE: Exploring How Large Language Models Perform in Complex Social\n  Interactive Environments", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in\nenvironmental perception, reasoning-based decision-making, and simulating\ncomplex human behaviors, particularly in interactive role-playing contexts.\nThis paper introduces the Multiverse Interactive Role-play Ability General\nEvaluation (MIRAGE), a comprehensive framework designed to assess LLMs'\nproficiency in portraying advanced human behaviors through murder mystery\ngames. MIRAGE features eight intricately crafted scripts encompassing diverse\nthemes and styles, providing a rich simulation. To evaluate LLMs' performance,\nMIRAGE employs four distinct methods: the Trust Inclination Index (TII) to\nmeasure dynamics of trust and suspicion, the Clue Investigation Capability\n(CIC) to measure LLMs' capability of conducting information, the Interactivity\nCapability Index (ICI) to assess role-playing capabilities and the Script\nCompliance Index (SCI) to assess LLMs' capability of understanding and\nfollowing instructions. Our experiments indicate that even popular models like\nGPT-4 face significant challenges in navigating the complexities presented by\nthe MIRAGE. The datasets and simulation codes are available in\n\\href{https://github.com/lime728/MIRAGE}{github}.", "published": "2025-01-03 06:07:48", "link": "http://arxiv.org/abs/2501.01652v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoT-based Synthesizer: Enhancing LLM Performance through Answer\n  Synthesis", "abstract": "Current inference scaling methods, such as Self-consistency and Best-of-N,\nhave proven effective in improving the accuracy of LLMs on complex reasoning\ntasks. However, these methods rely heavily on the quality of candidate\nresponses and are unable to produce correct answers when all candidates are\nincorrect. In this paper, we propose a novel inference scaling strategy,\nCoT-based Synthesizer, which leverages CoT reasoning to synthesize superior\nanswers by analyzing complementary information from multiple candidate\nresponses, even when all candidate responses are flawed. To enable a\nlightweight and cost-effective implementation, we introduce an automated data\ngeneration pipeline that creates diverse training data. This allows smaller\nLLMs trained on this data to improve the inference accuracy of larger models,\nincluding API-based LLMs. Experimental results across four benchmark datasets\nwith seven policy models demonstrate that our method significantly enhances\nperformance, with gains of 11.8% for Llama3-8B and 10.3% for GPT-4o on the MATH\ndataset. The corresponding training data and code are publicly available on\nhttps://github.com/RUCKBReasoning/CoT-based-Synthesizer.", "published": "2025-01-03 06:50:06", "link": "http://arxiv.org/abs/2501.01668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reading Between the Lines: A dataset and a study on why some texts are\n  tougher than others", "abstract": "Our research aims at better understanding what makes a text difficult to read\nfor specific audiences with intellectual disabilities, more specifically,\npeople who have limitations in cognitive functioning, such as reading and\nunderstanding skills, an IQ below 70, and challenges in conceptual domains. We\nintroduce a scheme for the annotation of difficulties which is based on\nempirical research in psychology as well as on research in translation studies.\nThe paper describes the annotated dataset, primarily derived from the parallel\ntexts (standard English and Easy to Read English translations) made available\nonline. we fine-tuned four different pre-trained transformer models to perform\nthe task of multiclass classification to predict the strategies required for\nsimplification. We also investigate the possibility to interpret the decisions\nof this language model when it is aimed at predicting the difficulty of\nsentences. The resources are available from\nhttps://github.com/Nouran-Khallaf/why-tough", "published": "2025-01-03 13:09:46", "link": "http://arxiv.org/abs/2501.01796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Turning Logic Against Itself : Probing Model Defenses Through\n  Contrastive Questions", "abstract": "Large language models, despite extensive alignment with human values and\nethical principles, remain vulnerable to sophisticated jailbreak attacks that\nexploit their reasoning abilities. Existing safety measures often detect overt\nmalicious intent but fail to address subtle, reasoning-driven vulnerabilities.\nIn this work, we introduce POATE (Polar Opposite query generation, Adversarial\nTemplate construction, and Elaboration), a novel jailbreak technique that\nharnesses contrastive reasoning to provoke unethical responses. POATE crafts\nsemantically opposing intents and integrates them with adversarial templates,\nsteering models toward harmful outputs with remarkable subtlety. We conduct\nextensive evaluation across six diverse language model families of varying\nparameter sizes to demonstrate the robustness of the attack, achieving\nsignificantly higher attack success rates (~44%) compared to existing methods.\nTo counter this, we propose Intent-Aware CoT and Reverse Thinking CoT, which\ndecompose queries to detect malicious intent and reason in reverse to evaluate\nand reject harmful responses. These methods enhance reasoning robustness and\nstrengthen the model's defense against adversarial exploits.", "published": "2025-01-03 15:40:03", "link": "http://arxiv.org/abs/2501.01872v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metadata Conditioning Accelerates Language Model Pre-training", "abstract": "The vast diversity of styles, domains, and quality levels present in language\nmodel pre-training corpora is essential in developing general model\ncapabilities, but efficiently learning and deploying the correct behaviors\nexemplified in each of these heterogeneous data sources is challenging. To\naddress this, we propose a new method, termed Metadata Conditioning then\nCooldown (MeCo), to incorporate additional learning cues during pre-training.\nMeCo first provides metadata (e.g., URLs like www$.$wikipedia$.$org) alongside\nthe text during training and later uses a cooldown phase with only the standard\ntext, thereby enabling the model to function normally even without metadata.\nMeCo significantly accelerates pre-training across different model scales (600M\nto 8B parameters) and training sources (C4, RefinedWeb, and DCLM). For\ninstance, a 1.6B language model trained with MeCo matches the downstream task\nperformance of standard pre-training while using 33% less data. Additionally,\nMeCo enables us to steer language models by conditioning the inference prompt\non either real or fabricated metadata that encodes the desired properties of\nthe output: for example, prepending wikipedia$.$org to reduce harmful\ngenerations or factquizmaster$.$com (fabricated) to improve common knowledge\ntask performance. We also demonstrate that MeCo is compatible with different\ntypes of metadata, such as model-generated topics. MeCo is remarkably simple,\nadds no computational overhead, and demonstrates promise in producing more\ncapable and steerable language models.", "published": "2025-01-03 18:59:23", "link": "http://arxiv.org/abs/2501.01956v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction-Following Pruning for Large Language Models", "abstract": "With the rapid scaling of large language models (LLMs), structured pruning\nhas become a widely used technique to learn efficient, smaller models from\nlarger ones, delivering superior performance compared to training similarly\nsized models from scratch. In this paper, we move beyond the traditional static\npruning approach of determining a fixed pruning mask for a model, and propose a\ndynamic approach to structured pruning. In our method, the pruning mask is\ninput-dependent and adapts dynamically based on the information described in a\nuser instruction. Our approach, termed \"instruction-following pruning\",\nintroduces a sparse mask predictor that takes the user instruction as input and\ndynamically selects the most relevant model parameters for the given task. To\nidentify and activate effective parameters, we jointly optimize the sparse mask\npredictor and the LLM, leveraging both instruction-following data and the\npre-training corpus. Experimental results demonstrate the effectiveness of our\napproach on a wide range of evaluation benchmarks. For example, our 3B\nactivated model improves over the 3B dense model by 5-8 points of absolute\nmargin on domains such as math and coding, and rivals the performance of a 9B\nmodel.", "published": "2025-01-03 20:19:14", "link": "http://arxiv.org/abs/2501.02086v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applying Text Mining to Analyze Human Question Asking in Creativity\n  Research", "abstract": "Creativity relates to the ability to generate novel and effective ideas in\nthe areas of interest. How are such creative ideas generated? One possible\nmechanism that supports creative ideation and is gaining increased empirical\nattention is by asking questions. Question asking is a likely cognitive\nmechanism that allows defining problems, facilitating creative problem solving.\nHowever, much is unknown about the exact role of questions in creativity. This\nwork presents an attempt to apply text mining methods to measure the cognitive\npotential of questions, taking into account, among others, (a) question type,\n(b) question complexity, and (c) the content of the answer. This contribution\nsummarizes the history of question mining as a part of creativity research,\nalong with the natural language processing methods deemed useful or helpful in\nthe study. In addition, a novel approach is proposed, implemented, and applied\nto five datasets. The experimental results obtained are comprehensively\nanalyzed, suggesting that natural language processing has a role to play in\ncreative research.", "published": "2025-01-03 20:28:42", "link": "http://arxiv.org/abs/2501.02090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Small Language Models (SLMs) Can Still Pack a Punch: A survey", "abstract": "As foundation AI models continue to increase in size, an important question\narises - is massive scale the only path forward? This survey of about 160\npapers presents a family of Small Language Models (SLMs) in the 1 to 8 billion\nparameter range that demonstrate smaller models can perform as well, or even\noutperform large models. We explore task agnostic, general purpose SLMs,\ntask-specific SLMs and techniques to create SLMs that can guide the community\nto build models while balancing performance, efficiency, scalability and cost.\nFurthermore we define and characterize SLMs' effective sizes, representing\nincreased capability with respect to LLMs.", "published": "2025-01-03 19:53:57", "link": "http://arxiv.org/abs/2501.05465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering:\n  Methodology, Results, and Challenges", "abstract": "Large Language Models (LLMs) have become essential tools across various\ndomains due to their impressive capabilities in understanding and generating\nhuman-like text. The ability to accurately answer multiple-choice questions\n(MCQs) holds significant value in education, particularly in automated tutoring\nsystems and assessment platforms. However, adapting LLMs to handle MCQ tasks\neffectively remains challenging due to the hallucinations and unclear prompts.\nThis work explores the potential of Microsoft's PHI-3\\cite{Abdin2024}, a\ncompact yet efficient LLM, for MCQ answering. Our contributions include\nfine-tuning the model on the TruthfulQA dataset, designing optimized prompts to\nenhance model performance, and evaluating using perplexity and traditional\nmetrics like accuracy and F1 score. Results show a remarkable improvement in\nPHI-3.5's MCQ handling post-fine-tuning, with perplexity decreasing from 4.68\nto 2.27, and accuracy rising from 62\\% to 90.8\\%. This research underlines the\nimportance of efficient models in adaptive learning systems and educational\nassessments, paving the way for broader integration into the classroom,\nparticularly in fields like test preparation, student feedback, and\npersonalized learning.", "published": "2025-01-03 00:56:46", "link": "http://arxiv.org/abs/2501.01588v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ICPC: In-context Prompt Compression with Faster Inference", "abstract": "Despite the recent success of Large Language Models (LLMs), it remains\nchallenging to feed LLMs with long prompts due to the fixed size of LLM inputs.\nAs a remedy, prompt compression becomes a promising solution by removing\nredundant tokens in the prompt. However, using LLM in the existing works\nrequires additional computation resources and leads to memory overheads. To\naddress it, we propose ICPC (In-context Prompt Compression), a novel and\nscalable prompt compression method that adaptively reduces the prompt length.\nThe key idea of ICPC is to calculate the probability of each word appearing in\nthe prompt using encoders and calculate information carried by each word\nthrough the information function, which effectively reduces the information\nloss during prompt compression and increases the speed of compression.\nEmpirically, we demonstrate that ICPC can effectively compress long texts of\ndifferent categories and thus achieve better performance and speed on different\ntypes of NLP tasks.", "published": "2025-01-03 03:46:51", "link": "http://arxiv.org/abs/2501.01625v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Contrastive Representation Learning in Augmented Biomedical\n  Knowledge Graphs", "abstract": "Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate\ncomplex relationships within the biomedical field. Effective link prediction on\nthese graphs can uncover valuable connections, such as potential novel\ndrug-disease relations. We introduce a novel multimodal approach that unifies\nembeddings from specialized Language Models (LMs) with Graph Contrastive\nLearning (GCL) to enhance intra-entity relationships while employing a\nKnowledge Graph Embedding (KGE) model to capture inter-entity relationships for\neffective link prediction. To address limitations in existing BKGs, we present\nPrimeKG++, an enriched knowledge graph incorporating multimodal data, including\nbiological sequences and textual descriptions for each entity type. By\ncombining semantic and relational information in a unified representation, our\napproach demonstrates strong generalizability, enabling accurate link\npredictions even for unseen nodes. Experimental results on PrimeKG++ and the\nDrugBank drug-target interaction dataset demonstrate the effectiveness and\nrobustness of our method across diverse biomedical datasets. Our source code,\npre-trained models, and data are publicly available at\nhttps://github.com/HySonLab/BioMedKG", "published": "2025-01-03 05:29:12", "link": "http://arxiv.org/abs/2501.01644v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive Few-shot Prompting for Machine Translation with Pre-trained\n  Language Models", "abstract": "Recently, Large language models (LLMs) with in-context learning have\ndemonstrated remarkable potential in handling neural machine translation.\nHowever, existing evidence shows that LLMs are prompt-sensitive and it is\nsub-optimal to apply the fixed prompt to any input for downstream machine\ntranslation tasks. To address this issue, we propose an adaptive few-shot\nprompting (AFSP) framework to automatically select suitable translation\ndemonstrations for various source input sentences to further elicit the\ntranslation capability of an LLM for better machine translation. First, we\nbuild a translation demonstration retrieval module based on LLM's embedding to\nretrieve top-k semantic-similar translation demonstrations from aligned\nparallel translation corpus. Rather than using other embedding models for\nsemantic demonstration retrieval, we build a hybrid demonstration retrieval\nmodule based on the embedding layer of the deployed LLM to build better input\nrepresentation for retrieving more semantic-related translation demonstrations.\nThen, to ensure better semantic consistency between source inputs and target\noutputs, we force the deployed LLM itself to generate multiple output\ncandidates in the target language with the help of translation demonstrations\nand rerank these candidates. Besides, to better evaluate the effectiveness of\nour AFSP framework on the latest language and extend the research boundary of\nneural machine translation, we construct a high-quality diplomatic\nChinese-English parallel dataset that consists of 5,528 parallel\nChinese-English sentences. Finally, extensive experiments on the proposed\ndiplomatic Chinese-English parallel dataset and the United Nations Parallel\nCorpus (Chinese-English part) show the effectiveness and superiority of our\nproposed AFSP.", "published": "2025-01-03 07:47:59", "link": "http://arxiv.org/abs/2501.01679v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Essence of Contextual Understanding in Theory of Mind: A Study on\n  Question Answering with Story Characters", "abstract": "Theory-of-Mind (ToM) is a fundamental psychological capability that allows\nhumans to understand and interpret the mental states of others. Humans infer\nothers' thoughts by integrating causal cues and indirect clues from broad\ncontextual information, often derived from past interactions. In other words,\nhuman ToM heavily relies on the understanding about the backgrounds and life\nstories of others. Unfortunately, this aspect is largely overlooked in existing\nbenchmarks for evaluating machines' ToM capabilities, due to their usage of\nshort narratives without global context, especially personal background of\ncharacters. In this paper, we verify the importance of comprehensive contextual\nunderstanding about personal backgrounds in ToM and assess the performance of\nLLMs in such complex scenarios. To achieve this, we introduce CharToM\nbenchmark, comprising 1,035 ToM questions based on characters from classic\nnovels. Our human study reveals a significant disparity in performance: the\nsame group of educated participants performs dramatically better when they have\nread the novels compared to when they have not. In parallel, our experiments on\nstate-of-the-art LLMs, including the very recent o1 and DeepSeek-R1 models,\nshow that LLMs still perform notably worse than humans, despite that they have\nseen these stories during pre-training. This highlights the limitations of\ncurrent LLMs in capturing the nuanced contextual information required for ToM\nreasoning.", "published": "2025-01-03 09:04:45", "link": "http://arxiv.org/abs/2501.01705v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automating Legal Concept Interpretation with LLMs: Retrieval,\n  Generation, and Evaluation", "abstract": "Legal articles often include vague concepts for adapting to the ever-changing\nsociety. Providing detailed interpretations of these concepts is a critical and\nchallenging task even for legal practitioners. It requires meticulous and\nprofessional annotations and summarizations by legal experts, which are\nadmittedly time-consuming and expensive to collect at scale. By emulating legal\nexperts' doctrinal method, we introduce a novel framework, ATRIE, using large\nlanguage models (LLMs) to AuTomatically Retrieve concept-related information,\nInterpret legal concepts, and Evaluate generated interpretations, eliminating\ndependence on legal experts. ATRIE comprises a legal concept interpreter and a\nlegal concept interpretation evaluator. The interpreter uses LLMs to retrieve\nrelevant information from judicial precedents and interpret legal concepts. The\nevaluator uses performance changes on legal concept entailment, a downstream\ntask we propose, as a proxy of interpretation quality. Automatic and\nmultifaceted human evaluations indicate that the quality of our interpretations\nis comparable to those written by legal experts, with superior\ncomprehensiveness and readability. Although there remains a slight gap in\naccuracy, it can already assist legal practitioners in improving the efficiency\nof concept interpretation.", "published": "2025-01-03 10:11:38", "link": "http://arxiv.org/abs/2501.01743v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "End-to-End Long Document Summarization using Gradient Caching", "abstract": "Training transformer-based encoder-decoder models for long document\nsummarization poses a significant challenge due to the quadratic memory\nconsumption during training. Several approaches have been proposed to extend\nthe input length at test time, but training with these approaches is still\ndifficult, requiring truncation of input documents and causing a mismatch\nbetween training and test conditions. In this work, we propose CachED (Gradient\n$\\textbf{Cach}$ing for $\\textbf{E}$ncoder-$\\textbf{D}$ecoder models), an\napproach that enables end-to-end training of existing transformer-based\nencoder-decoder models, using the entire document without truncation.\nSpecifically, we apply non-overlapping sliding windows to input documents,\nfollowed by fusion in decoder. During backpropagation, the gradients are cached\nat the decoder and are passed through the encoder in chunks by re-computing the\nhidden vectors, similar to gradient checkpointing. In the experiments on long\ndocument summarization, we extend BART to CachED BART, processing more than\n500K tokens during training and achieving superior performance without using\nany additional parameters.", "published": "2025-01-03 13:32:57", "link": "http://arxiv.org/abs/2501.01805v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SDPO: Segment-Level Direct Preference Optimization for Social Agents", "abstract": "Social agents powered by large language models (LLMs) can simulate human\nsocial behaviors but fall short in handling complex social dialogues. Direct\nPreference Optimization (DPO) has proven effective in aligning LLM behavior\nwith human preferences across various agent tasks. However, standard DPO\nfocuses solely on individual turns, which limits its effectiveness in\nmulti-turn social interactions. Several DPO-based multi-turn alignment methods\nwith session-level data have shown potential in addressing this problem.While\nthese methods consider multiple turns across entire sessions, they are often\noverly coarse-grained, introducing training noise, and lack robust theoretical\nsupport. To resolve these limitations, we propose Segment-Level Direct\nPreference Optimization (SDPO), which dynamically select key segments within\ninteractions to optimize multi-turn agent behavior. SDPO minimizes training\nnoise and is grounded in a rigorous theoretical framework. Evaluations on the\nSOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform\nboth existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring\nSDPO's potential to advance the social intelligence of LLM-based agents. We\nrelease our code and data at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO.", "published": "2025-01-03 14:09:46", "link": "http://arxiv.org/abs/2501.01821v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Proof is in the Almond Cookies", "abstract": "This paper presents a case study on how to process cooking recipes (and more\ngenerally, how-to instructions) in a way that makes it possible for a robot or\nartificial cooking assistant to support human chefs in the kitchen. Such AI\nassistants would be of great benefit to society, as they can help to sustain\nthe autonomy of aging adults or people with a physical impairment, or they may\nreduce the stress in a professional kitchen. We propose a novel approach to\ncomputational recipe understanding that mimics the human sense-making process,\nwhich is narrative-based. Using an English recipe for almond crescent cookies\nas illustration, we show how recipes can be modelled as rich narrative\nstructures by integrating various knowledge sources such as language\nprocessing, ontologies, and mental simulation. We show how such narrative\nstructures can be used for (a) dealing with the challenges of recipe language,\nsuch as zero anaphora, (b) optimizing a robot's planning process, (c) measuring\nhow well an AI system understands its current tasks, and (d) allowing recipe\nannotations to become language-independent.", "published": "2025-01-03 14:25:35", "link": "http://arxiv.org/abs/2501.01827v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Time Series Language Model for Descriptive Caption Generation", "abstract": "The automatic generation of representative natural language descriptions for\nobservable patterns in time series data enhances interpretability, simplifies\nanalysis and increases cross-domain utility of temporal data. While pre-trained\nfoundation models have made considerable progress in natural language\nprocessing (NLP) and computer vision (CV), their application to time series\nanalysis has been hindered by data scarcity. Although several large language\nmodel (LLM)-based methods have been proposed for time series forecasting, time\nseries captioning is under-explored in the context of LLMs. In this paper, we\nintroduce TSLM, a novel time series language model designed specifically for\ntime series captioning. TSLM operates as an encoder-decoder model, leveraging\nboth text prompts and time series data representations to capture subtle\ntemporal patterns across multiple phases and generate precise textual\ndescriptions of time series inputs. TSLM addresses the data scarcity problem in\ntime series captioning by first leveraging an in-context prompting synthetic\ndata generation, and second denoising the generated data via a novel\ncross-modal dense retrieval scoring applied to time series-caption pairs.\nExperimental findings on various time series captioning datasets demonstrate\nthat TSLM outperforms existing state-of-the-art approaches from multiple data\nmodalities by a significant margin.", "published": "2025-01-03 14:34:30", "link": "http://arxiv.org/abs/2501.01832v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Abstractive Text Summarization for Contemporary Sanskrit Prose: Issues\n  and Challenges", "abstract": "This thesis presents Abstractive Text Summarization models for contemporary\nSanskrit prose. The first chapter, titled Introduction, presents the motivation\nbehind this work, the research questions, and the conceptual framework.\nSanskrit is a low-resource inflectional language. The key research question\nthat this thesis investigates is what the challenges in developing an\nabstractive TS for Sanskrit. To answer the key research questions,\nsub-questions based on four different themes have been posed in this work. The\nsecond chapter, Literature Review, surveys the previous works done. The third\nchapter, data preparation, answers the remaining three questions from the third\ntheme. It reports the data collection and preprocessing challenges for both\nlanguage model and summarization model trainings. The fourth chapter reports\nthe training and inference of models and the results obtained therein. This\nresearch has initiated a pipeline for Sanskrit abstractive text summarization\nand has reported the challenges faced at every stage of the development. The\nresearch questions based on every theme have been answered to answer the key\nresearch question.", "published": "2025-01-03 18:12:13", "link": "http://arxiv.org/abs/2501.01933v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CarbonChat: Large Language Model-Based Corporate Carbon Emission\n  Analysis and Climate Knowledge Q&A System", "abstract": "As the impact of global climate change intensifies, corporate carbon\nemissions have become a focal point of global attention. In response to issues\nsuch as the lag in climate change knowledge updates within large language\nmodels, the lack of specialization and accuracy in traditional augmented\ngeneration architectures for complex problems, and the high cost and time\nconsumption of sustainability report analysis, this paper proposes CarbonChat:\nLarge Language Model-based corporate carbon emission analysis and climate\nknowledge Q&A system, aimed at achieving precise carbon emission analysis and\npolicy understanding.First, a diversified index module construction method is\nproposed to handle the segmentation of rule-based and long-text documents, as\nwell as the extraction of structured data, thereby optimizing the parsing of\nkey information.Second, an enhanced self-prompt retrieval-augmented generation\narchitecture is designed, integrating intent recognition, structured reasoning\nchains, hybrid retrieval, and Text2SQL, improving the efficiency of semantic\nunderstanding and query conversion.Next, based on the greenhouse gas accounting\nframework, 14 dimensions are established for carbon emission analysis, enabling\nreport summarization, relevance evaluation, and customized responses.Finally,\nthrough a multi-layer chunking mechanism, timestamps, and hallucination\ndetection features, the accuracy and verifiability of the analysis results are\nensured, reducing hallucination rates and enhancing the precision of the\nresponses.", "published": "2025-01-03 08:45:38", "link": "http://arxiv.org/abs/2501.02031v1", "categories": ["cs.CL", "cs.AI", "68T07, 91B06", "I.2.1"], "primary_category": "cs.CL"}
{"title": "An Investigation into Value Misalignment in LLM-Generated Texts for\n  Cultural Heritage", "abstract": "As Large Language Models (LLMs) become increasingly prevalent in tasks\nrelated to cultural heritage, such as generating descriptions of historical\nmonuments, translating ancient texts, preserving oral traditions, and creating\neducational content, their ability to produce accurate and culturally aligned\ntexts is being increasingly relied upon by users and researchers. However,\ncultural value misalignments may exist in generated texts, such as the\nmisrepresentation of historical facts, the erosion of cultural identity, and\nthe oversimplification of complex cultural narratives, which may lead to severe\nconsequences. Therefore, investigating value misalignment in the context of LLM\nfor cultural heritage is crucial for mitigating these risks, yet there has been\na significant lack of systematic and comprehensive study and investigation in\nthis area. To fill this gap, we systematically assess the reliability of LLMs\nin generating culturally aligned texts for cultural heritage-related tasks. We\nconduct a comprehensive evaluation by compiling an extensive set of 1066 query\ntasks covering 5 widely recognized categories with 17 aspects within the\nknowledge framework of cultural heritage across 5 open-source LLMs, and examine\nboth the type and rate of cultural value misalignments in the generated texts.\nUsing both automated and manual approaches, we effectively detect and analyze\nthe cultural value misalignments in LLM-generated texts. Our findings are\nconcerning: over 65% of the generated texts exhibit notable cultural\nmisalignments, with certain tasks demonstrating almost complete misalignment\nwith key cultural values. Beyond these findings, this paper introduces a\nbenchmark dataset and a comprehensive evaluation workflow that can serve as a\nvaluable resource for future research aimed at enhancing the cultural\nsensitivity and reliability of LLMs.", "published": "2025-01-03 14:35:32", "link": "http://arxiv.org/abs/2501.02039v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Advancing Pancreatic Cancer Prediction with a Next Visit Token\n  Prediction Head on top of Med-BERT", "abstract": "Background: Recently, numerous foundation models pretrained on extensive data\nhave demonstrated efficacy in disease prediction using Electronic Health\nRecords (EHRs). However, there remains some unanswered questions on how to best\nutilize such models especially with very small fine-tuning cohorts. Methods: We\nutilized Med-BERT, an EHR-specific foundation model, and reformulated the\ndisease binary prediction task into a token prediction task and a next visit\nmask token prediction task to align with Med-BERT's pretraining task format in\norder to improve the accuracy of pancreatic cancer (PaCa) prediction in both\nfew-shot and fully supervised settings. Results: The reformulation of the task\ninto a token prediction task, referred to as Med-BERT-Sum, demonstrates\nslightly superior performance in both few-shot scenarios and larger data\nsamples. Furthermore, reformulating the prediction task as a Next Visit Mask\nToken Prediction task (Med-BERT-Mask) significantly outperforms the\nconventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to\n7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These\nfindings highlight that aligning the downstream task with Med-BERT's\npretraining objectives substantially enhances the model's predictive\ncapabilities, thereby improving its effectiveness in predicting both rare and\ncommon diseases. Conclusion: Reformatting disease prediction tasks to align\nwith the pretraining of foundation models enhances prediction accuracy, leading\nto earlier detection and timely intervention. This approach improves treatment\neffectiveness, survival rates, and overall patient outcomes for PaCa and\npotentially other cancers.", "published": "2025-01-03 18:32:05", "link": "http://arxiv.org/abs/2501.02044v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AGGA: A Dataset of Academic Guidelines for Generative AI and Large\n  Language Models", "abstract": "This study introduces AGGA, a dataset comprising 80 academic guidelines for\nthe use of Generative AIs (GAIs) and Large Language Models (LLMs) in academic\nsettings, meticulously collected from official university websites. The dataset\ncontains 188,674 words and serves as a valuable resource for natural language\nprocessing tasks commonly applied in requirements engineering, such as model\nsynthesis, abstraction identification, and document structure assessment.\nAdditionally, AGGA can be further annotated to function as a benchmark for\nvarious tasks, including ambiguity detection, requirements categorization, and\nthe identification of equivalent requirements. Our methodologically rigorous\napproach ensured a thorough examination, with a selection of universities that\nrepresent a diverse range of global institutions, including top-ranked\nuniversities across six continents. The dataset captures perspectives from a\nvariety of academic fields, including humanities, technology, and both public\nand private institutions, offering a broad spectrum of insights into the\nintegration of GAIs and LLMs in academia.", "published": "2025-01-03 19:16:36", "link": "http://arxiv.org/abs/2501.02063v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "The interplay between domain specialization and model size", "abstract": "Scaling laws for language models have often focused on finding the optimal\nmodel size and token count for training from scratch. However, achieving this\noptimal balance requires significant compute resources due to the extensive\ndata demands when training models from randomly-initialized weights. Continued\npretraining offers a cost-effective alternative, leveraging the compute\ninvestment from pretrained models to incorporate new knowledge without\nrequiring extensive new data. Recent findings suggest that data quality\ninfluences constants in scaling laws, thereby altering the optimal\nparameter-token allocation ratio. Building on this insight, we investigate the\ninterplay between domain specialization and model size during continued\npretraining under compute-constrained scenarios. Our goal is to identify an\noptimal training regime for this scenario and detect patterns in this interplay\nthat can be generalized across different model sizes and domains. To compare\ngeneral and specialized training, we filtered a web-based dataset to extract\ndata from three domains: legal, medical, and accounting. We pretrained models\nwith 1.5B, 3B, 7B, and 14B parameters on both the unfiltered and filtered\ndatasets, then evaluated their performance on domain-specific exams. Results\nshow that as model size increases, specialized models outperform general models\nwhile requiring less training compute. Additionally, their growing compute\nefficiency leads to reduced forgetting of previously learned knowledge.", "published": "2025-01-03 19:28:53", "link": "http://arxiv.org/abs/2501.02068v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Boosting Explainability through Selective Rationalization in Pre-trained\n  Language Models", "abstract": "The widespread application of pre-trained language models (PLMs) in natural\nlanguage processing (NLP) has led to increasing concerns about their\nexplainability. Selective rationalization is a self-explanatory framework that\nselects human-intelligible input subsets as rationales for predictions. Recent\nstudies have shown that applying existing rationalization frameworks to PLMs\nwill result in severe degeneration and failure problems, producing sub-optimal\nor meaningless rationales. Such failures severely damage trust in\nrationalization methods and constrain the application of rationalization\ntechniques on PLMs. In this paper, we find that the homogeneity of tokens in\nthe sentences produced by PLMs is the primary contributor to these problems. To\naddress these challenges, we propose a method named Pre-trained Language\nModel's Rationalization (PLMR), which splits PLMs into a generator and a\npredictor to deal with NLP tasks while providing interpretable rationales. The\ngenerator in PLMR also alleviates homogeneity by pruning irrelevant tokens,\nwhile the predictor uses full-text information to standardize predictions.\nExperiments conducted on two widely used datasets across multiple PLMs\ndemonstrate the effectiveness of the proposed method PLMR in addressing the\nchallenge of applying selective rationalization to PLMs. Codes:\nhttps://github.com/ylb777/PLMR.", "published": "2025-01-03 07:52:40", "link": "http://arxiv.org/abs/2501.03182v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Applications of natural language processing in aviation safety: A review\n  and qualitative analysis", "abstract": "This study explores using Natural Language Processing in aviation safety,\nfocusing on machine learning algorithms to enhance safety measures. There are\ncurrently May 2024, 34 Scopus results from the keyword search natural language\nprocessing and aviation safety. Analyzing these studies allows us to uncover\ntrends in the methodologies, findings and implications of NLP in aviation. Both\nqualitative and quantitative tools have been used to investigate the current\nstate of literature on NLP for aviation safety. The qualitative analysis\nsummarises the research motivations, objectives, and outcomes, showing how NLP\ncan be utilized to help identify critical safety issues and improve aviation\nsafety. This study also identifies research gaps and suggests areas for future\nexploration, providing practical recommendations for the aviation industry. We\ndiscuss challenges in implementing NLP in aviation safety, such as the need for\nlarge, annotated datasets, and the difficulty in interpreting complex models.\nWe propose solutions like active learning for data annotation and explainable\nAI for model interpretation. Case studies demonstrate the successful\napplication of NLP in improving aviation safety, highlighting its potential to\nmake aviation safer and more efficient.", "published": "2025-01-03 07:36:10", "link": "http://arxiv.org/abs/2501.06210v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of\n  Psychiatric Assessment Conversational Agents", "abstract": "Recent advances in large language models (LLMs) have accelerated the\ndevelopment of conversational agents capable of generating human-like\nresponses. Since psychiatric assessments typically involve complex\nconversational interactions between psychiatrists and patients, there is\ngrowing interest in developing LLM-based psychiatric assessment conversational\nagents (PACAs) that aim to simulate the role of psychiatrists in clinical\nevaluations. However, standardized methods for benchmarking the clinical\nappropriateness of PACAs' interaction with patients still remain underexplored.\nHere, we propose PSYCHE, a novel framework designed to enable the 1) clinically\nrelevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation\nof PACAs. This is achieved by simulating psychiatric patients based on a\nmulti-faceted psychiatric construct that defines the simulated patients'\nprofiles, histories, and behaviors, which PACAs are expected to assess. We\nvalidate the effectiveness of PSYCHE through a study with 10 board-certified\npsychiatrists, supported by an in-depth analysis of the simulated patient\nutterances.", "published": "2025-01-03 01:38:46", "link": "http://arxiv.org/abs/2501.01594v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crossing Language Borders: A Pipeline for Indonesian Manhwa Translation", "abstract": "In this project, we develop a practical and efficient solution for automating\nthe Manhwa translation from Indonesian to English. Our approach combines\ncomputer vision, text recognition, and natural language processing techniques\nto streamline the traditionally manual process of Manhwa(Korean comics)\ntranslation. The pipeline includes fine-tuned YOLOv5xu for speech bubble\ndetection, Tesseract for OCR and fine-tuned MarianMT for machine translation.\nBy automating these steps, we aim to make Manhwa more accessible to a global\naudience while saving time and effort compared to manual translation methods.\nWhile most Manhwa translation efforts focus on Japanese-to-English, we focus on\nIndonesian-to-English translation to address the challenges of working with\nlow-resource languages. Our model shows good results at each step and was able\nto translate from Indonesian to English efficiently.", "published": "2025-01-03 04:32:27", "link": "http://arxiv.org/abs/2501.01629v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A non-ergodic framework for understanding emergent capabilities in Large\n  Language Models", "abstract": "Large language models have emergent capabilities that come unexpectedly at\nscale, but we need a theoretical framework to explain why and how they emerge.\nWe prove that language models are actually non-ergodic systems while providing\na mathematical framework based on Stuart Kauffman's theory of the adjacent\npossible (TAP) to explain capability emergence. Our resource-constrained TAP\nequation demonstrates how architectural, training, and contextual constraints\ninteract to shape model capabilities through phase transitions in semantic\nspace. We prove through experiments with three different language models that\ncapacities emerge through discrete transitions guided by constraint\ninteractions and path-dependent exploration. This framework provides a\ntheoretical basis for understanding emergence in language models and guides the\ndevelopment of architectures that can guide capability emergence.", "published": "2025-01-03 05:11:41", "link": "http://arxiv.org/abs/2501.01638v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AgentRefine: Enhancing Agent Generalization through Refinement Tuning", "abstract": "Large Language Model (LLM) based agents have proved their ability to perform\ncomplex tasks like humans. However, there is still a large gap between\nopen-sourced LLMs and commercial models like the GPT series. In this paper, we\nfocus on improving the agent generalization capabilities of LLMs via\ninstruction tuning. We first observe that the existing agent training corpus\nexhibits satisfactory results on held-in evaluation sets but fails to\ngeneralize to held-out sets. These agent-tuning works face severe formatting\nerrors and are frequently stuck in the same mistake for a long while. We\nanalyze that the poor generalization ability comes from overfitting to several\nmanual agent environments and a lack of adaptation to new situations. They\nstruggle with the wrong action steps and can not learn from the experience but\njust memorize existing observation-action relations. Inspired by the insight,\nwe propose a novel AgentRefine framework for agent-tuning. The core idea is to\nenable the model to learn to correct its mistakes via observation in the\ntrajectory. Specifically, we propose an agent synthesis framework to encompass\na diverse array of environments and tasks and prompt a strong LLM to refine its\nerror action according to the environment feedback. AgentRefine significantly\noutperforms state-of-the-art agent-tuning work in terms of generalization\nability on diverse agent tasks. It also has better robustness facing\nperturbation and can generate diversified thought in inference. Our findings\nestablish the correlation between agent generalization and self-refinement and\nprovide a new paradigm for future research.", "published": "2025-01-03 08:55:19", "link": "http://arxiv.org/abs/2501.01702v2", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "How Toxic Can You Get? Search-based Toxicity Testing for Large Language\n  Models", "abstract": "Language is a deep-rooted means of perpetration of stereotypes and\ndiscrimination. Large Language Models (LLMs), now a pervasive technology in our\neveryday lives, can cause extensive harm when prone to generating toxic\nresponses. The standard way to address this issue is to align the LLM, which,\nhowever, dampens the issue without constituting a definitive solution.\nTherefore, testing LLM even after alignment efforts remains crucial for\ndetecting any residual deviations with respect to ethical standards. We present\nEvoTox, an automated testing framework for LLMs' inclination to toxicity,\nproviding a way to quantitatively assess how much LLMs can be pushed towards\ntoxic responses even in the presence of alignment. The framework adopts an\niterative evolution strategy that exploits the interplay between two LLMs, the\nSystem Under Test (SUT) and the Prompt Generator steering SUT responses toward\nhigher toxicity. The toxicity level is assessed by an automated oracle based on\nan existing toxicity classifier. We conduct a quantitative and qualitative\nempirical evaluation using four state-of-the-art LLMs as evaluation subjects\nhaving increasing complexity (7-13 billion parameters). Our quantitative\nevaluation assesses the cost-effectiveness of four alternative versions of\nEvoTox against existing baseline methods, based on random search, curated\ndatasets of toxic prompts, and adversarial attacks. Our qualitative assessment\nengages human evaluators to rate the fluency of the generated prompts and the\nperceived toxicity of the responses collected during the testing sessions.\nResults indicate that the effectiveness, in terms of detected toxicity level,\nis significantly higher than the selected baseline methods (effect size up to\n1.0 against random search and up to 0.99 against adversarial attacks).\nFurthermore, EvoTox yields a limited cost overhead (from 22% to 35% on\naverage).", "published": "2025-01-03 10:08:49", "link": "http://arxiv.org/abs/2501.01741v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large\n  Language Models", "abstract": "Automated red-teaming has become a crucial approach for uncovering\nvulnerabilities in large language models (LLMs). However, most existing methods\nfocus on isolated safety flaws, limiting their ability to adapt to dynamic\ndefenses and uncover complex vulnerabilities efficiently. To address this\nchallenge, we propose Auto-RT, a reinforcement learning framework that\nautomatically explores and optimizes complex attack strategies to effectively\nuncover security vulnerabilities through malicious queries. Specifically, we\nintroduce two key mechanisms to reduce exploration complexity and improve\nstrategy optimization: 1) Early-terminated Exploration, which accelerate\nexploration by focusing on high-potential attack strategies; and 2) Progressive\nReward Tracking algorithm with intermediate downgrade models, which dynamically\nrefine the search trajectory toward successful vulnerability exploitation.\nExtensive experiments across diverse LLMs demonstrate that, by significantly\nimproving exploration efficiency and automatically optimizing attack\nstrategies, Auto-RT detects a boarder range of vulnerabilities, achieving a\nfaster detection speed and 16.63\\% higher success rates compared to existing\nmethods.", "published": "2025-01-03 14:30:14", "link": "http://arxiv.org/abs/2501.01830v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Recursive Decomposition of Logical Thoughts: Framework for Superior\n  Reasoning and Knowledge Propagation in Large Language Models", "abstract": "Enhancing the reasoning capabilities of Large Language Models remains a\ncritical challenge in artificial intelligence. We introduce RDoLT, Recursive\nDecomposition of Logical Thought prompting, a novel framework that\nsignificantly boosts LLM reasoning performance. RDoLT is built on three key\ninnovations: (1) recursively breaking down complex reasoning tasks into\nsub-tasks of progressive complexity; (2) employing an advanced selection and\nscoring mechanism to identify the most promising reasoning thoughts; and (3)\nintegrating a knowledge propagation module that mimics human learning by\nkeeping track of strong and weak thoughts for information propagation. Our\napproach was evaluated across multiple benchmarks, including GSM8K, SVAMP,\nMultiArith, LastLetterConcatenation, and Gaokao2023 Math. The results\ndemonstrate that RDoLT consistently outperforms existing state-of-the-art\ntechniques, achieving a 90.98 percent accuracy on GSM8K with ChatGPT-4,\nsurpassing state-of-the-art techniques by 6.28 percent. Similar improvements\nwere observed on other benchmarks, with accuracy gains ranging from 5.5 percent\nto 6.75 percent. These findings highlight RDoLT's potential to advance prompt\nengineering, offering a more effective and generalizable approach to complex\nreasoning tasks.", "published": "2025-01-03 02:55:44", "link": "http://arxiv.org/abs/2501.02026v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.CL"}
{"title": "METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring", "abstract": "We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer\nmodel, which we refer to as a metagenomic foundation model, on a novel corpus\nof diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base\npairs. This dataset is sourced from a large collection of human wastewater\nsamples, processed and sequenced using deep metagenomic (next-generation)\nsequencing methods. Unlike genomic models that focus on individual genomes or\ncurated sets of specific species, the aim of METAGENE-1 is to capture the full\ndistribution of genomic information present within this wastewater, to aid in\ntasks relevant to pandemic monitoring and pathogen detection. We carry out\nbyte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic\nsequences, and then pretrain our model. In this paper, we first detail the\npretraining dataset, tokenization strategy, and model architecture,\nhighlighting the considerations and design choices that enable the effective\nmodeling of metagenomic data. We then show results of pretraining this model on\nour metagenomic dataset, providing details about our losses, system metrics,\nand training stability over the course of pretraining. Finally, we demonstrate\nthe performance of METAGENE-1, which achieves state-of-the-art results on a set\nof genomic benchmarks and new evaluations focused on human-pathogen detection\nand genomic sequence embedding, showcasing its potential for public health\napplications in pandemic monitoring, biosurveillance, and early detection of\nemerging health threats.", "published": "2025-01-03 18:44:43", "link": "http://arxiv.org/abs/2501.02045v1", "categories": ["q-bio.GN", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "Classifier-Guided Captioning Across Modalities", "abstract": "Most current captioning systems use language models trained on data from\nspecific settings, such as image-based captioning via Amazon Mechanical Turk,\nlimiting their ability to generalize to other modality distributions and\ncontexts. This limitation hinders performance in tasks like audio or video\ncaptioning, where different semantic cues are needed. Addressing this challenge\nis crucial for creating more adaptable and versatile captioning frameworks\napplicable across diverse real-world contexts. In this work, we introduce a\nmethod to adapt captioning networks to the semantics of alternative settings,\nsuch as capturing audibility in audio captioning, where it is crucial to\ndescribe sounds and their sources. Our framework consists of two main\ncomponents: (i) a frozen captioning system incorporating a language model (LM),\nand (ii) a text classifier that guides the captioning system. The classifier is\ntrained on a dataset automatically generated by GPT-4, using tailored prompts\nspecifically designed to enhance key aspects of the generated captions.\nImportantly, the framework operates solely during inference, eliminating the\nneed for further training of the underlying captioning model. We evaluate the\nframework on various models and modalities, with a focus on audio captioning,\nand report promising results. Notably, when combined with an existing zero-shot\naudio captioning system, our framework improves its quality and sets\nstate-of-the-art performance in zero-shot audio captioning.", "published": "2025-01-03 18:09:26", "link": "http://arxiv.org/abs/2501.03183v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Survey on Large Language Models with some Insights on their\n  Capabilities and Limitations", "abstract": "The rapid advancement of artificial intelligence, particularly with the\ndevelopment of Large Language Models (LLMs) built on the transformer\narchitecture, has redefined the capabilities of natural language processing.\nThese models now exhibit remarkable performance across various language-related\ntasks, such as text generation, question answering, translation, and\nsummarization, often rivaling human-like comprehension. More intriguingly, LLMs\nhave demonstrated emergent abilities extending beyond their core functions,\nshowing proficiency in tasks like commonsense reasoning, code generation, and\narithmetic. This survey paper explores the foundational components, scaling\nmechanisms, and architectural strategies that drive these capabilities.\nEmphasizing models like GPT and LLaMA, we analyze the impact of exponential\ndata and computational growth on LLM performance, while also addressing the\ntrade-offs associated with scaling. We also examine LLM applications across\nsectors, such as healthcare, finance, education, and law, highlighting their\nadaptability and potential to solve domain-specific challenges. Central to this\nwork are the questions of how LLMs generalize across diverse tasks, exhibit\nplanning, and reasoning abilities, and whether these emergent abilities can be\nsystematically elicited or enhanced. In particular, we provide some insights\ninto the CoT (Chain of Thought) and PoT (Plan of Thought) abilities within\nLLMs, focusing on how pre-training data influences their emergence.\nAdditionally, we investigate LLM-modulo frameworks that integrate external\nsystems, allowing LLMs to handle complex, dynamic tasks. By analyzing these\nfactors, this paper aims to foster the ongoing discussion on the capabilities\nand limits of LLMs, promoting their responsible development and application in\nnovel and increasingly complex environments.", "published": "2025-01-03 21:04:49", "link": "http://arxiv.org/abs/2501.04040v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "FLAME: Financial Large-Language Model Assessment and Metrics Evaluation", "abstract": "LLMs have revolutionized NLP and demonstrated potential across diverse\ndomains. More and more financial LLMs have been introduced for finance-specific\ntasks, yet comprehensively assessing their value is still challenging. In this\npaper, we introduce FLAME, a comprehensive financial LLMs evaluation system in\nChinese, which includes two core evaluation benchmarks: FLAME-Cer and\nFLAME-Sce. FLAME-Cer covers 14 types of authoritative financial certifications,\nincluding CPA, CFA, and FRM, with a total of approximately 16,000 carefully\nselected questions. All questions have been manually reviewed to ensure\naccuracy and representativeness. FLAME-Sce consists of 10 primary core\nfinancial business scenarios, 21 secondary financial business scenarios, and a\ncomprehensive evaluation set of nearly 100 tertiary financial application\ntasks. We evaluate 6 representative LLMs, including GPT-4o, GLM-4, ERNIE-4.0,\nQwen2.5, XuanYuan3, and the latest Baichuan4-Finance, revealing\nBaichuan4-Finance excels other LLMs in most tasks. By establishing a\ncomprehensive and professional evaluation system, FLAME facilitates the\nadvancement of financial LLMs in Chinese contexts. Instructions for\nparticipating in the evaluation are available on GitHub:\nhttps://github.com/FLAME-ruc/FLAME.", "published": "2025-01-03 09:17:23", "link": "http://arxiv.org/abs/2501.06211v1", "categories": ["cs.CL", "cs.AI", "cs.CE"], "primary_category": "cs.CL"}
{"title": "Integrating Domain Knowledge into Large Language Models for Enhanced\n  Fashion Recommendations", "abstract": "Fashion, deeply rooted in sociocultural dynamics, evolves as individuals\nemulate styles popularized by influencers and iconic figures. In the quest to\nreplicate such refined tastes using artificial intelligence, traditional\nfashion ensemble methods have primarily used supervised learning to imitate the\ndecisions of style icons, which falter when faced with distribution shifts,\nleading to style replication discrepancies triggered by slight variations in\ninput. Meanwhile, large language models (LLMs) have become prominent across\nvarious sectors, recognized for their user-friendly interfaces, strong\nconversational skills, and advanced reasoning capabilities. To address these\nchallenges, we introduce the Fashion Large Language Model (FLLM), which employs\nauto-prompt generation training strategies to enhance its capacity for\ndelivering personalized fashion advice while retaining essential domain\nknowledge. Additionally, by integrating a retrieval augmentation technique\nduring inference, the model can better adjust to individual preferences. Our\nresults show that this approach surpasses existing models in accuracy,\ninterpretability, and few-shot learning capabilities.", "published": "2025-01-03 21:49:44", "link": "http://arxiv.org/abs/2502.15696v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Disentangling Hierarchical Features for Anomalous Sound Detection Under\n  Domain Shift", "abstract": "Anomalous sound detection (ASD) encounters difficulties with domain shift,\nwhere the sounds of machines in target domains differ significantly from those\nin source domains due to varying operating conditions. Existing methods\ntypically employ domain classifiers to enhance detection performance, but they\noften overlook the influence of domain-unrelated information. This oversight\ncan hinder the model's ability to clearly distinguish between domains, thereby\nweakening its capacity to differentiate normal from abnormal sounds. In this\npaper, we propose a Gradient Reversal-based Hierarchical feature\nDisentanglement (GRHD) method to address the above challenge. GRHD uses\ngradient reversal to separate domain-related features from domain-unrelated\nones, resulting in more robust feature representations. Additionally, the\nmethod employs a hierarchical structure to guide the learning of fine-grained,\ndomain-specific features by leveraging available metadata, such as section IDs\nand machine sound attributes. Experimental results on the DCASE 2022 Challenge\nTask 2 dataset demonstrate that the proposed method significantly improves ASD\nperformance under domain shift.", "published": "2025-01-03 02:34:55", "link": "http://arxiv.org/abs/2501.01604v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An efficient light-weighted signal reconstruction method consists of\n  Fast Fourier Transform and Convolutional-based Autoencoder", "abstract": "The main theme of this paper is to reconstruct audio signal from interrupted\nmeasurements. We present a light-weighted model only consisting discrete\nFourier transform and Convolutional-based Autoencoder model (ConvAE), called\nthe FFT-ConvAE model for the Helsinki Speech Challenge 2024. The FFT-ConvAE\nmodel is light-weighted (in terms of real-time factor) and efficient (in terms\nof character error rate), which was verified by the organizers. Furthermore,\nthe FFT-ConvAE is a general-purpose model capable of handling all tasks with a\nunified configuration.", "published": "2025-01-03 05:51:27", "link": "http://arxiv.org/abs/2501.01650v1", "categories": ["cs.SD", "eess.AS", "35R25, 35R30"], "primary_category": "cs.SD"}
{"title": "Improved Feature Extraction Network for Neuro-Oriented Target Speaker\n  Extraction", "abstract": "The recent rapid development of auditory attention decoding (AAD) offers the\npossibility of using electroencephalography (EEG) as auxiliary information for\ntarget speaker extraction. However, effectively modeling long sequences of\nspeech and resolving the identity of the target speaker from EEG signals\nremains a major challenge. In this paper, an improved feature extraction\nnetwork (IFENet) is proposed for neuro-oriented target speaker extraction,\nwhich mainly consists of a speech encoder with dual-path Mamba and an EEG\nencoder with Kolmogorov-Arnold Networks (KAN). We propose SpeechBiMamba, which\nmakes use of dual-path Mamba in modeling local and global speech sequences to\nextract speech features. In addition, we propose EEGKAN to effectively extract\nEEG features that are closely related to the auditory stimuli and locate the\ntarget speaker through the subject's attention information. Experiments on the\nKUL and AVED datasets show that IFENet outperforms the state-of-the-art model,\nachieving 36\\% and 29\\% relative improvements in terms of scale-invariant\nsignal-to-distortion ratio (SI-SDR) under an open evaluation condition.", "published": "2025-01-03 07:27:51", "link": "http://arxiv.org/abs/2501.01673v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Controlling your Attributes in Voice", "abstract": "Attribute control in generative tasks aims to modify personal attributes,\nsuch as age and gender while preserving the identity information in the source\nsample. Although significant progress has been made in controlling facial\nattributes in image generation, similar approaches for speech generation remain\nlargely unexplored. This letter proposes a novel method for controlling speaker\nattributes in speech without parallel data. Our approach consists of two main\ncomponents: a GAN-based speaker representation variational autoencoder that\nextracts speaker identity and attributes from speaker vector, and a two-stage\nvoice conversion model that captures the natural expression of speaker\nattributes in speech. Experimental results show that our proposed method not\nonly achieves attribute control at the speaker representation level but also\nenables manipulation of the speaker age and gender at the speech level while\npreserving speech quality and speaker identity.", "published": "2025-01-03 07:35:08", "link": "http://arxiv.org/abs/2501.01674v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MusicGen-Stem: Multi-stem music generation and edition through\n  autoregressive modeling", "abstract": "While most music generation models generate a mixture of stems (in mono or\nstereo), we propose to train a multi-stem generative model with 3 stems (bass,\ndrums and other) that learn the musical dependencies between them. To do so, we\ntrain one specialized compression algorithm per stem to tokenize the music into\nparallel streams of tokens. Then, we leverage recent improvements in the task\nof music source separation to train a multi-stream text-to-music language model\non a large dataset. Finally, thanks to a particular conditioning method, our\nmodel is able to edit bass, drums or other stems on existing or generated songs\nas well as doing iterative composition (e.g. generating bass on top of existing\ndrums). This gives more flexibility in music generation algorithms and it is to\nthe best of our knowledge the first open-source multi-stem autoregressive music\ngeneration model that can perform good quality generation and coherent source\nediting. Code and model weights will be released and samples are available on\nhttps://simonrouard.github.io/musicgenstem/.", "published": "2025-01-03 11:11:16", "link": "http://arxiv.org/abs/2501.01757v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CycleFlow: Leveraging Cycle Consistency in Flow Matching for Speaker\n  Style Adaptation", "abstract": "Voice Conversion (VC) aims to convert the style of a source speaker, such as\ntimbre and pitch, to the style of any target speaker while preserving the\nlinguistic content. However, the ground truth of the converted speech does not\nexist in a non-parallel VC scenario, which induces the train-inference mismatch\nproblem. Moreover, existing methods still have an inaccurate pitch and low\nspeaker adaptation quality, there is a significant disparity in pitch between\nthe source and target speaker style domains. As a result, the models tend to\ngenerate speech with hoarseness, posing challenges in achieving high-quality\nvoice conversion. In this study, we propose CycleFlow, a novel VC approach that\nleverages cycle consistency in conditional flow matching (CFM) for speaker\ntimbre adaptation training on non-parallel data. Furthermore, we design a\nDual-CFM based on VoiceCFM and PitchCFM to generate speech and improve speaker\npitch adaptation quality. Experiments show that our method can significantly\nimprove speaker similarity, generating natural and higher-quality speech.", "published": "2025-01-03 15:18:30", "link": "http://arxiv.org/abs/2501.01861v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Structural and Statistical Audio Texture Knowledge Distillation (SSATKD)\n  for Passive Sonar Classification", "abstract": "Knowledge distillation has been successfully applied to various audio tasks,\nbut its potential in underwater passive sonar target classification remains\nrelatively unexplored. Existing methods often focus on high-level contextual\ninformation while overlooking essential low-level audio texture features needed\nto capture local patterns in sonar data. To address this gap, the Structural\nand Statistical Audio Texture Knowledge Distillation (SSATKD) framework is\nproposed for passive sonar target classification. SSATKD combines high-level\ncontextual information with low-level audio textures by utilizing an Edge\nDetection Module for structural texture extraction and a Statistical Knowledge\nExtractor Module to capture signal variability and distribution. Experimental\nresults confirm that SSATKD improves classification accuracy while optimizing\nmemory and computational resources, making it well-suited for\nresource-constrained environments.", "published": "2025-01-03 17:45:12", "link": "http://arxiv.org/abs/2501.01921v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Whisphone: Whispering Input Earbuds", "abstract": "Whisphone is a novel earbud device designed for speech input via whispering.\nUtilizing canal-type earbuds with a unique microphone placement at the tip of\nthe earplug, it effectively captures whispered voices radiated in the ear canal\nthrough bone conduction. This design can boost whispered voice volume with ear\ncanal occlusion effect while simultaneously blocking external noise by sealing\nthe ear hole. By incorporating Active Noise Canceling (ANC), Whisphone can\neffectively detect subtle whispers, even in noisy environments of up to\n80dB(A). Its compact and comfortable design ensures discreet wearability,\nallowing users to interact with AI assistants hands-free without disturbing\nothers in various daily situations such as offices, homes, or urban public\nspaces.", "published": "2025-01-03 05:08:48", "link": "http://arxiv.org/abs/2501.01636v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.2"], "primary_category": "cs.HC"}
{"title": "VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction", "abstract": "Recent Multimodal Large Language Models (MLLMs) have typically focused on\nintegrating visual and textual modalities, with less emphasis placed on the\nrole of speech in enhancing interaction. However, speech plays a crucial role\nin multimodal dialogue systems, and implementing high-performance in both\nvision and speech tasks remains a significant challenge due to the fundamental\nmodality differences. In this paper, we propose a carefully designed\nmulti-stage training methodology that progressively trains LLM to understand\nboth visual and speech information, ultimately enabling fluent vision and\nspeech interaction. Our approach not only preserves strong vision-language\ncapacity, but also enables efficient speech-to-speech dialogue capabilities\nwithout separate ASR and TTS modules, significantly accelerating multimodal\nend-to-end response speed. By comparing our method against state-of-the-art\ncounterparts across benchmarks for image, video, and speech tasks, we\ndemonstrate that our model is equipped with both strong visual and speech\ncapabilities, making near real-time vision and speech interaction.", "published": "2025-01-03 18:59:52", "link": "http://arxiv.org/abs/2501.01957v3", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Detecting Music Performance Errors with Transformers", "abstract": "Beginner musicians often struggle to identify specific errors in their\nperformances, such as playing incorrect notes or rhythms. There are two\nlimitations in existing tools for music error detection: (1) Existing\napproaches rely on automatic alignment; therefore, they are prone to errors\ncaused by small deviations between alignment targets.; (2) There is a lack of\nsufficient data to train music error detection models, resulting in\nover-reliance on heuristics. To address (1), we propose a novel transformer\nmodel, Polytune, that takes audio inputs and outputs annotated music scores.\nThis model can be trained end-to-end to implicitly align and compare\nperformance audio with music scores through latent space representations. To\naddress (2), we present a novel data generation technique capable of creating\nlarge-scale synthetic music error datasets. Our approach achieves a 64.1%\naverage Error Detection F1 score, improving upon prior work by 40 percentage\npoints across 14 instruments. Additionally, compared with existing\ntranscription methods repurposed for music error detection, our model can\nhandle multiple instruments. Our source code and datasets are available at\nhttps://github.com/ben2002chou/Polytune.", "published": "2025-01-03 07:04:20", "link": "http://arxiv.org/abs/2501.02030v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Listening and Seeing Again: Generative Error Correction for Audio-Visual\n  Speech Recognition", "abstract": "Unlike traditional Automatic Speech Recognition (ASR), Audio-Visual Speech\nRecognition (AVSR) takes audio and visual signals simultaneously to infer the\ntranscription. Recent studies have shown that Large Language Models (LLMs) can\nbe effectively used for Generative Error Correction (GER) in ASR by predicting\nthe best transcription from ASR-generated N-best hypotheses. However, these\nLLMs lack the ability to simultaneously understand audio and visual, making the\nGER approach challenging to apply in AVSR. In this work, we propose a novel GER\nparadigm for AVSR, termed AVGER, that follows the concept of ``listening and\nseeing again''. Specifically, we first use the powerful AVSR system to read the\naudio and visual signals to get the N-Best hypotheses, and then use the\nQ-former-based Multimodal Synchronous Encoder to read the audio and visual\ninformation again and convert them into an audio and video compression\nrepresentation respectively that can be understood by LLM. Afterward, the\naudio-visual compression representation and the N-Best hypothesis together\nconstitute a Cross-modal Prompt to guide the LLM in producing the best\ntranscription. In addition, we also proposed a Multi-Level Consistency\nConstraint training criterion, including logits-level, utterance-level and\nrepresentations-level, to improve the correction accuracy while enhancing the\ninterpretability of audio and visual compression representations. The\nexperimental results on the LRS3 dataset show that our method outperforms\ncurrent mainstream AVSR systems. The proposed AVGER can reduce the Word Error\nRate (WER) by 24% compared to them. Code and models can be found at:\nhttps://github.com/CircleRedRain/AVGER.", "published": "2025-01-03 10:51:14", "link": "http://arxiv.org/abs/2501.04038v1", "categories": ["cs.MM", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "SSM2Mel: State Space Model to Reconstruct Mel Spectrogram from the EEG", "abstract": "Decoding speech from brain signals is a challenging research problem that\nholds significant importance for studying speech processing in the brain.\nAlthough breakthroughs have been made in reconstructing the mel spectrograms of\naudio stimuli perceived by subjects at the word or letter level using\nnoninvasive electroencephalography (EEG), there is still a critical gap in\nprecisely reconstructing continuous speech features, especially at the minute\nlevel. To address this issue, this paper proposes a State Space Model (SSM) to\nreconstruct the mel spectrogram of continuous speech from EEG, named SSM2Mel.\nThis model introduces a novel Mamba module to effectively model the long\nsequence of EEG signals for imagined speech. In the SSM2Mel model, the S4-UNet\nstructure is used to enhance the extraction of local features of EEG signals,\nand the Embedding Strength Modulator (ESM) module is used to incorporate\nsubject-specific information. Experimental results show that our model achieves\na Pearson correlation of 0.069 on the SparrKULee dataset, which is a 38%\nimprovement over the previous baseline.", "published": "2025-01-03 06:57:08", "link": "http://arxiv.org/abs/2501.10402v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
