{"title": "Incorporating BERT into Neural Machine Translation", "abstract": "The recently proposed BERT has shown great power on a variety of natural\nlanguage understanding tasks, such as text classification, reading\ncomprehension, etc. However, how to effectively apply BERT to neural machine\ntranslation (NMT) lacks enough exploration. While BERT is more commonly used as\nfine-tuning instead of contextual embedding for downstream language\nunderstanding tasks, in NMT, our preliminary exploration of using BERT as\ncontextual embedding is better than using for fine-tuning. This motivates us to\nthink how to better leverage BERT for NMT along this direction. We propose a\nnew algorithm named BERT-fused model, in which we first use BERT to extract\nrepresentations for an input sequence, and then the representations are fused\nwith each layer of the encoder and decoder of the NMT model through attention\nmechanisms. We conduct experiments on supervised (including sentence-level and\ndocument-level translations), semi-supervised and unsupervised machine\ntranslation, and achieve state-of-the-art results on seven benchmark datasets.\nOur code is available at \\url{https://github.com/bert-nmt/bert-nmt}.", "published": "2020-02-17 08:13:36", "link": "http://arxiv.org/abs/2002.06823v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GameWikiSum: a Novel Large Multi-Document Summarization Dataset", "abstract": "Today's research progress in the field of multi-document summarization is\nobstructed by the small number of available datasets. Since the acquisition of\nreference summaries is costly, existing datasets contain only hundreds of\nsamples at most, resulting in heavy reliance on hand-crafted features or\nnecessitating additional, manually annotated data. The lack of large corpora\ntherefore hinders the development of sophisticated models. Additionally, most\npublicly available multi-document summarization corpora are in the news domain,\nand no analogous dataset exists in the video game domain. In this paper, we\npropose GameWikiSum, a new domain-specific dataset for multi-document\nsummarization, which is one hundred times larger than commonly used datasets,\nand in another domain than news. Input documents consist of long professional\nvideo game reviews as well as references of their gameplay sections in\nWikipedia pages. We analyze the proposed dataset and show that both abstractive\nand extractive models can be trained on it. We release GameWikiSum for further\nresearch: https://github.com/Diego999/GameWikiSum.", "published": "2020-02-17 09:25:19", "link": "http://arxiv.org/abs/2002.06851v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HotelRec: a Novel Very Large-Scale Hotel Recommendation Dataset", "abstract": "Today, recommender systems are an inevitable part of everyone's daily digital\nroutine and are present on most internet platforms. State-of-the-art deep\nlearning-based models require a large number of data to achieve their best\nperformance. Many datasets fulfilling this criterion have been proposed for\nmultiple domains, such as Amazon products, restaurants, or beers. However,\nworks and datasets in the hotel domain are limited: the largest hotel review\ndataset is below the million samples. Additionally, the hotel domain suffers\nfrom a higher data sparsity than traditional recommendation datasets and\ntherefore, traditional collaborative-filtering approaches cannot be applied to\nsuch data. In this paper, we propose HotelRec, a very large-scale hotel\nrecommendation dataset, based on TripAdvisor, containing 50 million reviews. To\nthe best of our knowledge, HotelRec is the largest publicly available dataset\nin the hotel domain (50M versus 0.9M) and additionally, the largest\nrecommendation dataset in a single domain and with textual reviews (50M versus\n22M). We release HotelRec for further research:\nhttps://github.com/Diego999/HotelRec.", "published": "2020-02-17 09:30:52", "link": "http://arxiv.org/abs/2002.06854v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Controlling Computation versus Quality for Neural Sequence Models", "abstract": "Most neural networks utilize the same amount of compute for every example\nindependent of the inherent complexity of the input. Further, methods that\nadapt the amount of computation to the example focus on finding a fixed\ninference-time computational graph per example, ignoring any external\ncomputational budgets or varying inference time limitations. In this work, we\nutilize conditional computation to make neural sequence models (Transformer)\nmore efficient and computation-aware during inference. We first modify the\nTransformer architecture, making each set of operations conditionally\nexecutable depending on the output of a learned control network. We then train\nthis model in a multi-task setting, where each task corresponds to a particular\ncomputation budget. This allows us to train a single model that can be\ncontrolled to operate on different points of the computation-quality trade-off\ncurve, depending on the available computation budget at inference time. We\nevaluate our approach on two tasks: (i) WMT English-French Translation and (ii)\nUnsupervised representation learning (BERT). Our experiments demonstrate that\nthe proposed Conditional Computation Transformer (CCT) is competitive with\nvanilla Transformers when allowed to utilize its full computational budget,\nwhile improving significantly over computationally equivalent baselines when\noperating on smaller computational budgets.", "published": "2020-02-17 17:54:27", "link": "http://arxiv.org/abs/2002.07106v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Financial Service Chatbot based on Deep Bidirectional Transformers", "abstract": "We develop a chatbot using Deep Bidirectional Transformer models (BERT) to\nhandle client questions in financial investment customer service. The bot can\nrecognize 381 intents, and decides when to say \"I don't know\" and escalates\nirrelevant/uncertain questions to human operators. Our main novel contribution\nis the discussion about uncertainty measure for BERT, where three different\napproaches are systematically compared on real problems. We investigated two\nuncertainty metrics, information entropy and variance of dropout sampling in\nBERT, followed by mixed-integer programming to optimize decision thresholds.\nAnother novel contribution is the usage of BERT as a language model in\nautomatic spelling correction. Inputs with accidental spelling errors can\nsignificantly decrease intent classification performance. The proposed approach\ncombines probabilities from masked language model and word edit distances to\nfind the best corrections for misspelled words. The chatbot and the entire\nconversational AI system are developed using open-source tools, and deployed\nwithin our company's intranet. The proposed approach can be useful for\nindustries seeking similar in-house solutions in their specific business\ndomains. We share all our code and a sample chatbot built on a public dataset\non Github.", "published": "2020-02-17 18:48:55", "link": "http://arxiv.org/abs/2003.04987v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Computing rank-revealing factorizations of matrices stored out-of-core", "abstract": "This paper describes efficient algorithms for computing rank-revealing\nfactorizations of matrices that are too large to fit in RAM, and must instead\nbe stored on slow external memory devices such as solid-state or spinning disk\nhard drives (out-of-core or out-of-memory). Traditional algorithms for\ncomputing rank revealing factorizations, such as the column pivoted QR\nfactorization, or techniques for computing a full singular value decomposition\nof a matrix, are very communication intensive. They are naturally expressed as\na sequence of matrix-vector operations, which become prohibitively expensive\nwhen data is not available in main memory. Randomization allows these methods\nto be reformulated so that large contiguous blocks of the matrix can be\nprocessed in bulk. The paper describes two distinct methods. The first is a\nblocked version of column pivoted Householder QR, organized as a \"left-looking\"\nmethod to minimize the number of write operations (which are more expensive\nthan read operations on a spinning disk drive). The second method results in a\nso called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where\n$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an\nalgorithm-by-blocks, in which floating point operations overlap read and write\noperations. The second method incorporates power iterations, and is\nexceptionally good at revealing the numerical rank; it can often be used as a\nsubstitute for a full singular value decomposition. Numerical experiments\ndemonstrate that the new algorithms are almost as fast when processing data\nstored on a hard drive as traditional algorithms are for data stored in main\nmemory. To be precise, the computational time for fully factorizing an $n\\times\nn$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only\nmarginally larger when the matrix is stored out of core.", "published": "2020-02-17 13:58:08", "link": "http://arxiv.org/abs/2002.06960v2", "categories": ["cs.MS", "cs.CL", "cs.DC", "cs.DS", "cs.NA", "math.NA", "G.1.3; G.4; C.4; D.1.3; F.2.1"], "primary_category": "cs.MS"}
{"title": "Interactive Text-to-Speech System via Joint Style Analysis", "abstract": "While modern TTS technologies have made significant advancements in audio\nquality, there is still a lack of behavior naturalness compared to conversing\nwith people. We propose a style-embedded TTS system that generates styled\nresponses based on the speech query style. To achieve this, the system includes\na style extraction model that extracts a style embedding from the speech query,\nwhich is then used by the TTS to produce a matching response. We faced two main\nchallenges: 1) only a small portion of the TTS training dataset has style\nlabels, which is needed to train a multi-style TTS that respects different\nstyle embeddings during inference. 2) The TTS system and the style extraction\nmodel have disjoint training datasets. We need consistent style labels across\nthese two datasets so that the TTS can learn to respect the labels produced by\nthe style extraction model during inference. To solve these, we adopted a\nsemi-supervised approach that uses the style extraction model to create style\nlabels for the TTS dataset and applied transfer learning to learn the style\nembedding jointly. Our experiment results show user preference for the styled\nTTS responses and demonstrate the style-embedded TTS system's capability of\nmimicking the speech query style.", "published": "2020-02-17 03:35:24", "link": "http://arxiv.org/abs/2002.06758v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Lifter Training and Sub-band Modeling for Computationally Efficient and\n  High-Quality Voice Conversion Using Spectral Differentials", "abstract": "In this paper, we propose computationally efficient and high-quality methods\nfor statistical voice conversion (VC) with direct waveform modification based\non spectral differentials. The conventional method with a minimum-phase filter\nachieves high-quality conversion but requires heavy computation in filtering.\nThis is because the minimum phase using a fixed lifter of the Hilbert transform\noften results in a long-tap filter. One of our methods is a data-driven method\nfor lifter training. Since this method takes filter truncation into account in\ntraining, it can shorten the tap length of the filter while preserving\nconversion accuracy. Our other method is sub-band processing for extending the\nconventional method from narrow-band (16 kHz) to full-band (48 kHz) VC, which\ncan convert a full-band waveform with higher converted-speech quality.\nExperimental results indicate that 1) the proposed lifter-training method for\nnarrow-band VC can shorten the tap length to 1/16 without degrading the\nconverted-speech quality and 2) the proposed sub-band-processing method for\nfull-band VC can improve the converted-speech quality than the conventional\nmethod.", "published": "2020-02-17 05:41:54", "link": "http://arxiv.org/abs/2002.06778v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Addressing the confounds of accompaniments in singer identification", "abstract": "Identifying singers is an important task with many applications. However, the\ntask remains challenging due to many issues. One major issue is related to the\nconfounding factors from the background instrumental music that is mixed with\nthe vocals in music production. A singer identification model may learn to\nextract non-vocal related features from the instrumental part of the songs, if\na singer only sings in certain musical contexts (e.g., genres). The model\ncannot therefore generalize well when the singer sings in unseen contexts. In\nthis paper, we attempt to address this issue. Specifically, we employ\nopen-unmix, an open source tool with state-of-the-art performance in source\nseparation, to separate the vocal and instrumental tracks of music. We then\ninvestigate two means to train a singer identification model: by learning from\nthe separated vocal only, or from an augmented set of data where we\n\"shuffle-and-remix\" the separated vocal tracks and instrumental tracks of\ndifferent songs to artificially make the singers sing in different contexts. We\nalso incorporate melodic features learned from the vocal melody contour for\nbetter performance. Evaluation results on a benchmark dataset called the\nartist20 shows that this data augmentation method greatly improves the accuracy\nof singer identification.", "published": "2020-02-17 07:49:21", "link": "http://arxiv.org/abs/2002.06817v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Meta-learning Extractors for Music Source Separation", "abstract": "We propose a hierarchical meta-learning-inspired model for music source\nseparation (Meta-TasNet) in which a generator model is used to predict the\nweights of individual extractor models. This enables efficient\nparameter-sharing, while still allowing for instrument-specific\nparameterization. Meta-TasNet is shown to be more effective than the models\ntrained independently or in a multi-task setting, and achieve performance\ncomparable with state-of-the-art methods. In comparison to the latter, our\nextractors contain fewer parameters and have faster run-time performance. We\ndiscuss important architectural considerations, and explore the costs and\nbenefits of this approach.", "published": "2020-02-17 16:00:03", "link": "http://arxiv.org/abs/2002.07016v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
