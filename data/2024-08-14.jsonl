{"title": "Stylized facts in Web3", "abstract": "This paper presents a comprehensive statistical analysis of the Web3\necosystem, comparing various Web3 tokens with traditional financial assets\nacross multiple time scales. We examine probability distributions, tail\nbehaviors, and other key stylized facts of the returns for a diverse range of\ntokens, including decentralized exchanges, liquidity pools, and centralized\nexchanges. Despite functional differences, most tokens exhibit well-established\nempirical facts, including unconditional probability density of returns with\nheavy tails gradually becoming Gaussian and volatility clustering. Furthermore,\nwe compare assets traded on centralized (CEX) and decentralized (DEX)\nexchanges, finding that DEXs exhibit similar stylized facts despite different\ntrading mechanisms and often divergent long-term performance. We propose that\nthis similarity is attributable to arbitrageurs striving to maintain similar\ncentralized and decentralized prices. Our study contributes to a better\nunderstanding of the dynamics of Web3 tokens and the relationship between CEX\nand DEX markets, with important implications for risk management, pricing\nmodels, and portfolio construction in the rapidly evolving DeFi landscape.\nThese results add to the growing body of literature on cryptocurrency markets\nand provide insights that can guide the development of more accurate models for\nDeFi markets.", "published": "2024-08-14 16:28:05", "link": "http://arxiv.org/abs/2408.07653v3", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Model-based and empirical analyses of stochastic fluctuations in economy and finance", "abstract": "The objective of this work is the investigation of complexity, asymmetry,\nstochasticity and non-linearity of the financial and economic systems by using\nthe tools of statistical mechanics and information theory. More precisely, this\nthesis concerns statistical-based modeling and empirical analyses with\napplications in finance, forecasting, production processes and game theory. In\nthese areas the time dependence of probability distributions is of prime\ninterest and can be measured or exactly calculated for model systems. The\ncorrelation coefficients and moments are among the useful quantities to\ndescribe the dynamics and the correlations between random variables. However,\nthe full investigation can only be achieved if the probability distribution\nfunction of the variable is known; its derivation is one of the main focuses of\nthe present work.", "published": "2024-08-14 16:17:07", "link": "http://arxiv.org/abs/2408.16010v1", "categories": ["q-fin.ST", "physics.data-an"], "primary_category": "q-fin.ST"}
{"title": "Modeling of Measurement Error in Financial Returns Data", "abstract": "In this paper we consider the modeling of measurement error for fund returns\ndata. In particular, given access to a time-series of discretely observed\nlog-returns and the associated maximum over the observation period, we develop\na stochastic model which models the true log-returns and maximum via a L\\'evy\nprocess and the data as a measurement error there-of. The main technical\ndifficulty of trying to infer this model, for instance Bayesian parameter\nestimation, is that the joint transition density of the return and maximum is\nseldom known, nor can it be simulated exactly. Based upon the novel stick\nbreaking representation of [12] we provide an approximation of the model. We\ndevelop a Markov chain Monte Carlo (MCMC) algorithm to sample from the Bayesian\nposterior of the approximated posterior and then extend this to a multilevel\nMCMC method which can reduce the computational cost to approximate posterior\nexpectations, relative to ordinary MCMC. We implement our methodology on\nseveral applications including for real data.", "published": "2024-08-14 09:24:12", "link": "http://arxiv.org/abs/2408.07405v1", "categories": ["stat.CO", "q-fin.CP", "q-fin.ST"], "primary_category": "stat.CO"}
{"title": "Only One Relation Possible? Modeling the Ambiguity in Event Temporal\n  Relation Extraction", "abstract": "Event Temporal Relation Extraction (ETRE) aims to identify the temporal\nrelationship between two events, which plays an important role in natural\nlanguage understanding. Most previous works follow a single-label\nclassification style, classifying an event pair into either a specific temporal\nrelation (e.g., \\textit{Before}, \\textit{After}), or a special label\n\\textit{Vague} when there may be multiple possible temporal relations between\nthe pair. In our work, instead of directly making predictions on\n\\textit{Vague}, we propose a multi-label classification solution for ETRE\n(METRE) to infer the possibility of each temporal relation independently, where\nwe treat \\textit{Vague} as the cases when there is more than one possible\nrelation between two events. We design a speculation mechanism to explore the\npossible relations hidden behind \\textit{Vague}, which enables the latent\ninformation to be used efficiently. Experiments on TB-Dense, MATRES and UDS-T\nshow that our method can effectively utilize the \\textit{Vague} instances to\nimprove the recognition for specific temporal relations and outperforms most\nstate-of-the-art methods.", "published": "2024-08-14 07:57:51", "link": "http://arxiv.org/abs/2408.07353v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aquila2 Technical Report", "abstract": "This paper introduces the Aquila2 series, which comprises a wide range of\nbilingual models with parameter sizes of 7, 34, and 70 billion. These models\nare trained based on an innovative framework named HeuriMentor (HM), which\noffers real-time insights into model convergence and enhances the training\nprocess and data management. The HM System, comprising the Adaptive Training\nEngine (ATE), Training State Monitor (TSM), and Data Management Unit (DMU),\nallows for precise monitoring of the model's training progress and enables\nefficient optimization of data distribution, thereby enhancing training\neffectiveness. Extensive evaluations show that the Aquila2 model series\nperforms comparably well on both English and Chinese benchmarks. Specifically,\nAquila2-34B demonstrates only a slight decrease in performance when quantized\nto Int4. Furthermore, we have made our training code\n(https://github.com/FlagOpen/FlagScale) and model weights\n(https://github.com/FlagAI-Open/Aquila2) publicly available to support ongoing\nresearch and the development of applications.", "published": "2024-08-14 09:34:19", "link": "http://arxiv.org/abs/2408.07410v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge\n  Editing for Large Language Models", "abstract": "Knowledge editing aims to update outdated or incorrect knowledge in large\nlanguage models (LLMs). However, current knowledge editing methods have limited\nscalability for lifelong editing. This study explores the fundamental reason\nwhy knowledge editing fails in lifelong editing. We begin with the closed-form\nsolution derived from linear associative memory, which underpins\nstate-of-the-art knowledge editing methods. We extend the solution from single\nediting to lifelong editing, and through rigorous mathematical derivation,\nidentify an interference term in the final solution, suggesting that editing\nknowledge may impact irrelevant knowledge. Further analysis of the interference\nterm reveals a close relationship with superposition between knowledge\nrepresentations. When knowledge superposition does not exist in language\nmodels, the interference term vanishes, allowing for lossless knowledge\nediting. Experiments across numerous language models reveal that knowledge\nsuperposition is universal, exhibiting high kurtosis, zero mean, and\nheavy-tailed distributions with clear scaling laws. Ultimately, by combining\ntheory and experiments, we demonstrate that knowledge superposition is the\nfundamental reason for the failure of lifelong editing. Moreover, this is the\nfirst study to investigate knowledge editing from the perspective of\nsuperposition and provides a comprehensive observation of superposition across\nnumerous real-world language models. Code available at\nhttps://github.com/ChenhuiHu/knowledge_in_superposition.", "published": "2024-08-14 09:43:32", "link": "http://arxiv.org/abs/2408.07413v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Brazilian Portuguese to European Portuguese", "abstract": "Brazilian Portuguese and European Portuguese are two varieties of the same\nlanguage and, despite their close similarities, they exhibit several\ndifferences. However, there is a significant disproportion in the availability\nof resources between the two variants, with Brazilian Portuguese having more\nabundant resources. This inequity can impact the quality of translation\nservices accessible to European Portuguese speakers. To address this issue, we\npropose the development of a Brazilian Portuguese to European Portuguese\ntranslation system, leveraging recent advancements in neural architectures and\nmodels. To evaluate the performance of such systems, we manually curated a gold\ntest set comprising 500 sentences across five different topics. Each sentence\nin the gold test set has two distinct references, facilitating a\nstraightforward evaluation of future translation models. We experimented with\nvarious models by fine-tuning existing Large Language Models using parallel\ndata extracted from movie subtitles and TED Talks transcripts in both Brazilian\nand European Portuguese. Our evaluation involved the use of conventional\nautomatic metrics as well as a human evaluation. In addition, all models were\ncompared against ChatGPT 3.5 Turbo, which currently yields the best results.", "published": "2024-08-14 10:58:48", "link": "http://arxiv.org/abs/2408.07457v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Bridging and Modeling Correlations in Pairwise Data for Direct\n  Preference Optimization", "abstract": "Direct preference optimization (DPO), a widely adopted offline preference\noptimization algorithm, aims to align large language models (LLMs) with\nhuman-desired behaviors using pairwise preference data. However, the generation\nof the winning response and the losing response within pairwise data are\ntypically isolated, leading to weak correlations between them as well as\nsuboptimal alignment performance. To address this issue, we propose an\neffective framework for Bridging and Modeling Correlations in pairwise data,\nnamed BMC. Firstly, we increase the consistency and informativeness of the\npairwise preference signals through targeted modifications, synthesizing a\npseudo-winning response by improving the losing response with the winning\nresponse as a reference. Secondly, we identify that DPO alone is insufficient\nto model these correlations and capture nuanced variations. Therefore, we\npropose learning token-level correlations by dynamically leveraging the policy\nmodel's confidence during training. Comprehensive experiments on QA, math, and\ninstruction-following tasks demonstrate the effectiveness of our approach,\nsignificantly surpassing competitive baselines, including DPO. Additionally,\nour in-depth quantitative analysis reveals the reasons behind our method's\nsuperior performance over DPO and showcases its versatility to other DPO\nvariants. We release our repository at https://github.com/YJiangcm/BMC.", "published": "2024-08-14 11:29:47", "link": "http://arxiv.org/abs/2408.07471v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Know What Makes Exemplary Contexts", "abstract": "In-context learning (ICL) has proven to be a significant capability with the\nadvancement of Large Language models (LLMs). By instructing LLMs using few-shot\ndemonstrative examples, ICL enables them to perform a wide range of tasks\nwithout needing to update millions of parameters. This paper presents a unified\nframework for LLMs that allows them to self-select influential in-context\nexamples to compose their contexts; self-rank candidates with different\ndemonstration compositions; self-optimize the demonstration selection and\nordering through reinforcement learning. Specifically, our method designs a\nparameter-efficient retrieval head that generates the optimized demonstration\nafter training with rewards from LLM's own preference. Experimental results\nvalidate the proposed method's effectiveness in enhancing ICL performance.\nAdditionally, our approach effectively identifies and selects the most\nrepresentative examples for the current task, and includes more diversity in\nretrieval.", "published": "2024-08-14 12:32:41", "link": "http://arxiv.org/abs/2408.07505v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Role of Lexical Semantics in Cross-lingual Transfer\n  through Controlled Manipulations", "abstract": "While cross-linguistic model transfer is effective in many settings, there is\nstill limited understanding of the conditions under which it works. In this\npaper, we focus on assessing the role of lexical semantics in cross-lingual\ntransfer, as we compare its impact to that of other language properties.\nExamining each language property individually, we systematically analyze how\ndifferences between English and a target language influence the capacity to\nalign the language with an English pretrained representation space. We do so by\nartificially manipulating the English sentences in ways that mimic specific\ncharacteristics of the target language, and reporting the effect of each\nmanipulation on the quality of alignment with the representation space. We show\nthat while properties such as the script or word order only have a limited\nimpact on alignment quality, the degree of lexical matching between the two\nlanguages, which we define using a measure of translation entropy, greatly\naffects it.", "published": "2024-08-14 14:59:20", "link": "http://arxiv.org/abs/2408.07599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Detection of Conversational Mental Manipulation Through\n  Advanced Prompting Techniques", "abstract": "This study presents a comprehensive, long-term project to explore the\neffectiveness of various prompting techniques in detecting dialogical mental\nmanipulation. We implement Chain-of-Thought prompting with Zero-Shot and\nFew-Shot settings on a binary mental manipulation detection task, building upon\nexisting work conducted with Zero-Shot and Few- Shot prompting. Our primary\nobjective is to decipher why certain prompting techniques display superior\nperformance, so as to craft a novel framework tailored for detection of mental\nmanipulation. Preliminary findings suggest that advanced prompting techniques\nmay not be suitable for more complex models, if they are not trained through\nexample-based learning.", "published": "2024-08-14 17:23:12", "link": "http://arxiv.org/abs/2408.07676v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned\n  Language Models", "abstract": "Schema linking is a crucial step in Text-to-SQL pipelines. Its goal is to\nretrieve the relevant tables and columns of a target database for a user's\nquery while disregarding irrelevant ones. However, imperfect schema linking can\noften exclude required columns needed for accurate query generation. In this\nwork, we revisit schema linking when using the latest generation of large\nlanguage models (LLMs). We find empirically that newer models are adept at\nutilizing relevant schema elements during generation even in the presence of\nlarge numbers of irrelevant ones. As such, our Text-to-SQL pipeline entirely\nforgoes schema linking in cases where the schema fits within the model's\ncontext window in order to minimize issues due to filtering required schema\nelements. Furthermore, instead of filtering contextual information, we\nhighlight techniques such as augmentation, selection, and correction, and adopt\nthem to improve the accuracy of our Text-to-SQL pipeline. Our approach ranks\nfirst on the BIRD benchmark achieving an accuracy of 71.83%.", "published": "2024-08-14 17:59:04", "link": "http://arxiv.org/abs/2408.07702v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Retrieval Augmented Generation in Arabic", "abstract": "Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn't in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.", "published": "2024-08-14 10:03:28", "link": "http://arxiv.org/abs/2408.07425v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LiveFC: A System for Live Fact-Checking of Audio Streams", "abstract": "The advances in the digital era have led to rapid dissemination of\ninformation. This has also aggravated the spread of misinformation and\ndisinformation. This has potentially serious consequences, such as civil\nunrest. While fact-checking aims to combat this, manual fact-checking is\ncumbersome and not scalable. While automated fact-checking approaches exist,\nthey do not operate in real-time and do not always account for spread of\nmisinformation through different modalities. This is particularly important as\nproactive fact-checking on live streams in real-time can help people be\ninformed of false narratives and prevent catastrophic consequences that may\ncause civil unrest. This is particularly relevant with the rapid dissemination\nof information through video on social media platforms or other streams like\npolitical rallies and debates. Hence, in this work we develop a platform named\nLiveFC, that can aid in fact-checking live audio streams in real-time. LiveFC\nhas a user-friendly interface that displays the claims detected along with\ntheir veracity and evidence for live streams with associated speakers for\nclaims from respective segments. The app can be accessed at\nhttp://livefc.factiverse.ai and a screen recording of the demo can be found at\nhttps://bit.ly/3WVAoIw.", "published": "2024-08-14 10:36:17", "link": "http://arxiv.org/abs/2408.07448v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CMU's IWSLT 2024 Simultaneous Speech Translation System", "abstract": "This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech\nTranslation (SST) task for translating English speech to German text in a\nstreaming manner. Our end-to-end speech-to-text (ST) system integrates the\nWavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the\ndecoder. We employ a two-stage training approach: initially, we align the\nrepresentations of speech and text, followed by full fine-tuning. Both stages\nare trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST\nmodel for SST using a simple fixed hold-n policy. Experiments show that our\nmodel obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2\nseconds latency on the MuST-C-v2 tst-COMMON.", "published": "2024-08-14 10:44:51", "link": "http://arxiv.org/abs/2408.07452v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models Prompting With Episodic Memory", "abstract": "Prompt optimization is essential for enhancing the performance of Large\nLanguage Models (LLMs) in a range of Natural Language Processing (NLP) tasks,\nparticularly in scenarios of few-shot learning where training examples are\nincorporated directly into the prompt. Despite the growing interest in\noptimizing prompts with few-shot examples, existing methods for prompt\noptimization are often resource-intensive or perform inadequately. In this\nwork, we propose PrOmpting with Episodic Memory (POEM), a novel prompt\noptimization technique that is simple, efficient, and demonstrates strong\ngeneralization capabilities. We approach prompt optimization as a Reinforcement\nLearning (RL) challenge, using episodic memory to archive combinations of input\ndata, permutations of few-shot examples, and the rewards observed during\ntraining. In the testing phase, we optimize the sequence of examples for each\ntest query by selecting the sequence that yields the highest total rewards from\nthe top-k most similar training examples in the episodic memory. Our results\nshow that POEM outperforms recent techniques like TEMPERA and RLPrompt by over\n5.3% in various text classification tasks. Furthermore, our approach adapts\nwell to broader language understanding tasks, consistently outperforming\nconventional heuristic methods for ordering examples.", "published": "2024-08-14 11:19:28", "link": "http://arxiv.org/abs/2408.07465v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Study on Bias Detection and Classification in Natural Language\n  Processing", "abstract": "Human biases have been shown to influence the performance of models and\nalgorithms in various fields, including Natural Language Processing. While the\nstudy of this phenomenon is garnering focus in recent years, the available\nresources are still relatively scarce, often focusing on different forms or\nmanifestations of biases. The aim of our work is twofold: 1) gather\npublicly-available datasets and determine how to better combine them to\neffectively train models in the task of hate speech detection and\nclassification; 2) analyse the main issues with these datasets, such as\nscarcity, skewed resources, and reliance on non-persistent data. We discuss\nthese issues in tandem with the development of our experiments, in which we\nshow that the combinations of different datasets greatly impact the models'\nperformance.", "published": "2024-08-14 11:49:24", "link": "http://arxiv.org/abs/2408.07479v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MathScape: Evaluating MLLMs in multimodal Math Scenarios through a\n  Hierarchical Benchmark", "abstract": "With the development of Multimodal Large Language Models (MLLMs), the\nevaluation of multimodal models in the context of mathematical problems has\nbecome a valuable research field. Multimodal visual-textual mathematical\nreasoning serves as a critical indicator for evaluating the comprehension and\ncomplex multi-step quantitative reasoning abilities of MLLMs. However, previous\nmultimodal math benchmarks have not sufficiently integrated visual and textual\ninformation. To address this gap, we proposed MathScape, a new benchmark that\nemphasizes the understanding and application of combined visual and textual\ninformation. MathScape is designed to evaluate photo-based math problem\nscenarios, assessing the theoretical understanding and application ability of\nMLLMs through a categorical hierarchical approach. We conduct a\nmulti-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmark\nis challenging even for the most sophisticated models. By analyzing the\nevaluation results, we identify the limitations of MLLMs, offering valuable\ninsights for enhancing model performance.", "published": "2024-08-14 13:23:43", "link": "http://arxiv.org/abs/2408.07543v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation\n  Integrating Web Search and Knowledge Graphs", "abstract": "Large Language Models (LLMs) have greatly contributed to the development of\nadaptive intelligent agents and are positioned as an important way to achieve\nArtificial General Intelligence (AGI). However, LLMs are prone to produce\nfactually incorrect information and often produce \"phantom\" content that\nundermines their reliability, which poses a serious challenge for their\ndeployment in real-world scenarios. Enhancing LLMs by combining external\ndatabases and information retrieval mechanisms is an effective path. To address\nthe above challenges, we propose a new approach called WeKnow-RAG, which\nintegrates Web search and Knowledge Graphs into a \"Retrieval-Augmented\nGeneration (RAG)\" system. First, the accuracy and reliability of LLM responses\nare improved by combining the structured representation of Knowledge Graphs\nwith the flexibility of dense vector retrieval. WeKnow-RAG then utilizes\ndomain-specific knowledge graphs to satisfy a variety of queries and domains,\nthereby improving performance on factual information and complex reasoning\ntasks by employing multi-stage web page retrieval techniques using both sparse\nand dense retrieval methods. Our approach effectively balances the efficiency\nand accuracy of information retrieval, thus improving the overall retrieval\nprocess. Finally, we also integrate a self-assessment mechanism for the LLM to\nevaluate the trustworthiness of the answers it generates. Our approach proves\nits outstanding effectiveness in a wide range of offline experiments and online\nsubmissions.", "published": "2024-08-14 15:19:16", "link": "http://arxiv.org/abs/2408.07611v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "See It All: Contextualized Late Aggregation for 3D Dense Captioning", "abstract": "3D dense captioning is a task to localize objects in a 3D scene and generate\ndescriptive sentences for each object. Recent approaches in 3D dense captioning\nhave adopted transformer encoder-decoder frameworks from object detection to\nbuild an end-to-end pipeline without hand-crafted components. However, these\napproaches struggle with contradicting objectives where a single query\nattention has to simultaneously view both the tightly localized object regions\nand contextual environment. To overcome this challenge, we introduce SIA\n(See-It-All), a transformer pipeline that engages in 3D dense captioning with a\nnovel paradigm called late aggregation. SIA simultaneously decodes two sets of\nqueries-context query and instance query. The instance query focuses on\nlocalization and object attribute descriptions, while the context query\nversatilely captures the region-of-interest of relationships between multiple\nobjects or with the global scene, then aggregated afterwards (i.e., late\naggregation) via simple distance-based measures. To further enhance the quality\nof contextualized caption generation, we design a novel aggregator to generate\na fully informed caption based on the surrounding context, the global\nenvironment, and object instances. Extensive experiments on two of the most\nwidely-used 3D dense captioning datasets demonstrate that our proposed method\nachieves a significant improvement over prior methods.", "published": "2024-08-14 16:19:18", "link": "http://arxiv.org/abs/2408.07648v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining\n  of Probability Distributions", "abstract": "Large language models are susceptible to jailbreak attacks, which can result\nin the generation of harmful content. While prior defenses mitigate these risks\nby perturbing or inspecting inputs, they ignore competing objectives, the\nunderlying cause of alignment failures. In this paper, we propose\nAlignment-Enhanced Decoding (AED), a novel defense that employs adaptive\ndecoding to address the root causes of jailbreak issues. We first define the\nCompetitive Index to quantify alignment failures and utilize feedback from\nself-evaluation to compute post-alignment logits. Then, AED adaptively combines\nAED and post-alignment logits with the original logits to obtain harmless and\nhelpful distributions. Consequently, our method enhances safety alignment while\nmaintaining helpfulness. We conduct experiments across five models and four\ncommon jailbreaks, with the results validating the effectiveness of our\napproach. Code is available at https://github.com/GIGABaozi/AED.git.", "published": "2024-08-14 16:51:21", "link": "http://arxiv.org/abs/2408.07663v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech\n  Large Language Models", "abstract": "Warning: This paper may contain texts with uncomfortable content.\n  Large Language Models (LLMs) have achieved remarkable performance in various\ntasks, including those involving multimodal data like speech. However, these\nmodels often exhibit biases due to the nature of their training data. Recently,\nmore Speech Large Language Models (SLLMs) have emerged, underscoring the urgent\nneed to address these biases. This study introduces Spoken Stereoset, a dataset\nspecifically designed to evaluate social biases in SLLMs. By examining how\ndifferent models respond to speech from diverse demographic groups, we aim to\nidentify these biases. Our experiments reveal significant insights into their\nperformance and bias levels. The findings indicate that while most models show\nminimal bias, some still exhibit slightly stereotypical or anti-stereotypical\ntendencies.", "published": "2024-08-14 16:55:06", "link": "http://arxiv.org/abs/2408.07665v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion\n  Recognition", "abstract": "Speech emotion recognition (SER) has made significant strides with the advent\nof powerful self-supervised learning (SSL) models. However, the generalization\nof these models to diverse languages and emotional expressions remains a\nchallenge. We propose a large-scale benchmark to evaluate the robustness and\nadaptability of state-of-the-art SER models in both in-domain and out-of-domain\nsettings. Our benchmark includes a diverse set of multilingual datasets,\nfocusing on less commonly used corpora to assess generalization to new data. We\nemploy logit adjustment to account for varying class distributions and\nestablish a single dataset cluster for systematic evaluation. Surprisingly, we\nfind that the Whisper model, primarily designed for automatic speech\nrecognition, outperforms dedicated SSL models in cross-lingual SER. Our results\nhighlight the need for more robust and generalizable SER models, and our\nbenchmark serves as a valuable resource to drive future research in this\ndirection.", "published": "2024-08-14 23:33:10", "link": "http://arxiv.org/abs/2408.07851v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Visual Question Answering through Ranking-Based Hybrid\n  Training and Multimodal Fusion", "abstract": "Visual Question Answering (VQA) is a challenging task that requires systems\nto provide accurate answers to questions based on image content. Current VQA\nmodels struggle with complex questions due to limitations in capturing and\nintegrating multimodal information effectively. To address these challenges, we\npropose the Rank VQA model, which leverages a ranking-inspired hybrid training\nstrategy to enhance VQA performance. The Rank VQA model integrates high-quality\nvisual features extracted using the Faster R-CNN model and rich semantic text\nfeatures obtained from a pre-trained BERT model. These features are fused\nthrough a sophisticated multimodal fusion technique employing multi-head\nself-attention mechanisms. Additionally, a ranking learning module is\nincorporated to optimize the relative ranking of answers, thus improving answer\naccuracy. The hybrid training strategy combines classification and ranking\nlosses, enhancing the model's generalization ability and robustness across\ndiverse datasets. Experimental results demonstrate the effectiveness of the\nRank VQA model. Our model significantly outperforms existing state-of-the-art\nmodels on standard VQA datasets, including VQA v2.0 and COCO-QA, in terms of\nboth accuracy and Mean Reciprocal Rank (MRR). The superior performance of Rank\nVQA is evident in its ability to handle complex questions that require\nunderstanding nuanced details and making sophisticated inferences from the\nimage and text. This work highlights the effectiveness of a ranking-based\nhybrid training strategy in improving VQA performance and lays the groundwork\nfor further research in multimodal learning methods.", "published": "2024-08-14 05:18:43", "link": "http://arxiv.org/abs/2408.07303v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Do GPT Language Models Suffer From Split Personality Disorder? The\n  Advent Of Substrate-Free Psychometrics", "abstract": "Previous research on emergence in large language models shows these display\napparent human-like abilities and psychological latent traits. However, results\nare partly contradicting in expression and magnitude of these latent traits,\nyet agree on the worrisome tendencies to score high on the Dark Triad of\nnarcissism, psychopathy, and Machiavellianism, which, together with a track\nrecord of derailments, demands more rigorous research on safety of these\nmodels. We provided a state of the art language model with the same personality\nquestionnaire in nine languages, and performed Bayesian analysis of Gaussian\nMixture Model, finding evidence for a deeper-rooted issue. Our results suggest\nboth interlingual and intralingual instabilities, which indicate that current\nlanguage models do not develop a consistent core personality. This can lead to\nunsafe behaviour of artificial intelligence systems that are based on these\nfoundation models, and are increasingly integrated in human life. We\nsubsequently discuss the shortcomings of modern psychometrics, abstract it, and\nprovide a framework for its species-neutral, substrate-free formulation.", "published": "2024-08-14 08:53:00", "link": "http://arxiv.org/abs/2408.07377v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "DataVisT5: A Pre-trained Language Model for Jointly Understanding Text\n  and Data Visualization", "abstract": "Data visualization (DV) is the fundamental and premise tool to improve the\nefficiency in conveying the insights behind the big data, which has been widely\naccepted in existing data-driven world. Task automation in DV, such as\nconverting natural language queries to visualizations (i.e., text-to-vis),\ngenerating explanations from visualizations (i.e., vis-to-text), answering\nDV-related questions in free form (i.e. FeVisQA), and explicating tabular data\n(i.e., table-to-text), is vital for advancing the field. Despite their\npotential, the application of pre-trained language models (PLMs) like T5 and\nBERT in DV has been limited by high costs and challenges in handling\ncross-modal information, leading to few studies on PLMs for DV. We introduce\nDataVisT5, a novel PLM tailored for DV that enhances the T5 architecture\nthrough a hybrid objective pre-training and multi-task fine-tuning strategy,\nintegrating text and DV datasets to effectively interpret cross-modal\nsemantics. Extensive evaluations on public datasets show that DataVisT5\nconsistently outperforms current state-of-the-art models on various DV-related\ntasks. We anticipate that DataVisT5 will not only inspire further research on\nvertical PLMs but also expand the range of applications for PLMs.", "published": "2024-08-14 09:20:17", "link": "http://arxiv.org/abs/2408.07401v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "A Quantum-Inspired Analysis of Human Disambiguation Processes", "abstract": "Formal languages are essential for computer programming and are constructed\nto be easily processed by computers. In contrast, natural languages are much\nmore challenging and instigated the field of Natural Language Processing (NLP).\nOne major obstacle is the ubiquity of ambiguities. Recent advances in NLP have\nled to the development of large language models, which can resolve ambiguities\nwith high accuracy. At the same time, quantum computers have gained much\nattention in recent years as they can solve some computational problems faster\nthan classical computers. This new computing paradigm has reached the fields of\nmachine learning and NLP, where hybrid classical-quantum learning algorithms\nhave emerged. However, more research is needed to identify which NLP tasks\ncould benefit from a genuine quantum advantage. In this thesis, we applied\nformalisms arising from foundational quantum mechanics, such as contextuality\nand causality, to study ambiguities arising from linguistics. By doing so, we\nalso reproduced psycholinguistic results relating to the human disambiguation\nprocess. These results were subsequently used to predict human behaviour and\noutperformed current NLP methods.", "published": "2024-08-14 09:21:23", "link": "http://arxiv.org/abs/2408.07402v1", "categories": ["cs.CL", "cs.AI", "cs.LO", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Fact or Fiction? Improving Fact Verification with Knowledge Graphs\n  through Simplified Subgraph Retrievals", "abstract": "Despite recent success in natural language processing (NLP), fact\nverification still remains a difficult task. Due to misinformation spreading\nincreasingly fast, attention has been directed towards automatically verifying\nthe correctness of claims. In the domain of NLP, this is usually done by\ntraining supervised machine learning models to verify claims by utilizing\nevidence from trustworthy corpora. We present efficient methods for verifying\nclaims on a dataset where the evidence is in the form of structured knowledge\ngraphs. We use the FactKG dataset, which is constructed from the DBpedia\nknowledge graph extracted from Wikipedia. By simplifying the evidence retrieval\nprocess, from fine-tuned language models to simple logical retrievals, we are\nable to construct models that both require less computational resources and\nachieve better test-set accuracy.", "published": "2024-08-14 10:46:15", "link": "http://arxiv.org/abs/2408.07453v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Development of a Large Language Model-based Multi-Agent Clinical\n  Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based\n  Triage and Treatment Planning in Emergency Departments", "abstract": "Emergency department (ED) overcrowding and the complexity of rapid\ndecision-making in critical care settings pose significant challenges to\nhealthcare systems worldwide. While clinical decision support systems (CDSS)\nhave shown promise, the integration of large language models (LLMs) offers new\npossibilities for enhancing triage accuracy and clinical decision-making. This\nstudy presents an LLM-driven CDSS designed to assist ED physicians and nurses\nin patient triage, treatment planning, and overall emergency care management.\n  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,\norchestrated by CrewAI and Langchain. The system comprises four AI agents\nemulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED\nCoordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for\ntriage assessment and integrates with the RxNorm API for medication management.\n  The model was evaluated using the Asclepius dataset, with performance\nassessed by a clinical emergency medicine specialist. The CDSS demonstrated\nhigh accuracy in triage decision-making compared to the baseline of a\nsingle-agent system. Furthermore, the system exhibited strong performance in\ncritical areas, including primary diagnosis, critical findings identification,\ndisposition decision-making, treatment planning, and resource allocation.\n  Our multi-agent CDSS demonstrates significant potential for supporting\ncomprehensive emergency care management. By leveraging state-of-the-art AI\ntechnologies, this system offers a scalable and adaptable tool that could\nenhance emergency medical care delivery, potentially alleviating ED\novercrowding and improving patient outcomes. This work contributes to the\ngrowing field of AI applications in emergency medicine and offers a promising\ndirection for future research and clinical implementation.", "published": "2024-08-14 13:03:41", "link": "http://arxiv.org/abs/2408.07531v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Hierarchical Working Memory and a New Magic Number", "abstract": "The extremely limited working memory span, typically around four items,\ncontrasts sharply with our everyday experience of processing much larger\nstreams of sensory information concurrently. This disparity suggests that\nworking memory can organize information into compact representations such as\nchunks, yet the underlying neural mechanisms remain largely unknown. Here, we\npropose a recurrent neural network model for chunking within the framework of\nthe synaptic theory of working memory. We showed that by selectively\nsuppressing groups of stimuli, the network can maintain and retrieve the\nstimuli in chunks, hence exceeding the basic capacity. Moreover, we show that\nour model can dynamically construct hierarchical representations within working\nmemory through hierarchical chunking. A consequence of this proposed mechanism\nis a new limit on the number of items that can be stored and subsequently\nretrieved from working memory, depending only on the basic working memory\ncapacity when chunking is not invoked. Predictions from our model were\nconfirmed by analyzing single-unit responses in epileptic patients and memory\nexperiments with verbal material. Our work provides a novel conceptual and\nanalytical framework for understanding the on-the-fly organization of\ninformation in the brain that is crucial for cognition.", "published": "2024-08-14 16:03:47", "link": "http://arxiv.org/abs/2408.07637v1", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories,\n  Applications and Opportunities", "abstract": "Model merging is an efficient empowerment technique in the machine learning\ncommunity that does not require the collection of raw training data and does\nnot require expensive computation. As model merging becomes increasingly\nprevalent across various fields, it is crucial to understand the available\nmodel merging techniques comprehensively. However, there is a significant gap\nin the literature regarding a systematic and thorough review of these\ntechniques. This survey provides a comprehensive overview of model merging\nmethods and theories, their applications in various domains and settings, and\nfuture research directions. Specifically, we first propose a new taxonomic\napproach that exhaustively discusses existing model merging methods. Secondly,\nwe discuss the application of model merging techniques in large language\nmodels, multimodal large language models, and 10+ machine learning subfields,\nincluding continual learning, multi-task learning, few-shot learning, etc.\nFinally, we highlight the remaining challenges of model merging and discuss\nfuture research directions. A comprehensive list of papers about model merging\nis available at\n\\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.", "published": "2024-08-14 16:58:48", "link": "http://arxiv.org/abs/2408.07666v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Quantifying over Optimum Answer Sets", "abstract": "Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to\nprovide a natural extension of ASP modeling to problems in the polynomial\nhierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and\ncompact way problems requiring a polynomial number of calls to an oracle in\n$\\Sigma_n^p$ (that is, problems in $\\Delta_{n+1}^p$). Such problems include, in\nparticular, optimization problems. In this paper we propose an extension of\nASP(Q), in which component programs may contain weak constraints. Weak\nconstraints can be used both for expressing local optimization within\nquantified component programs and for modeling global optimization criteria. We\nshowcase the modeling capabilities of the new formalism through various\napplication scenarios. Further, we study its computational properties obtaining\ncomplexity results and unveiling non-obvious characteristics of ASP(Q) programs\nwith weak constraints.", "published": "2024-08-14 17:53:13", "link": "http://arxiv.org/abs/2408.07697v1", "categories": ["cs.AI", "cs.CC", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction\n  Based on Large Language Model", "abstract": "In the realm of event prediction, temporal knowledge graph forecasting (TKGF)\nstands as a pivotal technique. Previous approaches face the challenges of not\nutilizing experience during testing and relying on a single short-term history,\nwhich limits adaptation to evolving data. In this paper, we introduce the\nOnline Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by\nintegrating dynamic causal rule mining (DCRM) and dual history augmented\ngeneration (DHAG). DCRM dynamically constructs causal rules from real-time\ndata, allowing for swift adaptation to new causal relationships. In parallel,\nDHAG merges short-term and long-term historical contexts, leveraging a\nbi-branch approach to enrich event prediction. Our framework demonstrates\nnotable performance enhancements across diverse datasets, with significant\nHit@k (k=1,3,10) improvements, showcasing its ability to augment large language\nmodels (LLMs) for event prediction without necessitating extensive retraining.\nThe ONSEP framework not only advances the field of TKGF but also underscores\nthe potential of neural-symbolic approaches in adapting to dynamic data\nenvironments.", "published": "2024-08-14 22:28:19", "link": "http://arxiv.org/abs/2408.07840v1", "categories": ["cs.CL", "cs.AI", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Training Language Models on the Knowledge Graph: Insights on\n  Hallucinations and Their Detectability", "abstract": "While many capabilities of language models (LMs) improve with increased\ntraining budget, the influence of scale on hallucinations is not yet fully\nunderstood. Hallucinations come in many forms, and there is no universally\naccepted definition. We thus focus on studying only those hallucinations where\na correct answer appears verbatim in the training set. To fully control the\ntraining data content, we construct a knowledge graph (KG)-based dataset, and\nuse it to train a set of increasingly large LMs. We find that for a fixed\ndataset, larger and longer-trained LMs hallucinate less. However, hallucinating\non $\\leq5$% of the training data requires an order of magnitude larger model,\nand thus an order of magnitude more compute, than Hoffmann et al. (2022)\nreported was optimal. Given this costliness, we study how hallucination\ndetectors depend on scale. While we see detector size improves performance on\nfixed LM's outputs, we find an inverse relationship between the scale of the LM\nand the detectability of its hallucinations.", "published": "2024-08-14 23:34:28", "link": "http://arxiv.org/abs/2408.07852v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CodeMirage: Hallucinations in Code Generated by Large Language Models", "abstract": "Large Language Models (LLMs) have shown promising potentials in program\ngeneration and no-code automation. However, LLMs are prone to generate\nhallucinations, i.e., they generate text which sounds plausible but is\nincorrect. Although there has been a recent surge in research on LLM\nhallucinations for text generation, similar hallucination phenomenon can happen\nin code generation. Sometimes the generated code can have syntactical or\nlogical errors as well as more advanced issues like security vulnerabilities,\nmemory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in\ncode generation and development in general, it becomes imperative to\ninvestigate hallucinations in code generation. To the best of our knowledge,\nthis is the first attempt at studying hallucinations in the code generated by\nLLMs. We start by introducing the code hallucination definition and a\ncomprehensive taxonomy of code hallucination types. We propose the first\nbenchmark CodeMirage dataset for code hallucinations. The benchmark contains\n1,137 GPT-3.5 generated hallucinated code snippets for Python programming\nproblems from two base datasets - HumanEval and MBPP. We then propose the\nmethodology for code hallucination detection and experiment with open source\nLLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using\none-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and\ngives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset.\nTowards the end, we discuss various mitigation strategies for code\nhallucinations and conclude our work.", "published": "2024-08-14 22:53:07", "link": "http://arxiv.org/abs/2408.08333v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SAGE-RT: Synthetic Alignment data Generation for Safety Evaluation and\n  Red Teaming", "abstract": "We introduce Synthetic Alignment data Generation for Safety Evaluation and\nRed Teaming (SAGE-RT or SAGE) a novel pipeline for generating synthetic\nalignment and red-teaming data. Existing methods fall short in creating nuanced\nand diverse datasets, providing necessary control over the data generation and\nvalidation processes, or require large amount of manually generated seed data.\nSAGE addresses these limitations by using a detailed taxonomy to produce\nsafety-alignment and red-teaming data across a wide range of topics. We\ngenerated 51,000 diverse and in-depth prompt-response pairs, encompassing over\n1,500 topics of harmfulness and covering variations of the most frequent types\nof jailbreaking prompts faced by large language models (LLMs). We show that the\nred-teaming data generated through SAGE jailbreaks state-of-the-art LLMs in\nmore than 27 out of 32 sub-categories, and in more than 58 out of 279\nleaf-categories (sub-sub categories). The attack success rate for GPT-4o,\nGPT-3.5-turbo is 100% over the sub-categories of harmfulness. Our approach\navoids the pitfalls of synthetic safety-training data generation such as mode\ncollapse and lack of nuance in the generation pipeline by ensuring a detailed\ncoverage of harmful topics using iterative expansion of the topics and\nconditioning the outputs on the generated raw-text. This method can be used to\ngenerate red-teaming and alignment data for LLM Safety completely synthetically\nto make LLMs safer or for red-teaming the models over a diverse range of\ntopics.", "published": "2024-08-14 08:38:31", "link": "http://arxiv.org/abs/2408.11851v1", "categories": ["cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Fast Training Dataset Attribution via In-Context Learning", "abstract": "We investigate the use of in-context learning and prompt engineering to\nestimate the contributions of training data in the outputs of instruction-tuned\nlarge language models (LLMs). We propose two novel approaches: (1) a\nsimilarity-based approach that measures the difference between LLM outputs with\nand without provided context, and (2) a mixture distribution model approach\nthat frames the problem of identifying contribution scores as a matrix\nfactorization task. Our empirical comparison demonstrates that the mixture\nmodel approach is more robust to retrieval noise in in-context learning,\nproviding a more reliable estimation of data contributions.", "published": "2024-08-14 20:48:45", "link": "http://arxiv.org/abs/2408.11852v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformers and Large Language Models for Efficient Intrusion Detection\n  Systems: A Comprehensive Survey", "abstract": "With significant advancements in Transformers LLMs, NLP has extended its\nreach into many research fields due to its enhanced capabilities in text\ngeneration and user interaction. One field benefiting greatly from these\nadvancements is cybersecurity. In cybersecurity, many parameters that need to\nbe protected and exchanged between senders and receivers are in the form of\ntext and tabular data, making NLP a valuable tool in enhancing the security\nmeasures of communication protocols. This survey paper provides a comprehensive\nanalysis of the utilization of Transformers and LLMs in cyber-threat detection\nsystems. The methodology of paper selection and bibliometric analysis is\noutlined to establish a rigorous framework for evaluating existing research.\nThe fundamentals of Transformers are discussed, including background\ninformation on various cyber-attacks and datasets commonly used in this field.\nThe survey explores the application of Transformers in IDSs, focusing on\ndifferent architectures such as Attention-based models, LLMs like BERT and GPT,\nCNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.\nFurthermore, it explores the diverse environments and applications where\nTransformers and LLMs-based IDS have been implemented, including computer\nnetworks, IoT devices, critical infrastructure protection, cloud computing,\nSDN, as well as in autonomous vehicles. The paper also addresses research\nchallenges and future directions in this area, identifying key issues such as\ninterpretability, scalability, and adaptability to evolving threats, and more.\nFinally, the conclusion summarizes the findings and highlights the significance\nof Transformers and LLMs in enhancing cyber-threat detection capabilities,\nwhile also outlining potential avenues for further research and development.", "published": "2024-08-14 14:28:11", "link": "http://arxiv.org/abs/2408.07583v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CV", "eess.AS"], "primary_category": "cs.CR"}
{"title": "MorphFader: Enabling Fine-grained Controllable Morphing with\n  Text-to-Audio Models", "abstract": "Sound morphing is the process of gradually and smoothly transforming one\nsound into another to generate novel and perceptually hybrid sounds that\nsimultaneously resemble both. Recently, diffusion-based text-to-audio models\nhave produced high-quality sounds using text prompts. However, granularly\ncontrolling the semantics of the sound, which is necessary for morphing, can be\nchallenging using text. In this paper, we propose \\textit{MorphFader}, a\ncontrollable method for morphing sounds generated by disparate prompts using\ntext-to-audio models. By intercepting and interpolating the components of the\ncross-attention layers within the diffusion process, we can create smooth\nmorphs between sounds generated by different text prompts. Using both objective\nmetrics and perceptual listening tests, we demonstrate the ability of our\nmethod to granularly control the semantics in the sound and generate smooth\nmorphs.", "published": "2024-08-14 02:29:26", "link": "http://arxiv.org/abs/2408.07260v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "WavLM model ensemble for audio deepfake detection", "abstract": "Audio deepfake detection has become a pivotal task over the last couple of\nyears, as many recent speech synthesis and voice cloning systems generate\nhighly realistic speech samples, thus enabling their use in malicious\nactivities. In this paper we address the issue of audio deepfake detection as\nit was set in the ASVspoof5 challenge. First, we benchmark ten types of\npretrained representations and show that the self-supervised representations\nstemming from the wav2vec2 and wavLM families perform best. Of the two, wavLM\nis better when restricting the pretraining data to LibriSpeech, as required by\nthe challenge rules. To further improve performance, we finetune the wavLM\nmodel for the deepfake detection task. We extend the ASVspoof5 dataset with\nsamples from other deepfake detection datasets and apply data augmentation. Our\nfinal challenge submission consists of a late fusion combination of four models\nand achieves an equal error rate of 6.56% and 17.08% on the two evaluation\nsets.", "published": "2024-08-14 09:43:35", "link": "http://arxiv.org/abs/2408.07414v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DPSNN: Spiking Neural Network for Low-Latency Streaming Speech\n  Enhancement", "abstract": "Speech enhancement (SE) improves communication in noisy environments,\naffecting areas such as automatic speech recognition, hearing aids, and\ntelecommunications. With these domains typically being power-constrained and\nevent-based while requiring low latency, neuromorphic algorithms in the form of\nspiking neural networks (SNNs) have great potential. Yet, current effective SNN\nsolutions require a contextual sampling window imposing substantial latency,\ntypically around 32ms, too long for many applications. Inspired by Dual-Path\nSpiking Neural Networks (DPSNNs) in classical neural networks, we develop a\ntwo-phase time-domain streaming SNN framework -- the Dual-Path Spiking Neural\nNetwork (DPSNN). In the DPSNN, the first phase uses Spiking Convolutional\nNeural Networks (SCNNs) to capture global contextual information, while the\nsecond phase uses Spiking Recurrent Neural Networks (SRNNs) to focus on\nfrequency-related features. In addition, the regularizer suppresses activation\nto further enhance energy efficiency of our DPSNNs. Evaluating on the VCTK and\nIntel DNS Datasets, we demonstrate that our approach achieves the very low\nlatency (approximately 5ms) required for applications like hearing aids, while\ndemonstrating excellent signal-to-noise ratio (SNR), perceptual quality, and\nenergy efficiency.", "published": "2024-08-14 09:08:43", "link": "http://arxiv.org/abs/2408.07388v1", "categories": ["cs.SD", "cs.LG", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unsupervised Blind Joint Dereverberation and Room Acoustics Estimation\n  with Diffusion Models", "abstract": "This paper presents an unsupervised method for single-channel blind\ndereverberation and room impulse response (RIR) estimation, called BUDDy. The\nalgorithm is rooted in Bayesian posterior sampling: it combines a likelihood\nmodel enforcing fidelity to the reverberant measurement, and an anechoic speech\nprior implemented by an unconditional diffusion model. We design a parametric\nfilter representing the RIR, with exponential decay for each frequency subband.\nRoom acoustics estimation and speech dereverberation are jointly carried out,\nas the filter parameters are iteratively estimated and the speech utterance\nrefined along the reverse diffusion trajectory. In a blind scenario where the\nRIR is unknown, BUDDy successfully performs speech dereverberation in various\nacoustic scenarios, significantly outperforming other blind unsupervised\nbaselines. Unlike supervised methods, which often struggle to generalize, BUDDy\nseamlessly adapts to different acoustic conditions. This paper extends our\nprevious work by offering new experimental results and insights into the\nalgorithm's versatility. We demonstrate the robustness of our proposed method\nto new acoustic and speaker conditions, as well as its adaptability to\nhigh-resolution singing voice dereverberation, using both instrumental metrics\nand subjective listening evaluation. We study BUDDy's performance for RIR\nestimation and observe it surpasses a state-of-the-art supervised DNN-based\nestimator on mismatched acoustic conditions. Finally, we investigate the\nsensitivity of informed dereverberation methods to RIR estimation errors,\nthereby motivating the joint acoustic estimation and dereverberation design.\nAudio examples and code can be found online.", "published": "2024-08-14 11:31:32", "link": "http://arxiv.org/abs/2408.07472v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Optimising MFCC parameters for the automatic detection of respiratory\n  diseases", "abstract": "Voice signals originating from the respiratory tract are utilized as valuable\nacoustic biomarkers for the diagnosis and assessment of respiratory diseases.\nAmong the employed acoustic features, Mel Frequency Cepstral Coefficients\n(MFCC) is widely used for automatic analysis, with MFCC extraction commonly\nrelying on default parameters. However, no comprehensive study has\nsystematically investigated the impact of MFCC extraction parameters on\nrespiratory disease diagnosis. In this study, we address this gap by examining\nthe effects of key parameters, namely the number of coefficients, frame length,\nand hop length between frames, on respiratory condition examination. Our\ninvestigation uses four datasets: the Cambridge COVID-19 Sound database, the\nCoswara dataset, the Saarbrucken Voice Disorders (SVD) database, and a TACTICAS\ndataset. The Support Vector Machine (SVM) is employed as the classifier, given\nits widespread adoption and efficacy. Our findings indicate that the accuracy\nof MFCC decreases as hop length increases, and the optimal number of\ncoefficients is observed to be approximately 30. The performance of MFCC varies\nwith frame length across the datasets: for the COVID-19 datasets (Cambridge\nCOVID-19 Sound database and Coswara dataset), performance declines with longer\nframe lengths, while for the SVD dataset, performance improves with increasing\nframe length (from 50 ms to 500 ms). Furthermore, we investigate the optimized\ncombination of these parameters and observe substantial enhancements in\naccuracy. Compared to the worst combination, the SVM model achieves an accuracy\nof 81.1%, 80.6%, and 71.7%, with improvements of 19.6%, 16.10%, and 14.90% for\nthe Cambridge COVID-19 Sound database, the Coswara dataset, and the SVD dataset\nrespectively.", "published": "2024-08-14 12:56:17", "link": "http://arxiv.org/abs/2408.07522v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform\n  Generation", "abstract": "Recently, universal waveform generation tasks have been investigated\nconditioned on various out-of-distribution scenarios. Although GAN-based\nmethods have shown their strength in fast waveform generation, they are\nvulnerable to train-inference mismatch scenarios such as two-stage\ntext-to-speech. Meanwhile, diffusion-based models have shown their powerful\ngenerative performance in other domains; however, they stay out of the\nlimelight due to slow inference speed in waveform generation tasks. Above all,\nthere is no generator architecture that can explicitly disentangle the natural\nperiodic features of high-resolution waveform signals. In this paper, we\npropose PeriodWave, a novel universal waveform generation model. First, we\nintroduce a period-aware flow matching estimator that can capture the periodic\nfeatures of the waveform signal when estimating the vector fields.\nAdditionally, we utilize a multi-period estimator that avoids overlaps to\ncapture different periodic features of waveform signals. Although increasing\nthe number of periods can improve the performance significantly, this requires\nmore computational costs. To reduce this issue, we also propose a single\nperiod-conditional universal estimator that can feed-forward parallel by\nperiod-wise batch inference. Additionally, we utilize discrete wavelet\ntransform to losslessly disentangle the frequency information of waveform\nsignals for high-frequency modeling, and introduce FreeU to reduce the\nhigh-frequency noise for waveform generation. The experimental results\ndemonstrated that our model outperforms the previous models both in\nMel-spectrogram reconstruction and text-to-speech tasks. All source code will\nbe available at \\url{https://github.com/sh-lee-prml/PeriodWave}.", "published": "2024-08-14 13:36:17", "link": "http://arxiv.org/abs/2408.07547v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
