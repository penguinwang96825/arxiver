{"title": "Revisiting Challenges in Data-to-Text Generation with Fact Grounding", "abstract": "Data-to-text generation models face challenges in ensuring data fidelity by\nreferring to the correct input source. To inspire studies in this area, Wiseman\net al. (2017) introduced the RotoWire corpus on generating NBA game summaries\nfrom the box- and line-score tables. However, limited attempts have been made\nin this direction and the challenges remain. We observe a prominent bottleneck\nin the corpus where only about 60% of the summary contents can be grounded to\nthe boxscore records. Such information deficiency tends to misguide a\nconditioned language model to produce unconditioned random facts and thus leads\nto factual hallucinations. In this work, we restore the information balance and\nrevamp this task to focus on fact-grounded data-to-text generation. We\nintroduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),\nwith 50% more data from the year 2017-19 and enriched input tables, hoping to\nattract more research focuses in this direction. Moreover, we achieve improved\ndata fidelity over the state-of-the-art models by integrating a new form of\ntable reconstruction as an auxiliary task to boost the generation quality.", "published": "2020-01-12 02:31:07", "link": "http://arxiv.org/abs/2001.03830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Generalization of Neural Models: A Named Entity Recognition\n  Case Study", "abstract": "While neural network-based models have achieved impressive performance on a\nlarge body of NLP tasks, the generalization behavior of different models\nremains poorly understood: Does this excellent performance imply a perfect\ngeneralization model, or are there still some limitations? In this paper, we\ntake the NER task as a testbed to analyze the generalization behavior of\nexisting models from different perspectives and characterize the differences of\ntheir generalization abilities through the lens of our proposed measures, which\nguides us to better design models and training methods. Experiments with\nin-depth analyses diagnose the bottleneck of existing neural NER models in\nterms of breakdown performance analysis, annotation errors, dataset bias, and\ncategory relationships, which suggest directions for improvement. We have\nreleased the datasets: (ReCoNLL, PLONER) for the future research at our project\npage: http://pfliu.com/InterpretNER/. As a by-product of this paper, we have\nopen-sourced a project that involves a comprehensive summary of recent NER\npapers and classifies them into different research topics:\nhttps://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers.", "published": "2020-01-12 04:33:53", "link": "http://arxiv.org/abs/2001.03844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting New Word Meanings: A Comparison of Word Embedding Models in\n  Spanish", "abstract": "Semantic neologisms (SN) are defined as words that acquire a new word meaning\nwhile maintaining their form. Given the nature of this kind of neologisms, the\ntask of identifying these new word meanings is currently performed manually by\nspecialists at observatories of neology. To detect SN in a semi-automatic way,\nwe developed a system that implements a combination of the following\nstrategies: topic modeling, keyword extraction, and word sense disambiguation.\nThe role of topic modeling is to detect the themes that are treated in the\ninput text. Themes within a text give clues about the particular meaning of the\nwords that are used, for example: viral has one meaning in the context of\ncomputer science (CS) and another when talking about health. To extract\nkeywords, we used TextRank with POS tag filtering. With this method, we can\nobtain relevant words that are already part of the Spanish lexicon. We use a\ndeep learning model to determine if a given keyword could have a new meaning.\nEmbeddings that are different from all the known meanings (or topics) indicate\nthat a word might be a valid SN candidate. In this study, we examine the\nfollowing word embedding models: Word2Vec, Sense2Vec, and FastText. The models\nwere trained with equivalent parameters using Wikipedia in Spanish as corpora.\nThen we used a list of words and their concordances (obtained from our database\nof neologisms) to show the different embeddings that each model yields.\nFinally, we present a comparison of these outcomes with the concordances of\neach word to show how we can determine if a word could be a valid candidate for\nSN.", "published": "2020-01-12 21:54:52", "link": "http://arxiv.org/abs/2001.05285v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Urdu-English Machine Transliteration using Neural Networks", "abstract": "Machine translation has gained much attention in recent years. It is a\nsub-field of computational linguistic which focus on translating text from one\nlanguage to other language. Among different translation techniques, neural\nnetwork currently leading the domain with its capabilities of providing a\nsingle large neural network with attention mechanism, sequence-to-sequence and\nlong-short term modelling. Despite significant progress in domain of machine\ntranslation, translation of out-of-vocabulary words(OOV) which include\ntechnical terms, named-entities, foreign words are still a challenge for\ncurrent state-of-art translation systems, and this situation becomes even worse\nwhile translating between low resource languages or languages having different\nstructures. Due to morphological richness of a language, a word may have\ndifferent meninges in different context. In such scenarios, translation of word\nis not only enough in order provide the correct/quality translation.\nTransliteration is a way to consider the context of word/sentence during\ntranslation. For low resource language like Urdu, it is very difficult to\nhave/find parallel corpus for transliteration which is large enough to train\nthe system. In this work, we presented transliteration technique based on\nExpectation Maximization (EM) which is un-supervised and language independent.\nSystems learns the pattern and out-of-vocabulary (OOV) words from parallel\ncorpus and there is no need to train it on transliteration corpus explicitly.\nThis approach is tested on three models of statistical machine translation\n(SMT) which include phrasebased, hierarchical phrase-based and factor based\nmodels and two models of neural machine translation which include LSTM and\ntransformer model.", "published": "2020-01-12 17:30:42", "link": "http://arxiv.org/abs/2001.05296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stochastic Natural Language Generation Using Dependency Information", "abstract": "This article presents a stochastic corpus-based model for generating natural\nlanguage text. Our model first encodes dependency relations from training data\nthrough a feature set, then concatenates these features to produce a new\ndependency tree for a given meaning representation, and finally generates a\nnatural language utterance from the produced dependency tree. We test our model\non nine domains from tabular, dialogue act and RDF format. Our model\noutperforms the corpus-based state-of-the-art methods trained on tabular\ndatasets and also achieves comparable results with neural network-based\napproaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR\nevaluation metrics. Also, by reporting Human Evaluation results, we show that\nour model produces high-quality utterances in aspects of informativeness and\nnaturalness as well as quality.", "published": "2020-01-12 09:40:11", "link": "http://arxiv.org/abs/2001.03897v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tensor Graph Convolutional Networks for Text Classification", "abstract": "Compared to sequential learning models, graph-based neural networks exhibit\nsome excellent properties, such as ability capturing global information. In\nthis paper, we investigate graph-based neural networks for text classification\nproblem. A new framework TensorGCN (tensor graph convolutional networks), is\npresented for this task. A text graph tensor is firstly constructed to describe\nsemantic, syntactic, and sequential contextual information. Then, two kinds of\npropagation learning perform on the text graph tensor. The first is intra-graph\npropagation used for aggregating information from neighborhood nodes in a\nsingle graph. The second is inter-graph propagation used for harmonizing\nheterogeneous information between graphs. Extensive experiments are conducted\non benchmark datasets, and the results illustrate the effectiveness of our\nproposed framework. Our proposed TensorGCN presents an effective way to\nharmonize and integrate heterogeneous information from different kinds of\ngraphs.", "published": "2020-01-12 14:28:33", "link": "http://arxiv.org/abs/2001.05313v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CURE Dataset: Ladder Networks for Audio Event Classification", "abstract": "Audio event classification is an important task for several applications such\nas surveillance, audio, video and multimedia retrieval etc. There are\napproximately 3M people with hearing loss who can't perceive events happening\naround them. This paper establishes the CURE dataset which contains curated set\nof specific audio events most relevant for people with hearing loss. We propose\na ladder network based audio event classifier that utilizes 5s sound recordings\nderived from the Freesound project. We adopted the state-of-the-art\nconvolutional neural network (CNN) embeddings as audio features for this task.\nWe also investigate extreme learning machine (ELM) for event classification. In\nthis study, proposed classifiers are compared with support vector machine (SVM)\nbaseline. We propose signal and feature normalization that aims to reduce the\nmismatch between different recordings scenarios. Firstly, CNN is trained on\nweakly labeled Audioset data. Next, the pre-trained model is adopted as feature\nextractor for proposed CURE corpus. We incorporate ESC-50 dataset as second\nevaluation set. Results and discussions validate the superiority of Ladder\nnetwork over ELM and SVM classifier in terms of robustness and increased\nclassification accuracy. While Ladder network is robust to data mismatches,\nsimpler SVM and ELM classifiers are sensitive to such mismatches, where the\nproposed normalization techniques can play an important role. Experimental\nstudies with ESC-50 and CURE corpora elucidate the differences in dataset\ncomplexity and robustness offered by proposed approaches.", "published": "2020-01-12 09:35:30", "link": "http://arxiv.org/abs/2001.03896v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
