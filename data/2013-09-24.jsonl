{"title": "JRC-Names: A freely available, highly multilingual named entity resource", "abstract": "This paper describes a new, freely available, highly multilingual named\nentity resource for person and organisation names that has been compiled over\nseven years of large-scale multilingual news analysis combined with Wikipedia\nmining, resulting in 205,000 per-son and organisation names plus about the same\nnumber of spelling variants written in over 20 different scripts and in many\nmore languages. This resource, produced as part of the Europe Media Monitor\nactivity (EMM, http://emm.newsbrief.eu/overview.html), can be used for a number\nof purposes. These include improving name search in databases or on the\ninternet, seeding machine learning systems to learn named entity recognition\nrules, improve machine translation results, and more. We describe here how this\nresource was created; we give statistics on its current size; we address the\nissue of morphological inflection; and we give details regarding its\nfunctionality. Updates to this resource will be made available daily.", "published": "2013-09-24 14:09:53", "link": "http://arxiv.org/abs/1309.6162v1", "categories": ["cs.CL", "H.3.1; H.3.3; I.2.7; I.5"], "primary_category": "cs.CL"}
{"title": "Acronym recognition and processing in 22 languages", "abstract": "We are presenting work on recognising acronyms of the form Long-Form\n(Short-Form) such as \"International Monetary Fund (IMF)\" in millions of news\narticles in twenty-two languages, as part of our more general effort to\nrecognise entities and their variants in news text and to use them for the\nautomatic analysis of the news, including the linking of related news across\nlanguages. We show how the acronym recognition patterns, initially developed\nfor medical terms, needed to be adapted to the more general news domain and we\npresent evaluation results. We describe our effort to automatically merge the\nnumerous long-form variants referring to the same short-form, while keeping\nnon-related long-forms separate. Finally, we provide extensive statistics on\nthe frequency and the distribution of short-form/long-form pairs across\nlanguages.", "published": "2013-09-24 14:41:33", "link": "http://arxiv.org/abs/1309.6185v1", "categories": ["cs.CL", "H.3.1; H.3.3; I.2.7; I.5.4"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis in the News", "abstract": "Recent years have brought a significant growth in the volume of research in\nsentiment analysis, mostly on highly subjective text types (movie or product\nreviews). The main difference these texts have with news articles is that their\ntarget is clearly defined and unique across the text. Following different\nannotation efforts and the analysis of the issues encountered, we realised that\nnews opinion mining is different from that of other text types. We identified\nthree subtasks that need to be addressed: definition of the target; separation\nof the good and bad news content from the good and bad sentiment expressed on\nthe target; and analysis of clearly marked opinion that is expressed\nexplicitly, not needing interpretation or the use of world knowledge.\nFurthermore, we distinguish three different possible views on newspaper\narticles - author, reader and text, which have to be addressed differently at\nthe time of analysing sentiment. Given these definitions, we present work on\nmining opinions about entities in English language news, in which (a) we test\nthe relative suitability of various sentiment dictionaries and (b) we attempt\nto separate positive or negative opinion from good or bad news. In the\nexperiments described here, we tested whether or not subject domain-defining\nvocabulary should be ignored. Results showed that this idea is more appropriate\nin the context of news opinion mining and that the approaches taking this into\nconsideration produce a better performance.", "published": "2013-09-24 15:11:43", "link": "http://arxiv.org/abs/1309.6202v1", "categories": ["cs.CL", "H.3.1; H.3.3; I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "Tracking Sentiment in Mail: How Genders Differ on Emotional Axes", "abstract": "With the widespread use of email, we now have access to unprecedented amounts\nof text that we ourselves have written. In this paper, we show how sentiment\nanalysis can be used in tandem with effective visualizations to quantify and\ntrack emotions in many types of mail. We create a large word--emotion\nassociation lexicon by crowdsourcing, and use it to compare emotions in love\nletters, hate mail, and suicide notes. We show that there are marked\ndifferences across genders in how they use emotion words in work-place email.\nFor example, women use many words from the joy--sadness axis, whereas men\nprefer terms from the fear--trust axis. Finally, we show visualizations that\ncan help people track emotions in their emails.", "published": "2013-09-24 21:14:45", "link": "http://arxiv.org/abs/1309.6347v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Nuances of Emotion to Identify Personality", "abstract": "Past work on personality detection has shown that frequency of lexical\ncategories such as first person pronouns, past tense verbs, and sentiment words\nhave significant correlations with personality traits. In this paper, for the\nfirst time, we show that fine affect (emotion) categories such as that of\nexcitement, guilt, yearning, and admiration are significant indicators of\npersonality. Additionally, we perform experiments to show that the gains\nprovided by the fine affect categories are not obtained by using coarse affect\ncategories alone or with specificity features alone. We employ these features\nin five SVM classifiers for detecting five personality traits through essays.\nWe find that the use of fine emotion features leads to statistically\nsignificant improvement over a competitive baseline, whereas the use of coarse\naffect and specificity features does not.", "published": "2013-09-24 21:21:02", "link": "http://arxiv.org/abs/1309.6352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-negative Matrix Factorization with Linear Constraints for\n  Single-Channel Speech Enhancement", "abstract": "This paper investigates a non-negative matrix factorization (NMF)-based\napproach to the semi-supervised single-channel speech enhancement problem where\nonly non-stationary additive noise signals are given. The proposed method\nrelies on sinusoidal model of speech production which is integrated inside NMF\nframework using linear constraints on dictionary atoms. This method is further\ndeveloped to regularize harmonic amplitudes. Simple multiplicative algorithms\nare presented. The experimental evaluation was made on TIMIT corpus mixed with\nvarious types of noise. It has been shown that the proposed method outperforms\nsome of the state-of-the-art noise suppression techniques in terms of\nsignal-to-noise ratio.", "published": "2013-09-24 05:14:53", "link": "http://arxiv.org/abs/1309.6047v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
