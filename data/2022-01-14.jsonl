{"title": "Pretrained Language Models for Text Generation: A Survey", "abstract": "Text Generation aims to produce plausible and readable text in a human\nlanguage from input data. The resurgence of deep learning has greatly advanced\nthis field, in particular, with the help of neural generation models based on\npre-trained language models (PLMs). Text generation based on PLMs is viewed as\na promising approach in both academia and industry. In this paper, we provide a\nsurvey on the utilization of PLMs in text generation. We begin with introducing\nthree key aspects of applying PLMs to text generation: 1) how to encode the\ninput into representations preserving input semantics which can be fused into\nPLMs; 2) how to design an effective PLM to serve as the generation model; and\n3) how to effectively optimize PLMs given the reference text and to ensure that\nthe generated texts satisfy special text properties. Then, we show the major\nchallenges arisen in these aspects, as well as possible solutions for them. We\nalso include a summary of various useful resources and typical text generation\napplications based on PLMs. Finally, we highlight the future research\ndirections which will further improve these PLMs for text generation. This\ncomprehensive survey is intended to help researchers interested in text\ngeneration problems to learn the core concepts, the main techniques and the\nlatest developments in this area based on PLMs.", "published": "2022-01-14 01:44:58", "link": "http://arxiv.org/abs/2201.05273v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExtraPhrase: Efficient Data Augmentation for Abstractive Summarization", "abstract": "Neural models trained with large amount of parallel data have achieved\nimpressive performance in abstractive summarization tasks. However, large-scale\nparallel corpora are expensive and challenging to construct. In this work, we\nintroduce a low-cost and effective strategy, ExtraPhrase, to augment training\ndata for abstractive summarization tasks. ExtraPhrase constructs pseudo\ntraining data in two steps: extractive summarization and paraphrasing. We\nextract major parts of an input text in the extractive summarization step, and\nobtain its diverse expressions with the paraphrasing step. Through experiments,\nwe show that ExtraPhrase improves the performance of abstractive summarization\ntasks by more than 0.50 points in ROUGE scores compared to the setting without\ndata augmentation. ExtraPhrase also outperforms existing methods such as\nback-translation and self-training. We also show that ExtraPhrase is\nsignificantly effective when the amount of genuine training data is remarkably\nsmall, i.e., a low-resource setting. Moreover, ExtraPhrase is more\ncost-efficient than the existing approaches.", "published": "2022-01-14 06:14:34", "link": "http://arxiv.org/abs/2201.05313v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Controllable Text Generation using Transformer-based\n  Pre-trained Language Models", "abstract": "Controllable Text Generation (CTG) is emerging area in the field of natural\nlanguage generation (NLG). It is regarded as crucial for the development of\nadvanced text generation technologies that better meet the specific constraints\nin practical applications. In recent years, methods using large-scale\npre-trained language models (PLMs), in particular the widely used\ntransformer-based PLMs, have become a new paradigm of NLG, allowing generation\nof more diverse and fluent text. However, due to the limited level of\ninterpretability of deep neural networks, the controllability of these methods\nneed to be guaranteed. To this end, controllable text generation using\ntransformer-based PLMs has become a rapidly growing yet challenging new\nresearch hotspot. A diverse range of approaches have emerged in the recent 3-4\nyears, targeting different CTG tasks that require different types of controlled\nconstraints. In this paper, we present a systematic critical review on the\ncommon tasks, main approaches, and evaluation methods in this area. Finally, we\ndiscuss the challenges that the field is facing, and put forward various\npromising future directions. To the best of our knowledge, this is the first\nsurvey paper to summarize the state-of-the-art CTG techniques from the\nperspective of Transformer-based PLMs. We hope it can help researchers and\npractitioners in the related fields to quickly track the academic and\ntechnological frontier, providing them with a landscape of the area and a\nroadmap for future research.", "published": "2022-01-14 08:32:20", "link": "http://arxiv.org/abs/2201.05337v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Eliciting Knowledge from Pretrained Language Models for Prototypical\n  Prompt Verbalizer", "abstract": "Recent advances on prompt-tuning cast few-shot classification tasks as a\nmasked language modeling problem. By wrapping input into a template and using a\nverbalizer which constructs a mapping between label space and label word space,\nprompt-tuning can achieve excellent results in zero-shot and few-shot\nscenarios. However, typical prompt-tuning needs a manually designed verbalizer\nwhich requires domain expertise and human efforts. And the insufficient label\nspace may introduce considerable bias into the results. In this paper, we focus\non eliciting knowledge from pretrained language models and propose a\nprototypical prompt verbalizer for prompt-tuning. Labels are represented by\nprototypical embeddings in the feature space rather than by discrete words. The\ndistances between the embedding at the masked position of input and\nprototypical embeddings are used as classification criterion. For zero-shot\nsettings, knowledge is elicited from pretrained language models by a manually\ndesigned template to form initial prototypical embeddings. For few-shot\nsettings, models are tuned to learn meaningful and interpretable prototypical\nembeddings. Our method optimizes models by contrastive learning. Extensive\nexperimental results on several many-class text classification datasets with\nlow-resource settings demonstrate the effectiveness of our approach compared\nwith other verbalizer construction methods. Our implementation is available at\nhttps://github.com/Ydongd/prototypical-prompt-verbalizer.", "published": "2022-01-14 12:04:37", "link": "http://arxiv.org/abs/2201.05411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Czech Grammar Error Correction with a Large and Diverse Corpus", "abstract": "We introduce a large and diverse Czech corpus annotated for grammatical error\ncorrection (GEC) with the aim to contribute to the still scarce data resources\nin this domain for languages other than English. The Grammar Error Correction\nCorpus for Czech (GECCC) offers a variety of four domains, covering error\ndistributions ranging from high error density essays written by non-native\nspeakers, to website texts, where errors are expected to be much less common.\nWe compare several Czech GEC systems, including several Transformer-based ones,\nsetting a strong baseline to future research. Finally, we meta-evaluate common\nGEC metrics against human judgements on our data. We make the new Czech GEC\ncorpus publicly available under the CC BY-SA 4.0 license at\nhttp://hdl.handle.net/11234/1-4639 .", "published": "2022-01-14 18:20:47", "link": "http://arxiv.org/abs/2201.05590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Warm Start and a Clean Crawled Corpus -- A Recipe for Good Language\n  Models", "abstract": "We train several language models for Icelandic, including IceBERT, that\nachieve state-of-the-art performance in a variety of downstream tasks,\nincluding part-of-speech tagging, named entity recognition, grammatical error\ndetection and constituency parsing. To train the models we introduce a new\ncorpus of Icelandic text, the Icelandic Common Crawl Corpus (IC3), a collection\nof high quality texts found online by targeting the Icelandic top-level-domain\n(TLD). Several other public data sources are also collected for a total of 16GB\nof Icelandic text. To enhance the evaluation of model performance and to raise\nthe bar in baselines for Icelandic, we translate and adapt the WinoGrande\ndataset for co-reference resolution. Through these efforts we demonstrate that\na properly cleaned crawled corpus is sufficient to achieve state-of-the-art\nresults in NLP applications for low to medium resource languages, by comparison\nwith models trained on a curated corpus. We further show that initializing\nmodels using existing multilingual models can lead to state-of-the-art results\nfor some downstream tasks.", "published": "2022-01-14 18:45:31", "link": "http://arxiv.org/abs/2201.05601v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Open Text Release 1: Public Domain News in 44 Languages", "abstract": "We present Multilingual Open Text (MOT), a new multilingual corpus containing\ntext in 44 languages, many of which have limited existing text resources for\nnatural language processing. The first release of the corpus contains over 2.8\nmillion news articles and an additional 1 million short snippets (photo\ncaptions, video descriptions, etc.) published between 2001--2022 and collected\nfrom Voice of America's news websites. We describe our process for collecting,\nfiltering, and processing the data. The source material is in the public\ndomain, our collection is licensed using a creative commons license (CC BY\n4.0), and all software used to create the corpus is released under the MIT\nLicense. The corpus will be regularly updated as additional documents are\npublished.", "published": "2022-01-14 18:58:17", "link": "http://arxiv.org/abs/2201.05609v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Model Stability with Continuous Data Updates", "abstract": "In this paper, we study the \"stability\" of machine learning (ML) models\nwithin the context of larger, complex NLP systems with continuous training data\nupdates. For this study, we propose a methodology for the assessment of model\nstability (which we refer to as jitter under various experimental conditions.\nWe find that model design choices, including network architecture and input\nrepresentation, have a critical impact on stability through experiments on four\ntext classification tasks and two sequence labeling tasks. In classification\ntasks, non-RNN-based models are observed to be more stable than RNN-based ones,\nwhile the encoder-decoder model is less stable in sequence labeling tasks.\nMoreover, input representations based on pre-trained fastText embeddings\ncontribute to more stability than other choices. We also show that two learning\nstrategies -- ensemble models and incremental training -- have a significant\ninfluence on stability. We recommend ML model designers account for trade-offs\nin accuracy and jitter when making modeling choices.", "published": "2022-01-14 22:11:16", "link": "http://arxiv.org/abs/2201.05692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Narrative Semantic Overlap Task: Evaluation and Benchmark", "abstract": "In this paper, we introduce an important yet relatively unexplored NLP task\ncalled Multi-Narrative Semantic Overlap (MNSO), which entails generating a\nSemantic Overlap of multiple alternate narratives. As no benchmark dataset is\nreadily available for this task, we created one by crawling 2,925 narrative\npairs from the web and then, went through the tedious process of manually\ncreating 411 different ground-truth semantic overlaps by engaging human\nannotators. As a way to evaluate this novel task, we first conducted a\nsystematic study by borrowing the popular ROUGE metric from text-summarization\nliterature and discovered that ROUGE is not suitable for our task.\nSubsequently, we conducted further human annotations/validations to create 200\ndocument-level and 1,518 sentence-level ground-truth labels which helped us\nformulate a new precision-recall style evaluation metric, called SEM-F1\n(semantic F1). Experimental results show that the proposed SEM-F1 metric yields\nhigher correlation with human judgement as well as higher inter-rater-agreement\ncompared to ROUGE metric.", "published": "2022-01-14 03:56:41", "link": "http://arxiv.org/abs/2201.05294v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Applying a Generic Sequence-to-Sequence Model for Simple and Effective\n  Keyphrase Generation", "abstract": "In recent years, a number of keyphrase generation (KPG) approaches were\nproposed consisting of complex model architectures, dedicated training\nparadigms and decoding strategies. In this work, we opt for simplicity and show\nhow a commonly used seq2seq language model, BART, can be easily adapted to\ngenerate keyphrases from the text in a single batch computation using a simple\ntraining procedure. Empirical results on five benchmarks show that our approach\nis as good as the existing state-of-the-art KPG systems, but using a much\nsimpler and easy to deploy framework.", "published": "2022-01-14 04:50:28", "link": "http://arxiv.org/abs/2201.05302v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "This Must Be the Place: Predicting Engagement of Online Communities in a\n  Large-scale Distributed Campaign", "abstract": "Understanding collective decision making at a large-scale, and elucidating\nhow community organization and community dynamics shape collective behavior are\nat the heart of social science research. In this work we study the behavior of\nthousands of communities with millions of active members. We define a novel\ntask: predicting which community will undertake an unexpected, large-scale,\ndistributed campaign.\n  To this end, we develop a hybrid model, combining textual cues, community\nmeta-data, and structural properties. We show how this multi-faceted model can\naccurately predict large-scale collective decision-making in a distributed\nenvironment. We demonstrate the applicability of our model through Reddit's\nr/place - a large-scale online experiment in which millions of users,\nself-organized in thousands of communities, clashed and collaborated in an\neffort to realize their agenda.\n  Our hybrid model achieves a high F1 prediction score of 0.826. We find that\ncoarse meta-features are as important for prediction accuracy as fine-grained\ntextual cues, while explicit structural features play a smaller role.\nInterpreting our model, we provide and support various social insights about\nthe unique characteristics of the communities that participated in the \\r/place\nexperiment.\n  Our results and analysis shed light on the complex social dynamics that drive\ncollective behavior, and on the factors that propel user coordination. The\nscale and the unique conditions of the \\rp~experiment suggest that our findings\nmay apply in broader contexts, such as online activism, (countering) the spread\nof hate speech and reducing political polarization. The broader applicability\nof the model is demonstrated through an extensive analysis of the\nWallStreetBets community, their role in r/place and four years later, in the\nGameStop short squeeze campaign of 2021.", "published": "2022-01-14 08:23:16", "link": "http://arxiv.org/abs/2201.05334v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Polarity and Subjectivity Detection with Multitask Learning and BERT\n  Embedding", "abstract": "Multitask learning often helps improve the performance of related tasks as\nthese often have inter-dependence on each other and perform better when solved\nin a joint framework. In this paper, we present a deep multitask learning\nframework that jointly performs polarity and subjective detection. We propose\nan attention-based multitask model for predicting polarity and subjectivity.\nThe input sentences are transformed into vectors using pre-trained BERT and\nGlove embeddings, and the results depict that BERT embedding based model works\nbetter than the Glove based model. We compare our approach with\nstate-of-the-art models in both subjective and polarity classification\nsingle-task and multitask frameworks. The proposed approach reports baseline\nperformances for both polarity detection and subjectivity detection.", "published": "2022-01-14 09:52:15", "link": "http://arxiv.org/abs/2201.05363v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mental Health Assessment for the Chatbots", "abstract": "Previous researches on dialogue system assessment usually focus on the\nquality evaluation (e.g. fluency, relevance, etc) of responses generated by the\nchatbots, which are local and technical metrics. For a chatbot which responds\nto millions of online users including minors, we argue that it should have a\nhealthy mental tendency in order to avoid the negative psychological impact on\nthem. In this paper, we establish several mental health assessment dimensions\nfor chatbots (depression, anxiety, alcohol addiction, empathy) and introduce\nthe questionnaire-based mental health assessment methods. We conduct\nassessments on some well-known open-domain chatbots and find that there are\nsevere mental health issues for all these chatbots. We consider that it is due\nto the neglect of the mental health risks during the dataset building and the\nmodel training procedures. We expect to attract researchers' attention to the\nserious mental health problems of chatbots and improve the chatbots' ability in\npositive emotional interaction.", "published": "2022-01-14 10:38:59", "link": "http://arxiv.org/abs/2201.05382v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "The Dark Side of the Language: Pre-trained Transformers in the DarkNet", "abstract": "Pre-trained Transformers are challenging human performances in many NLP\ntasks. The massive datasets used for pre-training seem to be the key to their\nsuccess on existing tasks. In this paper, we explore how a range of pre-trained\nNatural Language Understanding models perform on definitely unseen sentences\nprovided by classification tasks over a DarkNet corpus. Surprisingly, results\nshow that syntactic and lexical neural networks perform on par with pre-trained\nTransformers even after fine-tuning. Only after what we call extreme domain\nadaptation, that is, retraining with the masked language model task on all the\nnovel corpus, pre-trained Transformers reach their standard high results. This\nsuggests that huge pre-training corpora may give Transformers unexpected help\nsince they are exposed to many of the possible sentences.", "published": "2022-01-14 16:04:09", "link": "http://arxiv.org/abs/2201.05613v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Reducing Manual Workload in Technology-Assisted Reviews:\n  Estimating Ranking Performance", "abstract": "Conducting a systematic review (SR) is comprised of multiple tasks: (i)\ncollect documents (studies) that are likely to be relevant from digital\nlibraries (eg., PubMed), (ii) manually read and label the documents as relevant\nor irrelevant, (iii) extract information from the relevant studies, and (iv)\nanalyze and synthesize the information and derive a conclusion of SR. When\nresearchers label studies, they can screen ranked documents where relevant\ndocuments are higher than irrelevant ones. This practice, known as screening\nprioritization (ie., document ranking approach), speeds up the process of\nconducting a SR as the documents labelled as relevant can move to the next\ntasks earlier. However, the approach is limited in reducing the manual workload\nbecause the total number of documents to screen remains the same. Towards\nreducing the manual workload in the screening process, we investigate the\nquality of document ranking of SR. This can signal researchers whereabouts in\nthe ranking relevant studies are located and let them decide where to stop the\nscreening. After extensive analysis on SR document rankings from different\nranking models, we hypothesize 'topic broadness' as a factor that affects the\nranking quality of SR. Finally, we propose a measure that estimates the topic\nbroadness and demonstrate that the proposed measure is a simple yet effective\nmethod to predict the qualities of document rankings for SRs.", "published": "2022-01-14 19:48:45", "link": "http://arxiv.org/abs/2201.05648v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Sequence-to-Sequence Models for Extracting Information from Registration\n  and Legal Documents", "abstract": "A typical information extraction pipeline consists of token- or span-level\nclassification models coupled with a series of pre- and post-processing\nscripts. In a production pipeline, requirements often change, with classes\nbeing added and removed, which leads to nontrivial modifications to the source\ncode and the possible introduction of bugs. In this work, we evaluate\nsequence-to-sequence models as an alternative to token-level classification\nmethods for information extraction of legal and registration documents. We\nfinetune models that jointly extract the information and generate the output\nalready in a structured format. Post-processing steps are learned during\ntraining, thus eliminating the need for rule-based methods and simplifying the\npipeline. Furthermore, we propose a novel method to align the output with the\ninput text, thus facilitating system inspection and auditing. Our experiments\non four real-world datasets show that the proposed method is an alternative to\nclassical pipelines.", "published": "2022-01-14 20:20:12", "link": "http://arxiv.org/abs/2201.05658v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Cost-Effective Training in Low-Resource Neural Machine Translation", "abstract": "While Active Learning (AL) techniques are explored in Neural Machine\nTranslation (NMT), only a few works focus on tackling low annotation budgets\nwhere a limited number of sentences can get translated. Such situations are\nespecially challenging and can occur for endangered languages with few human\nannotators or having cost constraints to label large amounts of data. Although\nAL is shown to be helpful with large budgets, it is not enough to build\nhigh-quality translation systems in these low-resource conditions. In this\nwork, we propose a cost-effective training procedure to increase the\nperformance of NMT models utilizing a small number of annotated sentences and\ndictionary entries. Our method leverages monolingual data with self-supervised\nobjectives and a small-scale, inexpensive dictionary for additional supervision\nto initialize the NMT model before applying AL. We show that improving the\nmodel using a combination of these knowledge sources is essential to exploit AL\nstrategies and increase gains in low-resource conditions. We also present a\nnovel AL strategy inspired by domain adaptation for NMT and show that it is\neffective for low budgets. We propose a new hybrid data-driven approach, which\nsamples sentences that are diverse from the labelled data and also most similar\nto unlabelled data. Finally, we show that initializing the NMT model and\nfurther using our AL strategy can achieve gains of up to $13$ BLEU compared to\nconventional AL methods.", "published": "2022-01-14 22:57:14", "link": "http://arxiv.org/abs/2201.05700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Thousand Words Are Worth More Than a Picture: Natural Language-Centric\n  Outside-Knowledge Visual Question Answering", "abstract": "Outside-knowledge visual question answering (OK-VQA) requires the agent to\ncomprehend the image, make use of relevant knowledge from the entire web, and\ndigest all the information to answer the question. Most previous works address\nthe problem by first fusing the image and question in the multi-modal space,\nwhich is inflexible for further fusion with a vast amount of external\nknowledge. In this paper, we call for a paradigm shift for the OK-VQA task,\nwhich transforms the image into plain text, so that we can enable knowledge\npassage retrieval, and generative question-answering in the natural language\nspace. This paradigm takes advantage of the sheer volume of gigantic knowledge\nbases and the richness of pre-trained language models. A\nTransform-Retrieve-Generate framework (TRiG) framework is proposed, which can\nbe plug-and-played with alternative image-to-text models and textual knowledge\nbases. Experimental results show that our TRiG framework outperforms all\nstate-of-the-art supervised methods by at least 11.1% absolute margin.", "published": "2022-01-14 04:12:46", "link": "http://arxiv.org/abs/2201.05299v1", "categories": ["cs.CV", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "CommonsenseQA 2.0: Exposing the Limits of AI through Gamification", "abstract": "Constructing benchmarks that test the abilities of modern natural language\nunderstanding models is difficult - pre-trained language models exploit\nartifacts in benchmarks to achieve human parity, but still fail on adversarial\nexamples and make errors that demonstrate a lack of common sense. In this work,\nwe propose gamification as a framework for data construction. The goal of\nplayers in the game is to compose questions that mislead a rival AI while using\nspecific phrases for extra points. The game environment leads to enhanced user\nengagement and simultaneously gives the game designer control over the\ncollected data, allowing us to collect high-quality data at scale. Using our\nmethod we create CommonsenseQA 2.0, which includes 14,343 yes/no questions, and\ndemonstrate its difficulty for models that are orders-of-magnitude larger than\nthe AI used in the game itself. Our best baseline, the T5-based Unicorn with\n11B parameters achieves an accuracy of 70.2%, substantially higher than GPT-3\n(52.9%) in a few-shot inference setup. Both score well below human performance\nwhich is at 94.1%.", "published": "2022-01-14 06:49:15", "link": "http://arxiv.org/abs/2201.05320v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Progressively Optimized Bi-Granular Document Representation for Scalable\n  Embedding Based Retrieval", "abstract": "Ad-hoc search calls for the selection of appropriate answers from a\nmassive-scale corpus. Nowadays, the embedding-based retrieval (EBR) becomes a\npromising solution, where deep learning based document representation and ANN\nsearch techniques are allied to handle this task. However, a major challenge is\nthat the ANN index can be too large to fit into memory, given the considerable\nsize of answer corpus. In this work, we tackle this problem with Bi-Granular\nDocument Representation, where the lightweight sparse embeddings are indexed\nand standby in memory for coarse-grained candidate search, and the heavyweight\ndense embeddings are hosted in disk for fine-grained post verification. For the\nbest of retrieval accuracy, a Progressive Optimization framework is designed.\nThe sparse embeddings are learned ahead for high-quality search of candidates.\nConditioned on the candidate distribution induced by the sparse embeddings, the\ndense embeddings are continuously learned to optimize the discrimination of\nground-truth from the shortlisted candidates. Besides, two techniques: the\ncontrastive quantization and the locality-centric sampling are introduced for\nthe learning of sparse and dense embeddings, which substantially contribute to\ntheir performances. Thanks to the above features, our method effectively\nhandles massive-scale EBR with strong advantages in accuracy: with up to +4.3%\nrecall gain on million-scale corpus, and up to +17.5% recall gain on\nbillion-scale corpus. Besides, Our method is applied to a major sponsored\nsearch platform with substantial gains on revenue (+1.95%), Recall (+1.01%) and\nCTR (+0.49%). Our code is available at https://github.com/microsoft/BiDR.", "published": "2022-01-14 12:02:47", "link": "http://arxiv.org/abs/2201.05409v3", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Reasoning Through Memorization: Nearest Neighbor Knowledge Graph\n  Embeddings", "abstract": "Previous knowledge graph embedding approaches usually map entities to\nrepresentations and utilize score functions to predict the target entities, yet\nthey typically struggle to reason rare or emerging unseen entities. In this\npaper, we propose kNN-KGE, a new knowledge graph embedding approach with\npre-trained language models, by linearly interpolating its entity distribution\nwith k-nearest neighbors. We compute the nearest neighbors based on the\ndistance in the entity embedding space from the knowledge store. Our approach\ncan allow rare or emerging entities to be memorized explicitly rather than\nimplicitly in model parameters. Experimental results demonstrate that our\napproach can improve inductive and transductive link prediction results and\nyield better performance for low-resource settings with only a few triples,\nwhich might be easier to reason via explicit memory. Code is available at\nhttps://github.com/zjunlp/KNN-KG.", "published": "2022-01-14 17:35:16", "link": "http://arxiv.org/abs/2201.05575v4", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Study of Transducer based End-to-End ASR with ESPnet: Architecture,\n  Auxiliary Loss and Decoding Strategies", "abstract": "In this study, we present recent developments of models trained with the\nRNN-T loss in ESPnet. It involves the use of various architectures such as\nrecently proposed Conformer, multi-task learning with different auxiliary\ncriteria and multiple decoding strategies, including our own proposition.\nThrough experiments and benchmarks, we show that our proposed systems can be\ncompetitive against other state-of-art systems on well-known datasets such as\nLibriSpeech and AISHELL-1. Additionally, we demonstrate that these models are\npromising against other already implemented systems in ESPnet in regards to\nboth performance and decoding speed, enabling the possibility to have powerful\nsystems for a streaming task. With these additions, we hope to expand the\nusefulness of the ESPnet toolkit for the research community and also give tools\nfor the ASR industry to deploy our systems in realistic and production\nenvironments.", "published": "2022-01-14 12:44:00", "link": "http://arxiv.org/abs/2201.05420v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Anomalous Sound Detection using Spectral-Temporal Information Fusion", "abstract": "Unsupervised anomalous sound detection aims to detect unknown abnormal sounds\nof machines from normal sounds. However, the state-of-the-art approaches are\nnot always stable and perform dramatically differently even for machines of the\nsame type, making it impractical for general applications. This paper proposes\na spectral-temporal fusion based self-supervised method to model the feature of\nthe normal sound, which improves the stability and performance consistency in\ndetection of anomalous sounds from individual machines, even of the same type.\nExperiments on the DCASE 2020 Challenge Task 2 dataset show that the proposed\nmethod achieved 81.39\\%, 83.48\\%, 98.22\\% and 98.83\\% in terms of the minimum\nAUC (worst-case detection performance amongst individuals) in four types of\nreal machines (fan, pump, slider and valve), respectively, giving 31.79\\%,\n17.78\\%, 10.42\\% and 21.13\\% improvement compared to the state-of-the-art\nmethod, i.e., Glow\\_Aff. Moreover, the proposed method has improved AUC\n(average performance of individuals) for all the types of machines in the\ndataset. The source codes are available at\nhttps://github.com/liuyoude/STgram_MFN", "published": "2022-01-14 15:29:47", "link": "http://arxiv.org/abs/2201.05510v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multiphonic modeling using Impulse Pattern Formulation (IPF)", "abstract": "Multiphonics, the presence of multiple pitches within the sound, can be\nproduced in several ways. In wind instruments, they can appear at low blowing\npressure when complex fingerings are used. Such multiphonics can be modeled by\nthe Impulse Pattern Formulation (IPF). This top-down method regards musical\ninstruments as systems working with impulses originating from a generating\nentity, travel through the instrument, are reflected at various positions, and\nare exponentially damped. Eventually, impulses return to the generating entity\nand retrigger or interact with subsequent impulses. Due to this straightforward\napproach, the IPF can explain fundamental principles of complex dynamic\nsystems. While modeling wind instruments played with blowing pressures at the\nthreshold of tone onset, the IPF captures transitions between regular\nperiodicity at nominal pitch, bifurcations, and noise. This corresponds to\nbehavior found in wind instruments where multiphonics appear at the transition\nbetween noise and regular musical note regimes. Using the IPF, complex\nfingerings correspond to multiple reflection points at open finger holes with\ndifferent reflection strengths. Multiphonics can be modeled if reflection\npoints farther away show higher reflection strength and thus, disrupt periodic\nmotion. The IPF can also synthesize multiphonic sounds by concatenating typical\nwind instrument waveforms at adjacent impulse time points.", "published": "2022-01-14 13:55:29", "link": "http://arxiv.org/abs/2201.05452v1", "categories": ["cs.SD", "eess.AS", "nlin.AO", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Spectro-Temporal Deep Features for Disordered Speech Assessment and\n  Recognition", "abstract": "Automatic recognition of disordered speech remains a highly challenging task\nto date. Sources of variability commonly found in normal speech including\naccent, age or gender, when further compounded with the underlying causes of\nspeech impairment and varying severity levels, create large diversity among\nspeakers. To this end, speaker adaptation techniques play a vital role in\ncurrent speech recognition systems. Motivated by the spectro-temporal level\ndifferences between disordered and normal speech that systematically manifest\nin articulatory imprecision, decreased volume and clarity, slower speaking\nrates and increased dysfluencies, novel spectro-temporal subspace basis\nembedding deep features derived by SVD decomposition of speech spectrum are\nproposed to facilitate both accurate speech intelligibility assessment and\nauxiliary feature based speaker adaptation of state-of-the-art hybrid DNN and\nend-to-end disordered speech recognition systems. Experiments conducted on the\nUASpeech corpus suggest the proposed spectro-temporal deep feature adapted\nsystems consistently outperformed baseline i-Vector adaptation by up to 2.63%\nabsolute (8.6% relative) reduction in word error rate (WER) with or without\ndata augmentation. Learning hidden unit contribution (LHUC) based speaker\nadaptation was further applied. The final speaker adapted system using the\nproposed spectral basis embedding features gave an overall WER of 25.6% on the\nUASpeech test set of 16 dysarthric speakers", "published": "2022-01-14 16:56:43", "link": "http://arxiv.org/abs/2201.05554v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigation of Data Augmentation Techniques for Disordered Speech\n  Recognition", "abstract": "Disordered speech recognition is a highly challenging task. The underlying\nneuro-motor conditions of people with speech disorders, often compounded with\nco-occurring physical disabilities, lead to the difficulty in collecting large\nquantities of speech required for system development. This paper investigates a\nset of data augmentation techniques for disordered speech recognition,\nincluding vocal tract length perturbation (VTLP), tempo perturbation and speed\nperturbation. Both normal and disordered speech were exploited in the\naugmentation process. Variability among impaired speakers in both the original\nand augmented data was modeled using learning hidden unit contributions (LHUC)\nbased speaker adaptive training. The final speaker adapted system constructed\nusing the UASpeech corpus and the best augmentation approach based on speed\nperturbation produced up to 2.92% absolute (9.3% relative) word error rate\n(WER) reduction over the baseline system without data augmentation, and gave an\noverall WER of 26.37% on the test set containing 16 dysarthric speakers.", "published": "2022-01-14 17:09:22", "link": "http://arxiv.org/abs/2201.05562v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
