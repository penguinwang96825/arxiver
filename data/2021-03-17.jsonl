{"title": "Dialogue History Matters! Personalized Response Selectionin Multi-turn\n  Retrieval-based Chatbots", "abstract": "Existing multi-turn context-response matching methods mainly concentrate on\nobtaining multi-level and multi-dimension representations and better\ninteractions between context utterances and response. However, in real-place\nconversation scenarios, whether a response candidate is suitable not only\ncounts on the given dialogue context but also other backgrounds, e.g., wording\nhabits, user-specific dialogue history content. To fill the gap between these\nup-to-date methods and the real-world applications, we incorporate\nuser-specific dialogue history into the response selection and propose a\npersonalized hybrid matching network (PHMN). Our contributions are two-fold: 1)\nour model extracts personalized wording behaviors from user-specific dialogue\nhistory as extra matching information; 2) we perform hybrid representation\nlearning on context-response utterances and explicitly incorporate a customized\nattention mechanism to extract vital information from context-response\ninteractions so as to improve the accuracy of matching. We evaluate our model\non two large datasets with user identification, i.e., personalized Ubuntu\ndialogue Corpus (P-Ubuntu) and personalized Weibo dataset (P-Weibo).\nExperimental results confirm that our method significantly outperforms several\nstrong models by combining personalized attention, wording behaviors, and\nhybrid representation learning.", "published": "2021-03-17 09:42:11", "link": "http://arxiv.org/abs/2103.09534v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Endangered Languages are not Low-Resourced!", "abstract": "The term low-resourced has been tossed around in the field of natural\nlanguage processing to a degree that almost any language that is not English\ncan be called \"low-resourced\"; sometimes even just for the sake of making a\nmundane or mediocre paper appear more interesting and insightful. In a field\nwhere English is a synonym for language and low-resourced is a synonym for\nanything not English, calling endangered languages low-resourced is a bit of an\noverstatement. In this paper, I inspect the relation of the endangered with the\nlow-resourced from my own experiences.", "published": "2021-03-17 11:05:29", "link": "http://arxiv.org/abs/2103.09567v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniParma at SemEval-2021 Task 5: Toxic Spans Detection Using\n  CharacterBERT and Bag-of-Words Model", "abstract": "With the ever-increasing availability of digital information, toxic content\nis also on the rise. Therefore, the detection of this type of language is of\nparamount importance. We tackle this problem utilizing a combination of a\nstate-of-the-art pre-trained language model (CharacterBERT) and a traditional\nbag-of-words technique. Since the content is full of toxic words that have not\nbeen written according to their dictionary spelling, attendance to individual\ncharacters is crucial. Therefore, we use CharacterBERT to extract features\nbased on the word characters. It consists of a CharacterCNN module that learns\ncharacter embeddings from the context. These are, then, fed into the well-known\nBERT architecture. The bag-of-words method, on the other hand, further improves\nupon that by making sure that some frequently used toxic words get labeled\naccordingly. With a 4 percent difference from the first team, our system ranked\n36th in the competition. The code is available for further re-search and\nreproduction of the results.", "published": "2021-03-17 13:39:49", "link": "http://arxiv.org/abs/2103.09645v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal End-to-End Sparse Model for Emotion Recognition", "abstract": "Existing works on multimodal affective computing tasks, such as emotion\nrecognition, generally adopt a two-phase pipeline, first extracting feature\nrepresentations for each single modality with hand-crafted algorithms and then\nperforming end-to-end learning with the extracted features. However, the\nextracted features are fixed and cannot be further fine-tuned on different\ntarget tasks, and manually finding feature extraction algorithms does not\ngeneralize or scale well to different tasks, which can lead to sub-optimal\nperformance. In this paper, we develop a fully end-to-end model that connects\nthe two phases and optimizes them jointly. In addition, we restructure the\ncurrent datasets to enable the fully end-to-end training. Furthermore, to\nreduce the computational overhead brought by the end-to-end model, we introduce\na sparse cross-modal attention mechanism for the feature extraction.\nExperimental results show that our fully end-to-end model significantly\nsurpasses the current state-of-the-art models based on the two-phase pipeline.\nMoreover, by adding the sparse cross-modal attention, our model can maintain\nperformance with around half the computation in the feature extraction part.", "published": "2021-03-17 14:05:05", "link": "http://arxiv.org/abs/2103.09666v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Human Evaluation Datasheet 1.0: A Template for Recording Details of\n  Human Evaluation Experiments in NLP", "abstract": "This paper introduces the Human Evaluation Datasheet, a template for\nrecording the details of individual human evaluation experiments in Natural\nLanguage Processing (NLP). Originally taking inspiration from seminal papers by\nBender and Friedman (2018), Mitchell et al. (2019), and Gebru et al. (2020),\nthe Human Evaluation Datasheet is intended to facilitate the recording of\nproperties of human evaluations in sufficient detail, and with sufficient\nstandardisation, to support comparability, meta-evaluation, and reproducibility\ntests.", "published": "2021-03-17 15:08:50", "link": "http://arxiv.org/abs/2103.09710v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Plenipotentiary to Puddingless: Users and Uses of New Words in\n  Early English Letters", "abstract": "We study neologism use in two samples of early English correspondence, from\n1640--1660 and 1760--1780. Of especial interest are the early adopters of new\nvocabulary, the social groups they represent, and the types and functions of\ntheir neologisms. We describe our computer-assisted approach and note the\ndifficulties associated with massive variation in the corpus. Our findings\ninclude that while male letter-writers tend to use neologisms more frequently\nthan women, the eighteenth century seems to have provided more opportunities\nfor women and the lower ranks to participate in neologism use as well. In both\nsamples, neologisms most frequently occur in letters written between close\nfriends, which could be due to this less stable relationship triggering more\ncreative language use. In the seventeenth-century sample, we observe the\ninfluence of the English Civil War, while the eighteenth-century sample appears\nto reflect the changing functions of letter-writing, as correspondence is\nincreasingly being used as a tool for building and maintaining social\nrelationships in addition to exchanging information.", "published": "2021-03-17 21:45:06", "link": "http://arxiv.org/abs/2103.09926v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Monolingual and Multilingual BERTModels for Vietnamese\n  Aspect Category Detection", "abstract": "Aspect category detection (ACD) is one of the challenging tasks in the\nAspect-based sentiment Analysis problem. The purpose of this task is to\nidentify the aspect categories mentioned in user-generated reviews from a set\nof pre-defined categories. In this paper, we investigate the performance of\nvarious monolingual pre-trained language models compared with multilingual\nmodels on the Vietnamese aspect category detection problem. We conduct the\nexperiments on two benchmark datasets for the restaurant and hotel domain. The\nexperimental results demonstrated the effectiveness of the monolingual PhoBERT\nmodel than others on two datasets. We also evaluate the performance of the\nmultilingual model based on the combination of whole SemEval-2016 datasets in\nother languages with the Vietnamese dataset. To the best of our knowledge, our\nresearch study is the first attempt at performing various available pre-trained\nlanguage models on aspect category detection task and utilize the datasets from\nother languages based on multilingual models.", "published": "2021-03-17 09:04:03", "link": "http://arxiv.org/abs/2103.09519v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Few-Shot Fact-Checking via Perplexity", "abstract": "Few-shot learning has drawn researchers' attention to overcome the problem of\ndata scarcity. Recently, large pre-trained language models have shown great\nperformance in few-shot learning for various downstream tasks, such as question\nanswering and machine translation. Nevertheless, little exploration has been\nmade to achieve few-shot learning for the fact-checking task. However,\nfact-checking is an important problem, especially when the amount of\ninformation online is growing exponentially every day. In this paper, we\npropose a new way of utilizing the powerful transfer learning ability of a\nlanguage model via a perplexity score. The most notable strength of our\nmethodology lies in its capability in few-shot learning. With only two training\nsamples, our methodology can already outperform the Major Class baseline by\nmore than absolute 10% on the F1-Macro metric across multiple datasets. Through\nexperiments, we empirically verify the plausibility of the rather surprising\nusage of the perplexity score in the context of fact-checking and highlight the\nstrength of our few-shot methodology by comparing it to strong\nfine-tuning-based baseline models. Moreover, we construct and publicly release\ntwo new fact-checking datasets related to COVID-19.", "published": "2021-03-17 09:43:19", "link": "http://arxiv.org/abs/2103.09535v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Generation of Contrast Sets from Scene Graphs: Probing the\n  Compositional Consistency of GQA", "abstract": "Recent works have shown that supervised models often exploit data artifacts\nto achieve good test scores while their performance severely degrades on\nsamples outside their training distribution. Contrast sets (Gardneret al.,\n2020) quantify this phenomenon by perturbing test samples in a minimal way such\nthat the output label is modified. While most contrast sets were created\nmanually, requiring intensive annotation effort, we present a novel method\nwhich leverages rich semantic input representation to automatically generate\ncontrast sets for the visual question answering task. Our method computes the\nanswer of perturbed questions, thus vastly reducing annotation cost and\nenabling thorough evaluation of models' performance on various semantic aspects\n(e.g., spatial or relational reasoning). We demonstrate the effectiveness of\nour approach on the GQA dataset and its semantic scene graph image\nrepresentation. We find that, despite GQA's compositionality and carefully\nbalanced label distribution, two high-performing models drop 13-17% in accuracy\ncompared to the original test set. Finally, we show that our automatic\nperturbation can be applied to the training set to mitigate the degradation in\nperformance, opening the door to more robust models.", "published": "2021-03-17 12:19:25", "link": "http://arxiv.org/abs/2103.09591v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Code Word Detection in Fraud Investigations using a Deep-Learning\n  Approach", "abstract": "In modern litigation, fraud investigators often face an overwhelming number\nof documents that must be reviewed throughout a matter. In the majority of\nlegal cases, fraud investigators do not know beforehand, exactly what they are\nlooking for, nor where to find it. In addition, fraudsters may use deception to\nhide their behaviour and intentions by using code words. Effectively, this\nmeans fraud investigators are looking for a needle in the haystack without\nknowing what the needle looks like.\n  As part of a larger research program, we use a framework to expedite the\ninvestigation process applying text-mining and machine learning techniques. We\nstructure this framework using three well-known methods in fraud\ninvestigations: (i) the fraud triangle (ii) the golden (\"W\") investigation\nquestions, and (iii) the analysis of competing hypotheses. With this framework,\nit is possible to automatically organize investigative data, so it is easier\nfor investigators to find answers to typical investigative questions.\n  In this research, we focus on one of the components of this framework: the\nidentification of the usage of code words by fraudsters. Here for, a novel\n(annotated) synthetic data set is created containing such code words, hidden in\nnormal email communication. Subsequently, a range of machine learning\ntechniques are employed to detect such code words. We show that the\nstate-of-the-art BERT model significantly outperforms other methods on this\ntask. With this result, we demonstrate that deep neural language models can\nreliably (F1 score of 0.9) be applied in fraud investigations for the detection\nof code words.", "published": "2021-03-17 12:49:55", "link": "http://arxiv.org/abs/2103.09606v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SILT: Efficient transformer training for inter-lingual inference", "abstract": "The ability of transformers to perform precision tasks such as question\nanswering, Natural Language Inference (NLI) or summarising, have enabled them\nto be ranked as one of the best paradigm to address Natural Language Processing\n(NLP) tasks. NLI is one of the best scenarios to test these architectures, due\nto the knowledge required to understand complex sentences and established\nrelationships between a hypothesis and a premise. Nevertheless, these models\nsuffer from incapacity to generalise to other domains or difficulties to face\nmultilingual and interlingual scenarios. The leading pathway in the literature\nto address these issues involve designing and training extremely large\narchitectures, which leads to unpredictable behaviours and to establish\nbarriers which impede broad access and fine tuning. In this paper, we propose a\nnew architecture called Siamese Inter-Lingual Transformer (SILT), to\nefficiently align multilingual embeddings for Natural Language Inference,\nallowing for unmatched language pairs to be processed. SILT leverages siamese\npre-trained multi-lingual transformers with frozen weights where the two input\nsentences attend each other to later be combined through a matrix alignment\nmethod. The experimental results carried out in this paper evidence that SILT\nallows to reduce drastically the number of trainable parameters while allowing\nfor inter-lingual NLI and achieving state-of-the-art performance on common\nbenchmarks.\n  We make our code and dataset available at\nhttps://github.com/jahuerta92/siamese-inter-lingual-transformer.", "published": "2021-03-17 13:23:53", "link": "http://arxiv.org/abs/2103.09635v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Value-aware Approximate Attention", "abstract": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. However, all approximations thus far have\nignored the contribution of the $\\textit{value vectors}$ to the quality of\napproximation. In this work, we argue that research efforts should be directed\ntowards approximating the true output of the attention sub-layer, which\nincludes the value vectors. We propose a value-aware objective, and show\ntheoretically and empirically that an optimal approximation of a value-aware\nobjective substantially outperforms an optimal approximation that ignores\nvalues, in the context of language modeling. Moreover, we show that the choice\nof kernel function for computing attention similarity can substantially affect\nthe quality of sparse approximations, where kernel functions that are less\nskewed are more affected by the value vectors.", "published": "2021-03-17 18:43:34", "link": "http://arxiv.org/abs/2103.09857v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "STYLER: Style Factor Modeling with Rapidity and Robustness via Speech\n  Decomposition for Expressive and Controllable Neural Text to Speech", "abstract": "Previous works on neural text-to-speech (TTS) have been addressed on limited\nspeed in training and inference time, robustness for difficult synthesis\nconditions, expressiveness, and controllability. Although several approaches\nresolve some limitations, there has been no attempt to solve all weaknesses at\nonce. In this paper, we propose STYLER, an expressive and controllable TTS\nframework with high-speed and robust synthesis. Our novel audio-text aligning\nmethod called Mel Calibrator and excluding autoregressive decoding enable rapid\ntraining and inference and robust synthesis on unseen data. Also, disentangled\nstyle factor modeling under supervision enlarges the controllability in\nsynthesizing process leading to expressive TTS. On top of it, a novel noise\nmodeling pipeline using domain adversarial training and Residual Decoding\nempowers noise-robust style transfer, decomposing the noise without any\nadditional label. Various experiments demonstrate that STYLER is more effective\nin speed and robustness than expressive TTS with autoregressive decoding and\nmore expressive and controllable than reading style non-autoregressive TTS.\nSynthesis samples and experiment results are provided via our demo page, and\ncode is available publicly.", "published": "2021-03-17 07:11:09", "link": "http://arxiv.org/abs/2103.09474v4", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs", "abstract": "Code completion has become an essential component of integrated development\nenvironments. Contemporary code completion methods rely on the abstract syntax\ntree (AST) to generate syntactically correct code. However, they cannot fully\ncapture the sequential and repetitive patterns of writing code and the\nstructural information of the AST. To alleviate these problems, we propose a\nnew code completion approach named CCAG, which models the flattened sequence of\na partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Block\nto capture different dependencies in the AST graph for representation learning\nin code completion. The sub-tasks of code completion are optimized via\nmulti-task learning in CCAG, and the task balance is automatically achieved\nusing uncertainty without the need to tune task weights. The experimental\nresults show that CCAG has superior performance than state-of-the-art\napproaches and it is able to provide intelligent code completion.", "published": "2021-03-17 08:11:09", "link": "http://arxiv.org/abs/2103.09499v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "ENCONTER: Entity Constrained Progressive Sequence Generation via\n  Insertion-based Transformer", "abstract": "Pretrained using large amount of data, autoregressive language models are\nable to generate high quality sequences. However, these models do not perform\nwell under hard lexical constraints as they lack fine control of content\ngeneration process. Progressive insertion-based transformers can overcome the\nabove limitation and efficiently generate a sequence in parallel given some\ninput tokens as constraint. These transformers however may fail to support hard\nlexical constraints as their generation process is more likely to terminate\nprematurely. The paper analyses such early termination problems and proposes\nthe Entity-constrained insertion transformer (ENCONTER), a new insertion\ntransformer that addresses the above pitfall without compromising much\ngeneration efficiency. We introduce a new training strategy that considers\npredefined hard lexical constraints (e.g., entities to be included in the\ngenerated sequence). Our experiments show that ENCONTER outperforms other\nbaseline models in several performance metrics rendering it more suitable in\npractical applications. Our code is available at\nhttps://github.com/LARC-CMU-SMU/Enconter", "published": "2021-03-17 10:24:10", "link": "http://arxiv.org/abs/2103.09548v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "On the Role of Images for Analyzing Claims in Social Media", "abstract": "Fake news is a severe problem in social media. In this paper, we present an\nempirical study on visual, textual, and multimodal models for the tasks of\nclaim, claim check-worthiness, and conspiracy detection, all of which are\nrelated to fake news detection. Recent work suggests that images are more\ninfluential than text and often appear alongside fake text. To this end,\nseveral multimodal models have been proposed in recent years that use images\nalong with text to detect fake news on social media sites like Twitter.\nHowever, the role of images is not well understood for claim detection,\nspecifically using transformer-based textual and multimodal models. We\ninvestigate state-of-the-art models for images, text (Transformer-based), and\nmultimodal information for four different datasets across two languages to\nunderstand the role of images in the task of claim and conspiracy detection.", "published": "2021-03-17 12:40:27", "link": "http://arxiv.org/abs/2103.09602v1", "categories": ["cs.SI", "cs.CL", "cs.CV"], "primary_category": "cs.SI"}
{"title": "Advancing RNN Transducer Technology for Speech Recognition", "abstract": "We investigate a set of techniques for RNN Transducers (RNN-Ts) that were\ninstrumental in lowering the word error rate on three different tasks\n(Switchboard 300 hours, conversational Spanish 780 hours and conversational\nItalian 900 hours). The techniques pertain to architectural changes, speaker\nadaptation, language model fusion, model combination and general training\nrecipe. First, we introduce a novel multiplicative integration of the encoder\nand prediction network vectors in the joint network (as opposed to additive).\nSecond, we discuss the applicability of i-vector speaker adaptation to RNN-Ts\nin conjunction with data perturbation. Third, we explore the effectiveness of\nthe recently proposed density ratio language model fusion for these tasks. Last\nbut not least, we describe the other components of our training recipe and\ntheir effect on recognition performance. We report a 5.9% and 12.5% word error\nrate on the Switchboard and CallHome test sets of the NIST Hub5 2000 evaluation\nand a 12.7% WER on the Mozilla CommonVoice Italian test set.", "published": "2021-03-17 22:19:11", "link": "http://arxiv.org/abs/2103.09935v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots", "abstract": "Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.", "published": "2021-03-17 12:20:53", "link": "http://arxiv.org/abs/2103.09593v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Improving Zero-shot Voice Style Transfer via Disentangled Representation\n  Learning", "abstract": "Voice style transfer, also called voice conversion, seeks to modify one\nspeaker's voice to generate speech as if it came from another (target) speaker.\nPrevious works have made progress on voice conversion with parallel training\ndata and pre-known speakers. However, zero-shot voice style transfer, which\nlearns from non-parallel data and generates voices for previously unseen\nspeakers, remains a challenging problem. We propose a novel zero-shot voice\ntransfer method via disentangled representation learning. The proposed method\nfirst encodes speaker-related style and voice content of each input voice into\nseparated low-dimensional embedding spaces, and then transfers to a new voice\nby combining the source content embedding and target style embedding through a\ndecoder. With information-theoretic guidance, the style and content embedding\nspaces are representative and (ideally) independent of each other. On\nreal-world VCTK datasets, our method outperforms other baselines and obtains\nstate-of-the-art results in terms of transfer accuracy and voice naturalness\nfor voice style transfer experiments under both many-to-many and zero-shot\nsetups.", "published": "2021-03-17 03:21:32", "link": "http://arxiv.org/abs/2103.09420v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Contrastive Learning of Musical Representations", "abstract": "While deep learning has enabled great advances in many areas of music,\nlabeled music datasets remain especially hard, expensive, and time-consuming to\ncreate. In this work, we introduce SimCLR to the music domain and contribute a\nlarge chain of audio data augmentations to form a simple framework for\nself-supervised, contrastive learning of musical representations: CLMR. This\napproach works on raw time-domain music data and requires no labels to learn\nuseful representations. We evaluate CLMR in the downstream task of music\nclassification on the MagnaTagATune and Million Song datasets and present an\nablation study to test which of our music-related innovations over SimCLR are\nmost effective. A linear classifier trained on the proposed representations\nachieves a higher average precision than supervised models on the MagnaTagATune\ndataset, and performs comparably on the Million Song dataset. Moreover, we show\nthat CLMR's representations are transferable using out-of-domain datasets,\nindicating that our method has strong generalisability in music classification.\nLastly, we show that the proposed method allows data-efficient learning on\nsmaller labeled datasets: we achieve an average precision of 33.1% despite\nusing only 259 labeled songs in the MagnaTagATune dataset (1% of the full\ndataset) during linear evaluation. To foster reproducibility and future\nresearch on self-supervised learning in music, we publicly release the\npre-trained models and the source code of all experiments of this paper.", "published": "2021-03-17 02:53:55", "link": "http://arxiv.org/abs/2103.09410v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Self-Supervised Learning of Audio Representations from Permutations with\n  Differentiable Ranking", "abstract": "Self-supervised pre-training using so-called \"pretext\" tasks has recently\nshown impressive performance across a wide range of modalities. In this work,\nwe advance self-supervised learning from permutations, by pre-training a model\nto reorder shuffled parts of the spectrogram of an audio signal, to improve\ndownstream classification performance. We make two main contributions. First,\nwe overcome the main challenges of integrating permutation inversions into an\nend-to-end training scheme, using recent advances in differentiable ranking.\nThis was heretofore sidestepped by casting the reordering task as\nclassification, fundamentally reducing the space of permutations that can be\nexploited. Our experiments validate that learning from all possible\npermutations improves the quality of the pre-trained representations over using\na limited, fixed set. Second, we show that inverting permutations is a\nmeaningful pretext task for learning audio representations in an unsupervised\nfashion. In particular, we improve instrument classification and pitch\nestimation of musical notes by reordering spectrogram patches in the\ntime-frequency space.", "published": "2021-03-17 19:36:04", "link": "http://arxiv.org/abs/2103.09879v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
