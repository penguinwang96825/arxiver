{"title": "Know More about Each Other: Evolving Dialogue Strategy via Compound\n  Assessment", "abstract": "In this paper, a novel Generation-Evaluation framework is developed for\nmulti-turn conversations with the objective of letting both participants know\nmore about each other. For the sake of rational knowledge utilization and\ncoherent conversation flow, a dialogue strategy which controls knowledge\nselection is instantiated and continuously adapted via reinforcement learning.\nUnder the deployed strategy, knowledge grounded conversations are conducted\nwith two dialogue agents. The generated dialogues are comprehensively evaluated\non aspects like informativeness and coherence, which are aligned with our\nobjective and human instinct. These assessments are integrated as a compound\nreward to guide the evolution of dialogue strategy via policy gradient.\nComprehensive experiments have been carried out on the publicly available\ndataset, demonstrating that the proposed method outperforms the other\nstate-of-the-art approaches significantly.", "published": "2019-06-03 03:45:15", "link": "http://arxiv.org/abs/1906.00549v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global Textual Relation Embedding for Relational Understanding", "abstract": "Pre-trained embeddings such as word embeddings and sentence embeddings are\nfundamental tools facilitating a wide range of downstream NLP tasks. In this\nwork, we investigate how to learn a general-purpose embedding of textual\nrelations, defined as the shortest dependency path between entities. Textual\nrelation embedding provides a level of knowledge between word/phrase level and\nsentence level, and we show that it can facilitate downstream tasks requiring\nrelational understanding of the text. To learn such an embedding, we create the\nlargest distant supervision dataset by linking the entire English ClueWeb09\ncorpus to Freebase. We use global co-occurrence statistics between textual and\nknowledge base relations as the supervision signal to train the embedding.\nEvaluation on two relational understanding tasks demonstrates the usefulness of\nthe learned textual relation embedding. The data and code can be found at\nhttps://github.com/czyssrs/GloREPlus", "published": "2019-06-03 03:47:37", "link": "http://arxiv.org/abs/1906.00550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fluent Translations from Disfluent Speech in End-to-End Speech\n  Translation", "abstract": "Spoken language translation applications for speech suffer due to\nconversational speech phenomena, particularly the presence of disfluencies.\nWith the rise of end-to-end speech translation models, processing steps such as\ndisfluency removal that were previously an intermediate step between speech\nrecognition and machine translation need to be incorporated into model\narchitectures. We use a sequence-to-sequence model to translate from noisy,\ndisfluent speech to fluent text with disfluencies removed using the recently\ncollected `copy-edited' references for the Fisher Spanish-English dataset. We\nare able to directly generate fluent translations and introduce considerations\nabout how to evaluate success on this task. This work provides a baseline for a\nnew task, the translation of conversational speech with joint removal of\ndisfluencies.", "published": "2019-06-03 03:57:11", "link": "http://arxiv.org/abs/1906.00556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Paraphrase Generation with a Syntactic Exemplar", "abstract": "Prior work on controllable text generation usually assumes that the\ncontrolled attribute can take on one of a small set of values known a priori.\nIn this work, we propose a novel task, where the syntax of a generated sentence\nis controlled rather by a sentential exemplar. To evaluate quantitatively with\nstandard metrics, we create a novel dataset with human annotations. We also\ndevelop a variational model with a neural module specifically designed for\ncapturing syntactic knowledge and several multitask training objectives to\npromote disentangled representation learning. Empirically, the proposed model\nis observed to achieve improvements over baselines and learn to capture\ndesirable characteristics.", "published": "2019-06-03 04:29:22", "link": "http://arxiv.org/abs/1906.00565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jointly Learning Semantic Parser and Natural Language Generator via Dual\n  Information Maximization", "abstract": "Semantic parsing aims to transform natural language (NL) utterances into\nformal meaning representations (MRs), whereas an NL generator achieves the\nreverse: producing a NL description for some given MRs. Despite this intrinsic\nconnection, the two tasks are often studied separately in prior work. In this\npaper, we model the duality of these two tasks via a joint learning framework,\nand demonstrate its effectiveness of boosting the performance on both tasks.\nConcretely, we propose a novel method of dual information maximization (DIM) to\nregularize the learning process, where DIM empirically maximizes the\nvariational lower bounds of expected joint distributions of NL and MRs. We\nfurther extend DIM to a semi-supervision setup (SemiDIM), which leverages\nunlabeled data of both tasks. Experiments on three datasets of dialogue\nmanagement and code generation (and summarization) show that performance on\nboth semantic parsing and NL generation can be consistently improved by DIM, in\nboth supervised and semi-supervised setups.", "published": "2019-06-03 05:00:09", "link": "http://arxiv.org/abs/1906.00575v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Semi-Supervised Approach for Low-Resourced Text Generation", "abstract": "Recently, encoder-decoder neural models have achieved great success on text\ngeneration tasks. However, one problem of this kind of models is that their\nperformances are usually limited by the scale of well-labeled data, which are\nvery expensive to get. The low-resource (of labeled data) problem is quite\ncommon in different task generation tasks, but unlabeled data are usually\nabundant. In this paper, we propose a method to make use of the unlabeled data\nto improve the performance of such models in the low-resourced circumstances.\nWe use denoising auto-encoder (DAE) and language model (LM) based reinforcement\nlearning (RL) to enhance the training of encoder and decoder with unlabeled\ndata. Our method shows adaptability for different text generation tasks, and\nmakes significant improvements over basic text generation models.", "published": "2019-06-03 05:42:33", "link": "http://arxiv.org/abs/1906.00584v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Gender Bias in Machine Translation", "abstract": "We present the first challenge set and evaluation protocol for the analysis\nof gender bias in machine translation (MT). Our approach uses two recent\ncoreference resolution datasets composed of English sentences which cast\nparticipants into non-stereotypical gender roles (e.g., \"The doctor asked the\nnurse to help her in the operation\"). We devise an automatic gender bias\nevaluation method for eight target languages with grammatical gender, based on\nmorphological analysis (e.g., the use of female inflection for the word\n\"doctor\"). Our analyses show that four popular industrial MT systems and two\nrecent state-of-the-art academic MT models are significantly prone to\ngender-biased translation errors for all tested target languages. Our data and\ncode are made publicly available.", "published": "2019-06-03 06:21:38", "link": "http://arxiv.org/abs/1906.00591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically Constrained Multilayer Annotation: The Case of Coreference", "abstract": "We propose a coreference annotation scheme as a layer on top of the Universal\nConceptual Cognitive Annotation foundational layer, treating units in\npredicate-argument structure as a basis for entity and event mentions. We argue\nthat this allows coreference annotators to sidestep some of the challenges\nfaced in other schemes, which do not enforce consistency with\npredicate-argument structure and vary widely in what kinds of mentions they\nannotate and how. The proposed approach is examined with a pilot annotation\nstudy and compared with annotations from other schemes.", "published": "2019-06-03 09:39:33", "link": "http://arxiv.org/abs/1906.00663v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-task Pairwise Neural Ranking for Hashtag Segmentation", "abstract": "Hashtags are often employed on social media and beyond to add metadata to a\ntextual utterance with the goal of increasing discoverability, aiding search,\nor providing additional semantics. However, the semantic content of hashtags is\nnot straightforward to infer as these represent ad-hoc conventions which\nfrequently include multiple words joined together and can include abbreviations\nand unorthodox spellings. We build a dataset of 12,594 hashtags split into\nindividual segments and propose a set of approaches for hashtag segmentation by\nframing it as a pairwise ranking problem between candidate segmentations. Our\nnovel neural approaches demonstrate 24.6% error reduction in hashtag\nsegmentation accuracy compared to the current state-of-the-art method. Finally,\nwe demonstrate that a deeper understanding of hashtag semantics obtained\nthrough segmentation is useful for downstream applications such as sentiment\nanalysis, for which we achieved a 2.6% increase in average recall on the\nSemEval 2017 sentiment analysis dataset.", "published": "2019-06-03 13:28:33", "link": "http://arxiv.org/abs/1906.00790v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by\n  Evidence Pooling", "abstract": "This paper presents a strong set of results for resolving gendered ambiguous\npronouns on the Gendered Ambiguous Pronouns shared task. The model presented\nhere draws upon the strengths of state-of-the-art language and coreference\nresolution models, and introduces a novel evidence-based deep learning\narchitecture. Injecting evidence from the coreference models compliments the\nbase architecture, and analysis shows that the model is not hindered by their\nweaknesses, specifically gender bias. The modularity and simplicity of the\narchitecture make it very easy to extend for further improvement and applicable\nto other NLP problems. Evaluation on GAP test data results in a\nstate-of-the-art performance at 92.5% F1 (gender bias of 0.97), edging closer\nto the human performance of 96.6%. The end-to-end solution presented here\nplaced 1st in the Kaggle competition, winning by a significant lead. The code\nis available at https://github.com/sattree/gap.", "published": "2019-06-03 14:37:57", "link": "http://arxiv.org/abs/1906.00839v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A computational linguistic study of personal recovery in bipolar\n  disorder", "abstract": "Mental health research can benefit increasingly fruitfully from computational\nlinguistics methods, given the abundant availability of language data in the\ninternet and advances of computational tools. This interdisciplinary project\nwill collect and analyse social media data of individuals diagnosed with\nbipolar disorder with regard to their recovery experiences. Personal recovery -\nliving a satisfying and contributing life along symptoms of severe mental\nhealth issues - so far has only been investigated qualitatively with structured\ninterviews and quantitatively with standardised questionnaires with mainly\nEnglish-speaking participants in Western countries. Complementary to this\nevidence, computational linguistic methods allow us to analyse first-person\naccounts shared online in large quantities, representing unstructured settings\nand a more heterogeneous, multilingual population, to draw a more complete\npicture of the aspects and mechanisms of personal recovery in bipolar disorder.", "published": "2019-06-03 18:17:09", "link": "http://arxiv.org/abs/1906.01010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Character Language Modeling Through Morphology", "abstract": "We incorporate morphological supervision into character language models\n(CLMs) via multitasking and show that this addition improves bits-per-character\n(BPC) performance across 24 languages, even when the morphology data and\nlanguage modeling data are disjoint. Analyzing the CLMs shows that inflected\nwords benefit more from explicitly modeling morphology than uninflected words,\nand that morphological supervision improves performance even as the amount of\nlanguage modeling data grows. We then transfer morphological supervision across\nlanguages to improve language modeling performance in the low-resource setting.", "published": "2019-06-03 19:30:51", "link": "http://arxiv.org/abs/1906.01037v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Complex Sentences into a Semantic Hierarchy", "abstract": "We present an approach for recursively splitting and rephrasing complex\nEnglish sentences into a novel semantic hierarchy of simplified sentences, with\neach of them presenting a more regular structure that may facilitate a wide\nvariety of artificial intelligence tasks, such as machine translation (MT) or\ninformation extraction (IE). Using a set of hand-crafted transformation rules,\ninput sentences are recursively transformed into a two-layered hierarchical\nrepresentation in the form of core sentences and accompanying contexts that are\nlinked via rhetorical relations. In this way, the semantic relationship of the\ndecomposed constituents is preserved in the output, maintaining its\ninterpretability for downstream applications. Both a thorough manual analysis\nand automatic evaluation across three datasets from two different domains\ndemonstrate that the proposed syntactic simplification approach outperforms the\nstate of the art in structural text simplification. Moreover, an extrinsic\nevaluation shows that when applying our framework as a preprocessing step the\nperformance of state-of-the-art Open IE systems can be improved by up to 346%\nin precision and 52% in recall. To enable reproducible research, all code is\nprovided online.", "published": "2019-06-03 19:33:13", "link": "http://arxiv.org/abs/1906.01038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Handling Divergent Reference Texts when Evaluating Table-to-Text\n  Generation", "abstract": "Automatically constructed datasets for generating text from semi-structured\ndata (tables), such as WikiBio, often contain reference texts that diverge from\nthe information in the corresponding semi-structured data. We show that metrics\nwhich rely solely on the reference texts, such as BLEU and ROUGE, show poor\ncorrelation with human judgments when those references diverge. We propose a\nnew metric, PARENT, which aligns n-grams from the reference and generated texts\nto the semi-structured data before computing their precision and recall.\nThrough a large scale human evaluation study of table-to-text models for\nWikiBio, we show that PARENT correlates with human judgments better than\nexisting text generation metrics. We also adapt and evaluate the information\nextraction based evaluation proposed by Wiseman et al (2017), and show that\nPARENT has comparable correlation to it, while being easier to use. We show\nthat PARENT is also applicable when the reference texts are elicited from\nhumans using the data from the WebNLG challenge.", "published": "2019-06-03 21:13:07", "link": "http://arxiv.org/abs/1906.01081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Embedding via Stroke and Glyph Information: A Dual-channel View", "abstract": "Recent studies have consistently given positive hints that morphology is\nhelpful in enriching word embeddings. In this paper, we argue that Chinese word\nembeddings can be substantially enriched by the morphological information\nhidden in characters which is reflected not only in strokes order sequentially,\nbut also in character glyphs spatially. Then, we propose a novel Dual-channel\nWord Embedding (DWE) model to realize the joint learning of sequential and\nspatial information of characters. Through the evaluation on both word\nsimilarity and word analogy tasks, our model shows its rationality and\nsuperiority in modelling the morphology of Chinese.", "published": "2019-06-03 13:47:40", "link": "http://arxiv.org/abs/1906.04287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Question Relevant Captions to Aid Visual Question Answering", "abstract": "Visual question answering (VQA) and image captioning require a shared body of\ngeneral knowledge connecting language and vision. We present a novel approach\nto improve VQA performance that exploits this connection by jointly generating\ncaptions that are targeted to help answer a specific visual question. The model\nis trained using an existing caption dataset by automatically determining\nquestion-relevant captions using an online gradient-based method. Experimental\nresults on the VQA v2 challenge demonstrates that our approach obtains\nstate-of-the-art VQA performance (e.g. 68.4% on the Test-standard set using a\nsingle model) by simultaneously generating question-relevant captions.", "published": "2019-06-03 00:42:08", "link": "http://arxiv.org/abs/1906.00513v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Sentiment Tagging with Partial Labels using Modular Architectures", "abstract": "Many NLP learning tasks can be decomposed into several distinct sub-tasks,\neach associated with a partial label. In this paper we focus on a popular class\nof learning problems, sequence prediction applied to several sentiment analysis\ntasks, and suggest a modular learning approach in which different sub-tasks are\nlearned using separate functional modules, combined to perform the final task\nwhile sharing information. Our experiments show this approach helps constrain\nthe learning process and can alleviate some of the supervision efforts.", "published": "2019-06-03 02:33:01", "link": "http://arxiv.org/abs/1906.00534v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing the Ability of Self-Attention Networks to Learn Word Order", "abstract": "Self-attention networks (SAN) have attracted a lot of interests due to their\nhigh parallelization and strong performance on a variety of NLP tasks, e.g.\nmachine translation. Due to the lack of recurrence structure such as recurrent\nneural networks (RNN), SAN is ascribed to be weak at learning positional\ninformation of words for sequence modeling. However, neither this speculation\nhas been empirically confirmed, nor explanations for their strong performances\non machine translation tasks when \"lacking positional information\" have been\nexplored. To this end, we propose a novel word reordering detection task to\nquantify how well the word order information learned by SAN and RNN.\nSpecifically, we randomly move one word to another position, and examine\nwhether a trained model can detect both the original and inserted positions.\nExperimental results reveal that: 1) SAN trained on word reordering detection\nindeed has difficulty learning the positional information even with the\nposition embedding; and 2) SAN trained on machine translation learns better\npositional information than its RNN counterpart, in which position embedding\nplays a critical role. Although recurrence structure make the model more\nuniversally-effective on learning word order, learning objectives matter more\nin the downstream tasks such as machine translation.", "published": "2019-06-03 06:32:29", "link": "http://arxiv.org/abs/1906.00592v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Federated Hierarchical Hybrid Networks for Clickbait Detection", "abstract": "Online media outlets adopt clickbait techniques to lure readers to click on\narticles in a bid to expand their reach and subsequently increase revenue\nthrough ad monetization. As the adverse effects of clickbait attract more and\nmore attention, researchers have started to explore machine learning techniques\nto automatically detect clickbaits. Previous work on clickbait detection\nassumes that all the training data is available locally during training. In\nmany real-world applications, however, training data is generally distributedly\nstored by different parties (e.g., different parties maintain data with\ndifferent feature spaces), and the parties cannot share their data with each\nother due to data privacy issues. It is challenging to build models of\nhigh-quality federally for detecting clickbaits effectively without data\nsharing. In this paper, we propose a federated training framework, which is\ncalled federated hierarchical hybrid networks, to build clickbait detection\nmodels, where the titles and contents are stored by different parties, whose\nrelationships must be exploited for clickbait detection. We empirically\ndemonstrate that our approach is effective by comparing our approach to the\nstate-of-the-art approaches using datasets from social media.", "published": "2019-06-03 08:50:04", "link": "http://arxiv.org/abs/1906.00638v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Contextually Propagated Term Weights for Document Representation", "abstract": "Word embeddings predict a word from its neighbours by learning small, dense\nembedding vectors. In practice, this prediction corresponds to a semantic score\ngiven to the predicted word (or term weight). We present a novel model that,\ngiven a target word, redistributes part of that word's weight (that has been\ncomputed with word embeddings) across words occurring in similar contexts as\nthe target word. Thus, our model aims to simulate how semantic meaning is\nshared by words occurring in similar contexts, which is incorporated into\nbag-of-words document representations. Experimental evaluation in an\nunsupervised setting against 8 state of the art baselines shows that our model\nyields the best micro and macro F1 scores across datasets of increasing\ndifficulty.", "published": "2019-06-03 09:52:47", "link": "http://arxiv.org/abs/1906.00674v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Gender-preserving Debiasing for Pre-trained Word Embeddings", "abstract": "Word embeddings learnt from massive text collections have demonstrated\nsignificant levels of discriminative biases such as gender, racial or ethnic\nbiases, which in turn bias the down-stream NLP applications that use those word\nembeddings. Taking gender-bias as a working example, we propose a debiasing\nmethod that preserves non-discriminative gender-related information, while\nremoving stereotypical discriminative gender biases from pre-trained word\nembeddings. Specifically, we consider four types of information:\n\\emph{feminine}, \\emph{masculine}, \\emph{gender-neutral} and\n\\emph{stereotypical}, which represent the relationship between gender vs. bias,\nand propose a debiasing method that (a) preserves the gender-related\ninformation in feminine and masculine words, (b) preserves the neutrality in\ngender-neutral words, and (c) removes the biases from stereotypical words.\nExperimental results on several previously proposed benchmark datasets show\nthat our proposed method can debias pre-trained word embeddings better than\nexisting SoTA methods proposed for debiasing word embeddings while preserving\ngender-related but non-discriminative information.", "published": "2019-06-03 12:26:25", "link": "http://arxiv.org/abs/1906.00742v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Decision Making by Generating and Following Natural\n  Language Instructions", "abstract": "We explore using latent natural language instructions as an expressive and\ncompositional representation of complex actions for hierarchical decision\nmaking. Rather than directly selecting micro-actions, our agent first generates\na latent plan in natural language, which is then executed by a separate model.\nWe introduce a challenging real-time strategy game environment in which the\nactions of a large number of units must be coordinated across long time scales.\nWe gather a dataset of 76 thousand pairs of instructions and executions from\nhuman play, and train instructor and executor models. Experiments show that\nmodels using natural language as a latent variable significantly outperform\nmodels that directly imitate human actions. The compositional structure of\nlanguage proves crucial to its effectiveness for action representation. We also\nrelease our code, models and data.", "published": "2019-06-03 12:28:50", "link": "http://arxiv.org/abs/1906.00744v5", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Dynamically Composing Domain-Data Selection with Clean-Data Selection by\n  \"Co-Curricular Learning\" for Neural Machine Translation", "abstract": "Noise and domain are important aspects of data quality for neural machine\ntranslation. Existing research focus separately on domain-data selection,\nclean-data selection, or their static combination, leaving the dynamic\ninteraction across them not explicitly examined. This paper introduces a\n\"co-curricular learning\" method to compose dynamic domain-data selection with\ndynamic clean-data selection, for transfer learning across both capabilities.\nWe apply an EM-style optimization procedure to further refine the\n\"co-curriculum\". Experiment results and analysis with two domains demonstrate\nthe effectiveness of the method and the properties of data scheduled by the\nco-curriculum.", "published": "2019-06-03 23:47:43", "link": "http://arxiv.org/abs/1906.01130v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Listening while Speaking and Visualizing: Improving ASR through\n  Multimodal Chain", "abstract": "Previously, a machine speech chain, which is based on sequence-to-sequence\ndeep learning, was proposed to mimic speech perception and production behavior.\nSuch chains separately processed listening and speaking by automatic speech\nrecognition (ASR) and text-to-speech synthesis (TTS) and simultaneously enabled\nthem to teach each other in semi-supervised learning when they received\nunpaired data. Unfortunately, this speech chain study is limited to speech and\ntextual modalities. In fact, natural communication is actually multimodal and\ninvolves both auditory and visual sensory systems. Although the said speech\nchain reduces the requirement of having a full amount of paired data, in this\ncase we still need a large amount of unpaired data. In this research, we take a\nfurther step and construct a multimodal chain and design a closely knit chain\narchitecture that combines ASR, TTS, image captioning, and image production\nmodels into a single framework. The framework allows the training of each\ncomponent without requiring a large number of parallel multimodal data. Our\nexperimental results also show that an ASR can be further trained without\nspeech and text data and cross-modal data augmentation remains possible through\nour proposed chain, which improves the ASR performance.", "published": "2019-06-03 05:25:42", "link": "http://arxiv.org/abs/1906.00579v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Massive Styles Transfer with Limited Labeled Data", "abstract": "Language style transfer has attracted more and more attention in the past few\nyears. Recent researches focus on improving neural models targeting at\ntransferring from one style to the other with labeled data. However,\ntransferring across multiple styles is often very useful in real-life\napplications. Previous researches of language style transfer have two main\ndeficiencies: dependency on massive labeled data and neglect of mutual\ninfluence among different style transfer tasks. In this paper, we propose a\nmulti-agent style transfer system (MAST) for addressing multiple style transfer\ntasks with limited labeled data, by leveraging abundant unlabeled data and the\nmutual benefit among the multiple styles. A style transfer agent in our system\nnot only learns from unlabeled data by using techniques like denoising\nauto-encoder and back-translation, but also learns to cooperate with other\nstyle transfer agents in a self-organization manner. We conduct our experiments\nby simulating a set of real-world style transfer tasks with multiple versions\nof the Bible. Our model significantly outperforms the other competitive\nmethods. Extensive results and analysis further verify the efficacy of our\nproposed system.", "published": "2019-06-03 05:27:05", "link": "http://arxiv.org/abs/1906.00580v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Unsupervised Neural Generative Semantic Hashing", "abstract": "Fast similarity search is a key component in large-scale information\nretrieval, where semantic hashing has become a popular strategy for\nrepresenting documents as binary hash codes. Recent advances in this area have\nbeen obtained through neural network based models: generative models trained by\nlearning to reconstruct the original documents. We present a novel unsupervised\ngenerative semantic hashing approach, \\textit{Ranking based Semantic Hashing}\n(RBSH) that consists of both a variational and a ranking based component.\nSimilarly to variational autoencoders, the variational component is trained to\nreconstruct the original document conditioned on its generated hash code, and\nas in prior work, it only considers documents individually. The ranking\ncomponent solves this limitation by incorporating inter-document similarity\ninto the hash code generation, modelling document ranking through a hinge loss.\nTo circumvent the need for labelled data to compute the hinge loss, we use a\nweak labeller and thus keep the approach fully unsupervised.\n  Extensive experimental evaluation on four publicly available datasets against\ntraditional baselines and recent state-of-the-art methods for semantic hashing\nshows that RBSH significantly outperforms all other methods across all\nevaluated hash code lengths. In fact, RBSH hash codes are able to perform\nsimilarly to state-of-the-art hash codes while using 2-4x fewer bits.", "published": "2019-06-03 09:52:17", "link": "http://arxiv.org/abs/1906.00671v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic\n  Attention for Neural TTS", "abstract": "Neural TTS has demonstrated strong capabilities to generate human-like speech\nwith high quality and naturalness, while its generalization to out-of-domain\ntexts is still a challenging task, with regard to the design of attention-based\nsequence-to-sequence acoustic modeling. Various errors occur in those inputs\nwith unseen context, including attention collapse, skipping, repeating, etc.,\nwhich limits the broader applications. In this paper, we propose a novel\nstepwise monotonic attention method in sequence-to-sequence acoustic modeling\nto improve the robustness on out-of-domain inputs. The method utilizes the\nstrict monotonic property in TTS with constraints on monotonic hard attention\nthat the alignments between inputs and outputs sequence must be not only\nmonotonic but allowing no skipping on inputs. Soft attention could be used to\nevade mismatch between training and inference. The experimental results show\nthat the proposed method could achieve significant improvements in robustness\non out-of-domain scenarios for phoneme-based models, without any regression on\nthe in-domain naturalness test.", "published": "2019-06-03 09:52:19", "link": "http://arxiv.org/abs/1906.00672v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Relation Embedding with Dihedral Group in Knowledge Graph", "abstract": "Link prediction is critical for the application of incomplete knowledge graph\n(KG) in the downstream tasks. As a family of effective approaches for link\npredictions, embedding methods try to learn low-rank representations for both\nentities and relations such that the bilinear form defined therein is a\nwell-behaved scoring function. Despite of their successful performances,\nexisting bilinear forms overlook the modeling of relation compositions,\nresulting in lacks of interpretability for reasoning on KG. To fulfill this\ngap, we propose a new model called DihEdral, named after dihedral symmetry\ngroup. This new model learns knowledge graph embeddings that can capture\nrelation compositions by nature. Furthermore, our approach models the relation\nembeddings parametrized by discrete values, thereby decrease the solution space\ndrastically. Our experiments show that DihEdral is able to capture all desired\nproperties such as (skew-) symmetry, inversion and (non-) Abelian composition,\nand outperforms existing bilinear form based approach and is comparable to or\nbetter than deep learning models such as ConvE.", "published": "2019-06-03 10:13:32", "link": "http://arxiv.org/abs/1906.00687v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Network-based Object Classification by Known and Unknown Features\n  (Based on Text Queries)", "abstract": "The article presents a method that improves the quality of classification of\nobjects described by a combination of known and unknown features. The method is\nbased on modernized Informational Neurobayesian Approach with consideration of\nunknown features. The proposed method was developed and trained on 1500 text\nqueries of Promobot users in Russian to classify them into 20 categories\n(classes). As a result, the use of the method allowed to completely solve the\nproblem of misclassification for queries with combining known and unknown\nfeatures of the model. The theoretical substantiation of the method is\npresented by the formulated and proved theorem On the Model with Limited\nKnowledge. It states, that in conditions of limited data, an equal number of\nequally unknown features of an object cannot have different significance for\nthe classification problem.", "published": "2019-06-03 13:38:20", "link": "http://arxiv.org/abs/1906.00800v1", "categories": ["cs.LG", "cs.CL", "stat.ML", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "From Words to Sentences: A Progressive Learning Approach for\n  Zero-resource Machine Translation with Visual Pivots", "abstract": "The neural machine translation model has suffered from the lack of\nlarge-scale parallel corpora. In contrast, we humans can learn multi-lingual\ntranslations even without parallel texts by referring our languages to the\nexternal world. To mimic such human learning behavior, we employ images as\npivots to enable zero-resource translation learning. However, a picture tells a\nthousand words, which makes multi-lingual sentences pivoted by the same image\nnoisy as mutual translations and thus hinders the translation model learning.\nIn this work, we propose a progressive learning approach for image-pivoted\nzero-resource machine translation. Since words are less diverse when grounded\nin the image, we first learn word-level translation with image pivots, and then\nprogress to learn the sentence-level translation by utilizing the learned word\ntranslation to suppress noises in image-pivoted multi-lingual sentences.\nExperimental results on two widely used image-pivot translation datasets,\nIAPR-TC12 and Multi30k, show that the proposed approach significantly\noutperforms other state-of-the-art methods.", "published": "2019-06-03 15:28:48", "link": "http://arxiv.org/abs/1906.00872v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Phase-based Minimalist Parsing and complexity in non-local dependencies", "abstract": "A cognitively plausible parsing algorithm should perform like the human\nparser in critical contexts. Here I propose an adaptation of Earley's parsing\nalgorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that\nis able to predict complexity effects in performance. Focusing on self-paced\nreading experiments of object clefts sentences (Warren & Gibson 2005) I will\nassociate to parsing a complexity metric based on cued features to be retrieved\nat the verb segment (Feature Retrieval & Encoding Cost, FREC). FREC is\ncrucially based on the usage of memory predicted by the discussed parsing\nalgorithm and it correctly fits with the reading time revealed.", "published": "2019-06-03 16:20:04", "link": "http://arxiv.org/abs/1906.00908v2", "categories": ["cs.CL", "cs.AI", "cs.CC"], "primary_category": "cs.CL"}
{"title": "A Language-Agnostic Model for Semantic Source Code Labeling", "abstract": "Code search and comprehension have become more difficult in recent years due\nto the rapid expansion of available source code. Current tools lack a way to\nlabel arbitrary code at scale while maintaining up-to-date representations of\nnew programming languages, libraries, and functionalities. Comprehensive\nlabeling of source code enables users to search for documents of interest and\nobtain a high-level understanding of their contents. We use Stack Overflow code\nsnippets and their tags to train a language-agnostic, deep convolutional neural\nnetwork to automatically predict semantic labels for source code documents. On\nStack Overflow code snippets, we demonstrate a mean area under ROC of 0.957\nover a long-tailed list of 4,508 tags. We also manually validate the model\noutputs on a diverse set of unlabeled source code documents retrieved from\nGithub, and we obtain a top-1 accuracy of 86.6%. This strongly indicates that\nthe model successfully transfers its knowledge from Stack Overflow snippets to\narbitrary source code documents.", "published": "2019-06-03 19:21:42", "link": "http://arxiv.org/abs/1906.01032v1", "categories": ["cs.LG", "cs.CL", "cs.SE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Episodic Memory in Lifelong Language Learning", "abstract": "We introduce a lifelong language learning setup where a model needs to learn\nfrom a stream of text examples without any dataset identifier. We propose an\nepisodic memory model that performs sparse experience replay and local\nadaptation to mitigate catastrophic forgetting in this setup. Experiments on\ntext classification and question answering demonstrate the complementary\nbenefits of sparse experience replay and local adaptation to allow the model to\ncontinuously learn from new datasets. We also show that the space complexity of\nthe episodic memory module can be reduced significantly (~50-90%) by randomly\nchoosing which examples to store in memory with a minimal decrease in\nperformance. We consider an episodic memory component as a crucial building\nblock of general linguistic intelligence and see our model as a first step in\nthat direction.", "published": "2019-06-03 20:50:58", "link": "http://arxiv.org/abs/1906.01076v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Training Neural Machine Translation To Apply Terminology Constraints", "abstract": "This paper proposes a novel method to inject custom terminology into neural\nmachine translation at run time. Previous works have mainly proposed\nmodifications to the decoding algorithm in order to constrain the output to\ninclude run-time-provided target terms. While being effective, these\nconstrained decoding methods add, however, significant computational overhead\nto the inference step, and, as we show in this paper, can be brittle when\ntested in realistic conditions. In this paper we approach the problem by\ntraining a neural MT system to learn how to use custom terminology when\nprovided with the input. Comparative experiments show that our method is not\nonly more effective than a state-of-the-art implementation of constrained\ndecoding, but is also as fast as constraint-free decoding.", "published": "2019-06-03 22:33:22", "link": "http://arxiv.org/abs/1906.01105v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Resolving Gendered Ambiguous Pronouns with BERT", "abstract": "Pronoun resolution is part of coreference resolution, the task of pairing an\nexpression to its referring entity. This is an important task for natural\nlanguage understanding and a necessary component of machine translation\nsystems, chat bots and assistants. Neural machine learning systems perform far\nfrom ideally in this task, reaching as low as 73% F1 scores on modern benchmark\ndatasets. Moreover, they tend to perform better for masculine pronouns than for\nfeminine ones. Thus, the problem is both challenging and important for NLP\nresearchers and practitioners. In this project, we describe our BERT-based\napproach to solving the problem of gender-balanced pronoun resolution. We are\nable to reach 92% F1 score and a much lower gender bias on the benchmark\ndataset shared by Google AI Language team.", "published": "2019-06-03 11:10:10", "link": "http://arxiv.org/abs/1906.01161v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "An Introduction to a New Text Classification and Visualization for\n  Natural Language Processing Using Topological Data Analysis", "abstract": "Topological Data Analysis (TDA) is a novel new and fast growing field of data\nscience providing a set of new topological and geometric tools to derive\nrelevant features out of complex high-dimensional data. In this paper we apply\ntwo of best methods in topological data analysis, \"Persistent Homology\" and\n\"Mapper\", in order to classify persian poems which has been composed by two of\nthe best Iranian poets namely \"Ferdowsi\" and \"Hafez\". This article has two main\nparts, in the first part we explain the mathematics behind these two methods\nwhich is easy to understand for general audience and in the second part we\ndescribe our models and the results of applying TDA tools to NLP.", "published": "2019-06-03 08:06:39", "link": "http://arxiv.org/abs/1906.01726v1", "categories": ["cs.CL", "cs.LG", "math.AT"], "primary_category": "cs.CL"}
{"title": "A Surprising Density of Illusionable Natural Speech", "abstract": "Recent work on adversarial examples has demonstrated that most natural inputs\ncan be perturbed to fool even state-of-the-art machine learning systems. But\ndoes this happen for humans as well? In this work, we investigate: what\nfraction of natural instances of speech can be turned into \"illusions\" which\neither alter humans' perception or result in different people having\nsignificantly different perceptions? We first consider the McGurk effect, the\nphenomenon by which adding a carefully chosen video clip to the audio channel\naffects the viewer's perception of what is said (McGurk and MacDonald, 1976).\nWe obtain empirical estimates that a significant fraction of both words and\nsentences occurring in natural speech have some susceptibility to this effect.\nWe also learn models for predicting McGurk illusionability. Finally we\ndemonstrate that the Yanny or Laurel auditory illusion (Pressnitzer et al.,\n2018) is not an isolated occurrence by generating several very different new\ninstances. We believe that the surprising density of illusionable natural\nspeech warrants further investigation, from the perspectives of both security\nand cognitive science. Supplementary videos are available at:\nhttps://www.youtube.com/playlist?list=PLaX7t1K-e_fF2iaenoKznCatm0RC37B_k.", "published": "2019-06-03 19:33:43", "link": "http://arxiv.org/abs/1906.01040v3", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "The Computational Structure of Unintentional Meaning", "abstract": "Speech-acts can have literal meaning as well as pragmatic meaning, but these\nboth involve consequences typically intended by a speaker. Speech-acts can also\nhave unintentional meaning, in which what is conveyed goes above and beyond\nwhat was intended. Here, we present a Bayesian analysis of how, to a listener,\nthe meaning of an utterance can significantly differ from a speaker's intended\nmeaning. Our model emphasizes how comprehending the intentional and\nunintentional meaning of speech-acts requires listeners to engage in\nsophisticated model-based perspective-taking and reasoning about the history of\nthe state of the world, each other's actions, and each other's observations. To\ntest our model, we have human participants make judgments about vignettes where\nspeakers make utterances that could be interpreted as intentional insults or\nunintentional faux pas. In elucidating the mechanics of speech-acts with\nunintentional meanings, our account provides insight into how communication\nboth functions and malfunctions.", "published": "2019-06-03 17:26:36", "link": "http://arxiv.org/abs/1906.01983v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with\n  SampleRNN", "abstract": "Text-to-speech (TTS) acoustic models map linguistic features into an acoustic\nrepresentation out of which an audible waveform is generated. The latest and\nmost natural TTS systems build a direct mapping between linguistic and waveform\ndomains, like SampleRNN. This way, possible signal naturalness losses are\navoided as intermediate acoustic representations are discarded. Another\nimportant dimension of study apart from naturalness is their adaptability to\ngenerate voice from new speakers that were unseen during training. In this\npaper we first propose the use of problem-agnostic speech embeddings in a\nmulti-speaker acoustic model for TTS based on SampleRNN. This way we feed the\nacoustic model with speaker acoustically dependent representations that enrich\nthe waveform generation more than discrete embeddings unrelated to these\nfactors. Our first results suggest that the proposed embeddings lead to better\nquality voices than those obtained with discrete embeddings. Furthermore, as we\ncan use any speech segment as an encoded representation during inference, the\nmodel is capable to generalize to new speaker identities without retraining the\nnetwork. We finally show that, with a small increase of speech duration in the\nembedding extractor, we dramatically reduce the spectral distortion to close\nthe gap towards the target identities.", "published": "2019-06-03 12:15:56", "link": "http://arxiv.org/abs/1906.00733v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MUSICNTWRK: data tools for music theory, analysis and composition", "abstract": "We present the API for MUSICNTWRK, a python library for pitch class set and\nrhythmic sequences classification and manipulation, the generation of networks\nin generalized music and sound spaces, deep learning algorithms for timbre\nrecognition, and the sonification of arbitrary data. The software is freely\navailable under GPL 3.0 and can be downloaded at www.musicntwrk.com or\ninstalled as a PyPi project (pip install musicntwrk).", "published": "2019-06-03 06:58:20", "link": "http://arxiv.org/abs/1906.01453v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluating Non-aligned Musical Score Transcriptions with MV2H", "abstract": "The original MV2H metric was designed to evaluate systems which transcribe\nfrom an input audio (or MIDI) piece to a complete musical score. However, it\nrequires both the transcribed score and the ground truth score to be\ntime-aligned with the input. Some recent work has begun to transcribe directly\nfrom an audio signal into a musical score, skipping the alignment step. This\npaper introduces an automatic alignment method based on dynamic time warp which\nallows for MV2H to be used to evaluate such non-aligned transcriptions. This\nhas the additional benefit of allowing non-aligned musical scores---which are\nsignificantly more widely available than aligned ones---to be used as ground\ntruth. The code for the improved MV2H, which now also includes a MusicXML\nparser, and allows for key and time signature changes, is available at\nwww.github.com/apmcleod/MV2H.", "published": "2019-06-03 04:30:04", "link": "http://arxiv.org/abs/1906.00566v2", "categories": ["eess.AS", "cs.IR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Continual Learning of New Sound Classes using Generative Replay", "abstract": "Continual learning consists in incrementally training a model on a sequence\nof datasets and testing on the union of all datasets. In this paper, we examine\ncontinual learning for the problem of sound classification, in which we wish to\nrefine already trained models to learn new sound classes. In practice one does\nnot want to maintain all past training data and retrain from scratch, but\nnaively updating a model with new data(sets) results in a degradation of\nalready learned tasks, which is referred to as \"catastrophic forgetting.\" We\ndevelop a generative replay procedure for generating training audio spectrogram\ndata, in place of keeping older training datasets. We show that by\nincrementally refining a classifier with generative replay a generator that is\n4% of the size of all previous training data matches the performance of\nrefining the classifier keeping 20% of all previous training data. We thus\nconclude that we can extend a trained sound classifier to learn new classes\nwithout having to keep previously used datasets.", "published": "2019-06-03 09:20:18", "link": "http://arxiv.org/abs/1906.00654v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Blow: a single-scale hyperconditioned flow for non-parallel raw-audio\n  voice conversion", "abstract": "End-to-end models for raw audio generation are a challenge, specially if they\nhave to work with non-parallel data, which is a desirable setup in many\nsituations. Voice conversion, in which a model has to impersonate a speaker in\na recording, is one of those situations. In this paper, we propose Blow, a\nsingle-scale normalizing flow using hypernetwork conditioning to perform\nmany-to-many voice conversion between raw audio. Blow is trained end-to-end,\nwith non-parallel data, on a frame-by-frame basis using a single speaker\nidentifier. We show that Blow compares favorably to existing flow-based\narchitectures and other competitive baselines, obtaining equal or better\nperformance in both objective and subjective evaluations. We further assess the\nimpact of its main components with an ablation study, and quantify a number of\nproperties such as the necessary amount of training data or the preference for\nsource or target speakers.", "published": "2019-06-03 13:33:36", "link": "http://arxiv.org/abs/1906.00794v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Voice Mimicry Attacks Assisted by Automatic Speaker Verification", "abstract": "In this work, we simulate a scenario, where a publicly available ASV system\nis used to enhance mimicry attacks against another closed source ASV system. In\nspecific, ASV technology is used to perform a similarity search between the\nvoices of recruited attackers (6) and potential target speakers (7,365) from\nVoxCeleb corpora to find the closest targets for each of the attackers. In\naddition, we consider 'median', 'furthest', and 'common' targets to serve as a\nreference points. Our goal is to gain insights how well similarity rankings\ntransfer from the attacker's ASV system to the attacked ASV system, whether the\nattackers are able to improve their attacks by mimicking, and how the\nproperties of the voices of attackers change due to mimicking. We address these\nquestions through ASV experiments, listening tests, and prosodic and formant\nanalyses. For the ASV experiments, we use i-vector technology in the attacker\nside, and x-vectors in the attacked side. For the listening tests, we recruit\nlisteners through crowdsourcing. The results of the ASV experiments indicate\nthat the speaker similarity scores transfer well from one ASV system to\nanother. Both the ASV experiments and the listening tests reveal that the\nmimicry attempts do not, in general, help in bringing attacker's scores closer\nto the target's. A detailed analysis shows that mimicking does not improve\nattacks, when the natural voices of attackers and targets are similar to each\nother. The analysis of prosody and formants suggests that the attackers were\nable to considerably change their speaking rates when mimicking, but the\nchanges in F0 and formants were modest. Overall, the results suggest that\nuntrained impersonators do not pose a high threat towards ASV systems, but the\nuse of ASV systems to attack other ASV systems is a potential threat.", "published": "2019-06-03 11:06:54", "link": "http://arxiv.org/abs/1906.01454v2", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
