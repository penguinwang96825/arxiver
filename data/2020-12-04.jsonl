{"title": "Few-Shot Event Detection with Prototypical Amortized Conditional Random\n  Field", "abstract": "Event detection tends to struggle when it needs to recognize novel event\ntypes with a few samples. The previous work attempts to solve this problem in\nthe identify-then-classify manner but ignores the trigger discrepancy between\nevent types, thus suffering from the error propagation. In this paper, we\npresent a novel unified model which converts the task to a few-shot tagging\nproblem with a double-part tagging scheme. To this end, we first propose the\nPrototypical Amortized Conditional Random Field (PA-CRF) to model the label\ndependency in the few-shot scenario, which approximates the transition scores\nbetween labels based on the label prototypes. Then Gaussian distribution is\nintroduced for modeling of the transition scores to alleviate the uncertain\nestimation resulting from insufficient data. Experimental results show that the\nunified models work better than existing identify-then-classify models and our\nPA-CRF further achieves the best results on the benchmark dataset FewEvent. Our\ncode and data are available at http://github.com/congxin95/PA-CRF.", "published": "2020-12-04 01:11:13", "link": "http://arxiv.org/abs/2012.02353v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning BERT for Low-Resource Natural Language Understanding via\n  Active Learning", "abstract": "Recently, leveraging pre-trained Transformer based language models in down\nstream, task specific models has advanced state of the art results in natural\nlanguage understanding tasks. However, only a little research has explored the\nsuitability of this approach in low resource settings with less than 1,000\ntraining data points. In this work, we explore fine-tuning methods of BERT -- a\npre-trained Transformer based language model -- by utilizing pool-based active\nlearning to speed up training while keeping the cost of labeling new data\nconstant. Our experimental results on the GLUE data set show an advantage in\nmodel performance by maximizing the approximate knowledge gain of the model\nwhen querying from the pool of unlabeled data. Finally, we demonstrate and\nanalyze the benefits of freezing layers of the language model during\nfine-tuning to reduce the number of trainable parameters, making it more\nsuitable for low-resource settings.", "published": "2020-12-04 08:34:39", "link": "http://arxiv.org/abs/2012.02462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Processing and Annotation Schemes for FinCausal Shared Task", "abstract": "This document explains the annotation schemes used to label the data for the\nFinCausal Shared Task (Mariko et al., 2020). This task is associated to the\nJoint Workshop on Financial Narrative Processing and MultiLing Financial\nSummarisation (FNP-FNS 2020), to be held at The 28th International Conference\non Computational Linguistics (COLING'2020), on December 12, 2020.", "published": "2020-12-04 09:58:47", "link": "http://arxiv.org/abs/2012.02498v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUED_speech at TREC 2020 Podcast Summarisation Track", "abstract": "In this paper, we describe our approach for the Podcast Summarisation\nchallenge in TREC 2020. Given a podcast episode with its transcription, the\ngoal is to generate a summary that captures the most important information in\nthe content. Our approach consists of two steps: (1) Filtering redundant or\nless informative sentences in the transcription using the attention of a\nhierarchical model; (2) Applying a state-of-the-art text summarisation system\n(BART) fine-tuned on the Podcast data using a sequence-level reward function.\nFurthermore, we perform ensembles of three and nine models for our submission\nruns. We also fine-tune the BART model on the Podcast data as our baseline. The\nhuman evaluation by NIST shows that our best submission achieves 1.777 in the\nEGFB scale, while the score of creator-provided description is 1.291. Our\nsystem won the Spotify Podcast Summarisation Challenge in the TREC2020 Podcast\nTrack in both human and automatic evaluation.", "published": "2020-12-04 11:32:55", "link": "http://arxiv.org/abs/2012.02535v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic\n  Dialogues", "abstract": "Interpersonal language style shifting in dialogues is an interesting and\nalmost instinctive ability of human. Understanding interpersonal relationship\nfrom language content is also a crucial step toward further understanding\ndialogues. Previous work mainly focuses on relation extraction between named\nentities in texts. In this paper, we propose the task of relation\nclassification of interlocutors based on their dialogues. We crawled movie\nscripts from IMSDb, and annotated the relation labels for each session\naccording to 13 pre-defined relationships. The annotated dataset DDRel consists\nof 6300 dyadic dialogue sessions between 694 pair of speakers with 53,126\nutterances in total. We also construct session-level and pair-level relation\nclassification tasks with widely-accepted baselines. The experimental results\nshow that this task is challenging for existing models and the dataset will be\nuseful for future research.", "published": "2020-12-04 12:30:31", "link": "http://arxiv.org/abs/2012.02553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Detection of Cyberbullying Against Women and Immigrants and\n  Cross-domain Adaptability", "abstract": "Cyberbullying is a prevalent and growing social problem due to the surge of\nsocial media technology usage. Minorities, women, and adolescents are among the\ncommon victims of cyberbullying. Despite the advancement of NLP technologies,\nthe automated cyberbullying detection remains challenging. This paper focuses\non advancing the technology using state-of-the-art NLP techniques. We use a\nTwitter dataset from SemEval 2019 - Task 5(HatEval) on hate speech against\nwomen and immigrants. Our best performing ensemble model based on DistilBERT\nhas achieved 0.73 and 0.74 of F1 score in the task of classifying hate speech\n(Task A) and aggressiveness and target (Task B) respectively. We adapt the\nensemble model developed for Task A to classify offensive language in external\ndatasets and achieved ~0.7 of F1 score using three benchmark datasets, enabling\npromising results for cross-domain adaptability. We conduct a qualitative\nanalysis of misclassified tweets to provide insightful recommendations for\nfuture cyberbullying research.", "published": "2020-12-04 13:12:31", "link": "http://arxiv.org/abs/2012.02565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ve'rdd. Narrowing the Gap between Paper Dictionaries, Low-Resource NLP\n  and Community Involvement", "abstract": "We present an open-source online dictionary editing system, Ve'rdd, that\noffers a chance to re-evaluate and edit grassroots dictionaries that have been\nexposed to multiple amateur editors. The idea is to incorporate community\nactivities into a state-of-the-art finite-state language description of a\nseriously endangered minority language, Skolt Sami. Problems involve getting\nthe community to take part in things above the pencil-and-paper level. At\ntimes, it seems that the native speakers and the dictionary oriented are\nlacking technical understanding to utilize the infrastructures which might make\ntheir work more meaningful in the future, i.e. multiple reuse of all of their\ninput. Therefore, our system integrates with the existing tools and\ninfrastructures for Uralic language masking the technical complexities behind a\nuser-friendly UI.", "published": "2020-12-04 13:36:29", "link": "http://arxiv.org/abs/2012.02578v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation", "abstract": "Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.", "published": "2020-12-04 14:17:46", "link": "http://arxiv.org/abs/2012.02613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Guided Denoising for Multilingual Relation Learning", "abstract": "General purpose relation extraction has recently seen considerable gains in\npart due to a massively data-intensive distant supervision technique from\nSoares et al. (2019) that produces state-of-the-art results across many\nbenchmarks. In this work, we present a methodology for collecting high quality\ntraining data for relation extraction from unlabeled text that achieves a\nnear-recreation of their zero-shot and few-shot results at a fraction of the\ntraining cost. Our approach exploits the predictable distributional structure\nof date-marked news articles to build a denoised corpus -- the extraction\nprocess filters out low quality examples. We show that a smaller multilingual\nencoder trained on this corpus performs comparably to the current\nstate-of-the-art (when both receive little to no fine-tuning) on few-shot and\nstandard relation benchmarks in English and Spanish despite using many fewer\nexamples (50k vs. 300mil+).", "published": "2020-12-04 17:11:04", "link": "http://arxiv.org/abs/2012.02721v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On-Device Sentence Similarity for SMS Dataset", "abstract": "Determining the sentence similarity between Short Message Service (SMS)\ntexts/sentences plays a significant role in mobile device industry. Gauging the\nsimilarity between SMS data is thus necessary for various applications like\nenhanced searching and navigation, clubbing together SMS of similar type when\ngiven a custom label or tag is provided by user irrespective of their sender\netc. The problem faced with SMS data is its incomplete structure and\ngrammatical inconsistencies. In this paper, we propose a unique pipeline for\nevaluating the text similarity between SMS texts. We use Part of Speech (POS)\nmodel for keyword extraction by taking advantage of the partial structure\nembedded in SMS texts and similarity comparisons are carried out using\nstatistical methods. The proposed pipeline deals with major semantic variations\nacross SMS data as well as makes it effective for its application on-device\n(mobile phone). To showcase the capabilities of our work, our pipeline has been\ndesigned with an inclination towards one of the possible applications of SMS\ntext similarity discussed in one of the following sections but nonetheless\nguarantees scalability for other applications as well.", "published": "2020-12-04 19:51:24", "link": "http://arxiv.org/abs/2012.02819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inductive Bias and Language Expressivity in Emergent Communication", "abstract": "Referential games and reconstruction games are the most common game types for\nstudying emergent languages. We investigate how the type of the language game\naffects the emergent language in terms of: i) language compositionality and ii)\ntransfer of an emergent language to a task different from its origin, which we\nrefer to as language expressivity. With empirical experiments on a handcrafted\nsymbolic dataset, we show that languages emerged from different games have\ndifferent compositionality and further different expressivity.", "published": "2020-12-04 22:20:55", "link": "http://arxiv.org/abs/2012.02875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Guided Image Captioning Performance across Domains", "abstract": "Image captioning models generally lack the capability to take into account\nuser interest, and usually default to global descriptions that try to balance\nreadability, informativeness, and information overload. On the other hand, VQA\nmodels generally lack the ability to provide long descriptive answers, while\nexpecting the textual question to be quite precise. We present a method to\ncontrol the concepts that an image caption should focus on, using an additional\ninput called the guiding text that refers to either groundable or ungroundable\nconcepts in the image. Our model consists of a Transformer-based multimodal\nencoder that uses the guiding text together with global and object-level image\nfeatures to derive early-fusion representations used to generate the guided\ncaption. While models trained on Visual Genome data have an in-domain advantage\nof fitting well when guided with automatic object labels, we find that guided\ncaptioning models trained on Conceptual Captions generalize better on\nout-of-domain images and guiding texts. Our human-evaluation results indicate\nthat attempting in-the-wild guided image captioning requires access to large,\nunrestricted-domain training datasets, and that increased style diversity (even\nwithout increasing the number of unique tokens) is a key factor for improved\nperformance.", "published": "2020-12-04 00:05:02", "link": "http://arxiv.org/abs/2012.02339v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "WeaQA: Weak Supervision via Captions for Visual Question Answering", "abstract": "Methodologies for training visual question answering (VQA) models assume the\navailability of datasets with human-annotated \\textit{Image-Question-Answer}\n(I-Q-A) triplets. This has led to heavy reliance on datasets and a lack of\ngeneralization to new types of questions and scenes. Linguistic priors along\nwith biases and errors due to annotator subjectivity have been shown to\npercolate into VQA models trained on such samples. We study whether models can\nbe trained without any human-annotated Q-A pairs, but only with images and\ntheir associated textual descriptions or captions. We present a method to train\nmodels with synthetic Q-A pairs generated procedurally from captions.\nAdditionally, we demonstrate the efficacy of spatial-pyramid image patches as a\nsimple but effective alternative to dense and costly object bounding box\nannotations used in existing VQA models. Our experiments on three VQA\nbenchmarks demonstrate the efficacy of this weakly-supervised approach,\nespecially on the VQA-CP challenge, which tests performance under changing\nlinguistic priors.", "published": "2020-12-04 01:22:05", "link": "http://arxiv.org/abs/2012.02356v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Benchmarking Automated Clinical Language Simplification: Dataset,\n  Algorithm, and Evaluation", "abstract": "Patients with low health literacy usually have difficulty understanding\nmedical jargon and the complex structure of professional medical language.\nAlthough some studies are proposed to automatically translate expert language\ninto layperson-understandable language, only a few of them focus on both\naccuracy and readability aspects simultaneously in the clinical domain. Thus,\nsimplification of the clinical language is still a challenging task, but\nunfortunately, it is not yet fully addressed in previous work. To benchmark\nthis task, we construct a new dataset named MedLane to support the development\nand evaluation of automated clinical language simplification approaches.\nBesides, we propose a new model called DECLARE that follows the human\nannotation procedure and achieves state-of-the-art performance compared with\neight strong baselines. To fairly evaluate the performance, we also propose\nthree specific evaluation metrics. Experimental results demonstrate the utility\nof the annotated MedLane dataset and the effectiveness of the proposed model\nDECLARE.", "published": "2020-12-04 06:09:02", "link": "http://arxiv.org/abs/2012.02420v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Spread Mechanism and Influence Measurement of Online Rumors in China\n  During the COVID-19 Pandemic", "abstract": "In early 2020, the Corona Virus Disease 2019 (COVID-19) pandemic swept the\nworld.In China, COVID-19 has caused severe consequences. Moreover, online\nrumors during the COVID-19 pandemic increased people's panic about public\nhealth and social stability. At present, understanding and curbing the spread\nof online rumors is an urgent task. Therefore, we analyzed the rumor spreading\nmechanism and propose a method to quantify a rumors' influence by the speed of\nnew insiders. The search frequency of the rumor is used as an observation\nvariable of new insiders. The peak coefficient and the attenuation coefficient\nare calculated for the search frequency, which conforms to the exponential\ndistribution. We designed several rumor features and used the above two\ncoefficients as predictable labels. A 5-fold cross-validation experiment using\nthe mean square error (MSE) as the loss function showed that the decision tree\nwas suitable for predicting the peak coefficient, and the linear regression\nmodel was ideal for predicting the attenuation coefficient. Our feature\nanalysis showed that precursor features were the most important for the\noutbreak coefficient, while location information and rumor entity information\nwere the most important for the attenuation coefficient. Meanwhile, features\nthat were conducive to the outbreak were usually harmful to the continued\nspread of rumors. At the same time, anxiety was a crucial rumor causing factor.\nFinally, we discuss how to use deep learning technology to reduce the forecast\nloss by using the Bidirectional Encoder Representations from Transformers\n(BERT) model.", "published": "2020-12-04 07:55:15", "link": "http://arxiv.org/abs/2012.02446v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Financial Document Causality Detection Shared Task (FinCausal 2020)", "abstract": "We present the FinCausal 2020 Shared Task on Causality Detection in Financial\nDocuments and the associated FinCausal dataset, and discuss the participating\nsystems and results. Two sub-tasks are proposed: a binary classification task\n(Task 1) and a relation extraction task (Task 2). A total of 16 teams submitted\nruns across the two Tasks and 13 of them contributed with a system description\npaper. This workshop is associated to the Joint Workshop on Financial Narrative\nProcessing and MultiLing Financial Summarisation (FNP-FNS 2020), held at The\n28th International Conference on Computational Linguistics (COLING'2020),\nBarcelona, Spain on September 12, 2020.", "published": "2020-12-04 10:17:42", "link": "http://arxiv.org/abs/2012.02505v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Spatial Language Understanding for Object Search in Partially Observed\n  City-scale Environments", "abstract": "Humans use spatial language to naturally describe object locations and their\nrelations. Interpreting spatial language not only adds a perceptual modality\nfor robots, but also reduces the barrier of interfacing with humans. Previous\nwork primarily considers spatial language as goal specification for instruction\nfollowing tasks in fully observable domains, often paired with reference paths\nfor reward-based learning. However, spatial language is inherently subjective\nand potentially ambiguous or misleading. Hence, in this paper, we consider\nspatial language as a form of stochastic observation. We propose SLOOP (Spatial\nLanguage Object-Oriented POMDP), a new framework for partially observable\ndecision making with a probabilistic observation model for spatial language. We\napply SLOOP to object search in city-scale environments. To interpret\nambiguous, context-dependent prepositions (e.g. front), we design a simple\nconvolutional neural network that predicts the language provider's latent frame\nof reference (FoR) given the environment context. Search strategies are\ncomputed via an online POMDP planner based on Monte Carlo Tree Search.\nEvaluation based on crowdsourced language data, collected over areas of five\ncities in OpenStreetMap, shows that our approach achieves faster search and\nhigher success rate compared to baselines, with a wider margin as the spatial\nlanguage becomes more complex. Finally, we demonstrate the proposed method in\nAirSim, a realistic simulator where a drone is tasked to find cars in a\nneighborhood environment.", "published": "2020-12-04 16:27:59", "link": "http://arxiv.org/abs/2012.02705v3", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Playing Text-Based Games with Common Sense", "abstract": "Text based games are simulations in which an agent interacts with the world\npurely through natural language. They typically consist of a number of puzzles\ninterspersed with interactions with common everyday objects and locations. Deep\nreinforcement learning agents can learn to solve these puzzles. However, the\neveryday interactions with the environment, while trivial for human players,\npresent as additional puzzles to agents. We explore two techniques for\nincorporating commonsense knowledge into agents. Inferring possibly hidden\naspects of the world state with either a commonsense inference model COMET, or\na language model BERT. Biasing an agents exploration according to common\npatterns recognized by a language model. We test our technique in the 9to05\ngame, which is an extreme version of a text based game that requires numerous\ninteractions with common, everyday objects in common, everyday scenarios. We\nconclude that agents that augment their beliefs about the world state with\ncommonsense inferences are more robust to observational errors and omissions of\ncommon elements from text descriptions.", "published": "2020-12-04 18:22:59", "link": "http://arxiv.org/abs/2012.02757v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs", "abstract": "Multilabel conditional image generation is a challenging problem in computer\nvision. In this work we propose Multi-ingredient Pizza Generator (MPG), a\nconditional Generative Neural Network (GAN) framework for synthesizing\nmultilabel images. We design MPG based on a state-of-the-art GAN structure\ncalled StyleGAN2, in which we develop a new conditioning technique by enforcing\nintermediate feature maps to learn scalewise label information. Because of the\ncomplex nature of the multilabel image generation problem, we also regularize\nsynthetic image by predicting the corresponding ingredients as well as\nencourage the discriminator to distinguish between matched image and mismatched\nimage. To verify the efficacy of MPG, we test it on Pizza10, which is a\ncarefully annotated multi-ingredient pizza image dataset. MPG can successfully\ngenerate photo-realist pizza images with desired ingredients. The framework can\nbe easily extend to other multilabel image generation scenarios.", "published": "2020-12-04 19:51:31", "link": "http://arxiv.org/abs/2012.02821v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Data-Driven Regular Expressions Evolution for Medical Text\n  Classification Using Genetic Programming", "abstract": "In medical fields, text classification is one of the most important tasks\nthat can significantly reduce human workload through structured information\ndigitization and intelligent decision support. Despite the popularity of\nlearning-based text classification techniques, it is hard for human to\nunderstand or manually fine-tune the classification results for better\nprecision and recall, due to the black box nature of learning. This study\nproposes a novel regular expression-based text classification method making use\nof genetic programming (GP) approaches to evolve regular expressions that can\nclassify a given medical text inquiry with satisfactory precision and recall\nwhile allow human to read the classifier and fine-tune accordingly if\nnecessary. Given a seed population of regular expressions (can be randomly\ninitialized or manually constructed by experts), our method evolves a\npopulation of regular expressions according to chosen fitness function, using a\nnovel regular expression syntax and a series of carefully chosen reproduction\noperators. Our method is evaluated with real-life medical text inquiries from\nan online healthcare provider and shows promising performance. More\nimportantly, our method generates classifiers that can be fully understood,\nchecked and updated by medical doctors, which are fundamentally crucial for\nmedical related practices.", "published": "2020-12-04 03:44:46", "link": "http://arxiv.org/abs/2012.07515v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Modelling General Properties of Nouns by Selectively Averaging\n  Contextualised Embeddings", "abstract": "While the success of pre-trained language models has largely eliminated the\nneed for high-quality static word vectors in many NLP applications, such\nvectors continue to play an important role in tasks where words need to be\nmodelled in the absence of linguistic context. In this paper, we explore how\nthe contextualised embeddings predicted by BERT can be used to produce\nhigh-quality word vectors for such domains, in particular related to knowledge\nbase completion, where our focus is on capturing the semantic properties of\nnouns. We find that a simple strategy of averaging the contextualised\nembeddings of masked word mentions leads to vectors that outperform the static\nword vectors learned by BERT, as well as those from standard word embedding\nmodels, in property induction tasks. We notice in particular that masking\ntarget words is critical to achieve this strong performance, as the resulting\nvectors focus less on idiosyncratic properties and more on general semantic\nproperties. Inspired by this view, we propose a filtering strategy which is\naimed at removing the most idiosyncratic mention vectors, allowing us to obtain\nfurther performance gains in property induction.", "published": "2020-12-04 14:03:03", "link": "http://arxiv.org/abs/2012.07580v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Research Progress of News Recommendation Methods", "abstract": "Due to researchers'aim to study personalized recommendations for different\nbusiness fields, the summary of recommendation methods in specific fields is of\npractical significance. News recommendation systems were the earliest research\nfield regarding recommendation systems, and were also the earliest\nrecommendation field to apply the collaborative filtering method. In addition,\nnews is real-time and rich in content, which makes news recommendation methods\nmore challenging than in other fields. Thus, this paper summarizes the research\nprogress regarding news recommendation methods. From 2018 to 2020, developed\nnews recommendation methods were mainly deep learning-based, attention-based,\nand knowledge graphs-based. As of 2020, there are many news recommendation\nmethods that combine attention mechanisms and knowledge graphs. However, these\nmethods were all developed based on basic methods (the collaborative filtering\nmethod, the content-based recommendation method, and a mixed recommendation\nmethod combining the two). In order to allow researchers to have a detailed\nunderstanding of the development process of news recommendation methods, the\nnews recommendation methods surveyed in this paper, which cover nearly 10\nyears, are divided into three categories according to the abovementioned basic\nmethods. Firstly, the paper introduces the basic ideas of each category of\nmethods and then summarizes the recommendation methods that are combined with\nother methods based on each category of methods and according to the time\nsequence of research results. Finally, this paper also summarizes the\nchallenges confronting news recommendation systems.", "published": "2020-12-04 01:47:24", "link": "http://arxiv.org/abs/2012.02360v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Coarse-to-Fine Entity Representations for Document-level Relation\n  Extraction", "abstract": "Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.", "published": "2020-12-04 10:18:59", "link": "http://arxiv.org/abs/2012.02507v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pre-trained language models as knowledge bases for Automotive Complaint\n  Analysis", "abstract": "Recently it has been shown that large pre-trained language models like BERT\n(Devlin et al., 2018) are able to store commonsense factual knowledge captured\nin its pre-training corpus (Petroni et al., 2019). In our work we further\nevaluate this ability with respect to an application from industry creating a\nset of probes specifically designed to reveal technical quality issues captured\nas described incidents out of unstructured customer feedback in the automotive\nindustry. After probing the out-of-the-box versions of the pre-trained models\nwith fill-in-the-mask tasks we dynamically provide it with more knowledge via\ncontinual pre-training on the Office of Defects Investigation (ODI) Complaints\ndata set. In our experiments the models exhibit performance regarding queries\non domain-specific topics compared to when queried on factual knowledge itself,\nas Petroni et al. (2019) have done. For most of the evaluated architectures the\ncorrect token is predicted with a $Precision@1$ ($P@1$) of above 60\\%, while\nfor $P@5$ and $P@10$ even values of well above 80\\% and up to 90\\% respectively\nare reached. These results show the potential of using language models as a\nknowledge base for structured analysis of customer feedback.", "published": "2020-12-04 12:49:47", "link": "http://arxiv.org/abs/2012.02558v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Comparison of Natural Language Understanding Platforms for Chatbots in\n  Software Engineering", "abstract": "Chatbots are envisioned to dramatically change the future of Software\nEngineering, allowing practitioners to chat and inquire about their software\nprojects and interact with different services using natural language. At the\nheart of every chatbot is a Natural Language Understanding (NLU) component that\nenables the chatbot to understand natural language input. Recently, many NLU\nplatforms were provided to serve as an off-the-shelf NLU component for\nchatbots, however, selecting the best NLU for Software Engineering chatbots\nremains an open challenge.\n  Therefore, in this paper, we evaluate four of the most commonly used NLUs,\nnamely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on\nwhich NLU should be used in Software Engineering based chatbots. Specifically,\nwe examine the NLUs' performance in classifying intents, confidence scores\nstability, and extracting entities. To evaluate the NLUs, we use two datasets\nthat reflect two common tasks performed by Software Engineering practitioners,\n1) the task of chatting with the chatbot to ask questions about software\nrepositories 2) the task of asking development questions on Q&A forums (e.g.,\nStack Overflow). According to our findings, IBM Watson is the best performing\nNLU when considering the three aspects (intents classification, confidence\nscores, and entity extraction). However, the results from each individual\naspect show that, in intents classification, IBM Watson performs the best with\nan F1-measure > 84%, but in confidence scores, Rasa comes on top with a median\nconfidence score higher than 0.91. Our results also show that all NLUs, except\nfor Dialogflow, generally provide trustable confidence scores. For entity\nextraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE\ntasks. Our results provide guidance to software engineering practitioners when\ndeciding which NLU to use in their chatbots.", "published": "2020-12-04 14:59:08", "link": "http://arxiv.org/abs/2012.02640v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Delexicalized Paraphrase Generation", "abstract": "We present a neural model for paraphrasing and train it to generate\ndelexicalized sentences. We achieve this by creating training data in which\neach input is paired with a number of reference paraphrases. These sets of\nreference paraphrases represent a weak type of semantic equivalence based on\nannotated slots and intents. To understand semantics from different types of\nslots, other than anonymizing slots, we apply convolutional neural networks\n(CNN) prior to pooling on slot values and use pointers to locate slots in the\noutput. We show empirically that the generated paraphrases are of high quality,\nleading to an additional 1.29% exact match on live utterances. We also show\nthat natural language understanding (NLU) tasks, such as intent classification\nand named entity recognition, can benefit from data augmentation using\nautomatically generated paraphrases.", "published": "2020-12-04 18:28:30", "link": "http://arxiv.org/abs/2012.02763v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-Modal Generalization: Learning in Low Resource Modalities via\n  Meta-Alignment", "abstract": "The natural world is abundant with concepts expressed via visual, acoustic,\ntactile, and linguistic modalities. Much of the existing progress in multimodal\nlearning, however, focuses primarily on problems where the same set of\nmodalities are present at train and test time, which makes learning in\nlow-resource modalities particularly difficult. In this work, we propose\nalgorithms for cross-modal generalization: a learning paradigm to train a model\nthat can (1) quickly perform new tasks in a target modality (i.e.\nmeta-learning) and (2) doing so while being trained on a different source\nmodality. We study a key research question: how can we ensure generalization\nacross modalities despite using separate encoders for different source and\ntarget modalities? Our solution is based on meta-alignment, a novel method to\nalign representation spaces using strongly and weakly paired cross-modal data\nwhile ensuring quick generalization to new tasks across different modalities.\nWe study this problem on 3 classification tasks: text to image, image to audio,\nand text to speech. Our results demonstrate strong performance even when the\nnew target modality has only a few (1-10) labeled samples and in the presence\nof noisy labels, a scenario particularly prevalent in low-resource modalities.", "published": "2020-12-04 19:27:26", "link": "http://arxiv.org/abs/2012.02813v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Acoustic Hologram Optimisation Using Automatic Differentiation", "abstract": "Acoustic holograms are the keystone of modern acoustics. It encodes\nthree-dimensional acoustic fields in two dimensions, and its quality determine\nthe performance of acoustic systems. Optimisation methods that control only the\nphase of an acoustic wave are considered inferior to methods that control both\nthe amplitude and phase of the wave. In this paper, we present Diff-PAT, an\nacoustic hologram optimisation algorithm with automatic differentiation. We\ndemonstrate that our method achieves superior accuracy than conventional\nmethods. The performance of Diff-PAT was evaluated by randomly generating 1000\nsets of up to 32 control points for single-sided arrays and single-axis arrays.\nThe improved acoustic hologram can be used in wide range of applications of\nPATs without introducing any changes to existing systems that control the PATs.\nIn addition, we applied Diff-PAT to acoustic metamaterial and achieved an >8 dB\nincrease in the peak noise-to-signal ratio of acoustic hologram.", "published": "2020-12-04 06:52:22", "link": "http://arxiv.org/abs/2012.02431v1", "categories": ["cs.SD", "eess.AS", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Predicting Emotions Perceived from Sounds", "abstract": "Sonification is the science of communication of data and events to users\nthrough sounds. Auditory icons, earcons, and speech are the common auditory\ndisplay schemes utilized in sonification, or more specifically in the use of\naudio to convey information. Once the captured data are perceived, their\nmeanings, and more importantly, intentions can be interpreted more easily and\nthus can be employed as a complement to visualization techniques. Through\nauditory perception it is possible to convey information related to temporal,\nspatial, or some other context-oriented information. An important research\nquestion is whether the emotions perceived from these auditory icons or earcons\nare predictable in order to build an automated sonification platform. This\npaper conducts an experiment through which several mainstream and conventional\nmachine learning algorithms are developed to study the prediction of emotions\nperceived from sounds. To do so, the key features of sounds are captured and\nthen are modeled using machine learning algorithms using feature reduction\ntechniques. We observe that it is possible to predict perceived emotions with\nhigh accuracy. In particular, the regression based on Random Forest\ndemonstrated its superiority compared to other machine learning algorithms.", "published": "2020-12-04 15:01:59", "link": "http://arxiv.org/abs/2012.02643v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
