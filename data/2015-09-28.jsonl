{"title": "A Preliminary Study on the Learning Informativeness of Data Subsets", "abstract": "Estimating the internal state of a robotic system is complex: this is\nperformed from multiple heterogeneous sensor inputs and knowledge sources.\nDiscretization of such inputs is done to capture saliences, represented as\nsymbolic information, which often presents structure and recurrence. As these\nsequences are used to reason over complex scenarios, a more compact\nrepresentation would aid exactness of technical cognitive reasoning\ncapabilities, which are today constrained by computational complexity issues\nand fallback to representational heuristics or human intervention. Such\nproblems need to be addressed to ensure timely and meaningful human-robot\ninteraction. Our work is towards understanding the variability of learning\ninformativeness when training on subsets of a given input dataset. This is in\nview of reducing the training size while retaining the majority of the symbolic\nlearning potential. We prove the concept on human-written texts, and conjecture\nthis work will reduce training data size of sequential instructions, while\npreserving semantic relations, when gathering information from large remote\nsources.", "published": "2015-09-28 15:21:00", "link": "http://arxiv.org/abs/1510.04104v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
