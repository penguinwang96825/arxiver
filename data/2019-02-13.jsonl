{"title": "SECTOR: A Neural Model for Coherent Topic Segmentation and\n  Classification", "abstract": "When searching for information, a human reader first glances over a document,\nspots relevant sections and then focuses on a few sentences for resolving her\nintention. However, the high variance of document structure complicates to\nidentify the salient topic of a given section at a glance. To tackle this\nchallenge, we present SECTOR, a model to support machine reading systems by\nsegmenting documents into coherent sections and assigning topic labels to each\nsection. Our deep neural network architecture learns a latent topic embedding\nover the course of a document. This can be leveraged to classify local topics\nfrom plain text and segment a document at topic shifts. In addition, we\ncontribute WikiSection, a publicly available dataset with 242k labeled sections\nin English and German from two distinct domains: diseases and cities. From our\nextensive evaluation of 20 architectures, we report a highest score of 71.6% F1\nfor the segmentation and classification of 30 topics from the English city\ndomain, scored by our SECTOR LSTM model with bloom filter embeddings and\nbidirectional segmentation. This is a significant improvement of 29.5 points F1\ncompared to state-of-the-art CNN classifiers with baseline segmentation.", "published": "2019-02-13 09:00:16", "link": "http://arxiv.org/abs/1902.04793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Select Knowledge for Response Generation in Dialog Systems", "abstract": "End-to-end neural models for intelligent dialogue systems suffer from the\nproblem of generating uninformative responses. Various methods were proposed to\ngenerate more informative responses by leveraging external knowledge. However,\nfew previous work has focused on selecting appropriate knowledge in the\nlearning process. The inappropriate selection of knowledge could prohibit the\nmodel from learning to make full use of the knowledge. Motivated by this, we\npropose an end-to-end neural model which employs a novel knowledge selection\nmechanism where both prior and posterior distributions over knowledge are used\nto facilitate knowledge selection. Specifically, a posterior distribution over\nknowledge is inferred from both utterances and responses, and it ensures the\nappropriate selection of knowledge during the training process. Meanwhile, a\nprior distribution, which is inferred from utterances only, is used to\napproximate the posterior distribution so that appropriate knowledge can be\nselected even without responses during the inference process. Compared with the\nprevious work, our model can better incorporate appropriate knowledge in\nresponse generation. Experiments on both automatic and human evaluation verify\nthe superiority of our model over previous baselines.", "published": "2019-02-13 14:13:21", "link": "http://arxiv.org/abs/1902.04911v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Newswire Treebanks for Parsing Conversational Data with\n  Argument Scrambling", "abstract": "We investigate the problem of parsing conversational data of\nmorphologically-rich languages such as Hindi where argument scrambling occurs\nfrequently. We evaluate a state-of-the-art non-linear transition-based parsing\nsystem on a new dataset containing 506 dependency trees for sentences from\nBollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual\nspeakers. We show that a dependency parser trained on a newswire treebank is\nstrongly biased towards the canonical structures and degrades when applied to\nconversational data. Inspired by Transformational Generative Grammar, we\nmitigate the sampling bias by generating all theoretically possible alternative\nword orders of a clause from the existing (kernel) structures in the treebank.\nTraining our parser on canonical and transformed structures improves\nperformance on conversational data by around 9% LAS over the baseline newswire\nparser.", "published": "2019-02-13 19:01:51", "link": "http://arxiv.org/abs/1902.05085v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explainable Text-Driven Neural Network for Stock Prediction", "abstract": "It has been shown that financial news leads to the fluctuation of stock\nprices. However, previous work on news-driven financial market prediction\nfocused only on predicting stock price movement without providing an\nexplanation. In this paper, we propose a dual-layer attention-based neural\nnetwork to address this issue. In the initial stage, we introduce a\nknowledge-based method to adaptively extract relevant financial news. Then, we\nuse input attention to pay more attention to the more influential news and\nconcatenate the day embeddings with the output of the news representation.\nFinally, we use an output attention mechanism to allocate different weights to\ndifferent days in terms of their contribution to stock price movement. Thorough\nempirical studies based upon historical prices of several individual stocks\ndemonstrate the superiority of our proposed method in stock price prediction\ncompared to state-of-the-art methods.", "published": "2019-02-13 16:37:32", "link": "http://arxiv.org/abs/1902.04994v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sentence Compression via DC Programming Approach", "abstract": "Sentence compression is an important problem in natural language processing.\nIn this paper, we firstly establish a new sentence compression model based on\nthe probability model and the parse tree model. Our sentence compression model\nis equivalent to an integer linear program (ILP) which can both guarantee the\nsyntax correctness of the compression and save the main meaning. We propose\nusing a DC (Difference of convex) programming approach (DCA) for finding local\noptimal solution of our model. Combing DCA with a parallel-branch-and-bound\nframework, we can find global optimal solution. Numerical results demonstrate\nthe good quality of our sentence compression model and the excellent\nperformance of our proposed solution algorithm.", "published": "2019-02-13 05:43:00", "link": "http://arxiv.org/abs/1902.07248v1", "categories": ["cs.CL", "math.OC"], "primary_category": "cs.CL"}
{"title": "Optimization problems with low SWaP tactical Computing", "abstract": "In a resource-constrained, contested environment, computing resources need to\nbe aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware\ncomputational efficiency depends upon optimization of computational resources\nand intelligent time versus efficiency tradeoffs in decision making. In this\npaper we address the complexity of various optimization strategies related to\nlow SWaP computing. Due to these restrictions, only a small subset of less\ncomplicated and fast computable algorithms can be used for tactical, adaptive\ncomputing.", "published": "2019-02-13 11:17:43", "link": "http://arxiv.org/abs/1902.05070v1", "categories": ["cs.AI", "cs.CC", "cs.CL", "cs.NI"], "primary_category": "cs.AI"}
{"title": "Predicting US State-Level Agricultural Sentiment as a Measure of Food\n  Security with Tweets from Farming Communities", "abstract": "The ability to obtain accurate food security metrics in developing areas\nwhere relevant data can be sparse is critically important for policy makers\ntasked with implementing food aid programs. As a result, a great deal of work\nhas been dedicated to predicting important food security metrics such as annual\ncrop yields using a variety of methods including simulation, remote sensing,\nweather models, and human expert input. As a complement to existing techniques\nin crop yield prediction, this work develops neural network models for\npredicting the sentiment of Twitter feeds from farming communities.\nSpecifically, we investigate the potential of both direct learning on a small\ndataset of agriculturally-relevant tweets and transfer learning from larger,\nwell-labeled sentiment datasets from other domains (e.g.~politics) to\naccurately predict agricultural sentiment, which we hope would ultimately serve\nas a useful crop yield predictor. We find that direct learning from small,\nrelevant datasets outperforms transfer learning from large, fully-labeled\ndatasets, that convolutional neural networks broadly outperform recurrent\nneural networks on Twitter sentiment classification, and that these models\nperform substantially less well on ternary sentiment problems characteristic of\npractical settings than on binary problems often found in the literature.", "published": "2019-02-13 20:29:00", "link": "http://arxiv.org/abs/1902.07087v2", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Networks with Stochastic Layers for Acoustic Novelty\n  Detection", "abstract": "In this paper, we adapt Recurrent Neural Networks with Stochastic Layers,\nwhich are the state-of-the-art for generating text, music and speech, to the\nproblem of acoustic novelty detection. By integrating uncertainty into the\nhidden states, this type of network is able to learn the distribution of\ncomplex sequences. Because the learned distribution can be calculated\nexplicitly in terms of probability, we can evaluate how likely an observation\nis then detect low-probability events as novel. The model is robust, highly\nunsupervised, end-to-end and requires minimum preprocessing, feature\nengineering or hyperparameter tuning. An experiment on a benchmark dataset\nshows that our model outperforms the state-of-the-art acoustic novelty\ndetectors.", "published": "2019-02-13 16:13:52", "link": "http://arxiv.org/abs/1902.04980v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving performance and inference on audio classification tasks using\n  capsule networks", "abstract": "Classification of audio samples is an important part of many auditory\nsystems. Deep learning models based on the Convolutional and the Recurrent\nlayers are state-of-the-art in many such tasks. In this paper, we approach\naudio classification tasks using capsule networks trained by recently proposed\ndynamic routing-by-agreement mechanism. We propose an architecture for capsule\nnetworks fit for audio classification tasks and study the impact of various\nparameters on classification accuracy. Further, we suggest modifications for\nregularization and multi-label classification. We also develop insights into\nthe data using capsule outputs and show the utility of the learned network for\ntransfer learning. We perform experiments on 7 datasets of different domains\nand sizes and show significant improvements in performance compared to strong\nbaseline models. To the best of our knowledge, this is the first detailed study\nabout the application of capsule networks in the audio domain.", "published": "2019-02-13 08:36:19", "link": "http://arxiv.org/abs/1902.05069v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source\n  Localization", "abstract": "Inspired by the behavior of humans talking in noisy environments, we propose\nan embodied embedded cognition approach to improve automatic speech recognition\n(ASR) systems for robots in challenging environments, such as with ego noise,\nusing binaural sound source localization (SSL). The approach is verified by\nmeasuring the impact of SSL with a humanoid robot head on the performance of an\nASR system. More specifically, a robot orients itself toward the angle where\nthe signal-to-noise ratio (SNR) of speech is maximized for one microphone\nbefore doing an ASR task. First, a spiking neural network inspired by the\nmidbrain auditory system based on our previous work is applied to calculate the\nsound signal angle. Then, a feedforward neural network is used to handle high\nlevels of ego noise and reverberation in the signal. Finally, the sound signal\nis fed into an ASR system. For ASR, we use a system developed by our group and\ncompare its performance with and without the support from SSL. We test our SSL\nand ASR systems on two humanoid platforms with different structural and\nmaterial properties. With our approach we halve the sentence error rate with\nrespect to the common downmixing of both channels. Surprisingly, the ASR\nperformance is more than two times better when the angle between the humanoid\nhead and the sound source allows sound waves to be reflected most intensely\nfrom the pinna to the ear microphone, rather than when sound waves arrive\nperpendicularly to the membrane.", "published": "2019-02-13 14:09:11", "link": "http://arxiv.org/abs/1902.05446v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
