{"title": "Learning Numeral Embeddings", "abstract": "Word embedding is an essential building block for deep learning methods for\nnatural language processing. Although word embedding has been extensively\nstudied over the years, the problem of how to effectively embed numerals, a\nspecial subset of words, is still underexplored. Existing word embedding\nmethods do not learn numeral embeddings well because there are an infinite\nnumber of numerals and their individual appearances in training corpora are\nhighly scarce. In this paper, we propose two novel numeral embedding methods\nthat can handle the out-of-vocabulary (OOV) problem for numerals. We first\ninduce a finite set of prototype numerals using either a self-organizing map or\na Gaussian mixture model. We then represent the embedding of a numeral as a\nweighted average of the prototype number embeddings. Numeral embeddings\nrepresented in this manner can be plugged into existing word embedding learning\napproaches such as skip-gram for training. We evaluated our methods and showed\nits effectiveness on four intrinsic and extrinsic tasks: word similarity,\nembedding numeracy, numeral prediction, and sequence labeling.", "published": "2019-12-28 03:15:43", "link": "http://arxiv.org/abs/2001.00003v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-guided Text Structuring in Clinical Trials", "abstract": "Clinical trial records are variable resources or the analysis of patients and\ndiseases. Information extraction from free text such as eligibility criteria\nand summary of results and conclusions in clinical trials would better support\ncomputer-based eligibility query formulation and electronic patient screening.\nPrevious research has focused on extracting information from eligibility\ncriteria, with usually a single pair of medical entity and attribute, but\nseldom considering other kinds of free text with multiple entities, attributes\nand relations that are more complex for parsing. In this paper, we propose a\nknowledge-guided text structuring framework with an automatically generated\nknowledge base as training corpus and word dependency relations as context\ninformation to transfer free text into formal, computer-interpretable\nrepresentations. Experimental results show that our method can achieve overall\nhigh precision and recall, demonstrating the effectiveness and efficiency of\nthe proposed method.", "published": "2019-12-28 01:12:15", "link": "http://arxiv.org/abs/1912.12380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural language processing of MIMIC-III clinical notes for identifying\n  diagnosis and procedures with neural networks", "abstract": "Coding diagnosis and procedures in medical records is a crucial process in\nthe healthcare industry, which includes the creation of accurate billings,\nreceiving reimbursements from payers, and creating standardized patient care\nrecords. In the United States, Billing and Insurance related activities cost\naround $471 billion in 2012 which constitutes about 25% of all the U.S hospital\nspending. In this paper, we report the performance of a natural language\nprocessing model that can map clinical notes to medical codes, and predict\nfinal diagnosis from unstructured entries of history of present illness,\nsymptoms at the time of admission, etc. Previous studies have demonstrated that\ndeep learning models perform better at such mapping when compared to\nconventional machine learning models. Therefore, we employed state-of-the-art\ndeep learning method, ULMFiT on the largest emergency department clinical notes\ndataset MIMIC III which has 1.2M clinical notes to select for the top-10 and\ntop-50 diagnosis and procedure codes. Our models were able to predict the\ntop-10 diagnoses and procedures with 80.3% and 80.5% accuracy, whereas the\ntop-50 ICD-9 codes of diagnosis and procedures are predicted with 70.7% and\n63.9% accuracy. Prediction of diagnosis and procedures from unstructured\nclinical notes benefit human coders to save time, eliminate errors and minimize\ncosts. With promising scores from our present model, the next step would be to\ndeploy this on a small-scale real-world scenario and compare it with human\ncoders as the gold standard. We believe that further research of this approach\ncan create highly accurate predictions that can ease the workflow in a clinical\nsetting.", "published": "2019-12-28 04:05:15", "link": "http://arxiv.org/abs/1912.12397v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tha3aroon at NSURL-2019 Task 8: Semantic Question Similarity in Arabic", "abstract": "In this paper, we describe our team's effort on the semantic text question\nsimilarity task of NSURL 2019. Our top performing system utilizes several\ninnovative data augmentation techniques to enlarge the training data. Then, it\ntakes ELMo pre-trained contextual embeddings of the data and feeds them into an\nON-LSTM network with self-attention. This results in sequence representation\nvectors that are used to predict the relation between the question pairs. The\nmodel is ranked in the 1st place with 96.499 F1-score (same as the second place\nF1-score) and the 2nd place with 94.848 F1-score (differs by 1.076 F1-score\nfrom the first place) on the public and private leaderboards, respectively.", "published": "2019-12-28 20:11:33", "link": "http://arxiv.org/abs/1912.12514v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint Robust Voicing Detection and Pitch Estimation Based on Residual\n  Harmonics", "abstract": "This paper focuses on the problem of pitch tracking in noisy conditions. A\nmethod using harmonic information in the residual signal is presented. The\nproposed criterion is used both for pitch estimation, as well as for\ndetermining the voicing segments of speech. In the experiments, the method is\ncompared to six state-of-the-art pitch trackers on the Keele and CSTR\ndatabases. The proposed technique is shown to be particularly robust to\nadditive noise, leading to a significant improvement in adverse conditions.", "published": "2019-12-28 13:45:29", "link": "http://arxiv.org/abs/2001.00459v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detection of Glottal Closure Instants from Speech Signals: a\n  Quantitative Review", "abstract": "The pseudo-periodicity of voiced speech can be exploited in several speech\nprocessing applications. This requires however that the precise locations of\nthe Glottal Closure Instants (GCIs) are available. The focus of this paper is\nthe evaluation of automatic methods for the detection of GCIs directly from the\nspeech waveform. Five state-of-the-art GCI detection algorithms are compared\nusing six different databases with contemporaneous electroglottographic\nrecordings as ground truth, and containing many hours of speech by multiple\nspeakers. The five techniques compared are the Hilbert Envelope-based detection\n(HE), the Zero Frequency Resonator-based method (ZFR), the Dynamic Programming\nPhase Slope Algorithm (DYPSA), the Speech Event Detection using the Residual\nExcitation And a Mean-based Signal (SEDREAMS) and the Yet Another GCI Algorithm\n(YAGA). The efficacy of these methods is first evaluated on clean speech, both\nin terms of reliabililty and accuracy. Their robustness to additive noise and\nto reverberation is also assessed. A further contribution of the paper is the\nevaluation of their performance on a concrete application of speech processing:\nthe causal-anticausal decomposition of speech. It is shown that for clean\nspeech, SEDREAMS and YAGA are the best performing techniques, both in terms of\nidentification rate and accuracy. ZFR and SEDREAMS also show a superior\nrobustness to additive noise and reverberation.", "published": "2019-12-28 14:12:16", "link": "http://arxiv.org/abs/2001.00473v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comparative Study of Glottal Source Estimation Techniques", "abstract": "Source-tract decomposition (or glottal flow estimation) is one of the basic\nproblems of speech processing. For this, several techniques have been proposed\nin the literature. However studies comparing different approaches are almost\nnonexistent. Besides, experiments have been systematically performed either on\nsynthetic speech or on sustained vowels. In this study we compare three of the\nmain representative state-of-the-art methods of glottal flow estimation:\nclosed-phase inverse filtering, iterative and adaptive inverse filtering, and\nmixed-phase decomposition. These techniques are first submitted to an objective\nassessment test on synthetic speech signals. Their sensitivity to various\nfactors affecting the estimation quality, as well as their robustness to noise\nare studied. In a second experiment, their ability to label voice quality\n(tensed, modal, soft) is studied on a large corpus of real connected speech. It\nis shown that changes of voice quality are reflected by significant\nmodifications in glottal feature distributions. Techniques based on the\nmixed-phase decomposition and on a closed-phase inverse filtering process turn\nout to give the best results on both clean synthetic and real speech signals.\nOn the other hand, iterative and adaptive inverse filtering is recommended in\nnoisy environments for its high robustness.", "published": "2019-12-28 20:40:08", "link": "http://arxiv.org/abs/2001.00840v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Glottal Closure and Opening Instant Detection from Speech Signals", "abstract": "This paper proposes a new procedure to detect Glottal Closure and Opening\nInstants (GCIs and GOIs) directly from speech waveforms. The procedure is\ndivided into two successive steps. First a mean-based signal is computed, and\nintervals where speech events are expected to occur are extracted from it.\nSecondly, at each interval a precise position of the speech event is assigned\nby locating a discontinuity in the Linear Prediction residual. The proposed\nmethod is compared to the DYPSA algorithm on the CMU ARCTIC database. A\nsignificant improvement as well as a better noise robustness are reported.\nBesides, results of GOI identification accuracy are promising for the glottal\nsource characterization.", "published": "2019-12-28 19:27:45", "link": "http://arxiv.org/abs/2001.00841v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "All-in-One Image-Grounded Conversational Agents", "abstract": "As single-task accuracy on individual language and image tasks has improved\nsubstantially in the last few years, the long-term goal of a generally skilled\nagent that can both see and talk becomes more feasible to explore. In this\nwork, we focus on leveraging individual language and image tasks, along with\nresources that incorporate both vision and language towards that objective. We\ndesign an architecture that combines state-of-the-art Transformer and ResNeXt\nmodules fed into a novel attentive multimodal module to produce a combined\nmodel trained on many tasks. We provide a thorough analysis of the components\nof the model, and transfer performance when training on one, some, or all of\nthe tasks. Our final models provide a single system that obtains good results\non all vision and language tasks considered, and improves the state-of-the-art\nin image-grounded conversational applications.", "published": "2019-12-28 03:51:52", "link": "http://arxiv.org/abs/1912.12394v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextScanner: Reading Characters in Order for Robust Scene Text\n  Recognition", "abstract": "Driven by deep learning and the large volume of data, scene text recognition\nhas evolved rapidly in recent years. Formerly, RNN-attention based methods have\ndominated this field, but suffer from the problem of \\textit{attention drift}\nin certain situations. Lately, semantic segmentation based algorithms have\nproven effective at recognizing text of different forms (horizontal, oriented\nand curved). However, these methods may produce spurious characters or miss\ngenuine characters, as they rely heavily on a thresholding procedure operated\non segmentation maps. To tackle these challenges, we propose in this paper an\nalternative approach, called TextScanner, for scene text recognition.\nTextScanner bears three characteristics: (1) Basically, it belongs to the\nsemantic segmentation family, as it generates pixel-wise, multi-channel\nsegmentation maps for character class, position and order; (2) Meanwhile, akin\nto RNN-attention based methods, it also adopts RNN for context modeling; (3)\nMoreover, it performs paralleled prediction for character position and class,\nand ensures that characters are transcripted in correct order. The experiments\non standard benchmark datasets demonstrate that TextScanner outperforms the\nstate-of-the-art methods. Moreover, TextScanner shows its superiority in\nrecognizing more difficult text such Chinese transcripts and aligning with\ntarget characters.", "published": "2019-12-28 07:52:00", "link": "http://arxiv.org/abs/1912.12422v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Robust Cross-lingual Embeddings from Parallel Sentences", "abstract": "Recent advances in cross-lingual word embeddings have primarily relied on\nmapping-based methods, which project pretrained word embeddings from different\nlanguages into a shared space through a linear transformation. However, these\napproaches assume word embedding spaces are isomorphic between different\nlanguages, which has been shown not to hold in practice (S{\\o}gaard et al.,\n2018), and fundamentally limits their performance. This motivates investigating\njoint learning methods which can overcome this impediment, by simultaneously\nlearning embeddings across languages via a cross-lingual term in the training\nobjective. We propose a bilingual extension of the CBOW method which leverages\nsentence-aligned corpora to obtain robust cross-lingual word and sentence\nrepresentations. Our approach significantly improves cross-lingual sentence\nretrieval performance over all other approaches while maintaining parity with\nthe current state-of-the-art methods on word-translation. It also achieves\nparity with a deep RNN method on a zero-shot cross-lingual document\nclassification task, requiring far fewer computational resources for training\nand inference. As an additional advantage, our bilingual method leads to a much\nmore pronounced improvement in the the quality of monolingual word vectors\ncompared to other competing methods.", "published": "2019-12-28 16:18:33", "link": "http://arxiv.org/abs/1912.12481v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weak Supervision for Fake News Detection via Reinforcement Learning", "abstract": "Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods.", "published": "2019-12-28 21:20:25", "link": "http://arxiv.org/abs/1912.12520v2", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Improved Multi-Stage Training of Online Attention-based Encoder-Decoder\n  Models", "abstract": "In this paper, we propose a refined multi-stage multi-task training strategy\nto improve the performance of online attention-based encoder-decoder (AED)\nmodels. A three-stage training based on three levels of architectural\ngranularity namely, character encoder, byte pair encoding (BPE) based encoder,\nand attention decoder, is proposed. Also, multi-task learning based on\ntwo-levels of linguistic granularity namely, character and BPE, is used. We\nexplore different pre-training strategies for the encoders including transfer\nlearning from a bidirectional encoder. Our encoder-decoder models with online\nattention show 35% and 10% relative improvement over their baselines for\nsmaller and bigger models, respectively. Our models achieve a word error rate\n(WER) of 5.04% and 4.48% on the Librispeech test-clean data for the smaller and\nbigger models respectively after fusion with long short-term memory (LSTM)\nbased external language model (LM).", "published": "2019-12-28 02:29:33", "link": "http://arxiv.org/abs/1912.12384v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP", "stat.ML"], "primary_category": "eess.AS"}
