{"title": "NapSS: Paragraph-level Medical Text Simplification via Narrative\n  Prompting and Sentence-matching Summarization", "abstract": "Accessing medical literature is difficult for laypeople as the content is\nwritten for specialists and contains medical jargon. Automated text\nsimplification methods offer a potential means to address this issue. In this\nwork, we propose a summarize-then-simplify two-stage strategy, which we call\nNapSS, identifying the relevant content to simplify while ensuring that the\noriginal narrative flow is preserved. In this approach, we first generate\nreference summaries via sentence matching between the original and the\nsimplified abstracts. These summaries are then used to train an extractive\nsummarizer, learning the most relevant content to be simplified. Then, to\nensure the narrative consistency of the simplified text, we synthesize\nauxiliary narrative prompts combining key phrases derived from the syntactical\nanalyses of the original text. Our model achieves results significantly better\nthan the seq2seq baseline on an English medical corpus, yielding 3%~4% absolute\nimprovements in terms of lexical similarity, and providing a further 1.1%\nimprovement of SARI score when combined with the baseline. We also highlight\nshortcomings of existing evaluation methods, and introduce new metrics that\ntake into account both lexical and high-level semantic similarity. A human\nevaluation conducted on a random sample of the test set further establishes the\neffectiveness of the proposed approach. Codes and models are released here:\nhttps://github.com/LuJunru/NapSS.", "published": "2023-02-11 02:20:25", "link": "http://arxiv.org/abs/2302.05574v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metaphor Detection with Effective Context Denoising", "abstract": "We propose a novel RoBERTa-based model, RoPPT, which introduces a\ntarget-oriented parse tree structure in metaphor detection. Compared to\nexisting models, RoPPT focuses on semantically relevant information and\nachieves the state-of-the-art on several main metaphor datasets. We also\ncompare our approach against several popular denoising and pruning methods,\ndemonstrating the effectiveness of our approach in context denoising. Our code\nand dataset can be found at https://github.com/MajiBear000/RoPPT", "published": "2023-02-11 05:53:51", "link": "http://arxiv.org/abs/2302.05611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialectograms: Machine Learning Differences between Discursive\n  Communities", "abstract": "Word embeddings provide an unsupervised way to understand differences in word\nusage between discursive communities. A number of recent papers have focused on\nidentifying words that are used differently by two or more communities. But\nword embeddings are complex, high-dimensional spaces and a focus on identifying\ndifferences only captures a fraction of their richness. Here, we take a step\ntowards leveraging the richness of the full embedding space, by using word\nembeddings to map out how words are used differently. Specifically, we describe\nthe construction of dialectograms, an unsupervised way to visually explore the\ncharacteristic ways in which each community use a focal word. Based on these\ndialectograms, we provide a new measure of the degree to which words are used\ndifferently that overcomes the tendency for existing measures to pick out low\nfrequent or polysemous words. We apply our methods to explore the discourses of\ntwo US political subreddits and show how our methods identify stark affective\npolarisation of politicians and political entities, differences in the\nassessment of proper political action as well as disagreement about whether\ncertain issues require political intervention at all.", "published": "2023-02-11 11:32:08", "link": "http://arxiv.org/abs/2302.05657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Divergence-Based Domain Transferability for Zero-Shot Classification", "abstract": "Transferring learned patterns from pretrained neural language models has been\nshown to significantly improve effectiveness across a variety of language-based\ntasks, meanwhile further tuning on intermediate tasks has been demonstrated to\nprovide additional performance benefits, provided the intermediate task is\nsufficiently related to the target task. However, how to identify related tasks\nis an open problem, and brute-force searching effective task combinations is\nprohibitively expensive. Hence, the question arises, are we able to improve the\neffectiveness and efficiency of tasks with no training examples through\nselective fine-tuning? In this paper, we explore statistical measures that\napproximate the divergence between domain representations as a means to\nestimate whether tuning using one task pair will exhibit performance benefits\nover tuning another. This estimation can then be used to reduce the number of\ntask pairs that need to be tested by eliminating pairs that are unlikely to\nprovide benefits. Through experimentation over 58 tasks and over 6,600 task\npair combinations, we demonstrate that statistical measures can distinguish\neffective task pairs, and the resulting estimates can reduce end-to-end runtime\nby up to 40%.", "published": "2023-02-11 16:04:38", "link": "http://arxiv.org/abs/2302.05735v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented\n  Large Language Models", "abstract": "Despite recent progress, it has been difficult to prevent semantic\nhallucinations in generative Large Language Models. One common solution to this\nis augmenting LLMs with a retrieval system and making sure that the generated\noutput is attributable to the retrieved information. Given this new added\nconstraint, it is plausible to expect that the overall quality of the output\nwill be affected, for example, in terms of fluency. Can scaling language models\nhelp?\n  Here we examine the relationship between fluency and attribution in LLMs\nprompted with retrieved evidence in knowledge-heavy dialog settings. Our\nexperiments were implemented with a set of auto-metrics that are aligned with\nhuman preferences. They were used to evaluate a large set of generations,\nproduced under varying parameters of LLMs and supplied context.\n  We show that larger models tend to do much better in both fluency and\nattribution, and that (naively) using top-k retrieval versus top-1 retrieval\nimproves attribution but hurts fluency. We next propose a recipe that could\nallow smaller models to both close the gap with larger models and preserve the\nbenefits of top-k retrieval while avoiding its drawbacks.", "published": "2023-02-11 02:43:34", "link": "http://arxiv.org/abs/2302.05578v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MatKB: Semantic Search for Polycrystalline Materials Synthesis\n  Procedures", "abstract": "In this paper, we present a novel approach to knowledge extraction and\nretrieval using Natural Language Processing (NLP) techniques for material\nscience. Our goal is to automatically mine structured knowledge from millions\nof research articles in the field of polycrystalline materials and make it\neasily accessible to the broader community. The proposed method leverages NLP\ntechniques such as entity recognition and document classification to extract\nrelevant information and build an extensive knowledge base, from a collection\nof 9.5 Million publications. The resulting knowledge base is integrated into a\nsearch engine, which enables users to search for information about specific\nmaterials, properties, and experiments with greater precision than traditional\nsearch engines like Google. We hope our results can enable material scientists\nquickly locate desired experimental procedures, compare their differences, and\neven inspire them to design new experiments. Our website will be available at\nGithub \\footnote{https://github.com/Xianjun-Yang/PcMSP.git} soon.", "published": "2023-02-11 04:18:07", "link": "http://arxiv.org/abs/2302.05597v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the Robustness of Discrete Prompts", "abstract": "Discrete prompts have been used for fine-tuning Pre-trained Language Models\nfor diverse NLP tasks. In particular, automatic methods that generate discrete\nprompts from a small set of training instances have reported superior\nperformance. However, a closer look at the learnt prompts reveals that they\ncontain noisy and counter-intuitive lexical constructs that would not be\nencountered in manually-written prompts. This raises an important yet\nunderstudied question regarding the robustness of automatically learnt discrete\nprompts when used in downstream tasks. To address this question, we conduct a\nsystematic study of the robustness of discrete prompts by applying carefully\ndesigned perturbations into an application using AutoPrompt and then measure\ntheir performance in two Natural Language Inference (NLI) datasets. Our\nexperimental results show that although the discrete prompt-based method\nremains relatively robust against perturbations to NLI inputs, they are highly\nsensitive to other types of perturbations such as shuffling and deletion of\nprompt tokens. Moreover, they generalize poorly across different NLI datasets.\nWe hope our findings will inspire future work on robust discrete prompt\nlearning.", "published": "2023-02-11 07:01:53", "link": "http://arxiv.org/abs/2302.05619v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous\n  Pronouns", "abstract": "Bias-measuring datasets play a critical role in detecting biased behavior of\nlanguage models and in evaluating progress of bias mitigation methods. In this\nwork, we focus on evaluating gender bias through coreference resolution, where\nprevious datasets are either hand-crafted or fail to reliably measure an\nexplicitly defined bias. To overcome these shortcomings, we propose a novel\nmethod to collect diverse, natural, and minimally distant text pairs via\ncounterfactual generation, and construct Counter-GAP, an annotated dataset\nconsisting of 4008 instances grouped into 1002 quadruples. We further identify\na bias cancellation problem in previous group-level metrics on Counter-GAP, and\npropose to use the difference between inconsistency across genders and within\ngenders to measure bias at a quadruple level. Our results show that four\npre-trained language models are significantly more inconsistent across\ndifferent gender groups than within each group, and that a name-based\ncounterfactual data augmentation method is more effective to mitigate such bias\nthan an anonymization-based method.", "published": "2023-02-11 12:11:03", "link": "http://arxiv.org/abs/2302.05674v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HateProof: Are Hateful Meme Detection Systems really Robust?", "abstract": "Exploiting social media to spread hate has tremendously increased over the\nyears. Lately, multi-modal hateful content such as memes has drawn relatively\nmore traction than uni-modal content. Moreover, the availability of implicit\ncontent payloads makes them fairly challenging to be detected by existing\nhateful meme detection systems. In this paper, we present a use case study to\nanalyze such systems' vulnerabilities against external adversarial attacks. We\nfind that even very simple perturbations in uni-modal and multi-modal settings\nperformed by humans with little knowledge about the model can make the existing\ndetection models highly vulnerable. Empirically, we find a noticeable\nperformance drop of as high as 10% in the macro-F1 score for certain attacks.\nAs a remedy, we attempt to boost the model's robustness using contrastive\nlearning as well as an adversarial training-based method - VILLA. Using an\nensemble of the above two approaches, in two of our high resolution datasets,\nwe are able to (re)gain back the performance to a large extent for certain\nattacks. We believe that ours is a first step toward addressing this crucial\nproblem in an adversarial setting and would inspire more such investigations in\nthe future.", "published": "2023-02-11 14:36:11", "link": "http://arxiv.org/abs/2302.05703v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MTTM: Metamorphic Testing for Textual Content Moderation Software", "abstract": "The exponential growth of social media platforms such as Twitter and Facebook\nhas revolutionized textual communication and textual content publication in\nhuman society. However, they have been increasingly exploited to propagate\ntoxic content, such as hate speech, malicious advertisement, and pornography,\nwhich can lead to highly negative impacts (e.g., harmful effects on teen mental\nhealth). Researchers and practitioners have been enthusiastically developing\nand extensively deploying textual content moderation software to address this\nproblem. However, we find that malicious users can evade moderation by changing\nonly a few words in the toxic content. Moreover, modern content moderation\nsoftware performance against malicious inputs remains underexplored. To this\nend, we propose MTTM, a Metamorphic Testing framework for Textual content\nModeration software. Specifically, we conduct a pilot study on 2,000 text\nmessages collected from real users and summarize eleven metamorphic relations\nacross three perturbation levels: character, word, and sentence. MTTM employs\nthese metamorphic relations on toxic textual contents to generate test cases,\nwhich are still toxic yet likely to evade moderation. In our evaluation, we\nemploy MTTM to test three commercial textual content moderation software and\ntwo state-of-the-art moderation algorithms against three kinds of toxic\ncontent. The results show that MTTM achieves up to 83.9%, 51%, and 82.5% error\nfinding rates (EFR) when testing commercial moderation software provided by\nGoogle, Baidu, and Huawei, respectively, and it obtains up to 91.2% EFR when\ntesting the state-of-the-art algorithms from the academy. In addition, we\nleverage the test cases generated by MTTM to retrain the model we explored,\nwhich largely improves model robustness (0% to 5.9% EFR) while maintaining the\naccuracy on the original test set.", "published": "2023-02-11 14:44:39", "link": "http://arxiv.org/abs/2302.05706v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Synthesizing Human Gaze Feedback for Improved NLP Performance", "abstract": "Integrating human feedback in models can improve the performance of natural\nlanguage processing (NLP) models. Feedback can be either explicit (e.g. ranking\nused in training language models) or implicit (e.g. using human cognitive\nsignals in the form of eyetracking). Prior eye tracking and NLP research reveal\nthat cognitive processes, such as human scanpaths, gleaned from human gaze\npatterns aid in the understanding and performance of NLP models. However, the\ncollection of real eyetracking data for NLP tasks is challenging due to the\nrequirement of expensive and precise equipment coupled with privacy invasion\nissues. To address this challenge, we propose ScanTextGAN, a novel model for\ngenerating human scanpaths over text. We show that ScanTextGAN-generated\nscanpaths can approximate meaningful cognitive signals in human gaze patterns.\nWe include synthetically generated scanpaths in four popular NLP tasks spanning\nsix different datasets as proof of concept and show that the models augmented\nwith generated scanpaths improve the performance of all downstream NLP tasks.", "published": "2023-02-11 15:34:23", "link": "http://arxiv.org/abs/2302.05721v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3", "abstract": "LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art\nlanguage model GPT-3, fine-tuned for the legal domain. The system is designed\nto provide legal assistance to users in a conversational manner, helping them\nwith tasks such as answering legal questions, generating legal documents, and\nproviding legal advice. In this paper, we provide a brief overview of LawGPT\n1.0, its architecture, and its performance on a set of legal benchmark tasks.\nPlease note that the detailed information about the model is protected by a\nnon-disclosure agreement (NDA) and cannot be disclosed in this report.", "published": "2023-02-11 15:50:20", "link": "http://arxiv.org/abs/2302.05729v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Reparameterized Discrete Diffusion Model for Text Generation", "abstract": "This work studies discrete diffusion probabilistic models with applications\nto natural language generation. We derive an alternative yet equivalent\nformulation of the sampling from discrete diffusion processes and leverage this\ninsight to develop a family of reparameterized discrete diffusion models. The\nderived generic framework is highly flexible, offers a fresh perspective of the\ngeneration process in discrete diffusion models, and features more effective\ntraining and decoding techniques. We conduct extensive experiments to evaluate\nthe text generation capability of our model, demonstrating significant\nimprovements over existing diffusion models.", "published": "2023-02-11 16:26:57", "link": "http://arxiv.org/abs/2302.05737v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Sign Recognition with Phonology", "abstract": "We use insights from research on American Sign Language (ASL) phonology to\ntrain models for isolated sign language recognition (ISLR), a step towards\nautomatic sign language understanding. Our key insight is to explicitly\nrecognize the role of phonology in sign production to achieve more accurate\nISLR than existing work which does not consider sign language phonology. We\ntrain ISLR models that take in pose estimations of a signer producing a single\nsign to predict not only the sign but additionally its phonological\ncharacteristics, such as the handshape. These auxiliary predictions lead to a\nnearly 9% absolute gain in sign recognition accuracy on the WLASL benchmark,\nwith consistent improvements in ISLR regardless of the underlying prediction\nmodel architecture. This work has the potential to accelerate linguistic\nresearch in the domain of signed languages and reduce communication barriers\nbetween deaf and hearing people.", "published": "2023-02-11 18:51:23", "link": "http://arxiv.org/abs/2302.05759v1", "categories": ["cs.CL", "cs.CV", "I.2.7; I.2.10; I.5.4"], "primary_category": "cs.CL"}
{"title": "Explaining text classifiers through progressive neighborhood\n  approximation with realistic samples", "abstract": "The importance of neighborhood construction in local explanation methods has\nbeen already highlighted in the literature. And several attempts have been made\nto improve neighborhood quality for high-dimensional data, for example, texts,\nby adopting generative models. Although the generators produce more realistic\nsamples, the intuitive sampling approaches in the existing solutions leave the\nlatent space underexplored. To overcome this problem, our work, focusing on\nlocal model-agnostic explanations for text classifiers, proposes a progressive\napproximation approach that refines the neighborhood of a to-be-explained\ndecision with a careful two-stage interpolation using counterfactuals as\nlandmarks. We explicitly specify the two properties that should be satisfied by\ngenerative models, the reconstruction ability and the locality-preserving\nproperty, to guide the selection of generators for local explanation methods.\nMoreover, noticing the opacity of generative models during the study, we\npropose another method that implements progressive neighborhood approximation\nwith probability-based editions as an alternative to the generator-based\nsolution. The explanation results from both methods consist of word-level and\ninstance-level explanations benefiting from the realistic neighborhood. Through\nexhaustive experiments, we qualitatively and quantitatively demonstrate the\neffectiveness of the two proposed methods.", "published": "2023-02-11 11:42:39", "link": "http://arxiv.org/abs/2302.07733v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT better than Human Annotators? Potential and Limitations of\n  ChatGPT in Explaining Implicit Hate Speech", "abstract": "Recent studies have alarmed that many online hate speeches are implicit. With\nits subtle nature, the explainability of the detection of such hateful speech\nhas been a challenging problem. In this work, we examine whether ChatGPT can be\nused for providing natural language explanations (NLEs) for implicit hateful\nspeech detection. We design our prompt to elicit concise ChatGPT-generated NLEs\nand conduct user studies to evaluate their qualities by comparison with\nhuman-written NLEs. We discuss the potential and limitations of ChatGPT in the\ncontext of implicit hateful speech research.", "published": "2023-02-11 03:13:54", "link": "http://arxiv.org/abs/2302.07736v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "ASDF: A Differential Testing Framework for Automatic Speech Recognition\n  Systems", "abstract": "Recent years have witnessed wider adoption of Automated Speech Recognition\n(ASR) techniques in various domains. Consequently, evaluating and enhancing the\nquality of ASR systems is of great importance. This paper proposes ASDF, an\nAutomated Speech Recognition Differential Testing Framework for testing ASR\nsystems. ASDF extends an existing ASR testing tool, the CrossASR++, which\nsynthesizes test cases from a text corpus. However, CrossASR++ fails to make\nuse of the text corpus efficiently and provides limited information on how the\nfailed test cases can improve ASR systems. To address these limitations, our\ntool incorporates two novel features: (1) a text transformation module to boost\nthe number of generated test cases and uncover more errors in ASR systems and\n(2) a phonetic analysis module to identify on which phonemes the ASR system\ntend to produce errors. ASDF generates more high-quality test cases by applying\nvarious text transformation methods (e.g., change tense) to the texts in failed\ntest cases. By doing so, ASDF can utilize a small text corpus to generate a\nlarge number of audio test cases, something which CrossASR++ is not capable of.\nIn addition, ASDF implements more metrics to evaluate the performance of ASR\nsystems from multiple perspectives. ASDF performs phonetic analysis on the\nidentified failed test cases to identify the phonemes that ASR systems tend to\ntranscribe incorrectly, providing useful information for developers to improve\nASR systems. The demonstration video of our tool is made online at\nhttps://www.youtube.com/watch?v=DzVwfc3h9As. The implementation is available at\nhttps://github.com/danielyuenhx/asdf-differential-testing.", "published": "2023-02-11 02:53:12", "link": "http://arxiv.org/abs/2302.05582v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "cs.SE"], "primary_category": "eess.AS"}
{"title": "Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis", "abstract": "Often, deep network models are purely inductive during training and while\nperforming inference on unseen data. Thus, when such models are used for\npredictions, it is well known that they often fail to capture the semantic\ninformation and implicit dependencies that exist among objects (or concepts) on\na population level. Moreover, it is still unclear how domain or prior modal\nknowledge can be specified in a backpropagation friendly manner, especially in\nlarge-scale and noisy settings. In this work, we propose an end-to-end vision\nand language model incorporating explicit knowledge graphs. We also introduce\nan interactive out-of-distribution (OOD) layer using implicit network operator.\nThe layer is used to filter noise that is brought by external knowledge base.\nIn practice, we apply our model on several vision and language downstream tasks\nincluding visual question answering, visual reasoning, and image-text retrieval\non different datasets. Our experiments show that it is possible to design\nmodels that perform similarly to state-of-art results but with significantly\nfewer samples and training time.", "published": "2023-02-11 05:46:21", "link": "http://arxiv.org/abs/2302.05608v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Emotion Detection From Social Media Posts", "abstract": "Over the last few years, social media has evolved into a medium for\nexpressing personal views, emotions, and even business and political proposals,\nrecommendations, and advertisements. We address the topic of identifying\nemotions from text data obtained from social media posts like Twitter in this\nresearch. We have deployed different traditional machine learning techniques\nsuch as Support Vector Machines (SVM), Naive Bayes, Decision Trees, and Random\nForest, as well as deep neural network models such as LSTM, CNN, GRU, BiLSTM,\nBiGRU to classify these tweets into four emotion categories (Fear, Anger, Joy,\nand Sadness). Furthermore, we have constructed a BiLSTM and BiGRU ensemble\nmodel. The evaluation result shows that the deep neural network models(BiGRU,\nto be specific) produce the most promising results compared to traditional\nmachine learning models, with an 87.53 % accuracy rate. The ensemble model\nperforms even better (87.66 %), albeit the difference is not significant. This\nresult will aid in the development of a decision-making tool that visualizes\nemotional fluctuations.", "published": "2023-02-11 05:52:33", "link": "http://arxiv.org/abs/2302.05610v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DocILE Benchmark for Document Information Localization and Extraction", "abstract": "This paper introduces the DocILE benchmark with the largest dataset of\nbusiness documents for the tasks of Key Information Localization and Extraction\nand Line Item Recognition. It contains 6.7k annotated business documents, 100k\nsynthetically generated documents, and nearly~1M unlabeled documents for\nunsupervised pre-training. The dataset has been built with knowledge of domain-\nand task-specific aspects, resulting in the following key features: (i)\nannotations in 55 classes, which surpasses the granularity of previously\npublished key information extraction datasets by a large margin; (ii) Line Item\nRecognition represents a highly practical information extraction task, where\nkey information has to be assigned to items in a table; (iii) documents come\nfrom numerous layouts and the test set includes zero- and few-shot cases as\nwell as layouts commonly seen in the training set. The benchmark comes with\nseveral baselines, including RoBERTa, LayoutLMv3 and DETR-based Table\nTransformer; applied to both tasks of the DocILE benchmark, with results shared\nin this paper, offering a quick starting point for future work. The dataset,\nbaselines and supplementary material are available at\nhttps://github.com/rossumai/docile.", "published": "2023-02-11 11:32:10", "link": "http://arxiv.org/abs/2302.05658v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compositional Exemplars for In-context Learning", "abstract": "Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.", "published": "2023-02-11 14:02:08", "link": "http://arxiv.org/abs/2302.05698v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fair Enough: Standardizing Evaluation and Model Selection for Fairness\n  Research in NLP", "abstract": "Modern NLP systems exhibit a range of biases, which a growing literature on\nmodel debiasing attempts to correct. However current progress is hampered by a\nplurality of definitions of bias, means of quantification, and oftentimes vague\nrelation between debiasing algorithms and theoretical measures of bias. This\npaper seeks to clarify the current situation and plot a course for meaningful\nprogress in fair learning, with two key contributions: (1) making clear\ninter-relations among the current gamut of methods, and their relation to\nfairness theory; and (2) addressing the practical problem of model selection,\nwhich involves a trade-off between fairness and accuracy and has led to\nsystemic issues in fairness research. Putting them together, we make several\nrecommendations to help shape future work.", "published": "2023-02-11 14:54:00", "link": "http://arxiv.org/abs/2302.05711v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning by Applying: A General Framework for Mathematical Reasoning via\n  Enhancing Explicit Knowledge Learning", "abstract": "Mathematical reasoning is one of the crucial abilities of general artificial\nintelligence, which requires machines to master mathematical logic and\nknowledge from solving problems. However, existing approaches are not\ntransparent (thus not interpretable) in terms of what knowledge has been\nlearned and applied in the reasoning process. In this paper, we propose a\ngeneral Learning by Applying (LeAp) framework to enhance existing models\n(backbones) in a principled way by explicit knowledge learning. In LeAp, we\nperform knowledge learning in a novel problem-knowledge-expression paradigm,\nwith a Knowledge Encoder to acquire knowledge from problem data and a Knowledge\nDecoder to apply knowledge for expression reasoning. The learned mathematical\nknowledge, including word-word relations and word-operator relations, forms an\nexplicit knowledge graph, which bridges the knowledge \"learning\" and \"applying\"\norganically. Moreover, for problem solving, we design a semantics-enhanced\nmodule and a reasoning-enhanced module that apply knowledge to improve the\nproblem comprehension and symbol reasoning abilities of any backbone,\nrespectively. We theoretically prove the superiority of LeAp's autonomous\nlearning mechanism. Experiments on three real-world datasets show that LeAp\nimproves all backbones' performances, learns accurate knowledge, and achieves a\nmore interpretable reasoning process.", "published": "2023-02-11 15:15:41", "link": "http://arxiv.org/abs/2302.05717v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Level Generation Through Large Language Models", "abstract": "Large Language Models (LLMs) are powerful tools, capable of leveraging their\ntraining on natural language to write stories, generate code, and answer\nquestions. But can they generate functional video game levels? Game levels,\nwith their complex functional constraints and spatial relationships in more\nthan one dimension, are very different from the kinds of data an LLM typically\nsees during training. Datasets of game levels are also hard to come by,\npotentially taxing the abilities of these data-hungry models. We investigate\nthe use of LLMs to generate levels for the game Sokoban, finding that LLMs are\nindeed capable of doing so, and that their performance scales dramatically with\ndataset size. We also perform preliminary experiments on controlling LLM level\ngenerators and discuss promising areas for future work.", "published": "2023-02-11 23:34:42", "link": "http://arxiv.org/abs/2302.05817v2", "categories": ["cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.AI"}
{"title": "See Your Heart: Psychological states Interpretation through Visual\n  Creations", "abstract": "In psychoanalysis, generating interpretations to one's psychological state\nthrough visual creations is facing significant demands. The two main tasks of\nexisting studies in the field of computer vision, sentiment/emotion\nclassification and affective captioning, can hardly satisfy the requirement of\npsychological interpreting. To meet the demands for psychoanalysis, we\nintroduce a challenging task, \\textbf{V}isual \\textbf{E}motion\n\\textbf{I}nterpretation \\textbf{T}ask (VEIT). VEIT requires AI to generate\nreasonable interpretations of creator's psychological state through visual\ncreations. To support the task, we present a multimodal dataset termed SpyIn\n(\\textbf{S}and\\textbf{p}la\\textbf{y} \\textbf{In}terpretation Dataset), which is\npsychological theory supported and professional annotated. Dataset analysis\nillustrates that SpyIn is not only able to support VEIT, but also more\nchallenging compared with other captioning datasets. Building on SpyIn, we\nconduct experiments of several image captioning method, and propose a\nvisual-semantic combined model which obtains a SOTA result on SpyIn. The\nresults indicate that VEIT is a more challenging task requiring scene graph\ninformation and psychological knowledge. Our work also show a promise for AI to\nanalyze and explain inner world of humanity through visual creations.", "published": "2023-02-11 07:30:21", "link": "http://arxiv.org/abs/2302.10276v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Attention does not guarantee best performance in speech enhancement", "abstract": "Attention mechanism has been widely utilized in speech enhancement (SE)\nbecause theoretically it can effectively model the long-term inherent\nconnection of signal both in time domain and spectrum domain. However, the\ngenerally used global attention mechanism might not be the best choice since\nthe adjacent information naturally imposes more influence than the far-apart\ninformation in speech enhancement. In this paper, we validate this conjecture\nby replacing attention with RNN in two typical state-of-the-art (SOTA) models,\nmulti-scale temporal frequency convolutional network (MTFAA) with axial\nattention and conformer-based metric-GAN network (CMGAN).", "published": "2023-02-11 13:17:59", "link": "http://arxiv.org/abs/2302.05690v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Local spectral attention for full-band speech enhancement", "abstract": "Attention mechanism has been widely utilized in speech enhancement (SE)\nbecause theoretically it can effectively model the inherent connection of\nsignal both in time domain and spectrum domain. Usually, the span of attention\nis limited in time domain while the attention in frequency domain spans the\nwhole frequency range. In this paper, we notice that the attention over the\nwhole frequency range hampers the inference for full-band SE and possibly leads\nto excessive residual noise. To alleviate this problem, we introduce local\nspectral attention (LSA) into full-band SE model by limiting the span of\nattention. The ablation test on the state-of-the-art (SOTA) full-band SE model\nreveals that the local frequency attention can effectively improve overall\nperformance. The improved model achieves the best objective score on the\nfull-band VoiceBank+DEMAND set.", "published": "2023-02-11 13:25:19", "link": "http://arxiv.org/abs/2302.05693v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Parameterizable Acoustical Modeling and Auralization of Cultural\n  Heritage Sites based on Photogrammetry", "abstract": "The photogrammetric and reconstructive modeling of cultural heritage sites is\nmostly focused on visually perceivable aspects, but if their intended purpose\nis the performance of cultural acts with a sonic emphasis, it is important to\nconsider the preservation of their acoustical behaviour to make them audible in\nan authentic way. This applies in particular to sacral and concert environments\nas popular objects for photogrammetric models, which contain geometrical and\ntextural information that can be used to locate and classify acoustically\nrelevant surface properties. With the advancing conversion or destruction of\nhistorical acoustical spaces, it becomes even more important to preserve their\nunique sonic characters, while three-dimensional auralizations become widely\napplicable. The proposed study presents the current state of a new\nmethodological approach to acoustical modeling using photogrammetric data and\nintroduces a parameterizable pipeline that will be accessible as an open-source\nsoftware with a graphical user interface.", "published": "2023-02-11 15:44:54", "link": "http://arxiv.org/abs/2302.05725v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improved Decoding of Attentional Selection in Multi-Talker Environments\n  with Self-Supervised Learned Speech Representation", "abstract": "Auditory attention decoding (AAD) is a technique used to identify and amplify\nthe talker that a listener is focused on in a noisy environment. This is done\nby comparing the listener's brainwaves to a representation of all the sound\nsources to find the closest match. The representation is typically the waveform\nor spectrogram of the sounds. The effectiveness of these representations for\nAAD is uncertain. In this study, we examined the use of self-supervised learned\nspeech representation in improving the accuracy and speed of AAD. We recorded\nthe brain activity of three subjects using invasive electrocorticography (ECoG)\nas they listened to two conversations and focused on one. We used WavLM to\nextract a latent representation of each talker and trained a spatiotemporal\nfilter to map brain activity to intermediate representations of speech. During\nthe evaluation, the reconstructed representation is compared to each speaker's\nrepresentation to determine the target speaker. Our results indicate that\nspeech representation from WavLM provides better decoding accuracy and speed\nthan the speech envelope and spectrogram. Our findings demonstrate the\nadvantages of self-supervised learned speech representation for auditory\nattention decoding and pave the way for developing brain-controlled hearable\ntechnologies.", "published": "2023-02-11 18:33:42", "link": "http://arxiv.org/abs/2302.05756v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
