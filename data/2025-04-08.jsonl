{"title": "Hogwild! Inference: Parallel LLM Generation via Concurrent Attention", "abstract": "Large Language Models (LLMs) have demonstrated the ability to tackle\nincreasingly complex tasks through advanced reasoning, long-form content\ngeneration, and tool use. Solving these tasks often involves long\ninference-time computations. In human problem solving, a common strategy to\nexpedite work is collaboration: by dividing the problem into sub-tasks,\nexploring different strategies concurrently, etc. Recent research has shown\nthat LLMs can also operate in parallel by implementing explicit cooperation\nframeworks, such as voting mechanisms or the explicit creation of independent\nsub-tasks that can be executed in parallel. However, each of these frameworks\nmay not be suitable for all types of tasks, which can hinder their\napplicability. In this work, we propose a different design approach: we run LLM\n\"workers\" in parallel , allowing them to synchronize via a concurrently-updated\nattention cache and prompt these workers to decide how best to collaborate. Our\napproach allows the instances to come up with their own collaboration strategy\nfor the problem at hand, all the while \"seeing\" each other's partial progress\nin the concurrent cache. We implement this approach via Hogwild! Inference: a\nparallel LLM inference engine where multiple instances of the same LLM run in\nparallel with the same attention cache, with \"instant\" access to each other's\ngenerated tokens. Hogwild! inference takes advantage of Rotary Position\nEmbeddings (RoPE) to avoid recomputation while improving parallel hardware\nutilization. We find that modern reasoning-capable LLMs can perform inference\nwith shared Key-Value cache out of the box, without additional fine-tuning.", "published": "2025-04-08 17:59:41", "link": "http://arxiv.org/abs/2504.06261v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "abstract": "Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench", "published": "2025-04-08 17:59:39", "link": "http://arxiv.org/abs/2504.06260v1", "categories": ["cs.AI", "cs.CL", "cs.NA", "math.NA"], "primary_category": "cs.AI"}
{"title": "LExT: Towards Evaluating Trustworthiness of Natural Language Explanations", "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nhigh-stakes domains, there have been several approaches proposed toward\ngenerating natural language explanations. These explanations are crucial for\nenhancing the interpretability of a model, especially in sensitive domains like\nhealthcare, where transparency and reliability are key. In light of such\nexplanations being generated by LLMs and its known concerns, there is a growing\nneed for robust evaluation frameworks to assess model-generated explanations.\nNatural Language Generation metrics like BLEU and ROUGE capture syntactic and\nsemantic accuracies but overlook other crucial aspects such as factual\naccuracy, consistency, and faithfulness. To address this gap, we propose a\ngeneral framework for quantifying trustworthiness of natural language\nexplanations, balancing Plausibility and Faithfulness, to derive a\ncomprehensive Language Explanation Trustworthiness Score (LExT) (The code and\nset up to reproduce our experiments are publicly available at\nhttps://github.com/cerai-iitm/LExT). Applying our domain-agnostic framework to\nthe healthcare domain using public medical datasets, we evaluate six models,\nincluding domain-specific and general-purpose models. Our findings demonstrate\nsignificant differences in their ability to generate trustworthy explanations.\nOn comparing these explanations, we make interesting observations such as\ninconsistencies in Faithfulness demonstrated by general-purpose models and\ntheir tendency to outperform domain-specific fine-tuned models. This work\nfurther highlights the importance of using a tailored evaluation framework to\nassess natural language explanations in sensitive fields, providing a\nfoundation for improving the trustworthiness and transparency of language\nmodels in healthcare and beyond.", "published": "2025-04-08 17:16:52", "link": "http://arxiv.org/abs/2504.06227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via Adaptation", "abstract": "While decoder-only large language models (LLMs) have shown impressive\nresults, encoder-decoder models are still widely adopted in real-world\napplications for their inference efficiency and richer encoder representation.\nIn this paper, we study a novel problem: adapting pretrained decoder-only LLMs\nto encoder-decoder, with the goal of leveraging the strengths of both\napproaches to achieve a more favorable quality-efficiency trade-off. We argue\nthat adaptation not only enables inheriting the capability of decoder-only LLMs\nbut also reduces the demand for computation compared to pretraining from\nscratch. We rigorously explore different pretraining objectives and parameter\ninitialization/optimization techniques. Through extensive experiments based on\nGemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to\n1.6B), we demonstrate the effectiveness of adaptation and the advantage of\nencoder-decoder LLMs. Under similar inference budget, encoder-decoder LLMs\nachieve comparable (often better) pretraining performance but substantially\nbetter finetuning performance than their decoder-only counterpart. For example,\nGemma 2B-2B outperforms Gemma 2B by $\\sim$7\\% after instruction tuning.\nEncoder-decoder adaptation also allows for flexible combination of\ndifferent-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B\nby $>$3\\%. The adapted encoder representation also yields better results on\nSuperGLUE. We will release our checkpoints to facilitate future research.", "published": "2025-04-08 17:13:41", "link": "http://arxiv.org/abs/2504.06225v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs", "abstract": "The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions.", "published": "2025-04-08 17:08:06", "link": "http://arxiv.org/abs/2504.06219v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models", "abstract": "Long-context capabilities are essential for a wide range of applications,\nincluding document and video understanding, in-context learning, and\ninference-time scaling, all of which require models to process and reason over\nlong sequences of text and multimodal data. In this work, we introduce a\nefficient training recipe for building ultra-long context LLMs from aligned\ninstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,\nand 4M tokens. Our approach leverages efficient continued pretraining\nstrategies to extend the context window and employs effective instruction\ntuning to maintain the instruction-following and reasoning abilities. Our\nUltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves\nstate-of-the-art performance across a diverse set of long-context benchmarks.\nImportantly, models trained with our approach maintain competitive performance\non standard benchmarks, demonstrating balanced improvements for both long and\nshort context tasks. We further provide an in-depth analysis of key design\nchoices, highlighting the impacts of scaling strategies and data composition.\nOur findings establish a robust framework for efficiently scaling context\nlengths while preserving general model capabilities. We release all model\nweights at: https://ultralong.github.io/.", "published": "2025-04-08 16:58:58", "link": "http://arxiv.org/abs/2504.06214v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TxGemma: Efficient and Agentic LLMs for Therapeutics", "abstract": "Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).", "published": "2025-04-08 16:39:02", "link": "http://arxiv.org/abs/2504.06196v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SkillFlow: Efficient Skill and Code Transfer Through Communication in Adapting AI Agents", "abstract": "AI agents are autonomous systems that can execute specific tasks based on\npredefined programming. Here, we present SkillFlow, a modular,\ntechnology-agnostic framework that allows agents to expand their functionality\nin an ad-hoc fashion by acquiring new skills from their environment or other\nagents. We present a theoretical model that examines under which conditions\nthis framework would be beneficial, and we then explore SkillFlow's ability to\naccelerate task completion and lead to lower cumulative costs in a real-world\napplication, namely scheduling agents for calendar events. We demonstrate that\nwithin a few iterations, SkillFlow leads to considerable (24.8%, p-value =\n$6.4\\times10^{-3}$) gains in time and cost, especially when the communication\ncost is high. Finally, we draw analogies from well-studied biological systems\nand compare this framework to that of lateral gene transfer, a significant\nprocess of adaptation and evolution in novel environments.", "published": "2025-04-08 16:33:24", "link": "http://arxiv.org/abs/2504.06188v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Assessing how hyperparameters impact Large Language Models' sarcasm detection performance", "abstract": "Sarcasm detection is challenging for both humans and machines. This work\nexplores how model characteristics impact sarcasm detection in OpenAI's GPT,\nand Meta's Llama-2 models, given their strong natural language understanding,\nand popularity. We evaluate fine-tuned and zero-shot models across various\nsizes, releases, and hyperparameters. Experiments were conducted on the\npolitical and balanced (pol-bal) portion of the popular Self-Annotated Reddit\nCorpus (SARC2.0) sarcasm dataset. Fine-tuned performance improves monotonically\nwith model size within a model family, while hyperparameter tuning also impacts\nperformance. In the fine-tuning scenario, full precision Llama-2-13b achieves\nstate-of-the-art accuracy and $F_1$-score, both measured at 0.83, comparable to\naverage human performance. In the zero-shot setting, one GPT-4 model achieves\ncompetitive performance to prior attempts, yielding an accuracy of 0.70 and an\n$F_1$-score of 0.75. Furthermore, a model's performance may increase or decline\nwith each release, highlighting the need to reassess performance after each\nrelease.", "published": "2025-04-08 16:05:25", "link": "http://arxiv.org/abs/2504.06166v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups", "abstract": "Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.", "published": "2025-04-08 15:56:57", "link": "http://arxiv.org/abs/2504.06160v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI", "J.4; K.4.1; K.4.2"], "primary_category": "cs.CL"}
{"title": "QGen Studio: An Adaptive Question-Answer Generation, Training and Evaluation Platform", "abstract": "We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.", "published": "2025-04-08 15:32:09", "link": "http://arxiv.org/abs/2504.06136v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Confidence Regularized Masked Language Modeling using Text Length", "abstract": "Masked language modeling, which is a task to predict a randomly masked word\nin the input text, is an efficient language representation learning method.\nMasked language modeling ignores various words which people can think of for\nfilling in the masked position and calculates the loss with a single word.\nEspecially when the input text is short, the entropy of the word distribution\nthat can fill in the masked position can be high. This may cause the model to\nbe overconfident in the single answer. To address this issue, we propose a\nnovel confidence regularizer that controls regularizing strength dynamically by\nthe input text length. Experiments with GLUE and SQuAD datasets showed that our\nmethod achieves better accuracy and lower expected calibration error.", "published": "2025-04-08 13:37:08", "link": "http://arxiv.org/abs/2504.06037v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Sense Embeddings for Language Models and Knowledge Distillation", "abstract": "Transformer-based large language models (LLMs) rely on contextual embeddings\nwhich generate different (continuous) representations for the same token\ndepending on its surrounding context. Nonetheless, words and tokens typically\nhave a limited number of senses (or meanings). We propose multi-sense\nembeddings as a drop-in replacement for each token in order to capture the\nrange of their uses in a language. To construct a sense embedding dictionary,\nwe apply a clustering algorithm to embeddings generated by an LLM and consider\nthe cluster centers as representative sense embeddings. In addition, we propose\na novel knowledge distillation method that leverages the sense dictionary to\nlearn a smaller student model that mimics the senses from the much larger base\nLLM model, offering significant space and inference time savings, while\nmaintaining competitive performance. Via thorough experiments on various\nbenchmarks, we showcase the effectiveness of our sense embeddings and knowledge\ndistillation approach. We share our code at\nhttps://github.com/Qitong-Wang/SenseDict", "published": "2025-04-08 13:36:36", "link": "http://arxiv.org/abs/2504.06036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Llama-3-Nanda-10B-Chat: An Open Generative Large Language Model for Hindi", "abstract": "Developing high-quality large language models (LLMs) for moderately resourced\nlanguages presents unique challenges in data availability, model adaptation,\nand evaluation. We introduce Llama-3-Nanda-10B-Chat, or Nanda for short, a\nstate-of-the-art Hindi-centric instruction-tuned generative LLM, designed to\npush the boundaries of open-source Hindi language models. Built upon\nLlama-3-8B, Nanda incorporates continuous pre-training with expanded\ntransformer blocks, leveraging the Llama Pro methodology. A key challenge was\nthe limited availability of high-quality Hindi text data; we addressed this\nthrough rigorous data curation, augmentation, and strategic bilingual training,\nbalancing Hindi and English corpora to optimize cross-linguistic knowledge\ntransfer. With 10 billion parameters, Nanda stands among the top-performing\nopen-source Hindi and multilingual models of similar scale, demonstrating\nsignificant advantages over many existing models. We provide an in-depth\ndiscussion of training strategies, fine-tuning techniques, safety alignment,\nand evaluation metrics, demonstrating how these approaches enabled Nanda to\nachieve state-of-the-art results. By open-sourcing Nanda, we aim to advance\nresearch in Hindi LLMs and support a wide range of real-world applications\nacross academia, industry, and public services.", "published": "2025-04-08 13:16:54", "link": "http://arxiv.org/abs/2504.06011v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge", "abstract": "The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).", "published": "2025-04-08 13:01:51", "link": "http://arxiv.org/abs/2504.05995v1", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Unsupervised Location Mapping for Narrative Corpora", "abstract": "This work presents the task of unsupervised location mapping, which seeks to\nmap the trajectory of an individual narrative on a spatial map of locations in\nwhich a large set of narratives take place. Despite the fundamentality and\ngenerality of the task, very little work addressed the spatial mapping of\nnarrative texts. The task consists of two parts: (1) inducing a ``map'' with\nthe locations mentioned in a set of texts, and (2) extracting a trajectory from\na single narrative and positioning it on the map. Following recent advances in\nincreasing the context length of large language models, we propose a pipeline\nfor this task in a completely unsupervised manner without predefining the set\nof labels. We test our method on two different domains: (1) Holocaust\ntestimonies and (2) Lake District writing, namely multi-century literature on\ntravels in the English Lake District. We perform both intrinsic and extrinsic\nevaluations for the task, with encouraging results, thereby setting a benchmark\nand evaluation practices for the task, as well as highlighting challenges.", "published": "2025-04-08 12:06:47", "link": "http://arxiv.org/abs/2504.05954v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "High-Resource Translation:Turning Abundance into Accessibility", "abstract": "This paper presents a novel approach to constructing an English-to-Telugu\ntranslation model by leveraging transfer learning techniques and addressing the\nchallenges associated with low-resource languages. Utilizing the Bharat\nParallel Corpus Collection (BPCC) as the primary dataset, the model\nincorporates iterative backtranslation to generate synthetic parallel data,\neffectively augmenting the training dataset and enhancing the model's\ntranslation capabilities. The research focuses on a comprehensive strategy for\nimproving model performance through data augmentation, optimization of training\nparameters, and the effective use of pre-trained models. These methodologies\naim to create a robust translation system that can handle diverse sentence\nstructures and linguistic nuances in both English and Telugu. This work\nhighlights the significance of innovative data handling techniques and the\npotential of transfer learning in overcoming limitations posed by sparse\ndatasets in low-resource languages. The study contributes to the field of\nmachine translation and seeks to improve communication between English and\nTelugu speakers in practical contexts.", "published": "2025-04-08 11:09:51", "link": "http://arxiv.org/abs/2504.05914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Defending Deep Neural Networks against Backdoor Attacks via Module Switching", "abstract": "The exponential increase in the parameters of Deep Neural Networks (DNNs) has\nsignificantly raised the cost of independent training, particularly for\nresource-constrained entities. As a result, there is a growing reliance on\nopen-source models. However, the opacity of training processes exacerbates\nsecurity risks, making these models more vulnerable to malicious threats, such\nas backdoor attacks, while simultaneously complicating defense mechanisms.\nMerging homogeneous models has gained attention as a cost-effective\npost-training defense. However, we notice that existing strategies, such as\nweight averaging, only partially mitigate the influence of poisoned parameters\nand remain ineffective in disrupting the pervasive spurious correlations\nembedded across model parameters. We propose a novel module-switching strategy\nto break such spurious correlations within the model's propagation path. By\nleveraging evolutionary algorithms to optimize fusion strategies, we validate\nour approach against backdoor attacks targeting text and vision domains. Our\nmethod achieves effective backdoor mitigation even when incorporating a couple\nof compromised models, e.g., reducing the average attack success rate (ASR) to\n22% compared to 31.9% with the best-performing baseline on SST-2.", "published": "2025-04-08 11:01:07", "link": "http://arxiv.org/abs/2504.05902v1", "categories": ["cs.CR", "cs.CL", "I.2.7; I.2.10"], "primary_category": "cs.CR"}
{"title": "Assessing Thai Dialect Performance in LLMs with Automatic Benchmarks and Human Evaluation", "abstract": "Large language models show promising results in various NLP tasks. Despite\nthese successes, the robustness and consistency of LLMs in underrepresented\nlanguages remain largely unexplored, especially concerning local dialects.\nExisting benchmarks also focus on main dialects, neglecting LLMs' ability on\nlocal dialect texts. In this paper, we introduce a Thai local dialect benchmark\ncovering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai,\nevaluating LLMs on five NLP tasks: summarization, question answering,\ntranslation, conversation, and food-related tasks. Furthermore, we propose a\nhuman evaluation guideline and metric for Thai local dialects to assess\ngeneration fluency and dialect-specific accuracy. Results show that LLM\nperformance declines significantly in local Thai dialects compared to standard\nThai, with only proprietary models like GPT-4o and Gemini2 demonstrating some\nfluency", "published": "2025-04-08 10:49:45", "link": "http://arxiv.org/abs/2504.05898v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Generative AI Agents Effective Personalized Financial Advisors?", "abstract": "Large language model-based agents are becoming increasingly popular as a\nlow-cost mechanism to provide personalized, conversational advice, and have\ndemonstrated impressive capabilities in relatively simple scenarios, such as\nmovie recommendations. But how do these agents perform in complex high-stakes\ndomains, where domain expertise is essential and mistakes carry substantial\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\nwhen users themselves may be unsure of their needs, (2) providing personalized\nguidance for diverse investment preferences, and (3) leveraging advisor\npersonality to build relationships and foster trust. Via a lab-based user study\nwith 64 participants, we show that LLM-advisors often match human advisor\nperformance when eliciting preferences, although they can struggle to resolve\nconflicting user needs. When providing personalized advice, the LLM was able to\npositively influence user behavior, but demonstrated clear failure modes. Our\nresults show that accurate preference elicitation is key, otherwise, the\nLLM-advisor has little impact, or can even direct the investor toward\nunsuitable assets. More worryingly, users appear insensitive to the quality of\nadvice being given, or worse these can have an inverse relationship. Indeed,\nusers reported a preference for and increased satisfaction as well as emotional\ntrust with LLMs adopting an extroverted persona, even though those agents\nprovided worse advice.", "published": "2025-04-08 09:41:03", "link": "http://arxiv.org/abs/2504.05862v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR", "q-fin.CP"], "primary_category": "cs.AI"}
{"title": "Enhancing Coreference Resolution with Pretrained Language Models: Bridging the Gap Between Syntax and Semantics", "abstract": "Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.", "published": "2025-04-08 09:33:09", "link": "http://arxiv.org/abs/2504.05855v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Robust Optimization for LLM Alignment under Distribution Shifts", "abstract": "Large language models (LLMs) increasingly rely on preference alignment\nmethods to steer outputs toward human values, yet these methods are often\nconstrained by the scarcity of high-quality human-annotated data. To tackle\nthis, recent approaches have turned to synthetic data generated by LLMs as a\nscalable alternative. However, synthetic data can introduce distribution\nshifts, compromising the nuanced human preferences that are essential for\ndesirable outputs. In this paper, we propose a novel distribution-aware\noptimization framework that improves preference alignment in the presence of\nsuch shifts. Our approach first estimates the likelihood ratios between the\ntarget and training distributions leveraging a learned classifier, then it\nminimizes the worst-case loss over data regions that reflect the target\nhuman-preferred distribution. By explicitly prioritizing the target\ndistribution during optimization, our method mitigates the adverse effects of\ndistributional variation and enhances the generation of responses that\nfaithfully reflect human values.", "published": "2025-04-08 09:14:38", "link": "http://arxiv.org/abs/2504.05831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Dialog Neural Coreference Resolution: Balancing Efficiency and Accuracy in Large-Scale Systems", "abstract": "Large-scale coreference resolution presents a significant challenge in\nnatural language processing, necessitating a balance between efficiency and\naccuracy. In response to this challenge, we introduce an End-to-End Neural\nCoreference Resolution system tailored for large-scale applications. Our system\nefficiently identifies and resolves coreference links in text, ensuring minimal\ncomputational overhead without compromising on performance. By utilizing\nadvanced neural network architectures, we incorporate various contextual\nembeddings and attention mechanisms, which enhance the quality of predictions\nfor coreference pairs. Furthermore, we apply optimization strategies to\naccelerate processing speeds, making the system suitable for real-world\ndeployment. Extensive evaluations conducted on benchmark datasets demonstrate\nthat our model achieves improved accuracy compared to existing approaches,\nwhile effectively maintaining rapid inference times. Rigorous testing confirms\nthe ability of our system to deliver precise coreference resolutions\nefficiently, thereby establishing a benchmark for future advancements in this\nfield.", "published": "2025-04-08 09:06:52", "link": "http://arxiv.org/abs/2504.05824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Document Contextual Coreference Resolution in Knowledge Graphs", "abstract": "Coreference resolution across multiple documents poses a significant\nchallenge in natural language processing, particularly within the domain of\nknowledge graphs. This study introduces an innovative method aimed at\nidentifying and resolving references to the same entities that appear across\ndiffering texts, thus enhancing the coherence and collaboration of information.\nOur method employs a dynamic linking mechanism that associates entities in the\nknowledge graph with their corresponding textual mentions. By utilizing\ncontextual embeddings along with graph-based inference strategies, we\neffectively capture the relationships and interactions among entities, thereby\nimproving the accuracy of coreference resolution. Rigorous evaluations on\nvarious benchmark datasets highlight notable advancements in our approach over\ntraditional methodologies. The results showcase how the contextual information\nderived from knowledge graphs enhances the understanding of complex\nrelationships across documents, leading to better entity linking and\ninformation extraction capabilities in applications driven by knowledge. Our\ntechnique demonstrates substantial improvements in both precision and recall,\nunderscoring its effectiveness in the area of cross-document coreference\nresolution.", "published": "2025-04-08 07:47:07", "link": "http://arxiv.org/abs/2504.05767v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Probabilistic Process Discovery with Stochastic Process Trees", "abstract": "In order to obtain a stochastic model that accounts for the stochastic\naspects of the dynamics of a business process, usually the following steps are\ntaken. Given an event log, a process tree is obtained through a process\ndiscovery algorithm, i.e., a process tree that is aimed at reproducing, as\naccurately as possible, the language of the log. The process tree is then\ntransformed into a Petri net that generates the same set of sequences as the\nprocess tree. In order to capture the frequency of the sequences in the event\nlog, weights are assigned to the transitions of the Petri net, resulting in a\nstochastic Petri net with a stochastic language in which each sequence is\nassociated with a probability. In this paper we show that this procedure has\nunfavorable properties. First, the weights assigned to the transitions of the\nPetri net have an unclear role in the resulting stochastic language. We will\nshow that a weight can have multiple, ambiguous impact on the probability of\nthe sequences generated by the Petri net. Second, a number of different Petri\nnets with different number of transitions can correspond to the same process\ntree. This means that the number of parameters (the number of weights) that\ndetermines the stochastic language is not well-defined. In order to avoid these\nambiguities, in this paper, we propose to add stochasticity directly to process\ntrees. The result is a new formalism, called stochastic process trees, in which\nthe number of parameters and their role in the associated stochastic language\nis clear and well-defined.", "published": "2025-04-08 07:46:06", "link": "http://arxiv.org/abs/2504.05765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Layer-Aware Embedding Fusion for LLMs in Text Classifications", "abstract": "Embedding fusion has emerged as an effective approach for enhancing\nperformance across various NLP tasks. However, systematic guidelines for\nselecting optimal layers and developing effective fusion strategies for the\nintegration of LLMs remain underexplored. In this study, we propose a\nlayer-aware embedding selection method and investigate how to quantitatively\nevaluate different layers to identify the most important ones for downstream\nNLP tasks, showing that the critical layers vary depending on the dataset. We\nalso explore how combining embeddings from multiple LLMs, without requiring\nmodel fine-tuning, can improve performance. Experiments on four English text\nclassification datasets (SST-2, MR, R8, and R52) demonstrate that different\nlayers in LLMs exhibit varying degrees of representational strength for\nclassification, and that combining embeddings from different models can enhance\nperformance if the models exhibit complementary characteristics. Additionally,\nwe discuss resources overhead (memory and inference time) to provide a balanced\nperspective on the real world feasibility of embedding fusion. Future work will\nexplore multilingual and domain specific datasets, as well as techniques for\nautomating layer selection, to improve both performance and scalability.", "published": "2025-04-08 07:45:50", "link": "http://arxiv.org/abs/2504.05764v1", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "RETROcode: Leveraging a Code Database for Improved Natural Language to Code Generation", "abstract": "As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.", "published": "2025-04-08 07:41:13", "link": "http://arxiv.org/abs/2504.05759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SEA-LION: Southeast Asian Languages in One Network", "abstract": "Recently, Large Language Models (LLMs) have dominated much of the artificial\nintelligence scene with their ability to process and generate natural\nlanguages. However, the majority of LLM research and development remains\nEnglish-centric, leaving low-resource languages such as those in the Southeast\nAsian (SEA) region under-represented. To address this representation gap, we\nintroduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge\nmultilingual LLMs designed for SEA languages. The SEA-LION family of LLMs\nsupports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese,\nMalay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages\nlarge-scale multilingual continued pre-training with a comprehensive\npost-training regime involving multiple stages of instruction fine-tuning,\nalignment, and model merging. Evaluation results on multilingual benchmarks\nindicate that our models achieve state-of-the-art performance across LLMs\nsupporting SEA languages. We open-source the models to benefit the wider SEA\ncommunity.", "published": "2025-04-08 07:24:51", "link": "http://arxiv.org/abs/2504.05747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rank-Then-Score: Enhancing Large Language Models for Automated Essay Scoring", "abstract": "In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.", "published": "2025-04-08 07:10:51", "link": "http://arxiv.org/abs/2504.05736v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM$\\times$MapReduce-V2: Entropy-Driven Convolutional Test-Time Scaling for Generating Long-Form Articles from Extremely Long Resources", "abstract": "Long-form generation is crucial for a wide range of practical applications,\ntypically categorized into short-to-long and long-to-long generation. While\nshort-to-long generations have received considerable attention, generating long\ntexts from extremely long resources remains relatively underexplored. The\nprimary challenge in long-to-long generation lies in effectively integrating\nand analyzing relevant information from extensive inputs, which remains\ndifficult for current large language models (LLMs). In this paper, we propose\nLLM$\\times$MapReduce-V2, a novel test-time scaling strategy designed to enhance\nthe ability of LLMs to process extremely long inputs. Drawing inspiration from\nconvolutional neural networks, which iteratively integrate local features into\nhigher-level global representations, LLM$\\times$MapReduce-V2 utilizes stacked\nconvolutional scaling layers to progressively expand the understanding of input\nmaterials. Both quantitative and qualitative experimental results demonstrate\nthat our approach substantially enhances the ability of LLMs to process long\ninputs and generate coherent, informative long-form articles, outperforming\nseveral representative baselines.", "published": "2025-04-08 07:03:48", "link": "http://arxiv.org/abs/2504.05732v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation", "abstract": "Recently, the personalization of Large Language Models (LLMs) to generate\ncontent that aligns with individual user preferences has garnered widespread\nattention. Personalized Retrieval-Augmented Generation (RAG), which retrieves\nrelevant documents from the user's history to reflect their preferences and\nenhance LLM generation, is one commonly used approach for personalization.\nHowever, existing personalized RAG methods do not consider that the histories\nof similar users can also assist in personalized generation for the current\nuser, meaning that collaborative information between users can also benefit\npersonalized generation. Inspired by the application of collaborative filtering\nin recommender systems, we propose a method called CFRAG, which adapts\nCollaborative Filtering to RAG for personalized text generation. However, this\npresents two challenges: (1)~how to incorporate collaborative information\nwithout explicit user similarity labels? (2)~how to retrieve documents that\nsupport personalized LLM generation? For Challenge 1, we use contrastive\nlearning to train user embeddings to retrieve similar users and introduce\ncollaborative information. For Challenge 2, we design a personalized retriever\nand reranker to retrieve the top-$k$ documents from these users' histories. We\ntake into account the user's preference during retrieval and reranking. Then we\nleverage feedback from the LLM to fine-tune the personalized retriever and\nreranker, enabling them to retrieve documents that meet the personalized\ngeneration needs of the LLM. Experimental results on the Language Model\nPersonalization (LaMP) benchmark validate the effectiveness of CFRAG. Further\nanalysis confirms the importance of incorporating collaborative information.", "published": "2025-04-08 07:03:36", "link": "http://arxiv.org/abs/2504.05731v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Evaluating Speech-to-Text Systems with PennSound", "abstract": "A random sample of nearly 10 hours of speech from PennSound, the world's\nlargest online collection of poetry readings and discussions, was used as a\nbenchmark to evaluate several commercial and open-source speech-to-text\nsystems. PennSound's wide variation in recording conditions and speech styles\nmakes it a good representative for many other untranscribed audio collections.\nReference transcripts were created by trained annotators, and system\ntranscripts were produced from AWS, Azure, Google, IBM, NeMo, Rev.ai, Whisper,\nand Whisper.cpp. Based on word error rate, Rev.ai was the top performer, and\nWhisper was the top open source performer (as long as hallucinations were\navoided). AWS had the best diarization error rates among three systems.\nHowever, WER and DER differences were slim, and various tradeoffs may motivate\nchoosing different systems for different end users. We also examine the issue\nof hallucinations in Whisper. Users of Whisper should be cautioned to be aware\nof runtime options, and whether the speed vs accuracy trade off is acceptable.", "published": "2025-04-08 05:49:53", "link": "http://arxiv.org/abs/2504.05702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STRIVE: A Think & Improve Approach with Iterative Refinement for Enhancing Question Quality Estimation", "abstract": "Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.", "published": "2025-04-08 05:34:38", "link": "http://arxiv.org/abs/2504.05693v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Separator Injection Attack: Uncovering Dialogue Biases in Large Language Models Caused by Role Separators", "abstract": "Conversational large language models (LLMs) have gained widespread attention\ndue to their instruction-following capabilities. To ensure conversational LLMs\nfollow instructions, role separators are employed to distinguish between\ndifferent participants in a conversation. However, incorporating role\nseparators introduces potential vulnerabilities. Misusing roles can lead to\nprompt injection attacks, which can easily misalign the model's behavior with\nthe user's intentions, raising significant security concerns. Although various\nprompt injection attacks have been proposed, recent research has largely\noverlooked the impact of role separators on safety. This highlights the\ncritical need to thoroughly understand the systemic weaknesses in dialogue\nsystems caused by role separators. This paper identifies modeling weaknesses\ncaused by role separators. Specifically, we observe a strong positional bias\nassociated with role separators, which is inherent in the format of dialogue\nmodeling and can be triggered by the insertion of role separators. We further\ndevelop the Separators Injection Attack (SIA), a new orthometric attack based\non role separators. The experiment results show that SIA is efficient and\nextensive in manipulating model behavior with an average gain of 18.2% for\nmanual methods and enhances the attack success rate to 100% with automatic\nmethods.", "published": "2025-04-08 05:20:56", "link": "http://arxiv.org/abs/2504.05689v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs Ready for HR Spoken Interview Transcript Analysis?", "abstract": "This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.", "published": "2025-04-08 04:46:10", "link": "http://arxiv.org/abs/2504.05683v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking", "abstract": "Large Language Models (LLMs) have become increasingly integral to a wide\nrange of applications. However, they still remain the threat of jailbreak\nattacks, where attackers manipulate designed prompts to make the models elicit\nmalicious outputs. Analyzing jailbreak methods can help us delve into the\nweakness of LLMs and improve it. In this paper, We reveal a vulnerability in\nlarge language models (LLMs), which we term Defense Threshold Decay (DTD), by\nanalyzing the attention weights of the model's output on input and subsequent\noutput on prior output: as the model generates substantial benign content, its\nattention weights shift from the input to prior output, making it more\nsusceptible to jailbreak attacks. To demonstrate the exploitability of DTD, we\npropose a novel jailbreak attack method, Sugar-Coated Poison (SCP), which\ninduces the model to generate substantial benign content through benign input\nand adversarial reasoning, subsequently producing malicious content. To\nmitigate such attacks, we introduce a simple yet effective defense strategy,\nPOSD, which significantly reduces jailbreak success rates while preserving the\nmodel's generalization capabilities.", "published": "2025-04-08 03:57:09", "link": "http://arxiv.org/abs/2504.05652v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using Large Language Models", "abstract": "We propose a novel three-step prompt-tuning method for Bengali Grammatical\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\nidentifying and categorizing grammatical errors in Bengali sentences,\ngenerating corrected versions of the sentences, and providing natural language\nexplanations for each identified error. We evaluate the performance of our BGEE\nsystem using both automated evaluation metrics and human evaluation conducted\nby experienced Bengali language experts. Our proposed prompt-tuning approach\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\nimprovement in exact match. Furthermore, compared to the previous baseline,\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\n26.27% in wrong error explanation. However, the results still lag behind the\nhuman baseline.", "published": "2025-04-08 03:38:01", "link": "http://arxiv.org/abs/2504.05642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DBOT: Artificial Intelligence for Systematic Long-Term Investing", "abstract": "Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.", "published": "2025-04-08 03:34:22", "link": "http://arxiv.org/abs/2504.05639v1", "categories": ["cs.CL", "cs.AI", "q-fin.PR"], "primary_category": "cs.CL"}
{"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "abstract": "Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.", "published": "2025-04-08 03:21:51", "link": "http://arxiv.org/abs/2504.05632v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement", "abstract": "Recent research has shown that large language models (LLMs) can enhance\ntranslation quality through self-refinement. In this paper, we build on this\nidea by extending the refinement from sentence-level to document-level\ntranslation, specifically focusing on document-to-document (Doc2Doc)\ntranslation refinement. Since sentence-to-sentence (Sent2Sent) and Doc2Doc\ntranslation address different aspects of the translation process, we propose\nfine-tuning LLMs for translation refinement using two intermediate\ntranslations, combining the strengths of both Sent2Sent and Doc2Doc.\nAdditionally, recognizing that the quality of intermediate translations varies,\nwe introduce an enhanced fine-tuning method with quality awareness that assigns\nlower weights to easier translations and higher weights to more difficult ones,\nenabling the model to focus on challenging translation cases. Experimental\nresults across ten translation tasks with LLaMA-3-8B-Instruct and\nMistral-Nemo-Instruct demonstrate the effectiveness of our approach.", "published": "2025-04-08 02:08:07", "link": "http://arxiv.org/abs/2504.05614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction", "abstract": "Extractive reading comprehension systems are designed to locate the correct\nanswer to a question within a given text. However, a persistent challenge lies\nin ensuring these models maintain high accuracy in answering questions while\nreliably recognizing unanswerable queries. Despite significant advances in\nlarge language models (LLMs) for reading comprehension, this issue remains\ncritical, particularly as the length of supported contexts continues to expand.\nTo address this challenge, we propose an innovative data augmentation\nmethodology grounded in a multi-agent collaborative framework. Unlike\ntraditional methods, such as the costly human annotation process required for\ndatasets like SQuAD 2.0, our method autonomously generates evidence-based\nquestion-answer pairs and systematically constructs unanswerable questions.\nUsing this methodology, we developed the FactGuard-Bench dataset, which\ncomprises 25,220 examples of both answerable and unanswerable question\nscenarios, with context lengths ranging from 8K to 128K. Experimental\nevaluations conducted on seven popular LLMs reveal that even the most advanced\nmodels achieve only 61.79% overall accuracy. Furthermore, we emphasize the\nimportance of a model's ability to reason about unanswerable questions to avoid\ngenerating plausible but incorrect answers. By implementing efficient data\nselection and generation within the multi-agent collaborative framework, our\nmethod significantly reduces the traditionally high costs associated with\nmanual annotation and provides valuable insights for the training and\noptimization of LLMs.", "published": "2025-04-08 01:45:16", "link": "http://arxiv.org/abs/2504.05607v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ShadowCoT: Cognitive Hijacking for Stealthy Reasoning Backdoors in LLMs", "abstract": "Chain-of-Thought (CoT) enhances an LLM's ability to perform complex reasoning\ntasks, but it also introduces new security issues. In this work, we present\nShadowCoT, a novel backdoor attack framework that targets the internal\nreasoning mechanism of LLMs. Unlike prior token-level or prompt-based attacks,\nShadowCoT directly manipulates the model's cognitive reasoning path, enabling\nit to hijack multi-step reasoning chains and produce logically coherent but\nadversarial outcomes. By conditioning on internal reasoning states, ShadowCoT\nlearns to recognize and selectively disrupt key reasoning steps, effectively\nmounting a self-reflective cognitive attack within the target model. Our\napproach introduces a lightweight yet effective multi-stage injection pipeline,\nwhich selectively rewires attention pathways and perturbs intermediate\nrepresentations with minimal parameter overhead (only 0.15% updated). ShadowCoT\nfurther leverages reinforcement learning and reasoning chain pollution (RCP) to\nautonomously synthesize stealthy adversarial CoTs that remain undetectable to\nadvanced defenses. Extensive experiments across diverse reasoning benchmarks\nand LLMs show that ShadowCoT consistently achieves high Attack Success Rate\n(94.4%) and Hijacking Success Rate (88.4%) while preserving benign performance.\nThese results reveal an emergent class of cognition-level threats and highlight\nthe urgent need for defenses beyond shallow surface-level consistency.", "published": "2025-04-08 01:36:16", "link": "http://arxiv.org/abs/2504.05605v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "On the Impact of Language Nuances on Sentiment Analysis with Large Language Models: Paraphrasing, Sarcasm, and Emojis", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, including sentiment analysis. However, data\nquality--particularly when sourced from social media--can significantly impact\ntheir accuracy. This research explores how textual nuances, including emojis\nand sarcasm, affect sentiment analysis, with a particular focus on improving\ndata quality through text paraphrasing techniques. To address the lack of\nlabeled sarcasm data, the authors created a human-labeled dataset of 5929\ntweets that enabled the assessment of LLM in various sarcasm contexts. The\nresults show that when topic-specific datasets, such as those related to\nnuclear power, are used to finetune LLMs these models are not able to\ncomprehend accurate sentiment in presence of sarcasm due to less diverse text,\nrequiring external interventions like sarcasm removal to boost model accuracy.\nSarcasm removal led to up to 21% improvement in sentiment accuracy, as LLMs\ntrained on nuclear power-related content struggled with sarcastic tweets,\nachieving only 30% accuracy. In contrast, LLMs trained on general tweet\ndatasets, covering a broader range of topics, showed considerable improvements\nin predicting sentiment for sarcastic tweets (60% accuracy), indicating that\nincorporating general text data can enhance sarcasm detection. The study also\nutilized adversarial text augmentation, showing that creating synthetic text\nvariants by making minor changes significantly increased model robustness and\naccuracy for sarcastic tweets (approximately 85%). Additionally, text\nparaphrasing of tweets with fragmented language transformed around 40% of the\ntweets with low-confidence labels into high-confidence ones, improving LLMs\nsentiment analysis accuracy by 6%.", "published": "2025-04-08 01:29:58", "link": "http://arxiv.org/abs/2504.05603v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought", "abstract": "We introduce Skywork R1V, a multimodal reasoning model extending the an\nR1-series Large language models (LLM) to visual modalities via an efficient\nmultimodal transfer method. Leveraging a lightweight visual projector, Skywork\nR1V facilitates seamless multimodal adaptation without necessitating retraining\nof either the foundational language model or the vision encoder. To strengthen\nvisual-text alignment, we propose a hybrid optimization strategy that combines\nIterative Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization\n(GRPO), significantly enhancing cross-modal integration efficiency.\nAdditionally, we introduce an adaptive-length Chain-of-Thought distillation\napproach for reasoning data generation. This approach dynamically optimizes\nreasoning chain lengths, thereby enhancing inference efficiency and preventing\nexcessive reasoning overthinking. Empirical evaluations demonstrate that\nSkywork R1V, with only 38B parameters, delivers competitive performance,\nachieving a score of 69.0 on the MMMU benchmark and 67.5 on MathVista.\nMeanwhile, it maintains robust textual reasoning performance, evidenced by\nimpressive scores of 72.0 on AIME and 94.0 on MATH500. The Skywork R1V model\nweights have been publicly released to promote openness and reproducibility.", "published": "2025-04-08 01:19:20", "link": "http://arxiv.org/abs/2504.05599v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DEL: Context-Aware Dynamic Exit Layer for Efficient Self-Speculative Decoding", "abstract": "Speculative Decoding (SD) is a widely used approach to accelerate the\ninference of large language models (LLMs) without reducing generation quality.\nIt operates by first using a compact model to draft multiple tokens\nefficiently, followed by parallel verification using the target LLM. This\napproach leads to faster inference compared to auto-regressive decoding. While\nthere are multiple approaches to create a draft model, one promising approach\nis to use early-exit methods. These methods draft candidate tokens by using a\nsubset of layers of the primary model and applying the remaining layers for\nverification, allowing a single model to handle both drafting and verification.\nWhile this technique reduces memory usage and computational cost, its\nperformance relies on the choice of the exit layer for drafting and the number\nof tokens drafted (speculation length) in each SD round. Prior works use\nhyperparameter exploration to statically select these values. However, our\nevaluations show that these hyperparameter values are task-specific, and even\nwithin a task they are dependent on the current sequence context. We introduce\nDEL, a plug-and-play method that adaptively selects the exit layer and\nspeculation length during inference. DEL dynamically tracks the token\nacceptance rate if the tokens are drafted at each layer of an LLM and uses that\nknowledge to heuristically select the optimal exit layer and speculation\nlength. Our experiments across a broad range of models and downstream tasks\nshow that DEL achieves overall speedups of $2.16\\times$$\\sim$$2.50\\times$ over\nvanilla auto-regressive decoding and improves upon the state-of-the-art SD\nmethods by up to $0.27\\times$.", "published": "2025-04-08 01:12:59", "link": "http://arxiv.org/abs/2504.05598v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions", "abstract": "While Large Language Models (LLMs) acquire vast knowledge during\npre-training, they often lack domain-specific, new, or niche information.\nContinual pre-training (CPT) attempts to address this gap but suffers from\ncatastrophic forgetting and inefficiencies in low-data regimes. We introduce\nKnowledge-Instruct, a novel approach to efficiently inject knowledge from\nlimited corpora through pure instruction-tuning. By generating\ninformation-dense synthetic instruction data, it effectively integrates new\nknowledge while preserving general reasoning and instruction-following\nabilities. Knowledge-Instruct demonstrates superior factual memorization,\nminimizes catastrophic forgetting, and remains scalable by leveraging synthetic\ndata from relatively small language models. Additionally, it enhances\ncontextual understanding, including complex multi-hop reasoning, facilitating\nintegration with retrieval systems. We validate its effectiveness across\ndiverse benchmarks, including Companies, a new dataset that we release to\nmeasure knowledge injection capabilities.", "published": "2025-04-08 00:00:36", "link": "http://arxiv.org/abs/2504.05571v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization", "abstract": "Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.", "published": "2025-04-08 17:59:57", "link": "http://arxiv.org/abs/2504.06265v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis", "abstract": "Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.", "published": "2025-04-08 17:32:56", "link": "http://arxiv.org/abs/2504.06235v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An experimental survey and Perspective View on Meta-Learning for Automated Algorithms Selection and Parametrization", "abstract": "Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.", "published": "2025-04-08 16:51:22", "link": "http://arxiv.org/abs/2504.06207v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction", "abstract": "Link prediction is a crucial graph-learning task with applications including\ncitation prediction and product recommendation. Distilling Graph Neural\nNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has\nemerged as an effective approach to achieve strong performance and reducing\ncomputational cost by removing graph dependency. However, existing distillation\nmethods only use standard GNNs and overlook alternative teachers such as\nspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,\ncommon neighbors). This paper first explores the impact of different teachers\nin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not\nalways produce stronger students: MLPs distilled from GNN4LP can underperform\nthose distilled from simpler GNNs, while weaker heuristic methods can teach\nMLPs to near-GNN performance with drastically reduced training costs. Building\non these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which\neliminates graph dependencies while effectively integrating complementary\nsignals via a gating mechanism. Experiments on ten datasets show an average\n7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less\ntraining time, indicating EHDM is an efficient and effective link prediction\nmethod.", "published": "2025-04-08 16:35:11", "link": "http://arxiv.org/abs/2504.06193v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care", "abstract": "Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.", "published": "2025-04-08 16:25:59", "link": "http://arxiv.org/abs/2504.06185v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Self-Supervised Framework for Space Object Behaviour Characterisation", "abstract": "Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.", "published": "2025-04-08 16:19:19", "link": "http://arxiv.org/abs/2504.06176v1", "categories": ["cs.LG", "cs.AI", "physics.space-ph"], "primary_category": "cs.LG"}
{"title": "Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep Learning", "abstract": "Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.", "published": "2025-04-08 16:18:00", "link": "http://arxiv.org/abs/2504.06173v1", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Real-Time Pitch/F0 Detection Using Spectrogram Images and Convolutional Neural Networks", "abstract": "This paper presents a novel approach to detect F0 through Convolutional\nNeural Networks and image processing techniques to directly estimate pitch from\nspectrogram images. Our new approach demonstrates a very good detection\naccuracy; a total of 92% of predicted pitch contours have strong or moderate\ncorrelations to the true pitch contours. Furthermore, the experimental\ncomparison between our new approach and other state-of-the-art CNN methods\nreveals that our approach can enhance the detection rate by approximately 5%\nacross various Signal-to-Noise Ratio conditions.", "published": "2025-04-08 16:01:25", "link": "http://arxiv.org/abs/2504.06165v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using LLMs", "abstract": "Software requirements expressed in natural language (NL) frequently suffer\nfrom verbosity, ambiguity, and inconsistency. This creates a range of\nchallenges, including selecting an appropriate architecture for a system and\nassessing different architectural alternatives. Relying on human expertise to\naccomplish the task of mapping NL requirements to architecture is\ntime-consuming and error-prone. This paper proposes ARLO, an approach that\nautomates this task by leveraging (1) a set of NL requirements for a system,\n(2) an existing standard that specifies architecturally relevant software\nquality attributes, and (3) a readily available Large Language Model (LLM).\nSpecifically, ARLO determines the subset of NL requirements for a given system\nthat is architecturally relevant and maps that subset to a tailorable matrix of\narchitectural choices. ARLO applies integer linear programming on the\narchitectural-choice matrix to determine the optimal architecture for the\ncurrent requirements. We demonstrate ARLO's efficacy using a set of real-world\nexamples. We highlight ARLO's ability (1) to trace the selected architectural\nchoices to the requirements and (2) to isolate NL requirements that exert a\nparticular influence on a system's architecture. This allows the\nidentification, comparative assessment, and exploration of alternative\narchitectural choices based on the requirements and constraints expressed\ntherein.", "published": "2025-04-08 15:38:42", "link": "http://arxiv.org/abs/2504.06143v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A Multimedia Analytics Model for the Foundation Model Era", "abstract": "The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.", "published": "2025-04-08 15:35:59", "link": "http://arxiv.org/abs/2504.06138v1", "categories": ["cs.MM", "cs.AI", "cs.HC"], "primary_category": "cs.MM"}
{"title": "Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning", "abstract": "Retrieval-Augmented Generation (RAG) and vector-based search have become\nfoundational tools for memory in AI systems, yet they struggle with\nabstraction, scalability, and semantic precision - especially in decentralized\nenvironments. We present SHIMI (Semantic Hierarchical Memory Index), a unified\narchitecture that models knowledge as a dynamically structured hierarchy of\nconcepts, enabling agents to retrieve information based on meaning rather than\nsurface similarity. SHIMI organizes memory into layered semantic nodes and\nsupports top-down traversal from abstract intent to specific entities, offering\nmore precise and explainable retrieval. Critically, SHIMI is natively designed\nfor decentralized ecosystems, where agents maintain local memory trees and\nsynchronize them asynchronously across networks. We introduce a lightweight\nsync protocol that leverages Merkle-DAG summaries, Bloom filters, and\nCRDT-style conflict resolution to enable partial synchronization with minimal\noverhead. Through benchmark experiments and use cases involving decentralized\nagent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy,\nsemantic fidelity, and scalability - positioning it as a core infrastructure\nlayer for decentralized cognitive systems.", "published": "2025-04-08 15:31:00", "link": "http://arxiv.org/abs/2504.06135v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning", "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have\nhighlighted the potential of formal reasoning with Lean 4 codes. However, ATP\nhas not yet be revolutionized by the recent posttraining scaling as\ndemonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the\nentire posttraining of ATP, aiming to align it with breakthroughs in reasoning\nmodels in natural languages.To begin, we continual train current ATP models\nwith a hybrid dataset, which consists of numerous statement-proof pairs, and\nadditional data aimed at incorporating cognitive behaviors that emulate human\nreasoning and hypothesis refinement. Next, we explore reinforcement learning\nwith the use of outcome reward returned by Lean 4 compiler. Through our\ndesigned continual training and reinforcement learning processes, we have\nsuccessfully improved existing formal provers, including both\nDeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance\nin the field of whole-proof generation. For example, we achieve a 59.8% pass\nrate (pass@32) on MiniF2F. This is an on-going project and we will\nprogressively update our findings, release our data and training details.", "published": "2025-04-08 15:15:26", "link": "http://arxiv.org/abs/2504.06122v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle Sideslip Angle Estimation", "abstract": "Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.", "published": "2025-04-08 14:49:58", "link": "http://arxiv.org/abs/2504.06105v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Towards Varroa destructor mite detection using a narrow spectra illumination", "abstract": "This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.", "published": "2025-04-08 14:41:42", "link": "http://arxiv.org/abs/2504.06099v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Real-Time LaCAM", "abstract": "The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.", "published": "2025-04-08 14:31:05", "link": "http://arxiv.org/abs/2504.06091v1", "categories": ["cs.MA", "cs.AI", "cs.RO"], "primary_category": "cs.MA"}
{"title": "MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer", "abstract": "Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.", "published": "2025-04-08 14:29:15", "link": "http://arxiv.org/abs/2504.06088v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Information-Theoretic Reward Decomposition for Generalizable RLHF", "abstract": "A generalizable reward model is crucial in Reinforcement Learning from Human\nFeedback (RLHF) as it enables correctly evaluating unseen prompt-response\npairs. However, existing reward models lack this ability, as they are typically\ntrained by increasing the reward gap between chosen and rejected responses,\nwhile overlooking the prompts that the responses are conditioned on.\nConsequently, when the trained reward model is evaluated on prompt-response\npairs that lie outside the data distribution, neglecting the effect of prompts\nmay result in poor generalization of the reward model. To address this issue,\nwe decompose the reward value into two independent components: prompt-free\nreward and prompt-related reward. Prompt-free reward represents the evaluation\nthat is determined only by responses, while the prompt-related reward reflects\nthe reward that derives from both the prompt and the response. We extract these\ntwo components from an information-theoretic perspective, which requires no\nextra models. Subsequently, we propose a new reward learning algorithm by\nprioritizing data samples based on their prompt-free reward values. Through toy\nexamples, we demonstrate that the extracted prompt-free and prompt-related\nrewards effectively characterize two parts of the reward model. Further,\nstandard evaluations show that our method improves both the alignment\nperformance and the generalization capability of the reward model.", "published": "2025-04-08 13:26:07", "link": "http://arxiv.org/abs/2504.06020v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform", "abstract": "AI development is shaped by academics and industry leaders - let us call them\n``influencers'' - but it is unclear how their views align with those of the\npublic. To address this gap, we developed an interactive platform that served\nas a data collection tool for exploring public views on AI, including their\nfears, hopes, and overall sense of hopefulness. We made the platform available\nto 330 participants representative of the U.S. population in terms of age, sex,\nethnicity, and political leaning, and compared their views with those of 100 AI\ninfluencers identified by Time magazine. The public fears AI getting out of\ncontrol, while influencers emphasize regulation, seemingly to deflect attention\nfrom their alleged focus on monetizing AI's potential. Interestingly, the views\nof AI influencers from underrepresented groups such as women and people of\ncolor often differ from the views of underrepresented groups in the public.", "published": "2025-04-08 13:21:31", "link": "http://arxiv.org/abs/2504.06016v1", "categories": ["cs.HC", "cs.AI", "I.2; K.4.1; K.4.2; K.4.3"], "primary_category": "cs.HC"}
{"title": "Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?", "abstract": "Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.", "published": "2025-04-08 13:15:47", "link": "http://arxiv.org/abs/2504.06006v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Temporal Alignment-Free Video Matching for Few-shot Action Recognition", "abstract": "Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.", "published": "2025-04-08 12:11:11", "link": "http://arxiv.org/abs/2504.05956v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Representing Normative Regulations in OWL DL for Automated Compliance Checking Supported by Text Annotation", "abstract": "Compliance checking is the process of determining whether a regulated entity\nadheres to these regulations. Currently, compliance checking is predominantly\nmanual, requiring significant time and highly skilled experts, while still\nbeing prone to errors caused by the human factor. Various approaches have been\nexplored to automate compliance checking, however, representing regulations in\nOWL DL language which enables compliance checking through OWL reasoning has not\nbeen adopted. In this work, we propose an annotation schema and an algorithm\nthat transforms text annotations into machine-interpretable OWL DL code. The\nproposed approach is validated through a proof-of-concept implementation\napplied to examples from the building construction domain.", "published": "2025-04-08 12:05:21", "link": "http://arxiv.org/abs/2504.05951v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems", "abstract": "Improving decision-making capabilities in Autonomous Intelligent Vehicles\n(AIVs) has been a heated topic in recent years. Despite advancements, training\nmachines to capture regions of interest for comprehensive scene understanding,\nlike human perception and reasoning, remains a significant challenge. This\nstudy introduces a novel framework, Human Attention-based Explainable Guidance\nfor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,\nconverted from eye-tracking, to guide reinforcement learning (RL) models to\nidentify critical regions of interest for decision-making. AEGIS uses a\npre-trained human attention model to guide RL models to identify critical\nregions of interest for decision-making. By collecting 1.2 million frames from\n20 participants across six scenarios, AEGIS pre-trains a model to predict human\nattention patterns.", "published": "2025-04-08 12:04:52", "link": "http://arxiv.org/abs/2504.05950v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CKGAN: Training Generative Adversarial Networks Using Characteristic Kernel Integral Probability Metrics", "abstract": "In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.", "published": "2025-04-08 11:58:56", "link": "http://arxiv.org/abs/2504.05945v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Uncovering Fairness through Data Complexity as an Early Indicator", "abstract": "Fairness constitutes a concern within machine learning (ML) applications.\nCurrently, there is no study on how disparities in classification complexity\nbetween privileged and unprivileged groups could influence the fairness of\nsolutions, which serves as a preliminary indicator of potential unfairness. In\nthis work, we investigate this gap, specifically, we focus on synthetic\ndatasets designed to capture a variety of biases ranging from historical bias\nto measurement and representational bias to evaluate how various complexity\nmetrics differences correlate with group fairness metrics. We then apply\nassociation rule mining to identify patterns that link disproportionate\ncomplexity differences between groups with fairness-related outcomes, offering\ndata-centric indicators to guide bias mitigation. Our findings are also\nvalidated by their application in real-world problems, providing evidence that\nquantifying group-wise classification complexity can uncover early indicators\nof potential fairness challenges. This investigation helps practitioners to\nproactively address bias in classification tasks.", "published": "2025-04-08 11:28:40", "link": "http://arxiv.org/abs/2504.05923v1", "categories": ["cs.LG", "cs.AI", "cs.DS"], "primary_category": "cs.LG"}
{"title": "PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario", "abstract": "Driving scene understanding is a critical real-world problem that involves\ninterpreting and associating various elements of a driving environment, such as\nvehicles, pedestrians, and traffic signals. Despite advancements in autonomous\ndriving, traditional pipelines rely on deterministic models that fail to\ncapture the probabilistic nature and inherent uncertainty of real-world\ndriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-aware\nmodel for object interaction and Chain-of-Thought (CoT) reasoning in driving\nscenarios. In particular, our approach combines LiDAR-based 3D object detection\nwith multi-view RGB references to ensure interpretable and reliable scene\nunderstanding. Uncertainty and risk assessment, along with object interactions,\nare modelled using Bayesian Graph Neural Networks (BGNNs) for probabilistic\nreasoning under ambiguous conditions. Interpretable decisions are facilitated\nthrough CoT reasoning, leveraging object dynamics and contextual cues, while\nGrad-CAM visualizations highlight attention regions. Extensive evaluations on\nthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperforms\nstate-of-the-art CoT and risk-aware models.", "published": "2025-04-08 11:06:02", "link": "http://arxiv.org/abs/2504.05908v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques", "abstract": "3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.", "published": "2025-04-08 10:17:14", "link": "http://arxiv.org/abs/2504.05882v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Systematic Parameter Decision in Approximate Model Counting", "abstract": "This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.", "published": "2025-04-08 09:58:41", "link": "http://arxiv.org/abs/2504.05874v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Agent Guide: A Simple Agent Behavioral Watermarking Framework", "abstract": "The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.", "published": "2025-04-08 09:54:49", "link": "http://arxiv.org/abs/2504.05871v1", "categories": ["cs.AI", "K.6.5"], "primary_category": "cs.AI"}
{"title": "Towards an AI-Driven Video-Based American Sign Language Dictionary: Exploring Design and Usage Experience with Learners", "abstract": "Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.", "published": "2025-04-08 09:35:46", "link": "http://arxiv.org/abs/2504.05857v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Physics-aware generative models for turbulent fluid flows through energy-consistent stochastic interpolants", "abstract": "Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.", "published": "2025-04-08 09:29:01", "link": "http://arxiv.org/abs/2504.05852v1", "categories": ["cs.CE", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.CE"}
{"title": "PathGPT: Leveraging Large Language Models for Personalized Route Generation", "abstract": "The proliferation of GPS enabled devices has led to the accumulation of a\nsubstantial corpus of historical trajectory data. By leveraging these data for\ntraining machine learning models,researchers have devised novel data-driven\nmethodologies that address the personalized route recommendation (PRR) problem.\nIn contrast to conventional algorithms such as Dijkstra shortest path\nalgorithm,these novel algorithms possess the capacity to discern and learn\npatterns within the data,thereby facilitating the generation of more\npersonalized paths. However,once these models have been trained,their\napplication is constrained to the generation of routes that align with their\ntraining patterns. This limitation renders them less adaptable to novel\nscenarios and the deployment of multiple machine learning models might be\nnecessary to address new possible scenarios,which can be costly as each model\nmust be trained separately. Inspired by recent advances in the field of Large\nLanguage Models (LLMs),we leveraged their natural language understanding\ncapabilities to develop a unified model to solve the PRR problem while being\nseamlessly adaptable to new scenarios without additional training. To\naccomplish this,we combined the extensive knowledge LLMs acquired during\ntraining with further access to external hand-crafted context\ninformation,similar to RAG (Retrieved Augmented Generation) systems,to enhance\ntheir ability to generate paths according to user-defined requirements.\nExtensive experiments on different datasets show a considerable uplift in LLM\nperformance on the PRR problem.", "published": "2025-04-08 09:25:21", "link": "http://arxiv.org/abs/2504.05846v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments", "abstract": "Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging", "published": "2025-04-08 09:21:39", "link": "http://arxiv.org/abs/2504.05840v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking", "abstract": "Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.", "published": "2025-04-08 09:20:29", "link": "http://arxiv.org/abs/2504.05838v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset", "abstract": "Human Activity Recognition (HAR) primarily relied on traditional RGB cameras\nto achieve high-performance activity recognition. However, the challenging\nfactors in real-world scenarios, such as insufficient lighting and rapid\nmovements, inevitably degrade the performance of RGB cameras. To address these\nchallenges, biologically inspired event cameras offer a promising solution to\novercome the limitations of traditional RGB cameras. In this work, we rethink\nhuman activity recognition by combining the RGB and event cameras. The first\ncontribution is the proposed large-scale multi-modal RGB-Event human activity\nrecognition benchmark dataset, termed HARDVS 2.0, which bridges the dataset\ngaps. It contains 300 categories of everyday real-world actions with a total of\n107,646 paired videos covering various challenging scenarios. Inspired by the\nphysics-informed heat conduction model, we propose a novel multi-modal heat\nconduction operation framework for effective activity recognition, termed\nMMHCO-HAR. More in detail, given the RGB frames and event streams, we first\nextract the feature embeddings using a stem network. Then, multi-modal Heat\nConduction blocks are designed to fuse the dual features, the key module of\nwhich is the multi-modal Heat Conduction Operation layer. We integrate RGB and\nevent embeddings through a multi-modal DCT-IDCT layer while adaptively\nincorporating the thermal conductivity coefficient via FVEs into this module.\nAfter that, we propose an adaptive fusion module based on a policy routing\nstrategy for high-performance classification. Comprehensive experiments\ndemonstrate that our method consistently performs well, validating its\neffectiveness and robustness. The source code and benchmark dataset will be\nreleased on https://github.com/Event-AHU/HARDVS/tree/HARDVSv2", "published": "2025-04-08 09:14:24", "link": "http://arxiv.org/abs/2504.05830v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models", "abstract": "Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.", "published": "2025-04-08 08:53:47", "link": "http://arxiv.org/abs/2504.05815v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Meta-Continual Learning of Neural Fields", "abstract": "Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.", "published": "2025-04-08 08:38:37", "link": "http://arxiv.org/abs/2504.05806v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM", "abstract": "In a conversational system, dynamically generating follow-up questions based\non context can help users explore information and provide a better user\nexperience. Humans are usually able to ask questions that involve some general\nlife knowledge and demonstrate higher order cognitive skills. However, the\nquestions generated by existing methods are often limited to shallow contextual\nquestions that are uninspiring and have a large gap to the human level. In this\npaper, we propose a three-stage external knowledge-enhanced follow-up question\ngeneration method, which generates questions by identifying contextual topics,\nconstructing a knowledge graph (KG) online, and finally combining these with a\nlarge language model to generate the final question. The model generates\ninformation-rich and exploratory follow-up questions by introducing external\ncommon sense knowledge and performing a knowledge fusion operation. Experiments\nshow that compared to baseline models, our method generates questions that are\nmore informative and closer to human questioning levels while maintaining\ncontextual relevance.", "published": "2025-04-08 08:31:03", "link": "http://arxiv.org/abs/2504.05801v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM", "abstract": "3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.", "published": "2025-04-08 08:11:39", "link": "http://arxiv.org/abs/2504.05786v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA", "abstract": "Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.", "published": "2025-04-08 08:08:03", "link": "http://arxiv.org/abs/2504.05783v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models", "abstract": "Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.", "published": "2025-04-08 08:06:53", "link": "http://arxiv.org/abs/2504.05782v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation", "abstract": "Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.", "published": "2025-04-08 07:53:51", "link": "http://arxiv.org/abs/2504.05774v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Lightweight Multi-Module Fusion Approach for Korean Character Recognition", "abstract": "Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.", "published": "2025-04-08 07:50:19", "link": "http://arxiv.org/abs/2504.05770v1", "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Temporal Dynamic Embedding for Irregularly Sampled Time Series", "abstract": "In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.", "published": "2025-04-08 07:49:22", "link": "http://arxiv.org/abs/2504.05768v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Unraveling Human-AI Teaming: A Review and Outlook", "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.", "published": "2025-04-08 07:37:25", "link": "http://arxiv.org/abs/2504.05755v1", "categories": ["cs.HC", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.HC"}
{"title": "DDT: Decoupled Diffusion Transformer", "abstract": "Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.", "published": "2025-04-08 07:17:45", "link": "http://arxiv.org/abs/2504.05741v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI-Driven Prognostics for State of Health Prediction in Li-ion Batteries: A Comprehensive Analysis with Validation", "abstract": "This paper presents a comprehensive review of AI-driven prognostics for State\nof Health (SoH) prediction in lithium-ion batteries. We compare the\neffectiveness of various AI algorithms, including FFNN, LSTM, and BiLSTM,\nacross multiple datasets (CALCE, NASA, UDDS) and scenarios (e.g., varying\ntemperatures and driving conditions). Additionally, we analyze the factors\ninfluencing SoH fluctuations, such as temperature and charge-discharge rates,\nand validate our findings through simulations. The results demonstrate that\nBiLSTM achieves the highest accuracy, with an average RMSE reduction of 15%\ncompared to LSTM, highlighting its robustness in real-world applications.", "published": "2025-04-08 06:58:39", "link": "http://arxiv.org/abs/2504.05728v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Automated Archival Descriptions with Federated Intelligence of LLMs", "abstract": "Enforcing archival standards requires specialized expertise, and manually\ncreating metadata descriptions for archival materials is a tedious and\nerror-prone task. This work aims at exploring the potential of agentic AI and\nlarge language models (LLMs) in addressing the challenges of implementing a\nstandardized archival description process. To this end, we introduce an agentic\nAI-driven system for automated generation of high-quality metadata descriptions\nof archival materials. We develop a federated optimization approach that unites\nthe intelligence of multiple LLMs to construct optimal archival metadata. We\nalso suggest methods to overcome the challenges associated with using LLMs for\nconsistent metadata generation. To evaluate the feasibility and effectiveness\nof our techniques, we conducted extensive experiments using a real-world\ndataset of archival materials, which covers a variety of document types and\ndata formats. The evaluation results demonstrate the feasibility of our\ntechniques and highlight the superior performance of the federated optimization\napproach compared to single-model solutions in metadata quality and\nreliability.", "published": "2025-04-08 06:11:05", "link": "http://arxiv.org/abs/2504.05711v1", "categories": ["cs.AI", "cs.DL", "cs.IR", "cs.LG", "I.2"], "primary_category": "cs.AI"}
{"title": "Architecture independent generalization bounds for overparametrized deep ReLU networks", "abstract": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.", "published": "2025-04-08 05:37:38", "link": "http://arxiv.org/abs/2504.05695v1", "categories": ["cs.LG", "cs.AI", "math.AP", "math.OC", "stat.ML", "57R70, 62M45"], "primary_category": "cs.LG"}
{"title": "Large Language Models Enhanced Hyperbolic Space Recommender Systems", "abstract": "Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.", "published": "2025-04-08 05:35:38", "link": "http://arxiv.org/abs/2504.05694v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "StayLTC: A Cost-Effective Multimodal Framework for Hospital Length of Stay Forecasting", "abstract": "Accurate prediction of Length of Stay (LOS) in hospitals is crucial for\nimproving healthcare services, resource management, and cost efficiency. This\npaper presents StayLTC, a multimodal deep learning framework developed to\nforecast real-time hospital LOS using Liquid Time-Constant Networks (LTCs).\nLTCs, with their continuous-time recurrent dynamics, are evaluated against\ntraditional models using structured data from Electronic Health Records (EHRs)\nand clinical notes. Our evaluation, conducted on the MIMIC-III dataset,\ndemonstrated that LTCs significantly outperform most of the other time series\nmodels, offering enhanced accuracy, robustness, and efficiency in resource\nutilization. Additionally, LTCs demonstrate a comparable performance in LOS\nprediction compared to time series large language models, while requiring\nsignificantly less computational power and memory, underscoring their potential\nto advance Natural Language Processing (NLP) tasks in healthcare.", "published": "2025-04-08 05:27:53", "link": "http://arxiv.org/abs/2504.05691v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization", "abstract": "Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc", "published": "2025-04-08 04:59:56", "link": "http://arxiv.org/abs/2504.05686v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis", "abstract": "This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.", "published": "2025-04-08 04:49:36", "link": "http://arxiv.org/abs/2504.05684v1", "categories": ["cs.SD", "cs.AI", "cs.CV"], "primary_category": "cs.SD"}
{"title": "Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing", "abstract": "Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.", "published": "2025-04-08 04:11:28", "link": "http://arxiv.org/abs/2504.05657v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Lattice: Learning to Efficiently Compress the Memory", "abstract": "Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.", "published": "2025-04-08 03:48:43", "link": "http://arxiv.org/abs/2504.05646v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism", "abstract": "Cognitive functions in current artificial intelligence networks are tied to\nthe exponential increase in network scale, whereas the human brain can\ncontinuously learn hundreds of cognitive functions with remarkably low energy\nconsumption. This advantage is in part due to the brain cross-regional temporal\ndevelopment mechanisms, where the progressive formation, reorganization, and\npruning of connections from basic to advanced regions, facilitate knowledge\ntransfer and prevent network redundancy. Inspired by these, we propose the\nContinual Learning of Multiple Cognitive Functions with Brain-inspired Temporal\nDevelopment Mechanism(TD-MCL), enabling cognitive enhancement from simple to\ncomplex in Perception-Motor-Interaction(PMI) multiple cognitive task scenarios.\nThe TD-MCL model proposes the sequential evolution of long-range connections\nbetween different cognitive modules to promote positive knowledge transfer,\nwhile using feedback-guided local connection inhibition and pruning to\neffectively eliminate redundancies in previous tasks, reducing energy\nconsumption while preserving acquired knowledge. Experiments show that the\nproposed method can achieve continual learning capabilities while reducing\nnetwork scale, without introducing regularization, replay, or freezing\nstrategies, and achieving superior accuracy on new tasks compared to direct\nlearning. The proposed method shows that the brain's developmental mechanisms\noffer a valuable reference for exploring biologically plausible, low-energy\nenhancements of general cognitive abilities.", "published": "2025-04-08 02:36:36", "link": "http://arxiv.org/abs/2504.05621v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Technical Report: Full Version of Analyzing and Optimizing Perturbation of DP-SGD Geometrically", "abstract": "Differential privacy (DP) has become a prevalent privacy model in a wide\nrange of machine learning tasks, especially after the debut of DP-SGD. However,\nDP-SGD, which directly perturbs gradients in the training iterations, fails to\nmitigate the negative impacts of noise on gradient direction. As a result,\nDP-SGD is often inefficient. Although various solutions (e.g., clipping to\nreduce the sensitivity of gradients and amplifying privacy bounds to save\nprivacy budgets) are proposed to trade privacy for model efficiency, the root\ncause of its inefficiency is yet unveiled.\n  In this work, we first generalize DP-SGD and theoretically derive the impact\nof DP noise on the training process. Our analysis reveals that, in terms of a\nperturbed gradient, only the noise on direction has eminent impact on the model\nefficiency while that on magnitude can be mitigated by optimization techniques,\ni.e., fine-tuning gradient clipping and learning rate. Besides, we confirm that\ntraditional DP introduces biased noise on the direction when adding unbiased\nnoise to the gradient itself. Overall, the perturbation of DP-SGD is actually\nsub-optimal from a geometric perspective. Motivated by this, we design a\ngeometric perturbation strategy GeoDP within the DP framework, which perturbs\nthe direction and the magnitude of a gradient, respectively. By directly\nreducing the noise on the direction, GeoDP mitigates the negative impact of DP\nnoise on model efficiency with the same DP guarantee. Extensive experiments on\ntwo public datasets (i.e., MNIST and CIFAR-10), one synthetic dataset and three\nprevalent models (i.e., Logistic Regression, CNN and ResNet) confirm the\neffectiveness and generality of our strategy.", "published": "2025-04-08 02:26:10", "link": "http://arxiv.org/abs/2504.05618v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DB"], "primary_category": "cs.LG"}
{"title": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels", "abstract": "Federated Learning (FL) is a powerful framework for privacy-preserving\ndistributed learning. It enables multiple clients to collaboratively train a\nglobal model without sharing raw data. However, handling noisy labels in FL\nremains a major challenge due to heterogeneous data distributions and\ncommunication constraints, which can severely degrade model performance. To\naddress this issue, we propose FedEFC, a novel method designed to tackle the\nimpact of noisy labels in FL. FedEFC mitigates this issue through two key\ntechniques: (1) prestopping, which prevents overfitting to mislabeled data by\ndynamically halting training at an optimal point, and (2) loss correction,\nwhich adjusts model updates to account for label noise. In particular, we\ndevelop an effective loss correction tailored to the unique challenges of FL,\nincluding data heterogeneity and decentralized training. Furthermore, we\nprovide a theoretical analysis, leveraging the composite proper loss property,\nto demonstrate that the FL objective function under noisy label distributions\ncan be aligned with the clean label distribution. Extensive experimental\nresults validate the effectiveness of our approach, showing that it\nconsistently outperforms existing FL techniques in mitigating the impact of\nnoisy labels, particularly under heterogeneous data settings (e.g., achieving\nup to 41.64% relative performance improvement over the existing loss correction\nmethod).", "published": "2025-04-08 02:14:50", "link": "http://arxiv.org/abs/2504.05615v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Class Imbalance Correction for Improved Universal Lesion Detection and Tagging in CT", "abstract": "Radiologists routinely detect and size lesions in CT to stage cancer and\nassess tumor burden. To potentially aid their efforts, multiple lesion\ndetection algorithms have been developed with a large public dataset called\nDeepLesion (32,735 lesions, 32,120 CT slices, 10,594 studies, 4,427 patients, 8\nbody part labels). However, this dataset contains missing measurements and\nlesion tags, and exhibits a severe imbalance in the number of lesions per label\ncategory. In this work, we utilize a limited subset of DeepLesion (6\\%, 1331\nlesions, 1309 slices) containing lesion annotations and body part label tags to\ntrain a VFNet model to detect lesions and tag them. We address the class\nimbalance by conducting three experiments: 1) Balancing data by the body part\nlabels, 2) Balancing data by the number of lesions per patient, and 3)\nBalancing data by the lesion size. In contrast to a randomly sampled\n(unbalanced) data subset, our results indicated that balancing the body part\nlabels always increased sensitivity for lesions >= 1cm for classes with low\ndata quantities (Bone: 80\\% vs. 46\\%, Kidney: 77\\% vs. 61\\%, Soft Tissue: 70\\%\nvs. 60\\%, Pelvis: 83\\% vs. 76\\%). Similar trends were seen for three other\nmodels tested (FasterRCNN, RetinaNet, FoveaBox). Balancing data by lesion size\nalso helped the VFNet model improve recalls for all classes in contrast to an\nunbalanced dataset. We also provide a structured reporting guideline for a\n``Lesions'' subsection to be entered into the ``Findings'' section of a\nradiology report. To our knowledge, we are the first to report the class\nimbalance in DeepLesion, and have taken data-driven steps to address it in the\ncontext of joint lesion detection and tagging.", "published": "2025-04-08 00:58:26", "link": "http://arxiv.org/abs/2504.05591v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Multi-fidelity Reinforcement Learning Control for Complex Dynamical Systems", "abstract": "Controlling instabilities in complex dynamical systems is challenging in\nscientific and engineering applications. Deep reinforcement learning (DRL) has\nseen promising results for applications in different scientific applications.\nThe many-query nature of control tasks requires multiple interactions with real\nenvironments of the underlying physics. However, it is usually sparse to\ncollect from the experiments or expensive to simulate for complex dynamics.\nAlternatively, controlling surrogate modeling could mitigate the computational\ncost issue. However, a fast and accurate learning-based model by offline\ntraining makes it very hard to get accurate pointwise dynamics when the\ndynamics are chaotic. To bridge this gap, the current work proposes a\nmulti-fidelity reinforcement learning (MFRL) framework that leverages\ndifferentiable hybrid models for control tasks, where a physics-based hybrid\nmodel is corrected by limited high-fidelity data. We also proposed a\nspectrum-based reward function for RL learning. The effect of the proposed\nframework is demonstrated on two complex dynamics in physics. The statistics of\nthe MFRL control result match that computed from many-query evaluations of the\nhigh-fidelity environments and outperform other SOTA baselines.", "published": "2025-04-08 00:50:15", "link": "http://arxiv.org/abs/2504.05588v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Finding Fantastic Experts in MoEs: A Unified Study for Expert Dropping Strategies and Observations", "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise in scaling up\nthe learning capacity of neural networks. However, vanilla SMoEs have issues\nsuch as expert redundancy and heavy memory requirements, making them\ninefficient and non-scalable, especially for resource-constrained scenarios.\nExpert-level sparsification of SMoEs involves pruning the least important\nexperts to address these limitations. In this work, we aim to address three\nquestions: (1) What is the best recipe to identify the least knowledgeable\nsubset of experts that can be dropped with minimal impact on performance? (2)\nHow should we perform expert dropping (one-shot or iterative), and what\ncorrection measures can we undertake to minimize its drastic impact on SMoE\nsubnetwork capabilities? (3) What capabilities of full-SMoEs are severely\nimpacted by the removal of the least dominant experts, and how can we recover\nthem? Firstly, we propose MoE Experts Compression Suite (MC-Suite), which is a\ncollection of some previously explored and multiple novel recipes to provide a\ncomprehensive benchmark for estimating expert importance from diverse\nperspectives, as well as unveil numerous valuable insights for SMoE experts.\nSecondly, unlike prior works with a one-shot expert pruning approach, we\nexplore the benefits of iterative pruning with the re-estimation of the\nMC-Suite criterion. Moreover, we introduce the benefits of task-agnostic\nfine-tuning as a correction mechanism during iterative expert dropping, which\nwe term MoE Lottery Subnetworks. Lastly, we present an experimentally validated\nconjecture that, during expert dropping, SMoEs' instruction-following\ncapabilities are predominantly hurt, which can be restored to a robust level\nsubject to external augmentation of instruction-following capabilities using\nk-shot examples and supervised fine-tuning.", "published": "2025-04-08 00:49:08", "link": "http://arxiv.org/abs/2504.05586v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning", "abstract": "Episodic tasks in Reinforcement Learning (RL) often pose challenges due to\nsparse reward signals and high-dimensional state spaces, which hinder efficient\nlearning. Additionally, these tasks often feature hidden \"trap states\" --\nirreversible failures that prevent task completion but do not provide explicit\nnegative rewards to guide agents away from repeated errors. To address these\nissues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an\nInverse Reinforcement Learning (IRL) framework that leverages both successful\nand failed demonstrations. By incorporating temporal information, TW-CRL learns\na dense reward function that identifies critical states associated with success\nor failure. This approach not only enables agents to avoid trap states but also\nencourages meaningful exploration beyond simple imitation of expert\ntrajectories. Empirical evaluations on navigation tasks and robotic\nmanipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art\nmethods, achieving improved efficiency and robustness.", "published": "2025-04-08 00:48:29", "link": "http://arxiv.org/abs/2504.05585v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding", "abstract": "We introduce SoundVista, a method to generate the ambient sound of an\narbitrary scene at novel viewpoints. Given a pre-acquired recording of the\nscene from sparsely distributed microphones, SoundVista can synthesize the\nsound of that scene from an unseen target viewpoint. The method learns the\nunderlying acoustic transfer function that relates the signals acquired at the\ndistributed microphones to the signal at the target viewpoint, using a limited\nnumber of known recordings. Unlike existing works, our method does not require\nconstraints or prior knowledge of sound source details. Moreover, our method\nefficiently adapts to diverse room layouts, reference microphone configurations\nand unseen environments. To enable this, we introduce a visual-acoustic binding\nmodule that learns visual embeddings linked with local acoustic properties from\npanoramic RGB and depth data. We first leverage these embeddings to optimize\nthe placement of reference microphones in any given scene. During synthesis, we\nleverage multiple embeddings extracted from reference locations to get adaptive\nweights for their contribution, conditioned on target viewpoint. We benchmark\nthe task on both publicly available data and real-world settings. We\ndemonstrate significant improvements over existing methods.", "published": "2025-04-08 00:22:16", "link": "http://arxiv.org/abs/2504.05576v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.SD"}
{"title": "MicroNN: An On-device Disk-resident Updatable Vector Database", "abstract": "Nearest neighbour search over dense vector collections has important\napplications in information retrieval, retrieval augmented generation (RAG),\nand content ranking. Performing efficient search over large vector collections\nis a well studied problem with many existing approaches and open source\nimplementations. However, most state-of-the-art systems are generally targeted\ntowards scenarios using large servers with an abundance of memory, static\nvector collections that are not updatable, and nearest neighbour search in\nisolation of other search criteria. We present Micro Nearest Neighbour\n(MicroNN), an embedded nearest-neighbour vector search engine designed for\nscalable similarity search in low-resource environments. MicroNN addresses the\nproblem of on-device vector search for real-world workloads containing updates\nand hybrid search queries that combine nearest neighbour search with structured\nattribute filters. In this scenario, memory is highly constrained and\ndisk-efficient index structures and algorithms are required, as well as support\nfor continuous inserts and deletes. MicroNN is an embeddable library that can\nscale to large vector collections with minimal resources. MicroNN is used in\nproduction and powers a wide range of vector search use-cases on-device.\nMicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with\n90% recall on publicly available million-scale vector benchmark while using ~10\nMB of memory.", "published": "2025-04-08 00:05:58", "link": "http://arxiv.org/abs/2504.05573v1", "categories": ["cs.DB", "cs.AI", "cs.IR"], "primary_category": "cs.DB"}
{"title": "D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic Scenes", "abstract": "We address the task of 3D reconstruction in dynamic scenes, where object\nmotions degrade the quality of previous 3D pointmap regression methods, such as\nDUSt3R, originally designed for static 3D scene reconstruction. Although these\nmethods provide an elegant and powerful solution in static settings, they\nstruggle in the presence of dynamic motions that disrupt alignment based solely\non camera poses. To overcome this, we propose D^2USt3R that regresses 4D\npointmaps that simultaneiously capture both static and dynamic 3D scene\ngeometry in a feed-forward manner. By explicitly incorporating both spatial and\ntemporal aspects, our approach successfully encapsulates spatio-temporal dense\ncorrespondence to the proposed 4D pointmaps, enhancing downstream tasks.\nExtensive experimental evaluations demonstrate that our proposed approach\nconsistently achieves superior reconstruction performance across various\ndatasets featuring complex motions.", "published": "2025-04-08 17:59:50", "link": "http://arxiv.org/abs/2504.06264v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniSVG: A Unified Scalable Vector Graphics Generation Model", "abstract": "Scalable Vector Graphics (SVG) is an important image format widely adopted in\ngraphic design because of their resolution independence and editability. The\nstudy of generating high-quality SVG has continuously drawn attention from both\ndesigners and researchers in the AIGC community. However, existing methods\neither produces unstructured outputs with huge computational cost or is limited\nto generating monochrome icons of over-simplified structures. To produce\nhigh-quality and complex SVG, we propose OmniSVG, a unified framework that\nleverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal\nSVG generation. By parameterizing SVG commands and coordinates into discrete\ntokens, OmniSVG decouples structural logic from low-level geometry for\nefficient training while maintaining the expressiveness of complex SVG\nstructure. To further advance the development of SVG synthesis, we introduce\nMMSVG-2M, a multimodal dataset with two million richly annotated SVG assets,\nalong with a standardized evaluation protocol for conditional SVG generation\ntasks. Extensive experiments show that OmniSVG outperforms existing methods and\ndemonstrates its potential for integration into professional SVG design\nworkflows.", "published": "2025-04-08 17:59:49", "link": "http://arxiv.org/abs/2504.06263v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PainNet: Statistical Relation Network with Episode-Based Training for Pain Estimation", "abstract": "Despite the span in estimating pain from facial expressions, limited works\nhave focused on estimating the sequence-level pain, which is reported by\npatients and used commonly in clinics. In this paper, we introduce a novel\nStatistical Relation Network, referred to as PainNet, designed for the\nestimation of the sequence-level pain. PainNet employs two key modules, the\nembedding and the relation modules, for comparing pairs of pain videos, and\nproducing relation scores indicating if each pair belongs to the same pain\ncategory or not. At the core of the embedding module is a statistical layer\nmounted on the top of a RNN for extracting compact video-level features. The\nstatistical layer is implemented as part of the deep architecture. Doing so,\nallows combining multiple training stages used in previous research, into a\nsingle end-to-end training stage. PainNet is trained using the episode-based\ntraining scheme, which involves comparing a query video with a set of videos\nrepresenting the different pain categories. Experimental results show the\nbenefit of using the statistical layer and the episode-based training in the\nproposed model. Furthermore, PainNet outperforms the state-of-the-art results\non self-reported pain estimation.", "published": "2025-04-08 17:58:52", "link": "http://arxiv.org/abs/2504.06257v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transfer between Modalities with MetaQueries", "abstract": "Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.", "published": "2025-04-08 17:58:47", "link": "http://arxiv.org/abs/2504.06256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Monitoring Viewer Attention During Online Ads", "abstract": "Nowadays, video ads spread through numerous online platforms, and are being\nwatched by millions of viewers worldwide. Big brands gauge the liking and\npurchase intent of their new ads, by analyzing the facial responses of viewers\nrecruited online to watch the ads from home or work. Although this approach\ncaptures naturalistic responses, it is susceptible to distractions inherent in\nthe participants' environments, such as a movie playing on TV, a colleague\nspeaking, or mobile notifications. Inattentive participants should get flagged\nand eliminated to avoid skewing the ad-testing process. In this paper we\nintroduce an architecture for monitoring viewer attention during online ads.\nLeveraging two behavior analysis toolkits; AFFDEX 2.0 and SmartEye SDK, we\nextract low-level facial features encompassing facial expressions, head pose,\nand gaze direction. These features are then combined to extract high-level\nfeatures that include estimated gaze on the screen plane, yawning, speaking,\netc -- this enables the identification of four primary distractors; off-screen\ngaze, drowsiness, speaking, and unattended screen. Our architecture tailors the\ngaze settings according to the device type (desktop or mobile). We validate our\narchitecture first on datasets annotated for specific distractors, and then on\na real-world ad testing dataset with various distractors. The proposed\narchitecture shows promising results in detecting distraction across both\ndesktop and mobile devices.", "published": "2025-04-08 17:34:02", "link": "http://arxiv.org/abs/2504.06237v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance", "abstract": "Text-to-image (T2I) diffusion/flow models have drawn considerable attention\nrecently due to their remarkable ability to deliver flexible visual creations.\nStill, high-resolution image synthesis presents formidable challenges due to\nthe scarcity and complexity of high-resolution content. To this end, we present\nHiFlow, a training-free and model-agnostic framework to unlock the resolution\npotential of pre-trained flow models. Specifically, HiFlow establishes a\nvirtual reference flow within the high-resolution space that effectively\ncaptures the characteristics of low-resolution flow information, offering\nguidance for high-resolution generation through three key aspects:\ninitialization alignment for low-frequency consistency, direction alignment for\nstructure preservation, and acceleration alignment for detail fidelity. By\nleveraging this flow-aligned guidance, HiFlow substantially elevates the\nquality of high-resolution image synthesis of T2I models and demonstrates\nversatility across their personalized variants. Extensive experiments validate\nHiFlow's superiority in achieving superior high-resolution image quality over\ncurrent state-of-the-art methods.", "published": "2025-04-08 17:30:40", "link": "http://arxiv.org/abs/2504.06232v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt\npowerful Foundation Models (FMs) to diverse downstream tasks while preserving\nand unleashing their inherent capabilities. However, we have observed that\nexisting PEFT methods, which are often designed with natural imagery in mind,\nstruggle when applied to Remote Sensing (RS) scenarios. This is primarily due\nto their inability to handle artifact influences, a problem particularly severe\nin RS image features. To tackle this challenge, we introduce Earth-Adapter, the\nfirst PEFT method specifically designed for RS artifacts conquering.\nEarth-Adapter introduces a novel Mixture of Frequency Adaptation process that\ncombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).\nBy utilizing DFT, Earth-Adapter can decompose features into different frequency\ncomponents, precisely separating artifacts from original features. The MoA then\ndynamically assigns weights to each adapter expert, allowing for the\ncombination of features across various frequency domains. These\nsimple-yet-effective approaches enable Earth-Adapter to more efficiently\novercome the disturbances caused by artifacts than previous PEFT methods,\nsignificantly enhancing the FMs' performance on RS scenarios. Experiments on\nDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentation\nbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline\nRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG\nbenchmarks. Our code will be released at\nhttps://github.com/VisionXLab/Earth-Adapter.", "published": "2025-04-08 17:09:33", "link": "http://arxiv.org/abs/2504.06220v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HiMoR: Monocular Deformable Gaussian Reconstruction with Hierarchical Motion Representation", "abstract": "We present Hierarchical Motion Representation (HiMoR), a novel deformation\nrepresentation for 3D Gaussian primitives capable of achieving high-quality\nmonocular dynamic 3D reconstruction. The insight behind HiMoR is that motions\nin everyday scenes can be decomposed into coarser motions that serve as the\nfoundation for finer details. Using a tree structure, HiMoR's nodes represent\ndifferent levels of motion detail, with shallower nodes modeling coarse motion\nfor temporal smoothness and deeper nodes capturing finer motion. Additionally,\nour model uses a few shared motion bases to represent motions of different sets\nof nodes, aligning with the assumption that motion tends to be smooth and\nsimple. This motion representation design provides Gaussians with a more\nstructured deformation, maximizing the use of temporal relationships to tackle\nthe challenging task of monocular dynamic 3D reconstruction. We also propose\nusing a more reliable perceptual metric as an alternative, given that\npixel-level metrics for evaluating monocular dynamic 3D reconstruction can\nsometimes fail to accurately reflect the true quality of reconstruction.\nExtensive experiments demonstrate our method's efficacy in achieving superior\nnovel view synthesis from challenging monocular videos with complex motions.", "published": "2025-04-08 16:55:12", "link": "http://arxiv.org/abs/2504.06210v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HRMedSeg: Unlocking High-resolution Medical Image segmentation via Memory-efficient Attention Modeling", "abstract": "High-resolution segmentation is critical for precise disease diagnosis by\nextracting micro-imaging information from medical images. Existing\ntransformer-based encoder-decoder frameworks have demonstrated remarkable\nversatility and zero-shot performance in medical segmentation. While\nbeneficial, they usually require huge memory costs when handling large-size\nsegmentation mask predictions, which are expensive to apply to real-world\nscenarios. To address this limitation, we propose a memory-efficient framework\nfor high-resolution medical image segmentation, called HRMedSeg. Specifically,\nwe first devise a lightweight gated vision transformer (LGViT) as our image\nencoder to model long-range dependencies with linear complexity. Then, we\ndesign an efficient cross-multiscale decoder (ECM-Decoder) to generate\nhigh-resolution segmentation masks. Moreover, we utilize feature distillation\nduring pretraining to unleash the potential of our proposed model. Extensive\nexperiments reveal that HRMedSeg outperforms state-of-the-arts in diverse\nhigh-resolution medical image segmentation tasks. In particular, HRMedSeg uses\nonly 0.59GB GPU memory per batch during fine-tuning, demonstrating low training\ncosts. Besides, when HRMedSeg meets the Segment Anything Model (SAM), our\nHRMedSegSAM takes 0.61% parameters of SAM-H. The code is available at\nhttps://github.com/xq141839/HRMedSeg.", "published": "2025-04-08 16:48:57", "link": "http://arxiv.org/abs/2504.06205v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Flash Sculptor: Modular 3D Worlds from Objects", "abstract": "Existing text-to-3D and image-to-3D models often struggle with complex scenes\ninvolving multiple objects and intricate interactions. Although some recent\nattempts have explored such compositional scenarios, they still require an\nextensive process of optimizing the entire layout, which is highly cumbersome\nif not infeasible at all. To overcome these challenges, we propose Flash\nSculptor in this paper, a simple yet effective framework for compositional 3D\nscene/object reconstruction from a single image. At the heart of Flash Sculptor\nlies a divide-and-conquer strategy, which decouples compositional scene\nreconstruction into a sequence of sub-tasks, including handling the appearance,\nrotation, scale, and translation of each individual instance. Specifically, for\nrotation, we introduce a coarse-to-fine scheme that brings the best of both\nworlds--efficiency and accuracy--while for translation, we develop an\noutlier-removal-based algorithm that ensures robust and precise parameters in a\nsingle step, without any iterative optimization. Extensive experiments\ndemonstrate that Flash Sculptor achieves at least a 3 times speedup over\nexisting compositional 3D methods, while setting new benchmarks in\ncompositional 3D reconstruction performance. Codes are available at\nhttps://github.com/YujiaHu1109/Flash-Sculptor.", "published": "2025-04-08 16:20:51", "link": "http://arxiv.org/abs/2504.06178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Action Valuation in Sports: A Survey", "abstract": "Action Valuation (AV) has emerged as a key topic in Sports Analytics,\noffering valuable insights by assigning scores to individual actions based on\ntheir contribution to desired outcomes. Despite a few surveys addressing\nrelated concepts such as Player Valuation, there is no comprehensive review\ndedicated to an in-depth analysis of AV across different sports. In this\nsurvey, we introduce a taxonomy with nine dimensions related to the AV task,\nencompassing data, methodological approaches, evaluation techniques, and\npractical applications. Through this analysis, we aim to identify the essential\ncharacteristics of effective AV methods, highlight existing gaps in research,\nand propose future directions for advancing the field.", "published": "2025-04-08 15:59:19", "link": "http://arxiv.org/abs/2504.06163v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation with Attention Mechanisms and Multiscale Feature Fusion", "abstract": "Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet", "published": "2025-04-08 15:53:46", "link": "http://arxiv.org/abs/2504.06158v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Large-Scale Analysis on Contextual Self-Supervised Video Representation Learning", "abstract": "Self-supervised learning has emerged as a powerful paradigm for label-free\nmodel pretraining, particularly in the video domain, where manual annotation is\ncostly and time-intensive. However, existing self-supervised approaches employ\ndiverse experimental setups, making direct comparisons challenging due to the\nabsence of a standardized benchmark. In this work, we establish a unified\nbenchmark that enables fair comparisons across different methods. Additionally,\nwe systematically investigate five critical aspects of self-supervised learning\nin videos: (1) dataset size, (2) model complexity, (3) data distribution, (4)\ndata noise, and (5) feature representations. To facilitate this study, we\nevaluate six self-supervised learning methods across six network architectures,\nconducting extensive experiments on five benchmark datasets and assessing\nperformance on two distinct downstream tasks. Our analysis reveals key insights\ninto the interplay between pretraining strategies, dataset characteristics,\npretext tasks, and model architectures. Furthermore, we extend these findings\nto Video Foundation Models (ViFMs), demonstrating their relevance in\nlarge-scale video representation learning. Finally, leveraging these insights,\nwe propose a novel approach that significantly reduces training data\nrequirements while surpassing state-of-the-art methods that rely on 10% more\npretraining data. We believe this work will guide future research toward a\ndeeper understanding of self-supervised video representation learning and its\nbroader implications.", "published": "2025-04-08 15:47:58", "link": "http://arxiv.org/abs/2504.06153v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have led to\nsignificant improvements across various multimodal benchmarks. However, as\nevaluations shift from static datasets to open-world, dynamic environments,\ncurrent game-based benchmarks remain inadequate because they lack\nvisual-centric tasks and fail to assess the diverse reasoning skills required\nfor real-world decision-making. To address this, we introduce Visual-centric\nMultiple Abilities Game Evaluation (V-MAGE), a game-based evaluation framework\ndesigned to assess visual reasoning capabilities of MLLMs. V-MAGE features five\ndiverse games with 30+ handcrafted levels, testing models on core visual skills\nsuch as positioning, trajectory tracking, timing, and visual memory, alongside\nhigher-level reasoning like long-term planning and deliberation. We use V-MAGE\nto evaluate leading MLLMs, revealing significant challenges in their visual\nperception and reasoning. In all game environments, the top-performing MLLMs,\nas determined by Elo rating comparisons, exhibit a substantial performance gap\ncompared to humans. Our findings highlight critical limitations, including\nvarious types of perceptual errors made by the models, and suggest potential\navenues for improvement from an agent-centric perspective, such as refining\nagent strategies and addressing perceptual inaccuracies. Code is available at\nhttps://github.com/CSU-JPG/V-MAGE.", "published": "2025-04-08 15:43:01", "link": "http://arxiv.org/abs/2504.06148v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Training-Free Style-aligned Image Generation with Scale-wise Autoregressive Model", "abstract": "We present a training-free style-aligned image generation method that\nleverages a scale-wise autoregressive model. While large-scale text-to-image\n(T2I) models, particularly diffusion-based methods, have demonstrated\nimpressive generation quality, they often suffer from style misalignment across\ngenerated image sets and slow inference speeds, limiting their practical\nusability. To address these issues, we propose three key components: initial\nfeature replacement to ensure consistent background appearance, pivotal feature\ninterpolation to align object placement, and dynamic style injection, which\nreinforces style consistency using a schedule function. Unlike previous methods\nrequiring fine-tuning or additional training, our approach maintains fast\ninference while preserving individual content details. Extensive experiments\nshow that our method achieves generation quality comparable to competing\napproaches, significantly improves style alignment, and delivers inference\nspeeds over six times faster than the fastest model.", "published": "2025-04-08 15:39:25", "link": "http://arxiv.org/abs/2504.06144v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FaceCloak: Learning to Protect Face Templates", "abstract": "Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face raising security\nand privacy concerns. We present FaceCloak, a neural network framework that\nprotects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperforms leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. FaceCloak-based matching is\nextremely fast (inference time cost=0.28ms) and light-weight (0.57MB).", "published": "2025-04-08 15:23:21", "link": "http://arxiv.org/abs/2504.06131v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions", "abstract": "Lane detection is a critical component of Advanced Driver Assistance Systems\n(ADAS). Existing lane detection algorithms generally perform well under\nfavorable weather conditions. However, their performance degrades significantly\nin adverse conditions, such as fog, which increases the risk of traffic\naccidents. This challenge is compounded by the lack of specialized datasets and\nmethods designed for foggy environments. To address this, we introduce the\nFoggyLane dataset, captured in real-world foggy scenarios, and synthesize two\nadditional datasets, FoggyCULane and FoggyTusimple, from existing popular lane\ndetection datasets. Furthermore, we propose a robust Fog-Enhanced Network for\nlane detection, incorporating a Global Feature Fusion Module (GFFM) to capture\nglobal relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to\nmodel the structural and positional relationships of lane instances, and a\nLow-level Edge Enhanced Module (LEEM) to address missing edge details in foggy\nconditions. Comprehensive experiments demonstrate that our method achieves\nstate-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on\nFoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT\nacceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA\nJetson AGX Orin, confirming its real-time capabilities and robustness in foggy\nenvironments.", "published": "2025-04-08 15:13:01", "link": "http://arxiv.org/abs/2504.06121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hyperbolic Category Discovery", "abstract": "Generalized Category Discovery (GCD) is an intriguing open-world problem that\nhas garnered increasing attention. Given a dataset that includes both labelled\nand unlabelled images, GCD aims to categorize all images in the unlabelled\nsubset, regardless of whether they belong to known or unknown classes. In GCD,\nthe common practice typically involves applying a spherical projection operator\nat the end of the self-supervised pretrained backbone, operating within\nEuclidean or spherical space. However, both of these spaces have been shown to\nbe suboptimal for encoding samples that possesses hierarchical structures. In\ncontrast, hyperbolic space exhibits exponential volume growth relative to\nradius, making it inherently strong at capturing the hierarchical structure of\nsamples from both seen and unseen categories. Therefore, we propose to tackle\nthe category discovery challenge in the hyperbolic space. We introduce HypCD, a\nsimple \\underline{Hyp}erbolic framework for learning hierarchy-aware\nrepresentations and classifiers for generalized \\underline{C}ategory\n\\underline{D}iscovery. HypCD first transforms the Euclidean embedding space of\nthe backbone network into hyperbolic space, facilitating subsequent\nrepresentation and classification learning by considering both hyperbolic\ndistance and the angle between samples. This approach is particularly helpful\nfor knowledge transfer from known to unknown categories in GCD. We thoroughly\nevaluate HypCD on public GCD benchmarks, by applying it to various baseline and\nstate-of-the-art methods, consistently achieving significant improvements.", "published": "2025-04-08 15:12:33", "link": "http://arxiv.org/abs/2504.06120v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "To Match or Not to Match: Revisiting Image Matching for Reliable Visual Place Recognition", "abstract": "Visual Place Recognition (VPR) is a critical task in computer vision,\ntraditionally enhanced by re-ranking retrieval results with image matching.\nHowever, recent advancements in VPR methods have significantly improved\nperformance, challenging the necessity of re-ranking. In this work, we show\nthat modern retrieval systems often reach a point where re-ranking can degrade\nresults, as current VPR datasets are largely saturated. We propose using image\nmatching as a verification step to assess retrieval confidence, demonstrating\nthat inlier counts can reliably predict when re-ranking is beneficial. Our\nfindings shift the paradigm of retrieval pipelines, offering insights for more\nrobust and adaptive VPR systems.", "published": "2025-04-08 15:10:10", "link": "http://arxiv.org/abs/2504.06116v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From Egocentric Videos", "abstract": "Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.", "published": "2025-04-08 14:25:25", "link": "http://arxiv.org/abs/2504.06084v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning Strategies", "abstract": "Capsule endoscopy is a method to capture images of the gastrointestinal tract\nand screen for diseases which might remain hidden if investigated with standard\nendoscopes. Due to the limited size of a video capsule, embedding AI models\ndirectly into the capsule demands careful consideration of the model size and\nthus complicates anomaly detection in this field. Furthermore, the scarcity of\navailable data in this domain poses an ongoing challenge to achieving effective\nanomaly detection. Thus, this work introduces an ensemble strategy to address\nthis challenge in anomaly detection tasks in video capsule endoscopies,\nrequiring only a small number of individual neural networks during both the\ntraining and inference phases. Ensemble learning combines the predictions of\nmultiple independently trained neural networks. This has shown to be highly\neffective in enhancing both the accuracy and robustness of machine learning\nmodels. However, this comes at the cost of higher memory usage and increased\ncomputational effort, which quickly becomes prohibitive in many real-world\napplications. Instead of applying the same training algorithm to each\nindividual network, we propose using various loss functions, drawn from the\nanomaly detection field, to train each network. The methods are validated on\nthe two largest publicly available datasets for video capsule endoscopy images,\nthe Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on\nthe Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our\napproach outperforms current baselines with significantly fewer parameters\nacross all models, which is a crucial step towards incorporating artificial\nintelligence into capsule endoscopies.", "published": "2025-04-08 13:39:39", "link": "http://arxiv.org/abs/2504.06039v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model", "abstract": "Multimodal remote sensing image registration aligns images from different\nsensors for data fusion and analysis. However, current methods often fail to\nextract modality-invariant features when aligning image pairs with large\nnonlinear radiometric differences. To address this issues, we propose\nOSDM-MReg, a novel multimodal image registration framework based image-to-image\ntranslation to eliminate the gap of multimodal images. Firstly, we propose a\nnovel one-step unaligned target-guided conditional denoising diffusion\nprobabilistic models(UTGOS-CDDPM)to translate multimodal images into a unified\ndomain. In the inference stage, traditional conditional DDPM generate\ntranslated source image by a large number of iterations, which severely slows\ndown the image registration task. To address this issues, we use the unaligned\ntraget image as a condition to promote the generation of low-frequency features\nof the translated source image. Furthermore, during the training stage, we add\nthe inverse process of directly predicting the translated image to ensure that\nthe translated source image can be generated in one step during the testing\nstage. Additionally, to supervised the detail features of translated source\nimage, we propose a new perceptual loss that focuses on the high-frequency\nfeature differences between the translated and ground-truth images. Finally, a\nmultimodal multiscale image registration network (MM-Reg) fuse the multimodal\nfeature of the unimodal images and multimodal images by proposed multimodal\nfeature fusion strategy. Experiments demonstrate superior accuracy and\nefficiency across various multimodal registration tasks, particularly for\nSAR-optical image pairs.", "published": "2025-04-08 13:32:56", "link": "http://arxiv.org/abs/2504.06027v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "CamContextI2V: Context-aware Controllable Video Generation", "abstract": "Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.", "published": "2025-04-08 13:26:59", "link": "http://arxiv.org/abs/2504.06022v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Memory-Modular Classification: Learning to Generalize with Memory Replacement", "abstract": "We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.", "published": "2025-04-08 13:26:24", "link": "http://arxiv.org/abs/2504.06021v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Multimodal Reconstruction for Misinformation Detection", "abstract": "Multimodal misinformation, such as miscaptioned images, where captions\nmisrepresent an image's origin, context, or meaning, poses a growing challenge\nin the digital age. To support fact-checkers, researchers have been focusing on\ncreating datasets and developing methods for multimodal misinformation\ndetection (MMD). Due to the scarcity of large-scale annotated MMD datasets,\nrecent studies leverage synthetic training data via out-of-context\nimage-caption pairs or named entity manipulations; altering names, dates, and\nlocations. However, these approaches often produce simplistic misinformation\nthat fails to reflect real-world complexity, limiting the robustness of\ndetection models trained on them. Meanwhile, despite recent advancements, Large\nVision-Language Models (LVLMs) remain underutilized for generating diverse,\nrealistic synthetic training data for MMD. To address this gap, we introduce\n\"MisCaption This!\", a training dataset comprising LVLM-generated miscaptioned\nimages. Additionally, we introduce \"Latent Multimodal Reconstruction\" (LAMAR),\na network trained to reconstruct the embeddings of truthful captions, providing\na strong auxiliary signal to the detection process. To optimize LAMAR, we\nexplore different training strategies (end-to-end training and large-scale\npre-training) and integration approaches (direct, mask, gate, and attention).\nExtensive experiments show that models trained on \"MisCaption This!\" generalize\nbetter on real-world misinformation, while LAMAR sets new state-of-the-art on\nboth NewsCLIPpings and VERITE benchmarks; highlighting the potential of\nLVLM-generated data and reconstruction-based approaches for advancing MMD. We\nrelease our code at:\nhttps://github.com/stevejpapad/miscaptioned-image-reconstruction", "published": "2025-04-08 13:16:48", "link": "http://arxiv.org/abs/2504.06010v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "FedFeat+: A Robust Federated Learning Framework Through Federated Aggregation and Differentially Private Feature-Based Classifier Retraining", "abstract": "In this paper, we propose the FedFeat+ framework, which distinctively\nseparates feature extraction from classification. We develop a two-tiered model\ntraining process: following local training, clients transmit their weights and\nsome features extracted from the feature extractor from the final local epochs\nto the server. The server aggregates these models using the FedAvg method and\nsubsequently retrains the global classifier utilizing the shared features. The\nclassifier retraining process enhances the model's understanding of the\nholistic view of the data distribution, ensuring better generalization across\ndiverse datasets. This improved generalization enables the classifier to\nadaptively influence the feature extractor during subsequent local training\nepochs. We establish a balance between enhancing model accuracy and\nsafeguarding individual privacy through the implementation of differential\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\nthe server, we ensure that sensitive data remains confidential. We present a\ncomprehensive convergence analysis, along with theoretical reasoning regarding\nperformance enhancement and privacy preservation. We validate our approach\nthrough empirical evaluations conducted on benchmark datasets, including\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\nto stringent privacy guarantees. The experimental results demonstrate that the\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\nCIFAR-100, and Fashion-MNIST datasets.", "published": "2025-04-08 13:12:38", "link": "http://arxiv.org/abs/2504.06004v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians", "abstract": "The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.", "published": "2025-04-08 13:12:31", "link": "http://arxiv.org/abs/2504.06003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Under-Sampled High-Dimensional Data Recovery via Symbiotic Multi-Prior Tensor Reconstruction", "abstract": "The advancement of sensing technology has driven the widespread application\nof high-dimensional data. However, issues such as missing entries during\nacquisition and transmission negatively impact the accuracy of subsequent\ntasks. Tensor reconstruction aims to recover the underlying complete data from\nunder-sampled observed data by exploring prior information in high-dimensional\ndata. However, due to insufficient exploration, reconstruction methods still\nface challenges when sampling rate is extremely low. This work proposes a\ntensor reconstruction method integrating multiple priors to comprehensively\nexploit the inherent structure of the data. Specifically, the method combines\nlearnable tensor decomposition to enforce low-rank constraints of the\nreconstructed data, a pre-trained convolutional neural network for smoothing\nand denoising, and block-matching and 3D filtering regularization to enhance\nthe non-local similarity in the reconstructed data. An alternating direction\nmethod of the multipliers algorithm is designed to decompose the resulting\noptimization problem into three subproblems for efficient resolution. Extensive\nexperiments on color images, hyperspectral images, and grayscale videos\ndatasets demonstrate the superiority of our method in extreme cases as compared\nwith state-of-the-art methods.", "published": "2025-04-08 12:55:18", "link": "http://arxiv.org/abs/2504.05992v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AI analysis of medical images at scale as a health disparities probe: a feasibility demonstration using chest radiographs", "abstract": "Health disparities (differences in non-genetic conditions that influence\nhealth) can be associated with differences in burden of disease by groups\nwithin a population. Social determinants of health (SDOH) are domains such as\nhealth care access, dietary access, and economics frequently studied for\npotential association with health disparities. Evaluating SDOH-related\nphenotypes using routine medical images as data sources may enhance health\ndisparities research. We developed a pipeline for using quantitative measures\nautomatically extracted from medical images as inputs into health disparities\nindex calculations. Our study focused on the use case of two SDOH demographic\ncorrelates (sex and race) and data extracted from chest radiographs of 1,571\nunique patients. The likelihood of severe disease within the lung parenchyma\nfrom each image type, measured using an established deep learning model, was\nmerged into a single numerical image-based phenotype for each patient. Patients\nwere then separated into phenogroups by unsupervised clustering of the\nimage-based phenotypes. The health rate for each phenogroup was defined as the\nmedian image-based phenotype for each SDOH used as inputs to four\nimaging-derived health disparities indices (iHDIs): one absolute measure\n(between-group variance) and three relative measures (index of disparity, Theil\nindex, and mean log deviation). The iHDI measures demonstrated feasible values\nfor each SDOH demographic correlate, showing potential for medical images to\nserve as a novel probe for health disparities. Large-scale AI analysis of\nmedical images can serve as a probe for a novel data source for health\ndisparities research.", "published": "2025-04-08 12:53:14", "link": "http://arxiv.org/abs/2504.05990v1", "categories": ["physics.med-ph", "cs.CV"], "primary_category": "physics.med-ph"}
{"title": "An Empirical Study of GPT-4o Image Generation Capabilities", "abstract": "The landscape of image generation has rapidly evolved, from early GAN-based\napproaches to diffusion models and, most recently, to unified generative\narchitectures that seek to bridge understanding and generation tasks. Recent\nadvances, especially the GPT-4o, have demonstrated the feasibility of\nhigh-fidelity multimodal generation, their architectural design remains\nmysterious and unpublished. This prompts the question of whether image and text\ngeneration have already been successfully integrated into a unified framework\nfor those methods. In this work, we conduct an empirical study of GPT-4o's\nimage generation capabilities, benchmarking it against leading open-source and\ncommercial models. Our evaluation covers four main categories, including\ntext-to-image, image-to-image, image-to-3D, and image-to-X generation, with\nmore than 20 tasks. Our analysis highlights the strengths and limitations of\nGPT-4o under various settings, and situates it within the broader evolution of\ngenerative modeling. Through this investigation, we identify promising\ndirections for future unified generative models, emphasizing the role of\narchitectural design and data scaling.", "published": "2025-04-08 12:34:36", "link": "http://arxiv.org/abs/2504.05979v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion Based Ambiguous Image Segmentation", "abstract": "Medical image segmentation often involves inherent uncertainty due to\nvariations in expert annotations. Capturing this uncertainty is an important\ngoal and previous works have used various generative image models for the\npurpose of representing the full distribution of plausible expert ground\ntruths. In this work, we explore the design space of diffusion models for\ngenerative segmentation, investigating the impact of noise schedules,\nprediction types, and loss weightings. Notably, we find that making the noise\nschedule harder with input scaling significantly improves performance. We\nconclude that x- and v-prediction outperform epsilon-prediction, likely because\nthe diffusion process is in the discrete segmentation domain. Many loss\nweightings achieve similar performance as long as they give enough weight to\nthe end of the diffusion process. We base our experiments on the LIDC-IDRI lung\nlesion dataset and obtain state-of-the-art (SOTA) performance. Additionally, we\nintroduce a randomly cropped variant of the LIDC-IDRI dataset that is better\nsuited for uncertainty in image segmentation. Our model also achieves SOTA in\nthis harder setting.", "published": "2025-04-08 12:33:26", "link": "http://arxiv.org/abs/2504.05977v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AVP-AP: Self-supervised Automatic View Positioning in 3D cardiac CT via Atlas Prompting", "abstract": "Automatic view positioning is crucial for cardiac computed tomography (CT)\nexaminations, including disease diagnosis and surgical planning. However, it is\nhighly challenging due to individual variability and large 3D search space.\nExisting work needs labor-intensive and time-consuming manual annotations to\ntrain view-specific models, which are limited to predicting only a fixed set of\nplanes. However, in real clinical scenarios, the challenge of positioning\nsemantic 2D slices with any orientation into varying coordinate space in\narbitrary 3D volume remains unsolved. We thus introduce a novel framework,\nAVP-AP, the first to use Atlas Prompting for self-supervised Automatic View\nPositioning in the 3D CT volume. Specifically, this paper first proposes an\natlas prompting method, which generates a 3D canonical atlas and trains a\nnetwork to map slices into their corresponding positions in the atlas space via\na self-supervised manner. Then, guided by atlas prompts corresponding to the\ngiven query images in a reference CT, we identify the coarse positions of\nslices in the target CT volume using rigid transformation between the 3D atlas\nand target CT volume, effectively reducing the search space. Finally, we refine\nthe coarse positions by maximizing the similarity between the predicted slices\nand the query images in the feature space of a given foundation model. Our\nframework is flexible and efficient compared to other methods, outperforming\nother methods by 19.8% average structural similarity (SSIM) in arbitrary view\npositioning and achieving 9% SSIM in two-chamber view compared to four\nradiologists. Meanwhile, experiments on a public dataset validate our\nframework's generalizability.", "published": "2025-04-08 12:24:37", "link": "http://arxiv.org/abs/2504.05966v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic Video Situation", "abstract": "Vision-language temporal alignment is a crucial capability for human dynamic\nrecognition and cognition in real-world scenarios. While existing research\nfocuses on capturing vision-language relevance, it faces limitations due to\nbiased temporal distributions, imprecise annotations, and insufficient\ncompositionally. To achieve fair evaluation and comprehensive exploration, our\nobjective is to investigate and evaluate the ability of models to achieve\nalignment from a temporal perspective, specifically focusing on their capacity\nto synchronize visual scenarios with linguistic context in a temporally\ncoherent manner. As a preliminary step, we present the statistical analysis of\nexisting benchmarks and reveal the existing challenges from a decomposed\nperspective. To this end, we introduce SVLTA, the Synthetic Vision-Language\nTemporal Alignment derived via a well-designed and feasible control generation\nmethod within a simulation environment. The approach considers commonsense\nknowledge, manipulable action, and constrained filtering, which generates\nreasonable, diverse, and balanced data distributions for diagnostic\nevaluations. Our experiments reveal diagnostic insights through the evaluations\nin temporal question answering, distributional shift sensitiveness, and\ntemporal alignment adaptation.", "published": "2025-04-08 11:31:37", "link": "http://arxiv.org/abs/2504.05925v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Balancing long- and short-term dynamics for the modeling of saliency in videos", "abstract": "The role of long- and short-term dynamics towards salient object detection in\nvideos is under-researched. We present a Transformer-based approach to learn a\njoint representation of video frames and past saliency information. Our model\nembeds long- and short-term information to detect dynamically shifting saliency\nin video. We provide our model with a stream of video frames and past saliency\nmaps, which acts as a prior for the next prediction, and extract spatiotemporal\ntokens from both modalities. The decomposition of the frame sequence into\ntokens lets the model incorporate short-term information from within the token,\nwhile being able to make long-term connections between tokens throughout the\nsequence. The core of the system consists of a dual-stream Transformer\narchitecture to process the extracted sequences independently before fusing the\ntwo modalities. Additionally, we apply a saliency-based masking scheme to the\ninput frames to learn an embedding that facilitates the recognition of\ndeviations from previous outputs. We observe that the additional prior\ninformation aids in the first detection of the salient location. Our findings\nindicate that the ratio of spatiotemporal long- and short-term features\ndirectly impacts the model's performance. While increasing the short-term\ncontext is beneficial up to a certain threshold, the model's performance\ngreatly benefits from an expansion of the long-term context.", "published": "2025-04-08 11:09:37", "link": "http://arxiv.org/abs/2504.05913v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Intrinsic Saliency Guided Trunk-Collateral Network for Unsupervised Video Object Segmentation", "abstract": "Recent unsupervised video object segmentation (UVOS) methods predominantly\nadopt the motion-appearance paradigm. Mainstream motion-appearance approaches\nuse either the two-encoder structure to separately encode motion and appearance\nfeatures, or the single-encoder structure for joint encoding. However, these\nmethods fail to properly balance the motion-appearance relationship.\nConsequently, even with complex fusion modules for motion-appearance\nintegration, the extracted suboptimal features degrade the models' overall\nperformance. Moreover, the quality of optical flow varies across scenarios,\nmaking it insufficient to rely solely on optical flow to achieve high-quality\nsegmentation results. To address these challenges, we propose the Intrinsic\nSaliency guided Trunk-Collateral Net}work (ISTC-Net), which better balances the\nmotion-appearance relationship and incorporates model's intrinsic saliency\ninformation to enhance segmentation performance. Specifically, considering that\noptical flow maps are derived from RGB images, they share both commonalities\nand differences. We propose a novel Trunk-Collateral structure. The shared\ntrunk backbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that ISTC-Net\nachieved state-of-the-art performance on three UVOS datasets (89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.", "published": "2025-04-08 11:02:14", "link": "http://arxiv.org/abs/2504.05904v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based Coding", "abstract": "Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.", "published": "2025-04-08 10:27:53", "link": "http://arxiv.org/abs/2504.05888v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "KAN-SAM: Kolmogorov-Arnold Network Guided Segment Anything Model for RGB-T Salient Object Detection", "abstract": "Existing RGB-thermal salient object detection (RGB-T SOD) methods aim to\nidentify visually significant objects by leveraging both RGB and thermal\nmodalities to enable robust performance in complex scenarios, but they often\nsuffer from limited generalization due to the constrained diversity of\navailable datasets and the inefficiencies in constructing multi-modal\nrepresentations. In this paper, we propose a novel prompt learning-based RGB-T\nSOD method, named KAN-SAM, which reveals the potential of visual foundational\nmodels for RGB-T SOD tasks. Specifically, we extend Segment Anything Model 2\n(SAM2) for RGB-T SOD by introducing thermal features as guiding prompts through\nefficient and accurate Kolmogorov-Arnold Network (KAN) adapters, which\neffectively enhance RGB representations and improve robustness. Furthermore, we\nintroduce a mutually exclusive random masking strategy to reduce reliance on\nRGB data and improve generalization. Experimental results on benchmarks\ndemonstrate superior performance over the state-of-the-art methods.", "published": "2025-04-08 10:07:02", "link": "http://arxiv.org/abs/2504.05878v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "On the Importance of Conditioning for Privacy-Preserving Data Augmentation", "abstract": "Latent diffusion models can be used as a powerful augmentation method to\nartificially extend datasets for enhanced training. To the human eye, these\naugmented images look very different to the originals. Previous work has\nsuggested to use this data augmentation technique for data anonymization.\nHowever, we show that latent diffusion models that are conditioned on features\nlike depth maps or edges to guide the diffusion process are not suitable as a\nprivacy preserving method. We use a contrastive learning approach to train a\nmodel that can correctly identify people out of a pool of candidates. Moreover,\nwe demonstrate that anonymization using conditioned diffusion models is\nsusceptible to black box attacks. We attribute the success of the described\nmethods to the conditioning of the latent diffusion model in the anonymization\nprocess. The diffusion model is instructed to produce similar edges for the\nanonymized images. Hence, a model can learn to recognize these patterns for\nidentification.", "published": "2025-04-08 09:27:51", "link": "http://arxiv.org/abs/2504.05849v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PaMi-VDPO: Mitigating Video Hallucinations by Prompt-Aware Multi-Instance Video Preference Learning", "abstract": "Direct Preference Optimization (DPO) helps reduce hallucinations in Video\nMultimodal Large Language Models (VLLMs), but its reliance on offline\npreference data limits adaptability and fails to capture true video-response\nmisalignment. We propose Video Direct Preference Optimization (VDPO), an online\npreference learning framework that eliminates the need for preference\nannotation by leveraging video augmentations to generate rejected samples while\nkeeping responses fixed. However, selecting effective augmentations is\nnon-trivial, as some clips may be semantically identical to the original under\nspecific prompts, leading to false rejections and disrupting alignment. To\naddress this, we introduce Prompt-aware Multi-instance Learning VDPO\n(PaMi-VDPO), which selects augmentations based on prompt context. Instead of a\nsingle rejection, we construct a candidate set of augmented clips and apply a\nclose-to-far selection strategy, initially ensuring all clips are semantically\nrelevant while then prioritizing the most prompt-aware distinct clip. This\nallows the model to better capture meaningful visual differences, mitigating\nhallucinations, while avoiding false rejections, and improving alignment.\nPaMi-VDPOseamlessly integrates into existing VLLMs without additional\nparameters, GPT-4/human supervision. With only 10k SFT data, it improves the\nbase model by 5.3% on VideoHallucer, surpassing GPT-4o, while maintaining\nstable performance on general video benchmarks.", "published": "2025-04-08 08:41:41", "link": "http://arxiv.org/abs/2504.05810v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Sphericity and Roundness approximation in 2D and 3D using Local Thickness", "abstract": "Sphericity and roundness are fundamental measures used for assessing object\nuniformity in 2D and 3D images. However, using their strict definition makes\ncomputation costly. As both 2D and 3D microscopy imaging datasets grow larger,\nthere is an increased demand for efficient algorithms that can quantify\nmultiple objects in large volumes. We propose a novel approach for extracting\nsphericity and roundness based on the output of a local thickness algorithm.\nFor sphericity, we simplify the surface area computation by modeling objects as\nspheroids/ellipses of varying lengths and widths of mean local thickness. For\nroundness, we avoid a complex corner curvature determination process by\napproximating it with local thickness values on the contour/surface of the\nobject. The resulting methods provide an accurate representation of the exact\nmeasures while being significantly faster than their existing implementations.", "published": "2025-04-08 08:40:50", "link": "http://arxiv.org/abs/2504.05808v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SE4Lip: Speech-Lip Encoder for Talking Head Synthesis to Solve Phoneme-Viseme Alignment Ambiguity", "abstract": "Speech-driven talking head synthesis tasks commonly use general acoustic\nfeatures (such as HuBERT and DeepSpeech) as guided speech features. However, we\ndiscovered that these features suffer from phoneme-viseme alignment ambiguity,\nwhich refers to the uncertainty and imprecision in matching phonemes (speech)\nwith visemes (lip). To address this issue, we propose the Speech Encoder for\nLip (SE4Lip) to encode lip features from speech directly, aligning speech and\nlip features in the joint embedding space by a cross-modal alignment framework.\nThe STFT spectrogram with the GRU-based model is designed in SE4Lip to preserve\nthe fine-grained speech features. Experimental results show that SE4Lip\nachieves state-of-the-art performance in both NeRF and 3DGS rendering models.\nIts lip sync accuracy improves by 13.7% and 14.2% compared to the best baseline\nand produces results close to the ground truth videos.", "published": "2025-04-08 08:35:59", "link": "http://arxiv.org/abs/2504.05803v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Storybooth: Training-free Multi-Subject Consistency for Improved Visual Storytelling", "abstract": "Training-free consistent text-to-image generation depicting the same subjects\nacross different images is a topic of widespread recent interest. Existing\nworks in this direction predominantly rely on cross-frame self-attention; which\nimproves subject-consistency by allowing tokens in each frame to pay attention\nto tokens in other frames during self-attention computation. While useful for\nsingle subjects, we find that it struggles when scaling to multiple characters.\nIn this work, we first analyze the reason for these limitations. Our\nexploration reveals that the primary-issue stems from self-attention-leakage,\nwhich is exacerbated when trying to ensure consistency across\nmultiple-characters. This happens when tokens from one subject pay attention to\nother characters, causing them to appear like each other (e.g., a dog appearing\nlike a duck). Motivated by these findings, we propose StoryBooth: a\ntraining-free approach for improving multi-character consistency. In\nparticular, we first leverage multi-modal chain-of-thought reasoning and\nregion-based generation to apriori localize the different subjects across the\ndesired story outputs. The final outputs are then generated using a modified\ndiffusion model which consists of two novel layers: 1) a bounded cross-frame\nself-attention layer for reducing inter-character attention leakage, and 2)\ntoken-merging layer for improving consistency of fine-grain subject details.\nThrough both qualitative and quantitative results we find that the proposed\napproach surpasses prior state-of-the-art, exhibiting improved consistency\nacross both multiple-characters and fine-grain subject details.", "published": "2025-04-08 08:30:55", "link": "http://arxiv.org/abs/2504.05800v1", "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Robust Fusion Controller: Degradation-aware Image Fusion with Fine-grained Language Instructions", "abstract": "Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.", "published": "2025-04-08 08:22:55", "link": "http://arxiv.org/abs/2504.05795v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DefMamba: Deformable Visual State Space Model", "abstract": "Recently, state space models (SSM), particularly Mamba, have attracted\nsignificant attention from scholars due to their ability to effectively balance\ncomputational efficiency and performance. However, most existing visual Mamba\nmethods flatten images into 1D sequences using predefined scan orders, which\nresults the model being less capable of utilizing the spatial structural\ninformation of the image during the feature extraction process. To address this\nissue, we proposed a novel visual foundation model called DefMamba. This model\nincludes a multi-scale backbone structure and deformable mamba (DM) blocks,\nwhich dynamically adjust the scanning path to prioritize important information,\nthus enhancing the capture and processing of relevant input features. By\ncombining a deformable scanning(DS) strategy, this model significantly improves\nits ability to learn image structures and detects changes in object details.\nNumerous experiments have shown that DefMamba achieves state-of-the-art\nperformance in various visual tasks, including image classification, object\ndetection, instance segmentation, and semantic segmentation. The code is open\nsource on DefMamba.", "published": "2025-04-08 08:22:54", "link": "http://arxiv.org/abs/2504.05794v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Synthetic Adult Datasets for Unsupervised Infant Pose Estimation", "abstract": "Human pose estimation is a critical tool across a variety of healthcare\napplications. Despite significant progress in pose estimation algorithms\ntargeting adults, such developments for infants remain limited. Existing\nalgorithms for infant pose estimation, despite achieving commendable\nperformance, depend on fully supervised approaches that require large amounts\nof labeled data. These algorithms also struggle with poor generalizability\nunder distribution shifts. To address these challenges, we introduce SHIFT:\nLeveraging SyntHetic Adult Datasets for Unsupervised InFanT Pose Estimation,\nwhich leverages the pseudo-labeling-based Mean-Teacher framework to compensate\nfor the lack of labeled data and addresses distribution shifts by enforcing\nconsistency between the student and the teacher pseudo-labels. Additionally, to\npenalize implausible predictions obtained from the mean-teacher framework, we\nincorporate an infant manifold pose prior. To enhance SHIFT's self-occlusion\nperception ability, we propose a novel visibility consistency module for\nimproved alignment of the predicted poses with the original image. Extensive\nexperiments on multiple benchmarks show that SHIFT significantly outperforms\nexisting state-of-the-art unsupervised domain adaptation (UDA) pose estimation\nmethods by 5% and supervised infant pose estimation methods by a margin of 16%.\nThe project page is available at: https://sarosijbose.github.io/SHIFT.", "published": "2025-04-08 08:13:38", "link": "http://arxiv.org/abs/2504.05789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency Priors", "abstract": "Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.", "published": "2025-04-08 08:00:58", "link": "http://arxiv.org/abs/2504.05779v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InvNeRF-Seg: Fine-Tuning a Pre-Trained NeRF for 3D Object Segmentation", "abstract": "Neural Radiance Fields (NeRF) have been widely adopted for reconstructing\nhigh quality 3D point clouds from 2D RGB images. However, the segmentation of\nthese reconstructed 3D scenes is more essential for downstream tasks such as\nobject counting, size estimation, and scene understanding. While segmentation\non raw 3D point clouds using deep learning requires labor intensive and\ntime-consuming manual annotation, directly training NeRF on binary masks also\nfails due to the absence of color and shading cues essential for geometry\nlearning. We propose Invariant NeRF for Segmentation (InvNeRFSeg), a two step,\nzero change fine tuning strategy for 3D segmentation. We first train a standard\nNeRF on RGB images and then fine tune it using 2D segmentation masks without\naltering either the model architecture or loss function. This approach produces\nhigher quality, cleaner segmented point clouds directly from the refined\nradiance field with minimal computational overhead or complexity. Field density\nanalysis reveals consistent semantic refinement: densities of object regions\nincrease while background densities are suppressed, ensuring clean and\ninterpretable segmentations. We demonstrate InvNeRFSegs superior performance\nover both SA3D and FruitNeRF on both synthetic fruit and real world soybean\ndatasets. This approach effectively extends 2D segmentation to high quality 3D\nsegmentation.", "published": "2025-04-08 07:31:01", "link": "http://arxiv.org/abs/2504.05751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "When Less Is More: A Sparse Facial Motion Structure For Listening Motion Learning", "abstract": "Effective human behavior modeling is critical for successful human-robot\ninteraction. Current state-of-the-art approaches for predicting listening head\nbehavior during dyadic conversations employ continuous-to-discrete\nrepresentations, where continuous facial motion sequence is converted into\ndiscrete latent tokens. However, non-verbal facial motion presents unique\nchallenges owing to its temporal variance and multi-modal nature.\nState-of-the-art discrete motion token representation struggles to capture\nunderlying non-verbal facial patterns making training the listening head\ninefficient with low-fidelity generated motion. This study proposes a novel\nmethod for representing and predicting non-verbal facial motion by encoding\nlong sequences into a sparse sequence of keyframes and transition frames. By\nidentifying crucial motion steps and interpolating intermediate frames, our\nmethod preserves the temporal structure of motion while enhancing instance-wise\ndiversity during the learning process. Additionally, we apply this novel sparse\nrepresentation to the task of listening head prediction, demonstrating its\ncontribution to improving the explanation of facial motion patterns.", "published": "2025-04-08 07:25:12", "link": "http://arxiv.org/abs/2504.05748v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Exploiting Temporal Audio-Visual Correlation Embedding for Audio-Driven One-Shot Talking Head Animation", "abstract": "The paramount challenge in audio-driven One-shot Talking Head Animation\n(ADOS-THA) lies in capturing subtle imperceptible changes between adjacent\nvideo frames. Inherently, the temporal relationship of adjacent audio clips is\nhighly correlated with that of the corresponding adjacent video frames,\noffering supplementary information that can be pivotal for guiding and\nsupervising talking head animations. In this work, we propose to learn\naudio-visual correlations and integrate the correlations to help enhance\nfeature representation and regularize final generation by a novel Temporal\nAudio-Visual Correlation Embedding (TAVCE) framework. Specifically, it first\nlearns an audio-visual temporal correlation metric, ensuring the temporal audio\nrelationships of adjacent clips are aligned with the temporal visual\nrelationships of corresponding adjacent video frames. Since the temporal audio\nrelationship contains aligned information about the visual frame, we first\nintegrate it to guide learning more representative features via a simple yet\neffective channel attention mechanism. During training, we also use the\nalignment correlations as an additional objective to supervise generating\nvisual frames. We conduct extensive experiments on several publicly available\nbenchmarks (i.e., HDTF, LRW, VoxCeleb1, and VoxCeleb2) to demonstrate its\nsuperiority over existing leading algorithms.", "published": "2025-04-08 07:23:28", "link": "http://arxiv.org/abs/2504.05746v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Micro-splatting: Maximizing Isotropic Constraints for Refined Optimization in 3D Gaussian Splatting", "abstract": "Recent advancements in 3D Gaussian Splatting have achieved impressive\nscalability and real-time rendering for large-scale scenes but often fall short\nin capturing fine-grained details. Conventional approaches that rely on\nrelatively large covariance parameters tend to produce blurred representations,\nwhile directly reducing covariance sizes leads to sparsity. In this work, we\nintroduce Micro-splatting (Maximizing Isotropic Constraints for Refined\nOptimization in 3D Gaussian Splatting), a novel framework designed to overcome\nthese limitations. Our approach leverages a covariance regularization term to\npenalize excessively large Gaussians to ensure each splat remains compact and\nisotropic. This work implements an adaptive densification strategy that\ndynamically refines regions with high image gradients by lowering the splitting\nthreshold, followed by loss function enhancement. This strategy results in a\ndenser and more detailed gaussian means where needed, without sacrificing\nrendering efficiency. Quantitative evaluations using metrics such as L1, L2,\nPSNR, SSIM, and LPIPS, alongside qualitative comparisons demonstrate that our\nmethod significantly enhances fine-details in 3D reconstructions.", "published": "2025-04-08 07:15:58", "link": "http://arxiv.org/abs/2504.05740v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "QEMesh: Employing A Quadric Error Metrics-Based Representation for Mesh Generation", "abstract": "Mesh generation plays a crucial role in 3D content creation, as mesh is\nwidely used in various industrial applications. Recent works have achieved\nimpressive results but still face several issues, such as unrealistic patterns\nor pits on surfaces, thin parts missing, and incomplete structures. Most of\nthese problems stem from the choice of shape representation or the capabilities\nof the generative network. To alleviate these, we extend PoNQ, a Quadric Error\nMetrics (QEM)-based representation, and propose a novel model, QEMesh, for\nhigh-quality mesh generation. PoNQ divides the shape surface into tiny patches,\neach represented by a point with its normal and QEM matrix, which preserves\nfine local geometry information. In our QEMesh, we regard these elements as\ngenerable parameters and design a unique latent diffusion model containing a\nnovel multi-decoder VAE for PoNQ parameters generation. Given the latent code\ngenerated by the diffusion model, three parameter decoders produce several PoNQ\nparameters within each voxel cell, and an occupancy decoder predicts which\nvoxel cells containing parameters to form the final shape. Extensive\nevaluations demonstrate that our method generates results with watertight\nsurfaces and is comparable to state-of-the-art methods in several main metrics.", "published": "2025-04-08 06:40:56", "link": "http://arxiv.org/abs/2504.05720v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SEVERE++: Evaluating Benchmark Sensitivity in Generalization of Video Representation Learning", "abstract": "Continued advances in self-supervised learning have led to significant\nprogress in video representation learning, offering a scalable alternative to\nsupervised approaches by removing the need for manual annotations. Despite\nstrong performance on standard action recognition benchmarks, video\nself-supervised learning methods are largely evaluated under narrow protocols,\ntypically pretraining on Kinetics-400 and fine-tuning on similar datasets,\nlimiting our understanding of their generalization in real world scenarios. In\nthis work, we present a comprehensive evaluation of modern video\nself-supervised models, focusing on generalization across four key downstream\nfactors: domain shift, sample efficiency, action granularity, and task\ndiversity. Building on our prior work analyzing benchmark sensitivity in\nCNN-based contrastive learning, we extend the study to cover state-of-the-art\ntransformer-based video-only and video-text models. Specifically, we benchmark\n12 transformer-based methods (7 video-only, 5 video-text) and compare them to\n10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7\ndownstream tasks. Our analysis shows that, despite architectural advances,\ntransformer-based models remain sensitive to downstream conditions. No method\ngeneralizes consistently across all factors, video-only transformers perform\nbetter under domain shifts, CNNs outperform for fine-grained tasks, and\nvideo-text models often underperform despite large scale pretraining. We also\nfind that recent transformer models do not consistently outperform earlier\napproaches. Our findings provide a detailed view of the strengths and\nlimitations of current video SSL methods and offer a unified benchmark for\nevaluating generalization in video representation learning.", "published": "2025-04-08 06:00:28", "link": "http://arxiv.org/abs/2504.05706v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pose-Aware Weakly-Supervised Action Segmentation", "abstract": "Understanding human behavior is an important problem in the pursuit of visual\nintelligence. A challenge in this endeavor is the extensive and costly effort\nrequired to accurately label action segments. To address this issue, we\nconsider learning methods that demand minimal supervision for segmentation of\nhuman actions in long instructional videos. Specifically, we introduce a\nweakly-supervised framework that uniquely incorporates pose knowledge during\ntraining while omitting its use during inference, thereby distilling pose\nknowledge pertinent to each action component. We propose a pose-inspired\ncontrastive loss as a part of the whole weakly-supervised framework which is\ntrained to distinguish action boundaries more effectively. Our approach,\nvalidated through extensive experiments on representative datasets, outperforms\nprevious state-of-the-art (SOTA) in segmenting long instructional videos under\nboth online and offline settings. Additionally, we demonstrate the framework's\nadaptability to various segmentation backbones and pose extractors across\ndifferent datasets.", "published": "2025-04-08 05:42:55", "link": "http://arxiv.org/abs/2504.05700v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Point-based Instance Completion with Scene Constraints", "abstract": "Recent point-based object completion methods have demonstrated the ability to\naccurately recover the missing geometry of partially observed objects. However,\nthese approaches are not well-suited for completing objects within a scene, as\nthey do not consider known scene constraints (e.g., other observed surfaces) in\ntheir completions and further expect the partial input to be in a canonical\ncoordinate system, which does not hold for objects within scenes. While\ninstance scene completion methods have been proposed for completing objects\nwithin a scene, they lag behind point-based object completion methods in terms\nof object completion quality and still do not consider known scene constraints\nduring completion. To overcome these limitations, we propose a point\ncloud-based instance completion model that can robustly complete objects at\narbitrary scales and pose in the scene. To enable reasoning at the scene level,\nwe introduce a sparse set of scene constraints represented as point clouds and\nintegrate them into our completion model via a cross-attention mechanism. To\nevaluate the instance scene completion task on indoor scenes, we further build\na new dataset called ScanWCF, which contains labeled partial scans as well as\naligned ground truth scene completions that are watertight and collision-free.\nThrough several experiments, we demonstrate that our method achieves improved\nfidelity to partial scans, higher completion quality, and greater plausibility\nover existing state-of-the-art methods.", "published": "2025-04-08 05:41:49", "link": "http://arxiv.org/abs/2504.05698v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diabetic Retinopathy Detection Based on Convolutional Neural Networks with SMOTE and CLAHE Techniques Applied to Fundus Images", "abstract": "Diabetic retinopathy (DR) is one of the major complications in diabetic\npatients' eyes, potentially leading to permanent blindness if not detected\ntimely. This study aims to evaluate the accuracy of artificial intelligence\n(AI) in diagnosing DR. The method employed is the Synthetic Minority\nOver-sampling Technique (SMOTE) algorithm, applied to identify DR and its\nseverity stages from fundus images using the public dataset \"APTOS 2019\nBlindness Detection.\" Literature was reviewed via ScienceDirect, ResearchGate,\nGoogle Scholar, and IEEE Xplore. Classification results using Convolutional\nNeural Network (CNN) showed the best performance for the binary classes normal\n(0) and DR (1) with an accuracy of 99.55%, precision of 99.54%, recall of\n99.54%, and F1-score of 99.54%. For the multiclass classification No_DR (0),\nMild (1), Moderate (2), Severe (3), Proliferate_DR (4), the accuracy was\n95.26%, precision 95.26%, recall 95.17%, and F1-score 95.23%. Evaluation using\nthe confusion matrix yielded results of 99.68% for binary classification and\n96.65% for multiclass. This study highlights the significant potential in\nenhancing the accuracy of DR diagnosis compared to traditional human analysis", "published": "2025-04-08 05:38:53", "link": "http://arxiv.org/abs/2504.05696v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.NC"], "primary_category": "eess.IV"}
{"title": "POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction", "abstract": "3D reconstruction in dynamic scenes primarily relies on the combination of\ngeometry estimation and matching modules where the latter task is pivotal for\ndistinguishing dynamic regions which can help to mitigate the interference\nintroduced by camera and object motion. Furthermore, the matching module\nexplicitly models object motion, enabling the tracking of specific targets and\nadvancing motion understanding in complex scenarios. Recently, the proposed\nrepresentation of pointmap in DUSt3R suggests a potential solution to unify\nboth geometry estimation and matching in 3D space, but it still struggles with\nambiguous matching in dynamic regions, which may hamper further improvement. In\nthis work, we present POMATO, a unified framework for dynamic 3D reconstruction\nby marrying pointmap matching with temporal motion. Specifically, our method\nfirst learns an explicit matching relationship by mapping RGB pixels from both\ndynamic and static regions across different views to 3D pointmaps within a\nunified coordinate system. Furthermore, we introduce a temporal motion module\nfor dynamic motions that ensures scale consistency across different frames and\nenhances performance in tasks requiring both precise geometry and reliable\nmatching, most notably 3D point tracking. We show the effectiveness of the\nproposed pointmap matching and temporal fusion paradigm by demonstrating the\nremarkable performance across multiple downstream tasks, including video depth\nestimation, 3D point tracking, and pose estimation. Code and models are\npublicly available at https://github.com/wyddmw/POMATO.", "published": "2025-04-08 05:33:13", "link": "http://arxiv.org/abs/2504.05692v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "On the Suitability of Reinforcement Fine-Tuning to Visual Tasks", "abstract": "Reinforcement Fine-Tuning (RFT) is proved to be greatly valuable for\nenhancing the reasoning ability of LLMs. Researchers have been starting to\napply RFT to MLLMs, hoping it will also enhance the capabilities of visual\nunderstanding. However, these works are at a very early stage and have not\nexamined how suitable RFT actually is for visual tasks. In this work, we\nendeavor to understand the suitabilities and limitations of RFT for visual\ntasks, through experimental analysis and observations. We start by quantitative\ncomparisons on various tasks, which shows RFT is generally better than SFT on\nvisual tasks. %especially when the number of training samples are limited. To\ncheck whether such advantages are brought up by the reasoning process, we\ndesign a new reward that encourages the model to ``think'' more, whose results\nshow more thinking can be beneficial for complicated tasks but harmful for\nsimple tasks. We hope this study can provide more insight for the rapid\nadvancements on this topic.", "published": "2025-04-08 04:45:00", "link": "http://arxiv.org/abs/2504.05682v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-based Civil Infrastructure Visual Defect Detection: ev-CIVIL Dataset and Benchmark", "abstract": "Small Unmanned Aerial Vehicle (UAV) based visual inspections are a more\nefficient alternative to manual methods for examining civil structural defects,\noffering safe access to hazardous areas and significant cost savings by\nreducing labor requirements. However, traditional frame-based cameras, widely\nused in UAV-based inspections, often struggle to capture defects under low or\ndynamic lighting conditions. In contrast, Dynamic Vision Sensors (DVS), or\nevent-based cameras, excel in such scenarios by minimizing motion blur,\nenhancing power efficiency, and maintaining high-quality imaging across diverse\nlighting conditions without saturation or information loss. Despite these\nadvantages, existing research lacks studies exploring the feasibility of using\nDVS for detecting civil structural defects.Moreover, there is no dedicated\nevent-based dataset tailored for this purpose. Addressing this gap, this study\nintroduces the first event-based civil infrastructure defect detection dataset,\ncapturing defective surfaces as a spatio-temporal event stream using DVS.In\naddition to event-based data, the dataset includes grayscale intensity image\nframes captured simultaneously using an Active Pixel Sensor (APS). Both data\ntypes were collected using the DAVIS346 camera, which integrates DVS and APS\nsensors.The dataset focuses on two types of defects: cracks and spalling, and\nincludes data from both field and laboratory environments. The field dataset\ncomprises 318 recording sequences,documenting 458 distinct cracks and 121\ndistinct spalling instances.The laboratory dataset includes 362 recording\nsequences, covering 220 distinct cracks and 308 spalling instances.Four\nrealtime object detection models were evaluated on it to validate the dataset\neffectiveness.The results demonstrate the dataset robustness in enabling\naccurate defect detection and classification,even under challenging lighting\nconditions.", "published": "2025-04-08 04:44:33", "link": "http://arxiv.org/abs/2504.05679v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Noisy Deep Ensemble: Accelerating Deep Ensemble Learning via Noise Injection", "abstract": "Neural network ensembles is a simple yet effective approach for enhancing\ngeneralization capabilities. The most common method involves independently\ntraining multiple neural networks initialized with different weights and then\naveraging their predictions during inference. However, this approach increases\ntraining time linearly with the number of ensemble members. To address this\nissue, we propose the novel ``\\textbf{Noisy Deep Ensemble}'' method,\nsignificantly reducing the training time required for neural network ensembles.\nIn this method, a \\textit{parent model} is trained until convergence, and then\nthe weights of the \\textit{parent model} are perturbed in various ways to\nconstruct multiple \\textit{child models}. This perturbation of the\n\\textit{parent model} weights facilitates the exploration of different local\nminima while significantly reducing the training time for each ensemble member.\nWe evaluated our method using diverse CNN architectures on CIFAR-10 and\nCIFAR-100 datasets, surpassing conventional efficient ensemble methods and\nachieving test accuracy comparable to standard ensembles. Code is available at\n\\href{https://github.com/TSTB-dev/NoisyDeepEnsemble}{https://github.com/TSTB-dev/NoisyDeepEnsemble}", "published": "2025-04-08 04:36:39", "link": "http://arxiv.org/abs/2504.05677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VC-LLM: Automated Advertisement Video Creation from Raw Footage using Multi-modal LLMs", "abstract": "As short videos have risen in popularity, the role of video content in\nadvertising has become increasingly significant. Typically, advertisers record\na large amount of raw footage about the product and then create numerous\ndifferent short-form advertisement videos based on this raw footage. Creating\nsuch videos mainly involves editing raw footage and writing advertisement\nscripts, which requires a certain level of creative ability. It is usually\nchallenging to create many different video contents for the same product, and\nmanual efficiency is often low. In this paper, we present VC-LLM, a framework\npowered by Large Language Models for the automatic creation of high-quality\nshort-form advertisement videos. Our approach leverages high-resolution spatial\ninput and low-resolution temporal input to represent video clips more\neffectively, capturing both fine-grained visual details and broader temporal\ndynamics. In addition, during training, we incorporate supplementary\ninformation generated by rewriting the ground truth text, ensuring that all key\noutput information can be directly traced back to the input, thereby reducing\nmodel hallucinations. We also designed a benchmark to evaluate the quality of\nthe created videos. Experiments show that VC-LLM based on GPT-4o can produce\nvideos comparable to those created by humans. Furthermore, we collected\nnumerous high-quality short advertisement videos to create a pre-training\ndataset and manually cleaned a portion of the data to construct a high-quality\nfine-tuning dataset. Experiments indicate that, on the benchmark, the VC-LLM\nbased on fine-tuned LLM can produce videos with superior narrative logic\ncompared to those created by the VC-LLM based on GPT-4o.", "published": "2025-04-08 04:35:23", "link": "http://arxiv.org/abs/2504.05673v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrastive Decoupled Representation Learning and Regularization for Speech-Preserving Facial Expression Manipulation", "abstract": "Speech-preserving facial expression manipulation (SPFEM) aims to modify a\ntalking head to display a specific reference emotion while preserving the mouth\nanimation of source spoken contents. Thus, emotion and content information\nexisting in reference and source inputs can provide direct and accurate\nsupervision signals for SPFEM models. However, the intrinsic intertwining of\nthese elements during the talking process poses challenges to their\neffectiveness as supervisory signals. In this work, we propose to learn content\nand emotion priors as guidance augmented with contrastive learning to learn\ndecoupled content and emotion representation via an innovative Contrastive\nDecoupled Representation Learning (CDRL) algorithm. Specifically, a Contrastive\nContent Representation Learning (CCRL) module is designed to learn audio\nfeature, which primarily contains content information, as content priors to\nguide learning content representation from the source input. Meanwhile, a\nContrastive Emotion Representation Learning (CERL) module is proposed to make\nuse of a pre-trained visual-language model to learn emotion prior, which is\nthen used to guide learning emotion representation from the reference input. We\nfurther introduce emotion-aware and emotion-augmented contrastive learning to\ntrain CCRL and CERL modules, respectively, ensuring learning\nemotion-independent content representation and content-independent emotion\nrepresentation. During SPFEM model training, the decoupled content and emotion\nrepresentations are used to supervise the generation process, ensuring more\naccurate emotion manipulation together with audio-lip synchronization.\nExtensive experiments and evaluations on various benchmarks show the\neffectiveness of the proposed algorithm.", "published": "2025-04-08 04:34:38", "link": "http://arxiv.org/abs/2504.05672v1", "categories": ["cs.CV", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Reconstruction-Free Anomaly Detection with Diffusion Models via Direct Latent Likelihood Evaluation", "abstract": "Diffusion models, with their robust distribution approximation capabilities,\nhave demonstrated excellent performance in anomaly detection. However,\nconventional reconstruction-based approaches rely on computing the\nreconstruction error between the original and denoised images, which requires\ncareful noise-strength tuning and over ten network evaluations per\ninput-leading to significantly slower detection speeds. To address these\nlimitations, we propose a novel diffusion-based anomaly detection method that\ncircumvents the need for resource-intensive reconstruction. Instead of\nreconstructing the input image, we directly infer its corresponding latent\nvariables and measure their density under the Gaussian prior distribution.\nRemarkably, the prior density proves effective as an anomaly score even when\nusing a short partial diffusion process of only 2-5 steps. We evaluate our\nmethod on the MVTecAD dataset, achieving an AUC of 0.991 at 15 FPS, thereby\nsetting a new state-of-the-art speed-AUC anomaly detection trade-off.", "published": "2025-04-08 04:23:43", "link": "http://arxiv.org/abs/2504.05662v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Measuring D\u00e9j\u00e0 vu Memorization Efficiently", "abstract": "Recent research has shown that representation learning models may\naccidentally memorize their training data. For example, the d\\'ej\\`a vu method\nshows that for certain representation learning models and training images, it\nis sometimes possible to correctly predict the foreground label given only the\nrepresentation of the background - better than through dataset-level\ncorrelations. However, their measurement method requires training two models -\none to estimate dataset-level correlations and the other to estimate\nmemorization. This multiple model setup becomes infeasible for large\nopen-source models. In this work, we propose alternative simple methods to\nestimate dataset-level correlations, and show that these can be used to\napproximate an off-the-shelf model's memorization ability without any\nretraining. This enables, for the first time, the measurement of memorization\nin pre-trained open-source image representation and vision-language\nrepresentation models. Our results show that different ways of measuring\nmemorization yield very similar aggregate results. We also find that\nopen-source models typically have lower aggregate memorization than similar\nmodels trained on a subset of the data. The code is available both for vision\nand vision language models.", "published": "2025-04-08 03:55:20", "link": "http://arxiv.org/abs/2504.05651v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point Cloud", "abstract": "LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.", "published": "2025-04-08 03:53:28", "link": "http://arxiv.org/abs/2504.05649v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via Eliminate Before Align and Keyword Explicit Reasoning", "abstract": "Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),\nwhich aims at searching for the corresponding targets based on the given query.\nAmong these efforts, the application of Foundation Models (FMs), such as CLIP,\nto the domain of remote sensing has yielded encouraging outcomes. However,\nexisting FM based methodologies neglect the negative impact of weakly\ncorrelated sample pairs and fail to account for the key distinctions among\nremote sensing texts, leading to biased and superficial exploration of sample\npairs. To address these challenges, we propose an approach named iEBAKER (an\nImproved Eliminate Before Align strategy with Keyword Explicit Reasoning\nframework) for RSITR. Specifically, we propose an innovative Eliminate Before\nAlign (EBA) strategy to filter out the weakly correlated sample pairs, thereby\nmitigating their deviations from optimal embedding space during\nalignment.Further, two specific schemes are introduced from the perspective of\nwhether local similarity and global similarity affect each other. On this\nbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)\nstrategy, aims at optimizing the similarity matrix via reverse retrieval.\nAdditionally, we incorporate a Keyword Explicit Reasoning (KER) module to\nfacilitate the beneficial impact of subtle key concept distinctions. Without\nbells and whistles, our approach enables a direct transition from FM to RSITR\ntask, eliminating the need for additional pretraining on remote sensing data.\nExtensive experiments conducted on three popular benchmark datasets demonstrate\nthat our proposed iEBAKER method surpasses the state-of-the-art models while\nrequiring less training data. Our source code will be released at\nhttps://github.com/zhangy0822/iEBAKER.", "published": "2025-04-08 03:40:19", "link": "http://arxiv.org/abs/2504.05644v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CTI-Unet: Cascaded Threshold Integration for Improved U-Net Segmentation of Pathology Images", "abstract": "Chronic kidney disease (CKD) is a growing global health concern,\nnecessitating precise and efficient image analysis to aid diagnosis and\ntreatment planning. Automated segmentation of kidney pathology images plays a\ncentral role in facilitating clinical workflows, yet conventional segmentation\nmodels often require delicate threshold tuning. This paper proposes a novel\n\\textit{Cascaded Threshold-Integrated U-Net (CTI-Unet)} to overcome the\nlimitations of single-threshold segmentation. By sequentially integrating\nmultiple thresholded outputs, our approach can reconcile noise suppression with\nthe preservation of finer structural details. Experiments on the challenging\nKPIs2024 dataset demonstrate that CTI-Unet outperforms state-of-the-art\narchitectures such as nnU-Net, Swin-Unet, and CE-Net, offering a robust and\nflexible framework for kidney pathology image segmentation.", "published": "2025-04-08 03:35:09", "link": "http://arxiv.org/abs/2504.05640v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Multi-Modal AI System for Screening Mammography: Integrating 2D and 3D Imaging to Improve Breast Cancer Detection in a Prospective Clinical Study", "abstract": "Although digital breast tomosynthesis (DBT) improves diagnostic performance\nover full-field digital mammography (FFDM), false-positive recalls remain a\nconcern in breast cancer screening. We developed a multi-modal artificial\nintelligence system integrating FFDM, synthetic mammography, and DBT to provide\nbreast-level predictions and bounding-box localizations of suspicious findings.\nOur AI system, trained on approximately 500,000 mammography exams, achieved\n0.945 AUROC on an internal test set. It demonstrated capacity to reduce recalls\nby 31.7% and radiologist workload by 43.8% while maintaining 100% sensitivity,\nunderscoring its potential to improve clinical workflows. External validation\nconfirmed strong generalizability, reducing the gap to a perfect AUROC by\n35.31%-69.14% relative to strong baselines. In prospective deployment across 18\nsites, the system reduced recall rates for low-risk cases. An improved version,\ntrained on over 750,000 exams with additional labels, further reduced the gap\nby 18.86%-56.62% across large external datasets. Overall, these results\nunderscore the importance of utilizing all available imaging modalities,\ndemonstrate the potential for clinical impact, and indicate feasibility of\nfurther reduction of the test error with increased training set when using\nlarge-capacity neural networks.", "published": "2025-04-08 03:29:40", "link": "http://arxiv.org/abs/2504.05636v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Time-Aware Auto White Balance in Mobile Photography", "abstract": "Cameras rely on auto white balance (AWB) to correct undesirable color casts\ncaused by scene illumination and the camera's spectral sensitivity. This is\ntypically achieved using an illuminant estimator that determines the global\ncolor cast solely from the color information in the camera's raw sensor image.\nMobile devices provide valuable additional metadata-such as capture timestamp\nand geolocation-that offers strong contextual clues to help narrow down the\npossible illumination solutions. This paper proposes a lightweight illuminant\nestimation method that incorporates such contextual metadata, along with\nadditional capture information and image colors, into a compact model (~5K\nparameters), achieving promising results, matching or surpassing larger models.\nTo validate our method, we introduce a dataset of 3,224 smartphone images with\ncontextual metadata collected at various times of day and under diverse\nlighting conditions. The dataset includes ground-truth illuminant colors,\ndetermined using a color chart, and user-preferred illuminants validated\nthrough a user study, providing a comprehensive benchmark for AWB evaluation.", "published": "2025-04-08 02:45:37", "link": "http://arxiv.org/abs/2504.05623v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Falcon: Fractional Alternating Cut with Overcoming Minima in Unsupervised Segmentation", "abstract": "Today's unsupervised image segmentation algorithms often segment\nsuboptimally. Modern graph-cut based approaches rely on high-dimensional\nattention maps from Transformer-based foundation models, typically employing a\nrelaxed Normalized Cut solved recursively via the Fiedler vector (the\neigenvector of the second smallest eigenvalue). Consequently, they still lag\nbehind supervised methods in both mask generation speed and segmentation\naccuracy. We present a regularized fractional alternating cut (Falcon), an\noptimization-based K-way Normalized Cut without relying on recursive\neigenvector computations, achieving substantially improved speed and accuracy.\nFalcon operates in two stages: (1) a fast K-way Normalized Cut solved by\nextending into a fractional quadratic transformation, with an alternating\niterative procedure and regularization to avoid local minima; and (2)\nrefinement of the resulting masks using complementary low-level information,\nproducing high-quality pixel-level segmentations. Experiments show that Falcon\nnot only surpasses existing state-of-the-art methods by an average of 2.5%\nacross six widely recognized benchmarks (reaching up to 4.3\\% improvement on\nCityscapes), but also reduces runtime by around 30% compared to prior\ngraph-based approaches. These findings demonstrate that the semantic\ninformation within foundation-model attention can be effectively harnessed by a\nhighly parallelizable graph cut framework. Consequently, Falcon can narrow the\ngap between unsupervised and supervised segmentation, enhancing scalability in\nreal-world applications and paving the way for dense prediction-based vision\npre-training in various downstream tasks. The code is released in\nhttps://github.com/KordingLab/Falcon.", "published": "2025-04-08 01:58:04", "link": "http://arxiv.org/abs/2504.05613v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PyTopo3D: A Python Framework for 3D SIMP-based Topology Optimization", "abstract": "Three-dimensional topology optimization (TO) is a powerful technique in\nengineering design, but readily usable, open-source implementations remain\nlimited within the popular Python scientific environment. This paper introduces\nPyTopo3D, a software framework developed to address this gap. PyTopo3D provides\na feature-rich tool for 3D TO by implementing the well-established Solid\nIsotropic Material with Penalization (SIMP) method and an Optimality Criteria\n(OC) update scheme, adapted and significantly enhanced from the efficient\nMATLAB code by Liu and Tovar (2014). While building on proven methodology,\nPyTopo3D's primary contribution is its integration and extension within Python,\nleveraging sparse matrix operations, optional parallel solvers, and accelerated\nKD-Tree sensitivity filtering for performance. Crucially, it incorporates\nfunctionalities vital for practical engineering workflows, including the direct\nimport of complex design domains and non-design obstacles via STL files,\nintegrated 3D visualization of the optimization process, and direct STL export\nof optimized geometries for manufacturing or further analysis. PyTopo3D is\npresented as an accessible, performance-aware tool and citable reference\ndesigned to empower engineers, students, and researchers to more easily utilize\n3D TO within their existing Python-based workflows.", "published": "2025-04-08 01:32:01", "link": "http://arxiv.org/abs/2504.05604v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "AD-Det: Boosting Object Detection in UAV Images with Focused Small Objects and Balanced Tail Classes", "abstract": "Object detection in Unmanned Aerial Vehicle (UAV) images poses significant\nchallenges due to complex scale variations and class imbalance among objects.\nExisting methods often address these challenges separately, overlooking the\nintricate nature of UAV images and the potential synergy between them. In\nresponse, this paper proposes AD-Det, a novel framework employing a coherent\ncoarse-to-fine strategy that seamlessly integrates two pivotal components:\nAdaptive Small Object Enhancement (ASOE) and Dynamic Class-balanced Copy-paste\n(DCC). ASOE utilizes a high-resolution feature map to identify and cluster\nregions containing small objects. These regions are subsequently enlarged and\nprocessed by a fine-grained detector. On the other hand, DCC conducts\nobject-level resampling by dynamically pasting tail classes around the cluster\ncenters obtained by ASOE, main-taining a dynamic memory bank for each tail\nclass. This approach enables AD-Det to not only extract regions with small\nobjects for precise detection but also dynamically perform reasonable\nresampling for tail-class objects. Consequently, AD-Det enhances the overall\ndetection performance by addressing the challenges of scale variations and\nclass imbalance in UAV images through a synergistic and adaptive framework. We\nextensively evaluate our approach on two public datasets, i.e., VisDrone and\nUAVDT, and demonstrate that AD-Det significantly outperforms existing\ncompetitive alternatives. Notably, AD-Det achieves a 37.5% Average Precision\n(AP) on the VisDrone dataset, surpassing its counterparts by at least 3.1%.", "published": "2025-04-08 01:22:52", "link": "http://arxiv.org/abs/2504.05601v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Tuning-Free Image Editing with Fidelity and Editability via Unified Latent Diffusion Model", "abstract": "Balancing fidelity and editability is essential in text-based image editing\n(TIE), where failures commonly lead to over- or under-editing issues. Existing\nmethods typically rely on attention injections for structure preservation and\nleverage the inherent text alignment capabilities of pre-trained text-to-image\n(T2I) models for editability, but they lack explicit and unified mechanisms to\nproperly balance these two objectives. In this work, we introduce UnifyEdit, a\ntuning-free method that performs diffusion latent optimization to enable a\nbalanced integration of fidelity and editability within a unified framework.\nUnlike direct attention injections, we develop two attention-based constraints:\na self-attention (SA) preservation constraint for structural fidelity, and a\ncross-attention (CA) alignment constraint to enhance text alignment for\nimproved editability. However, simultaneously applying both constraints can\nlead to gradient conflicts, where the dominance of one constraint results in\nover- or under-editing. To address this challenge, we introduce an adaptive\ntime-step scheduler that dynamically adjusts the influence of these\nconstraints, guiding the diffusion latent toward an optimal balance. Extensive\nquantitative and qualitative experiments validate the effectiveness of our\napproach, demonstrating its superiority in achieving a robust balance between\nstructure preservation and text alignment across various editing tasks,\noutperforming other state-of-the-art methods. The source code will be available\nat https://github.com/CUC-MIPG/UnifyEdit.", "published": "2025-04-08 01:02:50", "link": "http://arxiv.org/abs/2504.05594v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoA: Towards Real Image Dehazing via Compression-and-Adaptation", "abstract": "Learning-based image dehazing algorithms have shown remarkable success in\nsynthetic domains. However, real image dehazing is still in suspense due to\ncomputational resource constraints and the diversity of real-world scenes.\nTherefore, there is an urgent need for an algorithm that excels in both\nefficiency and adaptability to address real image dehazing effectively. This\nwork proposes a Compression-and-Adaptation (CoA) computational flow to tackle\nthese challenges from a divide-and-conquer perspective. First, model\ncompression is performed in the synthetic domain to develop a compact dehazing\nparameter space, satisfying efficiency demands. Then, a bilevel adaptation in\nthe real domain is introduced to be fearless in unknown real environments by\naggregating the synthetic dehazing capabilities during the learning process.\nLeveraging a succinct design free from additional constraints, our CoA exhibits\ndomain-irrelevant stability and model-agnostic flexibility, effectively\nbridging the model chasm between synthetic and real domains to further improve\nits practical utility. Extensive evaluations and analyses underscore the\napproach's superiority and effectiveness. The code is publicly available at\nhttps://github.com/fyxnl/COA.", "published": "2025-04-08 00:56:33", "link": "http://arxiv.org/abs/2504.05590v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gaze-Guided Learning: Avoiding Shortcut Bias in Visual Classification", "abstract": "Inspired by human visual attention, deep neural networks have widely adopted\nattention mechanisms to learn locally discriminative attributes for challenging\nvisual classification tasks. However, existing approaches primarily emphasize\nthe representation of such features while neglecting their precise\nlocalization, which often leads to misclassification caused by shortcut biases.\nThis limitation becomes even more pronounced when models are evaluated on\ntransfer or out-of-distribution datasets. In contrast, humans are capable of\nleveraging prior object knowledge to quickly localize and compare fine-grained\nattributes, a capability that is especially crucial in complex and\nhigh-variance classification scenarios. Motivated by this, we introduce\nGaze-CIFAR-10, a human gaze time-series dataset, along with a dual-sequence\ngaze encoder that models the precise sequential localization of human attention\non distinct local attributes. In parallel, a Vision Transformer (ViT) is\nemployed to learn the sequential representation of image content. Through\ncross-modal fusion, our framework integrates human gaze priors with\nmachine-derived visual sequences, effectively correcting inaccurate\nlocalization in image feature representations. Extensive qualitative and\nquantitative experiments demonstrate that gaze-guided cognitive cues\nsignificantly enhance classification accuracy.", "published": "2025-04-08 00:40:46", "link": "http://arxiv.org/abs/2504.05583v1", "categories": ["cs.CV", "I.4.9; I.5.1"], "primary_category": "cs.CV"}
{"title": "TAPNext: Tracking Any Point (TAP) as Next Token Prediction", "abstract": "Tracking Any Point (TAP) in a video is a challenging computer vision problem\nwith many demonstrated applications in robotics, video editing, and 3D\nreconstruction. Existing methods for TAP rely heavily on complex\ntracking-specific inductive biases and heuristics, limiting their generality\nand potential for scaling. To address these challenges, we present TAPNext, a\nnew approach that casts TAP as sequential masked token decoding. Our model is\ncausal, tracks in a purely online fashion, and removes tracking-specific\ninductive biases. This enables TAPNext to run with minimal latency, and removes\nthe temporal windowing required by many existing state of art trackers. Despite\nits simplicity, TAPNext achieves a new state-of-the-art tracking performance\namong both online and offline trackers. Finally, we present evidence that many\nwidely used tracking heuristics emerge naturally in TAPNext through end-to-end\ntraining.", "published": "2025-04-08 00:28:42", "link": "http://arxiv.org/abs/2504.05579v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Lightweight Large Vision-language Model for Multimodal Medical Images", "abstract": "Medical Visual Question Answering (VQA) enhances clinical decision-making by\nenabling systems to interpret medical images and answer clinical queries.\nHowever, developing efficient, high-performance VQA models is challenging due\nto the complexity of medical imagery and diverse modalities. In this paper, we\nintroduce a lightweight, multimodal VQA model integrating BiomedCLIP for image\nfeature extraction and LLaMA-3 for text processing. Designed for medical VQA\ntasks, our model achieves state-of-the-art performance on the OmniMedVQA\ndataset. With approximately 8 billion parameters, it requires only two NVIDIA\n40 GB A100 GPUs, demonstrating superior efficiency over larger models. Our\nresults show 73.4% accuracy for open-end questions, surpassing existing models\nand validating its potential for real-world medical applications. Key\ncontributions include a specialized multimodal VQA model, a resource-efficient\narchitecture, and strong performance in answering open-ended clinical\nquestions.", "published": "2025-04-08 00:19:48", "link": "http://arxiv.org/abs/2504.05575v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut", "abstract": "The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm\nthat finds approximate solutions to problems in combinatorial optimization,\nespecially those that can be formulated as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem. In prior work, researchers have considered various\nways of \"warm-starting\" QAOA by constructing an initial quantum state using\nclassically-obtained solutions or information; these warm-starts typically\ncause QAOA to yield better approximation ratios at much lower circuit depths.\nFor the Max-Cut problem, one warm-start approaches constructs the initial state\nusing the high-dimensional vectors that are output from an SDP relaxation of\nthe corresponding Max-Cut problem. This work leverages these semidefinite\nwarmstarts for a broader class of problem instances by using a standard\nreduction that transforms any QUBO instance into a Max-Cut instance. We\nempirically compare this approach to a \"QUBO-relaxation\" approach that relaxes\nthe QUBO directly. Our results consider a variety of QUBO instances ranging\nfrom randomly generated QUBOs to QUBOs corresponding to specific problems such\nas the traveling salesman problem, maximum independent set, and portfolio\noptimization. We find that the best choice of warmstart approach is strongly\ndependent on the problem type.", "published": "2025-04-08 17:57:12", "link": "http://arxiv.org/abs/2504.06253v1", "categories": ["quant-ph", "cs.DM", "math.OC"], "primary_category": "quant-ph"}
{"title": "Totally equimodular matrices: decomposition and triangulation", "abstract": "Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.", "published": "2025-04-08 11:40:59", "link": "http://arxiv.org/abs/2504.05930v1", "categories": ["math.CO", "cs.DM", "90C27 (Primary), 05B20, 90C10 (Secondary)"], "primary_category": "math.CO"}
{"title": "A Method for Generating Connected Erdos-Renyi Random Graphs", "abstract": "We propose a novel and exact algorithm for generating connected Erdos-Renyi\nrandom graphs $G(n, p)$. Our approach exploits a link between the distribution\nof exploration process trajectories and an inhomogeneous random walk. In\ncontrast to existing methods, our approach guarantees the correct distribution\nunder the connectivity condition and achieves $O(n^2)$ runtime in the sparse\ncase $p = c/n$. Furthermore, we show that our method can be extended to\nuniformly generate connected graphs $G(n, m)$ via an acceptance-rejection\nprocedure.", "published": "2025-04-08 11:06:01", "link": "http://arxiv.org/abs/2504.05907v1", "categories": ["cs.DS", "cs.DM", "cs.IT", "math.CO", "math.IT", "math.PR"], "primary_category": "cs.DS"}
{"title": "Sparse Bounded Hop-Spanners for Geometric Intersection Graphs", "abstract": "We present new results on $2$- and $3$-hop spanners for geometric\nintersection graphs. These include improved upper and lower bounds for $2$- and\n$3$-hop spanners for many geometric intersection graphs in $\\mathbb{R}^d$. For\nexample, we show that the intersection graph of $n$ balls in $\\mathbb{R}^d$\nadmits a $2$-hop spanner of size $O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2\\lfloor\nd/2\\rfloor +1)}}\\right)$ and the intersection graph of $n$ fat axis-parallel\nboxes in $\\mathbb{R}^d$ admits a $2$-hop spanner of size $O(n \\log^{d+1}n)$.\n  Furthermore, we show that the intersection graph of general semi-algebraic\nobjects in $\\mathbb{R}^d$ admits a $3$-hop spanner of size\n$O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2D-1)}}\\right)$, where $D$ is a parameter\nassociated with the description complexity of the objects. For such families\n(or more specifically, for tetrahedra in $\\mathbb{R}^3$), we provide a lower\nbound of $\\Omega(n^{\\frac{4}{3}})$. For $3$-hop and axis-parallel boxes in\n$\\mathbb{R}^d$, we provide the upper bound $O(n \\log ^{d-1}n)$ and lower bound\n$\\Omega\\left(n (\\frac{\\log n}{\\log \\log n})^{d-2}\\right)$.", "published": "2025-04-08 09:40:14", "link": "http://arxiv.org/abs/2504.05861v1", "categories": ["cs.CG", "cs.DM"], "primary_category": "cs.CG"}
{"title": "Knowledge Graph Completion with Relation-Aware Anchor Enhancement", "abstract": "Text-based knowledge graph completion methods take advantage of pre-trained\nlanguage models (PLM) to enhance intrinsic semantic connections of raw triplets\nwith detailed text descriptions. Typical methods in this branch map an input\nquery (textual descriptions associated with an entity and a relation) and its\ncandidate entities into feature vectors, respectively, and then maximize the\nprobability of valid triples. These methods are gaining promising performance\nand increasing attention for the rapid development of large language models.\nAccording to the property of the language models, the more related and specific\ncontext information the input query provides, the more discriminative the\nresultant embedding will be. In this paper, through observation and validation,\nwe find a neglected fact that the relation-aware neighbors of the head entities\nin queries could act as effective contexts for more precise link prediction.\nDriven by this finding, we propose a relation-aware anchor enhanced knowledge\ngraph completion method (RAA-KGC). Specifically, in our method, to provide a\nreference of what might the target entity be like, we first generate anchor\nentities within the relation-aware neighborhood of the head entity. Then, by\npulling the query embedding towards the neighborhoods of the anchors, it is\ntuned to be more discriminative for target entity matching. The results of our\nextensive experiments not only validate the efficacy of RAA-KGC but also reveal\nthat by integrating our relation-aware anchor enhancement strategy, the\nperformance of current leading methods can be notably enhanced without\nsubstantial modifications.", "published": "2025-04-08 15:22:08", "link": "http://arxiv.org/abs/2504.06129v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Widening the Role of Group Recommender Systems with CAJO", "abstract": "Group Recommender Systems (GRSs) have been studied and developed for more\nthan twenty years. However, their application and usage has not grown. They can\neven be labeled as failures, if compared to the very successful and common\nrecommender systems (RSs) used on all the major ecommerce and social platforms.\nAs a result, the RSs that we all use now, are only targeted for individual\nusers, aiming at choosing an item exclusively for themselves; no choice support\nis provided to groups trying to select a service, a product, an experience, a\nperson, serving equally well all the group members. In this opinion article we\ndiscuss why the success of group recommender systems is lagging and we propose\na research program unfolding on the analysis and development of new forms of\ncollaboration between humans and intelligent systems. We define a set of roles,\nnamed CAJO, that GRSs should play in order to become more useful tools for\ngroup decision making.", "published": "2025-04-08 11:47:40", "link": "http://arxiv.org/abs/2504.05934v1", "categories": ["cs.IR", "cs.HC", "H.1.2; H.5.0; H.5.2; H.5.3; I.2.6; I.2.7; I.2.8"], "primary_category": "cs.IR"}
{"title": "Why is Normalization Necessary for Linear Recommenders?", "abstract": "Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.", "published": "2025-04-08 08:37:32", "link": "http://arxiv.org/abs/2504.05805v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization", "abstract": "The integration of large language models (LLMs) into information retrieval\nsystems introduces new attack surfaces, particularly for adversarial ranking\nmanipulations. We present StealthRank, a novel adversarial ranking attack that\nmanipulates LLM-driven product recommendation systems while maintaining textual\nfluency and stealth. Unlike existing methods that often introduce detectable\nanomalies, StealthRank employs an energy-based optimization framework combined\nwith Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text\nsequences embedded within product descriptions that subtly yet effectively\ninfluence LLM ranking mechanisms. We evaluate StealthRank across multiple LLMs,\ndemonstrating its ability to covertly boost the ranking of target products\nwhile avoiding explicit manipulation traces that can be easily detected. Our\nresults show that StealthRank consistently outperforms state-of-the-art\nadversarial ranking baselines in both effectiveness and stealth, highlighting\ncritical vulnerabilities in LLM-driven recommendation systems.", "published": "2025-04-08 08:36:18", "link": "http://arxiv.org/abs/2504.05804v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Unified Generative Search and Recommendation", "abstract": "Modern commercial platforms typically offer both search and recommendation\nfunctionalities to serve diverse user needs, making joint modeling of these\ntasks an appealing direction. While prior work has shown that integrating\nsearch and recommendation can be mutually beneficial, it also reveals a\nperformance trade-off: enhancements in one task often come at the expense of\nthe other. This challenge arises from their distinct information requirements:\nsearch emphasizes semantic relevance between queries and items, whereas\nrecommendation depends more on collaborative signals among users and items.\nEffectively addressing this trade-off requires tackling two key problems: (1)\nintegrating both semantic and collaborative signals into item representations,\nand (2) guiding the model to distinguish and adapt to the unique demands of\nsearch and recommendation. The emergence of generative retrieval with Large\nLanguage Models (LLMs) presents new possibilities. This paradigm encodes items\nas identifiers and frames both search and recommendation as sequential\ngeneration tasks, offering the flexibility to leverage multiple identifiers and\ntask-specific prompts. In light of this, we introduce GenSAR, a unified\ngenerative framework for balanced search and recommendation. Our approach\ndesigns dual-purpose identifiers and tailored training strategies to\nincorporate complementary signals and align with task-specific objectives.\nExperiments on both public and commercial datasets demonstrate that GenSAR\neffectively reduces the trade-off and achieves state-of-the-art performance on\nboth tasks.", "published": "2025-04-08 07:03:08", "link": "http://arxiv.org/abs/2504.05730v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task Fusion in Recommender Systems", "abstract": "Recommender systems need to optimize various types of user feedback, e.g.,\nclicks, likes, and shares. A typical recommender system handling multiple types\nof feedback has two components: a multi-task learning (MTL) module, predicting\nfeedback such as click-through rate and like rate; and a multi-task fusion\n(MTF) module, integrating these predictions into a single score for item\nranking. MTF is essential for ensuring user satisfaction, as it directly\ninfluences recommendation outcomes. Recently, reinforcement learning (RL) has\nbeen applied to MTF tasks to improve long-term user satisfaction. However,\nexisting RL-based MTF methods are formula-based methods, which only adjust\nlimited coefficients within pre-defined formulas. The pre-defined formulas\nrestrict the RL search space and become a bottleneck for MTF. To overcome this,\nwe propose a formula-free MTF framework. We demonstrate that any suitable\nfusion function can be expressed as a composition of single-variable monotonic\nfunctions, as per the Sprecher Representation Theorem. Leveraging this, we\nintroduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined\nformulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we\nemploy a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By\nexpanding the MTF search space, xMTF outperforms existing methods in extensive\noffline and online experiments.", "published": "2025-04-08 04:28:22", "link": "http://arxiv.org/abs/2504.05669v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Simplifying Data Integration: SLM-Driven Systems for Unified Semantic Queries Across Heterogeneous Databases", "abstract": "The integration of heterogeneous databases into a unified querying framework\nremains a critical challenge, particularly in resource-constrained\nenvironments. This paper presents a novel Small Language Model(SLM)-driven\nsystem that synergizes advancements in lightweight Retrieval-Augmented\nGeneration (RAG) and semantic-aware data structuring to enable efficient,\naccurate, and scalable query resolution across diverse data formats. By\nintegrating MiniRAG's semantic-aware heterogeneous graph indexing and\ntopology-enhanced retrieval with SLM-powered structured data extraction, our\nsystem addresses the limitations of traditional methods in handling\nMulti-Entity Question Answering (Multi-Entity QA) and complex semantic queries.\nExperimental results demonstrate superior performance in accuracy and\nefficiency, while the introduction of semantic entropy as an unsupervised\nevaluation metric provides robust insights into model uncertainty. This work\npioneers a cost-effective, domain-agnostic solution for next-generation\ndatabase systems.", "published": "2025-04-08 03:28:03", "link": "http://arxiv.org/abs/2504.05634v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Stratified Expert Cloning with Adaptive Selection for User Retention in Large-Scale Recommender Systems", "abstract": "User retention has emerged as a critical challenge in large-scale recommender\nsystems, significantly impacting the long-term success of online platforms.\nExisting methods often focus on short-term engagement metrics, failing to\ncapture the complex dynamics of user preferences and behaviors over extended\nperiods. While reinforcement learning (RL) approaches have shown promise in\noptimizing long-term rewards, they face difficulties in credit assignment,\nsample efficiency, and exploration when applied to the user retention problem.\nIn this work, we propose Stratified Expert Cloning (SEC), a novel imitation\nlearning framework that effectively leverages abundant logged data from\nhigh-retention users to learn robust recommendation policies. SEC introduces\nthree key innovations: 1) a multi-level expert stratification strategy that\ncaptures the nuances in expert user behaviors at different retention levels; 2)\nan adaptive expert selection mechanism that dynamically assigns users to the\nmost suitable policy based on their current state and historical retention\nlevel; and 3) an action entropy regularization technique that promotes\nrecommendation diversity and mitigates the risk of policy collapse. Through\nextensive offline experiments and online A/B tests on two major video\nplatforms, Kuaishou and Kuaishou Lite, with hundreds of millions of daily\nactive users, we demonstrate SEC's significant improvements over\nstate-of-the-art methods in user retention. The results demonstrate significant\nimprovements in user retention, with cumulative lifts of 0.098\\% and 0.122\\% in\nactive days on Kuaishou and Kuaishou Lite respectively, additionally bringing\ntens of thousands of daily active users to each platform.", "published": "2025-04-08 03:10:42", "link": "http://arxiv.org/abs/2504.05628v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The Work Capacity of Channels with Memory: Maximum Extractable Work in Percept-Action Loops", "abstract": "Predicting future observations plays a central role in machine learning,\nbiology, economics, and many other fields. It lies at the heart of\norganizational principles such as the variational free energy principle and has\neven been shown -- based on the second law of thermodynamics -- to be necessary\nfor reaching the fundamental energetic limits of sequential information\nprocessing. While the usefulness of the predictive paradigm is undisputed,\ncomplex adaptive systems that interact with their environment are more than\njust predictive machines: they have the power to act upon their environment and\ncause change. In this work, we develop a framework to analyze the\nthermodynamics of information processing in percept-action loops -- a model of\nagent-environment interaction -- allowing us to investigate the thermodynamic\nimplications of actions and percepts on equal footing. To this end, we\nintroduce the concept of work capacity -- the maximum rate at which an agent\ncan expect to extract work from its environment. Our results reveal that\nneither of two previously established design principles for work-efficient\nagents -- maximizing predictive power and forgetting past actions -- remains\noptimal in environments where actions have observable consequences. Instead, a\ntrade-off emerges: work-efficient agents must balance prediction and\nforgetting, as remembering past actions can reduce the available free energy.\nThis highlights a fundamental departure from the thermodynamics of passive\nobservation, suggesting that prediction and energy efficiency may be at odds in\nactive learning systems.", "published": "2025-04-08 16:54:20", "link": "http://arxiv.org/abs/2504.06209v1", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.IT", "math.IT", "nlin.AO", "nlin.CD", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Old and New Results on Alphabetic Codes", "abstract": "This comprehensive survey examines the field of alphabetic codes, tracing\ntheir development from the 1960s to the present day. We explore classical\nalphabetic codes and their variants, analyzing their properties and the\nunderlying mathematical and algorithmic principles. The paper covers the\nfundamental relationship between alphabetic codes and comparison-based search\nprocedures and their applications in data compression, routing, and testing. We\nreview optimal alphabetic code construction algorithms, necessary and\nsufficient conditions for their existence, and upper bounds on the average code\nlength of optimal alphabetic codes. The survey also discusses variations and\ngeneralizations of the classical problem of constructing minimum average length\nalphabetic codes. By elucidating both classical results and recent findings,\nthis paper aims to serve as a valuable resource for researchers and students,\nconcluding with promising future research directions in this still-active\nfield.", "published": "2025-04-08 12:15:53", "link": "http://arxiv.org/abs/2504.05959v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacity Region for Covert Secret Key Generation over Multiple Access Channels", "abstract": "We study covert secret key generation over a binary-input two-user multiple\naccess channel with one-way public discussion and derive bounds on the capacity\nregion. Specifically, in this problem, there are three legitimate parties:\nAlice, Bob and Charlie. The goal is to allow Charlie to generate a secret key\nwith Alice and another secret key with Bob, reliably, secretly and covertly.\nReliability ensures that the key generated by Alice and Charlie is the same and\nthe key generated by Bob and Charlie is the same. Secrecy ensures that the\nsecret keys generated are only known to specific legitimate parties. Covertness\nensures that the key generation process is undetectable by a warden Willie. As\na corollary of our result, we establish bounds on the capacity region of\nwiretap secret key generation without the covertness constraint and discuss the\nimpact of covertness. Our results generalize the point-to-point result of\nTahmasbi and Bloch (TIFS 2020) to the setting of multiterminal communication.", "published": "2025-04-08 09:08:45", "link": "http://arxiv.org/abs/2504.05828v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-Complexity AoI-Optimal Status Update Control with Partial Battery State Information in Energy Harvesting IoT Networks", "abstract": "For a two-hop IoT system consisting of multiple energy harvesting sensors, a\ncache-enabled edge node, and multiple monitors, the status update control at\nthe edge node, which has partial battery state information (pBSI) of the\nsensors, is formulated as a pBSI problem. The concept of inferred pBSI is\nintroduced to reduce the noiseless single-sensor pBSI problem to a Markov\ndecision process with a moderate state-space size, enabling the optimal policy\nto be obtained through a value iteration algorithm. A lower bound on the\nexpected time-average on-demand age of information performance is established\nfor the general single-sensor status update problem. For the single-sensor pBSI\nproblem, a semi-closed-form policy called the current-next (CN) policy is\nproposed, along with an efficient post-update value iteration algorithm with a\nper-iteration time complexity proportional to the square of the battery\ncapacity. A weighted-update-gain-competition (WUGC) approach is further\nleveraged to extend the CN policy to the multi-sensor case. Numerical results\nin the single-sensor case demonstrate the near-optimal performance of the CN\npolicy across various energy arrival processes. Simulations for an IoT system\nwith $100$ sensors reveal that the WUGC-CN policy outperforms the\nmaximum-age-first policy and the random-scheduling-based CN policy under\nBernoulli energy arrival processes.", "published": "2025-04-08 08:40:36", "link": "http://arxiv.org/abs/2504.05807v1", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Pinching-Antenna Assisted ISAC: A CRLB Perspective", "abstract": "Recently, pinching antennas have attracted significant research interest due\nto their capability to reconfigure wireless channels as well as their array\nconfiguration flexibility. This letter focuses on how these features can be\nused to support integrated sensing and communications (ISAC) from the Cramer\nRao lower bound (CRLB) perspective. In particular, the CRLB achieved by\npinching antennas is first derived and then compared to that of conventional\nantennas. The presented analytical and simulation results demonstrate that\nusing pinching antennas can significantly reduce CRLB and, hence, enhance\npositioning accuracy. In addition, this letter also reveals that the low-cost\nand reconfigurability features of pinching antennas can be utilized to realize\nflexible user-centric positioning.", "published": "2025-04-08 08:21:58", "link": "http://arxiv.org/abs/2504.05792v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust and Efficient Average Consensus with Non-Coherent Over-the-Air Aggregation", "abstract": "Non-coherent over-the-air (OTA) computation has garnered increasing attention\nfor its advantages in facilitating information aggregation among distributed\nagents in resource-constrained networks without requiring precise channel\nestimation. A promising application scenario of this method is distributed\naverage consensus in wireless multi-agent systems. However, in such scenario,\nnon-coherent interference from concurrent OTA transmissions can introduce bias\nin the consensus value. To address this issue, we develop a robust distributed\naverage consensus algorithm by formulating the consensus problem as a\ndistributed optimization problem. Using decentralized projected gradient\ndescent (D-PGD), our proposed algorithm can achieve unbiased mean square\naverage consensus even in the presence of non-coherent interference and noise.\nAdditionally, we implement transmit power control and receive scaling\nmechanisms to further accelerate convergence. Simulation results demonstrate\nthat our method can significantly enhance the convergence speed of the D-PGD\nalgorithm for OTA average consensus without compromising accuracy.", "published": "2025-04-08 07:03:02", "link": "http://arxiv.org/abs/2504.05729v1", "categories": ["cs.IT", "cs.SY", "eess.SP", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Curved representational Bregman divergences and their applications", "abstract": "By analogy to curved exponential families, we define curved Bregman\ndivergences as restrictions of Bregman divergences to sub-dimensional parameter\nsubspaces, and prove that the barycenter of a finite weighted parameter set\nwith respect to a curved Bregman divergence amounts to the Bregman projection\nonto the subspace induced by the constraint of the barycenter with respect to\nthe unconstrained full Bregman divergence. We demonstrate the significance of\ncurved Bregman divergences with two examples: (1) symmetrized Bregman\ndivergences and (2) the Kullback-Leibler divergence between circular complex\nnormal distributions. We then consider monotonic embeddings to define\nrepresentational curved Bregman divergences and show that the\n$\\alpha$-divergences are representational curved Bregman divergences with\nrespect to $\\alpha$-embeddings of the probability simplex into the positive\nmeasure cone. As an application, we report an efficient method to calculate the\nintersection of a finite set of $\\alpha$-divergence spheres.", "published": "2025-04-08 04:05:12", "link": "http://arxiv.org/abs/2504.05654v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Recent Advances in Near-Field Beam Training and Channel Estimation for XL-MIMO Systems", "abstract": "Extremely large-scale multiple-input multiple-output (XL-MIMO) is a key\ntechnology for next-generation wireless communication systems. By deploying\nsignificantly more antennas than conventional massive MIMO systems, XL-MIMO\npromises substantial improvements in spectral efficiency. However, due to the\ndrastically increased array size, the conventional planar wave channel model is\nno longer accurate, necessitating a transition to a near-field spherical wave\nmodel. This shift challenges traditional beam training and channel estimation\nmethods, which were designed for planar wave propagation. In this article, we\npresent a comprehensive review of state-of-the-art beam training and channel\nestimation techniques for XL-MIMO systems. We analyze the fundamental\nprinciples, key methodologies, and recent advancements in this area,\nhighlighting their respective strengths and limitations in addressing the\nchallenges posed by the near-field propagation environment. Furthermore, we\nexplore open research challenges that remain unresolved to provide valuable\ninsights for researchers and engineers working toward the development of\nnext-generation XL-MIMO communication systems.", "published": "2025-04-08 00:26:32", "link": "http://arxiv.org/abs/2504.05578v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fractal and Regular Geometry of Deep Neural Networks", "abstract": "We study the geometric properties of random neural networks by investigating\nthe boundary volumes of their excursion sets for different activation\nfunctions, as the depth increases. More specifically, we show that, for\nactivations which are not very regular (e.g., the Heaviside step function), the\nboundary volumes exhibit fractal behavior, with their Hausdorff dimension\nmonotonically increasing with the depth. On the other hand, for activations\nwhich are more regular (e.g., ReLU, logistic and $\\tanh$), as the depth\nincreases, the expected boundary volumes can either converge to zero, remain\nconstant or diverge exponentially, depending on a single spectral parameter\nwhich can be easily computed. Our theoretical results are confirmed in some\nnumerical experiments based on Monte Carlo simulations.", "published": "2025-04-08 17:56:05", "link": "http://arxiv.org/abs/2504.06250v1", "categories": ["math.PR", "cs.LG", "stat.ML", "60G60, 62B10, 62M45, 68T07"], "primary_category": "math.PR"}
{"title": "NNN: Next-Generation Neural Networks for Marketing Mix Modeling", "abstract": "We present NNN, a Transformer-based neural network approach to Marketing Mix\nModeling (MMM) designed to address key limitations of traditional methods.\nUnlike conventional MMMs which rely on scalar inputs and parametric decay\nfunctions, NNN uses rich embeddings to capture both quantitative and\nqualitative aspects of marketing and organic channels (e.g., search queries, ad\ncreatives). This, combined with its attention mechanism, enables NNN to model\ncomplex interactions, capture long-term effects, and potentially improve sales\nattribution accuracy. We show that L1 regularization permits the use of such\nexpressive models in typical data-constrained settings. Evaluating NNN on\nsimulated and real-world data demonstrates its efficacy, particularly through\nconsiderable improvement in predictive power. Beyond attribution, NNN provides\nvaluable, complementary insights through model probing, such as evaluating\nkeyword or creative effectiveness, enhancing model interpretability.", "published": "2025-04-08 16:57:11", "link": "http://arxiv.org/abs/2504.06212v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Hall Effect Thruster Forecasting using a Topological Approach for Data Assimilation", "abstract": "Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized\ngas particles from the spacecraft to generate thrust. Although traditionally\nthey were used for station keeping, recently They have been used for\ninterplanetary space missions due to their high delta-V potential and their\noperational longevity in contrast to other thrusters, e.g., chemical. However,\nthe operation of HETs involves complex processes such as ionization of gases,\nstrong magnetic fields, and complicated solar panel power supply interactions.\nTherefore, their operation is extremely difficult to model thus necessitating\nData Assimilation (DA) approaches for estimating and predicting their\noperational states. Because HET's operating environment is often noisy with\nnon-Gaussian sources, this significantly limits applicable DA tools. We\ndescribe a topological approach for data assimilation that bypasses these\nlimitations that does not depend on the noise model, and utilize it to forecast\nspatiotemporal plume field states of HETs. Our approach is a generalization of\nthe Topological Approach for Data Assimilation (TADA) method that allows\nincluding different forecast functions. We show how TADA can be combined with\nthe Long Short-Term Memory network for accurate forecasting. We then apply our\napproach to high-fidelity Hall Effect Thruster (HET) simulation data from the\nAir Force Research Laboratory (AFRL) rocket propulsion division where we\ndemonstrate the forecast resiliency of TADA on noise contaminated,\nhigh-dimensional data.", "published": "2025-04-08 15:52:50", "link": "http://arxiv.org/abs/2504.06157v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adversarial Training of Reward Models", "abstract": "Reward modeling has emerged as a promising approach for the scalable\nalignment of language models. However, contemporary reward models (RMs) often\nlack robustness, awarding high rewards to low-quality, out-of-distribution\n(OOD) samples. This can lead to reward hacking, where policies exploit\nunintended shortcuts to maximize rewards, undermining alignment. To address\nthis challenge, we introduce Adv-RM, a novel adversarial training framework\nthat automatically identifies adversarial examples -- responses that receive\nhigh rewards from the target RM but are OOD and of low quality. By leveraging\nreinforcement learning, Adv-RM trains a policy to generate adversarial examples\nthat reliably expose vulnerabilities in large state-of-the-art reward models\nsuch as Nemotron 340B RM. Incorporating these adversarial examples into the\nreward training process improves the robustness of RMs, mitigating reward\nhacking and enhancing downstream performance in RLHF. We demonstrate that\nAdv-RM significantly outperforms conventional RM training, increasing stability\nand enabling more effective RLHF training in both synthetic and real-data\nsettings.", "published": "2025-04-08 15:38:25", "link": "http://arxiv.org/abs/2504.06141v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms", "abstract": "Vehicle Routing Problems (VRP) are an extension of the Traveling Salesperson\nProblem and are a fundamental NP-hard challenge in combinatorial optimization.\nSolving VRP in real-time at large scale has become critical in numerous\napplications, from growing markets like last-mile delivery to emerging\nuse-cases like interactive logistics planning. Such applications involve\nsolving similar problem instances repeatedly, yet current state-of-the-art\nsolvers treat each instance on its own without leveraging previous examples. We\nintroduce a novel optimization framework that uses a reinforcement learning\nagent - trained on prior instances - to quickly generate initial solutions,\nwhich are then further optimized by genetic algorithms. Our framework,\nEvolutionary Algorithm with Reinforcement Learning Initialization (EARLI),\nconsistently outperforms current state-of-the-art solvers across various time\nscales. For example, EARLI handles vehicle routing with 500 locations within\n1s, 10x faster than current solvers for the same solution quality, enabling\napplications like real-time and interactive routing. EARLI can generalize to\nnew data, as demonstrated on real e-commerce delivery data of a previously\nunseen city. Our hybrid framework presents a new way to combine reinforcement\nlearning and genetic algorithms, paving the road for closer interdisciplinary\ncollaboration between AI and optimization communities towards real-time\noptimization in diverse domains.", "published": "2025-04-08 15:21:01", "link": "http://arxiv.org/abs/2504.06126v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Robo-taxi Fleet Coordination at Scale via Reinforcement Learning", "abstract": "Fleets of robo-taxis offering on-demand transportation services, commonly\nknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise\nfor societal benefits, such as reducing pollution, energy consumption, and\nurban congestion. However, orchestrating these systems at scale remains a\ncritical challenge, with existing coordination algorithms often failing to\nexploit the systems' full potential. This work introduces a novel\ndecision-making framework that unites mathematical modeling with data-driven\ntechniques. In particular, we present the AMoD coordination problem through the\nlens of reinforcement learning and propose a graph network-based framework that\nexploits the main strengths of graph representation learning, reinforcement\nlearning, and classical operations research tools. Extensive evaluations across\ndiverse simulation fidelities and scenarios demonstrate the flexibility of our\napproach, achieving superior system performance, computational efficiency, and\ngeneralizability compared to prior methods. Finally, motivated by the need to\ndemocratize research efforts in this area, we release publicly available\nbenchmarks, datasets, and simulators for network-level coordination alongside\nan open-source codebase designed to provide accessible simulation platforms and\nestablish a standardized validation process for comparing methodologies. Code\navailable at: https://github.com/StanfordASL/RL4AMOD", "published": "2025-04-08 15:19:41", "link": "http://arxiv.org/abs/2504.06125v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Leveraging Axis-Aligned Subspaces for High-Dimensional Bayesian Optimization with Group Testing", "abstract": "Bayesian optimization (BO ) is an effective method for optimizing\nexpensive-to-evaluate black-box functions. While high-dimensional problems can\nbe particularly challenging, due to the multitude of parameter choices and the\npotentially high number of data points required to fit the model, this\nlimitation can be addressed if the problem satisfies simplifying assumptions.\nAxis-aligned subspace approaches, where few dimensions have a significant\nimpact on the objective, motivated several algorithms for high-dimensional BO .\nHowever, the validity of this assumption is rarely verified, and the assumption\nis rarely exploited to its full extent. We propose a group testing ( GT)\napproach to identify active variables to facilitate efficient optimization in\nthese domains. The proposed algorithm, Group Testing Bayesian Optimization\n(GTBO), first runs a testing phase where groups of variables are systematically\nselected and tested on whether they influence the objective, then terminates\nonce active dimensions are identified. To that end, we extend the\nwell-established GT theory to functions over continuous domains. In the second\nphase, GTBO guides optimization by placing more importance on the active\ndimensions. By leveraging the axis-aligned subspace assumption, GTBO\noutperforms state-of-the-art methods on benchmarks satisfying the assumption of\naxis-aligned subspaces, while offering improved interpretability.", "published": "2025-04-08 15:00:15", "link": "http://arxiv.org/abs/2504.06111v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for Scaled-up LLM Training", "abstract": "LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.", "published": "2025-04-08 14:35:40", "link": "http://arxiv.org/abs/2504.06095v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Accurate Ab-initio Neural-network Solutions to Large-Scale Electronic Structure Problems", "abstract": "We present finite-range embeddings (FiRE), a novel wave function ansatz for\naccurate large-scale ab-initio electronic structure calculations. Compared to\ncontemporary neural-network wave functions, FiRE reduces the asymptotic\ncomplexity of neural-network variational Monte Carlo (NN-VMC) by $\\sim\nn_\\text{el}$, the number of electrons. By restricting electron-electron\ninteractions within the neural network, FiRE accelerates all key operations --\nsampling, pseudopotentials, and Laplacian computations -- resulting in a\nreal-world $10\\times$ acceleration in now-feasible 180-electron calculations.\nWe validate our method's accuracy on various challenging systems, including\nbiochemical compounds, conjugated hydrocarbons, and organometallic compounds.\nOn these systems, FiRE's energies are consistently within chemical accuracy of\nthe most reliable data, including experiments, even in cases where\nhigh-accuracy methods such as CCSD(T), AFQMC, or contemporary NN-VMC fall\nshort. With these improvements in both runtime and accuracy, FiRE represents a\nnew `gold-standard' method for fast and accurate large-scale ab-initio\ncalculations, potentially enabling new computational studies in fields like\nquantum chemistry, solid-state physics, and material design.", "published": "2025-04-08 14:28:54", "link": "http://arxiv.org/abs/2504.06087v1", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph"], "primary_category": "physics.comp-ph"}
{"title": "Collaborative Prediction: Tractable Information Aggregation via Agreement", "abstract": "We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.", "published": "2025-04-08 14:12:42", "link": "http://arxiv.org/abs/2504.06075v1", "categories": ["cs.LG", "cs.DS", "cs.GT"], "primary_category": "cs.LG"}
{"title": "PINP: Physics-Informed Neural Predictor with latent estimation of fluid flows", "abstract": "Accurately predicting fluid dynamics and evolution has been a long-standing\nchallenge in physical sciences. Conventional deep learning methods often rely\non the nonlinear modeling capabilities of neural networks to establish mappings\nbetween past and future states, overlooking the fluid dynamics, or only\nmodeling the velocity field, neglecting the coupling of multiple physical\nquantities. In this paper, we propose a new physics-informed learning approach\nthat incorporates coupled physical quantities into the prediction process to\nassist with forecasting. Central to our method lies in the discretization of\nphysical equations, which are directly integrated into the model architecture\nand loss function. This integration enables the model to provide robust,\nlong-term future predictions. By incorporating physical equations, our model\ndemonstrates temporal extrapolation and spatial generalization capabilities.\nExperimental results show that our approach achieves the state-of-the-art\nperformance in spatiotemporal prediction across both numerical simulations and\nreal-world extreme-precipitation nowcasting benchmarks.", "published": "2025-04-08 14:11:01", "link": "http://arxiv.org/abs/2504.06070v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Explainable AI for building energy retrofitting under data scarcity", "abstract": "Enhancing energy efficiency in residential buildings is a crucial step toward\nmitigating climate change and reducing greenhouse gas emissions. Retrofitting\nexisting buildings, which account for a significant portion of energy\nconsumption, is critical particularly in regions with outdated and inefficient\nbuilding stocks. This study presents an Artificial Intelligence (AI) and\nMachine Learning (ML)-based framework to recommend energy efficiency measures\nfor residential buildings, leveraging accessible building characteristics to\nachieve energy class targets. Using Latvia as a case study, the methodology\naddresses challenges associated with limited datasets, class imbalance and data\nscarcity. The proposed approach integrates Conditional Tabular Generative\nAdversarial Networks (CTGAN) to generate synthetic data, enriching and\nbalancing the dataset. A Multi-Layer Perceptron (MLP) model serves as the\npredictive model performing multi-label classification to predict appropriate\nretrofit strategies. Explainable Artificial Intelligence (XAI), specifically\nSHapley Additive exPlanations (SHAP), ensures transparency and trust by\nidentifying key features that influence recommendations and guiding feature\nengineering choices for improved reliability and performance. The evaluation of\nthe approach shows that it notably overcomes data limitations, achieving\nimprovements up to 54% in precision, recall and F1 score. Although this study\nfocuses on Latvia, the methodology is adaptable to other regions, underscoring\nthe potential of AI in reducing the complexity and cost of building energy\nretrofitting overcoming data limitations. By facilitating decision-making\nprocesses and promoting stakeholders engagement, this work supports the global\ntransition toward sustainable energy use in the residential building sector.", "published": "2025-04-08 14:00:08", "link": "http://arxiv.org/abs/2504.06055v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Trust-Region Twisted Policy Improvement", "abstract": "Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.", "published": "2025-04-08 13:47:07", "link": "http://arxiv.org/abs/2504.06048v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Smart Exploration in Reinforcement Learning using Bounded Uncertainty Models", "abstract": "Reinforcement learning (RL) is a powerful tool for decision-making in\nuncertain environments, but it often requires large amounts of data to learn an\noptimal policy. We propose using prior model knowledge to guide the exploration\nprocess to speed up this learning process. This model knowledge comes in the\nform of a model set to which the true transition kernel and reward function\nbelong. We optimize over this model set to obtain upper and lower bounds on the\nQ-function, which are then used to guide the exploration of the agent. We\nprovide theoretical guarantees on the convergence of the Q-function to the\noptimal Q-function under the proposed class of exploring policies. Furthermore,\nwe also introduce a data-driven regularized version of the model set\noptimization problem that ensures the convergence of the class of exploring\npolicies to the optimal policy. Lastly, we show that when the model set has a\nspecific structure, namely the bounded-parameter MDP (BMDP) framework, the\nregularized model set optimization problem becomes convex and simple to\nimplement. In this setting, we also show that we obtain finite-time convergence\nto the optimal policy under additional assumptions. We demonstrate the\neffectiveness of the proposed exploration strategy in a simulation study. The\nresults indicate that the proposed method can significantly speed up the\nlearning process in reinforcement learning.", "published": "2025-04-08 12:33:38", "link": "http://arxiv.org/abs/2504.05978v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "MLPROP -- an open interactive web interface for thermophysical property prediction with machine learning", "abstract": "Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.", "published": "2025-04-08 12:28:18", "link": "http://arxiv.org/abs/2504.05970v1", "categories": ["cs.CE", "cs.LG"], "primary_category": "cs.CE"}
{"title": "Autoencoder-Based Detection of Anomalous Stokes V Spectra in the Flare-Producing Active Region 13663 Using Hinode/SP Observations", "abstract": "Detecting unusual signals in observational solar spectra is crucial for\nunderstanding the features associated with impactful solar events, such as\nsolar flares. However, existing spectral analysis techniques face challenges,\nparticularly when relying on pre-defined, physics-based calculations to process\nlarge volumes of noisy and complex observational data. To address these\nlimitations, we applied deep learning to detect anomalies in the Stokes V\nspectra from the Hinode/SP instrument. Specifically, we developed an\nautoencoder model for spectral compression, which serves as an anomaly\ndetection method. Our model effectively identifies anomalous spectra within\nspectro-polarimetric maps captured prior to the onset of the X1.3 flare on May\n5, 2024, in NOAA AR 13663. These atypical spectral points exhibit highly\ncomplex profiles and spatially align with polarity inversion lines in\nmagnetogram images, indicating their potential as sites of magnetic energy\nstorage and possible triggers for flares. Notably, the detected anomalies are\nhighly localized, making them particularly challenging to identify in\nmagnetogram images using current manual methods.", "published": "2025-04-08 12:20:47", "link": "http://arxiv.org/abs/2504.05962v1", "categories": ["cs.LG", "astro-ph.IM", "astro-ph.SR"], "primary_category": "cs.LG"}
{"title": "Drought forecasting using a hybrid neural architecture for integrating time series and static data", "abstract": "Reliable forecasting is critical for early warning systems and adaptive\ndrought management. Most previous deep learning approaches focus solely on\nhomogeneous regions and rely on single-structured data. This paper presents a\nhybrid neural architecture that integrates time series and static data,\nachieving state-of-the-art performance on the DroughtED dataset. Our results\nillustrate the potential of designing neural models for the treatment of\nheterogeneous data in climate related tasks and present reliable prediction of\nUSDM categories, an expert-informed drought metric. Furthermore, this work\nvalidates the potential of DroughtED for enabling location-agnostic training of\ndeep learning models.", "published": "2025-04-08 12:11:34", "link": "http://arxiv.org/abs/2504.05957v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluation of the impact of expert knowledge: How decision support scores impact the effectiveness of automatic knowledge-driven feature engineering (aKDFE)", "abstract": "Adverse Drug Events (ADEs), harmful medication effects, pose significant\nhealthcare challenges, impacting patient safety and costs. This study evaluates\nautomatic Knowledge-Driven Feature Engineering (aKDFE) for improved ADE\nprediction from Electronic Health Record (EHR) data, comparing it with\nautomated event-based Knowledge Discovery in Databases (KDD). We investigated\nhow incorporating domain-specific ADE risk scores for prolonged heart QT\ninterval, extracted from the Janusmed Riskprofile (Janusmed) Clinical Decision\nSupport System (CDSS), affects prediction performance using EHR data and\nmedication handling events. Results indicate that, while aKDFE step 1\n(event-based feature generation) alone did not significantly improve ADE\nprediction performance, aKDFE step 2 (patient-centric transformation) enhances\nthe prediction performance. High Area Under the Receiver Operating\nCharacteristic curve (AUROC) values suggest strong feature correlations to the\noutcome, aligning with the predictive power of patients' prior healthcare\nhistory for ADEs. Statistical analysis did not confirm that incorporating the\nJanusmed information (i) risk scores and (ii) medication route of\nadministration into the model's feature set enhanced predictive performance.\nHowever, the patient-centric transformation applied by aKDFE proved to be a\nhighly effective feature engineering approach. Limitations include a\nsingle-project focus, potential bias from machine learning pipeline methods,\nand reliance on AUROC. In conclusion, aKDFE, particularly with patient-centric\ntransformation, improves ADE prediction from EHR data. Future work will explore\nattention-based models, event feature sequences, and automatic methods for\nincorporating domain knowledge into the aKDFE framework.", "published": "2025-04-08 11:34:38", "link": "http://arxiv.org/abs/2504.05928v1", "categories": ["cs.LG", "62R01, 68T05", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Deep RL-based Autonomous Navigation of Micro Aerial Vehicles (MAVs) in a complex GPS-denied Indoor Environment", "abstract": "The Autonomy of Unmanned Aerial Vehicles (UAVs) in indoor environments poses\nsignificant challenges due to the lack of reliable GPS signals in enclosed\nspaces such as warehouses, factories, and indoor facilities. Micro Aerial\nVehicles (MAVs) are preferred for navigating in these complex, GPS-denied\nscenarios because of their agility, low power consumption, and limited\ncomputational capabilities. In this paper, we propose a Reinforcement Learning\nbased Deep-Proximal Policy Optimization (D-PPO) algorithm to enhance realtime\nnavigation through improving the computation efficiency. The end-to-end network\nis trained in 3D realistic meta-environments created using the Unreal Engine.\nWith these trained meta-weights, the MAV system underwent extensive\nexperimental trials in real-world indoor environments. The results indicate\nthat the proposed method reduces computational latency by 91\\% during training\nperiod without significant degradation in performance. The algorithm was tested\non a DJI Tello drone, yielding similar results.", "published": "2025-04-08 11:14:37", "link": "http://arxiv.org/abs/2504.05918v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference", "abstract": "The Mixture of Experts (MoE) architecture has demonstrated significant\nadvantages as it enables to increase the model capacity without a proportional\nincrease in computation. However, the large MoE model size still introduces\nsubstantial memory demands, which usually requires expert offloading on\nresource-constrained platforms and incurs significant overhead. Hybrid CPU-GPU\ninference has been proposed to leverage CPU computation to reduce expert\nloading overhead but faces major challenges: on one hand, the expert activation\npatterns of MoE models are highly unstable, rendering the fixed mapping\nstrategies in existing works inefficient; on the other hand, the hybrid CPU-GPU\nschedule for MoE is inherently complex due to the diverse expert sizes,\nstructures, uneven workload distribution, etc. To address these challenges, in\nthis paper, we propose HybriMoE, a hybrid CPU-GPU inference framework that\nimproves resource utilization through a novel CPU-GPU scheduling and cache\nmanagement system. HybriMoE introduces (i) a dynamic intra-layer scheduling\nstrategy to balance workloads across CPU and GPU, (ii) an impact-driven\ninter-layer prefetching algorithm, and (iii) a score-based caching algorithm to\nmitigate expert activation instability. We implement HybriMoE on top of the\nkTransformers framework and evaluate it on three widely used MoE-based LLMs.\nExperimental results demonstrate that HybriMoE achieves an average speedup of\n1.33$\\times$ in the prefill stage and 1.70$\\times$ in the decode stage compared\nto state-of-the-art hybrid MoE inference framework. Our code is available at:\nhttps://github.com/PKU-SEC-Lab/HybriMoE.", "published": "2025-04-08 10:47:37", "link": "http://arxiv.org/abs/2504.05897v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Why do zeroes happen? A model-based approach for demand classification", "abstract": "Effective demand forecasting is critical for inventory management, production\nplanning, and decision making across industries. Selecting the appropriate\nmodel and suitable features to efficiently capture patterns in the data is one\nof the main challenges in demand forecasting. In reality, this becomes even\nmore complicated when the recorded sales have zeroes, which can happen\nnaturally or due to some anomalies, such as stockouts and recording errors.\nMistreating the zeroes can lead to the application of inappropriate forecasting\nmethods, and thus leading to poor decision making. Furthermore, the demand\nitself can have different fundamental characteristics, and being able to\ndistinguish one type from another might bring substantial benefits in terms of\naccuracy and thus decision making. We propose a two-stage model-based\nclassification framework that in the first step, identifies artificially\noccurring zeroes, and then classifies demand to one of the possible types:\nregular/intermittent, intermittent smooth/lumpy, fractional/count. The\nframework utilises statistical modelling and information criteria to detect\nanomalous zeroes and then classify demand into those categories. We then argue\nthat different types of demand need different features, and show empirically\nthat they tend to increase the accuracy of the forecasting methods compared to\nthose applied directly to the dataset without the generated features and the\ntwo-stage framework. Our general practical recommendation based on that is to\nuse the mixture approach for intermittent demand, capturing the demand sizes\nand demand probability separately, as it seems to improve the accuracy of\ndifferent forecasting approaches.", "published": "2025-04-08 10:45:30", "link": "http://arxiv.org/abs/2504.05894v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "To Give or Not to Give? The Impacts of Strategically Withheld Recourse", "abstract": "Individuals often aim to reverse undesired outcomes in interactions with\nautomated systems, like loan denials, by either implementing system-recommended\nactions (recourse), or manipulating their features. While providing recourse\nbenefits users and enhances system utility, it also provides information about\nthe decision process that can be used for more effective strategic\nmanipulation, especially when the individuals collectively share such\ninformation with each other.\n  We show that this tension leads rational utility-maximizing systems to\nfrequently withhold recourse, resulting in decreased population utility,\nparticularly impacting sensitive groups.\n  To mitigate these effects, we explore the role of recourse subsidies, finding\nthem effective in increasing the provision of recourse actions by rational\nsystems, as well as lowering the potential social cost and mitigating\nunfairness caused by recourse withholding.", "published": "2025-04-08 10:36:16", "link": "http://arxiv.org/abs/2504.05891v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Actuarial Learning for Pension Fund Mortality Forecasting", "abstract": "For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.", "published": "2025-04-08 10:09:41", "link": "http://arxiv.org/abs/2504.05881v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Energy-Conserving Neural Network Closure Model for Long-Time Accurate and Stable LES", "abstract": "Machine learning-based closure models for LES have shown promise in capturing\ncomplex turbulence dynamics but often suffer from instabilities and physical\ninconsistencies. In this work, we develop a novel skew-symmetric neural\narchitecture as closure model that enforces stability while preserving key\nphysical conservation laws. Our approach leverages a discretization that\nensures mass, momentum, and energy conservation, along with a face-averaging\nfilter to maintain mass conservation in coarse-grained velocity fields. We\ncompare our model against several conventional data-driven closures (including\nunconstrained convolutional neural networks), and the physics-based Smagorinsky\nmodel. Performance is evaluated on decaying turbulence and Kolmogorov flow for\nmultiple coarse-graining factors. In these test cases we observe that\nunconstrained machine learning models suffer from numerical instabilities. In\ncontrast, our skew-symmetric model remains stable across all tests, though at\nthe cost of increased dissipation. Despite this trade-off, we demonstrate that\nour model still outperforms the Smagorinsky model in unseen scenarios. These\nfindings highlight the potential of structure-preserving machine learning\nclosures for reliable long-time LES.", "published": "2025-04-08 09:49:18", "link": "http://arxiv.org/abs/2504.05868v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65Mxx"], "primary_category": "cs.LG"}
{"title": "Adaptive Substructure-Aware Expert Model for Molecular Property Prediction", "abstract": "Molecular property prediction is essential for applications such as drug\ndiscovery and toxicity assessment. While Graph Neural Networks (GNNs) have\nshown promising results by modeling molecules as molecular graphs, their\nreliance on data-driven learning limits their ability to generalize,\nparticularly in the presence of data imbalance and diverse molecular\nsubstructures. Existing methods often overlook the varying contributions of\ndifferent substructures to molecular properties, treating them uniformly. To\naddress these challenges, we propose ASE-Mol, a novel GNN-based framework that\nleverages a Mixture-of-Experts (MoE) approach for molecular property\nprediction. ASE-Mol incorporates BRICS decomposition and significant\nsubstructure awareness to dynamically identify positive and negative\nsubstructures. By integrating a MoE architecture, it reduces the adverse impact\nof negative motifs while improving adaptability to positive motifs.\nExperimental results on eight benchmark datasets demonstrate that ASE-Mol\nachieves state-of-the-art performance, with significant improvements in both\naccuracy and interpretability.", "published": "2025-04-08 09:25:03", "link": "http://arxiv.org/abs/2504.05844v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Federated Unlearning Made Practical: Seamless Integration via Negated Pseudo-Gradients", "abstract": "The right to be forgotten is a fundamental principle of privacy-preserving\nregulations and extends to Machine Learning (ML) paradigms such as Federated\nLearning (FL). While FL enhances privacy by enabling collaborative model\ntraining without sharing private data, trained models still retain the\ninfluence of training data. Federated Unlearning (FU) methods recently proposed\noften rely on impractical assumptions for real-world FL deployments, such as\nstoring client update histories or requiring access to a publicly available\ndataset. To address these constraints, this paper introduces a novel method\nthat leverages negated Pseudo-gradients Updates for Federated Unlearning (PUF).\nOur approach only uses standard client model updates, anyway employed during\nregular FL rounds, and interprets them as pseudo-gradients. When a client needs\nto be forgotten, we apply the negated of their pseudo-gradients, appropriately\nscaled, to the global model. Unlike state-of-the-art mechanisms, PUF seamlessly\nintegrates with FL workflows, incurs no additional computational and\ncommunication overhead beyond standard FL rounds, and supports concurrent\nunlearning requests. We extensively evaluated the proposed method on two\nwell-known benchmark image classification datasets (CIFAR-10 and CIFAR-100) and\na real-world medical imaging dataset for segmentation (ProstateMRI), using\nthree different neural architectures: two residual networks and a vision\ntransformer. The experimental results across various settings demonstrate that\nPUF achieves state-of-the-art forgetting effectiveness and recovery time,\nwithout relying on any additional assumptions, thus underscoring its practical\napplicability.", "published": "2025-04-08 09:05:33", "link": "http://arxiv.org/abs/2504.05822v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization", "abstract": "While large language models (LLMs) have demonstrated exceptional capabilities\nin challenging tasks such as mathematical reasoning, existing methods to\nenhance reasoning ability predominantly rely on supervised fine-tuning (SFT)\nfollowed by reinforcement learning (RL) on reasoning-specific data after\npre-training. However, these approaches critically depend on external\nsupervisions--such as human labelled reasoning traces, verified golden answers,\nor pre-trained reward models--which limits scalability and practical\napplicability. In this work, we propose Entropy Minimized Policy Optimization\n(EMPO), which makes an early attempt at fully unsupervised LLM reasoning\nincentivization. EMPO does not require any supervised information for\nincentivizing reasoning capabilities (i.e., neither verifiable reasoning\ntraces, problems with golden answers, nor additional pre-trained reward\nmodels). By continuously minimizing the predictive entropy of LLMs on unlabeled\nuser queries in a latent semantic space, EMPO enables purely self-supervised\nevolution of reasoning capabilities with strong flexibility and practicality.\nOur experiments demonstrate competitive performance of EMPO on both\nmathematical reasoning and free-form commonsense reasoning tasks. Specifically,\nwithout any supervised signals, EMPO boosts the accuracy of Qwen2.5-Math-7B\nBase from 30.7\\% to 48.1\\% on mathematical benchmarks and improves truthfulness\naccuracy of Qwen2.5-7B Instruct from 87.16\\% to 97.25\\% on TruthfulQA.", "published": "2025-04-08 08:48:51", "link": "http://arxiv.org/abs/2504.05812v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AiGAS-dEVL-RC: An Adaptive Growing Neural Gas Model for Recurrently Drifting Unsupervised Data Streams", "abstract": "Concept drift and extreme verification latency pose significant challenges in\ndata stream learning, particularly when dealing with recurring concept changes\nin dynamic environments. This work introduces a novel method based on the\nGrowing Neural Gas (GNG) algorithm, designed to effectively handle abrupt\nrecurrent drifts while adapting to incrementally evolving data distributions\n(incremental drifts). Leveraging the self-organizing and topological\nadaptability of GNG, the proposed approach maintains a compact yet informative\nmemory structure, allowing it to efficiently store and retrieve knowledge of\npast or recurring concepts, even under conditions of delayed or sparse stream\nsupervision. Our experiments highlight the superiority of our approach over\nexisting data stream learning methods designed to cope with incremental\nnon-stationarities and verification latency, demonstrating its ability to\nquickly adapt to new drifts, robustly manage recurring patterns, and maintain\nhigh predictive accuracy with a minimal memory footprint. Unlike other\ntechniques that fail to leverage recurring knowledge, our proposed approach is\nproven to be a robust and efficient online learning solution for unsupervised\ndrifting data flows.", "published": "2025-04-08 07:42:50", "link": "http://arxiv.org/abs/2504.05761v1", "categories": ["cs.LG", "cs.NE", "68T05 (Primary) 68T07 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Addressing Class Imbalance with Probabilistic Graphical Models and Variational Inference", "abstract": "This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research.", "published": "2025-04-08 07:38:30", "link": "http://arxiv.org/abs/2504.05758v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interpretable Non-linear Survival Analysis with Evolutionary Symbolic Regression", "abstract": "Survival Regression (SuR) is a key technique for modeling time to event in\nimportant applications such as clinical trials and semiconductor manufacturing.\nCurrently, SuR algorithms belong to one of three classes: non-linear black-box\n-- allowing adaptability to many datasets but offering limited interpretability\n(e.g., tree ensembles); linear glass-box -- being easier to interpret but\nlimited to modeling only linear interactions (e.g., Cox proportional hazards);\nand non-linear glass-box -- allowing adaptability and interpretability, but\nempirically found to have several limitations (e.g., explainable boosting\nmachines, survival trees). In this work, we investigate whether Symbolic\nRegression (SR), i.e., the automated search of mathematical expressions from\ndata, can lead to non-linear glass-box survival models that are interpretable\nand accurate. We propose an evolutionary, multi-objective, and multi-expression\nimplementation of SR adapted to SuR. Our empirical results on five real-world\ndatasets show that SR consistently outperforms traditional glass-box methods\nfor SuR in terms of accuracy per number of dimensions in the model, while\nexhibiting comparable accuracy with black-box methods. Furthermore, we offer\nqualitative examples to assess the interpretability potential of SR models for\nSuR. Code at: https://github.com/lurovi/SurvivalMultiTree-pyNSGP.", "published": "2025-04-08 07:37:37", "link": "http://arxiv.org/abs/2504.05756v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Single-Agent vs. Multi-Agent LLM Strategies for Automated Student Reflection Assessment", "abstract": "We explore the use of Large Language Models (LLMs) for automated assessment\nof open-text student reflections and prediction of academic performance.\nTraditional methods for evaluating reflections are time-consuming and may not\nscale effectively in educational settings. In this work, we employ LLMs to\ntransform student reflections into quantitative scores using two assessment\nstrategies (single-agent and multi-agent) and two prompting techniques\n(zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278\nreflections from 377 students over three academic terms, demonstrate that the\nsingle-agent with few-shot strategy achieves the highest match rate with human\nevaluations. Furthermore, models utilizing LLM-assessed reflection scores\noutperform baselines in both at-risk student identification and grade\nprediction tasks. These findings suggest that LLMs can effectively automate\nreflection assessment, reduce educators' workload, and enable timely support\nfor students who may need additional assistance. Our work emphasizes the\npotential of integrating advanced generative AI technologies into educational\npractices to enhance student engagement and academic success.", "published": "2025-04-08 06:34:15", "link": "http://arxiv.org/abs/2504.05716v1", "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "primary_category": "cs.LG"}
{"title": "Dual Boost-Driven Graph-Level Clustering Network", "abstract": "Graph-level clustering remains a pivotal yet formidable challenge in graph\nlearning. Recently, the integration of deep learning with representation\nlearning has demonstrated notable advancements, yielding performance\nenhancements to a certain degree. However, existing methods suffer from at\nleast one of the following issues: 1. the original graph structure has noise,\nand 2. during feature propagation and pooling processes, noise is gradually\naggregated into the graph-level embeddings through information propagation.\nConsequently, these two limitations mask clustering-friendly information,\nleading to suboptimal graph-level clustering performance. To this end, we\npropose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) to\nalternately promote graph-level clustering and filtering out interference\ninformation in a unified framework. Specifically, in the pooling step, we\nevaluate the contribution of features at the global and optimize them using a\nlearnable transformation matrix to obtain high-quality graph-level\nrepresentation, such that the model's reasoning capability can be improved.\nMoreover, to enable reliable graph-level clustering, we first identify and\nsuppress information detrimental to clustering by evaluating similarities\nbetween graph-level representations, providing more accurate guidance for\nmulti-view fusion. Extensive experiments demonstrated that DBGCN outperforms\nthe state-of-the-art graph-level clustering methods on six benchmark datasets.", "published": "2025-04-08 04:32:46", "link": "http://arxiv.org/abs/2504.05670v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improved Inference of Inverse Ising Problems under Missing Observations in Restricted Boltzmann Machines", "abstract": "Restricted Boltzmann machines (RBMs) are energy-based models analogous to the\nIsing model and are widely applied in statistical machine learning. The\nstandard inverse Ising problem with a complete dataset requires computing both\ndata and model expectations and is computationally challenging because model\nexpectations have a combinatorial explosion. Furthermore, in many applications,\nthe available datasets are partially incomplete, making it difficult to compute\neven data expectations. In this study, we propose a approximation framework for\nthese expectations in the practical inverse Ising problems that integrates\nmean-field approximation or persistent contrastive divergence to generate\nrefined initial points and spatial Monte Carlo integration to enhance estimator\naccuracy. We demonstrate that the proposed method effectively and accurately\ntunes the model parameters in comparison to the conventional method.", "published": "2025-04-08 03:39:56", "link": "http://arxiv.org/abs/2504.05643v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "physics.data-an"], "primary_category": "stat.ML"}
{"title": "TAGC: Optimizing Gradient Communication in Distributed Transformer Training", "abstract": "The increasing complexity of large language models (LLMs) necessitates\nefficient training strategies to mitigate the high computational costs\nassociated with distributed training. A significant bottleneck in this process\nis gradient synchronization across multiple GPUs, particularly in the\nzero-redundancy parallelism mode. In this paper, we introduce Transformer-Aware\nGradient Compression (TAGC), an optimized gradient compression algorithm\ndesigned specifically for transformer-based models. TAGC extends the lossless\nhomomorphic compression method by adapting it for sharded models and\nincorporating transformer-specific optimizations, such as layer-selective\ncompression and dynamic sparsification. Our experimental results demonstrate\nthat TAGC accelerates training by up to 15% compared to the standard Fully\nSharded Data Parallel (FSDP) approach, with minimal impact on model quality. We\nintegrate TAGC into the PyTorch FSDP framework, the implementation is publicly\navailable at https://github.com/ipolyakov/TAGC.", "published": "2025-04-08 03:33:39", "link": "http://arxiv.org/abs/2504.05638v1", "categories": ["cs.LG", "cs.DC", "I.2.6; C.2.4; I.2.11"], "primary_category": "cs.LG"}
{"title": "To Start Up a Start-Up$-$Embedding Strategic Demand Development in Operational On-Demand Fulfillment via Reinforcement Learning with Information Shaping", "abstract": "The last few years have witnessed rapid growth in the on-demand delivery\nmarket, with many start-ups entering the field. However, not all of these\nstart-ups have succeeded due to various reasons, among others, not being able\nto establish a large enough customer base. In this paper, we address this\nproblem that many on-demand transportation start-ups face: how to establish\nthemselves in a new market. When starting, such companies often have limited\nfleet resources to serve demand across a city. Depending on the use of the\nfleet, varying service quality is observed in different areas of the city, and\nin turn, the service quality impacts the respective growth of demand in each\narea. Thus, operational fulfillment decisions drive the longer-term demand\ndevelopment. To integrate strategic demand development into real-time\nfulfillment operations, we propose a two-step approach. First, we derive\nanalytical insights into optimal allocation decisions for a stylized problem.\nSecond, we use these insights to shape the training data of a reinforcement\nlearning strategy for operational real-time fulfillment. Our experiments\ndemonstrate that combining operational efficiency with long-term strategic\nplanning is highly advantageous. Further, we show that the careful shaping of\ntraining data is essential for the successful development of demand.", "published": "2025-04-08 03:25:37", "link": "http://arxiv.org/abs/2504.05633v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Maternal and Fetal Health Status Assessment by Using Machine Learning on Optical 3D Body Scans", "abstract": "Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.", "published": "2025-04-08 03:02:26", "link": "http://arxiv.org/abs/2504.05627v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Model-Agnostic Policy Explanations with Large Language Models", "abstract": "Intelligent agents, such as robots, are increasingly deployed in real-world,\nhuman-centric environments. To foster appropriate human trust and meet legal\nand ethical standards, these agents must be able to explain their behavior.\nHowever, state-of-the-art agents are typically driven by black-box models like\ndeep neural networks, limiting their interpretability. We propose a method for\ngenerating natural language explanations of agent behavior based only on\nobserved states and actions -- without access to the agent's underlying model.\nOur approach learns a locally interpretable surrogate model of the agent's\nbehavior from observations, which then guides a large language model to\ngenerate plausible explanations with minimal hallucination. Empirical results\nshow that our method produces explanations that are more comprehensible and\ncorrect than those from baselines, as judged by both language models and human\nevaluators. Furthermore, we find that participants in a user study more\naccurately predicted the agent's future actions when given our explanations,\nsuggesting improved understanding of agent behavior.", "published": "2025-04-08 02:56:02", "link": "http://arxiv.org/abs/2504.05625v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fairness in Machine Learning-based Hand Load Estimation: A Case Study on Load Carriage Tasks", "abstract": "Predicting external hand load from sensor data is essential for ergonomic\nexposure assessments, as obtaining this information typically requires direct\nobservation or supplementary data. While machine learning methods have been\nused to estimate external hand load from worker postures or force exertion\ndata, our findings reveal systematic bias in these predictions due to\nindividual differences such as age and biological sex. To explore this issue,\nwe examined bias in hand load prediction by varying the sex ratio in the\ntraining dataset. We found substantial sex disparity in predictive performance,\nespecially when the training dataset is more sex-imbalanced. To address this\nbias, we developed and evaluated a fair predictive model for hand load\nestimation that leverages a Variational Autoencoder (VAE) with feature\ndisentanglement. This approach is designed to separate sex-agnostic and\nsex-specific latent features, minimizing feature overlap. The disentanglement\ncapability enables the model to make predictions based solely on sex-agnostic\nfeatures of motion patterns, ensuring fair prediction for both biological\nsexes. Our proposed fair algorithm outperformed conventional machine learning\nmethods (e.g., Random Forests) in both fairness and predictive accuracy,\nachieving a lower mean absolute error (MAE) difference across male and female\nsets and improved fairness metrics such as statistical parity (SP) and positive\nand negative residual differences (PRD and NRD), even when trained on\nimbalanced sex datasets. These findings emphasize the importance of\nfairness-aware machine learning algorithms to prevent potential disadvantages\nin workplace health and safety for certain worker populations.", "published": "2025-04-08 01:55:40", "link": "http://arxiv.org/abs/2504.05610v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An asymptotic preserving scheme for the M1model of non-local thermal transport for two-dimensional structured and unstructured meshes", "abstract": "The M1 moment model for electronic transport is commonly used to describe\nnon-local thermal transport effects in laser-plasma simulations. In this\narticle, we propose a new asymptotic-preserving scheme based on the Unified Gas\nKinetic Scheme (UGKS) for this model in two-dimensional space. This finite\nvolume kinetic scheme follows the same approach as in our previous article and\nrelies on a moment closure, at the numerical scale, of the microscopic flux of\nUGKS. The method is developed for both structured and unstructured meshes, and\nseveral techniques are introduced to ensure accurate fluxes in the diffusion\nlimit. A second-order extension is also proposed. Several test cases validate\nthe different aspects of the scheme and demonstrate its efficiency in\nmultiscale simulations. In particular, the results demonstrate that this method\naccurately captures non-local thermal effects.", "published": "2025-04-08 15:46:14", "link": "http://arxiv.org/abs/2504.06149v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stochastic numerical approximation for nonlinear Fokker-Planck equations with singular kernels", "abstract": "This paper studies the convergence rate of the Euler-Maruyama scheme for\nsystems of interacting particles used to approximate solutions of nonlinear\nFokker-Planck equations with singular interaction kernels, such as the\nKeller-Segel model. We derive explicit error estimates in the large-particle\nlimit for two objects: the empirical measure of the interacting particle system\nand the density distribution of a single particle. Specifically, under certain\nassumptions on the interaction kernel and initial conditions, we show that the\nconvergence rate of both objects towards solutions of the corresponding\nnonlinear FokkerPlanck equation depends polynomially on N (the number of\nparticles) and on h (the discretization step). The analysis shows that the\nscheme converges despite singularities in the drift term. To the best of our\nknowledge, there are no existing results in the literature of such kind for the\nsingular kernels considered in this work.", "published": "2025-04-08 15:24:44", "link": "http://arxiv.org/abs/2504.06132v1", "categories": ["math.PR", "cs.NA", "math.NA", "65C35, 60H35, 65C30, 60K35, 60H30,"], "primary_category": "math.PR"}
{"title": "Variational discretizations of viscous and resistive magnetohydrodynamics using structure-preserving finite elements", "abstract": "We propose a novel structure preserving discretization for viscous and\nresistive magnetohydrodynamics. We follow the recent line of work on discrete\nleast action principle for fluid and plasma equation, incorporating the recent\nadvances to model dissipative phenomena through a generalized Lagrange-d\nAlembert constrained variational principle. We prove that our semi-discrete\nscheme is equivalent to a metriplectic system and use this property to propose\na Poisson splitting time integration. The resulting approximation preserves\nmass, energy and the divergence constraint of the magnetic field. We then show\nsome numerical results obtained with our approach. We first test our scheme on\nsimple academic test to compare the results with established methodologies, and\nthen focus specifically on the simulation of plasma instabilities, with some\ntests on non Cartesian geometries to validate our discretization in the scope\nof tokamak instabilities.", "published": "2025-04-08 15:12:32", "link": "http://arxiv.org/abs/2504.06119v1", "categories": ["math.NA", "cs.NA", "G.1.8; J.2"], "primary_category": "math.NA"}
{"title": "On non-local exchange and scattering operators in domain decomposition methods", "abstract": "We study non-local exchange and scattering operators arising in domain\ndecomposition algorithms for solving elliptic problems on domains in\n$\\mathbb{R}^2$. Motivated by recent formulations of the Optimized Schwarz\nMethod introduced by Claeys, we rigorously analyze the behavior of a family of\nnon-local exchange operators $\\Pi_\\gamma$, defined in terms of boundary\nintegral operators associated to the fundamental solution for $-\\Delta +\n\\gamma^{-2}$, with $\\gamma > 0$. Our first main result establishes precise\nestimates comparing $\\Pi_\\gamma$ to its local counterpart $\\Pi_0$ as $\\gamma\n\\to 0$, providing a quantitative bridge between the classical and non-local\nformulations of the Optimized Schwarz Method. In addition, we investigate the\ncorresponding scattering operators, proving norm estimates that relate them to\ntheir classical analogues through a detailed analysis of the associated\nDirichlet-to-Neumann operators. Our results clarify the relationship between\nclassical and non-local formulations of domain decomposition methods and yield\nnew insights that are essential for the analysis of these algorithms,\nparticularly in the presence of cross points and for domains with curvilinear\npolygonal boundaries.", "published": "2025-04-08 12:54:54", "link": "http://arxiv.org/abs/2504.05991v1", "categories": ["math.NA", "cs.NA", "math.AP", "35J25, 65N12"], "primary_category": "math.NA"}
{"title": "Higher-order meshless schemes for hyperbolic equations", "abstract": "We discuss the order, efficiency, stability and positivity of several\nmeshless schemes for linear scalar hyperbolic equations. Meshless schemes are\nGeneralised Finite Difference Methods (GFDMs) for arbitrary irregular grids in\nwhich there is no connectivity between the grid points. We propose a new\nMUSCL-like meshless scheme that uses a central stencil, with which we can\nachieve arbitrarily high orders, and compare it to existing meshless upwind\nschemes and meshless WENO schemes. The stability of the newly proposed scheme\nis guaranteed by an upwind reconstruction to the midpoints of the stencil. The\nnew meshless MUSCL scheme is also efficient due to the reuse of the GFDM\nsolution in the reconstruction. We combine the new MUSCL scheme with a\nMulti-dimensional Optimal Order Detection (MOOD) procedure to avoid spurious\noscillations at discontinuities. In one spatial dimension, our fourth order\nMUSCL scheme outperforms existing WENO and upwind schemes in terms of stability\nand accuracy. In two spatial dimensions, our MUSCL scheme achieves similar\naccuracy to an existing WENO scheme but is significantly more stable.", "published": "2025-04-08 11:57:01", "link": "http://arxiv.org/abs/2504.05942v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Orthogonal Matching Pursuit based Reconstruction for Modulo Hysteresis Operators", "abstract": "Unlimited sampling provides an acquisition scheme for high dynamic range\nsignals by folding the signal into the dynamic range of the analog-to-digital\nconverter (ADC) using modulo non-linearity prior to sampling to prevent\nsaturation. Recently, a generalized scheme called modulo hysteresis was\nintroduced to account for hardware non-idealities. The encoding operator,\nhowever, does not guarantee that the output signal is within the dynamic range\nof the ADC. To resolve this, we propose a modified modulo hysteresis operator\nand show identifiability of bandlimited signals from modulo hysteresis samples.\nWe propose a recovery algorithm based on orthogonal matching pursuit and\nvalidate our theoretical results through numerical experiments.", "published": "2025-04-08 10:45:44", "link": "http://arxiv.org/abs/2504.05895v1", "categories": ["math.NA", "cs.NA", "eess.SP"], "primary_category": "math.NA"}
{"title": "Eikonal boundary condition for level set method", "abstract": "In this paper, we propose to use the eikonal equation as a boundary condition\nwhen advective or normal flow equations in the level set formulation are solved\nnumerically on polyhedral meshes in the three-dimensional domain. Since the\nlevel set method can use a signed distance function as an initial condition,\nthe eikonal equation on the boundary is a suitable choice at the initial time.\nEnforcing the eikonal equation on the boundary for later times can eliminate\nthe need for inflow boundary conditions, which are typically required for\ntransport equations. In selected examples where exact solutions are available,\nwe compare the proposed method with the method using the exact Dirichlet\nboundary condition. The numerical results confirm that the use of the eikonal\nboundary condition provides comparable accuracy and robustness in surface\nevolution compared to the use of the exact Dirichlet boundary condition, which\nis generally not available. We also present numerical results of evolving a\ngeneral closed surface.", "published": "2025-04-08 09:25:19", "link": "http://arxiv.org/abs/2504.05845v1", "categories": ["math.NA", "cs.NA", "65N08, 35F30, 35G30, 35D40, 49L25"], "primary_category": "math.NA"}
{"title": "A structure-preserving LDG discretization of the Fisher-Kolmogorov equation for modeling neurodegenerative diseases", "abstract": "This work presents a structure-preserving, high-order, unconditionally stable\nnumerical method for approximating the solution to the Fisher-Kolmogorov\nequation on polytopic meshes, with a particular focus on its application in\nsimulating misfolded protein spreading in neurodegenerative diseases. The model\nproblem is reformulated using an entropy variable to guarantee solution\npositivity, boundedness, and satisfaction of a discrete entropy-stability\ninequality at the numerical level. The scheme combines a local discontinuous\nGalerkin method on polytopal meshes for the space discretization with a\n$\\nu$-step backward differentiation formula for the time integration.\nImplementation details are discussed, including a detailed derivation of the\nlinear systems arising from Newton's iteration. The accuracy and robustness of\nthe proposed method are demonstrated through extensive numerical tests.\nFinally, the method's practical performance is demonstrated through simulations\nof \\textalpha{}-synuclein propagation in a two-dimensional brain geometry\nsegmented from MRI data, providing a relevant computational framework for\nmodeling synucleopathies (such as Parkinson's disease) and, more generally,\nneurodegenerative diseases.", "published": "2025-04-08 08:10:42", "link": "http://arxiv.org/abs/2504.05784v1", "categories": ["math.NA", "cs.NA", "65M60, 65N22, 35Q92"], "primary_category": "math.NA"}
{"title": "Quantifying uncertainty in inverse scattering problems set in layered environments", "abstract": "The attempt to solve inverse scattering problems often leads to optimization\nand sampling problems that require handling moderate to large amounts of\npartial differential equations acting as constraints. We focus here on\ndetermining inclusions in a layered medium from the measurement of wave fields\non the surface, while quantifying uncertainty and addressing the effect of wave\nsolver quality. Inclusions are characterized by a few parameters describing\ntheir material properties and shapes. We devise algorithms to estimate the most\nlikely configurations by optimizing cost functionals with Bayesian\nregularizations and wave constraints. In particular, we design an automatic\nLevenberg-Marquardt-Fletcher type scheme based on the use of algorithmic\ndifferentiation and adaptive finite element meshes for time dependent wave\nequation constraints with changing inclusions. In synthetic tests with a single\nfrequency, this scheme converges in few iterations for increasing noise levels.\nTo attain a global view of other possible high probability configurations and\nasymmetry effects we resort to parallelizable affine invariant Markov Chain\nMonte Carlo methods, at the cost of solving a few million wave problems. This\nforces the use of prefixed meshes. While the optimal configurations remain\nsimilar, we encounter additional high probability inclusions influenced by the\nprior information, the noise level and the layered structure, effect that can\nbe reduced by considering more frequencies. We analyze the effect on the\ncalculations of working with adaptive and fixed meshes, under a simple choice\nof non-reflecting boundary conditions in truncated layered domains for which we\nestablish wellposedness and convergence results.", "published": "2025-04-08 07:57:36", "link": "http://arxiv.org/abs/2504.05776v1", "categories": ["math.NA", "cs.NA", "math.OC", "physics.comp-ph", "physics.data-an", "physics.geo-ph"], "primary_category": "math.NA"}
{"title": "Improved Polynomial Bounds and Acceleration of GMRES by Solving a min-max Problem on Rectangles, and by Deflating", "abstract": "Polynomial convergence bounds are considered for left, right, and split\npreconditioned GMRES. They include the cases of Weighted and Deflated GMRES for\na linear system Ax = b. In particular, the case of positive definite A is\nconsidered. The well-known polynomial bounds are generalized to the cases\nconsidered, and then reduced to solving a min-max problem on rectangles on the\ncomplex plane. Several approaches are considered and compared. The new bounds\ncan be improved by using specific deflation spaces and preconditioners. This in\nturn accelerates the convergence of GMRES. Numerical examples illustrate the\nresults obtained.", "published": "2025-04-08 06:45:34", "link": "http://arxiv.org/abs/2504.05723v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Mean-Reverting Model of Exchange Rate Risk Premium Using Ornstein-Uhlenbeck Dynamics", "abstract": "This paper examines the empirical failure of uncovered interest parity (UIP)\nand proposes a structural explanation based on a mean-reverting risk premium.\nWe define a realized premium as the deviation between observed exchange rate\nreturns and the interest rate differential, and demonstrate its strong\nmean-reverting behavior across multiple horizons. Motivated by this pattern, we\nmodel the risk premium using an Ornstein-Uhlenbeck (OU) process embedded within\na stochastic differential equation for the exchange rate.\n  Our model yields closed-form approximations for future exchange rate\ndistributions, which we evaluate using coverage-based backtesting. Applied to\nUSD/KRW data from 2010 to 2025, the model shows strong predictive performance\nat both short-term and long-term horizons, while underperforming at\nintermediate (3-month) horizons and showing conservative behavior in the tails\nof long-term forecasts. These results suggest that exchange rate deviations\nfrom UIP may reflect structured, forecastable dynamics rather than pure noise,\nand point to future modeling improvements via regime-switching or time-varying\nvolatility.", "published": "2025-04-08 13:33:15", "link": "http://arxiv.org/abs/2504.06028v1", "categories": ["q-fin.CP", "q-fin.ST", "91G80, 60J60"], "primary_category": "q-fin.CP"}
{"title": "Functional It\u00f4-formula and Taylor expansions for non-anticipative maps of c\u00e0dl\u00e0g rough paths", "abstract": "We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).", "published": "2025-04-08 16:00:21", "link": "http://arxiv.org/abs/2504.06164v1", "categories": ["math.PR", "math.CA", "q-fin.MF", "60L20, 60L10"], "primary_category": "math.PR"}
{"title": "Financial resilience of agricultural and food production companies in Spain: A compositional cluster analysis of the impact of the Ukraine-Russia war (2021-2023)", "abstract": "This study analyzes the financial resilience of agricultural and food\nproduction companies in Spain amid the Ukraine-Russia war using cluster\nanalysis based on financial ratios. This research utilizes centered log-ratios\nto transform financial ratios for compositional data analysis. The dataset\ncomprises financial information from 1197 firms in Spain's agricultural and\nfood sectors over the period 2021-2023. The analysis reveals distinct clusters\nof firms with varying financial performance, characterized by metrics of\nsolvency and profitability. The results highlight an increase in resilient\nfirms by 2023, underscoring sectoral adaptation to the conflict's economic\nchallenges. These findings together provide insights for stakeholders and\npolicymakers to improve sectorial stability and strategic planning.", "published": "2025-04-08 11:08:51", "link": "http://arxiv.org/abs/2504.05912v1", "categories": ["q-fin.ST", "stat.AP", "62H30, 62P20"], "primary_category": "q-fin.ST"}
{"title": "Matched Topological Subspace Detector", "abstract": "Topological spaces, represented by simplicial complexes, capture richer\nrelationships than graphs by modeling interactions not only between nodes but\nalso among higher-order entities, such as edges or triangles. This motivates\nthe representation of information defined in irregular domains as topological\nsignals. By leveraging the spectral dualities of Hodge and Dirac theory,\npractical topological signals often concentrate in specific spectral subspaces\n(e.g., gradient or curl). For instance, in a foreign currency exchange network,\nthe exchange flow signals typically satisfy the arbitrage-free condition and\nhence are curl-free. However, the presence of anomalies can disrupt these\nconditions, causing the signals to deviate from such subspaces. In this work,\nwe formulate a hypothesis testing framework to detect whether simplicial\ncomplex signals lie in specific subspaces in a principled and tractable manner.\nConcretely, we propose Neyman-Pearson matched topological subspace detectors\nfor signals defined at a single simplicial level (such as edges) or jointly\nacross all levels of a simplicial complex. The (energy-based projection)\nproposed detectors handle missing values, provide closed-form performance\nanalysis, and effectively capture the unique topological properties of the\ndata. We demonstrate the effectiveness of the proposed topological detectors on\nvarious real-world data, including foreign currency exchange networks.", "published": "2025-04-08 10:38:30", "link": "http://arxiv.org/abs/2504.05892v1", "categories": ["stat.ML", "eess.SP"], "primary_category": "stat.ML"}
{"title": "R\u00e9duire le bruit gr\u00e2ce \u00e0 la r\u00e9alit\u00e9 augment\u00e9e sonore -- Auditory Concealer", "abstract": "This report presents the work done over 22 weeks of internship within the\nSound Perception and Design team of the Sciences and Technologies of Music and\nSound (STMS) laboratory at the Institute for Research and Coordination in\nAcoustics/Music (IRCAM). As part of the launch of the project Reducing Noise\nwith Augmented Reality (ReNAR); which aims to create a tool to reduce in\nreal-time the cognitive impact of sounds perceived as unpleasant or annoying in\nindoor environments; an initial study was conducted to validate the feasibility\nand effectiveness of a new masking approach called concealer. The main\nhypothesis is that the concealer approach could provide better results than a\nmasker approach in terms of perceived pleasantness. Mixtures of two noise\nsources (ventilation) and five masking sounds (water sounds) were generated\nusing both approaches at various levels. The evaluation of the perceived\npleasantness of these mixtures showed that the masker approach remains more\neffective than the concealer approach, regardless of the noise source, water\nsound, or level used.", "published": "2025-04-08 09:27:07", "link": "http://arxiv.org/abs/2504.05847v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mass-Spring Models for Passive Keyword Spotting: A Springtronics Approach", "abstract": "Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.", "published": "2025-04-08 08:31:19", "link": "http://arxiv.org/abs/2504.05802v1", "categories": ["cs.SD", "cond-mat.dis-nn", "eess.AS"], "primary_category": "cs.SD"}
{"title": "STAGE: Stemmed Accompaniment Generation through Prefix-Based Conditioning", "abstract": "Recent advances in generative models have made it possible to create\nhigh-quality, coherent music, with some systems delivering production-level\noutput.Yet, most existing models focus solely on generating music from scratch,\nlimiting their usefulness for musicians who want to integrate such models into\na human, iterative composition workflow.In this paper we introduce STAGE, our\nSTemmed Accompaniment GEneration model, fine-tuned from the state-of-the-art\nMusicGen to generate single-stem instrumental accompaniments conditioned on a\ngiven mixture. Inspired by instruction-tuning methods for language models, we\nextend the transformer's embedding matrix with a context token, enabling the\nmodel to attend to a musical context through prefix-based conditioning.Compared\nto the baselines, STAGE yields accompaniments that exhibit stronger coherence\nwith the input mixture, higher audio quality, and closer alignment with textual\nprompts.Moreover, by conditioning on a metronome-like track, our framework\nnaturally supports tempo-constrained generation, achieving state-of-the-art\nalignment with the target rhythmic structure--all without requiring any\nadditional tempo-specific module.As a result, STAGE offers a practical,\nversatile tool for interactive music creation that can be readily adopted by\nmusicians in real-world workflows.", "published": "2025-04-08 05:24:11", "link": "http://arxiv.org/abs/2504.05690v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-Complexity SDP-ADMM for Physical-Layer Multicasting in Massive MIMO Systems", "abstract": "There is a demand for the same data content from several user equipments\n(UEs) in many wireless communication applications. Physical-layer multicasting\ncombines the beamforming capability of massive MIMO (multiple-input\nmultiple-output) and the broadcast nature of the wireless channel to\nefficiently deliver the same data to a group of UEs using a single\ntransmission. This paper tackles the max-min fair (MMF) multicast beamforming\noptimization, which is an NP-hard problem. We develop an efficient semidefinite\nprogram-alternating direction method of multipliers (SDP-ADMM) algorithm to\nfind the near-global optimal rank-1 solution to the MMF multicast problem in a\nmassive MIMO system. Numerical results show that the proposed SDP-ADMM\nalgorithm exhibits similar spectral efficiency performance to state-of-the-art\nalgorithms running on standard SDP solvers at a vastly reduced computational\ncomplexity. We highlight that the proposed ADMM elimination procedure can be\nemployed as an effective low-complexity rank reduction method for other\nproblems utilizing semidefinite relaxation.", "published": "2025-04-08 14:30:44", "link": "http://arxiv.org/abs/2504.06090v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Unimodular Waveform Design that Minimizes PSL of Ambiguity Function over A Continuous Doppler Frequency Shift Region of Interest", "abstract": "In active sensing systems, waveforms with ambiguity functions (AFs) of low\npeak sidelobe levels (PSLs) across a time delay and Doppler frequency shift\nplane (delay-Doppler plane) of interest are desirable for reducing false\nalarms. Additionally, unimodular waveforms are preferred due to hardware\nlimitations. In this paper, a new method is proposed to design unimodular\nwaveforms with PSL suppression over a continuous Doppler frequency shift\nregion, based on the discrete-time ambiguity function (DTAF). Compared with\nexisting methods that suppress PSL over grid points in the delay-Doppler plane\nby using the discrete ambiguity function (DAF), we regard the DTAF optimization\nproblem as of more practical interest because the Doppler frequency shifts\nobserved in echo signals reflected from targets are inherently continuous\nrather than discrete. The problem of interest is formulated as an optimization\nproblem with infinite constraints along with unimodular constraints. To the\nbest of the authors' knowledge, such a problem has not been studied yet. We\npropose to reformulate a non-convex semi-infinite programming (SIP) to a\nsemidefinite programming (SDP) with a finite number of constraints and a\nrank-one constraint, which is then solved by the sequential rank-one constraint\nrelaxation (SROCR) algorithm. Simulation results demonstrate that the proposed\nmethod outperforms existing methods in achieving a lower PSL of AF over a\ncontinuous Doppler frequency shift region of interest. Moreover, the designed\nwaveform can effectively prevent false alarms when detecting a target with an\narbitrary velocity.", "published": "2025-04-08 13:37:22", "link": "http://arxiv.org/abs/2504.06038v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fair Resource Allocation in UAV-based Semantic Communication System with Fluid Antenna", "abstract": "In this paper, the problem of maximization of the minimum equivalent rate in\na unmanned-aerial-vehicle (UAV)-based multi-user semantic communication system\nis investigated. In the considered model, a multi-antenna UAV employs semantic\nextraction techniques to compress the data ready to be sent to the users, which\nare equipped with fluid antennas. Our aim is to jointly optimize the trajectory\nof the UAV, the transmit beamforming and the semantic compression rate at the\nUAV, as well as the selection of activated ports in fluid antenna system (FAS),\nto maximize the minimum equivalent transmission rate among all user. An\nalternating algorithm is designed to solve the problem. Simulation results\nvalidate the effectiveness of the proposed algorithm.", "published": "2025-04-08 12:10:55", "link": "http://arxiv.org/abs/2504.05955v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Unimodular Waveform Design for Integrated Sensing and Communication MIMO System via Manifold Optimization", "abstract": "Integrated sensing and communication (ISAC) has been widely recognized as one\nof the key technologies for 6G wireless networks. In this paper, we focus on\nthe waveform design of ISAC system, which can realize radar sensing while also\nfacilitate information transmission. The main content is as follows: first, we\nformulate the waveform design problem as a nonconvex and non-smooth model with\na unimodulus constraint based on the measurement metric of the radar and\ncommunication system. Second, we transform the model into an unconstrained\nproblem on the Riemannian manifold and construct the corresponding operators by\nanalyzing the unimodulus constraint. Third, to achieve the solution\nefficiently, we propose a low-complexity non-smooth unimodulus manifold\ngradient descent (N-UMGD) algorithm with theoretical convergence guarantee. The\nsimulation results show that the proposed algorithm can concentrate the energy\nof the sensing signal in the desired direction and realize information\ntransmission with a low bit error rate.", "published": "2025-04-08 09:08:50", "link": "http://arxiv.org/abs/2504.05829v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "PRACH Preamble Detection as a Multi-Class Classification Problem: A Machine Learning Approach Using SVM", "abstract": "This study addresses the preamble detection problem in the Random Access\nprocedure of LTE/5G networks by formulating it as a multi-class classification\ntask and evaluating the effectiveness of machine learning techniques. A Support\nVector Machine (SVM) model is implemented and compared against conventional\ndetection methods. The proposed approach improves preamble index assignment,\nenhancing detection efficiency for User Equipment (UE) accessing the network.\nPerformance analysis demonstrates that the SVM-based solution increases\ndetection accuracy while reducing missed detections. These findings underscore\nthe potential of machine learning in optimizing the Random Access procedure and\nimproving network accessibility.", "published": "2025-04-08 07:15:50", "link": "http://arxiv.org/abs/2504.05739v1", "categories": ["eess.SP", "40-06", "I.2.6; I.2.8; I.5.5"], "primary_category": "eess.SP"}
{"title": "Signal and Backward Raman Pump Power Optimization in Multi-Band Systems Using Fast Power Profile Estimation", "abstract": "This paper presents an efficient numerical method for calculating spatial\npower profiles of both signal and pump with significant Interchannel Stimulated\nRaman Scattering (ISRS) and backward Raman amplification in multiband systems.\nThis method was evaluated in the optimization of a C+L+S/C+L+S+E 1000km link,\nemploying three backward Raman pumps, by means of a closed-form EGN model\n(CFM6). The results show a 100x computational speed increase, enabling deep\noptimization which made it possible to obtain very good overall system\nperformance and flat GSNR.", "published": "2025-04-08 06:54:56", "link": "http://arxiv.org/abs/2504.05726v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Hogwild! Inference: Parallel LLM Generation via Concurrent Attention", "abstract": "Large Language Models (LLMs) have demonstrated the ability to tackle\nincreasingly complex tasks through advanced reasoning, long-form content\ngeneration, and tool use. Solving these tasks often involves long\ninference-time computations. In human problem solving, a common strategy to\nexpedite work is collaboration: by dividing the problem into sub-tasks,\nexploring different strategies concurrently, etc. Recent research has shown\nthat LLMs can also operate in parallel by implementing explicit cooperation\nframeworks, such as voting mechanisms or the explicit creation of independent\nsub-tasks that can be executed in parallel. However, each of these frameworks\nmay not be suitable for all types of tasks, which can hinder their\napplicability. In this work, we propose a different design approach: we run LLM\n\"workers\" in parallel , allowing them to synchronize via a concurrently-updated\nattention cache and prompt these workers to decide how best to collaborate. Our\napproach allows the instances to come up with their own collaboration strategy\nfor the problem at hand, all the while \"seeing\" each other's partial progress\nin the concurrent cache. We implement this approach via Hogwild! Inference: a\nparallel LLM inference engine where multiple instances of the same LLM run in\nparallel with the same attention cache, with \"instant\" access to each other's\ngenerated tokens. Hogwild! inference takes advantage of Rotary Position\nEmbeddings (RoPE) to avoid recomputation while improving parallel hardware\nutilization. We find that modern reasoning-capable LLMs can perform inference\nwith shared Key-Value cache out of the box, without additional fine-tuning.", "published": "2025-04-08 17:59:41", "link": "http://arxiv.org/abs/2504.06261v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups", "abstract": "Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.", "published": "2025-04-08 15:56:57", "link": "http://arxiv.org/abs/2504.06160v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI", "J.4; K.4.1; K.4.2"], "primary_category": "cs.CL"}
{"title": "Confidence Regularized Masked Language Modeling using Text Length", "abstract": "Masked language modeling is a widely used method for learning language\nrepresentations, where the model predicts a randomly masked word in each input.\nHowever, this approach typically considers only a single correct answer during\ntraining, ignoring the variety of plausible alternatives that humans might\nchoose. This issue becomes more pronounced when the input text is short, as the\npossible word distribution tends to have higher entropy, potentially causing\nthe model to become overconfident in its predictions. To mitigate this, we\npropose a novel confidence regularizer that adaptively adjusts the\nregularization strength based on the input length. Experiments on the GLUE and\nSQuAD benchmarks show that our method improves both accuracy and expected\ncalibration error", "published": "2025-04-08 13:37:08", "link": "http://arxiv.org/abs/2504.06037v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RETROcode: Leveraging a Code Database for Improved Natural Language to Code Generation", "abstract": "As text and code resources have expanded, large-scale pre-trained models have\nshown promising capabilities in code generation tasks, typically employing\nsupervised fine-tuning with problem statement-program pairs. However,\nincreasing model size and data volume for performance gains also raises\ncomputational demands and risks of overfitting. Addressing these challenges, we\npresent RETROcode, a novel adaptation of the RETRO architecture \\cite{RETRO}\nfor sequence-to-sequence models, utilizing a large code database as an\nauxiliary scaling method. This approach, diverging from simply enlarging model\nand dataset sizes, allows RETROcode to leverage a vast code database for\nprediction, enhancing the model's efficiency by integrating extensive memory.\nOur findings indicate that RETROcode not only outperforms similar-sized\ntraditional architectures on test sets but also approaches the effectiveness of\nthe much larger Codex model, despite being trained from scratch on a\nsubstantially smaller dataset.", "published": "2025-04-08 07:41:13", "link": "http://arxiv.org/abs/2504.05759v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "abstract": "Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.", "published": "2025-04-08 03:21:51", "link": "http://arxiv.org/abs/2504.05632v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning", "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have\nhighlighted the potential of formal reasoning with Lean 4 codes. However, ATP\nhas not yet be revolutionized by the recent posttraining scaling as\ndemonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the\nentire posttraining of ATP, aiming to align it with breakthroughs in reasoning\nmodels in natural languages. To begin, we continual train current ATP models\nwith a hybrid dataset, which consists of numerous statement-proof pairs, and\nadditional data aimed at incorporating cognitive behaviors that emulate human\nreasoning and hypothesis refinement. Next, we explore reinforcement learning\nwith the use of outcome reward returned by Lean 4 compiler. Through our\ndesigned continual training and reinforcement learning processes, we have\nsuccessfully improved existing formal provers, including both\nDeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance\nin the field of whole-proof generation. For example, we achieve a 59.8% pass\nrate (pass@32) on MiniF2F. This is an on-going project and we will\nprogressively update our findings, release our data and training details.", "published": "2025-04-08 15:15:26", "link": "http://arxiv.org/abs/2504.06122v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Unraveling Human-AI Teaming: A Review and Outlook", "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.", "published": "2025-04-08 07:37:25", "link": "http://arxiv.org/abs/2504.05755v2", "categories": ["cs.HC", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.HC"}
{"title": "DDT: Decoupled Diffusion Transformer", "abstract": "Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.", "published": "2025-04-08 07:17:45", "link": "http://arxiv.org/abs/2504.05741v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Architecture independent generalization bounds for overparametrized deep ReLU networks", "abstract": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.", "published": "2025-04-08 05:37:38", "link": "http://arxiv.org/abs/2504.05695v2", "categories": ["cs.LG", "cs.AI", "math.AP", "math.OC", "stat.ML", "57R70, 62M45"], "primary_category": "cs.LG"}
{"title": "Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adapt\npowerful Foundation Models (FMs) to diverse downstream tasks while preserving\nand unleashing their inherent capabilities. However, we have observed that\nexisting PEFT methods, which are often designed with natural imagery in mind,\nstruggle when applied to Remote Sensing (RS) scenarios. This is primarily due\nto their inability to handle artifact influences, a problem particularly severe\nin RS image features. To tackle this challenge, we introduce Earth-Adapter, the\nfirst PEFT method specifically designed for RS artifacts conquering.\nEarth-Adapter introduces a novel Mixture of Frequency Adaptation process that\ncombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).\nBy utilizing DFT, Earth-Adapter can decompose features into different frequency\ncomponents, precisely separating artifacts from original features. The MoA then\ndynamically assigns weights to each adapter expert, allowing for the\ncombination of features across various frequency domains. These\nsimple-yet-effective approaches enable Earth-Adapter to more efficiently\novercome the disturbances caused by artifacts than previous PEFT methods,\nsignificantly enhancing the FMs' performance on RS scenarios. Experiments on\nDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentation\nbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baseline\nRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DG\nbenchmarks. Our code will be released at\nhttps://github.com/VisionXLab/Earth-Adapter.", "published": "2025-04-08 17:09:33", "link": "http://arxiv.org/abs/2504.06220v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Fusion Controller: Degradation-aware Image Fusion with Fine-grained Language Instructions", "abstract": "Current image fusion methods struggle to adapt to real-world environments\nencompassing diverse degradations with spatially varying characteristics. To\naddress this challenge, we propose a robust fusion controller (RFC) capable of\nachieving degradation-aware image fusion through fine-grained language\ninstructions, ensuring its reliable application in adverse environments.\nSpecifically, RFC first parses language instructions to innovatively derive the\nfunctional condition and the spatial condition, where the former specifies the\ndegradation type to remove, while the latter defines its spatial coverage.\nThen, a composite control priori is generated through a multi-condition\ncoupling network, achieving a seamless transition from abstract language\ninstructions to latent control variables. Subsequently, we design a hybrid\nattention-based fusion network to aggregate multi-modal information, in which\nthe obtained composite control priori is deeply embedded to linearly modulate\nthe intermediate fused features. To ensure the alignment between language\ninstructions and control outcomes, we introduce a novel language-feature\nalignment loss, which constrains the consistency between feature-level gains\nand the composite control priori. Extensive experiments on publicly available\ndatasets demonstrate that our RFC is robust against various composite\ndegradations, particularly in highly challenging flare scenarios.", "published": "2025-04-08 08:22:55", "link": "http://arxiv.org/abs/2504.05795v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Totally equimodular matrices: decomposition and triangulation", "abstract": "Totally equimodular matrices generalize totally unimodular matrices and arise\nin the context of box-total dual integral polyhedra. This work further explores\nthe parallels between these two classes and introduces foundational building\nblocks for constructing totally equimodular matrices. Consequently, we present\na decomposition theorem for totally equimodular matrices of full row rank.\n  Building on this decomposition theorem, we prove that simplicial cones whose\ngenerators form the rows of a totally equimodular matrix sa\\-tisfy strong\nintegrality decomposition properties. More precisely, we provide the Hilbert\nbasis for these cones and construct regular unimodular Hilbert triangulations\nin most cases. We conjecture that cases not covered here do not exist.", "published": "2025-04-08 11:40:59", "link": "http://arxiv.org/abs/2504.05930v2", "categories": ["math.CO", "cs.DM", "90C27 (Primary), 05B20, 90C10 (Secondary)"], "primary_category": "math.CO"}
{"title": "Robo-taxi Fleet Coordination at Scale via Reinforcement Learning", "abstract": "Fleets of robo-taxis offering on-demand transportation services, commonly\nknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise\nfor societal benefits, such as reducing pollution, energy consumption, and\nurban congestion. However, orchestrating these systems at scale remains a\ncritical challenge, with existing coordination algorithms often failing to\nexploit the systems' full potential. This work introduces a novel\ndecision-making framework that unites mathematical modeling with data-driven\ntechniques. In particular, we present the AMoD coordination problem through the\nlens of reinforcement learning and propose a graph network-based framework that\nexploits the main strengths of graph representation learning, reinforcement\nlearning, and classical operations research tools. Extensive evaluations across\ndiverse simulation fidelities and scenarios demonstrate the flexibility of our\napproach, achieving superior system performance, computational efficiency, and\ngeneralizability compared to prior methods. Finally, motivated by the need to\ndemocratize research efforts in this area, we release publicly available\nbenchmarks, datasets, and simulators for network-level coordination alongside\nan open-source codebase designed to provide accessible simulation platforms and\nestablish a standardized validation process for comparing methodologies. Code\navailable at: https://github.com/StanfordASL/RL4AMOD", "published": "2025-04-08 15:19:41", "link": "http://arxiv.org/abs/2504.06125v2", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Effective Method for Inverse Ising Problem under Missing Observations in Restricted Boltzmann Machines", "abstract": "Restricted Boltzmann machines (RBMs) are energy-based models analogous to the\nIsing model and are widely applied in statistical machine learning. The\nstandard inverse Ising problem with a complete dataset requires computing both\ndata and model expectations and is computationally challenging because model\nexpectations have a combinatorial explosion. Furthermore, in many applications,\nthe available datasets are partially incomplete, making it difficult to compute\neven data expectations. In this study, we propose a approximation framework for\nthese expectations in the practical inverse Ising problems that integrates\nmean-field approximation or persistent contrastive divergence to generate\nrefined initial points and spatial Monte Carlo integration to enhance estimator\naccuracy. We demonstrate that the proposed method effectively and accurately\ntunes the model parameters in comparison to the conventional method.", "published": "2025-04-08 03:39:56", "link": "http://arxiv.org/abs/2504.05643v2", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "physics.data-an"], "primary_category": "stat.ML"}
{"title": "STAGE: Stemmed Accompaniment Generation through Prefix-Based Conditioning", "abstract": "Recent advances in generative models have made it possible to create\nhigh-quality, coherent music, with some systems delivering production-level\noutput. Yet, most existing models focus solely on generating music from\nscratch, limiting their usefulness for musicians who want to integrate such\nmodels into a human, iterative composition workflow. In this paper we introduce\nSTAGE, our STemmed Accompaniment GEneration model, fine-tuned from the\nstate-of-the-art MusicGen to generate single-stem instrumental accompaniments\nconditioned on a given mixture. Inspired by instruction-tuning methods for\nlanguage models, we extend the transformer's embedding matrix with a context\ntoken, enabling the model to attend to a musical context through prefix-based\nconditioning. Compared to the baselines, STAGE yields accompaniments that\nexhibit stronger coherence with the input mixture, higher audio quality, and\ncloser alignment with textual prompts. Moreover, by conditioning on a\nmetronome-like track, our framework naturally supports tempo-constrained\ngeneration, achieving state-of-the-art alignment with the target rhythmic\nstructure--all without requiring any additional tempo-specific module. As a\nresult, STAGE offers a practical, versatile tool for interactive music creation\nthat can be readily adopted by musicians in real-world workflows.", "published": "2025-04-08 05:24:11", "link": "http://arxiv.org/abs/2504.05690v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analyzing Examinee Comments using DistilBERT and Machine Learning to Ensure Quality Control in Exam Content", "abstract": "This study explores using Natural Language Processing (NLP) to analyze\ncandidate comments for identifying problematic test items. We developed and\nvalidated machine learning models that automatically identify relevant negative\nfeedback, evaluated approaches of incorporating psychometric features enhances\nmodel performance, and compared NLP-flagged items with traditionally flagged\nitems. Results demonstrate that candidate feedback provides valuable\ncomplementary information to statistical methods, potentially improving test\nvalidity while reducing manual review burden. This research offers testing\norganizations an efficient mechanism to incorporate direct candidate experience\ninto quality assurance processes.", "published": "2025-04-08 22:08:37", "link": "http://arxiv.org/abs/2504.06465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Simulate Personas with Reversed Performance? A Benchmark for Counterfactual Instruction Following", "abstract": "Large Language Models (LLMs) are now increasingly widely used to simulate\npersonas in virtual environments, leveraging their instruction-following\ncapability. However, we discovered that even state-of-the-art LLMs cannot\nsimulate personas with reversed performance (e.g., student personas with low\nproficiency in educational settings), which impairs the simulation diversity\nand limits the practical applications of the simulated environments. In this\nwork, using mathematical reasoning as a representative scenario, we propose the\nfirst benchmark dataset for evaluating LLMs on simulating personas with\nreversed performance, a capability that we dub \"counterfactual instruction\nfollowing\". We evaluate both open-weight and closed-source LLMs on this task\nand find that LLMs, including the OpenAI o1 reasoning model, all struggle to\nfollow counterfactual instructions for simulating reversedly performing\npersonas. Intersectionally simulating both the performance level and the race\npopulation of a persona worsens the effect even further. These results\nhighlight the challenges of counterfactual instruction following and the need\nfor further research.", "published": "2025-04-08 22:00:32", "link": "http://arxiv.org/abs/2504.06460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Let It Hallucinate: Premise Verification via Retrieval-Augmented Logical Reasoning", "abstract": "Large language models (LLMs) have shown substantial capacity for generating\nfluent, contextually appropriate responses. However, they can produce\nhallucinated outputs, especially when a user query includes one or more false\npremises-claims that contradict established facts. Such premises can mislead\nLLMs into offering fabricated or misleading details. Existing approaches\ninclude pretraining, fine-tuning, and inference-time techniques that often rely\non access to logits or address hallucinations after they occur. These methods\ntend to be computationally expensive, require extensive training data, or lack\nproactive mechanisms to prevent hallucination before generation, limiting their\nefficiency in real-time applications. We propose a retrieval-based framework\nthat identifies and addresses false premises before generation. Our method\nfirst transforms a user's query into a logical representation, then applies\nretrieval-augmented generation (RAG) to assess the validity of each premise\nusing factual sources. Finally, we incorporate the verification results into\nthe LLM's prompt to maintain factual consistency in the final output.\nExperiments show that this approach effectively reduces hallucinations,\nimproves factual accuracy, and does not require access to model logits or\nlarge-scale fine-tuning.", "published": "2025-04-08 21:14:48", "link": "http://arxiv.org/abs/2504.06438v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini", "abstract": "As leading examples of large language models, ChatGPT and Gemini claim to\nprovide accurate and unbiased information, emphasizing their commitment to\npolitical neutrality and avoidance of personal bias. This research investigates\nthe political tendency of large language models and the existence of\ndifferentiation according to the query language. For this purpose, ChatGPT and\nGemini were subjected to a political axis test using 14 different languages.\nThe findings of the study suggest that these large language models do exhibit\npolitical tendencies, with both models demonstrating liberal and leftist\nbiases. A comparative analysis revealed that Gemini exhibited a more pronounced\nliberal and left-wing tendency compared to ChatGPT. The study also found that\nthese political biases varied depending on the language used for inquiry. The\nstudy delves into the factors that constitute political tendencies and\nlinguistic differentiation, exploring differences in the sources and scope of\neducational data, structural and grammatical features of languages, cultural\nand political contexts, and the model's response to linguistic features. From\nthis standpoint, and an ethical perspective, it is proposed that artificial\nintelligence tools should refrain from asserting a lack of political tendencies\nand neutrality, instead striving for political neutrality and executing user\nqueries by incorporating these tendencies.", "published": "2025-04-08 21:13:01", "link": "http://arxiv.org/abs/2504.06436v1", "categories": ["cs.CL", "cs.AI", "cs.ET", "stat.AP"], "primary_category": "cs.CL"}
{"title": "S'MoRE: Structural Mixture of Residual Experts for LLM Fine-tuning", "abstract": "Fine-tuning pre-trained large language models (LLMs) presents a dual\nchallenge of balancing parameter efficiency and model capacity. Existing\nmethods like low-rank adaptations (LoRA) are efficient but lack flexibility,\nwhile Mixture-of-Experts (MoE) architectures enhance model capacity at the cost\nof more & under-utilized parameters. To address these limitations, we propose\nStructural Mixture of Residual Experts (S'MoRE), a novel framework that\nseamlessly integrates the efficiency of LoRA with the flexibility of MoE.\nSpecifically, S'MoRE employs hierarchical low-rank decomposition of expert\nweights, yielding residuals of varying orders interconnected in a multi-layer\nstructure. By routing input tokens through sub-trees of residuals, S'MoRE\nemulates the capacity of many experts by instantiating and assembling just a\nfew low-rank matrices. We craft the inter-layer propagation of S'MoRE's\nresiduals as a special type of Graph Neural Network (GNN), and prove that under\nsimilar parameter budget, S'MoRE improves \"structural flexibility\" of\ntraditional MoE (or Mixture-of-LoRA) by exponential order. Comprehensive\ntheoretical analysis and empirical results demonstrate that S'MoRE achieves\nsuperior fine-tuning performance, offering a transformative approach for\nefficient LLM adaptation.", "published": "2025-04-08 20:54:00", "link": "http://arxiv.org/abs/2504.06426v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Machine Unlearning Through the Lens of Mode Connectivity", "abstract": "Machine Unlearning aims to remove undesired information from trained models\nwithout requiring full retraining from scratch. Despite recent advancements,\ntheir underlying loss landscapes and optimization dynamics received less\nattention. In this paper, we investigate and analyze machine unlearning through\nthe lens of mode connectivity - the phenomenon where independently trained\nmodels can be connected by smooth low-loss paths in the parameter space. We\ndefine and study mode connectivity in unlearning across a range of overlooked\nconditions, including connections between different unlearning methods, models\ntrained with and without curriculum learning, and models optimized with\nfirst-order and secondorder techniques. Our findings show distinct patterns of\nfluctuation of different evaluation metrics along the curve, as well as the\nmechanistic (dis)similarity between unlearning methods. To the best of our\nknowledge, this is the first study on mode connectivity in the context of\nmachine unlearning.", "published": "2025-04-08 20:02:10", "link": "http://arxiv.org/abs/2504.06407v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "The Zero Body Problem: Probing LLM Use of Sensory Language", "abstract": "Sensory language expresses embodied experiences ranging from taste and sound\nto excitement and stomachache. This language is of interest to scholars from a\nwide range of domains including robotics, narratology, linguistics, and\ncognitive science. In this work, we explore whether language models, which are\nnot embodied, can approximate human use of embodied language. We extend an\nexisting corpus of parallel human and model responses to short story prompts\nwith an additional 18,000 stories generated by 18 popular models. We find that\nall models generate stories that differ significantly from human usage of\nsensory language, but the direction of these differences varies considerably\nbetween model families. Namely, Gemini models use significantly more sensory\nlanguage than humans along most axes whereas most models from the remaining\nfive families use significantly less. Linear probes run on five models suggest\nthat they are capable of identifying sensory language. However, we find\npreliminary evidence suggesting that instruction tuning may discourage usage of\nsensory language. Finally, to support further work, we release our expanded\nstory dataset.", "published": "2025-04-08 19:31:37", "link": "http://arxiv.org/abs/2504.06393v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Query Understanding in LLM-based Conversational Information Seeking", "abstract": "Query understanding in Conversational Information Seeking (CIS) involves\naccurately interpreting user intent through context-aware interactions. This\nincludes resolving ambiguities, refining queries, and adapting to evolving\ninformation needs. Large Language Models (LLMs) enhance this process by\ninterpreting nuanced language and adapting dynamically, improving the relevance\nand precision of search results in real-time. In this tutorial, we explore\nadvanced techniques to enhance query understanding in LLM-based CIS systems. We\ndelve into LLM-driven methods for developing robust evaluation metrics to\nassess query understanding quality in multi-turn interactions, strategies for\nbuilding more interactive systems, and applications like proactive query\nmanagement and query reformulation. We also discuss key challenges in\nintegrating LLMs for query understanding in conversational search systems and\noutline future research directions. Our goal is to deepen the audience's\nunderstanding of LLM-based conversational query understanding and inspire\ndiscussions to drive ongoing advancements in this field.", "published": "2025-04-08 18:04:43", "link": "http://arxiv.org/abs/2504.06356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Meta-Learning-based Poisoning Attacks for Graph Link Prediction", "abstract": "Link prediction in graph data utilizes various algorithms and machine\nlearning/deep learning models to predict potential relationships between graph\nnodes. This technique has found widespread use in numerous real-world\napplications, including recommendation systems, community networks, and\nbiological structures. However, recent research has highlighted the\nvulnerability of link prediction models to adversarial attacks, such as\npoisoning and evasion attacks. Addressing the vulnerability of these models is\ncrucial to ensure stable and robust performance in link prediction\napplications. While many works have focused on enhancing the robustness of the\nGraph Convolution Network (GCN) model, the Variational Graph Auto-Encoder\n(VGAE), a sophisticated model for link prediction, has not been thoroughly\ninvestigated in the context of graph adversarial attacks. To bridge this gap,\nthis article proposes an unweighted graph poisoning attack approach using\nmeta-learning techniques to undermine VGAE's link prediction performance. We\nconducted comprehensive experiments on diverse datasets to evaluate the\nproposed method and its parameters, comparing it with existing approaches in\nsimilar settings. Our results demonstrate that our approach significantly\ndiminishes link prediction performance and outperforms other state-of-the-art\nmethods.", "published": "2025-04-08 23:36:29", "link": "http://arxiv.org/abs/2504.06492v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AI-Assisted Transport of Radioactive Ion Beams", "abstract": "Beams of radioactive heavy ions allow researchers to study rare and unstable\natomic nuclei, shedding light into the internal structure of exotic nuclei and\non how chemical elements are formed in stars. However, the extraction and\ntransport of radioactive beams rely on time-consuming expert-driven tuning\nmethods, where hundreds of parameters are manually optimized. Here, we\nintroduce a system that uses Artificial Intelligence (AI) to assist in the\nradioactive beam transport process. We apply our methodology to real-life\nscenarios showing advantages when compared with standard tuning methods. Our\nmethod can be extended to other radioactive beam facilities around the world to\nimprove operational efficiency and enhance scientific output.", "published": "2025-04-08 22:21:54", "link": "http://arxiv.org/abs/2504.06469v1", "categories": ["physics.acc-ph", "cs.AI", "nucl-ex"], "primary_category": "physics.acc-ph"}
{"title": "Agent-Arena: A General Framework for Evaluating Control Algorithms", "abstract": "Robotic research is inherently challenging, requiring expertise in diverse\nenvironments and control algorithms. Adapting algorithms to new environments\noften poses significant difficulties, compounded by the need for extensive\nhyper-parameter tuning in data-driven methods. To address these challenges, we\npresent Agent-Arena, a Python framework designed to streamline the integration,\nreplication, development, and testing of decision-making policies across a wide\nrange of benchmark environments. Unlike existing frameworks, Agent-Arena is\nuniquely generalised to support all types of control algorithms and is\nadaptable to both simulation and real-robot scenarios. Please see our GitHub\nrepository https://github.com/halid1020/agent-arena-v0.", "published": "2025-04-08 22:20:50", "link": "http://arxiv.org/abs/2504.06468v1", "categories": ["cs.RO", "cs.AI", "cs.SE"], "primary_category": "cs.RO"}
{"title": "Federated Neural Architecture Search with Model-Agnostic Meta Learning", "abstract": "Federated Learning (FL) often struggles with data heterogeneity due to the\nnaturally uneven distribution of user data across devices. Federated Neural\nArchitecture Search (NAS) enables collaborative search for optimal model\narchitectures tailored to heterogeneous data to achieve higher accuracy.\nHowever, this process is time-consuming due to extensive search space and\nretraining. To overcome this, we introduce FedMetaNAS, a framework that\nintegrates meta-learning with NAS within the FL context to expedite the\narchitecture search by pruning the search space and eliminating the retraining\nstage. Our approach first utilizes the Gumbel-Softmax reparameterization to\nfacilitate relaxation of the mixed operations in the search space. We then\nrefine the local search process by incorporating Model-Agnostic Meta-Learning,\nwhere a task-specific learner adapts both weights and architecture parameters\n(alphas) for individual tasks, while a meta learner adjusts the overall model\nweights and alphas based on the gradient information from task learners.\nFollowing the meta-update, we propose soft pruning using the same trick on\nsearch space to gradually sparsify the architecture, ensuring that the\nperformance of the chosen architecture remains robust after pruning which\nallows for immediate use of the model without retraining. Experimental\nevaluations demonstrate that FedMetaNAS significantly accelerates the search\nprocess by more than 50\\% with higher accuracy compared to FedNAS.", "published": "2025-04-08 21:57:40", "link": "http://arxiv.org/abs/2504.06457v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Can you Finetune your Binoculars? Embedding Text Watermarks into the Weights of Large Language Models", "abstract": "The indistinguishability of AI-generated content from human text raises\nchallenges in transparency and accountability. While several methods exist to\nwatermark models behind APIs, embedding watermark strategies directly into\nmodel weights that are later reflected in the outputs of the model is\nchallenging. In this study we propose a strategy to finetune a pair of low-rank\nadapters of a model, one serving as the text-generating model, and the other as\nthe detector, so that a subtle watermark is embedded into the text generated by\nthe first model and simultaneously optimized for detectability by the second.\nIn this way, the watermarking strategy is fully learned end-to-end. This\nprocess imposes an optimization challenge, as balancing watermark robustness,\nnaturalness, and task performance requires trade-offs. We discuss strategies on\nhow to optimize this min-max objective and present results showing the effect\nof this modification to instruction finetuning.", "published": "2025-04-08 21:34:02", "link": "http://arxiv.org/abs/2504.06446v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evaluating Mutation Techniques in Genetic Algorithm-Based Quantum Circuit Synthesis", "abstract": "Quantum computing leverages the unique properties of qubits and quantum\nparallelism to solve problems intractable for classical systems, offering\nunparalleled computational potential. However, the optimization of quantum\ncircuits remains critical, especially for noisy intermediate-scale quantum\n(NISQ) devices with limited qubits and high error rates. Genetic algorithms\n(GAs) provide a promising approach for efficient quantum circuit synthesis by\nautomating optimization tasks. This work examines the impact of various\nmutation strategies within a GA framework for quantum circuit synthesis. By\nanalyzing how different mutations transform circuits, it identifies strategies\nthat enhance efficiency and performance. Experiments utilized a fitness\nfunction emphasizing fidelity, while accounting for circuit depth and T\noperations, to optimize circuits with four to six qubits. Comprehensive\nhyperparameter testing revealed that combining delete and swap strategies\noutperformed other approaches, demonstrating their effectiveness in developing\nrobust GA-based quantum circuit optimizers.", "published": "2025-04-08 20:14:35", "link": "http://arxiv.org/abs/2504.06413v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Physical spline for denoising object trajectory data by combining splines, ML feature regression and model knowledge", "abstract": "This article presents a method for estimating the dynamic driving states\n(position, velocity, acceleration and heading) from noisy measurement data. The\nproposed approach is effective with both complete and partial observations,\nproducing refined trajectory signals with kinematic consistency, ensuring that\nvelocity is the integral of acceleration and position is the integral of\nvelocity. Additionally, the method accounts for the constraint that vehicles\ncan only move in the direction of their orientation. The method is implemented\nas a configurable python library that also enables trajectory estimation solely\nbased on position data. Regularization is applied to prevent extreme state\nvariations. A key application is enhancing recorded trajectory data for use as\nreference inputs in machine learning models. At the end, the article presents\nthe results of the method along with a comparison to ground truth data.", "published": "2025-04-08 19:53:57", "link": "http://arxiv.org/abs/2504.06404v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images", "abstract": "This paper investigates the application of Low-Rank Adaptation (LoRA) to\nsmall models for cross-domain few-shot object detection in aerial images.\nOriginally designed for large-scale models, LoRA helps mitigate overfitting,\nmaking it a promising approach for resource-constrained settings. We integrate\nLoRA into DiffusionDet, and evaluate its performance on the DOTA and DIOR\ndatasets. Our results show that LoRA applied after an initial fine-tuning\nslightly improves performance in low-shot settings (e.g., 1-shot and 5-shot),\nwhile full fine-tuning remains more effective in higher-shot configurations.\nThese findings highlight LoRA's potential for efficient adaptation in aerial\nobject detection, encouraging further research into parameter-efficient\nfine-tuning strategies for few-shot learning. Our code is available here:\nhttps://github.com/HichTala/LoRA-DiffusionDet.", "published": "2025-04-08 14:10:39", "link": "http://arxiv.org/abs/2504.06330v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Geometric-Aware Perspective and Beyond: Hybrid Quantum-Classical Machine Learning Methods", "abstract": "Geometric Machine Learning (GML) has shown that respecting non-Euclidean\ngeometry in data spaces can significantly improve performance over naive\nEuclidean assumptions. In parallel, Quantum Machine Learning (QML) has emerged\nas a promising paradigm that leverages superposition, entanglement, and\ninterference within quantum state manifolds for learning tasks. This paper\noffers a unifying perspective by casting QML as a specialized yet more\nexpressive branch of GML. We argue that quantum states, whether pure or mixed,\nreside on curved manifolds (e.g., projective Hilbert spaces or density-operator\nmanifolds), mirroring how covariance matrices inhabit the manifold of symmetric\npositive definite (SPD) matrices or how image sets occupy Grassmann manifolds.\nHowever, QML also benefits from purely quantum properties, such as\nentanglement-induced curvature, that can yield richer kernel structures and\nmore nuanced data embeddings.\n  We illustrate these ideas with published and newly discussed results,\nincluding hybrid classical -quantum pipelines for diabetic foot ulcer\nclassification and structural health monitoring. Despite near-term hardware\nlimitations that constrain purely quantum solutions, hybrid architectures\nalready demonstrate tangible benefits by combining classical manifold-based\nfeature extraction with quantum embeddings. We present a detailed mathematical\ntreatment of the geometrical underpinnings of quantum states, emphasizing\nparallels to classical Riemannian geometry and manifold-based optimization.\nFinally, we outline open research challenges and future directions, including\nQuantum Large Language Models (LLMs), quantum reinforcement learning, and\nemerging hardware approaches, demonstrating how synergizing GML and QML\nprinciples can unlock the next generation of machine intelligence.", "published": "2025-04-08 13:24:55", "link": "http://arxiv.org/abs/2504.06328v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Mind the Gap: Evaluating Vision Systems in Small Data Applications", "abstract": "The practical application of AI tools for specific computer vision tasks\nrelies on the \"small-data regime\" of hundreds to thousands of labeled samples.\nThis small-data regime is vital for applications requiring expensive expert\nannotations, such as ecological monitoring, medical diagnostics or industrial\nquality control. We find, however, that computer vision research has ignored\nthe small data regime as evaluations increasingly focus on zero- and few-shot\nlearning. We use the Natural World Tasks (NeWT) benchmark to compare\nmulti-modal large language models (MLLMs) and vision-only methods across\nvarying training set sizes. MLLMs exhibit early performance plateaus, while\nvision-only methods improve throughout the small-data regime, with performance\ngaps widening beyond 10 training examples. We provide the first comprehensive\ncomparison between these approaches in small-data contexts and advocate for\nexplicit small-data evaluations in AI research to better bridge theoretical\nadvances with practical deployments.", "published": "2025-04-08 23:19:00", "link": "http://arxiv.org/abs/2504.06486v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Holistic Fusion: Task- and Setup-Agnostic Robot Localization and State Estimation with Factor Graphs", "abstract": "Seamless operation of mobile robots in challenging environments requires\nlow-latency local motion estimation (e.g., dynamic maneuvers) and accurate\nglobal localization (e.g., wayfinding). While most existing sensor-fusion\napproaches are designed for specific scenarios, this work introduces a flexible\nopen-source solution for task- and setup-agnostic multimodal sensor fusion that\nis distinguished by its generality and usability. Holistic Fusion formulates\nsensor fusion as a combined estimation problem of i) the local and global robot\nstate and ii) a (theoretically unlimited) number of dynamic context variables,\nincluding automatic alignment of reference frames; this formulation fits\ncountless real-world applications without any conceptual modifications. The\nproposed factor-graph solution enables the direct fusion of an arbitrary number\nof absolute, local, and landmark measurements expressed with respect to\ndifferent reference frames by explicitly including them as states in the\noptimization and modeling their evolution as random walks. Moreover, local\nsmoothness and consistency receive particular attention to prevent jumps in the\nrobot state belief. HF enables low-latency and smooth online state estimation\non typical robot hardware while simultaneously providing low-drift global\nlocalization at the IMU measurement rate. The efficacy of this released\nframework is demonstrated in five real-world scenarios on three robotic\nplatforms, each with distinct task requirements.", "published": "2025-04-08 22:54:52", "link": "http://arxiv.org/abs/2504.06479v1", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Implementation of a Zed 2i Stereo Camera for High-Frequency Shoreline Change and Coastal Elevation Monitoring", "abstract": "The increasing population, thus financial interests, in coastal areas have\nincreased the need to monitor coastal elevation and shoreline change. Though\nseveral resources exist to obtain this information, they often lack the\nrequired temporal resolution for short-term monitoring (e.g., every hour). To\naddress this issue, this study implements a low-cost ZED 2i stereo camera\nsystem and close-range photogrammetry to collect images for generating 3D point\nclouds, digital surface models (DSMs) of beach elevation, and georectified\nimagery at a localized scale and high temporal resolution. The main\ncontributions of this study are (i) intrinsic camera calibration, (ii)\ngeorectification and registration of acquired imagery and point cloud, (iii)\ngeneration of the DSM of the beach elevation, and (iv) a comparison of derived\nproducts against those from uncrewed aircraft system structure-from-motion\nphotogrammetry. Preliminary results show that despite its limitations, the ZED\n2i can provide the desired mapping products at localized and high temporal\nscales. The system achieved a mean reprojection error of 0.20 px, a point cloud\nregistration of 27 cm, a vertical error of 37.56 cm relative to ground truth,\nand georectification root mean square errors of 2.67 cm and 2.81 cm for x and\ny.", "published": "2025-04-08 22:08:05", "link": "http://arxiv.org/abs/2504.06464v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AstroClearNet: Deep image prior for multi-frame astronomical image restoration", "abstract": "Recovering high-fidelity images of the night sky from blurred observations is\na fundamental problem in astronomy, where traditional methods typically fall\nshort. In ground-based astronomy, combining multiple exposures to enhance\nsignal-to-noise ratios is further complicated by variations in the point-spread\nfunction caused by atmospheric turbulence. In this work, we present a\nself-supervised multi-frame method, based on deep image priors, for denoising,\ndeblurring, and coadding ground-based exposures. Central to our approach is a\ncarefully designed convolutional neural network that integrates information\nacross multiple observations and enforces physically motivated constraints. We\ndemonstrate the method's potential by processing Hyper Suprime-Cam exposures,\nyielding promising preliminary results with sharper restored images.", "published": "2025-04-08 22:07:00", "link": "http://arxiv.org/abs/2504.06463v1", "categories": ["astro-ph.IM", "cs.CV"], "primary_category": "astro-ph.IM"}
{"title": "D-Feat Occlusions: Diffusion Features for Robustness to Partial Visual Occlusions in Object Recognition", "abstract": "Applications of diffusion models for visual tasks have been quite noteworthy.\nThis paper targets making classification models more robust to occlusions for\nthe task of object recognition by proposing a pipeline that utilizes a frozen\ndiffusion model. Diffusion features have demonstrated success in image\ngeneration and image completion while understanding image context. Occlusion\ncan be posed as an image completion problem by deeming the pixels of the\noccluder to be `missing.' We hypothesize that such features can help\nhallucinate object visual features behind occluding objects, and hence we\npropose using them to enable models to become more occlusion robust. We design\nexperiments to include input-based augmentations as well as feature-based\naugmentations. Input-based augmentations involve finetuning on images where the\noccluder pixels are inpainted, and feature-based augmentations involve\naugmenting classification features with intermediate diffusion features. We\ndemonstrate that our proposed use of diffusion-based features results in models\nthat are more robust to partial object occlusions for both Transformers and\nConvNets on ImageNet with simulated occlusions. We also propose a dataset that\nencompasses real-world occlusions and demonstrate that our method is more\nrobust to partial object occlusions.", "published": "2025-04-08 21:05:29", "link": "http://arxiv.org/abs/2504.06432v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open Source AI", "abstract": "Developmental dysplasia of the hip (DDH) poses significant diagnostic\nchallenges, hindering timely intervention. Current screening methodologies lack\nstandardization, and AI-driven studies suffer from reproducibility issues due\nto limited data and code availability. To address these limitations, we\nintroduce Retuve, an open-source framework for multi-modality DDH analysis,\nencompassing both ultrasound (US) and X-ray imaging. Retuve provides a complete\nand reproducible workflow, offering open datasets comprising expert-annotated\nUS and X-ray images, pre-trained models with training code and weights, and a\nuser-friendly Python Application Programming Interface (API). The framework\nintegrates segmentation and landmark detection models, enabling automated\nmeasurement of key diagnostic parameters such as the alpha angle and acetabular\nindex. By adhering to open-source principles, Retuve promotes transparency,\ncollaboration, and accessibility in DDH research. This initiative has the\npotential to democratize DDH screening, facilitate early diagnosis, and\nultimately improve patient outcomes by enabling widespread screening and early\nintervention. The GitHub repository/code can be found here:\nhttps://github.com/radoss-org/retuve", "published": "2025-04-08 20:41:21", "link": "http://arxiv.org/abs/2504.06422v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "PEEL the Layers and Find Yourself: Revisiting Inference-time Data Leakage for Residual Neural Networks", "abstract": "This paper explores inference-time data leakage risks of deep neural networks\n(NNs), where a curious and honest model service provider is interested in\nretrieving users' private data inputs solely based on the model inference\nresults. Particularly, we revisit residual NNs due to their popularity in\ncomputer vision and our hypothesis that residual blocks are a primary cause of\ndata leakage owing to the use of skip connections. By formulating\ninference-time data leakage as a constrained optimization problem, we propose a\nnovel backward feature inversion method, \\textbf{PEEL}, which can effectively\nrecover block-wise input features from the intermediate output of residual NNs.\nThe surprising results in high-quality input data recovery can be explained by\nthe intuition that the output from these residual blocks can be considered as a\nnoisy version of the input and thus the output retains sufficient information\nfor input recovery. We demonstrate the effectiveness of our layer-by-layer\nfeature inversion method on facial image datasets and pre-trained classifiers.\nOur results show that PEEL outperforms the state-of-the-art recovery methods by\nan order of magnitude when evaluated by mean squared error (MSE). The code is\navailable at\n\\href{https://github.com/Huzaifa-Arif/PEEL}{https://github.com/Huzaifa-Arif/PEEL}", "published": "2025-04-08 20:11:05", "link": "http://arxiv.org/abs/2504.06410v1", "categories": ["cs.LG", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "PromptHMR: Promptable Human Mesh Recovery", "abstract": "Human pose and shape (HPS) estimation presents challenges in diverse\nscenarios such as crowded scenes, person-person interactions, and single-view\nreconstruction. Existing approaches lack mechanisms to incorporate auxiliary\n\"side information\" that could enhance reconstruction accuracy in such\nchallenging scenarios. Furthermore, the most accurate methods rely on cropped\nperson detections and cannot exploit scene context while methods that process\nthe whole image often fail to detect people and are less accurate than methods\nthat use crops. While recent language-based methods explore HPS reasoning\nthrough large language or vision-language models, their metric accuracy is well\nbelow the state of the art. In contrast, we present PromptHMR, a\ntransformer-based promptable method that reformulates HPS estimation through\nspatial and semantic prompts. Our method processes full images to maintain\nscene context and accepts multiple input modalities: spatial prompts like\nbounding boxes and masks, and semantic prompts like language descriptions or\ninteraction labels. PromptHMR demonstrates robust performance across\nchallenging scenarios: estimating people from bounding boxes as small as faces\nin crowded scenes, improving body shape estimation through language\ndescriptions, modeling person-person interactions, and producing temporally\ncoherent motions in videos. Experiments on benchmarks show that PromptHMR\nachieves state-of-the-art performance while offering flexible prompt-based\ncontrol over the HPS estimation process.", "published": "2025-04-08 19:38:04", "link": "http://arxiv.org/abs/2504.06397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation", "abstract": "Domain Adaptation (DA) and Semi-supervised Learning (SSL) converge in\nSemi-supervised Domain Adaptation (SSDA), where the objective is to transfer\nknowledge from a source domain to a target domain using a combination of\nlimited labeled target samples and abundant unlabeled target data. Although\nintuitive, a simple amalgamation of DA and SSL is suboptimal in semantic\nsegmentation due to two major reasons: (1) previous methods, while able to\nlearn good segmentation boundaries, are prone to confuse classes with similar\nvisual appearance due to limited supervision; and (2) skewed and imbalanced\ntraining data distribution preferring source representation learning whereas\nimpeding from exploring limited information about tailed classes. Language\nguidance can serve as a pivotal semantic bridge, facilitating robust class\ndiscrimination and mitigating visual ambiguities by leveraging the rich\nsemantic relationships encoded in pre-trained language models to enhance\nfeature representations across domains. Therefore, we propose the first\nlanguage-guided SSDA setting for semantic segmentation in this work.\nSpecifically, we harness the semantic generalization capabilities inherent in\nvision-language models (VLMs) to establish a synergistic framework within the\nSSDA paradigm. To address the inherent class-imbalance challenges in\nlong-tailed distributions, we introduce class-balanced segmentation loss\nformulations that effectively regularize the learning process. Through\nextensive experimentation across diverse domain adaptation scenarios, our\napproach demonstrates substantial performance improvements over contemporary\nstate-of-the-art (SoTA) methodologies. Code is available:\n\\href{https://github.com/hritam-98/SemiDAViL}{GitHub}.", "published": "2025-04-08 19:14:34", "link": "http://arxiv.org/abs/2504.06389v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Globally Optimal and Geometrically Consistent 3D Shape Matching", "abstract": "Geometric consistency, i.e. the preservation of neighbourhoods, is a natural\nand strong prior in 3D shape matching. Geometrically consistent matchings are\ncrucial for many downstream applications, such as texture transfer or\nstatistical shape modelling. Yet, in practice, geometric consistency is often\noverlooked, or only achieved under severely limiting assumptions (e.g. a good\ninitialisation). In this work, we propose a novel formalism for computing\nglobally optimal and geometrically consistent matchings between 3D shapes which\nis scalable in practice. Our key idea is to represent the surface of the source\nshape as a collection of cyclic paths, which are then consistently matched to\nthe target shape. Mathematically, we construct a hyper product graph (between\nsource and target shape), and then cast 3D shape matching as a minimum-cost\ncirculation flow problem in this hyper graph, which yields global geometrically\nconsistent matchings between both shapes. We empirically show that our\nformalism is efficiently solvable and that it leads to high-quality results.", "published": "2025-04-08 19:08:43", "link": "http://arxiv.org/abs/2504.06385v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Towards Calibration Enhanced Network by Inverse Adversarial Attack", "abstract": "Test automation has become increasingly important as the complexity of both\ndesign and content in Human Machine Interface (HMI) software continues to grow.\nCurrent standard practice uses Optical Character Recognition (OCR) techniques\nto automatically extract textual information from HMI screens for validation.\nAt present, one of the key challenges faced during the automation of HMI screen\nvalidation is the noise handling for the OCR models. In this paper, we propose\nto utilize adversarial training techniques to enhance OCR models in HMI testing\nscenarios. More specifically, we design a new adversarial attack objective for\nOCR models to discover the decision boundaries in the context of HMI testing.\nWe then adopt adversarial training to optimize the decision boundaries towards\na more robust and accurate OCR model. In addition, we also built an HMI screen\ndataset based on real-world requirements and applied multiple types of\nperturbation onto the clean HMI dataset to provide a more complete coverage for\nthe potential scenarios. We conduct experiments to demonstrate how using\nadversarial training techniques yields more robust OCR models against various\nkinds of noises, while still maintaining high OCR model accuracy. Further\nexperiments even demonstrate that the adversarial training models exhibit a\ncertain degree of robustness against perturbations from other patterns.", "published": "2025-04-08 18:13:23", "link": "http://arxiv.org/abs/2504.06358v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Broadcast to Minimap: Achieving State-of-the-Art SoccerNet Game State Reconstruction", "abstract": "Game State Reconstruction (GSR), a critical task in Sports Video\nUnderstanding, involves precise tracking and localization of all individuals on\nthe football field-players, goalkeepers, referees, and others - in real-world\ncoordinates. This capability enables coaches and analysts to derive actionable\ninsights into player movements, team formations, and game dynamics, ultimately\noptimizing training strategies and enhancing competitive advantage. Achieving\naccurate GSR using a single-camera setup is highly challenging due to frequent\ncamera movements, occlusions, and dynamic scene content. In this work, we\npresent a robust end-to-end pipeline for tracking players across an entire\nmatch using a single-camera setup. Our solution integrates a fine-tuned YOLOv5m\nfor object detection, a SegFormer-based camera parameter estimator, and a\nDeepSORT-based tracking framework enhanced with re-identification, orientation\nprediction, and jersey number recognition. By ensuring both spatial accuracy\nand temporal consistency, our method delivers state-of-the-art game state\nreconstruction, securing first place in the SoccerNet Game State Reconstruction\nChallenge 2024 and significantly outperforming competing methods.", "published": "2025-04-08 18:10:44", "link": "http://arxiv.org/abs/2504.06357v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Sparsified-Learning for Heavy-Tailed Locally Stationary Processes", "abstract": "Sparsified Learning is ubiquitous in many machine learning tasks. It aims to\nregularize the objective function by adding a penalization term that considers\nthe constraints made on the learned parameters. This paper considers the\nproblem of learning heavy-tailed LSP. We develop a flexible and robust sparse\nlearning framework capable of handling heavy-tailed data with locally\nstationary behavior and propose concentration inequalities. We further provide\nnon-asymptotic oracle inequalities for different types of sparsity, including\n$\\ell_1$-norm and total variation penalization for the least square loss.", "published": "2025-04-08 22:43:55", "link": "http://arxiv.org/abs/2504.06477v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Deep Fair Learning: A Unified Framework for Fine-tuning Representations with Sufficient Networks", "abstract": "Ensuring fairness in machine learning is a critical and challenging task, as\nbiased data representations often lead to unfair predictions. To address this,\nwe propose Deep Fair Learning, a framework that integrates nonlinear sufficient\ndimension reduction with deep learning to construct fair and informative\nrepresentations. By introducing a novel penalty term during fine-tuning, our\nmethod enforces conditional independence between sensitive attributes and\nlearned representations, addressing bias at its source while preserving\npredictive performance. Unlike prior methods, it supports diverse sensitive\nattributes, including continuous, discrete, binary, or multi-group types.\nExperiments on various types of data structure show that our approach achieves\na superior balance between fairness and utility, significantly outperforming\nstate-of-the-art baselines.", "published": "2025-04-08 22:24:22", "link": "http://arxiv.org/abs/2504.06470v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Classifying Subjective Time Perception in a Multi-robot Control Scenario Using Eye-tracking Information", "abstract": "As automation and mobile robotics reshape work environments, rising\nexpectations for productivity increase cognitive demands on human operators,\nleading to potential stress and cognitive overload. Accurately assessing an\noperator's mental state is critical for maintaining performance and well-being.\nWe use subjective time perception, which can be altered by stress and cognitive\nload, as a sensitive, low-latency indicator of well-being and cognitive strain.\nDistortions in time perception can affect decision-making, reaction times, and\noverall task effectiveness, making it a valuable metric for adaptive\nhuman-swarm interaction systems.\n  We study how human physiological signals can be used to estimate a person's\nsubjective time perception in a human-swarm interaction scenario as example. A\nhuman operator needs to guide and control a swarm of small mobile robots. We\nobtain eye-tracking data that is classified for subjective time perception\nbased on questionnaire data. Our results show that we successfully estimate a\nperson's time perception from eye-tracking data. The approach can profit from\nindividual-based pretraining using only 30 seconds of data. In future work, we\naim for robots that respond to human operator needs by automatically\nclassifying physiological data in a closed control loop.", "published": "2025-04-08 21:30:18", "link": "http://arxiv.org/abs/2504.06442v1", "categories": ["cs.RO", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach", "abstract": "In this paper, we consider the distributed optimal control problem for linear\nnetworked systems. In particular, we are interested in learning distributed\noptimal controllers using graph recurrent neural networks (GRNNs). Most of the\nexisting approaches result in centralized optimal controllers with offline\ntraining processes. However, as the increasing demand of network resilience,\nthe optimal controllers are further expected to be distributed, and are\ndesirable to be trained in an online distributed fashion, which are also the\nmain contributions of our work. To solve this problem, we first propose a\nGRNN-based distributed optimal control method, and we cast the problem as a\nself-supervised learning problem. Then, the distributed online training is\nachieved via distributed gradient computation, and inspired by the\n(consensus-based) distributed optimization idea, a distributed online training\noptimizer is designed. Furthermore, the local closed-loop stability of the\nlinear networked system under our proposed GRNN-based controller is provided by\nassuming that the nonlinear activation function of the GRNN-based controller is\nboth local sector-bounded and slope-restricted. The effectiveness of our\nproposed method is illustrated by numerical simulations using a specifically\ndeveloped simulator.", "published": "2025-04-08 21:18:43", "link": "http://arxiv.org/abs/2504.06439v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "SPIRe: Boosting LLM Inference Throughput with Speculative Decoding", "abstract": "Speculative decoding (SD) has been shown to reduce the latency of\nautoregressive decoding (AD) by 2-3x for small batch sizes. However, increasing\nthroughput and therefore reducing the cost per token requires decoding with\nlarge batch sizes. Recent work shows that SD can accelerate decoding with large\nbatch sizes too if the context is sufficiently long and the draft model's KV\ncache is sparse. We introduce SPIRe, a draft model that combines static sparse\nattention, pruned initialization, and feedback memory to increase the modeled\nthroughput of speculative decoding by over 100% compared to speculation with a\nmuch smaller draft model and by over 35% compared to the strong baseline of\nsparse self-speculation. Our approach is particularly effective when context\nlengths vary significantly across requests.", "published": "2025-04-08 20:39:20", "link": "http://arxiv.org/abs/2504.06419v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Releasing Differentially Private Event Logs Using Generative Models", "abstract": "In recent years, the industry has been witnessing an extended usage of\nprocess mining and automated event data analysis. Consequently, there is a\nrising significance in addressing privacy apprehensions related to the\ninclusion of sensitive and private information within event data utilized by\nprocess mining algorithms. State-of-the-art research mainly focuses on\nproviding quantifiable privacy guarantees, e.g., via differential privacy, for\ntrace variants that are used by the main process mining techniques, e.g.,\nprocess discovery. However, privacy preservation techniques designed for the\nrelease of trace variants are still insufficient to meet all the demands of\nindustry-scale utilization. Moreover, ensuring privacy guarantees in situations\ncharacterized by a high occurrence of infrequent trace variants remains a\nchallenging endeavor. In this paper, we introduce two novel approaches for\nreleasing differentially private trace variants based on trained generative\nmodels. With TraVaG, we leverage \\textit{Generative Adversarial Networks}\n(GANs) to sample from a privatized implicit variant distribution. Our second\nmethod employs \\textit{Denoising Diffusion Probabilistic Models} that\nreconstruct artificial trace variants from noise via trained Markov chains.\nBoth methods offer industry-scale benefits and elevate the degree of privacy\nassurances, particularly in scenarios featuring a substantial prevalence of\ninfrequent variants. Also, they overcome the shortcomings of conventional\nprivacy preservation techniques, such as bounding the length of variants and\nintroducing fake variants. Experimental results on real-life event data\ndemonstrate that our approaches surpass state-of-the-art techniques in terms of\nprivacy guarantees and utility preservation.", "published": "2025-04-08 20:35:53", "link": "http://arxiv.org/abs/2504.06418v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Unifying Autoregressive and Diffusion-Based Sequence Generation", "abstract": "We present significant extensions to diffusion-based sequence generation\nmodels, blurring the line with autoregressive language models. We introduce\nhyperschedules, which assign distinct noise schedules to individual token\npositions, generalizing both autoregressive models (e.g., GPT) and conventional\ndiffusion models (e.g., SEDD, MDLM) as special cases. Second, we propose two\nhybrid token-wise noising processes that interpolate between absorbing and\nuniform processes, enabling the model to fix past mistakes, and we introduce a\nnovel inference algorithm that leverages this new feature in a simplified\ncontext inspired from MDLM. To support efficient training and inference, we\ndesign attention masks compatible with KV-caching. Our methods achieve\nstate-of-the-art perplexity and generate diverse, high-quality sequences across\nstandard benchmarks, suggesting a promising path for autoregressive\ndiffusion-based sequence generation.", "published": "2025-04-08 20:32:10", "link": "http://arxiv.org/abs/2504.06416v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Low Rank Learning for Offline Query Optimization", "abstract": "Recent deployments of learned query optimizers use expensive neural networks\nand ad-hoc search policies. To address these issues, we introduce\n\\textsc{LimeQO}, a framework for offline query optimization leveraging low-rank\nlearning to efficiently explore alternative query plans with minimal resource\nusage. By modeling the workload as a partially observed, low-rank matrix, we\npredict unobserved query plan latencies using purely linear methods,\nsignificantly reducing computational overhead compared to neural networks. We\nformalize offline exploration as an active learning problem, and present simple\nheuristics that reduces a 3-hour workload to 1.5 hours after just 1.5 hours of\nexploration. Additionally, we propose a transductive Tree Convolutional Neural\nNetwork (TCNN) that, despite higher computational costs, achieves the same\nworkload reduction with only 0.5 hours of exploration. Unlike previous\napproaches that place expensive neural networks directly in the query\nprocessing ``hot'' path, our approach offers a low-overhead solution and a\nno-regressions guarantee, all without making assumptions about the underlying\nDBMS. The code is available in\n\\href{https://github.com/zixy17/LimeQO}{https://github.com/zixy17/LimeQO}.", "published": "2025-04-08 19:41:19", "link": "http://arxiv.org/abs/2504.06399v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Sharpness-Aware Parameter Selection for Machine Unlearning", "abstract": "It often happens that some sensitive personal information, such as credit\ncard numbers or passwords, are mistakenly incorporated in the training of\nmachine learning models and need to be removed afterwards. The removal of such\ninformation from a trained model is a complex task that needs to partially\nreverse the training process. There have been various machine unlearning\ntechniques proposed in the literature to address this problem. Most of the\nproposed methods revolve around removing individual data samples from a trained\nmodel. Another less explored direction is when features/labels of a group of\ndata samples need to be reverted. While the existing methods for these tasks do\nthe unlearning task by updating the whole set of model parameters or only the\nlast layer of the model, we show that there are a subset of model parameters\nthat have the largest contribution in the unlearning target features. More\nprecisely, the model parameters with the largest corresponding diagonal value\nin the Hessian matrix (computed at the learned model parameter) have the most\ncontribution in the unlearning task. By selecting these parameters and updating\nthem during the unlearning stage, we can have the most progress in unlearning.\nWe provide theoretical justifications for the proposed strategy by connecting\nit to sharpness-aware minimization and robust unlearning. We empirically show\nthe effectiveness of the proposed strategy in improving the efficacy of\nunlearning with a low computational cost.", "published": "2025-04-08 19:41:07", "link": "http://arxiv.org/abs/2504.06398v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SPoRt -- Safe Policy Ratio: Certified Training and Deployment of Task Policies in Model-Free RL", "abstract": "To apply reinforcement learning to safety-critical applications, we ought to\nprovide safety guarantees during both policy training and deployment. In this\nwork we present novel theoretical results that provide a bound on the\nprobability of violating a safety property for a new task-specific policy in a\nmodel-free, episodic setup: the bound, based on a `maximum policy ratio' that\nis computed with respect to a `safe' base policy, can also be more generally\napplied to temporally-extended properties (beyond safety) and to robust control\nproblems. We thus present SPoRt, which also provides a data-driven approach for\nobtaining such a bound for the base policy, based on scenario theory, and which\nincludes Projected PPO, a new projection-based approach for training the\ntask-specific policy while maintaining a user-specified bound on property\nviolation. Hence, SPoRt enables the user to trade off safety guarantees in\nexchange for task-specific performance. Accordingly, we present experimental\nresults demonstrating this trade-off, as well as a comparison of the\ntheoretical bound to posterior bounds based on empirical violation rates.", "published": "2025-04-08 19:09:07", "link": "http://arxiv.org/abs/2504.06386v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep spatio-temporal point processes: Advances and new directions", "abstract": "Spatio-temporal point processes (STPPs) model discrete events distributed in\ntime and space, with important applications in areas such as criminology,\nseismology, epidemiology, and social networks. Traditional models often rely on\nparametric kernels, limiting their ability to capture heterogeneous,\nnonstationary dynamics. Recent innovations integrate deep neural architectures\n-- either by modeling the conditional intensity function directly or by\nlearning flexible, data-driven influence kernels, substantially broadening\ntheir expressive power. This article reviews the development of the deep\ninfluence kernel approach, which enjoys statistical explainability, since the\ninfluence kernel remains in the model to capture the spatiotemporal propagation\nof event influence and its impact on future events, while also possessing\nstrong expressive power, thereby benefiting from both worlds. We explain the\nmain components in developing deep kernel point processes, leveraging tools\nsuch as functional basis decomposition and graph neural networks to encode\ncomplex spatial or network structures, as well as estimation using both\nlikelihood-based and likelihood-free methods, and address computational\nscalability for large-scale data. We also discuss the theoretical foundation of\nkernel identifiability. Simulated and real-data examples highlight applications\nto crime analysis, earthquake aftershock prediction, and sepsis prediction\nmodeling, and we conclude by discussing promising directions for the field.", "published": "2025-04-08 18:28:12", "link": "http://arxiv.org/abs/2504.06364v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "An Information-Geometric Approach to Artificial Curiosity", "abstract": "Learning in environments with sparse rewards remains a fundamental challenge\nin reinforcement learning. Artificial curiosity addresses this limitation\nthrough intrinsic rewards to guide exploration, however, the precise\nformulation of these rewards has remained elusive. Ideally, such rewards should\ndepend on the agent's information about the environment, remaining agnostic to\nthe representation of the information -- an invariance central to information\ngeometry. Leveraging information geometry, we show that invariance under\ncongruent Markov morphisms and the agent-environment interaction, uniquely\nconstrains intrinsic rewards to concave functions of the reciprocal occupancy.\nAdditional geometrically motivated restrictions effectively limits the\ncandidates to those determined by a real parameter that governs the occupancy\nspace geometry. Remarkably, special values of this parameter are found to\ncorrespond to count-based and maximum entropy exploration, revealing a\ngeometric exploration-exploitation trade-off. This framework provides important\nconstraints to the engineering of intrinsic reward while integrating\nfoundational exploration methods into a single, cohesive model.", "published": "2025-04-08 18:04:15", "link": "http://arxiv.org/abs/2504.06355v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Extended Version: Multi-Robot Motion Planning with Cooperative Localization", "abstract": "We consider the uncertain multi-robot motion planning (MRMP) problem with\ncooperative localization (CL-MRMP), under both motion and measurement noise,\nwhere each robot can act as a sensor for its nearby teammates. We formalize\nCL-MRMP as a chance-constrained motion planning problem, and propose a\nsafety-guaranteed algorithm that explicitly accounts for robot-robot\ncorrelations. Our approach extends a sampling-based planner to solve CL-MRMP\nwhile preserving probabilistic completeness. To improve efficiency, we\nintroduce novel biasing techniques. We evaluate our method across diverse\nbenchmarks, demonstrating its effectiveness in generating motion plans, with\nsignificant performance gains from biasing strategies.", "published": "2025-04-08 20:58:19", "link": "http://arxiv.org/abs/2504.06429v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Successive randomized compression: A randomized algorithm for the compressed MPO-MPS product", "abstract": "Tensor networks like matrix product states (MPSs) and matrix product\noperators (MPOs) are powerful tools for representing exponentially large states\nand operators, with applications in quantum many-body physics, machine\nlearning, numerical analysis, and other areas. In these applications, computing\na compressed representation of the MPO--MPS product is a fundamental\ncomputational primitive. For this operation, this paper introduces a new\nsingle-pass, randomized algorithm, called successive randomized compression\n(SRC), that improves on existing approaches in speed or in accuracy. The\nperformance of the new algorithm is evaluated on synthetic problems and unitary\ntime evolution problems for quantum spin systems.", "published": "2025-04-08 22:33:49", "link": "http://arxiv.org/abs/2504.06475v1", "categories": ["quant-ph", "cond-mat.str-el", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "Solving Power System Problems using Adiabatic Quantum Computing", "abstract": "This letter proposes a novel combinatorial optimization framework that\nreformulates existing power system problems into a format executable on quantum\nannealers. The proposed framework accommodates both normal and complex numbers\nand enables efficient handling of large-scale problems, thus ensuring broad\napplicability across power system problems. As a proof of concept, we\ndemonstrate its applicability in two classical problems: (i) power system\nparameter identification, where we estimate the admittance matrix given voltage\nand current measurements, and (ii) power flow analysis, where we reformulate\nthe nonlinear equations governing active and reactive power balance. The\nresults show that the proposed framework effectively and efficiently solves\nboth linear and nonlinear power system problems, and thus offers significant\nadvantages in scenarios where traditional solvers face challenges, such as\nill-conditioned systems and fault conditions.", "published": "2025-04-08 21:59:46", "link": "http://arxiv.org/abs/2504.06458v1", "categories": ["cs.ET", "cs.NA", "cs.SY", "eess.SY", "math.NA"], "primary_category": "cs.ET"}
{"title": "Neural Network Enhanced Polyconvexification of Isotropic Energy Densities in Computational Mechanics", "abstract": "We present a neural network approach for fast evaluation of\nparameter-dependent polyconvex envelopes, which are crucial in computational\nmechanics. Our method uses a neural network architecture that inherently\nencodes polyconvexity in the main variable by combining a feature extraction\nlayer that computes the minors function on the signed singular value\ncharacterisation of isotropic energy densities with a partially input convex\nneural network (PICNN). Polyconvex underestimation is weakly enforced by\npenalisation during training, as are the symmetries of the function. As a\nguiding example, we focus on a well-known isotropic damage problem,\nreformulated in terms of signed singular values, and apply a splitting approach\nto reduce the dimensionality of the parameter space, thereby making training\nmore tractable. Numerical experiments show that the networks achieve sufficient\naccuracy for engineering applications while providing high compression and\nsignificant speed-up over traditional polyconvexification schemes. Most\nimportantly, the network adapts to varying physical or material parameters,\nenabling real-time polyconvexification in large-scale computational mechanics\nscenarios.", "published": "2025-04-08 20:48:39", "link": "http://arxiv.org/abs/2504.06425v1", "categories": ["math.NA", "cs.NA", "49J45, 49J10, 74G65, 74B20, 68T07, 74A45"], "primary_category": "math.NA"}
{"title": "On Mixed-Precision Iterative Methods and Analysis for Nearly Completely Decomposable Markov Processes", "abstract": "In this paper we consider the problem of computing the stationary\ndistribution of nearly completely decomposable Markov processes, a\nwell-established area in the classical theory of Markov processes with broad\napplications in the design, modeling, analysis and optimization of computer\nsystems. We design general classes of algorithmic solution approaches that\nexploit forms of mixed-precision computation to significantly reduce\ncomputation times and that exploit forms of iterative approximate methods to\nmitigate the impact of inaccurate computations, further reduce computation\ntimes, and ensure convergence. Then we derive a mathematical analysis of our\ngeneral algorithmic approaches that establishes theoretical results on\napproximation errors, convergence behaviors, and other algorithmic properties.\nNumerical experiments demonstrate that our general algorithmic approaches\nprovide significant improvements in computation times over the most efficient\nexisting numerical methods.", "published": "2025-04-08 18:57:25", "link": "http://arxiv.org/abs/2504.06378v1", "categories": ["math.NA", "cs.NA", "65C40, 65Fxx", "G.1.3"], "primary_category": "math.NA"}
{"title": "Efficient Simulation of Singularly Perturbed Systems Using a Stabilized Multirate Explicit Scheme", "abstract": "Singularly perturbed systems (SPSs) are prevalent in engineering\napplications, where numerically solving their initial value problems (IVPs) is\nchallenging due to stiffness arising from multiple time scales. Classical\nexplicit methods require impractically small time steps for stability, while\nimplicit methods developed for SPSs are computationally intensive and less\nefficient for strongly nonlinear systems. This paper introduces a Stabilized\nMultirate Explicit Scheme (SMES) that stabilizes classical explicit methods\nwithout the need for small time steps or implicit formulations. By employing a\nmultirate approach with variable time steps, SMES allows the fast dynamics to\nrapidly converge to their equilibrium manifold while slow dynamics evolve with\nlarger steps. Analysis shows that SMES achieves numerical stability with\nsignificantly reduced computational effort and controlled error. Its\neffectiveness is illustrated with a numerical example.", "published": "2025-04-08 18:40:53", "link": "http://arxiv.org/abs/2504.06371v1", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY"], "primary_category": "math.NA"}
{"title": "Local signature-based expansions", "abstract": "We study the local (in time) expansion of a continuous-time process and its\nconditional moments, including the process' characteristic function. The\nexpansions are conducted by using the properties of the (time-extended) Ito\nsignature, a tractable basis composed of iterated integrals of the driving\ndeterministic and stochastic signals: time, multiple correlated Brownian\nmotions and multiple correlated compound Poisson processes. We show that these\nproperties are conducive to automated expansions to any order with explicit\ncoefficients and, therefore, to stochastic representations in which asymptotics\ncan be conducted for a shrinking time (t to 0), as in the extant\ncontinuous-time econometrics literature, but, also, for a fixed time (such that\nt smaller than 1) with a diverging expansion order. The latter design opens up\nnovel opportunities for identifying deep characteristics of the assumed\nprocess.", "published": "2025-04-08 18:01:04", "link": "http://arxiv.org/abs/2504.06351v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "Bounds in Wasserstein Distance for Locally Stationary Functional Time Series", "abstract": "Functional time series (FTS) extend traditional methodologies to accommodate\ndata observed as functions/curves. A significant challenge in FTS consists of\naccurately capturing the time-dependence structure, especially with the\npresence of time-varying covariates. When analyzing time series with\ntime-varying statistical properties, locally stationary time series (LSTS)\nprovide a robust framework that allows smooth changes in mean and variance over\ntime. This work investigates Nadaraya-Watson (NW) estimation procedure for the\nconditional distribution of locally stationary functional time series (LSFTS),\nwhere the covariates reside in a semi-metric space endowed with a semi-metric.\nUnder small ball probability and mixing condition, we establish convergence\nrates of NW estimator for LSFTS with respect to Wasserstein distance. The\nfinite-sample performances of the model and the estimation method are\nillustrated through extensive numerical experiments both on functional\nsimulated and real data.", "published": "2025-04-08 21:49:58", "link": "http://arxiv.org/abs/2504.06453v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Metropolis-Adjusted Langevin Algorithm for Sampling Jeffreys Prior", "abstract": "Inference and estimation are fundamental aspects of statistics, system\nidentification and machine learning. For most inference problems, prior\nknowledge is available on the system to be modeled, and Bayesian analysis is a\nnatural framework to impose such prior information in the form of a prior\ndistribution. However, in many situations, coming out with a fully specified\nprior distribution is not easy, as prior knowledge might be too vague, so\npractitioners prefer to use a prior distribution that is as `ignorant' or\n`uninformative' as possible, in the sense of not imposing subjective beliefs,\nwhile still supporting reliable statistical analysis. Jeffreys prior is an\nappealing uninformative prior because it offers two important benefits: (i) it\nis invariant under any re-parameterization of the model, (ii) it encodes the\nintrinsic geometric structure of the parameter space through the Fisher\ninformation matrix, which in turn enhances the diversity of parameter samples.\nDespite these benefits, drawing samples from Jeffreys prior is a challenging\ntask. In this paper, we propose a general sampling scheme using the\nMetropolis-Adjusted Langevin Algorithm that enables sampling of parameter\nvalues from Jeffreys prior, and provide numerical illustrations of our approach\nthrough several examples.", "published": "2025-04-08 18:44:33", "link": "http://arxiv.org/abs/2504.06372v1", "categories": ["eess.SY", "cs.SY", "stat.ME", "stat.ML"], "primary_category": "eess.SY"}
{"title": "Panoptic: True Joint mmWave Communication and Sensing with Compressive Sidelobe Forming", "abstract": "The integration of communication and sensing functions within mmWave systems\nhas gained attention due to the potential for enhanced passive sensing and\nimproved communication reliability. State-of-the-art techniques separate these\ntwo functions in frequency, use of hardware, or time, i.e., sending known\npreambles for channel sensing or unknown symbols for communications. In this\npaper, we introduce Panoptic, a novel system architecture for integrated\ncommunication and sensing sharing the same hardware, frequency, and time\nresources. Panoptic jointly detects unknown symbols and channel components from\ndata-modulated signals. The core idea is a new beam manipulation technique,\nwhich we call compressive sidelobe forming, that maintains a directional\nmainlobe toward the intended communication nodes while acquiring unique spatial\ninformation through pseudorandom sidelobe perturbations. We implemented\nPanoptic on 60 GHz mmWave radios and conducted extensive over-the-air\nexperiments. Our results show that Panoptic achieves reflector angular\nlocalization error of less than 2\\deg while at the same time supporting mmWave\ndata communication with a negligible BER penalty when compared with\nconventional communication-only mmWave systems.", "published": "2025-04-08 19:41:48", "link": "http://arxiv.org/abs/2504.06400v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization", "abstract": "Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.", "published": "2025-04-08 17:59:57", "link": "http://arxiv.org/abs/2504.06265v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Multimedia Analytics Model for the Foundation Model Era", "abstract": "The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.", "published": "2025-04-08 15:35:59", "link": "http://arxiv.org/abs/2504.06138v2", "categories": ["cs.MM", "cs.AI", "cs.HC"], "primary_category": "cs.MM"}
{"title": "Fast Globally Optimal and Geometrically Consistent 3D Shape Matching", "abstract": "Geometric consistency, i.e. the preservation of neighbourhoods, is a natural\nand strong prior in 3D shape matching. Geometrically consistent matchings are\ncrucial for many downstream applications, such as texture transfer or\nstatistical shape modelling. Yet, in practice, geometric consistency is often\noverlooked, or only achieved under severely limiting assumptions (e.g. a good\ninitialisation). In this work, we propose a novel formalism for computing\nglobally optimal and geometrically consistent matchings between 3D shapes which\nis scalable in practice. Our key idea is to represent the surface of the source\nshape as a collection of cyclic paths, which are then consistently matched to\nthe target shape. Mathematically, we construct a hyper product graph (between\nsource and target shape), and then cast 3D shape matching as a minimum-cost\ncirculation flow problem in this hyper graph, which yields global geometrically\nconsistent matchings between both shapes. We empirically show that our\nformalism is efficiently solvable and that it leads to high-quality results.", "published": "2025-04-08 19:08:43", "link": "http://arxiv.org/abs/2504.06385v2", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Unified Generative Search and Recommendation", "abstract": "Modern commercial platforms typically offer both search and recommendation\nfunctionalities to serve diverse user needs, making joint modeling of these\ntasks an appealing direction. While prior work has shown that integrating\nsearch and recommendation can be mutually beneficial, it also reveals a\nperformance trade-off: enhancements in one task often come at the expense of\nthe other. This challenge arises from their distinct information requirements:\nsearch emphasizes semantic relevance between queries and items, whereas\nrecommendation depends more on collaborative signals among users and items.\nEffectively addressing this trade-off requires tackling two key problems: (1)\nintegrating both semantic and collaborative signals into item representations,\nand (2) guiding the model to distinguish and adapt to the unique demands of\nsearch and recommendation. The emergence of generative retrieval with Large\nLanguage Models (LLMs) presents new possibilities. This paradigm encodes items\nas identifiers and frames both search and recommendation as sequential\ngeneration tasks, offering the flexibility to leverage multiple identifiers and\ntask-specific prompts. In light of this, we introduce GenSAR, a unified\ngenerative framework for balanced search and recommendation. Our approach\ndesigns dual-purpose identifiers and tailored training strategies to\nincorporate complementary signals and align with task-specific objectives.\nExperiments on both public and commercial datasets demonstrate that GenSAR\neffectively reduces the trade-off and achieves state-of-the-art performance on\nboth tasks.", "published": "2025-04-08 07:03:08", "link": "http://arxiv.org/abs/2504.05730v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Fusing Global and Local: Transformer-CNN Synergy for Next-Gen Current Estimation", "abstract": "This paper presents a hybrid model combining Transformer and CNN for\npredicting the current waveform in signal lines. Unlike traditional approaches\nsuch as current source models, driver linear representations, waveform\nfunctional fitting, or equivalent load capacitance methods, our model does not\nrely on fixed simplified models of standard-cell drivers or RC loads. Instead,\nit replaces the complex Newton iteration process used in traditional SPICE\nsimulations, leveraging the powerful sequence modeling capabilities of the\nTransformer framework to directly predict current responses without iterative\nsolving steps. The hybrid architecture effectively integrates the global\nfeature-capturing ability of Transformers with the local feature extraction\nadvantages of CNNs, significantly improving the accuracy of current waveform\npredictions.\n  Experimental results demonstrate that, compared to traditional SPICE\nsimulations, the proposed algorithm achieves an error of only 0.0098. These\nresults highlight the algorithm's superior capabilities in predicting signal\nline current waveforms, timing analysis, and power evaluation, making it\nsuitable for a wide range of technology nodes, from 40nm to 3nm.", "published": "2025-04-08 19:42:10", "link": "http://arxiv.org/abs/2504.07996v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Towards Simple Machine Learning Baselines for GNSS RFI Detection", "abstract": "Machine learning research in GNSS radio frequency interference (RFI)\ndetection often lacks a proper justification for the decisions made in deep\nlearning-based model architectures. Our paper challenges the status quo in\nmachine learning approaches for GNSS RFI detection, revealing the potentially\nmisleading track of current research and highlighting alternative directions.\nOur position advocates for a shift in focus from solely pursuing novel model\ndesigns to critically evaluating the utility of complex black box deep learning\nmethods against simpler and more interpretable machine learning baselines. Our\nfindings demonstrate the need for the creation of simple baselines and suggest\nthe need for more exploration and development of simple and interpretable\nmachine learning methods for the detection of GNSS RFIs. The increment of model\ncomplexity in the state-of-the-art deep learning-based models often provides\nvery little improvement. Thanks to a unique dataset from Swiss Air Force and\nSwiss Air-Rescue (Rega), preprocessed by Swiss Air Navigation Services Ltd.\n(Skyguide), we demonstrate the effectiveness of a simple machine learning\nbaseline for GNSS RFI detection on real-world large-scale aircraft data\ncontaining flight recordings impacted by real jamming. The experimental results\nindicate that our solution successfully detects potential GNSS RFI with 91%\naccuracy outperforming state-of-the-art deep learning architectures. We believe\nthat our work offers insights and suggestions for the field to move forward.", "published": "2025-04-08 12:45:01", "link": "http://arxiv.org/abs/2504.07993v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
