{"title": "Helping Crisis Responders Find the Informative Needle in the Tweet\n  Haystack", "abstract": "Crisis responders are increasingly using social media, data and other digital\nsources of information to build a situational understanding of a crisis\nsituation in order to design an effective response. However with the increased\navailability of such data, the challenge of identifying relevant information\nfrom it also increases. This paper presents a successful automatic approach to\nhandling this problem. Messages are filtered for informativeness based on a\ndefinition of the concept drawn from prior research and crisis response\nexperts. Informative messages are tagged for actionable data -- for example,\npeople in need, threats to rescue efforts, changes in environment, and so on.\nIn all, eight categories of actionability are identified. The two components --\ninformativeness and actionability classification -- are packaged together as an\nopenly-available tool called Emina (Emergent Informativeness and\nActionability).", "published": "2018-01-29 17:18:40", "link": "http://arxiv.org/abs/1801.09633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts", "abstract": "Motivated by a project to create a system for people who are deaf or\nhard-of-hearing that would use automatic speech recognition (ASR) to produce\nreal-time text captions of spoken English during in-person meetings with\nhearing individuals, we have augmented a transcript of the Switchboard\nconversational dialogue corpus with an overlay of word-importance annotations,\nwith a numeric score for each word, to indicate its importance to the meaning\nof each dialogue turn. Further, we demonstrate the utility of this corpus by\ntraining an automatic word importance labeling model; our best performing model\nhas an F-score of 0.60 in an ordinal 6-class word-importance classification\ntask with an agreement (concordance correlation coefficient) of 0.839 with the\nhuman annotators (agreement score between annotators is 0.89). Finally, we\ndiscuss our intended future applications of this resource, particularly for the\ntask of evaluating ASR performance, i.e. creating metrics that predict\nASR-output caption text usability for DHH users better thanWord Error Rate\n(WER).", "published": "2018-01-29 20:37:10", "link": "http://arxiv.org/abs/1801.09746v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geospatial distributions reflect rates of evolution of features of\n  language", "abstract": "Quantifying the speed of linguistic change is challenging due to the fact\nthat the historical evolution of languages is sparsely documented.\nConsequently, traditional methods rely on phylogenetic reconstruction. In this\npaper, we propose a model-based approach to the problem through the analysis of\nlanguage change as a stochastic process combining vertical descent, spatial\ninteractions, and mutations in both dimensions. A notion of linguistic\ntemperature emerges naturally from this analysis as a dimensionless measure of\nthe propensity of a linguistic feature to undergo change. We demonstrate how\ntemperatures of linguistic features can be inferred from their present-day\ngeospatial distributions, without recourse to information about their\nphylogenies. Thus the evolutionary dynamics of language, operating across\nthousands of years, leaves a measurable geospatial signature. This signature\nlicenses inferences about the historical evolution of languages even in the\nabsence of longitudinal data.", "published": "2018-01-29 17:24:27", "link": "http://arxiv.org/abs/1801.09637v2", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "cs.CL", "nlin.AO"], "primary_category": "physics.soc-ph"}
{"title": "Evaluating approaches for supervised semantic labeling", "abstract": "Relational data sources are still one of the most popular ways to store\nenterprise or Web data, however, the issue with relational schema is the lack\nof a well-defined semantic description. A common ontology provides a way to\nrepresent the meaning of a relational schema and can facilitate the integration\nof heterogeneous data sources within a domain. Semantic labeling is achieved by\nmapping attributes from the data sources to the classes and properties in the\nontology. We formulate this problem as a multi-class classification problem\nwhere previously labeled data sources are used to learn rules for labeling new\ndata sources. The majority of existing approaches for semantic labeling have\nfocused on data integration challenges such as naming conflicts and semantic\nheterogeneity. In addition, machine learning approaches typically have issues\naround class imbalance, lack of labeled instances and relative importance of\nattributes. To address these issues, we develop a new machine learning model\nwith engineered features as well as two deep learning models which do not\nrequire extensive feature engineering. We evaluate our new approaches with the\nstate-of-the-art.", "published": "2018-01-29 22:43:32", "link": "http://arxiv.org/abs/1801.09788v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Highly-Reverberant Real Environment database: HRRE", "abstract": "Speech recognition in highly-reverberant real environments remains a major\nchallenge. An evaluation dataset for this task is needed. This report describes\nthe generation of the Highly-Reverberant Real Environment database (HRRE). This\ndatabase contains 13.4 hours of data recorded in real reverberant environments\nand consists of 20 different testing conditions which consider a wide range of\nreverberation times and speaker-to-microphone distances. These evaluation sets\nwere generated by re-recording the clean test set of the Aurora-4 database\nwhich corresponds to five loudspeaker-microphone distances in four reverberant\nconditions.", "published": "2018-01-29 18:08:34", "link": "http://arxiv.org/abs/1801.09651v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On Psychoacoustically Weighted Cost Functions Towards Resource-Efficient\n  Deep Neural Networks for Speech Denoising", "abstract": "We present a psychoacoustically enhanced cost function to balance network\ncomplexity and perceptual performance of deep neural networks for speech\ndenoising. While training the network, we utilize perceptual weights added to\nthe ordinary mean-squared error to emphasize contribution from frequency bins\nwhich are most audible while ignoring error from inaudible bins. To generate\nthe weights, we employ psychoacoustic models to compute the global masking\nthreshold from the clean speech spectra. We then evaluate the speech denoising\nperformance of our perceptually guided neural network by using both objective\nand perceptual sound quality metrics, testing on various network structures\nranging from shallow and narrow ones to deep and wide ones. The experimental\nresults showcase our method as a valid approach for infusing perceptual\nsignificance to deep neural network operations. In particular, the more\nperceptually sensible enhancement in performance seen by simple neural network\ntopologies proves that the proposed method can lead to resource-efficient\nspeech denoising implementations in small devices without degrading the\nperceived signal fidelity.", "published": "2018-01-29 21:45:05", "link": "http://arxiv.org/abs/1801.09774v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multichannel Sound Event Detection Using 3D Convolutional Neural\n  Networks for Learning Inter-channel Features", "abstract": "In this paper, we propose a stacked convolutional and recurrent neural\nnetwork (CRNN) with a 3D convolutional neural network (CNN) in the first layer\nfor the multichannel sound event detection (SED) task. The 3D CNN enables the\nnetwork to simultaneously learn the inter- and intra-channel features from the\ninput multichannel audio. In order to evaluate the proposed method,\nmultichannel audio datasets with different number of overlapping sound sources\nare synthesized. Each of this dataset has a four-channel first-order Ambisonic,\nbinaural, and single-channel versions, on which the performance of SED using\nthe proposed method are compared to study the potential of SED using\nmultichannel audio. A similar study is also done with the binaural and\nsingle-channel versions of the real-life recording TUT-SED 2017 development\ndataset. The proposed method learns to recognize overlapping sound events from\nmultichannel features faster and performs better SED with a fewer number of\ntraining epochs. The results show that on using multichannel Ambisonic audio in\nplace of single-channel audio we improve the overall F-score by 7.5%, overall\nerror rate by 10% and recognize 15.6% more sound events in time frames with\nfour overlapping sound sources.", "published": "2018-01-29 14:24:39", "link": "http://arxiv.org/abs/1801.09522v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
