{"title": "Assessing the impact of contextual information in hate speech detection", "abstract": "In recent years, hate speech has gained great relevance in social networks\nand other virtual media because of its intensity and its relationship with\nviolent acts against members of protected groups. Due to the great amount of\ncontent generated by users, great effort has been made in the research and\ndevelopment of automatic tools to aid the analysis and moderation of this\nspeech, at least in its most threatening forms. One of the limitations of\ncurrent approaches to automatic hate speech detection is the lack of context.\nMost studies and resources are performed on data without context; that is,\nisolated messages without any type of conversational context or the topic being\ndiscussed. This restricts the available information to define if a post on a\nsocial network is hateful or not. In this work, we provide a novel corpus for\ncontextualized hate speech detection based on user responses to news posts from\nmedia outlets on Twitter. This corpus was collected in the Rioplatense\ndialectal variety of Spanish and focuses on hate speech associated with the\nCOVID-19 pandemic. Classification experiments using state-of-the-art techniques\nshow evidence that adding contextual information improves hate speech detection\nperformance for two proposed tasks (binary and multi-label prediction). We make\nour code, models, and corpus available for further research.", "published": "2022-10-02 09:04:47", "link": "http://arxiv.org/abs/2210.00465v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-grained Contrastive Learning for Definition Generation", "abstract": "Recently, pre-trained transformer-based models have achieved great success in\nthe task of definition generation (DG). However, previous encoder-decoder\nmodels lack effective representation learning to contain full semantic\ncomponents of the given word, which leads to generating under-specific\ndefinitions. To address this problem, we propose a novel contrastive learning\nmethod, encouraging the model to capture more detailed semantic representations\nfrom the definition sequence encoding. According to both automatic and manual\nevaluation, the experimental results on three mainstream benchmarks demonstrate\nthat the proposed method could generate more specific and high-quality\ndefinitions compared with several state-of-the-art models.", "published": "2022-10-02 14:55:01", "link": "http://arxiv.org/abs/2210.00543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ALT: A software for readability analysis of Portuguese-language texts", "abstract": "In the initial stage of human life, communication, seen as a process of\nsocial interaction, was always the best way to reach consensus between the\nparties. Understanding and credibility in this process are essential for the\nmutual agreement to be validated. But, how to do it so that this communication\nreaches the great mass? This is the main challenge when what is sought is the\ndissemination of information and its approval. In this context, this study\npresents the ALT software, developed from original readability metrics adapted\nto the Portuguese language, available on the web, to reduce communication\ndifficulties. The development of the software was motivated by the theory of\ncommunicative action of Habermas, which uses a multidisciplinary style to\nmeasure the credibility of the discourse in the communication channels used to\nbuild and maintain a safe and healthy relationship with the public.", "published": "2022-10-02 15:24:52", "link": "http://arxiv.org/abs/2210.00553v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Risk-graded Safety for Handling Medical Queries in Conversational AI", "abstract": "Conversational AI systems can engage in unsafe behaviour when handling users'\nmedical queries that can have severe consequences and could even lead to\ndeaths. Systems therefore need to be capable of both recognising the\nseriousness of medical inputs and producing responses with appropriate levels\nof risk. We create a corpus of human written English language medical queries\nand the responses of different types of systems. We label these with both\ncrowdsourced and expert annotations. While individual crowdworkers may be\nunreliable at grading the seriousness of the prompts, their aggregated labels\ntend to agree with professional opinion to a greater extent on identifying the\nmedical queries and recognising the risk types posed by the responses. Results\nof classification experiments suggest that, while these tasks can be automated,\ncaution should be exercised, as errors can potentially be very serious.", "published": "2022-10-02 16:49:51", "link": "http://arxiv.org/abs/2210.00572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Community Learning: Understanding A Community Through NLP for Positive\n  Impact", "abstract": "A post-pandemic world resulted in economic upheaval, particularly for the\ncities' communities. While significant work in NLP4PI focuses on national and\ninternational events, there is a gap in bringing such state-of-the-art methods\ninto the community development field. In order to help with community\ndevelopment, we must learn about the communities we develop. To that end, we\npropose the task of community learning as a computational task of extracting\nnatural language data about the community, transforming and loading it into a\nsuitable knowledge graph structure for further downstream applications. We\nstudy two particular cases of homelessness and education in showing the\nvisualization capabilities of a knowledge graph, and also discuss other\nusefulness such a model can provide.", "published": "2022-10-02 17:56:52", "link": "http://arxiv.org/abs/2210.00590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReAct: A Review Comment Dataset for Actionability (and more)", "abstract": "Review comments play an important role in the evolution of documents. For a\nlarge document, the number of review comments may become large, making it\ndifficult for the authors to quickly grasp what the comments are about. It is\nimportant to identify the nature of the comments to identify which comments\nrequire some action on the part of document authors, along with identifying the\ntypes of these comments. In this paper, we introduce an annotated review\ncomment dataset ReAct. The review comments are sourced from OpenReview site. We\ncrowd-source annotations for these reviews for actionability and type of\ncomments. We analyze the properties of the dataset and validate the quality of\nannotations. We release the dataset (https://github.com/gtmdotme/ReAct) to the\nresearch community as a major contribution. We also benchmark our data with\nstandard baselines for classification tasks and analyze their performance.", "published": "2022-10-02 07:09:38", "link": "http://arxiv.org/abs/2210.00443v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The boundaries of meaning: a case study in neural machine translation", "abstract": "The success of deep learning in natural language processing raises intriguing\nquestions about the nature of linguistic meaning and ways in which it can be\nprocessed by natural and artificial systems. One such question has to do with\nsubword segmentation algorithms widely employed in language modeling, machine\ntranslation, and other tasks since 2016. These algorithms often cut words into\nsemantically opaque pieces, such as 'period', 'on', 't', and 'ist' in\n'period|on|t|ist'. The system then represents the resulting segments in a dense\nvector space, which is expected to model grammatical relations among them. This\nrepresentation may in turn be used to map 'period|on|t|ist' (English) to\n'par|od|ont|iste' (French). Thus, instead of being modeled at the lexical\nlevel, translation is reformulated more generally as the task of learning the\nbest bilingual mapping between the sequences of subword segments of two\nlanguages; and sometimes even between pure character sequences:\n'p|e|r|i|o|d|o|n|t|i|s|t' $\\rightarrow$ 'p|a|r|o|d|o|n|t|i|s|t|e'. Such subword\nsegmentations and alignments are at work in highly efficient end-to-end machine\ntranslation systems, despite their allegedly opaque nature. The computational\nvalue of such processes is unquestionable. But do they have any linguistic or\nphilosophical plausibility? I attempt to cast light on this question by\nreviewing the relevant details of the subword segmentation algorithms and by\nrelating them to important philosophical and linguistic debates, in the spirit\nof making artificial intelligence more transparent and explainable.", "published": "2022-10-02 20:26:20", "link": "http://arxiv.org/abs/2210.00613v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does Wikidata Support Analogical Reasoning?", "abstract": "Analogical reasoning methods have been built over various resources,\nincluding commonsense knowledge bases, lexical resources, language models, or\ntheir combination. While the wide coverage of knowledge about entities and\nevents make Wikidata a promising resource for analogical reasoning across\nsituations and domains, Wikidata has not been employed for this task yet. In\nthis paper, we investigate whether the knowledge in Wikidata supports\nanalogical reasoning. Specifically, we study whether relational knowledge is\nmodeled consistently in Wikidata, observing that relevant relational\ninformation is typically missing or modeled in an inconsistent way. Our further\nexperiments show that Wikidata can be used to create data for analogy\nclassification, but this requires much manual effort. To facilitate future work\nthat can support analogies, we discuss key desiderata, and devise a set of\nmetrics to guide an automatic method for extracting analogies from Wikidata.", "published": "2022-10-02 20:46:52", "link": "http://arxiv.org/abs/2210.00620v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Music-to-Text Synaesthesia: Generating Descriptive Text from Music\n  Recordings", "abstract": "In this paper, we consider a novel research problem: music-to-text\nsynaesthesia. Different from the classical music tagging problem that\nclassifies a music recording into pre-defined categories, music-to-text\nsynaesthesia aims to generate descriptive texts from music recordings with the\nsame sentiment for further understanding. As existing music-related datasets do\nnot contain the semantic descriptions on music recordings, we collect a new\ndataset that contains 1,955 aligned pairs of classical music recordings and\ntext descriptions. Based on this, we build a computational model to generate\nsentences that can describe the content of the music recording. To tackle the\nhighly non-discriminative classical music, we design a group\ntopology-preservation loss, which considers more samples as a group reference\nand preserves the relative topology among different samples. Extensive\nexperimental results qualitatively and quantitatively demonstrate the\neffectiveness of our proposed model over five heuristics or pre-trained\ncompetitive methods and their variants on our collected dataset.", "published": "2022-10-02 06:06:55", "link": "http://arxiv.org/abs/2210.00434v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cognitive modelling with multilayer networks: Insights, advancements and\n  future challenges", "abstract": "The mental lexicon is a complex cognitive system representing information\nabout the words/concepts that one knows. Decades of psychological experiments\nhave shown that conceptual associations across multiple, interactive cognitive\nlevels can greatly influence word acquisition, storage, and processing. How can\nsemantic, phonological, syntactic, and other types of conceptual associations\nbe mapped within a coherent mathematical framework to study how the mental\nlexicon works? We here review cognitive multilayer networks as a promising\nquantitative and interpretative framework for investigating the mental lexicon.\nCognitive multilayer networks can map multiple types of information at once,\nthus capturing how different layers of associations might co-exist within the\nmental lexicon and influence cognitive processing. This review starts with a\ngentle introduction to the structure and formalism of multilayer networks. We\nthen discuss quantitative mechanisms of psychological phenomena that could not\nbe observed in single-layer networks and were only unveiled by combining\nmultiple layers of the lexicon: (i) multiplex viability highlights language\nkernels and facilitative effects of knowledge processing in healthy and\nclinical populations; (ii) multilayer community detection enables contextual\nmeaning reconstruction depending on psycholinguistic features; (iii) layer\nanalysis can mediate latent interactions of mediation, suppression and\nfacilitation for lexical access. By outlining novel quantitative perspectives\nwhere multilayer networks can shed light on cognitive knowledge\nrepresentations, also in next-generation brain/mind models, we discuss key\nlimitations and promising directions for cutting-edge future research.", "published": "2022-10-02 12:22:53", "link": "http://arxiv.org/abs/2210.00500v1", "categories": ["cs.CL", "cs.AI", "cs.SI", "physics.data-an", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Voice Spoofing Countermeasures: Taxonomy, State-of-the-art, experimental\n  analysis of generalizability, open challenges, and the way forward", "abstract": "Malicious actors may seek to use different voice-spoofing attacks to fool ASV\nsystems and even use them for spreading misinformation. Various countermeasures\nhave been proposed to detect these spoofing attacks. Due to the extensive work\ndone on spoofing detection in automated speaker verification (ASV) systems in\nthe last 6-7 years, there is a need to classify the research and perform\nqualitative and quantitative comparisons on state-of-the-art countermeasures.\nAdditionally, no existing survey paper has reviewed integrated solutions to\nvoice spoofing evaluation and speaker verification, adversarial/antiforensics\nattacks on spoofing countermeasures, and ASV itself, or unified solutions to\ndetect multiple attacks using a single model. Further, no work has been done to\nprovide an apples-to-apples comparison of published countermeasures in order to\nassess their generalizability by evaluating them across corpora. In this work,\nwe conduct a review of the literature on spoofing detection using hand-crafted\nfeatures, deep learning, end-to-end, and universal spoofing countermeasure\nsolutions to detect speech synthesis (SS), voice conversion (VC), and replay\nattacks. Additionally, we also review integrated solutions to voice spoofing\nevaluation and speaker verification, adversarial and anti-forensics attacks on\nvoice countermeasures, and ASV. The limitations and challenges of the existing\nspoofing countermeasures are also presented. We report the performance of these\ncountermeasures on several datasets and evaluate them across corpora. For the\nexperiments, we employ the ASVspoof2019 and VSDC datasets along with GMM, SVM,\nCNN, and CNN-GRU classifiers. (For reproduceability of the results, the code of\nthe test bed can be found in our GitHub Repository.", "published": "2022-10-02 03:53:37", "link": "http://arxiv.org/abs/2210.00417v2", "categories": ["eess.AS", "cs.CY", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Contrastive Audio-Visual Masked Autoencoder", "abstract": "In this paper, we first extend the recent Masked Auto-Encoder (MAE) model\nfrom a single modality to audio-visual multi-modalities. Subsequently, we\npropose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining\ncontrastive learning and masked data modeling, two major self-supervised\nlearning frameworks, to learn a joint and coordinated audio-visual\nrepresentation. Our experiments show that the contrastive audio-visual\ncorrespondence learning objective not only enables the model to perform\naudio-visual retrieval tasks, but also helps the model learn a better joint\nrepresentation. As a result, our fully self-supervised pretrained CAV-MAE\nachieves a new SOTA accuracy of 65.9% on VGGSound, and is comparable with the\nprevious best supervised pretrained model on AudioSet in the audio-visual event\nclassification task. Code and pretrained models are at\nhttps://github.com/yuangongnd/cav-mae.", "published": "2022-10-02 07:29:57", "link": "http://arxiv.org/abs/2210.07839v4", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
