{"title": "Counterfactual reasoning: Testing language models' understanding of\n  hypothetical scenarios", "abstract": "Current pre-trained language models have enabled remarkable improvements in\ndownstream tasks, but it remains difficult to distinguish effects of\nstatistical correlation from more systematic logical reasoning grounded on the\nunderstanding of real world. We tease these factors apart by leveraging\ncounterfactual conditionals, which force language models to predict unusual\nconsequences based on hypothetical propositions. We introduce a set of tests\nfrom psycholinguistic experiments, as well as larger-scale controlled datasets,\nto probe counterfactual predictions from five pre-trained language models. We\nfind that models are consistently able to override real-world knowledge in\ncounterfactual scenarios, and that this effect is more robust in case of\nstronger baseline world knowledge -- however, we also find that for most models\nthis effect appears largely to be driven by simple lexical cues. When we\nmitigate effects of both world knowledge and lexical cues to test knowledge of\nlinguistic nuances of counterfactuals, we find that only GPT-3 shows\nsensitivity to these nuances, though this sensitivity is also non-trivially\nimpacted by lexical associative factors.", "published": "2023-05-26 01:42:57", "link": "http://arxiv.org/abs/2305.16572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nichelle and Nancy: The Influence of Demographic Attributes and\n  Tokenization Length on First Name Biases", "abstract": "Through the use of first name substitution experiments, prior research has\ndemonstrated the tendency of social commonsense reasoning models to\nsystematically exhibit social biases along the dimensions of race, ethnicity,\nand gender (An et al., 2023). Demographic attributes of first names, however,\nare strongly correlated with corpus frequency and tokenization length, which\nmay influence model behavior independent of or in addition to demographic\nfactors. In this paper, we conduct a new series of first name substitution\nexperiments that measures the influence of these factors while controlling for\nthe others. We find that demographic attributes of a name (race, ethnicity, and\ngender) and name tokenization length are both factors that systematically\naffect the behavior of social commonsense reasoning models.", "published": "2023-05-26 01:57:42", "link": "http://arxiv.org/abs/2305.16577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Investigation of Noise in Morphological Inflection", "abstract": "With a growing focus on morphological inflection systems for languages where\nhigh-quality data is scarce, training data noise is a serious but so far\nlargely ignored concern. We aim at closing this gap by investigating the types\nof noise encountered within a pipeline for truly unsupervised morphological\nparadigm completion and its impact on morphological inflection systems: First,\nwe propose an error taxonomy and annotation pipeline for inflection training\ndata. Then, we compare the effect of different types of noise on multiple\nstate-of-the-art inflection models. Finally, we propose a novel character-level\nmasked language modeling (CMLM) pretraining objective and explore its impact on\nthe models' resistance to noise. Our experiments show that various\narchitectures are impacted differently by separate types of noise, but\nencoder-decoders tend to be more robust to noise than models trained with a\ncopy bias. CMLM pretraining helps transformers, but has lower impact on LSTMs.", "published": "2023-05-26 02:14:34", "link": "http://arxiv.org/abs/2305.16581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in\n  Language Models", "abstract": "With the widespread use of language models (LMs) in NLP tasks, researchers\nhave discovered the potential of Chain-of-thought (CoT) to assist LMs in\naccomplishing complex reasoning tasks by generating intermediate steps.\nHowever, human thought processes are often non-linear, rather than simply\nsequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT)\nreasoning, which models human thought processes not only as a chain but also as\na graph. By representing thought units as nodes and connections between them as\nedges, our approach captures the non-sequential nature of human thinking and\nallows for a more realistic modeling of thought processes. GoT adopts a\ntwo-stage framework with an additional GoT encoder for thought graph\nrepresentation and fuses the graph representation with the original input\nrepresentation through a gated fusion mechanism. We evaluate GoT's performance\non a text-only reasoning task (AQUA-RAT) and a multimodal reasoning task\n(ScienceQA). Our model achieves significant improvement over the strong CoT\nbaseline on the AQUA-RAT test set and boosts accuracy from 85.19% to 87.59%\nusing the T5-base model over the state-of-the-art Multimodal-CoT on the\nScienceQA test set.", "published": "2023-05-26 02:15:09", "link": "http://arxiv.org/abs/2305.16582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR\n  Back-Translation", "abstract": "Paraphrase generation is a long-standing task in natural language processing\n(NLP). Supervised paraphrase generation models, which rely on human-annotated\nparaphrase pairs, are cost-inefficient and hard to scale up. On the other hand,\nautomatically annotated paraphrase pairs (e.g., by machine back-translation),\nusually suffer from the lack of syntactic diversity -- the generated paraphrase\nsentences are very similar to the source sentences in terms of syntax. In this\nwork, we present ParaAMR, a large-scale syntactically diverse paraphrase\ndataset created by abstract meaning representation back-translation. Our\nquantitative analysis, qualitative examples, and human evaluation demonstrate\nthat the paraphrases of ParaAMR are syntactically more diverse compared to\nexisting large-scale paraphrase datasets while preserving good semantic\nsimilarity. In addition, we show that ParaAMR can be used to improve on three\nNLP tasks: learning sentence embeddings, syntactically controlled paraphrase\ngeneration, and data augmentation for few-shot learning. Our results thus\nshowcase the potential of ParaAMR for improving various NLP applications.", "published": "2023-05-26 02:27:33", "link": "http://arxiv.org/abs/2305.16585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm\n  Discovery", "abstract": "Norms, which are culturally accepted guidelines for behaviours, can be\nintegrated into conversational models to generate utterances that are\nappropriate for the socio-cultural context. Existing methods for norm\nrecognition tend to focus only on surface-level features of dialogues and do\nnot take into account the interactions within a conversation. To address this\nissue, we propose NormMark, a probabilistic generative Markov model to carry\nthe latent features throughout a dialogue. These features are captured by\ndiscrete and continuous latent variables conditioned on the conversation\nhistory, and improve the model's ability in norm recognition. The model is\ntrainable on weakly annotated data using the variational technique. On a\ndataset with limited norm annotations, we show that our approach achieves\nhigher F1 score, outperforming current state-of-the-art methods, including\nGPT3.", "published": "2023-05-26 03:03:37", "link": "http://arxiv.org/abs/2305.16598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging the Domain Gaps in Context Representations for k-Nearest\n  Neighbor Neural Machine Translation", "abstract": "$k$-Nearest neighbor machine translation ($k$NN-MT) has attracted increasing\nattention due to its ability to non-parametrically adapt to new translation\ndomains. By using an upstream NMT model to traverse the downstream training\ncorpus, it is equipped with a datastore containing vectorized key-value pairs,\nwhich are retrieved during inference to benefit translation. However, there\noften exists a significant gap between upstream and downstream domains, which\nhurts the retrieval accuracy and the final translation quality. To deal with\nthis issue, we propose a novel approach to boost the datastore retrieval of\n$k$NN-MT by reconstructing the original datastore. Concretely, we design a\nreviser to revise the key representations, making them better fit for the\ndownstream domain. The reviser is trained using the collected\nsemantically-related key-queries pairs, and optimized by two proposed losses:\none is the key-queries semantic distance ensuring each revised key\nrepresentation is semantically related to its corresponding queries, and the\nother is an L2-norm loss encouraging revised key representations to effectively\nretain the knowledge learned by the upstream NMT model. Extensive experiments\non domain adaptation tasks demonstrate that our method can effectively boost\nthe datastore retrieval and translation quality of $k$NN-MT.\\footnote{Our code\nis available at \\url{https://github.com/DeepLearnXMU/RevisedKey-knn-mt}.}", "published": "2023-05-26 03:04:42", "link": "http://arxiv.org/abs/2305.16599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Multi-task Learning for End-to-end Metaphor Detection", "abstract": "Metaphor detection (MD) suffers from limited training data. In this paper, we\nstarted with a linguistic rule called Metaphor Identification Procedure and\nthen proposed a novel multi-task learning framework to transfer knowledge in\nbasic sense discrimination (BSD) to MD. BSD is constructed from word sense\ndisambiguation (WSD), which has copious amounts of data. We leverage\nadversarial training to align the data distributions of MD and BSD in the same\nfeature space, so task-invariant representations can be learned. To capture\nfine-grained alignment patterns, we utilize the multi-mode structures of MD and\nBSD. Our method is totally end-to-end and can mitigate the data scarcity\nproblem in MD. Competitive results are reported on four public datasets. Our\ncode and datasets are available.", "published": "2023-05-26 05:28:00", "link": "http://arxiv.org/abs/2305.16638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event\n  Chains of Children's Fairy Tales", "abstract": "Social biases and stereotypes are embedded in our culture in part through\ntheir presence in our stories, as evidenced by the rich history of humanities\nand social science literature analyzing such biases in children stories.\nBecause these analyses are often conducted manually and at a small scale, such\ninvestigations can benefit from the use of more recent natural language\nprocessing methods that examine social bias in models and data corpora. Our\nwork joins this interdisciplinary effort and makes a unique contribution by\ntaking into account the event narrative structures when analyzing the social\nbias of stories. We propose a computational pipeline that automatically\nextracts a story's temporal narrative verb-based event chain for each of its\ncharacters as well as character attributes such as gender. We also present a\nverb-based event annotation scheme that can facilitate bias analysis by\nincluding categories such as those that align with traditional stereotypes.\nThrough a case study analyzing gender bias in fairy tales, we demonstrate that\nour framework can reveal bias in not only the unigram verb-based events in\nwhich female and male characters participate but also in the temporal narrative\norder of such event participation.", "published": "2023-05-26 05:29:37", "link": "http://arxiv.org/abs/2305.16641v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Dramatic Conversation Disentanglement", "abstract": "We present a new dataset for studying conversation disentanglement in movies\nand TV series. While previous work has focused on conversation disentanglement\nin IRC chatroom dialogues, movies and TV shows provide a space for studying\ncomplex pragmatic patterns of floor and topic change in face-to-face\nmulti-party interactions. In this work, we draw on theoretical research in\nsociolinguistics, sociology, and film studies to operationalize a\nconversational thread (including the notion of a floor change) in dramatic\ntexts, and use that definition to annotate a dataset of 10,033 dialogue turns\n(comprising 2,209 threads) from 831 movies. We compare the performance of\nseveral disentanglement models on this dramatic dataset, and apply the\nbest-performing model to disentangle 808 movies. We see that, contrary to\nexpectation, average thread lengths do not decrease significantly over the past\n40 years, and characters portrayed by actors who are women, while\nunderrepresented, initiate more new conversational threads relative to their\nspeaking time.", "published": "2023-05-26 05:39:49", "link": "http://arxiv.org/abs/2305.16648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TADA: Task-Agnostic Dialect Adapters for English", "abstract": "Large Language Models, the dominant starting point for Natural Language\nProcessing (NLP) applications, fail at a higher rate for speakers of English\ndialects other than Standard American English (SAE). Prior work addresses this\nusing task-specific data or synthetic data augmentation, both of which require\nintervention for each dialect and task pair. This poses a scalability issue\nthat prevents the broad adoption of robust dialectal English NLP. We introduce\na simple yet effective method for task-agnostic dialect adaptation by aligning\nnon-SAE dialects using adapters and composing them with task-specific adapters\nfrom SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on\n4 dialectal variants of the GLUE benchmark without task-specific supervision.", "published": "2023-05-26 05:45:03", "link": "http://arxiv.org/abs/2305.16651v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GDA: Generative Data Augmentation Techniques for Relation Extraction\n  Tasks", "abstract": "Relation extraction (RE) tasks show promising performance in extracting\nrelations from two entities mentioned in sentences, given sufficient\nannotations available during training. Such annotations would be\nlabor-intensive to obtain in practice. Existing work adopts data augmentation\ntechniques to generate pseudo-annotated sentences beyond limited annotations.\nThese techniques neither preserve the semantic consistency of the original\nsentences when rule-based augmentations are adopted, nor preserve the syntax\nstructure of sentences when expressing relations using seq2seq models,\nresulting in less diverse augmentations. In this work, we propose a dedicated\naugmentation technique for relational texts, named GDA, which uses two\ncomplementary modules to preserve both semantic consistency and syntax\nstructures. We adopt a generative formulation and design a multi-tasking\nsolution to achieve synergies. Furthermore, GDA adopts entity hints as the\nprior knowledge of the generative model to augment diverse sentences.\nExperimental results in three datasets under a low-resource setting showed that\nGDA could bring {\\em 2.0\\%} F1 improvements compared with no augmentation\ntechnique. Source code and data are available.", "published": "2023-05-26 06:21:01", "link": "http://arxiv.org/abs/2305.16663v2", "categories": ["cs.CL", "68T01", "I.2.7"], "primary_category": "cs.CL"}
{"title": "DKAF: KB Arbitration for Learning Task-Oriented Dialog Systems with\n  Dialog-KB Inconsistencies", "abstract": "Task-oriented dialog (TOD) agents often ground their responses on external\nknowledge bases (KBs). These KBs can be dynamic and may be updated frequently.\nExisting approaches for learning TOD agents assume the KB snapshot contemporary\nto each individual dialog is available during training. However, in real-world\nscenarios, only the latest KB snapshot is available during training and as a\nresult, the train dialogs may contain facts conflicting with the latest KB.\nThese dialog-KB inconsistencies in the training data may potentially confuse\nthe TOD agent learning algorithm.\n  In this work, we define the novel problem of learning a TOD agent with\ndialog-KB inconsistencies in the training data. We propose a Dialog-KB\nArbitration Framework (DKAF) which reduces the dialog-KB inconsistencies by\npredicting the contemporary KB snapshot for each train dialog. These predicted\nKB snapshots are then used for training downstream TOD agents. As there are no\nexisting datasets with dialog-KB inconsistencies, we systematically introduce\ninconsistencies in two publicly available dialog datasets. We show that TOD\nagents trained with DKAF perform better than existing baselines on both these\ndatasets", "published": "2023-05-26 07:36:23", "link": "http://arxiv.org/abs/2305.16697v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "People and Places of Historical Europe: Bootstrapping Annotation\n  Pipeline and a New Corpus of Named Entities in Late Medieval Texts", "abstract": "Although pre-trained named entity recognition (NER) models are highly\naccurate on modern corpora, they underperform on historical texts due to\ndifferences in language OCR errors. In this work, we develop a new NER corpus\nof 3.6M sentences from late medieval charters written mainly in Czech, Latin,\nand German.\n  We show that we can start with a list of known historical figures and\nlocations and an unannotated corpus of historical texts, and use information\nretrieval techniques to automatically bootstrap a NER-annotated corpus. Using\nour corpus, we train a NER model that achieves entity-level Precision of\n72.81-93.98% with 58.14-81.77% Recall on a manually-annotated test dataset.\nFurthermore, we show that using a weighted loss function helps to combat class\nimbalance in token classification tasks. To make it easy for others to\nreproduce and build upon our work, we publicly release our corpus, models, and\nexperimental code.", "published": "2023-05-26 08:05:01", "link": "http://arxiv.org/abs/2305.16718v2", "categories": ["cs.CL", "68T50", "I.2.7; I.7.0"], "primary_category": "cs.CL"}
{"title": "Automatic Emotion Experiencer Recognition", "abstract": "The most prominent subtask in emotion analysis is emotion classification; to\nassign a category to a textual unit, for instance a social media post. Many\nresearch questions from the social sciences do, however, not only require the\ndetection of the emotion of an author of a post but to understand who is\nascribed an emotion in text. This task is tackled by emotion role labeling\nwhich aims at extracting who is described in text to experience an emotion,\nwhy, and towards whom. This could, however, be considered overly sophisticated\nif the main question to answer is who feels which emotion. A targeted approach\nfor such setup is to classify emotion experiencer mentions (aka \"emoters\")\nregarding the emotion they presumably perceive. This task is similar to named\nentity recognition of person names with the difference that not every mentioned\nentity name is an emoter. While, very recently, data with emoter annotations\nhas been made available, no experiments have yet been performed to detect such\nmentions. With this paper, we provide baseline experiments to understand how\nchallenging the task is. We further evaluate the impact on experiencer-specific\nemotion categorization and appraisal detection in a pipeline, when gold\nmentions are not available. We show that experiencer detection in text is a\nchallenging task, with a precision of .82 and a recall of .56 (F1 =.66). These\nresults motivate future work of jointly modeling emoter spans and\nemotion/appraisal predictions.", "published": "2023-05-26 08:33:28", "link": "http://arxiv.org/abs/2305.16731v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AlignScore: Evaluating Factual Consistency with a Unified Alignment\n  Function", "abstract": "Many text generation applications require the generated text to be factually\nconsistent with input information. Automatic evaluation of factual consistency\nis challenging. Previous work has developed various metrics that often depend\non specific functions, such as natural language inference (NLI) or question\nanswering (QA), trained on limited data. Those metrics thus can hardly assess\ndiverse factual inconsistencies (e.g., contradictions, hallucinations) that\noccur in varying inputs/outputs (e.g., sentences, documents) from different\ntasks. In this paper, we propose AlignScore, a new holistic metric that applies\nto a variety of factual inconsistency scenarios as above. AlignScore is based\non a general function of information alignment between two arbitrary text\npieces. Crucially, we develop a unified training framework of the alignment\nfunction by integrating a large diversity of data sources, resulting in 4.7M\ntraining examples from 7 well-established tasks (NLI, QA, paraphrasing, fact\nverification, information retrieval, semantic similarity, and summarization).\nWe conduct extensive experiments on large-scale benchmarks including 22\nevaluation datasets, where 19 of the datasets were never seen in the alignment\ntraining. AlignScore achieves substantial improvement over a wide range of\nprevious metrics. Moreover, AlignScore (355M parameters) matches or even\noutperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude\nlarger.", "published": "2023-05-26 08:41:59", "link": "http://arxiv.org/abs/2305.16739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conjunct Resolution in the Face of Verbal Omissions", "abstract": "Verbal omissions are complex syntactic phenomena in VP coordination\nstructures. They occur when verbs and (some of) their arguments are omitted\nfrom subsequent clauses after being explicitly stated in an initial clause.\nRecovering these omitted elements is necessary for accurate interpretation of\nthe sentence, and while humans easily and intuitively fill in the missing\ninformation, state-of-the-art models continue to struggle with this task.\nPrevious work is limited to small-scale datasets, synthetic data creation\nmethods, and to resolution methods in the dependency-graph level. In this work\nwe propose a conjunct resolution task that operates directly on the text and\nmakes use of a split-and-rephrase paradigm in order to recover the missing\nelements in the coordination structure. To this end, we first formulate a\npragmatic framework of verbal omissions which describes the different types of\nomissions, and develop an automatic scalable collection method. Based on this\nmethod, we curate a large dataset, containing over 10K examples of\nnaturally-occurring verbal omissions with crowd-sourced annotations of the\nresolved conjuncts. We train various neural baselines for this task, and show\nthat while our best method obtains decent performance, it leaves ample space\nfor improvement. We propose our dataset, metrics and models as a starting point\nfor future research on this topic.", "published": "2023-05-26 08:44:02", "link": "http://arxiv.org/abs/2305.16740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Backpack Language Models", "abstract": "We present Backpacks: a new neural architecture that marries strong modeling\nperformance with an interface for interpretability and control. Backpacks learn\nmultiple non-contextual sense vectors for each word in a vocabulary, and\nrepresent a word in a sequence as a context-dependent, non-negative linear\ncombination of sense vectors in this sequence. We find that, after training,\nsense vectors specialize, each encoding a different aspect of a word. We can\ninterpret a sense vector by inspecting its (non-contextual, linear) projection\nonto the output space, and intervene on these interpretable hooks to change the\nmodel's behavior in predictable ways. We train a 170M-parameter Backpack\nlanguage model on OpenWebText, matching the loss of a GPT-2 small\n(124Mparameter) Transformer. On lexical similarity evaluations, we find that\nBackpack sense vectors outperform even a 6B-parameter Transformer LM's word\nembeddings. Finally, we present simple algorithms that intervene on sense\nvectors to perform controllable text generation and debiasing. For example, we\ncan edit the sense vocabulary to tend more towards a topic, or localize a\nsource of gender bias to a sense vector and globally suppress that sense.", "published": "2023-05-26 09:26:23", "link": "http://arxiv.org/abs/2305.16765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Calibration of Transformer-based Models for Identifying Stress and\n  Depression in Social Media", "abstract": "In today's fast-paced world, the rates of stress and depression present a\nsurge. Social media provide assistance for the early detection of mental health\nconditions. Existing methods mainly introduce feature extraction approaches and\ntrain shallow machine learning classifiers. Other researches use deep neural\nnetworks or transformers. Despite the fact that transformer-based models\nachieve noticeable improvements, they cannot often capture rich factual\nknowledge. Although there have been proposed a number of studies aiming to\nenhance the pretrained transformer-based models with extra information or\nadditional modalities, no prior work has exploited these modifications for\ndetecting stress and depression through social media. In addition, although the\nreliability of a machine learning model's confidence in its predictions is\ncritical for high-risk applications, there is no prior work taken into\nconsideration the model calibration. To resolve the above issues, we present\nthe first study in the task of depression and stress detection in social media,\nwhich injects extra linguistic information in transformer-based models, namely\nBERT and MentalBERT. Specifically, the proposed approach employs a Multimodal\nAdaptation Gate for creating the combined embeddings, which are given as input\nto a BERT (or MentalBERT) model. For taking into account the model calibration,\nwe apply label smoothing. We test our proposed approaches in three publicly\navailable datasets and demonstrate that the integration of linguistic features\ninto transformer-based models presents a surge in the performance. Also, the\nusage of label smoothing contributes to both the improvement of the model's\nperformance and the calibration of the model. We finally perform a linguistic\nanalysis of the posts and show differences in language between stressful and\nnon-stressful texts, as well as depressive and non-depressive posts.", "published": "2023-05-26 10:19:04", "link": "http://arxiv.org/abs/2305.16797v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To Revise or Not to Revise: Learning to Detect Improvable Claims for\n  Argumentative Writing Support", "abstract": "Optimizing the phrasing of argumentative text is crucial in higher education\nand professional development. However, assessing whether and how the different\nclaims in a text should be revised is a hard task, especially for novice\nwriters. In this work, we explore the main challenges to identifying\nargumentative claims in need of specific revisions. By learning from\ncollaborative editing behaviors in online debates, we seek to capture implicit\nrevision patterns in order to develop approaches aimed at guiding writers in\nhow to further improve their arguments. We systematically compare the ability\nof common word embedding models to capture the differences between different\nversions of the same text, and we analyze their impact on various types of\nwriting issues. To deal with the noisy nature of revision-based corpora, we\npropose a new sampling strategy based on revision distance. Opposed to\napproaches from prior work, such sampling can be done without employing\nadditional annotations and judgments. Moreover, we provide evidence that using\ncontextual information and domain knowledge can further improve prediction\nresults. How useful a certain type of context is, depends on the issue the\nclaim is suffering from, though.", "published": "2023-05-26 10:19:54", "link": "http://arxiv.org/abs/2305.16799v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Songs Across Borders: Singable and Controllable Neural Lyric Translation", "abstract": "The development of general-domain neural machine translation (NMT) methods\nhas advanced significantly in recent years, but the lack of naturalness and\nmusical constraints in the outputs makes them unable to produce singable lyric\ntranslations. This paper bridges the singability quality gap by formalizing\nlyric translation into a constrained translation problem, converting\ntheoretical guidance and practical techniques from translatology literature to\nprompt-driven NMT approaches, exploring better adaptation methods, and\ninstantiating them to an English-Chinese lyric translation system. Our model\nachieves 99.85%, 99.00%, and 95.52% on length accuracy, rhyme accuracy, and\nword boundary recall. In our subjective evaluation, our model shows a 75%\nrelative enhancement on overall quality, compared against naive fine-tuning\n(Code available at https://github.com/Sonata165/ControllableLyricTranslation).", "published": "2023-05-26 10:50:17", "link": "http://arxiv.org/abs/2305.16816v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "With a Little Push, NLI Models can Robustly and Efficiently Predict\n  Faithfulness", "abstract": "Conditional language models still generate unfaithful output that is not\nsupported by their input. These unfaithful generations jeopardize trust in\nreal-world applications such as summarization or human-machine interaction,\nmotivating a need for automatic faithfulness metrics. To implement such\nmetrics, NLI models seem attractive, since they solve a strongly related task\nthat comes with a wealth of prior research and data. But recent research\nsuggests that NLI models require costly additional machinery to perform\nreliably across datasets, e.g., by running inference on a cartesian product of\ninput and generated sentences, or supporting them with a\nquestion-generation/answering step.\n  In this work we show that pure NLI models _can_ outperform more complex\nmetrics when combining task-adaptive data augmentation with robust inference\nprocedures. We propose: (1) Augmenting NLI training data to adapt NL inferences\nto the specificities of faithfulness prediction in dialogue; (2) Making use of\nboth entailment and contradiction probabilities in NLI, and (3) Using\nMonte-Carlo dropout during inference. Applied to the TRUE benchmark, which\ncombines faithfulness datasets across diverse domains and tasks, our approach\nstrongly improves a vanilla NLI model and significantly outperforms previous\nwork, while showing favourable computational cost.", "published": "2023-05-26 11:00:04", "link": "http://arxiv.org/abs/2305.16819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KNSE: A Knowledge-aware Natural Language Inference Framework for\n  Dialogue Symptom Status Recognition", "abstract": "Symptom diagnosis in medical conversations aims to correctly extract both\nsymptom entities and their status from the doctor-patient dialogue. In this\npaper, we propose a novel framework called KNSE for symptom status recognition\n(SSR), where the SSR is formulated as a natural language inference (NLI) task.\nFor each mentioned symptom in a dialogue window, we first generate knowledge\nabout the symptom and hypothesis about status of the symptom, to form a\n(premise, knowledge, hypothesis) triplet. The BERT model is then used to encode\nthe triplet, which is further processed by modules including utterance\naggregation, self-attention, cross-attention, and GRU to predict the symptom\nstatus. Benefiting from the NLI formalization, the proposed framework can\nencode more informative prior knowledge to better localize and track symptom\nstatus, which can effectively improve the performance of symptom status\nrecognition. Preliminary experiments on Chinese medical dialogue datasets show\nthat KNSE outperforms previous competitive baselines and has advantages in\ncross-disease and cross-symptom scenarios.", "published": "2023-05-26 11:23:26", "link": "http://arxiv.org/abs/2305.16833v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging", "abstract": "Massively multilingual language models have displayed strong performance in\nzero-shot (ZS-XLT) and few-shot (FS-XLT) cross-lingual transfer setups, where\nmodels fine-tuned on task data in a source language are transferred without any\nor with only a few annotated instances to the target language(s). However,\ncurrent work typically overestimates model performance as fine-tuned models are\nfrequently evaluated at model checkpoints that generalize best to validation\ninstances in the target languages. This effectively violates the main\nassumptions of \"true\" ZS-XLT and FS-XLT. Such XLT setups require robust methods\nthat do not depend on labeled target language data for validation and model\nselection. In this work, aiming to improve the robustness of \"true\" ZS-XLT and\nFS-XLT, we propose a simple and effective method that averages different\ncheckpoints (i.e., model snapshots) during task fine-tuning. We conduct\nexhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks\n(NLI, extractive QA) and lower-level token classification tasks (NER, POS). The\nresults indicate that averaging model checkpoints yields systematic and\nconsistent performance gains across diverse target languages in all tasks.\nImportantly, it simultaneously substantially desensitizes XLT to varying\nhyperparameter choices in the absence of target language validation. We also\nshow that checkpoint averaging benefits performance when further combined with\nrun averaging (i.e., averaging the parameters of models fine-tuned over\nindependent runs).", "published": "2023-05-26 11:24:32", "link": "http://arxiv.org/abs/2305.16834v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scientific Fact-Checking: A Survey of Resources and Approaches", "abstract": "The task of fact-checking deals with assessing the veracity of factual claims\nbased on credible evidence and background knowledge. In particular, scientific\nfact-checking is the variation of the task concerned with verifying claims\nrooted in scientific knowledge. This task has received significant attention\ndue to the growing importance of scientific and health discussions on online\nplatforms. Automated scientific fact-checking methods based on NLP can help\ncombat the spread of misinformation, assist researchers in knowledge discovery,\nand help individuals understand new scientific breakthroughs. In this paper, we\npresent a comprehensive survey of existing research in this emerging field and\nits related tasks. We provide a task description, discuss the construction\nprocess of existing datasets, and analyze proposed models and approaches. Based\non our findings, we identify intriguing challenges and outline potential future\ndirections to advance the field.", "published": "2023-05-26 12:12:15", "link": "http://arxiv.org/abs/2305.16859v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Playing repeated games with Large Language Models", "abstract": "Large Language Models (LLMs) are transforming society and permeating into\ndiverse applications. As a result, LLMs will frequently interact with us and\nother agents. It is, therefore, of great societal value to understand how LLMs\nbehave in interactive social settings. Here, we propose to use behavioral game\ntheory to study LLM's cooperation and coordination behavior. To do so, we let\ndifferent LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with\neach other and with other, human-like strategies. Our results show that LLMs\ngenerally perform well in such tasks and also uncover persistent behavioral\nsignatures. In a large set of two players-two strategies games, we find that\nLLMs are particularly good at games where valuing their own self-interest pays\noff, like the iterated Prisoner's Dilemma family. However, they behave\nsub-optimally in games that require coordination. We, therefore, further focus\non two games from these distinct families. In the canonical iterated Prisoner's\nDilemma, we find that GPT-4 acts particularly unforgivingly, always defecting\nafter another agent has defected only once. In the Battle of the Sexes, we find\nthat GPT-4 cannot match the behavior of the simple convention to alternate\nbetween options. We verify that these behavioral signatures are stable across\nrobustness checks. Finally, we show how GPT-4's behavior can be modified by\nproviding further information about the other player as well as by asking it to\npredict the other player's actions before making a choice. These results enrich\nour understanding of LLM's social behavior and pave the way for a behavioral\ngame theory for machines.", "published": "2023-05-26 12:17:59", "link": "http://arxiv.org/abs/2305.16867v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification", "abstract": "Due to the complex label hierarchy and intensive labeling cost in practice,\nthe hierarchical text classification (HTC) suffers a poor performance\nespecially when low-resource or few-shot settings are considered. Recently,\nthere is a growing trend of applying prompts on pre-trained language models\n(PLMs), which has exhibited effectiveness in the few-shot flat text\nclassification tasks. However, limited work has studied the paradigm of\nprompt-based learning in the HTC problem when the training data is extremely\nscarce. In this work, we define a path-based few-shot setting and establish a\nstrict path-based evaluation metric to further explore few-shot HTC tasks. To\naddress the issue, we propose the hierarchical verbalizer (\"HierVerb\"), a\nmulti-verbalizer framework treating HTC as a single- or multi-label\nclassification problem at multiple layers and learning vectors as verbalizers\nconstrained by hierarchical structure and hierarchical contrastive learning. In\nthis manner, HierVerb fuses label hierarchy knowledge into verbalizers and\nremarkably outperforms those who inject hierarchy through graph encoders,\nmaximizing the benefits of PLMs. Extensive experiments on three popular HTC\ndatasets under the few-shot settings demonstrate that prompt with HierVerb\nsignificantly boosts the HTC performance, meanwhile indicating an elegant way\nto bridge the gap between the large pre-trained model and downstream\nhierarchical classification tasks. Our code and few-shot dataset are publicly\navailable at https://github.com/1KE-JI/HierVerb.", "published": "2023-05-26 12:41:49", "link": "http://arxiv.org/abs/2305.16885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustness of Multi-Source MT to Transcription Errors", "abstract": "Automatic speech translation is sensitive to speech recognition errors, but\nin a multilingual scenario, the same content may be available in various\nlanguages via simultaneous interpreting, dubbing or subtitling. In this paper,\nwe hypothesize that leveraging multiple sources will improve translation\nquality if the sources complement one another in terms of correct information\nthey contain. To this end, we first show that on a 10-hour ESIC corpus, the ASR\nerrors in the original English speech and its simultaneous interpreting into\nGerman and Czech are mutually independent. We then use two sources, English and\nGerman, in a multi-source setting for translation into Czech to establish its\nrobustness to ASR errors. Furthermore, we observe this robustness when\ntranslating both noisy sources together in a simultaneous translation setting.\nOur results show that multi-source neural machine translation has the potential\nto be useful in a real-time simultaneous translation setting, thereby\nmotivating further investigation in this area.", "published": "2023-05-26 12:54:16", "link": "http://arxiv.org/abs/2305.16894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Partially Primed in Pronoun Interpretation", "abstract": "While a large body of literature suggests that large language models (LLMs)\nacquire rich linguistic representations, little is known about whether they\nadapt to linguistic biases in a human-like way. The present study probes this\nquestion by asking whether LLMs display human-like referential biases using\nstimuli and procedures from real psycholinguistic experiments. Recent\npsycholinguistic studies suggest that humans adapt their referential biases\nwith recent exposure to referential patterns; closely replicating three\nrelevant psycholinguistic experiments from Johnson & Arnold (2022) in an\nin-context learning (ICL) framework, we found that InstructGPT adapts its\npronominal interpretations in response to the frequency of referential patterns\nin the local discourse, though in a limited fashion: adaptation was only\nobserved relative to syntactic but not semantic biases. By contrast, FLAN-UL2\nfails to generate meaningful patterns. Our results provide further evidence\nthat contemporary LLMs discourse representations are sensitive to syntactic\npatterns in the local context but less so to semantic patterns. Our data and\ncode are available at \\url{https://github.com/zkx06111/llm_priming}.", "published": "2023-05-26 13:30:48", "link": "http://arxiv.org/abs/2305.16917v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Lost In Translation: How Bridging The Gap Between Languages\n  Affects Gender Bias in Zero-Shot Multilingual Translation", "abstract": "Neural machine translation (NMT) models often suffer from gender biases that\nharm users and society at large. In this work, we explore how bridging the gap\nbetween languages for which parallel data is not available affects gender bias\nin multilingual NMT, specifically for zero-shot directions. We evaluate\ntranslation between grammatical gender languages which requires preserving the\ninherent gender information from the source in the target language. We study\nthe effect of encouraging language-agnostic hidden representations on models'\nability to preserve gender and compare pivot-based and zero-shot translation\nregarding the influence of the bridge language (participating in all language\npairs during training) on gender preservation. We find that language-agnostic\nrepresentations mitigate zero-shot models' masculine bias, and with increased\nlevels of gender inflection in the bridge language, pivoting surpasses\nzero-shot translation regarding fairer gender preservation for speaker-related\ngender agreement.", "published": "2023-05-26 13:51:50", "link": "http://arxiv.org/abs/2305.16935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and\n  Evaluation", "abstract": "Few-shot fine-tuning and in-context learning are two alternative strategies\nfor task adaptation of pre-trained language models. Recently, in-context\nlearning has gained popularity over fine-tuning due to its simplicity and\nimproved out-of-domain generalization, and because extensive evidence shows\nthat fine-tuned models pick up on spurious correlations. Unfortunately,\nprevious comparisons of the two approaches were done using models of different\nsizes. This raises the question of whether the observed weaker out-of-domain\ngeneralization of fine-tuned models is an inherent property of fine-tuning or a\nlimitation of the experimental setup. In this paper, we compare the\ngeneralization of few-shot fine-tuning and in-context learning to challenge\ndatasets, while controlling for the models used, the number of examples, and\nthe number of parameters, ranging from 125M to 30B. Our results show that\nfine-tuned language models can in fact generalize well out-of-domain. We find\nthat both approaches generalize similarly; they exhibit large variation and\ndepend on properties such as model size and the number of examples,\nhighlighting that robust task adaptation remains a challenge.", "published": "2023-05-26 13:55:17", "link": "http://arxiv.org/abs/2305.16938v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Imagine: Visually-Augmented Natural Language Generation", "abstract": "People often imagine relevant scenes to aid in the writing process. In this\nwork, we aim to utilize visual information for composition in the same manner\nas humans. We propose a method, LIVE, that makes pre-trained language models\n(PLMs) Learn to Imagine for Visuallyaugmented natural language gEneration.\nFirst, we imagine the scene based on the text: we use a diffusion model to\nsynthesize high-quality images conditioned on the input texts. Second, we use\nCLIP to determine whether the text can evoke the imagination in a posterior\nway. Finally, our imagination is dynamic, and we conduct synthesis for each\nsentence rather than generate only one image for an entire paragraph.\nTechnically, we propose a novel plug-and-play fusion layer to obtain\nvisually-augmented representations for each text. Our vision-text fusion layer\nis compatible with Transformerbased architecture. We have conducted extensive\nexperiments on four generation tasks using BART and T5, and the automatic\nresults and human evaluation demonstrate the effectiveness of our proposed\nmethod. We will release the code, model, and data at the link:\nhttps://github.com/RUCAIBox/LIVE.", "published": "2023-05-26 13:59:45", "link": "http://arxiv.org/abs/2305.16944v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence-Incremental Neural Coreference Resolution", "abstract": "We propose a sentence-incremental neural coreference resolution system which\nincrementally builds clusters after marking mention boundaries in a\nshift-reduce method. The system is aimed at bridging two recent approaches at\ncoreference resolution: (1) state-of-the-art non-incremental models that incur\nquadratic complexity in document length with high computational cost, and (2)\nmemory network-based models which operate incrementally but do not generalize\nbeyond pronouns. For comparison, we simulate an incremental setting by\nconstraining non-incremental systems to form partial coreference chains before\nobserving new sentences. In this setting, our system outperforms comparable\nstate-of-the-art methods by 2 F1 on OntoNotes and 7 F1 on the CODI-CRAC 2021\ncorpus. In a conventional coreference setup, our system achieves 76.3 F1 on\nOntoNotes and 45.8 F1 on CODI-CRAC 2021, which is comparable to\nstate-of-the-art baselines. We also analyze variations of our system and show\nthat the degree of incrementality in the encoder has a surprisingly large\neffect on the resulting performance.", "published": "2023-05-26 14:00:25", "link": "http://arxiv.org/abs/2305.16947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Generalization without Trees using Multiset Tagging and\n  Latent Permutations", "abstract": "Seq2seq models have been shown to struggle with compositional generalization\nin semantic parsing, i.e. generalizing to unseen compositions of phenomena that\nthe model handles correctly in isolation.\n  We phrase semantic parsing as a two-step process: we first tag each input\ntoken with a multiset of output tokens. Then we arrange the tokens into an\noutput sequence using a new way of parameterizing and predicting permutations.\nWe formulate predicting a permutation as solving a regularized linear program\nand we backpropagate through the solver. In contrast to prior work, our\napproach does not place a priori restrictions on possible permutations, making\nit very expressive.\n  Our model outperforms pretrained seq2seq models and prior work on realistic\nsemantic parsing tasks that require generalization to longer examples. We also\noutperform non-tree-based models on structural generalization on the COGS\nbenchmark. For the first time, we show that a model without an inductive bias\nprovided by trees achieves high accuracy on generalization to deeper recursion.", "published": "2023-05-26 14:09:35", "link": "http://arxiv.org/abs/2305.16954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Open-Domain Dialogues in Latent Space with Next Sentence\n  Prediction and Mutual Information", "abstract": "The long-standing one-to-many issue of the open-domain dialogues poses\nsignificant challenges for automatic evaluation methods, i.e., there may be\nmultiple suitable responses which differ in semantics for a given\nconversational context. To tackle this challenge, we propose a novel\nlearning-based automatic evaluation metric (CMN), which can robustly evaluate\nopen-domain dialogues by augmenting Conditional Variational Autoencoders\n(CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual\nInformation (MI) to model the semantic similarity of text in the latent space.\nExperimental results on two open-domain dialogue datasets demonstrate the\nsuperiority of our method compared with a wide range of baselines, especially\nin handling responses which are distant to the golden reference responses in\nsemantics.", "published": "2023-05-26 14:21:54", "link": "http://arxiv.org/abs/2305.16967v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Comparison of LM-based Question and Answer Generation\n  Methods", "abstract": "Question and answer generation (QAG) consists of generating a set of\nquestion-answer pairs given a context (e.g. a paragraph). This task has a\nvariety of applications, such as data augmentation for question answering (QA)\nmodels, information retrieval and education. In this paper, we establish\nbaselines with three different QAG methodologies that leverage\nsequence-to-sequence language model (LM) fine-tuning. Experiments show that an\nend-to-end QAG model, which is computationally light at both training and\ninference times, is generally robust and outperforms other more convoluted\napproaches. However, there are differences depending on the underlying\ngenerative LM. Finally, our analysis shows that QA models fine-tuned solely on\ngenerated question-answer pairs can be competitive when compared to supervised\nQA models trained on human-labeled data.", "published": "2023-05-26 14:59:53", "link": "http://arxiv.org/abs/2305.17002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NormBank: A Knowledge Bank of Situational Social Norms", "abstract": "We present NormBank, a knowledge bank of 155k situational norms. This\nresource is designed to ground flexible normative reasoning for interactive,\nassistive, and collaborative AI systems. Unlike prior commonsense resources,\nNormBank grounds each inference within a multivalent sociocultural frame, which\nincludes the setting (e.g., restaurant), the agents' contingent roles (waiter,\ncustomer), their attributes (age, gender), and other physical, social, and\ncultural constraints (e.g., the temperature or the country of operation). In\ntotal, NormBank contains 63k unique constraints from a taxonomy that we\nintroduce and iteratively refine here. Constraints then apply in different\ncombinations to frame social norms. Under these manipulations, norms are\nnon-monotonic - one can cancel an inference by updating its frame even\nslightly. Still, we find evidence that neural models can help reliably extend\nthe scope and coverage of NormBank. We further demonstrate the utility of this\nresource with a series of transfer experiments.", "published": "2023-05-26 15:09:11", "link": "http://arxiv.org/abs/2305.17008v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "D-CALM: A Dynamic Clustering-based Active Learning Approach for\n  Mitigating Bias", "abstract": "Despite recent advancements, NLP models continue to be vulnerable to bias.\nThis bias often originates from the uneven distribution of real-world data and\ncan propagate through the annotation process. Escalated integration of these\nmodels in our lives calls for methods to mitigate bias without overbearing\nannotation costs. While active learning (AL) has shown promise in training\nmodels with a small amount of annotated data, AL's reliance on the model's\nbehavior for selective sampling can lead to an accumulation of unwanted bias\nrather than bias mitigation. However, infusing clustering with AL can overcome\nthe bias issue of both AL and traditional annotation methods while exploiting\nAL's annotation efficiency. In this paper, we propose a novel adaptive\nclustering-based active learning algorithm, D-CALM, that dynamically adjusts\nclustering and annotation efforts in response to an estimated classifier\nerror-rate. Experiments on eight datasets for a diverse set of text\nclassification tasks, including emotion, hatespeech, dialog act, and book type\ndetection, demonstrate that our proposed algorithm significantly outperforms\nbaseline AL approaches with both pretrained transformers and traditional\nSupport Vector Machines. D-CALM showcases robustness against different measures\nof information gain and, as evident from our analysis of label and error\ndistribution, can significantly reduce unwanted model bias.", "published": "2023-05-26 15:17:43", "link": "http://arxiv.org/abs/2305.17013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commonsense Knowledge Graph Completion Via Contrastive Pretraining and\n  Node Clustering", "abstract": "The nodes in the commonsense knowledge graph (CSKG) are normally represented\nby free-form short text (e.g., word or phrase). Different nodes may represent\nthe same concept. This leads to the problems of edge sparsity and node\nredundancy, which challenges CSKG representation and completion. On the one\nhand, edge sparsity limits the performance of graph representation learning; On\nthe other hand, node redundancy makes different nodes corresponding to the same\nconcept have inconsistent relations with other nodes. To address the two\nproblems, we propose a new CSKG completion framework based on Contrastive\nPretraining and Node Clustering (CPNC). Contrastive Pretraining constructs\npositive and negative head-tail node pairs on CSKG and utilizes contrastive\nlearning to obtain better semantic node representation. Node Clustering\naggregates nodes with the same concept into a latent concept, assisting the\ntask of CSKG completion. We evaluate our CPNC approach on two CSKG completion\nbenchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-art\nmethods. Extensive experiments demonstrate that both Contrastive Pretraining\nand Node Clustering can significantly improve the performance of CSKG\ncompletion. The source code of CPNC is publicly available on\n\\url{https://github.com/NUSTM/CPNC}.", "published": "2023-05-26 15:24:32", "link": "http://arxiv.org/abs/2305.17019v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Abstract Meaning Representation for Open-Domain Question\n  Answering", "abstract": "The Open-Domain Question Answering (ODQA) task involves retrieving and\nsubsequently generating answers from fine-grained relevant passages within a\ndatabase. Current systems leverage Pretrained Language Models (PLMs) to model\nthe relationship between questions and passages. However, the diversity in\nsurface form expressions can hinder the model's ability to capture accurate\ncorrelations, especially within complex contexts. Therefore, we utilize\nAbstract Meaning Representation (AMR) graphs to assist the model in\nunderstanding complex semantic information. We introduce a method known as\nGraph-as-Token (GST) to incorporate AMRs into PLMs. Results from Natural\nQuestions (NQ) and TriviaQA (TQ) demonstrate that our GST method can\nsignificantly improve performance, resulting in up to 2.44/3.17 Exact Match\nscore improvements on NQ/TQ respectively. Furthermore, our method enhances\nrobustness and outperforms alternative Graph Neural Network (GNN) methods for\nintegrating AMRs. To the best of our knowledge, we are the first to employ\nsemantic graphs in ODQA.", "published": "2023-05-26 16:00:16", "link": "http://arxiv.org/abs/2305.17050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactuals of Counterfactuals: a back-translation-inspired approach\n  to analyse counterfactual editors", "abstract": "In the wake of responsible AI, interpretability methods, which attempt to\nprovide an explanation for the predictions of neural models have seen rapid\nprogress. In this work, we are concerned with explanations that are applicable\nto natural language processing (NLP) models and tasks, and we focus\nspecifically on the analysis of counterfactual, contrastive explanations. We\nnote that while there have been several explainers proposed to produce\ncounterfactual explanations, their behaviour can vary significantly and the\nlack of a universal ground truth for the counterfactual edits imposes an\ninsuperable barrier on their evaluation. We propose a new back\ntranslation-inspired evaluation methodology that utilises earlier outputs of\nthe explainer as ground truth proxies to investigate the consistency of\nexplainers. We show that by iteratively feeding the counterfactual to the\nexplainer we can obtain valuable insights into the behaviour of both the\npredictor and the explainer models, and infer patterns that would be otherwise\nobscured. Using this methodology, we conduct a thorough analysis and propose a\nnovel metric to evaluate the consistency of counterfactual generation\napproaches with different characteristics across available performance\nindicators.", "published": "2023-05-26 16:04:28", "link": "http://arxiv.org/abs/2305.17055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeuroX Library for Neuron Analysis of Deep NLP Models", "abstract": "Neuron analysis provides insights into how knowledge is structured in\nrepresentations and discovers the role of neurons in the network. In addition\nto developing an understanding of our models, neuron analysis enables various\napplications such as debiasing, domain adaptation and architectural search. We\npresent NeuroX, a comprehensive open-source toolkit to conduct neuron analysis\nof natural language processing models. It implements various interpretation\nmethods under a unified API, and provides a framework for data processing and\nevaluation, thus making it easier for researchers and practitioners to perform\nneuron analysis. The Python toolkit is available at\nhttps://www.github.com/fdalvi/NeuroX. Demo Video available at\nhttps://youtu.be/mLhs2YMx4u8.", "published": "2023-05-26 16:32:56", "link": "http://arxiv.org/abs/2305.17073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CREST: A Joint Framework for Rationalization and Counterfactual Text\n  Generation", "abstract": "Selective rationales and counterfactual examples have emerged as two\neffective, complementary classes of interpretability methods for analyzing and\ntraining NLP models. However, prior work has not explored how these methods can\nbe integrated to combine their complementary advantages. We overcome this\nlimitation by introducing CREST (ContRastive Edits with Sparse\nraTionalization), a joint framework for selective rationalization and\ncounterfactual text generation, and show that this framework leads to\nimprovements in counterfactual quality, model robustness, and interpretability.\nFirst, CREST generates valid counterfactuals that are more natural than those\nproduced by previous methods, and subsequently can be used for data\naugmentation at scale, reducing the need for human-generated examples. Second,\nwe introduce a new loss function that leverages CREST counterfactuals to\nregularize selective rationales and show that this regularization improves both\nmodel robustness and rationale quality, compared to methods that do not\nleverage CREST counterfactuals. Our results demonstrate that CREST successfully\nbridges the gap between selective rationales and counterfactual examples,\naddressing the limitations of existing methods and providing a more\ncomprehensive view of a model's predictions.", "published": "2023-05-26 16:34:58", "link": "http://arxiv.org/abs/2305.17075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question\n  Answering", "abstract": "We propose EAR, a query Expansion And Reranking approach for improving\npassage retrieval, with the application to open-domain question answering. EAR\nfirst applies a query expansion model to generate a diverse set of queries, and\nthen uses a query reranker to select the ones that could lead to better\nretrieval results. Motivated by the observation that the best query expansion\noften is not picked by greedy decoding, EAR trains its reranker to predict the\nrank orders of the gold passages when issuing the expanded queries to a given\nretriever. By connecting better the query expansion model and retriever, EAR\nsignificantly enhances a traditional sparse retrieval method, BM25.\nEmpirically, EAR improves top-5/20 accuracy by 3-8 and 5-10 points in in-domain\nand out-of-domain settings, respectively, when compared to a vanilla query\nexpansion model, GAR, and a dense retrieval model, DPR.", "published": "2023-05-26 16:41:03", "link": "http://arxiv.org/abs/2305.17080v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PromptNER: Prompt Locating and Typing for Named Entity Recognition", "abstract": "Prompt learning is a new paradigm for utilizing pre-trained language models\nand has achieved great success in many tasks. To adopt prompt learning in the\nNER task, two kinds of methods have been explored from a pair of symmetric\nperspectives, populating the template by enumerating spans to predict their\nentity types or constructing type-specific prompts to locate entities. However,\nthese methods not only require a multi-round prompting manner with a high time\noverhead and computational cost, but also require elaborate prompt templates,\nthat are difficult to apply in practical scenarios. In this paper, we unify\nentity locating and entity typing into prompt learning, and design a dual-slot\nmulti-prompt template with the position slot and type slot to prompt locating\nand typing respectively. Multiple prompts can be input to the model\nsimultaneously, and then the model extracts all entities by parallel\npredictions on the slots. To assign labels for the slots during training, we\ndesign a dynamic template filling mechanism that uses the extended bipartite\ngraph matching between prompts and the ground-truth entities. We conduct\nexperiments in various settings, including resource-rich flat and nested NER\ndatasets and low-resource in-domain and cross-domain datasets. Experimental\nresults show that the proposed model achieves a significant performance\nimprovement, especially in the cross-domain few-shot setting, which outperforms\nthe state-of-the-art model by +7.7% on average.", "published": "2023-05-26 17:16:11", "link": "http://arxiv.org/abs/2305.17104v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing and Measuring Linguistic Dataset Drift", "abstract": "NLP models often degrade in performance when real world data distributions\ndiffer markedly from training data. However, existing dataset drift metrics in\nNLP have generally not considered specific dimensions of linguistic drift that\naffect model performance, and they have not been validated in their ability to\npredict model performance at the individual example level, where such metrics\nare often used in practice. In this paper, we propose three dimensions of\nlinguistic dataset drift: vocabulary, structural, and semantic drift. These\ndimensions correspond to content word frequency divergences, syntactic\ndivergences, and meaning changes not captured by word frequencies (e.g. lexical\nsemantic change). We propose interpretable metrics for all three drift\ndimensions, and we modify past performance prediction methods to predict model\nperformance at both the example and dataset level for English sentiment\nclassification and natural language inference. We find that our drift metrics\nare more effective than previous metrics at predicting out-of-domain model\naccuracies (mean 16.8% root mean square error decrease), particularly when\ncompared to popular fine-tuned embedding distances (mean 47.7% error decrease).\nFine-tuned embedding distances are much more effective at ranking individual\nexamples by expected performance, but decomposing into vocabulary, structural,\nand semantic drift produces the best example rankings of all considered\nmodel-agnostic drift metrics (mean 6.7% ROC AUC increase).", "published": "2023-05-26 17:50:51", "link": "http://arxiv.org/abs/2305.17127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAMP: Retrieval and Attribute-Marking Enhanced Prompting for\n  Attribute-Controlled Translation", "abstract": "Attribute-controlled translation (ACT) is a subtask of machine translation\nthat involves controlling stylistic or linguistic attributes (like formality\nand gender) of translation outputs. While ACT has garnered attention in recent\nyears due to its usefulness in real-world applications, progress in the task is\ncurrently limited by dataset availability, since most prior approaches rely on\nsupervised methods. To address this limitation, we propose Retrieval and\nAttribute-Marking enhanced Prompting (RAMP), which leverages large multilingual\nlanguage models to perform ACT in few-shot and zero-shot settings. RAMP\nimproves generation accuracy over the standard prompting approach by (1)\nincorporating a semantic similarity retrieval component for selecting similar\nin-context examples, and (2) marking in-context examples with attribute\nannotations. Our comprehensive experiments show that RAMP is a viable approach\nin both zero-shot and few-shot settings.", "published": "2023-05-26 17:56:53", "link": "http://arxiv.org/abs/2305.17131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tokenization Impacts Multilingual Language Modeling: Assessing\n  Vocabulary Allocation and Overlap Across Languages", "abstract": "Multilingual language models have recently gained attention as a promising\nsolution for representing multiple languages in a single model. In this paper,\nwe propose new criteria to evaluate the quality of lexical representation and\nvocabulary overlap observed in sub-word tokenizers. Our findings show that the\noverlap of vocabulary across languages can be actually detrimental to certain\ndownstream tasks (POS, dependency tree labeling). In contrast, NER and\nsentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing\nvocabulary. We also observe that the coverage of the language-specific tokens\nin the multilingual vocabulary significantly impacts the word-level tasks. Our\nstudy offers a deeper understanding of the role of tokenizers in multilingual\nlanguage models and guidelines for future model developers to choose the most\nsuitable tokenizer for their specific application before undertaking costly\nmodel pre-training", "published": "2023-05-26 18:06:49", "link": "http://arxiv.org/abs/2305.17179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entailment as Robust Self-Learner", "abstract": "Entailment has been recognized as an important metric for evaluating natural\nlanguage understanding (NLU) models, and recent studies have found that\nentailment pretraining benefits weakly supervised fine-tuning. In this work, we\ndesign a prompting strategy that formulates a number of different NLU tasks as\ncontextual entailment. This approach improves the zero-shot adaptation of\npretrained entailment models. Secondly, we notice that self-training\nentailment-based models with unlabeled data can significantly improve the\nadaptation performance on downstream tasks. To achieve more stable improvement,\nwe propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better\npseudo-labeling quality in self-training. We also found that both pretrained\nentailment-based models and the self-trained models are robust against\nadversarial evaluation data. Experiments on binary and multi-class\nclassification tasks show that SimPLE leads to more robust self-training\nresults, indicating that the self-trained entailment models are more efficient\nand trustworthy than large language models on language understanding tasks.", "published": "2023-05-26 18:41:23", "link": "http://arxiv.org/abs/2305.17197v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BIG-C: a Multimodal Multi-Purpose Dataset for Bemba", "abstract": "We present BIG-C (Bemba Image Grounded Conversations), a large multimodal\ndataset for Bemba. While Bemba is the most populous language of Zambia, it\nexhibits a dearth of resources which render the development of language\ntechnologies or language processing research almost impossible. The dataset is\ncomprised of multi-turn dialogues between Bemba speakers based on images,\ntranscribed and translated into English. There are more than 92,000\nutterances/sentences, amounting to more than 180 hours of audio data with\ncorresponding transcriptions and English translations. We also provide\nbaselines on speech recognition (ASR), machine translation (MT) and speech\ntranslation (ST) tasks, and sketch out other potential future multimodal uses\nof our dataset. We hope that by making the dataset available to the research\ncommunity, this work will foster research and encourage collaboration across\nthe language, speech, and vision communities especially for languages outside\nthe \"traditionally\" used high-resourced ones. All data and code are publicly\navailable: https://github.com/csikasote/bigc.", "published": "2023-05-26 18:49:55", "link": "http://arxiv.org/abs/2305.17202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coping with low data availability for social media crisis message\n  categorisation", "abstract": "During crisis situations, social media allows people to quickly share\ninformation, including messages requesting help. This can be valuable to\nemergency responders, who need to categorise and prioritise these messages\nbased on the type of assistance being requested. However, the high volume of\nmessages makes it difficult to filter and prioritise them without the use of\ncomputational techniques. Fully supervised filtering techniques for crisis\nmessage categorisation typically require a large amount of annotated training\ndata, but this can be difficult to obtain during an ongoing crisis and is\nexpensive in terms of time and labour to create.\n  This thesis focuses on addressing the challenge of low data availability when\ncategorising crisis messages for emergency response. It first presents domain\nadaptation as a solution for this problem, which involves learning a\ncategorisation model from annotated data from past crisis events (source\ndomain) and adapting it to categorise messages from an ongoing crisis event\n(target domain). In many-to-many adaptation, where the model is trained on\nmultiple past events and adapted to multiple ongoing events, a multi-task\nlearning approach is proposed using pre-trained language models. This approach\noutperforms baselines and an ensemble approach further improves performance...", "published": "2023-05-26 19:08:24", "link": "http://arxiv.org/abs/2305.17211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale", "abstract": "In recent years, language models have drastically grown in size, and the\nabilities of these models have been shown to improve with scale. The majority\nof recent scaling laws studies focused on high-compute high-parameter count\nsettings, leaving the question of when these abilities begin to emerge largely\nunanswered. In this paper, we investigate whether the effects of pre-training\ncan be observed when the problem size is reduced, modeling a smaller,\nreduced-vocabulary language. We show the benefits of pre-training with masked\nlanguage modeling (MLM) objective in models as small as 1.25M parameters, and\nestablish a strong correlation between pre-training perplexity and downstream\nperformance (GLUE benchmark). We examine downscaling effects, extending scaling\nlaws to models as small as ~1M parameters. At this scale, we observe a break of\nthe power law for compute-optimal models and show that the MLM loss does not\nscale smoothly with compute-cost (FLOPs) below $2.2 \\times 10^{15}$ FLOPs. We\nalso find that adding layers does not always benefit downstream performance.", "published": "2023-05-26 21:22:10", "link": "http://arxiv.org/abs/2305.17266v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine\n  Translation", "abstract": "Neural machine translation (NMT) systems exhibit limited robustness in\nhandling source-side linguistic variations. Their performance tends to degrade\nwhen faced with even slight deviations in language usage, such as different\ndomains or variations introduced by second-language speakers. It is intuitive\nto extend this observation to encompass dialectal variations as well, but the\nwork allowing the community to evaluate MT systems on this dimension is\nlimited. To alleviate this issue, we compile and release CODET, a contrastive\ndialectal benchmark encompassing 891 different variations from twelve different\nlanguages. We also quantitatively demonstrate the challenges large MT models\nface in effectively translating dialectal variants. All the data and code have\nbeen released.", "published": "2023-05-26 21:24:00", "link": "http://arxiv.org/abs/2305.17267v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metaphor Detection via Explicit Basic Meanings Modelling", "abstract": "One noticeable trend in metaphor detection is the embrace of linguistic\ntheories such as the metaphor identification procedure (MIP) for model\narchitecture design. While MIP clearly defines that the metaphoricity of a\nlexical unit is determined based on the contrast between its \\textit{contextual\nmeaning} and its \\textit{basic meaning}, existing work does not strictly follow\nthis principle, typically using the \\textit{aggregated meaning} to approximate\nthe basic meaning of target words. In this paper, we propose a novel metaphor\ndetection method, which models the basic meaning of the word based on literal\nannotation from the training set, and then compares this with the contextual\nmeaning in a target sentence to identify metaphors. Empirical results show that\nour method outperforms the state-of-the-art method significantly by 1.0\\% in F1\nscore. Moreover, our performance even reaches the theoretical upper bound on\nthe VUA18 benchmark for targets with basic annotations, which demonstrates the\nimportance of modelling basic meanings for metaphor detection.", "published": "2023-05-26 21:25:05", "link": "http://arxiv.org/abs/2305.17268v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Instruction Ordering in Recipe-Grounded Conversation", "abstract": "In this paper, we study the task of instructional dialogue and focus on the\ncooking domain. Analyzing the generated output of the GPT-J model, we reveal\nthat the primary challenge for a recipe-grounded dialog system is how to\nprovide the instructions in the correct order. We hypothesize that this is due\nto the model's lack of understanding of user intent and inability to track the\ninstruction state (i.e., which step was last instructed). Therefore, we propose\nto explore two auxiliary subtasks, namely User Intent Detection and Instruction\nState Tracking, to support Response Generation with improved instruction\ngrounding. Experimenting with our newly collected dataset, ChattyChef, shows\nthat incorporating user intent and instruction state information helps the\nresponse generation model mitigate the incorrect order issue. Furthermore, to\ninvestigate whether ChatGPT has completely solved this task, we analyze its\noutputs and find that it also makes mistakes (10.7% of the responses), about\nhalf of which are out-of-order instructions. We will release ChattyChef to\nfacilitate further research in this area at:\nhttps://github.com/octaviaguo/ChattyChef.", "published": "2023-05-26 21:57:11", "link": "http://arxiv.org/abs/2305.17280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "External Language Model Integration for Factorized Neural Transducers", "abstract": "We propose an adaptation method for factorized neural transducers (FNT) with\nexternal language models. We demonstrate that both neural and n-gram external\nLMs add significantly more value when linearly interpolated with predictor\noutput compared to shallow fusion, thus confirming that FNT forces the\npredictor to act like regular language models. Further, we propose a method to\nintegrate class-based n-gram language models into FNT framework resulting in\naccuracy gains similar to a hybrid setup. We show average gains of 18% WERR\nwith lexical adaptation across various scenarios and additive gains of up to\n60% WERR in one entity-rich scenario through a combination of class-based\nn-gram and neural LMs.", "published": "2023-05-26 23:30:21", "link": "http://arxiv.org/abs/2305.17304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AaKOS: Aspect-adaptive Knowledge-based Opinion Summarization", "abstract": "The rapid growth of information on the Internet has led to an overwhelming\namount of opinions and comments on various activities, products, and services.\nThis makes it difficult and time-consuming for users to process all the\navailable information when making decisions. Text summarization, a Natural\nLanguage Processing (NLP) task, has been widely explored to help users quickly\nretrieve relevant information by generating short and salient content from long\nor multiple documents. Recent advances in pre-trained language models, such as\nChatGPT, have demonstrated the potential of Large Language Models (LLMs) in\ntext generation. However, LLMs require massive amounts of data and resources\nand are challenging to implement as offline applications. Furthermore, existing\ntext summarization approaches often lack the ``adaptive\" nature required to\ncapture diverse aspects in opinion summarization, which is particularly\ndetrimental to users with specific requirements or preferences. In this paper,\nwe propose an Aspect-adaptive Knowledge-based Opinion Summarization model for\nproduct reviews, which effectively captures the adaptive nature required for\nopinion summarization. The model generates aspect-oriented summaries given a\nset of reviews for a particular product, efficiently providing users with\nuseful information on specific aspects they are interested in, ensuring the\ngenerated summaries are more personalized and informative. Extensive\nexperiments have been conducted using real-world datasets to evaluate the\nproposed model. The results demonstrate that our model outperforms\nstate-of-the-art approaches and is adaptive and efficient in generating\nsummaries that focus on particular aspects, enabling users to make\nwell-informed decisions and catering to their diverse interests and\npreferences.", "published": "2023-05-26 03:44:35", "link": "http://arxiv.org/abs/2306.05537v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotating and Detecting Fine-grained Factual Errors for Dialogue\n  Summarization", "abstract": "A series of datasets and models have been proposed for summaries generated\nfor well-formatted documents such as news articles. Dialogue summaries,\nhowever, have been under explored. In this paper, we present the first dataset\nwith fine-grained factual error annotations named DIASUMFACT. We define\nfine-grained factual error detection as a sentence-level multi-label\nclassification problem, and we evaluate two state-of-the-art (SOTA) models on\nour dataset. Both models yield sub-optimal results, with a macro-averaged F1\nscore of around 0.25 over 6 error classes. We further propose an unsupervised\nmodel ENDERANKER via candidate ranking using pretrained encoder-decoder models.\nOur model performs on par with the SOTA models while requiring fewer resources.\nThese observations confirm the challenges in detecting factual errors from\ndialogue summaries, which call for further studies, for which our dataset and\nresults offer a solid foundation.", "published": "2023-05-26 00:18:33", "link": "http://arxiv.org/abs/2305.16548v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NLP Reproducibility For All: Understanding Experiences of Beginners", "abstract": "As natural language processing (NLP) has recently seen an unprecedented level\nof excitement, and more people are eager to enter the field, it is unclear\nwhether current research reproducibility efforts are sufficient for this group\nof beginners to apply the latest developments. To understand their needs, we\nconducted a study with 93 students in an introductory NLP course, where\nstudents reproduced the results of recent NLP papers. Surprisingly, we find\nthat their programming skill and comprehension of research papers have a\nlimited impact on their effort spent completing the exercise. Instead, we find\naccessibility efforts by research authors to be the key to success, including\ncomplete documentation, better coding practice, and easier access to data\nfiles. Going forward, we recommend that NLP researchers pay close attention to\nthese simple aspects of open-sourcing their work, and use insights from\nbeginners' feedback to provide actionable ideas on how to better support them.", "published": "2023-05-26 02:08:54", "link": "http://arxiv.org/abs/2305.16579v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluation of Question Generation Needs More References", "abstract": "Question generation (QG) is the task of generating a valid and fluent\nquestion based on a given context and the target answer. According to various\npurposes, even given the same context, instructors can ask questions about\ndifferent concepts, and even the same concept can be written in different ways.\nHowever, the evaluation for QG usually depends on single reference-based\nsimilarity metrics, such as n-gram-based metric or learned metric, which is not\nsufficient to fully evaluate the potential of QG methods. To this end, we\npropose to paraphrase the reference question for a more robust QG evaluation.\nUsing large language models such as GPT-3, we created semantically and\nsyntactically diverse questions, then adopt the simple aggregation of the\npopular evaluation metrics as the final scores. Through our experiments, we\nfound that using multiple (pseudo) references is more effective for QG\nevaluation while showing a higher correlation with human evaluations than\nevaluation with a single reference.", "published": "2023-05-26 04:40:56", "link": "http://arxiv.org/abs/2305.16626v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for\n  Financial Tasks", "abstract": "Recently large language models (LLMs) like ChatGPT have shown impressive\nperformance on many natural language processing tasks with zero-shot. In this\npaper, we investigate the effectiveness of zero-shot LLMs in the financial\ndomain. We compare the performance of ChatGPT along with some open-source\ngenerative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We\naddress three inter-related research questions on data annotation, performance\ngaps, and the feasibility of employing generative models in the finance domain.\nOur findings demonstrate that ChatGPT performs well even without labeled data\nbut fine-tuned models generally outperform it. Our research also highlights how\nannotating with generative models can be time-intensive. Our codebase is\npublicly available on GitHub under CC BY-NC 4.0 license.", "published": "2023-05-26 05:13:01", "link": "http://arxiv.org/abs/2305.16633v1", "categories": ["cs.CL", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase\n  Generation", "abstract": "Syntactically controlled paraphrase generation requires language models to\ngenerate paraphrases for sentences according to specific syntactic structures.\nExisting fine-tuning methods for this task are costly as all the parameters of\nthe model need to be updated during the training process. Inspired by recent\nstudies on parameter-efficient learning, we propose Parse-Instructed Prefix\n(PIP), a novel adaptation of prefix-tuning to tune large pre-trained language\nmodels on syntactically controlled paraphrase generation task in a low-data\nsetting with significantly less training cost. We introduce two methods to\ninstruct a model's encoder prefix to capture syntax-related knowledge: direct\ninitiation (PIP-Direct) and indirect optimization (PIP-Indirect). In contrast\nto traditional fine-tuning methods for this task, PIP is a compute-efficient\nalternative with 10 times less learnable parameters. Compared to existing\nprefix-tuning methods, PIP excels at capturing syntax control information,\nachieving significantly higher performance at the same level of learnable\nparameter count.", "published": "2023-05-26 07:42:38", "link": "http://arxiv.org/abs/2305.16701v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Code-Switched Text Synthesis in Unseen Language Pairs", "abstract": "Existing efforts on text synthesis for code-switching mostly require training\non code-switched texts in the target language pairs, limiting the deployment of\nthe models to cases lacking code-switched data. In this work, we study the\nproblem of synthesizing code-switched texts for language pairs absent from the\ntraining data. We introduce GLOSS, a model built on top of a pre-trained\nmultilingual machine translation model (PMMTM) with an additional\ncode-switching module. This module, either an adapter or extra prefixes, learns\ncode-switching patterns from code-switched data during training, while the\nprimary component of GLOSS, i.e., the PMMTM, is frozen. The design of only\nadjusting the code-switching module prevents our model from overfitting to the\nconstrained training data for code-switching. Hence, GLOSS exhibits the ability\nto generalize and synthesize code-switched texts across a broader spectrum of\nlanguage pairs. Additionally, we develop a self-training algorithm on target\nlanguage pairs further to enhance the reliability of GLOSS. Automatic\nevaluations on four language pairs show that GLOSS achieves at least 55%\nrelative BLEU and METEOR scores improvements compared to strong baselines.\nHuman evaluations on two language pairs further validate the success of GLOSS.", "published": "2023-05-26 08:22:35", "link": "http://arxiv.org/abs/2305.16724v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RankCSE: Unsupervised Sentence Representations Learning via Learning to\n  Rank", "abstract": "Unsupervised sentence representation learning is one of the fundamental\nproblems in natural language processing with various downstream applications.\nRecently, contrastive learning has been widely adopted which derives\nhigh-quality sentence representations by pulling similar semantics closer and\npushing dissimilar ones away. However, these methods fail to capture the\nfine-grained ranking information among the sentences, where each sentence is\nonly treated as either positive or negative. In many real-world scenarios, one\nneeds to distinguish and rank the sentences based on their similarities to a\nquery sentence, e.g., very relevant, moderate relevant, less relevant,\nirrelevant, etc. In this paper, we propose a novel approach, RankCSE, for\nunsupervised sentence representation learning, which incorporates ranking\nconsistency and ranking distillation with contrastive learning into a unified\nframework. In particular, we learn semantically discriminative sentence\nrepresentations by simultaneously ensuring ranking consistency between two\nrepresentations with different dropout masks, and distilling listwise ranking\nknowledge from the teacher. An extensive set of experiments are conducted on\nboth semantic textual similarity (STS) and transfer (TR) tasks. Experimental\nresults demonstrate the superior performance of our approach over several\nstate-of-the-art baselines.", "published": "2023-05-26 08:27:07", "link": "http://arxiv.org/abs/2305.16726v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction\n  Model", "abstract": "Event argument extraction (EAE) identifies event arguments and their specific\nroles for a given event. Recent advancement in generation-based EAE models has\nshown great performance and generalizability over classification-based models.\nHowever, existing generation-based EAE models mostly focus on problem\nre-formulation and prompt design, without incorporating additional information\nthat has been shown to be effective for classification-based models, such as\nthe abstract meaning representation (AMR) of the input passages. Incorporating\nsuch information into generation-based models is challenging due to the\nheterogeneous nature of the natural language form prevalently used in\ngeneration-based models and the structured form of AMRs. In this work, we study\nstrategies to incorporate AMR into generation-based EAE models. We propose\nAMPERE, which generates AMR-aware prefixes for every layer of the generation\nmodel. Thus, the prefix introduces AMR information to the generation-based EAE\nmodel and then improves the generation. We also introduce an adjusted copy\nmechanism to AMPERE to help overcome potential noises brought by the AMR graph.\nComprehensive experiments and analyses on ACE2005 and ERE datasets show that\nAMPERE can get 4% - 10% absolute F1 score improvements with reduced training\ndata and it is in general powerful across different training sizes.", "published": "2023-05-26 08:38:25", "link": "http://arxiv.org/abs/2305.16734v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automating the Analysis of Institutional Design in International\n  Agreements", "abstract": "This paper explores the automatic knowledge extraction of formal\ninstitutional design - norms, rules, and actors - from international\nagreements. The focus was to analyze the relationship between the visibility\nand centrality of actors in the formal institutional design in regulating\ncritical aspects of cultural heritage relations. The developed tool utilizes\ntechniques such as collecting legal documents, annotating them with\nInstitutional Grammar, and using graph analysis to explore the formal\ninstitutional design. The system was tested against the 2003 UNESCO Convention\nfor the Safeguarding of the Intangible Cultural Heritage.", "published": "2023-05-26 08:57:11", "link": "http://arxiv.org/abs/2305.16750v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Can large language models generate salient negative statements?", "abstract": "We examine the ability of large language models (LLMs) to generate salient\n(interesting) negative statements about real-world entities; an emerging\nresearch topic of the last few years. We probe the LLMs using zero- and k-shot\nunconstrained probes, and compare with traditional methods for negation\ngeneration, i.e., pattern-based textual extractions and knowledge-graph-based\ninferences, as well as crowdsourced gold statements. We measure the correctness\nand salience of the generated lists about subjects from different domains. Our\nevaluation shows that guided probes do in fact improve the quality of generated\nnegatives, compared to the zero-shot variant. Nevertheless, using both prompts,\nLLMs still struggle with the notion of factuality of negatives, frequently\ngenerating many ambiguous statements, or statements with negative keywords but\na positive meaning.", "published": "2023-05-26 09:13:59", "link": "http://arxiv.org/abs/2305.16755v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian\n  Response Entry Classification", "abstract": "Accurate and rapid situation analysis during humanitarian crises is critical\nto delivering humanitarian aid efficiently and is fundamental to humanitarian\nimperatives and the Leave No One Behind (LNOB) principle. This data analysis\ncan highly benefit from language processing systems, e.g., by classifying the\ntext data according to a humanitarian ontology. However, approaching this by\nsimply fine-tuning a generic large language model (LLM) involves considerable\npractical and ethical issues, particularly the lack of effectiveness on\ndata-sparse and complex subdomains, and the encoding of societal biases and\nunwanted associations. In this work, we aim to provide an effective and\nethically-aware system for humanitarian data analysis. We approach this by (1)\nintroducing a novel architecture adjusted to the humanitarian analysis\nframework, (2) creating and releasing a novel humanitarian-specific LLM called\nHumBert, and (3) proposing a systematic way to measure and mitigate biases. Our\nexperiments' results show the better performance of our approach on zero-shot\nand full-training settings in comparison with strong baseline models, while\nalso revealing the existence of biases in the resulting LLMs. Utilizing a\ntargeted counterfactual data augmentation approach, we significantly reduce\nthese biases without compromising performance.", "published": "2023-05-26 09:15:05", "link": "http://arxiv.org/abs/2305.16756v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards a Common Understanding of Contributing Factors for Cross-Lingual\n  Transfer in Multilingual Language Models: A Review", "abstract": "In recent years, pre-trained Multilingual Language Models (MLLMs) have shown\na strong ability to transfer knowledge across different languages. However,\ngiven that the aspiration for such an ability has not been explicitly\nincorporated in the design of the majority of MLLMs, it is challenging to\nobtain a unique and straightforward explanation for its emergence. In this\nreview paper, we survey literature that investigates different factors\ncontributing to the capacity of MLLMs to perform zero-shot cross-lingual\ntransfer and subsequently outline and discuss these factors in detail. To\nenhance the structure of this review and to facilitate consolidation with\nfuture studies, we identify five categories of such factors. In addition to\nproviding a summary of empirical evidence from past studies, we identify\nconsensuses among studies with consistent findings and resolve conflicts among\ncontradictory ones. Our work contextualizes and unifies existing research\nstreams which aim at explaining the cross-lingual potential of MLLMs. This\nreview provides, first, an aligned reference point for future research and,\nsecond, guidance for a better-informed and more efficient way of leveraging the\ncross-lingual capacity of MLLMs.", "published": "2023-05-26 09:31:12", "link": "http://arxiv.org/abs/2305.16768v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues", "abstract": "User Satisfaction Modeling (USM) is one of the popular choices for\ntask-oriented dialogue systems evaluation, where user satisfaction typically\ndepends on whether the user's task goals were fulfilled by the system.\nTask-oriented dialogue systems use task schema, which is a set of task\nattributes, to encode the user's task goals. Existing studies on USM neglect\nexplicitly modeling the user's task goals fulfillment using the task schema. In\nthis paper, we propose SG-USM, a novel schema-guided user satisfaction modeling\nframework. It explicitly models the degree to which the user's preferences\nregarding the task attributes are fulfilled by the system for predicting the\nuser's satisfaction level. SG-USM employs a pre-trained language model for\nencoding dialogue context and task attributes. Further, it employs a\nfulfillment representation layer for learning how many task attributes have\nbeen fulfilled in the dialogue, an importance predictor component for\ncalculating the importance of task attributes. Finally, it predicts the user\nsatisfaction based on task attribute fulfillment and task attribute importance.\nExperimental results on benchmark datasets (i.e. MWOZ, SGD, ReDial, and JDDC)\nshow that SG-USM consistently outperforms competitive existing methods. Our\nextensive analysis demonstrates that SG-USM can improve the interpretability of\nuser satisfaction modeling, has good scalability as it can effectively deal\nwith unseen tasks and can also effectively work in low-resource settings by\nleveraging unlabeled data.", "published": "2023-05-26 10:19:30", "link": "http://arxiv.org/abs/2305.16798v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Motion-Based Sign Language Video Summarization using Curvature and\n  Torsion", "abstract": "An interesting problem in many video-based applications is the generation of\nshort synopses by selecting the most informative frames, a procedure which is\nknown as video summarization. For sign language videos the benefits of using\nthe $t$-parameterized counterpart of the curvature of the 2-D signer's wrist\ntrajectory to identify keyframes, have been recently reported in the\nliterature. In this paper we extend these ideas by modeling the 3-D hand motion\nthat is extracted from each frame of the video. To this end we propose a new\ninformative function based on the $t$-parameterized curvature and torsion of\nthe 3-D trajectory. The method to characterize video frames as keyframes\ndepends on whether the motion occurs in 2-D or 3-D space. Specifically, in the\ncase of 3-D motion we look for the maxima of the harmonic mean of the curvature\nand torsion of the target's trajectory; in the planar motion case we seek for\nthe maxima of the trajectory's curvature. The proposed 3-D feature is\nexperimentally evaluated in applications of sign language videos on (1)\nobjective measures using ground-truth keyframe annotations, (2) human-based\nevaluation of understanding, and (3) gloss classification and the results\nobtained are promising.", "published": "2023-05-26 10:30:23", "link": "http://arxiv.org/abs/2305.16801v3", "categories": ["cs.CV", "cs.CL", "68T45, 68U10", "I.4.9; I.5.4; I.2.7"], "primary_category": "cs.CV"}
{"title": "Do GPTs Produce Less Literal Translations?", "abstract": "Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose\nlanguage models capable of addressing many natural language generation or\nunderstanding tasks. On the task of Machine Translation (MT), multiple works\nhave investigated few-shot prompting mechanisms to elicit better translations\nfrom LLMs. However, there has been relatively little investigation on how such\ntranslations differ qualitatively from the translations generated by standard\nNeural Machine Translation (NMT) models. In this work, we investigate these\ndifferences in terms of the literalness of translations produced by the two\nsystems. Using literalness measures involving word alignment and monotonicity,\nwe find that translations out of English (E-X) from GPTs tend to be less\nliteral, while exhibiting similar or better scores on MT quality metrics. We\ndemonstrate that this finding is borne out in human evaluations as well. We\nthen show that these differences are especially pronounced when translating\nsentences that contain idiomatic expressions.", "published": "2023-05-26 10:38:31", "link": "http://arxiv.org/abs/2305.16806v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improved Visual Story Generation with Adaptive Context Modeling", "abstract": "Diffusion models developed on top of powerful text-to-image generation models\nlike Stable Diffusion achieve remarkable success in visual story generation.\nHowever, the best-performing approach considers historically generated results\nas flattened memory cells, ignoring the fact that not all preceding images\ncontribute equally to the generation of the characters and scenes at the\ncurrent stage. To address this, we present a simple method that improves the\nleading system with adaptive context modeling, which is not only incorporated\nin the encoder but also adopted as additional guidance in the sampling stage to\nboost the global consistency of the generated story. We evaluate our model on\nPororoSV and FlintstonesSV datasets and show that our approach achieves\nstate-of-the-art FID scores on both story visualization and continuation\nscenarios. We conduct detailed model analysis and show that our model excels at\ngenerating semantically consistent images for stories.", "published": "2023-05-26 10:43:42", "link": "http://arxiv.org/abs/2305.16811v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Domain Aligned Prefix Averaging for Domain Generalization in Abstractive\n  Summarization", "abstract": "Domain generalization is hitherto an underexplored area applied in\nabstractive summarization. Moreover, most existing works on domain\ngeneralization have sophisticated training algorithms. In this paper, we\npropose a lightweight, weight averaging based, Domain Aligned Prefix Averaging\napproach to domain generalization for abstractive summarization. Given a number\nof source domains, our method first trains a prefix for each one of them. These\nsource prefixes generate summaries for a small number of target domain\ndocuments. The similarity of the generated summaries to their corresponding\ndocuments is used for calculating weights required to average source prefixes.\nIn DAPA, prefix tuning allows for lightweight finetuning, and weight averaging\nallows for the computationally efficient addition of new source domains. When\nevaluated on four diverse summarization domains, DAPA shows comparable or\nbetter performance against the baselines, demonstrating the effectiveness of\nits prefix averaging scheme.", "published": "2023-05-26 11:02:38", "link": "http://arxiv.org/abs/2305.16820v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring", "abstract": "Automated essay scoring (AES) aims to score essays written for a given\nprompt, which defines the writing topic. Most existing AES systems assume to\ngrade essays of the same prompt as used in training and assign only a holistic\nscore. However, such settings conflict with real-education situations;\npre-graded essays for a particular prompt are lacking, and detailed trait\nscores of sub-rubrics are required. Thus, predicting various trait scores of\nunseen-prompt essays (called cross-prompt essay trait scoring) is a remaining\nchallenge of AES. In this paper, we propose a robust model: prompt- and trait\nrelation-aware cross-prompt essay trait scorer. We encode prompt-aware essay\nrepresentation by essay-prompt attention and utilizing the topic-coherence\nfeature extracted by the topic-modeling mechanism without access to labeled\ndata; therefore, our model considers the prompt adherence of an essay, even in\na cross-prompt setting. To facilitate multi-trait scoring, we design\ntrait-similarity loss that encapsulates the correlations of traits. Experiments\nprove the efficacy of our model, showing state-of-the-art results for all\nprompts and traits. Significant improvements in low-resource-prompt and\ninferior traits further indicate our model's strength.", "published": "2023-05-26 11:11:19", "link": "http://arxiv.org/abs/2305.16826v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Controlling Learned Effects to Reduce Spurious Correlations in Text\n  Classifiers", "abstract": "To address the problem of NLP classifiers learning spurious correlations\nbetween training features and target labels, a common approach is to make the\nmodel's predictions invariant to these features. However, this can be\ncounter-productive when the features have a non-zero causal effect on the\ntarget label and thus are important for prediction. Therefore, using methods\nfrom the causal inference literature, we propose an algorithm to regularize the\nlearnt effect of the features on the model's prediction to the estimated effect\nof feature on label. This results in an automated augmentation method that\nleverages the estimated effect of a feature to appropriately change the labels\nfor new augmented inputs. On toxicity and IMDB review datasets, the proposed\nalgorithm minimises spurious correlations and improves the minority group\n(i.e., samples breaking spurious correlations) accuracy, while also improving\nthe total accuracy compared to standard training.", "published": "2023-05-26 12:15:54", "link": "http://arxiv.org/abs/2305.16863v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "UMSE: Unified Multi-scenario Summarization Evaluation", "abstract": "Summarization quality evaluation is a non-trivial task in text summarization.\nContemporary methods can be mainly categorized into two scenarios: (1)\nreference-based: evaluating with human-labeled reference summary; (2)\nreference-free: evaluating the summary consistency of the document. Recent\nstudies mainly focus on one of these scenarios and explore training neural\nmodels built on PLMs to align with human criteria. However, the models from\ndifferent scenarios are optimized individually, which may result in sub-optimal\nperformance since they neglect the shared knowledge across different scenarios.\nBesides, designing individual models for each scenario caused inconvenience to\nthe user. Inspired by this, we propose Unified Multi-scenario Summarization\nEvaluation Model (UMSE). More specifically, we propose a perturbed prefix\ntuning method to share cross-scenario knowledge between scenarios and use a\nself-supervised training paradigm to optimize the model without extra human\nlabeling. Our UMSE is the first unified summarization evaluation framework\nengaged with the ability to be used in three evaluation scenarios. Experimental\nresults across three typical scenarios on the benchmark dataset SummEval\nindicate that our UMSE can achieve comparable performance with several existing\nstrong methods which are specifically designed for each scenario.", "published": "2023-05-26 12:54:44", "link": "http://arxiv.org/abs/2305.16895v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TranSFormer: Slow-Fast Transformer for Machine Translation", "abstract": "Learning multiscale Transformer models has been evidenced as a viable\napproach to augmenting machine translation systems. Prior research has\nprimarily focused on treating subwords as basic units in developing such\nsystems. However, the incorporation of fine-grained character-level features\ninto multiscale Transformer has not yet been explored. In this work, we present\na \\textbf{S}low-\\textbf{F}ast two-stream learning model, referred to as\nTran\\textbf{SF}ormer, which utilizes a ``slow'' branch to deal with subword\nsequences and a ``fast'' branch to deal with longer character sequences. This\nmodel is efficient since the fast branch is very lightweight by reducing the\nmodel width, and yet provides useful fine-grained features for the slow branch.\nOur TranSFormer shows consistent BLEU improvements (larger than 1 BLEU point)\non several machine translation benchmarks.", "published": "2023-05-26 14:37:38", "link": "http://arxiv.org/abs/2305.16982v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-shot Visual Question Answering with Language Model Feedback", "abstract": "In this paper, we propose a novel language model guided captioning approach,\nLAMOC, for knowledge-based visual question answering (VQA). Our approach\nemploys the generated captions by a captioning model as the context of an\nanswer prediction model, which is a Pre-trained Language model (PLM). As the\nmajor contribution, we leverage the guidance and feedback of the prediction\nmodel to improve the capability of the captioning model. In this way, the\ncaptioning model can become aware of the task goal and information need from\nthe PLM. To develop our approach, we design two specific training stages, where\nthe first stage adapts the captioning model to the prediction model (selecting\nmore suitable caption propositions for training) and the second stage tunes the\ncaptioning model according to the task goal (learning from feedback of the\nPLM). Extensive experiments demonstrate the effectiveness of the proposed\napproach on the knowledge-based VQA task. Specifically, on the challenging\nA-OKVQA dataset, LAMOC outperforms several competitive zero-shot methods and\neven achieves comparable results to a fine-tuned VLP model. Our code is\npublicly available at https://github.com/RUCAIBox/LAMOC.", "published": "2023-05-26 15:04:20", "link": "http://arxiv.org/abs/2305.17006v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Diable: Efficient Dialogue State Tracking as Operations on Tables", "abstract": "Sequence-to-sequence state-of-the-art systems for dialogue state tracking\n(DST) use the full dialogue history as input, represent the current state as a\nlist with all the slots, and generate the entire state from scratch at each\ndialogue turn. This approach is inefficient, especially when the number of\nslots is large and the conversation is long. We propose Diable, a new task\nformalisation that simplifies the design and implementation of efficient DST\nsystems and allows one to easily plug and play large language models. We\nrepresent the dialogue state as a table and formalise DST as a table\nmanipulation task. At each turn, the system updates the previous state by\ngenerating table operations based on the dialogue context. Extensive\nexperimentation on the MultiWoz datasets demonstrates that Diable (i)\noutperforms strong efficient DST baselines, (ii) is 2.4x more time efficient\nthan current state-of-the-art methods while retaining competitive Joint Goal\nAccuracy, and (iii) is robust to noisy data annotations due to the table\noperations approach.", "published": "2023-05-26 15:26:12", "link": "http://arxiv.org/abs/2305.17020v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Powerful are Decoder-Only Transformer Neural Models?", "abstract": "In this article we prove that the general transformer neural model\nundergirding modern large language models (LLMs) is Turing complete under\nreasonable assumptions. This is the first work to directly address the Turing\ncompleteness of the underlying technology employed in GPT-x as past work has\nfocused on the more expressive, full auto-encoder transformer architecture.\nFrom this theoretical analysis, we show that the sparsity/compressibility of\nthe word embedding is an important consideration for Turing completeness to\nhold. We also show that Transformers are are a variant of B machines studied by\nHao Wang.", "published": "2023-05-26 15:35:43", "link": "http://arxiv.org/abs/2305.17026v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Mechanism for Sample-Efficient In-Context Learning for Sparse\n  Retrieval Tasks", "abstract": "We study the phenomenon of \\textit{in-context learning} (ICL) exhibited by\nlarge language models, where they can adapt to a new learning task, given a\nhandful of labeled examples, without any explicit parameter optimization. Our\ngoal is to explain how a pre-trained transformer model is able to perform ICL\nunder reasonable assumptions on the pre-training process and the downstream\ntasks. We posit a mechanism whereby a transformer can achieve the following:\n(a) receive an i.i.d. sequence of examples which have been converted into a\nprompt using potentially-ambiguous delimiters, (b) correctly segment the prompt\ninto examples and labels, (c) infer from the data a \\textit{sparse linear\nregressor} hypothesis, and finally (d) apply this hypothesis on the given test\nexample and return a predicted label. We establish that this entire procedure\nis implementable using the transformer mechanism, and we give sample complexity\nguarantees for this learning framework. Our empirical findings validate the\nchallenge of segmentation, and we show a correspondence between our posited\nmechanisms and observed attention maps for step (c).", "published": "2023-05-26 15:49:43", "link": "http://arxiv.org/abs/2305.17040v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RFiD: Towards Rational Fusion-in-Decoder for Open-Domain Question\n  Answering", "abstract": "Open-Domain Question Answering (ODQA) systems necessitate a reader model\ncapable of generating answers by simultaneously referring to multiple passages.\nAlthough representative models like Fusion-in-Decoder (FiD) have been proposed\nto address this challenge, these systems can inadvertently rely on spurious\nfeatures instead of genuine causal relationships between the question and the\npassages to generate answers. To counter this problem, we introduce the\nRational Fusion-in-Decoder (RFiD) model. Our model leverages the encoders of\nFiD to differentiate between causal relationships and spurious features,\nsubsequently guiding the decoder to generate answers informed by this\ndiscernment. Experimental results on two ODQA datasets, Natural Questions (NQ)\nand TriviaQA (TQ), demonstrate that our model surpasses previous methods,\nachieving improvements of up to 1.5 and 0.7 in Exact Match scores on NQ, and\nexhibits an enhanced ability to identify causal relationships.", "published": "2023-05-26 15:51:25", "link": "http://arxiv.org/abs/2305.17041v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Stereotypes and Smut: The (Mis)representation of Non-cisgender\n  Identities by Text-to-Image Models", "abstract": "Cutting-edge image generation has been praised for producing high-quality\nimages, suggesting a ubiquitous future in a variety of applications. However,\ninitial studies have pointed to the potential for harm due to predictive bias,\nreflecting and potentially reinforcing cultural stereotypes. In this work, we\nare the first to investigate how multimodal models handle diverse gender\nidentities. Concretely, we conduct a thorough analysis in which we compare the\noutput of three image generation models for prompts containing cisgender vs.\nnon-cisgender identity terms. Our findings demonstrate that certain\nnon-cisgender identities are consistently (mis)represented as less human, more\nstereotyped and more sexualised. We complement our experimental analysis with\n(a)~a survey among non-cisgender individuals and (b) a series of interviews, to\nestablish which harms affected individuals anticipate, and how they would like\nto be represented. We find respondents are particularly concerned about\nmisrepresentation, and the potential to drive harmful behaviours and beliefs.\nSimple heuristics to limit offensive content are widely rejected, and instead\nrespondents call for community involvement, curated training data and the\nability to customise. These improvements could pave the way for a future where\nchange is led by the affected community, and technology is used to positively\n``[portray] queerness in ways that we haven't even thought of'' rather than\nreproducing stale, offensive stereotypes.", "published": "2023-05-26 16:28:49", "link": "http://arxiv.org/abs/2305.17072v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Learning and Leveraging Verifiers to Improve Planning Capabilities of\n  Pre-trained Language Models", "abstract": "There have been wide spread claims in the literature about the emergent\nreasoning capabilities of Pretrained Large Language Models. However, recent\nstudies, have found that their ability to plan remains questionable. Through\nour experiments using GPT-2, we empirically demonstrate that the performance of\na finetuned baseline remains poor because it violates pre-conditions of actions\nin the plans that it generates. To improve the planning capabilities of a\nfinetuned LLM, we train a verifier, which can classify actions as being valid\nor invalid in a particular state. By randomly sampling actions from the same\ndataset, we generate examples of invalid actions which are then used to train a\nverifier which can check for action applicability. In the presence of diverse\nsampling from a generator and a verifier which can prune invalid trajectories,\nwe show significant gains in the success rate on the Blocksworld domain.\nAdditionally, we show that finetuning the GPT-2 generator itself to create the\nverifier generalizes better than finetuning the base GPT-2. Lastly, we\ninvestigate the role of the sampling temperature which can be used to control\nthe exploration-exploitation tradeoff.", "published": "2023-05-26 16:36:55", "link": "http://arxiv.org/abs/2305.17077v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BiomedGPT: A Generalist Vision-Language Foundation Model for Diverse\n  Biomedical Tasks", "abstract": "Traditional biomedical artificial intelligence (AI) models, designed for\nspecific tasks or modalities, often exhibit limited flexibility in real-world\ndeployment and struggle to utilize holistic information. Generalist AI holds\nthe potential to address these limitations due to its versatility in\ninterpreting different data types and generating tailored outputs for diverse\nneeds. However, existing biomedical generalist AI solutions are typically\nheavyweight and closed source to researchers, practitioners, and patients.\nHere, we propose BiomedGPT, the first open-source and lightweight\nvision-language foundation model, designed as a generalist capable of\nperforming various biomedical tasks. BiomedGPT achieved state-of-the-art\nresults in 16 out of 25 experiments while maintaining a computing-friendly\nmodel scale. We also conducted human evaluations to assess the capabilities of\nBiomedGPT in radiology visual question answering, report generation, and\nsummarization. BiomedGPT exhibits robust prediction ability with a low error\nrate of 3.8% in question answering, satisfactory performance with an error rate\nof 8.3% in writing complex radiology reports, and competitive summarization\nability with a nearly equivalent preference score to human experts. Our method\ndemonstrates that effective training with diverse data can lead to more\npractical biomedical AI for improving diagnosis and workflow efficiency.", "published": "2023-05-26 17:14:43", "link": "http://arxiv.org/abs/2305.17100v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving accuracy of GPT-3/4 results on biomedical data using a\n  retrieval-augmented language model", "abstract": "Large language models (LLMs) have made significant advancements in natural\nlanguage processing (NLP). Broad corpora capture diverse patterns but can\nintroduce irrelevance, while focused corpora enhance reliability by reducing\nmisleading information. Training LLMs on focused corpora poses computational\nchallenges. An alternative approach is to use a retrieval-augmentation (RetA)\nmethod tested in a specific domain.\n  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a\ncustom RetA model were compared using 19 questions on diffuse large B-cell\nlymphoma (DLBCL) disease. Eight independent reviewers assessed responses based\non accuracy, relevance, and readability (rated 1-3).\n  The RetA model performed best in accuracy (12/19 3-point scores, total=47)\nand relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4\nreceived the highest readability scores (17/19, 55), followed by GPT-3 (15/19,\n53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),\nrelevance (32), and readability (38).\n  Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared\nto the RetA model and Prometheus. Hallucinations were mostly associated with\nnon-existent references or fabricated efficacy data.\n  These findings suggest that RetA models, supplemented with domain-specific\ncorpora, may outperform general-purpose LLMs in accuracy and relevance within\nspecific domains. However, this evaluation was limited to specific questions\nand metrics and may not capture challenges in semantic search and other NLP\ntasks. Further research will explore different LLM architectures, RetA\nmethodologies, and evaluation methods to assess strengths and limitations more\ncomprehensively.", "published": "2023-05-26 17:33:05", "link": "http://arxiv.org/abs/2305.17116v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for\n  LLM KV Cache Compression at Test Time", "abstract": "Large language models(LLMs) have sparked a new wave of exciting AI\napplications. Hosting these models at scale requires significant memory\nresources. One crucial memory bottleneck for the deployment stems from the\ncontext window. It is commonly recognized that model weights are memory hungry;\nhowever, the size of key-value embedding stored during the generation process\n(KV cache) can easily surpass the model size. The enormous size of the KV cache\nputs constraints on the inference batch size, which is crucial for high\nthroughput inference workload. Inspired by an interesting observation of the\nattention scores, we hypothesize the persistence of importance: only pivotal\ntokens, which had a substantial influence at one step, will significantly\ninfluence future generations. Based on our empirical verification and\ntheoretical analysis around this hypothesis, we propose Scissorhands, a system\nthat maintains the memory usage of the KV cache at a fixed budget without\nfinetuning the model. In essence, Scissorhands manages the KV cache by storing\nthe pivotal tokens with a higher probability. We validate that Scissorhands\nreduces the inference memory usage of the KV cache by up to 5X without\ncompromising model quality. We further demonstrate that Scissorhands can be\ncombined with 4-bit quantization, traditionally used to compress model weights,\nto achieve up to 20X compression.", "published": "2023-05-26 17:39:58", "link": "http://arxiv.org/abs/2305.17118v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language\n  Models", "abstract": "Dogwhistles are coded expressions that simultaneously convey one meaning to a\nbroad audience and a second one, often hateful or provocative, to a narrow\nin-group; they are deployed to evade both political repercussions and\nalgorithmic content moderation. For example, in the sentence 'we need to end\nthe cosmopolitan experiment,' the word 'cosmopolitan' likely means 'worldly' to\nmany, but secretly means 'Jewish' to a select few. We present the first\nlarge-scale computational investigation of dogwhistles. We develop a typology\nof dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles\nwith rich contextual information and examples, and analyze their usage in\nhistorical U.S. politicians' speeches. We then assess whether a large language\nmodel (GPT-3) can identify dogwhistles and their meanings, and find that\nGPT-3's performance varies widely across types of dogwhistles and targeted\ngroups. Finally, we show that harmful content containing dogwhistles avoids\ntoxicity detection, highlighting online risks of such coded language. This work\nsheds light on the theoretical and applied importance of dogwhistles in both\nNLP and computational social science, and provides resources for future\nresearch in modeling dogwhistles and mitigating their online harms.", "published": "2023-05-26 18:00:57", "link": "http://arxiv.org/abs/2305.17174v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "On the Copying Problem of Unsupervised NMT: A Training Schedule with a\n  Language Discriminator Loss", "abstract": "Although unsupervised neural machine translation (UNMT) has achieved success\nin many language pairs, the copying problem, i.e., directly copying some parts\nof the input sentence as the translation, is common among distant language\npairs, especially when low-resource languages are involved. We find this issue\nis closely related to an unexpected copying behavior during online\nback-translation (BT). In this work, we propose a simple but effective training\nschedule that incorporates a language discriminator loss. The loss imposes\nconstraints on the intermediate translation so that the translation is in the\ndesired language. By conducting extensive experiments on different language\npairs, including similar and distant, high and low-resource languages, we find\nthat our method alleviates the copying problem, thus improving the translation\nperformance on low-resource languages.", "published": "2023-05-26 18:14:23", "link": "http://arxiv.org/abs/2305.17182v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document\n  AMR Parsing", "abstract": "The sliding window approach provides an elegant way to handle contexts of\nsizes larger than the Transformer's input window, for tasks like language\nmodeling. Here we extend this approach to the sequence-to-sequence task of\ndocument parsing. For this, we exploit recent progress in transition-based\nparsing to implement a parser with synchronous sliding windows over source and\ntarget. We develop an oracle and a parser for document-level AMR by expanding\non Structured-BART such that it leverages source-target alignments and\nconstrains decoding to guarantee synchronicity and consistency across\noverlapping windows. We evaluate our oracle and parser using the Abstract\nMeaning Representation (AMR) parsing 3.0 corpus. On the Multi-Sentence\ndevelopment set of AMR 3.0, we show that our transition oracle loses only 8\\%\nof the gold cross-sentential links despite using a sliding window. In practice,\nthis approach also results in a high-quality document-level parser with\nmanageable memory requirements. Our proposed system performs on par with the\nstate-of-the-art pipeline approach for document-level AMR parsing task on\nMulti-Sentence AMR 3.0 corpus while maintaining sentence-level parsing\nperformance.", "published": "2023-05-26 21:38:08", "link": "http://arxiv.org/abs/2305.17273v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HowkGPT: Investigating the Detection of ChatGPT-generated University\n  Student Homework through Context-Aware Perplexity Analysis", "abstract": "As the use of Large Language Models (LLMs) in text generation tasks\nproliferates, concerns arise over their potential to compromise academic\nintegrity. The education sector currently tussles with distinguishing\nstudent-authored homework assignments from AI-generated ones. This paper\naddresses the challenge by introducing HowkGPT, designed to identify homework\nassignments generated by AI. HowkGPT is built upon a dataset of academic\nassignments and accompanying metadata [17] and employs a pretrained LLM to\ncompute perplexity scores for student-authored and ChatGPT-generated responses.\nThese scores then assist in establishing a threshold for discerning the origin\nof a submitted assignment. Given the specificity and contextual nature of\nacademic work, HowkGPT further refines its analysis by defining\ncategory-specific thresholds derived from the metadata, enhancing the precision\nof the detection. This study emphasizes the critical need for effective\nstrategies to uphold academic integrity amidst the growing influence of LLMs\nand provides an approach to ensuring fair and accurate grading in educational\ninstitutions.", "published": "2023-05-26 11:07:25", "link": "http://arxiv.org/abs/2305.18226v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Study on Knowledge Distillation from Weak Teacher for Scaling Up\n  Pre-trained Language Models", "abstract": "Distillation from Weak Teacher (DWT) is a method of transferring knowledge\nfrom a smaller, weaker teacher model to a larger student model to improve its\nperformance. Previous studies have shown that DWT can be effective in the\nvision domain and natural language processing (NLP) pre-training stage.\nSpecifically, DWT shows promise in practical scenarios, such as enhancing new\ngeneration or larger models using pre-trained yet older or smaller models and\nlacking a resource budget. However, the optimal conditions for using DWT have\nyet to be fully investigated in NLP pre-training. Therefore, this study\nexamines three key factors to optimize DWT, distinct from those used in the\nvision domain or traditional knowledge distillation. These factors are: (i) the\nimpact of teacher model quality on DWT effectiveness, (ii) guidelines for\nadjusting the weighting value for DWT loss, and (iii) the impact of parameter\nremapping as a student model initialization technique for DWT.", "published": "2023-05-26 13:24:49", "link": "http://arxiv.org/abs/2305.18239v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and\n  the Importance of Object-based Representations", "abstract": "Can a Large Language Model (LLM) solve simple abstract reasoning problems? We\nexplore this broad question through a systematic analysis of GPT on the\nAbstraction and Reasoning Corpus (ARC), a representative benchmark of abstract\nreasoning ability from limited examples in which solutions require some \"core\nknowledge\" of concepts such as objects, goal states, counting, and basic\ngeometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when\nusing textual encodings for their two-dimensional input-output grids. Our\nfailure analysis reveals that GPT-4's capacity to identify objects and reason\nabout them is significantly influenced by the sequential nature of the text\nthat represents an object within a text encoding of a task. To test this\nhypothesis, we design a new benchmark, the 1D-ARC, which consists of\none-dimensional (array-like) tasks that are more conducive to GPT-based\nreasoning, and where it indeed performs better than on the (2D) ARC. To\nalleviate this issue, we propose an object-based representation that is\nobtained through an external tool, resulting in nearly doubling the performance\non solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the\nstate-of-the-art GPT-4 is unable to \"reason\" perfectly within non-language\ndomains such as the 1D-ARC or a simple ARC subset, our study reveals that the\nuse of object-based representations can significantly improve its reasoning\nability. Visualizations, GPT logs, and data are available at\nhttps://khalil-research.github.io/LLM4ARC.", "published": "2023-05-26 16:32:17", "link": "http://arxiv.org/abs/2305.18354v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in\n  Class-incremental Information Extraction", "abstract": "Class-incremental learning (CIL) aims to develop a learning system that can\ncontinually learn new classes from a data stream without forgetting previously\nlearned classes. When learning classes incrementally, the classifier must be\nconstantly updated to incorporate new classes, and the drift in decision\nboundary may lead to severe forgetting. This fundamental challenge, however,\nhas not yet been studied extensively, especially in the setting where no\nsamples from old classes are stored for rehearsal. In this paper, we take a\ncloser look at how the drift in the classifier leads to forgetting, and\naccordingly, design four simple yet (super-) effective solutions to alleviate\nthe classifier drift: an Individual Classifiers with Frozen Feature Extractor\n(ICE) framework where we individually train a classifier for each learning\nsession, and its three variants ICE-PL, ICE-O, and ICE-PL&O which further take\nthe logits of previously learned classes from old sessions or a constant logit\nof an Other class as a constraint to the learning of new classifiers. Extensive\nexperiments and analysis on 6 class-incremental information extraction tasks\ndemonstrate that our solutions, especially ICE-O, consistently show significant\nimprovement over the previous state-of-the-art approaches with up to 44.7%\nabsolute F-score gain, providing a strong baseline and insights for future\nresearch on class-incremental learning.", "published": "2023-05-26 00:57:43", "link": "http://arxiv.org/abs/2305.16559v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Architecture Search for Parameter-Efficient Fine-tuning of Large\n  Pre-trained Language Models", "abstract": "Parameter-efficient tuning (PET) methods fit pre-trained language models\n(PLMs) to downstream tasks by either computing a small compressed update for a\nsubset of model parameters, or appending and fine-tuning a small number of new\nmodel parameters to the pre-trained network. Hand-designed PET architectures\nfrom the literature perform well in practice, but have the potential to be\nimproved via automated neural architecture search (NAS). We propose an\nefficient NAS method for learning PET architectures via structured and\nunstructured pruning. We present experiments on GLUE demonstrating the\neffectiveness of our algorithm and discuss how PET architectural design choices\naffect performance in practice.", "published": "2023-05-26 03:01:07", "link": "http://arxiv.org/abs/2305.16597v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Efficient Detection of LLM-generated Texts with a Bayesian Surrogate\n  Model", "abstract": "The detection of machine-generated text, especially from large language\nmodels (LLMs), is crucial in preventing serious social problems resulting from\ntheir misuse. Some methods train dedicated detectors on specific datasets but\nfall short in generalizing to unseen test data, while other zero-shot ones\noften yield suboptimal performance. Although the recent DetectGPT has shown\npromising detection performance, it suffers from significant inefficiency\nissues, as detecting a single candidate requires querying the source LLM with\nhundreds of its perturbations. This paper aims to bridge this gap. Concretely,\nwe propose to incorporate a Bayesian surrogate model, which allows us to select\ntypical samples based on Bayesian uncertainty and interpolate scores from\ntypical samples to other samples, to improve query efficiency. Empirical\nresults demonstrate that our method significantly outperforms existing\napproaches under a low query budget. Notably, when detecting the text generated\nby LLaMA family models, our method with just 2 or 3 queries can outperform\nDetectGPT with 200 queries.", "published": "2023-05-26 04:23:10", "link": "http://arxiv.org/abs/2305.16617v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Impossible Distillation: from Low-Quality Model to High-Quality Dataset\n  & Model for Summarization and Paraphrasing", "abstract": "We present Impossible Distillation, a novel framework for paraphrasing and\nsentence summarization, that distills a high-quality dataset and model from a\nlow-quality teacher that itself cannot perform these tasks. Unlike prior works\nthat rely on an extreme-scale teacher model (e.g., GPT3) or task-specific\narchitecture, we hypothesize and verify the paraphrastic proximity intrinsic to\npre-trained LMs (e.g., GPT2), where paraphrases occupy a proximal subspace in\nthe LM distribution. By identifying and distilling generations from these\nsubspaces, Impossible Distillation produces a high-quality dataset and model\neven from GPT2-scale LMs. We evaluate our method on multiple benchmarks\nspanning unconstrained / syntax-controlled paraphrase generation and sentence\nsummarization. Our model with 770M parameters consistently outperforms strong\nbaselines, including models distilled from ChatGPT, and sometimes, even ChatGPT\nitself. Also, we find that our distilled dataset from 1.5B LMs exhibits higher\ndiversity and fidelity than up to 13 times larger datasets.", "published": "2023-05-26 05:19:24", "link": "http://arxiv.org/abs/2305.16635v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DataFinder: Scientific Dataset Recommendation from Natural Language\n  Descriptions", "abstract": "Modern machine learning relies on datasets to develop and validate research\nideas. Given the growth of publicly available data, finding the right dataset\nto use is increasingly difficult. Any research question imposes explicit and\nimplicit constraints on how well a given dataset will enable researchers to\nanswer this question, such as dataset size, modality, and domain. We\noperationalize the task of recommending datasets given a short natural language\ndescription of a research idea, to help people find relevant datasets for their\nneeds. Dataset recommendation poses unique challenges as an information\nretrieval problem; datasets are hard to directly index for search and there are\nno corpora readily available for this task. To facilitate this task, we build\nthe DataFinder Dataset which consists of a larger automatically-constructed\ntraining set (17.5K queries) and a smaller expert-annotated evaluation set (392\nqueries). Using this data, we compare various information retrieval algorithms\non our test set and present a superior bi-encoder retriever for text-based\ndataset recommendation. This system, trained on the DataFinder Dataset, finds\nmore relevant search results than existing third-party dataset search engines.\nTo encourage progress on dataset recommendation, we release our dataset and\nmodels to the public.", "published": "2023-05-26 05:22:36", "link": "http://arxiv.org/abs/2305.16636v2", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Language Models Can Improve Event Prediction by Few-Shot Abductive\n  Reasoning", "abstract": "Large language models have shown astonishing performance on a wide range of\nreasoning tasks. In this paper, we investigate whether they could reason about\nreal-world events and help improve the prediction performance of event sequence\nmodels. We design LAMP, a framework that integrates a large language model in\nevent prediction. Particularly, the language model performs abductive reasoning\nto assist an event sequence model: the event model proposes predictions on\nfuture events given the past; instructed by a few expert-annotated\ndemonstrations, the language model learns to suggest possible causes for each\nproposal; a search module finds out the previous events that match the causes;\na scoring function learns to examine whether the retrieved events could\nactually cause the proposal. Through extensive experiments on several\nchallenging real-world datasets, we demonstrate that our framework -- thanks to\nthe reasoning capabilities of large language models -- could significantly\noutperform the state-of-the-art event sequence models.", "published": "2023-05-26 05:32:29", "link": "http://arxiv.org/abs/2305.16646v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AdaPlanner: Adaptive Planning from Feedback with Language Models", "abstract": "Large language models (LLMs) have recently demonstrated the potential in\nacting as autonomous agents for sequential decision-making tasks. However, most\nexisting methods either take actions greedily without planning or rely on\nstatic plans that are not adaptable to environmental feedback. Consequently,\nthe sequential decision-making performance of LLM agents degenerates with\nproblem complexity and plan horizons increase. We propose a closed-loop\napproach, AdaPlanner, which allows the LLM agent to refine its self-generated\nplan adaptively in response to environmental feedback. In AdaPlanner, the LLM\nagent adaptively refines its plan from feedback with both in-plan and\nout-of-plan refinement strategies. To mitigate hallucination, we develop a\ncode-style LLM prompt structure that facilitates plan generation across a\nvariety of tasks, environments, and agent capabilities. Furthermore, we propose\na skill discovery mechanism that leverages successful plans as few-shot\nexemplars, enabling the agent to plan and refine with fewer task\ndemonstrations. Our experiments in the ALFWorld and MiniWoB++ environments\ndemonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and\n4.11% while utilizing 2x and 600x fewer samples, respectively.", "published": "2023-05-26 05:52:27", "link": "http://arxiv.org/abs/2305.16653v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Score-balanced Loss for Multi-aspect Pronunciation Assessment", "abstract": "With rapid technological growth, automatic pronunciation assessment has\ntransitioned toward systems that evaluate pronunciation in various aspects,\nsuch as fluency and stress. However, despite the highly imbalanced score labels\nwithin each aspect, existing studies have rarely tackled the data imbalance\nproblem. In this paper, we suggest a novel loss function, score-balanced loss,\nto address the problem caused by uneven data, such as bias toward the majority\nscores. As a re-weighting approach, we assign higher costs when the predicted\nscore is of the minority class, thus, guiding the model to gain positive\nfeedback for sparse score prediction. Specifically, we design two weighting\nfactors by leveraging the concept of an effective number of samples and using\nthe ranks of scores. We evaluate our method on the speechocean762 dataset,\nwhich has noticeably imbalanced scores for several aspects. Improved results\nparticularly on such uneven aspects prove the effectiveness of our method.", "published": "2023-05-26 06:21:37", "link": "http://arxiv.org/abs/2305.16664v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multiview Identifiers Enhanced Generative Retrieval", "abstract": "Instead of simply matching a query to pre-existing passages, generative\nretrieval generates identifier strings of passages as the retrieval target. At\na cost, the identifier must be distinctive enough to represent a passage.\nCurrent approaches use either a numeric ID or a text piece (such as a title or\nsubstrings) as the identifier. However, these identifiers cannot cover a\npassage's content well. As such, we are motivated to propose a new type of\nidentifier, synthetic identifiers, that are generated based on the content of a\npassage and could integrate contextualized information that text pieces lack.\nFurthermore, we simultaneously consider multiview identifiers, including\nsynthetic identifiers, titles, and substrings. These views of identifiers\ncomplement each other and facilitate the holistic ranking of passages from\nmultiple perspectives. We conduct a series of experiments on three public\ndatasets, and the results indicate that our proposed approach performs the best\nin generative retrieval, demonstrating its effectiveness and robustness.", "published": "2023-05-26 06:50:21", "link": "http://arxiv.org/abs/2305.16675v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Parameter-Efficient Fine-Tuning without Introducing New Latency", "abstract": "Parameter-efficient fine-tuning (PEFT) of pre-trained language models has\nrecently demonstrated remarkable achievements, effectively matching the\nperformance of full fine-tuning while utilizing significantly fewer trainable\nparameters, and consequently addressing the storage and communication\nconstraints. Nonetheless, various PEFT methods are limited by their inherent\ncharacteristics. In the case of sparse fine-tuning, which involves modifying\nonly a small subset of the existing parameters, the selection of fine-tuned\nparameters is task- and domain-specific, making it unsuitable for federated\nlearning. On the other hand, PEFT methods with adding new parameters typically\nintroduce additional inference latency. In this paper, we demonstrate the\nfeasibility of generating a sparse mask in a task-agnostic manner, wherein all\ndownstream tasks share a common mask. Our approach, which relies solely on the\nmagnitude information of pre-trained parameters, surpasses existing\nmethodologies by a significant margin when evaluated on the GLUE benchmark.\nAdditionally, we introduce a novel adapter technique that directly applies the\nadapter to pre-trained parameters instead of the hidden representation, thereby\nachieving identical inference speed to that of full fine-tuning. Through\nextensive experiments, our proposed method attains a new state-of-the-art\noutcome in terms of both performance and storage efficiency, storing only 0.03%\nparameters of full fine-tuning.", "published": "2023-05-26 08:44:42", "link": "http://arxiv.org/abs/2305.16742v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Incorporating Distributions of Discourse Structure for Long Document\n  Abstractive Summarization", "abstract": "For text summarization, the role of discourse structure is pivotal in\ndiscerning the core content of a text. Regrettably, prior studies on\nincorporating Rhetorical Structure Theory (RST) into transformer-based\nsummarization models only consider the nuclearity annotation, thereby\noverlooking the variety of discourse relation types. This paper introduces the\n'RSTformer', a novel summarization model that comprehensively incorporates both\nthe types and uncertainty of rhetorical relations. Our RST-attention mechanism,\nrooted in document-level rhetorical structure, is an extension of the recently\ndevised Longformer framework. Through rigorous evaluation, the model proposed\nherein exhibits significant superiority over state-of-the-art models, as\nevidenced by its notable performance on several automatic metrics and human\nevaluation.", "published": "2023-05-26 09:51:47", "link": "http://arxiv.org/abs/2305.16784v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GenQ: Automated Question Generation to Support Caregivers While Reading\n  Stories with Children", "abstract": "When caregivers ask open--ended questions to motivate dialogue with children,\nit facilitates the child's reading comprehension skills.Although there is scope\nfor use of technological tools, referred here as \"intelligent tutoring\nsystems\", to scaffold this process, it is currently unclear whether existing\nintelligent systems that generate human--language like questions is beneficial.\nAdditionally, training data used in the development of these automated question\ngeneration systems is typically sourced without attention to demographics, but\npeople with different cultural backgrounds may ask different questions. As a\npart of a broader project to design an intelligent reading support app for\nLatinx children, we crowdsourced questions from Latinx caregivers and\nnoncaregivers as well as caregivers and noncaregivers from other demographics.\nWe examine variations in question--asking within this dataset mediated by\nindividual, cultural, and contextual factors. We then design a system that\nautomatically extracts templates from this data to generate open--ended\nquestions that are representative of those asked by Latinx caregivers.", "published": "2023-05-26 10:42:21", "link": "http://arxiv.org/abs/2305.16809v3", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Randomized Positional Encodings Boost Length Generalization of\n  Transformers", "abstract": "Transformers have impressive generalization capabilities on tasks with a\nfixed context length. However, they fail to generalize to sequences of\narbitrary length, even for seemingly simple tasks such as duplicating a string.\nMoreover, simply training on longer sequences is inefficient due to the\nquadratic computation complexity of the global attention mechanism. In this\nwork, we demonstrate that this failure mode is linked to positional encodings\nbeing out-of-distribution for longer sequences (even for relative encodings)\nand introduce a novel family of positional encodings that can overcome this\nproblem. Concretely, our randomized positional encoding scheme simulates the\npositions of longer sequences and randomly selects an ordered subset to fit the\nsequence's length. Our large-scale empirical evaluation of 6000 models across\n15 algorithmic reasoning tasks shows that our method allows Transformers to\ngeneralize to sequences of unseen length (increasing test accuracy by 12.0% on\naverage).", "published": "2023-05-26 11:47:52", "link": "http://arxiv.org/abs/2305.16843v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Model-Based Simulation for Optimising Smart Reply", "abstract": "Smart Reply (SR) systems present a user with a set of replies, of which one\ncan be selected in place of having to type out a response. To perform well at\nthis task, a system should be able to effectively present the user with a\ndiverse set of options, to maximise the chance that at least one of them\nconveys the user's desired response. This is a significant challenge, due to\nthe lack of datasets containing sets of responses to learn from. Resultantly,\nprevious work has focused largely on post-hoc diversification, rather than\nexplicitly learning to predict sets of responses. Motivated by this problem, we\npresent a novel method SimSR, that employs model-based simulation to discover\nhigh-value response sets, through simulating possible user responses with a\nlearned world model. Unlike previous approaches, this allows our method to\ndirectly optimise the end-goal of SR--maximising the relevance of at least one\nof the predicted replies. Empirically on two public datasets, when compared to\nSoTA baselines, our method achieves up to 21% and 18% improvement in ROUGE\nscore and Self-ROUGE score respectively.", "published": "2023-05-26 12:04:33", "link": "http://arxiv.org/abs/2305.16852v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of\n  Thought Prompting", "abstract": "Large language models (LLMs) have achieved impressive performance on various\nreasoning tasks. To further improve the performance, we propose MultiTool-CoT,\na novel framework that leverages chain-of-thought (CoT) prompting to\nincorporate multiple external tools, such as a calculator and a knowledge\nretriever, during the reasoning process. We apply MultiTool-CoT to the Task 2\ndataset of NumGLUE, which requires both numerical reasoning and domain-specific\nknowledge. The experiments show that our method significantly outperforms\nstrong baselines and achieves state-of-the-art performance.", "published": "2023-05-26 13:00:58", "link": "http://arxiv.org/abs/2305.16896v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inter-connection: Effective Connection between Pre-trained Encoder and\n  Decoder for Speech Translation", "abstract": "In end-to-end speech translation, speech and text pre-trained models improve\ntranslation quality. Recently proposed models simply connect the pre-trained\nmodels of speech and text as encoder and decoder. Therefore, only the\ninformation from the final layer of encoders is input to the decoder. Since it\nis clear that the speech pre-trained model outputs different information from\neach layer, the simple connection method cannot fully utilize the information\nthat the speech pre-trained model has. In this study, we propose an\ninter-connection mechanism that aggregates the information from each layer of\nthe speech pre-trained model by weighted sums and inputs into the decoder. This\nmechanism increased BLEU by approximately 2 points in en-de, en-ja, and en-zh\nby increasing parameters by 2K when the speech pre-trained model was frozen.\nFurthermore, we investigated the contribution of each layer for each language\nby visualizing layer weights and found that the contributions were different.", "published": "2023-05-26 13:01:29", "link": "http://arxiv.org/abs/2305.16897v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Neural State-Space Model Approach to Efficient Speech Separation", "abstract": "In this work, we introduce S4M, a new efficient speech separation framework\nbased on neural state-space models (SSM). Motivated by linear time-invariant\nsystems for sequence modeling, our SSM-based approach can efficiently model\ninput signals into a format of linear ordinary differential equations (ODEs)\nfor representation learning. To extend the SSM technique into speech separation\ntasks, we first decompose the input mixture into multi-scale representations\nwith different resolutions. This mechanism enables S4M to learn globally\ncoherent separation and reconstruction. The experimental results show that S4M\nperforms comparably to other separation backbones in terms of SI-SDRi, while\nhaving a much lower model complexity with significantly fewer trainable\nparameters. In addition, our S4M-tiny model (1.8M parameters) even surpasses\nattention-based Sepformer (26.0M parameters) in noisy conditions with only 9.2\nof multiply-accumulate operation (MACs).", "published": "2023-05-26 13:47:11", "link": "http://arxiv.org/abs/2305.16932v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Finspector: A Human-Centered Visual Inspection Tool for Exploring and\n  Comparing Biases among Foundation Models", "abstract": "Pre-trained transformer-based language models are becoming increasingly\npopular due to their exceptional performance on various benchmarks. However,\nconcerns persist regarding the presence of hidden biases within these models,\nwhich can lead to discriminatory outcomes and reinforce harmful stereotypes. To\naddress this issue, we propose Finspector, a human-centered visual inspection\ntool designed to detect biases in different categories through log-likelihood\nscores generated by language models. The goal of the tool is to enable\nresearchers to easily identify potential biases using visual analytics,\nultimately contributing to a fairer and more just deployment of these models in\nboth academic and industrial settings. Finspector is available at\nhttps://github.com/IBM/finspector.", "published": "2023-05-26 13:53:15", "link": "http://arxiv.org/abs/2305.16937v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "DisfluencyFixer: A tool to enhance Language Learning through Speech To\n  Speech Disfluency Correction", "abstract": "Conversational speech often consists of deviations from the speech plan,\nproducing disfluent utterances that affect downstream NLP tasks. Removing these\ndisfluencies is necessary to create fluent and coherent speech. This paper\npresents DisfluencyFixer, a tool that performs speech-to-speech disfluency\ncorrection in English and Hindi using a pipeline of Automatic Speech\nRecognition (ASR), Disfluency Correction (DC) and Text-To-Speech (TTS) models.\nOur proposed system removes disfluencies from input speech and returns fluent\nspeech as output along with its transcript, disfluency type and total\ndisfluency count in source utterance, providing a one-stop destination for\nlanguage learners to improve the fluency of their speech. We evaluate the\nperformance of our tool subjectively and receive scores of 4.26, 4.29 and 4.42\nout of 5 in ASR performance, DC performance and ease-of-use of the system. Our\ntool can be accessed openly at the following link.", "published": "2023-05-26 14:13:38", "link": "http://arxiv.org/abs/2305.16957v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MixCE: Training Autoregressive Language Models by Mixing Forward and\n  Reverse Cross-Entropies", "abstract": "Autoregressive language models are trained by minimizing the cross-entropy of\nthe model distribution Q relative to the data distribution P -- that is,\nminimizing the forward cross-entropy, which is equivalent to maximum likelihood\nestimation (MLE). We have observed that models trained in this way may\n\"over-generalize\", in the sense that they produce non-human-like text.\nMoreover, we believe that reverse cross-entropy, i.e., the cross-entropy of P\nrelative to Q, is a better reflection of how a human would evaluate text\ngenerated by a model. Hence, we propose learning with MixCE, an objective that\nmixes the forward and reverse cross-entropies. We evaluate models trained with\nthis objective on synthetic data settings (where P is known) and real data, and\nshow that the resulting models yield better generated text without complex\ndecoding strategies. Our code and models are publicly available at\nhttps://github.com/bloomberg/mixce-acl2023", "published": "2023-05-26 14:14:51", "link": "http://arxiv.org/abs/2305.16958v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Socially Aligned Language Models on Simulated Social\n  Interactions", "abstract": "Social alignment in AI systems aims to ensure that these models behave\naccording to established societal values. However, unlike humans, who derive\nconsensus on value judgments through social interaction, current language\nmodels (LMs) are trained to rigidly replicate their training corpus in\nisolation, leading to subpar generalization in unfamiliar scenarios and\nvulnerability to adversarial attacks. This work presents a novel training\nparadigm that permits LMs to learn from simulated social interactions. In\ncomparison to existing methodologies, our approach is considerably more\nscalable and efficient, demonstrating superior performance in alignment\nbenchmarks and human evaluations. This paradigm shift in the training of LMs\nbrings us a step closer to developing AI systems that can robustly and\naccurately reflect societal norms and values.", "published": "2023-05-26 14:17:36", "link": "http://arxiv.org/abs/2305.16960v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large\n  Language Models", "abstract": "Trained with an unprecedented scale of data, large language models (LLMs)\nlike ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities\nfrom model scaling. Such a trend underscored the potential of training LLMs\nwith unlimited language data, advancing the development of a universal embodied\nagent. In this work, we introduce the NavGPT, a purely LLM-based\ninstruction-following navigation agent, to reveal the reasoning capability of\nGPT models in complex embodied scenes by performing zero-shot sequential action\nprediction for vision-and-language navigation (VLN). At each step, NavGPT takes\nthe textual descriptions of visual observations, navigation history, and future\nexplorable directions as inputs to reason the agent's current status, and makes\nthe decision to approach the target. Through comprehensive experiments, we\ndemonstrate NavGPT can explicitly perform high-level planning for navigation,\nincluding decomposing instruction into sub-goal, integrating commonsense\nknowledge relevant to navigation task resolution, identifying landmarks from\nobserved scenes, tracking navigation progress, and adapting to exceptions with\nplan adjustment. Furthermore, we show that LLMs is capable of generating\nhigh-quality navigational instructions from observations and actions along a\npath, as well as drawing accurate top-down metric trajectory given the agent's\nnavigation history. Despite the performance of using NavGPT to zero-shot R2R\ntasks still falling short of trained models, we suggest adapting multi-modality\ninputs for LLMs to use as visual navigation agents and applying the explicit\nreasoning of LLMs to benefit learning-based models.", "published": "2023-05-26 14:41:06", "link": "http://arxiv.org/abs/2305.16986v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Large Language Models as Tool Makers", "abstract": "Recent research has highlighted the potential of large language models (LLMs)\nto improve their problem-solving capabilities with the aid of suitable external\ntools. In our work, we further advance this concept by introducing a\nclosed-loop framework, referred to as LLMs A s Tool Makers (LATM), where LLMs\ncreate their own reusable tools for problem-solving. Our approach consists of\ntwo phases: 1) tool making: an LLM acts as the tool maker that crafts tools for\na set of tasks. 2) tool using: another LLM acts as the tool user, which applies\nthe tool built by the tool maker for problem-solving. On the problem-solving\nserver side, tool-making enables continual tool generation and caching as new\nrequests emerge. This framework enables subsequent requests to access cached\ntools via their corresponding APIs, enhancing the efficiency of task\nresolution. Recognizing that tool-making requires more sophisticated\ncapabilities, we assign this task to a powerful, albeit resource-intensive,\nmodel. Conversely, the simpler tool-using phase is delegated to a lightweight\nmodel. This strategic division of labor allows the once-off cost of tool-making\nto be spread over multiple instances of tool-using, significantly reducing\naverage costs while maintaining strong performance. Furthermore, our method\noffers a functional cache through the caching and reuse of tools, which stores\nthe functionality of a class of requests instead of the natural language\nresponses from LLMs, thus extending the applicability of the conventional cache\nmechanism. We evaluate our approach across various complex reasoning tasks,\nincluding Big-Bench tasks. With GPT-4 as the tool maker and GPT-3.5 as the tool\nuser, LATM demonstrates performance equivalent to using GPT-4 for both roles,\nbut with a significantly reduced inference cost.", "published": "2023-05-26 17:50:11", "link": "http://arxiv.org/abs/2305.17126v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Heterogeneous Value Alignment Evaluation for Large Language Models", "abstract": "The emergent capabilities of Large Language Models (LLMs) have made it\ncrucial to align their values with those of humans. However, current\nmethodologies typically attempt to assign value as an attribute to LLMs, yet\nlack attention to the ability to pursue value and the importance of\ntransferring heterogeneous values in specific practical applications. In this\npaper, we propose a Heterogeneous Value Alignment Evaluation (HVAE) system,\ndesigned to assess the success of aligning LLMs with heterogeneous values.\nSpecifically, our approach first brings the Social Value Orientation (SVO)\nframework from social psychology, which corresponds to how much weight a person\nattaches to the welfare of others in relation to their own. We then assign the\nLLMs with different social values and measure whether their behaviors align\nwith the inducing values. We conduct evaluations with new auto-metric\n\\textit{value rationality} to represent the ability of LLMs to align with\nspecific values. Evaluating the value rationality of five mainstream LLMs, we\ndiscern a propensity in LLMs towards neutral values over pronounced personal\nvalues. By examining the behavior of these LLMs, we contribute to a deeper\ninsight into the value alignment of LLMs within a heterogeneous value system.", "published": "2023-05-26 02:34:20", "link": "http://arxiv.org/abs/2305.17147v3", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Images with Multimodal Language Models", "abstract": "We propose a method to fuse frozen text-only large language models (LLMs)\nwith pre-trained image encoder and decoder models, by mapping between their\nembedding spaces. Our model demonstrates a wide suite of multimodal\ncapabilities: image retrieval, novel image generation, and multimodal dialogue.\nOurs is the first approach capable of conditioning on arbitrarily interleaved\nimage and text inputs to generate coherent image (and text) outputs. To achieve\nstrong performance on image generation, we propose an efficient mapping network\nto ground the LLM to an off-the-shelf text-to-image generation model. This\nmapping network translates hidden representations of text into the embedding\nspace of the visual models, enabling us to leverage the strong text\nrepresentations of the LLM for visual outputs. Our approach outperforms\nbaseline generation models on tasks with longer and more complex language. In\naddition to novel image generation, our model is also capable of image\nretrieval from a prespecified dataset, and decides whether to retrieve or\ngenerate at inference time. This is done with a learnt decision module which\nconditions on the hidden representations of the LLM. Our model exhibits a wider\nrange of capabilities compared to prior multimodal language models. It can\nprocess image-and-text inputs, and produce retrieved images, generated images,\nand generated text -- outperforming non-LLM based generation models across\nseveral text-to-image tasks that measure context dependence.", "published": "2023-05-26 19:22:03", "link": "http://arxiv.org/abs/2305.17216v3", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GVdoc: Graph-based Visual Document Classification", "abstract": "The robustness of a model for real-world deployment is decided by how well it\nperforms on unseen data and distinguishes between in-domain and out-of-domain\nsamples. Visual document classifiers have shown impressive performance on\nin-distribution test sets. However, they tend to have a hard time correctly\nclassifying and differentiating out-of-distribution examples. Image-based\nclassifiers lack the text component, whereas multi-modality transformer-based\nmodels face the token serialization problem in visual documents due to their\ndiverse layouts. They also require a lot of computing power during inference,\nmaking them impractical for many real-world applications. We propose, GVdoc, a\ngraph-based document classification model that addresses both of these\nchallenges. Our approach generates a document graph based on its layout, and\nthen trains a graph neural network to learn node and graph embeddings. Through\nexperiments, we show that our model, even with fewer parameters, outperforms\nstate-of-the-art models on out-of-distribution data while retaining comparable\nperformance on the in-distribution test set.", "published": "2023-05-26 19:23:20", "link": "http://arxiv.org/abs/2305.17219v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Federated Learning for Semantic Parsing: Task Formulation, Evaluation\n  Setup, New Algorithms", "abstract": "This paper studies a new task of federated learning (FL) for semantic\nparsing, where multiple clients collaboratively train one global model without\nsharing their semantic parsing data. By leveraging data from multiple clients,\nthe FL paradigm can be especially beneficial for clients that have little\ntraining data to develop a data-hungry neural semantic parser on their own. We\npropose an evaluation setup to study this task, where we re-purpose widely-used\nsingle-domain text-to-SQL datasets as clients to form a realistic heterogeneous\nFL setting and collaboratively train a global model. As standard FL algorithms\nsuffer from the high client heterogeneity in our realistic setup, we further\npropose a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to\nmitigate the performance degradation, which adjusts each client's contribution\nto the global model update based on its training loss reduction during each\nround. Our intuition is that the larger the loss reduction, the further away\nthe current global model is from the client's local optimum, and the larger\nweight the client should get. By applying Lorar to three widely adopted FL\nalgorithms (FedAvg, FedOPT and FedProx), we observe that their performance can\nbe improved substantially on average (4%-20% absolute gain under MacroAvg) and\nthat clients with smaller datasets enjoy larger performance gains. In addition,\nthe global model converges faster for almost all the clients.", "published": "2023-05-26 19:25:49", "link": "http://arxiv.org/abs/2305.17221v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models Can be Lazy Learners: Analyze Shortcuts in\n  In-Context Learning", "abstract": "Large language models (LLMs) have recently shown great potential for\nin-context learning, where LLMs learn a new task simply by conditioning on a\nfew input-label pairs (prompts). Despite their potential, our understanding of\nthe factors influencing end-task performance and the robustness of in-context\nlearning remains limited. This paper aims to bridge this knowledge gap by\ninvestigating the reliance of LLMs on shortcuts or spurious correlations within\nprompts. Through comprehensive experiments on classification and extraction\ntasks, we reveal that LLMs are \"lazy learners\" that tend to exploit shortcuts\nin prompts for downstream tasks. Additionally, we uncover a surprising finding\nthat larger models are more likely to utilize shortcuts in prompts during\ninference. Our findings provide a new perspective on evaluating robustness in\nin-context learning and pose new challenges for detecting and mitigating the\nuse of shortcuts in prompts.", "published": "2023-05-26 20:56:30", "link": "http://arxiv.org/abs/2305.17256v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language\n  Models' Reasoning Performance", "abstract": "As large language models (LLMs) are continuously being developed, their\nevaluation becomes increasingly important yet challenging. This work proposes\nChain-of-Thought Hub, an open-source evaluation suite on the multi-step\nreasoning capabilities of large language models. We are interested in this\nsetting for two reasons: (1) from the behavior of GPT and PaLM model family, we\nobserve that complex reasoning is likely to be a key differentiator between\nweaker and stronger LLMs; (2) we envisage large language models to become the\nnext-generation computational platform and foster an ecosystem of LLM-based new\napplications, this naturally requires the foundation models to perform complex\ntasks that often involve the composition of linguistic and logical operations.\nOur approach is to compile a suite of challenging reasoning benchmarks to track\nthe progress of LLMs. Our current results show that: (1) model scale clearly\ncorrelates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and\nPaLM-2 are the only two models that are comparable with GPT-4, while\nopen-sourced models still lag behind; (3) LLaMA-65B performs closely to\ncode-davinci-002, indicating that with successful further development such as\nreinforcement learning from human feedback (RLHF), it has great potential to be\nclose to GPT-3.5-Turbo. Our results also suggest that for the open-source\nefforts to catch up, the community may focus more on building better base\nmodels and exploring RLHF.", "published": "2023-05-26 23:46:42", "link": "http://arxiv.org/abs/2305.17306v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Open-World Product Attribute Mining: A Lightly-Supervised\n  Approach", "abstract": "We present a new task setting for attribute mining on e-commerce products,\nserving as a practical solution to extract open-world attributes without\nextensive human intervention. Our supervision comes from a high-quality seed\nattribute set bootstrapped from existing resources, and we aim to expand the\nattribute vocabulary of existing seed types, and also to discover any new\nattribute types automatically. A new dataset is created to support our setting,\nand our approach Amacer is proposed specifically to tackle the limited\nsupervision. Especially, given that no direct supervision is available for\nthose unseen new attributes, our novel formulation exploits self-supervised\nheuristic and unsupervised latent attributes, which attains implicit semantic\nsignals as additional supervision by leveraging product context. Experiments\nsuggest that our approach surpasses various baselines by 12 F1, expanding\nattributes of existing types significantly by up to 12 times, and discovering\nvalues from 39% new types.", "published": "2023-05-26 11:51:31", "link": "http://arxiv.org/abs/2305.18350v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "DeepSI: Interactive Deep Learning for Semantic Interaction", "abstract": "In this paper, we design novel interactive deep learning methods to improve\nsemantic interactions in visual analytics applications. The ability of semantic\ninteraction to infer analysts' precise intents during sensemaking is dependent\non the quality of the underlying data representation. We propose the\n$\\text{DeepSI}_{\\text{finetune}}$ framework that integrates deep learning into\nthe human-in-the-loop interactive sensemaking pipeline, with two important\nproperties. First, deep learning extracts meaningful representations from raw\ndata, which improves semantic interaction inference. Second, semantic\ninteractions are exploited to fine-tune the deep learning representations,\nwhich then further improves semantic interaction inference. This feedback loop\nbetween human interaction and deep learning enables efficient learning of user-\nand task-specific representations. To evaluate the advantage of embedding the\ndeep learning within the semantic interaction loop, we compare\n$\\text{DeepSI}_{\\text{finetune}}$ against a state-of-the-art but more basic use\nof deep learning as only a feature extractor pre-processed outside of the\ninteractive loop. Results of two complementary studies, a human-centered\nqualitative case study and an algorithm-centered simulation-based quantitative\nexperiment, show that $\\text{DeepSI}_{\\text{finetune}}$ more accurately\ncaptures users' complex mental models with fewer interactions.", "published": "2023-05-26 18:05:57", "link": "http://arxiv.org/abs/2305.18357v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "CONA: A novel CONtext-Aware instruction paradigm for communication using\n  large language model", "abstract": "We introduce CONA, a novel context-aware instruction paradigm for effective\nknowledge dissemination using generative pre-trained transformer (GPT) models.\nCONA is a flexible framework designed to leverage the capabilities of Large\nLanguage Models (LLMs) and incorporate DIKW (Data, Information, Knowledge,\nWisdom) hierarchy to automatically instruct and optimise presentation content,\nanticipate potential audience inquiries, and provide context-aware answers that\nadaptive to the knowledge level of the audience group. The unique aspect of the\nCONA paradigm lies in its combination of an independent advisory mechanism and\na recursive feedback loop rooted on the DIKW hierarchy. This synergy\nsignificantly enhances context-aware contents, ensuring they are accessible and\neasily comprehended by the audience. This paradigm is an early pioneer to\nexplore new methods for knowledge dissemination and communication in the LLM\nera, offering effective support for everyday knowledge sharing scenarios. We\nconduct experiments on a range of audience roles, along with materials from\nvarious disciplines using GPT4. Both quantitative and qualitative results\ndemonstrated that the proposed CONA paradigm achieved remarkable performance\ncompared to the outputs guided by conventional prompt engineering.", "published": "2023-05-26 00:53:18", "link": "http://arxiv.org/abs/2305.18620v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Large language models improve Alzheimer's disease diagnosis using\n  multi-modality data", "abstract": "In diagnosing challenging conditions such as Alzheimer's disease (AD),\nimaging is an important reference. Non-imaging patient data such as patient\ninformation, genetic data, medication information, cognitive and memory tests\nalso play a very important role in diagnosis. Effect. However, limited by the\nability of artificial intelligence models to mine such information, most of the\nexisting models only use multi-modal image data, and cannot make full use of\nnon-image data. We use a currently very popular pre-trained large language\nmodel (LLM) to enhance the model's ability to utilize non-image data, and\nachieved SOTA results on the ADNI dataset.", "published": "2023-05-26 18:42:19", "link": "http://arxiv.org/abs/2305.19280v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL\n  (extended)", "abstract": "Text-to-SQL, the process of translating natural language into Structured\nQuery Language (SQL), represents a transformative application of large language\nmodels (LLMs), potentially revolutionizing how humans interact with data. This\npaper introduces the SQL-PaLM framework, a comprehensive solution for\nunderstanding and enhancing Text-to-SQL using LLMs, using in the learning\nregimes of few-shot prompting and instruction fine-tuning. With few-shot\nprompting, we explore the effectiveness of consistency decoding with\nexecution-based error filtering. With instruction fine-tuning, we delve deep in\nunderstanding the critical paradigms that influence the performance of tuned\nLLMs. In particular, we investigate how performance can be improved through\nexpanded training data coverage and diversity, synthetic data augmentation, and\nintegrating query-specific database content. We propose a test-time selection\nmethod to further refine accuracy by integrating SQL outputs from multiple\nparadigms with execution feedback as guidance. Additionally, we tackle the\npractical challenge of navigating intricate databases with a significant number\nof tables and columns, proposing efficient techniques for accurately selecting\nrelevant database elements to enhance Text-to-SQL performance. Our holistic\napproach yields substantial advancements in Text-to-SQL, as demonstrated on two\nkey public benchmarks, Spider and BIRD. Through comprehensive ablations and\nerror analyses, we shed light on the strengths and weaknesses of our framework,\noffering valuable insights into Text-to-SQL's future work.", "published": "2023-05-26 21:39:05", "link": "http://arxiv.org/abs/2306.00739v4", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Distinguishing Human Generated Text From ChatGPT Generated Text Using\n  Machine Learning", "abstract": "ChatGPT is a conversational artificial intelligence that is a member of the\ngenerative pre-trained transformer of the large language model family. This\ntext generative model was fine-tuned by both supervised learning and\nreinforcement learning so that it can produce text documents that seem to be\nwritten by natural intelligence. Although there are numerous advantages of this\ngenerative model, it comes with some reasonable concerns as well. This paper\npresents a machine learning-based solution that can identify the ChatGPT\ndelivered text from the human written text along with the comparative analysis\nof a total of 11 machine learning and deep learning algorithms in the\nclassification process. We have tested the proposed model on a Kaggle dataset\nconsisting of 10,000 texts out of which 5,204 texts were written by humans and\ncollected from news and social media. On the corpus generated by GPT-3.5, the\nproposed algorithm presents an accuracy of 77%.", "published": "2023-05-26 09:27:43", "link": "http://arxiv.org/abs/2306.01761v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Evaluating Adversarial Robustness of Large Vision-Language Models", "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved unprecedented\nperformance in response generation, especially with visual inputs, enabling\nmore creative and adaptable interaction than large language models such as\nChatGPT. Nonetheless, multimodal generation exacerbates safety concerns, since\nadversaries may successfully evade the entire system by subtly manipulating the\nmost vulnerable modality (e.g., vision). To this end, we propose evaluating the\nrobustness of open-source large VLMs in the most realistic and high-risk\nsetting, where adversaries have only black-box system access and seek to\ndeceive the model into returning the targeted responses. In particular, we\nfirst craft targeted adversarial examples against pretrained models such as\nCLIP and BLIP, and then transfer these adversarial examples to other VLMs such\nas MiniGPT-4, LLaVA, UniDiffuser, BLIP-2, and Img2Prompt. In addition, we\nobserve that black-box queries on these VLMs can further improve the\neffectiveness of targeted evasion, resulting in a surprisingly high success\nrate for generating targeted responses. Our findings provide a quantitative\nunderstanding regarding the adversarial vulnerability of large VLMs and call\nfor a more thorough examination of their potential security flaws before\ndeployment in practice. Code is at https://github.com/yunqing-me/AttackVLM.", "published": "2023-05-26 13:49:44", "link": "http://arxiv.org/abs/2305.16934v2", "categories": ["cs.CV", "cs.CL", "cs.CR", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Mindstorms in Natural Language-Based Societies of Mind", "abstract": "Both Minsky's \"society of mind\" and Schmidhuber's \"learning to think\" inspire\ndiverse societies of large multimodal neural networks (NNs) that solve problems\nby interviewing each other in a \"mindstorm.\" Recent implementations of NN-based\nsocieties of minds consist of large language models (LLMs) and other NN-based\nexperts communicating through a natural language interface. In doing so, they\novercome the limitations of single LLMs, improving multimodal zero-shot\nreasoning. In these natural language-based societies of mind (NLSOMs), new\nagents -- all communicating through the same universal symbolic language -- are\neasily added in a modular fashion. To demonstrate the power of NLSOMs, we\nassemble and experiment with several of them (having up to 129 members),\nleveraging mindstorms in them to solve some practical AI tasks: visual question\nanswering, image captioning, text-to-image synthesis, 3D generation, egocentric\nretrieval, embodied AI, and general language-based task solving. We view this\nas a starting point towards much larger NLSOMs with billions of agents-some of\nwhich may be humans. And with this emergence of great societies of\nheterogeneous minds, many new research questions have suddenly become paramount\nto the future of artificial intelligence. What should be the social structure\nof an NLSOM? What would be the (dis)advantages of having a monarchical rather\nthan a democratic structure? How can principles of NN economies be used to\nmaximize the total reward of a reinforcement learning NLSOM? In this work, we\nidentify, discuss, and try to answer some of these questions.", "published": "2023-05-26 16:21:25", "link": "http://arxiv.org/abs/2305.17066v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA", "68T07", "I.2.6; I.2.11"], "primary_category": "cs.AI"}
{"title": "Neural Task Synthesis for Visual Programming", "abstract": "Generative neural models hold great promise in enhancing programming\neducation by synthesizing new content. We seek to design neural models that can\nautomatically generate programming tasks for a given specification in the\ncontext of visual programming domains. Despite the recent successes of large\ngenerative models like GPT-4, our initial results show that these models are\nineffective in synthesizing visual programming tasks and struggle with logical\nand spatial reasoning. We propose a novel neuro-symbolic technique,\nNeurTaskSyn, that can synthesize programming tasks for a specification given in\nthe form of desired programming concepts exercised by its solution code and\nconstraints on the visual task. NeurTaskSyn has two components: the first\ncomponent is trained via imitation learning procedure to generate possible\nsolution codes, and the second component is trained via reinforcement learning\nprocedure to guide an underlying symbolic execution engine that generates\nvisual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn\nthrough an extensive empirical evaluation and a qualitative study on reference\ntasks taken from the Hour of Code: Classic Maze challenge by Code-dot-org and\nthe Intro to Programming with Karel course by CodeHS-dot-com.", "published": "2023-05-26 01:08:18", "link": "http://arxiv.org/abs/2305.18342v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.PL"], "primary_category": "cs.LG"}
{"title": "Multimodal Recommendation Dialog with Subjective Preference: A New\n  Challenge and Benchmark", "abstract": "Existing multimodal task-oriented dialog data fails to demonstrate the\ndiverse expressions of user subjective preferences and recommendation acts in\nthe real-life shopping scenario. This paper introduces a new dataset SURE\n(Multimodal Recommendation Dialog with SUbjective PREference), which contains\n12K shopping dialogs in complex store scenes. The data is built in two phases\nwith human annotations to ensure quality and diversity. SURE is well-annotated\nwith subjective preferences and recommendation acts proposed by sales experts.\nA comprehensive analysis is given to reveal the distinguishing features of\nSURE. Three benchmark tasks are then proposed on the data to evaluate the\ncapability of multimodal recommendation agents. Based on the SURE, we propose a\nbaseline model, powered by a state-of-the-art multimodal model, for these\ntasks.", "published": "2023-05-26 08:43:46", "link": "http://arxiv.org/abs/2305.18212v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.IR"}
{"title": "AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec", "abstract": "A good audio codec for live applications such as telecommunication is\ncharacterized by three key properties: (1) compression, i.e.\\ the bitrate that\nis required to transmit the signal should be as low as possible; (2) latency,\ni.e.\\ encoding and decoding the signal needs to be fast enough to enable\ncommunication without or with only minimal noticeable delay; and (3)\nreconstruction quality of the signal. In this work, we propose an open-source,\nstreamable, and real-time neural audio codec that achieves strong performance\nalong all three axes: it can reconstruct highly natural sounding 48~kHz speech\nsignals while operating at only 12~kbps and running with less than 6~ms\n(GPU)/10~ms (CPU) latency. An efficient training paradigm is also demonstrated\nfor developing such neural audio codecs for real-world scenarios. Both\nobjective and subjective evaluations using the VCTK corpus are provided. To sum\nup, AudioDec is a well-developed plug-and-play benchmark for audio codec\napplications.", "published": "2023-05-26 04:01:16", "link": "http://arxiv.org/abs/2305.16608v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "2-bit Conformer quantization for automatic speech recognition", "abstract": "Large speech models are rapidly gaining traction in research community. As a\nresult, model compression has become an important topic, so that these models\ncan fit in memory and be served with reduced cost. Practical approaches for\ncompressing automatic speech recognition (ASR) model use int8 or int4 weight\nquantization. In this study, we propose to develop 2-bit ASR models. We explore\nthe impact of symmetric and asymmetric quantization combined with sub-channel\nquantization and clipping on both LibriSpeech dataset and large-scale training\ndata. We obtain a lossless 2-bit Conformer model with 32% model size reduction\nwhen compared to state of the art 4-bit Conformer model for LibriSpeech. With\nthe large-scale training data, we obtain a 2-bit Conformer model with over 40%\nmodel size reduction against the 4-bit version at the cost of 17% relative word\nerror rate degradation", "published": "2023-05-26 04:26:42", "link": "http://arxiv.org/abs/2305.16619v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Learning Representation of Therapist Empathy in Counseling Conversation\n  Using Siamese Hierarchical Attention Network", "abstract": "Counseling is an activity of conversational speaking between a therapist and\na client. Therapist empathy is an essential indicator of counseling quality and\nassessed subjectively by considering the entire conversation. This paper\nproposes to encode long counseling conversation using a hierarchical attention\nnetwork. Conversations with extreme values of empathy rating are used to train\na Siamese network based encoder with contrastive loss. Two-level attention\nmechanisms are applied to learn the importance weights of individual speaker\nturns and groups of turns in the conversation. Experimental results show that\nthe use of contrastive loss is effective in encouraging the conversation\nencoder to learn discriminative embeddings that are related to therapist\nempathy. The distances between conversation embeddings positively correlate\nwith the differences in the respective empathy scores. The learned conversation\nembeddings can be used to predict the subjective rating of therapist empathy.", "published": "2023-05-26 07:23:15", "link": "http://arxiv.org/abs/2305.16690v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Multi-Scale Attentive Transformer for Multi-Instrument Symbolic Music\n  Generation", "abstract": "Recently, multi-instrument music generation has become a hot topic. Different\nfrom single-instrument generation, multi-instrument generation needs to\nconsider inter-track harmony besides intra-track coherence. This is usually\nachieved by composing note segments from different instruments into a signal\nsequence. This composition could be on different scales, such as note, bar, or\ntrack. Most existing work focuses on a particular scale, leading to a shortage\nin modeling music with diverse temporal and track dependencies.\n  This paper proposes a multi-scale attentive Transformer model to improve the\nquality of multi-instrument generation. We first employ multiple Transformer\ndecoders to learn multi-instrument representations of different scales and then\ndesign an attentive mechanism to fuse the multi-scale information. Experiments\nconducted on SOD and LMD datasets show that our model improves both\nquantitative and qualitative performance compared to models based on\nsingle-scale information. The source code and some generated samples can be\nfound at https://github.com/HaRry-qaq/MSAT.", "published": "2023-05-26 02:41:56", "link": "http://arxiv.org/abs/2305.16592v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ABC-KD: Attention-Based-Compression Knowledge Distillation for Deep\n  Learning-Based Noise Suppression", "abstract": "Noise suppression (NS) models have been widely applied to enhance speech\nquality. Recently, Deep Learning-Based NS, which we denote as Deep Noise\nSuppression (DNS), became the mainstream NS method due to its excelling\nperformance over traditional ones. However, DNS models face 2 major challenges\nfor supporting the real-world applications. First, high-performing DNS models\nare usually large in size, causing deployment difficulties. Second, DNS models\nrequire extensive training data, including noisy audios as inputs and clean\naudios as labels. It is often difficult to obtain clean labels for training DNS\nmodels. We propose the use of knowledge distillation (KD) to resolve both\nchallenges. Our study serves 2 main purposes. To begin with, we are among the\nfirst to comprehensively investigate mainstream KD techniques on DNS models to\nresolve the two challenges. Furthermore, we propose a novel\nAttention-Based-Compression KD method that outperforms all investigated\nmainstream KD frameworks on DNS task.", "published": "2023-05-26 06:29:00", "link": "http://arxiv.org/abs/2305.16665v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Diverse and Expressive Speech Prosody Prediction with Denoising\n  Diffusion Probabilistic Model", "abstract": "Expressive human speech generally abounds with rich and flexible speech\nprosody variations. The speech prosody predictors in existing expressive speech\nsynthesis methods mostly produce deterministic predictions, which are learned\nby directly minimizing the norm of prosody prediction error. Its unimodal\nnature leads to a mismatch with ground truth distribution and harms the model's\nability in making diverse predictions. Thus, we propose a novel prosody\npredictor based on the denoising diffusion probabilistic model to take\nadvantage of its high-quality generative modeling and training stability.\nExperiment results confirm that the proposed prosody predictor outperforms the\ndeterministic baseline on both the expressiveness and diversity of prediction\nresults with even fewer network parameters.", "published": "2023-05-26 08:53:46", "link": "http://arxiv.org/abs/2305.16749v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Tuning of Loss Trade-offs without Hyper-parameter Search in\n  End-to-End Zero-Shot Speech Synthesis", "abstract": "Recently, zero-shot TTS and VC methods have gained attention due to their\npracticality of being able to generate voices even unseen during training.\nAmong these methods, zero-shot modifications of the VITS model have shown\nsuperior performance, while having useful properties inherited from VITS.\nHowever, the performance of VITS and VITS-based zero-shot models vary\ndramatically depending on how the losses are balanced. This can be problematic,\nas it requires a burdensome procedure of tuning loss balance hyper-parameters\nto find the optimal balance. In this work, we propose a novel framework that\nfinds this optimum without search, by inducing the decoder of VITS-based models\nto its full reconstruction ability. With our framework, we show superior\nperformance compared to baselines in zero-shot TTS and VC, achieving\nstate-of-the-art performance. Furthermore, we show the robustness of our\nframework in various settings. We provide an explanation for the results in the\ndiscussion.", "published": "2023-05-26 07:39:26", "link": "http://arxiv.org/abs/2305.16699v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "ElectrodeNet -- A Deep Learning Based Sound Coding Strategy for Cochlear\n  Implants", "abstract": "ElectrodeNet, a deep learning based sound coding strategy for the cochlear\nimplant (CI), is proposed to emulate the advanced combination encoder (ACE)\nstrategy by replacing the conventional envelope detection using various\nartificial neural networks. The extended ElectrodeNet-CS strategy further\nincorporates the channel selection (CS). Network models of deep neural network\n(DNN), convolutional neural network (CNN), and long short-term memory (LSTM)\nwere trained using the Fast Fourier Transformed bins and channel envelopes\nobtained from the processing of clean speech by the ACE strategy. Objective\nspeech understanding using short-time objective intelligibility (STOI) and\nnormalized covariance metric (NCM) was estimated for ElectrodeNet using CI\nsimulations. Sentence recognition tests for vocoded Mandarin speech were\nconducted with normal-hearing listeners. DNN, CNN, and LSTM based ElectrodeNets\nexhibited strong correlations to ACE in objective and subjective scores using\nmean squared error (MSE), linear correlation coefficient (LCC) and Spearman's\nrank correlation coefficient (SRCC). The ElectrodeNet-CS strategy was capable\nof producing N-of-M compatible electrode patterns using a modified DNN network\nto embed maxima selection, and to perform in similar or even slightly higher\naverage in STOI and sentence recognition compared to ACE. The methods and\nfindings demonstrated the feasibility and potential of using deep learning in\nCI coding strategy.", "published": "2023-05-26 09:06:04", "link": "http://arxiv.org/abs/2305.16753v1", "categories": ["eess.AS", "cs.AI", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Neural modeling of magnetic tape recorders", "abstract": "The sound of magnetic recording media, such as open-reel and cassette tape\nrecorders, is still sought after by today's sound practitioners due to the\nimperfections embedded in the physics of the magnetic recording process. This\npaper proposes a method for digitally emulating this character using neural\nnetworks. The signal chain of the proposed system consists of three main\ncomponents: the hysteretic nonlinearity and filtering jointly produced by the\nmagnetic recording process as well as the record and playback amplifiers, the\nfluctuating delay originating from the tape transport, and the combined\nadditive noise component from various electromagnetic origins. In our approach,\nthe hysteretic nonlinear block is modeled using a recurrent neural network,\nwhile the delay trajectories and the noise component are generated using\nseparate diffusion models, which employ U-net deep convolutional neural\nnetworks. According to the conducted objective evaluation, the proposed\narchitecture faithfully captures the character of the magnetic tape recorder.\nThe results of this study can be used to construct virtual replicas of vintage\nsound recording devices with applications in music production and audio\nantiquing tasks.", "published": "2023-05-26 12:15:11", "link": "http://arxiv.org/abs/2305.16862v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DistriBlock: Identifying adversarial audio samples by leveraging\n  characteristics of the output distribution", "abstract": "Adversarial attacks can mislead automatic speech recognition (ASR) systems\ninto predicting an arbitrary target text, thus posing a clear security threat.\nTo prevent such attacks, we propose DistriBlock, an efficient detection\nstrategy applicable to any ASR system that predicts a probability distribution\nover output tokens in each time step. We measure a set of characteristics of\nthis distribution: the median, maximum, and minimum over the output\nprobabilities, the entropy of the distribution, as well as the Kullback-Leibler\nand the Jensen-Shannon divergence with respect to the distributions of the\nsubsequent time step. Then, by leveraging the characteristics observed for both\nbenign and adversarial data, we apply binary classifiers, including simple\nthreshold-based classification, ensembles of such classifiers, and neural\nnetworks. Through extensive analysis across different state-of-the-art ASR\nsystems and language data sets, we demonstrate the supreme performance of this\napproach, with a mean area under the receiver operating characteristic curve\nfor distinguishing target adversarial examples against clean and noisy data of\n99% and 97%, respectively. To assess the robustness of our method, we show that\nadaptive adversarial examples that can circumvent DistriBlock are much noisier,\nwhich makes them easier to detect through filtering and creates another avenue\nfor preserving the system's robustness.", "published": "2023-05-26 14:59:28", "link": "http://arxiv.org/abs/2305.17000v8", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Efficient Membership Inference Attack for the Diffusion Model by\n  Proximal Initialization", "abstract": "Recently, diffusion models have achieved remarkable success in generating\ntasks, including image and audio generation. However, like other generative\nmodels, diffusion models are prone to privacy issues. In this paper, we propose\nan efficient query-based membership inference attack (MIA), namely Proximal\nInitialization Attack (PIA), which utilizes groundtruth trajectory obtained by\n$\\epsilon$ initialized in $t=0$ and predicted point to infer memberships.\nExperimental results indicate that the proposed method can achieve competitive\nperformance with only two queries on both discrete-time and continuous-time\ndiffusion models. Moreover, previous works on the privacy of diffusion models\nhave focused on vision tasks without considering audio tasks. Therefore, we\nalso explore the robustness of diffusion models to MIA in the text-to-speech\n(TTS) task, which is an audio generation task. To the best of our knowledge,\nthis work is the first to study the robustness of diffusion models to MIA in\nthe TTS task. Experimental results indicate that models with mel-spectrogram\n(image-like) output are vulnerable to MIA, while models with audio output are\nrelatively robust to MIA. {Code is available at\n\\url{https://github.com/kong13661/PIA}}.", "published": "2023-05-26 16:38:48", "link": "http://arxiv.org/abs/2305.18355v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
