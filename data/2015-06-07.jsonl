{"title": "Confounds and Consequences in Geotagged Twitter Data", "abstract": "Twitter is often used in quantitative studies that identify\ngeographically-preferred topics, writing styles, and entities. These studies\nrely on either GPS coordinates attached to individual messages, or on the\nuser-supplied location field in each profile. In this paper, we compare these\ndata acquisition techniques and quantify the biases that they introduce; we\nalso measure their effects on linguistic analysis and text-based geolocation.\nGPS-tagging and self-reported locations yield measurably different corpora, and\nthese linguistic differences are partially attributable to differences in\ndataset composition by age and gender. Using a latent variable model to induce\nage and gender, we show how these demographic variables interact with geography\nto affect language use. We also show that the accuracy of text-based\ngeolocation varies with population demographics, giving the best results for\nmen above the age of 40.", "published": "2015-06-07 15:29:26", "link": "http://arxiv.org/abs/1506.02275v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQUINKY! A Corpus of Sentence-level Formality, Informativeness, and\n  Implicature", "abstract": "We introduce a corpus of 7,032 sentences rated by human annotators for\nformality, informativeness, and implicature on a 1-7 scale. The corpus was\nannotated using Amazon Mechanical Turk. Reliability in the obtained judgments\nwas examined by comparing mean ratings across two MTurk experiments, and\ncorrelation with pilot annotations (on sentence formality) conducted in a more\ncontrolled setting. Despite the subjectivity and inherent difficulty of the\nannotation task, correlations between mean ratings were quite encouraging,\nespecially on formality and informativeness. We further explored correlation\nbetween the three linguistic variables, genre-wise variation of ratings and\ncorrelations within genres, compatibility with automatic stylistic scoring, and\nsentential make-up of a document in terms of style. To date, our corpus is the\nlargest sentence-level annotated corpus released for formality,\ninformativeness, and implicature.", "published": "2015-06-07 19:54:00", "link": "http://arxiv.org/abs/1506.02306v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN) for\n  Unsupervised Discovery of Linguistic Units and Generation of High Quality\n  Features", "abstract": "This paper summarizes the work done by the authors for the Zero Resource\nSpeech Challenge organized in the technical program of Interspeech 2015. The\ngoal of the challenge is to discover linguistic units directly from unlabeled\nspeech data. The Multi-layered Acoustic Tokenizer (MAT) proposed in this work\nautomatically discovers multiple sets of acoustic tokens from the given corpus.\nEach acoustic token set is specified by a set of hyperparameters that describe\nthe model configuration. These sets of acoustic tokens carry different\ncharacteristics of the given corpus and the language behind thus can be\nmutually reinforced. The multiple sets of token labels are then used as the\ntargets of a Multi-target DNN (MDNN) trained on low-level acoustic features.\nBottleneck features extracted from the MDNN are used as feedback for the MAT\nand the MDNN itself. We call this iterative system the Multi-layered Acoustic\nTokenizing Deep Neural Network (MAT-DNN) which generates high quality features\nfor track 1 of the challenge and acoustic tokens for track 2 of the challenge.", "published": "2015-06-07 23:52:54", "link": "http://arxiv.org/abs/1506.02327v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
