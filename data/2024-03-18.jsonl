{"title": "X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment", "abstract": "The impressive development of large language models (LLMs) is expanding into\nthe realm of large multimodal models (LMMs), which incorporate multiple types\nof data beyond text. However, the nature of multimodal models leads to\nsignificant expenses in the creation of training data. Furthermore,\nconstructing multilingual data for LMMs presents its own set of challenges due\nto language diversity and complexity. Therefore, in this study, we propose two\ncost-effective methods to solve this problem: (1) vocabulary expansion and\npretraining of multilingual LLM for specific languages, and (2) automatic and\nelaborate construction of multimodal datasets using GPT4-V. Based on015 these\nmethods, we constructed a 91K English-Korean-Chinese multilingual, multimodal\ntraining dataset. Additionally, we developed a bilingual multimodal model that\nexhibits excellent performance in both Korean and English, surpassing existing\napproaches.", "published": "2024-03-18 01:14:47", "link": "http://arxiv.org/abs/2403.11399v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Contexts for Generating Suggestion Questions in RAG Based\n  Conversational Systems", "abstract": "When interacting with Retrieval-Augmented Generation (RAG)-based\nconversational agents, the users must carefully craft their queries to be\nunderstood correctly. Yet, understanding the system's capabilities can be\nchallenging for the users, leading to ambiguous questions that necessitate\nfurther clarification. This work aims to bridge the gap by developing a\nsuggestion question generator. To generate suggestion questions, our approach\ninvolves utilizing dynamic context, which includes both dynamic few-shot\nexamples and dynamically retrieved contexts. Through experiments, we show that\nthe dynamic contexts approach can generate better suggestion questions as\ncompared to other prompting approaches.", "published": "2024-03-18 02:01:58", "link": "http://arxiv.org/abs/2403.11413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Novel Paradigm Boosting Translation Capabilities of Large Language\n  Models", "abstract": "This paper presents a study on strategies to enhance the translation\ncapabilities of large language models (LLMs) in the context of machine\ntranslation (MT) tasks. The paper proposes a novel paradigm consisting of three\nstages: Secondary Pre-training using Extensive Monolingual Data, Continual\nPre-training with Interlinear Text Format Documents, and Leveraging\nSource-Language Consistent Instruction for Supervised Fine-Tuning. Previous\nresearch on LLMs focused on various strategies for supervised fine-tuning\n(SFT), but their effectiveness has been limited. While traditional machine\ntranslation approaches rely on vast amounts of parallel bilingual data, our\nparadigm highlights the importance of using smaller sets of high-quality\nbilingual data. We argue that the focus should be on augmenting LLMs'\ncross-lingual alignment abilities during pre-training rather than solely\nrelying on extensive bilingual data during SFT. Experimental results conducted\nusing the Llama2 model, particularly on Chinese-Llama2 after monolingual\naugmentation, demonstrate the improved translation capabilities of LLMs. A\nsignificant contribution of our approach lies in Stage2: Continual Pre-training\nwith Interlinear Text Format Documents, which requires less than 1B training\ndata, making our method highly efficient. Additionally, in Stage3, we observed\nthat setting instructions consistent with the source language benefits the\nsupervised fine-tuning process. Experimental results demonstrate that our\napproach surpasses previous work and achieves superior performance compared to\nmodels such as NLLB-54B and GPT3.5-text-davinci-003, despite having a\nsignificantly smaller parameter count of only 7B or 13B. This achievement\nestablishes our method as a pioneering strategy in the field of machine\ntranslation.", "published": "2024-03-18 02:53:49", "link": "http://arxiv.org/abs/2403.11430v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning\n  Large Language Models with Instructions", "abstract": "Instruction tuning effectively optimizes Large Language Models (LLMs) for\ndownstream tasks. Due to the changing environment in real-life applications,\nLLMs necessitate continual task-specific adaptation without catastrophic\nforgetting. Considering the heavy computational cost, replay-based Continual\nLearning (CL) methods are the simplest and most widely used for LLMs to address\nthe forgetting issue. However, traditional replay-based methods do not fully\nutilize instructions to customize the replay strategy. In this work, we propose\na novel paradigm called Instruction-based Continual Learning (InsCL). InsCL\ndynamically replays previous data based on task similarity, calculated by\nWasserstein Distance with instructions. Moreover, we further introduce an\nInstruction Information Metric (InsInfo) to quantify the complexity and\ndiversity of instructions. According to InsInfo, InsCL guides the replay\nprocess more inclined to high-quality data. We conduct extensive experiments\nover 16 tasks with different training orders, observing consistent performance\nimprovements of InsCL. When all tasks have been trained, InsCL achieves\nperformance gains of 3.0 Relative Gain compared with Random Replay, and 27.96\nRelative Gain compared with No Replay.", "published": "2024-03-18 03:10:36", "link": "http://arxiv.org/abs/2403.11435v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized\n  Dialogue Generation", "abstract": "Large Language Models (LLMs) demonstrate superior performance in generative\nscenarios and have attracted widespread attention. Among them, stylized\ndialogue generation is essential in the context of LLMs for building\nintelligent and engaging dialogue agent. However the ability of LLMs is\ndata-driven and limited by data bias, leading to poor performance on specific\ntasks. In particular, stylized dialogue generation suffers from a severe lack\nof supervised data. Furthermore, although many prompt-based methods have been\nproposed to accomplish specific tasks, their performance in complex real-world\nscenarios involving a wide variety of dialog styles further enhancement. In\nthis work, we first introduce a stylized dialogue dataset StyleEval with 38\nstyles by leveraging the generative power of LLMs comprehensively, which has\nbeen carefully constructed with rigorous human-led quality control. Based on\nthis, we propose the stylized dialogue framework StyleChat via\nrecitation-augmented memory strategy and multi-task style learning strategy to\npromote generalization ability. To evaluate the effectiveness of our approach,\nwe created a test benchmark that included both a generation task and a choice\ntask to comprehensively evaluate trained models and assess whether styles and\npreferences are remembered and understood. Experimental results show that our\nproposed framework StyleChat outperforms all the baselines and helps to break\nthe style boundary of LLMs.", "published": "2024-03-18 03:26:18", "link": "http://arxiv.org/abs/2403.11439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEE: Dual-stage Explainable Evaluation Method for Text Generation", "abstract": "Automatic methods for evaluating machine-generated texts hold significant\nimportance due to the expanding applications of generative systems.\nConventional methods tend to grapple with a lack of explainability, issuing a\nsolitary numerical score to signify the assessment outcome. Recent advancements\nhave sought to mitigate this limitation by incorporating large language models\n(LLMs) to offer more detailed error analyses, yet their applicability remains\nconstrained, particularly in industrial contexts where comprehensive error\ncoverage and swift detection are paramount. To alleviate these challenges, we\nintroduce DEE, a Dual-stage Explainable Evaluation method for estimating the\nquality of text generation. Built upon Llama 2, DEE follows a dual-stage\nprinciple guided by stage-specific instructions to perform efficient\nidentification of errors in generated texts in the initial stage and\nsubsequently delves into providing comprehensive diagnostic reports in the\nsecond stage. DEE is fine-tuned on our elaborately assembled dataset AntEval,\nwhich encompasses 15K examples from 4 real-world applications of Alipay that\nemploy generative systems. The dataset concerns newly emerged issues like\nhallucination and toxicity, thereby broadening the scope of DEE's evaluation\ncriteria. Experimental results affirm that DEE's superiority over existing\nevaluation methods, achieving significant improvements in both human\ncorrelation as well as efficiency.", "published": "2024-03-18 06:30:41", "link": "http://arxiv.org/abs/2403.11509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large\n  Language Model", "abstract": "Large Language Models (LLMs) are composed of neurons that exhibit various\nbehaviors and roles, which become increasingly diversified as models scale.\nRecent studies have revealed that not all neurons are active across different\ndatasets, and this sparsity correlates positively with the task-specific\nability, leading to advancements in model pruning and training efficiency.\nTraditional fine-tuning methods engage all parameters of LLMs, which is\ncomputationally expensive and may not be necessary. In contrast,\nParameter-Efficient Fine-Tuning (PEFT) approaches aim to minimize the number of\ntrainable parameters, yet they still operate at a relatively macro scale (e.g.,\nlayer-level). We introduce Neuron-Level Fine-Tuning (NeFT), a novel approach\nthat refines the granularity of parameter training down to the individual\nneuron, enabling more precise and computationally efficient model updates. The\nexperimental results show that NeFT not only exceeded the performance of\nfull-parameter fine-tuning and PEFT but also provided insights into the\nanalysis of neurons.", "published": "2024-03-18 09:55:01", "link": "http://arxiv.org/abs/2403.11621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embedded Named Entity Recognition using Probing Classifiers", "abstract": "Streaming text generation has become a common way of increasing the\nresponsiveness of language model powered applications, such as chat assistants.\nAt the same time, extracting semantic information from generated text is a\nuseful tool for applications such as automated fact checking or retrieval\naugmented generation. Currently, this requires either separate models during\ninference, which increases computational cost, or destructive fine-tuning of\nthe language model. Instead, we propose an approach called EMBER which enables\nstreaming named entity recognition in decoder-only language models without\nfine-tuning them and while incurring minimal additional computational cost at\ninference time. Specifically, our experiments show that EMBER maintains high\ntoken generation rates, with only a negligible decrease in speed of around 1%\ncompared to a 43.64% slowdown measured for a baseline. We make our code and\ndata available online, including a toolkit for training, testing, and deploying\nefficient token classification models optimized for streaming text generation.", "published": "2024-03-18 12:58:16", "link": "http://arxiv.org/abs/2403.11747v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting The Classics: A Study on Identifying and Rectifying Gender\n  Stereotypes in Rhymes and Poems", "abstract": "Rhymes and poems are a powerful medium for transmitting cultural norms and\nsocietal roles. However, the pervasive existence of gender stereotypes in these\nworks perpetuates biased perceptions and limits the scope of individuals'\nidentities. Past works have shown that stereotyping and prejudice emerge in\nearly childhood, and developmental research on causal mechanisms is critical\nfor understanding and controlling stereotyping and prejudice. This work\ncontributes by gathering a dataset of rhymes and poems to identify gender\nstereotypes and propose a model with 97% accuracy to identify gender bias.\nGender stereotypes were rectified using a Large Language Model (LLM) and its\neffectiveness was evaluated in a comparative survey against human educator\nrectifications. To summarize, this work highlights the pervasive nature of\ngender stereotypes in literary works and reveals the potential of LLMs to\nrectify gender stereotypes. This study raises awareness and promotes\ninclusivity within artistic expressions, making a significant contribution to\nthe discourse on gender equality.", "published": "2024-03-18 13:02:02", "link": "http://arxiv.org/abs/2403.11752v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counting-Stars: A Multi-evidence, Position-aware, and Scalable Benchmark\n  for Evaluating Long-Context Large Language Models", "abstract": "Despite recent efforts to develop large language models with robust\nlong-context capabilities, the lack of long-context benchmarks means that\nrelatively little is known about their performance. To alleviate this gap, in\nthis paper, we propose \\textbf{Counting-Stars}, a multi-evidence,\nposition-aware, and scalable benchmark designed to evaluate the multi-evidence\nretrieval capabilities of long-context LLMs. \\textbf{Counting-Stars} comprises\ntwo counting-based multiple pieces of evidence retrieval sub-tasks: searching\nand reasoning. Using Counting-Stars, we conduct experiments to evaluate several\nlong-context LLMs, including GPT-4 Turbo, Gemini 1.5 Pro, Claude3 Opus, GLM-4,\nand Moonshot-v1. Extensive experimental results demonstrate that Gemini 1.5 Pro\nachieves the best overall results, while GPT-4 Turbo exhibits the most stable\nperformance across various tasks. Furthermore, our analysis of these LLMs,\nwhich have been extended to handle long-context scenarios, indicates that\nsignificant room for improvement remains as the length of the input context and\nthe complexity of the tasks increase.", "published": "2024-03-18 14:01:45", "link": "http://arxiv.org/abs/2403.11802v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metaphor Understanding Challenge Dataset for LLMs", "abstract": "Metaphors in natural language are a reflection of fundamental cognitive\nprocesses such as analogical reasoning and categorisation, and are deeply\nrooted in everyday communication. Metaphor understanding is therefore an\nessential task for large language models (LLMs). We release the Metaphor\nUnderstanding Challenge Dataset (MUNCH), designed to evaluate the metaphor\nunderstanding capabilities of LLMs. The dataset provides over 10k paraphrases\nfor sentences containing metaphor use, as well as 1.5k instances containing\ninapt paraphrases. The inapt paraphrases were carefully selected to serve as\ncontrol to determine whether the model indeed performs full metaphor\ninterpretation or rather resorts to lexical similarity. All apt and inapt\nparaphrases were manually annotated. The metaphorical sentences cover natural\nmetaphor uses across 4 genres (academic, news, fiction, and conversation), and\nthey exhibit different levels of novelty. Experiments with LLaMA and GPT-3.5\ndemonstrate that MUNCH presents a challenging task for LLMs. The dataset is\nfreely accessible at\nhttps://github.com/xiaoyuisrain/metaphor-understanding-challenge.", "published": "2024-03-18 14:08:59", "link": "http://arxiv.org/abs/2403.11810v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPT-4 as Evaluator: Evaluating Large Language Models on Pest Management\n  in Agriculture", "abstract": "In the rapidly evolving field of artificial intelligence (AI), the\napplication of large language models (LLMs) in agriculture, particularly in\npest management, remains nascent. We aimed to prove the feasibility by\nevaluating the content of the pest management advice generated by LLMs,\nincluding the Generative Pre-trained Transformer (GPT) series from OpenAI and\nthe FLAN series from Google. Considering the context-specific properties of\nagricultural advice, automatically measuring or quantifying the quality of text\ngenerated by LLMs becomes a significant challenge. We proposed an innovative\napproach, using GPT-4 as an evaluator, to score the generated content on\nCoherence, Logical Consistency, Fluency, Relevance, Comprehensibility, and\nExhaustiveness. Additionally, we integrated an expert system based on crop\nthreshold data as a baseline to obtain scores for Factual Accuracy on whether\npests found in crop fields should take management action. Each model's score\nwas weighted by percentage to obtain a final score. The results showed that\nGPT-3.4 and GPT-4 outperform the FLAN models in most evaluation categories.\nFurthermore, the use of instruction-based prompting containing domain-specific\nknowledge proved the feasibility of LLMs as an effective tool in agriculture,\nwith an accuracy rate of 72%, demonstrating LLMs' effectiveness in providing\npest management suggestions.", "published": "2024-03-18 15:08:01", "link": "http://arxiv.org/abs/2403.11858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CO3: Low-resource Contrastive Co-training for Generative Conversational\n  Query Rewrite", "abstract": "Generative query rewrite generates reconstructed query rewrites using the\nconversation history while rely heavily on gold rewrite pairs that are\nexpensive to obtain. Recently, few-shot learning is gaining increasing\npopularity for this task, whereas these methods are sensitive to the inherent\nnoise due to limited data size. Besides, both attempts face performance\ndegradation when there exists language style shift between training and testing\ncases. To this end, we study low-resource generative conversational query\nrewrite that is robust to both noise and language style shift. The core idea is\nto utilize massive unlabeled data to make further improvements via a\ncontrastive co-training paradigm. Specifically, we co-train two dual models\n(namely Rewriter and Simplifier) such that each of them provides extra guidance\nthrough pseudo-labeling for enhancing the other in an iterative manner. We also\nleverage contrastive learning with data augmentation, which enables our model\npay more attention on the truly valuable information than the noise. Extensive\nexperiments demonstrate the superiority of our model under both few-shot and\nzero-shot scenarios. We also verify the better generalization ability of our\nmodel when encountering language style shift.", "published": "2024-03-18 15:26:32", "link": "http://arxiv.org/abs/2403.11873v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Closer Look at Claim Decomposition", "abstract": "As generated text becomes more commonplace, it is increasingly important to\nevaluate how well-supported such text is by external knowledge sources. Many\napproaches for evaluating textual support rely on some method for decomposing\ntext into its individual subclaims which are scored against a trusted\nreference. We investigate how various methods of claim decomposition --\nespecially LLM-based methods -- affect the result of an evaluation approach\nsuch as the recently proposed FActScore, finding that it is sensitive to the\ndecomposition method used. This sensitivity arises because such metrics\nattribute overall textual support to the model that generated the text even\nthough error can also come from the metric's decomposition step. To measure\ndecomposition quality, we introduce an adaptation of FActScore, which we call\nDecompScore. We then propose an LLM-based approach to generating decompositions\ninspired by Bertrand Russell's theory of logical atomism and neo-Davidsonian\nsemantics and demonstrate its improved decomposition quality over previous\nmethods.", "published": "2024-03-18 16:03:45", "link": "http://arxiv.org/abs/2403.11903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptative Bilingual Aligning Using Multilingual Sentence Embedding", "abstract": "In this paper, we present an adaptive bitextual alignment system called\nAIlign. This aligner relies on sentence embeddings to extract reliable anchor\npoints that can guide the alignment path, even for texts whose parallelism is\nfragmentary and not strictly monotonic. In an experiment on several datasets,\nwe show that AIlign achieves results equivalent to the state of the art, with\nquasi-linear complexity. In addition, AIlign is able to handle texts whose\nparallelism and monotonicity properties are only satisfied locally, unlike\nrecent systems such as Vecalign or Bertalign.", "published": "2024-03-18 16:19:41", "link": "http://arxiv.org/abs/2403.11921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Taiwanese Hokkien Dual Translation by Exploring and\n  Standardizing of Four Writing Systems", "abstract": "Machine translation focuses mainly on high-resource languages (HRLs), while\nlow-resource languages (LRLs) like Taiwanese Hokkien are relatively\nunder-explored. The study aims to address this gap by developing a dual\ntranslation model between Taiwanese Hokkien and both Traditional Mandarin\nChinese and English. We employ a pre-trained LLaMA 2-7B model specialized in\nTraditional Mandarin Chinese to leverage the orthographic similarities between\nTaiwanese Hokkien Han and Traditional Mandarin Chinese. Our comprehensive\nexperiments involve translation tasks across various writing systems of\nTaiwanese Hokkien as well as between Taiwanese Hokkien and other HRLs. We find\nthat the use of a limited monolingual corpus still further improves the model's\nTaiwanese Hokkien capabilities. We then utilize our translation model to\nstandardize all Taiwanese Hokkien writing systems into Hokkien Han, resulting\nin further performance improvements. Additionally, we introduce an evaluation\nmethod incorporating back-translation and GPT-4 to ensure reliable translation\nquality assessment even for LRLs. The study contributes to narrowing the\nresource gap for Taiwanese Hokkien and empirically investigates the advantages\nand limitations of pre-training and fine-tuning based on LLaMA 2.", "published": "2024-03-18 17:56:13", "link": "http://arxiv.org/abs/2403.12024v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syn-QA2: Evaluating False Assumptions in Long-tail Questions with\n  Synthetic QA Datasets", "abstract": "Sensitivity to false assumptions (or false premises) in information-seeking\nquestions is critical for robust question-answering (QA) systems. Recent work\nhas shown that false assumptions in naturally occurring questions pose\nchallenges to current models, with low performance on both generative QA and\nsimple detection tasks (Kim et al. 2023). However, the focus of existing work\non naturally occurring questions leads to a gap in the analysis of model\nbehavior on the long tail of the distribution of possible questions. To this\nend, we introduce Syn-(QA)$^2$, a set of two synthetically generated QA\ndatasets: one generated using perturbed relations from Wikidata, and the other\nby perturbing HotpotQA (Yang et al. 2018). Our findings from evaluating a range\nof large language models are threefold: (1) false assumptions in QA are\nchallenging, echoing the findings of prior work, (2) the binary detection task\nis challenging even compared to the difficulty of generative QA itself,\npossibly due to the linguistic structure of the problem, and (3) the detection\ntask is more challenging with long-tail questions compared to naturally\noccurring questions, highlighting the utility of our synthetic datasets and\ngeneration method.", "published": "2024-03-18 18:01:26", "link": "http://arxiv.org/abs/2403.12145v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Multi-task Hallucination Detection", "abstract": "In recent studies, the extensive utilization of large language models has\nunderscored the importance of robust evaluation methodologies for assessing\ntext generation quality and relevance to specific tasks. This has revealed a\nprevalent issue known as hallucination, an emergent condition in the model\nwhere generated text lacks faithfulness to the source and deviates from the\nevaluation criteria. In this study, we formally define hallucination and\npropose a framework for its quantitative detection in a zero-shot setting,\nleveraging our definition and the assumption that model outputs entail task and\nsample specific inputs. In detecting hallucinations, our solution achieves an\naccuracy of 0.78 in a model-aware setting and 0.61 in a model-agnostic setting.\nNotably, our solution maintains computational efficiency, requiring far less\ncomputational resources than other SOTA approaches, aligning with the trend\ntowards lightweight and compressed models.", "published": "2024-03-18 20:50:26", "link": "http://arxiv.org/abs/2403.12244v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Investigation of Compositional Syntax and Semantics in\n  DALL-E 2", "abstract": "In this study we compared how well DALL-E 2 visually represented the meaning\nof linguistic prompts also given to young children in comprehension tests.\nSentences representing fundamental components of grammatical knowledge were\nselected from assessment tests used with several hundred English-speaking\nchildren aged 2-7 years for whom we had collected original item-level data.\nDALL-E 2 was given these prompts five times to generate 20 cartoons per item,\nfor 9 adult judges to score. Results revealed no conditions in which DALL-E\n2-generated images that matched the semantic accuracy of children, even at the\nyoungest age (2 years). DALL-E 2 failed to assign the appropriate roles in\nreversible forms; it failed on negation despite an easier contrastive prompt\nthan the children received; it often assigned the adjective to the wrong noun;\nit ignored implicit agents in passives. This work points to a clear absence of\ncompositional sentence representations for DALL-E 2.", "published": "2024-03-18 22:33:51", "link": "http://arxiv.org/abs/2403.12294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and\n  Safety", "abstract": "The rapid development of Chinese large language models (LLMs) poses big\nchallenges for efficient LLM evaluation. While current initiatives have\nintroduced new benchmarks or evaluation platforms for assessing Chinese LLMs,\nmany of these focus primarily on capabilities, usually overlooking potential\nalignment and safety issues. To address this gap, we introduce OpenEval, an\nevaluation testbed that benchmarks Chinese LLMs across capability, alignment\nand safety. For capability assessment, we include 12 benchmark datasets to\nevaluate Chinese LLMs from 4 sub-dimensions: NLP tasks, disciplinary knowledge,\ncommonsense reasoning and mathematical reasoning. For alignment assessment,\nOpenEval contains 7 datasets that examines the bias, offensiveness and\nillegalness in the outputs yielded by Chinese LLMs. To evaluate safety,\nespecially anticipated risks (e.g., power-seeking, self-awareness) of advanced\nLLMs, we include 6 datasets. In addition to these benchmarks, we have\nimplemented a phased public evaluation and benchmark update strategy to ensure\nthat OpenEval is in line with the development of Chinese LLMs or even able to\nprovide cutting-edge benchmark datasets to guide the development of Chinese\nLLMs. In our first public evaluation, we have tested a range of Chinese LLMs,\nspanning from 7B to 72B parameters, including both open-source and proprietary\nmodels. Evaluation results indicate that while Chinese LLMs have shown\nimpressive performance in certain tasks, more attention should be directed\ntowards broader aspects such as commonsense reasoning, alignment, and safety.", "published": "2024-03-18 23:21:37", "link": "http://arxiv.org/abs/2403.12316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NovelQA: Benchmarking Question Answering on Documents Exceeding 200K\n  Tokens", "abstract": "The rapid advancement of Large Language Models (LLMs) has introduced a new\nfrontier in natural language processing, particularly in understanding and\nprocessing long-context information. However, the evaluation of these models'\nlong-context abilities remains a challenge due to the limitations of current\nbenchmarks. To address this gap, we introduce NovelQA, a benchmark specifically\ndesigned to test the capabilities of LLMs with extended texts. Constructed from\nEnglish novels, NovelQA offers a unique blend of complexity, length, and\nnarrative coherence, making it an ideal tool for assessing deep textual\nunderstanding in LLMs. This paper presents the design and construction of\nNovelQA, highlighting its manual annotation, and diverse question types. Our\nevaluation of Long-context LLMs on NovelQA reveals significant insights into\nthe models' performance, particularly emphasizing the challenges they face with\nmulti-hop reasoning, detail-oriented questions, and extremely long input with\nan average length more than 200,000 tokens. The results underscore the\nnecessity for further advancements in LLMs to improve their long-context\ncomprehension.", "published": "2024-03-18 17:32:32", "link": "http://arxiv.org/abs/2403.12766v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Enabling FAIR Dataspaces Using Large Language Models", "abstract": "Dataspaces have recently gained adoption across various sectors, including\ntraditionally less digitized domains such as culture. Leveraging Semantic Web\ntechnologies helps to make dataspaces FAIR, but their complexity poses a\nsignificant challenge to the adoption of dataspaces and increases their cost.\nThe advent of Large Language Models (LLMs) raises the question of how these\nmodels can support the adoption of FAIR dataspaces. In this work, we\ndemonstrate the potential of LLMs in dataspaces with a concrete example. We\nalso derive a research agenda for exploring this emerging field.", "published": "2024-03-18 16:46:00", "link": "http://arxiv.org/abs/2403.15451v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLM-Augmented autonomous agents cooperate?, An evaluation of their\n  cooperative capabilities through Melting Pot", "abstract": "As the field of AI continues to evolve, a significant dimension of this\nprogression is the development of Large Language Models and their potential to\nenhance multi-agent artificial intelligence systems. This paper explores the\ncooperative capabilities of Large Language Model-augmented Autonomous Agents\n(LAAs) using the well-known Meltin Pot environments along with reference models\nsuch as GPT4 and GPT3.5. Preliminary results suggest that while these agents\ndemonstrate a propensity for cooperation, they still struggle with effective\ncollaboration in given environments, emphasizing the need for more robust\narchitectures. The study's contributions include an abstraction layer to adapt\nMelting Pot game scenarios for LLMs, the implementation of a reusable\narchitecture for LLM-mediated agent development - which includes short and\nlong-term memories and different cognitive modules, and the evaluation of\ncooperation capabilities using a set of metrics tied to the Melting Pot's\n\"Commons Harvest\" game. The paper closes, by discussing the limitations of the\ncurrent architectural framework and the potential of a new set of modules that\nfosters better cooperation among LAAs.", "published": "2024-03-18 00:13:43", "link": "http://arxiv.org/abs/2403.11381v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Narrative Feature or Structured Feature? A Study of Large Language\n  Models to Identify Cancer Patients at Risk of Heart Failure", "abstract": "Cancer treatments are known to introduce cardiotoxicity, negatively impacting\noutcomes and survivorship. Identifying cancer patients at risk of heart failure\n(HF) is critical to improving cancer treatment outcomes and safety. This study\nexamined machine learning (ML) models to identify cancer patients at risk of HF\nusing electronic health records (EHRs), including traditional ML, Time-Aware\nlong short-term memory (T-LSTM), and large language models (LLMs) using novel\nnarrative features derived from the structured medical codes. We identified a\ncancer cohort of 12,806 patients from the University of Florida Health,\ndiagnosed with lung, breast, and colorectal cancers, among which 1,602\nindividuals developed HF after cancer. The LLM, GatorTron-3.9B, achieved the\nbest F1 scores, outperforming the traditional support vector machines by 39%,\nthe T-LSTM deep learning model by 7%, and a widely used transformer model,\nBERT, by 5.6%. The analysis shows that the proposed narrative features\nremarkably increased feature density and improved performance.", "published": "2024-03-18 02:42:01", "link": "http://arxiv.org/abs/2403.11425v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Word Order's Impacts: Insights from Reordering and Generation Analysis", "abstract": "Existing works have studied the impacts of the order of words within natural\ntext. They usually analyze it by destroying the original order of words to\ncreate a scrambled sequence, and then comparing the models' performance between\nthe original and scrambled sequences. The experimental results demonstrate\nmarginal drops. Considering this findings, different hypothesis about word\norder is proposed, including ``the order of words is redundant with lexical\nsemantics'', and ``models do not rely on word order''. In this paper, we\nrevisit the aforementioned hypotheses by adding a order reconstruction\nperspective, and selecting datasets of different spectrum. Specifically, we\nfirst select four different datasets, and then design order reconstruction and\ncontinuing generation tasks. Empirical findings support that ChatGPT relies on\nword order to infer, but cannot support or negate the redundancy relations\nbetween word order lexical semantics.", "published": "2024-03-18 04:45:44", "link": "http://arxiv.org/abs/2403.11473v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning with Token-level Feedback for Controllable Text\n  Generation", "abstract": "To meet the requirements of real-world applications, it is essential to\ncontrol generations of large language models (LLMs). Prior research has tried\nto introduce reinforcement learning (RL) into controllable text generation\nwhile most existing methods suffer from overfitting issues (finetuning-based\nmethods) or semantic collapse (post-processing methods). However, current RL\nmethods are generally guided by coarse-grained (sentence/paragraph-level)\nfeedback, which may lead to suboptimal performance owing to semantic twists or\nprogressions within sentences. To tackle that, we propose a novel reinforcement\nlearning algorithm named TOLE which formulates TOken-LEvel rewards for\ncontrollable text generation, and employs a \"first-quantize-then-noise\"\nparadigm to enhance the robustness of the RL algorithm.Furthermore, TOLE can be\nflexibly extended to multiple constraints with little computational expense.\nExperimental results show that our algorithm can achieve superior performance\non both single-attribute and multi-attribute control tasks. We have released\nour codes at https://github.com/WindyLee0822/CTG", "published": "2024-03-18 08:18:37", "link": "http://arxiv.org/abs/2403.11558v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modality-Agnostic fMRI Decoding of Vision and Language", "abstract": "Previous studies have shown that it is possible to map brain activation data\nof subjects viewing images onto the feature representation space of not only\nvision models (modality-specific decoding) but also language models\n(cross-modal decoding). In this work, we introduce and use a new large-scale\nfMRI dataset (~8,500 trials per subject) of people watching both images and\ntext descriptions of such images. This novel dataset enables the development of\nmodality-agnostic decoders: a single decoder that can predict which stimulus a\nsubject is seeing, irrespective of the modality (image or text) in which the\nstimulus is presented. We train and evaluate such decoders to map brain signals\nonto stimulus representations from a large range of publicly available vision,\nlanguage and multimodal (vision+language) models. Our findings reveal that (1)\nmodality-agnostic decoders perform as well as (and sometimes even better than)\nmodality-specific decoders (2) modality-agnostic decoders mapping brain data\nonto representations from unimodal models perform as well as decoders relying\non multimodal representations (3) while language and low-level visual\n(occipital) brain regions are best at decoding text and image stimuli,\nrespectively, high-level visual (temporal) regions perform well on both\nstimulus types.", "published": "2024-03-18 13:30:03", "link": "http://arxiv.org/abs/2403.11771v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained\n  Large Language Models", "abstract": "Extracting hyper-relations is crucial for constructing comprehensive\nknowledge graphs, but there are limited supervised methods available for this\ntask. To address this gap, we introduce a zero-shot prompt-based method using\nOpenAI's GPT-3.5 model for extracting hyper-relational knowledge from text.\nComparing our model with a baseline, we achieved promising results, with a\nrecall of 0.77. Although our precision is currently lower, a detailed analysis\nof the model outputs has uncovered potential pathways for future research in\nthis area.", "published": "2024-03-18 13:44:48", "link": "http://arxiv.org/abs/2403.11786v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming\n  Ability in Multi-Agent Environments", "abstract": "Decision-making is a complex process requiring diverse abilities, making it\nan excellent framework for evaluating Large Language Models (LLMs). Researchers\nhave examined LLMs' decision-making through the lens of Game Theory. However,\nexisting evaluation mainly focus on two-player scenarios where an LLM competes\nagainst another. Additionally, previous benchmarks suffer from test set leakage\ndue to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework\nfor evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes\neight classical game theory scenarios and a dynamic scoring scheme specially\ndesigned to quantitatively assess LLMs' performance. $\\gamma$-Bench allows\nflexible game settings and adapts the scoring system to different game\nparameters, enabling comprehensive evaluation of robustness, generalizability,\nand strategies for improvement. Our results indicate that GPT-3.5 demonstrates\nstrong robustness but limited generalizability, which can be enhanced using\nmethods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,\nincluding GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.\nGemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by\nLLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental\nresults are publicly available at https://github.com/CUHK-ARISE/GAMABench.", "published": "2024-03-18 14:04:47", "link": "http://arxiv.org/abs/2403.11807v7", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards Understanding the Relationship between In-context Learning and\n  Compositional Generalization", "abstract": "According to the principle of compositional generalization, the meaning of a\ncomplex expression can be understood as a function of the meaning of its parts\nand of how they are combined. This principle is crucial for human language\nprocessing and also, arguably, for NLP models in the face of\nout-of-distribution data. However, many neural network models, including\nTransformers, have been shown to struggle with compositional generalization. In\nthis paper, we hypothesize that forcing models to in-context learn can provide\nan inductive bias to promote compositional generalization. To test this\nhypothesis, we train a causal Transformer in a setting that renders ordinary\nlearning very difficult: we present it with different orderings of the training\ninstance and shuffle instance labels. This corresponds to training the model on\nall possible few-shot learning problems attainable from the dataset. The model\ncan solve the task, however, by utilizing earlier examples to generalize to\nlater ones (i.e. in-context learning). In evaluations on the datasets, SCAN,\nCOGS, and GeoQuery, models trained in this manner indeed show improved\ncompositional generalization. This indicates the usefulness of in-context\nlearning problems as an inductive bias for generalization.", "published": "2024-03-18 14:45:52", "link": "http://arxiv.org/abs/2403.11834v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for\n  Language Models", "abstract": "Large Language Models (LLMs) exhibit impressive capabilities but also present\nrisks such as biased content generation and privacy issues. One of the current\nalignment techniques includes principle-driven integration, but it faces\nchallenges arising from the imprecision of manually crafted rules and\ninadequate risk perception in models without safety training. To address these,\nwe introduce Guide-Align, a two-stage approach. Initially, a safety-trained\nmodel identifies potential risks and formulates specific guidelines for various\ninputs, establishing a comprehensive library of guidelines and a model for\ninput-guidelines retrieval. Subsequently, the retrieval model correlates new\ninputs with relevant guidelines, which guide LLMs in response generation to\nensure safe and high-quality outputs, thereby aligning with human values. An\nadditional optional stage involves fine-tuning a model with well-aligned\ndatasets generated through the process implemented in the second stage. Our\nmethod customizes guidelines to accommodate diverse inputs, thereby enhancing\nthe fine-grainedness and comprehensiveness of the guideline library.\nFurthermore, it incorporates safety expertise from a safety-trained LLM through\na lightweight retrieval model. We evaluate our approach on three benchmarks,\ndemonstrating significant improvements in LLM security and quality. Notably,\nour fine-tuned model, Labrador, even at 13 billion parameters, outperforms\nGPT-3.5-turbo and surpasses GPT-4 in alignment capabilities.", "published": "2024-03-18 14:48:29", "link": "http://arxiv.org/abs/2403.11838v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QueryAgent: A Reliable and Efficient Reasoning Framework with\n  Environmental Feedback-based Self-Correction", "abstract": "Employing Large Language Models (LLMs) for semantic parsing has achieved\nremarkable success. However, we find existing methods fall short in terms of\nreliability and efficiency when hallucinations are encountered. In this paper,\nwe address these challenges with a framework called QueryAgent, which solves a\nquestion step-by-step and performs step-wise self-correction. We introduce an\nenvironmental feedback-based self-correction method called ERASER. Unlike\ntraditional approaches, ERASER leverages rich environmental feedback in the\nintermediate steps to perform selective and differentiated self-correction only\nwhen necessary. Experimental results demonstrate that QueryAgent notably\noutperforms all previous few-shot methods using only one example on GrailQA and\nGraphQ by 7.0 and 15.0 F1. Moreover, our approach exhibits superiority in terms\nof efficiency, including runtime, query overhead, and API invocation costs. By\nleveraging ERASER, we further improve another baseline (i.e., AgentBench) by\napproximately 10 points, revealing the strong transferability of our approach.", "published": "2024-03-18 15:39:14", "link": "http://arxiv.org/abs/2403.11886v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CICLe: Conformal In-Context Learning for Largescale Multi-Class Food\n  Risk Classification", "abstract": "Contaminated or adulterated food poses a substantial risk to human health.\nGiven sets of labeled web texts for training, Machine Learning and Natural\nLanguage Processing can be applied to automatically detect such risks. We\npublish a dataset of 7,546 short texts describing public food recall\nannouncements. Each text is manually labeled, on two granularity levels (coarse\nand fine), for food products and hazards that the recall corresponds to. We\ndescribe the dataset and benchmark naive, traditional, and Transformer models.\nBased on our analysis, Logistic Regression based on a tf-idf representation\noutperforms RoBERTa and XLM-R on classes with low support. Finally, we discuss\ndifferent prompting strategies and present an LLM-in-the-loop framework, based\non Conformal Prediction, which boosts the performance of the base classifier\nwhile reducing energy consumption compared to normal prompting.", "published": "2024-03-18 16:04:55", "link": "http://arxiv.org/abs/2403.11904v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Evolution with Deep Learning", "abstract": "Computational modeling plays an essential role in the study of language\nemergence. It aims to simulate the conditions and learning processes that could\ntrigger the emergence of a structured language within a simulated controlled\nenvironment. Several methods have been used to investigate the origin of our\nlanguage, including agent-based systems, Bayesian agents, genetic algorithms,\nand rule-based systems. This chapter explores another class of computational\nmodels that have recently revolutionized the field of machine learning: deep\nlearning models. The chapter introduces the basic concepts of deep and\nreinforcement learning methods and summarizes their helpfulness for simulating\nlanguage emergence. It also discusses the key findings, limitations, and recent\nattempts to build realistic simulations. This chapter targets linguists and\ncognitive scientists seeking an introduction to deep learning as a tool to\ninvestigate language evolution.", "published": "2024-03-18 16:52:54", "link": "http://arxiv.org/abs/2403.11958v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "EasyJailbreak: A Unified Framework for Jailbreaking Large Language\n  Models", "abstract": "Jailbreak attacks are crucial for identifying and mitigating the security\nvulnerabilities of Large Language Models (LLMs). They are designed to bypass\nsafeguards and elicit prohibited outputs. However, due to significant\ndifferences among various jailbreak methods, there is no standard\nimplementation framework available for the community, which limits\ncomprehensive security evaluations. This paper introduces EasyJailbreak, a\nunified framework simplifying the construction and evaluation of jailbreak\nattacks against LLMs. It builds jailbreak attacks using four components:\nSelector, Mutator, Constraint, and Evaluator. This modular framework enables\nresearchers to easily construct attacks from combinations of novel and existing\ncomponents. So far, EasyJailbreak supports 11 distinct jailbreak methods and\nfacilitates the security validation of a broad spectrum of LLMs. Our validation\nacross 10 distinct LLMs reveals a significant vulnerability, with an average\nbreach probability of 60% under various jailbreaking attacks. Notably, even\nadvanced models like GPT-3.5-Turbo and GPT-4 exhibit average Attack Success\nRates (ASR) of 57% and 33%, respectively. We have released a wealth of\nresources for researchers, including a web platform, PyPI published package,\nscreencast video, and experimental outputs.", "published": "2024-03-18 18:39:53", "link": "http://arxiv.org/abs/2403.12171v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models to Extract Information on Substance Use\n  Disorder Severity from Clinical Notes: A Zero-shot Learning Approach", "abstract": "Substance use disorder (SUD) poses a major concern due to its detrimental\neffects on health and society. SUD identification and treatment depend on a\nvariety of factors such as severity, co-determinants (e.g., withdrawal\nsymptoms), and social determinants of health. Existing diagnostic coding\nsystems used by American insurance providers, like the International\nClassification of Diseases (ICD-10), lack granularity for certain diagnoses,\nbut clinicians will add this granularity (as that found within the Diagnostic\nand Statistical Manual of Mental Disorders classification or DSM-5) as\nsupplemental unstructured text in clinical notes. Traditional natural language\nprocessing (NLP) methods face limitations in accurately parsing such diverse\nclinical language. Large Language Models (LLMs) offer promise in overcoming\nthese challenges by adapting to diverse language patterns. This study\ninvestigates the application of LLMs for extracting severity-related\ninformation for various SUD diagnoses from clinical notes. We propose a\nworkflow employing zero-shot learning of LLMs with carefully crafted prompts\nand post-processing techniques. Through experimentation with Flan-T5, an\nopen-source LLM, we demonstrate its superior recall compared to the rule-based\napproach. Focusing on 11 categories of SUD diagnoses, we show the effectiveness\nof LLMs in extracting severity information, contributing to improved risk\nassessment and treatment planning for SUD patients.", "published": "2024-03-18 22:39:03", "link": "http://arxiv.org/abs/2403.12297v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient\n  LLMs Under Compression", "abstract": "Compressing high-capability Large Language Models (LLMs) has emerged as a\nfavored strategy for resource-efficient inferences. While state-of-the-art\n(SoTA) compression methods boast impressive advancements in preserving benign\ntask performance, the potential risks of compression in terms of safety and\ntrustworthiness have been largely neglected. This study conducts the first,\nthorough evaluation of three (3) leading LLMs using five (5) SoTA compression\ntechniques across eight (8) trustworthiness dimensions. Our experiments\nhighlight the intricate interplay between compression and trustworthiness,\nrevealing some interesting patterns. We find that quantization is currently a\nmore effective approach than pruning in achieving efficiency and\ntrustworthiness simultaneously. For instance, a 4-bit quantized model retains\nthe trustworthiness of its original counterpart, but model pruning\nsignificantly degrades trustworthiness, even at 50% sparsity. Moreover,\nemploying quantization within a moderate bit range could unexpectedly improve\ncertain trustworthiness dimensions such as ethics and fairness. Conversely,\nextreme quantization to very low bit levels (3 bits) tends to reduce\ntrustworthiness significantly. This increased risk cannot be uncovered by\nlooking at benign performance alone, in turn, mandating comprehensive\ntrustworthiness evaluation in practice. These findings culminate in practical\nrecommendations for simultaneously achieving high utility, efficiency, and\ntrustworthiness in LLMs. Code and models are available at\nhttps://decoding-comp-trust.github.io.", "published": "2024-03-18 01:38:19", "link": "http://arxiv.org/abs/2403.15447v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hatred Stems from Ignorance! Distillation of the Persuasion Modes in\n  Countering Conversational Hate Speech", "abstract": "Examining the factors that the counterspeech uses are at the core of\nunderstanding the optimal methods for confronting hate speech online. Various\nstudies have assessed the emotional base factors used in counter speech, such\nas emotional empathy, offensiveness, and hostility. To better understand the\ncounterspeech used in conversations, this study distills persuasion modes into\nreason, emotion, and credibility and evaluates their use in two types of\nconversation interactions: closed (multi-turn) and open (single-turn)\nconcerning racism, sexism, and religious bigotry. The evaluation covers the\ndistinct behaviors seen with human-sourced as opposed to machine-generated\ncounterspeech. It also assesses the interplay between the stance taken and the\nmode of persuasion seen in the counterspeech.\n  Notably, we observe nuanced differences in the counterspeech persuasion modes\nused in open and closed interactions, especially in terms of the topic, with a\ngeneral tendency to use reason as a persuasion mode to express the counterpoint\nto hate comments. The machine-generated counterspeech tends to exhibit an\nemotional persuasion mode, while human counters lean toward reason.\nFurthermore, our study shows that reason tends to obtain more supportive\nreplies than other persuasion modes. The findings highlight the potential for\nincorporating persuasion modes into studies about countering hate speech, as\nthey can serve as an optimal means of explainability and pave the way for the\nfurther adoption of the reply's stance and the role it plays in assessing what\ncomprises the optimal counterspeech.", "published": "2024-03-18 07:20:35", "link": "http://arxiv.org/abs/2403.15449v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Loops On Retrieval Augmented Generation (LoRAG)", "abstract": "This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new\nframework designed to enhance the quality of retrieval-augmented text\ngeneration through the incorporation of an iterative loop mechanism. The\narchitecture integrates a generative model, a retrieval mechanism, and a\ndynamic loop module, allowing for iterative refinement of the generated text\nthrough interactions with relevant information retrieved from the input\ncontext. Experimental evaluations on benchmark datasets demonstrate that LoRAG\nsurpasses existing state-of-the-art models in terms of BLEU score, ROUGE score,\nand perplexity, showcasing its effectiveness in achieving both coherence and\nrelevance in generated text. The qualitative assessment further illustrates\nLoRAG's capability to produce contextually rich and coherent outputs. This\nresearch contributes valuable insights into the potential of iterative loops in\nmitigating challenges in text generation, positioning LoRAG as a promising\nadvancement in the field.", "published": "2024-03-18 15:19:17", "link": "http://arxiv.org/abs/2403.15450v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "What Are Tools Anyway? A Survey from the Language Model Perspective", "abstract": "Language models (LMs) are powerful yet mostly for text generation tasks.\nTools have substantially enhanced their performance for tasks that require\ncomplex skills. However, many works adopt the term \"tool\" in different ways,\nraising the question: What is a tool anyway? Subsequently, where and how do\ntools help LMs? In this survey, we provide a unified definition of tools as\nexternal programs used by LMs, and perform a systematic review of LM tooling\nscenarios and approaches. Grounded on this review, we empirically study the\nefficiency of various tooling methods by measuring their required compute and\nperformance gains on various benchmarks, and highlight some challenges and\npotential future research in the field.", "published": "2024-03-18 17:20:07", "link": "http://arxiv.org/abs/2403.15452v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emotion Detection with Transformers: A Comparative Study", "abstract": "In this study, we explore the application of transformer-based models for\nemotion classification on text data. We train and evaluate several pre-trained\ntransformer models, on the Emotion dataset using different variants of\ntransformers. The paper also analyzes some factors that in-fluence the\nperformance of the model, such as the fine-tuning of the transformer layer, the\ntrainability of the layer, and the preprocessing of the text data. Our analysis\nreveals that commonly applied techniques like removing punctuation and stop\nwords can hinder model performance. This might be because transformers strength\nlies in understanding contextual relationships within text. Elements like\npunctuation and stop words can still convey sentiment or emphasis and removing\nthem might disrupt this context.", "published": "2024-03-18 23:22:50", "link": "http://arxiv.org/abs/2403.15454v4", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Improving Sampling Methods for Fine-tuning SentenceBERT in Text Streams", "abstract": "The proliferation of textual data on the Internet presents a unique\nopportunity for institutions and companies to monitor public opinion about\ntheir services and products. Given the rapid generation of such data, the text\nstream mining setting, which handles sequentially arriving, potentially\ninfinite text streams, is often more suitable than traditional batch learning.\nWhile pre-trained language models are commonly employed for their high-quality\ntext vectorization capabilities in streaming contexts, they face challenges\nadapting to concept drift - the phenomenon where the data distribution changes\nover time, adversely affecting model performance. Addressing the issue of\nconcept drift, this study explores the efficacy of seven text sampling methods\ndesigned to selectively fine-tune language models, thereby mitigating\nperformance degradation. We precisely assess the impact of these methods on\nfine-tuning the SBERT model using four different loss functions. Our\nevaluation, focused on Macro F1-score and elapsed time, employs two text stream\ndatasets and an incremental SVM classifier to benchmark performance. Our\nfindings indicate that Softmax loss and Batch All Triplets loss are\nparticularly effective for text stream classification, demonstrating that\nlarger sample sizes generally correlate with improved macro F1-scores. Notably,\nour proposed WordPieceToken ratio sampling method significantly enhances\nperformance with the identified loss functions, surpassing baseline results.", "published": "2024-03-18 23:41:52", "link": "http://arxiv.org/abs/2403.15455v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive\n  Speech Detection via Large Language Models", "abstract": "The widespread use of social media necessitates reliable and efficient\ndetection of offensive content to mitigate harmful effects. Although\nsophisticated models perform well on individual datasets, they often fail to\ngeneralize due to varying definitions and labeling of \"offensive content.\" In\nthis paper, we introduce HateCOT, an English dataset with over 52,000 samples\nfrom diverse sources, featuring explanations generated by GPT-3.5Turbo and\ncurated by humans. We demonstrate that pretraining on HateCOT significantly\nenhances the performance of open-source Large Language Models on three\nbenchmark datasets for offensive content detection in both zero-shot and\nfew-shot settings, despite differences in domain and task. Additionally,\nHateCOT facilitates effective K-shot fine-tuning of LLMs with limited data and\nimproves the quality of their explanations, as confirmed by our human\nevaluation.", "published": "2024-03-18 04:12:35", "link": "http://arxiv.org/abs/2403.11456v4", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Reasoning Abilities of Large Language Models: In-Depth Analysis on the\n  Abstraction and Reasoning Corpus", "abstract": "The existing methods for evaluating the inference abilities of Large Language\nModels (LLMs) have been predominantly results-centric, making it challenging to\nassess the inference process comprehensively. We introduce a novel approach\nusing the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the\ninference and contextual understanding abilities of LLMs in a process-centric\nmanner, focusing on three key components from the Language of Thought\nHypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our\ncarefully designed experiments reveal that while LLMs demonstrate some\ninference capabilities, they still significantly lag behind human-level\nreasoning in these three aspects. The main contribution of this paper lies in\nintroducing the LoTH perspective, which provides a method for evaluating the\nreasoning process that conventional results-oriented approaches fail to\ncapture, thereby offering new insights into the development of human-level\nreasoning in artificial intelligence systems.", "published": "2024-03-18 13:50:50", "link": "http://arxiv.org/abs/2403.11793v3", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.SC"], "primary_category": "cs.CL"}
{"title": "SSCAE -- Semantic, Syntactic, and Context-aware natural language\n  Adversarial Examples generator", "abstract": "Machine learning models are vulnerable to maliciously crafted Adversarial\nExamples (AEs). Training a machine learning model with AEs improves its\nrobustness and stability against adversarial attacks. It is essential to\ndevelop models that produce high-quality AEs. Developing such models has been\nmuch slower in natural language processing (NLP) than in areas such as computer\nvision. This paper introduces a practical and efficient adversarial attack\nmodel called SSCAE for \\textbf{S}emantic, \\textbf{S}yntactic, and\n\\textbf{C}ontext-aware natural language \\textbf{AE}s generator. SSCAE\nidentifies important words and uses a masked language model to generate an\nearly set of substitutions. Next, two well-known language models are employed\nto evaluate the initial set in terms of semantic and syntactic characteristics.\nWe introduce (1) a dynamic threshold to capture more efficient perturbations\nand (2) a local greedy search to generate high-quality AEs. As a black-box\nmethod, SSCAE generates humanly imperceptible and context-aware AEs that\npreserve semantic consistency and the source language's syntactical and\ngrammatical requirements. The effectiveness and superiority of the proposed\nSSCAE model are illustrated with fifteen comparative experiments and extensive\nsensitivity analysis for parameter optimization. SSCAE outperforms the existing\nmodels in all experiments while maintaining a higher semantic consistency with\na lower query number and a comparable perturbation rate.", "published": "2024-03-18 14:45:20", "link": "http://arxiv.org/abs/2403.11833v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Explainable to Interpretable Deep Learning for Natural Language\n  Processing in Healthcare: How Far from Reality?", "abstract": "Deep learning (DL) has substantially enhanced natural language processing\n(NLP) in healthcare research. However, the increasing complexity of DL-based\nNLP necessitates transparent model interpretability, or at least\nexplainability, for reliable decision-making. This work presents a thorough\nscoping review of explainable and interpretable DL in healthcare NLP. The term\n\"eXplainable and Interpretable Artificial Intelligence\" (XIAI) is introduced to\ndistinguish XAI from IAI. Different models are further categorized based on\ntheir functionality (model-, input-, output-based) and scope (local, global).\nOur analysis shows that attention mechanisms are the most prevalent emerging\nIAI technique. The use of IAI is growing, distinguishing it from XAI. The major\nchallenges identified are that most XIAI does not explore \"global\" modelling\nprocesses, the lack of best practices, and the lack of systematic evaluation\nand benchmarks. One important opportunity is to use attention mechanisms to\nenhance multi-modal XIAI for personalized medicine. Additionally, combining DL\nwith causal logic holds promise. Our discussion encourages the integration of\nXIAI in Large Language Models (LLMs) and domain-specific smaller models. In\nconclusion, XIAI adoption in healthcare requires dedicated in-house expertise.\nCollaboration with domain experts, end-users, and policymakers can lead to\nready-to-use XIAI methods across NLP and medical tasks. While challenges exist,\nXIAI techniques offer a valuable foundation for interpretable NLP algorithms in\nhealthcare.", "published": "2024-03-18 15:53:33", "link": "http://arxiv.org/abs/2403.11894v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Markers and Drivers of Gender Bias in Machine Translations", "abstract": "Implicit gender bias in Large Language Models (LLMs) is a well-documented\nproblem, and implications of gender introduced into automatic translations can\nperpetuate real-world biases. However, some LLMs use heuristics or\npost-processing to mask such bias, making investigation difficult. Here, we\nexamine bias in LLMss via back-translation, using the DeepL translation API to\ninvestigate the bias evinced when repeatedly translating a set of 56 Software\nEngineering tasks used in a previous study. Each statement starts with 'she',\nand is translated first into a 'genderless' intermediate language then back\ninto English; we then examine pronoun-choice in the back-translated texts. We\nexpand prior research in the following ways: (1) by comparing results across\nfive intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and\nHungarian; (2) by proposing a novel metric for assessing the variation in\ngender implied in the repeated translations, avoiding the over-interpretation\nof individual pronouns, apparent in earlier work; (3) by investigating sentence\nfeatures that drive bias; (4) and by comparing results from three time-lapsed\ndatasets to establish the reproducibility of the approach. We found that some\nlanguages display similar patterns of pronoun use, falling into three loose\ngroups, but that patterns vary between groups; this underlines the need to work\nwith multiple languages. We also identify the main verb appearing in a sentence\nas a likely significant driver of implied gender in the translations. Moreover,\nwe see a good level of replicability in the results, and establish that our\nvariation metric proves robust despite an obvious change in the behaviour of\nthe DeepL translation API during the course of the study. These results show\nthat the back-translation method can provide further insights into bias in\nlanguage models.", "published": "2024-03-18 15:54:46", "link": "http://arxiv.org/abs/2403.11896v2", "categories": ["cs.CL", "cs.CY", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Tur[k]ingBench: A Challenge Benchmark for Web Agents", "abstract": "Can advanced multi-modal models effectively tackle complex web-based tasks?\nSuch tasks are often found on crowdsourcing platforms, where crowdworkers\nengage in challenging micro-tasks within web-based environments.\n  Building on this idea, we present TurkingBench, a benchmark consisting of\ntasks presented as web pages with textual instructions and multi-modal\ncontexts. Unlike previous approaches that rely on artificially synthesized web\npages, our benchmark uses natural HTML pages originally designed for\ncrowdsourcing workers to perform various annotation tasks. Each task's HTML\ninstructions are instantiated with different values derived from crowdsourcing\ntasks, creating diverse instances. This benchmark includes 32.2K instances\nspread across 158 tasks.\n  To support the evaluation of TurkingBench, we have developed a framework that\nlinks chatbot responses to actions on web pages (e.g., modifying a text box,\nselecting a radio button). We assess the performance of cutting-edge private\nand open-source models, including language-only and vision-language models\n(such as GPT4 and InternVL), on this benchmark. Our results show that while\nthese models outperform random chance, there is still significant room for\nimprovement. We hope that this benchmark will drive progress in the evaluation\nand development of web-based agents.", "published": "2024-03-18 16:06:30", "link": "http://arxiv.org/abs/2403.11905v4", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Using Generative Text Models to Create Qualitative Codebooks for Student\n  Evaluations of Teaching", "abstract": "Feedback is a critical aspect of improvement. Unfortunately, when there is a\nlot of feedback from multiple sources, it can be difficult to distill the\ninformation into actionable insights. Consider student evaluations of teaching\n(SETs), which are important sources of feedback for educators. They can give\ninstructors insights into what worked during a semester. A collection of SETs\ncan also be useful to administrators as signals for courses or entire programs.\nHowever, on a large scale as in high-enrollment courses or administrative\nrecords over several years, the volume of SETs can render them difficult to\nanalyze. In this paper, we discuss a novel method for analyzing SETs using\nnatural language processing (NLP) and large language models (LLMs). We\ndemonstrate the method by applying it to a corpus of 5,000 SETs from a large\npublic university. We show that the method can be used to extract, embed,\ncluster, and summarize the SETs to identify the themes they express. More\ngenerally, this work illustrates how to use the combination of NLP techniques\nand LLMs to generate a codebook for SETs. We conclude by discussing the\nimplications of this method for analyzing SETs and other types of student\nwriting in teaching and research settings.", "published": "2024-03-18 17:21:35", "link": "http://arxiv.org/abs/2403.11984v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "EnvGen: Generating and Adapting Environments via LLMs for Training\n  Embodied Agents", "abstract": "Recent SOTA approaches for embodied learning via interaction directly employ\nlarge language models (LLMs) as agents to determine the next steps in an\nenvironment. Due to their world knowledge and reasoning capabilities, LLM\nagents achieve stronger performance than previous smaller agents based on\nreinforcement learning (RL); however, frequently calling LLMs is slow and\nexpensive. Instead of directly employing LLMs as agents, can we use LLMs'\nreasoning capabilities to adaptively create training environments to help\nsmaller RL agents learn useful skills that they are weak at? We propose EnvGen,\na novel framework to address this question. We first prompt an LLM to generate\ntraining environments by giving it the task description and simulator\nobjectives that the agents should learn and then asking it to generate a set of\nenvironment configurations (e.g., different terrains, items initially given to\nagents, etc.). Next, we train a small RL agent in a mixture of the original and\nLLM-generated environments. Then, we enable the LLM to continuously adapt the\ngenerated environments to progressively improve the skills that the agent is\nweak at, by providing feedback to the LLM in the form of the agent's\nperformance. We demonstrate the usefulness of EnvGen with comprehensive\nexperiments in Crafter and Heist environments. We find that a small RL agent\ntrained with EnvGen can outperform SOTA methods, including a GPT-4 agent, and\nlearns long-horizon tasks significantly faster. We also show that using an LLM\nto adapt environments dynamically outperforms curriculum learning approaches\nand how the environments are adapted to help improve RL agents' weaker skills\nover time. Additionally, EnvGen is substantially more efficient as it only uses\na small number of LLM calls (e.g., 4 in total), whereas LLM agents require\nthousands of calls. Lastly, we present detailed ablation studies for EnvGen\ndesign choices.", "published": "2024-03-18 17:51:16", "link": "http://arxiv.org/abs/2403.12014v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Supervised Fine-Tuning as Inverse Reinforcement Learning", "abstract": "The prevailing approach to aligning Large Language Models (LLMs) typically\nrelies on human or AI feedback and assumes access to specific types of\npreference datasets. In our work, we question the efficacy of such datasets and\nexplore various scenarios where alignment with expert demonstrations proves\nmore realistic. We build a sequential decision-making framework to formulate\nthe problem of aligning LLMs using demonstration datasets. Drawing insights\nfrom inverse reinforcement learning and imitation learning, we introduce\nvarious approaches for divergence minimization in the LLM alignment tasks. Our\nanalysis highlights the mass-covering and mode-seeking behaviors of these\ndifferent approaches. Inclusively, we examine the pros and cons of the\nclassical supervised fine-tuning method, elaborating on scenarios where\ndifferent methods shine.", "published": "2024-03-18 17:52:57", "link": "http://arxiv.org/abs/2403.12017v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Toolbox for Surfacing Health Equity Harms and Biases in Large Language\n  Models", "abstract": "Large language models (LLMs) hold promise to serve complex health information\nneeds but also have the potential to introduce harm and exacerbate health\ndisparities. Reliably evaluating equity-related model failures is a critical\nstep toward developing systems that promote health equity. We present resources\nand methodologies for surfacing biases with potential to precipitate\nequity-related harms in long-form, LLM-generated answers to medical questions\nand conduct a large-scale empirical case study with the Med-PaLM 2 LLM. Our\ncontributions include a multifactorial framework for human assessment of\nLLM-generated answers for biases, and EquityMedQA, a collection of seven\ndatasets enriched for adversarial queries. Both our human assessment framework\nand dataset design process are grounded in an iterative participatory approach\nand review of Med-PaLM 2 answers. Through our empirical study, we find that our\napproach surfaces biases that may be missed via narrower evaluation approaches.\nOur experience underscores the importance of using diverse assessment\nmethodologies and involving raters of varying backgrounds and expertise. While\nour approach is not sufficient to holistically assess whether the deployment of\nan AI system promotes equitable health outcomes, we hope that it can be\nleveraged and built upon towards a shared goal of LLMs that promote accessible\nand equitable healthcare.", "published": "2024-03-18 17:56:37", "link": "http://arxiv.org/abs/2403.12025v2", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "FlexCap: Describe Anything in Images in Controllable Detail", "abstract": "We introduce FlexCap, a vision-language model that generates region-specific\ndescriptions of varying lengths. FlexCap is trained to produce\nlength-conditioned captions for input boxes, enabling control over information\ndensity, with descriptions ranging from concise object labels to detailed\ncaptions. To achieve this, we create large-scale training datasets of image\nregion descriptions with varying lengths from captioned web images. We\ndemonstrate FlexCap's effectiveness in several applications: first, it achieves\nstrong performance in dense captioning tasks on the Visual Genome dataset.\nSecond, we show how FlexCap's localized descriptions can serve as input to a\nlarge language model to create a visual question answering (VQA) system,\nachieving state-of-the-art zero-shot performance on multiple VQA benchmarks.\nOur experiments illustrate FlexCap's utility for tasks including image\nlabeling, object attribute recognition, and visual dialog. Project webpage:\nhttps://flex-cap.github.io .", "published": "2024-03-18 17:57:02", "link": "http://arxiv.org/abs/2403.12026v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Pixels to Insights: A Survey on Automatic Chart Understanding in\n  the Era of Large Foundation Models", "abstract": "Data visualization in the form of charts plays a pivotal role in data\nanalysis, offering critical insights and aiding in informed decision-making.\nAutomatic chart understanding has witnessed significant advancements with the\nrise of large foundation models in recent years. Foundation models, such as\nlarge language models, have revolutionized various natural language processing\ntasks and are increasingly being applied to chart understanding tasks. This\nsurvey paper provides a comprehensive overview of the recent developments,\nchallenges, and future directions in chart understanding within the context of\nthese foundation models. We review fundamental building blocks crucial for\nstudying chart understanding tasks. Additionally, we explore various tasks and\ntheir evaluation metrics and sources of both charts and textual inputs. Various\nmodeling strategies are then examined, encompassing both classification-based\nand generation-based approaches, along with tool augmentation techniques that\nenhance chart understanding performance. Furthermore, we discuss the\nstate-of-the-art performance of each task and discuss how we can improve the\nperformance. Challenges and future directions are addressed, highlighting the\nimportance of several topics, such as domain-specific charts, lack of efforts\nin developing evaluation metrics, and agent-oriented settings. This survey\npaper serves as a comprehensive resource for researchers and practitioners in\nthe fields of natural language processing, computer vision, and data analysis,\nproviding valuable insights and directions for future research in chart\nunderstanding leveraging large foundation models. The studies mentioned in this\npaper, along with emerging new research, will be continually updated at:\nhttps://github.com/khuangaf/Awesome-Chart-Understanding.", "published": "2024-03-18 17:57:09", "link": "http://arxiv.org/abs/2403.12027v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Fusing Domain-Specific Content from Large Language Models into Knowledge\n  Graphs for Enhanced Zero Shot Object State Classification", "abstract": "Domain-specific knowledge can significantly contribute to addressing a wide\nvariety of vision tasks. However, the generation of such knowledge entails\nconsiderable human labor and time costs. This study investigates the potential\nof Large Language Models (LLMs) in generating and providing domain-specific\ninformation through semantic embeddings. To achieve this, an LLM is integrated\ninto a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors\nin the context of the Vision-based Zero-shot Object State Classification task.\nWe thoroughly examine the behavior of the LLM through an extensive ablation\nstudy. Our findings reveal that the integration of LLM-based embeddings, in\ncombination with general-purpose pre-trained embeddings, leads to substantial\nperformance improvements. Drawing insights from this ablation study, we conduct\na comparative analysis against competing models, thereby highlighting the\nstate-of-the-art performance achieved by the proposed approach.", "published": "2024-03-18 18:08:44", "link": "http://arxiv.org/abs/2403.12151v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "TnT-LLM: Text Mining at Scale with Large Language Models", "abstract": "Transforming unstructured text into structured and meaningful forms,\norganized by useful category labels, is a fundamental step in text mining for\ndownstream analysis and application. However, most existing methods for\nproducing label taxonomies and building text-based label classifiers still rely\nheavily on domain expertise and manual curation, making the process expensive\nand time-consuming. This is particularly challenging when the label space is\nunder-specified and large-scale data annotations are unavailable. In this\npaper, we address these challenges with Large Language Models (LLMs), whose\nprompt-based interface facilitates the induction and use of large-scale pseudo\nlabels. We propose TnT-LLM, a two-phase framework that employs LLMs to automate\nthe process of end-to-end label generation and assignment with minimal human\neffort for any given use-case. In the first phase, we introduce a zero-shot,\nmulti-stage reasoning approach which enables LLMs to produce and refine a label\ntaxonomy iteratively. In the second phase, LLMs are used as data labelers that\nyield training samples so that lightweight supervised classifiers can be\nreliably built, deployed, and served at scale. We apply TnT-LLM to the analysis\nof user intent and conversational domain for Bing Copilot (formerly Bing Chat),\nan open-domain chat-based search engine. Extensive experiments using both human\nand automatic evaluation metrics demonstrate that TnT-LLM generates more\naccurate and relevant label taxonomies when compared against state-of-the-art\nbaselines, and achieves a favorable balance between accuracy and efficiency for\nclassification at scale. We also share our practical experiences and insights\non the challenges and opportunities of using LLMs for large-scale text mining\nin real-world applications.", "published": "2024-03-18 18:45:28", "link": "http://arxiv.org/abs/2403.12173v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluating Named Entity Recognition: A comparative analysis of mono- and\n  multilingual transformer models on a novel Brazilian corporate earnings call\n  transcripts dataset", "abstract": "Since 2018, when the Transformer architecture was introduced, Natural\nLanguage Processing has gained significant momentum with pre-trained\nTransformer-based models that can be fine-tuned for various tasks. Most models\nare pre-trained on large English corpora, making them less applicable to other\nlanguages, such as Brazilian Portuguese. In our research, we identified two\nmodels pre-trained in Brazilian Portuguese (BERTimbau and PTT5) and two\nmultilingual models (mBERT and mT5). BERTimbau and mBERT use only the Encoder\nmodule, while PTT5 and mT5 use both the Encoder and Decoder. Our study aimed to\nevaluate their performance on a financial Named Entity Recognition (NER) task\nand determine the computational requirements for fine-tuning and inference. To\nthis end, we developed the Brazilian Financial NER (BraFiNER) dataset,\ncomprising sentences from Brazilian banks' earnings calls transcripts annotated\nusing a weakly supervised approach. Additionally, we introduced a novel\napproach that reframes the token classification task as a text generation\nproblem. After fine-tuning the models, we evaluated them using performance and\nerror metrics. Our findings reveal that BERT-based models consistently\noutperform T5-based models. While the multilingual models exhibit comparable\nmacro F1-scores, BERTimbau demonstrates superior performance over PTT5. In\nterms of error metrics, BERTimbau outperforms the other models. We also\nobserved that PTT5 and mT5 generated sentences with changes in monetary and\npercentage values, highlighting the importance of accuracy and consistency in\nthe financial domain. Our findings provide insights into the differing\nperformance of BERT- and T5-based models for the NER task.", "published": "2024-03-18 19:53:56", "link": "http://arxiv.org/abs/2403.12212v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50"], "primary_category": "cs.CL"}
{"title": "Reference-based Metrics Disprove Themselves in Question Generation", "abstract": "Reference-based metrics such as BLEU and BERTScore are widely used to\nevaluate question generation (QG). In this study, on QG benchmarks such as\nSQuAD and HotpotQA, we find that using human-written references cannot\nguarantee the effectiveness of the reference-based metrics. Most QG benchmarks\nhave only one reference; we replicate the annotation process and collect\nanother reference. A good metric is expected to grade a human-validated\nquestion no worse than generated questions. However, the results of\nreference-based metrics on our newly collected reference disproved the metrics\nthemselves. We propose a reference-free metric consisted of multi-dimensional\ncriteria such as naturalness, answerability, and complexity, utilizing large\nlanguage models. These criteria are not constrained to the syntactic or\nsemantic of a single reference question, and the metric does not require a\ndiverse set of references. Experiments reveal that our metric accurately\ndistinguishes between high-quality questions and flawed ones, and achieves\nstate-of-the-art alignment with human judgment.", "published": "2024-03-18 20:47:10", "link": "http://arxiv.org/abs/2403.12242v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FinLlama: Financial Sentiment Classification for Algorithmic Trading\n  Applications", "abstract": "There are multiple sources of financial news online which influence market\nmovements and trader's decisions. This highlights the need for accurate\nsentiment analysis, in addition to having appropriate algorithmic trading\ntechniques, to arrive at better informed trading decisions. Standard lexicon\nbased sentiment approaches have demonstrated their power in aiding financial\ndecisions. However, they are known to suffer from issues related to context\nsensitivity and word ordering. Large Language Models (LLMs) can also be used in\nthis context, but they are not finance-specific and tend to require significant\ncomputational resources. To facilitate a finance specific LLM framework, we\nintroduce a novel approach based on the Llama 2 7B foundational model, in order\nto benefit from its generative nature and comprehensive language manipulation.\nThis is achieved by fine-tuning the Llama2 7B model on a small portion of\nsupervised financial sentiment analysis data, so as to jointly handle the\ncomplexities of financial lexicon and context, and further equipping it with a\nneural network based decision mechanism. Such a generator-classifier scheme,\nreferred to as FinLlama, is trained not only to classify the sentiment valence\nbut also quantify its strength, thus offering traders a nuanced insight into\nfinancial news articles. Complementing this, the implementation of\nparameter-efficient fine-tuning through LoRA optimises trainable parameters,\nthus minimising computational and memory requirements, without sacrificing\naccuracy. Simulation results demonstrate the ability of the proposed FinLlama\nto provide a framework for enhanced portfolio management decisions and\nincreased market returns. These results underpin the ability of FinLlama to\nconstruct high-return portfolios which exhibit enhanced resilience, even during\nvolatile periods and unpredictable market events.", "published": "2024-03-18 22:11:00", "link": "http://arxiv.org/abs/2403.12285v1", "categories": ["cs.CL", "cs.LG", "q-fin.ST", "q-fin.TR"], "primary_category": "cs.CL"}
{"title": "Methods for Generating Drift in Text Streams", "abstract": "Systems and individuals produce data continuously. On the Internet, people\nshare their knowledge, sentiments, and opinions, provide reviews about services\nand products, and so on. Automatically learning from these textual data can\nprovide insights to organizations and institutions, thus preventing financial\nimpacts, for example. To learn from textual data over time, the machine\nlearning system must account for concept drift. Concept drift is a frequent\nphenomenon in real-world datasets and corresponds to changes in data\ndistribution over time. For instance, a concept drift occurs when sentiments\nchange or a word's meaning is adjusted over time. Although concept drift is\nfrequent in real-world applications, benchmark datasets with labeled drifts are\nrare in the literature. To bridge this gap, this paper provides four textual\ndrift generation methods to ease the production of datasets with labeled\ndrifts. These methods were applied to Yelp and Airbnb datasets and tested using\nincremental classifiers respecting the stream mining paradigm to evaluate their\nability to recover from the drifts. Results show that all methods have their\nperformance degraded right after the drifts, and the incremental SVM is the\nfastest to run and recover the previous performance levels regarding accuracy\nand Macro F1-Score.", "published": "2024-03-18 23:48:33", "link": "http://arxiv.org/abs/2403.12328v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Decoding Multilingual Topic Dynamics and Trend Identification through\n  ARIMA Time Series Analysis on Social Networks: A Novel Data Translation\n  Framework Enhanced by LDA/HDP Models", "abstract": "In this study, the authors present a novel methodology adept at decoding\nmultilingual topic dynamics and identifying communication trends during crises.\nWe focus on dialogues within Tunisian social networks during the Coronavirus\nPandemic and other notable themes like sports and politics. We start by\naggregating a varied multilingual corpus of comments relevant to these\nsubjects. This dataset undergoes rigorous refinement during data preprocessing.\nWe then introduce our No-English-to-English Machine Translation approach to\nhandle linguistic differences. Empirical tests of this method showed high\naccuracy and F1 scores, highlighting its suitability for linguistically\ncoherent tasks. Delving deeper, advanced modeling techniques, specifically LDA\nand HDP models are employed to extract pertinent topics from the translated\ncontent. This leads to applying ARIMA time series analysis to decode evolving\ntopic trends. Applying our method to a multilingual Tunisian dataset, we\neffectively identified key topics mirroring public sentiment. Such insights\nprove vital for organizations and governments striving to understand public\nperspectives during crises. Compared to standard approaches, our model\noutperforms, as confirmed by metrics like Coherence Score, U-mass, and Topic\nCoherence. Additionally, an in-depth assessment of the identified topics\nrevealed notable thematic shifts in discussions, with our trends identification\nindicating impressive accuracy, backed by RMSE-based analysis.", "published": "2024-03-18 00:01:10", "link": "http://arxiv.org/abs/2403.15445v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Span-Oriented Information Extraction -- A Unifying Perspective on\n  Information Extraction", "abstract": "Information Extraction refers to a collection of tasks within Natural\nLanguage Processing (NLP) that identifies sub-sequences within text and their\nlabels. These tasks have been used for many years to link extract relevant\ninformation and to link free text to structured data. However, the\nheterogeneity among information extraction tasks impedes progress in this area.\nWe therefore offer a unifying perspective centered on what we define to be\nspans in text. We then re-orient these seemingly incongruous tasks into this\nunified perspective and then re-present the wide assortment of information\nextraction tasks as variants of the same basic Span-Oriented Information\nExtraction task.", "published": "2024-03-18 20:10:44", "link": "http://arxiv.org/abs/2403.15453v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Disease Labeler for Chinese Chest X-Ray Report Generation", "abstract": "In the field of medical image analysis, the scarcity of Chinese chest X-ray\nreport datasets has hindered the development of technology for generating\nChinese chest X-ray reports. On one hand, the construction of a Chinese chest\nX-ray report dataset is limited by the time-consuming and costly process of\naccurate expert disease annotation. On the other hand, a single natural\nlanguage generation metric is commonly used to evaluate the similarity between\ngenerated and ground-truth reports, while the clinical accuracy and\neffectiveness of the generated reports rely on an accurate disease labeler\n(classifier). To address the issues, this study proposes a disease labeler\ntailored for the generation of Chinese chest X-ray reports. This labeler\nleverages a dual BERT architecture to handle diagnostic reports and clinical\ninformation separately and constructs a hierarchical label learning algorithm\nbased on the affiliation between diseases and body parts to enhance text\nclassification performance. Utilizing this disease labeler, a Chinese chest\nX-ray report dataset comprising 51,262 report samples was established. Finally,\nexperiments and analyses were conducted on a subset of expert-annotated Chinese\nchest X-ray reports, validating the effectiveness of the proposed disease\nlabeler.", "published": "2024-03-18 07:10:33", "link": "http://arxiv.org/abs/2404.16852v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Linguacodus: A Synergistic Framework for Transformative Code Generation\n  in Machine Learning Pipelines", "abstract": "In the ever-evolving landscape of machine learning, seamless translation of\nnatural language descriptions into executable code remains a formidable\nchallenge. This paper introduces Linguacodus, an innovative framework designed\nto tackle this challenge by deploying a dynamic pipeline that iteratively\ntransforms natural language task descriptions into code through high-level\ndata-shaping instructions. The core of Linguacodus is a fine-tuned large\nlanguage model (LLM), empowered to evaluate diverse solutions for various\nproblems and select the most fitting one for a given task. This paper details\nthe fine-tuning process, and sheds light on how natural language descriptions\ncan be translated into functional code. Linguacodus represents a substantial\nleap towards automated code generation, effectively bridging the gap between\ntask descriptions and executable code. It holds great promise for advancing\nmachine learning applications across diverse domains. Additionally, we propose\nan algorithm capable of transforming a natural description of an ML task into\ncode with minimal human interaction. In extensive experiments on a vast machine\nlearning code dataset originating from Kaggle, we showcase the effectiveness of\nLinguacodus. The investigations highlight its potential applications across\ndiverse domains, emphasizing its impact on applied machine learning in various\nscientific fields.", "published": "2024-03-18 08:58:47", "link": "http://arxiv.org/abs/2403.11585v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Accelerating Scientific Discovery with Generative Knowledge Extraction,\n  Graph-Based Representation, and Multimodal Intelligent Graph Reasoning", "abstract": "Leveraging generative Artificial Intelligence (AI), we have transformed a\ndataset comprising 1,000 scientific papers into an ontological knowledge graph.\nThrough an in-depth structural analysis, we have calculated node degrees,\nidentified communities and connectivities, and evaluated clustering\ncoefficients and betweenness centrality of pivotal nodes, uncovering\nfascinating knowledge architectures. The graph has an inherently scale-free\nnature, is highly connected, and can be used for graph reasoning by taking\nadvantage of transitive and isomorphic properties that reveal unprecedented\ninterdisciplinary relationships that can be used to answer queries, identify\ngaps in knowledge, propose never-before-seen material designs, and predict\nmaterial behaviors. We compute deep node embeddings for combinatorial node\nsimilarity ranking for use in a path sampling strategy links dissimilar\nconcepts that have previously not been related. One comparison revealed\nstructural parallels between biological materials and Beethoven's 9th Symphony,\nhighlighting shared patterns of complexity through isomorphic mapping. In\nanother example, the algorithm proposed a hierarchical mycelium-based composite\nbased on integrating path sampling with principles extracted from Kandinsky's\n'Composition VII' painting. The resulting material integrates an innovative set\nof concepts that include a balance of chaos/order, adjustable porosity,\nmechanical strength, and complex patterned chemical functionalization. We\nuncover other isomorphisms across science, technology and art, revealing a\nnuanced ontology of immanence that reveal a context-dependent heterarchical\ninterplay of constituents. Graph-based generative AI achieves a far higher\ndegree of novelty, explorative capacity, and technical detail, than\nconventional approaches and establishes a widely useful framework for\ninnovation by revealing hidden connections.", "published": "2024-03-18 17:30:27", "link": "http://arxiv.org/abs/2403.11996v3", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Discriminative Neighborhood Smoothing for Generative Anomalous Sound\n  Detection", "abstract": "We propose discriminative neighborhood smoothing of generative anomaly scores\nfor anomalous sound detection. While the discriminative approach is known to\nachieve better performance than generative approaches often, we have found that\nit sometimes causes significant performance degradation due to the discrepancy\nbetween the training and test data, making it less robust than the generative\napproach. Our proposed method aims to compensate for the disadvantages of\ngenerative and discriminative approaches by combining them. Generative anomaly\nscores are smoothed using multiple samples with similar discriminative features\nto improve the performance of the generative approach in an ensemble manner\nwhile keeping its robustness. Experimental results show that our proposed\nmethod greatly improves the original generative method, including absolute\nimprovement of 22% in AUC and robustly works, while a discriminative method\nsuffers from the discrepancy.", "published": "2024-03-18 06:26:32", "link": "http://arxiv.org/abs/2403.11508v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AdaMER-CTC: Connectionist Temporal Classification with Adaptive Maximum\n  Entropy Regularization for Automatic Speech Recognition", "abstract": "In Automatic Speech Recognition (ASR) systems, a recurring obstacle is the\ngeneration of narrowly focused output distributions. This phenomenon emerges as\na side effect of Connectionist Temporal Classification (CTC), a robust sequence\nlearning tool that utilizes dynamic programming for sequence mapping. While\nearlier efforts have tried to combine the CTC loss with an entropy maximization\nregularization term to mitigate this issue, they employed a constant weighting\nterm on the regularization during the training, which we find may not be\noptimal. In this work, we introduce Adaptive Maximum Entropy Regularization\n(AdaMER), a technique that can modulate the impact of entropy regularization\nthroughout the training process. This approach not only refines ASR model\ntraining but ensures that as training proceeds, predictions display the desired\nmodel confidence.", "published": "2024-03-18 08:53:04", "link": "http://arxiv.org/abs/2403.11578v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Latent CLAP Loss for Better Foley Sound Synthesis", "abstract": "Foley sound generation, the art of creating audio for multimedia, has\nrecently seen notable advancements through text-conditioned latent diffusion\nmodels. These systems use multimodal text-audio representation models, such as\nContrastive Language-Audio Pretraining (CLAP), whose objective is to map\ncorresponding audio and text prompts into a joint embedding space. AudioLDM, a\ntext-to-audio model, was the winner of the DCASE2023 task 7 Foley sound\nsynthesis challenge. The winning system fine-tuned the model for specific audio\nclasses and applied a post-filtering method using CLAP similarity scores\nbetween output audio and input text at inference time, requiring the generation\nof extra samples, thus reducing data generation efficiency. We introduce a new\nloss term to enhance Foley sound generation in AudioLDM without post-filtering.\nThis loss term uses a new module based on the CLAP mode-Latent CLAP encode-to\nalign the latent diffusion output with real audio in a shared CLAP embedding\nspace. Our experiments demonstrate that our method effectively reduces the\nFrechet Audio Distance (FAD) score of the generated audio and eliminates the\nneed for post-filtering, thus enhancing generation efficiency.", "published": "2024-03-18 18:55:37", "link": "http://arxiv.org/abs/2403.12182v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Hallucination in Perceptual Metric-Driven Speech Enhancement Networks", "abstract": "Within the area of speech enhancement, there is an ongoing interest in the\ncreation of neural systems which explicitly aim to improve the perceptual\nquality of the processed audio. In concert with this is the topic of\nnon-intrusive (i.e. without clean reference) speech quality prediction, for\nwhich neural networks are trained to predict human-assigned quality labels\ndirectly from distorted audio. When combined, these areas allow for the\ncreation of powerful new speech enhancement systems which can leverage large\nreal-world datasets of distorted audio, by taking inference of a pre-trained\nspeech quality predictor as the sole loss function of the speech enhancement\nsystem. This paper aims to identify a potential pitfall with this approach,\nnamely hallucinations which are introduced by the enhancement system `tricking'\nthe speech quality predictor.", "published": "2024-03-18 12:42:11", "link": "http://arxiv.org/abs/2403.11732v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Multi-loudspeaker Binaural Room Impulse Response Dataset with\n  High-Resolution Translational and Rotational Head Coordinates in a Listening\n  Room", "abstract": "Data report for the 3D3A Lab Binaural Room Impulse Response (BRIR) Dataset\n(https://doi.org/10.34770/6gc9-5787).", "published": "2024-03-18 21:14:18", "link": "http://arxiv.org/abs/2403.12258v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Generalized Multi-Source Inference for Text Conditioned Music Diffusion\n  Models", "abstract": "Multi-Source Diffusion Models (MSDM) allow for compositional musical\ngeneration tasks: generating a set of coherent sources, creating\naccompaniments, and performing source separation. Despite their versatility,\nthey require estimating the joint distribution over the sources, necessitating\npre-separated musical data, which is rarely available, and fixing the number\nand type of sources at training time. This paper generalizes MSDM to arbitrary\ntime-domain diffusion models conditioned on text embeddings. These models do\nnot require separated data as they are trained on mixtures, can parameterize an\narbitrary number of sources, and allow for rich semantic control. We propose an\ninference procedure enabling the coherent generation of sources and\naccompaniments. Additionally, we adapt the Dirac separator of MSDM to perform\nsource separation. We experiment with diffusion models trained on Slakh2100 and\nMTG-Jamendo, showcasing competitive generation and separation results in a\nrelaxed data setting.", "published": "2024-03-18 12:08:01", "link": "http://arxiv.org/abs/2403.11706v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Feature Extraction and Late Fusion Strategy for Audiovisual\n  Emotional Mimicry Intensity Estimation", "abstract": "In this paper, we present the solution to the Emotional Mimicry Intensity\n(EMI) Estimation challenge, which is part of 6th Affective Behavior Analysis\nin-the-wild (ABAW) Competition.The EMI Estimation challenge task aims to\nevaluate the emotional intensity of seed videos by assessing them from a set of\npredefined emotion categories (i.e., \"Admiration\", \"Amusement\",\n\"Determination\", \"Empathic Pain\", \"Excitement\" and \"Joy\"). To tackle this\nchallenge, we extracted rich dual-channel visual features based on ResNet18 and\nAUs for the video modality and effective single-channel features based on\nWav2Vec2.0 for the audio modality. This allowed us to obtain comprehensive\nemotional features for the audiovisual modality. Additionally, leveraging a\nlate fusion strategy, we averaged the predictions of the visual and acoustic\nmodels, resulting in a more accurate estimation of audiovisual emotional\nmimicry intensity. Experimental results validate the effectiveness of our\napproach, with the average Pearson's correlation Coefficient($\\rho$) across the\n6 emotion dimensionson the validation set achieving 0.3288.", "published": "2024-03-18 13:11:10", "link": "http://arxiv.org/abs/2403.11757v2", "categories": ["cs.MM", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Towards the Development of a Real-Time Deepfake Audio Detection System\n  in Communication Platforms", "abstract": "Deepfake audio poses a rising threat in communication platforms,\nnecessitating real-time detection for audio stream integrity. Unlike\ntraditional non-real-time approaches, this study assesses the viability of\nemploying static deepfake audio detection models in real-time communication\nplatforms. An executable software is developed for cross-platform\ncompatibility, enabling real-time execution. Two deepfake audio detection\nmodels based on Resnet and LCNN architectures are implemented using the\nASVspoof 2019 dataset, achieving benchmark performances compared to ASVspoof\n2019 challenge baselines. The study proposes strategies and frameworks for\nenhancing these models, paving the way for real-time deepfake audio detection\nin communication platforms. This work contributes to the advancement of audio\nstream security, ensuring robust detection capabilities in dynamic, real-time\ncommunication scenarios.", "published": "2024-03-18 13:35:10", "link": "http://arxiv.org/abs/2403.11778v1", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural\n  Language Prompt", "abstract": "Recent singing-voice-synthesis (SVS) methods have achieved remarkable audio\nquality and naturalness, yet they lack the capability to control the style\nattributes of the synthesized singing explicitly. We propose Prompt-Singer, the\nfirst SVS method that enables attribute controlling on singer gender, vocal\nrange and volume with natural language. We adopt a model architecture based on\na decoder-only transformer with a multi-scale hierarchy, and design a\nrange-melody decoupled pitch representation that enables text-conditioned vocal\nrange control while keeping melodic accuracy. Furthermore, we explore various\nexperiment settings, including different types of text representations, text\nencoder fine-tuning, and introducing speech data to alleviate data scarcity,\naiming to facilitate further research. Experiments show that our model achieves\nfavorable controlling ability and audio quality. Audio samples are available at\nhttp://prompt-singer.github.io .", "published": "2024-03-18 13:39:05", "link": "http://arxiv.org/abs/2403.11780v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Event Detection and Localization with Distance Estimation", "abstract": "Sound Event Detection and Localization (SELD) is a combined task of\nidentifying sound events and their corresponding direction-of-arrival (DOA).\nWhile this task has numerous applications and has been extensively researched\nin recent years, it fails to provide full information about the sound source\nposition. In this paper, we overcome this problem by extending the task to\nSound Event Detection, Localization with Distance Estimation (3D SELD). We\nstudy two ways of integrating distance estimation within the SELD core - a\nmulti-task approach, in which the problem is tackled by a separate model\noutput, and a single-task approach obtained by extending the multi-ACCDOA\nmethod to include distance information. We investigate both methods for the\nAmbisonic and binaural versions of STARSS23: Sony-TAU Realistic Spatial\nSoundscapes 2023. Moreover, our study involves experiments on the loss function\nrelated to the distance estimation part. Our results show that it is possible\nto perform 3D SELD without any degradation of performance in sound event\ndetection and DOA estimation.", "published": "2024-03-18 14:34:16", "link": "http://arxiv.org/abs/2403.11827v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unimodal Multi-Task Fusion for Emotional Mimicry Intensity Prediction", "abstract": "In this research, we introduce a novel methodology for assessing Emotional\nMimicry Intensity (EMI) as part of the 6th Workshop and Competition on\nAffective Behavior Analysis in-the-wild. Our methodology utilises the Wav2Vec\n2.0 architecture, which has been pre-trained on an extensive podcast dataset,\nto capture a wide array of audio features that include both linguistic and\nparalinguistic components. We refine our feature extraction process by\nemploying a fusion technique that combines individual features with a global\nmean vector, thereby embedding a broader contextual understanding into our\nanalysis. A key aspect of our approach is the multi-task fusion strategy that\nnot only leverages these features but also incorporates a pre-trained\nValence-Arousal-Dominance (VAD) model. This integration is designed to refine\nemotion intensity prediction by concurrently processing multiple emotional\ndimensions, thereby embedding a richer contextual understanding into our\nframework. For the temporal analysis of audio data, our feature fusion process\nutilises a Long Short-Term Memory (LSTM) network. This approach, which relies\nsolely on the provided audio data, shows marked advancements over the existing\nbaseline, offering a more comprehensive understanding of emotional mimicry in\nnaturalistic settings, achieving the second place in the EMI challenge.", "published": "2024-03-18 15:32:02", "link": "http://arxiv.org/abs/2403.11879v4", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Notochord: a Flexible Probabilistic Model for Real-Time MIDI Performance", "abstract": "Deep learning-based probabilistic models of musical data are producing\nincreasingly realistic results and promise to enter creative workflows of many\nkinds. Yet they have been little-studied in a performance setting, where the\nresults of user actions typically ought to feel instantaneous. To enable such\nstudy, we designed Notochord, a deep probabilistic model for sequences of\nstructured events, and trained an instance of it on the Lakh MIDI dataset. Our\nprobabilistic formulation allows interpretable interventions at a sub-event\nlevel, which enables one model to act as a backbone for diverse interactive\nmusical functions including steerable generation, harmonization, machine\nimprovisation, and likelihood-based interfaces. Notochord can generate\npolyphonic and multi-track MIDI, and respond to inputs with latency below ten\nmilliseconds. Training code, model checkpoints and interactive examples are\nprovided as open source software.", "published": "2024-03-18 17:35:02", "link": "http://arxiv.org/abs/2403.12000v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "QEAN: Quaternion-Enhanced Attention Network for Visual Dance Generation", "abstract": "The study of music-generated dance is a novel and challenging Image\ngeneration task. It aims to input a piece of music and seed motions, then\ngenerate natural dance movements for the subsequent music. Transformer-based\nmethods face challenges in time series prediction tasks related to human\nmovements and music due to their struggle in capturing the nonlinear\nrelationship and temporal aspects. This can lead to issues like joint\ndeformation, role deviation, floating, and inconsistencies in dance movements\ngenerated in response to the music. In this paper, we propose a\nQuaternion-Enhanced Attention Network (QEAN) for visual dance synthesis from a\nquaternion perspective, which consists of a Spin Position Embedding (SPE)\nmodule and a Quaternion Rotary Attention (QRA) module. First, SPE embeds\nposition information into self-attention in a rotational manner, leading to\nbetter learning of features of movement sequences and audio sequences, and\nimproved understanding of the connection between music and dance. Second, QRA\nrepresents and fuses 3D motion features and audio features in the form of a\nseries of quaternions, enabling the model to better learn the temporal\ncoordination of music and dance under the complex temporal cycle conditions of\ndance generation. Finally, we conducted experiments on the dataset AIST++, and\nthe results show that our approach achieves better and more robust performance\nin generating accurate, high-quality dance movements. Our source code and\ndataset can be available from https://github.com/MarasyZZ/QEAN and\nhttps://google.github.io/aistplusplus_dataset respectively.", "published": "2024-03-18 09:58:43", "link": "http://arxiv.org/abs/2403.11626v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
