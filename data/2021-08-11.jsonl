{"title": "Perturbing Inputs for Fragile Interpretations in Deep Natural Language\n  Processing", "abstract": "Interpretability methods like Integrated Gradient and LIME are popular\nchoices for explaining natural language model predictions with relative word\nimportance scores. These interpretations need to be robust for trustworthy NLP\napplications in high-stake areas like medicine or finance. Our paper\ndemonstrates how interpretations can be manipulated by making simple word\nperturbations on an input text. Via a small portion of word-level swaps, these\nadversarial perturbations aim to make the resulting text semantically and\nspatially similar to its seed input (therefore sharing similar\ninterpretations). Simultaneously, the generated examples achieve the same\nprediction label as the seed yet are given a substantially different\nexplanation by the interpretation methods. Our experiments generate fragile\ninterpretations to attack two SOTA interpretation methods, across three popular\nTransformer models and on two different NLP datasets. We observe that the rank\norder correlation drops by over 20% when less than 10% of words are perturbed\non average. Further, rank-order correlation keeps decreasing as more words get\nperturbed. Furthermore, we demonstrate that candidates generated from our\nmethod have good quality metrics.", "published": "2021-08-11 02:07:21", "link": "http://arxiv.org/abs/2108.04990v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Position-based Contributive Embeddings for Aspect-Based Sentiment\n  Analysis", "abstract": "Aspect-based sentiment analysis (ABSA), exploring sentiment polarity of\naspect-given sentence, is a fine-grained task in the field of nature language\nprocessing. Previously researches typically tend to predict polarity based on\nthe meaning of aspect and opinions. However, those approaches mainly focus on\nconsidering relations implicitly at the word level, ignore the historical\nimpact of other positional words when the aspect appears in a certain position.\nTherefore, we propose a Position-based Contributive Embeddings (PosCE) to\nhighlight the historical reference to special position aspect. Contribution of\neach positional words to the polarity is similar to the process of fairly\ndistributing gains to several actors working in coalition (game theory).\nTherefore, we quote from the method of Shapley Value and finally gain PosCE to\nenhance the aspect-based representation for ABSA task. Furthermore, the PosCE\ncan also be used for improving performances on multimodal ABSA task. Extensive\nexperiments on both text and text-audio level using SemEval dataset show that\nthe mainstream models advance performance in accuracy and F1 (increase 2.82%\nand 4.21% on average respectively) by applying our PosCE.", "published": "2021-08-11 08:43:13", "link": "http://arxiv.org/abs/2108.05098v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Icelandic Parallel Abstracts Corpus", "abstract": "We present a new Icelandic-English parallel corpus, the Icelandic Parallel\nAbstracts Corpus (IPAC), composed of abstracts from student theses and\ndissertations. The texts were collected from the Skemman repository which keeps\nrecords of all theses, dissertations and final projects from students at\nIcelandic universities. The corpus was aligned based on sentence-level BLEU\nscores, in both translation directions, from NMT models using Bleualign. The\nresult is a corpus of 64k sentence pairs from over 6 thousand parallel\nabstracts.", "published": "2021-08-11 15:47:07", "link": "http://arxiv.org/abs/2108.05289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Transformer-based Math Language Model for Handwritten Math Expression\n  Recognition", "abstract": "Handwritten mathematical expressions (HMEs) contain ambiguities in their\ninterpretations, even for humans sometimes. Several math symbols are very\nsimilar in the writing style, such as dot and comma or 0, O, and o, which is a\nchallenge for HME recognition systems to handle without using contextual\ninformation. To address this problem, this paper presents a Transformer-based\nMath Language Model (TMLM). Based on the self-attention mechanism, the\nhigh-level representation of an input token in a sequence of tokens is computed\nby how it is related to the previous tokens. Thus, TMLM can capture long\ndependencies and correlations among symbols and relations in a mathematical\nexpression (ME). We trained the proposed language model using a corpus of\napproximately 70,000 LaTeX sequences provided in CROHME 2016. TMLM achieved the\nperplexity of 4.42, which outperformed the previous math language models, i.e.,\nthe N-gram and recurrent neural network-based language models. In addition, we\ncombine TMLM into a stochastic context-free grammar-based HME recognition\nsystem using a weighting parameter to re-rank the top-10 best candidates. The\nexpression rates on the testing sets of CROHME 2016 and CROHME 2019 were\nimproved by 2.97 and 0.83 percentage points, respectively.", "published": "2021-08-11 03:03:48", "link": "http://arxiv.org/abs/2108.05002v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DEMix Layers: Disentangling Domains for Modular Language Modeling", "abstract": "We introduce a new domain expert mixture (DEMix) layer that enables\nconditioning a language model (LM) on the domain of the input text. A DEMix\nlayer is a collection of expert feedforward networks, each specialized to a\ndomain, that makes the LM modular: experts can be mixed, added or removed after\ninitial training. Extensive experiments with autoregressive transformer LMs (up\nto 1.3B parameters) show that DEMix layers reduce test-time perplexity,\nincrease training efficiency, and enable rapid adaptation with little overhead.\nWe show that mixing experts during inference, using a parameter-free weighted\nensemble, allows the model to better generalize to heterogeneous or unseen\ndomains. We also show that experts can be added to iteratively incorporate new\ndomains without forgetting older ones, and that experts can be removed to\nrestrict access to unwanted domains, without additional training. Overall,\nthese results demonstrate benefits of explicitly conditioning on textual\ndomains during language modeling.", "published": "2021-08-11 05:15:33", "link": "http://arxiv.org/abs/2108.05036v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report\n  Generation With Alternate Learning", "abstract": "Medical imaging technologies, including computed tomography (CT) or chest\nX-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.\nSince manual report writing is usually too time-consuming, a more intelligent\nauxiliary medical system that could generate medical reports automatically and\nimmediately is urgently needed. In this article, we propose to use the medical\nvisual language BERT (Medical-VLBERT) model to identify the abnormality on the\nCOVID-19 scans and generate the medical report automatically based on the\ndetected lesion regions. To produce more accurate medical reports and minimize\nthe visual-and-linguistic differences, this model adopts an alternate learning\nstrategy with two procedures that are knowledge pretraining and transferring.\nTo be more precise, the knowledge pretraining procedure is to memorize the\nknowledge from medical texts, while the transferring procedure is to utilize\nthe acquired knowledge for professional medical sentences generations through\nobservations of medical images. In practice, for automatic medical report\ngeneration on the COVID-19 cases, we constructed a dataset of 368 medical\nfindings in Chinese and 1104 chest CT scans from The First Affiliated Hospital\nof Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun\nYat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of\nthe COVID-19 training samples, our model was first trained on the large-scale\nChinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for\nfurther fine-tuning. The experimental results showed that Medical-VLBERT\nachieved state-of-the-art performances on terminology prediction and report\ngeneration with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The\nChinese COVID-19 CT dataset is available at https://covid19ct.github.io/.", "published": "2021-08-11 07:12:57", "link": "http://arxiv.org/abs/2108.05067v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "abstract": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "published": "2021-08-11 19:13:04", "link": "http://arxiv.org/abs/2108.05419v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Extracting Semantics from Maintenance Records", "abstract": "Rapid progress in natural language processing has led to its utilization in a\nvariety of industrial and enterprise settings, including in its use for\ninformation extraction, specifically named entity recognition and relation\nextraction, from documents such as engineering manuals and field maintenance\nreports. While named entity recognition is a well-studied problem, existing\nstate-of-the-art approaches require large labelled datasets which are hard to\nacquire for sensitive data such as maintenance records. Further, industrial\ndomain experts tend to distrust results from black box machine learning models,\nespecially when the extracted information is used in downstream predictive\nmaintenance analytics. We overcome these challenges by developing three\napproaches built on the foundation of domain expert knowledge captured in\ndictionaries and ontologies. We develop a syntactic and semantic rules-based\napproach and an approach leveraging a pre-trained language model, fine-tuned\nfor a question-answering task on top of our base dictionary lookup to extract\nentities of interest from maintenance records. We also develop a preliminary\nontology to represent and capture the semantics of maintenance records. Our\nevaluations on a real-world aviation maintenance records dataset show promising\nresults and help identify challenges specific to named entity recognition in\nthe context of noisy industrial data.", "published": "2021-08-11 21:23:10", "link": "http://arxiv.org/abs/2108.05454v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ensuring the Inclusive Use of Natural Language Processing in the Global\n  Response to COVID-19", "abstract": "Natural language processing (NLP) plays a significant role in tools for the\nCOVID-19 pandemic response, from detecting misinformation on social media to\nhelping to provide accurate clinical information or summarizing scientific\nresearch. However, the approaches developed thus far have not benefited all\npopulations, regions or languages equally. We discuss ways in which current and\nfuture NLP approaches can be made more inclusive by covering low-resource\nlanguages, including alternative modalities, leveraging out-of-the-box tools\nand forming meaningful partnerships. We suggest several future directions for\nresearchers interested in maximizing the positive societal impacts of NLP.", "published": "2021-08-11 12:54:26", "link": "http://arxiv.org/abs/2108.10791v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "DeliData: A dataset for deliberation in multi-party problem solving", "abstract": "Group deliberation enables people to collaborate and solve problems, however,\nit is understudied due to a lack of resources. To this end, we introduce the\nfirst publicly available dataset containing collaborative conversations on\nsolving a well-established cognitive task, consisting of 500 group dialogues\nand 14k utterances. In 64% of these conversations, the group members are able\nto find a better solution than they had identified individually, and in 43.8%\nof the groups who had a correct answer as their final solution, none of the\nparticipants had solved the task correctly by themselves. Furthermore, we\npropose a novel annotation schema that captures deliberation cues and release\nall 14k utterances annotated with it. Finally, we use the proposed dataset to\ndevelop and evaluate two methods for generating deliberation utterances. The\ndata collection platform, dataset and annotated corpus are publicly available\nat https://delibot.xyz.", "published": "2021-08-11 15:13:07", "link": "http://arxiv.org/abs/2108.05271v3", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "On The Compensation Between Magnitude and Phase in Speech Separation", "abstract": "Deep neural network (DNN) based end-to-end optimization in the complex\ntime-frequency (T-F) domain or time domain has shown considerable potential in\nmonaural speech separation. Many recent studies optimize loss functions defined\nsolely in the time or complex domain, without including a loss on magnitude.\nAlthough such loss functions typically produce better scores if the evaluation\nmetrics are objective time-domain metrics, they however produce worse scores on\nspeech quality and intelligibility metrics and usually lead to worse speech\nrecognition performance, compared with including a loss on magnitude. While\nthis phenomenon has been experimentally observed by many studies, it is often\nnot accurately explained and there lacks a thorough understanding on its\nfundamental cause. This paper provides a novel view from the perspective of the\nimplicit compensation between estimated magnitude and phase. Analytical results\nbased on monaural speech separation and robust automatic speech recognition\n(ASR) tasks in noisy-reverberant conditions support the validity of our view.", "published": "2021-08-11 23:03:31", "link": "http://arxiv.org/abs/2108.05470v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset", "abstract": "While the significant advancements have made in the generation of deepfakes\nusing deep learning technologies, its misuse is a well-known issue now.\nDeepfakes can cause severe security and privacy issues as they can be used to\nimpersonate a person's identity in a video by replacing his/her face with\nanother person's face. Recently, a new problem of generating synthesized human\nvoice of a person is emerging, where AI-based deep learning models can\nsynthesize any person's voice requiring just a few seconds of audio. With the\nemerging threat of impersonation attacks using deepfake audios and videos, a\nnew generation of deepfake detectors is needed to focus on both video and audio\ncollectively. To develop a competent deepfake detector, a large amount of\nhigh-quality data is typically required to capture real-world (or practical)\nscenarios. Existing deepfake datasets either contain deepfake videos or audios,\nwhich are racially biased as well. As a result, it is critical to develop a\nhigh-quality video and audio deepfake dataset that can be used to detect both\naudio and video deepfakes simultaneously. To fill this gap, we propose a novel\nAudio-Video Deepfake dataset, FakeAVCeleb, which contains not only deepfake\nvideos but also respective synthesized lip-synced fake audios. We generate this\ndataset using the most popular deepfake generation methods. We selected real\nYouTube videos of celebrities with four ethnic backgrounds to develop a more\nrealistic multimodal dataset that addresses racial bias, and further help\ndevelop multimodal deepfake detectors. We performed several experiments using\nstate-of-the-art detection methods to evaluate our deepfake dataset and\ndemonstrate the challenges and usefulness of our multimodal Audio-Video\ndeepfake dataset.", "published": "2021-08-11 07:49:36", "link": "http://arxiv.org/abs/2108.05080v4", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS", "I.4.9; I.5.4"], "primary_category": "cs.CV"}
