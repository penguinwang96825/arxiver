{"title": "A Two-Stage Multimodal Emotion Recognition Model Based on Graph\n  Contrastive Learning", "abstract": "In terms of human-computer interaction, it is becoming more and more\nimportant to correctly understand the user's emotional state in a conversation,\nso the task of multimodal emotion recognition (MER) started to receive more\nattention. However, existing emotion classification methods usually perform\nclassification only once. Sentences are likely to be misclassified in a single\nround of classification. Previous work usually ignores the similarities and\ndifferences between different morphological features in the fusion process. To\naddress the above issues, we propose a two-stage emotion recognition model\nbased on graph contrastive learning (TS-GCL). First, we encode the original\ndataset with different preprocessing modalities. Second, a graph contrastive\nlearning (GCL) strategy is introduced for these three modal data with other\nstructures to learn similarities and differences within and between modalities.\nFinally, we use MLP twice to achieve the final emotion classification. This\nstaged classification method can help the model to better focus on different\nlevels of emotional information, thereby improving the performance of the\nmodel. Extensive experiments show that TS-GCL has superior performance on\nIEMOCAP and MELD datasets compared with previous methods.", "published": "2024-01-03 01:58:31", "link": "http://arxiv.org/abs/2401.01495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Social Media Ready Caption Generation for Brands", "abstract": "Social media advertisements are key for brand marketing, aiming to attract\nconsumers with captivating captions and pictures or logos. While previous\nresearch has focused on generating captions for general images, incorporating\nbrand personalities into social media captioning remains unexplored. Brand\npersonalities are shown to be affecting consumers' behaviours and social\ninteractions and thus are proven to be a key aspect of marketing strategies.\nCurrent open-source multimodal LLMs are not directly suited for this task.\nHence, we propose a pipeline solution to assist brands in creating engaging\nsocial media captions that align with the image and the brand personalities.\nOur architecture is based on two parts: a the first part contains an image\ncaptioning model that takes in an image that the brand wants to post online and\ngives a plain English caption; b the second part takes in the generated caption\nalong with the target brand personality and outputs a catchy\npersonality-aligned social media caption. Along with brand personality, our\nsystem also gives users the flexibility to provide hashtags, Instagram handles,\nURLs, and named entities they want the caption to contain, making the captions\nmore semantically related to the social media handles. Comparative evaluations\nagainst various baselines demonstrate the effectiveness of our approach, both\nqualitatively and quantitatively.", "published": "2024-01-03 09:27:01", "link": "http://arxiv.org/abs/2401.01637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MLPs Compass: What is learned when MLPs are combined with PLMs?", "abstract": "While Transformer-based pre-trained language models and their variants\nexhibit strong semantic representation capabilities, the question of\ncomprehending the information gain derived from the additional components of\nPLMs remains an open question in this field. Motivated by recent efforts that\nprove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture\ncapabilities, even outperforming Graph Neural Networks (GNNs), this paper aims\nto quantify whether simple MLPs can further enhance the already potent ability\nof PLMs to capture linguistic information. Specifically, we design a simple yet\neffective probing framework containing MLPs components based on BERT structure\nand conduct extensive experiments encompassing 10 probing tasks spanning three\ndistinct linguistic levels. The experimental results demonstrate that MLPs can\nindeed enhance the comprehension of linguistic structure by PLMs. Our research\nprovides interpretable and valuable insights into crafting variations of PLMs\nutilizing MLPs for tasks that emphasize diverse linguistic structures.", "published": "2024-01-03 11:06:01", "link": "http://arxiv.org/abs/2401.01667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Patterns of Persistence and Diffusibility across the World's Languages", "abstract": "Language similarities can be caused by genetic relatedness, areal contact,\nuniversality, or chance. Colexification, i.e. a type of similarity where a\nsingle lexical form is used to convey multiple meanings, is underexplored. In\nour work, we shed light on the linguistic causes of cross-lingual similarity in\ncolexification and phonology, by exploring genealogical stability (persistence)\nand contact-induced change (diffusibility). We construct large-scale graphs\nincorporating semantic, genealogical, phonological and geographical data for\n1,966 languages. We then show the potential of this resource, by investigating\nseveral established hypotheses from previous work in linguistics, while\nproposing new ones. Our results strongly support a previously established\nhypothesis in the linguistic literature, while offering contradicting evidence\nto another. Our large scale resource opens for further research across\ndisciplines, e.g.~in multilingual NLP and comparative linguistics.", "published": "2024-01-03 12:05:38", "link": "http://arxiv.org/abs/2401.01698v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-target Stance Detection by Exploiting Target Analytical\n  Perspectives", "abstract": "Cross-target stance detection (CTSD) is an important task, which infers the\nattitude of the destination target by utilizing annotated data derived from the\nsource target. One important approach in CTSD is to extract domain-invariant\nfeatures to bridge the knowledge gap between multiple targets. However, the\nanalysis of informal and short text structure, and implicit expressions,\ncomplicate the extraction of domain-invariant knowledge. In this paper, we\npropose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the\nanalysis perspective as a bridge to transfer knowledge. First, we develop a\ntwo-stage instruct-based chain-of-thought method (TsCoT) to elicit target\nanalysis perspectives and provide natural language explanations (NLEs) from\nmultiple viewpoints by formulating instructions based on large language model\n(LLM). Second, we propose a multi-perspective prompt-tuning framework\n(MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments\nresults demonstrate the superiority of MPPT against the state-of-the-art\nbaseline methods.", "published": "2024-01-03 14:28:55", "link": "http://arxiv.org/abs/2401.01761v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question-Answering Based Summarization of Electronic Health Records\n  using Retrieval Augmented Generation", "abstract": "Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.", "published": "2024-01-03 00:09:34", "link": "http://arxiv.org/abs/2401.01469v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing and Multimodal Stock Price Prediction", "abstract": "In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.", "published": "2024-01-03 01:21:30", "link": "http://arxiv.org/abs/2401.01487v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GOAT-Bench: Safety Insights to Large Multimodal Models through\n  Meme-Based Social Abuse", "abstract": "The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and image. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g., GPT-4o) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.", "published": "2024-01-03 03:28:55", "link": "http://arxiv.org/abs/2401.01523v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English\n  Clinical Queries", "abstract": "In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.", "published": "2024-01-03 07:58:25", "link": "http://arxiv.org/abs/2401.01596v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Large Language Model Capabilities in Perioperative Risk Prediction and\n  Prognostication", "abstract": "We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.", "published": "2024-01-03 08:41:27", "link": "http://arxiv.org/abs/2401.01620v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Can AI Be as Creative as Humans?", "abstract": "Creativity serves as a cornerstone for societal progress and innovation. With\nthe rise of advanced generative AI models capable of tasks once reserved for\nhuman creativity, the study of AI's creative potential becomes imperative for\nits responsible development and application. In this paper, we prove in theory\nthat AI can be as creative as humans under the condition that it can properly\nfit the data generated by human creators. Therefore, the debate on AI's\ncreativity is reduced into the question of its ability to fit a sufficient\namount of data. To arrive at this conclusion, this paper first addresses the\ncomplexities in defining creativity by introducing a new concept called\nRelative Creativity. Rather than attempting to define creativity universally,\nwe shift the focus to whether AI can match the creative abilities of a\nhypothetical human. The methodological shift leads to a statistically\nquantifiable assessment of AI's creativity, term Statistical Creativity. This\nconcept, statistically comparing the creative abilities of AI with those of\nspecific human groups, facilitates theoretical exploration of AI's creative\npotential. Our analysis reveals that by fitting extensive conditional data\nwithout marginalizing out the generative conditions, AI can emerge as a\nhypothetical new creator. The creator possesses the same creative abilities on\npar with the human creators it was trained on. Building on theoretical\nfindings, we discuss the application in prompt-conditioned autoregressive\nmodels, providing a practical means for evaluating creative abilities of\ngenerative AI models, such as Large Language Models (LLMs). Additionally, this\nstudy provides an actionable training guideline, bridging the theoretical\nquantification of creativity with practical model training.", "published": "2024-01-03 08:49:12", "link": "http://arxiv.org/abs/2401.01623v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Predicting challenge moments from students' discourse: A comparison of\n  GPT-4 to two traditional natural language processing approaches", "abstract": "Effective collaboration requires groups to strategically regulate themselves\nto overcome challenges. Research has shown that groups may fail to regulate due\nto differences in members' perceptions of challenges which may benefit from\nexternal support. In this study, we investigated the potential of leveraging\nthree distinct natural language processing models: an expert knowledge\nrule-based model, a supervised machine learning (ML) model and a Large Language\nmodel (LLM), in challenge detection and challenge dimension identification\n(cognitive, metacognitive, emotional and technical/other challenges) from\nstudent discourse, was investigated. The results show that the supervised ML\nand the LLM approaches performed considerably well in both tasks, in contrast\nto the rule-based approach, whose efficacy heavily relies on the engineered\nfeatures by experts. The paper provides an extensive discussion of the three\napproaches' performance for automated detection and support of students'\nchallenge moments in collaborative learning activities. It argues that,\nalthough LLMs provide many advantages, they are unlikely to be the panacea to\nissues of the detection and feedback provision of socially shared regulation of\nlearning due to their lack of reliability, as well as issues of validity\nevaluation, privacy and confabulation. We conclude the paper with a discussion\non additional considerations, including model transparency to explore feasible\nand meaningful analytical feedback for students and educators using LLMs.", "published": "2024-01-03 11:54:30", "link": "http://arxiv.org/abs/2401.01692v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models in Semantic Parsing for Conversational\n  Question Answering over Knowledge Graphs", "abstract": "Conversational question answering systems often rely on semantic parsing to\nenable interactive information retrieval, which involves the generation of\nstructured database queries from a natural language input. For\ninformation-seeking conversations about facts stored within a knowledge graph,\ndialogue utterances are transformed into graph queries in a process that is\ncalled knowledge-based conversational question answering. This paper evaluates\nthe performance of large language models that have not been explicitly\npre-trained on this task. Through a series of experiments on an extensive\nbenchmark dataset, we compare models of varying sizes with different prompting\ntechniques and identify common issue types in the generated output. Our results\ndemonstrate that large language models are capable of generating graph queries\nfrom dialogues, with significant improvements achievable through few-shot\nprompting and fine-tuning techniques, especially for smaller models that\nexhibit lower zero-shot performance.", "published": "2024-01-03 12:28:33", "link": "http://arxiv.org/abs/2401.01711v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Navigating Uncertainty: Optimizing API Dependency for Hallucination\n  Reduction in Closed-Book Question Answering", "abstract": "While Large Language Models (LLM) are able to accumulate and restore\nknowledge, they are still prone to hallucination. Especially when faced with\nfactual questions, LLM cannot only rely on knowledge stored in parameters to\nguarantee truthful and correct answers. Augmenting these models with the\nability to search on external information sources, such as the web, is a\npromising approach to ground knowledge to retrieve information. However,\nsearching in a large collection of documents introduces additional\ncomputational/time costs. An optimal behavior would be to query external\nresources only when the LLM is not confident about answers. In this paper, we\npropose a new LLM able to self-estimate if it is able to answer directly or\nneeds to request an external tool. We investigate a supervised approach by\nintroducing a hallucination masking mechanism in which labels are generated\nusing a close book question-answering task. In addition, we propose to leverage\nparameter-efficient fine-tuning techniques to train our model on a small amount\nof data. Our model directly provides answers for $78.2\\%$ of the known queries\nand opts to search for $77.2\\%$ of the unknown ones. This results in the API\nbeing utilized only $62\\%$ of the time.", "published": "2024-01-03 15:12:42", "link": "http://arxiv.org/abs/2401.01780v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Physio: An LLM-Based Physiotherapy Advisor", "abstract": "The capabilities of the most recent language models have increased the\ninterest in integrating them into real-world applications. However, the fact\nthat these models generate plausible, yet incorrect text poses a constraint\nwhen considering their use in several domains. Healthcare is a prime example of\na domain where text-generative trustworthiness is a hard requirement to\nsafeguard patient well-being. In this paper, we present Physio, a chat-based\napplication for physical rehabilitation. Physio is capable of making an initial\ndiagnosis while citing reliable health sources to support the information\nprovided. Furthermore, drawing upon external knowledge databases, Physio can\nrecommend rehabilitation exercises and over-the-counter medication for symptom\nrelief. By combining these features, Physio can leverage the power of\ngenerative models for language processing while also conditioning its response\non dependable and verifiable sources. A live demo of Physio is available at\nhttps://physio.inesctec.pt.", "published": "2024-01-03 16:42:13", "link": "http://arxiv.org/abs/2401.01825v1", "categories": ["cs.CL", "cs.IR", "68T07", "I.2; J.3"], "primary_category": "cs.CL"}
{"title": "Generalist embedding models are better at short-context clinical\n  semantic search than specialized embedding models", "abstract": "The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.", "published": "2024-01-03 19:03:32", "link": "http://arxiv.org/abs/2401.01943v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO\n  and Toxicity", "abstract": "While alignment algorithms are now commonly used to tune pre-trained language\nmodels towards a user's preferences, we lack explanations for the underlying\nmechanisms in which models become ``aligned'', thus making it difficult to\nexplain phenomena like jailbreaks. In this work we study a popular algorithm,\ndirect preference optimization (DPO), and the mechanisms by which it reduces\ntoxicity. Namely, we first study how toxicity is represented and elicited in a\npre-trained language model, GPT2-medium. We then apply DPO with a carefully\ncrafted pairwise dataset to reduce toxicity. We examine how the resulting model\naverts toxic outputs, and find that capabilities learned from pre-training are\nnot removed, but rather bypassed. We use this insight to demonstrate a simple\nmethod to un-align the model, reverting it back to its toxic behavior.", "published": "2024-01-03 20:26:15", "link": "http://arxiv.org/abs/2401.01967v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large\n  Language Models from the Perspective of Position Bias", "abstract": "We characterize and study zero-shot abstractive summarization in Large\nLanguage Models (LLMs) by measuring position bias, which we propose as a\ngeneral formulation of the more restrictive lead bias phenomenon studied\npreviously in the literature. Position bias captures the tendency of a model\nunfairly prioritizing information from certain parts of the input text over\nothers, leading to undesirable behavior. Through numerous experiments on four\ndiverse real-world datasets, we study position bias in multiple LLM models such\nas GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained\nencoder-decoder abstractive summarization models such as Pegasus and BART. Our\nfindings lead to novel insights and discussion on performance and position bias\nof models for zero-shot summarization tasks.", "published": "2024-01-03 21:38:40", "link": "http://arxiv.org/abs/2401.01989v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Latent Dirichlet Allocation (LDA) Semantic Text Analytics Approach to\n  Explore Topical Features in Charity Crowdfunding Campaigns", "abstract": "Crowdfunding in the realm of the Social Web has received substantial\nattention, with prior research examining various aspects of campaigns,\nincluding project objectives, durations, and influential project categories for\nsuccessful fundraising. These factors are crucial for entrepreneurs seeking\ndonor support. However, the terrain of charity crowdfunding within the Social\nWeb remains relatively unexplored, lacking comprehension of the motivations\ndriving donations that often lack concrete reciprocation. Distinct from\nconventional crowdfunding that offers tangible returns, charity crowdfunding\nrelies on intangible rewards like tax advantages, recognition posts, or\nadvisory roles. Such details are often embedded within campaign narratives,\nyet, the analysis of textual content in charity crowdfunding is limited. This\nstudy introduces an inventive text analytics framework, utilizing Latent\nDirichlet Allocation (LDA) to extract latent themes from textual descriptions\nof charity campaigns. The study has explored four different themes, two each in\ncampaign and incentive descriptions. Campaign description themes are focused on\nchild and elderly health mainly the ones who are diagnosed with terminal\ndiseases. Incentive description themes are based on tax benefits, certificates,\nand appreciation posts. These themes, combined with numerical parameters,\npredict campaign success. The study was successful in using Random Forest\nClassifier to predict success of the campaign using both thematic and numerical\nparameters. The study distinguishes thematic categories, particularly medical\nneed-based charity and general causes, based on project and incentive\ndescriptions. In conclusion, this research bridges the gap by showcasing topic\nmodelling utility in uncharted charity crowdfunding domains.", "published": "2024-01-03 09:17:46", "link": "http://arxiv.org/abs/2401.02988v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Studying and Recommending Information Highlighting in Stack Overflow\n  Answers", "abstract": "Context: Navigating the knowledge of Stack Overflow (SO) remains challenging.\nTo make the posts vivid to users, SO allows users to write and edit posts with\nMarkdown or HTML so that users can leverage various formatting styles (e.g.,\nbold, italic, and code) to highlight the important information. Nonetheless,\nthere have been limited studies on the highlighted information. Objective: We\ncarried out the first large-scale exploratory study on the information\nhighlighted in SO answers in our recent study. To extend our previous study, we\ndevelop approaches to automatically recommend highlighted content with\nformatting styles using neural network architectures initially designed for the\nNamed Entity Recognition task. Method: In this paper, we studied 31,169,429\nanswers of Stack Overflow. For training recommendation models, we choose\nCNN-based and BERT-based models for each type of formatting (i.e., Bold,\nItalic, Code, and Heading) using the information highlighting dataset we\ncollected from SO answers. Results: Our models achieve a precision ranging from\n0.50 to 0.72 for different formatting types. It is easier to build a model to\nrecommend Code than other types. Models for text formatting types (i.e.,\nHeading, Bold, and Italic) suffer low recall. Our analysis of failure cases\nindicates that the majority of the failure cases are due to missing\nidentification. One explanation is that the models are easy to learn the\nfrequent highlighted words while struggling to learn less frequent words (i.g.,\nlong-tail knowledge). Conclusion: Our findings suggest that it is possible to\ndevelop recommendation models for highlighting information for answers with\ndifferent formatting styles on Stack Overflow.", "published": "2024-01-03 00:13:52", "link": "http://arxiv.org/abs/2401.01472v3", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic\n  Token Prediction", "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural\ntransducer. Our approach divides the whole TTS pipeline into semantic-level\nsequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling\nstages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings.\nFor a robust and efficient alignment modeling, we employ a neural transducer\nnamed token transducer for the semantic token prediction, benefiting from its\nhard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR)\nspeech generator efficiently synthesizes waveforms from these semantic tokens.\nAdditionally, a reference speech controls temporal dynamics and acoustic\nconditions at each stage. This decoupled framework reduces the training\ncomplexity of TTS while allowing each stage to focus on semantic and acoustic\nmodeling. Our experimental results on zero-shot adaptive TTS demonstrate that\nour model surpasses the baseline in terms of speech quality and speaker\nsimilarity, both objectively and subjectively. We also delve into the inference\nspeed and prosody control capabilities of our approach, highlighting the\npotential of neural transducers in TTS frameworks.", "published": "2024-01-03 02:03:36", "link": "http://arxiv.org/abs/2401.01498v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hallucinations in Neural Automatic Speech Recognition: Identifying\n  Errors and Hallucinatory Models", "abstract": "Hallucinations are a type of output error produced by deep neural networks.\nWhile this has been studied in natural language processing, they have not been\nresearched previously in automatic speech recognition. Here, we define\nhallucinations in ASR as transcriptions generated by a model that are\nsemantically unrelated to the source utterance, yet still fluent and coherent.\nThe similarity of hallucinations to probable natural language outputs of the\nmodel creates a danger of deception and impacts the credibility of the system.\nWe show that commonly used metrics, such as word error rates, cannot\ndifferentiate between hallucinatory and non-hallucinatory models. To address\nthis, we propose a perturbation-based method for assessing the susceptibility\nof an automatic speech recognition (ASR) model to hallucination at test time,\nwhich does not require access to the training dataset. We demonstrate that this\nmethod helps to distinguish between hallucinatory and non-hallucinatory models\nthat have similar baseline word error rates. We further explore the\nrelationship between the types of ASR errors and the types of dataset noise to\ndetermine what types of noise are most likely to create hallucinatory outputs.\nWe devise a framework for identifying hallucinations by analysing their\nsemantic connection with the ground truth and their fluency. Finally, we\ndiscover how to induce hallucinations with a random noise injection to the\nutterance.", "published": "2024-01-03 06:56:56", "link": "http://arxiv.org/abs/2401.01572v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PLLaMa: An Open-source Large Language Model for Plant Science", "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.", "published": "2024-01-03 08:06:26", "link": "http://arxiv.org/abs/2401.01600v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded", "abstract": "The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents -- it\ncan successfully complete 51.1 of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out to be not effective for web agents, and the best grounding strategy\nwe develop in this paper leverages both the HTML structure and visuals. Yet,\nthere is still a substantial gap with oracle grounding, leaving ample room for\nfurther improvement. All code, data, and evaluation tools are available at\nhttps://github.com/OSU-NLP-Group/SeeAct.", "published": "2024-01-03 08:33:09", "link": "http://arxiv.org/abs/2401.01614v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "WordArt Designer API: User-Driven Artistic Typography Synthesis with\n  Large Language Models on ModelScope", "abstract": "This paper introduces the WordArt Designer API, a novel framework for\nuser-driven artistic typography synthesis utilizing Large Language Models\n(LLMs) on ModelScope. We address the challenge of simplifying artistic\ntypography for non-professionals by offering a dynamic, adaptive, and\ncomputationally efficient alternative to traditional rigid templates. Our\napproach leverages the power of LLMs to understand and interpret user input,\nfacilitating a more intuitive design process. We demonstrate through various\ncase studies how users can articulate their aesthetic preferences and\nfunctional requirements, which the system then translates into unique and\ncreative typographic designs. Our evaluations indicate significant improvements\nin user satisfaction, design flexibility, and creative expression over existing\nsystems. The WordArt Designer API not only democratizes the art of typography\nbut also opens up new possibilities for personalized digital communication and\ndesign.", "published": "2024-01-03 12:06:02", "link": "http://arxiv.org/abs/2401.01699v2", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "VGA: Vision and Graph Fused Attention Network for Rumor Detection", "abstract": "With the development of social media, rumors have been spread broadly on\nsocial media platforms, causing great harm to society. Beside textual\ninformation, many rumors also use manipulated images or conceal textual\ninformation within images to deceive people and avoid being detected, making\nmultimodal rumor detection be a critical problem. The majority of multimodal\nrumor detection methods mainly concentrate on extracting features of source\nclaims and their corresponding images, while ignoring the comments of rumors\nand their propagation structures. These comments and structures imply the\nwisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these\nmethods usually only extract visual features in a basic manner, seldom consider\ntampering or textual information in images. Therefore, in this study, we\npropose a novel Vision and Graph Fused Attention Network (VGA) for rumor\ndetection to utilize propagation structures among posts so as to obtain the\ncrowd opinions and further explore visual tampering features, as well as the\ntextual information hidden in images. We conduct extensive experiments on three\ndatasets, demonstrating that VGA can effectively detect multimodal rumors and\noutperform state-of-the-art methods significantly.", "published": "2024-01-03 14:24:02", "link": "http://arxiv.org/abs/2401.01759v1", "categories": ["cs.SI", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.SI"}
{"title": "Iterative Mask Filling: An Effective Text Augmentation Method Using\n  Masked Language Modeling", "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.", "published": "2024-01-03 16:47:13", "link": "http://arxiv.org/abs/2401.01830v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets", "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.", "published": "2024-01-03 17:22:48", "link": "http://arxiv.org/abs/2401.01843v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality", "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages\nfrom the pre-training corpus. We first show that many languages transfer some\ninstruction-following capabilities to other languages from even monolingual\ntuning. Furthermore, we find that only 40 multilingual examples integrated in\nan English tuning set substantially improve multilingual instruction-following,\nboth in seen and unseen languages during tuning. In general, we observe that\nmodels tuned on multilingual mixtures exhibit comparable or superior\nperformance in multiple languages compared to monolingually tuned models,\ndespite training on 10x fewer examples in those languages. Finally, we find\nthat diversifying the instruction tuning set with even just 2-4 languages\nsignificantly improves cross-lingual generalization. Our results suggest that\nbuilding massively multilingual instruction-tuned models can be done with only\na very small set of multilingual instruction-responses.", "published": "2024-01-03 17:48:10", "link": "http://arxiv.org/abs/2401.01854v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Vision Check-up for Language Models", "abstract": "What does learning to model relationships between strings teach large\nlanguage models (LLMs) about the visual world? We systematically evaluate LLMs'\nabilities to generate and recognize an assortment of visual concepts of\nincreasing complexity and then demonstrate how a preliminary visual\nrepresentation learning system can be trained using models of text. As language\nmodels lack the ability to consume or output visual information as pixels, we\nuse code to represent images in our study. Although LLM-generated images do not\nlook like natural images, results on image generation and the ability of models\nto correct these generated images indicate that precise modeling of strings can\nteach language models about numerous aspects of the visual world. Furthermore,\nexperiments on self-supervised visual representation learning, utilizing images\ngenerated with text models, highlight the potential to train vision models\ncapable of making semantic assessments of natural images using just LLMs.", "published": "2024-01-03 18:09:33", "link": "http://arxiv.org/abs/2401.01862v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Theoretical guarantees on the best-of-n alignment policy", "abstract": "A simple and effective method for the inference-time alignment of generative\nmodels is the best-of-$n$ policy, where $n$ samples are drawn from a reference\npolicy, ranked based on a reward function, and the highest ranking one is\nselected. A commonly used analytical expression in the literature claims that\nthe KL divergence between the best-of-$n$ policy and the reference policy is\nequal to $\\log (n) - (n-1)/n.$ We disprove the validity of this claim, and show\nthat it is an upper bound on the actual KL divergence. We also explore the\ntightness of this upper bound in different regimes, and propose a new estimator\nfor the KL divergence and empirically show that it provides a tight\napproximation. We also show that the win rate of the best-of-$n$ policy against\nthe reference policy is upper bounded by $n/(n+1)$ and derive bounds on the\ntightness of this characterization. We conclude with analyzing the tradeoffs\nbetween win rate and KL divergence of the best-of-$n$ alignment policy, which\ndemonstrate that very good tradeoffs are achievable with $n < 1000$.", "published": "2024-01-03 18:39:13", "link": "http://arxiv.org/abs/2401.01879v2", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Instruct-Imagen: Image Generation with Multi-modal Instruction", "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image\ngeneration tasks and generalizes across unseen tasks. We introduce *multi-modal\ninstruction* for image generation, a task representation articulating a range\nof generation intents with precision. It uses natural language to amalgamate\ndisparate modalities (e.g., text, edge, style, subject, etc.), such that\nabundant generation intents can be standardized in a uniform format.\n  We then build instruct-imagen by fine-tuning a pre-trained text-to-image\ndiffusion model with a two-stage framework. First, we adapt the model using the\nretrieval-augmented training, to enhance model's capabilities to ground its\ngeneration on external multimodal context. Subsequently, we fine-tune the\nadapted model on diverse image generation tasks that requires vision-language\nunderstanding (e.g., subject-driven generation, etc.), each paired with a\nmulti-modal instruction encapsulating the task's essence. Human evaluation on\nvarious image generation datasets reveals that instruct-imagen matches or\nsurpasses prior task-specific models in-domain and demonstrates promising\ngeneralization to unseen and more complex tasks.", "published": "2024-01-03 19:31:58", "link": "http://arxiv.org/abs/2401.01952v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GLIDE-RL: Grounded Language Instruction through DEmonstration in RL", "abstract": "One of the final frontiers in the development of complex human - AI\ncollaborative systems is the ability of AI agents to comprehend the natural\nlanguage and perform tasks accordingly. However, training efficient\nReinforcement Learning (RL) agents grounded in natural language has been a\nlong-standing challenge due to the complexity and ambiguity of the language and\nsparsity of the rewards, among other factors. Several advances in reinforcement\nlearning, curriculum learning, continual learning, language models have\nindependently contributed to effective training of grounded agents in various\nenvironments. Leveraging these developments, we present a novel algorithm,\nGrounded Language Instruction through DEmonstration in RL (GLIDE-RL) that\nintroduces a teacher-instructor-student curriculum learning framework for\ntraining an RL agent capable of following natural language instructions that\ncan generalize to previously unseen language instructions. In this multi-agent\nframework, the teacher and the student agents learn simultaneously based on the\nstudent's current skill level. We further demonstrate the necessity for\ntraining the student agent with not just one, but multiple teacher agents.\nExperiments on a complex sparse reward environment validates the effectiveness\nof our proposed approach.", "published": "2024-01-03 17:32:13", "link": "http://arxiv.org/abs/2401.02991v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse\n  Datasets", "abstract": "We explore the potential of enhancing LLM performance in astronomy-focused\nquestion-answering through targeted, continual pre-training. By employing a\ncompact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of\nastronomy corpora -- comprising abstracts, introductions, and conclusions -- we\nachieve notable improvements in specialized topic comprehension. While general\nLLMs like GPT-4 excel in broader question-answering scenarios due to superior\nreasoning capabilities, our findings suggest that continual pre-training with\nlimited resources can still enhance model performance on specialized topics.\nAdditionally, we present an extension of AstroLLaMA: the fine-tuning of the 7B\nLLaMA model on a domain-specific conversational dataset, culminating in the\nrelease of the chat-enabled AstroLLaMA for community use. Comprehensive\nquantitative benchmarking is currently in progress and will be detailed in an\nupcoming full paper. The model, AstroLLaMA-Chat, is now available at\nhttps://huggingface.co/universeTBD, providing the first open-source\nconversational AI tool tailored for the astronomy community.", "published": "2024-01-03 04:47:02", "link": "http://arxiv.org/abs/2401.01916v2", "categories": ["astro-ph.IM", "astro-ph.CO", "astro-ph.GA", "astro-ph.SR", "cs.CL", "cs.LG"], "primary_category": "astro-ph.IM"}
{"title": "Self-supervised Reflective Learning through Self-distillation and Online\n  Clustering for Speaker Representation Learning", "abstract": "Speaker representation learning is critical for modern voice recognition\nsystems. While supervised learning techniques require extensive labeled data,\nunsupervised methodologies can leverage vast unlabeled corpora, offering a\nscalable solution. This paper introduces self-supervised reflective learning\n(SSRL), a novel paradigm that streamlines existing iterative unsupervised\nframeworks. SSRL integrates self-supervised knowledge distillation with online\nclustering to refine pseudo labels and train the model without iterative\nbottlenecks. Specifically, a teacher model continually refines pseudo labels\nthrough online clustering, providing dynamic supervision signals to train the\nstudent model. The student model undergoes noisy student training with input\nand model noise to boost its modeling capacity. The teacher model is updated\nvia an exponential moving average of the student, acting as an ensemble of past\niterations. Further, a pseudo label queue retains historical labels for\nconsistency, and noisy label modeling directs learning towards clean samples.\nExperiments on VoxCeleb show SSRL's superiority over current iterative\napproaches, surpassing the performance of a 5-round method in just a single\ntraining round. Ablation studies validate the contributions of key components\nlike noisy label modeling and pseudo label queues. Moreover, consistent\nimprovements in pseudo labeling and the convergence of cluster counts\ndemonstrate SSRL's effectiveness in deciphering unlabeled data. This work marks\nan important advancement in efficient and accurate speaker representation\nlearning through the novel reflective learning paradigm.", "published": "2024-01-03 00:17:39", "link": "http://arxiv.org/abs/2401.01473v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Independent low-rank matrix analysis based on the Sinkhorn divergence\n  source model for blind source separation", "abstract": "The so-called independent low-rank matrix analysis (ILRMA) has demonstrated a\ngreat potential for dealing with the problem of determined blind source\nseparation (BSS) for audio and speech signals. This method assumes that the\nspectra from different frequency bands are independent and the spectral\ncoefficients in any frequency band are Gaussian distributed. The Itakura-Saito\ndivergence is then employed to estimate the source model related parameters. In\nreality, however, the spectral coefficients from different frequency bands may\nbe dependent, which is not considered in the existing ILRMA algorithm. This\npaper presents an improved version of ILRMA, which considers the dependency\nbetween the spectral coefficients from different frequency bands. The Sinkhorn\ndivergence is then exploited to optimize the source model parameters. As a\nresult of using the cross-band information, the BSS performance is improved.\nBut the number of parameters to be estimated also increases significantly, and\nso is the computational complexity. To reduce the algorithm complexity, we\napply the Kronecker product to decompose the modeling matrix into the product\nof a number of matrices of much smaller dimensionality. An efficient algorithm\nis then developed to implement the Sinkhorn divergence based BSS algorithm and\nthe complexity is reduced by an order of magnitude.", "published": "2024-01-03 14:32:38", "link": "http://arxiv.org/abs/2401.01762v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multichannel blind speech source separation with a disjoint constraint\n  source model", "abstract": "Multichannel convolutive blind speech source separation refers to the problem\nof separating different speech sources from the observed multichannel mixtures\nwithout much a priori information about the mixing system. Multichannel\nnonnegative matrix factorization (MNMF) has been proven to be one of the most\npowerful separation frameworks and the representative algorithms such as MNMF\nand the independent low-rank matrix analysis (ILRMA) have demonstrated great\nperformance. However, the sparseness properties of speech source signals are\nnot fully taken into account in such a framework. It is well known that speech\nsignals are sparse in nature, which is considered in this work to improve the\nseparation performance. Specifically, we utilize the Bingham and Laplace\ndistributions to formulate a disjoint constraint regularizer, which is\nsubsequently incorporated into both MNMF and ILRMA. We then derive\nmajorization-minimization rules for updating parameters related to the source\nmodel, resulting in the development of two enhanced algorithms: s-MNMF and\ns-ILRMA. Comprehensive simulations are conducted, and the results unequivocally\ndemonstrate the efficacy of our proposed methodologies.", "published": "2024-01-03 14:32:47", "link": "http://arxiv.org/abs/2401.01763v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Incremental FastPitch: Chunk-based High Quality Text to Speech", "abstract": "Parallel text-to-speech models have been widely applied for real-time speech\nsynthesis, and they offer more controllability and a much faster synthesis\nprocess compared with conventional auto-regressive models. Although parallel\nmodels have benefits in many aspects, they become naturally unfit for\nincremental synthesis due to their fully parallel architecture such as\ntransformer. In this work, we propose Incremental FastPitch, a novel FastPitch\nvariant capable of incrementally producing high-quality Mel chunks by improving\nthe architecture with chunk-based FFT blocks, training with receptive-field\nconstrained chunk attention masks, and inference with fixed size past model\nstates. Experimental results show that our proposal can produce speech quality\ncomparable to the parallel FastPitch, with a significant lower latency that\nallows even lower response time for real-time speech applications.", "published": "2024-01-03 14:17:35", "link": "http://arxiv.org/abs/2401.01755v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoMoSVC: Consistency Model-based Singing Voice Conversion", "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved\nremarkable performances, producing natural audios with high similarity to the\ntarget timbre. However, the iterative sampling process results in slow\ninference speed, and acceleration thus becomes crucial. In this paper, we\npropose CoMoSVC, a consistency model-based SVC method, which aims to achieve\nboth high-quality generation and high-speed sampling. A diffusion-based teacher\nmodel is first specially designed for SVC, and a student model is further\ndistilled under self-consistency properties to achieve one-step sampling.\nExperiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a\nsignificantly faster inference speed than the state-of-the-art (SOTA)\ndiffusion-based SVC system, it still achieves comparable or superior conversion\nperformance based on both subjective and objective metrics. Audio samples and\ncodes are available at https://comosvc.github.io/.", "published": "2024-01-03 15:47:17", "link": "http://arxiv.org/abs/2401.01792v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
