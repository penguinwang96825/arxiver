{"title": "Surfacing contextual hate speech words within social media", "abstract": "Social media platforms have recently seen an increase in the occurrence of\nhate speech discourse which has led to calls for improved detection methods.\nMost of these rely on annotated data, keywords, and a classification technique.\nWhile this approach provides good coverage, it can fall short when dealing with\nnew terms produced by online extremist communities which act as original\nsources of words which have alternate hate speech meanings. These code words\n(which can be both created and adopted words) are designed to evade automatic\ndetection and often have benign meanings in regular discourse. As an example,\n\"skypes\", \"googles\", and \"yahoos\" are all instances of words which have an\nalternate meaning that can be used for hate speech. This overlap introduces\nadditional challenges when relying on keywords for both the collection of data\nthat is specific to hate speech, and downstream classification. In this work,\nwe develop a community detection approach for finding extremist hate speech\ncommunities and collecting data from their members. We also develop a word\nembedding model that learns the alternate hate speech meaning of words and\ndemonstrate the candidacy of our code words with several annotation\nexperiments, designed to determine if it is possible to recognize a word as\nbeing used for hate speech without knowing its alternate meaning. We report an\ninter-annotator agreement rate of K=0.871, and K=0.676 for data drawn from our\nextremist community and the keyword approach respectively, supporting our claim\nthat hate speech detection is a contextual task and does not depend on a fixed\nlist of keywords. Our goal is to advance the domain by providing a high quality\nhate speech dataset in addition to learned code words that can be fed into\nexisting classification approaches, thus improving the accuracy of automated\ndetection.", "published": "2017-11-28 02:56:12", "link": "http://arxiv.org/abs/1711.10093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-end Adversarial Learning for Generative Conversational Agents", "abstract": "This paper presents a new adversarial learning method for generative\nconversational agents (GCA) besides a new model of GCA. Similar to previous\nworks on adversarial learning for dialogue generation, our method assumes the\nGCA as a generator that aims at fooling a discriminator that labels dialogues\nas human-generated or machine-generated; however, in our approach, the\ndiscriminator performs token-level classification, i.e. it indicates whether\nthe current token was generated by humans or machines. To do so, the\ndiscriminator also receives the context utterances (the dialogue history) and\nthe incomplete answer up to the current token as input. This new approach makes\npossible the end-to-end training by backpropagation. A self-conversation\nprocess enables to produce a set of generated data with more diversity for the\nadversarial training. This approach improves the performance on questions not\nrelated to the training data. Experimental results with human and adversarial\nevaluations show that the adversarial method yields significant performance\ngains over the usual teacher forcing training.", "published": "2017-11-28 04:42:24", "link": "http://arxiv.org/abs/1711.10122v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vietnamese Semantic Role Labelling", "abstract": "In this paper, we study semantic role labelling (SRL), a subtask of semantic\nparsing of natural language sentences and its application for the Vietnamese\nlanguage. We present our effort in building Vietnamese PropBank, the first\nVietnamese SRL corpus and a software system for labelling semantic roles of\nVietnamese texts. In particular, we present a novel constituent extraction\nalgorithm in the argument candidate identification step which is more suitable\nand more accurate than the common node-mapping method. In the machine learning\npart, our system integrates distributed word features produced by two recent\nunsupervised learning models in two learned statistical classifiers and makes\nuse of integer linear programming inference procedure to improve the accuracy.\nThe system is evaluated in a series of experiments and achieves a good result,\nan $F_1$ score of 74.77%. Our system, including corpus and software, is\navailable as an open source project for free research and we believe that it is\na good baseline for the development of future Vietnamese SRL systems.", "published": "2017-11-28 04:51:25", "link": "http://arxiv.org/abs/1711.10124v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Discovery of Structured Acoustic Tokens with Applications\n  to Spoken Term Detection", "abstract": "In this paper, we compare two paradigms for unsupervised discovery of\nstructured acoustic tokens directly from speech corpora without any human\nannotation. The Multigranular Paradigm seeks to capture all available\ninformation in the corpora with multiple sets of tokens for different model\ngranularities. The Hierarchical Paradigm attempts to jointly learn several\nlevels of signal representations in a hierarchical structure. The two paradigms\nare unified within a theoretical framework in this paper. Query-by-Example\nSpoken Term Detection (QbE-STD) experiments on the QUESST dataset of MediaEval\n2015 verifies the competitiveness of the acoustic tokens. The Enhanced\nRelevance Score (ERS) proposed in this work improves both paradigms for the\ntask of QbE-STD. We also list results on the ABX evaluation task of the Zero\nResource Challenge 2015 for comparison of the Paradigms.", "published": "2017-11-28 05:43:44", "link": "http://arxiv.org/abs/1711.10133v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acoustic-To-Word Model Without OOV", "abstract": "Recently, the acoustic-to-word model based on the Connectionist Temporal\nClassification (CTC) criterion was shown as a natural end-to-end model directly\ntargeting words as output units. However, this type of word-based CTC model\nsuffers from the out-of-vocabulary (OOV) issue as it can only model limited\nnumber of words in the output layer and maps all the remaining words into an\nOOV output node. Therefore, such word-based CTC model can only recognize the\nfrequent words modeled by the network output nodes. It also cannot easily\nhandle the hot-words which emerge after the model is trained. In this study, we\nimprove the acoustic-to-word model with a hybrid CTC model which can predict\nboth words and characters at the same time. With a shared-hidden-layer\nstructure and modular design, the alignments of words generated from the\nword-based CTC and the character-based CTC are synchronized. Whenever the\nacoustic-to-word model emits an OOV token, we back off that OOV segment to the\nword output generated from the character-based CTC, hence solving the OOV or\nhot-words issue. Evaluated on a Microsoft Cortana voice assistant task, the\nproposed model can reduce the errors introduced by the OOV output token in the\nacoustic-to-word model by 30%.", "published": "2017-11-28 05:55:11", "link": "http://arxiv.org/abs/1711.10136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Oracle: Making Use of Ambiguity in Transition-based Chinese\n  Dependency Parsing", "abstract": "In the training of transition-based dependency parsers, an oracle is used to\npredict a transition sequence for a sentence and its gold tree. However, the\ntransition system may exhibit ambiguity, that is, there can be multiple correct\ntransition sequences that form the gold tree. We propose to make use of the\nproperty in the training of neural dependency parsers, and present the Hybrid\nOracle. The new oracle gives all the correct transitions for a parsing state,\nwhich are used in the cross entropy loss function to provide better supervisory\nsignal. It is also used to generate different transition sequences for a\nsentence to better explore the training data and improve the generalization\nability of the parser. Evaluations show that the parsers trained using the\nhybrid oracle outperform the parsers using the traditional oracle in Chinese\ndependency parsing. We provide analysis from a linguistic view. The code is\navailable at https://github.com/lancopku/nndep .", "published": "2017-11-28 07:58:34", "link": "http://arxiv.org/abs/1711.10163v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visualisation and 'diagnostic classifiers' reveal how recurrent and\n  recursive neural networks process hierarchical structure", "abstract": "We investigate how neural networks can learn and process languages with\nhierarchical, compositional semantics. To this end, we define the artificial\ntask of processing nested arithmetic expressions, and study whether different\ntypes of neural networks can learn to compute their meaning. We find that\nrecursive neural networks can find a generalising solution to this problem, and\nwe visualise this solution by breaking it up in three steps: project, sum and\nsquash. As a next step, we investigate recurrent neural networks, and show that\na gated recurrent unit, that processes its input incrementally, also performs\nvery well on this task. To develop an understanding of what the recurrent\nnetwork encodes, visualisation techniques alone do not suffice. Therefore, we\ndevelop an approach where we formulate and test multiple hypotheses on the\ninformation encoded and processed by the network. For each hypothesis, we\nderive predictions about features of the hidden state representations at each\ntime step, and train 'diagnostic classifiers' to test those predictions. Our\nresults indicate that the networks follow a strategy similar to our\nhypothesised 'cumulative strategy', which explains the high accuracy of the\nnetwork on novel expressions, the generalisation to longer expressions than\nseen in training, and the mild deterioration with increasing length. This is\nturn shows that diagnostic classifiers can be a useful technique for opening up\nthe black box of neural networks. We argue that diagnostic classification,\nunlike most visualisation techniques, does scale up from small networks in a\ntoy domain, to larger and deeper recurrent networks dealing with real-life\ndata, and may therefore contribute to a better understanding of the internal\ndynamics of current state-of-the-art models in natural language processing.", "published": "2017-11-28 09:41:34", "link": "http://arxiv.org/abs/1711.10203v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Technology-Assisted Review (STAR) Document analysis and\n  monitoring using random vectors", "abstract": "The review and analysis of large collections of documents and the periodic\nmonitoring of new additions thereto has greatly benefited from new developments\nin computer software. This paper demonstrates how using random vectors to\nconstruct a low-dimensional Euclidean space embedding words and documents\nenables fast and accurate computation of semantic similarities between them.\nWith this technique of Semantic Technology-Assisted Review (STAR), documents\ncan be selected, compared, classified, summarized and evaluated very quickly\nwith minimal expert involvement and high-quality results.", "published": "2017-11-28 14:28:54", "link": "http://arxiv.org/abs/1711.10307v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Generative Interest Estimation for Document Recommendations", "abstract": "Learning distributed representations of documents has pushed the\nstate-of-the-art in several natural language processing tasks and was\nsuccessfully applied to the field of recommender systems recently. In this\npaper, we propose a novel content-based recommender system based on learned\nrepresentations and a generative model of user interest. Our method works as\nfollows: First, we learn representations on a corpus of text documents. Then,\nwe capture a user's interest as a generative model in the space of the document\nrepresentations. In particular, we model the distribution of interest for each\nuser as a Gaussian mixture model (GMM). Recommendations can be obtained\ndirectly by sampling from a user's generative model. Using Latent semantic\nanalysis (LSA) as comparison, we compute and explore document representations\non the Delicious bookmarks dataset, a standard benchmark for recommender\nsystems. We then perform density estimation in both spaces and show that\nlearned representations outperform LSA in terms of predictive performance.", "published": "2017-11-28 15:00:24", "link": "http://arxiv.org/abs/1711.10327v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "WSNet: Compact and Efficient Networks Through Weight Sampling", "abstract": "We present a new approach and a novel architecture, termed WSNet, for\nlearning compact and efficient deep neural networks. Existing approaches\nconventionally learn full model parameters independently and then compress them\nvia ad hoc processing such as model pruning or filter factorization.\nAlternatively, WSNet proposes learning model parameters by sampling from a\ncompact set of learnable parameters, which naturally enforces {parameter\nsharing} throughout the learning process. We demonstrate that such a novel\nweight sampling approach (and induced WSNet) promotes both weights and\ncomputation sharing favorably. By employing this method, we can more\nefficiently learn much smaller networks with competitive performance compared\nto baseline networks with equal numbers of convolution filters. Specifically,\nwe consider learning compact and efficient 1D convolutional neural networks for\naudio classification. Extensive experiments on multiple audio classification\ndatasets verify the effectiveness of WSNet. Combined with weight quantization,\nthe resulted models are up to 180 times smaller and theoretically up to 16\ntimes faster than the well-established baselines, without noticeable\nperformance drop.", "published": "2017-11-28 00:43:20", "link": "http://arxiv.org/abs/1711.10067v3", "categories": ["cs.CV", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Exploiting Nontrivial Connectivity for Automatic Speech Recognition", "abstract": "Nontrivial connectivity has allowed the training of very deep networks by\naddressing the problem of vanishing gradients and offering a more efficient\nmethod of reusing parameters. In this paper we make a comparison between\nresidual networks, densely-connected networks and highway networks on an image\nclassification task. Next, we show that these methodologies can easily be\ndeployed into automatic speech recognition and provide significant improvements\nto existing models.", "published": "2017-11-28 13:13:41", "link": "http://arxiv.org/abs/1711.10271v1", "categories": ["cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Learning from Between-class Examples for Deep Sound Recognition", "abstract": "Deep learning methods have achieved high performance in sound recognition\ntasks. Deciding how to feed the training data is important for further\nperformance improvement. We propose a novel learning method for deep sound\nrecognition: Between-Class learning (BC learning). Our strategy is to learn a\ndiscriminative feature space by recognizing the between-class sounds as\nbetween-class sounds. We generate between-class sounds by mixing two sounds\nbelonging to different classes with a random ratio. We then input the mixed\nsound to the model and train the model to output the mixing ratio. The\nadvantages of BC learning are not limited only to the increase in variation of\nthe training data; BC learning leads to an enlargement of Fisher's criterion in\nthe feature space and a regularization of the positional relationship among the\nfeature distributions of the classes. The experimental results show that BC\nlearning improves the performance on various sound recognition networks,\ndatasets, and data augmentation schemes, in which BC learning proves to be\nalways beneficial. Furthermore, we construct a new deep sound recognition\nnetwork (EnvNet-v2) and train it with BC learning. As a result, we achieved a\nperformance surpasses the human level.", "published": "2017-11-28 13:29:45", "link": "http://arxiv.org/abs/1711.10282v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
