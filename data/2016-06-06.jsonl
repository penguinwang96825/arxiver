{"title": "Generating and Exploiting Large-scale Pseudo Training Data for Zero\n  Pronoun Resolution", "abstract": "Most existing approaches for zero pronoun resolution are heavily relying on\nannotated data, which is often released by shared task organizers. Therefore,\nthe lack of annotated data becomes a major obstacle in the progress of zero\npronoun resolution task. Also, it is expensive to spend manpower on labeling\nthe data for better performance. To alleviate the problem above, in this paper,\nwe propose a simple but novel approach to automatically generate large-scale\npseudo training data for zero pronoun resolution. Furthermore, we successfully\ntransfer the cloze-style reading comprehension neural network model into zero\npronoun resolution task and propose a two-step training mechanism to overcome\nthe gap between the pseudo training data and the real one. Experimental results\nshow that the proposed approach significantly outperforms the state-of-the-art\nsystems with an absolute improvements of 3.1% F-score on OntoNotes 5.0 data.", "published": "2016-06-06 02:45:47", "link": "http://arxiv.org/abs/1606.01603v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Deep Averaging Networks for Cross-Lingual Sentiment\n  Classification", "abstract": "In recent years great success has been achieved in sentiment classification\nfor English, thanks in part to the availability of copious annotated resources.\nUnfortunately, most languages do not enjoy such an abundance of labeled data.\nTo tackle the sentiment classification problem in low-resource languages\nwithout adequate annotated data, we propose an Adversarial Deep Averaging\nNetwork (ADAN) to transfer the knowledge learned from labeled data on a\nresource-rich source language to low-resource languages where only unlabeled\ndata exists. ADAN has two discriminative branches: a sentiment classifier and\nan adversarial language discriminator. Both branches take input from a shared\nfeature extractor to learn hidden representations that are simultaneously\nindicative for the classification task and invariant across languages.\nExperiments on Chinese and Arabic sentiment classification demonstrate that\nADAN significantly outperforms state-of-the-art systems.", "published": "2016-06-06 05:04:23", "link": "http://arxiv.org/abs/1606.01614v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gated Word-Character Recurrent Language Model", "abstract": "We introduce a recurrent neural network language model (RNN-LM) with long\nshort-term memory (LSTM) units that utilizes both character-level and\nword-level inputs. Our model has a gate that adaptively finds the optimal\nmixture of the character-level and word-level inputs. The gate creates the\nfinal vector representation of a word by combining two distinct representations\nof the word. The character-level inputs are converted into vector\nrepresentations of words using a bidirectional LSTM. The word-level inputs are\nprojected into another high-dimensional space by a word lookup table. The final\nvector representations of words are used in the LSTM language model which\npredicts the next word given all the preceding words. Our model with the gating\nmechanism effectively utilizes the character-level inputs for rare and\nout-of-vocabulary words and outperforms word-level language models on several\nEnglish corpora.", "published": "2016-06-06 11:43:28", "link": "http://arxiv.org/abs/1606.01700v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation with External Phrase Memory", "abstract": "In this paper, we propose phraseNet, a neural machine translator with a\nphrase memory which stores phrase pairs in symbolic form, mined from corpus or\nspecified by human experts. For any given source sentence, phraseNet scans the\nphrase memory to determine the candidate phrase pairs and integrates tagging\ninformation in the representation of source sentence accordingly. The decoder\nutilizes a mixture of word-generating component and phrase-generating\ncomponent, with a specifically designed strategy to generate a sequence of\nmultiple words all at once. The phraseNet not only approaches one step towards\nincorporating external knowledge into neural machine translation, but also\nmakes an effort to extend the word-by-word generation mechanism of recurrent\nneural network. Our empirical study on Chinese-to-English translation shows\nthat, with carefully-chosen phrase table in memory, phraseNet yields 3.45 BLEU\nimprovement over the generic neural machine translator.", "published": "2016-06-06 15:45:41", "link": "http://arxiv.org/abs/1606.01792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Decomposable Attention Model for Natural Language Inference", "abstract": "We propose a simple neural architecture for natural language inference. Our\napproach uses attention to decompose the problem into subproblems that can be\nsolved separately, thus making it trivially parallelizable. On the Stanford\nNatural Language Inference (SNLI) dataset, we obtain state-of-the-art results\nwith almost an order of magnitude fewer parameters than previous work and\nwithout relying on any word-order information. Adding intra-sentence attention\nthat takes a minimum amount of order into account yields further improvements.", "published": "2016-06-06 20:30:57", "link": "http://arxiv.org/abs/1606.01933v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proof nets for the Displacement calculus", "abstract": "We present a proof net calculus for the Displacement calculus and show its\ncorrectness. This is the first proof net calculus which models the Displacement\ncalculus directly and not by some sort of translation into another formalism.\nThe proof net calculus opens up new possibilities for parsing and proof search\nwith the Displacement calculus.", "published": "2016-06-06 12:55:57", "link": "http://arxiv.org/abs/1606.01720v1", "categories": ["cs.LO", "cs.CL"], "primary_category": "cs.LO"}
{"title": "Very Deep Convolutional Networks for Text Classification", "abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in\nparticular LSTMs, and convolutional neural networks. However, these\narchitectures are rather shallow in comparison to the deep convolutional\nnetworks which have pushed the state-of-the-art in computer vision. We present\na new architecture (VDCNN) for text processing which operates directly at the\ncharacter level and uses only small convolutions and pooling operations. We are\nable to show that the performance of this model increases with depth: using up\nto 29 convolutional layers, we report improvements over the state-of-the-art on\nseveral public text classification tasks. To the best of our knowledge, this is\nthe first time that very deep convolutional nets have been applied to text\nprocessing.", "published": "2016-06-06 15:14:50", "link": "http://arxiv.org/abs/1606.01781v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and\n  Visual Grounding", "abstract": "Modeling textual or visual information with vector representations trained\nfrom large language or visual datasets has been successfully explored in recent\nyears. However, tasks such as visual question answering require combining these\nvector representations with each other. Approaches to multimodal pooling\ninclude element-wise product or sum, as well as concatenation of the visual and\ntextual representations. We hypothesize that these methods are not as\nexpressive as an outer product of the visual and textual vectors. As the outer\nproduct is typically infeasible due to its high dimensionality, we instead\npropose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and\nexpressively combine multimodal features. We extensively evaluate MCB on the\nvisual question answering and grounding tasks. We consistently show the benefit\nof MCB over ablations without MCB. For visual question answering, we present an\narchitecture which uses MCB twice, once for predicting attention over spatial\nfeatures and again to combine the attended representation with the question\nrepresentation. This model outperforms the state-of-the-art on the Visual7W\ndataset and the VQA challenge.", "published": "2016-06-06 17:59:56", "link": "http://arxiv.org/abs/1606.01847v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
