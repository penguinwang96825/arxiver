{"title": "Variation and generality in encoding of syntactic anomaly information in\n  sentence embeddings", "abstract": "While sentence anomalies have been applied periodically for testing in NLP,\nwe have yet to establish a picture of the precise status of anomaly information\nin representations from NLP models. In this paper we aim to fill two primary\ngaps, focusing on the domain of syntactic anomalies. First, we explore\nfine-grained differences in anomaly encoding by designing probing tasks that\nvary the hierarchical level at which anomalies occur in a sentence. Second, we\ntest not only models' ability to detect a given anomaly, but also the\ngenerality of the detected anomaly signal, by examining transfer between\ndistinct anomaly types. Results suggest that all models encode some information\nsupporting anomaly detection, but detection performance varies between\nanomalies, and only representations from more recent transformer models show\nsigns of generalized knowledge of anomalies. Follow-up analyses support the\nnotion that these models pick up on a legitimate, general notion of sentence\noddity, while coarser-grained word position information is likely also a\ncontributor to the observed anomaly detection.", "published": "2021-11-12 10:23:43", "link": "http://arxiv.org/abs/2111.06644v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker and Time-aware Joint Contextual Learning for Dialogue-act\n  Classification in Counselling Conversations", "abstract": "The onset of the COVID-19 pandemic has brought the mental health of people\nunder risk. Social counselling has gained remarkable significance in this\nenvironment. Unlike general goal-oriented dialogues, a conversation between a\npatient and a therapist is considerably implicit, though the objective of the\nconversation is quite apparent. In such a case, understanding the intent of the\npatient is imperative in providing effective counselling in therapy sessions,\nand the same applies to a dialogue system as well. In this work, we take\nforward a small but an important step in the development of an automated\ndialogue system for mental-health counselling. We develop a novel dataset,\nnamed HOPE, to provide a platform for the dialogue-act classification in\ncounselling conversations. We identify the requirement of such conversation and\npropose twelve domain-specific dialogue-act (DAC) labels. We collect 12.9K\nutterances from publicly-available counselling session videos on YouTube,\nextract their transcripts, clean, and annotate them with DAC labels. Further,\nwe propose SPARTA, a transformer-based architecture with a novel speaker- and\ntime-aware contextual learning for the dialogue-act classification. Our\nevaluation shows convincing performance over several baselines, achieving\nstate-of-the-art on HOPE. We also supplement our experiments with extensive\nempirical and qualitative analyses of SPARTA.", "published": "2021-11-12 10:30:30", "link": "http://arxiv.org/abs/2111.06647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Transferability of Prompt Tuning for Natural Language Processing", "abstract": "Prompt tuning (PT) is a promising parameter-efficient method to utilize\nextremely large pre-trained language models (PLMs), which can achieve\ncomparable performance to full-parameter fine-tuning by only tuning a few soft\nprompts. However, PT requires much more training time than fine-tuning.\nIntuitively, knowledge transfer can help to improve the efficiency. To explore\nwhether we can improve PT via prompt transfer, we empirically investigate the\ntransferability of soft prompts across different downstream tasks and PLMs in\nthis work. We find that (1) in zero-shot setting, trained soft prompts can\neffectively transfer to similar tasks on the same PLM and also to other PLMs\nwith a cross-model projector trained on similar tasks; (2) when used as\ninitialization, trained soft prompts of similar tasks and projected prompts of\nother PLMs can significantly accelerate training and also improve the\nperformance of PT. Moreover, to explore what decides prompt transferability, we\ninvestigate various transferability indicators and find that the overlapping\nrate of activated neurons strongly reflects the transferability, which suggests\nhow the prompts stimulate PLMs is essential. Our findings show that prompt\ntransfer is promising for improving PT, and further research shall focus more\non prompts' stimulation to PLMs. The source code can be obtained from\nhttps://github.com/thunlp/Prompt-Transferability.", "published": "2021-11-12 13:39:28", "link": "http://arxiv.org/abs/2111.06719v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BitextEdit: Automatic Bitext Editing for Improved Low-Resource Machine\n  Translation", "abstract": "Mined bitexts can contain imperfect translations that yield unreliable\ntraining signals for Neural Machine Translation (NMT). While filtering such\npairs out is known to improve final model quality, we argue that it is\nsuboptimal in low-resource conditions where even mined data can be limited. In\nour work, we propose instead, to refine the mined bitexts via automatic\nediting: given a sentence in a language xf, and a possibly imperfect\ntranslation of it xe, our model generates a revised version xf' or xe' that\nyields a more equivalent translation pair (i.e., <xf, xe'> or <xf', xe>). We\nuse a simple editing strategy by (1) mining potentially imperfect translations\nfor each sentence in a given bitext, (2) learning a model to reconstruct the\noriginal translations and translate, in a multi-task fashion. Experiments\ndemonstrate that our approach successfully improves the quality of CCMatrix\nmined bitext for 5 low-resource language-pairs and 10 translation directions by\nup to ~ 8 BLEU points, in most cases improving upon a competitive\nback-translation baseline.", "published": "2021-11-12 16:00:39", "link": "http://arxiv.org/abs/2111.06787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting All Samples in Low-Resource Sentence Classification: Early\n  Stopping and Initialization Parameters", "abstract": "To improve deep-learning performance in low-resource settings, many\nresearchers have redesigned model architectures or applied additional data\n(e.g., external resources, unlabeled samples). However, there have been\nrelatively few discussions on how to make good use of small amounts of labeled\nsamples, although it is potentially beneficial and should be done before\napplying additional data or redesigning models. In this study, we assume a\nlow-resource setting in which only a few labeled samples (i.e., 30-100 per\nclass) are available, and we discuss how to exploit them without additional\ndata or model redesigns. We explore possible approaches in the following three\naspects: training-validation splitting, early stopping, and weight\ninitialization. Extensive experiments are conducted on six public sentence\nclassification datasets. Performance on various evaluation metrics (e.g.,\naccuracy, loss, and calibration error) significantly varied depending on the\napproaches that were combined in the three aspects. Based on the results, we\npropose an integrated method, which is to initialize the model with a weight\naveraging method and use a non-validation stop method to train all samples.\nThis simple integrated method consistently outperforms the competitive methods;\ne.g., the average accuracy of six datasets of this method was 1.8% higher than\nthose of conventional validation-based methods. In addition, the integrated\nmethod further improves the performance when adapted to several\nstate-of-the-art models that use additional data or redesign the network\narchitecture (e.g., self-training and enhanced structural models). Our results\nhighlight the importance of the training strategy and suggest that the\nintegrated method can be the first step in the low-resource setting. This study\nprovides empirical knowledge that will be helpful when dealing with\nlow-resource data in future efforts.", "published": "2021-11-12 22:31:47", "link": "http://arxiv.org/abs/2111.06971v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RATE: Overcoming Noise and Sparsity of Textual Features in Real-Time\n  Location Estimation", "abstract": "Real-time location inference of social media users is the fundamental of some\nspatial applications such as localized search and event detection. While tweet\ntext is the most commonly used feature in location estimation, most of the\nprior works suffer from either the noise or the sparsity of textual features.\nIn this paper, we aim to tackle these two problems. We use topic modeling as a\nbuilding block to characterize the geographic topic variation and lexical\nvariation so that \"one-hot\" encoding vectors will no longer be directly used.\nWe also incorporate other features which can be extracted through the Twitter\nstreaming API to overcome the noise problem. Experimental results show that our\nRATE algorithm outperforms several benchmark methods, both in the precision of\nregion classification and the mean distance error of latitude and longitude\nregression.", "published": "2021-11-12 00:57:42", "link": "http://arxiv.org/abs/2111.06515v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extraction of Medication Names from Twitter Using Augmentation and an\n  Ensemble of Language Models", "abstract": "The BioCreative VII Track 3 challenge focused on the identification of\nmedication names in Twitter user timelines. For our submission to this\nchallenge, we expanded the available training data by using several data\naugmentation techniques. The augmented data was then used to fine-tune an\nensemble of language models that had been pre-trained on general-domain Twitter\ncontent. The proposed approach outperformed the prior state-of-the-art\nalgorithm Kusuri and ranked high in the competition for our selected objective\nfunction, overlapping F1 score.", "published": "2021-11-12 11:18:46", "link": "http://arxiv.org/abs/2111.06664v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deciphering Speech: a Zero-Resource Approach to Cross-Lingual Transfer\n  in ASR", "abstract": "We present a method for cross-lingual training an ASR system using absolutely\nno transcribed training data from the target language, and with no phonetic\nknowledge of the language in question. Our approach uses a novel application of\na decipherment algorithm, which operates given only unpaired speech and text\ndata from the target language. We apply this decipherment to phone sequences\ngenerated by a universal phone recogniser trained on out-of-language speech\ncorpora, which we follow with flat-start semi-supervised training to obtain an\nacoustic model for the new language. To the best of our knowledge, this is the\nfirst practical approach to zero-resource cross-lingual ASR which does not rely\non any hand-crafted phonetic information. We carry out experiments on read\nspeech from the GlobalPhone corpus, and show that it is possible to learn a\ndecipherment model on just 20 minutes of data from the target language. When\nused to generate pseudo-labels for semi-supervised training, we obtain WERs\nthat range from 32.5% to just 1.9% absolute worse than the equivalent fully\nsupervised models trained on the same data.", "published": "2021-11-12 16:16:46", "link": "http://arxiv.org/abs/2111.06799v3", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Benchmarking deep generative models for diverse antibody sequence design", "abstract": "Computational protein design, i.e. inferring novel and diverse protein\nsequences consistent with a given structure, remains a major unsolved\nchallenge. Recently, deep generative models that learn from sequences alone or\nfrom sequences and structures jointly have shown impressive performance on this\ntask. However, those models appear limited in terms of modeling structural\nconstraints, capturing enough sequence diversity, or both. Here we consider\nthree recently proposed deep generative frameworks for protein design: (AR) the\nsequence-based autoregressive generative model, (GVP) the precise\nstructure-based graph neural network, and Fold2Seq that leverages a fuzzy and\nscale-free representation of a three-dimensional fold, while enforcing\nstructure-to-sequence (and vice versa) consistency. We benchmark these models\non the task of computational design of antibody sequences, which demand\ndesigning sequences with high diversity for functional implication. The\nFold2Seq framework outperforms the two other baselines in terms of diversity of\nthe designed sequences, while maintaining the typical fold.", "published": "2021-11-12 16:23:32", "link": "http://arxiv.org/abs/2111.06801v1", "categories": ["q-bio.BM", "cs.CL"], "primary_category": "q-bio.BM"}
{"title": "Speeding Up Entmax", "abstract": "Softmax is the de facto standard in modern neural networks for language\nprocessing when it comes to normalizing logits. However, by producing a dense\nprobability distribution each token in the vocabulary has a nonzero chance of\nbeing selected at each generation step, leading to a variety of reported\nproblems in text generation. $\\alpha$-entmax of Peters et al. (2019,\narXiv:1905.05702) solves this problem, but is considerably slower than softmax.\n  In this paper, we propose an alternative to $\\alpha$-entmax, which keeps its\nvirtuous characteristics, but is as fast as optimized softmax and achieves on\npar or better performance in machine translation task.", "published": "2021-11-12 17:34:11", "link": "http://arxiv.org/abs/2111.06832v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MS-LaTTE: A Dataset of Where and When To-do Tasks are Completed", "abstract": "Tasks are a fundamental unit of work in the daily lives of people, who are\nincreasingly using digital means to keep track of, organize, triage and act on\nthem. These digital tools -- such as task management applications -- provide a\nunique opportunity to study and understand tasks and their connection to the\nreal world, and through intelligent assistance, help people be more productive.\nBy logging signals such as text, timestamp information, and social connectivity\ngraphs, an increasingly rich and detailed picture of how tasks are created and\norganized, what makes them important, and who acts on them, can be\nprogressively developed. Yet the context around actual task completion remains\nfuzzy, due to the basic disconnect between actions taken in the real world and\ntelemetry recorded in the digital world. Thus, in this paper we compile and\nrelease a novel, real-life, large-scale dataset called MS-LaTTE that captures\ntwo core aspects of the context surrounding task completion: location and time.\nWe describe our annotation framework and conduct a number of analyses on the\ndata that were collected, demonstrating that it captures intuitive contextual\nproperties for common tasks. Finally, we test the dataset on the two problems\nof predicting spatial and temporal task co-occurrence, concluding that\npredictors for co-location and co-time are both learnable, with a BERT\nfine-tuned model outperforming several other baselines. The MS-LaTTE dataset\nprovides an opportunity to tackle many new modeling challenges in contextual\ntask understanding and we hope that its release will spur future research in\ntask intelligence more broadly.", "published": "2021-11-12 19:01:06", "link": "http://arxiv.org/abs/2111.06902v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unifying Heterogeneous Electronic Health Records Systems via Text-Based\n  Code Embedding", "abstract": "EHR systems lack a unified code system forrepresenting medical concepts,\nwhich acts asa barrier for the deployment of deep learningmodels in large scale\nto multiple clinics and hos-pitals. To overcome this problem, we\nintroduceDescription-based Embedding,DescEmb, a code-agnostic representation\nlearning framework forEHR. DescEmb takes advantage of the flexibil-ity of\nneural language understanding models toembed clinical events using their\ntextual descrip-tions rather than directly mapping each event toa dedicated\nembedding. DescEmb outperformedtraditional code-based embedding in\nextensiveexperiments, especially in a zero-shot transfertask (one hospital to\nanother), and was able totrain a single unified model for heterogeneousEHR\ndatasets.", "published": "2021-11-12 20:27:55", "link": "http://arxiv.org/abs/2111.09098v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On-the-Fly Rectification for Robust Large-Vocabulary Topic Inference", "abstract": "Across many data domains, co-occurrence statistics about the joint appearance\nof objects are powerfully informative. By transforming unsupervised learning\nproblems into decompositions of co-occurrence statistics, spectral algorithms\nprovide transparent and efficient algorithms for posterior inference such as\nlatent topic analysis and community detection. As object vocabularies grow,\nhowever, it becomes rapidly more expensive to store and run inference\nalgorithms on co-occurrence statistics. Rectifying co-occurrence, the key\nprocess to uphold model assumptions, becomes increasingly more vital in the\npresence of rare terms, but current techniques cannot scale to large\nvocabularies. We propose novel methods that simultaneously compress and rectify\nco-occurrence statistics, scaling gracefully with the size of vocabulary and\nthe dimension of latent space. We also present new algorithms learning latent\nvariables from the compressed statistics, and verify that our methods perform\ncomparably to previous approaches on both textual and non-textual data.", "published": "2021-11-12 06:44:04", "link": "http://arxiv.org/abs/2111.06580v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PESTO: Switching Point based Dynamic and Relative Positional Encoding\n  for Code-Mixed Languages", "abstract": "NLP applications for code-mixed (CM) or mix-lingual text have gained a\nsignificant momentum recently, the main reason being the prevalence of language\nmixing in social media communications in multi-lingual societies like India,\nMexico, Europe, parts of USA etc. Word embeddings are basic build-ing blocks of\nany NLP system today, yet, word embedding for CM languages is an unexplored\nterritory. The major bottleneck for CM word embeddings is switching points,\nwhere the language switches. These locations lack in contextually and\nstatistical systems fail to model this phenomena due to high variance in the\nseen examples. In this paper we present our initial observations on applying\nswitching point based positional encoding techniques for CM language,\nspecifically Hinglish (Hindi - English). Results are only marginally better\nthan SOTA, but it is evident that positional encoding could bean effective way\nto train position sensitive language models for CM text.", "published": "2021-11-12 08:18:21", "link": "http://arxiv.org/abs/2111.06599v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Convolutional Neural Network Based Approach to Recognize Bangla Spoken\n  Digits from Speech Signal", "abstract": "Speech recognition is a technique that converts human speech signals into\ntext or words or in any form that can be easily understood by computers or\nother machines. There have been a few studies on Bangla digit recognition\nsystems, the majority of which used small datasets with few variations in\ngenders, ages, dialects, and other variables. Audio recordings of Bangladeshi\npeople of various genders, ages, and dialects were used to create a large\nspeech dataset of spoken '0-9' Bangla digits in this study. Here, 400 noisy and\nnoise-free samples per digit have been recorded for creating the dataset. Mel\nFrequency Cepstrum Coefficients (MFCCs) have been utilized for extracting\nmeaningful features from the raw speech data. Then, to detect Bangla numeral\ndigits, Convolutional Neural Networks (CNNs) were utilized. The suggested\ntechnique recognizes '0-9' Bangla spoken digits with 97.1% accuracy throughout\nthe whole dataset. The efficiency of the model was also assessed using 10-fold\ncrossvalidation, which yielded a 96.7% accuracy.", "published": "2021-11-12 09:38:15", "link": "http://arxiv.org/abs/2111.06625v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Sci-Net: Scale Invariant Model for Buildings Segmentation from Aerial\n  Imagery", "abstract": "Buildings' segmentation is a fundamental task in the field of earth\nobservation and aerial imagery analysis. Most existing deep learning-based\nmethods in the literature can be applied to a fixed or narrow-range spatial\nresolution imagery. In practical scenarios, users deal with a broad spectrum of\nimage resolutions. Thus, a given aerial image often needs to be re-sampled to\nmatch the spatial resolution of the dataset used to train the deep learning\nmodel, which results in a degradation in segmentation performance. To overcome\nthis challenge, we propose, in this manuscript, Scale-invariant Neural Network\n(Sci-Net) architecture that segments buildings from wide-range spatial\nresolution aerial images. Specifically, our approach leverages UNet\nhierarchical representation and Dense Atrous Spatial Pyramid Pooling to extract\nfine-grained multi-scale representations. Sci-Net significantly outperforms\nstate of the art models on the Open Cities AI and the Multi-Scale Building\ndatasets with a steady improvement margin across different spatial resolutions.", "published": "2021-11-12 16:45:20", "link": "http://arxiv.org/abs/2111.06812v5", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Offense Detection in Dravidian Languages using Code-Mixing Index based\n  Focal Loss", "abstract": "Over the past decade, we have seen exponential growth in online content\nfueled by social media platforms. Data generation of this scale comes with the\ncaveat of insurmountable offensive content in it. The complexity of identifying\noffensive content is exacerbated by the usage of multiple modalities (image,\nlanguage, etc.), code-mixed language and more. Moreover, even after careful\nsampling and annotation of offensive content, there will always exist a\nsignificant class imbalance between offensive and non-offensive content. In\nthis paper, we introduce a novel Code-Mixing Index (CMI) based focal loss which\ncircumvents two challenges (1) code-mixing in languages (2) class imbalance\nproblem for Dravidian language offense detection. We also replace the\nconventional dot product-based classifier with the cosine-based classifier\nwhich results in a boost in performance. Further, we use multilingual models\nthat help transfer characteristics learnt across languages to work effectively\nwith low resourced languages. It is also important to note that our model\nhandles instances of mixed script (say usage of Latin and Dravidian-Tamil\nscript) as well. To summarize, our model can handle offensive language\ndetection in a low-resource, class imbalanced, multilingual and code-mixed\nsetting.", "published": "2021-11-12 19:50:24", "link": "http://arxiv.org/abs/2111.06916v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Disentangling Physical Parameters for Anomalous Sound Detection Under\n  Domain Shifts", "abstract": "To develop a sound-monitoring system for machines, a method for detecting\nanomalous sound under domain shifts is proposed. A domain shift occurs when a\nmachine's physical parameters change. Because a domain shift changes the\ndistribution of normal sound data, conventional unsupervised anomaly detection\nmethods can output false positives. To solve this problem, the proposed method\nconstrains some latent variables of a normalizing flows (NF) model to represent\nphysical parameters, which enables disentanglement of the factors of domain\nshifts and learning of a latent space that is invariant with respect to these\ndomain shifts. Anomaly scores calculated from this domain-shift-invariant\nlatent space are unaffected by such shifts, which reduces false positives and\nimproves the detection performance. Experiments were conducted with sound data\nfrom a slide rail under different operation velocities. The results show that\nthe proposed method disentangled the velocity to obtain a latent space that was\ninvariant with respect to domain shifts, which improved the AUC by 13.2% for\nGlow with a single block and 2.6% for Glow with multiple blocks.", "published": "2021-11-12 02:32:50", "link": "http://arxiv.org/abs/2111.06539v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AC-VC: Non-parallel Low Latency Phonetic Posteriorgrams Based Voice\n  Conversion", "abstract": "This paper presents AC-VC (Almost Causal Voice Conversion), a phonetic\nposteriorgrams based voice conversion system that can perform any-to-many voice\nconversion while having only 57.5 ms future look-ahead. The complete system is\ncomposed of three neural networks trained separately with non-parallel data.\nWhile most of the current voice conversion systems focus primarily on quality\nirrespective of algorithmic latency, this work elaborates on designing a method\nusing a minimal amount of future context thus allowing a future real-time\nimplementation. According to a subjective listening test organized in this\nwork, the proposed AC-VC system achieves parity with the non-causal ASR-TTS\nbaseline of the Voice Conversion Challenge 2020 in naturalness with a MOS of\n3.5. In contrast, the results indicate that missing future context impacts\nspeaker similarity. Obtained similarity percentage of 65% is lower than the\nsimilarity of current best voice conversion systems.", "published": "2021-11-12 08:21:54", "link": "http://arxiv.org/abs/2111.06601v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HLT-NUS SUBMISSION FOR 2020 NIST Conversational Telephone Speech SRE", "abstract": "This work provides a brief description of Human Language Technology (HLT)\nLaboratory, National University of Singapore (NUS) system submission for 2020\nNIST conversational telephone speech (CTS) speaker recognition evaluation\n(SRE). The challenge focuses on evaluation under CTS data containing\nmultilingual speech. The systems developed at HLT-NUS consider time-delay\nneural network (TDNN) x-vector and ECAPA-TDNN systems. We also perform domain\nadaption of probabilistic linear discriminant analysis (PLDA) model and\nadaptive s-norm on our systems. The score level fusion of TDNN x-vector and\nECAPA-TDNN systems is carried out, which improves the final system performance\nof our submission to 2020 NIST CTS SRE.", "published": "2021-11-12 11:47:44", "link": "http://arxiv.org/abs/2111.06671v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Domain Generalization on Efficient Acoustic Scene Classification using\n  Residual Normalization", "abstract": "It is a practical research topic how to deal with multi-device audio inputs\nby a single acoustic scene classification system with efficient design. In this\nwork, we propose Residual Normalization, a novel feature normalization method\nthat uses frequency-wise normalization % instance normalization with a shortcut\npath to discard unnecessary device-specific information without losing useful\ninformation for classification. Moreover, we introduce an efficient\narchitecture, BC-ResNet-ASC, a modified version of the baseline architecture\nwith a limited receptive field. BC-ResNet-ASC outperforms the baseline\narchitecture even though it contains the small number of parameters. Through\nthree model compression schemes: pruning, quantization, and knowledge\ndistillation, we can reduce model complexity further while mitigating the\nperformance degradation. The proposed system achieves an average test accuracy\nof 76.3% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with\n315k parameters, and average test accuracy of 75.3% after compression to 61.0KB\nof non-zero parameters. The proposed method won the 1st place in DCASE 2021\nchallenge, TASK1A.", "published": "2021-11-12 01:57:36", "link": "http://arxiv.org/abs/2111.06531v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fully Automatic Page Turning on Real Scores", "abstract": "We present a prototype of an automatic page turning system that works\ndirectly on real scores, i.e., sheet images, without any symbolic\nrepresentation. Our system is based on a multi-modal neural network\narchitecture that observes a complete sheet image page as input, listens to an\nincoming musical performance, and predicts the corresponding position in the\nimage. Using the position estimation of our system, we use a simple heuristic\nto trigger a page turning event once a certain location within the sheet image\nis reached. As a proof of concept we further combine our system with an actual\nmachine that will physically turn the page on command.", "published": "2021-11-12 10:23:14", "link": "http://arxiv.org/abs/2111.06643v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
