{"title": "Delta Embedding Learning", "abstract": "Unsupervised word embeddings have become a popular approach of word\nrepresentation in NLP tasks. However there are limitations to the semantics\nrepresented by unsupervised embeddings, and inadequate fine-tuning of\nembeddings can lead to suboptimal performance. We propose a novel learning\ntechnique called Delta Embedding Learning, which can be applied to general NLP\ntasks to improve performance by optimized tuning of the word embeddings. A\nstructured regularization is applied to the embeddings to ensure they are tuned\nin an incremental way. As a result, the tuned word embeddings become better\nword representations by absorbing semantic information from supervision without\n\"forgetting.\" We apply the method to various NLP tasks and see a consistent\nimprovement in performance. Evaluation also confirms the tuned word embeddings\nhave better semantic properties.", "published": "2018-12-11 00:19:32", "link": "http://arxiv.org/abs/1812.04160v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RESIDE: Improving Distantly-Supervised Neural Relation Extraction using\n  Side Information", "abstract": "Distantly-supervised Relation Extraction (RE) methods train an extractor by\nautomatically aligning relation instances in a Knowledge Base (KB) with\nunstructured text. In addition to relation instances, KBs often contain other\nrelevant side information, such as aliases of relations (e.g., founded and\nco-founded are aliases for the relation founderOfCompany). RE models usually\nignore such readily available side information. In this paper, we propose\nRESIDE, a distantly-supervised neural relation extraction method which utilizes\nadditional side information from KBs for improved relation extraction. It uses\nentity type and relation alias information for imposing soft constraints while\npredicting relations. RESIDE employs Graph Convolution Networks (GCN) to encode\nsyntactic information from text and improves performance even when limited side\ninformation is available. Through extensive experiments on benchmark datasets,\nwe demonstrate RESIDE's effectiveness. We have made RESIDE's source code\navailable to encourage reproducible research.", "published": "2018-12-11 12:41:14", "link": "http://arxiv.org/abs/1812.04361v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conditional Variational Autoencoder for Neural Machine Translation", "abstract": "We explore the performance of latent variable models for conditional text\ngeneration in the context of neural machine translation (NMT). Similar to Zhang\net al., we augment the encoder-decoder NMT paradigm by introducing a continuous\nlatent variable to model features of the translation process. We extend this\nmodel with a co-attention mechanism motivated by Parikh et al. in the inference\nnetwork. Compared to the vision domain, latent variable models for text face\nadditional challenges due to the discrete nature of language, namely posterior\ncollapse. We experiment with different approaches to mitigate this issue. We\nshow that our conditional variational model improves upon both discriminative\nattention-based translation and the variational baseline presented in Zhang et\nal. Finally, we present some exploration of the learned latent space to\nillustrate what the latent variable is capable of capturing. This is the first\nreported conditional variational model for text that meaningfully utilizes the\nlatent variable without weakening the translation model.", "published": "2018-12-11 14:05:24", "link": "http://arxiv.org/abs/1812.04405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scalable language model adaptation for spoken dialogue systems", "abstract": "Language models (LM) for interactive speech recognition systems are trained\non large amounts of data and the model parameters are optimized on past user\ndata. New application intents and interaction types are released for these\nsystems over time, imposing challenges to adapt the LMs since the existing\ntraining data is no longer sufficient to model the future user interactions. It\nis unclear how to adapt LMs to new application intents without degrading the\nperformance on existing applications. In this paper, we propose a solution to\n(a) estimate n-gram counts directly from the hand-written grammar for training\nLMs and (b) use constrained optimization to optimize the system parameters for\nfuture use cases, while not degrading the performance on past usage. We\nevaluated our approach on new applications intents for a personal assistant\nsystem and find that the adaptation improves the word error rate by up to 15%\non new applications even when there is no adaptation data available for an\napplication.", "published": "2018-12-11 19:02:05", "link": "http://arxiv.org/abs/1812.04647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised domain-agnostic identification of product names in social\n  media posts", "abstract": "Product name recognition is a significant practical problem, spurred by the\ngreater availability of platforms for discussing products such as social media\nand product review functionalities of online marketplaces. Customers, product\nmanufacturers and online marketplaces may want to identify product names in\nunstructured text to extract important insights, such as sentiment, surrounding\na product. Much extant research on product name identification has been\ndomain-specific (e.g., identifying mobile phone models) and used supervised or\nsemi-supervised methods. With massive numbers of new products released to the\nmarket every year such methods may require retraining on updated labeled data\nto stay relevant, and may transfer poorly across domains. This research\naddresses this challenge and develops a domain-agnostic, unsupervised algorithm\nfor identifying product names based on Facebook posts. The algorithm consists\nof two general steps: (a) candidate product name identification using an\noff-the-shelf pretrained conditional random fields (CRF) model, part-of-speech\ntagging and a set of simple patterns; and (b) filtering of candidate names to\nremove spurious entries using clustering and word embeddings generated from the\ndata.", "published": "2018-12-11 19:34:49", "link": "http://arxiv.org/abs/1812.04662v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting the Effects of News Sentiments on the Stock Market", "abstract": "Stock market forecasting is very important in the planning of business\nactivities. Stock price prediction has attracted many researchers in multiple\ndisciplines including computer science, statistics, economics, finance, and\noperations research. Recent studies have shown that the vast amount of online\ninformation in the public domain such as Wikipedia usage pattern, news stories\nfrom the mainstream media, and social media discussions can have an observable\neffect on investors opinions towards financial markets. The reliability of the\ncomputational models on stock market prediction is important as it is very\nsensitive to the economy and can directly lead to financial loss. In this\npaper, we retrieved, extracted, and analyzed the effects of news sentiments on\nthe stock market. Our main contributions include the development of a sentiment\nanalysis dictionary for the financial sector, the development of a\ndictionary-based sentiment analysis model, and the evaluation of the model for\ngauging the effects of news sentiments on stocks for the pharmaceutical market.\nUsing only news sentiments, we achieved a directional accuracy of 70.59% in\npredicting the trends in short-term stock price movement.", "published": "2018-12-11 03:06:02", "link": "http://arxiv.org/abs/1812.04199v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Reader: Information extraction from Document images via relation\n  extraction and Natural Language", "abstract": "Recent advancements in the area of Computer Vision with state-of-art Neural\nNetworks has given a boost to Optical Character Recognition (OCR) accuracies.\nHowever, extracting characters/text alone is often insufficient for relevant\ninformation extraction as documents also have a visual structure that is not\ncaptured by OCR. Extracting information from tables, charts, footnotes, boxes,\nheadings and retrieving the corresponding structured representation for the\ndocument remains a challenge and finds application in a large number of\nreal-world use cases. In this paper, we propose a novel enterprise based\nend-to-end framework called DeepReader which facilitates information extraction\nfrom document images via identification of visual entities and populating a\nmeta relational model across different entities in the document image. The\nmodel schema allows for an easy to understand abstraction of the entities\ndetected by the deep vision models and the relationships between them.\nDeepReader has a suite of state-of-the-art vision algorithms which are applied\nto recognize handwritten and printed text, eliminate noisy effects, identify\nthe type of documents and detect visual entities like tables, lines and boxes.\nDeep Reader maps the extracted entities into a rich relational schema so as to\ncapture all the relevant relationships between entities (words, textboxes,\nlines etc) detected in the document. Relevant information and fields can then\nbe extracted from the document by writing SQL queries on top of the\nrelationship tables. A natural language based interface is added on top of the\nrelationship schema so that a non-technical user, specifying the queries in\nnatural language, can fetch the information with minimal effort. In this paper,\nwe also demonstrate many different capabilities of Deep Reader and report\nresults on a real-world use case.", "published": "2018-12-11 13:09:13", "link": "http://arxiv.org/abs/1812.04377v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Hyperbolic Deep Learning for Chinese Natural Language Understanding", "abstract": "Recently hyperbolic geometry has proven to be effective in building\nembeddings that encode hierarchical and entailment information. This makes it\nparticularly suited to modelling the complex asymmetrical relationships between\nChinese characters and words. In this paper we first train a large scale\nhyperboloid skip-gram model on a Chinese corpus, then apply the character\nembeddings to a downstream hyperbolic Transformer model derived from the\nprinciples of gyrovector space for Poincare disk model. In our experiments the\ncharacter-based Transformer outperformed its word-based Euclidean equivalent.\nTo the best of our knowledge, this is the first time in Chinese NLP that a\ncharacter-based model outperformed its word-based counterpart, allowing the\ncircumvention of the challenging and domain-dependent task of Chinese Word\nSegmentation (CWS).", "published": "2018-12-11 09:48:17", "link": "http://arxiv.org/abs/1812.10408v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Dimensionality of Word Embedding", "abstract": "In this paper, we provide a theoretical understanding of word embedding and\nits dimensionality. Motivated by the unitary-invariance of word embedding, we\npropose the Pairwise Inner Product (PIP) loss, a novel metric on the\ndissimilarity between word embeddings. Using techniques from matrix\nperturbation theory, we reveal a fundamental bias-variance trade-off in\ndimensionality selection for word embeddings. This bias-variance trade-off\nsheds light on many empirical observations which were previously unexplained,\nfor example the existence of an optimal dimensionality. Moreover, new insights\nand discoveries, like when and how word embeddings are robust to over-fitting,\nare revealed. By optimizing over the bias-variance trade-off of the PIP loss,\nwe can explicitly answer the open question of dimensionality selection for word\nembedding.", "published": "2018-12-11 05:25:38", "link": "http://arxiv.org/abs/1812.04224v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Machine Translation : From Statistical to modern Deep-learning practices", "abstract": "Machine translation (MT) is an area of study in Natural Language processing\nwhich deals with the automatic translation of human language, from one language\nto another by the computer. Having a rich research history spanning nearly\nthree decades, Machine translation is one of the most sought after area of\nresearch in the linguistics and computational community. In this paper, we\ninvestigate the models based on deep learning that have achieved substantial\nprogress in recent years and becoming the prominent method in MT. We shall\ndiscuss the two main deep-learning based Machine Translation methods, one at\ncomponent or domain level which leverages deep learning models to enhance the\nefficacy of Statistical Machine Translation (SMT) and end-to-end deep learning\nmodels in MT which uses neural networks to find correspondence between the\nsource and target languages using the encoder-decoder architecture. We conclude\nthis paper by providing a time line of the major research problems solved by\nthe researchers and also provide a comprehensive overview of present areas of\nresearch in Neural Machine Translation.", "published": "2018-12-11 07:04:44", "link": "http://arxiv.org/abs/1812.04238v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning latent representations for style control and transfer in\n  end-to-end speech synthesis", "abstract": "In this paper, we introduce the Variational Autoencoder (VAE) to an\nend-to-end speech synthesis model, to learn the latent representation of\nspeaking styles in an unsupervised manner. The style representation learned\nthrough VAE shows good properties such as disentangling, scaling, and\ncombination, which makes it easy for style control. Style transfer can be\nachieved in this framework by first inferring style representation through the\nrecognition network of VAE, then feeding it into TTS network to guide the style\nin synthesizing speech. To avoid Kullback-Leibler (KL) divergence collapse in\ntraining, several techniques are adopted. Finally, the proposed model shows\ngood performance of style control and outperforms Global Style Token (GST)\nmodel in ABX preference tests on style transfer.", "published": "2018-12-11 12:00:06", "link": "http://arxiv.org/abs/1812.04342v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Deep Anomaly Detection with Outlier Exposure", "abstract": "It is important to detect anomalous inputs when deploying machine learning\nsystems. The use of larger and more complex inputs in deep learning magnifies\nthe difficulty of distinguishing between anomalous and in-distribution\nexamples. At the same time, diverse image and text data are available in\nenormous quantities. We propose leveraging these data to improve deep anomaly\ndetection by training anomaly detectors against an auxiliary dataset of\noutliers, an approach we call Outlier Exposure (OE). This enables anomaly\ndetectors to generalize and detect unseen anomalies. In extensive experiments\non natural language processing and small- and large-scale vision tasks, we find\nthat Outlier Exposure significantly improves detection performance. We also\nobserve that cutting-edge generative models trained on CIFAR-10 may assign\nhigher likelihoods to SVHN images than to CIFAR-10 images; we use OE to\nmitigate this issue. We also analyze the flexibility and robustness of Outlier\nExposure, and identify characteristics of the auxiliary dataset that improve\nperformance.", "published": "2018-12-11 18:49:50", "link": "http://arxiv.org/abs/1812.04606v3", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reading Industrial Inspection Sheets by Inferring Visual Relations", "abstract": "The traditional mode of recording faults in heavy factory equipment has been\nvia hand marked inspection sheets, wherein a machine engineer manually marks\nthe faulty machine regions on a paper outline of the machine. Over the years,\nmillions of such inspection sheets have been recorded and the data within these\nsheets has remained inaccessible. However, with industries going digital and\nwaking up to the potential value of fault data for machine health monitoring,\nthere is an increased impetus towards digitization of these hand marked\ninspection records. To target this digitization, we propose a novel visual\npipeline combining state of the art deep learning models, with domain knowledge\nand low level vision techniques, followed by inference of visual relationships.\nOur framework is robust to the presence of both static and non-static\nbackground in the document, variability in the machine template diagrams,\nunstructured shape of graphical objects to be identified and variability in the\nstrokes of handwritten text. The proposed pipeline incorporates a capsule and\nspatial transformer network based classifier for accurate text reading, and a\ncustomized CTPN network for text detection in addition to hybrid techniques for\narrow detection and dialogue cloud removal. We have tested our approach on a\nreal world dataset of 50 inspection sheets for large containers and boilers.\nThe results are visually appealing and the pipeline achieved an accuracy of\n87.1% for text detection and 94.6% for text reading.", "published": "2018-12-11 13:10:14", "link": "http://arxiv.org/abs/1812.07104v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A cascaded multiple-speaker localization and tracking system", "abstract": "This paper presents an online multiple-speaker localization and tracking\nmethod, as the INRIA-Perception contribution to the LOCATA Challenge 2018.\nFirst, the recursive least-square method is used to adaptively estimate the\ndirect-path relative transfer function as an interchannel localization feature.\nThe feature is assumed to associate with a single speaker at each\ntime-frequency bin. Second, a complex Gaussian mixture model (CGMM) is used as\na generative model of the features. The weight of each CGMM component\nrepresents the probability that this component corresponds to an active\nspeaker, and is adaptively estimated with an online optimization algorithm.\nFinally, taking the CGMM component weights as observations, a Bayesian\nmultiple-speaker tracking method based on the variational expectation\nmaximization algorithm is used. The tracker accounts for the variation of\nactive speakers and the localization miss measurements, by introducing speaker\nbirth and sleeping processes. The experiments carried out on the development\ndataset of the challenge are reported.", "published": "2018-12-11 14:12:10", "link": "http://arxiv.org/abs/1812.04417v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Functional Taxonomy of Music Generation Systems", "abstract": "Digital advances have transformed the face of automatic music generation\nsince its beginnings at the dawn of computing. Despite the many breakthroughs,\nissues such as the musical tasks targeted by different machines and the degree\nto which they succeed remain open questions. We present a functional taxonomy\nfor music generation systems with reference to existing systems. The taxonomy\norganizes systems according to the purposes for which they were designed. It\nalso reveals the inter-relatedness amongst the systems. This design-centered\napproach contrasts with predominant methods-based surveys and facilitates the\nidentification of grand challenges to set the stage for new breakthroughs.", "published": "2018-12-11 02:07:06", "link": "http://arxiv.org/abs/1812.04186v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "68Txx, 68-XX"], "primary_category": "cs.SD"}
{"title": "DCASE 2018 Challenge: Solution for Task 5", "abstract": "To address Task 5 in the Detection and Classification of Acoustic Scenes and\nEvents (DCASE) 2018 challenge, in this paper, we propose an ensemble learning\nsystem. The proposed system consists of three different models, based on\nconvolutional neural network and long short memory recurrent neural network.\nWith extracted features such as spectrogram and mel-frequency cepstrum\ncoefficients from different channels, the proposed system can classify\ndifferent domestic activities effectively. Experimental results obtained from\nthe provided development dataset show that good performance with F1-score of\n92.19% can be achieved. Compared with the baseline system, our proposed system\nsignificantly improves the performance of F1-score by 7.69%.", "published": "2018-12-11 07:35:42", "link": "http://arxiv.org/abs/1812.04618v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
