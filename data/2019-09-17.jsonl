{"title": "Grounding learning of modifier dynamics: An application to color naming", "abstract": "Grounding is crucial for natural language understanding. An important subtask\nis to understand modified color expressions, such as 'dirty blue'. We present a\nmodel of color modifiers that, compared with previous additive models in RGB\nspace, learns more complex transformations. In addition, we present a model\nthat operates in the HSV color space. We show that certain adjectives are\nbetter modeled in that space. To account for all modifiers, we train a hard\nensemble model that selects a color space depending on the modifier color pair.\nExperimental results show significant and consistent improvements compared to\nthe state-of-the-art baseline model.", "published": "2019-09-17 04:49:25", "link": "http://arxiv.org/abs/1909.07586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Explicit and Implicit Structures for Targeted Sentiment\n  Analysis", "abstract": "Targeted sentiment analysis is the task of jointly predicting target entities\nand their associated sentiment information. Existing research efforts mostly\nregard this joint task as a sequence labeling problem, building models that can\ncapture explicit structures in the output space. However, the importance of\ncapturing implicit global structural information that resides in the input\nspace is largely unexplored. In this work, we argue that both types of\ninformation (implicit and explicit structural information) are crucial for\nbuilding a successful targeted sentiment analysis model. Our experimental\nresults show that properly capturing both information is able to lead to better\nperformance than competitive existing approaches. We also conduct extensive\nexperiments to investigate our model's effectiveness and robustness.", "published": "2019-09-17 05:03:43", "link": "http://arxiv.org/abs/1909.07593v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple yet Effective Bridge Reasoning for Open-Domain Multi-Hop Question\n  Answering", "abstract": "A key challenge of multi-hop question answering (QA) in the open-domain\nsetting is to accurately retrieve the supporting passages from a large corpus.\nExisting work on open-domain QA typically relies on off-the-shelf information\nretrieval (IR) techniques to retrieve \\textbf{answer passages}, i.e., the\npassages containing the groundtruth answers. However, IR-based approaches are\ninsufficient for multi-hop questions, as the topic of the second or further\nhops is not explicitly covered by the question. To resolve this issue, we\nintroduce a new sub-problem of open-domain multi-hop QA, which aims to\nrecognize the bridge (\\emph{i.e.}, the anchor that links to the answer passage)\nfrom the context of a set of start passages with a reading comprehension model.\nThis model, the \\textbf{bridge reasoner}, is trained with a weakly supervised\nsignal and produces the candidate answer passages for the \\textbf{passage\nreader} to extract the answer. On the full-wiki HotpotQA benchmark, we\nsignificantly improve the baseline method by 14 point F1. Without using any\nmemory-inefficient contextual embeddings, our result is also competitive with\nthe state-of-the-art that applies BERT in multiple modules.", "published": "2019-09-17 05:15:05", "link": "http://arxiv.org/abs/1909.07597v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-step Entity-centric Information Retrieval for Multi-Hop Question\n  Answering", "abstract": "Multi-hop question answering (QA) requires an information retrieval (IR)\nsystem that can find \\emph{multiple} supporting evidence needed to answer the\nquestion, making the retrieval process very challenging. This paper introduces\nan IR technique that uses information of entities present in the initially\nretrieved evidence to learn to `\\emph{hop}' to other relevant evidence. In a\nsetting, with more than \\textbf{5 million} Wikipedia paragraphs, our approach\nleads to significant boost in retrieval performance. The retrieved evidence\nalso increased the performance of an existing QA model (without any training)\non the \\hotpot benchmark by \\textbf{10.59} F1.", "published": "2019-09-17 05:23:50", "link": "http://arxiv.org/abs/1909.07598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SocialNLP EmotionX 2019 Challenge Overview: Predicting Emotions in\n  Spoken Dialogues and Chats", "abstract": "We present an overview of the EmotionX 2019 Challenge, held at the 7th\nInternational Workshop on Natural Language Processing for Social Media\n(SocialNLP), in conjunction with IJCAI 2019. The challenge entailed predicting\nemotions in spoken and chat-based dialogues using augmented EmotionLines\ndatasets. EmotionLines contains two distinct datasets: the first includes\nexcerpts from a US-based TV sitcom episode scripts (Friends) and the second\ncontains online chats (EmotionPush). A total of thirty-six teams registered to\nparticipate in the challenge. Eleven of the teams successfully submitted their\npredictions performance evaluation. The top-scoring team achieved a micro-F1\nscore of 81.5% for the spoken-based dialogues (Friends) and 79.5% for the\nchat-based dialogues (EmotionPush).", "published": "2019-09-17 11:55:32", "link": "http://arxiv.org/abs/1909.07734v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pointer-based Fusion of Bilingual Lexicons into Neural Machine\n  Translation", "abstract": "Neural machine translation (NMT) systems require large amounts of high\nquality in-domain parallel corpora for training. State-of-the-art NMT systems\nstill face challenges related to out-of-vocabulary words and dealing with\nlow-resource language pairs. In this paper, we propose and compare several\nmodels for fusion of bilingual lexicons with an end-to-end trained\nsequence-to-sequence model for machine translation. The result is a fusion\nmodel with two information sources for the decoder: a neural conditional\nlanguage model and a bilingual lexicon. This fusion model learns how to combine\nboth sources of information in order to produce higher quality translation\noutput. Our experiments show that our proposed models work well in relatively\nlow-resource scenarios, and also effectively reduce the parameter size and\ntraining cost for NMT without sacrificing performance.", "published": "2019-09-17 15:52:18", "link": "http://arxiv.org/abs/1909.07907v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Say Anything: Automatic Semantic Infelicity Detection in L2 English\n  Indefinite Pronouns", "abstract": "Computational research on error detection in second language speakers has\nmainly addressed clear grammatical anomalies typical to learners at the\nbeginner-to-intermediate level. We focus instead on acquisition of subtle\nsemantic nuances of English indefinite pronouns by non-native speakers at\nvarying levels of proficiency. We first lay out theoretical, linguistically\nmotivated hypotheses, and supporting empirical evidence on the nature of the\nchallenges posed by indefinite pronouns to English learners. We then suggest\nand evaluate an automatic approach for detection of atypical usage patterns,\ndemonstrating that deep learning architectures are promising for this task\ninvolving nuanced semantic anomalies.", "published": "2019-09-17 16:46:58", "link": "http://arxiv.org/abs/1909.07928v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using\n  Model Parallelism", "abstract": "Recent work in language modeling demonstrates that training large transformer\nmodels advances the state of the art in Natural Language Processing\napplications. However, very large models can be quite difficult to train due to\nmemory constraints. In this work, we present our techniques for training very\nlarge transformer models and implement a simple, efficient intra-layer model\nparallel approach that enables training transformer models with billions of\nparameters. Our approach does not require a new compiler or library changes, is\northogonal and complimentary to pipeline model parallelism, and can be fully\nimplemented with the insertion of a few communication operations in native\nPyTorch. We illustrate this approach by converging transformer based models up\nto 8.3 billion parameters using 512 GPUs. We sustain 15.1 PetaFLOPs across the\nentire application with 76% scaling efficiency when compared to a strong single\nGPU baseline that sustains 39 TeraFLOPs, which is 30% of peak FLOPs. To\ndemonstrate that large language models can further advance the state of the art\n(SOTA), we train an 8.3 billion parameter transformer language model similar to\nGPT-2 and a 3.9 billion parameter model similar to BERT. We show that careful\nattention to the placement of layer normalization in BERT-like models is\ncritical to achieving increased performance as the model size grows. Using the\nGPT-2 model we achieve SOTA results on the WikiText103 (10.8 compared to SOTA\nperplexity of 15.8) and LAMBADA (66.5% compared to SOTA accuracy of 63.2%)\ndatasets. Our BERT model achieves SOTA results on the RACE dataset (90.9%\ncompared to SOTA accuracy of 89.4%).", "published": "2019-09-17 19:42:54", "link": "http://arxiv.org/abs/1909.08053v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extractive Summarization of Long Documents by Combining Global and Local\n  Context", "abstract": "In this paper, we propose a novel neural single document extractive\nsummarization model for long documents, incorporating both the global context\nof the whole document and the local context within the current topic. We\nevaluate the model on two datasets of scientific papers, Pubmed and arXiv,\nwhere it outperforms previous work, both extractive and abstractive models, on\nROUGE-1, ROUGE-2 and METEOR scores. We also show that, consistently with our\ngoal, the benefits of our method become stronger as we apply it to longer\ndocuments. Rather surprisingly, an ablation study indicates that the benefits\nof our model seem to come exclusively from modeling the local context, even for\nthe longest documents.", "published": "2019-09-17 20:52:19", "link": "http://arxiv.org/abs/1909.08089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DOVER: A Method for Combining Diarization Outputs", "abstract": "Speech recognition and other natural language tasks have long benefited from\nvoting-based algorithms as a method to aggregate outputs from several systems\nto achieve a higher accuracy than any of the individual systems. Diarization,\nthe task of segmenting an audio stream into speaker-homogeneous and co-indexed\nregions, has so far not seen the benefit of this strategy because the structure\nof the task does not lend itself to a simple voting approach. This paper\npresents DOVER (diarization output voting error reduction), an algorithm for\nweighted voting among diarization hypotheses, in the spirit of the ROVER\nalgorithm for combining speech recognition hypotheses. We evaluate the\nalgorithm for diarization of meeting recordings with multiple microphones, and\nfind that it consistently reduces diarization error rate over the average of\nresults from individual channels, and often improves on the single best channel\nchosen by an oracle.", "published": "2019-09-17 20:56:50", "link": "http://arxiv.org/abs/1909.08090v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SUPP.AI: Finding Evidence for Supplement-Drug Interactions", "abstract": "Dietary supplements are used by a large portion of the population, but\ninformation on their pharmacologic interactions is incomplete. To address this\nchallenge, we present SUPP.AI, an application for browsing evidence of\nsupplement-drug interactions (SDIs) extracted from the biomedical literature.\nWe train a model to automatically extract supplement information and identify\nsuch interactions from the scientific literature. To address the lack of\nlabeled data for SDI identification, we use labels of the closely related task\nof identifying drug-drug interactions (DDIs) for supervision. We fine-tune the\ncontextualized word representations of the RoBERTa language model using labeled\nDDI data, and apply the fine-tuned model to identify supplement interactions.\nWe extract 195k evidence sentences from 22M articles (P=0.82, R=0.58, F1=0.68)\nfor 60k interactions. We create the SUPP.AI application for users to search\nevidence sentences extracted by our model. SUPP.AI is an attempt to close the\ninformation gap on dietary supplements by making up-to-date evidence on SDIs\nmore discoverable for researchers, clinicians, and consumers.", "published": "2019-09-17 22:54:10", "link": "http://arxiv.org/abs/1909.08135v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Length Control Neural Encoder-Decoder via Reinforcement\n  Learning", "abstract": "Controlling output length in neural language generation is valuable in many\nscenarios, especially for the tasks that have length constraints. A model with\nstronger length control capacity can produce sentences with more specific\nlength, however, it usually sacrifices semantic accuracy of the generated\nsentences. Here, we denote a concept of Controllable Length Control (CLC) for\nthe trade-off between length control capacity and semantic accuracy of the\nlanguage generation model. More specifically, CLC is to alter length control\ncapacity of the model so as to generate sentence with corresponding quality.\nThis is meaningful in real applications when length control capacity and\noutputs quality are requested with different priorities, or to overcome\nunstability of length control during model training. In this paper, we propose\ntwo reinforcement learning (RL) methods to adjust the trade-off between length\ncontrol capacity and semantic accuracy of length control models. Results show\nthat our RL methods improve scores across a wide range of target lengths and\nachieve the goal of CLC. Additionally, two models LenMC and LenLInit modified\non previous length-control models are proposed to obtain better performance in\nsummarization task while still maintain the ability to control length.", "published": "2019-09-17 08:57:07", "link": "http://arxiv.org/abs/1909.09492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap between Pre-Training and Fine-Tuning for End-to-End\n  Speech Translation", "abstract": "End-to-end speech translation, a hot topic in recent years, aims to translate\na segment of audio into a specific language with an end-to-end model.\nConventional approaches employ multi-task learning and pre-training methods for\nthis task, but they suffer from the huge gap between pre-training and\nfine-tuning. To address these issues, we propose a Tandem Connectionist\nEncoding Network (TCEN) which bridges the gap by reusing all subnets in\nfine-tuning, keeping the roles of subnets consistent, and pre-training the\nattention module. Furthermore, we propose two simple but effective methods to\nguarantee the speech encoder outputs and the MT encoder inputs are consistent\nin terms of semantic representation and sequence length. Experimental results\nshow that our model outperforms baselines 2.2 BLEU on a large benchmark\ndataset.", "published": "2019-09-17 03:47:25", "link": "http://arxiv.org/abs/1909.07575v3", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "K-BERT: Enabling Language Representation with Knowledge Graph", "abstract": "Pre-trained language representation models, such as BERT, capture a general\nlanguage representation from large-scale corpora, but lack domain-specific\nknowledge. When reading a domain text, experts make inferences with relevant\nknowledge. For machines to achieve this capability, we propose a\nknowledge-enabled language representation model (K-BERT) with knowledge graphs\n(KGs), in which triples are injected into the sentences as domain knowledge.\nHowever, too much knowledge incorporation may divert the sentence from its\ncorrect meaning, which is called knowledge noise (KN) issue. To overcome KN,\nK-BERT introduces soft-position and visible matrix to limit the impact of\nknowledge. K-BERT can easily inject domain knowledge into the models by\nequipped with a KG without pre-training by-self because it is capable of\nloading model parameters from the pre-trained BERT. Our investigation reveals\npromising results in twelve NLP tasks. Especially in domain-specific tasks\n(including finance, law, and medicine), K-BERT significantly outperforms BERT,\nwhich demonstrates that K-BERT is an excellent choice for solving the\nknowledge-driven problems that require experts.", "published": "2019-09-17 06:16:04", "link": "http://arxiv.org/abs/1909.07606v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Course Concept Expansion in MOOCs with External Knowledge and\n  Interactive Game", "abstract": "As Massive Open Online Courses (MOOCs) become increasingly popular, it is\npromising to automatically provide extracurricular knowledge for MOOC users.\nSuffering from semantic drifts and lack of knowledge guidance, existing methods\ncan not effectively expand course concepts in complex MOOC environments. In\nthis paper, we first build a novel boundary during searching for new concepts\nvia external knowledge base and then utilize heterogeneous features to verify\nthe high-quality results. In addition, to involve human efforts in our model,\nwe design an interactive optimization mechanism based on a game. Our\nexperiments on the four datasets from Coursera and XuetangX show that the\nproposed method achieves significant improvements(+0.19 by MAP) over existing\nmethods. The source code and datasets have been published.", "published": "2019-09-17 12:07:22", "link": "http://arxiv.org/abs/1909.07739v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Span-based Joint Entity and Relation Extraction with Transformer\n  Pre-training", "abstract": "We introduce SpERT, an attention model for span-based joint entity and\nrelation extraction. Our key contribution is a light-weight reasoning on BERT\nembeddings, which features entity recognition and filtering, as well as\nrelation classification with a localized, marker-free context representation.\nThe model is trained using strong within-sentence negative samples, which are\nefficiently extracted in a single BERT pass. These aspects facilitate a search\nover all spans in the sentence.\n  In ablation studies, we demonstrate the benefits of pre-training, strong\nnegative sampling and localized context. Our model outperforms prior work by up\nto 2.6% F1 score on several datasets for joint entity and relation extraction.", "published": "2019-09-17 13:01:12", "link": "http://arxiv.org/abs/1909.07755v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Character-Centric Storytelling", "abstract": "Sequential vision-to-language or visual storytelling has recently been one of\nthe areas of focus in computer vision and language modeling domains. Though\nexisting models generate narratives that read subjectively well, there could be\ncases when these models miss out on generating stories that account and address\nall prospective human and animal characters in the image sequences. Considering\nthis scenario, we propose a model that implicitly learns relationships between\nprovided characters and thereby generates stories with respective characters in\nscope. We use the VIST dataset for this purpose and report numerous statistics\non the dataset. Eventually, we describe the model, explain the experiment and\ndiscuss our current status and future work.", "published": "2019-09-17 14:51:59", "link": "http://arxiv.org/abs/1909.07863v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning to Deceive with Attention-Based Explanations", "abstract": "Attention mechanisms are ubiquitous components in neural architectures\napplied to natural language processing. In addition to yielding gains in\npredictive accuracy, attention weights are often claimed to confer\ninterpretability, purportedly useful both for providing insights to\npractitioners and for explaining why a model makes its decisions to\nstakeholders. We call the latter use of attention mechanisms into question by\ndemonstrating a simple method for training models to produce deceptive\nattention masks. Our method diminishes the total weight assigned to designated\nimpermissible tokens, even when the models can be shown to nevertheless rely on\nthese features to drive predictions. Across multiple models and tasks, our\napproach manipulates attention weights while paying surprisingly little cost in\naccuracy. Through a human study, we show that our manipulated attention-based\nexplanations deceive people into thinking that predictions from a model biased\nagainst gender minorities do not rely on the gender. Consequently, our results\ncast doubt on attention's reliability as a tool for auditing algorithms in the\ncontext of fairness and accountability.", "published": "2019-09-17 16:10:30", "link": "http://arxiv.org/abs/1909.07913v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do NLP Models Know Numbers? Probing Numeracy in Embeddings", "abstract": "The ability to understand and work with numbers (numeracy) is critical for\nmany complex reasoning tasks. Currently, most NLP models treat numbers in text\nin the same way as other tokens---they embed them as distributed vectors. Is\nthis enough to capture numeracy? We begin by investigating the numerical\nreasoning capabilities of a state-of-the-art question answering model on the\nDROP dataset. We find this model excels on questions that require numerical\nreasoning, i.e., it already captures numeracy. To understand how this\ncapability emerges, we probe token embedding methods (e.g., BERT, GloVe) on\nsynthetic list maximum, number decoding, and addition tasks. A surprising\ndegree of numeracy is naturally present in standard embeddings. For example,\nGloVe and word2vec accurately encode magnitude for numbers up to 1,000.\nFurthermore, character-level embeddings are even more precise---ELMo captures\nnumeracy the best for all pre-trained methods---but BERT, which uses sub-word\nunits, is less exact.", "published": "2019-09-17 17:24:37", "link": "http://arxiv.org/abs/1909.07940v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Relatedness Based Re-ranker for Text Spotting", "abstract": "Applications such as textual entailment, plagiarism detection or document\nclustering rely on the notion of semantic similarity, and are usually\napproached with dimension reduction techniques like LDA or with embedding-based\nneural approaches. We present a scenario where semantic similarity is not\nenough, and we devise a neural approach to learn semantic relatedness. The\nscenario is text spotting in the wild, where a text in an image (e.g. street\nsign, advertisement or bus destination) must be identified and recognized. Our\ngoal is to improve the performance of vision systems by leveraging semantic\ninformation. Our rationale is that the text to be spotted is often related to\nthe image context in which it appears (word pairs such as Delta-airplane, or\nquarters-parking are not similar, but are clearly related). We show how\nlearning a word-to-word or word-to-sentence relatedness score can improve the\nperformance of text spotting systems up to 2.9 points, outperforming other\nmeasures in a benchmark dataset.", "published": "2019-09-17 17:31:37", "link": "http://arxiv.org/abs/1909.07950v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Generative Dialog Policy for Task-oriented Dialog Systems", "abstract": "There is an increasing demand for task-oriented dialogue systems which can\nassist users in various activities such as booking tickets and restaurant\nreservations. In order to complete dialogues effectively, dialogue policy plays\na key role in task-oriented dialogue systems. As far as we know, the existing\ntask-oriented dialogue systems obtain the dialogue policy through\nclassification, which can assign either a dialogue act and its corresponding\nparameters or multiple dialogue acts without their corresponding parameters for\na dialogue action. In fact, a good dialogue policy should construct multiple\ndialogue acts and their corresponding parameters at the same time. However,\nit's hard for existing classification-based methods to achieve this goal. Thus,\nto address the issue above, we propose a novel generative dialogue policy\nlearning method. Specifically, the proposed method uses attention mechanism to\nfind relevant segments of given dialogue context and input utterance and then\nconstructs the dialogue policy by a seq2seq way for task-oriented dialogue\nsystems. Extensive experiments on two benchmark datasets show that the proposed\nmodel significantly outperforms the state-of-the-art baselines. In addition, we\nhave publicly released our codes.", "published": "2019-09-17 15:50:56", "link": "http://arxiv.org/abs/1909.09484v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inverse Visual Question Answering with Multi-Level Attentions", "abstract": "In this paper, we propose a novel deep multi-level attention model to address\ninverse visual question answering. The proposed model generates regional visual\nand semantic features at the object level and then enhances them with the\nanswer cue by using attention mechanisms. Two levels of multiple attentions are\nemployed in the model, including the dual attention at the partial question\nencoding step and the dynamic attention at the next question word generation\nstep. We evaluate the proposed model on the VQA V1 dataset. It demonstrates\nstate-of-the-art performance in terms of multiple commonly used metrics.", "published": "2019-09-17 04:41:12", "link": "http://arxiv.org/abs/1909.07583v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multi Sense Embeddings from Topic Models", "abstract": "Distributed word embeddings have yielded state-of-the-art performance in many\nNLP tasks, mainly due to their success in capturing useful semantic\ninformation. These representations assign only a single vector to each word\nwhereas a large number of words are polysemous (i.e., have multiple meanings).\nIn this work, we approach this critical problem in lexical semantics, namely\nthat of representing various senses of polysemous words in vector spaces. We\npropose a topic modeling based skip-gram approach for learning multi-prototype\nword embeddings. We also introduce a method to prune the embeddings determined\nby the probabilistic representation of the word in each topic. We use our\nembeddings to show that they can capture the context and word similarity\nstrongly and outperform various state-of-the-art implementations.", "published": "2019-09-17 12:23:33", "link": "http://arxiv.org/abs/1909.07746v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Generating Black-Box Adversarial Examples for Text Classifiers Using a\n  Deep Reinforced Model", "abstract": "Recently, generating adversarial examples has become an important means of\nmeasuring robustness of a deep learning model. Adversarial examples help us\nidentify the susceptibilities of the model and further counter those\nvulnerabilities by applying adversarial training techniques. In natural\nlanguage domain, small perturbations in the form of misspellings or paraphrases\ncan drastically change the semantics of the text. We propose a reinforcement\nlearning based approach towards generating adversarial examples in black-box\nsettings. We demonstrate that our method is able to fool well-trained models\nfor (a) IMDB sentiment classification task and (b) AG's news corpus news\ncategorization task with significantly high success rates. We find that the\nadversarial examples generated are semantics-preserving perturbations to the\noriginal text.", "published": "2019-09-17 15:05:31", "link": "http://arxiv.org/abs/1909.07873v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing\n  and Machine Learning", "abstract": "Consumption of diets with low glycemic impact is highly recommended for\ndiabetics and pre-diabetics as it helps maintain their blood glucose levels.\nHowever, laboratory analysis of dietary glycemic potency is time-consuming and\nexpensive. In this paper, we explore a data-driven approach utilizing online\ncrowdsourcing and machine learning to estimate the glycemic impact of cooking\nrecipes. We show that a commonly used healthiness metric may not always be\neffective in determining recipes suitable for diabetics, thus emphasizing the\nimportance of the glycemic-impact estimation task. Our best classification\nmodel, trained on nutritional and crowdsourced data obtained from Amazon\nMechanical Turk (AMT), can accurately identify recipes which are unhealthful\nfor diabetics.", "published": "2019-09-17 15:14:51", "link": "http://arxiv.org/abs/1909.07881v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Revealing the Importance of Semantic Retrieval for Machine Reading at\n  Scale", "abstract": "Machine Reading at Scale (MRS) is a challenging task in which a system is\ngiven an input query and is asked to produce a precise output by \"reading\"\ninformation from a large knowledge base. The task has gained popularity with\nits natural combination of information retrieval (IR) and machine comprehension\n(MC). Advancements in representation learning have led to separated progress in\nboth IR and MC; however, very few studies have examined the relationship and\ncombined design of retrieval and comprehension at different levels of\ngranularity, for development of MRS systems. In this work, we give general\nguidelines on system design for MRS by proposing a simple yet effective\npipeline system with special consideration on hierarchical semantic retrieval\nat both paragraph and sentence level, and their potential effects on the\ndownstream task. The system is evaluated on both fact verification and\nopen-domain multihop QA, achieving state-of-the-art results on the leaderboard\ntest sets of both FEVER and HOTPOTQA. To further demonstrate the importance of\nsemantic retrieval, we present ablation and analysis studies to quantify the\ncontribution of neural retrieval modules at both paragraph-level and\nsentence-level, and illustrate that intermediate semantic retrieval modules are\nvital for not only effectively filtering upstream information and thus saving\ndownstream computation, but also for shaping upstream data distribution and\nproviding better data for downstream modeling. Code/data made publicly\navailable at: https://github.com/easonnie/semanticRetrievalMRS", "published": "2019-09-17 19:21:11", "link": "http://arxiv.org/abs/1909.08041v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relaxed Softmax for learning from Positive and Unlabeled data", "abstract": "In recent years, the softmax model and its fast approximations have become\nthe de-facto loss functions for deep neural networks when dealing with\nmulti-class prediction. This loss has been extended to language modeling and\nrecommendation, two fields that fall into the framework of learning from\nPositive and Unlabeled data. In this paper, we stress the different drawbacks\nof the current family of softmax losses and sampling schemes when applied in a\nPositive and Unlabeled learning setup. We propose both a Relaxed Softmax loss\n(RS) and a new negative sampling scheme based on Boltzmann formulation. We show\nthat the new training objective is better suited for the tasks of density\nestimation, item similarity and next-event prediction by driving uplifts in\nperformance on textual and recommendation datasets against classical softmax.", "published": "2019-09-17 20:29:57", "link": "http://arxiv.org/abs/1909.08079v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Simultaneous Speech Recognition and Speaker Diarization for Monaural\n  Dialogue Recordings with Target-Speaker Acoustic Models", "abstract": "This paper investigates the use of target-speaker automatic speech\nrecognition (TS-ASR) for simultaneous speech recognition and speaker\ndiarization of single-channel dialogue recordings. TS-ASR is a technique to\nautomatically extract and recognize only the speech of a target speaker given a\nshort sample utterance of that speaker. One obvious drawback of TS-ASR is that\nit cannot be used when the speakers in the recordings are unknown because it\nrequires a sample of the target speakers in advance of decoding. To remove this\nlimitation, we propose an iterative method, in which (i) the estimation of\nspeaker embeddings and (ii) TS-ASR based on the estimated speaker embeddings\nare alternately executed. We evaluated the proposed method by using very\nchallenging dialogue recordings in which the speaker overlap ratio was over\n20%. We confirmed that the proposed method significantly reduced both the word\nerror rate (WER) and diarization error rate (DER). Our proposed method combined\nwith i-vector speaker embeddings ultimately achieved a WER that differed by\nonly 2.1 % from that of TS-ASR given oracle speaker embeddings. Furthermore,\nour method can solve speaker diarization simultaneously as a by-product and\nachieved better DER than that of the conventional clustering-based speaker\ndiarization method based on i-vector.", "published": "2019-09-17 21:12:11", "link": "http://arxiv.org/abs/1909.08103v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning to Generate Questions with Adaptive Copying Neural Networks", "abstract": "Automatic question generation is an important problem in natural language\nprocessing. In this paper we propose a novel adaptive copying recurrent neural\nnetwork model to tackle the problem of question generation from sentences and\nparagraphs. The proposed model adds a copying mechanism component onto a\nbidirectional LSTM architecture to generate more suitable questions adaptively\nfrom the input data. Our experimental results show the proposed model can\noutperform the state-of-the-art question generation methods in terms of BLEU\nand ROUGE evaluation scores.", "published": "2019-09-17 05:27:45", "link": "http://arxiv.org/abs/1909.08187v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Exploring Scholarly Data by Semantic Query on Knowledge Graph Embedding\n  Space", "abstract": "The trends of open science have enabled several open scholarly datasets which\ninclude millions of papers and authors. Managing, exploring, and utilizing such\nlarge and complicated datasets effectively are challenging. In recent years,\nthe knowledge graph has emerged as a universal data format for representing\nknowledge about heterogeneous entities and their relationships. The knowledge\ngraph can be modeled by knowledge graph embedding methods, which represent\nentities and relations as embedding vectors in semantic space, then model the\ninteractions between these embedding vectors. However, the semantic structures\nin the knowledge graph embedding space are not well-studied, thus knowledge\ngraph embedding methods are usually only used for knowledge graph completion\nbut not data representation and analysis. In this paper, we propose to analyze\nthese semantic structures based on the well-studied word embedding space and\nuse them to support data exploration. We also define the semantic queries,\nwhich are algebraic operations between the embedding vectors in the knowledge\ngraph embedding space, to solve queries such as similarity and analogy between\nthe entities on the original datasets. We then design a general framework for\ndata exploration by semantic queries and discuss the solution to some\ntraditional scholarly data exploration tasks. We also propose some new\ninteresting tasks that can be solved based on the uncanny semantic structures\nof the embedding space.", "published": "2019-09-17 04:32:00", "link": "http://arxiv.org/abs/1909.08191v2", "categories": ["cs.AI", "cs.CL", "cs.DL"], "primary_category": "cs.AI"}
{"title": "BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase\n  Generation", "abstract": "This study mainly investigates two common decoding problems in neural\nkeyphrase generation: sequence length bias and beam diversity. To tackle the\nproblems, we introduce a beam search decoding strategy based on word-level and\nngram-level reward function to constrain and refine Seq2Seq inference at test\ntime. Results show that our simple proposal can overcome the algorithm bias to\nshorter and nearly identical sequences, resulting in a significant improvement\nof the decoding performance on generating keyphrases that are present and\nabsent in source text.", "published": "2019-09-17 18:44:54", "link": "http://arxiv.org/abs/1909.09485v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Ludwig: a type-based declarative deep learning toolbox", "abstract": "In this work we present Ludwig, a flexible, extensible and easy to use\ntoolbox which allows users to train deep learning models and use them for\nobtaining predictions without writing code. Ludwig implements a novel approach\nto deep learning model building based on two main abstractions: data types and\ndeclarative configuration files. The data type abstraction allows for easier\ncode and sub-model reuse, and the standardized interfaces imposed by this\nabstraction allow for encapsulation and make the code easy to extend.\nDeclarative model definition configuration files enable inexperienced users to\nobtain effective models and increase the productivity of expert users.\nAlongside these two innovations, Ludwig introduces a general modularized deep\nlearning architecture called Encoder-Combiner-Decoder that can be instantiated\nto perform a vast amount of machine learning tasks. These innovations make it\npossible for engineers, scientists from other fields and, in general, a much\nbroader audience to adopt deep learning models for their tasks, concretely\nhelping in its democratization.", "published": "2019-09-17 16:54:29", "link": "http://arxiv.org/abs/1909.07930v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.SE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Black-box Attacks on Automatic Speaker Verification using\n  Feedback-controlled Voice Conversion", "abstract": "Automatic speaker verification (ASV) systems in practice are greatly\nvulnerable to spoofing attacks. The latest voice conversion technologies are\nable to produce perceptually natural sounding speech that mimics any target\nspeakers. However, the perceptual closeness to a speaker's identity may not be\nenough to deceive an ASV system. In this work, we propose a framework that uses\nthe output scores of an ASV system as the feedback to a voice conversion\nsystem. The attacker framework is a black-box adversary that steals one's voice\nidentity, because it does not require any knowledge about the ASV system but\nthe system outputs. Experimental results conducted on ASVspoof 2019 database\nconfirm that the proposed feedback-controlled voice conversion framework\nproduces adversarial samples that are more deceptive than the straightforward\nvoice conversion, thereby boosting the impostor ASV scores. Further, the\nperceptual evaluation studies reveal that converted speech does not adversely\naffect the voice quality from the baseline system.", "published": "2019-09-17 08:54:17", "link": "http://arxiv.org/abs/1909.07655v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A scalable noisy speech dataset and online subjective test framework", "abstract": "Background noise is a major source of quality impairments in Voice over\nInternet Protocol (VoIP) and Public Switched Telephone Network (PSTN) calls.\nRecent work shows the efficacy of deep learning for noise suppression, but the\ndatasets have been relatively small compared to those used in other domains\n(e.g., ImageNet) and the associated evaluations have been more focused. In\norder to better facilitate deep learning research in Speech Enhancement, we\npresent a noisy speech dataset (MS-SNSD) that can scale to arbitrary sizes\ndepending on the number of speakers, noise types, and Speech to Noise Ratio\n(SNR) levels desired. We show that increasing dataset sizes increases noise\nsuppression performance as expected. In addition, we provide an open-source\nevaluation methodology to evaluate the results subjectively at scale using\ncrowdsourcing, with a reference algorithm to normalize the results. To\ndemonstrate the dataset and evaluation framework we apply it to several noise\nsuppressors and compare the subjective Mean Opinion Score (MOS) with objective\nquality measures such as SNR, PESQ, POLQA, and VISQOL and show why MOS is still\nrequired. Our subjective MOS evaluation is the first large scale evaluation of\nSpeech Enhancement algorithms that we are aware of.", "published": "2019-09-17 19:40:34", "link": "http://arxiv.org/abs/1909.08050v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Data-Efficient Classification of Birdcall Through Convolutional Neural\n  Networks Transfer Learning", "abstract": "Deep learning Convolutional Neural Network (CNN) models are powerful\nclassification models but require a large amount of training data. In niche\ndomains such as bird acoustics, it is expensive and difficult to obtain a large\nnumber of training samples. One method of classifying data with a limited\nnumber of training samples is to employ transfer learning. In this research, we\nevaluated the effectiveness of birdcall classification using transfer learning\nfrom a larger base dataset (2814 samples in 46 classes) to a smaller target\ndataset (351 samples in 10 classes) using the ResNet-50 CNN. We obtained 79%\naverage validation accuracy on the target dataset in 5-fold cross-validation.\nThe methodology of transfer learning from an ImageNet-trained CNN to a\nproject-specific and a much smaller set of classes and images was extended to\nthe domain of spectrogram images, where the base dataset effectively played the\nrole of the ImageNet.", "published": "2019-09-17 00:16:16", "link": "http://arxiv.org/abs/1909.07526v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.CV"}
