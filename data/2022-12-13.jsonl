{"title": "The Massively Multilingual Natural Language Understanding 2022\n  (MMNLU-22) Workshop and Competition", "abstract": "Despite recent progress in Natural Language Understanding (NLU), the creation\nof multilingual NLU systems remains a challenge. It is common to have NLU\nsystems limited to a subset of languages due to lack of available data. They\nalso often vary widely in performance. We launch a three-phase approach to\naddress the limitations in NLU and help propel NLU technology to new heights.\nWe release a 52 language dataset called the Multilingual Amazon SLU resource\npackage (SLURP) for Slot-filling, Intent classification, and Virtual assistant\nEvaluation, or MASSIVE, in an effort to address parallel data availability for\nvoice assistants. We organize the Massively Multilingual NLU 2022 Challenge to\nprovide a competitive environment and push the state-of-the art in the\ntransferability of models into other languages. Finally, we host the first\nMassively Multilingual NLU workshop which brings these components together. The\nMMNLU workshop seeks to advance the science behind multilingual NLU by\nproviding a platform for the presentation of new research in the field and\nconnecting teams working on this research direction. This paper summarizes the\ndataset, workshop and the competition and the findings of each phase.", "published": "2022-12-13 03:00:36", "link": "http://arxiv.org/abs/2212.06346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Technical Report -- Competition Solution for Prompt Tuning using\n  Pretrained Language Model", "abstract": "Prompt tuning recently becomes a hot-spot in the applications of large\npretrained language models on specific downstream tasks. Regarding the Language\nModel as a Service (LMaaS), black-box tuning using derivative-free optimization\n(DFO) provides a novel approach to expand the practical scenarios of pretrained\nmodels and enrich the researches of few-shot learning. In this report, we\npresent our solution in this competition that is based on the LMaaS scenario.\nOur solution consists of several modifications to BBTv2, including multiple\nlabel words, selection of P0, rolling update strategy, multi-task loss from MLP\nclassifier, and finally using the ensemble method to further improve\ngeneralization ability. We also shared some strategies that we tried but didn't\nuse in the final submission for further discussion. In the end we raised a\nquestion about the SNLI dataset and the impact on the results, as well as our\nconcerns about the competition.", "published": "2022-12-13 04:57:04", "link": "http://arxiv.org/abs/2212.06369v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a general purpose machine translation system for Sranantongo", "abstract": "Machine translation for Sranantongo (Sranan, srn), a low-resource Creole\nlanguage spoken predominantly in Surinam, is virgin territory. In this study we\ncreate a general purpose machine translation system for srn. In order to\nfacilitate this research, we introduce the SRNcorpus, a collection of parallel\nDutch (nl) to srn and monolingual srn data. We experiment with a wide range of\nproven machine translation methods. Our results demonstrate a strong baseline\nmachine translation system for srn.", "published": "2022-12-13 05:36:18", "link": "http://arxiv.org/abs/2212.06383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models\n  of Different Modalities", "abstract": "Recently, the success of pre-training in text domain has been fully extended\nto vision, audio, and cross-modal scenarios. The proposed pre-training models\nof different modalities are showing a rising trend of homogeneity in their\nmodel structures, which brings the opportunity to implement different\npre-training models within a uniform framework. In this paper, we present\nTencentPretrain, a toolkit supporting pre-training models of different\nmodalities. The core feature of TencentPretrain is the modular design. The\ntoolkit uniformly divides pre-training models into 5 components: embedding,\nencoder, target embedding, decoder, and target. As almost all of common modules\nare provided in each component, users can choose the desired modules from\ndifferent components to build a complete pre-training model. The modular design\nenables users to efficiently reproduce existing pre-training models or build\nbrand-new one. We test the toolkit on text, vision, and audio benchmarks and\nshow that it can match the performance of the original implementations.", "published": "2022-12-13 05:46:40", "link": "http://arxiv.org/abs/2212.06385v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distantly-Supervised Named Entity Recognition with Adaptive Teacher\n  Learning and Fine-grained Student Ensemble", "abstract": "Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates\nthe data scarcity problem in NER by automatically generating training samples.\nUnfortunately, the distant supervision may induce noisy labels, thus\nundermining the robustness of the learned models and restricting the practical\napplication. To relieve this problem, recent works adopt self-training\nteacher-student frameworks to gradually refine the training labels and improve\nthe generalization ability of NER models. However, we argue that the\nperformance of the current self-training frameworks for DS-NER is severely\nunderestimated by their plain designs, including both inadequate student\nlearning and coarse-grained teacher updating. Therefore, in this paper, we make\nthe first attempt to alleviate these issues by proposing: (1) adaptive teacher\nlearning comprised of joint training of two teacher-student networks and\nconsidering both consistent and inconsistent predictions between two teachers,\nthus promoting comprehensive student learning. (2) fine-grained student\nensemble that updates each fragment of the teacher model with a temporal moving\naverage of the corresponding fragment of the student, which enhances consistent\npredictions on each model fragment against noise. To verify the effectiveness\nof our proposed method, we conduct experiments on four DS-NER datasets. The\nexperimental results demonstrate that our method significantly surpasses\nprevious SOTA methods.", "published": "2022-12-13 12:14:09", "link": "http://arxiv.org/abs/2212.06522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Text-to-Text Multi-Task Learners Suffer from Task Conflict?", "abstract": "Traditional multi-task learning architectures train a single model across\nmultiple tasks through a shared encoder followed by task-specific decoders.\nLearning these models often requires specialized training algorithms that\naddress task-conflict in the shared parameter updates, which otherwise can lead\nto negative transfer. A new type of multi-task learning within NLP homogenizes\nmulti-task architectures as a shared encoder and language model decoder, which\ndoes surprisingly well across a range of diverse tasks. Does this new\narchitecture suffer from task-conflicts that require specialized training\nalgorithms? We study how certain factors in the shift towards text-to-text\nmodels affects multi-task conflict and negative transfer, finding that both\ndirectional conflict and transfer are surprisingly constant across\narchitectures.", "published": "2022-12-13 15:28:57", "link": "http://arxiv.org/abs/2212.06645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Prompting: Scaling In-Context Learning to 1,000 Examples", "abstract": "Large language models have exhibited intriguing in-context learning\ncapability, achieving promising zero- and few-shot performance without updating\nthe parameters. However, conventional in-context learning is usually restricted\nby length constraints, rendering it ineffective to absorb supervision from a\nlarge number of examples. In order to go beyond few shots, we introduce\nstructured prompting that breaks the length limit and scales in-context\nlearning to thousands of examples. Specifically, demonstration examples are\nseparately encoded with well-designed position embeddings, and then they are\njointly attended by the test example using a rescaled attention mechanism. So\nwe can scale the number of exemplars with linear complexity instead of\nquadratic complexity with respect to length. Experimental results on a diverse\nset of tasks show that our approach improves end-task performance and reduces\nevaluation variance over conventional in-context learning as the number of\ndemonstration examples increases. Code has been released at\nhttps://aka.ms/structured-prompting.", "published": "2022-12-13 16:31:21", "link": "http://arxiv.org/abs/2212.06713v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diverse Demonstrations Improve In-context Compositional Generalization", "abstract": "In-context learning has shown great success in i.i.d semantic parsing splits,\nwhere the training and test sets are drawn from the same distribution. In this\nsetup, models are typically prompted with demonstrations that are similar to\nthe input utterance. However, in the setup of compositional generalization,\nwhere models are tested on outputs with structures that are absent from the\ntraining set, selecting similar demonstrations is insufficient, as often no\nexample will be similar enough to the input. In this work, we propose a method\nto select diverse demonstrations that aims to collectively cover all of the\nstructures required in the output program, in order to encourage the model to\ngeneralize to new structures from these demonstrations. We empirically show\nthat combining diverse demonstrations with in-context learning substantially\nimproves performance across three compositional generalization semantic parsing\ndatasets in the pure in-context learning setup and when combined with\nfinetuning.", "published": "2022-12-13 18:34:15", "link": "http://arxiv.org/abs/2212.06800v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Despite \"super-human\" performance, current LLMs are unsuited for\n  decisions about ethics and safety", "abstract": "Large language models (LLMs) have exploded in popularity in the past few\nyears and have achieved undeniably impressive results on benchmarks as varied\nas question answering and text summarization. We provide a simple new prompting\nstrategy that leads to yet another supposedly \"super-human\" result, this time\noutperforming humans at common sense ethical reasoning (as measured by accuracy\non a subset of the ETHICS dataset). Unfortunately, we find that relying on\naverage performance to judge capabilities can be highly misleading. LLM errors\ndiffer systematically from human errors in ways that make it easy to craft\nadversarial examples, or even perturb existing examples to flip the output\nlabel. We also observe signs of inverse scaling with model size on some\nexamples, and show that prompting models to \"explain their reasoning\" often\nleads to alarming justifications of unethical actions. Our results highlight\nhow human-like performance does not necessarily imply human-like understanding\nor reasoning.", "published": "2022-12-13 00:29:45", "link": "http://arxiv.org/abs/2212.06295v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InferEM: Inferring the Speaker's Intention for Empathetic Dialogue\n  Generation", "abstract": "Current approaches to empathetic response generation typically encode the\nentire dialogue history directly and put the output into a decoder to generate\nfriendly feedback. These methods focus on modelling contextual information but\nneglect capturing the direct intention of the speaker. We argue that the last\nutterance in the dialogue empirically conveys the intention of the speaker.\nConsequently, we propose a novel model named InferEM for empathetic response\ngeneration. We separately encode the last utterance and fuse it with the entire\ndialogue through the multi-head attention based intention fusion module to\ncapture the speaker's intention. Besides, we utilize previous utterances to\npredict the last utterance, which simulates human's psychology to guess what\nthe interlocutor may speak in advance. To balance the optimizing rates of the\nutterance prediction and response generation, a multi-task learning strategy is\ndesigned for InferEM. Experimental results demonstrate the plausibility and\nvalidity of InferEM in improving empathetic expression.", "published": "2022-12-13 05:12:40", "link": "http://arxiv.org/abs/2212.06373v7", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Lisan: Yemeni, Iraqi, Libyan, and Sudanese Arabic Dialect Copora with\n  Morphological Annotations", "abstract": "This article presents morphologically-annotated Yemeni, Sudanese, Iraqi, and\nLibyan Arabic dialects Lisan corpora. Lisan features around 1.2 million tokens.\nWe collected the content of the corpora from several social media platforms.\nThe Yemeni corpus (~ 1.05M tokens) was collected automatically from Twitter.\nThe corpora of the other three dialects (~ 50K tokens each) came manually from\nFacebook and YouTube posts and comments.\n  Thirty five (35) annotators who are native speakers of the target dialects\ncarried out the annotations. The annotators segemented all words in the four\ncorpora into prefixes, stems and suffixes and labeled each with different\nmorphological features such as part of speech, lemma, and a gloss in English.\nAn Arabic Dialect Annotation Toolkit ADAT was developped for the purpose of the\nannation. The annotators were trained on a set of guidelines and on how to use\nADAT. We developed ADAT to assist the annotators and to ensure compatibility\nwith SAMA and Curras tagsets. The tool is open source, and the four corpora are\nalso available online.", "published": "2022-12-13 10:37:10", "link": "http://arxiv.org/abs/2212.06468v2", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Exploring Fake News Detection with Heterogeneous Social Media Context\n  Graphs", "abstract": "Fake news detection has become a research area that goes way beyond a purely\nacademic interest as it has direct implications on our society as a whole.\nRecent advances have primarily focused on textbased approaches. However, it has\nbecome clear that to be effective one needs to incorporate additional,\ncontextual information such as spreading behaviour of news articles and user\ninteraction patterns on social media. We propose to construct heterogeneous\nsocial context graphs around news articles and reformulate the problem as a\ngraph classification task. Exploring the incorporation of different types of\ninformation (to get an idea as to what level of social context is most\neffective) and using different graph neural network architectures indicates\nthat this approach is highly effective with robust results on a common\nbenchmark dataset.", "published": "2022-12-13 13:29:47", "link": "http://arxiv.org/abs/2212.06560v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Categorical Tools for Natural Language Processing", "abstract": "This thesis develops the translation between category theory and\ncomputational linguistics as a foundation for natural language processing. The\nthree chapters deal with syntax, semantics and pragmatics. First, string\ndiagrams provide a unified model of syntactic structures in formal grammars.\nSecond, functors compute semantics by turning diagrams into logical, tensor,\nneural or quantum computation. Third, the resulting functorial models can be\ncomposed to form games where equilibria are the solutions of language\nprocessing tasks. This framework is implemented as part of DisCoPy, the Python\nlibrary for computing with string diagrams. We describe the correspondence\nbetween categorical, linguistic and computational structures, and demonstrate\ntheir applications in compositional natural language processing.", "published": "2022-12-13 15:12:37", "link": "http://arxiv.org/abs/2212.06636v1", "categories": ["cs.CL", "math.CT"], "primary_category": "cs.CL"}
{"title": "On Text-based Personality Computing: Challenges and Future Directions", "abstract": "Text-based personality computing (TPC) has gained many research interests in\nNLP. In this paper, we describe 15 challenges that we consider deserving the\nattention of the research community. These challenges are organized by the\nfollowing topics: personality taxonomies, measurement quality, datasets,\nperformance evaluation, modelling choices, as well as ethics and fairness. When\naddressing each challenge, not only do we combine perspectives from both NLP\nand social sciences, but also offer concrete suggestions. We hope to inspire\nmore valid and reliable TPC research.", "published": "2022-12-13 16:29:51", "link": "http://arxiv.org/abs/2212.06711v4", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A fine-grained comparison of pragmatic language understanding in humans\n  and language models", "abstract": "Pragmatics and non-literal language understanding are essential to human\ncommunication, and present a long-standing challenge for artificial language\nmodels. We perform a fine-grained comparison of language models and humans on\nseven pragmatic phenomena, using zero-shot prompting on an expert-curated set\nof English materials. We ask whether models (1) select pragmatic\ninterpretations of speaker utterances, (2) make similar error patterns as\nhumans, and (3) use similar linguistic cues as humans to solve the tasks. We\nfind that the largest models achieve high accuracy and match human error\npatterns: within incorrect responses, models favor literal interpretations over\nheuristic-based distractors. We also find preliminary evidence that models and\nhumans are sensitive to similar linguistic cues. Our results suggest that\npragmatic behaviors can emerge in models without explicitly constructed\nrepresentations of mental states. However, models tend to struggle with\nphenomena relying on social expectation violations.", "published": "2022-12-13 18:34:59", "link": "http://arxiv.org/abs/2212.06801v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CREPE: Can Vision-Language Foundation Models Reason Compositionally?", "abstract": "A fundamental characteristic common to both human vision and natural language\nis their compositional nature. Yet, despite the performance gains contributed\nby large vision and language pretraining, we find that: across 7 architectures\ntrained with 4 algorithms on massive datasets, they struggle at\ncompositionality. To arrive at this conclusion, we introduce a new\ncompositionality evaluation benchmark, CREPE, which measures two important\naspects of compositionality identified by cognitive science literature:\nsystematicity and productivity. To measure systematicity, CREPE consists of a\ntest dataset containing over $370K$ image-text pairs and three different\nseen-unseen splits. The three splits are designed to test models trained on\nthree popular training datasets: CC-12M, YFCC-15M, and LAION-400M. We also\ngenerate $325K$, $316K$, and $309K$ hard negative captions for a subset of the\npairs. To test productivity, CREPE contains $17K$ image-text pairs with nine\ndifferent complexities plus $183K$ hard negative captions with atomic, swapping\nand negation foils. The datasets are generated by repurposing the Visual Genome\nscene graphs and region descriptions and applying handcrafted templates and\nGPT-3. For systematicity, we find that model performance decreases consistently\nwhen novel compositions dominate the retrieval set, with Recall@1 dropping by\nup to $12\\%$. For productivity, models' retrieval success decays as complexity\nincreases, frequently nearing random chance at high complexity. These results\nhold regardless of model and training dataset size.", "published": "2022-12-13 19:17:36", "link": "http://arxiv.org/abs/2212.07796v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Attentive Deep Neural Networks for Legal Document Retrieval", "abstract": "Legal text retrieval serves as a key component in a wide range of legal text\nprocessing tasks such as legal question answering, legal case entailment, and\nstatute law retrieval. The performance of legal text retrieval depends, to a\nlarge extent, on the representation of text, both query and legal documents.\nBased on good representations, a legal text retrieval model can effectively\nmatch the query to its relevant documents. Because legal documents often\ncontain long articles and only some parts are relevant to queries, it is quite\na challenge for existing models to represent such documents. In this paper, we\nstudy the use of attentive neural network-based text representation for statute\nlaw document retrieval. We propose a general approach using deep neural\nnetworks with attention mechanisms. Based on it, we develop two hierarchical\narchitectures with sparse attention to represent long sentences and articles,\nand we name them Attentive CNN and Paraformer. The methods are evaluated on\ndatasets of different sizes and characteristics in English, Japanese, and\nVietnamese. Experimental results show that: i) Attentive neural methods\nsubstantially outperform non-neural methods in terms of retrieval performance\nacross datasets and languages; ii) Pretrained transformer-based models achieve\nbetter accuracy on small datasets at the cost of high computational complexity\nwhile lighter weight Attentive CNN achieves better accuracy on large datasets;\nand iii) Our proposed Paraformer outperforms state-of-the-art methods on COLIEE\ndataset, achieving the highest recall and F2 scores in the top-N retrieval\ntask.", "published": "2022-12-13 01:37:27", "link": "http://arxiv.org/abs/2212.13899v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Style-Label-Free: Cross-Speaker Style Transfer by Quantized VAE and\n  Speaker-wise Normalization in Speech Synthesis", "abstract": "Cross-speaker style transfer in speech synthesis aims at transferring a style\nfrom source speaker to synthesised speech of a target speaker's timbre. Most\nprevious approaches rely on data with style labels, but manually-annotated\nlabels are expensive and not always reliable. In response to this problem, we\npropose Style-Label-Free, a cross-speaker style transfer method, which can\nrealize the style transfer from source speaker to target speaker without style\nlabels. Firstly, a reference encoder structure based on quantized variational\nautoencoder (Q-VAE) and style bottleneck is designed to extract discrete style\nrepresentations. Secondly, a speaker-wise batch normalization layer is proposed\nto reduce the source speaker leakage. In order to improve the style extraction\nability of the reference encoder, a style invariant and contrastive data\naugmentation method is proposed. Experimental results show that the method\noutperforms the baseline. We provide a website with audio samples.", "published": "2022-12-13 06:26:25", "link": "http://arxiv.org/abs/2212.06397v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Stance Detection by Leveraging Measurement Knowledge from\n  Social Sciences: A Case Study of Dutch Political Tweets and Traditional\n  Gender Role Division", "abstract": "Stance detection (SD) concerns automatically determining the viewpoint (i.e.,\nin favour of, against, or neutral) of a text's author towards a target. SD has\nbeen applied to many research topics, among which the detection of stances\nbehind political tweets is an important one. In this paper, we apply SD to a\ndataset of tweets from official party accounts in the Netherlands between 2017\nand 2021, with a focus on stances towards traditional gender role division, a\ndividing issue between (some) Dutch political parties. To implement and improve\nSD of traditional gender role division, we propose to leverage an established\nsurvey instrument from social sciences, which has been validated for the\npurpose of measuring attitudes towards traditional gender role division. Based\non our experiments, we show that using such a validated survey instrument helps\nto improve SD performance.", "published": "2022-12-13 12:56:55", "link": "http://arxiv.org/abs/2212.06543v2", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Localized Latent Updates for Fine-Tuning Vision-Language Models", "abstract": "Although massive pre-trained vision-language models like CLIP show impressive\ngeneralization capabilities for many tasks, still it often remains necessary to\nfine-tune them for improved performance on specific datasets. When doing so, it\nis desirable that updating the model is fast and that the model does not lose\nits capabilities on data outside of the dataset, as is often the case with\nclassical fine-tuning approaches. In this work we suggest a lightweight\nadapter, that only updates the models predictions close to seen datapoints. We\ndemonstrate the effectiveness and speed of this relatively simple approach in\nthe context of few-shot learning, where our results both on classes seen and\nunseen during training are comparable with or improve on the state of the art.", "published": "2022-12-13 13:15:20", "link": "http://arxiv.org/abs/2212.06556v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Category Theory for Quantum Natural Language Processing", "abstract": "This thesis introduces quantum natural language processing (QNLP) models\nbased on a simple yet powerful analogy between computational linguistics and\nquantum mechanics: grammar as entanglement. The grammatical structure of text\nand sentences connects the meaning of words in the same way that entanglement\nstructure connects the states of quantum systems. Category theory allows to\nmake this language-to-qubit analogy formal: it is a monoidal functor from\ngrammar to vector spaces. We turn this abstract analogy into a concrete\nalgorithm that translates the grammatical structure onto the architecture of\nparameterised quantum circuits. We then use a hybrid classical-quantum\nalgorithm to train the model so that evaluating the circuits computes the\nmeaning of sentences in data-driven tasks.\n  The implementation of QNLP models motivated the development of DisCoPy\n(Distributional Compositional Python), the toolkit for applied category theory\nof which the first chapter gives a comprehensive overview. String diagrams are\nthe core data structure of DisCoPy, they allow to reason about computation at a\nhigh level of abstraction. We show how they can encode both grammatical\nstructures and quantum circuits, but also logical formulae, neural networks or\narbitrary Python code. Monoidal functors allow to translate these abstract\ndiagrams into concrete computation, interfacing with optimised task-specific\nlibraries.\n  The second chapter uses DisCopy to implement QNLP models as parameterised\nfunctors from grammar to quantum circuits. It gives a first proof-of-concept\nfor the more general concept of functorial learning: generalising machine\nlearning from functions to functors by learning from diagram-like data. In\norder to learn optimal functor parameters via gradient descent, we introduce\nthe notion of diagrammatic differentiation: a graphical calculus for computing\nthe gradients of parameterised diagrams.", "published": "2022-12-13 14:38:57", "link": "http://arxiv.org/abs/2212.06615v1", "categories": ["math.CT", "cs.CL", "quant-ph"], "primary_category": "math.CT"}
{"title": "ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for\n  Programming Languages", "abstract": "Software engineers working with the same programming language (PL) may speak\ndifferent natural languages (NLs) and vice versa, erecting huge barriers to\ncommunication and working efficiency. Recent studies have demonstrated the\neffectiveness of generative pre-training in computer programs, yet they are\nalways English-centric. In this work, we step towards bridging the gap between\nmultilingual NLs and multilingual PLs for large language models (LLMs). We\nrelease ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs.\nWe employ two methods for universal cross-lingual pre-training: span-corruption\nlanguage modeling that learns patterns from monolingual NL or PL; and\npivot-based translation language modeling that relies on parallel data of many\nNLs and PLs. Extensive results show that ERNIE-Code outperforms previous\nmultilingual LLMs for PL or NL across a wide range of end tasks of code\nintelligence, including multilingual code-to-text, text-to-code, code-to-code,\nand text-to-text generation. We further show its advantage of zero-shot\nprompting on multilingual code summarization and text-to-text translation. We\nrelease our code and pre-trained checkpoints.", "published": "2022-12-13 17:21:44", "link": "http://arxiv.org/abs/2212.06742v2", "categories": ["cs.CL", "cs.LG", "cs.PL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Deep Image Style Transfer from Freeform Text", "abstract": "This paper creates a novel method of deep neural style transfer by generating\nstyle images from freeform user text input. The language model and style\ntransfer model form a seamless pipeline that can create output images with\nsimilar losses and improved quality when compared to baseline style transfer\nmethods. The language model returns a closely matching image given a style text\nand description input, which is then passed to the style transfer model with an\ninput content image to create a final output. A proof-of-concept tool is also\ndeveloped to integrate the models and demonstrate the effectiveness of deep\nimage style transfer from freeform text.", "published": "2022-12-13 19:24:08", "link": "http://arxiv.org/abs/2212.06868v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Paraphrase Identification with Deep Learning: A Review of Datasets and\n  Methods", "abstract": "The rapid progress of Natural Language Processing (NLP) technologies has led\nto the widespread availability and effectiveness of text generation tools such\nas ChatGPT and Claude. While highly useful, these technologies also pose\nsignificant risks to the credibility of various media forms if they are\nemployed for paraphrased plagiarism -- one of the most subtle forms of content\nmisuse in scientific literature and general text media. Although automated\nmethods for paraphrase identification have been developed, detecting this type\nof plagiarism remains challenging due to the inconsistent nature of the\ndatasets used to train these methods. In this article, we examine traditional\nand contemporary approaches to paraphrase identification, investigating how the\nunder-representation of certain paraphrase types in popular datasets, including\nthose used to train Large Language Models (LLMs), affects the ability to detect\nplagiarism. We introduce and validate a new refined typology for paraphrases\n(ReParaphrased, REfined PARAPHRASE typology definitions) to better understand\nthe disparities in paraphrase type representation. Lastly, we propose new\ndirections for future research and dataset development to enhance AI-based\nparaphrase detection.", "published": "2022-12-13 23:06:20", "link": "http://arxiv.org/abs/2212.06933v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Foresight -- Generative Pretrained Transformer (GPT) for Modelling of\n  Patient Timelines using EHRs", "abstract": "Background: Electronic Health Records hold detailed longitudinal information\nabout each patient's health status and general clinical history, a large\nportion of which is stored within the unstructured text. Existing approaches\nfocus mostly on structured data and a subset of single-domain outcomes. We\nexplore how temporal modelling of patients from free text and structured data,\nusing deep generative transformers can be used to forecast a wide range of\nfuture disorders, substances, procedures or findings. Methods: We present\nForesight, a novel transformer-based pipeline that uses named entity\nrecognition and linking tools to convert document text into structured, coded\nconcepts, followed by providing probabilistic forecasts for future medical\nevents such as disorders, substances, procedures and findings. We processed the\nentire free-text portion from three different hospital datasets totalling\n811336 patients covering both physical and mental health. Findings: On tests in\ntwo UK hospitals (King's College Hospital, South London and Maudsley) and the\nUS MIMIC-III dataset precision@10 0.68, 0.76 and 0.88 was achieved for\nforecasting the next disorder in a patient timeline, while precision@10 of\n0.80, 0.81 and 0.91 was achieved for forecasting the next biomedical concept.\nForesight was also validated on 34 synthetic patient timelines by five\nclinicians and achieved relevancy of 97% for the top forecasted candidate\ndisorder. As a generative model, it can forecast follow-on biomedical concepts\nfor as many steps as required. Interpretation: Foresight is a general-purpose\nmodel for biomedical concept modelling that can be used for real-world risk\nforecasting, virtual trials and clinical research to study the progression of\ndisorders, simulate interventions and counterfactuals, and educational\npurposes.", "published": "2022-12-13 19:06:00", "link": "http://arxiv.org/abs/2212.08072v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RT-1: Robotics Transformer for Real-World Control at Scale", "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern\nmachine learning models can solve specific downstream tasks either zero-shot or\nwith small task-specific datasets to a high level of performance. While this\ncapability has been demonstrated in other fields such as computer vision,\nnatural language processing or speech recognition, it remains to be shown in\nrobotics, where the generalization capabilities of the models are particularly\ncritical due to the difficulty of collecting real-world robotic data. We argue\nthat one of the keys to the success of such general robotic models lies with\nopen-ended task-agnostic training, combined with high-capacity architectures\nthat can absorb all of the diverse, robotic data. In this paper, we present a\nmodel class, dubbed Robotics Transformer, that exhibits promising scalable\nmodel properties. We verify our conclusions in a study of different model\nclasses and their ability to generalize as a function of the data size, model\nsize, and data diversity based on a large-scale data collection on real robots\nperforming real-world tasks. The project's website and videos can be found at\nrobotics-transformer1.github.io", "published": "2022-12-13 18:55:15", "link": "http://arxiv.org/abs/2212.06817v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Towards trustworthy phoneme boundary detection with autoregressive model\n  and improved evaluation metric", "abstract": "Phoneme boundary detection has been studied due to its central role in\nvarious speech applications. In this work, we point out that this task needs to\nbe addressed not only by algorithmic way, but also by evaluation metric. To\nthis end, we first propose a state-of-the-art phoneme boundary detector that\noperates in an autoregressive manner, dubbed SuperSeg. Experiments on the TIMIT\nand Buckeye corpora demonstrates that SuperSeg identifies phoneme boundaries\nwith significant margin compared to existing models. Furthermore, we note that\nthere is a limitation on the popular evaluation metric, R-value, and propose\nnew evaluation metrics that prevent each boundary from contributing to\nevaluation multiple times. The proposed metrics reveal the weaknesses of\nnon-autoregressive baselines and establishes a reliable criterion that suits\nfor evaluating phoneme boundary detection.", "published": "2022-12-13 05:56:57", "link": "http://arxiv.org/abs/2212.06387v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards deep generation of guided wave representations for composite\n  materials", "abstract": "Laminated composite materials are widely used in most fields of engineering.\nWave propagation analysis plays an essential role in understanding the\nshort-duration transient response of composite structures. The forward\nphysics-based models are utilized to map from elastic properties space to wave\npropagation behavior in a laminated composite material. Due to the\nhigh-frequency, multi-modal, and dispersive nature of the guided waves, the\nphysics-based simulations are computationally demanding. It makes property\nprediction, generation, and material design problems more challenging. In this\nwork, a forward physics-based simulator such as the stiffness matrix method is\nutilized to collect group velocities of guided waves for a set of composite\nmaterials. A variational autoencoder (VAE)-based deep generative model is\nproposed for the generation of new and realistic polar group velocity\nrepresentations. It is observed that the deep generator is able to reconstruct\nunseen representations with very low mean square reconstruction error. Global\nMonte Carlo and directional equally-spaced samplers are used to sample the\ncontinuous, complete and organized low-dimensional latent space of VAE. The\nsampled point is fed into the trained decoder to generate new polar\nrepresentations. The network has shown exceptional generation capabilities. It\nis also seen that the latent space forms a conceptual space where different\ndirections and regions show inherent patterns related to the generated\nrepresentations and their corresponding material properties.", "published": "2022-12-13 04:35:36", "link": "http://arxiv.org/abs/2212.06365v1", "categories": ["eess.SP", "eess.AS", "eess.IV"], "primary_category": "eess.SP"}
