{"title": "Cross-domain Semantic Parsing via Paraphrasing", "abstract": "Existing studies on semantic parsing mainly focus on the in-domain setting.\nWe formulate cross-domain semantic parsing as a domain adaptation problem:\ntrain a semantic parser on some source domains and then adapt it to the target\ndomain. Due to the diversity of logical forms in different domains, this\nproblem presents unique and intriguing challenges. By converting logical forms\ninto canonical utterances in natural language, we reduce semantic parsing to\nparaphrasing, and develop an attentive sequence-to-sequence paraphrase model\nthat is general and flexible to adapt to different domains. We discover two\nproblems, small micro variance and large macro variance, of pre-trained word\nembeddings that hinder their direct use in neural networks, and propose\nstandardization techniques as a remedy. On the popular Overnight dataset, which\ncontains eight domains, we show that both cross-domain training and\nstandardized pre-trained word embeddings can bring significant improvement.", "published": "2017-04-20 01:26:23", "link": "http://arxiv.org/abs/1704.05974v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural End-to-End Learning for Computational Argumentation Mining", "abstract": "We investigate neural techniques for end-to-end computational argumentation\nmining (AM). We frame AM both as a token-based dependency parsing and as a\ntoken-based sequence tagging problem, including a multi-task learning setup.\nContrary to models that operate on the argument component level, we find that\nframing AM as dependency parsing leads to subpar performance results. In\ncontrast, less complex (local) tagging models based on BiLSTMs perform robustly\nacross classification scenarios, being able to catch long-range dependencies\ninherent to the AM problem. Moreover, we find that jointly learning 'natural'\nsubtasks, in a multi-task learning setup, improves performance.", "published": "2017-04-20 12:20:43", "link": "http://arxiv.org/abs/1704.06104v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning with External Knowledge and Two-Stage Q-functions\n  for Predicting Popular Reddit Threads", "abstract": "This paper addresses the problem of predicting popularity of comments in an\nonline discussion forum using reinforcement learning, particularly addressing\ntwo challenges that arise from having natural language state and action spaces.\nFirst, the state representation, which characterizes the history of comments\ntracked in a discussion at a particular point, is augmented to incorporate the\nglobal context represented by discussions on world events available in an\nexternal knowledge source. Second, a two-stage Q-learning framework is\nintroduced, making it feasible to search the combinatorial action space while\nalso accounting for redundancy among sub-actions. We experiment with five\nReddit communities, showing that the two methods improve over previous reported\nresults on this task.", "published": "2017-04-20 16:30:39", "link": "http://arxiv.org/abs/1704.06217v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SwellShark: A Generative Model for Biomedical Named Entity Recognition\n  without Labeled Data", "abstract": "We present SwellShark, a framework for building biomedical named entity\nrecognition (NER) systems quickly and without hand-labeled data. Our approach\nviews biomedical resources like lexicons as function primitives for\nautogenerating weak supervision. We then use a generative model to unify and\ndenoise this supervision and construct large-scale, probabilistically labeled\ndatasets for training high-accuracy NER taggers. In three biomedical NER tasks,\nSwellShark achieves competitive scores with state-of-the-art supervised\nbenchmarks using no hand-labeled training data. In a drug name extraction task\nusing patient medical records, one domain expert using SwellShark achieved\nwithin 5.1% of a crowdsourced annotation approach -- which originally utilized\n20 teams over the course of several weeks -- in 24 hours.", "published": "2017-04-20 23:02:14", "link": "http://arxiv.org/abs/1704.06360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support\n  for rumours", "abstract": "Media is full of false claims. Even Oxford Dictionaries named \"post-truth\" as\nthe word of 2016. This makes it more important than ever to build systems that\ncan identify the veracity of a story, and the kind of discourse there is around\nit. RumourEval is a SemEval shared task that aims to identify and handle\nrumours and reactions to them, in text. We present an annotation scheme, a\nlarge dataset covering multiple topics - each having their own families of\nclaims and replies - and use these to pose two concrete challenges as well as\nthe results achieved by participants on these challenges.", "published": "2017-04-20 01:21:20", "link": "http://arxiv.org/abs/1704.05972v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Call Attention to Rumors: Deep Attention Based Recurrent Neural Networks\n  for Early Rumor Detection", "abstract": "The proliferation of social media in communication and information\ndissemination has made it an ideal platform for spreading rumors. Automatically\ndebunking rumors at their stage of diffusion is known as \\textit{early rumor\ndetection}, which refers to dealing with sequential posts regarding disputed\nfactual claims with certain variations and highly textual duplication over\ntime. Thus, identifying trending rumors demands an efficient yet flexible model\nthat is able to capture long-range dependencies among postings and produce\ndistinct representations for the accurate early detection. However, it is a\nchallenging task to apply conventional classification algorithms to rumor\ndetection in earliness since they rely on hand-crafted features which require\nintensive manual efforts in the case of large amount of posts. This paper\npresents a deep attention model on the basis of recurrent neural networks (RNN)\nto learn \\textit{selectively} temporal hidden representations of sequential\nposts for identifying rumors. The proposed model delves soft-attention into the\nrecurrence to simultaneously pool out distinct features with particular focus\nand produce hidden representations that capture contextual variations of\nrelevant posts over time. Extensive experiments on real datasets collected from\nsocial media websites demonstrate that (1) the deep attention based RNN model\noutperforms state-of-the-arts that rely on hand-crafted features; (2) the\nintroduction of soft attention mechanism can effectively distill relevant parts\nto rumors from original posts in advance; (3) the proposed method detects\nrumors more quickly and accurately than competitors.", "published": "2017-04-20 01:22:57", "link": "http://arxiv.org/abs/1704.05973v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and\n  LSTMs", "abstract": "In this paper we describe our attempt at producing a state-of-the-art Twitter\nsentiment classifier using Convolutional Neural Networks (CNNs) and Long Short\nTerm Memory (LSTMs) networks. Our system leverages a large amount of unlabeled\ndata to pre-train word embeddings. We then use a subset of the unlabeled data\nto fine tune the embeddings using distant supervision. The final CNNs and LSTMs\nare trained on the SemEval-2017 Twitter dataset where the embeddings are fined\ntuned again. To boost performances we ensemble several CNNs and LSTMs together.\nOur approach achieved first rank on all of the five English subtasks amongst 40\nteams.", "published": "2017-04-20 13:10:25", "link": "http://arxiv.org/abs/1704.06125v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Stability and Fluctuations in a Simple Model of Phonetic Category Change", "abstract": "In spoken languages, speakers divide up the space of phonetic possibilities\ninto different regions, corresponding to different phonemes. We consider a\nsimple exemplar model of how this division of phonetic space varies over time\namong a population of language users. In the particular model we consider, we\nshow that, once the system is initialized with a given set of phonemes, that\nphonemes do not become extinct: all phonemes will be maintained in the system\nfor all time. This is in contrast to what is observed in more complex models.\nFurthermore, we show that the boundaries between phonemes fluctuate and we\nquantitatively study the fluctuations in a simple instance of our model. These\nresults prepare the ground for more sophisticated models in which some phonemes\ngo extinct or new phonemes emerge through other processes.", "published": "2017-04-20 22:28:14", "link": "http://arxiv.org/abs/1704.06358v3", "categories": ["cs.CL", "math.DS", "91F20, 94A99, 60GNN"], "primary_category": "cs.CL"}
{"title": "Improved Neural Relation Detection for Knowledge Base Question Answering", "abstract": "Relation detection is a core component for many NLP applications including\nKnowledge Base Question Answering (KBQA). In this paper, we propose a\nhierarchical recurrent neural network enhanced by residual learning that\ndetects KB relations given an input question. Our method uses deep residual\nbidirectional LSTMs to compare questions and relation names via different\nhierarchies of abstraction. Additionally, we propose a simple KBQA system that\nintegrates entity linking and our proposed relation detector to enable one\nenhance another. Experimental results evidence that our approach achieves not\nonly outstanding relation detection performance, but more importantly, it helps\nour KBQA system to achieve state-of-the-art accuracy for both single-relation\n(SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.", "published": "2017-04-20 15:48:05", "link": "http://arxiv.org/abs/1704.06194v2", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Adversarial Neural Machine Translation", "abstract": "In this paper, we study a new learning paradigm for Neural Machine\nTranslation (NMT). Instead of maximizing the likelihood of the human\ntranslation as in previous works, we minimize the distinction between human\ntranslation and the translation given by an NMT model. To achieve this goal,\ninspired by the recent success of generative adversarial networks (GANs), we\nemploy an adversarial training architecture and name it as Adversarial-NMT. In\nAdversarial-NMT, the training of the NMT model is assisted by an adversary,\nwhich is an elaborately designed Convolutional Neural Network (CNN). The goal\nof the adversary is to differentiate the translation result generated by the\nNMT model from that by human. The goal of the NMT model is to produce high\nquality translations so as to cheat the adversary. A policy gradient method is\nleveraged to co-train the NMT model and the adversary. Experimental results on\nEnglish$\\rightarrow$French and German$\\rightarrow$English translation tasks\nshow that Adversarial-NMT can achieve significantly better translation quality\nthan several strong baselines.", "published": "2017-04-20 05:08:47", "link": "http://arxiv.org/abs/1704.06933v4", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Audio-based performance evaluation of squash players", "abstract": "In competitive sports it is often very hard to quantify the performance. A\nplayer to score or overtake may depend on only millesimal of seconds or\nmillimeters. In racquet sports like tennis, table tennis and squash many events\nwill occur in a short time duration, whose recording and analysis can help\nreveal the differences in performance. In this paper we show that it is\npossible to architect a framework that utilizes the characteristic sound\npatterns to precisely classify the types of and localize the positions of these\nevents. From these basic information the shot types and the ball speed along\nthe trajectories can be estimated. Comparing these estimates with the optimal\nspeed and target the precision of the shot can be defined. The detailed shot\nstatistics and precision information significantly enriches and improves data\navailable today. Feeding them back to the players and the coaches facilitates\nto describe playing performance objectively and to improve strategy skills. The\nframework is implemented, its hardware and software components are installed\nand tested in a squash court.", "published": "2017-04-20 07:16:44", "link": "http://arxiv.org/abs/1704.08765v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
