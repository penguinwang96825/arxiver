{"title": "Open Domain Suggestion Mining: Problem Definition and Datasets", "abstract": "We propose a formal definition for the task of suggestion mining in the\ncontext of a wide range of open domain applications. Human perception of the\nterm \\emph{suggestion} is subjective and this effects the preparation of hand\nlabeled datasets for the task of suggestion mining. Existing work either lacks\na formal problem definition and annotation procedure, or provides domain and\napplication specific definitions. Moreover, many previously used manually\nlabeled datasets remain proprietary. We first present an annotation study, and\nbased on our observations propose a formal task definition and annotation\nprocedure for creating benchmark datasets for suggestion mining. With this\nstudy, we also provide publicly available labeled datasets for suggestion\nmining in multiple domains.", "published": "2018-06-06 13:38:57", "link": "http://arxiv.org/abs/1806.02179v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Limitations of Cross-language Word Embeddings Evaluation", "abstract": "The aim of this work is to explore the possible limitations of existing\nmethods of cross-language word embeddings evaluation, addressing the lack of\ncorrelation between intrinsic and extrinsic cross-language evaluation methods.\nTo prove this hypothesis, we construct English-Russian datasets for extrinsic\nand intrinsic evaluation tasks and compare performances of 5 different\ncross-language models on them. The results say that the scores even on\ndifferent intrinsic benchmarks do not correlate to each other. We can conclude\nthat the use of human references as ground truth for cross-language word\nembeddings is not proper unless one does not understand how do native speakers\nprocess semantics in their cognition.", "published": "2018-06-06 15:42:22", "link": "http://arxiv.org/abs/1806.02253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Convincing Arguments Using Scalable Bayesian Preference Learning", "abstract": "We introduce a scalable Bayesian preference learning method for identifying\nconvincing arguments in the absence of gold-standard rat- ings or rankings. In\ncontrast to previous work, we avoid the need for separate methods to perform\nquality control on training data, predict rankings and perform pairwise\nclassification. Bayesian approaches are an effective solution when faced with\nsparse or noisy training data, but have not previously been used to identify\nconvincing arguments. One issue is scalability, which we address by developing\na stochastic variational inference method for Gaussian process (GP) preference\nlearning. We show how our method can be applied to predict argument\nconvincingness from crowdsourced data, outperforming the previous\nstate-of-the-art, particularly when trained with small amounts of unreliable\ndata. We demonstrate how the Bayesian approach enables more effective active\nlearning, thereby reducing the amount of data required to identify convincing\narguments for new users and domains. While word embeddings are principally used\nwith neural networks, our results show that word embeddings in combination with\nlinguistic features also benefit GPs when predicting argument convincingness.", "published": "2018-06-06 20:47:47", "link": "http://arxiv.org/abs/1806.02418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Studying the Difference Between Natural and Programming Language Corpora", "abstract": "Code corpora, as observed in large software systems, are now known to be far\nmore repetitive and predictable than natural language corpora. But why? Does\nthe difference simply arise from the syntactic limitations of programming\nlanguages? Or does it arise from the differences in authoring decisions made by\nthe writers of these natural and programming language texts? We conjecture that\nthe differences are not entirely due to syntax, but also from the fact that\nreading and writing code is un-natural for humans, and requires substantial\nmental effort; so, people prefer to write code in ways that are familiar to\nboth reader and writer. To support this argument, we present results from two\nsets of studies: 1) a first set aimed at attenuating the effects of syntax, and\n2) a second, aimed at measuring repetitiveness of text written in other\nsettings (e.g. second language, technical/specialized jargon), which are also\neffortful to write. We find find that this repetition in source code is not\nentirely the result of grammar constraints, and thus some repetition must\nresult from human choice. While the evidence we find of similar repetitive\nbehavior in technical and learner corpora does not conclusively show that such\nlanguage is used by humans to mitigate difficulty, it is consistent with that\ntheory.", "published": "2018-06-06 22:00:32", "link": "http://arxiv.org/abs/1806.02437v1", "categories": ["cs.CL", "68N15, 68T50"], "primary_category": "cs.CL"}
{"title": "Medical Concept Embedding with Time-Aware Attention", "abstract": "Embeddings of medical concepts such as medication, procedure and diagnosis\ncodes in Electronic Medical Records (EMRs) are central to healthcare analytics.\nPrevious work on medical concept embedding takes medical concepts and EMRs as\nwords and documents respectively. Nevertheless, such models miss out the\ntemporal nature of EMR data. On the one hand, two consecutive medical concepts\ndo not indicate they are temporally close, but the correlations between them\ncan be revealed by the time gap. On the other hand, the temporal scopes of\nmedical concepts often vary greatly (e.g., \\textit{common cold} and\n\\textit{diabetes}). In this paper, we propose to incorporate the temporal\ninformation to embed medical codes. Based on the Continuous Bag-of-Words model,\nwe employ the attention mechanism to learn a \"soft\" time-aware context window\nfor each medical concept. Experiments on public and proprietary datasets\nthrough clustering and nearest neighbour search tasks demonstrate the\neffectiveness of our model, showing that it outperforms five state-of-the-art\nbaselines.", "published": "2018-06-06 07:45:06", "link": "http://arxiv.org/abs/1806.02873v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StarGAN-VC: Non-parallel many-to-many voice conversion with star\n  generative adversarial networks", "abstract": "This paper proposes a method that allows non-parallel many-to-many voice\nconversion (VC) by using a variant of a generative adversarial network (GAN)\ncalled StarGAN. Our method, which we call StarGAN-VC, is noteworthy in that it\n(1) requires no parallel utterances, transcriptions, or time alignment\nprocedures for speech generator training, (2) simultaneously learns\nmany-to-many mappings across different attribute domains using a single\ngenerator network, (3) is able to generate converted speech signals quickly\nenough to allow real-time implementations and (4) requires only several minutes\nof training examples to generate reasonably realistic-sounding speech.\nSubjective evaluation experiments on a non-parallel many-to-many speaker\nidentity conversion task revealed that the proposed method obtained higher\nsound quality and speaker similarity than a state-of-the-art method based on\nvariational autoencoding GANs.", "published": "2018-06-06 13:24:23", "link": "http://arxiv.org/abs/1806.02169v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
