{"title": "Analyzing Gender Representation in Multilingual Models", "abstract": "Multilingual language models were shown to allow for nontrivial transfer\nacross scripts and languages. In this work, we study the structure of the\ninternal representations that enable this transfer. We focus on the\nrepresentation of gender distinctions as a practical case study, and examine\nthe extent to which the gender concept is encoded in shared subspaces across\ndifferent languages. Our analysis shows that gender representations consist of\nseveral prominent components that are shared across languages, alongside\nlanguage-specific components. The existence of language-independent and\nlanguage-specific components provides an explanation for an intriguing\nempirical observation we make: while gender classification transfers well\nacross languages, interventions for gender removal, trained on a single\nlanguage, do not transfer easily to others.", "published": "2022-04-20 00:13:01", "link": "http://arxiv.org/abs/2204.09168v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Semantics and Inference System for Temporal Order based on\n  Japanese CCG", "abstract": "Natural Language Inference (NLI) is the task of determining whether a premise\nentails a hypothesis. NLI with temporal order is a challenging task because\ntense and aspect are complex linguistic phenomena involving interactions with\ntemporal adverbs and temporal connectives. To tackle this, temporal and\naspectual inference has been analyzed in various ways in the field of formal\nsemantics. However, a Japanese NLI system for temporal order based on the\nanalysis of formal semantics has not been sufficiently developed. We present a\nlogic-based NLI system that considers temporal order in Japanese based on\ncompositional semantics via Combinatory Categorial Grammar (CCG) syntactic\nanalysis. Our system performs inference involving temporal order by using\naxioms for temporal relations and automated theorem provers. We evaluate our\nsystem by experimenting with Japanese NLI datasets that involve temporal order.\nWe show that our system outperforms previous logic-based systems as well as\ncurrent deep learning-based models.", "published": "2022-04-20 06:21:21", "link": "http://arxiv.org/abs/2204.09245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Arabic Sentence Simplification via Classification and Generative\n  Approaches", "abstract": "This paper presents an attempt to build a Modern Standard Arabic (MSA)\nsentence-level simplification system. We experimented with sentence\nsimplification using two approaches: (i) a classification approach leading to\nlexical simplification pipelines which use Arabic-BERT, a pre-trained\ncontextualised model, as well as a model of fastText word embeddings; and (ii)\na generative approach, a Seq2Seq technique by applying a multilingual\nText-to-Text Transfer Transformer mT5. We developed our training corpus by\naligning the original and simplified sentences from the internationally\nacclaimed Arabic novel \"Saaq al-Bambuu\". We evaluate effectiveness of these\nmethods by comparing the generated simple sentences to the target simple\nsentences using the BERTScore evaluation metric. The simple sentences produced\nby the mT5 model achieve P 0.72, R 0.68 and F-1 0.70 via BERTScore, while,\ncombining Arabic-BERT and fastText achieves P 0.97, R 0.97 and F-1 0.97. In\naddition, we report a manual error analysis for these experiments.\n\\url{https://github.com/Nouran-Khallaf/Lexical_Simplification}", "published": "2022-04-20 08:17:33", "link": "http://arxiv.org/abs/2204.09292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Active Few-Shot Learning with FASL", "abstract": "Recent advances in natural language processing (NLP) have led to strong text\nclassification models for many tasks. However, still often thousands of\nexamples are needed to train models with good quality. This makes it\nchallenging to quickly develop and deploy new models for real world problems\nand business needs. Few-shot learning and active learning are two lines of\nresearch, aimed at tackling this problem. In this work, we combine both lines\ninto FASL, a platform that allows training text classification models using an\niterative and fast process. We investigate which active learning methods work\nbest in our few-shot setup. Additionally, we develop a model to predict when to\nstop annotating. This is relevant as in a few-shot setup we do not have access\nto a large validation set.", "published": "2022-04-20 09:32:56", "link": "http://arxiv.org/abs/2204.09347v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative or Contrastive? Phrase Reconstruction for Better Sentence\n  Representation Learning", "abstract": "Though offering amazing contextualized token-level representations, current\npre-trained language models actually take less attention on acquiring\nsentence-level representation during its self-supervised pre-training. If\nself-supervised learning can be distinguished into two subcategories,\ngenerative and contrastive, then most existing studies show that sentence\nrepresentation learning may more benefit from the contrastive methods but not\nthe generative methods. However, contrastive learning cannot be well compatible\nwith the common token-level generative self-supervised learning, and does not\nguarantee good performance on downstream semantic retrieval tasks. Thus, to\nalleviate such obvious inconveniences, we instead propose a novel generative\nself-supervised learning objective based on phrase reconstruction. Empirical\nstudies show that our generative learning may yield powerful enough sentence\nrepresentation and achieve performance in Sentence Textual Similarity (STS)\ntasks on par with contrastive learning. Further, in terms of unsupervised\nsetting, our generative method outperforms previous state-of-the-art SimCSE on\nthe benchmark of downstream semantic retrieval tasks.", "published": "2022-04-20 10:00:46", "link": "http://arxiv.org/abs/2204.09358v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing the Intensity of Complaints on Social Media", "abstract": "Complaining is a speech act that expresses a negative inconsistency between\nreality and human expectations. While prior studies mostly focus on identifying\nthe existence or the type of complaints, in this work, we present the first\nstudy in computational linguistics of measuring the intensity of complaints\nfrom text. Analyzing complaints from such perspective is particularly useful,\nas complaints of certain degrees may cause severe consequences for companies or\norganizations. We create the first Chinese dataset containing 3,103 posts about\ncomplaints from Weibo, a popular Chinese social media platform. These posts are\nthen annotated with complaints intensity scores using Best-Worst Scaling (BWS)\nmethod. We show that complaints intensity can be accurately estimated by\ncomputational models with the best mean square error achieving 0.11.\nFurthermore, we conduct a comprehensive linguistic analysis around complaints,\nincluding the connections between complaints and sentiment, and a cross-lingual\ncomparison for complaints expressions used by Chinese and English speakers. We\nfinally show that our complaints intensity scores can be incorporated for\nbetter estimating the popularity of posts on social media.", "published": "2022-04-20 10:15:44", "link": "http://arxiv.org/abs/2204.09366v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in\n  Text Classification", "abstract": "Incorrect labels in training data occur when human annotators make mistakes\nor when the data is generated via weak or distant supervision. It has been\nshown that complex noise-handling techniques - by modeling, cleaning or\nfiltering the noisy instances - are required to prevent models from fitting\nthis label noise. However, we show in this work that, for text classification\ntasks with modern NLP models like BERT, over a variety of noise types, existing\nnoisehandling methods do not always improve its performance, and may even\ndeteriorate it, suggesting the need for further investigation. We also back our\nobservations with a comprehensive analysis.", "published": "2022-04-20 10:24:19", "link": "http://arxiv.org/abs/2204.09371v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Are What You Write: Preserving Privacy in the Era of Large Language\n  Models", "abstract": "Large scale adoption of large language models has introduced a new era of\nconvenient knowledge transfer for a slew of natural language processing tasks.\nHowever, these models also run the risk of undermining user trust by exposing\nunwanted information about the data subjects, which may be extracted by a\nmalicious party, e.g. through adversarial attacks. We present an empirical\ninvestigation into the extent of the personal information encoded into\npre-trained representations by a range of popular models, and we show a\npositive correlation between the complexity of a model, the amount of data used\nin pre-training, and data leakage. In this paper, we present the first wide\ncoverage evaluation and comparison of some of the most popular\nprivacy-preserving algorithms, on a large, multi-lingual dataset on sentiment\nanalysis annotated with demographic information (location, age and gender). The\nresults show since larger and more complex models are more prone to leaking\nprivate information, use of privacy-preserving methods is highly desirable. We\nalso find that highly privacy-preserving technologies like differential privacy\n(DP) can have serious model utility effects, which can be ameliorated using\nhybrid or metric-DP techniques.", "published": "2022-04-20 11:12:53", "link": "http://arxiv.org/abs/2204.09391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus for Understanding and Generating Moral Stories", "abstract": "Teaching morals is one of the most important purposes of storytelling. An\nessential ability for understanding and writing moral stories is bridging story\nplots and implied morals. Its challenges mainly lie in: (1) grasping knowledge\nabout abstract concepts in morals, (2) capturing inter-event discourse\nrelations in stories, and (3) aligning value preferences of stories and morals\nconcerning good or bad behavior. In this paper, we propose two understanding\ntasks and two generation tasks to assess these abilities of machines. We\npresent STORAL, a new dataset of Chinese and English human-written moral\nstories. We show the difficulty of the proposed tasks by testing various models\nwith automatic and manual evaluation on STORAL. Furthermore, we present a\nretrieval-augmented algorithm that effectively exploits related concepts or\nevents in training sets as additional guidance to improve performance on these\ntasks.", "published": "2022-04-20 13:12:36", "link": "http://arxiv.org/abs/2204.09438v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Transition Planning for Open-ended Text Generation", "abstract": "Open-ended text generation tasks, such as dialogue generation and story\ncompletion, require models to generate a coherent continuation given limited\npreceding context. The open-ended nature of these tasks brings new challenges\nto the neural auto-regressive text generators nowadays. Despite these neural\nmodels are good at producing human-like text, it is difficult for them to\narrange causalities and relations between given facts and possible ensuing\nevents. To bridge this gap, we propose a novel two-stage method which\nexplicitly arranges the ensuing events in open-ended text generation. Our\napproach can be understood as a specially-trained coarse-to-fine algorithm,\nwhere an event transition planner provides a \"coarse\" plot skeleton and a text\ngenerator in the second stage refines the skeleton. Experiments on two\nopen-ended text generation tasks demonstrate that our proposed method\neffectively improves the quality of the generated text, especially in coherence\nand diversity. The code is available at:\n\\url{https://github.com/qtli/EventPlanforTextGen}.", "published": "2022-04-20 13:37:51", "link": "http://arxiv.org/abs/2204.09453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Neural Abstractive Summarization Methods and Factual\n  Consistency of Summarization", "abstract": "Automatic summarization is the process of shortening a set of textual data\ncomputationally, to create a subset (a summary) that represents the most\nimportant pieces of information in the original text. Existing summarization\nmethods can be roughly divided into two types: extractive and abstractive. An\nextractive summarizer explicitly selects text snippets (words, phrases,\nsentences, etc.) from the source document, while an abstractive summarizer\ngenerates novel text snippets to convey the most salient concepts prevalent in\nthe source.", "published": "2022-04-20 14:56:36", "link": "http://arxiv.org/abs/2204.09519v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "yosm: A new yoruba sentiment corpus for movie reviews", "abstract": "A movie that is thoroughly enjoyed and recommended by an individual might be\nhated by another. One characteristic of humans is the ability to have feelings\nwhich could be positive or negative. To automatically classify and study human\nfeelings, an aspect of natural language processing, sentiment analysis and\nopinion mining were designed to understand human feelings regarding several\nissues which could affect a product, a social media platforms, government, or\nsocietal discussions or even movies. Several works on sentiment analysis have\nbeen done on high resource languages while low resources languages like Yoruba\nhave been sidelined. Due to the scarcity of datasets and linguistic\narchitectures that will suit low resource languages, African languages \"low\nresource languages\" have been ignored and not fully explored. For this reason,\nour attention is placed on Yoruba to explore sentiment analysis on reviews of\nNigerian movies. The data comprised 1500 movie reviews that were sourced from\nIMDB, Rotten Tomatoes, Letterboxd, Cinemapointer and Nollyrated. We develop\nsentiment classification models using the state-of-the-art pre-trained language\nmodels like mBERT and AfriBERTa to classify the movie reviews.", "published": "2022-04-20 18:00:37", "link": "http://arxiv.org/abs/2204.09711v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Res-CNN-BiLSTM Network for overcoming Mental Health Disturbances caused\n  due to Cyberbullying through Social Media", "abstract": "Mental Health Disturbance has many reasons and cyberbullying is one of the\nmajor causes that does exploitation using social media as an instrument. The\ncyberbullying is done on the basis of Religion, Ethnicity, Age and Gender which\nis a sensitive psychological issue. This can be addressed using Natural\nLanguage Processing with Deep Learning, since social media is the medium and it\ngenerates massive form of data in textual form. Such data can be leveraged to\nfind the semantics and derive what type of cyberbullying is done and who are\nthe people involved for early measures. Since deriving semantics is essential\nwe proposed a Hybrid Deep Learning Model named 1-Dimensional\nCNN-Bidirectional-LSTMs with Residuals shortly known as Res-CNN-BiLSTM. In this\npaper we have proposed the architecture and compared its performance with\ndifferent approaches of Embedding Deep Learning Algorithms.", "published": "2022-04-20 18:40:39", "link": "http://arxiv.org/abs/2204.09738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Representation Collapse of Sparse Mixture of Experts", "abstract": "Sparse mixture of experts provides larger model capacity while requiring a\nconstant computational overhead. It employs the routing mechanism to distribute\ninput tokens to the best-matched experts according to their hidden\nrepresentations. However, learning such a routing mechanism encourages token\nclustering around expert centroids, implying a trend toward representation\ncollapse. In this work, we propose to estimate the routing scores between\ntokens and experts on a low-dimensional hypersphere. We conduct extensive\nexperiments on cross-lingual language model pre-training and fine-tuning on\ndownstream tasks. Experimental results across seven multilingual benchmarks\nshow that our method achieves consistent gains. We also present a comprehensive\nanalysis on the representation and routing behaviors of our models. Our method\nalleviates the representation collapse issue and achieves more consistent\nrouting than the baseline mixture-of-experts methods.", "published": "2022-04-20 01:40:19", "link": "http://arxiv.org/abs/2204.09179v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Who Is Missing? Characterizing the Participation of Different\n  Demographic Groups in a Korean Nationwide Daily Conversation Corpus", "abstract": "A conversation corpus is essential to build interactive AI applications.\nHowever, the demographic information of the participants in such corpora is\nlargely underexplored mainly due to the lack of individual data in many\ncorpora. In this work, we analyze a Korean nationwide daily conversation corpus\nconstructed by the National Institute of Korean Language (NIKL) to characterize\nthe participation of different demographic (age and sex) groups in the corpus.", "published": "2022-04-20 03:32:37", "link": "http://arxiv.org/abs/2204.09209v1", "categories": ["cs.CL", "cs.LG", "I.2"], "primary_category": "cs.CL"}
{"title": "LingYi: Medical Conversational Question Answering System based on\n  Multi-modal Knowledge Graphs", "abstract": "The medical conversational system can relieve the burden of doctors and\nimprove the efficiency of healthcare, especially during the pandemic. This\npaper presents a medical conversational question answering (CQA) system based\non the multi-modal knowledge graph, namely \"LingYi\", which is designed as a\npipeline framework to maintain high flexibility. Our system utilizes automated\nmedical procedures including medical triage, consultation, image-text drug\nrecommendation and record. To conduct knowledge-grounded dialogues with\npatients, we first construct a Chinese Medical Multi-Modal Knowledge Graph\n(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared\nwith the other existing medical question-answering systems, our system adopts\nseveral state-of-the-art technologies including medical entity disambiguation\nand medical dialogue generation, which is more friendly to provide medical\nservices to patients. In addition, we have open-sourced our codes which contain\nback-end models and front-end web pages at https://github.com/WENGSYX/LingYi.\nThe datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at\nhttps://github.com/WENGSYX/CMCQA are also released to further promote future\nresearch.", "published": "2022-04-20 04:41:26", "link": "http://arxiv.org/abs/2204.09220v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Synthetic Target Domain Supervision for Open Retrieval QA", "abstract": "Neural passage retrieval is a new and promising approach in open retrieval\nquestion answering. In this work, we stress-test the Dense Passage Retriever\n(DPR) -- a state-of-the-art (SOTA) open domain neural retrieval model -- on\nclosed and specialized target domains such as COVID-19, and find that it lags\nbehind standard BM25 in this important real-world setting. To make DPR more\nrobust under domain shift, we explore its fine-tuning with synthetic training\nexamples, which we generate from unlabeled target domain text using a\ntext-to-text generator. In our experiments, this noisy but fully automated\ntarget domain supervision gives DPR a sizable advantage over BM25 in\nout-of-domain settings, making it a more viable model in practice. Finally, an\nensemble of BM25 and our improved DPR model yields the best results, further\npushing the SOTA for open retrieval QA on multiple out-of-domain test sets.", "published": "2022-04-20 06:28:13", "link": "http://arxiv.org/abs/2204.09248v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DaLC: Domain Adaptation Learning Curve Prediction for Neural Machine\n  Translation", "abstract": "Domain Adaptation (DA) of Neural Machine Translation (NMT) model often relies\non a pre-trained general NMT model which is adapted to the new domain on a\nsample of in-domain parallel data. Without parallel data, there is no way to\nestimate the potential benefit of DA, nor the amount of parallel samples it\nwould require. It is however a desirable functionality that could help MT\npractitioners to make an informed decision before investing resources in\ndataset creation. We propose a Domain adaptation Learning Curve prediction\n(DaLC) model that predicts prospective DA performance based on in-domain\nmonolingual samples in the source language. Our model relies on the NMT encoder\nrepresentations combined with various instance and corpus-level features. We\ndemonstrate that instance-level is better able to distinguish between different\ndomains compared to corpus-level frameworks proposed in previous studies.\nFinally, we perform in-depth analyses of the results highlighting the\nlimitations of our approach, and provide directions for future research.", "published": "2022-04-20 06:57:48", "link": "http://arxiv.org/abs/2204.09259v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Non-Autoregressive Generation for Neural Machine Translation\n  and Beyond", "abstract": "Non-autoregressive (NAR) generation, which is first proposed in neural\nmachine translation (NMT) to speed up inference, has attracted much attention\nin both machine learning and natural language processing communities. While NAR\ngeneration can significantly accelerate inference speed for machine\ntranslation, the speedup comes at the cost of sacrificed translation accuracy\ncompared to its counterpart, autoregressive (AR) generation. In recent years,\nmany new models and algorithms have been designed/proposed to bridge the\naccuracy gap between NAR generation and AR generation. In this paper, we\nconduct a systematic survey with comparisons and discussions of various\nnon-autoregressive translation (NAT) models from different aspects.\nSpecifically, we categorize the efforts of NAT into several groups, including\ndata manipulation, modeling methods, training criterion, decoding algorithms,\nand the benefit from pre-trained models. Furthermore, we briefly review other\napplications of NAR models beyond machine translation, such as grammatical\nerror correction, text summarization, text style transfer, dialogue, semantic\nparsing, automatic speech recognition, and so on. In addition, we also discuss\npotential directions for future exploration, including releasing the dependency\nof KD, reasonable training objectives, pre-training for NAR, and wider\napplications, etc. We hope this survey can help researchers capture the latest\nprogress in NAR generation, inspire the design of advanced NAR models and\nalgorithms, and enable industry practitioners to choose appropriate solutions\nfor their applications. The web page of this survey is at\n\\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}.", "published": "2022-04-20 07:25:22", "link": "http://arxiv.org/abs/2204.09269v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Situational Perception Guided Image Matting", "abstract": "Most automatic matting methods try to separate the salient foreground from\nthe background. However, the insufficient quantity and subjective bias of the\ncurrent existing matting datasets make it difficult to fully explore the\nsemantic association between object-to-object and object-to-environment in a\ngiven image. In this paper, we propose a Situational Perception Guided Image\nMatting (SPG-IM) method that mitigates subjective bias of matting annotations\nand captures sufficient situational perception information for better global\nsaliency distilled from the visual-to-textual task. SPG-IM can better associate\ninter-objects and object-to-environment saliency, and compensate the subjective\nnature of image matting and its expensive annotation. We also introduce a\ntextual Semantic Transformation (TST) module that can effectively transform and\nintegrate the semantic feature stream to guide the visual representations. In\naddition, an Adaptive Focal Transformation (AFT) Refinement Network is proposed\nto adaptively switch multi-scale receptive fields and focal points to enhance\nboth global and local details. Extensive experiments demonstrate the\neffectiveness of situational perception guidance from the visual-to-textual\ntasks on image matting, and our model outperforms the state-of-the-art methods.\nWe also analyze the significance of different components in our model. The code\nwill be released soon.", "published": "2022-04-20 07:35:51", "link": "http://arxiv.org/abs/2204.09276v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Unsupervised Ranking and Aggregation of Label Descriptions for Zero-Shot\n  Classifiers", "abstract": "Zero-shot text classifiers based on label descriptions embed an input text\nand a set of labels into the same space: measures such as cosine similarity can\nthen be used to select the most similar label description to the input text as\nthe predicted label. In a true zero-shot setup, designing good label\ndescriptions is challenging because no development set is available. Inspired\nby the literature on Learning with Disagreements, we look at how probabilistic\nmodels of repeated rating analysis can be used for selecting the best label\ndescriptions in an unsupervised fashion. We evaluate our method on a set of\ndiverse datasets and tasks (sentiment, topic and stance). Furthermore, we show\nthat multiple, noisy label descriptions can be aggregated to boost the\nperformance.", "published": "2022-04-20 14:23:09", "link": "http://arxiv.org/abs/2204.09481v2", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "When Does Syntax Mediate Neural Language Model Performance? Evidence\n  from Dropout Probes", "abstract": "Recent causal probing literature reveals when language models and syntactic\nprobes use similar representations. Such techniques may yield \"false negative\"\ncausality results: models may use representations of syntax, but probes may\nhave learned to use redundant encodings of the same syntactic information. We\ndemonstrate that models do encode syntactic information redundantly and\nintroduce a new probe design that guides probes to consider all syntactic\ninformation present in embeddings. Using these probes, we find evidence for the\nuse of syntax in models where prior methods did not, allowing us to boost model\nperformance by injecting syntactic information into representations.", "published": "2022-04-20 18:09:36", "link": "http://arxiv.org/abs/2204.09722v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "K-LITE: Learning Transferable Visual Models with External Knowledge", "abstract": "The new generation of state-of-the-art computer vision systems are trained\nfrom natural language supervision, ranging from simple object category names to\ndescriptive captions. This form of supervision ensures high generality and\nusability of the learned visual models, due to the broad concept coverage\nachieved via large-scale data collection process. Alternatively, we argue that\nlearning with external knowledge is a promising way which leverages a much more\nstructured source of supervision and offers sample efficiency. We propose\nK-LITE, a simple strategy to leverage external knowledge for building\ntransferable visual systems: In training, it enriches entities in text with\nWordNet and Wiktionary knowledge, leading to an efficient and scalable approach\nto learning image representations that uses knowledge about the visual\nconcepts. In evaluation, the text is also augmented with external knowledge and\nthen used to reference learned visual concepts (or describe new ones) to enable\nzero-shot and few-shot transfer of the pre-trained models. We study the\nperformance of K-LITE on two important computer vision problems, image\nclassification and object detection, benchmarking on 20 and 13 different\nexisting datasets, respectively. The proposed knowledge-augmented models show\nsignificant improvement in transfer learning performance over existing methods.\nOur code is available at https://github.com/microsoft/klite.", "published": "2022-04-20 04:47:01", "link": "http://arxiv.org/abs/2204.09222v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Cross-stitched Multi-modal Encoders", "abstract": "In this paper, we propose a novel architecture for multi-modal speech and\ntext input. We combine pretrained speech and text encoders using multi-headed\ncross-modal attention and jointly fine-tune on the target problem. The\nresultant architecture can be used for continuous token-level classification or\nutterance-level prediction acting on simultaneous text and speech. The\nresultant encoder efficiently captures both acoustic-prosodic and lexical\ninformation. We compare the benefits of multi-headed attention-based fusion for\nmulti-modal utterance-level classification against a simple concatenation of\npre-pooled, modality-specific representations. Our model architecture is\ncompact, resource efficient, and can be trained on a single consumer GPU card.", "published": "2022-04-20 05:09:36", "link": "http://arxiv.org/abs/2204.09227v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Uncertainty-based Cross-Modal Retrieval with Probabilistic\n  Representations", "abstract": "Probabilistic embeddings have proven useful for capturing polysemous word\nmeanings, as well as ambiguity in image matching. In this paper, we study the\nadvantages of probabilistic embeddings in a cross-modal setting (i.e., text and\nimages), and propose a simple approach that replaces the standard vector point\nembeddings in extant image-text matching models with probabilistic\ndistributions that are parametrically learned. Our guiding hypothesis is that\nthe uncertainty encoded in the probabilistic embeddings captures the\ncross-modal ambiguity in the input instances, and that it is through capturing\nthis uncertainty that the probabilistic models can perform better at downstream\ntasks, such as image-to-text or text-to-image retrieval. Through extensive\nexperiments on standard and new benchmarks, we show a consistent advantage for\nprobabilistic representations in cross-modal retrieval, and validate the\nability of our embeddings to capture uncertainty.", "published": "2022-04-20 07:24:20", "link": "http://arxiv.org/abs/2204.09268v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Exploration strategies for articulatory synthesis of complex syllable\n  onsets", "abstract": "High-quality articulatory speech synthesis has many potential applications in\nspeech science and technology. However, developing appropriate mappings from\nlinguistic specification to articulatory gestures is difficult and time\nconsuming. In this paper we construct an optimisation-based framework as a\nfirst step towards learning these mappings without manual intervention. We\ndemonstrate the production of syllables with complex onsets and discuss the\nquality of the articulatory gestures with reference to coarticulation.", "published": "2022-04-20 10:47:28", "link": "http://arxiv.org/abs/2204.09381v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generalizing to the Future: Mitigating Entity Bias in Fake News\n  Detection", "abstract": "The wide dissemination of fake news is increasingly threatening both\nindividuals and society. Fake news detection aims to train a model on the past\nnews and detect fake news of the future. Though great efforts have been made,\nexisting fake news detection methods overlooked the unintended entity bias in\nthe real-world data, which seriously influences models' generalization ability\nto future data. For example, 97\\% of news pieces in 2010-2017 containing the\nentity `Donald Trump' are real in our data, but the percentage falls down to\nmerely 33\\% in 2018. This would lead the model trained on the former set to\nhardly generalize to the latter, as it tends to predict news pieces about\n`Donald Trump' as real for lower training loss. In this paper, we propose an\nentity debiasing framework (\\textbf{ENDEF}) which generalizes fake news\ndetection models to the future data by mitigating entity bias from a\ncause-effect perspective. Based on the causal graph among entities, news\ncontents, and news veracity, we separately model the contribution of each cause\n(entities and contents) during training. In the inference stage, we remove the\ndirect effect of the entities to mitigate entity bias. Extensive offline\nexperiments on the English and Chinese datasets demonstrate that the proposed\nframework can largely improve the performance of base fake news detectors, and\nonline tests verify its superiority in practice. To the best of our knowledge,\nthis is the first work to explicitly improve the generalization ability of fake\nnews detection models to the future data. The code has been released at\nhttps://github.com/ICTMCG/ENDEF-SIGIR2022.", "published": "2022-04-20 14:32:34", "link": "http://arxiv.org/abs/2204.09484v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Ethical Considerations of Text Simplification", "abstract": "This paper outlines the ethical implications of text simplification within\nthe framework of assistive systems. We argue that a distinction should be made\nbetween the technologies that perform text simplification and the realisation\nof these in assistive technologies. When using the latter as a motivation for\nresearch, it is important that the subsequent ethical implications be carefully\nconsidered. We provide guidelines for the framing of text simplification\nindependently of assistive systems, as well as suggesting directions for future\nresearch and discussion based on the concerns raised.", "published": "2022-04-20 16:05:36", "link": "http://arxiv.org/abs/2204.09565v1", "categories": ["cs.CL", "cs.ET", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous\n  Environments", "abstract": "Recent work in Vision-and-Language Navigation (VLN) has presented two\nenvironmental paradigms with differing realism -- the standard VLN setting\nbuilt on topological environments where navigation is abstracted away, and the\nVLN-CE setting where agents must navigate continuous 3D environments using\nlow-level actions. Despite sharing the high-level task and even the underlying\ninstruction-path data, performance on VLN-CE lags behind VLN significantly. In\nthis work, we explore this gap by transferring an agent from the abstract\nenvironment of VLN to the continuous environment of VLN-CE. We find that this\nsim-2-sim transfer is highly effective, improving over the prior state of the\nart in VLN-CE by +12% success rate. While this demonstrates the potential for\nthis direction, the transfer does not fully retain the original performance of\nthe agent in the abstract setting. We present a sequence of experiments to\nidentify what differences result in performance degradation, providing clear\ndirections for further improvement.", "published": "2022-04-20 17:57:11", "link": "http://arxiv.org/abs/2204.09667v2", "categories": ["cs.CV", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multi-label classification for biomedical literature: an overview of the\n  BioCreative VII LitCovid Track for COVID-19 literature topic annotations", "abstract": "The COVID-19 pandemic has been severely impacting global society since\nDecember 2019. Massive research has been undertaken to understand the\ncharacteristics of the virus and design vaccines and drugs. The related\nfindings have been reported in biomedical literature at a rate of about 10,000\narticles on COVID-19 per month. Such rapid growth significantly challenges\nmanual curation and interpretation. For instance, LitCovid is a literature\ndatabase of COVID-19-related articles in PubMed, which has accumulated more\nthan 200,000 articles with millions of accesses each month by users worldwide.\nOne primary curation task is to assign up to eight topics (e.g., Diagnosis and\nTreatment) to the articles in LitCovid. Despite the continuing advances in\nbiomedical text mining methods, few have been dedicated to topic annotations in\nCOVID-19 literature. To close the gap, we organized the BioCreative LitCovid\ntrack to call for a community effort to tackle automated topic annotation for\nCOVID-19 literature. The BioCreative LitCovid dataset, consisting of over\n30,000 articles with manually reviewed topics, was created for training and\ntesting. It is one of the largest multilabel classification datasets in\nbiomedical scientific literature. 19 teams worldwide participated and made 80\nsubmissions in total. Most teams used hybrid systems based on transformers. The\nhighest performing submissions achieved 0.8875, 0.9181, and 0.9394 for macro\nF1-score, micro F1-score, and instance-based F1-score, respectively. The level\nof participation and results demonstrate a successful track and help close the\ngap between dataset curation and method development. The dataset is publicly\navailable via https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/ for\nbenchmarking and further development.", "published": "2022-04-20 20:47:55", "link": "http://arxiv.org/abs/2204.09781v3", "categories": ["cs.DL", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.DL"}
{"title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation", "abstract": "Text-to-image generation has seen an explosion of interest since 2021. Today,\nbeautiful and intriguing digital images and artworks can be synthesized from\ntextual inputs (\"prompts\") with deep generative models. Online communities\naround text-to-image generation and AI generated art have quickly emerged. This\npaper identifies six types of prompt modifiers used by practitioners in the\nonline community based on a 3-month ethnographic study. The novel taxonomy of\nprompt modifiers provides researchers a conceptual starting point for\ninvestigating the practice of text-to-image generation, but may also help\npractitioners of AI generated art improve their images. We further outline how\nprompt modifiers are applied in the practice of \"prompt engineering.\" We\ndiscuss research opportunities of this novel creative practice in the field of\nHuman-Computer Interaction (HCI). The paper concludes with a discussion of\nbroader implications of prompt engineering from the perspective of Human-AI\nInteraction (HAI) in future applications beyond the use case of text-to-image\ngeneration and AI generated art.", "published": "2022-04-20 06:15:50", "link": "http://arxiv.org/abs/2204.13988v3", "categories": ["cs.MM", "cs.CL", "cs.HC", "H.5; H.m; J.5"], "primary_category": "cs.MM"}
{"title": "Detecting Unintended Memorization in Language-Model-Fused ASR", "abstract": "End-to-end (E2E) models are often being accompanied by language models (LMs)\nvia shallow fusion for boosting their overall quality as well as recognition of\nrare words. At the same time, several prior works show that LMs are susceptible\nto unintentionally memorizing rare or unique sequences in the training data. In\nthis work, we design a framework for detecting memorization of random textual\nsequences (which we call canaries) in the LM training data when one has only\nblack-box (query) access to LM-fused speech recognizer, as opposed to direct\naccess to the LM. On a production-grade Conformer RNN-T E2E model fused with a\nTransformer LM, we show that detecting memorization of singly-occurring\ncanaries from the LM training data of 300M examples is possible. Motivated to\nprotect privacy, we also show that such memorization gets significantly reduced\nby per-example gradient-clipped LM training without compromising overall\nquality.", "published": "2022-04-20 16:35:13", "link": "http://arxiv.org/abs/2204.09606v2", "categories": ["cs.CL", "cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Parametric Models for DOA Trajectory Localization", "abstract": "Directions of arrival (DOA) estimation or localization of sources is an\nimportant problem in many applications for which numerous algorithms have been\nproposed. Most localization methods use block-level processing that combines\nmultiple data snapshots to estimate DOA within a block. The DOAs are assumed to\nbe constant within the block duration. However, these assumptions are often\nviolated due to source motion. In this paper, we propose a signal model that\ncaptures the linear variations in DOA within a block. We applied conventional\nbeamforming (CBF) algorithm to this model to estimate linear DOA trajectories.\nFurther, we formulate the proposed signal model as a block sparse model and\nsubsequently derive sparse Bayesian learning (SBL) algorithm. Our simulation\nresults show that this linear parametric DOA model and corresponding algorithms\ncapture the DOA trajectories for moving sources more accurately than\ntraditional signal models and methods.", "published": "2022-04-20 17:44:09", "link": "http://arxiv.org/abs/2204.09647v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "ContentVec: An Improved Self-Supervised Speech Representation by\n  Disentangling Speakers", "abstract": "Self-supervised learning in speech involves training a speech representation\nnetwork on a large-scale unannotated speech corpus, and then applying the\nlearned representations to downstream tasks. Since the majority of the\ndownstream tasks of SSL learning in speech largely focus on the content\ninformation in speech, the most desirable speech representations should be able\nto disentangle unwanted variations, such as speaker variations, from the\ncontent. However, disentangling speakers is very challenging, because removing\nthe speaker information could easily result in a loss of content as well, and\nthe damage of the latter usually far outweighs the benefit of the former. In\nthis paper, we propose a new SSL method that can achieve speaker\ndisentanglement without severe loss of content. Our approach is adapted from\nthe HuBERT framework, and incorporates disentangling mechanisms to regularize\nboth the teacher labels and the learned representations. We evaluate the\nbenefit of speaker disentanglement on a set of content-related downstream\ntasks, and observe a consistent and notable performance advantage of our\nspeaker-disentangled representations.", "published": "2022-04-20 04:56:14", "link": "http://arxiv.org/abs/2204.09224v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Clotho-AQA: A Crowdsourced Dataset for Audio Question Answering", "abstract": "Audio question answering (AQA) is a multimodal translation task where a\nsystem analyzes an audio signal and a natural language question, to generate a\ndesirable natural language answer. In this paper, we introduce Clotho-AQA, a\ndataset for Audio question answering consisting of 1991 audio files each\nbetween 15 to 30 seconds in duration selected from the Clotho dataset. For each\naudio file, we collect six different questions and corresponding answers by\ncrowdsourcing using Amazon Mechanical Turk. The questions and answers are\nproduced by different annotators. Out of the six questions for each audio, two\nquestions each are designed to have 'yes' and 'no' as answers, while the\nremaining two questions have other single-word answers. For each question, we\ncollect answers from three different annotators. We also present two baseline\nexperiments to describe the usage of our dataset for the AQA task - an\nLSTM-based multimodal binary classifier for 'yes' or 'no' type answers and an\nLSTM-based multimodal multi-class classifier for 828 single-word answers. The\nbinary classifier achieved an accuracy of 62.7% and the multi-class classifier\nachieved a top-1 accuracy of 54.2% and a top-5 accuracy of 93.7%. Clotho-AQA\ndataset is freely available online at https://zenodo.org/record/6473207.", "published": "2022-04-20 17:28:53", "link": "http://arxiv.org/abs/2204.09634v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Delamination prediction in composite panels using unsupervised-feature\n  learning methods with wavelet-enhanced guided wave representations", "abstract": "With the introduction of damage tolerance-based design philosophies, the\ndemand for reliable and robust structural health monitoring (SHM) procedures\nfor aerospace composite structures is increasing rapidly. The performance of\nsupervised learning algorithms for SHM depends on the amount of labeled and\nbalanced datasets. Apart from this, collecting datasets accommodating all\npossible damage scenarios is cumbersome, costly, and inaccessible for aerospace\napplications. In this paper, we have proposed two different\nunsupervised-feature learning approaches where the algorithms are trained only\non the baseline scenarios to learn the distribution of baseline signals. The\ntrained unsupervised feature learner is used for delamination prediction with\nan anomaly detection philosophy. In the first approach, we have combined\ndimensionality reduction techniques (principal component analysis and\nindependent component analysis) with a one-class support vector machine. In\nanother approach, we have utilized deep learning-based deep convolutional\nautoencoders (CAE). These state-of-the-art algorithms are applied on three\ndifferent guided wave-based experimental datasets. The raw guided wave signals\npresent in the datasets are converted into wavelet-enhanced higher-order\nrepresentations for training unsupervised feature-learning algorithms. We have\nalso compared different techniques, and it is seen that CAE generates better\nreconstructions with lower mean squared error and can provide higher accuracy\non all the datasets.", "published": "2022-04-20 20:03:20", "link": "http://arxiv.org/abs/2204.09764v1", "categories": ["eess.SP", "eess.AS", "eess.IV"], "primary_category": "eess.SP"}
