{"title": "Sentence Simplification with Memory-Augmented Neural Networks", "abstract": "Sentence simplification aims to simplify the content and structure of complex\nsentences, and thus make them easier to interpret for human readers, and easier\nto process for downstream NLP applications. Recent advances in neural machine\ntranslation have paved the way for novel approaches to the task. In this paper,\nwe adapt an architecture with augmented memory capacities called Neural\nSemantic Encoders (Munkhdalai and Yu, 2017) for sentence simplification. Our\nexperiments demonstrate the effectiveness of our approach on different\nsimplification datasets, both in terms of automatic evaluation measures and\nhuman judgments.", "published": "2018-04-20 03:52:20", "link": "http://arxiv.org/abs/1804.07445v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language\n  Understanding", "abstract": "For natural language understanding (NLU) technology to be maximally useful,\nboth practically and as a scientific object of study, it must be general: it\nmust be able to process language in a way that is not exclusively tailored to\nany one specific task or dataset. In pursuit of this objective, we introduce\nthe General Language Understanding Evaluation benchmark (GLUE), a tool for\nevaluating and analyzing the performance of models across a diverse range of\nexisting NLU tasks. GLUE is model-agnostic, but it incentivizes sharing\nknowledge across tasks because certain tasks have very limited training data.\nWe further provide a hand-crafted diagnostic test suite that enables detailed\nlinguistic analysis of NLU models. We evaluate baselines based on current\nmethods for multi-task and transfer learning and find that they do not\nimmediately give substantial improvements over the aggregate performance of\ntraining a separate model per task, indicating room for improvement in\ndeveloping general and robust NLU systems.", "published": "2018-04-20 06:35:04", "link": "http://arxiv.org/abs/1804.07461v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Stance Detection Using End-to-End Memory Networks", "abstract": "We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.", "published": "2018-04-20 12:48:10", "link": "http://arxiv.org/abs/1804.07581v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "abstract": "We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.", "published": "2018-04-20 13:00:58", "link": "http://arxiv.org/abs/1804.07587v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Acquisition of Phrase Correspondences using Natural Deduction Proofs", "abstract": "How to identify, extract, and use phrasal knowledge is a crucial problem for\nthe task of Recognizing Textual Entailment (RTE). To solve this problem, we\npropose a method for detecting paraphrases via natural deduction proofs of\nsemantic relations between sentence pairs. Our solution relies on a graph\nreformulation of partial variable unifications and an algorithm that induces\nsubgraph alignments between meaning representations. Experiments show that our\nmethod can automatically detect various paraphrases that are absent from\nexisting paraphrase databases. In addition, the detection of paraphrases using\nproof information improves the accuracy of RTE tasks.", "published": "2018-04-20 15:02:25", "link": "http://arxiv.org/abs/1804.07656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lightweight Adaptive Mixture of Neural and N-gram Language Models", "abstract": "It is often the case that the best performing language model is an ensemble\nof a neural language model with n-grams. In this work, we propose a method to\nimprove how these two models are combined. By using a small network which\npredicts the mixture weight between the two models, we adapt their relative\nimportance at each time step. Because the gating network is small, it trains\nquickly on small amounts of held out data, and does not add overhead at scoring\ntime. Our experiments carried out on the One Billion Word benchmark show a\nsignificant improvement over the state of the art ensemble without retraining\nof the basic modules.", "published": "2018-04-20 16:18:35", "link": "http://arxiv.org/abs/1804.07705v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factorising AMR generation through syntax", "abstract": "Generating from Abstract Meaning Representation (AMR) is an underspecified\nproblem, as many syntactic decisions are not constrained by the semantic graph.\nTo explicitly account for this underspecification, we break down generating\nfrom AMR into two steps: first generate a syntactic structure, and then\ngenerate the surface form. We show that decomposing the generation process this\nway leads to state-of-the-art single model performance generating from AMR\nwithout additional unlabelled data. We also demonstrate that we can generate\nmeaning-preserving syntactic paraphrases of the same AMR graph, as judged by\nhumans.", "published": "2018-04-20 16:24:12", "link": "http://arxiv.org/abs/1804.07707v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phrase-Indexed Question Answering: A New Challenge for Scalable Document\n  Comprehension", "abstract": "We formalize a new modular variant of current question answering tasks by\nenforcing complete independence of the document encoder from the question\nencoder. This formulation addresses a key challenge in machine comprehension by\nrequiring a standalone representation of the document discourse. It\nadditionally leads to a significant scalability advantage since the encoding of\nthe answer candidate phrases in the document can be pre-computed and indexed\noffline for efficient retrieval. We experiment with baseline models for the new\ntask, which achieve a reasonable accuracy but significantly underperform\nunconstrained QA models. We invite the QA research community to engage in\nPhrase-Indexed Question Answering (PIQA, pika) for closing the gap. The\nleaderboard is at: nlp.cs.washington.edu/piqa", "published": "2018-04-20 17:05:03", "link": "http://arxiv.org/abs/1804.07726v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Semantic Textual Similarity from Conversations", "abstract": "We present a novel approach to learn representations for sentence-level\nsemantic similarity using conversational data. Our method trains an\nunsupervised model to predict conversational input-response pairs. The\nresulting sentence embeddings perform well on the semantic textual similarity\n(STS) benchmark and SemEval 2017's Community Question Answering (CQA) question\nsimilarity subtask. Performance is further improved by introducing multitask\ntraining combining the conversational input-response prediction task and a\nnatural language inference task. Extensive experiments show the proposed model\nachieves the best performance among all neural models on the STS benchmark and\nis competitive with the state-of-the-art feature engineered and mixed systems\nin both tasks.", "published": "2018-04-20 17:58:45", "link": "http://arxiv.org/abs/1804.07754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phrase-Based & Neural Unsupervised Machine Translation", "abstract": "Machine translation systems achieve near human-level performance on some\nlanguages, yet their effectiveness strongly relies on the availability of large\namounts of parallel sentences, which hinders their applicability to the\nmajority of language pairs. This work investigates how to learn to translate\nwhen having access to only large monolingual corpora in each language. We\npropose two model variants, a neural and a phrase-based model. Both versions\nleverage a careful initialization of the parameters, the denoising effect of\nlanguage models and automatic generation of parallel data by iterative\nback-translation. These models are significantly better than methods from the\nliterature, while being simpler and having fewer hyper-parameters. On the\nwidely used WMT'14 English-French and WMT'16 German-English benchmarks, our\nmodels respectively obtain 28.1 and 25.2 BLEU points without using a single\nparallel sentence, outperforming the state of the art by more than 11 BLEU\npoints. On low-resource languages like English-Urdu and English-Romanian, our\nmethods achieve even better results than semi-supervised and supervised\napproaches leveraging the paucity of available bitexts. Our code for NMT and\nPBSMT is publicly available.", "published": "2018-04-20 17:59:13", "link": "http://arxiv.org/abs/1804.07755v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pathologies of Neural Models Make Interpretations Difficult", "abstract": "One way to interpret neural model predictions is to highlight the most\nimportant input features---for example, a heatmap visualization over the words\nin an input sentence. In existing interpretation methods for NLP, a word's\nimportance is determined by either input perturbation---measuring the decrease\nin model confidence when that word is removed---or by the gradient with respect\nto that word. To understand the limitations of these methods, we use input\nreduction, which iteratively removes the least important word from the input.\nThis exposes pathological behaviors of neural models: the remaining words\nappear nonsensical to humans and are not the ones determined as important by\ninterpretation methods. As we confirm with human experiments, the reduced\nexamples lack information to support the prediction of any label, but models\nstill make the same predictions with high confidence. To explain these\ncounterintuitive results, we draw connections to adversarial examples and\nconfidence calibration: pathological behaviors reveal difficulties in\ninterpreting neural models trained with maximum likelihood. To mitigate their\ndeficiencies, we fine-tune the models by encouraging high entropy outputs on\nreduced examples. Fine-tuned models become more interpretable under input\nreduction without accuracy loss on regular examples.", "published": "2018-04-20 18:18:06", "link": "http://arxiv.org/abs/1804.07781v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Contextualized Representation: Language Model Pruning for\n  Sequence Labeling", "abstract": "Many efforts have been made to facilitate natural language processing tasks\nwith pre-trained language models (LMs), and brought significant improvements to\nvarious applications. To fully leverage the nearly unlimited corpora and\ncapture linguistic information of multifarious levels, large-size LMs are\nrequired; but for a specific task, only parts of these information are useful.\nSuch large-sized LMs, even in the inference stage, may cause heavy computation\nworkloads, making them too time-consuming for large-scale applications. Here we\npropose to compress bulky LMs while preserving useful information with regard\nto a specific task. As different layers of the model keep different\ninformation, we develop a layer selection method for model pruning using\nsparsity-inducing regularization. By introducing the dense connectivity, we can\ndetach any layer without affecting others, and stretch shallow and wide LMs to\nbe deep and narrow. In model training, LMs are learned with layer-wise dropouts\nfor better robustness. Experiments on two benchmark datasets demonstrate the\neffectiveness of our method.", "published": "2018-04-20 21:10:17", "link": "http://arxiv.org/abs/1804.07827v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "abstract": "Existing temporal relation (TempRel) annotation schemes often have low\ninter-annotator agreements (IAA) even between experts, suggesting that the\ncurrent annotation task needs a better definition. This paper proposes a new\nmulti-axis modeling to better capture the temporal structure of events. In\naddition, we identify that event end-points are a major source of confusion in\nannotation, so we also propose to annotate TempRels based on start-points only.\nA pilot expert annotation using the proposed scheme shows significant\nimprovement in IAA from the conventional 60's to 80's (Cohen's Kappa). This\nbetter-defined annotation scheme further enables the use of crowdsourcing to\nalleviate the labor intensity for each annotator. We hope that this work can\nfoster more interesting studies towards event understanding.", "published": "2018-04-20 21:10:21", "link": "http://arxiv.org/abs/1804.07828v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Direct Network Transfer: Transfer Learning of Sentence Embeddings for\n  Semantic Similarity", "abstract": "Sentence encoders, which produce sentence embeddings using neural networks,\nare typically evaluated by how well they transfer to downstream tasks. This\nincludes semantic similarity, an important task in natural language\nunderstanding. Although there has been much work dedicated to building sentence\nencoders, the accompanying transfer learning techniques have received\nrelatively little attention. In this paper, we propose a transfer learning\nsetting specialized for semantic similarity, which we refer to as direct\nnetwork transfer. Through experiments on several standard text similarity\ndatasets, we show that applying direct network transfer to existing encoders\ncan lead to state-of-the-art performance. Additionally, we compare several\napproaches to transfer sentence encoders to semantic similarity tasks, showing\nthat the choice of transfer learning setting greatly affects the performance in\nmany cases, and differs by encoder and dataset.", "published": "2018-04-20 21:40:28", "link": "http://arxiv.org/abs/1804.07835v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint entity recognition and relation extraction as a multi-head\n  selection problem", "abstract": "State-of-the-art models for joint entity recognition and relation extraction\nstrongly rely on external natural language processing (NLP) tools such as POS\n(part-of-speech) taggers and dependency parsers. Thus, the performance of such\njoint models depends on the quality of the features obtained from these NLP\ntools. However, these features are not always accurate for various languages\nand contexts. In this paper, we propose a joint neural model which performs\nentity recognition and relation extraction simultaneously, without the need of\nany manually extracted features or the use of any external tool. Specifically,\nwe model the entity recognition task using a CRF (Conditional Random Fields)\nlayer and the relation extraction task as a multi-head selection problem (i.e.,\npotentially identify multiple relations for each entity). We present an\nextensive experimental setup, to demonstrate the effectiveness of our method\nusing datasets from various contexts (i.e., news, biomedical, real estate) and\nlanguages (i.e., English, Dutch). Our model outperforms the previous neural\nmodels that use automatically extracted features, while it performs within a\nreasonable margin of feature-based neural models, or even beats them.", "published": "2018-04-20 22:16:40", "link": "http://arxiv.org/abs/1804.07847v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mutual Information Maximization for Simple and Accurate Part-Of-Speech\n  Induction", "abstract": "We address part-of-speech (POS) induction by maximizing the mutual\ninformation between the induced label and its context. We focus on two training\nobjectives that are amenable to stochastic gradient descent (SGD): a novel\ngeneralization of the classical Brown clustering objective and a recently\nproposed variational lower bound. While both objectives are subject to noise in\ngradient updates, we show through analysis and experiments that the variational\nlower bound is robust whereas the generalized Brown objective is vulnerable. We\nobtain competitive performance on a multitude of datasets and languages with a\nsimple architecture that encodes morphology and context.", "published": "2018-04-20 22:34:29", "link": "http://arxiv.org/abs/1804.07849v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's Going On in Neural Constituency Parsers? An Analysis", "abstract": "A number of differences have emerged between modern and classic approaches to\nconstituency parsing in recent years, with structural components like grammars\nand feature-rich lexicons becoming less central while recurrent neural network\nrepresentations rise in popularity. The goal of this work is to analyze the\nextent to which information provided directly by the model structure in\nclassical systems is still being captured by neural methods. To this end, we\npropose a high-performance neural model (92.08 F1 on PTB) that is\nrepresentative of recent work and perform a series of investigative\nexperiments. We find that our model implicitly learns to encode much of the\nsame information that was explicitly provided by grammars and lexicons in the\npast, indicating that this scaffolding can largely be subsumed by powerful\ngeneral-purpose neural machinery.", "published": "2018-04-20 23:00:11", "link": "http://arxiv.org/abs/1804.07853v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Approaches for Enriching and Improving Textual Knowledge Bases", "abstract": "Verifiability is one of the core editing principles in Wikipedia, where\neditors are encouraged to provide citations for the added statements.\nStatements can be any arbitrary piece of text, ranging from a sentence up to a\nparagraph. However, in many cases, citations are either outdated, missing, or\nlink to non-existing references (e.g. dead URL, moved content etc.). In total,\n20\\% of the cases such citations refer to news articles and represent the\nsecond most cited source. Even in cases where citations are provided, there are\nno explicit indicators for the span of a citation for a given piece of text. In\naddition to issues related with the verifiability principle, many Wikipedia\nentity pages are incomplete, with relevant information that is already\navailable in online news sources missing. Even for the already existing\ncitations, there is often a delay between the news publication time and the\nreference time.\n  In this thesis, we address the aforementioned issues and propose automated\napproaches that enforce the verifiability principle in Wikipedia, and suggest\nrelevant and missing news references for further enriching Wikipedia entity\npages.", "published": "2018-04-20 12:49:54", "link": "http://arxiv.org/abs/1804.07583v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Cross-domain Dialogue Policy Transfer via Simultaneous Speech-act and\n  Slot Alignment", "abstract": "Dialogue policy transfer enables us to build dialogue policies in a target\ndomain with little data by leveraging knowledge from a source domain with\nplenty of data. Dialogue sentences are usually represented by speech-acts and\ndomain slots, and the dialogue policy transfer is usually achieved by assigning\na slot mapping matrix based on human heuristics. However, existing dialogue\npolicy transfer methods cannot transfer across dialogue domains with different\nspeech-acts, for example, between systems built by different companies. Also,\nthey depend on either common slots or slot entropy, which are not available\nwhen the source and target slots are totally disjoint and no database is\navailable to calculate the slot entropy. To solve this problem, we propose a\nPolicy tRansfer across dOMaIns and SpEech-acts (PROMISE) model, which is able\nto transfer dialogue policies across domains with different speech-acts and\ndisjoint slots. The PROMISE model can learn to align different speech-acts and\nslots simultaneously, and it does not require common slots or the calculation\nof the slot entropy. Experiments on both real-world dialogue data and\nsimulations demonstrate that PROMISE model can effectively transfer dialogue\npolicies across domains with different speech-acts and disjoint slots.", "published": "2018-04-20 15:51:14", "link": "http://arxiv.org/abs/1804.07691v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Loss in Translation: Learning Bilingual Word Mapping with a Retrieval\n  Criterion", "abstract": "Continuous word representations learned separately on distinct languages can\nbe aligned so that their words become comparable in a common space. Existing\nworks typically solve a least-square regression problem to learn a rotation\naligning a small bilingual lexicon, and use a retrieval criterion for\ninference. In this paper, we propose an unified formulation that directly\noptimizes a retrieval criterion in an end-to-end fashion. Our experiments on\nstandard benchmarks show that our approach outperforms the state of the art on\nword translation, with the biggest improvements observed for distant language\npairs such as English-Chinese.", "published": "2018-04-20 17:41:15", "link": "http://arxiv.org/abs/1804.07745v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Mixed Hierarchical Attention based Encoder-Decoder Approach for\n  Standard Table Summarization", "abstract": "Structured data summarization involves generation of natural language\nsummaries from structured input data. In this work, we consider summarizing\nstructured data occurring in the form of tables as they are prevalent across a\nwide variety of domains. We formulate the standard table summarization problem,\nwhich deals with tables conforming to a single predefined schema. To this end,\nwe propose a mixed hierarchical attention based encoder-decoder model which is\nable to leverage the structure in addition to the content of the tables. Our\nexperiments on the publicly available WEATHERGOV dataset show around 18 BLEU (~\n30%) improvement over the current state-of-the-art.", "published": "2018-04-20 18:31:29", "link": "http://arxiv.org/abs/1804.07790v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Skin Tone Emoji and Sentiment on Twitter", "abstract": "In 2015, the Unicode Consortium introduced five skin tone emoji that can be\nused in combination with emoji representing human figures and body parts. In\nthis study, use of the skin tone emoji is analyzed geographically in a large\nsample of data from Twitter. It can be shown that values for the skin tone\nemoji by country correspond approximately to the skin tone of the resident\npopulations, and that a negative correlation exists between tweet sentiment and\ndarker skin tone at the global level. In an era of large-scale migrations and\ncontinued sensitivity to questions of skin color and race, understanding how\nnew language elements such as skin tone emoji are used can help frame our\nunderstanding of how people represent themselves and others in terms of a\nsalient personal appearance attribute.", "published": "2018-04-20 12:25:59", "link": "http://arxiv.org/abs/1805.00444v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Generating Descriptions from Structured Data Using a Bifocal Attention\n  Mechanism and Gated Orthogonalization", "abstract": "In this work, we focus on the task of generating natural language\ndescriptions from a structured table of facts containing fields (such as\nnationality, occupation, etc) and values (such as Indian, actor, director,\netc). One simple choice is to treat the table as a sequence of fields and\nvalues and then use a standard seq2seq model for this task. However, such a\nmodel is too generic and does not exploit task-specific characteristics. For\nexample, while generating descriptions from a table, a human would attend to\ninformation at two levels: (i) the fields (macro level) and (ii) the values\nwithin the field (micro level). Further, a human would continue attending to a\nfield for a few timesteps till all the information from that field has been\nrendered and then never return back to this field (because there is nothing\nleft to say about it). To capture this behavior we use (i) a fused bifocal\nattention mechanism which exploits and combines this micro and macro level\ninformation and (ii) a gated orthogonalization mechanism which tries to ensure\nthat a field is remembered for a few time steps and then forgotten. We\nexperiment with a recently released dataset which contains fact tables about\npeople and their corresponding one line biographical descriptions in English.\nIn addition, we also introduce two similar datasets for French and German. Our\nexperiments show that the proposed model gives 21% relative improvement over a\nrecently proposed state of the art method and 10% relative improvement over\nbasic seq2seq models. The code and the datasets developed as a part of this\nwork are publicly available.", "published": "2018-04-20 18:30:18", "link": "http://arxiv.org/abs/1804.07789v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Subgoal Discovery for Hierarchical Dialogue Policy Learning", "abstract": "Developing agents to engage in complex goal-oriented dialogues is challenging\npartly because the main learning signals are very sparse in long conversations.\nIn this paper, we propose a divide-and-conquer approach that discovers and\nexploits the hidden structure of the task to enable efficient policy learning.\nFirst, given successful example dialogues, we propose the Subgoal Discovery\nNetwork (SDN) to divide a complex goal-oriented task into a set of simpler\nsubgoals in an unsupervised fashion. We then use these subgoals to learn a\nmulti-level policy by hierarchical reinforcement learning. We demonstrate our\nmethod by building a dialogue agent for the composite task of travel planning.\nExperiments with simulated and real users show that our approach performs\ncompetitively against a state-of-the-art method that requires human-defined\nsubgoals. Moreover, we show that the learned subgoals are often human\ncomprehensible.", "published": "2018-04-20 23:06:44", "link": "http://arxiv.org/abs/1804.07855v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Domain Adversarial for Acoustic Emotion Recognition", "abstract": "The performance of speech emotion recognition is affected by the differences\nin data distributions between train (source domain) and test (target domain)\nsets used to build and evaluate the models. This is a common problem, as\nmultiple studies have shown that the performance of emotional classifiers drop\nwhen they are exposed to data that does not match the distribution used to\nbuild the emotion classifiers. The difference in data distributions becomes\nvery clear when the training and testing data come from different domains,\ncausing a large performance gap between validation and testing performance. Due\nto the high cost of annotating new data and the abundance of unlabeled data, it\nis crucial to extract as much useful information as possible from the available\nunlabeled data. This study looks into the use of adversarial multitask training\nto extract a common representation between train and test domains. The primary\ntask is to predict emotional attribute-based descriptors for arousal, valence,\nor dominance. The secondary task is to learn a common representation where the\ntrain and test domains cannot be distinguished. By using a gradient reversal\nlayer, the gradients coming from the domain classifier are used to bring the\nsource and target domain representations closer. We show that exploiting\nunlabeled data consistently leads to better emotion recognition performance\nacross all emotional dimensions. We visualize the effect of adversarial\ntraining on the feature representation across the proposed deep learning\narchitecture. The analysis shows that the data representations for the train\nand test domains converge as the data is passed to deeper layers of the\nnetwork. We also evaluate the difference in performance when we use a shallow\nneural network versus a \\emph{deep neural network} (DNN) and the effect of the\nnumber of shared layers used by the task and domain classifiers.", "published": "2018-04-20 15:49:38", "link": "http://arxiv.org/abs/1804.07690v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
