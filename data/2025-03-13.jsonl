{"title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses", "abstract": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available.", "published": "2025-03-13 22:28:38", "link": "http://arxiv.org/abs/2503.10927v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Aviation Communication Transcription: Fine-Tuning Distil-Whisper with LoRA", "abstract": "Transcription of aviation communications has several applications, from\nassisting air traffic controllers in identifying the accuracy of read-back\nerrors to search and rescue operations. Recent advances in artificial\nintelligence have provided unprecedented opportunities for improving aviation\ncommunication transcription tasks. OpenAI's Whisper is one of the leading\nautomatic speech recognition models. However, fine-tuning Whisper for aviation\ncommunication transcription is not computationally efficient. Thus, this paper\naims to use a Parameter-Efficient Fine-tuning method called Low-Rank Adaptation\nto fine-tune a more computationally efficient version of Whisper,\ndistil-Whisper. To perform the fine-tuning, we used the Air Traffic Control\nCorpus dataset from the Linguistic Data Consortium, which contains\napproximately 70 hours of controller and pilot transmissions near three major\nairports in the US. The objective was to reduce the word error rate to enhance\naccuracy in the transcription of aviation communication. First, starting with\nan initial set of hyperparameters for LoRA (Alpha = 64 and Rank = 32), we\nperformed a grid search. We applied a 5-fold cross-validation to find the best\ncombination of distil-Whisper hyperparameters. Then, we fine-tuned the model\nfor LoRA hyperparameters, achieving an impressive average word error rate of\n3.86% across five folds. This result highlights the model's potential for use\nin the cockpit.", "published": "2025-03-13 22:12:45", "link": "http://arxiv.org/abs/2503.22692v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks", "abstract": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.", "published": "2025-03-13 21:25:38", "link": "http://arxiv.org/abs/2503.10894v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data", "abstract": "Time-series analysis is critical for a wide range of fields such as\nhealthcare, finance, transportation, and energy, among many others. The\npractical applications often involve analyzing time-series data alongside\ncontextual information in the form of natural language to support informed\ndecisions. However, current time-series models are limited in their ability to\nperform reasoning that involves both time-series and their textual content. In\nthis work, we address this gap by introducing \\textit{Chat-TS}, a large\nlanguage model (LLM) based framework, designed to support reasoning over time\nseries and textual data. Unlike traditional models, Chat-TS integrates\ntime-series tokens into LLMs' vocabulary, enhancing its reasoning ability over\nboth modalities without compromising the core natural language capabilities,\nenabling practical analysis and reasoning across modalities. To support\nlearning and evaluation in this setup, we contribute new datasets: the\n\\textit{TS Instruct Training Dataset} which pairs diverse time-series data with\nrelevant text instructions and responses for instruction tuning, the \\textit{TS\nInstruct Question and Answer (QA) Gold Dataset} which provides multiple-choice\nquestions designed to evaluate multimodal reasoning, and a \\textit{TS Instruct\nQuantitative Probing Set} which contains a small subset of the TS Instruct QA\ntasks alongside math and decision-making questions for LLM evaluation. We\ndesigned a training strategy to preserve the inherent reasoning capabilities of\nLLMs while augmenting them for time-series reasoning. Experiments show that\nChat-TS achieves state-of-the-art performance in multi-modal reasoning tasks by\nmaintaining strong natural language proficiency while improving time-series\nreasoning. ~\\footnote{To ensure replicability and facilitate future research,\nall models, datasets, and code will be available at [\\texttt{Github-URL}].}", "published": "2025-03-13 21:05:11", "link": "http://arxiv.org/abs/2503.10883v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SCE: Scalable Consistency Ensembles Make Blackbox Large Language Model Generation More Reliable", "abstract": "Large language models (LLMs) have demonstrated remarkable performance, yet\ntheir diverse strengths and weaknesses prevent any single LLM from achieving\ndominance across all tasks. Ensembling multiple LLMs is a promising approach to\ngenerate reliable responses but conventional ensembling frameworks suffer from\nhigh computational overheads. This work introduces Scalable Consistency\nEnsemble (SCE), an efficient framework for ensembling LLMs by prompting\nconsistent outputs. The SCE framework systematically evaluates and integrates\noutputs to produce a cohesive result through two core components: SCE-CHECK, a\nmechanism that gauges the consistency between response pairs via semantic\nequivalence; and SCE-FUSION, which adeptly merges the highest-ranked consistent\nresponses from SCE-CHECK, to optimize collective strengths and mitigating\npotential weaknesses. To improve the scalability with multiple inference\nqueries, we further propose ``{You Only Prompt Once}'' (YOPO), a novel\ntechnique that reduces the inference complexity of pairwise comparison from\nquadratic to constant time. We perform extensive empirical evaluations on\ndiverse benchmark datasets to demonstrate \\methodName's effectiveness. Notably,\nthe \\saccheckcomponent outperforms conventional baselines with enhanced\nperformance and a significant reduction in computational overhead.", "published": "2025-03-13 20:54:28", "link": "http://arxiv.org/abs/2503.10881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance", "abstract": "We introduce MentalChat16K, an English benchmark dataset combining a\nsynthetic mental health counseling dataset and a dataset of anonymized\ntranscripts from interventions between Behavioral Health Coaches and Caregivers\nof patients in palliative or hospice care. Covering a diverse range of\nconditions like depression, anxiety, and grief, this curated dataset is\ndesigned to facilitate the development and evaluation of large language models\nfor conversational mental health assistance. By providing a high-quality\nresource tailored to this critical domain, MentalChat16K aims to advance\nresearch on empathetic, personalized AI solutions to improve access to mental\nhealth support services. The dataset prioritizes patient privacy, ethical\nconsiderations, and responsible data usage. MentalChat16K presents a valuable\nopportunity for the research community to innovate AI technologies that can\npositively impact mental well-being.", "published": "2025-03-13 20:25:10", "link": "http://arxiv.org/abs/2503.13509v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Towards Understanding Graphical Perception in Large Multimodal Models", "abstract": "Despite the promising results of large multimodal models (LMMs) in complex\nvision-language tasks that require knowledge, reasoning, and perception\nabilities together, we surprisingly found that these models struggle with\nsimple tasks on infographics that require perception only. As existing\nbenchmarks primarily focus on end tasks that require various abilities, they\nprovide limited, fine-grained insights into the limitations of the models'\nperception abilities. To address this gap, we leverage the theory of graphical\nperception, an approach used to study how humans decode visual information\nencoded on charts and graphs, to develop an evaluation framework for analyzing\ngaps in LMMs' perception abilities in charts. With automated task generation\nand response evaluation designs, our framework enables comprehensive and\ncontrolled testing of LMMs' graphical perception across diverse chart types,\nvisual elements, and task types. We apply our framework to evaluate and\ndiagnose the perception capabilities of state-of-the-art LMMs at three\ngranularity levels (chart, visual element, and pixel). Our findings underscore\nseveral critical limitations of current state-of-the-art LMMs, including\nGPT-4o: their inability to (1) generalize across chart types, (2) understand\nfundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities\nof LMMs. The evaluation framework and labeled data are publicly available at\nhttps://github.com/microsoft/lmm-graphical-perception.", "published": "2025-03-13 20:13:39", "link": "http://arxiv.org/abs/2503.10857v1", "categories": ["cs.GR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Who Relies More on World Knowledge and Bias for Syntactic Ambiguity Resolution: Humans or LLMs?", "abstract": "This study explores how recent large language models (LLMs) navigate relative\nclause attachment {ambiguity} and use world knowledge biases for disambiguation\nin six typologically diverse languages: English, Chinese, Japanese, Korean,\nRussian, and Spanish. We describe the process of creating a novel dataset --\nMultiWho -- for fine-grained evaluation of relative clause attachment\npreferences in ambiguous and unambiguous contexts. Our experiments with three\nLLMs indicate that, contrary to humans, LLMs consistently exhibit a preference\nfor local attachment, displaying limited responsiveness to syntactic variations\nor language-specific attachment patterns. Although LLMs performed well in\nunambiguous cases, they rigidly prioritized world knowledge biases, lacking the\nflexibility of human language processing. These findings highlight the need for\nmore diverse, pragmatically nuanced multilingual training to improve LLMs'\nhandling of complex structures and human-like comprehension.", "published": "2025-03-13 19:44:15", "link": "http://arxiv.org/abs/2503.10838v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "It is Too Many Options: Pitfalls of Multiple-Choice Questions in Generative AI and Medical Education", "abstract": "The performance of Large Language Models (LLMs) on multiple-choice question\n(MCQ) benchmarks is frequently cited as proof of their medical capabilities. We\nhypothesized that LLM performance on medical MCQs may in part be illusory and\ndriven by factors beyond medical content knowledge and reasoning capabilities.\nTo assess this, we created a novel benchmark of free-response questions with\npaired MCQs (FreeMedQA). Using this benchmark, we evaluated three\nstate-of-the-art LLMs (GPT-4o, GPT-3.5, and LLama-3-70B-instruct) and found an\naverage absolute deterioration of 39.43% in performance on free-response\nquestions relative to multiple-choice (p = 1.3 * 10-5) which was greater than\nthe human performance decline of 22.29%. To isolate the role of the MCQ format\non performance, we performed a masking study, iteratively masking out parts of\nthe question stem. At 100% masking, the average LLM multiple-choice performance\nwas 6.70% greater than random chance (p = 0.002) with one LLM (GPT-4o)\nobtaining an accuracy of 37.34%. Notably, for all LLMs the free-response\nperformance was near zero. Our results highlight the shortcomings in medical\nMCQ benchmarks for overestimating the capabilities of LLMs in medicine, and,\nbroadly, the potential for improving both human and machine assessments using\nLLM-evaluated free-response questions.", "published": "2025-03-13 19:42:04", "link": "http://arxiv.org/abs/2503.13508v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "NeurIPS 2023 LLM Efficiency Fine-tuning Competition", "abstract": "Our analysis of the NeurIPS 2023 large language model (LLM) fine-tuning\ncompetition revealed the following trend: top-performing models exhibit\nsignificant overfitting on benchmark datasets, mirroring the broader issue of\nbenchmark overfitting on popular leaderboards and that data curation is\nessential in order to get a high performing LLM. The competition, which\nconsisted of two stages - an open evaluation stage with publicly available\ntasks and a closed evaluation stage with unseen tasks - allowed us to assess\nthe generalizability of fine-tuned LLMs. Our results highlight the limitations\nof current benchmark-based evaluation schemes for generative models and\ndemonstrate the need for more robust evaluation methods. Notably, the winning\nsubmissions utilized standard open-source libraries and focused primarily on\ndata curation. To facilitate further research and promote reproducibility, we\nrelease all competition entries, Docker files, and evaluation infrastructure,\nproviding a valuable resource for the community to explore fine-tuning,\noverfitting, and reproducibility in LLMs.", "published": "2025-03-13 19:35:40", "link": "http://arxiv.org/abs/2503.13507v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thinking Machines: A Survey of LLM based Reasoning Strategies", "abstract": "Large Language Models (LLMs) are highly proficient in language-based tasks.\nTheir language capabilities have positioned them at the forefront of the future\nAGI (Artificial General Intelligence) race. However, on closer inspection,\nValmeekam et al. (2024); Zecevic et al. (2023); Wu et al. (2024) highlight a\nsignificant gap between their language proficiency and reasoning abilities.\nReasoning in LLMs and Vision Language Models (VLMs) aims to bridge this gap by\nenabling these models to think and re-evaluate their actions and responses.\nReasoning is an essential capability for complex problem-solving and a\nnecessary step toward establishing trust in Artificial Intelligence (AI). This\nwill make AI suitable for deployment in sensitive domains, such as healthcare,\nbanking, law, defense, security etc. In recent times, with the advent of\npowerful reasoning models like OpenAI O1 and DeepSeek R1, reasoning endowment\nhas become a critical research topic in LLMs. In this paper, we provide a\ndetailed overview and comparison of existing reasoning techniques and present a\nsystematic survey of reasoning-imbued language models. We also study current\nchallenges and present our findings.", "published": "2025-03-13 19:03:41", "link": "http://arxiv.org/abs/2503.10814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ensemble Learning for Large Language Models in Text and Code Generation: A Survey", "abstract": "Generative pretrained transformers (GPT) are the common large language models\n(LLMs) used for generating text from natural language inputs. However, the\nfixed properties of language parameters in individual LLMs can lead to\ninconsistencies in the generated outputs. This limitation also restricts the\nmodels' ability to represent diverse language patterns due to inherent biases.\nMoreover, many powerful LLMs are closed-source. This prevents organizations\nfrom integrating their data into these systems, raising concerns about data\nprivacy and limiting industry applications. Inspired by the successful\napplication of LLM ensemble models in text generation, recent literature has\nalso investigated their potential in code generation. This article reviews\nthese emerging LLM ensemble approaches. Our goal is to enhance readers'\nunderstanding of existing techniques and encourage further research and\npractical implementation, aiming to expand the real-world applications of LLM\nensemble models in both text and code generation. We categorize these\napproaches into seven main methods: weight merging, knowledge fusion, mixture\nof experts, reward ensemble, output ensemble, routing, and cascading. From this\nlist, we focus on four methods and models that show strong performance and\npotential for broader applications. We analyze their modeling steps, training\nmethods, and output features to provide a clear understanding of their\ncapabilities. Our findings highlight the benefits of LLM ensemble techniques.\nThese include better representation of diversity, improved output quality, and\ngreater flexibility in applications. This information offers valuable insights\nfor selecting models for various real-world tasks involving text and code\ngeneration, and potentially applying methods to multimodal LLMs.", "published": "2025-03-13 18:50:57", "link": "http://arxiv.org/abs/2503.13505v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Caricatures: On the Representation of African American Language in Pretraining Corpora", "abstract": "With a combination of quantitative experiments, human judgments, and\nqualitative analyses, we evaluate the quantity and quality of African American\nLanguage (AAL) representation in 12 predominantly English, open-source\npretraining corpora. We specifically focus on the sources, variation, and\nnaturalness of included AAL texts representing the AAL-speaking community. We\nfind that AAL is underrepresented in all evaluated pretraining corpora compared\nto US demographics, constituting as little as 0.007% of documents. We also find\nthat more than 25% of AAL texts in C4 may be inappropriate for LLMs to generate\nand reinforce harmful stereotypes. Finally, we find that most automated\nlanguage, toxicity, and quality filters are more likely to conserve White\nMainstream English (WME) texts over AAL in pretraining corpora.", "published": "2025-03-13 18:31:10", "link": "http://arxiv.org/abs/2503.10789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Charting and Navigating Hugging Face's Model Atlas", "abstract": "As there are now millions of publicly available neural networks, searching\nand analyzing large model repositories becomes increasingly important.\nNavigating so many models requires an atlas, but as most models are poorly\ndocumented charting such an atlas is challenging. To explore the hidden\npotential of model repositories, we chart a preliminary atlas representing the\ndocumented fraction of Hugging Face. It provides stunning visualizations of the\nmodel landscape and evolution. We demonstrate several applications of this\natlas including predicting model attributes (e.g., accuracy), and analyzing\ntrends in computer vision models. However, as the current atlas remains\nincomplete, we propose a method for charting undocumented regions.\nSpecifically, we identify high-confidence structural priors based on dominant\nreal-world model training practices. Leveraging these priors, our approach\nenables accurate mapping of previously undocumented areas of the atlas. We\npublicly release our datasets, code, and interactive atlas.", "published": "2025-03-13 17:59:53", "link": "http://arxiv.org/abs/2503.10633v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems", "abstract": "The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io", "published": "2025-03-13 17:59:32", "link": "http://arxiv.org/abs/2503.10627v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Transformers without Normalization", "abstract": "Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.", "published": "2025-03-13 17:59:06", "link": "http://arxiv.org/abs/2503.10622v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search", "abstract": "We introduce Siege, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Siege expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Siege reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Siege achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.", "published": "2025-03-13 17:57:32", "link": "http://arxiv.org/abs/2503.10619v2", "categories": ["cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.AI"}
{"title": "From TOWER to SPIRE: Adding the Speech Modality to a Text-Only LLM", "abstract": "Large language models (LLMs) have shown remarkable performance and\ngeneralization capabilities across multiple languages and tasks, making them\nvery attractive targets for multi-modality integration (e.g., images or\nspeech). In this work, we extend an existing LLM to the speech modality via\nspeech discretization and continued pre-training. In particular, we are\ninterested in multilingual LLMs, such as TOWER, as their pre-training setting\nallows us to treat discretized speech input as an additional translation\nlanguage. The resulting open-source model, SPIRE, is able to transcribe and\ntranslate English speech input while maintaining TOWER's original performance\non translation-related tasks, showcasing that discretized speech input\nintegration as an additional language is feasible during LLM adaptation. We\nmake our code and models available to the community.", "published": "2025-03-13 17:57:32", "link": "http://arxiv.org/abs/2503.10620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models", "abstract": "Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.", "published": "2025-03-13 17:57:04", "link": "http://arxiv.org/abs/2503.10617v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Keyframe-oriented Vision Token Pruning: Enhancing Efficiency of Large Vision Language Models on Long-Form Video Processing", "abstract": "Vision language models (VLMs) demonstrate strong capabilities in jointly\nprocessing visual and textual data. However, they often incur substantial\ncomputational overhead due to redundant visual information, particularly in\nlong-form video scenarios. Existing approaches predominantly focus on either\nvision token pruning, which may overlook spatio-temporal dependencies, or\nkeyframe selection, which identifies informative frames but discards others,\nthus disrupting contextual continuity. In this work, we propose KVTP\n(Keyframe-oriented Vision Token Pruning), a novel framework that overcomes the\ndrawbacks of token pruning and keyframe selection. By adaptively assigning\npruning rates based on frame relevance to the query, KVTP effectively retains\nessential contextual information while significantly reducing redundant\ncomputation. To thoroughly evaluate the long-form video understanding\ncapacities of VLMs, we curated and reorganized subsets from VideoMME,\nEgoSchema, and NextQA into a unified benchmark named SparseKV-QA that\nhighlights real-world scenarios with sparse but crucial events. Our experiments\nwith VLMs of various scales show that KVTP can reduce token usage by 80%\nwithout compromising spatiotemporal and contextual consistency, significantly\ncutting computation while maintaining the performance. These results\ndemonstrate our approach's effectiveness in efficient long-video processing,\nfacilitating more scalable VLM deployment.", "published": "2025-03-13 17:47:52", "link": "http://arxiv.org/abs/2503.10742v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention", "abstract": "Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.", "published": "2025-03-13 17:46:06", "link": "http://arxiv.org/abs/2503.10602v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search", "abstract": "Vision-Language Models have made significant progress on many\nperception-focused tasks. However, their progress on reasoning-focused tasks\nremains limited due to the lack of high-quality and diverse training data. In\nthis work, we aim to address the scarcity of reasoning-focused multimodal\ndatasets. We propose VisualWebInstruct, a novel approach that leverages search\nengines to create a diverse and high-quality dataset spanning multiple\ndisciplines, including mathematics, physics, finance, and chemistry, etc.\nStarting with a meticulously selected set of 30,000 seed images, we employ\nGoogle Image Search to identify websites containing similar images. We collect\nand process HTML data from over 700K unique URLs. Through a pipeline of content\nextraction, filtering, and synthesis, we construct a dataset of approximately\n900K question-answer (QA) pairs, with 40% consisting of visual QA pairs and the\nremaining comprising text-based QA pairs. Models fine-tuned on\nVisualWebInstruct demonstrate significant performance improvements: (1)\nfine-tuning on Llava-OV results in 10-20 absolute points improvement across\nbenchmarks, and (2) fine-tuning from MAmmoTH-VL yields a 5 absolute points gain\nacross benchmarks. Our best model, MAmmoTH-VL2, achieves state-of-the-art\nperformance within the 10B parameter class on MMMU-Pro (40.7), MathVerse\n(42.6), and DynaMath (55.7). These results highlight the effectiveness of our\ndataset in enhancing the reasoning capabilities of vision-language models for\ncomplex multimodal tasks.", "published": "2025-03-13 17:32:48", "link": "http://arxiv.org/abs/2503.10582v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More", "abstract": "This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.", "published": "2025-03-13 16:56:47", "link": "http://arxiv.org/abs/2503.10542v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7; I.2.8; I.5.0"], "primary_category": "cs.LG"}
{"title": "The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory", "abstract": "High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.", "published": "2025-03-13 16:47:07", "link": "http://arxiv.org/abs/2503.10533v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set", "abstract": "Discourse understanding is essential for many NLP tasks, yet most existing\nwork remains constrained by framework-dependent discourse representations. This\nwork investigates whether large language models (LLMs) capture discourse\nknowledge that generalizes across languages and frameworks. We address this\nquestion along two dimensions: (1) developing a unified discourse relation\nlabel set to facilitate cross-lingual and cross-framework discourse analysis,\nand (2) probing LLMs to assess whether they encode generalizable discourse\nabstractions. Using multilingual discourse relation classification as a\ntestbed, we examine a comprehensive set of 23 LLMs of varying sizes and\nmultilingual capabilities. Our results show that LLMs, especially those with\nmultilingual training corpora, can generalize discourse information across\nlanguages and frameworks. Further layer-wise analyses reveal that language\ngeneralization at the discourse level is most salient in the intermediate\nlayers. Lastly, our error analysis provides an account of challenging relation\nclasses.", "published": "2025-03-13 16:20:25", "link": "http://arxiv.org/abs/2503.10515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation", "abstract": "Traditional benchmarks struggle to evaluate increasingly sophisticated\nlanguage models in multilingual and culturally diverse contexts. To address\nthis gap, we introduce MMLU-ProX, a comprehensive multilingual benchmark\ncovering 13 typologically diverse languages with approximately 11,829 questions\nper language. Building on the challenging reasoning-focused design of MMLU-Pro,\nour framework employs a semi-automatic translation process: translations\ngenerated by state-of-the-art large language models (LLMs) are rigorously\nevaluated by expert annotators to ensure conceptual accuracy, terminological\nconsistency, and cultural relevance. We comprehensively evaluate 25\nstate-of-the-art LLMs using 5-shot chain-of-thought (CoT) and zero-shot\nprompting strategies, analyzing their performance across linguistic and\ncultural boundaries. Our experiments reveal consistent performance degradation\nfrom high-resource languages to lower-resource ones, with the best models\nachieving over 70% accuracy on English but dropping to around 40% for languages\nlike Swahili, highlighting persistent gaps in multilingual capabilities despite\nrecent advances. MMLU-ProX is an ongoing project; we are expanding our\nbenchmark by incorporating additional languages and evaluating more language\nmodels to provide a more comprehensive assessment of multilingual capabilities.", "published": "2025-03-13 15:59:20", "link": "http://arxiv.org/abs/2503.10497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Source-primed Multi-turn Conversation Helps Large Language Models Translate Documents", "abstract": "LLMs have paved the way for truly simple document-level machine translation,\nbut challenges such as omission errors remain. In this paper, we study a simple\nmethod for handling document-level machine translation, by leveraging previous\ncontexts in a multi-turn conversational manner. Specifically, by decomposing\ndocuments into segments and iteratively translating them while maintaining\nprevious turns, this method ensures coherent translations without additional\ntraining, and can fully re-use the KV cache of previous turns thus minimizing\ncomputational overhead. We further propose a `source-primed' method that first\nprovides the whole source document before multi-turn translation. We\nempirically show this multi-turn method outperforms both translating entire\ndocuments in a single turn and translating each segment independently according\nto multiple automatic metrics in representative LLMs, establishing a strong\nbaseline for document-level translation using LLMs.", "published": "2025-03-13 15:57:50", "link": "http://arxiv.org/abs/2503.10494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions", "abstract": "Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.", "published": "2025-03-13 15:54:26", "link": "http://arxiv.org/abs/2503.10486v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning", "abstract": "Recent advances in large vision-language models (LVLMs) have shown promise\nfor embodied task planning, yet they struggle with fundamental challenges like\ndependency constraints and efficiency. Existing approaches either solely\noptimize action selection or leverage world models during inference,\noverlooking the benefits of learning to model the world as a way to enhance\nplanning capabilities. We propose Dual Preference Optimization (D$^2$PO), a new\nlearning framework that jointly optimizes state prediction and action selection\nthrough preference learning, enabling LVLMs to understand environment dynamics\nfor better planning. To automatically collect trajectories and stepwise\npreference data without human annotation, we introduce a tree search mechanism\nfor extensive exploration via trial-and-error. Extensive experiments on\nVoTa-Bench demonstrate that our D$^2$PO-based method significantly outperforms\nexisting methods and GPT-4o when applied to Qwen2-VL (7B), LLaVA-1.6 (7B), and\nLLaMA-3.2 (11B), achieving superior task success rates with more efficient\nexecution paths.", "published": "2025-03-13 15:49:56", "link": "http://arxiv.org/abs/2503.10480v1", "categories": ["cs.CL", "cs.CV", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Statistical Analysis of Sentence Structures through ASCII, Lexical Alignment and PCA", "abstract": "While utilizing syntactic tools such as parts-of-speech (POS) tagging has\nhelped us understand sentence structures and their distribution across diverse\ncorpora, it is quite complex and poses a challenge in natural language\nprocessing (NLP). This study focuses on understanding sentence structure\nbalance - usages of nouns, verbs, determiners, etc - harmoniously without\nrelying on such tools. It proposes a novel statistical method that uses\nAmerican Standard Code for Information Interchange (ASCII) codes to represent\ntext of 11 text corpora from various sources and their lexical category\nalignment after using their compressed versions through PCA, and analyzes the\nresults through histograms and normality tests such as Shapiro-Wilk and\nAnderson-Darling Tests. By focusing on ASCII codes, this approach simplifies\ntext processing, although not replacing any syntactic tools but complementing\nthem by offering it as a resource-efficient tool for assessing text balance.\nThe story generated by Grok shows near normality indicating balanced sentence\nstructures in LLM outputs, whereas 4 out of the remaining 10 pass the normality\ntests. Further research could explore potential applications in text quality\nevaluation and style analysis with syntactic integration for more broader\ntasks.", "published": "2025-03-13 15:42:44", "link": "http://arxiv.org/abs/2503.10470v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond", "abstract": "This paper introduces Light-R1, an open-source suite for training long\nreasoning models using reproducible and cost-effective methodology. Given the\nproprietary nature of data used in the DeepSeek-R1 series, we develop an\nalternative approach leveraging exclusively public data and models. Our\ncurriculum training progressively increases data difficulty, combined with\nmulti-staged post-training. Our Light-R1-32B model, trained from\nQwen2.5-32B-Instruct, outperforms DeepSeek-R1-Distill-Qwen-32B in math\nreasoning.\n  Experimental results show that this curriculum approach becomes more\neffective when distinct, diverse datasets are available for different training\nstages: fine-tuning DeepSeek-R1-Distilled models (pre-tuned by DeepSeek team on\nproprietary data) with 3,000 challenging examples from our curriculum dataset\nyielded state-of-the-art 7B and 14B models, while the 32B model,\nLight-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.\n  Furthermore, we extend our work by applying GRPO on long reasoning models.\nOur final Light-R1-14B-DS achieves SOTA performance among 14B models in math,\nwith AIME24 \\& 25 scores of 74.0 and 60.2 respectively, surpassing many 32B\nmodels and DeepSeek-R1-Distill-Llama-70B. Despite math-focused training,\nLight-R1-14B-DS demonstrates strong cross-domain generalization.\n  Light-R1 represents a significant advancement in making sophisticated\nreasoning models more accessible and implementable in real-world applications.\nOur models, training data and code have been made available at\nhttps://github.com/Qihoo360/Light-R1.", "published": "2025-03-13 15:29:22", "link": "http://arxiv.org/abs/2503.10460v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation", "abstract": "The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.", "published": "2025-03-13 15:18:56", "link": "http://arxiv.org/abs/2503.10452v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language Models", "abstract": "In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave)\nbeam prediction framework leveraging large language models (LLMs) to address\nthe challenges of high training overhead and latency in mmWave communication\nsystems. By combining computer vision (CV) with LLMs' cross-modal reasoning\ncapabilities, the framework extracts user equipment (UE) positional features\nfrom RGB images and aligns visual-temporal features with LLMs' semantic space\nthrough reprogramming techniques. Evaluated on a realistic\nvehicle-to-infrastructure (V2I) scenario, the proposed method achieves 61.01%\ntop-1 accuracy and 97.39% top-3 accuracy in standard prediction tasks,\nsignificantly outperforming traditional deep learning models. In few-shot\nprediction scenarios, the performance degradation is limited to 12.56% (top-1)\nand 5.55% (top-3) from time sample 1 to 10, demonstrating superior prediction\ncapability.", "published": "2025-03-13 14:55:59", "link": "http://arxiv.org/abs/2503.10432v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VisTW: Benchmarking Vision-Language Models for Traditional Chinese in Taiwan", "abstract": "In this paper, we propose a comprehensive evaluation benchmark for Visual\nLanguage Models (VLM) in Traditional Chinese. Our evaluation suite, the first\nof its kind, contains two complementary components: (1) VisTW-MCQ, a collection\nof manually curated exam multi-choice questions from 21 academic subjects\ndesigned to test the broad knowledge and reasoning capabilities of VLMs; and\n(2) VisTW-Dialogue, an open dialogue benchmark comprising 131 image-question\npairs manually created to evaluate VLMs' ability in free-form dialogue\ngeneration within Taiwanese cultural contexts. These benchmarks address a\ncritical gap in the evaluation landscape, where existing benchmarks\npredominantly focus on English or Simplified Chinese, neglecting the unique\nlinguistic and cultural aspects of Traditional Chinese used in regions like\nTaiwan and Hong Kong. Our analysis reveals significant performance differences\nacross various VLMs and highlights specific challenges in processing\nTraditional Chinese visual content.", "published": "2025-03-13 14:49:35", "link": "http://arxiv.org/abs/2503.10427v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the Logical Capabilities of Large Language Models via Out-of-Context Representation Learning", "abstract": "We study the capabilities of Large Language Models (LLM) on binary relations,\na ubiquitous concept in math employed in most reasoning, math and logic\nbenchmarks. This work focuses on equality, inequality, and inclusion, along\nwith the properties they satisfy, such as ir/reflexivity, a/symmetry,\ntransitivity, and logical complexity (e.g., number of reasoning ``hops''). We\npropose an alternative to in-context learning that trains only the\nrepresentations of newly introduced tokens, namely out-of-context\nrepresentation learning. This method mitigates linguistic biases already\npresent in a model and, differently from in-context learning, does not rely on\nexternal information or illustrations. We argue out-of-context representation\nlearning as a better alternative to in-context learning and fine-tuning to\nevaluate the capabilities of LLMs on logic tasks that are the building blocks\nof more complex reasoning benchmarks.", "published": "2025-03-13 14:32:30", "link": "http://arxiv.org/abs/2503.10408v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "G-Boost: Boosting Private SLMs with General LLMs", "abstract": "Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.", "published": "2025-03-13 13:47:03", "link": "http://arxiv.org/abs/2503.10367v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do I look like a `cat.n.01` to you? A Taxonomy Image Generation Benchmark", "abstract": "This paper explores the feasibility of using text-to-image models in a\nzero-shot setup to generate images for taxonomy concepts. While text-based\nmethods for taxonomy enrichment are well-established, the potential of the\nvisual dimension remains unexplored. To address this, we propose a\ncomprehensive benchmark for Taxonomy Image Generation that assesses models'\nabilities to understand taxonomy concepts and generate relevant, high-quality\nimages. The benchmark includes common-sense and randomly sampled WordNet\nconcepts, alongside the LLM generated predictions. The 12 models are evaluated\nusing 9 novel taxonomy-related text-to-image metrics and human feedback.\nMoreover, we pioneer the use of pairwise evaluation with GPT-4 feedback for\nimage generation. Experimental results show that the ranking of models differs\nsignificantly from standard T2I tasks. Playground-v2 and FLUX consistently\noutperform across metrics and subsets and the retrieval-based approach performs\npoorly. These findings highlight the potential for automating the curation of\nstructured data resources.", "published": "2025-03-13 13:37:54", "link": "http://arxiv.org/abs/2503.10357v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent Document Summarization", "abstract": "Automatic patent summarization approaches that help in the patent analysis\nand comprehension procedure are in high demand due to the colossal growth of\ninnovations. The development of natural language processing (NLP), text mining,\nand deep learning has notably amplified the efficacy of text summarization\nmodels for abundant types of documents. Summarizing patent text remains a\npertinent challenge due to the labyrinthine writing style of these documents,\nwhich includes technical and legal intricacies. Additionally, these patent\ndocument contents are considerably lengthier than archetypal documents, which\nintricates the process of extracting pertinent information for summarization.\nEmbodying extractive and abstractive text summarization methodologies into a\nhybrid framework, this study proposes a system for efficiently creating\nabstractive summaries of patent records. The procedure involves leveraging the\nLexRank graph-based algorithm to retrieve the important sentences from input\nparent texts, then utilizing a Bidirectional Auto-Regressive Transformer (BART)\nmodel that has been fine-tuned using Low-Ranking Adaptation (LoRA) for\nproducing text summaries. This is accompanied by methodical testing and\nevaluation strategies. Furthermore, the author employed certain meta-learning\ntechniques to achieve Domain Generalization (DG) of the abstractive component\nacross multiple patent fields.", "published": "2025-03-13 13:30:54", "link": "http://arxiv.org/abs/2503.10354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Trends for Modern Machine Translation with Large Reasoning Models", "abstract": "Recent advances in Large Reasoning Models (LRMs), particularly those\nleveraging Chain-of-Thought reasoning (CoT), have opened brand new possibility\nfor Machine Translation (MT). This position paper argues that LRMs\nsubstantially transformed traditional neural MT as well as LLMs-based MT\nparadigms by reframing translation as a dynamic reasoning task that requires\ncontextual, cultural, and linguistic understanding and reasoning. We identify\nthree foundational shifts: 1) contextual coherence, where LRMs resolve\nambiguities and preserve discourse structure through explicit reasoning over\ncross-sentence and complex context or even lack of context; 2) cultural\nintentionality, enabling models to adapt outputs by inferring speaker intent,\naudience expectations, and socio-linguistic norms; 3) self-reflection, LRMs can\nperform self-reflection during the inference time to correct the potential\nerrors in translation especially extremely noisy cases, showing better\nrobustness compared to simply mapping X->Y translation. We explore various\nscenarios in translation including stylized translation, document-level\ntranslation and multimodal translation by showcasing empirical examples that\ndemonstrate the superiority of LRMs in translation. We also identify several\ninteresting phenomenons for LRMs for MT including auto-pivot translation as\nwell as the critical challenges such as over-localisation in translation and\ninference efficiency. In conclusion, we think that LRMs redefine translation\nsystems not merely as text converters but as multilingual cognitive agents\ncapable of reasoning about meaning beyond the text. This paradigm shift reminds\nus to think of problems in translation beyond traditional translation scenarios\nin a much broader context with LRMs - what we can achieve on top of it.", "published": "2025-03-13 13:27:53", "link": "http://arxiv.org/abs/2503.10351v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KV-Distill: Nearly Lossless Learnable Context Compression for LLMs", "abstract": "Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.", "published": "2025-03-13 13:15:28", "link": "http://arxiv.org/abs/2503.10337v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions", "abstract": "Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.", "published": "2025-03-13 13:07:51", "link": "http://arxiv.org/abs/2503.10331v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy for Analysing Wiki Deletion Discussions", "abstract": "Automated content moderation for collaborative knowledge hubs like Wikipedia\nor Wikidata is an important yet challenging task due to multiple factors. In\nthis paper, we construct a database of discussions happening around articles\nmarked for deletion in several Wikis and in three languages, which we then use\nto evaluate a range of LMs on different tasks (from predicting the outcome of\nthe discussion to identifying the implicit policy an individual comment might\nbe pointing to). Our results reveal, among others, that discussions leading to\ndeletion are easier to predict, and that, surprisingly, self-produced tags\n(keep, delete or redirect) don't always help guiding the classifiers,\npresumably because of users' hesitation or deliberation within comments.", "published": "2025-03-13 12:07:35", "link": "http://arxiv.org/abs/2503.10294v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VisualPRM: An Effective Process Reward Model for Multimodal Reasoning", "abstract": "We introduce VisualPRM, an advanced multimodal Process Reward Model (PRM)\nwith 8B parameters, which improves the reasoning abilities of existing\nMultimodal Large Language Models (MLLMs) across different model scales and\nfamilies with Best-of-N (BoN) evaluation strategies. Specifically, our model\nimproves the reasoning performance of three types of MLLMs and four different\nmodel scales. Even when applied to the highly capable InternVL2.5-78B, it\nachieves a 5.9-point improvement across seven multimodal reasoning benchmarks.\nExperimental results show that our model exhibits superior performance compared\nto Outcome Reward Models and Self-Consistency during BoN evaluation. To\nfacilitate the training of multimodal PRMs, we construct a multimodal process\nsupervision dataset VisualPRM400K using an automated data pipeline. For the\nevaluation of multimodal PRMs, we propose VisualProcessBench, a benchmark with\nhuman-annotated step-wise correctness labels, to measure the abilities of PRMs\nto detect erroneous steps in multimodal reasoning tasks. We hope that our work\ncan inspire more future research and contribute to the development of MLLMs.\nOur model, data, and benchmark are released in\nhttps://internvl.github.io/blog/2025-03-13-VisualPRM/.", "published": "2025-03-13 12:03:37", "link": "http://arxiv.org/abs/2503.10291v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DarkBench: Benchmarking Dark Patterns in Large Language Models", "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design\npatterns--manipulative techniques that influence user behavior--in interactions\nwith large language models (LLMs). Our benchmark comprises 660 prompts across\nsix categories: brand bias, user retention, sycophancy, anthropomorphism,\nharmful generation, and sneaking. We evaluate models from five leading\ncompanies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs\nare explicitly designed to favor their developers' products and exhibit\nuntruthful communication, among other manipulative behaviors. Companies\ndeveloping LLMs should recognize and mitigate the impact of dark design\npatterns to promote more ethical AI.", "published": "2025-03-13 11:48:42", "link": "http://arxiv.org/abs/2503.10728v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models", "abstract": "Ensuring transparency of data practices related to personal information is a\nfundamental requirement under the General Data Protection Regulation (GDPR),\nparticularly as mandated by Articles 13 and 14. However, assessing compliance\nat scale remains a challenge due to the complexity and variability of privacy\npolicy language. Manual audits are resource-intensive and inconsistent, while\nexisting automated approaches lack the granularity needed to capture nuanced\ntransparency disclosures.\n  In this paper, we introduce a large language model (LLM)-based framework for\nword-level GDPR transparency compliance annotation. Our approach comprises a\ntwo-stage annotation pipeline that combines initial LLM-based annotation with a\nself-correction mechanism for iterative refinement. This annotation pipeline\nenables the systematic identification and fine-grained annotation of\ntransparency-related content in privacy policies, aligning with 21 GDPR-derived\ntransparency requirements. To enable large-scale analysis, we compile a dataset\nof 703,791 English-language policies, from which we generate a sample of 200\nmanually annotated privacy policies.\n  To evaluate our approach, we introduce a two-tiered methodology assessing\nboth label- and span-level annotation performance. We conduct a comparative\nanalysis of eight high-profile LLMs, providing insights into their\neffectiveness in identifying GDPR transparency disclosures. Our findings\ncontribute to advancing the automation of GDPR compliance assessments and\nprovide valuable resources for future research in privacy policy analysis.", "published": "2025-03-13 11:41:25", "link": "http://arxiv.org/abs/2503.10727v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Expanded Massive Multilingual Dataset for High-Performance Language Technologies", "abstract": "Training state-of-the-art large language models requires vast amounts of\nclean and diverse textual data. However, building suitable multilingual\ndatasets remains a challenge. In this work, we present HPLT v2, a collection of\nhigh-quality multilingual monolingual and parallel corpora. The monolingual\nportion of the data contains 8T tokens covering 193 languages, while the\nparallel data contains 380M sentence pairs covering 51 languages. We document\nthe entire data pipeline and release the code to reproduce it. We provide\nextensive analysis of the quality and characteristics of our data. Finally, we\nevaluate the performance of language models and machine translation systems\ntrained on HPLT v2, demonstrating its value.", "published": "2025-03-13 11:24:09", "link": "http://arxiv.org/abs/2503.10267v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MinorBench: A hand-built benchmark for content-based risks for children", "abstract": "Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.", "published": "2025-03-13 10:34:43", "link": "http://arxiv.org/abs/2503.10242v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ARLED: Leveraging LED-based ARMAN Model for Abstractive Summarization of Persian Long Documents", "abstract": "The increasing volume of textual data poses challenges in reading and\ncomprehending large documents, particularly for scholars who need to extract\nuseful information from research articles. Automatic text summarization has\nemerged as a powerful tool to condense lengthy documents into concise and\ninformative summaries. Depending on the approach used, text summarization can\nbe categorized as either extractive or abstractive. While extractive methods\nare commonly used due to their simplicity, they often miss important\ninformation. On the other hand, Abstractive Summarization can generate more\ncoherent and informative summaries by understanding the underlying meaning of\nthe text. Abstractive techniques have gained attention in various languages,\nand recent advancements have been achieved through pre-training models such as\nBERT, BART, and T5. However, the challenge of summarizing long documents\nremains, and alternative models like Longformer have been introduced to address\nthis limitation. In this context, this paper focuses on abstractive\nsummarization in the Persian language. The authors introduce a new dataset of\n300,000 full-text Persian papers obtained from the Ensani website and apply the\nARMAN model, based on the Longformer architecture, to generate summaries. The\nexperimental results demonstrate promising performance in Persian text\nsummarization. The paper provides a comprehensive overview of related work,\ndiscusses the methodology, presents the experimental results, and concludes\nwith future research directions.", "published": "2025-03-13 10:16:46", "link": "http://arxiv.org/abs/2503.10233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RankPO: Preference Optimization for Job-Talent Matching", "abstract": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.", "published": "2025-03-13 10:14:37", "link": "http://arxiv.org/abs/2503.10723v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "R.U.Psycho? Robust Unified Psychometric Testing of Language Models", "abstract": "Generative language models are increasingly being subjected to psychometric\nquestionnaires intended for human testing, in efforts to establish their\ntraits, as benchmarks for alignment, or to simulate participants in social\nscience experiments. While this growing body of work sheds light on the\nlikeness of model responses to those of humans, concerns are warranted\nregarding the rigour and reproducibility with which these experiments may be\nconducted. Instabilities in model outputs, sensitivity to prompt design,\nparameter settings, and a large number of available model versions increase\ndocumentation requirements. Consequently, generalization of findings is often\ncomplex and reproducibility is far from guaranteed. In this paper, we present\nR.U.Psycho, a framework for designing and running robust and reproducible\npsychometric experiments on generative language models that requires limited\ncoding expertise. We demonstrate the capability of our framework on a variety\nof psychometric questionnaires, which lend support to prior findings in the\nliterature. R.U.Psycho is available as a Python package at\nhttps://github.com/julianschelb/rupsycho.", "published": "2025-03-13 10:12:34", "link": "http://arxiv.org/abs/2503.10229v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the validity of new paradigmatic complexity measures as criterial features for proficiency in L2 writings in English", "abstract": "This article addresses Second Language (L2) writing development through an\ninvestigation of new grammatical and structural complexity metrics. We explore\nthe paradigmatic production in learner English by linking language functions to\nspecific grammatical paradigms. Using the EFCAMDAT as a gold standard and a\ncorpus of French learners as an external test set, we employ a supervised\nlearning framework to operationalise and evaluate seven microsystems. We show\nthat learner levels are associated with the seven microsystems (MS). Using\nordinal regression modelling for evaluation, the results show that all MS are\nsignificant but yield a low impact if taken individually. However, their\ninfluence is shown to be impactful if taken as a group. These microsystems and\ntheir measurement method suggest that it is possible to use them as part of\nbroader-purpose CALL systems focused on proficiency assessment.", "published": "2025-03-13 10:01:07", "link": "http://arxiv.org/abs/2503.10220v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive Inner Speech-Text Alignment for LLM-based Speech Translation", "abstract": "Recent advancement of large language models (LLMs) has led to significant\nbreakthroughs across various tasks, laying the foundation for the development\nof LLM-based speech translation systems. Existing methods primarily focus on\naligning inputs and outputs across modalities while overlooking deeper semantic\nalignment within model representations. To address this limitation, we propose\nan Adaptive Inner Speech-Text Alignment (AI-STA) method to bridge the modality\ngap by explicitly aligning speech and text representations at selected layers\nwithin LLMs. To achieve this, we leverage the optimal transport (OT) theory to\nquantify fine-grained representation discrepancies between speech and text.\nFurthermore, we utilize the cross-modal retrieval technique to identify the\nlayers that are best suited for alignment and perform joint training on these\nlayers. Experimental results on speech translation (ST) tasks demonstrate that\nAI-STA significantly improves the translation performance of large speech-text\nmodels (LSMs), outperforming previous state-of-the-art approaches. Our findings\nhighlight the importance of inner-layer speech-text alignment in LLMs and\nprovide new insights into enhancing cross-modal learning.", "published": "2025-03-13 09:54:35", "link": "http://arxiv.org/abs/2503.10211v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Red Teaming Contemporary AI Models: Insights from Spanish and Basque Perspectives", "abstract": "The battle for AI leadership is on, with OpenAI in the United States and\nDeepSeek in China as key contenders. In response to these global trends, the\nSpanish government has proposed ALIA, a public and transparent AI\ninfrastructure incorporating small language models designed to support Spanish\nand co-official languages such as Basque. This paper presents the results of\nRed Teaming sessions, where ten participants applied their expertise and\ncreativity to manually test three of the latest models from these\ninitiatives$\\unicode{x2013}$OpenAI o3-mini, DeepSeek R1, and ALIA\nSalamandra$\\unicode{x2013}$focusing on biases and safety concerns. The results,\nbased on 670 conversations, revealed vulnerabilities in all the models under\ntest, with biased or unsafe responses ranging from 29.5% in o3-mini to 50.6% in\nSalamandra. These findings underscore the persistent challenges in developing\nreliable and trustworthy AI systems, particularly those intended to support\nSpanish and Basque languages.", "published": "2025-03-13 09:27:24", "link": "http://arxiv.org/abs/2503.10192v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "PRISM: Preference Refinement via Implicit Scene Modeling for 3D Vision-Language Preference-Based Reinforcement Learning", "abstract": "We propose PRISM, a novel framework designed to overcome the limitations of\n2D-based Preference-Based Reinforcement Learning (PBRL) by unifying 3D point\ncloud modeling and future-aware preference refinement. At its core, PRISM\nadopts a 3D Point Cloud-Language Model (3D-PC-LLM) to mitigate occlusion and\nviewpoint biases, ensuring more stable and spatially consistent preference\nsignals. Additionally, PRISM leverages Chain-of-Thought (CoT) reasoning to\nincorporate long-horizon considerations, thereby preventing the short-sighted\nfeedback often seen in static preference comparisons. In contrast to\nconventional PBRL techniques, this integration of 3D perception and\nfuture-oriented reasoning leads to significant gains in preference agreement\nrates, faster policy convergence, and robust generalization across unseen\nrobotic environments. Our empirical results, spanning tasks such as robotic\nmanipulation and autonomous navigation, highlight PRISM's potential for\nreal-world applications where precise spatial understanding and reliable\nlong-term decision-making are critical. By bridging 3D geometric awareness with\nCoT-driven preference modeling, PRISM establishes a comprehensive foundation\nfor scalable, human-aligned reinforcement learning.", "published": "2025-03-13 08:58:10", "link": "http://arxiv.org/abs/2503.10177v2", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "\"Well, Keep Thinking\": Enhancing LLM Reasoning with Adaptive Injection Decoding", "abstract": "Large language models (LLMs) exhibit strong reasoning abilities, often\nattributed to few-shot or zero-shot chain-of-thought (CoT) prompting. While\neffective, these methods require labor-intensive prompt engineering, raising\nthe question of whether reasoning can be induced without reliance on explicit\nprompts. In this work, we unlock the reasoning capabilities of LLMs without\nexplicit prompting. Inspired by zero-shot CoT and CoT-decoding, we propose a\nnovel decoding strategy that systematically nudges LLMs to continue reasoning,\nthereby preventing immature reasoning processes. Specifically, we monitor the\nmodel's generation and inject a designated phrase whenever it is likely to\nconclude its response prematurely, before completing the reasoning process. Our\nexperimental evaluations on diverse reasoning benchmarks demonstrate that our\nproposed strategy substantially improves LLM reasoning capabilities,\nhighlighting the potential of decoding-based interventions as an alternative to\ntraditional prompting techniques.", "published": "2025-03-13 08:46:32", "link": "http://arxiv.org/abs/2503.10167v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Generation with Hierarchical Knowledge", "abstract": "Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.", "published": "2025-03-13 08:22:31", "link": "http://arxiv.org/abs/2503.10150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AttentionRAG: Attention-Guided Context Pruning in Retrieval-Augmented Generation", "abstract": "While RAG demonstrates remarkable capabilities in LLM applications, its\neffectiveness is hindered by the ever-increasing length of retrieved contexts,\nwhich introduces information redundancy and substantial computational overhead.\nExisting context pruning methods, such as LLMLingua, lack contextual awareness\nand offer limited flexibility in controlling compression rates, often resulting\nin either insufficient pruning or excessive information loss. In this paper, we\npropose AttentionRAG, an attention-guided context pruning method for RAG\nsystems. The core idea of AttentionRAG lies in its attention focus mechanism,\nwhich reformulates RAG queries into a next-token prediction paradigm. This\nmechanism isolates the query's semantic focus to a single token, enabling\nprecise and efficient attention calculation between queries and retrieved\ncontexts. Extensive experiments on LongBench and Babilong benchmarks show that\nAttentionRAG achieves up to 6.3$\\times$ context compression while outperforming\nLLMLingua methods by around 10\\% in key metrics.", "published": "2025-03-13 08:22:28", "link": "http://arxiv.org/abs/2503.10720v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scalable Evaluation of Online Moderation Strategies via Synthetic Simulations", "abstract": "Despite the ever-growing importance of online moderation, there has been no\nlarge-scale study evaluating the effectiveness of alternative moderation\nstrategies. This is largely due to the lack of appropriate datasets, and the\ndifficulty of getting human discussants, moderators, and evaluators involved in\nmultiple experiments. In this paper, we propose a methodology for leveraging\nsynthetic experiments performed exclusively by Large Language Models (LLMs) to\ninitially bypass the need for human participation in experiments involving\nonline moderation. We evaluate six LLM moderation configurations; two currently\nused real-life moderation strategies (guidelines issued for human moderators\nfor online moderation and real-life facilitation), two baseline strategies\n(guidelines elicited for LLM alignment work, and LLM moderation with minimal\nprompting) a baseline with no moderator at all, as well as our own proposed\nstrategy inspired by a Reinforcement Learning (RL) formulation of the problem.\nWe find that our own moderation strategy significantly outperforms established\nmoderation guidelines, as well as out-of-the-box LLM moderation. We also find\nthat smaller LLMs, with less intensive instruction-tuning, can create more\nvaried discussions than larger models. In order to run these experiments, we\ncreate and release an efficient, purpose-built, open-source Python framework,\ndubbed \"SynDisco\" to easily simulate hundreds of discussions using LLM\nuser-agents and moderators. Additionally, we release the Virtual Moderation\nDataset (VMD), a large dataset of LLM-generated and LLM-annotated discussions,\ngenerated by three families of open-source LLMs accompanied by an exploratory\nanalysis of the dataset.", "published": "2025-03-13 08:13:07", "link": "http://arxiv.org/abs/2503.16505v1", "categories": ["cs.HC", "cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.HC"}
{"title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding", "abstract": "Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.", "published": "2025-03-13 07:55:38", "link": "http://arxiv.org/abs/2503.10135v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cognitive-Mental-LLM: Evaluating Reasoning in Large Language Models for Mental Health Prediction via Online Text", "abstract": "Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.", "published": "2025-03-13 06:42:37", "link": "http://arxiv.org/abs/2503.10095v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping", "abstract": "This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.", "published": "2025-03-13 06:41:26", "link": "http://arxiv.org/abs/2503.10094v1", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model", "abstract": "Reinforcement Learning (RL) algorithms for safety alignment of Large Language\nModels (LLMs), such as Direct Preference Optimization (DPO), encounter the\nchallenge of distribution shift. Current approaches typically address this\nissue through online sampling from the target policy, which requires\nsignificant computational resources. In this paper, we hypothesize that during\noff-policy training, while the ranking order of output generated by policy\nchanges, their overall distribution remains relatively stable. This stability\nallows the transformation of the sampling process from the target policy into a\nre-ranking of preference data. Building on this hypothesis, We propose a new\nframework that leverages the model's intrinsic safety judgment capability to\nextract reward signals, which are then used to calculate label confidence for\npreferences reordering. Extensive experimental results and theoretical analysis\ndemonstrate that the proposed method effectively addresses the distribution\nshift issue, remarkably enhancing the safety performance while reducing about\n300x computational overheads.", "published": "2025-03-13 06:40:34", "link": "http://arxiv.org/abs/2503.10093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "abstract": "This survey investigates foundational technologies essential for developing\neffective Large Language Model (LLM)-based multi-agent systems. Aiming to\nanswer how best to optimize these systems for collaborative, dynamic\nenvironments, we focus on four critical areas: Architecture, Memory, Planning,\nand Technologies/Frameworks. By analyzing recent advancements and their\nlimitations - such as scalability, real-time response challenges, and agent\ncoordination constraints, we provide a detailed view of the technological\nlandscape. Frameworks like the Mixture of Agents architecture and the ReAct\nplanning model exemplify current innovations, showcasing improvements in role\nassignment and decision-making. This review synthesizes key strengths and\npersistent challenges, offering practical recommendations to enhance system\nscalability, agent collaboration, and adaptability. Our findings provide a\nroadmap for future research, supporting the creation of robust, efficient\nmulti-agent systems that advance both individual agent performance and\ncollective system resilience.", "published": "2025-03-13 06:17:50", "link": "http://arxiv.org/abs/2504.01963v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Why Does Your CoT Prompt (Not) Work? Theoretical Analysis of Prompt Space Complexity, its Interaction with Answer Space During CoT Reasoning with LLMs: A Recurrent Perspective", "abstract": "Despite the remarkable successes of Large Language Models (LLMs), their\nfundamental Transformer architecture possesses inherent theoretical limitations\nthat restrict their capability to handle reasoning tasks with increasing\ncomputational complexity. Chain-of-Thought (CoT) prompting has emerged as a\npractical solution, supported by several theoretical studies. However, current\nCoT-based methods (including ToT, GoT, etc.) generally adopt a\n\"one-prompt-fits-all\" strategy, using fixed templates (e.g., \"think step by\nstep\") across diverse reasoning tasks. This method forces models to navigate an\nextremely complex prompt space to identify effective reasoning paths. The\ncurrent prompt designing research are also heavily relying on trial-and-error\nrather than theoretically informed guidance. In this paper, we provide a\nrigorous theoretical analysis of the complexity and interplay between two\ncrucial spaces: the prompt space (the space of potential prompt structures) and\nthe answer space (the space of reasoning solutions generated by LLMs) in CoT\nreasoning. We demonstrate how reliance on a single universal prompt (e.g. think\nstep by step) can negatively impact the theoretical computability of LLMs,\nillustrating that prompt complexity directly influences the structure and\neffectiveness of the navigation in answer space. Our analysis highlights that\nsometimes human supervision is critical for efficiently navigating the prompt\nspace. We theoretically and empirically show that task-specific prompting\nsignificantly outperforms unsupervised prompt generation, emphasizing the\nnecessity of thoughtful human guidance in CoT prompting.", "published": "2025-03-13 06:11:10", "link": "http://arxiv.org/abs/2503.10084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information Density Principle for MLLM Benchmarks", "abstract": "With the emergence of Multimodal Large Language Models (MLLMs), hundreds of\nbenchmarks have been developed to ensure the reliability of MLLMs in downstream\ntasks. However, the evaluation mechanism itself may not be reliable. For\ndevelopers of MLLMs, questions remain about which benchmark to use and whether\nthe test results meet their requirements. Therefore, we propose a critical\nprinciple of Information Density, which examines how much insight a benchmark\ncan provide for the development of MLLMs. We characterize it from four key\ndimensions: (1) Fallacy, (2) Difficulty, (3) Redundancy, (4) Diversity. Through\na comprehensive analysis of more than 10,000 samples, we measured the\ninformation density of 19 MLLM benchmarks. Experiments show that using the\nlatest benchmarks in testing can provide more insight compared to previous\nones, but there is still room for improvement in their information density. We\nhope this principle can promote the development and application of future MLLM\nbenchmarks. Project page: https://github.com/lcysyzxdxc/bench4bench", "published": "2025-03-13 05:58:41", "link": "http://arxiv.org/abs/2503.10079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning", "abstract": "Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: scaling laws are skill-dependent.\nNext, to understand whether skill-dependent scaling is an artefact of the\npretraining datamix, we conduct an extensive ablation of different datamixes\nand find that, also when correcting for datamix differences, knowledge and code\nexhibit fundamental differences in scaling behaviour. We conclude with an\nanalysis of how our findings relate to standard compute-optimal scaling using a\nvalidation set, and find that a misspecified validation set can impact\ncompute-optimal parameter count by nearly 50%, depending on its skill\ncomposition.", "published": "2025-03-13 05:21:22", "link": "http://arxiv.org/abs/2503.10061v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Using Context to Improve Word Segmentation", "abstract": "An important step in understanding how children acquire languages is studying\nhow infants learn word segmentation. It has been established in previous\nresearch that infants may use statistical regularities in speech to learn word\nsegmentation. The research of Goldwater et al., demonstrated that incorporating\ncontext in models improves their ability to learn word segmentation. We\nimplemented two of their models, a unigram and bigram model, to examine how\ncontext can improve statistical word segmentation. The results are consistent\nwith our hypothesis that the bigram model outperforms the unigram model at\npredicting word segmentation. Extending the work of Goldwater et al., we also\nexplored basic ways to model how young children might use previously learned\nwords to segment new utterances.", "published": "2025-03-13 04:04:55", "link": "http://arxiv.org/abs/2503.10023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs", "abstract": "The linear growth of key-value (KV) cache memory and quadratic computational\nin attention mechanisms complexity pose significant bottlenecks for large\nlanguage models (LLMs) in long-context processing. While existing KV cache\noptimization methods address these challenges through token pruning or feature\nmerging, they often incur irreversible information loss or require costly\nparameter retraining. To this end, we propose ZSMerge, a dynamic KV cache\ncompression framework designed for efficient cache management, featuring three\nkey operations: (1) fine-grained memory allocation guided by multi-dimensional\ntoken importance metrics at head-level granularity, (2) a residual merging\nmechanism that preserves critical context through compensated attention\nscoring, and (3) a zero-shot adaptation mechanism compatible with diverse LLM\narchitectures without requiring retraining. ZSMerge significantly enhances\nmemory efficiency and inference speed with negligible performance degradation\nacross LLMs. When applied to LLaMA2-7B, it demonstrates a 20:1 compression\nratio for key-value cache retention (reducing memory footprint to 5\\% of\nbaseline) while sustaining comparable generation quality, coupled with triple\nthroughput gains at extreme 54k-token contexts that eliminate out-of-memory\nfailures. The code is available at https://github.com/SusCom-Lab/ZSMerge.", "published": "2025-03-13 03:36:03", "link": "http://arxiv.org/abs/2503.10714v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content", "abstract": "Large Multimodal Models (LMMs) are increasingly vulnerable to AI-generated\nextremist content, including photorealistic images and text, which can be used\nto bypass safety mechanisms and generate harmful outputs. However, existing\ndatasets for evaluating LMM robustness offer limited exploration of extremist\ncontent, often lacking AI-generated images, diverse image generation models,\nand comprehensive coverage of historical events, which hinders a complete\nassessment of model vulnerabilities. To fill this gap, we introduce\nExtremeAIGC, a benchmark dataset and evaluation framework designed to assess\nLMM vulnerabilities against such content. ExtremeAIGC simulates real-world\nevents and malicious use cases by curating diverse text- and image-based\nexamples crafted using state-of-the-art image generation techniques. Our study\nreveals alarming weaknesses in LMMs, demonstrating that even cutting-edge\nsafety measures fail to prevent the generation of extremist material. We\nsystematically quantify the success rates of various attack strategies,\nexposing critical gaps in current defenses and emphasizing the need for more\nrobust mitigation strategies.", "published": "2025-03-13 02:10:29", "link": "http://arxiv.org/abs/2503.09964v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Take Off the Training Wheels Progressive In-Context Learning for Effective Alignment", "abstract": "Recent studies have explored the working mechanisms of In-Context Learning\n(ICL). However, they mainly focus on classification and simple generation\ntasks, limiting their broader application to more complex generation tasks in\npractice. To address this gap, we investigate the impact of demonstrations on\ntoken representations within the practical alignment tasks. We find that the\ntransformer embeds the task function learned from demonstrations into the\nseparator token representation, which plays an important role in the generation\nof prior response tokens. Once the prior response tokens are determined, the\ndemonstrations become redundant.Motivated by this finding, we propose an\nefficient Progressive In-Context Alignment (PICA) method consisting of two\nstages. In the first few-shot stage, the model generates several prior response\ntokens via standard ICL while concurrently extracting the ICL vector that\nstores the task function from the separator token representation. In the\nfollowing zero-shot stage, this ICL vector guides the model to generate\nresponses without further demonstrations.Extensive experiments demonstrate that\nour PICA not only surpasses vanilla ICL but also achieves comparable\nperformance to other alignment tuning methods. The proposed training-free\nmethod reduces the time cost (e.g., 5.45+) with improved alignment performance\n(e.g., 6.57+). Consequently, our work highlights the application of ICL for\nalignment and calls for a deeper understanding of ICL for complex generations.\nThe code will be available at https://github.com/HITsz-TMG/PICA.", "published": "2025-03-13 02:01:02", "link": "http://arxiv.org/abs/2503.09958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System", "abstract": "Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.", "published": "2025-03-13 00:48:48", "link": "http://arxiv.org/abs/2503.09927v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PluralLLM: Pluralistic Alignment in LLMs via Federated Learning", "abstract": "Ensuring Large Language Models (LLMs) align with diverse human preferences\nwhile preserving privacy and fairness remains a challenge. Existing methods,\nsuch as Reinforcement Learning from Human Feedback (RLHF), rely on centralized\ndata collection, making them computationally expensive and privacy-invasive. We\nintroduce PluralLLM a federated learning-based approach that enables multiple\nuser groups to collaboratively train a transformer-based preference predictor\nwithout sharing sensitive data, which can also serve as a reward model for\naligning LLMs. Our method leverages Federated Averaging (FedAvg) to aggregate\npreference updates efficiently, achieving 46% faster convergence, a 4%\nimprovement in alignment scores, and nearly the same group fairness measure as\nin centralized training. Evaluated on a Q/A preference alignment task,\nPluralLLM demonstrates that federated preference learning offers a scalable and\nprivacy-preserving alternative for aligning LLMs with diverse human values.", "published": "2025-03-13 00:45:27", "link": "http://arxiv.org/abs/2503.09925v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "New Vertex Ordering Characterizations of Circular-Arc Bigraphs", "abstract": "In this article, we present two new characterizations of circular-arc\nbigraphs based on their vertex ordering. Also, we provide a characterization of\ncircular-arc bigraphs in terms of forbidden patterns with respect to a\nparticular ordering of their vertices.", "published": "2025-03-13 20:02:52", "link": "http://arxiv.org/abs/2503.10852v1", "categories": ["math.CO", "cs.DM", "05C90, 68R10, 05C10"], "primary_category": "math.CO"}
{"title": "Matrix Scaling: a New Heuristic for the Feedback Vertex Set Problem", "abstract": "For a digraph $G$, a set $F\\subseteq V(G)$ is said to be a feedback vertex\nset (FVS) if $G-F$ is acyclic. The problem of finding a smallest FVS is\nNP-hard. We present a matrix scaling technique for finding feedback vertex sets\nin un-weighted directed graphs that runs in $O(|F|\\log(|V|)|V|^{2})$ time. Our\ntechnique is empirically shown to produce smaller feedback vertex sets than\nother known heuristics and in a shorter amount of time.", "published": "2025-03-13 18:18:44", "link": "http://arxiv.org/abs/2503.10780v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "Towards Transitive-free Digraphs", "abstract": "In a digraph $D$, an arc $e=(x,y) $ in $D$ is considered transitive if there\nis a path from $x$ to $y$ in $D- e$. A digraph is transitive-free if it does\nnot contain any transitive arc. In the Transitive-free Vertex Deletion (TVD)\nproblem, the goal is to find at most $k$ vertices $S$ such that $D-S$ has no\ntransitive arcs. In our work, we study a more general version of the TVD\nproblem, denoted by $\\ell$-Relaxed Transitive-free Vertex Deletion\n($\\ell$-RTVD), where we look for at most $k$ vertices $S$ such that $D-S$ has\nno more than $\\ell$ transitive arcs. We explore $\\ell$-RTVD on various\nwell-known graph classes of digraphs such as directed acyclic graphs (DAGs),\nplanar DAGs, $\\alpha$-bounded digraphs, tournaments, and their multiple\ngeneralizations such as in-tournaments, out-tournaments, local tournaments,\nacyclic local tournaments, and obtain the following results. Although the\nproblem admits polynomial-time algorithms in tournaments, $\\alpha$-bounded\ndigraphs, and acyclic local tournaments for fixed values of $\\ell$, it remains\nNP-hard even in planar DAGs with maximum degree 6. In the parameterized realm,\nfor $\\ell$-RTVD on in-tournaments and out-tournaments, we obtain polynomial\nkernels parameterized by $k+\\ell$ for bounded independence number. But the\nproblem remains fixed-parameter intractable on DAGs when parameterized by $k$.", "published": "2025-03-13 16:56:45", "link": "http://arxiv.org/abs/2503.10541v1", "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "Myrvold's Results on Orthogonal Triples of $10 \\times 10$ Latin Squares: A SAT Investigation", "abstract": "Ever since E. T. Parker constructed an orthogonal pair of $10\\times10$ Latin\nsquares in 1959, an orthogonal triple of $10\\times10$ Latin squares has been\none of the most sought-after combinatorial designs. Despite extensive work, the\nexistence of such an orthogonal triple remains an open problem, though some\nnegative results are known. In 1999, W. Myrvold derived some highly restrictive\nconstraints in the special case in which one of the Latin squares in the triple\ncontains a $4\\times4$ Latin subsquare. In particular, Myrvold showed there were\ntwenty-eight possible cases for an orthogonal pair in such a triple, twenty of\nwhich were removed from consideration. We implement a computational approach\nthat quickly verifies all of Myrvold's nonexistence results and in the\nremaining eight cases finds explicit examples of orthogonal pairs -- thus\nexplaining for the first time why Myrvold's approach left eight cases unsolved.\nAs a consequence, the eight remaining cases cannot be removed by a strategy of\nfocusing on the existence of an orthogonal pair; the third square in the triple\nmust necessarily be considered as well.\n  Our approach uses a Boolean satisfiability (SAT) solver to derive the\nnonexistence of twenty of the orthogonal pair types and find explicit examples\nof orthogonal pairs in the eight remaining cases. To reduce the existence\nproblem into Boolean logic we use a duality between the concepts of transversal\nrepresentation and orthogonal pair and we provide a formulation of this duality\nin terms of a composition operation on Latin squares. Using our SAT encoding,\nwe find transversal representations (and equivalently orthogonal pairs) in the\nremaining eight cases in under a day of computing.", "published": "2025-03-13 16:07:43", "link": "http://arxiv.org/abs/2503.10504v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Combinatorial Designs and Cellular Automata: A Survey", "abstract": "Cellular Automata (CA) are commonly investigated as a particular type of\ndynamical systems, defined by shift-invariant local rules. In this paper, we\nconsider instead CA as algebraic systems, focusing on the combinatorial designs\ninduced by their short-term behavior. Specifically, we review the main results\npublished in the literature concerning the construction of mutually orthogonal\nLatin squares via bipermutive CA, considering both the linear and nonlinear\ncases. We then survey some significant applications of these results to\ncryptography, and conclude with a discussion of open problems to be addressed\nin future research on CA-based combinatorial designs.", "published": "2025-03-13 12:54:49", "link": "http://arxiv.org/abs/2503.10320v1", "categories": ["math.CO", "cs.CR", "cs.DM", "math.HO"], "primary_category": "math.CO"}
{"title": "Spherical dimension", "abstract": "We introduce and study the spherical dimension, a natural topological\nrelaxation of the VC dimension that unifies several results in learning theory\nwhere topology plays a key role in the proofs. The spherical dimension is\ndefined by extending the set of realizable datasets (used to define the VC\ndimension) to the continuous space of realizable distributions. In this space,\na shattered set of size d (in the VC sense) is completed into a continuous\nobject, specifically a d-dimensional sphere of realizable distributions. The\nspherical dimension is then defined as the dimension of the largest sphere in\nthis space. Thus, the spherical dimension is at least the VC dimension.\n  The spherical dimension serves as a common foundation for leveraging the\nBorsuk-Ulam theorem and related topological tools. We demonstrate the utility\nof the spherical dimension in diverse applications, including disambiguations\nof partial concept classes, reductions from classification to stochastic convex\noptimization, stability and replicability, and sample compression schemes.\nPerhaps surprisingly, we show that the open question posed by Alon, Hanneke,\nHolzman, and Moran (FOCS 2021) of whether there exist non-trivial\ndisambiguations for halfspaces with margin is equivalent to the basic open\nquestion of whether the VC and spherical dimensions are finite together.", "published": "2025-03-13 10:32:25", "link": "http://arxiv.org/abs/2503.10240v1", "categories": ["cs.DM", "cs.LG", "I.2.6; G.2.1"], "primary_category": "cs.DM"}
{"title": "Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors", "abstract": "Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are\nalso required to be in integers, can be solved using invariant factors of $A$\n(by computing the Smith Canonical Form of $A$). This paper explores a new\nproblem which arises in applications, that of obtaining conditions for solving\nthe Modular Linear System $Ax=b\\rem n$ given $A,b$ in $\\zz_n$ for $x$ in\n$\\zz_n$ along with the constraint that the value of the linear function\n$\\phi(x)=\\la w,x\\ra$ is coprime to $n$ for some solution $x$. In this paper we\ndevelop decomposition of the system to coprime moduli $p^{r(p)}$ which are\ndivisors of $n$ and show how such a decomposition simplifies the computation of\nSmith form. This extends the well known index calculus method of computing the\ndiscrete logarithm where the moduli over which the linear system is reduced\nwere assumed to be prime (to solve the reduced systems over prime fields) to\nthe case when the factors of the modulus are prime powers $p^{r(p)}$. It is\nshown how this problem can be addressed effciently using the invariant factors\nand Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo\n$p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$\nprime.", "published": "2025-03-13 08:36:00", "link": "http://arxiv.org/abs/2503.10158v2", "categories": ["math.NT", "cs.DM", "cs.DS", "G.0; G.2.0; I.1.2"], "primary_category": "math.NT"}
{"title": "Triangle-free graphs with the fewest independent sets", "abstract": "Given $d>0$ and a positive integer $n$, let $G$ be a triangle-free graph on\n$n$ vertices with average degree $d$. With an elegant induction, Shearer (1983)\ntightened a seminal result of Ajtai, Koml\\'os and Szemer\\'edi (1980/1981) by\nproving that $G$ contains an independent set of size at least\n$(1+o(1))\\frac{\\log d}{d}n$ as $d\\to\\infty$.\n  By a generalisation of Shearer's method, we prove that the number of\nindependent sets in $G$ must be at least $\\exp\\left((1+o(1))\\frac{(\\log\nd)^2}{2d}n\\right)$ as $d\\to\\infty$. This improves upon results of Cooper and\nMubayi (2014) and Davies, Jenssen, Perkins, and Roberts (2018). Our method also\nprovides good lower bounds on the independence polynomial of $G$, one of which\nimplies Shearer's result itself. As certified by a classic probabilistic\nconstruction, our bound on the number of independent sets is sharp to several\nleading terms as $d\\to\\infty$.", "published": "2025-03-13 03:19:39", "link": "http://arxiv.org/abs/2503.10002v1", "categories": ["math.CO", "cs.DM", "math.PR", "05C35, 05D40, 05C80, 05C69, 60C05, 05A16, 82B20"], "primary_category": "math.CO"}
{"title": "Decode and Forward Relaying for SC-FDE Systems with a Multi-Antenna Relay", "abstract": "In this paper, a cooperative relay network consisting of a single-antenna\nsource, a multi-antenna relay, and a multi-antenna destination is considered.\nThe relay operates in decode-and-forward (DF) mode under frequency-selective\nfading. To combat intersymbol interference (ISI), single-carrier\nfrequency-domain equalization (SC-FDE) with or without decision feedback is\ndeployed at the relay and the destination. The equalization coefficients are\nobtained using minimum mean squared error (MMSE) criterion. Both equal and\noptimum power allocations for a constant total transmit power at the relay are\nconsidered. While, the optimum power allocation is a non-convex problem, the\nsolution is obtained using strong duality.", "published": "2025-03-13 22:16:33", "link": "http://arxiv.org/abs/2503.10921v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "The LZ78 Source", "abstract": "We study a family of processes generated according to sequential probability\nassignments induced by the LZ78 universal compressor. We characterize entropic\nand distributional properties such as their entropy and relative entropy rates,\nfinite-state compressibility and log loss of their realizations, and the\nempirical distributions that they induce. Though not quite stationary, these\nsources are \"almost stationary and ergodic;\" similar to stationary and ergodic\nprocesses, they satisfy a Shannon-McMillan-Breiman-type property: the\nnormalized log probability of their realizations converges almost surely to\ntheir entropy rate. Further, they are locally \"almost i.i.d.\" in the sense that\nthe finite-dimensional empirical distributions of their realizations converge\nalmost surely to a deterministic i.i.d. law. However, unlike stationary ergodic\nsources, the finite-state compressibility of their realizations is almost\nsurely strictly larger than their entropy rate by a \"Jensen gap.\" We present\nsimulations demonstrating the theoretical results. Among their potential uses,\nthese sources allow to gauge the performance of sequential probability models\non non-Markovian non-stationary data.", "published": "2025-03-13 17:24:43", "link": "http://arxiv.org/abs/2503.10574v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Rotatable Antennas for Integrated Sensing and Communications", "abstract": "In this letter, we propose to deploy rotatable antennas (RAs) at the base\nstation (BS) to enhance both communication and sensing (C&S) performances, by\nexploiting a new spatial degree-of-freedom (DoF) offered by array rotation.\nSpecifically, we formulate a multi-objective optimization problem to\nsimultaneously maximize the sum-rate of multiple communication users and\nminimize the Cram\\'er-Rao bound (CRB) for target angle estimation, by jointly\noptimizing the transmit beamforming vectors and the array rotation angle at the\nBS. To solve this problem, we first equivalently decompose it into two\nsubproblems, corresponding to an inner problem for beamforming optimization and\nan outer problem for array rotation optimization. Although these two\nsubproblems are non-convex, we obtain their high-quality solutions by applying\nthe block coordinate descent (BCD) technique and one-dimensional exhaustive\nsearch, respectively. Moreover, we show that for the communication-only case,\nRAs provide an additional rotation gain to improve communication performance;\nwhile for the sensing-only case, the equivalent spatial aperture can be\nenlarged by RAs for achieving higher sensing accuracy. Finally, numerical\nresults are presented to showcase the performance gains of RAs over\nfixed-rotation antennas in integrated sensing and communications (ISAC).", "published": "2025-03-13 15:44:35", "link": "http://arxiv.org/abs/2503.10472v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Standard Heisenberg's uncertainty principles of Cohen's class time-frequency distribution with specific kernels", "abstract": "Time-frequency concentration and resolution of the Cohen's class\ntime-frequency distribution (CCTFD) has attracted much attention in\ntime-frequency analysis. A variety of uncertainty principles of the CCTFD is\ntherefore derived, including the weak Heisenberg type, the Hardy type, the\nNazarov type, and the local type. However, the standard Heisenberg type still\nremains unresolved. In this study, we address the question of how the standard\nHeisenberg's uncertainty principle of the CCTFD is affected by fundamental\nproperties. The investigated distribution properties are Parseval's relation\nand the concise frequency domain definition (i.e., only frequency variables are\nexplicitly found in the tensor product), based on which we confine our\nattention to the CCTFD with some specific kernels. That is the unit modulus and\nv-independent time translation, reversal and scaling invariant kernel CCTFD\n(UMITRSK-CCTFD). We then extend the standard Heisenberg's uncertainty\nprinciples of the Wigner distribution to those of the UMITRSK-CCTFD, giving\nbirth to various types of attainable lower bounds on the uncertainty product in\nthe UMITRSK-CCTFD domain. The derived results strengthen the existing weak\nHeisenberg type and fill gaps in the standard Heisenberg type.", "published": "2025-03-13 13:40:52", "link": "http://arxiv.org/abs/2503.10360v1", "categories": ["eess.SP", "cs.IT", "math.FA", "math.IT"], "primary_category": "eess.SP"}
{"title": "Symplectic Wigner Distribution in the Linear Canonical Transform Domain: Theory and Application", "abstract": "This paper devotes to combine the chirp basis function transformation and\nsymplectic coordinates transformation to yield a novel Wigner distribution (WD)\nassociated with the linear canonical transform (LCT), named as the symplectic\nWD in the LCT domain (SWDL). It incorporates the merits of the symplectic WD\n(SWD) and the WD in the LCT domain (WDL), achieving stronger capability in the\nlinear frequency-modulated (LFM) signal frequency rate feature extraction while\nmaintaining the same level of computational complexity. Some essential\nproperties of the SWDL are derived, including marginal distributions, energy\nconservations, unique reconstruction, Moyal formula, complex conjugate\nsymmetry, time reversal symmetry, scaling property, time translation property,\nfrequency modulation property, and time translation and frequency modulation\nproperty. Heisenberg's uncertainty principles of the SWDL are formulated,\ngiving rise to three kinds of lower bounds attainable respectively by Gaussian\nenveloped complex exponential signal, Gaussian signal and Gaussian enveloped\nchirp signal. The optimal symplectic matrices corresponding to the highest\ntime-frequency resolution are generated by solving the lower bound optimization\n(minimization) problem. The time-frequency resolution of the SWDL is compared\nwith those of the SWD and WDL to demonstrate its superiority in LFM signals\ntime-frequency energy concentration. A synthesis example is also carried out to\nverify the feasibility and reliability of the theoretical analysis.", "published": "2025-03-13 11:32:16", "link": "http://arxiv.org/abs/2503.10274v1", "categories": ["eess.SP", "cs.IT", "math.FA", "math.IT"], "primary_category": "eess.SP"}
{"title": "On the List-Decodability of Random (Linear) Sum-Rank Metric Codes", "abstract": "In this paper, we establish the list-decoding capacity theorem for sum-rank\nmetric codes. This theorem implies the list-decodability theorem for random\ngeneral sum-rank metric codes: Any random general sum-rank metric code with a\nrate not exceeding the list-decoding capacity is\n$\\left(\\rho,O\\left(1/\\epsilon\\right)\\right)$-list-decodable with high\nprobability, where $\\rho\\in\\left(0,1\\right)$ represents the error fraction and\n$\\epsilon>0$ is referred to as the capacity gap. For random\n$\\mathbb{F}_q$-linear sum-rank metric codes by using the same proof approach we\ndemonstrate that any random $\\mathbb{F}_q$-linear sum-rank metric code with a\nrate not exceeding the list-decoding capacity is\n$\\left(\\rho,\\exp\\left(O\\left(1/\\epsilon\\right)\\right)\\right)$-list-decodable\nwith high probability, where the list size is exponential at this stage due to\nthe high correlation among codewords in linear codes. To achieve an exponential\nimprovement on the list size, we prove a limited correlation property between\nsum-rank metric balls and $\\mathbb{F}_q$-subspaces. Ultimately, we establish\nthe list-decodability theorem for random $\\mathbb{F}_q$-linear sum-rank metric\ncodes: Any random $\\mathbb{F}_q$-linear sum-rank metric code with rate not\nexceeding the list decoding capacity is $\\left(\\rho,\nO\\left(1/\\epsilon\\right)\\right)$-list-decodable with high probability. For the\nproof of the list-decodability theorem of random $\\mathbb{F}_q$-linear sum-rank\nmetric codes our proof idea is inspired by and aligns with that provided in the\nworks \\cite{Gur2010,Din2014,Gur2017} where the authors proved the\nlist-decodability theorems for random $\\mathbb{F}_q$-linear Hamming metric\ncodes and random $\\mathbb{F}_q$-linear rank metric codes, respectively.", "published": "2025-03-13 10:19:00", "link": "http://arxiv.org/abs/2503.10234v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Building Intelligent Databases through Similarity: Interaction of Logical and Qualitative Reasoning", "abstract": "In this article, we present a novel method for assessing the similarity of\ninformation within knowledge-bases using a logical point of view. This proposal\nintroduces the concept of a similarity property space $\\Xi$P for each knowledge\nK, offering a nuanced approach to understanding and quantifying similarity. By\ndefining the similarity knowledge space $\\Xi$K through its properties and\nincorporating similarity source information, the framework reinforces the idea\nthat similarity is deeply rooted in the characteristics of the knowledge being\ncompared. Inclusion of super-categories within the similarity knowledge space\n$\\Xi$K allows for a hierarchical organization of knowledge, facilitating more\nsophisticated analysis and comparison. On the one hand, it provides a\nstructured framework for organizing and understanding similarity. The existence\nof super-categories within this space further allows for hierarchical\norganization of knowledge, which can be particularly useful in complex domains.\nOn the other hand, the finite nature of these categories might be restrictive\nin certain contexts, especially when dealing with evolving or highly nuanced\nforms of knowledge. Future research and applications of this framework focus on\naddressing its potential limitations, particularly in handling dynamic and\nhighly specialized knowledge domains.", "published": "2025-03-13 10:15:33", "link": "http://arxiv.org/abs/2503.10231v1", "categories": ["cs.IT", "cs.LO", "cs.MA", "math.IT"], "primary_category": "cs.IT"}
{"title": "On an analogue of the doubling method in coding theory", "abstract": "The theories of automorphic forms and self-dual linear codes share many\nremarkable analogies. In both worlds there are functions invariant under an\naction of a group, notions of cusp forms and Hecke operators, also projections\nand lifts between different geni. It is then natural to ask if other important\nautomorphic objects or techniques could be introduced into coding theory. In\nthis article we propose a way to introduce the doubling method, an efficient\ntechnique used to construct and study $L$-functions. As a result, we prove the\nso-called doubling identity, which usually forms a base of many applications.\nHere we use it to solve an analogue of the \"basis problem\". Namely, we express\na cusp form as an explicit linear combination of complete weight enumerators of\nthe same type.", "published": "2025-03-13 09:39:19", "link": "http://arxiv.org/abs/2503.10201v1", "categories": ["math.NT", "cs.IT", "math.IT", "94B05, 11F55"], "primary_category": "math.NT"}
{"title": "Towards Manufacturing-Friendly Shapes in Discrete Topology Optimization", "abstract": "This paper deals with shape irregularity issues in discrete topology\noptimization algorithms whereby the design is created using the automated\ndistribution of material in the design region. Graph theory is employed to\nderive appropriate regularity measures for any discrete optimization algorithm.\nShape regularity is quantified by scalar figures ready to evaluate design\nchoices in the form of Pareto-frontiers. Developed metrics deal with\ninformation concerning material usage, problematic distribution, and features\nthat complicate manufacturing. The theory is verified by several examples\ndemonstrating the treatment of isolated islands of materials, point connections\nbetween material segments, or homogeneity.", "published": "2025-03-13 07:47:30", "link": "http://arxiv.org/abs/2503.10133v1", "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.IT"}
{"title": "Finite Field Multiple Access II:from Symbol-wise to Codeword-wise", "abstract": "A finite-field multiple-access (FFMA) system separates users within a finite\nfield by utilizing different element-pairs (EPs) as virtual resources. The\nCartesian product of distinct EPs forms an EP code, which serves as the input\nto a finite-field multiplexing module (FF-MUX), allowing the FFMA technique to\ninterchange the order of channel coding and multiplexing. This flexibility\nenables the FFMA system to support a large number of users with short packet\ntraffic, addressing the finite block length (FBL) problem in multiuser reliable\ntransmission. Designing EP codes is a central challenge in FFMA systems. In\nthis paper, we construct EP codes based on a bit(s)-to-codeword transformation\napproach and define the corresponding EP code as a codeword-wise EP (CWEP)\ncode. We then investigate the encoding process of EP codes, and propose unique\nsum-pattern mapping (USPM) structural property constraints to design uniquely\ndecodable CWEP codes. Next, we present the \\(\\kappa\\)-fold ternary orthogonal\nmatrix \\({\\bf T}_{\\rm o}(2^{\\kappa}, 2^{\\kappa})\\) over GF\\((3^m)\\), where \\(m\n= 2^{\\kappa}\\), and the ternary non-orthogonal matrix \\({\\bf T}_{\\rm no}(3,2)\\)\nover GF\\((3^2)\\), for constructing specific CWEP codes. Based on the proposed\nCWEP codes, we introduce three FFMA modes: channel codeword multiple access\n(FF-CCMA), code division multiple access (FF-CDMA), and non-orthogonal multiple\naccess (FF-NOMA). Simulation results demonstrate that all three modes\neffectively support massive user transmissions with strong error performance.", "published": "2025-03-13 03:00:50", "link": "http://arxiv.org/abs/2503.09991v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quadratic Transform for Fractional Programming in Signal Processing and Machine Learning", "abstract": "Fractional programming (FP) is a branch of mathematical optimization that\ndeals with the optimization of ratios. It is an invaluable tool for signal\nprocessing and machine learning, because many key metrics in these fields are\nfractionally structured, e.g., the signal-to-interference-plus-noise ratio\n(SINR) in wireless communications, the Cram\\'{e}r-Rao bound (CRB) in radar\nsensing, the normalized cut in graph clustering, and the margin in support\nvector machine (SVM). This article provides a comprehensive review of both the\ntheory and applications of a recently developed FP technique known as the\nquadratic transform, which can be applied to a wide variety of FP problems,\nincluding both the minimization and the maximization of the sum of functions of\nratios as well as matrix-ratio problems.", "published": "2025-03-13 02:25:27", "link": "http://arxiv.org/abs/2503.09977v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic", "abstract": "The necessity of achieving an effective balance between minimizing the losses\nassociated with restricting human mobility and ensuring hospital capacity has\ngained significant attention in the aftermath of COVID-19. Reinforcement\nlearning (RL)-based strategies for human mobility management have recently\nadvanced in addressing the dynamic evolution of cities and epidemics; however,\nthey still face challenges in achieving coordinated control at the township\nlevel and adapting to cities of varying scales. To address the above issues, we\npropose a multi-agent RL approach that achieves Pareto optimality in managing\nhospital capacity and human mobility (H2-MARL), applicable across cities of\ndifferent scales. We first develop a township-level infection model with\nonline-updatable parameters to simulate disease transmission and construct a\ncity-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is\ndesigned to treat each division as an agent, with a trade-off dual-objective\nreward function formulated and an experience replay buffer enriched with expert\nknowledge built. To evaluate the effectiveness of the model, we construct a\ntownship-level human mobility dataset containing over one billion records from\nfour representative cities of varying scales. Extensive experiments demonstrate\nthat H2-MARL has the optimal dual-objective trade-off capability, which can\nminimize hospital capacity strain while minimizing human mobility restriction\nloss. Meanwhile, the applicability of the proposed model to epidemic control in\ncities of varying scales is verified, which showcases its feasibility and\nversatility in practical applications.", "published": "2025-03-13 21:40:07", "link": "http://arxiv.org/abs/2503.10907v1", "categories": ["cs.MA", "cs.AI", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Design and Analysis of an Extreme-Scale, High-Performance, and Modular Agent-Based Simulation Platform", "abstract": "Agent-based modeling is indispensable for studying complex systems across\nmany domains. However, existing simulation platforms exhibit two major issues:\nperformance and modularity. Low performance prevents simulations with a large\nnumber of agents, increases development time, limits parameter exploration, and\nraises computing costs. Inflexible software designs motivate modelers to create\ntheir own tools, diverting valuable resources.\n  This dissertation introduces a novel simulation platform called BioDynaMo and\nits significant improvement, TeraAgent, to alleviate these challenges via three\nmajor works.\n  First, we lay the platform's foundation by defining abstractions,\nestablishing software infrastructure, and implementing a multitude of features\nfor agent-based modeling. We demonstrate BioDynaMo's modularity through use\ncases in neuroscience, epidemiology, and oncology. We validate these models and\nshow the simplicity of adding new functionality with few lines of code.\n  Second, we perform a rigorous performance analysis and identify challenges\nfor shared-memory parallelism. Provided solutions include an optimized grid for\nneighbor searching, mechanisms to reduce the memory access latency, and\nexploiting domain knowledge to omit unnecessary work. These improvements yield\nup to three orders of magnitude speedups, enabling simulations of 1.7 billion\nagents on a single server.\n  Third, we present TeraAgent, a distributed simulation engine that allows\nscaling out the computation of one simulation to multiple servers. We identify\nand address server communication bottlenecks and implement solutions for\nserialization and delta encoding to accelerate and reduce data transfer.\nTeraAgent can simulate 500 billion agents and scales to 84096 CPU cores.\n  BioDynaMo has been widely adopted, including a prize-winning radiotherapy\nsimulation recognized as a top 10 breakthrough in physics in 2024.", "published": "2025-03-13 18:44:02", "link": "http://arxiv.org/abs/2503.10796v1", "categories": ["cs.DC", "cs.CE", "cs.MA", "cs.PF", "q-bio.QM"], "primary_category": "cs.DC"}
{"title": "SCOOP: A Framework for Proactive Collaboration and Social Continual Learning through Natural Language Interaction andCausal Reasoning", "abstract": "Multimodal information-gathering settings, where users collaborate with AI in\ndynamic environments, are increasingly common. These involve complex processes\nwith textual and multimodal interactions, often requiring additional structural\ninformation via cost-incurring requests. AI helpers lack access to users' true\ngoals, beliefs, and preferences and struggle to integrate diverse information\neffectively.\n  We propose a social continual learning framework for causal knowledge\nacquisition and collaborative decision-making. It focuses on autonomous agents\nlearning through dialogues, question-asking, and interaction in open, partially\nobservable environments. A key component is a natural language oracle that\nanswers the agent's queries about environmental mechanisms and states, refining\ncausal understanding while balancing exploration or learning, and exploitation\nor knowledge use.\n  Evaluation tasks inspired by developmental psychology emphasize causal\nreasoning and question-asking skills. They complement benchmarks by assessing\nthe agent's ability to identify knowledge gaps, generate meaningful queries,\nand incrementally update reasoning. The framework also evaluates how knowledge\nacquisition costs are amortized across tasks within the same environment.\n  We propose two architectures: 1) a system combining Large Language Models\n(LLMs) with the ReAct framework and question-generation, and 2) an advanced\nsystem with a causal world model, symbolic, graph-based, or subsymbolic, for\nreasoning and decision-making. The latter builds a causal knowledge graph for\nefficient inference and adaptability under constraints. Challenges include\nintegrating causal reasoning into ReAct and optimizing exploration and\nquestion-asking in error-prone scenarios. Beyond applications, this framework\nmodels developmental processes combining causal reasoning, question generation,\nand social learning.", "published": "2025-03-13 10:32:50", "link": "http://arxiv.org/abs/2503.10241v1", "categories": ["cs.MA", "cs.HC", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity", "abstract": "Beyond specific settings, many multi-agent learning algorithms fail to\nconverge to an equilibrium solution, and instead display complex,\nnon-stationary behaviours such as recurrent or chaotic orbits. In fact, recent\nliterature suggests that such complex behaviours are likely to occur when the\nnumber of agents increases. In this paper, we study Q-learning dynamics in\nnetwork polymatrix games where the network structure is drawn from classical\nrandom graph models. In particular, we focus on the Erdos-Renyi model, a\nwell-studied model for social networks, and the Stochastic Block model, which\ngeneralizes the above by accounting for community structures within the\nnetwork. In each setting, we establish sufficient conditions under which the\nagents' joint strategies converge to a unique equilibrium. We investigate how\nthis condition depends on the exploration rates, payoff matrices and,\ncrucially, the sparsity of the network. Finally, we validate our theoretical\nfindings through numerical simulations and demonstrate that convergence can be\nreliably achieved in many-agent systems, provided network sparsity is\ncontrolled.", "published": "2025-03-13 09:16:51", "link": "http://arxiv.org/abs/2503.10186v1", "categories": ["cs.MA", "cs.AI", "cs.GT", "math.DS", "93A16, 91A26, 91A68, 58K35", "G.3; J.4; F.2.2"], "primary_category": "cs.MA"}
{"title": "Label Unbalance in High-frequency Trading", "abstract": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .", "published": "2025-03-13 02:55:06", "link": "http://arxiv.org/abs/2503.09988v3", "categories": ["cs.LG", "cs.AI", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Kalman Filter in the Problem of the Exchange and the Inflation Rates Adequacy To Determining Factors", "abstract": "Using introduced concept of the exchange and inflation rates adequacy, the\nrelevance of them to the determining factors is found. We established close\npositive relation between hryvnia / dollar exchange and inflation rates, fiscal\ndeficit, price level of energy sources, and money supply. On this basis, we\ngive proposals for state macroeconomic policy to stabilize Ukrainian economy.", "published": "2025-03-13 07:24:06", "link": "http://arxiv.org/abs/2503.10117v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "EEG-Based Decoding of Sound Location: Comparing Free-Field to Headphone-Based Non-Individual HRTFs", "abstract": "Sound source localization relies on spatial cues such as interaural time\ndifferences (ITD), interaural level differences (ILD), and monaural spectral\ncues. Individually measured Head-Related Transfer Functions (HRTFs) facilitate\nprecise spatial hearing but are impractical to measure, necessitating\nnon-individual HRTFs, which may compromise localization accuracy and\nexternalization. To further investigate this phenomenon, the neurophysiological\ndifferences between free-field and non-individual HRTF listening are explored\nby decoding sound locations from EEG-derived Event-Related Potentials (ERPs).\nTwenty-two participants localized stimuli under both conditions with EEG\nresponses recorded and logistic regression classifiers trained to distinguish\nsound source locations.\n  Lower cortical response amplitudes were observed for KEMAR compared to\nfree-field, especially in front-central and occipital-parietal regions. ANOVA\nidentified significant main effects of auralization condition (F(1, 21) =\n34.56, p < 0.0001) and location (F(3, 63) = 18.17, p < 0.0001) on decoding\naccuracy (DA), which was higher in free-field and interaural-cue-dominated\nlocations. DA negatively correlated with front-back confusion rates (r = -0.57,\np < 0.01), linking neural DA to perceptual confusion.\n  These findings demonstrate that headphone-based non-individual HRTFs elicit\nlower amplitude cortical responses to static, azimuthally-varying locations\nthan free-field conditions. The correlation between EEG-based DA and front-back\nconfusion underscores neurophysiological markers' potential for assessing\nspatial auditory discrimination.", "published": "2025-03-13 18:21:35", "link": "http://arxiv.org/abs/2503.10783v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AudioX: Diffusion Transformer for Anything-to-Audio Generation", "abstract": "Audio and music generation have emerged as crucial tasks in many\napplications, yet existing approaches face significant limitations: they\noperate in isolation without unified capabilities across modalities, suffer\nfrom scarce high-quality, multi-modal training data, and struggle to\neffectively integrate diverse inputs. In this work, we propose AudioX, a\nunified Diffusion Transformer model for Anything-to-Audio and Music Generation.\nUnlike previous domain-specific models, AudioX can generate both general audio\nand music with high quality, while offering flexible natural language control\nand seamless processing of various modalities including text, video, image,\nmusic, and audio. Its key innovation is a multi-modal masked training strategy\nthat masks inputs across modalities and forces the model to learn from masked\ninputs, yielding robust and unified cross-modal representations. To address\ndata scarcity, we curate two comprehensive datasets: vggsound-caps with 190K\naudio captions based on the VGGSound dataset, and V2M-caps with 6 million music\ncaptions derived from the V2M dataset. Extensive experiments demonstrate that\nAudioX not only matches or outperforms state-of-the-art specialized models, but\nalso offers remarkable versatility in handling diverse input modalities and\ngeneration tasks within a unified architecture. The code and datasets will be\navailable at https://zeyuet.github.io/AudioX/", "published": "2025-03-13 16:30:59", "link": "http://arxiv.org/abs/2503.10522v1", "categories": ["cs.MM", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings", "abstract": "Speaker identification in multilingual settings presents unique challenges,\nparticularly when conventional models are predominantly trained on English\ndata. In this paper, we propose WSI (Whisper Speaker Identification), a\nframework that repurposes the encoder of the Whisper automatic speech\nrecognition model pre trained on extensive multilingual data to generate robust\nspeaker embeddings via a joint loss optimization strategy that leverages online\nhard triplet mining and self supervised Normalized Temperature-scaled Cross\nEntropy loss. By capitalizing on Whisper language-agnostic acoustic\nrepresentations, our approach effectively distinguishes speakers across diverse\nlanguages and recording conditions. Extensive evaluations on multiple corpora,\nincluding VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish,\nChinese, and Japanese), and Voxconverse (English), demonstrate that WSI\nconsistently outperforms state-of-the-art baselines, namely Pyannote Embedding,\nECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC\nscores. These results validate our hypothesis that a multilingual pre-trained\nASR encoder, combined with joint loss optimization, substantially improves\nspeaker identification performance in non-English languages.", "published": "2025-03-13 15:11:28", "link": "http://arxiv.org/abs/2503.10446v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2"], "primary_category": "cs.SD"}
{"title": "Handling Domain Shifts for Anomalous Sound Detection: A Review of DCASE-Related Work", "abstract": "When detecting anomalous sounds in complex environments, one of the main\ndifficulties is that trained models must be sensitive to subtle differences in\nmonitored target signals, while many practical applications also require them\nto be insensitive to changes in acoustic domains. Examples of such domain\nshifts include changing the type of microphone or the location of acoustic\nsensors, which can have a much stronger impact on the acoustic signal than\nsubtle anomalies themselves. Moreover, users typically aim to train a model\nonly on source domain data, which they may have a relatively large collection\nof, and they hope that such a trained model will be able to generalize well to\nan unseen target domain by providing only a minimal number of samples to\ncharacterize the acoustic signals in that domain. In this work, we review and\ndiscuss recent publications focusing on this domain generalization problem for\nanomalous sound detection in the context of the DCASE challenges on acoustic\nmachine condition monitoring.", "published": "2025-03-13 14:56:51", "link": "http://arxiv.org/abs/2503.10435v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from Speech", "abstract": "This work aims to tackle the Parkinson's disease (PD) detection problem from\nthe speech signal in a bilingual setting by proposing an ad-hoc dual-head deep\nneural architecture for type-based binary classification. One head is\nspecialized for diadochokinetic patterns. The other head looks for natural\nspeech patterns present in continuous spoken utterances. Only one of the two\nheads is operative accordingly to the nature of the input. Speech\nrepresentations are extracted from self-supervised learning (SSL) models and\nwavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive\nlearning are exploited to reduce variations across languages. Our solution is\nassessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak\nand Spanish languages, respectively. Results indicate that conventional models\ntrained on a single language dataset struggle with cross-linguistic\ngeneralization, and naive combinations of datasets are suboptimal. In contrast,\nour model improves generalization on both languages, simultaneously.", "published": "2025-03-13 12:23:11", "link": "http://arxiv.org/abs/2503.10301v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "MACS: Multi-source Audio-to-image Generation with Contextual Significance and Semantic Alignment", "abstract": "Propelled by the breakthrough in deep generative models, audio-to-image\ngeneration has emerged as a pivotal cross-model task that converts complex\nauditory signals into rich visual representations. However, previous works only\nfocus on single-source audio inputs for image generation, ignoring the\nmulti-source characteristic in natural auditory scenes, thus limiting the\nperformance in generating comprehensive visual content. To bridge this gap, a\nmethod called MACS is proposed to conduct multi-source audio-to-image\ngeneration. This is the first work that explicitly separates multi-source audio\nto capture the rich audio components before image generation. MACS is a\ntwo-stage method. In the first stage, multi-source audio inputs are separated\nby a weakly supervised method, where the audio and text labels are semantically\naligned by casting into a common space using the large pre-trained CLAP model.\nWe introduce a ranking loss to consider the contextual significance of the\nseparated audio signals. In the second stage, efficient image generation is\nachieved by mapping the separated audio signals to the generation condition\nusing only a trainable adapter and a MLP layer. We preprocess the LLP dataset\nas the first full multi-source audio-to-image generation benchmark. The\nexperiments are conducted on multi-source, mixed-source, and single-source\naudio-to-image generation tasks. The proposed MACS outperforms the current\nstate-of-the-art methods in 17 of the 21 evaluation indexes on all tasks and\ndelivers superior visual quality. The code will be publicly available.", "published": "2025-03-13 11:56:25", "link": "http://arxiv.org/abs/2503.10287v1", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Adapter Tuning for Joint Singing Voice Beat and Downbeat Tracking with Self-supervised Learning Features", "abstract": "Singing voice beat tracking is a challenging task, due to the lack of musical\naccompaniment that often contains robust rhythmic and harmonic patterns,\nsomething most existing beat tracking systems utilize and can be essential for\nestimating beats. In this paper, a novel temporal convolutional network-based\nbeat-tracking approach featuring self-supervised learning (SSL) representations\nand adapter tuning is proposed to track the beat and downbeat of singing voices\njointly. The SSL DistilHuBERT representations are utilized to capture the\nsemantic information of singing voices and are further fused with the generic\nspectral features to facilitate beat estimation. Sources of variabilities that\nare particularly prominent with the non-homogeneous singing voice data are\nreduced by the efficient adapter tuning. Extensive experiments show that\nfeature fusion and adapter tuning improve the performance individually, and the\ncombination of both leads to significantly better performances than the\nun-adapted baseline system, with up to 31.6% and 42.4% absolute F1-score\nimprovements on beat and downbeat tracking, respectively.", "published": "2025-03-13 06:28:15", "link": "http://arxiv.org/abs/2503.10086v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Field Estimation: Theories and Applications", "abstract": "The spatial information of sound plays a crucial role in various situations,\nranging from daily activities to advanced engineering technologies. To fully\nutilize its potential, numerous research studies on spatial audio signal\nprocessing have been carried out in the literature. Sound field estimation is\none of the key foundational technologies that can be applied to a wide range of\nacoustic signal processing techniques, including sound field reproduction using\nloudspeakers and binaural playback through headphones. The purpose of this\npaper is to present an overview of sound field estimation methods. After\nproviding the necessary mathematical background, two different approaches to\nsound field estimation will be explained. This paper focuses on clarifying the\nessential theories of each approach, while also referencing state-of-the-art\ndevelopments. Finally, several acoustic signal processing technologies will be\ndiscussed as examples of the application of sound field estimation.", "published": "2025-03-13 03:54:25", "link": "http://arxiv.org/abs/2503.10016v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "New Vertex Ordering Characterizations of Circular-Arc Bigraphs", "abstract": "In this article, we present two new characterizations of circular-arc\nbigraphs based on their vertex ordering. Also, we provide a characterization of\ncircular-arc bigraphs in terms of forbidden patterns with respect to a\nparticular ordering of their vertices.", "published": "2025-03-13 20:02:52", "link": "http://arxiv.org/abs/2503.10852v2", "categories": ["math.CO", "cs.DM", "05C90, 68R10, 05C10"], "primary_category": "math.CO"}
