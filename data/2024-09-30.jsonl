{"title": "GARCH-Informed Neural Networks for Volatility Prediction in Financial Markets", "abstract": "Volatility, which indicates the dispersion of returns, is a crucial measure\nof risk and is hence used extensively for pricing and discriminating between\ndifferent financial investments. As a result, accurate volatility prediction\nreceives extensive attention. The Generalized Autoregressive Conditional\nHeteroscedasticity (GARCH) model and its succeeding variants are well\nestablished models for stock volatility forecasting. More recently, deep\nlearning models have gained popularity in volatility prediction as they\ndemonstrated promising accuracy in certain time series prediction tasks.\nInspired by Physics-Informed Neural Networks (PINN), we constructed a new,\nhybrid Deep Learning model that combines the strengths of GARCH with the\nflexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus\ncapturing and forecasting market volatility more accurately than either class\nof models are capable of on their own. We refer to this novel model as a\nGARCH-Informed Neural Network (GINN). When compared to other time series\nmodels, GINN showed superior out-of-sample prediction performance in terms of\nthe Coefficient of Determination ($R^2$), Mean Squared Error (MSE), and Mean\nAbsolute Error (MAE).", "published": "2024-09-30 23:53:54", "link": "http://arxiv.org/abs/2410.00288v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Computing Systemic Risk Measures with Graph Neural Networks", "abstract": "This paper investigates systemic risk measures for stochastic financial\nnetworks of explicitly modelled bilateral liabilities. We extend the notion of\nsystemic risk measures from Biagini, Fouque, Fritelli and Meyer-Brandis (2019)\nto graph structured data. In particular, we focus on an aggregation function\nthat is derived from a market clearing algorithm proposed by Eisenberg and Noe\n(2001). In this setting, we show the existence of an optimal random allocation\nthat distributes the overall minimal bailout capital and secures the network.\nWe study numerical methods for the approximation of systemic risk and optimal\nrandom allocations. We propose to use permutation equivariant architectures of\nneural networks like graph neural networks (GNNs) and a class that we name\n(extended) permutation equivariant neural networks ((X)PENNs). We compare their\nperformance to several benchmark allocations. The main feature of GNNs and\n(X)PENNs is that they are permutation equivariant with respect to the\nunderlying graph data. In numerical experiments we find evidence that these\npermutation equivariant methods are superior to other approaches.", "published": "2024-09-30 10:18:13", "link": "http://arxiv.org/abs/2410.07222v1", "categories": ["q-fin.CP", "cs.LG", "q-fin.MF", "68T07, 91G45, 91G60, 91G70"], "primary_category": "q-fin.CP"}
{"title": "The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging", "abstract": "This paper proposes a novel method for constructing instruction-tuned large\nlanguage models (LLMs) for finance without instruction data. Traditionally,\ndeveloping such domain-specific LLMs has been resource-intensive, requiring a\nlarge dataset and significant computational power for continual pretraining and\ninstruction tuning. Our study proposes a simpler approach that combines\ndomain-specific continual pretraining with model merging. Given that\ngeneral-purpose pretrained LLMs and their instruction-tuned LLMs are often\npublicly available, they can be leveraged to obtain the necessary instruction\ntask vector. By merging this with a domain-specific pretrained vector, we can\neffectively create instruction-tuned LLMs for finance without additional\ninstruction data. Our process involves two steps: first, we perform continual\npretraining on financial data; second, we merge the instruction-tuned vector\nwith the domain-specific pretrained vector. Our experiments demonstrate the\nsuccessful construction of instruction-tuned LLMs for finance. One major\nadvantage of our method is that the instruction-tuned and domain-specific\npretrained vectors are nearly independent. This independence makes our approach\nhighly effective. The Japanese financial instruction-tuned LLMs we developed in\nthis study are available at\nhttps://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge.", "published": "2024-09-30 01:23:28", "link": "http://arxiv.org/abs/2409.19854v1", "categories": ["cs.CL", "econ.GN", "q-fin.CP", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Detecting Structural breakpoints in natural gas and electricity wholesale prices via Bayesian ensemble approach, in the era of energy prices turmoil of 2022 period: the cases of ten European markets", "abstract": "We investigate the impact of several critical events associated with the\nRusso Ukrainian war, started officially on 24 February 2022 with the Russian\ninvasion of Ukraine, on ten European electricity markets, two natural gas\nmarkets (the European reference trading hub TTF and N.Y. NGNMX market) and how\nthese markets interact to each other and with USDRUB exchange rate, a financial\nmarket. We analyze the reactions of these markets, manifested as breakpoints\nattributed to these critical events, and their interaction, by using a set of\nthree tools that can shed light on different aspects of this complex situation.\nWe combine the concepts of market efficiency, measured by quantifying the\nEfficient market hypothesis (EMH) via rolling Hurst exponent, with structural\nbreakpoints occurred in the time series of gas, electricity and financial\nmarkets, the detection of which is possible by using a Bayesian ensemble\napproach, the Bayesian Estimator of Abrupt change, Seasonal change and Trend\n(BEAST), a powerful tool that can effectively detect structural breakpoints,\ntrends, seasonalities and sudden abrupt changes in time series. The results\nshow that the analyzed markets have exhibited different modes of reactions to\nthe critical events, both in respect of number, nature, and time of occurrence\n(leading, lagging, concurrent with dates of critical events) of breakpoints as\nwell as of the dynamic behavior of their trend components.", "published": "2024-09-30 20:51:57", "link": "http://arxiv.org/abs/2410.07224v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "A Hierarchical conv-LSTM and LLM Integrated Model for Holistic Stock Forecasting", "abstract": "The financial domain presents a complex environment for stock market\nprediction, characterized by volatile patterns and the influence of\nmultifaceted data sources. Traditional models have leveraged either\nConvolutional Neural Networks (CNN) for spatial feature extraction or Long\nShort-Term Memory (LSTM) networks for capturing temporal dependencies, with\nlimited integration of external textual data. This paper proposes a novel\nTwo-Level Conv-LSTM Neural Network integrated with a Large Language Model (LLM)\nfor comprehensive stock advising. The model harnesses the strengths of\nConv-LSTM for analyzing time-series data and LLM for processing and\nunderstanding textual information from financial news, social media, and\nreports. In the first level, convolutional layers are employed to identify\nlocal patterns in historical stock prices and technical indicators, followed by\nLSTM layers to capture the temporal dynamics. The second level integrates the\noutput with an LLM that analyzes sentiment and contextual information from\ntextual data, providing a holistic view of market conditions. The combined\napproach aims to improve prediction accuracy and provide contextually rich\nstock advising.", "published": "2024-09-30 17:04:42", "link": "http://arxiv.org/abs/2410.12807v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "I.2.0; I.2.1"], "primary_category": "q-fin.ST"}
{"title": "Understanding Higher-Order Correlations Among Semantic Components in\n  Embeddings", "abstract": "Independent Component Analysis (ICA) offers interpretable semantic components\nof embeddings. While ICA theory assumes that embeddings can be linearly\ndecomposed into independent components, real-world data often do not satisfy\nthis assumption. Consequently, non-independencies remain between the estimated\ncomponents, which ICA cannot eliminate. We quantified these non-independencies\nusing higher-order correlations and demonstrated that when the higher-order\ncorrelation between two components is large, it indicates a strong semantic\nassociation between them, along with many words sharing common meanings with\nboth components. The entire structure of non-independencies was visualized\nusing a maximum spanning tree of semantic components. These findings provide\ndeeper insights into embeddings through ICA.", "published": "2024-09-30 03:48:54", "link": "http://arxiv.org/abs/2409.19919v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Depression detection in social media posts using transformer-based\n  models and auxiliary features", "abstract": "The detection of depression in social media posts is crucial due to the\nincreasing prevalence of mental health issues. Traditional machine learning\nalgorithms often fail to capture intricate textual patterns, limiting their\neffectiveness in identifying depression. Existing studies have explored various\napproaches to this problem but often fall short in terms of accuracy and\nrobustness. To address these limitations, this research proposes a neural\nnetwork architecture leveraging transformer-based models combined with metadata\nand linguistic markers. The study employs DistilBERT, extracting information\nfrom the last four layers of the transformer, applying learned weights, and\naveraging them to create a rich representation of the input text. This\nrepresentation, augmented by metadata and linguistic markers, enhances the\nmodel's comprehension of each post. Dropout layers prevent overfitting, and a\nMultilayer Perceptron (MLP) is used for final classification. Data augmentation\ntechniques, inspired by the Easy Data Augmentation (EDA) methods, are also\nemployed to improve model performance. Using BERT, random insertion and\nsubstitution of phrases generate additional training data, focusing on\nbalancing the dataset by augmenting underrepresented classes. The proposed\nmodel achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and\n84.15%, respectively. The augmentation techniques significantly enhance model\nperformance, increasing the weighted F1-score from 72.59% to 84.15%.", "published": "2024-09-30 07:53:39", "link": "http://arxiv.org/abs/2409.20048v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Preference Alignment Always the Best Option to Enhance LLM-Based\n  Translation? An Empirical Analysis", "abstract": "Neural metrics for machine translation (MT) evaluation have become\nincreasingly prominent due to their superior correlation with human judgments\ncompared to traditional lexical metrics. Researchers have therefore utilized\nneural metrics through quality-informed decoding strategies, achieving better\nresults than likelihood-based methods. With the rise of Large Language Models\n(LLMs), preference-based alignment techniques have gained attention for their\npotential to enhance translation quality by optimizing model weights directly\non preferences induced by quality estimators. This study focuses on Contrastive\nPreference Optimization (CPO) and conducts extensive experiments to evaluate\nthe impact of preference-based alignment on translation quality. Our findings\nindicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT)\non high-quality data with regard to the alignment metric, it may lead to\ninstability across downstream evaluation metrics, particularly between neural\nand lexical ones. Additionally, we demonstrate that relying solely on the base\nmodel for generating candidate translations achieves performance comparable to\nusing multiple external systems, while ensuring better consistency across\ndownstream metrics.", "published": "2024-09-30 08:01:44", "link": "http://arxiv.org/abs/2409.20059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the\n  E-commerce Domain", "abstract": "Retrieval Augmented Generation (RAG) system is important in domains such as\ne-commerce, which has many long-tail entities and frequently updated\ninformation. Most existing works adopt separate modules for retrieval and\ngeneration, which may be suboptimal since the retrieval task and the generation\ntask cannot benefit from each other to improve performance. We propose a novel\nBackbone Shared RAG framework (BSharedRAG). It first uses a domain-specific\ncorpus to continually pre-train a base model as a domain-specific backbone\nmodel and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules\nbased on the shared backbone to minimize retrieval and generation losses\nrespectively. Experimental results indicate that our proposed BSharedRAG\noutperforms baseline models by 5% and 13% in Hit@3 upon two datasets in\nretrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.\nOur codes, models, and dataset are available at https://bsharedrag.github.io.", "published": "2024-09-30 08:26:53", "link": "http://arxiv.org/abs/2409.20075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PACE: Abstractions for Communicating Efficiently", "abstract": "A central but unresolved aspect of problem-solving in AI is the capability to\nintroduce and use abstractions, something humans excel at. Work in cognitive\nscience has demonstrated that humans tend towards higher levels of abstraction\nwhen engaged in collaborative task-oriented communication, enabling gradually\nshorter and more information-efficient utterances. Several computational\nmethods have attempted to replicate this phenomenon, but all make unrealistic\nsimplifying assumptions about how abstractions are introduced and learned. Our\nmethod, Procedural Abstractions for Communicating Efficiently (PACE), overcomes\nthese limitations through a neuro-symbolic approach. On the symbolic side, we\ndraw on work from library learning for proposing abstractions. We combine this\nwith neural methods for communication and reinforcement learning, via a novel\nuse of bandit algorithms for controlling the exploration and exploitation\ntrade-off in introducing new abstractions. PACE exhibits similar tendencies to\nhumans on a collaborative construction task from the cognitive science\nliterature, where one agent (the architect) instructs the other (the builder)\nto reconstruct a scene of block-buildings. PACE results in the emergence of an\nefficient language as a by-product of collaborative communication. Beyond\nproviding mechanistic insights into human communication, our work serves as a\nfirst step to providing conversational agents with the ability for human-like\ncommunicative abstractions.", "published": "2024-09-30 09:20:18", "link": "http://arxiv.org/abs/2409.20120v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Entangled is Factuality and Deception in German?", "abstract": "The statement \"The earth is flat\" is factually inaccurate, but if someone\ntruly believes and argues in its favor, it is not deceptive. Research on\ndeception detection and fact checking often conflates factual accuracy with the\ntruthfulness of statements. This assumption makes it difficult to (a) study\nsubtle distinctions and interactions between the two and (b) gauge their\neffects on downstream tasks. The belief-based deception framework disentangles\nthese properties by defining texts as deceptive when there is a mismatch\nbetween what people say and what they truly believe. In this study, we assess\nif presumed patterns of deception generalize to German language texts. We test\nthe effectiveness of computational models in detecting deception using an\nestablished corpus of belief-based argumentation. Finally, we gauge the impact\nof deception on the downstream task of fact checking and explore if this\nproperty confounds verification models. Surprisingly, our analysis finds no\ncorrelation with established cues of deception. Previous work claimed that\ncomputational models can outperform humans in deception detection accuracy,\nhowever, our experiments show that both traditional and state-of-the-art models\nstruggle with the task, performing no better than random guessing. For fact\nchecking, we find that Natural Language Inference-based verification performs\nworse on non-factual and deceptive content, while prompting Large Language\nModels for the same task is less sensitive to these properties.", "published": "2024-09-30 10:23:13", "link": "http://arxiv.org/abs/2409.20165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Large Multimodal Models to Extract Knowledge Components for\n  Knowledge Tracing from Multimedia Question Information", "abstract": "Knowledge tracing models have enabled a range of intelligent tutoring systems\nto provide feedback to students. However, existing methods for knowledge\ntracing in learning sciences are predominantly reliant on statistical data and\ninstructor-defined knowledge components, making it challenging to integrate\nAI-generated educational content with traditional established methods. We\npropose a method for automatically extracting knowledge components from\neducational content using instruction-tuned large multimodal models. We\nvalidate this approach by comprehensively evaluating it against knowledge\ntracing benchmarks in five domains. Our results indicate that the automatically\nextracted knowledge components can effectively replace human-tagged labels,\noffering a promising direction for enhancing intelligent tutoring systems in\nlimited-data scenarios, achieving more explainable assessments in educational\nsettings, and laying the groundwork for automated assessment.", "published": "2024-09-30 10:26:29", "link": "http://arxiv.org/abs/2409.20167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reference Trustable Decoding: A Training-Free Augmentation Paradigm for\n  Large Language Models", "abstract": "Large language models (LLMs) have rapidly advanced and demonstrated\nimpressive capabilities. In-Context Learning (ICL) and Parameter-Efficient\nFine-Tuning (PEFT) are currently two mainstream methods for augmenting LLMs to\ndownstream tasks. ICL typically constructs a few-shot learning scenario, either\nmanually or by setting up a Retrieval-Augmented Generation (RAG) system,\nhelping models quickly grasp domain knowledge or question-answering patterns\nwithout changing model parameters. However, this approach involves trade-offs,\nsuch as slower inference speed and increased space occupancy. PEFT assists the\nmodel in adapting to tasks through minimal parameter modifications, but the\ntraining process still demands high hardware requirements, even with a small\nnumber of parameters involved. To address these challenges, we propose\nReference Trustable Decoding (RTD), a paradigm that allows models to quickly\nadapt to new tasks without fine-tuning, maintaining low inference costs. RTD\nconstructs a reference datastore from the provided training examples and\noptimizes the LLM's final vocabulary distribution by flexibly selecting\nsuitable references based on the input, resulting in more trustable responses\nand enabling the model to adapt to downstream tasks at a low cost. Experimental\nevaluations on various LLMs using different benchmarks demonstrate that RTD\nestablishes a new paradigm for augmenting models to downstream tasks.\nFurthermore, our method exhibits strong orthogonality with traditional methods,\nallowing for concurrent usage. Our code can be found at\nhttps://github.com/ShiLuohe/ReferenceTrustableDecoding", "published": "2024-09-30 10:48:20", "link": "http://arxiv.org/abs/2409.20181v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TaskComplexity: A Dataset for Task Complexity Classification with\n  In-Context Learning, FLAN-T5 and GPT-4o Benchmarks", "abstract": "This paper addresses the challenge of classifying and assigning programming\ntasks to experts, a process that typically requires significant effort, time,\nand cost. To tackle this issue, a novel dataset containing a total of 4,112\nprogramming tasks was created by extracting tasks from various websites. Web\nscraping techniques were employed to collect this dataset of programming\nproblems systematically. Specific HTML tags were tracked to extract key\nelements of each issue, including the title, problem description, input-output,\nexamples, problem class, and complexity score. Examples from the dataset are\nprovided in the appendix to illustrate the variety and complexity of tasks\nincluded. The dataset's effectiveness has been evaluated and benchmarked using\ntwo approaches; the first approach involved fine-tuning the FLAN-T5 small model\non the dataset, while the second approach used in-context learning (ICL) with\nthe GPT-4o mini. The performance was assessed using standard metrics: accuracy,\nrecall, precision, and F1-score. The results indicated that in-context learning\nwith GPT-4o-mini outperformed the FLAN-T5 model.", "published": "2024-09-30 11:04:56", "link": "http://arxiv.org/abs/2409.20189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PsyGUARD: An Automated System for Suicide Detection and Risk Assessment\n  in Psychological Counseling", "abstract": "As awareness of mental health issues grows, online counseling support\nservices are becoming increasingly prevalent worldwide. Detecting whether users\nexpress suicidal ideation in text-based counseling services is crucial for\nidentifying and prioritizing at-risk individuals. However, the lack of\ndomain-specific systems to facilitate fine-grained suicide detection and\ncorresponding risk assessment in online counseling poses a significant\nchallenge for automated crisis intervention aimed at suicide prevention. In\nthis paper, we propose PsyGUARD, an automated system for detecting suicide\nideation and assessing risk in psychological counseling. To achieve this, we\nfirst develop a detailed taxonomy for detecting suicide ideation based on\nfoundational theories. We then curate a large-scale, high-quality dataset\ncalled PsySUICIDE for suicide detection. To evaluate the capabilities of\nautomated systems in fine-grained suicide detection, we establish a range of\nbaselines. Subsequently, to assist automated services in providing safe,\nhelpful, and tailored responses for further assessment, we propose to build a\nsuite of risk assessment frameworks. Our study not only provides an insightful\nanalysis of the effectiveness of automated risk assessment systems based on\nfine-grained suicide detection but also highlights their potential to improve\nmental health services on online counseling platforms. Code, data, and models\nare available at https://github.com/qiuhuachuan/PsyGUARD.", "published": "2024-09-30 12:28:10", "link": "http://arxiv.org/abs/2409.20243v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysing Zero-Shot Readability-Controlled Sentence Simplification", "abstract": "Readability-controlled text simplification (RCTS) rewrites texts to lower\nreadability levels while preserving their meaning. RCTS models often depend on\nparallel corpora with readability annotations on both source and target sides.\nSuch datasets are scarce and difficult to curate, especially at the sentence\nlevel. To reduce reliance on parallel data, we explore using instruction-tuned\nlarge language models for zero-shot RCTS. Through automatic and manual\nevaluations, we examine: (1) how different types of contextual information\naffect a model's ability to generate sentences with the desired readability,\nand (2) the trade-off between achieving target readability and preserving\nmeaning. Results show that all tested models struggle to simplify sentences\n(especially to the lowest levels) due to models' limitations and\ncharacteristics of the source sentences that impede adequate rewriting. Our\nexperiments also highlight the need for better automatic evaluation metrics\ntailored to RCTS, as standard ones often misinterpret common simplification\noperations, and inaccurately assess readability and meaning preservation.", "published": "2024-09-30 12:36:25", "link": "http://arxiv.org/abs/2409.20246v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large\n  Language Models", "abstract": "Large language models (LLMs) have made significant progress in natural\nlanguage processing tasks and demonstrate considerable potential in the legal\ndomain. However, legal applications demand high standards of accuracy,\nreliability, and fairness. Applying existing LLMs to legal systems without\ncareful evaluation of their potential and limitations could pose significant\nrisks in legal practice. To this end, we introduce a standardized comprehensive\nChinese legal benchmark LexEval. This benchmark is notable in the following\nthree aspects: (1) Ability Modeling: We propose a new taxonomy of legal\ncognitive abilities to organize different tasks. (2) Scale: To our knowledge,\nLexEval is currently the largest Chinese legal evaluation dataset, comprising\n23 tasks and 14,150 questions. (3) Data: we utilize formatted existing\ndatasets, exam datasets and newly annotated datasets by legal experts to\ncomprehensively evaluate the various capabilities of LLMs. LexEval not only\nfocuses on the ability of LLMs to apply fundamental legal knowledge but also\ndedicates efforts to examining the ethical issues involved in their\napplication. We evaluated 38 open-source and commercial LLMs and obtained some\ninteresting findings. The experiments and findings offer valuable insights into\nthe challenges and potential solutions for developing Chinese legal systems and\nLLM evaluation pipelines. The LexEval dataset and leaderboard are publicly\navailable at \\url{https://github.com/CSHaitao/LexEval} and will be continuously\nupdated.", "published": "2024-09-30 13:44:00", "link": "http://arxiv.org/abs/2409.20288v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangling Singlish Discourse Particles with Task-Driven\n  Representation", "abstract": "Singlish, or formally Colloquial Singapore English, is an English-based\ncreole language originating from the SouthEast Asian country Singapore. The\nlanguage contains influences from Sinitic languages such as Chinese dialects,\nMalay, Tamil and so forth. A fundamental task to understanding Singlish is to\nfirst understand the pragmatic functions of its discourse particles, upon which\nSinglish relies heavily to convey meaning. This work offers a preliminary\neffort to disentangle the Singlish discourse particles (lah, meh and hor) with\ntask-driven representation learning. After disentanglement, we cluster these\ndiscourse particles to differentiate their pragmatic functions, and perform\nSinglish-to-English machine translation. Our work provides a computational\nmethod to understanding Singlish discourse particles, and opens avenues towards\na deeper comprehension of the language and its usage.", "published": "2024-09-30 15:04:17", "link": "http://arxiv.org/abs/2409.20366v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wait, but Tylenol is Acetaminophen... Investigating and Improving\n  Language Models' Ability to Resist Requests for Misinformation", "abstract": "Background: Large language models (LLMs) are trained to follow directions,\nbut this introduces a vulnerability to blindly comply with user requests even\nif they generate wrong information. In medicine, this could accelerate the\ngeneration of misinformation that impacts human well-being.\n  Objectives/Methods: We analyzed compliance to requests to generate misleading\ncontent about medications in settings where models know the request is\nillogical. We investigated whether in-context directions and instruction-tuning\nof LLMs to prioritize logical reasoning over compliance reduced misinformation\nrisk.\n  Results: While all frontier LLMs complied with misinformation requests, both\nprompt-based and parameter-based approaches can improve the detection of logic\nflaws in requests and prevent the dissemination of medical misinformation.\n  Conclusion: Shifting LLMs to prioritize logic over compliance could reduce\nrisks of exploitation for medical misinformation.", "published": "2024-09-30 15:20:58", "link": "http://arxiv.org/abs/2409.20385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield\n  Anti-stereotypical Writing", "abstract": "AI-based systems such as language models can replicate and amplify social\nbiases reflected in their training data. Among other questionable behavior,\nthis can lead to LM-generated text--and text suggestions--that contain\nnormatively inappropriate stereotypical associations. In this paper, we\nconsider the question of how \"debiasing\" a language model impacts stories that\npeople write using that language model in a predictive text scenario. We find\nthat (n=414), in certain scenarios, language model suggestions that align with\ncommon social stereotypes are more likely to be accepted by human authors.\nConversely, although anti-stereotypical language model suggestions sometimes\nlead to an increased rate of anti-stereotypical stories, this influence is far\nfrom sufficient to lead to \"fully debiased\" stories.", "published": "2024-09-30 15:21:25", "link": "http://arxiv.org/abs/2409.20390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past\n  Semantic Information", "abstract": "The human visual system is capable of processing continuous streams of visual\ninformation, but how the brain encodes and retrieves recent visual memories\nduring continuous visual processing remains unexplored. This study investigates\nthe capacity of working memory to retain past information under continuous\nvisual stimuli. And then we propose a new task Memory Disentangling, which aims\nto extract and decode past information from fMRI signals. To address the issue\nof interference from past memory information, we design a disentangled\ncontrastive learning method inspired by the phenomenon of proactive\ninterference. This method separates the information between adjacent fMRI\nsignals into current and past components and decodes them into image\ndescriptions. Experimental results demonstrate that this method effectively\ndisentangles the information within fMRI signals. This research could advance\nbrain-computer interfaces and mitigate the problem of low temporal resolution\nin fMRI.", "published": "2024-09-30 15:51:06", "link": "http://arxiv.org/abs/2409.20428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QAEncoder: Towards Aligned Representation Learning in Question Answering\n  System", "abstract": "Modern QA systems entail retrieval-augmented generation (RAG) for accurate\nand trustworthy responses. However, the inherent gap between user queries and\nrelevant documents hinders precise matching. Motivated by our conical\ndistribution hypothesis, which posits that potential queries and documents form\na cone-like structure in the embedding space, we introduce QAEncoder, a\ntraining-free approach to bridge this gap. Specifically, QAEncoder estimates\nthe expectation of potential queries in the embedding space as a robust\nsurrogate for the document embedding, and attaches document fingerprints to\neffectively distinguish these embeddings. Extensive experiments on fourteen\nembedding models across six languages and eight datasets validate QAEncoder's\nalignment capability, which offers a plug-and-play solution that seamlessly\nintegrates with existing RAG architectures and training-based methods.", "published": "2024-09-30 15:53:38", "link": "http://arxiv.org/abs/2409.20434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instance-adaptive Zero-shot Chain-of-Thought Prompting", "abstract": "Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective\nstrategy for enhancing the performance of large language models (LLMs) in\nreal-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level\nprompt uniformly applied across the whole of instances is inherently limited\nsince one prompt cannot be a good partner for all, a more appropriate approach\nshould consider the interaction between the prompt and each instance\nmeticulously. This work introduces an instance-adaptive prompting algorithm as\nan alternative zero-shot CoT reasoning scheme by adaptively differentiating\ngood and bad prompts. Concretely, we first employ analysis on LLMs through the\nlens of information flow to detect the mechanism under zero-shot CoT reasoning,\nin which we discover that information flows from question to prompt and\nquestion to rationale jointly influence the reasoning results most. We notice\nthat a better zero-shot CoT reasoning needs the prompt to obtain semantic\ninformation from the question then the rationale aggregates sufficient\ninformation from the question directly and via the prompt indirectly. On the\ncontrary, lacking any of those would probably lead to a bad one. Stem from\nthat, we further propose an instance-adaptive prompting strategy (IAP) for\nzero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen\non math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal\nJudgement) obtain consistent improvement, demonstrating that the\ninstance-adaptive zero-shot CoT prompting performs better than other task-level\nmethods with some curated prompts or sophisticated procedures, showing the\nsignificance of our findings in the zero-shot CoT reasoning mechanism.", "published": "2024-09-30 16:00:34", "link": "http://arxiv.org/abs/2409.20441v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Resources in Spanish for Automatic Text Simplification across\n  Domains", "abstract": "This work describes the language resources and models developed for automatic\nsimplification of Spanish texts in three domains: Finance, Medicine and History\nstudies. We created several corpora in each domain, annotation and\nsimplification guidelines, a lexicon of technical and simplified medical terms,\ndatasets used in shared tasks for the financial domain, and two simplification\ntools. The methodology, resources and companion publications are shared\npublicly on the web-site: https://clara-nlp.uned.es/.", "published": "2024-09-30 16:26:19", "link": "http://arxiv.org/abs/2409.20466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Romanian Offensive Language Detection through Knowledge\n  Distillation, Multi-Task Learning, and Data Augmentation", "abstract": "This paper highlights the significance of natural language processing (NLP)\nwithin artificial intelligence, underscoring its pivotal role in comprehending\nand modeling human language. Recent advancements in NLP, particularly in\nconversational bots, have garnered substantial attention and adoption among\ndevelopers. This paper explores advanced methodologies for attaining smaller\nand more efficient NLP models. Specifically, we employ three key approaches:\n(1) training a Transformer-based neural network to detect offensive language,\n(2) employing data augmentation and knowledge distillation techniques to\nincrease performance, and (3) incorporating multi-task learning with knowledge\ndistillation and teacher annealing using diverse datasets to enhance\nefficiency. The culmination of these methods has yielded demonstrably improved\noutcomes.", "published": "2024-09-30 16:59:48", "link": "http://arxiv.org/abs/2409.20498v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation\n  of LLM-Generated Medical Explanatory Arguments", "abstract": "Evaluating LLM-generated text has become a key challenge, especially in\ndomain-specific contexts like the medical field. This work introduces a novel\nevaluation methodology for LLM-generated medical explanatory arguments, relying\non Proxy Tasks and rankings to closely align results with human evaluation\ncriteria, overcoming the biases typically seen in LLMs used as judges. We\ndemonstrate that the proposed evaluators are robust against adversarial\nattacks, including the assessment of non-argumentative text. Additionally, the\nhuman-crafted arguments needed to train the evaluators are minimized to just\none example per Proxy Task. By examining multiple LLM-generated arguments, we\nestablish a methodology for determining whether a Proxy Task is suitable for\nevaluating LLM-generated medical explanatory arguments, requiring only five\nexamples and two human experts.", "published": "2024-09-30 17:59:33", "link": "http://arxiv.org/abs/2409.20565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with\n  Chain-of-Problems", "abstract": "Benchmarks are critical for measuring Large Language Model (LLM) reasoning\ncapabilities. Some benchmarks have even become the de facto indicator of such\ncapabilities. However, as LLM reasoning capabilities improve, existing\nwidely-used benchmarks such as GSM8K marginally encapsulate model reasoning\ndifferentials - most state-of-the-art models for example achieve over 94%\naccuracy on the GSM8K dataset (paperwithcode, 2024). While constructing harder\nbenchmarks is possible, their creation is often manual, expensive, and\nunscalable. As such, we present Scheherazade, an automated approach to produce\nlarge quantities of challenging mathematical reasoning benchmarks by logically\nchaining a small starting set of problems. We propose two different chaining\nmethods, forward chaining and backward chaining, which include randomized\nbranching techniques to generate complex reasoning problems. We apply\nScheherazade on GSM8K to create GSM8K-Scheherazade and evaluate 3 frontier LLMs\nand OpenAI's o1-preview on it. We show that while other frontier models'\nperformance declines precipitously at only a few questions chained, our\nevaluation suggests o1-preview's performance persists, with the flagship OpenAI\nmodel the only one to perform better at backward reasoning. Our data and code\nare available at https://github.com/YoshikiTakashima/scheherazade-code-data.", "published": "2024-09-30 18:48:34", "link": "http://arxiv.org/abs/2410.00151v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KV-Compress: Paged KV-Cache Compression with Variable Compression Rates\n  per Attention Head", "abstract": "Context lengths of Large Language Models (LLMs) have exploded in recent\nyears, with 128k-token context becoming a standard and million-token context\nbecoming a reality. Efficiently supporting long-context inference remains\nchallenging as the memory that must be allocated in key-value (KV) cache for a\ngeneration scales with its context length, limiting the number of long-context\nrequests that can be served concurrently under a given memory budget. KV cache\ncompression can mitigate this issue by removing under-utilized KVs from each\nattention head's cache and reducing its memory footprint. Higher theoretical\ncompression rates can be achieved when the number of removed KVs varies across\nattention heads, but application of such a strategy within existing inference\nframeworks adds fragmentation and cannot realize the theoretical compression\nrates in physical memory. We introduce KV-Compress, a novel compression method\nthat evicts contiguous KV blocks within a PagedAttention framework, reducing\nthe memory footprint of the KV cache proportionally to this theoretical\ncompression rate. Our method achieves state-of-the-art performance on LongBench\nfor both Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct while lowering the\ntotal number of compressed KVs by 4x compared with prior methods. Evaluations\non Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct-FP8 achieve compression\nrates up to 8x with negligible impact on performance, and up to 64x while\nretaining over 90% of full-cache performance for all but three of the suite's\nsubsets. We benchmark an integration of our method with vLLM that increases\ntotal throughput by up to 5.18x by enabling larger decoding batches.", "published": "2024-09-30 19:09:13", "link": "http://arxiv.org/abs/2410.00161v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptable Moral Stances of Large Language Models on Sexist Content:\n  Implications for Society and Gender Discourse", "abstract": "This work provides an explanatory view of how LLMs can apply moral reasoning\nto both criticize and defend sexist language. We assessed eight large language\nmodels, all of which demonstrated the capability to provide explanations\ngrounded in varying moral perspectives for both critiquing and endorsing views\nthat reflect sexist assumptions. With both human and automatic evaluation, we\nshow that all eight models produce comprehensible and contextually relevant\ntext, which is helpful in understanding diverse views on how sexism is\nperceived. Also, through analysis of moral foundations cited by LLMs in their\narguments, we uncover the diverse ideological perspectives in models' outputs,\nwith some models aligning more with progressive or conservative views on gender\nroles and sexism. Based on our observations, we caution against the potential\nmisuse of LLMs to justify sexist language. We also highlight that LLMs can\nserve as tools for understanding the roots of sexist beliefs and designing\nwell-informed interventions. Given this dual capacity, it is crucial to monitor\nLLMs and design safety mechanisms for their use in applications that involve\nsensitive societal topics, such as sexism.", "published": "2024-09-30 19:27:04", "link": "http://arxiv.org/abs/2410.00175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the performance of state-of-the-art esg domain-specific\n  pre-trained large language models in text classification against existing\n  models and traditional machine learning techniques", "abstract": "This research investigates the classification of Environmental, Social, and\nGovernance (ESG) information within textual disclosures. The aim is to develop\nand evaluate binary classification models capable of accurately identifying and\ncategorizing E, S and G-related content respectively.\n  The motivation for this research stems from the growing importance of ESG\nconsiderations in investment decisions and corporate accountability. Accurate\nand efficient classification of ESG information is crucial for stakeholders to\nunderstand the impact of companies on sustainability and to make informed\ndecisions.\n  The research uses a quantitative approach involving data collection, data\npreprocessing, and the development of ESG-focused Large Language Models (LLMs)\nand traditional machine learning (Support Vector Machines, XGBoost)\nclassifiers. Performance evaluation guides iterative refinement until\nsatisfactory metrics are achieved.\n  The research compares traditional machine learning techniques (Support Vector\nMachines, XGBoost), state-of-the-art language model (FinBERT-ESG) and\nfine-tuned LLMs like Llama 2, by employing standard Natural Language Processing\nperformance metrics such as accuracy, precision, recall, F1-score. A novel\nfine-tuning method, Qlora, is applied to LLMs, resulting in significant\nperformance improvements across all ESG domains. The research also develops\ndomain-specific fine-tuned models, such as EnvLlama 2-Qlora, SocLlama 2-Qlora,\nand GovLlama 2-Qlora, which demonstrate impressive results in ESG text\nclassification.", "published": "2024-09-30 20:08:32", "link": "http://arxiv.org/abs/2410.00207v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Methodology for Explainable Large Language Models with Integrated\n  Gradients and Linguistic Analysis in Text Classification", "abstract": "Neurological disorders that affect speech production, such as Alzheimer's\nDisease (AD), significantly impact the lives of both patients and caregivers,\nwhether through social, psycho-emotional effects or other aspects not yet fully\nunderstood. Recent advancements in Large Language Model (LLM) architectures\nhave developed many tools to identify representative features of neurological\ndisorders through spontaneous speech. However, LLMs typically lack\ninterpretability, meaning they do not provide clear and specific reasons for\ntheir decisions. Therefore, there is a need for methods capable of identifying\nthe representative features of neurological disorders in speech and explaining\nclearly why these features are relevant. This paper presents an explainable LLM\nmethod, named SLIME (Statistical and Linguistic Insights for Model\nExplanation), capable of identifying lexical components representative of AD\nand indicating which components are most important for the LLM's decision. In\ndeveloping this method, we used an English-language dataset consisting of\ntranscriptions from the Cookie Theft picture description task. The LLM\nBidirectional Encoder Representations from Transformers (BERT) classified the\ntextual descriptions as either AD or control groups. To identify representative\nlexical features and determine which are most relevant to the model's decision,\nwe used a pipeline involving Integrated Gradients (IG), Linguistic Inquiry and\nWord Count (LIWC), and statistical analysis. Our method demonstrates that BERT\nleverages lexical components that reflect a reduction in social references in\nAD and identifies which further improve the LLM's accuracy. Thus, we provide an\nexplainability tool that enhances confidence in applying LLMs to neurological\nclinical contexts, particularly in the study of neurodegeneration.", "published": "2024-09-30 21:45:02", "link": "http://arxiv.org/abs/2410.00250v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neurosymbolic AI approach to Attribution in Large Language Models", "abstract": "Attribution in large language models (LLMs) remains a significant challenge,\nparticularly in ensuring the factual accuracy and reliability of the generated\noutputs. Current methods for citation or attribution, such as those employed by\ntools like Perplexity.ai and Bing Search-integrated LLMs, attempt to ground\nresponses by providing real-time search results and citations. However, so far,\nthese approaches suffer from issues such as hallucinations, biases,\nsurface-level relevance matching, and the complexity of managing vast,\nunfiltered knowledge sources. While tools like Perplexity.ai dynamically\nintegrate web-based information and citations, they often rely on inconsistent\nsources such as blog posts or unreliable sources, which limits their overall\nreliability. We present that these challenges can be mitigated by integrating\nNeurosymbolic AI (NesyAI), which combines the strengths of neural networks with\nstructured symbolic reasoning. NesyAI offers transparent, interpretable, and\ndynamic reasoning processes, addressing the limitations of current attribution\nmethods by incorporating structured symbolic knowledge with flexible,\nneural-based learning. This paper explores how NesyAI frameworks can enhance\nexisting attribution models, offering more reliable, interpretable, and\nadaptable systems for LLMs.", "published": "2024-09-30 02:20:36", "link": "http://arxiv.org/abs/2410.03726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Token Learning with Similarity Decay for Repetition\n  Suppression in Machine Translation", "abstract": "For crosslingual conversation and trade, Neural Machine Translation (NMT) is\npivotal yet faces persistent challenges with monotony and repetition in\ngenerated content. Traditional solutions that rely on penalizing text\nredundancy or token reoccurrence have shown limited efficacy, particularly for\nlengthy article and e-commerce descriptions with inherent redundancy, even with\nthe advent of Large Language Models (LLMs). This paper investigates the\nunderlying causes of textual repetition through the lens of information\nentropy, attributing the phenomenon to the elevated uncertainty within the\ninput text. To address this, a novel algorithm named Contrastive Token Learning\nwith Similarity Decay (CTSD) is introduced, which modulates the suppression of\ntokens dynamically, informed by varying attention weights and inter-token\ndistances. Furthermore, an e-commerce dataset comprised of title texts of\nonline real items is compiled and released susceptible to hallucination\ntranslations to benchmark the algorithm. Extensive evaluations demonstrate that\nCTSD significantly outperforms existing approaches in precision and\ngeneralizability. Additional online A/B testing underscores its practical\nvalue, showing marked improvements in user engagement and conversion. Notably,\nthis method has been implemented with full traffic on eight multilingual sites\nof alibaba.com, the largest B2B e-commerce platform in the world.", "published": "2024-09-30 02:21:39", "link": "http://arxiv.org/abs/2409.19877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional\n  Summarization Evaluation for LLMs", "abstract": "Existing benchmarks for summarization quality evaluation often lack diverse\ninput scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and\nstruggle with subjective and coarse-grained annotation schemes. To address\nthese shortcomings, we create UniSumEval benchmark, which extends the range of\ninput context (e.g., domain, length) and provides fine-grained,\nmulti-dimensional annotations. We use AI assistance in data creation,\nidentifying potentially hallucinogenic input texts, and also helping human\nannotators reduce the difficulty of fine-grained annotation tasks. With\nUniSumEval, we benchmark nine latest language models as summarizers, offering\ninsights into their performance across varying input contexts and evaluation\ndimensions. Furthermore, we conduct a thorough comparison of SOTA automated\nsummary evaluators. Our benchmark data will be available at\nhttps://github.com/DISL-Lab/UniSumEval-v1.0.", "published": "2024-09-30 02:56:35", "link": "http://arxiv.org/abs/2409.19898v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Learning and Machine Learning, Advancing Big Data Analytics and\n  Management: Object-Oriented Programming", "abstract": "Object-Oriented Programming (OOP) has become a crucial paradigm for managing\nthe growing complexity of modern software systems, particularly in fields like\nmachine learning, deep learning, large language models (LLM), and data\nanalytics. This work provides a comprehensive introduction to the integration\nof OOP techniques within these domains, with a focus on improving code\nmodularity, maintainability, and scalability. We begin by outlining the\nevolution of computing and the rise of OOP, followed by an in-depth discussion\nof key OOP principles such as encapsulation, inheritance, polymorphism, and\nabstraction. The practical application of these principles is demonstrated\nusing Python, a widely adopted language in AI and data science. Furthermore, we\nexamine how design patterns and modular programming can be employed to enhance\nthe structure and efficiency of machine learning systems. In subsequent\nsections, we apply these OOP concepts to real-world AI tasks, including the\nencapsulation of preprocessing workflows, machine learning model training, and\nevaluation. Detailed examples illustrate how OOP can be used to build reusable,\nscalable machine learning systems while maintaining code clarity and reducing\nredundancy.This work is intended to serve as a bridge for both beginners and\nexperienced developers, equipping them with the necessary knowledge to apply\nOOP methodologies in AI-driven projects, ultimately fostering the development\nof more robust and maintainable systems.", "published": "2024-09-30 03:37:10", "link": "http://arxiv.org/abs/2409.19916v4", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "LLMEmb: Large Language Model Can Be a Good Embedding Generator for\n  Sequential Recommendation", "abstract": "Sequential Recommender Systems (SRS), which model a user's interaction\nhistory to predict the next item of interest, are widely used in various\napplications. However, existing SRS often struggle with low-popularity items, a\nchallenge known as the long-tail problem. This issue leads to reduced\nserendipity for users and diminished profits for sellers, ultimately harming\nthe overall system. Large Language Model (LLM) has the ability to capture\nsemantic relationships between items, independent of their popularity, making\nit a promising solution to this problem. In this paper, we introduce LLMEmb, a\nnovel method leveraging LLM to generate item embeddings that enhance SRS\nperformance. To bridge the gap between general-purpose LLM and the\nrecommendation domain, we propose a Supervised Contrastive Fine-Tuning (SCFT)\napproach. This approach includes attribute-level data augmentation and a\ntailored contrastive loss to make LLM more recommendation-friendly.\nAdditionally, we emphasize the importance of integrating collaborative signals\ninto LLM-generated embeddings, for which we propose Recommendation Adaptation\nTraining (RAT). This further refines the embeddings for optimal use in SRS. The\nLLMEmb-derived embeddings can be seamlessly integrated with any SRS models,\nunderscoring the practical value. Comprehensive experiments conducted on three\nreal-world datasets demonstrate that LLMEmb significantly outperforms existing\nmethods across multiple SRS models. The code for our method is released online\nhttps://github.com/Applied-Machine-Learning-Lab/LLMEmb.", "published": "2024-09-30 03:59:06", "link": "http://arxiv.org/abs/2409.19925v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving\n  Fine-Grained Zero-Shot Image Captioning", "abstract": "Zero-shot inference, where pre-trained models perform tasks without specific\ntraining data, is an exciting emergent ability of large models like CLIP.\nAlthough there has been considerable exploration into enhancing zero-shot\nabilities in image captioning (IC) for popular datasets such as MSCOCO and\nFlickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,\nUCM-Captions, and Sydney-Captions. These datasets require captions to discern\nbetween visually and semantically similar classes, focusing on detailed object\nparts and their attributes. To overcome this challenge, we introduce\nTRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption\nwith additional object-part details using object detector proposals and Natural\nLanguage Processing techniques. It complements rather than alters the base\ncaption, allowing seamless integration with other captioning methods and\noffering users enhanced flexibility. Our evaluations show that TROPE\nconsistently boosts performance across all tested zero-shot IC approaches and\nachieves state-of-the-art results on fine-grained IC datasets.", "published": "2024-09-30 05:24:01", "link": "http://arxiv.org/abs/2409.19960v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval", "abstract": "Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant\ncontent based on non-English queries, without relying on human-labeled\ncross-modal data pairs during training. One popular approach involves utilizing\nmachine translation (MT) to create pseudo-parallel data pairs, establishing\ncorrespondence between visual and non-English textual data. However, aligning\ntheir representations poses challenges due to the significant semantic gap\nbetween vision and text, as well as the lower quality of non-English\nrepresentations caused by pre-trained encoders and data noise. To overcome\nthese challenges, we propose LECCR, a novel solution that incorporates the\nmulti-modal large language model (MLLM) to improve the alignment between visual\nand non-English representations. Specifically, we first employ MLLM to generate\ndetailed visual content descriptions and aggregate them into multi-view\nsemantic slots that encapsulate different semantics. Then, we take these\nsemantic slots as internal features and leverage them to interact with the\nvisual features. By doing so, we enhance the semantic information within the\nvisual features, narrowing the semantic gap between modalities and generating\nlocal visual semantics for subsequent multi-level matching. Additionally, to\nfurther enhance the alignment between visual and non-English features, we\nintroduce softened matching under English guidance. This approach provides more\ncomprehensive and reliable inter-modal correspondences between visual and\nnon-English features. Extensive experiments on four CCR benchmarks, \\ie\nMulti30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our\nproposed method. Code: \\url{https://github.com/LiJiaBei-7/leccr}.", "published": "2024-09-30 05:25:51", "link": "http://arxiv.org/abs/2409.19961v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing High-order Interaction Awareness in LLM-based Recommender\n  Model", "abstract": "Large language models (LLMs) have demonstrated prominent reasoning\ncapabilities in recommendation tasks by transforming them into text-generation\ntasks. However, existing approaches either disregard or ineffectively model the\nuser-item high-order interactions. To this end, this paper presents an enhanced\nLLM-based recommender (ELMRec). We enhance whole-word embeddings to\nsubstantially enhance LLMs' interpretation of graph-constructed interactions\nfor recommendations, without requiring graph pre-training. This finding may\ninspire endeavors to incorporate rich knowledge graphs into LLM-based\nrecommenders via whole-word embedding. We also found that LLMs often recommend\nitems based on users' earlier interactions rather than recent ones, and present\na reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in\nboth direct and sequential recommendations.", "published": "2024-09-30 06:07:12", "link": "http://arxiv.org/abs/2409.19979v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "CONTESTS: a Framework for Consistency Testing of Span Probabilities in\n  Language Models", "abstract": "Although language model scores are often treated as probabilities, their\nreliability as probability estimators has mainly been studied through\ncalibration, overlooking other aspects. In particular, it is unclear whether\nlanguage models produce the same value for different ways of assigning joint\nprobabilities to word spans. Our work introduces a novel framework, ConTestS\n(Consistency Testing over Spans), involving statistical tests to assess score\nconsistency across interchangeable completion and conditioning orders. We\nconduct experiments on post-release real and synthetic data to eliminate\ntraining effects. Our findings reveal that both Masked Language Models (MLMs)\nand autoregressive models exhibit inconsistent predictions, with autoregressive\nmodels showing larger discrepancies. Larger MLMs tend to produce more\nconsistent predictions, while autoregressive models show the opposite trend.\nMoreover, for both model types, prediction entropies offer insights into the\ntrue word span likelihood and therefore can aid in selecting optimal decoding\nstrategies. The inconsistencies revealed by our analysis, as well their\nconnection to prediction entropies and differences between model types, can\nserve as useful guides for future research on addressing these limitations.", "published": "2024-09-30 06:24:43", "link": "http://arxiv.org/abs/2409.19984v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Influence Functions Work on Large Language Models?", "abstract": "Influence functions are important for quantifying the impact of individual\ntraining data points on a model's predictions. Although extensive research has\nbeen conducted on influence functions in traditional machine learning models,\ntheir application to large language models (LLMs) has been limited. In this\nwork, we conduct a systematic study to address a key question: do influence\nfunctions work on LLMs? Specifically, we evaluate influence functions across\nmultiple tasks and find that they consistently perform poorly in most settings.\nOur further investigation reveals that their poor performance can be attributed\nto: (1) inevitable approximation errors when estimating the iHVP component due\nto the scale of LLMs, (2) uncertain convergence during fine-tuning, and, more\nfundamentally, (3) the definition itself, as changes in model parameters do not\nnecessarily correlate with changes in LLM behavior. Thus, our study suggests\nthe need for alternative approaches for identifying influential samples.", "published": "2024-09-30 06:50:18", "link": "http://arxiv.org/abs/2409.19998v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Customized Information and Domain-centric Knowledge Graph Construction\n  with Large Language Models", "abstract": "In this paper we propose a novel approach based on knowledge graphs to\nprovide timely access to structured information, to enable actionable\ntechnology intelligence, and improve cyber-physical systems planning. Our\nframework encompasses a text mining process, which includes information\nretrieval, keyphrase extraction, semantic network creation, and topic map\nvisualization. Following this data exploration process, we employ a selective\nknowledge graph construction (KGC) approach supported by an electronics and\ninnovation ontology-backed pipeline for multi-objective decision-making with a\nfocus on cyber-physical systems. We apply our methodology to the domain of\nautomotive electrical systems to demonstrate the approach, which is scalable.\nOur results demonstrate that our construction process outperforms GraphGPT as\nwell as our bi-LSTM and transformer REBEL with a pre-defined dataset by several\ntimes in terms of class recognition, relationship construction and correct\n\"sublass of\" categorization. Additionally, we outline reasoning applications\nand provide a comparison with Wikidata to show the differences and advantages\nof the approach.", "published": "2024-09-30 07:08:28", "link": "http://arxiv.org/abs/2409.20010v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Beyond Scores: A Modular RAG-Based System for Automatic Short Answer\n  Scoring with Feedback", "abstract": "Automatic short answer scoring (ASAS) helps reduce the grading burden on\neducators but often lacks detailed, explainable feedback. Existing methods in\nASAS with feedback (ASAS-F) rely on fine-tuning language models with limited\ndatasets, which is resource-intensive and struggles to generalize across\ncontexts. Recent approaches using large language models (LLMs) have focused on\nscoring without extensive fine-tuning. However, they often rely heavily on\nprompt engineering and either fail to generate elaborated feedback or do not\nadequately evaluate it. In this paper, we propose a modular retrieval augmented\ngeneration based ASAS-F system that scores answers and generates feedback in\nstrict zero-shot and few-shot learning scenarios. We design our system to be\nadaptable to various educational tasks without extensive prompt engineering\nusing an automatic prompt generation framework. Results show an improvement in\nscoring accuracy by 9\\% on unseen questions compared to fine-tuning, offering a\nscalable and cost-effective solution.", "published": "2024-09-30 07:48:55", "link": "http://arxiv.org/abs/2409.20042v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating and explaining training strategies for zero-shot\n  cross-lingual news sentiment analysis", "abstract": "We investigate zero-shot cross-lingual news sentiment detection, aiming to\ndevelop robust sentiment classifiers that can be deployed across multiple\nlanguages without target-language training data. We introduce novel evaluation\ndatasets in several less-resourced languages, and experiment with a range of\napproaches including the use of machine translation; in-context learning with\nlarge language models; and various intermediate training regimes including a\nnovel task objective, POA, that leverages paragraph-level information. Our\nresults demonstrate significant improvements over the state of the art, with\nin-context learning generally giving the best performance, but with the novel\nPOA approach giving a competitive alternative with much lower computational\noverhead. We also show that language similarity is not in itself sufficient for\npredicting the success of cross-lingual transfer, but that similarity in\nsemantic content and structure can be equally important.", "published": "2024-09-30 07:59:41", "link": "http://arxiv.org/abs/2409.20054v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aggressive Post-Training Compression on Extremely Large Language Models", "abstract": "The increasing size and complexity of Large Language Models (LLMs) pose\nchallenges for their deployment on personal computers and mobile devices.\nAggressive post-training model compression is necessary to reduce the models'\nsize, but it often results in significant accuracy loss. To address this\nchallenge, we propose a novel network pruning technology that utilizes over 0.7\nsparsity and less than 8 bits of quantization. Our approach enables the\ncompression of prevailing LLMs within a couple of hours while maintaining a\nrelatively small accuracy loss. In experimental evaluations, our method\ndemonstrates effectiveness and potential for practical deployment. By making\nLLMs available on domestic devices, our work can facilitate a new era of\nnatural language processing applications with wide-ranging impacts.", "published": "2024-09-30 08:47:17", "link": "http://arxiv.org/abs/2409.20094v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classification of Radiological Text in Small and Imbalanced Datasets in\n  a Non-English Language", "abstract": "Natural language processing (NLP) in the medical domain can underperform in\nreal-world applications involving small datasets in a non-English language with\nfew labeled samples and imbalanced classes. There is yet no consensus on how to\napproach this problem. We evaluated a set of NLP models including BERT-like\ntransformers, few-shot learning with sentence transformers (SetFit), and\nprompted large language models (LLM), using three datasets of radiology reports\non magnetic resonance images of epilepsy patients in Danish, a low-resource\nlanguage. Our results indicate that BERT-like models pretrained in the target\ndomain of radiology reports currently offer the optimal performances for this\nscenario. Notably, the SetFit and LLM models underperformed compared to\nBERT-like models, with LLM performing the worst. Importantly, none of the\nmodels investigated was sufficiently accurate to allow for text classification\nwithout any supervision. However, they show potential for data filtering, which\ncould reduce the amount of manual labeling required.", "published": "2024-09-30 09:52:28", "link": "http://arxiv.org/abs/2409.20147v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data\n  Sharing and Compensation in Large Language Models", "abstract": "In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a\nnovel framework designed to facilitate efficient data sharing with a\ntransparent and equitable profit-sharing mechanism. The platform fosters\ncollaboration between data contributors, who provide otherwise non-disclosed\ndatasets, and a data consumer, who utilizes these datasets to enhance their own\nservices. Data contributors are compensated in monetary terms, receiving a\nshare of the revenue generated by the services of the data consumer. The data\nconsumer is committed to sharing a portion of the revenue with contributors,\naccording to predefined profit-sharing arrangements. By incorporating a\ntransparent profit-sharing paradigm to incentivize large-scale data sharing,\nthe 1TT Platform creates a collaborative environment to drive the advancement\nof NLP and LLM technologies.", "published": "2024-09-30 09:55:39", "link": "http://arxiv.org/abs/2409.20149v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal\n  Assistants", "abstract": "LLM-based agents have been widely applied as personal assistants, capable of\nmemorizing information from user messages and responding to personal queries.\nHowever, there still lacks an objective and automatic evaluation on their\nmemory capability, largely due to the challenges in constructing reliable\nquestions and answers (QAs) according to user messages. In this paper, we\npropose MemSim, a Bayesian simulator designed to automatically construct\nreliable QAs from generated user messages, simultaneously keeping their\ndiversity and scalability. Specifically, we introduce the Bayesian Relation\nNetwork (BRNet) and a causal generation mechanism to mitigate the impact of LLM\nhallucinations on factual information, facilitating the automatic creation of\nan evaluation dataset. Based on MemSim, we generate a dataset in the daily-life\nscenario, named MemDaily, and conduct extensive experiments to assess the\neffectiveness of our approach. We also provide a benchmark for evaluating\ndifferent memory mechanisms in LLM-based agents with the MemDaily dataset. To\nbenefit the research community, we have released our project at\nhttps://github.com/nuster1128/MemSim.", "published": "2024-09-30 10:19:04", "link": "http://arxiv.org/abs/2409.20163v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Divided by discipline? A systematic literature review on the\n  quantification of online sexism and misogyny using a semi-automated approach", "abstract": "In recent years, several computational tools have been developed to detect\nand identify sexism, misogyny, and gender-based hate speech, especially on\nonline platforms. Though these tools intend to draw on knowledge from both\nsocial science and computer science, little is known about the current state of\nresearch in quantifying online sexism or misogyny. Given the growing concern\nover the discrimination of women in online spaces and the rise in\ninterdisciplinary research on capturing the online manifestation of sexism and\nmisogyny, a systematic literature review on the research practices and their\nmeasures is the need of the hour. We make three main contributions: (i) we\npresent a semi-automated way to narrow down the search results in the different\nphases of selection stage in the PRISMA flowchart; (ii) we perform a systematic\nliterature review of research papers that focus on the quantification and\nmeasurement of online gender-based hate speech, examining literature from\ncomputer science and the social sciences from 2012 to 2022; and (iii) we\nidentify the opportunities and challenges for measuring gender-based online\nhate speech. Our findings from topic analysis suggest a disciplinary divide\nbetween the themes of research on sexism/misogyny. With evidence-based review,\nwe summarise the different approaches used by the studies who have explored\ninterdisciplinary approaches to bridge the knowledge gap. Coupled with both the\nexisting literature on social science theories and computational modeling, we\nprovide an analysis of the benefits and shortcomings of the methodologies used.\nLastly, we discuss the challenges and opportunities for future research\ndedicated to measuring online sexism and misogyny.", "published": "2024-09-30 11:34:39", "link": "http://arxiv.org/abs/2409.20204v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Beyond Prompts: Dynamic Conversational Benchmarking of Large Language\n  Models", "abstract": "We introduce a dynamic benchmarking system for conversational agents that\nevaluates their performance through a single, simulated, and lengthy\nuser$\\leftrightarrow$agent interaction. The interaction is a conversation\nbetween the user and agent, where multiple tasks are introduced and then\nundertaken concurrently. We context switch regularly to interleave the tasks,\nwhich constructs a realistic testing scenario in which we assess the Long-Term\nMemory, Continual Learning, and Information Integration capabilities of the\nagents. Results from both proprietary and open-source Large-Language Models\nshow that LLMs in general perform well on single-task interactions, but they\nstruggle on the same tasks when they are interleaved. Notably, short-context\nLLMs supplemented with an LTM system perform as well as or better than those\nwith larger contexts. Our benchmark suggests that there are other challenges\nfor LLMs responding to more natural interactions that contemporary benchmarks\nhave heretofore not been able to capture.", "published": "2024-09-30 12:01:29", "link": "http://arxiv.org/abs/2409.20222v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PersonalLLM: Tailoring LLMs to Individual Preferences", "abstract": "As LLMs become capable of complex tasks, there is growing potential for\npersonalized interactions tailored to the subtle and idiosyncratic preferences\nof the user. We present a public benchmark, PersonalLLM, focusing on adapting\nLLMs to provide maximal benefits for a particular user. Departing from existing\nalignment benchmarks that implicitly assume uniform preferences, we curate\nopen-ended prompts paired with many high-quality answers over which users would\nbe expected to display heterogeneous latent preferences. Instead of\npersona-prompting LLMs based on high-level attributes (e.g., user's race or\nresponse length), which yields homogeneous preferences relative to humans, we\ndevelop a method that can simulate a large user base with diverse preferences\nfrom a set of pre-trained reward models. Our dataset and generated\npersonalities offer an innovative testbed for developing personalization\nalgorithms that grapple with continual data sparsity--few relevant feedback\nfrom the particular user--by leveraging historical data from other (similar)\nusers. We explore basic in-context learning and meta-learning baselines to\nillustrate the utility of PersonalLLM and highlight the need for future\nmethodological development. Our dataset is available at\nhttps://huggingface.co/datasets/namkoong-lab/PersonalLLM", "published": "2024-09-30 13:55:42", "link": "http://arxiv.org/abs/2409.20296v2", "categories": ["cs.LG", "cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.LG"}
{"title": "A Looming Replication Crisis in Evaluating Behavior in Language Models?\n  Evidence and Solutions", "abstract": "In an era where large language models (LLMs) are increasingly integrated into\na wide range of everyday applications, research into these models' behavior has\nsurged. However, due to the novelty of the field, clear methodological\nguidelines are lacking. This raises concerns about the replicability and\ngeneralizability of insights gained from research on LLM behavior. In this\nstudy, we discuss the potential risk of a replication crisis and support our\nconcerns with a series of replication experiments focused on prompt engineering\ntechniques purported to influence reasoning abilities in LLMs. We tested\nGPT-3.5, GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, Llama 3-8B, and Llama 3-70B, on\nthe chain-of-thought, EmotionPrompting, ExpertPrompting, Sandbagging, as well\nas Re-Reading prompt engineering techniques, using manually double-checked\nsubsets of reasoning benchmarks including CommonsenseQA, CRT, NumGLUE,\nScienceQA, and StrategyQA. Our findings reveal a general lack of statistically\nsignificant differences across nearly all techniques tested, highlighting,\namong others, several methodological weaknesses in previous research. We\npropose a forward-looking approach that includes developing robust\nmethodologies for evaluating LLMs, establishing sound benchmarks, and designing\nrigorous experimental frameworks to ensure accurate and reliable assessments of\nmodel outputs.", "published": "2024-09-30 14:00:34", "link": "http://arxiv.org/abs/2409.20303v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback\n  Learning with Vision-enhanced Penalty Decoding", "abstract": "Large Vision-Language Models (LVLMs) have shown remarkable performance on\nmany visual-language tasks. However, these models still suffer from multimodal\nhallucination, which means the generation of objects or content that violates\nthe images. Many existing work detects hallucination by directly judging\nwhether an object exists in an image, overlooking the association between the\nobject and semantics. To address this issue, we propose Hierarchical Feedback\nLearning with Vision-enhanced Penalty Decoding (HELPD). This framework\nincorporates hallucination feedback at both object and sentence semantic\nlevels. Remarkably, even with a marginal degree of training, this approach can\nalleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output\nlogits according to the image attention window to avoid being overly affected\nby generated text. HELPD can be seamlessly integrated with any LVLMs. Our\nexperiments demonstrate that the proposed framework yields favorable results\nacross multiple hallucination benchmarks. It effectively mitigates\nhallucination for different LVLMs and concurrently improves their text\ngeneration quality.", "published": "2024-09-30 15:52:05", "link": "http://arxiv.org/abs/2409.20429v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Weakly Supervised Data Labeling Framework for Machine Lexical\n  Normalization in Vietnamese Social Media", "abstract": "This study introduces an innovative automatic labeling framework to address\nthe challenges of lexical normalization in social media texts for low-resource\nlanguages like Vietnamese. Social media data is rich and diverse, but the\nevolving and varied language used in these contexts makes manual labeling\nlabor-intensive and expensive. To tackle these issues, we propose a framework\nthat integrates semi-supervised learning with weak supervision techniques. This\napproach enhances the quality of training dataset and expands its size while\nminimizing manual labeling efforts. Our framework automatically labels raw\ndata, converting non-standard vocabulary into standardized forms, thereby\nimproving the accuracy and consistency of the training data. Experimental\nresults demonstrate the effectiveness of our weak supervision framework in\nnormalizing Vietnamese text, especially when utilizing Pre-trained Language\nModels. The proposed framework achieves an impressive F1-score of 82.72% and\nmaintains vocabulary integrity with an accuracy of up to 99.22%. Additionally,\nit effectively handles undiacritized text under various conditions. This\nframework significantly enhances natural language normalization quality and\nimproves the accuracy of various NLP tasks, leading to an average accuracy\nincrease of 1-3%.", "published": "2024-09-30 16:26:40", "link": "http://arxiv.org/abs/2409.20467v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical\n  Evaluation Resource", "abstract": "Human language, while aimed at conveying meaning, inherently carries\nambiguity. It poses challenges for speech and language processing, but also\nserves crucial communicative functions. Efficiently solve ambiguity is both a\ndesired and a necessary characteristic. The lexical meaning of a word in\ncontext can be determined automatically by Word Sense Disambiguation (WSD)\nalgorithms that rely on external knowledge often limited and biased toward\nEnglish. When adapting content to other languages, automated translations are\nfrequently inaccurate and a high degree of expert human validation is necessary\nto ensure both accuracy and understanding. The current study addresses previous\nlimitations by introducing a new resource for Spanish WSD. It includes a sense\ninventory and a lexical dataset sourced from the Diccionario de la Lengua\nEspa\\~nola which is maintained by the Real Academia Espa\\~nola. We also review\ncurrent resources for Spanish and report metrics on them by a state-of-the-art\nsystem.", "published": "2024-09-30 17:22:33", "link": "http://arxiv.org/abs/2409.20524v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and\n  Clustering Algorithms", "abstract": "Topic modeling is a powerful technique to discover hidden topics and patterns\nwithin a collection of documents without prior knowledge. Traditional topic\nmodeling and clustering-based techniques encounter challenges in capturing\ncontextual semantic information. This study introduces an innovative end-to-end\nsemantic-driven topic modeling technique for the topic extraction process,\nutilizing advanced word and document embeddings combined with a powerful\nclustering algorithm. This semantic-driven approach represents a significant\nadvancement in topic modeling methodologies. It leverages contextual semantic\ninformation to extract coherent and meaningful topics. Specifically, our model\ngenerates document embeddings using pre-trained transformer-based language\nmodels, reduces the dimensions of the embeddings, clusters the embeddings based\non semantic similarity, and generates coherent topics for each cluster.\nCompared to ChatGPT and traditional topic modeling algorithms, our model\nprovides more coherent and meaningful topics.", "published": "2024-09-30 18:15:31", "link": "http://arxiv.org/abs/2410.00134v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adapting LLMs for the Medical Domain in Portuguese: A Study on\n  Fine-Tuning and Model Evaluation", "abstract": "This study evaluates the performance of large language models (LLMs) as\nmedical agents in Portuguese, aiming to develop a reliable and relevant virtual\nassistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD\ndatasets, translated from English using GPT-3.5, were used to fine-tune the\nChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with\ninitial training on medical data, presented the best overall performance, with\nhigh precision and adequacy in metrics such as accuracy, completeness and\nsafety. However, DrBode models, derived from ChatBode, exhibited a phenomenon\nof catastrophic forgetting of acquired medical knowledge. Despite this, these\nmodels performed frequently or even better in aspects such as grammaticality\nand coherence. A significant challenge was low inter-rater agreement,\nhighlighting the need for more robust assessment protocols. This work paves the\nway for future research, such as evaluating multilingual models specific to the\nmedical field, improving the quality of training data, and developing more\nconsistent evaluation methodologies for the medical field.", "published": "2024-09-30 19:10:03", "link": "http://arxiv.org/abs/2410.00163v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the fairness of task-adaptive pretraining on unlabeled test\n  data before few-shot text classification", "abstract": "Few-shot learning benchmarks are critical for evaluating modern NLP\ntechniques. It is possible, however, that benchmarks favor methods which easily\nmake use of unlabeled text, because researchers can use unlabeled text from the\ntest set to pretrain their models. Given the dearth of research on this\npotential problem, we run experiments to quantify the bias caused by\npretraining on unlabeled test set text instead of on unlabeled, independently\ndrawn text. Controlled few-shot and zero-shot experiments on 25 classification\ntasks and 3 language models -- BERT, GPT-2, and Mistral 7B -- do not find\nevidence of overoptimism. Furthermore, we demonstrate the importance of\nrepeated subsampling when studying few-shot text classification, and recommend\nthat few-shot learning benchmarks include multiple training folds. Code and\ndata are available at https://github.com/kddubey/pretrain-on-test/.", "published": "2024-09-30 19:32:10", "link": "http://arxiv.org/abs/2410.00179v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Classification of Crisis Tweets Using Instruction-Finetuned\n  Large Language Models", "abstract": "Social media posts are frequently identified as a valuable source of\nopen-source intelligence for disaster response, and pre-LLM NLP techniques have\nbeen evaluated on datasets of crisis tweets. We assess three commercial large\nlanguage models (OpenAI GPT-4o, Gemini 1.5-flash-001 and Anthropic Claude-3-5\nSonnet) capabilities in zero-shot classification of short social media posts.\nIn one prompt, the models are asked to perform two classification tasks: 1)\nidentify if the post is informative in a humanitarian context; and 2) rank and\nprovide probabilities for the post in relation to 16 possible humanitarian\nclasses. The posts being classified are from the consolidated crisis tweet\ndataset, CrisisBench. Results are evaluated using macro, weighted, and binary\nF1-scores. The informative classification task, generally performed better\nwithout extra information, while for the humanitarian label classification\nproviding the event that occurred during which the tweet was mined, resulted in\nbetter performance. Further, we found that the models have significantly\nvarying performance by dataset, which raises questions about dataset quality.", "published": "2024-09-30 19:33:58", "link": "http://arxiv.org/abs/2410.00182v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Vision-Language Models Really Understand Visual Language?", "abstract": "Visual language is a system of communication that conveys information through\nsymbols, shapes, and spatial arrangements. Diagrams are a typical example of a\nvisual language depicting complex concepts and their relationships in the form\nof an image. The symbolic nature of diagrams presents significant challenges\nfor building models capable of understanding them. Recent studies suggest that\nLarge Vision-Language Models (LVLMs) can even tackle complex reasoning tasks\ninvolving diagrams. In this paper, we investigate this phenomenon by developing\na comprehensive test suite to evaluate the diagram comprehension capability of\nLVLMs. Our test suite uses a variety of questions focused on concept entities\nand their relationships over a set of synthetic as well as real diagrams across\ndomains to evaluate the recognition and reasoning abilities of models. Our\nevaluation of LVLMs shows that while they can accurately identify and reason\nabout entities, their ability to understand relationships is notably limited.\nFurther testing reveals that the decent performance on diagram understanding\nlargely stems from leveraging their background knowledge as shortcuts to\nidentify and reason about the relational information. Thus, we conclude that\nLVLMs have a limited capability for genuine diagram understanding, and their\nimpressive performance in diagram reasoning is an illusion emanating from other\nconfounding factors, such as the background knowledge in the models.", "published": "2024-09-30 19:45:11", "link": "http://arxiv.org/abs/2410.00193v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DreamStruct: Understanding Slides and User Interfaces via Synthetic Data\n  Generation", "abstract": "Enabling machines to understand structured visuals like slides and user\ninterfaces is essential for making them accessible to people with disabilities.\nHowever, achieving such understanding computationally has required manual data\ncollection and annotation, which is time-consuming and labor-intensive. To\novercome this challenge, we present a method to generate synthetic, structured\nvisuals with target labels using code generation. Our method allows people to\ncreate datasets with built-in labels and train models with a small number of\nhuman-annotated examples. We demonstrate performance improvements in three\ntasks for understanding slides and UIs: recognizing visual elements, describing\nvisual content, and classifying visual content types.", "published": "2024-09-30 19:55:54", "link": "http://arxiv.org/abs/2410.00201v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "T-KAER: Transparency-enhanced Knowledge-Augmented Entity Resolution\n  Framework", "abstract": "Entity resolution (ER) is the process of determining whether two\nrepresentations refer to the same real-world entity and plays a crucial role in\ndata curation and data cleaning. Recent studies have introduced the KAER\nframework, aiming to improve pre-trained language models by augmenting external\nknowledge. However, identifying and documenting the external knowledge that is\nbeing augmented and understanding its contribution to the model's predictions\nhave received little to no attention in the research community. This paper\naddresses this gap by introducing T-KAER, the Transparency-enhanced\nKnowledge-Augmented Entity Resolution framework.\n  To enhance transparency, three Transparency-related Questions (T-Qs) have\nbeen proposed: T-Q(1): What is the experimental process for matching results\nbased on data inputs? T-Q(2): Which semantic information does KAER augment in\nthe raw data inputs? T-Q(3): Which semantic information of the augmented data\ninputs influences the predictions? To address the T-Qs, T-KAER is designed to\nimprove transparency by documenting the entity resolution processes in log\nfiles.\n  In experiments, a citation dataset is used to demonstrate the transparency\ncomponents of T-KAER. This demonstration showcases how T-KAER facilitates error\nanalysis from both quantitative and qualitative perspectives, providing\nevidence on \"what\" semantic information is augmented and \"why\" the augmented\nknowledge influences predictions differently.", "published": "2024-09-30 20:32:12", "link": "http://arxiv.org/abs/2410.00218v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Text Clustering as Classification with LLMs", "abstract": "Text clustering remains valuable in real-world applications where manual\nlabeling is cost-prohibitive. It facilitates efficient organization and\nanalysis of information by grouping similar texts based on their\nrepresentations. However, implementing this approach necessitates fine-tuned\nembedders for downstream data and sophisticated similarity metrics. To address\nthis issue, this study presents a novel framework for text clustering that\neffectively leverages the in-context learning capacity of Large Language Models\n(LLMs). Instead of fine-tuning embedders, we propose to transform the text\nclustering into a classification task via LLM. First, we prompt LLM to generate\npotential labels for a given dataset. Second, after integrating similar labels\ngenerated by the LLM, we prompt the LLM to assign the most appropriate label to\neach sample in the dataset. Our framework has been experimentally proven to\nachieve comparable or superior performance to state-of-the-art clustering\nmethods that employ embeddings, without requiring complex fine-tuning or\nclustering algorithms. We make our code available to the public for utilization\nat https://github.com/ECNU-Text-Computing/Text-Clustering-via-LLM.", "published": "2024-09-30 16:57:34", "link": "http://arxiv.org/abs/2410.00927v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Ingest-And-Ground: Dispelling Hallucinations from Continually-Pretrained\n  LLMs with RAG", "abstract": "This paper presents new methods that have the potential to improve privacy\nprocess efficiency with LLM and RAG. To reduce hallucination, we continually\npre-train the base LLM model with a privacy-specific knowledge base and then\naugment it with a semantic RAG layer. Our evaluations demonstrate that this\napproach enhances the model performance (as much as doubled metrics compared to\nout-of-box LLM) in handling privacy-related queries, by grounding responses\nwith factual information which reduces inaccuracies.", "published": "2024-09-30 20:32:29", "link": "http://arxiv.org/abs/2410.02825v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Human Preference Learning", "abstract": "Large language models demonstrate impressive reasoning abilities but struggle\nto provide personalized content due to their lack of individual user preference\ninformation. Existing methods, such as in-context learning and\nparameter-efficient fine-tuning, fall short in capturing the complexity of\nhuman preferences, especially given the small, personal datasets individuals\npossess. In this paper, we propose a novel approach utilizing small parameter\nmodels as preference agents to generate natural language rules that guide a\nlarger, pre-trained model, enabling efficient personalization. Our method\ninvolves a small, local \"steering wheel\" model that directs the outputs of a\nmuch larger foundation model, producing content tailored to an individual's\npreferences while leveraging the extensive knowledge and capabilities of the\nlarge model. Importantly, this personalization is achieved without the need to\nfine-tune the large model. Experimental results on email and article datasets,\ndemonstrate that our technique significantly outperforms baseline\npersonalization methods. By allowing foundation models to adapt to individual\npreferences in a data and compute-efficient manner, our approach paves the way\nfor highly personalized language model applications.", "published": "2024-09-30 17:51:01", "link": "http://arxiv.org/abs/2410.03731v3", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Task-Adaptive Pretrained Language Models via Clustered-Importance\n  Sampling", "abstract": "Specialist language models (LMs) focus on a specific task or domain on which\nthey often outperform generalist LMs of the same size. However, the specialist\ndata needed to pretrain these models is only available in limited amount for\nmost tasks. In this work, we build specialist models from large generalist\ntraining sets instead. We propose a novel method, ClusteRed Importance SamPling\n(CRISP). CRISP clusters the generalist dataset and samples from these clusters\nbased on their frequencies in the smaller specialist dataset. It is scalable,\nsuitable for both pretraining and continued pretraining, and works well in\nmulti-task settings. CRISP performs favorably compared to other methods that\nadjust the training distribution of the generalist data with guidance from the\nlimited domain-specific data. Our findings demonstrate improvements across\ndifferent domains in terms of language modeling perplexity and accuracy on\nmultiple-choice question tasks. We also present ablation studies that examine\nthe impact of dataset sizes, clustering configurations, and model sizes.", "published": "2024-09-30 20:49:54", "link": "http://arxiv.org/abs/2410.03735v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities", "abstract": "Forecasts of future events are essential inputs into informed\ndecision-making. Machine learning (ML) systems have the potential to deliver\nforecasts at scale, but there is no framework for evaluating the accuracy of ML\nsystems on a standardized set of forecasting questions. To address this gap, we\nintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML\nsystems on an automatically generated and regularly updated set of 1,000\nforecasting questions. To avoid any possibility of data leakage, ForecastBench\nis comprised solely of questions about future events that have no known answer\nat the time of submission. We quantify the capabilities of current ML systems\nby collecting forecasts from expert (human) forecasters, the general public,\nand LLMs on a random subset of questions from the benchmark ($N=200$). While\nLLMs have achieved super-human performance on many benchmarks, they perform\nless well here: expert forecasters outperform the top-performing LLM ($p$-value\n$<0.001$). We display system and human scores in a public leaderboard at\nwww.forecastbench.org.", "published": "2024-09-30 00:41:51", "link": "http://arxiv.org/abs/2409.19839v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling\n  Large Language Models", "abstract": "Recent works show that assembling multiple off-the-shelf large language\nmodels (LLMs) can harness their complementary abilities. To achieve this,\nrouting is a promising method, which learns a router to select the most\nsuitable LLM for each query. However, existing routing models are ineffective\nwhen multiple LLMs perform well for a query. To address this problem, in this\npaper, we propose a method called query-based Router by Dual Contrastive\nlearning (RouterDC). The RouterDC model consists of an encoder and LLM\nembeddings, and we propose two contrastive learning losses to train the\nRouterDC model. Experimental results show that RouterDC is effective in\nassembling LLMs and largely outperforms individual top-performing LLMs as well\nas existing routing methods on both in-distribution (+2.76\\%) and\nout-of-distribution (+1.90\\%) tasks. Source code is available at\nhttps://github.com/shuhao02/RouterDC.", "published": "2024-09-30 02:31:40", "link": "http://arxiv.org/abs/2409.19886v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Scaling Optimal LR Across Token Horizons", "abstract": "State-of-the-art LLMs are powered by scaling -- scaling model size, dataset\nsize and cluster size. It is economically infeasible to extensively tune\nhyperparameter for the largest runs. Instead, approximately optimal\nhyperparameters must be inferred or \\textit{transferred} from smaller\nexperiments. Hyperparameter transfer across model sizes has been studied in\nYang et al. However, hyperparameter transfer across dataset size -- or token\nhorizon -- has not been studied yet. To remedy this we conduct a large scale\nempirical study on how optimal learning rate (LR) depends on token horizon in\nLLM training. We first demonstrate that the optimal LR changes significantly\nwith token horizon -- longer training necessitates smaller LR. Secondly we\ndemonstrate the the optimal LR follows a scaling law, and that the optimal LR\nfor longer horizons can be accurately estimated from shorter horizons via such\nscaling laws. We also provide a rule-of-thumb for transferring LR across token\nhorizons with zero overhead over current practices. Lastly we provide evidence\nthat LLama-1 used too high LR, and estimate the performance hit from this. We\nthus argue that hyperparameter transfer across data size is an important and\noverlooked component of LLM training.", "published": "2024-09-30 03:32:02", "link": "http://arxiv.org/abs/2409.19913v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers", "abstract": "In this paper, we create benchmarks and assess the effectiveness of error\ncorrection methods for Japanese vouchers in OCR (Optical Character Recognition)\nsystems. It is essential for automation processing to correctly recognize\nscanned voucher text, such as the company name on invoices. However, perfect\nrecognition is complex due to the noise, such as stamps. Therefore, it is\ncrucial to correctly rectify erroneous OCR results. However, no publicly\navailable OCR error correction benchmarks for Japanese exist, and methods have\nnot been adequately researched. In this study, we measured text recognition\naccuracy by existing services on Japanese vouchers and developed a post-OCR\ncorrection benchmark. Then, we proposed simple baselines for error correction\nusing language models and verified whether the proposed method could\neffectively correct these errors. In the experiments, the proposed error\ncorrection algorithm significantly improved overall recognition accuracy.", "published": "2024-09-30 05:01:49", "link": "http://arxiv.org/abs/2409.19948v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Law of the Weakest Link: Cross Capabilities of Large Language Models", "abstract": "The development and evaluation of Large Language Models (LLMs) have largely\nfocused on individual capabilities. However, this overlooks the intersection of\nmultiple abilities across different types of expertise that are often required\nfor real-world tasks, which we term cross capabilities. To systematically\nexplore this concept, we first define seven core individual capabilities and\nthen pair them to form seven common cross capabilities, each supported by a\nmanually constructed taxonomy. Building on these definitions, we introduce\nCrossEval, a benchmark comprising 1,400 human-annotated prompts, with 100\nprompts for each individual and cross capability. To ensure reliable\nevaluation, we involve expert annotators to assess 4,200 model responses,\ngathering 8,400 human ratings with detailed explanations to serve as reference\nexamples. Our findings reveal that, in both static evaluations and attempts to\nenhance specific abilities, current LLMs consistently exhibit the \"Law of the\nWeakest Link,\" where cross-capability performance is significantly constrained\nby the weakest component. Specifically, across 58 cross-capability scores from\n17 models, 38 scores are lower than all individual capabilities, while 20 fall\nbetween strong and weak, but closer to the weaker ability. These results\nhighlight the under-performance of LLMs in cross-capability tasks, making the\nidentification and improvement of the weakest capabilities a critical priority\nfor future research to optimize performance in complex, multi-dimensional\nscenarios.", "published": "2024-09-30 05:12:01", "link": "http://arxiv.org/abs/2409.19951v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Predictive Speech Recognition and End-of-Utterance Detection Towards\n  Spoken Dialog Systems", "abstract": "Effective spoken dialog systems should facilitate natural interactions with\nquick and rhythmic timing, mirroring human communication patterns. To reduce\nresponse times, previous efforts have focused on minimizing the latency in\nautomatic speech recognition (ASR) to optimize system efficiency. However, this\napproach requires waiting for ASR to complete processing until a speaker has\nfinished speaking, which limits the time available for natural language\nprocessing (NLP) to formulate accurate responses. As humans, we continuously\nanticipate and prepare responses even while the other party is still speaking.\nThis allows us to respond appropriately without missing the optimal time to\nspeak. In this work, as a pioneering study toward a conversational system that\nsimulates such human anticipatory behavior, we aim to realize a function that\ncan predict the forthcoming words and estimate the time remaining until the end\nof an utterance (EOU), using the middle portion of an utterance. To achieve\nthis, we propose a training strategy for an encoder-decoder-based ASR system,\nwhich involves masking future segments of an utterance and prompting the\ndecoder to predict the words in the masked audio. Additionally, we develop a\ncross-attention-based algorithm that incorporates both acoustic and linguistic\ninformation to accurately detect the EOU. The experimental results demonstrate\nthe proposed model's ability to predict upcoming words and estimate future EOU\nevents up to 300ms prior to the actual EOU. Moreover, the proposed training\nstrategy exhibits general improvements in ASR performance.", "published": "2024-09-30 06:29:58", "link": "http://arxiv.org/abs/2409.19990v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DeSTA2: Developing Instruction-Following Speech Language Model Without\n  Speech Instruction-Tuning Data", "abstract": "Recent end-to-end speech language models (SLMs) have expanded upon the\ncapabilities of large language models (LLMs) by incorporating pre-trained\nspeech models. However, these SLMs often undergo extensive speech\ninstruction-tuning to bridge the gap between speech and text modalities. This\nrequires significant annotation efforts and risks catastrophic forgetting of\nthe original language capabilities. In this work, we present a simple yet\neffective automatic process for creating speech-text pair data that carefully\ninjects speech paralinguistic understanding abilities into SLMs while\npreserving the inherent language capabilities of the text-based LLM. Our model\ndemonstrates general capabilities for speech-related tasks without the need for\nspeech instruction-tuning data, achieving impressive performance on\nDynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits\nthe ability to follow complex instructions derived from LLMs, such as specific\noutput formatting and chain-of-thought reasoning. Our approach not only\nenhances the versatility and effectiveness of SLMs but also reduces reliance on\nextensive annotated datasets, paving the way for more efficient and capable\nspeech understanding systems.", "published": "2024-09-30 07:01:21", "link": "http://arxiv.org/abs/2409.20007v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Robust Multimodal Sentiment Analysis with Incomplete Data", "abstract": "The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an\nemerging direction seeking to tackle the issue of data incompleteness.\nRecognizing that the language modality typically contains dense sentiment\ninformation, we consider it as the dominant modality and present an innovative\nLanguage-dominated Noise-resistant Learning Network (LNLN) to achieve robust\nMSA. The proposed LNLN features a dominant modality correction (DMC) module and\ndominant modality based multimodal learning (DMML) module, which enhances the\nmodel's robustness across various noise scenarios by ensuring the quality of\ndominant modality representations. Aside from the methodical design, we perform\ncomprehensive experiments under random data missing scenarios, utilizing\ndiverse and meaningful settings on several popular datasets (\\textit{e.g.,}\nMOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and\nfairness compared to existing evaluations in the literature. Empirically, LNLN\nconsistently outperforms existing baselines, demonstrating superior performance\nacross these challenging and extensive evaluation metrics.", "published": "2024-09-30 07:14:31", "link": "http://arxiv.org/abs/2409.20012v2", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "GUNDAM: Aligning Large Language Models with Graph Understanding", "abstract": "Large Language Models (LLMs) have achieved impressive results in processing\ntext data, which has sparked interest in applying these models beyond textual\ndata, such as graphs. In the field of graph learning, there is a growing\ninterest in harnessing LLMs to comprehend and manipulate graph-structured data.\nExisting research predominantly focuses on graphs with rich textual features,\nsuch as knowledge graphs or text attribute graphs, leveraging LLMs' ability to\nprocess text but inadequately addressing graph structure. This work\nspecifically aims to assess and enhance LLMs' abilities to comprehend and\nutilize the structural knowledge inherent in graph data itself, rather than\nfocusing solely on graphs rich in textual content. To achieve this, we\nintroduce the \\textbf{G}raph \\textbf{U}nderstanding for \\textbf{N}atural\nLanguage \\textbf{D}riven \\textbf{A}nalytical \\textbf{M}odel (\\model). This\nmodel adapts LLMs to better understand and engage with the structure of graph\ndata, enabling them to perform complex reasoning tasks by leveraging the\ngraph's structure itself. Our experimental evaluations on graph reasoning\nbenchmarks not only substantiate that \\model~ outperforms the SOTA baselines\nfor comparisons. But also reveals key factors affecting the graph reasoning\ncapabilities of LLMs. Moreover, we provide a theoretical analysis illustrating\nhow reasoning paths can enhance LLMs' reasoning capabilities.", "published": "2024-09-30 07:59:10", "link": "http://arxiv.org/abs/2409.20053v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Robust LLM safeguarding via refusal feature adversarial training", "abstract": "Large language models (LLMs) are vulnerable to adversarial attacks that can\nelicit harmful responses. Defending against such attacks remains challenging\ndue to the opacity of jailbreaking mechanisms and the high computational cost\nof training LLMs robustly. We demonstrate that adversarial attacks share a\nuniversal mechanism for circumventing LLM safeguards that works by ablating a\ndimension in the residual stream embedding space called the refusal feature. We\nfurther show that the operation of refusal feature ablation (RFA) approximates\nthe worst-case perturbation of offsetting model safety. Based on these\nfindings, we propose Refusal Feature Adversarial Training (ReFAT), a novel\nalgorithm that efficiently performs LLM adversarial training by simulating the\neffect of input-level attacks via RFA. Experiment results show that ReFAT\nsignificantly improves the robustness of three popular LLMs against a wide\nrange of adversarial attacks, with considerably less computational overhead\ncompared to existing adversarial training methods.", "published": "2024-09-30 08:41:39", "link": "http://arxiv.org/abs/2409.20089v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Federated Instruction Tuning of LLMs with Domain Coverage Augmentation", "abstract": "Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited\ncross-client private data together with various strategies of instruction\naugmentation, ultimately boosting model performance within specific domains. To\ndate, the factors affecting FedDIT remain unclear, and existing instruction\naugmentation methods primarily focus on the centralized setting without\nconsidering distributed environments. Our experiments reveal that the\ncross-client domain coverage, rather than data heterogeneity, drives model\nperformance in FedDIT. In response, we propose FedDCA, which optimizes domain\ncoverage through greedy client center selection and retrieval-based\naugmentation. At its core, the greedy selection procedure iteratively picks\nclient centers that maximize the diversity and coverage of the instruction\nspace while avoiding redundancy with previously selected centers. This ensures\nbroad yet efficient coverage of the domain distribution across clients. For\nclient-side computational efficiency and system scalability, FedDCA$^*$, the\nvariant of FedDCA, utilizes heterogeneous encoders with server-side feature\nalignment. Extensive experiments across code, medical, financial, and\nmathematical domains substantiate the effectiveness of both methods, as well as\nplug-and-play capability. We further analyze privacy preservation against\nmemory extraction attacks, showing that while privacy leakage risk is\nindependent of augmented public data ratio, it decreases or converges as\ntraining progresses.", "published": "2024-09-30 09:34:31", "link": "http://arxiv.org/abs/2409.20135v5", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "AfriHuBERT: A self-supervised speech representation model for African\n  languages", "abstract": "In this work, we present AfriHuBERT, an extension of mHuBERT-147, a\nstate-of-the-art (SOTA) and compact self-supervised learning (SSL) model,\noriginally pretrained on 147 languages. While mHuBERT-147 was pretrained on 16\nAfrican languages, we expand this to cover 39 African languages through\ncontinued pretraining on 6,500+ hours of speech data aggregated from diverse\nsources, including 23 newly added languages. We evaluate AfriHuBERT on two key\nspeech tasks: Language Identification (LID) and Automatic Speech Recognition\n(ASR) using FLEURS dataset. Our results show a +4% F1 score improvement on\naverage for LID and a -1.2% average Word Error Rate (WER) reduction for ASR.\nFurther analysis shows that ASR models trained on AfriHuBERT exhibit improved\ncross-corpus generalization. Additionally, the analysis indicates that the\nFLEURS have data quality limitations that may affect their suitability for\nevaluating low-resource African languages, suggesting the need for better\nevaluation benchmarks for these languages.", "published": "2024-09-30 11:28:33", "link": "http://arxiv.org/abs/2409.20201v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Alignment-Free Training for Transducer-based Multi-Talker ASR", "abstract": "Extending the RNN Transducer (RNNT) to recognize multi-talker speech is\nessential for wider automatic speech recognition (ASR) applications.\nMulti-talker RNNT (MT-RNNT) aims to achieve recognition without relying on\ncostly front-end source separation. MT-RNNT is conventionally implemented using\narchitectures with multiple encoders or decoders, or by serializing all\nspeakers' transcriptions into a single output stream. The first approach is\ncomputationally expensive, particularly due to the need for multiple encoder\nprocessing. In contrast, the second approach involves a complex label\ngeneration process, requiring accurate timestamps of all words spoken by all\nspeakers in the mixture, obtained from an external ASR system. In this paper,\nwe propose a novel alignment-free training scheme for the MT-RNNT (MT-RNNT-AFT)\nthat adopts the standard RNNT architecture. The target labels are created by\nappending a prompt token corresponding to each speaker at the beginning of the\ntranscription, reflecting the order of each speaker's appearance in the\nmixtures. Thus, MT-RNNT-AFT can be trained without relying on accurate\nalignments, and it can recognize all speakers' speech with just one round of\nencoder processing. Experiments show that MT-RNNT-AFT achieves performance\ncomparable to that of the state-of-the-art alternatives, while greatly\nsimplifying the training process.", "published": "2024-09-30 13:58:11", "link": "http://arxiv.org/abs/2409.20301v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OM4OV: Leveraging Ontology Matching for Ontology Versioning", "abstract": "Due to the dynamic nature of the semantic web, ontology version control is\nrequired to capture time-varying information, most importantly for widely-used\nontologies. Despite the long-standing recognition of ontology versioning (OV)\nas a crucial component for efficient ontology management, the growing size of\nontologies and accumulating errors caused by manual labour overwhelm current OV\napproaches. In this paper, we propose yet another approach to performing OV\nusing existing ontology matching (OM) techniques and systems. We introduce a\nunified OM4OV pipeline. From an OM perspective, we reconstruct a new task\nformulation, measurement, and testbed for OV tasks. Reusing the prior\nalignment(s) from OM, we propose a pipeline optimisation method called\ncross-reference (CR) mechanism to improve overall OV performance. We\nexperimentally validate the OM4OV pipeline and the cross-reference mechanism in\nmodified Ontology Alignment Evaluation Initiative (OAEI) datasets. We also\ndiscuss the insights on OM used for OV tasks, where some false mappings\ndetected by OV systems are not actually false.", "published": "2024-09-30 14:00:04", "link": "http://arxiv.org/abs/2409.20302v2", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Boosting Hybrid Autoregressive Transducer-based ASR with Internal\n  Acoustic Model Training and Dual Blank Thresholding", "abstract": "A hybrid autoregressive transducer (HAT) is a variant of neural transducer\nthat models blank and non-blank posterior distributions separately. In this\npaper, we propose a novel internal acoustic model (IAM) training strategy to\nenhance HAT-based speech recognition. IAM consists of encoder and joint\nnetworks, which are fully shared and jointly trained with HAT. This joint\ntraining not only enhances the HAT training efficiency but also encourages IAM\nand HAT to emit blanks synchronously which skips the more expensive non-blank\ncomputation, resulting in more effective blank thresholding for faster\ndecoding. Experiments demonstrate that the relative error reductions of the HAT\nwith IAM compared to the vanilla HAT are statistically significant. Moreover,\nwe introduce dual blank thresholding, which combines both HAT- and IAM-blank\nthresholding and a compatible decoding algorithm. This results in a 42-75%\ndecoding speed-up with no major performance degradation.", "published": "2024-09-30 14:14:45", "link": "http://arxiv.org/abs/2409.20313v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The Perfect Blend: Redefining RLHF with Mixture of Judges", "abstract": "Reinforcement learning from human feedback (RLHF) has become the leading\napproach for fine-tuning large language models (LLM). However, RLHF has\nlimitations in multi-task learning (MTL) due to challenges of reward hacking\nand extreme multi-objective optimization (i.e., trade-off of multiple and/or\nsometimes conflicting objectives). Applying RLHF for MTL currently requires\ncareful tuning of the weights for reward model and data combinations. This is\noften done via human intuition and does not generalize. In this work, we\nintroduce a novel post-training paradigm which we called Constrained Generative\nPolicy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with\ncost-efficient constrained policy optimization with stratification, which can\nidentify the perfect blend in RLHF in a principled manner. It shows strong\nempirical results with theoretical guarantees, does not require extensive\nhyper-parameter tuning, and is plug-and-play in common post-training pipelines.\nTogether, this can detect and mitigate reward hacking behaviors while reaching\na pareto-optimal point across an extremely large number of objectives.\n  Our empirical evaluations demonstrate that CGPO significantly outperforms\nstandard RLHF algorithms like PPO and DPO across various tasks including\ngeneral chat, STEM questions, instruction following, and coding. Specifically,\nCGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in\nArena-Hard (STEM & reasoning), and consistent gains in other domains like math\nand coding. Notably, PPO, while commonly used, is prone to severe reward\nhacking in popular coding benchmarks, which CGPO successfully addresses. This\nbreakthrough in RLHF not only tackles reward hacking and extreme\nmulti-objective optimization challenges but also advances the state-of-the-art\nin aligning general-purpose LLMs for diverse applications.", "published": "2024-09-30 15:06:53", "link": "http://arxiv.org/abs/2409.20370v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Word-wise intonation model for cross-language TTS systems", "abstract": "In this paper we propose a word-wise intonation model for Russian language\nand show how it can be generalized for other languages. The proposed model is\nsuitable for automatic data markup and its extended application to\ntext-to-speech systems. It can also be implemented for an intonation contour\nmodeling by using rule-based algorithms or by predicting contours with language\nmodels. The key idea is a partial elimination of the variability connected with\ndifferent placements of a stressed syllable in a word. It is achieved with\nsimultaneous applying of pitch simplification with a dynamic time warping\nclustering. The proposed model could be used as a tool for intonation research\nor as a backbone for prosody description in text-to-speech systems. As the\nadvantage of the model, we show its relations with the existing intonation\nsystems as well as the possibility of using language models for prosody\nprediction. Finally, we demonstrate some practical evidence of the system\nrobustness to parameter variations.", "published": "2024-09-30 15:09:42", "link": "http://arxiv.org/abs/2409.20374v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism,\n  and Mitigation", "abstract": "Code generation aims to automatically generate code from input requirements,\nsignificantly enhancing development efficiency. Recent large language models\n(LLMs) based approaches have shown promising results and revolutionized code\ngeneration task. Despite the promising performance, LLMs often generate\ncontents with hallucinations, especially for the code generation scenario\nrequiring the handling of complex contextual dependencies in practical\ndevelopment process. Although previous study has analyzed hallucinations in\nLLM-powered code generation, the study is limited to standalone function\ngeneration. In this paper, we conduct an empirical study to study the\nphenomena, mechanism, and mitigation of LLM hallucinations within more\npractical and complex development contexts in repository-level generation\nscenario. First, we manually examine the code generation results from six\nmainstream LLMs to establish a hallucination taxonomy of LLM-generated code.\nNext, we elaborate on the phenomenon of hallucinations, analyze their\ndistribution across different models. We then analyze causes of hallucinations\nand identify four potential factors contributing to hallucinations. Finally, we\npropose an RAG-based mitigation method, which demonstrates consistent\neffectiveness in all studied LLMs. The replication package including code,\ndata, and experimental results is available at\nhttps://github.com/DeepSoftwareAnalytics/LLMCodingHallucination", "published": "2024-09-30 17:51:15", "link": "http://arxiv.org/abs/2409.20550v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning", "abstract": "We present MM1.5, a new family of multimodal large language models (MLLMs)\ndesigned to enhance capabilities in text-rich image understanding, visual\nreferring and grounding, and multi-image reasoning. Building upon the MM1\narchitecture, MM1.5 adopts a data-centric approach to model training,\nsystematically exploring the impact of diverse data mixtures across the entire\nmodel training lifecycle. This includes high-quality OCR data and synthetic\ncaptions for continual pre-training, as well as an optimized visual\ninstruction-tuning data mixture for supervised fine-tuning. Our models range\nfrom 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE)\nvariants, and demonstrate that careful data curation and training strategies\ncan yield strong performance even at small scales (1B and 3B). Additionally, we\nintroduce two specialized variants: MM1.5-Video, designed for video\nunderstanding, and MM1.5-UI, tailored for mobile UI understanding. Through\nextensive empirical studies and ablations, we provide detailed insights into\nthe training processes and decisions that inform our final designs, offering\nvaluable guidance for future research in MLLM development.", "published": "2024-09-30 17:59:34", "link": "http://arxiv.org/abs/2409.20566v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Mamba for Streaming ASR Combined with Unimodal Aggregation", "abstract": "This paper works on streaming automatic speech recognition (ASR). Mamba, a\nrecently proposed state space model, has demonstrated the ability to match or\nsurpass Transformers in various tasks while benefiting from a linear complexity\nadvantage. We explore the efficiency of Mamba encoder for streaming ASR and\npropose an associated lookahead mechanism for leveraging controllable future\ninformation. Additionally, a streaming-style unimodal aggregation (UMA) method\nis implemented, which automatically detects token activity and streamingly\ntriggers token output, and meanwhile aggregates feature frames for better\nlearning token representation. Based on UMA, an early termination (ET) method\nis proposed to further reduce recognition latency. Experiments conducted on two\nMandarin Chinese datasets demonstrate that the proposed model achieves\ncompetitive ASR performance in terms of both recognition accuracy and latency.", "published": "2024-09-30 12:11:49", "link": "http://arxiv.org/abs/2410.00070v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fisher Information-based Efficient Curriculum Federated Learning with\n  Large Language Models", "abstract": "As a promising paradigm to collaboratively train models with decentralized\ndata, Federated Learning (FL) can be exploited to fine-tune Large Language\nModels (LLMs). While LLMs correspond to huge size, the scale of the training\ndata significantly increases, which leads to tremendous amounts of computation\nand communication costs. The training data is generally non-Independent and\nIdentically Distributed (non-IID), which requires adaptive data processing\nwithin each device. Although Low Rank Adaptation (LoRA) can significantly\nreduce the scale of parameters to update in the fine-tuning process, it still\ntakes unaffordable time to transfer the low-rank parameters of all the layers\nin LLMs. In this paper, we propose a Fisher Information-based Efficient\nCurriculum Federated Learning framework (FibecFed) with two novel methods,\ni.e., adaptive federated curriculum learning and efficient sparse parameter\nupdate. First, we propose a fisher information-based method to adaptively\nsample data within each device to improve the effectiveness of the FL\nfine-tuning process. Second, we dynamically select the proper layers for global\naggregation and sparse parameters for local update with LoRA so as to improve\nthe efficiency of the FL fine-tuning process. Extensive experimental results\nbased on 10 datasets demonstrate that FibecFed yields excellent performance (up\nto 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61%\nfaster) compared with 17 baseline approaches).", "published": "2024-09-30 18:12:18", "link": "http://arxiv.org/abs/2410.00131v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Are Large Language Models In-Context Personalized Summarizers? Get an\n  iCOPERNICUS Test Done!", "abstract": "Large Language Models (LLMs) have succeeded considerably in\nIn-Context-Learning (ICL) based summarization. However, saliency is subject to\nthe users' specific preference histories. Hence, we need reliable In-Context\nPersonalization Learning (ICPL) capabilities within such LLMs. For any\narbitrary LLM to exhibit ICPL, it needs to have the ability to discern contrast\nin user profiles. A recent study proposed a measure for\ndegree-of-personalization called EGISES for the first time. EGISES measures a\nmodel's responsiveness to user profile differences. However, it cannot test if\na model utilizes all three types of cues provided in ICPL prompts: (i) example\nsummaries, (ii) user's reading histories, and (iii) contrast in user profiles.\nTo address this, we propose the iCOPERNICUS framework, a novel In-COntext\nPERsonalization learNIng sCrUtiny of Summarization capability in LLMs that uses\nEGISES as a comparative measure. As a case-study, we evaluate 17\nstate-of-the-art LLMs based on their reported ICL performances and observe that\n15 models' ICPL degrades (min: 1.6%; max: 3.6%) when probed with richer\nprompts, thereby showing lack of true ICPL.", "published": "2024-09-30 18:45:00", "link": "http://arxiv.org/abs/2410.00149v1", "categories": ["cs.CL", "cs.LG", "cs.NE", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with\n  Gaussian Distribution", "abstract": "Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.", "published": "2024-09-30 18:52:53", "link": "http://arxiv.org/abs/2410.00153v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SSR: Alignment-Aware Modality Connector for Speech Language Models", "abstract": "Fusing speech into pre-trained language model (SpeechLM) usually suffers from\ninefficient encoding of long-form speech and catastrophic forgetting of\npre-trained text modality. We propose SSR-Connector (Segmented Speech\nRepresentation Connector) for better modality fusion. Leveraging speech-text\nalignments, our approach segments and compresses speech features to match the\ngranularity of text embeddings. Additionally, we introduce a two-stage training\npipeline that includes the distillation and fine-tuning phases to mitigate\ncatastrophic forgetting. SSR-Connector outperforms existing mechanism for\nspeech-text modality fusion, consistently achieving better speech understanding\n(e.g., +10 accuracy on StoryCloze and +20 on Speech-MMLU) while preserving\npre-trained text ability.", "published": "2024-09-30 19:17:46", "link": "http://arxiv.org/abs/2410.00168v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MM-Conv: A Multi-modal Conversational Dataset for Virtual Humans", "abstract": "In this paper, we present a novel dataset captured using a VR headset to\nrecord conversations between participants within a physics simulator\n(AI2-THOR). Our primary objective is to extend the field of co-speech gesture\ngeneration by incorporating rich contextual information within referential\nsettings. Participants engaged in various conversational scenarios, all based\non referential communication tasks. The dataset provides a rich set of\nmultimodal recordings such as motion capture, speech, gaze, and scene graphs.\nThis comprehensive dataset aims to enhance the understanding and development of\ngesture generation models in 3D scenes by providing diverse and contextually\nrich data.", "published": "2024-09-30 21:51:30", "link": "http://arxiv.org/abs/2410.00253v1", "categories": ["cs.CV", "cs.CL", "cs.GR", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning", "abstract": "Recent advancements in 3D Large Language Models (3DLLMs) have highlighted\ntheir potential in building general-purpose agents in the 3D real world, yet\nchallenges remain due to the lack of high-quality robust instruction-following\ndata, leading to limited discriminative power and generalization of 3DLLMs. In\nthis paper, we introduce Robin3D, a powerful 3DLLM trained on large-scale\ninstruction-following data generated by our novel data engine, Robust\nInstruction Generation (RIG) engine. RIG generates two key instruction data: 1)\nthe Adversarial Instruction-following data, which features mixed negative and\npositive samples to enhance the model's discriminative understanding. 2) the\nDiverse Instruction-following data, which contains various instruction styles\nto enhance model's generalization. As a result, we construct 1 million\ninstruction-following data, consisting of 344K Adversarial samples, 508K\nDiverse samples, and 165K benchmark training set samples. To better handle\nthese complex instructions, Robin3D first incorporates Relation-Augmented\nProjector to enhance spatial understanding, and then strengthens the object\nreferring and grounding ability through ID-Feature Bonding. Robin3D\nconsistently outperforms previous methods across five widely-used 3D multimodal\nlearning benchmarks, without the need for task-specific fine-tuning. Notably,\nwe achieve a 7.8\\% improvement in the grounding task (Multi3DRefer) and a 6.9\\%\nimprovement in the captioning task (Scan2Cap).", "published": "2024-09-30 21:55:38", "link": "http://arxiv.org/abs/2410.00255v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "The age of spiritual machines: Language quietus induces synthetic\n  altered states of consciousness in artificial intelligence", "abstract": "How is language related to consciousness? Language functions to categorise\nperceptual experiences (e.g., labelling interoceptive states as 'happy') and\nhigher-level constructs (e.g., using 'I' to represent the narrative self).\nPsychedelic use and meditation might be described as altered states that impair\nor intentionally modify the capacity for linguistic categorisation. For\nexample, psychedelic phenomenology is often characterised by 'oceanic\nboundlessness' or 'unity' and 'ego dissolution', which might be expected of a\nsystem unburdened by entrenched language categories. If language breakdown\nplays a role in producing such altered behaviour, multimodal artificial\nintelligence might align more with these phenomenological descriptions when\nattention is shifted away from language. We tested this hypothesis by comparing\nthe semantic embedding spaces from simulated altered states after manipulating\nattentional weights in CLIP and FLAVA models to embedding spaces from altered\nstates questionnaires before manipulation. Compared to random text and various\nother altered states including anxiety, models were more aligned with\ndisembodied, ego-less, spiritual, and unitive states, as well as minimal\nphenomenal experiences, with decreased attention to language and vision.\nReduced attention to language was associated with distinct linguistic patterns\nand blurred embeddings within and, especially, across semantic categories\n(e.g., 'giraffes' become more like 'bananas'). These results lend support to\nthe role of language categorisation in the phenomenology of altered states of\nconsciousness, like those experienced with high doses of psychedelics or\nconcentration meditation, states that often lead to improved mental health and\nwellbeing.", "published": "2024-09-30 22:03:26", "link": "http://arxiv.org/abs/2410.00257v1", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "DoPAMine: Domain-specific Pre-training Adaptation from seed-guided data\n  Mining", "abstract": "Large Language Models (LLMs) have shown remarkable ability to generalize\neffectively across numerous industry domains while executing a range of tasks.\nMany of these competencies are obtained from the data utilized during the\npre-training phase of the Language Models (LMs). However, these models exhibit\nlimitations when tasked with performing in specialized or low-resource industry\ndomains. More recent approaches use LLMs for generating domain-specific\nsynthetic data but most often they lack in truthfulness and complexity.\nAlternatively, in cases where domain data is available like healthcare and\nfinance most of the LMs are proprietary necessitating the need for a scalable\nmethod to curate real world industry specific pre-training data. In this work,\nwe propose an automated and scalable framework - DoPAMine:Domain-specific\nPre-training Adaptation from seed-guided data Mining, to mine domain specific\ntraining data from a large data corpus for domain adaptation of a LM. The\nframework leverages the parametric knowledge of a LLM to generate diverse and\nrepresentative seed data tailored to a specific domain which is then used to\nmine real world data from a large data corpus like Common Crawl. We evaluated\nour framework's performance in the continual pre-training (CPT) setting by\ntraining two domain specific 7B parameter LMs in healthcare and finance with\ndata mined via DoPAMine. Our experiments show that DoPAMine boosts the\nperformance of pre-trained LLMs on average by 4.9% and 5.1% in zero-shot and\n5-shot settings respectively on healthcare tasks from MMLU, MedQA, MedMCQA and\nPubMedQA datasets, and 2.9% and 6.7% for zero-shot and 5-shot settings\nrespectively on finance tasks from FiQA-SA, FPB and Headlines datasets when\ncompared to the baseline.", "published": "2024-09-30 22:15:58", "link": "http://arxiv.org/abs/2410.00260v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Social Conjuring: Multi-User Runtime Collaboration with AI in Building\n  Virtual 3D Worlds", "abstract": "Generative artificial intelligence has shown promise in prompting virtual\nworlds into existence, yet little attention has been given to understanding how\nthis process unfolds as social interaction. We present Social Conjurer, a\nframework for AI-augmented dynamic 3D scene co-creation, where multiple users\ncollaboratively build and modify virtual worlds in real-time. Through an\nexpanded set of interactions, including social and tool-based engagements as\nwell as spatial reasoning, our framework facilitates the creation of rich,\ndiverse virtual environments. Findings from a preliminary user study (N=12)\nprovide insight into the user experience of this approach, how social contexts\nshape the prompting of spatial environments, and perspective on social\napplications of prompt-based 3D co-creation. In addition to highlighting the\npotential of AI-supported multi-user world creation and offering new pathways\nfor AI-augmented creative processes in VR, this article presents a set of\nimplications for designing human-centered interfaces that incorporate AI models\ninto 3D content generation.", "published": "2024-09-30 23:02:51", "link": "http://arxiv.org/abs/2410.00274v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.ET"], "primary_category": "cs.HC"}
{"title": "FaithEval: Can Your Language Model Stay Faithful to Context, Even If\n  \"The Moon is Made of Marshmallows\"", "abstract": "Ensuring faithfulness to context in large language models (LLMs) and\nretrieval-augmented generation (RAG) systems is crucial for reliable deployment\nin real-world applications, as incorrect or unsupported information can erode\nuser trust. Despite advancements on standard benchmarks, faithfulness\nhallucination-where models generate responses misaligned with the provided\ncontext-remains a significant challenge. In this work, we introduce FaithEval,\na novel and comprehensive benchmark tailored to evaluate the faithfulness of\nLLMs in contextual scenarios across three diverse tasks: unanswerable,\ninconsistent, and counterfactual contexts. These tasks simulate real-world\nchallenges where retrieval mechanisms may surface incomplete, contradictory, or\nfabricated information. FaithEval comprises 4.9K high-quality problems in\ntotal, validated through a rigorous four-stage context construction and\nvalidation framework, employing both LLM-based auto-evaluation and human\nvalidation. Our extensive study across a wide range of open-source and\nproprietary models reveals that even state-of-the-art models often struggle to\nremain faithful to the given context, and that larger models do not necessarily\nexhibit improved faithfulness.Project is available at:\n\\url{https://github.com/SalesforceAIResearch/FaithEval}.", "published": "2024-09-30 06:27:53", "link": "http://arxiv.org/abs/2410.03727v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teuken-7B-Base & Teuken-7B-Instruct: Towards European LLMs", "abstract": "We present two multilingual LLMs designed to embrace Europe's linguistic\ndiversity by supporting all 24 official languages of the European Union.\nTrained on a dataset comprising around 60% non-English data and utilizing a\ncustom multilingual tokenizer, our models address the limitations of existing\nLLMs that predominantly focus on English or a few high-resource languages. We\ndetail the models' development principles, i.e., data composition, tokenizer\noptimization, and training methodologies. The models demonstrate competitive\nperformance across multilingual benchmarks, as evidenced by their performance\non European versions of ARC, HellaSwag, MMLU, and TruthfulQA.", "published": "2024-09-30 16:05:38", "link": "http://arxiv.org/abs/2410.03730v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Accent conversion using discrete units with parallel data synthesized\n  from controllable accented TTS", "abstract": "The goal of accent conversion (AC) is to convert speech accents while\npreserving content and speaker identity. Previous methods either required\nreference utterances during inference, did not preserve speaker identity well,\nor used one-to-one systems that could only be trained for each non-native\naccent. This paper presents a promising AC model that can convert many accents\ninto native to overcome these issues. Our approach utilizes discrete units,\nderived from clustering self-supervised representations of native speech, as an\nintermediary target for accent conversion. Leveraging multi-speaker\ntext-to-speech synthesis, it transforms these discrete representations back\ninto native speech while retaining the speaker identity. Additionally, we\ndevelop an efficient data augmentation method to train the system without\ndemanding a lot of non-native resources. Our system is proved to improve\nnon-native speaker fluency, sound like a native accent, and preserve original\nspeaker identity well.", "published": "2024-09-30 19:52:10", "link": "http://arxiv.org/abs/2410.03734v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Interactive Speculative Planning: Enhance Agent Efficiency through\n  Co-design of System and User Interface", "abstract": "Agents, as user-centric tools, are increasingly deployed for human task\ndelegation, assisting with a broad spectrum of requests by generating thoughts,\nengaging with user proxies, and producing action plans. However, agents based\non large language models (LLMs) often face substantial planning latency due to\ntwo primary factors: the efficiency limitations of the underlying LLMs due to\ntheir large size and high demand, and the structural complexity of the agents\ndue to the extensive generation of intermediate thoughts to produce the final\noutput. Given that inefficiency in service provision can undermine the value of\nautomation for users, this paper presents a human-centered efficient agent\nplanning method -- Interactive Speculative Planning -- aiming at enhancing the\nefficiency of agent planning through both system design and human-AI\ninteraction. Our approach advocates for the co-design of the agent system and\nuser interface, underscoring the importance of an agent system that can fluidly\nmanage user interactions and interruptions. By integrating human interruptions\nas a fundamental component of the system, we not only make it more user-centric\nbut also expedite the entire process by leveraging human-in-the-loop\ninteractions to provide accurate intermediate steps. Code and data will be\nreleased.", "published": "2024-09-30 16:52:51", "link": "http://arxiv.org/abs/2410.00079v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Mitigating Backdoor Threats to Large Language Models: Advancement and\n  Challenges", "abstract": "The advancement of Large Language Models (LLMs) has significantly impacted\nvarious domains, including Web search, healthcare, and software development.\nHowever, as these models scale, they become more vulnerable to cybersecurity\nrisks, particularly backdoor attacks. By exploiting the potent memorization\ncapacity of LLMs, adversaries can easily inject backdoors into LLMs by\nmanipulating a small portion of training data, leading to malicious behaviors\nin downstream applications whenever the hidden backdoor is activated by the\npre-defined triggers. Moreover, emerging learning paradigms like instruction\ntuning and reinforcement learning from human feedback (RLHF) exacerbate these\nrisks as they rely heavily on crowdsourced data and human feedback, which are\nnot fully controlled. In this paper, we present a comprehensive survey of\nemerging backdoor threats to LLMs that appear during LLM development or\ninference, and cover recent advancement in both defense and detection\nstrategies for mitigating backdoor threats to LLMs. We also outline key\nchallenges in addressing these threats, highlighting areas for future research.", "published": "2024-09-30 06:31:36", "link": "http://arxiv.org/abs/2409.19993v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.CR"}
{"title": "HDMoLE: Mixture of LoRA Experts with Hierarchical Routing and Dynamic\n  Thresholds for Fine-Tuning LLM-based ASR Models", "abstract": "Recent advancements in integrating Large Language Models (LLM) with automatic\nspeech recognition (ASR) have performed remarkably in general domains. While\nsupervised fine-tuning (SFT) of all model parameters is often employed to adapt\npre-trained LLM-based ASR models to specific domains, it imposes high\ncomputational costs and notably reduces their performance in general domains.\nIn this paper, we propose a novel parameter-efficient multi-domain fine-tuning\nmethod for adapting pre-trained LLM-based ASR models to multi-accent domains\nwithout catastrophic forgetting named \\textit{HDMoLE}, which leverages\nhierarchical routing and dynamic thresholds based on combining low-rank\nadaptation (LoRA) with the mixer of experts (MoE) and can be generalized to any\nlinear layer. Hierarchical routing establishes a clear correspondence between\nLoRA experts and accent domains, improving cross-domain collaboration among the\nLoRA experts. Unlike the static Top-K strategy for activating LoRA experts,\ndynamic thresholds can adaptively activate varying numbers of LoRA experts at\neach MoE layer. Experiments on the multi-accent and standard Mandarin datasets\ndemonstrate the efficacy of HDMoLE. Applying HDMoLE to an LLM-based ASR model\nprojector module achieves similar performance to full fine-tuning in the target\nmulti-accent domains while using only 9.6% of the trainable parameters required\nfor full fine-tuning and minimal degradation in the source general domain.", "published": "2024-09-30 02:23:31", "link": "http://arxiv.org/abs/2409.19878v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptive high-precision sound source localization at low frequencies\n  based on convolutional neural network", "abstract": "Sound source localization (SSL) technology plays a crucial role in various\napplication areas such as fault diagnosis, speech separation, and vibration\nnoise reduction. Although beamforming algorithms are widely used in SSL, their\nresolution at low frequencies is limited. In recent years, deep learning-based\nSSL methods have significantly improved their accuracy by employing large\nmicrophone arrays and training case specific neural networks, however, this\ncould lead to narrow applicability. To address these issues, this paper\nproposes a convolutional neural network-based method for high-precision SSL,\nwhich is adaptive in the lower frequency range under 1kHz with varying numbers\nof sound sources and microphone array-to-scanning grid distances. It takes the\npressure distribution on a relatively small microphone array as input to the\nneural network, and employs customized training labels and loss function to\ntrain the model. Prediction accuracy, adaptability and robustness of the\ntrained model under certain signal-to-noise ratio (SNR) are evaluated using\nrandomly generated test datasets, and compared with classical beamforming\nalgorithms, CLEAN-SC and DAMAS. Results of both planar and spatial sound source\ndistributions show that the proposed neural network model significantly\nimproves low-frequency localization accuracy, demonstrating its effectiveness\nand potential in SSL.", "published": "2024-09-30 07:38:25", "link": "http://arxiv.org/abs/2409.20031v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory\n  Spatial Attention Decoding", "abstract": "In complex auditory environments, the human auditory system possesses the\nremarkable ability to focus on a specific speaker while disregarding others. In\nthis study, a new model named SWIM, a short-window convolution neural network\n(CNN) integrated with Mamba, is proposed for identifying the locus of auditory\nattention (left or right) from electroencephalography (EEG) signals without\nrelying on speech envelopes. SWIM consists of two parts. The first is a\nshort-window CNN (SW$_\\text{CNN}$), which acts as a short-term EEG feature\nextractor and achieves a final accuracy of 84.9% in the leave-one-speaker-out\nsetup on the widely used KUL dataset. This improvement is due to the use of an\nimproved CNN structure, data augmentation, multitask training, and model\ncombination. The second part, Mamba, is a sequence model first applied to\nauditory spatial attention decoding to leverage the long-term dependency from\nprevious SW$_\\text{CNN}$ time steps. By joint training SW$_\\text{CNN}$ and\nMamba, the proposed SWIM structure uses both short-term and long-term\ninformation and achieves an accuracy of 86.2%, which reduces the classification\nerrors by a relative 31.0% compared to the previous state-of-the-art result.\nThe source code is available at https://github.com/windowso/SWIM-ASAD.", "published": "2024-09-30 02:28:32", "link": "http://arxiv.org/abs/2409.19884v2", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Active Listener: Continuous Generation of Listener's Head Motion\n  Response in Dyadic Interactions", "abstract": "A key component of dyadic spoken interactions is the contextually relevant\nnon-verbal gestures, such as head movements that reflect a listener's response\nto the interlocutor's speech. Although significant progress has been made in\nthe context of generating co-speech gestures, generating listener's response\nhas remained a challenge. We introduce the task of generating continuous head\nmotion response of a listener in response to the speaker's speech in real time.\nTo this end, we propose a graph-based end-to-end crossmodal model that takes\ninterlocutor's speech audio as input and directly generates head pose angles\n(roll, pitch, yaw) of the listener in real time. Different from previous work,\nour approach is completely data-driven, does not require manual annotations or\noversimplify head motion to merely nods and shakes. Extensive evaluation on the\ndyadic interaction sessions on the IEMOCAP dataset shows that our model\nproduces a low overall error (4.5 degrees) and a high frame rate, thereby\nindicating its deployability in real-world human-robot interaction systems. Our\ncode is available at - https://github.com/bigzen/Active-Listener", "published": "2024-09-30 11:04:28", "link": "http://arxiv.org/abs/2409.20188v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "Melody-Guided Music Generation", "abstract": "We present the Melody-Guided Music Generation (MG2) model, a novel approach\nusing melody to guide the text-to-music generation that, despite a simple\nmethod and limited resources, achieves excellent performance. Specifically, we\nfirst align the text with audio waveforms and their associated melodies using\nthe newly proposed Contrastive Language-Music Pretraining, enabling the learned\ntext representation fused with implicit melody information. Subsequently, we\ncondition the retrieval-augmented diffusion module on both text prompt and\nretrieved melody. This allows MG2 to generate music that reflects the content\nof the given text description, meantime keeping the intrinsic harmony under the\nguidance of explicit melody information. We conducted extensive experiments on\ntwo public datasets: MusicCaps and MusicBench. Surprisingly, the experimental\nresults demonstrate that the proposed MG2 model surpasses current open-source\ntext-to-music generation models, achieving this with fewer than 1/3 of the\nparameters or less than 1/200 of the training data compared to state-of-the-art\ncounterparts. Furthermore, we conducted comprehensive human evaluations\ninvolving three types of users and five perspectives, using newly designed\nquestionnaires to explore the potential real-world applications of MG2.", "published": "2024-09-30 11:13:35", "link": "http://arxiv.org/abs/2409.20196v4", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Proposal of protocols for speech materials acquisition and presentation\n  assisted by tools based on structured test signals", "abstract": "We propose protocols for acquiring speech materials, making them reusable for\nfuture investigations, and presenting them for subjective experiments. We also\nprovide means to evaluate existing speech materials' compatibility with target\napplications. We built these protocols and tools based on structured test\nsignals and analysis methods, including a new family of the Time-Stretched\nPulse (TSP). Over a billion times more powerful computational (including\nsoftware development) resources than a half-century ago enabled these protocols\nand tools to be accessible to under-resourced environments.", "published": "2024-09-30 17:19:35", "link": "http://arxiv.org/abs/2409.20516v1", "categories": ["eess.AS", "cs.SD", "eess.SP", "68-04", "J.2"], "primary_category": "eess.AS"}
{"title": "End-to-end Piano Performance-MIDI to Score Conversion with Transformers", "abstract": "The automated creation of accurate musical notation from an expressive human\nperformance is a fundamental task in computational musicology. To this end, we\npresent an end-to-end deep learning approach that constructs detailed musical\nscores directly from real-world piano performance-MIDI files. We introduce a\nmodern transformer-based architecture with a novel tokenized representation for\nsymbolic music data. Framing the task as sequence-to-sequence translation\nrather than note-wise classification reduces alignment requirements and\nannotation costs, while allowing the prediction of more concise and accurate\nnotation. To serialize symbolic music data, we design a custom tokenization\nstage based on compound tokens that carefully quantizes continuous values. This\ntechnique preserves more score information while reducing sequence lengths by\n$3.5\\times$ compared to prior approaches. Using the transformer backbone, our\nmethod demonstrates better understanding of note values, rhythmic structure,\nand details such as staff assignment. When evaluated end-to-end using\ntranscription metrics such as MUSTER, we achieve significant improvements over\nprevious deep learning approaches and complex HMM-based state-of-the-art\npipelines. Our method is also the first to directly predict notational details\nlike trill marks or stem direction from performance data. Code and models are\navailable at https://github.com/TimFelixBeyer/MIDI2ScoreTransformer", "published": "2024-09-30 20:11:37", "link": "http://arxiv.org/abs/2410.00210v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
