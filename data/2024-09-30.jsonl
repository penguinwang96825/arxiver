{"title": "GARCH-Informed Neural Networks for Volatility Prediction in Financial Markets", "abstract": "Volatility, which indicates the dispersion of returns, is a crucial measure\nof risk and is hence used extensively for pricing and discriminating between\ndifferent financial investments. As a result, accurate volatility prediction\nreceives extensive attention. The Generalized Autoregressive Conditional\nHeteroscedasticity (GARCH) model and its succeeding variants are well\nestablished models for stock volatility forecasting. More recently, deep\nlearning models have gained popularity in volatility prediction as they\ndemonstrated promising accuracy in certain time series prediction tasks.\nInspired by Physics-Informed Neural Networks (PINN), we constructed a new,\nhybrid Deep Learning model that combines the strengths of GARCH with the\nflexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus\ncapturing and forecasting market volatility more accurately than either class\nof models are capable of on their own. We refer to this novel model as a\nGARCH-Informed Neural Network (GINN). When compared to other time series\nmodels, GINN showed superior out-of-sample prediction performance in terms of\nthe Coefficient of Determination ($R^2$), Mean Squared Error (MSE), and Mean\nAbsolute Error (MAE).", "published": "2024-09-30 23:53:54", "link": "http://arxiv.org/abs/2410.00288v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Computing Systemic Risk Measures with Graph Neural Networks", "abstract": "This paper investigates systemic risk measures for stochastic financial\nnetworks of explicitly modelled bilateral liabilities. We extend the notion of\nsystemic risk measures from Biagini, Fouque, Fritelli and Meyer-Brandis (2019)\nto graph structured data. In particular, we focus on an aggregation function\nthat is derived from a market clearing algorithm proposed by Eisenberg and Noe\n(2001). In this setting, we show the existence of an optimal random allocation\nthat distributes the overall minimal bailout capital and secures the network.\nWe study numerical methods for the approximation of systemic risk and optimal\nrandom allocations. We propose to use permutation equivariant architectures of\nneural networks like graph neural networks (GNNs) and a class that we name\n(extended) permutation equivariant neural networks ((X)PENNs). We compare their\nperformance to several benchmark allocations. The main feature of GNNs and\n(X)PENNs is that they are permutation equivariant with respect to the\nunderlying graph data. In numerical experiments we find evidence that these\npermutation equivariant methods are superior to other approaches.", "published": "2024-09-30 10:18:13", "link": "http://arxiv.org/abs/2410.07222v1", "categories": ["q-fin.CP", "cs.LG", "q-fin.MF", "68T07, 91G45, 91G60, 91G70"], "primary_category": "q-fin.CP"}
{"title": "The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging", "abstract": "This paper proposes a novel method for constructing instruction-tuned large\nlanguage models (LLMs) for finance without instruction data. Traditionally,\ndeveloping such domain-specific LLMs has been resource-intensive, requiring a\nlarge dataset and significant computational power for continual pretraining and\ninstruction tuning. Our study proposes a simpler approach that combines\ndomain-specific continual pretraining with model merging. Given that\ngeneral-purpose pretrained LLMs and their instruction-tuned LLMs are often\npublicly available, they can be leveraged to obtain the necessary instruction\ntask vector. By merging this with a domain-specific pretrained vector, we can\neffectively create instruction-tuned LLMs for finance without additional\ninstruction data. Our process involves two steps: first, we perform continual\npretraining on financial data; second, we merge the instruction-tuned vector\nwith the domain-specific pretrained vector. Our experiments demonstrate the\nsuccessful construction of instruction-tuned LLMs for finance. One major\nadvantage of our method is that the instruction-tuned and domain-specific\npretrained vectors are nearly independent. This independence makes our approach\nhighly effective. The Japanese financial instruction-tuned LLMs we developed in\nthis study are available at\nhttps://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge.", "published": "2024-09-30 01:23:28", "link": "http://arxiv.org/abs/2409.19854v1", "categories": ["cs.CL", "econ.GN", "q-fin.CP", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Detecting Structural breakpoints in natural gas and electricity wholesale prices via Bayesian ensemble approach, in the era of energy prices turmoil of 2022 period: the cases of ten European markets", "abstract": "We investigate the impact of several critical events associated with the\nRusso Ukrainian war, started officially on 24 February 2022 with the Russian\ninvasion of Ukraine, on ten European electricity markets, two natural gas\nmarkets (the European reference trading hub TTF and N.Y. NGNMX market) and how\nthese markets interact to each other and with USDRUB exchange rate, a financial\nmarket. We analyze the reactions of these markets, manifested as breakpoints\nattributed to these critical events, and their interaction, by using a set of\nthree tools that can shed light on different aspects of this complex situation.\nWe combine the concepts of market efficiency, measured by quantifying the\nEfficient market hypothesis (EMH) via rolling Hurst exponent, with structural\nbreakpoints occurred in the time series of gas, electricity and financial\nmarkets, the detection of which is possible by using a Bayesian ensemble\napproach, the Bayesian Estimator of Abrupt change, Seasonal change and Trend\n(BEAST), a powerful tool that can effectively detect structural breakpoints,\ntrends, seasonalities and sudden abrupt changes in time series. The results\nshow that the analyzed markets have exhibited different modes of reactions to\nthe critical events, both in respect of number, nature, and time of occurrence\n(leading, lagging, concurrent with dates of critical events) of breakpoints as\nwell as of the dynamic behavior of their trend components.", "published": "2024-09-30 20:51:57", "link": "http://arxiv.org/abs/2410.07224v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "A Hierarchical conv-LSTM and LLM Integrated Model for Holistic Stock Forecasting", "abstract": "The financial domain presents a complex environment for stock market\nprediction, characterized by volatile patterns and the influence of\nmultifaceted data sources. Traditional models have leveraged either\nConvolutional Neural Networks (CNN) for spatial feature extraction or Long\nShort-Term Memory (LSTM) networks for capturing temporal dependencies, with\nlimited integration of external textual data. This paper proposes a novel\nTwo-Level Conv-LSTM Neural Network integrated with a Large Language Model (LLM)\nfor comprehensive stock advising. The model harnesses the strengths of\nConv-LSTM for analyzing time-series data and LLM for processing and\nunderstanding textual information from financial news, social media, and\nreports. In the first level, convolutional layers are employed to identify\nlocal patterns in historical stock prices and technical indicators, followed by\nLSTM layers to capture the temporal dynamics. The second level integrates the\noutput with an LLM that analyzes sentiment and contextual information from\ntextual data, providing a holistic view of market conditions. The combined\napproach aims to improve prediction accuracy and provide contextually rich\nstock advising.", "published": "2024-09-30 17:04:42", "link": "http://arxiv.org/abs/2410.12807v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "I.2.0; I.2.1"], "primary_category": "q-fin.ST"}
