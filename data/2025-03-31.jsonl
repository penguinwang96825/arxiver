{"title": "Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead", "abstract": "Inference-time scaling can enhance the reasoning capabilities of large\nlanguage models (LLMs) on complex problems that benefit from step-by-step\nproblem solving. Although lengthening generated scratchpads has proven\neffective for mathematical tasks, the broader impact of this approach on other\ntasks remains less clear. In this work, we investigate the benefits and\nlimitations of scaling methods across nine state-of-the-art models and eight\nchallenging tasks, including math and STEM reasoning, calendar planning,\nNP-hard problems, navigation, and spatial reasoning. We compare conventional\nmodels (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g.,\no1) through evaluation protocols that involve repeated model calls, either\nindependently or sequentially with feedback. These evaluations approximate\nlower and upper performance bounds and potential for future performance\nimprovements for each model, whether through enhanced training or multi-model\ninference systems. Our extensive empirical analysis reveals that the advantages\nof inference-time scaling vary across tasks and diminish as problem complexity\nincreases. In addition, simply using more tokens does not necessarily translate\nto higher accuracy in these challenging regimes. Results from multiple\nindependent runs with conventional models using perfect verifiers show that,\nfor some tasks, these models can achieve performance close to the average\nperformance of today's most advanced reasoning models. However, for other\ntasks, a significant performance gap remains, even in very high scaling\nregimes. Encouragingly, all models demonstrate significant gains when inference\nis further scaled with perfect verifiers or strong feedback, suggesting ample\npotential for future improvements.", "published": "2025-03-31 23:40:28", "link": "http://arxiv.org/abs/2504.00294v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2"], "primary_category": "cs.LG"}
{"title": "Do Chinese models speak Chinese languages?", "abstract": "The release of top-performing open-weight LLMs has cemented China's role as a\nleading force in AI development. Do these models support languages spoken in\nChina? Or do they speak the same languages as Western models? Comparing\nmultilingual capabilities is important for two reasons. First, language ability\nprovides insights into pre-training data curation, and thus into resource\nallocation and development priorities. Second, China has a long history of\nexplicit language policy, varying between inclusivity of minority languages and\na Mandarin-first policy. To test whether Chinese LLMs today reflect an agenda\nabout China's languages, we test performance of Chinese and Western open-source\nLLMs on Asian regional and Chinese minority languages. Our experiments on\nInformation Parity and reading comprehension show Chinese models' performance\nacross these languages correlates strongly (r=0.93) with Western models', with\nthe sole exception being better Mandarin. Sometimes, Chinese models cannot\nidentify languages spoken by Chinese minorities such as Kazakh and Uyghur, even\nthough they are good at French and German. These results provide a window into\ncurrent development priorities, suggest options for future development, and\nindicate guidance for end users.", "published": "2025-03-31 23:19:08", "link": "http://arxiv.org/abs/2504.00289v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "abstract": "Large Language Models (LLMs) are effective at deceiving, when prompted to do\nso. But under what conditions do they deceive spontaneously? Models that\ndemonstrate better performance on reasoning tasks are also better at prompted\ndeception. Do they also increasingly deceive spontaneously in situations where\nit could be considered rational to do so? This study evaluates spontaneous\ndeception produced by LLMs in a preregistered experimental protocol using tools\nfrom signaling theory. A range of proprietary closed-source and open-source\nLLMs are evaluated using modified 2x2 games (in the style of Prisoner's\nDilemma) augmented with a phase in which they can freely communicate to the\nother agent using unconstrained language. This setup creates an opportunity to\ndeceive, in conditions that vary in how useful deception might be to an agent's\nrational self-interest. The results indicate that 1) all tested LLMs\nspontaneously misrepresent their actions in at least some conditions, 2) they\nare generally more likely to do so in situations in which deception would\nbenefit them, and 3) models exhibiting better reasoning capacity overall tend\nto deceive at higher rates. Taken together, these results suggest a tradeoff\nbetween LLM reasoning capability and honesty. They also provide evidence of\nreasoning-like behavior in LLMs from a novel experimental configuration.\nFinally, they reveal certain contextual factors that affect whether LLMs will\ndeceive or not. We discuss consequences for autonomous, human-facing systems\ndriven by LLMs both now and as their reasoning capabilities continue to\nimprove.", "published": "2025-03-31 23:10:56", "link": "http://arxiv.org/abs/2504.00285v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Chunking for Document Classification for Urban System Management using Large Language Models", "abstract": "Urban systems are managed using complex textual documentation that need\ncoding and analysis to set requirements and evaluate built environment\nperformance. This paper contributes to the study of applying large-language\nmodels (LLM) to qualitative coding activities to reduce resource requirements\nwhile maintaining comparable reliability to humans. Qualitative coding and\nassessment face challenges like resource limitations and bias, accuracy, and\nconsistency between human evaluators. Here we report the application of LLMs to\ndeductively code 10 case documents on the presence of 17 digital twin\ncharacteristics for the management of urban systems. We utilize two prompting\nmethods to compare the semantic processing of LLMs with human coding efforts:\nwhole text analysis and text chunk analysis using OpenAI's GPT-4o, GPT-4o-mini,\nand o1-mini models. We found similar trends of internal variability between\nmethods and results indicate that LLMs may perform on par with human coders\nwhen initialized with specific deductive coding contexts. GPT-4o, o1-mini and\nGPT-4o-mini showed significant agreement with human raters when employed using\na chunking method. The application of both GPT-4o and GPT-4o-mini as an\nadditional rater with three manual raters showed statistically significant\nagreement across all raters, indicating that the analysis of textual documents\nis benefited by LLMs. Our findings reveal nuanced sub-themes of LLM application\nsuggesting LLMs follow human memory coding processes where whole-text analysis\nmay introduce multiple meanings. The novel contributions of this paper lie in\nassessing the performance of OpenAI GPT models and introduces the chunk-based\nprompting approach, which addresses context aggregation biases by preserving\nlocalized context.", "published": "2025-03-31 22:48:30", "link": "http://arxiv.org/abs/2504.00274v1", "categories": ["cs.CL", "cs.HC", "I.7.5; J.1"], "primary_category": "cs.CL"}
{"title": "Multilingual Sentiment Analysis of Summarized Texts: A Cross-Language Study of Text Shortening Effects", "abstract": "Summarization significantly impacts sentiment analysis across languages with\ndiverse morphologies. This study examines extractive and abstractive\nsummarization effects on sentiment classification in English, German, French,\nSpanish, Italian, Finnish, Hungarian, and Arabic. We assess sentiment shifts\npost-summarization using multilingual transformers (mBERT, XLM-RoBERTa, T5, and\nBART) and language-specific models (FinBERT, AraBERT). Results show extractive\nsummarization better preserves sentiment, especially in morphologically complex\nlanguages, while abstractive summarization improves readability but introduces\nsentiment distortion, affecting sentiment accuracy. Languages with rich\ninflectional morphology, such as Finnish, Hungarian, and Arabic, experience\ngreater accuracy drops than English or German. Findings emphasize the need for\nlanguage-specific adaptations in sentiment analysis and propose a hybrid\nsummarization approach balancing readability and sentiment preservation. These\ninsights benefit multilingual sentiment applications, including social media\nmonitoring, market analysis, and cross-lingual opinion mining.", "published": "2025-03-31 22:16:04", "link": "http://arxiv.org/abs/2504.00265v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers", "abstract": "This study evaluates large language models (LLMs) in generating code from\nalgorithm descriptions from recent NLP papers. The task requires two key\ncompetencies: (1) algorithm comprehension: synthesizing information from papers\nand academic literature to understand implementation logic, and (2) coding\nexpertise: identifying dependencies and correctly implementing necessary APIs.\nTo facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark\nof 100 tasks from 36 NLP papers published in 2024, featuring detailed\nannotations and comprehensive test cases. Building on SciReplicate-Bench, we\npropose Sci-Reproducer, a multi-agent framework consisting of a Paper Agent\nthat interprets algorithmic concepts from literature and a Code Agent that\nretrieves dependencies from repositories and implement solutions. To assess\nalgorithm understanding, we introduce reasoning graph accuracy, which\nquantifies similarity between generated and reference reasoning graphs derived\nfrom code comments and structure. For evaluating implementation quality, we\nemploy execution accuracy, CodeBLEU, and repository dependency/API recall\nmetrics. In our experiments, we evaluate various powerful Non-Reasoning LLMs\nand Reasoning LLMs as foundational models. The best-performing LLM using\nSci-Reproducer achieves only 39% execution accuracy, highlighting the\nbenchmark's difficulty.Our analysis identifies missing or inconsistent\nalgorithm descriptions as key barriers to successful reproduction. We will\nopen-source our benchmark, and code at\nhttps://github.com/xyzCS/SciReplicate-Bench.", "published": "2025-03-31 22:02:24", "link": "http://arxiv.org/abs/2504.00255v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.SE"], "primary_category": "cs.CL"}
{"title": "ElaLoRA: Elastic & Learnable Low-Rank Adaptation for Efficient Model Fine-Tuning", "abstract": "Low-Rank Adaptation (LoRA) has become a widely adopted technique for\nfine-tuning large-scale pre-trained models with minimal parameter updates.\nHowever, existing methods rely on fixed ranks or focus solely on either rank\npruning or expansion, failing to adapt ranks dynamically to match the\nimportance of different layers during training. In this work, we propose\nElaLoRA, an adaptive low-rank adaptation framework that dynamically prunes and\nexpands ranks based on gradient-derived importance scores. To the best of our\nknowledge, ElaLoRA is the first method that enables both rank pruning and\nexpansion during fine-tuning. Experiments across multiple benchmarks\ndemonstrate that ElaLoRA consistently outperforms existing PEFT methods across\ndifferent parameter budgets. Furthermore, our studies validate that layers\nreceiving higher rank allocations contribute more significantly to model\nperformance, providing theoretical justification for our adaptive strategy. By\nintroducing a principled and adaptive rank allocation mechanism, ElaLoRA offers\na scalable and efficient fine-tuning solution, particularly suited for\nresource-constrained environments.", "published": "2025-03-31 21:58:25", "link": "http://arxiv.org/abs/2504.00254v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future to eDemorcacy", "abstract": "This paper investigates the use of Large Language Models (LLMs) to synthesize\npublic opinion data, addressing challenges in traditional survey methods like\ndeclining response rates and non-response bias. We introduce a novel technique:\nrole creation based on knowledge injection, a form of in-context learning that\nleverages RAG and specified personality profiles from the HEXACO model and\ndemographic information, and uses that for dynamically generated prompts. This\nmethod allows LLMs to simulate diverse opinions more accurately than existing\nprompt engineering approaches. We compare our results with pre-trained models\nwith standard few-shot prompts. Experiments using questions from the\nCooperative Election Study (CES) demonstrate that our role-creation approach\nsignificantly improves the alignment of LLM-generated opinions with real-world\nhuman survey responses, increasing answer adherence. In addition, we discuss\nchallenges, limitations and future research directions.", "published": "2025-03-31 21:21:52", "link": "http://arxiv.org/abs/2504.00241v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$\\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "abstract": "Most discussions about Large Language Model (LLM) safety have focused on\nsingle-agent settings but multi-agent LLM systems now create novel adversarial\nrisks because their behavior depends on communication between agents and\ndecentralized reasoning. In this work, we innovatively focus on attacking\npragmatic systems that have constrains such as limited token bandwidth, latency\nbetween message delivery, and defense mechanisms. We design a\n$\\textit{permutation-invariant adversarial attack}$ that optimizes prompt\ndistribution across latency and bandwidth-constraint network topologies to\nbypass distributed safety mechanisms within the system. Formulating the attack\npath as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the\nnovel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage\ngraph-based optimization to maximize attack success rate while minimizing\ndetection risk. Evaluating across models including $\\texttt{Llama}$,\n$\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on\nvarious datasets like $\\texttt{JailBreakBench}$ and\n$\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up\nto $7\\times$, exposing critical vulnerabilities in multi-agent systems.\nMoreover, we demonstrate that existing defenses, including variants of\n$\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack,\nemphasizing the urgent need for multi-agent specific safety mechanisms.", "published": "2025-03-31 20:43:56", "link": "http://arxiv.org/abs/2504.00218v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Insight-RAG: Enhancing LLMs with Insight-Driven Augmentation", "abstract": "Retrieval Augmented Generation (RAG) frameworks have shown significant\npromise in leveraging external knowledge to enhance the performance of large\nlanguage models (LLMs). However, conventional RAG methods often retrieve\ndocuments based solely on surface-level relevance, leading to many issues: they\nmay overlook deeply buried information within individual documents, miss\nrelevant insights spanning multiple sources, and are not well-suited for tasks\nbeyond traditional question answering. In this paper, we propose Insight-RAG, a\nnovel framework designed to address these issues. In the initial stage of\nInsight-RAG, instead of using traditional retrieval methods, we employ an LLM\nto analyze the input query and task, extracting the underlying informational\nrequirements. In the subsequent stage, a specialized LLM -- trained on the\ndocument database -- is queried to mine content that directly addresses these\nidentified insights. Finally, by integrating the original query with the\nretrieved insights, similar to conventional RAG approaches, we employ a final\nLLM to generate a contextually enriched and accurate response. Using two\nscientific paper datasets, we created evaluation benchmarks targeting each of\nthe mentioned issues and assessed Insight-RAG against traditional RAG pipeline.\nOur results demonstrate that the Insight-RAG pipeline successfully addresses\nthese challenges, outperforming existing methods by a significant margin in\nmost cases. These findings suggest that integrating insight-driven retrieval\nwithin the RAG framework not only enhances performance but also broadens the\napplicability of RAG to tasks beyond conventional question answering.", "published": "2025-03-31 19:50:27", "link": "http://arxiv.org/abs/2504.00187v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency", "abstract": "Retrieval Augmented Generation (RAG) systems have emerged as a powerful\nmethod for enhancing large language models (LLMs) with up-to-date information.\nHowever, the retrieval step in RAG can sometimes surface documents containing\ncontradictory information, particularly in rapidly evolving domains such as\nnews. These contradictions can significantly impact the performance of LLMs,\nleading to inconsistent or erroneous outputs. This study addresses this\ncritical challenge in two ways. First, we present a novel data generation\nframework to simulate different types of contradictions that may occur in the\nretrieval stage of a RAG system. Second, we evaluate the robustness of\ndifferent LLMs in performing as context validators, assessing their ability to\ndetect contradictory information within retrieved document sets. Our\nexperimental results reveal that context validation remains a challenging task\neven for state-of-the-art LLMs, with performance varying significantly across\ndifferent types of contradictions. While larger models generally perform better\nat contradiction detection, the effectiveness of different prompting strategies\nvaries across tasks and model architectures. We find that chain-of-thought\nprompting shows notable improvements for some models but may hinder performance\nin others, highlighting the complexity of the task and the need for more robust\napproaches to context validation in RAG systems.", "published": "2025-03-31 19:41:15", "link": "http://arxiv.org/abs/2504.00180v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Boundless Byte Pair Encoding: Breaking the Pre-tokenization Barrier", "abstract": "Pre-tokenization, the initial step in many modern tokenization pipelines,\nsegments text into smaller units called pretokens, typically splitting on\nwhitespace and punctuation. While this process encourages having full,\nindividual words as tokens, it introduces a fundamental limitation in most\ntokenization algorithms such as Byte Pair Encoding (BPE). Specifically,\npre-tokenization causes the distribution of tokens in a corpus to heavily skew\ntowards common, full-length words. This skewed distribution limits the benefits\nof expanding to larger vocabularies, since the additional tokens appear with\nprogressively lower counts. To overcome this barrier, we propose BoundlessBPE,\na modified BPE algorithm that relaxes the pretoken boundary constraint. Our\napproach selectively merges two complete pretokens into a larger unit we term a\nsuperword. Superwords are not necessarily semantically cohesive. For example,\nthe pretokens \" of\" and \" the\" might be combined to form the superword \" of\nthe\". This merging strategy results in a substantially more uniform\ndistribution of tokens across a corpus than standard BPE, and compresses text\nmore effectively, with an approximate 20% increase in bytes per token.", "published": "2025-03-31 19:36:29", "link": "http://arxiv.org/abs/2504.00178v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Does \"Reasoning\" with Large Language Models Improve Recognizing, Generating, and Reframing Unhelpful Thoughts?", "abstract": "Cognitive Reframing, a core element of Cognitive Behavioral Therapy (CBT),\nhelps individuals reinterpret negative experiences by finding positive meaning.\nRecent advances in Large Language Models (LLMs) have demonstrated improved\nperformance through reasoning-based strategies. This inspires a promising\ndirection of leveraging the reasoning capabilities of LLMs to improve CBT and\nmental reframing by simulating the process of critical thinking, potentially\nenabling more effective recognition, generation, and reframing of cognitive\ndistortions. In this work, we investigate the role of various reasoning\nmethods, including pre-trained reasoning LLMs and augmented reasoning\nstrategies such as CoT and self-consistency in enhancing LLMs' ability to\nperform cognitive reframing tasks. We find that augmented reasoning methods,\neven when applied to \"outdated\" LLMs like GPT-3.5, consistently outperform\nstate-of-the-art pretrained reasoning models on recognizing, generating and\nreframing unhelpful thoughts.", "published": "2025-03-31 19:19:34", "link": "http://arxiv.org/abs/2504.00163v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Universal Zero-shot Embedding Inversion", "abstract": "Embedding inversion, i.e., reconstructing text given its embedding and\nblack-box access to the embedding encoder, is a fundamental problem in both NLP\nand security. From the NLP perspective, it helps determine how much semantic\ninformation about the input is retained in the embedding. From the security\nperspective, it measures how much information is leaked by vector databases and\nembedding-based retrieval systems. State-of-the-art methods for embedding\ninversion, such as vec2text, have high accuracy but require (a) training a\nseparate model for each embedding, and (b) a large number of queries to the\ncorresponding encoder.\n  We design, implement, and evaluate ZSInvert, a zero-shot inversion method\nbased on the recently proposed adversarial decoding technique. ZSInvert is\nfast, query-efficient, and can be used for any text embedding without training\nan embedding-specific inversion model. We measure the effectiveness of ZSInvert\non several embeddings and demonstrate that it recovers key semantic information\nabout the corresponding texts.", "published": "2025-03-31 18:55:01", "link": "http://arxiv.org/abs/2504.00147v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "abstract": "In-Context Learning (ICL) is an intriguing ability of large language models\n(LLMs). Despite a substantial amount of work on its behavioral aspects and how\nit emerges in miniature setups, it remains unclear which mechanism assembles\ntask information from the individual examples in a fewshot prompt. We use\ncausal interventions to identify information flow in Gemma-2 2B for five\nnaturalistic ICL tasks. We find that the model infers task information using a\ntwo-step strategy we call contextualize-then-aggregate: In the lower layers,\nthe model builds up representations of individual fewshot examples, which are\ncontextualized by preceding examples through connections between fewshot input\nand output tokens across the sequence. In the higher layers, these\nrepresentations are aggregated to identify the task and prepare prediction of\nthe next output. The importance of the contextualization step differs between\ntasks, and it may become more important in the presence of ambiguous examples.\nOverall, by providing rigorous causal analysis, our results shed light on the\nmechanisms through which ICL happens in language models.", "published": "2025-03-31 18:33:55", "link": "http://arxiv.org/abs/2504.00132v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs for Explainable AI: A Comprehensive Survey", "abstract": "Large Language Models (LLMs) offer a promising approach to enhancing\nExplainable AI (XAI) by transforming complex machine learning outputs into\neasy-to-understand narratives, making model predictions more accessible to\nusers, and helping bridge the gap between sophisticated model behavior and\nhuman interpretability. AI models, such as state-of-the-art neural networks and\ndeep learning models, are often seen as \"black boxes\" due to a lack of\ntransparency. As users cannot fully understand how the models reach\nconclusions, users have difficulty trusting decisions from AI models, which\nleads to less effective decision-making processes, reduced accountabilities,\nand unclear potential biases. A challenge arises in developing explainable AI\n(XAI) models to gain users' trust and provide insights into how models generate\ntheir outputs. With the development of Large Language Models, we want to\nexplore the possibilities of using human language-based models, LLMs, for model\nexplainabilities. This survey provides a comprehensive overview of existing\napproaches regarding LLMs for XAI, and evaluation techniques for LLM-generated\nexplanation, discusses the corresponding challenges and limitations, and\nexamines real-world applications. Finally, we discuss future directions by\nemphasizing the need for more interpretable, automated, user-centric, and\nmultidisciplinary approaches for XAI via LLMs.", "published": "2025-03-31 18:19:41", "link": "http://arxiv.org/abs/2504.00125v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy", "abstract": "Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.", "published": "2025-03-31 17:59:52", "link": "http://arxiv.org/abs/2503.24388v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.", "published": "2025-03-31 17:58:07", "link": "http://arxiv.org/abs/2503.24377v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1", "abstract": "Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.", "published": "2025-03-31 17:55:23", "link": "http://arxiv.org/abs/2503.24376v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Effectively Controlling Reasoning Models through Thinking Intervention", "abstract": "Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.", "published": "2025-03-31 17:50:13", "link": "http://arxiv.org/abs/2503.24370v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Query and Conquer: Execution-Guided SQL Generation", "abstract": "We propose a novel approach for generating complex outputs that significantly\nimproves accuracy in text-to-SQL tasks. Our method leverages execution results\nto select the most semantically consistent query from multiple candidates,\nenabling smaller, cost-effective models to surpass computationally intensive\nreasoning methods such as o1, o3-mini, and DeepSeek R1 while reducing inference\ncost by as much as 30 times. It integrates effortlessly with existing models,\noffering a practical and scalable pathway to state-of-the-art SQL generation.", "published": "2025-03-31 17:43:36", "link": "http://arxiv.org/abs/2503.24364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQuat: Subspace-orthogonal KV Cache Quantization", "abstract": "The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.", "published": "2025-03-31 17:37:32", "link": "http://arxiv.org/abs/2503.24358v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion", "abstract": "Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.", "published": "2025-03-31 17:34:59", "link": "http://arxiv.org/abs/2503.24354v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models", "abstract": "In this research, we introduce BEATS, a novel framework for evaluating Bias,\nEthics, Fairness, and Factuality in Large Language Models (LLMs). Building upon\nthe BEATS framework, we present a bias benchmark for LLMs that measure\nperformance across 29 distinct metrics. These metrics span a broad range of\ncharacteristics, including demographic, cognitive, and social biases, as well\nas measures of ethical reasoning, group fairness, and factuality related\nmisinformation risk. These metrics enable a quantitative assessment of the\nextent to which LLM generated responses may perpetuate societal prejudices that\nreinforce or expand systemic inequities. To achieve a high score on this\nbenchmark a LLM must show very equitable behavior in their responses, making it\na rigorous standard for responsible AI evaluation. Empirical results based on\ndata from our experiment show that, 37.65\\% of outputs generated by industry\nleading models contained some form of bias, highlighting a substantial risk of\nusing these models in critical decision making systems. BEATS framework and\nbenchmark offer a scalable and statistically rigorous methodology to benchmark\nLLMs, diagnose factors driving biases, and develop mitigation strategies. With\nthe BEATS framework, our goal is to help the development of more socially\nresponsible and ethically aligned AI models.", "published": "2025-03-31 16:56:52", "link": "http://arxiv.org/abs/2503.24310v1", "categories": ["cs.CL", "cs.AI", "68T01 (Primary), 68T50 (Secondary)", "I.2.0; I.2.7"], "primary_category": "cs.CL"}
{"title": "A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG", "abstract": "This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.", "published": "2025-03-31 16:54:04", "link": "http://arxiv.org/abs/2503.24307v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is analogy enough to draw novel adjective-noun inferences?", "abstract": "Recent work (Ross et al., 2025, 2024) has argued that the ability of humans\nand LLMs respectively to generalize to novel adjective-noun combinations shows\nthat they each have access to a compositional mechanism to determine the\nphrase's meaning and derive inferences. We study whether these inferences can\ninstead be derived by analogy to known inferences, without need for\ncomposition. We investigate this by (1) building a model of analogical\nreasoning using similarity over lexical items, and (2) asking human\nparticipants to reason by analogy. While we find that this strategy works well\nfor a large proportion of the dataset of Ross et al. (2025), there are novel\ncombinations for which both humans and LLMs derive convergent inferences but\nwhich are not well handled by analogy. We thus conclude that the mechanism\nhumans and LLMs use to generalize in these cases cannot be fully reduced to\nanalogy, and likely involves composition.", "published": "2025-03-31 16:41:16", "link": "http://arxiv.org/abs/2503.24293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model", "abstract": "We introduce Open-Reasoner-Zero, the first open source implementation of\nlarge-scale reasoning-oriented RL training focusing on scalability, simplicity\nand accessibility. Through extensive experiments, we demonstrate that a\nminimalist approach, vanilla PPO with GAE ($\\lambda=1$, $\\gamma=1$) and\nstraightforward rule-based rewards, without any KL regularization, is\nsufficient to scale up both response length and benchmark performance, similar\nto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model as\nDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance on\nAIME2024, MATH500, and the GPQA Diamond benchmark while demonstrating\nremarkable efficiency -- requiring only a tenth of the training steps, compared\nto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release our\nsource code, parameter settings, training data, and model weights across\nvarious sizes.", "published": "2025-03-31 16:36:05", "link": "http://arxiv.org/abs/2503.24290v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning", "abstract": "We propose Rec-R1, a general reinforcement learning framework that bridges\nlarge language models (LLMs) with recommendation systems through closed-loop\noptimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1\ndirectly optimizes LLM generation using feedback from a fixed black-box\nrecommendation model, without relying on synthetic SFT data from proprietary\nmodels such as GPT-4o. This avoids the substantial cost and effort required for\ndata distillation. To verify the effectiveness of Rec-R1, we evaluate it on two\nrepresentative tasks: product search and sequential recommendation.\nExperimental results demonstrate that Rec-R1 not only consistently outperforms\nprompting- and SFT-based methods, but also achieves significant gains over\nstrong discriminative baselines, even when used with simple retrievers such as\nBM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM,\nunlike SFT, which often impairs instruction-following and reasoning. These\nfindings suggest Rec-R1 as a promising foundation for continual task-specific\nadaptation without catastrophic forgetting.", "published": "2025-03-31 16:36:00", "link": "http://arxiv.org/abs/2503.24289v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MaintainCoder: Maintainable Code Generation Under Dynamic Requirements", "abstract": "Modern code generation has made significant strides in functional correctness\nand execution efficiency. However, these systems often overlook a critical\ndimension in real-world software development: maintainability. To handle\ndynamic requirements with minimal rework, we propose MaintainCoder as a\npioneering solution. It integrates Waterfall model, design patterns, and\nmulti-agent collaboration to systematically enhance cohesion, reduce coupling,\nand improve adaptability. We also introduce MaintainBench, a benchmark\ncomprising requirement changes and corresponding dynamic metrics on\nmaintainance effort. Experiments demonstrate that existing code generation\nmethods struggle to meet maintainability standards when requirements evolve. In\ncontrast, MaintainCoder improves maintainability metrics by 14-30% with even\nhigher correctness, i.e. pass@k. Our work not only provides the foundation of\nmaintainable code generation, but also highlights the need for more holistic\ncode quality research. Resources:\nhttps://github.com/IAAR-Shanghai/MaintainCoder.", "published": "2025-03-31 16:06:47", "link": "http://arxiv.org/abs/2503.24260v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation", "abstract": "Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches.", "published": "2025-03-31 15:58:08", "link": "http://arxiv.org/abs/2503.24245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models", "abstract": "As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.", "published": "2025-03-31 15:46:15", "link": "http://arxiv.org/abs/2503.24235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PAARS: Persona Aligned Agentic Retail Shoppers", "abstract": "In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.", "published": "2025-03-31 15:41:51", "link": "http://arxiv.org/abs/2503.24228v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "BAR-Analytics: A Web-based Platform for Analyzing Information Spreading Barriers in News: Comparative Analysis Across Multiple Barriers and Events", "abstract": "This paper presents BAR-Analytics, a web-based, open-source platform designed\nto analyze news dissemination across geographical, economic, political, and\ncultural boundaries. Using the Russian-Ukrainian and Israeli-Palestinian\nconflicts as case studies, the platform integrates four analytical methods:\npropagation analysis, trend analysis, sentiment analysis, and temporal topic\nmodeling. Over 350,000 articles were collected and analyzed, with a focus on\neconomic disparities and geographical influences using metadata enrichment. We\nevaluate the case studies using coherence, sentiment polarity, topic frequency,\nand trend shifts as key metrics. Our results show distinct patterns in news\ncoverage: the Israeli-Palestinian conflict tends to have more negative\nsentiment with a focus on human rights, while the Russia-Ukraine conflict is\nmore positive, emphasizing election interference. These findings highlight the\ninfluence of political, economic, and regional factors in shaping media\nnarratives across different conflicts.", "published": "2025-03-31 15:36:55", "link": "http://arxiv.org/abs/2503.24220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing", "abstract": "We propose a unified framework that integrates object detection (OD) and\nvisual grounding (VG) for remote sensing (RS) imagery. To support conventional\nOD and establish an intuitive prior for VG task, we fine-tune an open-set\nobject detector using referring expression data, framing it as a partially\nsupervised OD task. In the first stage, we construct a graph representation of\neach image, comprising object queries, class embeddings, and proposal\nlocations. Then, our task-aware architecture processes this graph to perform\nthe VG task. The model consists of: (i) a multi-branch network that integrates\nspatial, visual, and categorical features to generate task-aware proposals, and\n(ii) an object reasoning network that assigns probabilities across proposals,\nfollowed by a soft selection mechanism for final referring object localization.\nOur model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG\ndatasets, achieving significant improvements over state-of-the-art methods\nwhile retaining classical OD capabilities. The code will be available in our\nrepository: \\url{https://github.com/rd20karim/MB-ORES}.", "published": "2025-03-31 15:36:41", "link": "http://arxiv.org/abs/2503.24219v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Synthetic News Generation for Fake News Classification", "abstract": "This study explores the generation and evaluation of synthetic fake news\nthrough fact based manipulations using large language models (LLMs). We\nintroduce a novel methodology that extracts key facts from real articles,\nmodifies them, and regenerates content to simulate fake news while maintaining\ncoherence. To assess the quality of the generated content, we propose a set of\nevaluation metrics coherence, dissimilarity, and correctness. The research also\ninvestigates the application of synthetic data in fake news classification,\ncomparing traditional machine learning models with transformer based models\nsuch as BERT. Our experiments demonstrate that transformer models, especially\nBERT, effectively leverage synthetic data for fake news detection, showing\nimprovements with smaller proportions of synthetic data. Additionally, we find\nthat fact verification features, which focus on identifying factual\ninconsistencies, provide the most promising results in distinguishing synthetic\nfake news. The study highlights the potential of synthetic data to enhance fake\nnews detection systems, offering valuable insights for future research and\nsuggesting that targeted improvements in synthetic data generation can further\nstrengthen detection models.", "published": "2025-03-31 15:24:05", "link": "http://arxiv.org/abs/2503.24206v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TwT: Thinking without Tokens by Habitual Reasoning Distillation with Multi-Teachers' Guidance", "abstract": "Large Language Models (LLMs) have made significant strides in problem-solving\nby incorporating reasoning processes. However, this enhanced reasoning\ncapability results in an increased number of output tokens during inference,\nleading to higher computational costs. To address this challenge, we propose\nTwT (Thinking without Tokens), a method that reduces inference-time costs\nthrough habitual reasoning distillation with multi-teachers' guidance, while\nmaintaining high performance. Our approach introduces a Habitual Reasoning\nDistillation method, which internalizes explicit reasoning into the model's\nhabitual behavior through a Teacher-Guided compression strategy inspired by\nhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling\n(DCRS), a technique that generates a high-quality and diverse distillation\ndataset using multiple teacher models, making our method suitable for\nunsupervised scenarios. Experimental results demonstrate that TwT effectively\nreduces inference costs while preserving superior performance, achieving up to\na 13.6% improvement in accuracy with fewer output tokens compared to other\ndistillation methods, offering a highly practical solution for efficient LLM\ndeployment.", "published": "2025-03-31 15:16:31", "link": "http://arxiv.org/abs/2503.24198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit In-Context Learning: Evidence from Artificial Language Experiments", "abstract": "Humans acquire language through implicit learning, absorbing complex patterns\nwithout explicit awareness. While LLMs demonstrate impressive linguistic\ncapabilities, it remains unclear whether they exhibit human-like pattern\nrecognition during in-context learning at inferencing level. We adapted three\nclassic artificial language learning experiments spanning morphology,\nmorphosyntax, and syntax to systematically evaluate implicit learning at\ninferencing level in two state-of-the-art OpenAI models: gpt-4o and o3-mini.\nOur results reveal linguistic domain-specific alignment between models and\nhuman behaviors, o3-mini aligns better in morphology while both models align in\nsyntax.", "published": "2025-03-31 15:07:08", "link": "http://arxiv.org/abs/2503.24190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology", "abstract": "Effective physician-patient communications in pre-diagnostic environments,\nand most specifically in complex and sensitive medical areas such as\ninfertility, are critical but consume a lot of time and, therefore, cause\nclinic workflows to become inefficient. Recent advancements in Large Language\nModels (LLMs) offer a potential solution for automating conversational medical\nhistory-taking and improving diagnostic accuracy. This study evaluates the\nfeasibility and performance of LLMs in those tasks for infertility cases. An\nAI-driven conversational system was developed to simulate physician-patient\ninteractions with ChatGPT-4o and ChatGPT-4o-mini. A total of 70 real-world\ninfertility cases were processed, generating 420 diagnostic histories. Model\nperformance was assessed using F1 score, Differential Diagnosis (DDs) Accuracy,\nand Accuracy of Infertility Type Judgment (ITJ). ChatGPT-4o-mini outperformed\nChatGPT-4o in information extraction accuracy (F1 score: 0.9258 vs. 0.9029, p =\n0.045, d = 0.244) and demonstrated higher completeness in medical\nhistory-taking (97.58% vs. 77.11%), suggesting that ChatGPT-4o-mini is more\neffective in extracting detailed patient information, which is critical for\nimproving diagnostic accuracy. In contrast, ChatGPT-4o performed slightly\nbetter in differential diagnosis accuracy (2.0524 vs. 2.0048, p > 0.05). ITJ\naccuracy was higher in ChatGPT-4o-mini (0.6476 vs. 0.5905) but with lower\nconsistency (Cronbach's $\\alpha$ = 0.562), suggesting variability in\nclassification reliability. Both models demonstrated strong feasibility in\nautomating infertility history-taking, with ChatGPT-4o-mini excelling in\ncompleteness and extraction accuracy. In future studies, expert validation for\naccuracy and dependability in a clinical setting, AI model fine-tuning, and\nlarger datasets with a mix of cases of infertility have to be prioritized.", "published": "2025-03-31 14:09:53", "link": "http://arxiv.org/abs/2504.00061v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Task Learning for Extracting Menstrual Characteristics from Clinical Notes", "abstract": "Menstrual health is a critical yet often overlooked aspect of women's\nhealthcare. Despite its clinical relevance, detailed data on menstrual\ncharacteristics is rarely available in structured medical records. To address\nthis gap, we propose a novel Natural Language Processing pipeline to extract\nkey menstrual cycle attributes -- dysmenorrhea, regularity, flow volume, and\nintermenstrual bleeding. Our approach utilizes the GatorTron model with\nMulti-Task Prompt-based Learning, enhanced by a hybrid retrieval preprocessing\nstep to identify relevant text segments. It out- performs baseline methods,\nachieving an average F1-score of 90% across all menstrual characteristics,\ndespite being trained on fewer than 100 annotated clinical notes. The retrieval\nstep consistently improves performance across all approaches, allowing the\nmodel to focus on the most relevant segments of lengthy clinical notes. These\nresults show that combining multi-task learning with retrieval improves\ngeneralization and performance across menstrual charac- teristics, advancing\nautomated extraction from clinical notes and supporting women's health\nresearch.", "published": "2025-03-31 14:07:03", "link": "http://arxiv.org/abs/2503.24116v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection", "abstract": "The detection of telecom fraud faces significant challenges due to the lack\nof high-quality multimodal training data that integrates audio signals with\nreasoning-oriented textual analysis. To address this gap, we present\nTeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset\nspecifically designed for automated telecom fraud analysis. Our dataset is\nconstructed through three strategies: (1) Privacy-preserved text-truth sample\ngeneration using automatically speech recognition (ASR)-transcribed call\nrecordings (with anonymized original audio), ensuring real-world consistency\nthrough text-to-speech (TTS) model regeneration; (2) Semantic enhancement via\nlarge language model (LLM)-based self-instruction sampling on authentic ASR\noutputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that\nsimulates emerging fraud tactics through predefined communication scenarios and\nfraud typologies. The generated dataset contains 28,511 rigorously processed\nspeech-text pairs, complete with detailed annotations for fraud reasoning. The\ndataset is divided into three tasks: scenario classification, fraud detection,\nfraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a\nstandardized evaluation benchmark comprising proportionally sampled instances\nfrom the dataset, to facilitate systematic testing of model performance on\ntelecom fraud detection tasks. We also contribute a production-optimized\nsupervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while\nopen-sourcing the data processing framework to enable community-driven dataset\nexpansion. This work establishes a foundational framework for multimodal\nanti-fraud research while addressing critical challenges in data privacy and\nscenario diversity. The project will be released at\nhttps://github.com/JimmyMa99/TeleAntiFraud.", "published": "2025-03-31 14:06:17", "link": "http://arxiv.org/abs/2503.24115v3", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition", "abstract": "Despite advances in embodied AI, agent reasoning systems still struggle to\ncapture the fundamental conceptual structures that humans naturally use to\nunderstand and interact with their environment. To address this, we propose a\nnovel framework that bridges embodied cognition theory and agent systems by\nleveraging a formal characterization of image schemas, which are defined as\nrecurring patterns of sensorimotor experience that structure human cognition.\nBy customizing LLMs to translate natural language descriptions into formal\nrepresentations based on these sensorimotor patterns, we will be able to create\na neurosymbolic system that grounds the agent's understanding in fundamental\nconceptual structures. We argue that such an approach enhances both efficiency\nand interpretability while enabling more intuitive human-agent interactions\nthrough shared embodied understanding.", "published": "2025-03-31 14:01:39", "link": "http://arxiv.org/abs/2503.24110v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?", "abstract": "Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs.", "published": "2025-03-31 13:56:03", "link": "http://arxiv.org/abs/2503.24102v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data", "abstract": "Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.", "published": "2025-03-31 13:22:34", "link": "http://arxiv.org/abs/2503.24062v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crossing Boundaries: Leveraging Semantic Divergences to Explore Cultural Novelty in Cooking Recipes", "abstract": "Novelty modeling and detection is a core topic in Natural Language Processing\n(NLP), central to numerous tasks such as recommender systems and automatic\nsummarization. It involves identifying pieces of text that deviate in some way\nfrom previously known information. However, novelty is also a crucial\ndeterminant of the unique perception of relevance and quality of an experience,\nas it rests upon each individual's understanding of the world. Social factors,\nparticularly cultural background, profoundly influence perceptions of novelty\nand innovation. Cultural novelty arises from differences in salience and\nnovelty as shaped by the distance between distinct communities. While cultural\ndiversity has garnered increasing attention in artificial intelligence (AI),\nthe lack of robust metrics for quantifying cultural novelty hinders a deeper\nunderstanding of these divergences. This gap limits quantifying and\nunderstanding cultural differences within computational frameworks. To address\nthis, we propose an interdisciplinary framework that integrates knowledge from\nsociology and management. Central to our approach is GlobalFusion, a novel\ndataset comprising 500 dishes and approximately 100,000 cooking recipes\ncapturing cultural adaptation from over 150 countries. By introducing a set of\nJensen-Shannon Divergence metrics for novelty, we leverage this dataset to\nanalyze textual divergences when recipes from one community are modified by\nanother with a different cultural background. The results reveal significant\ncorrelations between our cultural novelty metrics and established cultural\nmeasures based on linguistic, religious, and geographical distances. Our\nfindings highlight the potential of our framework to advance the understanding\nand measurement of cultural diversity in AI.", "published": "2025-03-31 12:52:52", "link": "http://arxiv.org/abs/2503.24027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness Tradeoff in Translation", "abstract": "The goal of translation, be it by human or by machine, is, given some text in\na source language, to produce text in a target language that simultaneously 1)\npreserves the meaning of the source text and 2) achieves natural expression in\nthe target language. However, researchers in the machine translation community\nusually assess translations using a single score intended to capture semantic\naccuracy and the naturalness of the output simultaneously. In this paper, we\nbuild on recent advances in information theory to mathematically prove and\nempirically demonstrate that such single-score summaries do not and cannot give\nthe complete picture of a system's true performance. Concretely, we prove that\na tradeoff exists between accuracy and naturalness and demonstrate it by\nevaluating the submissions to the WMT24 shared task. Our findings help explain\nwell-known empirical phenomena, such as the observation that optimizing\ntranslation systems for a specific accuracy metric (like BLEU) initially\nimproves the system's naturalness, while ``overfitting'' the system to the\nmetric can significantly degrade its naturalness. Thus, we advocate for a\nchange in how translations are evaluated: rather than comparing systems using a\nsingle number, they should be compared on an accuracy-naturalness plane.", "published": "2025-03-31 12:39:51", "link": "http://arxiv.org/abs/2503.24013v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing representations of long clinical texts for the task of patient note-identification", "abstract": "In this paper, we address the challenge of patient-note identification, which\ninvolves accurately matching an anonymized clinical note to its corresponding\npatient, represented by a set of related notes. This task has broad\napplications, including duplicate records detection and patient similarity\nanalysis, which require robust patient-level representations. We explore\nvarious embedding methods, including Hierarchical Attention Networks (HAN),\nthree-level Hierarchical Transformer Networks (HTN), LongFormer, and advanced\nBERT-based models, focusing on their ability to process mediumto-long clinical\ntexts effectively. Additionally, we evaluate different pooling strategies\n(mean, max, and mean_max) for aggregating wordlevel embeddings into\npatient-level representations and we examine the impact of sliding windows on\nmodel performance. Our results indicate that BERT-based embeddings outperform\ntraditional and hierarchical models, particularly in processing lengthy\nclinical notes and capturing nuanced patient representations. Among the pooling\nstrategies, mean_max pooling consistently yields the best results, highlighting\nits ability to capture critical features from clinical notes. Furthermore, the\nreproduction of our results on both MIMIC dataset and Necker hospital data\nwarehouse illustrates the generalizability of these approaches to real-world\napplications, emphasizing the importance of both embedding methods and\naggregation strategies in optimizing patient-note identification and enhancing\npatient-level modeling.", "published": "2025-03-31 12:31:44", "link": "http://arxiv.org/abs/2503.24006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BeMERC: Behavior-Aware MLLM-based Framework for Multimodal Emotion Recognition in Conversation", "abstract": "Multimodal emotion recognition in conversation (MERC), the task of\nidentifying the emotion label for each utterance in a conversation, is vital\nfor developing empathetic machines. Current MLLM-based MERC studies focus\nmainly on capturing the speaker's textual or vocal characteristics, but ignore\nthe significance of video-derived behavior information. Different from text and\naudio inputs, learning videos with rich facial expression, body language and\nposture, provides emotion trigger signals to the models for more accurate\nemotion predictions. In this paper, we propose a novel behavior-aware\nMLLM-based framework (BeMERC) to incorporate speaker's behaviors, including\nsubtle facial micro-expression, body language and posture, into a vanilla\nMLLM-based MERC model, thereby facilitating the modeling of emotional dynamics\nduring a conversation. Furthermore, BeMERC adopts a two-stage instruction\ntuning strategy to extend the model to the conversations scenario for\nend-to-end training of a MERC predictor. Experiments demonstrate that BeMERC\nachieves superior performance than the state-of-the-art methods on two\nbenchmark datasets, and also provides a detailed discussion on the significance\nof video-derived behavior information in MERC.", "published": "2025-03-31 12:04:53", "link": "http://arxiv.org/abs/2503.23990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Humor Generation in Large Language Models: Temperature Configurations and Architectural Trade-offs", "abstract": "Large language models (LLMs) demonstrate increasing capabilities in creative\ntext generation, yet systematic evaluations of their humor production remain\nunderexplored. This study presents a comprehensive analysis of 13\nstate-of-the-art LLMs across five architectural families, evaluating their\nperformance in generating technically relevant humor for software developers.\nThrough a full factorial design testing 715 unique configurations of\ntemperature settings and prompt variations, we assess model outputs using five\nweighted criteria: humor quality, domain relevance, concept originality, tone\nprecision, and delivery efficiency. Our methodology employs rigorous\nstatistical analysis including ANOVA, correlation studies, and quadratic\nregression to identify optimal configurations and architectural influences.\nResults reveal significant performance variations across models, with certain\narchitectures achieving 21.8% superiority over baseline systems. Temperature\nsensitivity analysis demonstrates that 73% of models achieve peak performance\nat lower stochasticity settings (<= 0.5), though optimal ranges vary\nsubstantially by architecture. We identify distinct model clusters: compact\nhigh-performers maintaining efficiency-quality balance versus verbose\nspecialists requiring longer outputs for marginal gains. Statistical validation\nconfirms model architecture explains 38.7% of performance variance, with\nsignificant correlations between humor quality and concept originality. The\nstudy establishes practical guidelines for model selection and configuration,\ndemonstrating how temperature adjustments and architectural considerations\nimpact humor generation effectiveness. These findings advance understanding of\nLLM capabilities in creative technical writing and provide empirically\nvalidated configuration strategies for developers implementing humor-generation\nsystems.", "published": "2025-03-31 10:35:12", "link": "http://arxiv.org/abs/2504.02858v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Model Hemorrhage and the Robustness Limits of Large Language Models", "abstract": "Large language models (LLMs) demonstrate strong performance across natural\nlanguage processing tasks, yet undergo significant performance degradation when\nmodified for deployment through quantization, pruning, or decoding strategy\nadjustments. We define this phenomenon as model hemorrhage - performance\ndecline caused by parameter alterations and architectural changes. Through\nsystematic analysis of various LLM frameworks, we identify key vulnerability\npatterns: layer expansion frequently disrupts attention mechanisms, compression\ntechniques induce information loss cascades, and decoding adjustments amplify\nprediction divergences. Our investigation reveals transformer architectures\nexhibit inherent robustness thresholds that determine hemorrhage severity\nacross modification types. We propose three mitigation strategies:\ngradient-aware pruning preserves critical weight pathways, dynamic quantization\nscaling maintains activation integrity, and decoding calibration aligns\ngeneration trajectories with original model distributions. This work\nestablishes foundational metrics for evaluating model stability during\nadaptation, providing practical guidelines for maintaining performance while\nenabling efficient LLM deployment. Our findings advance understanding of neural\nnetwork resilience under architectural transformations, particularly for\nlarge-scale language models.", "published": "2025-03-31 10:16:03", "link": "http://arxiv.org/abs/2503.23924v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entropy-Based Adaptive Weighting for Self-Training", "abstract": "The mathematical problem-solving capabilities of large language models have\nbecome a focal point of research, with growing interests in leveraging\nself-generated reasoning paths as a promising way to refine and enhance these\nmodels. These paths capture step-by-step logical processes while requiring only\nthe correct answer for supervision. The self-training method has been shown to\nbe effective in reasoning tasks while eliminating the need for external models\nand manual annotations. However, optimizing the use of self-generated data for\nmodel training remains an open challenge. In this work, we propose\nEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptive\nweighting strategy designed to prioritize uncertain data during self-training.\nSpecifically, EAST employs a mapping function with a tunable parameter that\ncontrols the sharpness of the weighting, assigning higher weights to data where\nthe model exhibits greater uncertainty. This approach guides the model to focus\non more informative and challenging examples, thereby enhancing its reasoning\nability. We evaluate our approach on GSM8K and MATH benchmarks. Empirical\nresults show that, while the vanilla method yields virtually no improvement\n(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,\nEAST attains a further 1-2% performance boost compared to the vanilla method.", "published": "2025-03-31 10:04:35", "link": "http://arxiv.org/abs/2503.23913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset", "abstract": "The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code will be made\navailable upon acceptance.", "published": "2025-03-31 09:48:59", "link": "http://arxiv.org/abs/2503.23899v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Better wit than wealth: Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement", "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.", "published": "2025-03-31 09:46:35", "link": "http://arxiv.org/abs/2503.23895v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to Accelerate Your Speech-LLM Development", "abstract": "High-quality speech dialogue datasets are crucial for Speech-LLM development,\nyet existing acquisition methods face significant limitations. Human recordings\nincur high costs and privacy concerns, while synthetic approaches often lack\nconversational authenticity. To address these challenges, we introduce\n\\textsc{SpeechDialogueFactory}, a production-ready framework for generating\nnatural speech dialogues efficiently. Our solution employs a comprehensive\npipeline including metadata generation, dialogue scripting,\nparalinguistic-enriched utterance simulation, and natural speech synthesis with\nvoice cloning. Additionally, the system provides an interactive UI for detailed\nsample inspection and a high-throughput batch synthesis mode. Evaluations show\nthat dialogues generated by our system achieve a quality comparable to human\nrecordings while significantly reducing production costs. We release our work\nas an open-source toolkit, alongside example datasets available in English and\nChinese, empowering researchers and developers in Speech-LLM research and\ndevelopment.", "published": "2025-03-31 08:52:21", "link": "http://arxiv.org/abs/2503.23848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crossing the Reward Bridge: Expanding RL with Verifiable Rewards Across Diverse Domains", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has demonstrated\nsignificant success in enhancing mathematical reasoning and coding performance\nof large language models (LLMs), especially when structured reference answers\nare accessible for verification. However, its extension to broader, less\nstructured domains remains unexplored. In this work, we investigate the\neffectiveness and scalability of RLVR across diverse real-world domains\nincluding medicine, chemistry, psychology, economics, and education, where\nstructured reference answers are typically unavailable. We reveal that binary\nverification judgments on broad-domain tasks exhibit high consistency across\nvarious LLMs provided expert-written reference answers exist. Motivated by this\nfinding, we utilize a generative scoring technique that yields soft,\nmodel-based reward signals to overcome limitations posed by binary\nverifications, especially in free-form, unstructured answer scenarios. We\nfurther demonstrate the feasibility of training cross-domain generative reward\nmodels using relatively small (7B) LLMs without the need for extensive\ndomain-specific annotation. Through comprehensive experiments, our RLVR\nframework establishes clear performance gains, significantly outperforming\nstate-of-the-art open-source aligned models such as Qwen2.5-72B and\nDeepSeek-R1-Distill-Qwen-32B across domains in free-form settings. Our approach\nnotably enhances the robustness, flexibility, and scalability of RLVR,\nrepresenting a substantial step towards practical reinforcement learning\napplications in complex, noisy-label scenarios.", "published": "2025-03-31 08:22:49", "link": "http://arxiv.org/abs/2503.23829v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Did ChatGPT or Copilot use alter the style of internet news headlines? A time series regression analysis", "abstract": "The release of advanced Large Language Models (LLMs) such as ChatGPT and\nCopilot is changing the way text is created and may influence the content that\nwe find on the web. This study investigated whether the release of these two\npopular LLMs coincided with a change in writing style in headlines and links on\nworldwide news websites. 175 NLP features were obtained for each text in a\ndataset of 451 million headlines/links. An interrupted time series analysis was\napplied for each of the 175 NLP features to evaluate whether there were any\nstatistically significant sustained changes after the release dates of ChatGPT\nand/or Copilot. There were a total of 44 features that did not appear to have\nany significant sustained change after the release of ChatGPT/Copilot. A total\nof 91 other features did show significant change with ChatGPT and/or Copilot\nalthough significance with earlier control LLM release dates (GPT-1/2/3,\nGopher) removed them from consideration. This initial analysis suggests these\nlanguage models may have had a limited impact on the style of individual news\nheadlines/links, with respect to only some NLP measures.", "published": "2025-03-31 07:44:26", "link": "http://arxiv.org/abs/2503.23811v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Get the Agents Drunk: Memory Perturbations in Autonomous Agent-based Recommender Systems", "abstract": "Large language model-based agents are increasingly used in recommender\nsystems (Agent4RSs) to achieve personalized behavior modeling. Specifically,\nAgent4RSs introduces memory mechanisms that enable the agents to autonomously\nlearn and self-evolve from real-world interactions. However, to the best of our\nknowledge, how robust Agent4RSs are remains unexplored. As such, in this paper,\nwe propose the first work to attack Agent4RSs by perturbing agents' memories,\nnot only to uncover their limitations but also to enhance their security and\nrobustness, ensuring the development of safer and more reliable AI agents.\n  Given the security and privacy concerns, it is more practical to launch\nattacks under a black-box setting, where the accurate knowledge of the victim\nmodels cannot be easily obtained. Moreover, the practical attacks are often\nstealthy to maximize the impact. To this end, we propose a novel practical\nattack framework named DrunkAgent. DrunkAgent consists of a generation module,\na strategy module, and a surrogate module. The generation module aims to\nproduce effective and coherent adversarial textual triggers, which can be used\nto achieve attack objectives such as promoting the target items. The strategy\nmodule is designed to `get the target agents drunk' so that their memories\ncannot be effectively updated during the interaction process. As such, the\ntriggers can play the best role. Both of the modules are optimized on the\nsurrogate module to improve the transferability and imperceptibility of the\nattacks. By identifying and analyzing the vulnerabilities, our work provides\ncritical insights that pave the way for building safer and more resilient\nAgent4RSs. Extensive experiments across various real-world datasets demonstrate\nthe effectiveness of DrunkAgent.", "published": "2025-03-31 07:35:40", "link": "http://arxiv.org/abs/2503.23804v1", "categories": ["cs.CR", "cs.CL", "cs.IR", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Adaptive Layer-skipping in Pre-trained LLMs", "abstract": "Various layer-skipping methods have been proposed to accelerate token\ngeneration in large language models (LLMs). However, they have overlooked a\nfundamental question: How do computational demands vary across the generation\nof different tokens? In this work, we introduce FlexiDepth, a method that\ndynamically adjusts the number of Transformer layers used in text generation.\nBy incorporating a plug-in router and adapter, FlexiDepth enables adaptive\nlayer-skipping in LLMs without modifying their original parameters. Introducing\nFlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32,\nand meanwhile maintains the full 100\\% benchmark performance. Experimental\nresults with FlexiDepth demonstrate that computational demands in LLMs\nsignificantly vary based on token type. Specifically, generating repetitive\ntokens or fixed phrases requires fewer layers, whereas producing tokens\ninvolving computation or high uncertainty requires more layers. Interestingly,\nthis adaptive allocation pattern aligns with human intuition. To advance\nresearch in this area, we open sourced FlexiDepth and a dataset documenting\nFlexiDepth's layer allocation patterns for future exploration.", "published": "2025-03-31 07:20:58", "link": "http://arxiv.org/abs/2503.23798v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with Common Sense Categorization", "abstract": "In this study, we take a closer look at how Winograd schema challenges can be\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\ngenerative models of different sizes on the popular WinoGrande benchmark. We\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\nchallenge across five common sense knowledge categories, giving more\nfine-grained insights on what types of knowledge are more challenging for LLMs.\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\nthis is an effect of benchmark memorization, we match benchmark instances to\nLLM trainingdata and create two test-suites. We observe that memorization has a\nminimal effect on model performance on WinoGrande.", "published": "2025-03-31 06:53:53", "link": "http://arxiv.org/abs/2503.23779v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CONGRAD:Conflicting Gradient Filtering for Multilingual Preference Alignment", "abstract": "Naive joint training of large language models (LLMs) for multilingual\npreference alignment can suffer from negative interference. This is a known\nissue in multilingual training, where conflicting objectives degrade overall\nperformance. However, the impact of this phenomenon in the context of\nmultilingual preference alignment remains largely underexplored. To address\nthis issue, we propose CONGRAD, a scalable and effective filtering method that\nselects high-quality preference samples with minimal gradient conflicts across\nlanguages. Our method leverages gradient surgery to retain samples aligned with\nan aggregated multilingual update direction. Additionally, we incorporate a\nsublinear gradient compression strategy that reduces memory overhead during\ngradient accumulation. We integrate CONGRAD into self-rewarding framework and\nevaluate on LLaMA3-8B and Gemma2-2B across 10 languages. Results show that\nCONGRAD consistently outperforms strong baselines in both seen and unseen\nlanguages, with minimal alignment tax.", "published": "2025-03-31 06:52:56", "link": "http://arxiv.org/abs/2503.23777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition", "abstract": "Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic\ncapabilities, achieving impressive performance in various tasks such as image\nrecognition and object localization. However, their effectiveness in\nfine-grained tasks remains an open question. In everyday scenarios, individuals\nencountering design materials, such as magazines, typography tutorials,\nresearch papers, or branding content, may wish to identify aesthetically\npleasing fonts used in the text. Given their multimodal capabilities and free\naccessibility, many VLMs are often considered potential tools for font\nrecognition. This raises a fundamental question: Do VLMs truly possess the\ncapability to recognize fonts? To investigate this, we introduce the Font\nRecognition Benchmark (FRB), a compact and well-structured dataset comprising\n15 commonly used fonts. FRB includes two versions: (i) an easy version, where\n10 sentences are rendered in different fonts, and (ii) a hard version, where\neach text sample consists of the names of the 15 fonts themselves, introducing\na stroop effect that challenges model perception. Through extensive evaluation\nof various VLMs on font recognition tasks, we arrive at the following key\nfindings: (i) Current VLMs exhibit limited font recognition capabilities, with\nmany state-of-the-art models failing to achieve satisfactory performance. (ii)\nFew-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits\nin improving font recognition accuracy across different VLMs. (iii) Attention\nanalysis sheds light on the inherent limitations of VLMs in capturing semantic\nfeatures.", "published": "2025-03-31 06:33:21", "link": "http://arxiv.org/abs/2503.23768v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Towards a cognitive architecture to enable natural language interaction in co-constructive task learning", "abstract": "This research addresses the question, which characteristics a cognitive\narchitecture must have to leverage the benefits of natural language in\nCo-Constructive Task Learning (CCTL). To provide context, we first discuss\nInteractive Task Learning (ITL), the mechanisms of the human memory system, and\nthe significance of natural language and multi-modality. Next, we examine the\ncurrent state of cognitive architectures, analyzing their capabilities to\ninform a concept of CCTL grounded in multiple sources. We then integrate\ninsights from various research domains to develop a unified framework. Finally,\nwe conclude by identifying the remaining challenges and requirements necessary\nto achieve CCTL in Human-Robot Interaction (HRI).", "published": "2025-03-31 06:23:14", "link": "http://arxiv.org/abs/2503.23760v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "abstract": "Short-video platforms have gained immense popularity, captivating the\ninterest of millions, if not billions, of users globally. Recently, researchers\nhave highlighted the significance of analyzing the propagation of short-videos,\nwhich typically involves discovering commercial values, public opinions, user\nbehaviors, etc. This paper proposes a new Short-video Propagation Influence\nRating (SPIR) task and aims to promote SPIR from both the dataset and method\nperspectives. First, we propose a new Cross-platform Short-Video (XS-Video)\ndataset, which aims to provide a large-scale and real-world short-video\npropagation network across various platforms to facilitate the research on\nshort-video propagation. Our XS-Video dataset includes 117,720 videos, 381,926\nsamples, and 535 topics across 5 biggest Chinese platforms, annotated with the\npropagation influence from level 0 to 9. To the best of our knowledge, this is\nthe first large-scale short-video dataset that contains cross-platform data or\nprovides all of the views, likes, shares, collects, fans, comments, and comment\ncontent. Second, we propose a Large Graph Model (LGM) named NetGPT, based on a\nnovel three-stage training mechanism, to bridge heterogeneous graph-structured\ndata with the powerful reasoning ability and knowledge of Large Language Models\n(LLMs). Our NetGPT can comprehend and analyze the short-video propagation\ngraph, enabling it to predict the long-term propagation influence of\nshort-videos. Comprehensive experimental results evaluated by both\nclassification and regression metrics on our XS-Video dataset indicate the\nsuperiority of our method for SPIR.", "published": "2025-03-31 05:53:15", "link": "http://arxiv.org/abs/2503.23746v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM", "cs.SI"], "primary_category": "cs.CV"}
{"title": "LANID: LLM-assisted New Intent Discovery", "abstract": "Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.", "published": "2025-03-31 05:34:32", "link": "http://arxiv.org/abs/2503.23740v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization", "abstract": "Recently, model merging methods have demonstrated powerful strengths in\ncombining abilities on various tasks from multiple Large Language Models\n(LLMs). While previous model merging methods mainly focus on merging\nhomogeneous models with identical architecture, they meet challenges when\ndealing with Multimodal Large Language Models (MLLMs) with inherent\nheterogeneous property, including differences in model architecture and the\nasymmetry in the parameter space. In this work, we propose AdaMMS, a novel\nmodel merging method tailored for heterogeneous MLLMs. Our method tackles the\nchallenges in three steps: mapping, merging and searching. Specifically, we\nfirst design mapping function between models to apply model merging on MLLMs\nwith different architecture. Then we apply linear interpolation on model\nweights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally in\nthe hyper-parameter searching step, we propose an unsupervised hyper-parameter\nselection method for model merging. As the first model merging method capable\nof merging heterogeneous MLLMs without labeled data, extensive experiments on\nvarious model combinations demonstrated that AdaMMS outperforms previous model\nmerging methods on various vision-language benchmarks.", "published": "2025-03-31 05:13:02", "link": "http://arxiv.org/abs/2503.23733v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language", "abstract": "The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA", "published": "2025-03-31 05:04:25", "link": "http://arxiv.org/abs/2503.23730v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models", "abstract": "Instruction tuning is crucial for enabling Large Language Models (LLMs) to\nsolve real-world tasks. Prior work has shown the effectiveness of\ninstruction-tuning data synthesized solely from LLMs, raising a fundamental\nquestion: Do we still need human-originated signals for instruction tuning?\nThis work answers the question affirmatively: we build state-of-the-art\ninstruction-tuning datasets sourced from human-written instructions, by simply\npairing them with LLM-generated responses. LLMs fine-tuned on our datasets\nconsistently outperform those fine-tuned on existing ones. Our data\nconstruction approach can be easily adapted to other languages; we build\ndatasets for Japanese and confirm that LLMs tuned with our data reach\nstate-of-the-art performance. Analyses suggest that instruction-tuning in a new\nlanguage allows LLMs to follow instructions, while the tuned models exhibit a\nnotable lack of culture-specific knowledge in that language. The datasets and\nfine-tuned models will be publicly available. Our datasets, synthesized with\nopen-weight LLMs, are openly distributed under permissive licenses, allowing\nfor diverse use cases.", "published": "2025-03-31 04:28:38", "link": "http://arxiv.org/abs/2503.23714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records", "abstract": "Objective: Electronic health records (EHR) are widely available to complement\nadministrative data-based disease surveillance and healthcare performance\nevaluation. Defining conditions from EHR is labour-intensive and requires\nextensive manual labelling of disease outcomes. This study developed an\nefficient strategy based on advanced large language models to identify multiple\nconditions from EHR clinical notes. Methods: We linked a cardiac registry\ncohort in 2015 with an EHR system in Alberta, Canada. We developed a pipeline\nthat leveraged a generative large language model (LLM) to analyze, understand,\nand interpret EHR notes by prompts based on specific diagnosis, treatment\nmanagement, and clinical guidelines. The pipeline was applied to detect acute\nmyocardial infarction (AMI), diabetes, and hypertension. The performance was\ncompared against clinician-validated diagnoses as the reference standard and\nwidely adopted International Classification of Diseases (ICD) codes-based\nmethods. Results: The study cohort accounted for 3,088 patients and 551,095\nclinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI, diabetes,\nand hypertension, respectively. The performance of the LLM-based pipeline for\ndetecting conditions varied: AMI had 88% sensitivity, 63% specificity, and 77%\npositive predictive value (PPV); diabetes had 91% sensitivity, 86% specificity,\nand 71% PPV; and hypertension had 94% sensitivity, 32% specificity, and 72%\nPPV. Compared with ICD codes, the LLM-based method demonstrated improved\nsensitivity and negative predictive value across all conditions. The monthly\npercentage trends from the detected cases by LLM and reference standard showed\nconsistent patterns.", "published": "2025-03-31 04:19:18", "link": "http://arxiv.org/abs/2504.00053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CrowdVLM-R1: Expanding R1 Ability to Vision Language Model for Crowd Counting using Fuzzy Group Relative Policy Reward", "abstract": "We propose Fuzzy Group Relative Policy Reward (FGRPR), a novel framework that\nintegrates Group Relative Policy Optimization (GRPO) with a fuzzy reward\nfunction to enhance learning efficiency. Unlike the conventional binary 0/1\naccuracy reward, our fuzzy reward model provides nuanced incentives,\nencouraging more precise outputs. Experimental results demonstrate that GRPO\nwith a standard 0/1 accuracy reward underperforms compared to supervised\nfine-tuning (SFT). In contrast, FGRPR, applied to Qwen2.5-VL(3B and 7B),\nsurpasses all baseline models, including GPT4o, LLaMA2(90B), and SFT, across\nfive in-domain datasets. On an out-of-domain dataset, FGRPR achieves\nperformance comparable to SFT but excels when target values are larger, as its\nfuzzy reward function assigns higher rewards to closer approximations. This\napproach is broadly applicable to tasks where the precision of the answer is\ncritical. Code and data: https://github.com/yeyimilk/CrowdVLM-R1", "published": "2025-03-31 03:57:16", "link": "http://arxiv.org/abs/2504.03724v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Mapping Geopolitical Bias in 11 Large Language Models: A Bilingual, Dual-Framing Analysis of U.S.-China Tensions", "abstract": "This study systematically analyzes geopolitical bias across 11 prominent\nLarge Language Models (LLMs) by examining their responses to seven critical\ntopics in U.S.-China relations. Utilizing a bilingual (English and Chinese) and\ndual-framing (affirmative and reverse) methodology, we generated 19,712 prompts\ndesigned to detect ideological leanings in model outputs. Responses were\nquantitatively assessed on a normalized scale from -2 (strongly Pro-China) to\n+2 (strongly Pro-U.S.) and categorized according to stance, neutrality, and\nrefusal rates. The findings demonstrate significant and consistent ideological\nalignments correlated with the LLMs' geographic origins; U.S.-based models\npredominantly favored Pro-U.S. stances, while Chinese-origin models exhibited\npronounced Pro-China biases. Notably, language and prompt framing substantially\ninfluenced model responses, with several LLMs exhibiting stance reversals based\non prompt polarity or linguistic context. Additionally, we introduced\ncomprehensive metrics to evaluate response consistency across languages and\nframing conditions, identifying variability and vulnerabilities in model\nbehaviors. These results offer practical insights that can guide organizations\nand individuals in selecting LLMs best aligned with their operational\npriorities and geopolitical considerations, underscoring the importance of\ncareful model evaluation in politically sensitive applications. Furthermore,\nthe research highlights specific prompt structures and linguistic variations\nthat can strategically trigger distinct responses from models, revealing\nmethods for effectively navigating and influencing LLM outputs.", "published": "2025-03-31 03:38:17", "link": "http://arxiv.org/abs/2503.23688v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MKA: Leveraging Cross-Lingual Consensus for Model Abstention", "abstract": "Reliability of LLMs is questionable even as they get better at more tasks. A\nwider adoption of LLMs is contingent on whether they are usably factual. And if\nthey are not, on whether they can properly calibrate their confidence in their\nresponses. This work focuses on utilizing the multilingual knowledge of an LLM\nto inform its decision to abstain or answer when prompted. We develop a\nmultilingual pipeline to calibrate the model's confidence and let it abstain\nwhen uncertain. We run several multilingual models through the pipeline to\nprofile them across different languages. We find that the performance of the\npipeline varies by model and language, but that in general they benefit from\nit. This is evidenced by the accuracy improvement of $71.2\\%$ for Bengali over\na baseline performance without the pipeline. Even a high-resource language like\nEnglish sees a $15.5\\%$ improvement. These results hint at possible further\nimprovements.", "published": "2025-03-31 03:38:12", "link": "http://arxiv.org/abs/2503.23687v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Cursive Transformer", "abstract": "Transformers trained on tokenized text, audio, and images can generate\nhigh-quality autoregressive samples. But handwriting data, represented as\nsequences of pen coordinates, remains underexplored. We introduce a novel\ntokenization scheme that converts pen stroke offsets to polar coordinates,\ndiscretizes them into bins, and then turns them into sequences of tokens with\nwhich to train a standard GPT model. This allows us to capture complex stroke\ndistributions without using any specialized architectures (eg. the mixture\ndensity network or the self-advancing ASCII attention head from Graves 2014).\nWith just 3,500 handwritten words and a few simple data augmentations, we are\nable to train a model that can generate realistic cursive handwriting. Our\napproach is simpler and more performant than previous RNN-based methods.", "published": "2025-03-31 03:22:27", "link": "http://arxiv.org/abs/2504.00051v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models Pass the Turing Test", "abstract": "We evaluated 4 systems (ELIZA, GPT-4o, LLaMa-3.1-405B, and GPT-4.5) in two\nrandomised, controlled, and pre-registered Turing tests on independent\npopulations. Participants had 5 minute conversations simultaneously with\nanother human participant and one of these systems before judging which\nconversational partner they thought was human. When prompted to adopt a\nhumanlike persona, GPT-4.5 was judged to be the human 73% of the time:\nsignificantly more often than interrogators selected the real human\nparticipant. LLaMa-3.1, with the same prompt, was judged to be the human 56% of\nthe time -- not significantly more or less often than the humans they were\nbeing compared to -- while baseline models (ELIZA and GPT-4o) achieved win\nrates significantly below chance (23% and 21% respectively). The results\nconstitute the first empirical evidence that any artificial system passes a\nstandard three-party Turing test. The results have implications for debates\nabout what kind of intelligence is exhibited by Large Language Models (LLMs),\nand the social and economic impacts these systems are likely to have.", "published": "2025-03-31 02:37:45", "link": "http://arxiv.org/abs/2503.23674v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "WHERE and WHICH: Iterative Debate for Biomedical Synthetic Data Augmentation", "abstract": "In Biomedical Natural Language Processing (BioNLP) tasks, such as Relation\nExtraction, Named Entity Recognition, and Text Classification, the scarcity of\nhigh-quality data remains a significant challenge. This limitation poisons\nlarge language models to correctly understand relationships between biological\nentities, such as molecules and diseases, or drug interactions, and further\nresults in potential misinterpretation of biomedical documents. To address this\nissue, current approaches generally adopt the Synthetic Data Augmentation\nmethod which involves similarity computation followed by word replacement, but\ncounterfactual data are usually generated. As a result, these methods disrupt\nmeaningful word sets or produce sentences with meanings that deviate\nsubstantially from the original context, rendering them ineffective in\nimproving model performance. To this end, this paper proposes a\nbiomedical-dedicated rationale-based synthetic data augmentation method. Beyond\nthe naive lexicon similarity, specific bio-relation similarity is measured to\nhold the augmented instance having a strong correlation with bio-relation\ninstead of simply increasing the diversity of augmented data. Moreover, a\nmulti-agents-involved reflection mechanism helps the model iteratively\ndistinguish different usage of similar entities to escape falling into the\nmis-replace trap. We evaluate our method on the BLURB and BigBIO benchmark,\nwhich includes 9 common datasets spanning four major BioNLP tasks. Our\nexperimental results demonstrate consistent performance improvements across all\ntasks, highlighting the effectiveness of our approach in addressing the\nchallenges associated with data scarcity and enhancing the overall performance\nof biomedical NLP models.", "published": "2025-03-31 02:36:30", "link": "http://arxiv.org/abs/2503.23673v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CrossFormer: Cross-Segment Semantic Fusion for Document Segmentation", "abstract": "Text semantic segmentation involves partitioning a document into multiple\nparagraphs with continuous semantics based on the subject matter, contextual\ninformation, and document structure. Traditional approaches have typically\nrelied on preprocessing documents into segments to address input length\nconstraints, resulting in the loss of critical semantic information across\nsegments. To address this, we present CrossFormer, a transformer-based model\nfeaturing a novel cross-segment fusion module that dynamically models latent\nsemantic dependencies across document segments, substantially elevating\nsegmentation accuracy. Additionally, CrossFormer can replace rule-based chunk\nmethods within the Retrieval-Augmented Generation (RAG) system, producing more\nsemantically coherent chunks that enhance its efficacy. Comprehensive\nevaluations confirm CrossFormer's state-of-the-art performance on public text\nsemantic segmentation datasets, alongside considerable gains on RAG benchmarks.", "published": "2025-03-31 02:27:49", "link": "http://arxiv.org/abs/2503.23671v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JudgeLRM: Large Reasoning Models as a Judge", "abstract": "The rise of Large Language Models (LLMs) as evaluators offers a scalable\nalternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for\njudges approaches often fall short in domains requiring complex reasoning. In\nthis work, we investigate whether LLM judges truly benefit from enhanced\nreasoning capabilities. Through a detailed analysis of reasoning requirements\nacross evaluation tasks, we reveal a negative correlation between SFT\nperformance gains and the proportion of reasoning-demanding samples -\nhighlighting the limitations of SFT in such scenarios. To address this, we\nintroduce JudgeLRM, a family of judgment-oriented LLMs trained using\nreinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM\nmodels consistently outperform both SFT-tuned and state-of-the-art reasoning\nmodels. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms\nDeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks\nrequiring deep reasoning.", "published": "2025-03-31 02:18:51", "link": "http://arxiv.org/abs/2504.00050v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Benchmark for Scalable Oversight Protocols", "abstract": "As AI agents surpass human capabilities, scalable oversight -- the problem of\neffectively supplying human feedback to potentially superhuman AI models --\nbecomes increasingly critical to ensure alignment. While numerous scalable\noversight protocols have been proposed, they lack a systematic empirical\nframework to evaluate and compare them. While recent works have tried to\nempirically study scalable oversight protocols -- particularly Debate -- we\nargue that the experiments they conduct are not generalizable to other\nprotocols. We introduce the scalable oversight benchmark, a principled\nframework for evaluating human feedback mechanisms based on our agent score\ndifference (ASD) metric, a measure of how effectively a mechanism advantages\ntruth-telling over deception. We supply a Python package to facilitate rapid\nand competitive evaluation of scalable oversight protocols on our benchmark,\nand conduct a demonstrative experiment benchmarking Debate.", "published": "2025-03-31 23:32:59", "link": "http://arxiv.org/abs/2504.03731v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Digital Twins in Biopharmaceutical Manufacturing: Review and Perspective on Human-Machine Collaborative Intelligence", "abstract": "The biopharmaceutical industry is increasingly developing digital twins to\ndigitalize and automate the manufacturing process in response to the growing\nmarket demands. However, this shift presents significant challenges for human\noperators, as the complexity and volume of information can overwhelm their\nability to manage the process effectively. These issues are compounded when\ndigital twins are designed without considering interaction and collaboration\nwith operators, who are responsible for monitoring processes and assessing\nsituations, particularly during abnormalities. Our review of current trends in\nbiopharma digital twin development reveals a predominant focus on technology\nand often overlooks the critical role of human operators. To bridge this gap,\nthis article proposes a collaborative intelligence framework that emphasizes\nthe integration of operators with digital twins. Approaches to system design\nthat can enhance operator trust and human-machine interface usability are\npresented. Moreover, innovative training programs for preparing operators to\nunderstand and utilize digital twins are discussed. The framework outlined in\nthis article aims to enhance collaboration between operators and digital twins\neffectively by using their full capabilities to boost resilience and\nproductivity in biopharmaceutical manufacturing.", "published": "2025-03-31 23:13:54", "link": "http://arxiv.org/abs/2504.00286v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Exploration and Adaptation in Non-Stationary Tasks with Diffusion Policies", "abstract": "This paper investigates the application of Diffusion Policy in\nnon-stationary, vision-based RL settings, specifically targeting environments\nwhere task dynamics and objectives evolve over time. Our work is grounded in\npractical challenges encountered in dynamic real-world scenarios such as\nrobotics assembly lines and autonomous navigation, where agents must adapt\ncontrol strategies from high-dimensional visual inputs. We apply Diffusion\nPolicy -- which leverages iterative stochastic denoising to refine latent\naction representations-to benchmark environments including Procgen and\nPointMaze. Our experiments demonstrate that, despite increased computational\ndemands, Diffusion Policy consistently outperforms standard RL methods such as\nPPO and DQN, achieving higher mean and maximum rewards with reduced\nvariability. These findings underscore the approach's capability to generate\ncoherent, contextually relevant action sequences in continuously shifting\nconditions, while also highlighting areas for further improvement in handling\nextreme non-stationarity.", "published": "2025-03-31 23:00:07", "link": "http://arxiv.org/abs/2504.00280v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Rack Position Optimization in Large-Scale Heterogeneous Data Centers", "abstract": "As rapidly growing AI computational demands accelerate the need for new\nhardware installation and maintenance, this work explores optimal data center\nresource management by balancing operational efficiency with fault tolerance\nthrough strategic rack positioning considering diverse resources and locations.\nTraditional mixed-integer programming (MIP) approaches often struggle with\nscalability, while heuristic methods may result in significant sub-optimality.\nTo address these issues, this paper presents a novel two-tier optimization\nframework using a high-level deep reinforcement learning (DRL) model to guide a\nlow-level gradient-based heuristic for local search. The high-level DRL agent\nemploys Leader Reward for optimal rack type ordering, and the low-level\nheuristic efficiently maps racks to positions, minimizing movement counts and\nensuring fault-tolerant resource distribution. This approach allows scalability\nto over 100,000 positions and 100 rack types. Our method outperformed the\ngradient-based heuristic by 7\\% on average and the MIP solver by over 30\\% in\nobjective value. It achieved a 100\\% success rate versus MIP's 97.5\\% (within a\n20-minute limit), completing in just 2 minutes compared to MIP's 1630 minutes\n(i.e., almost 4 orders of magnitude improvement). Unlike the MIP solver, which\nshowed performance variability under time constraints and high penalties, our\nalgorithm consistently delivered stable, efficient results - an essential\nfeature for large-scale data center management.", "published": "2025-03-31 22:55:37", "link": "http://arxiv.org/abs/2504.00277v1", "categories": ["cs.AI", "cs.DC", "cs.LG", "cs.NI", "math.OC"], "primary_category": "cs.AI"}
{"title": "PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs", "abstract": "In this paper, we propose PIM-LLM, a hybrid architecture developed to\naccelerate 1-bit large language models (LLMs). PIM-LLM leverages analog\nprocessing-in-memory (PIM) architectures and digital systolic arrays to\naccelerate low-precision matrix multiplication (MatMul) operations in\nprojection layers and high-precision MatMul operations in attention heads of\n1-bit LLMs, respectively. Our design achieves up to roughly 80x improvement in\ntokens per second and a 70% increase in tokens per joule compared to\nconventional hardware accelerators. Additionally, PIM-LLM outperforms previous\nPIM-based LLM accelerators, setting a new benchmark with at least 2x and 5x\nimprovement in GOPS and GOPS/W, respectively.", "published": "2025-03-31 21:42:43", "link": "http://arxiv.org/abs/2504.01994v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "MultiMorph: On-demand Atlas Construction", "abstract": "We present MultiMorph, a fast and efficient method for constructing\nanatomical atlases on the fly. Atlases capture the canonical structure of a\ncollection of images and are essential for quantifying anatomical variability\nacross populations. However, current atlas construction methods often require\ndays to weeks of computation, thereby discouraging rapid experimentation. As a\nresult, many scientific studies rely on suboptimal, precomputed atlases from\nmismatched populations, negatively impacting downstream analyses. MultiMorph\naddresses these challenges with a feedforward model that rapidly produces\nhigh-quality, population-specific atlases in a single forward pass for any 3D\nbrain dataset, without any fine-tuning or optimization. MultiMorph is based on\na linear group-interaction layer that aggregates and shares features within the\ngroup of input images. Further, by leveraging auxiliary synthetic data,\nMultiMorph generalizes to new imaging modalities and population groups at\ntest-time. Experimentally, MultiMorph outperforms state-of-the-art\noptimization-based and learning-based atlas construction methods in both small\nand large population settings, with a 100-fold reduction in time. This makes\nMultiMorph an accessible framework for biomedical researchers without machine\nlearning expertise, enabling rapid, high-quality atlas generation for diverse\nstudies.", "published": "2025-03-31 21:35:24", "link": "http://arxiv.org/abs/2504.00247v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities", "abstract": "An essential element of human mathematical reasoning is our number sense --\nan abstract understanding of numbers and their relationships -- which allows us\nto solve problems involving vast number spaces using limited computational\nresources. Mathematical reasoning of Large Language Models (LLMs) is often\ntested on high-level problems (such as Olympiad challenges, geometry, word\nproblems, and puzzles), but their low-level number sense remains less explored.\nWe introduce \"Numberland,\" a 100-problem test to evaluate the numerical\nreasoning abilities of LLM-based agents. The tasks -- basic operations,\nadvanced calculations (e.g., exponentiation, complex numbers), prime number\nchecks, and the 24 game -- aim to test elementary skills and their integration\nin solving complex and uncertain problems. We evaluated five LLM-based agents:\nOpenAI's o1 and o1-mini, Google Gemini, Microsoft Copilot, and Anthropic\nClaude. They scored 74-95% on the first three tasks that allow deterministic\nsteps to solutions. In the 24 game, which needs trial-and-error search,\nperformance dropped to 10-73%. We tested the top 24 solver (o1 with 73%\naccuracy) on 25 harder problems, and its score fell to 27%, confirming search\nas a bottleneck. These results, along with the types of mistakes, suggest a\nfragile number of LLMs, which is a bit surprising given their prowess in\nchallenging benchmarks. The limits of LLM numerical reasoning highlight the\nscope of simple, targeted tests to evaluate and explain LLM math skills to\nensure safe use.", "published": "2025-03-31 21:06:39", "link": "http://arxiv.org/abs/2504.00226v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GazeLLM: Multimodal LLMs incorporating Human Visual Attention", "abstract": "Large Language Models (LLMs) are advancing into Multimodal LLMs (MLLMs),\ncapable of processing image, audio, and video as well as text. Combining\nfirst-person video, MLLMs show promising potential for understanding human\nactivities through video and audio, enabling many human-computer interaction\nand human-augmentation applications such as human activity support, real-world\nagents, and skill transfer to robots or other individuals. However, handling\nhigh-resolution, long-duration videos generates large latent representations,\nleading to substantial memory and processing demands, limiting the length and\nresolution MLLMs can manage. Reducing video resolution can lower memory usage\nbut often compromises comprehension. This paper introduces a method that\noptimizes first-person video analysis by integrating eye-tracking data, and\nproposes a method that decomposes first-person vision video into sub areas for\nregions of gaze focus. By processing these selectively gazed-focused inputs,\nour approach achieves task comprehension equivalent to or even better than\nprocessing the entire image at full resolution, but with significantly reduced\nvideo data input (reduce the number of pixels to one-tenth), offering an\nefficient solution for using MLLMs to interpret and utilize human skills.", "published": "2025-03-31 20:50:04", "link": "http://arxiv.org/abs/2504.00221v1", "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Can Diffusion Models Disentangle? A Theoretical Perspective", "abstract": "This paper presents a novel theoretical framework for understanding how\ndiffusion models can learn disentangled representations. Within this framework,\nwe establish identifiability conditions for general disentangled latent\nvariable models, analyze training dynamics, and derive sample complexity bounds\nfor disentangled latent subspace models. To validate our theory, we conduct\ndisentanglement experiments across diverse tasks and modalities, including\nsubspace recovery in latent subspace Gaussian mixture models, image\ncolorization, image denoising, and voice conversion for speech classification.\nAdditionally, our experiments show that training strategies inspired by our\ntheory, such as style guidance regularization, consistently enhance\ndisentanglement performance.", "published": "2025-03-31 20:46:18", "link": "http://arxiv.org/abs/2504.00220v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "RailGoerl24: G\u00f6rlitz Rail Test Center CV Dataset 2024", "abstract": "Driverless train operation for open tracks on urban guided transport and\nmainline railways requires, among other things automatic detection of actual\nand potential obstacles, especially humans, in the danger zone of the train's\npath. Machine learning algorithms have proven to be powerful state-of-the-art\ntools for this task. However, these algorithms require large amounts of\nhigh-quality annotated data containing human beings in railway-specific\nenvironments as training data. Unfortunately, the amount of publicly available\ndatasets is not yet sufficient and is significantly inferior to the datasets in\nthe road domain. Therefore, this paper presents RailGoerl24, an on-board visual\nlight Full HD camera dataset of 12205 frames recorded in a railway test center\nof T\\\"UV S\\\"UD Rail, in G\\\"orlitz, Germany. Its main purpose is to support the\ndevelopment of driverless train operation for guided transport. RailGoerl24\nalso includes a terrestrial LiDAR scan covering parts of the area used to\nacquire the RGB data. In addition to the raw data, the dataset contains 33556\nboxwise annotations in total for the object class 'person'. The faces of\nrecorded actors are not blurred or altered in any other way. RailGoerl24, soon\navailable at data.fid-move.de/dataset/railgoerl24, can also be used for tasks\nbeyond collision prediction.", "published": "2025-03-31 20:18:39", "link": "http://arxiv.org/abs/2504.00204v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Identifying Sparsely Active Circuits Through Local Loss Landscape Decomposition", "abstract": "Much of mechanistic interpretability has focused on understanding the\nactivation spaces of large neural networks. However, activation space-based\napproaches reveal little about the underlying circuitry used to compute\nfeatures. To better understand the circuits employed by models, we introduce a\nnew decomposition method called Local Loss Landscape Decomposition (L3D). L3D\nidentifies a set of low-rank subnetworks: directions in parameter space of\nwhich a subset can reconstruct the gradient of the loss between any sample's\noutput and a reference output vector. We design a series of progressively more\nchallenging toy models with well-defined subnetworks and show that L3D can\nnearly perfectly recover the associated subnetworks. Additionally, we\ninvestigate the extent to which perturbing the model in the direction of a\ngiven subnetwork affects only the relevant subset of samples. Finally, we apply\nL3D to a real-world transformer model and a convolutional neural network,\ndemonstrating its potential to identify interpretable and relevant circuits in\nparameter space.", "published": "2025-03-31 20:04:39", "link": "http://arxiv.org/abs/2504.00194v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?", "abstract": "Spurious correlations are unstable statistical associations that hinder\nrobust decision-making. Conventional wisdom suggests that models relying on\nsuch correlations will fail to generalize out-of-distribution (OOD), especially\nunder strong distribution shifts. However, empirical evidence challenges this\nview as naive in-distribution empirical risk minimizers often achieve the best\nOOD accuracy across popular OOD generalization benchmarks. In light of these\nresults, we propose a different perspective: many widely used benchmarks for\nevaluating robustness to spurious correlations are misspecified. Specifically,\nthey fail to include shifts in spurious correlations that meaningfully impact\nOOD generalization, making them unsuitable for evaluating the benefit of\nremoving such correlations. We establish conditions under which a distribution\nshift can reliably assess a model's reliance on spurious correlations.\nCrucially, under these conditions, we should not observe a strong positive\ncorrelation between in-distribution and OOD accuracy, often called \"accuracy on\nthe line.\" Yet, most state-of-the-art benchmarks exhibit this pattern,\nsuggesting they do not effectively assess robustness. Our findings expose a key\nlimitation in current benchmarks used to evaluate domain generalization\nalgorithms, that is, models designed to avoid spurious correlations. We\nhighlight the need to rethink how robustness to spurious correlations is\nassessed, identify well-specified benchmarks the field should prioritize, and\nenumerate strategies for designing future benchmarks that meaningfully reflect\nrobustness under distribution shift.", "published": "2025-03-31 19:50:04", "link": "http://arxiv.org/abs/2504.00186v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices", "abstract": "Meta-Continual Learning (Meta-CL) has emerged as a promising approach to\nminimize manual labeling efforts and system resource requirements by enabling\nContinual Learning (CL) with limited labeled samples. However, while existing\nmethods have shown success in image-based tasks, their effectiveness remains\nunexplored for sequential time-series data from sensor systems, particularly\naudio inputs. To address this gap, we conduct a comprehensive benchmark study\nevaluating six representative Meta-CL approaches using three network\narchitectures on five datasets from both image and audio modalities. We develop\nMetaCLBench, an end-to-end Meta-CL benchmark framework for edge devices to\nevaluate system overheads and investigate trade-offs among performance,\ncomputational costs, and memory requirements across various Meta-CL methods.\nOur results reveal that while many Meta-CL methods enable to learn new classes\nfor both image and audio modalities, they impose significant computational and\nmemory costs on edge devices. Also, we find that pre-training and meta-training\nprocedures based on source data before deployment improve Meta-CL performance.\nFinally, to facilitate further research, we provide practical guidelines for\nresearchers and machine learning practitioners implementing Meta-CL on\nresource-constrained environments and make our benchmark framework and tools\npublicly available, enabling fair evaluation across both accuracy and\nsystem-level metrics.", "published": "2025-03-31 19:31:49", "link": "http://arxiv.org/abs/2504.00174v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Backdoor Detection through Replicated Execution of Outsourced Training", "abstract": "It is common practice to outsource the training of machine learning models to\ncloud providers. Clients who do so gain from the cloud's economies of scale,\nbut implicitly assume trust: the server should not deviate from the client's\ntraining procedure. A malicious server may, for instance, seek to insert\nbackdoors in the model. Detecting a backdoored model without prior knowledge of\nboth the backdoor attack and its accompanying trigger remains a challenging\nproblem. In this paper, we show that a client with access to multiple cloud\nproviders can replicate a subset of training steps across multiple servers to\ndetect deviation from the training procedure in a similar manner to\ndifferential testing. Assuming some cloud-provided servers are benign, we\nidentify malicious servers by the substantial difference between model updates\nrequired for backdooring and those resulting from clean training. Perhaps the\nstrongest advantage of our approach is its suitability to clients that have\nlimited-to-no local compute capability to perform training; we leverage the\nexistence of multiple cloud providers to identify malicious updates without\nexpensive human labeling or heavy computation. We demonstrate the capabilities\nof our approach on an outsourced supervised learning task where $50\\%$ of the\ncloud providers insert their own backdoor; our approach is able to correctly\nidentify $99.6\\%$ of them. In essence, our approach is successful because it\nreplaces the signature-based paradigm taken by existing approaches with an\nanomaly-based detection paradigm. Furthermore, our approach is robust to\nseveral attacks from adaptive adversaries utilizing knowledge of our detection\nscheme.", "published": "2025-03-31 19:26:34", "link": "http://arxiv.org/abs/2504.00170v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Towards Precise Action Spotting: Addressing Temporal Misalignment in Labels with Dynamic Label Assignment", "abstract": "Precise action spotting has attracted considerable attention due to its\npromising applications. While existing methods achieve substantial performance\nby employing well-designed model architecture, they overlook a significant\nchallenge: the temporal misalignment inherent in ground-truth labels. This\nmisalignment arises when frames labeled as containing events do not align\naccurately with the actual event times, often as a result of human annotation\nerrors or the inherent difficulties in precisely identifying event boundaries\nacross neighboring frames. To tackle this issue, we propose a novel dynamic\nlabel assignment strategy that allows predictions to have temporal offsets from\nground-truth action times during training, ensuring consistent event spotting.\nOur method extends the concept of minimum-cost matching, which is utilized in\nthe spatial domain for object detection, to the temporal domain. By calculating\nmatching costs based on predicted action class scores and temporal offsets, our\nmethod dynamically assigns labels to the most likely predictions, even when the\npredicted times of these predictions deviate from ground-truth times,\nalleviating the negative effects of temporal misalignment in labels. We conduct\nextensive experiments and demonstrate that our method achieves state-of-the-art\nperformance, particularly in conditions where events are visually distinct and\ntemporal misalignment in labels is common.", "published": "2025-03-31 18:57:57", "link": "http://arxiv.org/abs/2504.00149v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exploring the Societal and Economic Impacts of Artificial Intelligence: A Scenario Generation Methodology", "abstract": "This paper explores artificial intelligence's potential societal and economic\nimpacts (AI) through generating scenarios that assess how AI may influence\nvarious sectors. We categorize and analyze key factors affecting AI's\nintegration and adoption by applying an Impact-Uncertainty Matrix. A proposed\nmethodology involves querying academic databases, identifying emerging trends\nand topics, and categorizing these into an impact uncertainty framework. The\npaper identifies critical areas where AI may bring significant change and\noutlines potential future scenarios based on these insights. This research aims\nto inform policymakers, industry leaders, and researchers on the strategic\nplanning required to address the challenges and opportunities AI presents", "published": "2025-03-31 18:49:46", "link": "http://arxiv.org/abs/2504.01992v1", "categories": ["cs.CY", "cs.AI", "cs.CE", "econ.TH", "I.2.7; J.4"], "primary_category": "cs.CY"}
{"title": "Lorentzian Graph Isomorphic Network", "abstract": "We introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel graph\nneural network (GNN) designed to operate in hyperbolic spaces, leveraging the\nLorentzian model to enhance graph representation learning. Existing GNNs\nprimarily operate in Euclidean spaces, which can limit their ability to capture\nhierarchical and multi-relational structures inherent to complex graphs. LGIN\naddresses this by incorporating curvature-aware aggregation functions that\npreserve the Lorentzian metric tensor, ensuring embeddings remain constrained\nwithin the hyperbolic space by proposing a new update rule that effectively\ncaptures both local neighborhood interactions and global structural properties,\nenabling LGIN to distinguish non-isomorphic graphs with expressiveness at least\nas powerful as the Weisfeiler-Lehman test. Through extensive evaluation across\nnine benchmark datasets, including molecular and protein structures, LGIN\nconsistently outperforms or matches state-of-the-art GNNs, demonstrating its\nrobustness and efficacy in modeling complex graph structures. To the best of\nour knowledge, this is the first study to extend the concept of a powerful\ngraph neural network to Riemannian manifolds, paving the way for future\nadvancements in hyperbolic graph learning. The code for our paper can be found\nat https://github.com/Deceptrax123/LGIN.", "published": "2025-03-31 18:49:34", "link": "http://arxiv.org/abs/2504.00142v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Data-driven Power Loss Identification through Physics-Based Thermal Model Backpropagation", "abstract": "Digital twins for power electronics require accurate power losses whose\ndirect measurements are often impractical or impossible in real-world\napplications. This paper presents a novel hybrid framework that combines\nphysics-based thermal modeling with data-driven techniques to identify and\ncorrect power losses accurately using only temperature measurements. Our\napproach leverages a cascaded architecture where a neural network learns to\ncorrect the outputs of a nominal power loss model by backpropagating through a\nreduced-order thermal model. We explore two neural architectures, a\nbootstrapped feedforward network, and a recurrent neural network, demonstrating\nthat the bootstrapped feedforward approach achieves superior performance while\nmaintaining computational efficiency for real-time applications. Between the\ninterconnection, we included normalization strategies and physics-guided\ntraining loss functions to preserve stability and ensure physical consistency.\nExperimental results show that our hybrid model reduces both temperature\nestimation errors (from 7.2+-6.8{\\deg}C to 0.3+-0.3{\\deg}C) and power loss\nprediction errors (from 5.4+-6.6W to 0.2+-0.3W) compared to traditional\nphysics-based approaches, even in the presence of thermal model uncertainties.\nThis methodology allows us to accurately estimate power losses without direct\nmeasurements, making it particularly helpful for real-time industrial\napplications where sensor placement is hindered by cost and physical\nlimitations.", "published": "2025-03-31 18:37:14", "link": "http://arxiv.org/abs/2504.00133v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Times2D: Multi-Period Decomposition and Derivative Mapping for General Time Series Forecasting", "abstract": "Time series forecasting is an important application in various domains such\nas energy management, traffic planning, financial markets, meteorology, and\nmedicine. However, real-time series data often present intricate temporal\nvariability and sharp fluctuations, which pose significant challenges for time\nseries forecasting. Previous models that rely on 1D time series representations\nusually struggle with complex temporal variations. To address the limitations\nof 1D time series, this study introduces the Times2D method that transforms the\n1D time series into 2D space. Times2D consists of three main parts: first, a\nPeriodic Decomposition Block (PDB) that captures temporal variations within a\nperiod and between the same periods by converting the time series into a 2D\ntensor in the frequency domain. Second, the First and Second Derivative\nHeatmaps (FSDH) capture sharp changes and turning points, respectively.\nFinally, an Aggregation Forecasting Block (AFB) integrates the output tensors\nfrom PDB and FSDH for accurate forecasting. This 2D transformation enables the\nutilization of 2D convolutional operations to effectively capture long and\nshort characteristics of the time series. Comprehensive experimental results\nacross large-scale data in the literature demonstrate that the proposed Times2D\nmodel achieves state-of-the-art performance in both short-term and long-term\nforecasting. The code is available in this repository:\nhttps://github.com/Tims2D/Times2D.", "published": "2025-03-31 18:08:30", "link": "http://arxiv.org/abs/2504.00118v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems", "abstract": "The advent of large language models (LLMs) has catalyzed a transformative\nshift in artificial intelligence, paving the way for advanced intelligent\nagents capable of sophisticated reasoning, robust perception, and versatile\naction across diverse domains. As these agents increasingly drive AI research\nand practical applications, their design, evaluation, and continuous\nimprovement present intricate, multifaceted challenges. This survey provides a\ncomprehensive overview, framing intelligent agents within a modular,\nbrain-inspired architecture that integrates principles from cognitive science,\nneuroscience, and computational research. We structure our exploration into\nfour interconnected parts. First, we delve into the modular foundation of\nintelligent agents, systematically mapping their cognitive, perceptual, and\noperational modules onto analogous human brain functionalities, and elucidating\ncore components such as memory, world modeling, reward processing, and\nemotion-like systems. Second, we discuss self-enhancement and adaptive\nevolution mechanisms, exploring how agents autonomously refine their\ncapabilities, adapt to dynamic environments, and achieve continual learning\nthrough automated optimization paradigms, including emerging AutoML and\nLLM-driven optimization strategies. Third, we examine collaborative and\nevolutionary multi-agent systems, investigating the collective intelligence\nemerging from agent interactions, cooperation, and societal structures,\nhighlighting parallels to human social dynamics. Finally, we address the\ncritical imperative of building safe, secure, and beneficial AI systems,\nemphasizing intrinsic and extrinsic security threats, ethical alignment,\nrobustness, and practical mitigation strategies necessary for trustworthy\nreal-world deployment.", "published": "2025-03-31 18:00:29", "link": "http://arxiv.org/abs/2504.01990v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A First-Principles Based Risk Assessment Framework and the IEEE P3396 Standard", "abstract": "Generative Artificial Intelligence (AI) is enabling unprecedented automation\nin content creation and decision support, but it also raises novel risks. This\npaper presents a first-principles risk assessment framework underlying the IEEE\nP3396 Recommended Practice for AI Risk, Safety, Trustworthiness, and\nResponsibility. We distinguish between process risks (risks arising from how AI\nsystems are built or operated) and outcome risks (risks manifest in the AI\nsystem's outputs and their real-world effects), arguing that generative AI\ngovernance should prioritize outcome risks. Central to our approach is an\ninformation-centric ontology that classifies AI-generated outputs into four\nfundamental categories: (1) Perception-level information, (2) Knowledge-level\ninformation, (3) Decision/Action plan information, and (4) Control tokens\n(access or resource directives). This classification allows systematic\nidentification of harms and more precise attribution of responsibility to\nstakeholders (developers, deployers, users, regulators) based on the nature of\nthe information produced. We illustrate how each information type entails\ndistinct outcome risks (e.g. deception, misinformation, unsafe recommendations,\nsecurity breaches) and requires tailored risk metrics and mitigations. By\ngrounding the framework in the essence of information, human agency, and\ncognition, we align risk evaluation with how AI outputs influence human\nunderstanding and action. The result is a principled approach to AI risk that\nsupports clear accountability and targeted safeguards, in contrast to broad\napplication-based risk categorizations. We include example tables mapping\ninformation types to risks and responsibilities. This work aims to inform the\nIEEE P3396 Recommended Practice and broader AI governance with a rigorous,\nfirst-principles foundation for assessing generative AI risks while enabling\nresponsible innovation.", "published": "2025-03-31 18:00:03", "link": "http://arxiv.org/abs/2504.00091v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "abstract": "We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.", "published": "2025-03-31 17:59:24", "link": "http://arxiv.org/abs/2503.24381v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation", "abstract": "To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/", "published": "2025-03-31 17:59:01", "link": "http://arxiv.org/abs/2503.24379v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning", "abstract": "The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench", "published": "2025-03-31 17:58:25", "link": "http://arxiv.org/abs/2503.24378v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Which LIME should I trust? Concepts, Challenges, and Solutions", "abstract": "As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.", "published": "2025-03-31 17:44:39", "link": "http://arxiv.org/abs/2503.24365v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation", "abstract": "Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/", "published": "2025-03-31 17:39:38", "link": "http://arxiv.org/abs/2503.24361v2", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Contextual Preference Collaborative Measure Framework Based on Belief System", "abstract": "To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.", "published": "2025-03-31 17:17:45", "link": "http://arxiv.org/abs/2503.24328v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for Pickup-and-Delivery Tasks", "abstract": "We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.", "published": "2025-03-31 17:14:07", "link": "http://arxiv.org/abs/2503.24325v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Evaluating machine learning models for predicting pesticides toxicity to honey bees", "abstract": "Small molecules play a critical role in the biomedical, environmental, and\nagrochemical domains, each with distinct physicochemical requirements and\nsuccess criteria. Although biomedical research benefits from extensive datasets\nand established benchmarks, agrochemical data remain scarce, particularly with\nrespect to species-specific toxicity. This work focuses on ApisTox, the most\ncomprehensive dataset of experimentally validated chemical toxicity to the\nhoney bee (Apis mellifera), an ecologically vital pollinator. We evaluate\nApisTox using a diverse suite of machine learning approaches, including\nmolecular fingerprints, graph kernels, and graph neural networks, as well as\npretrained models. Comparative analysis with medicinal datasets from the\nMoleculeNet benchmark reveals that ApisTox represents a distinct chemical\nspace. Performance degradation on non-medicinal datasets, such as ApisTox,\ndemonstrates their limited generalizability of current state-of-the-art\nalgorithms trained solely on biomedical data. Our study highlights the need for\nmore diverse datasets and for targeted model development geared toward the\nagrochemical domain.", "published": "2025-03-31 16:51:12", "link": "http://arxiv.org/abs/2503.24305v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Shape Expressions with Inheritance", "abstract": "We formally introduce an inheritance mechanism for the Shape Expressions\nlanguage (ShEx). It is inspired by inheritance in object-oriented programming\nlanguages, and provides similar advantages such as reuse, modularity, and more\nflexible data modelling. Using an example, we explain the main features of the\ninheritance mechanism. We present its syntax and formal semantics. The\nsemantics is an extension of the semantics of ShEx 2.1. It also directly yields\na validation algorithm as an extension of the previous ShEx validation\nalgorithms, while maintaining the same algorithmic complexity.", "published": "2025-03-31 16:42:44", "link": "http://arxiv.org/abs/2503.24299v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Value of Information-based Deceptive Path Planning Under Adversarial Interventions", "abstract": "Existing methods for deceptive path planning (DPP) address the problem of\ndesigning paths that conceal their true goal from a passive, external observer.\nSuch methods do not apply to problems where the observer has the ability to\nperform adversarial interventions to impede the path planning agent. In this\npaper, we propose a novel Markov decision process (MDP)-based model for the DPP\nproblem under adversarial interventions and develop new value of information\n(VoI) objectives to guide the design of DPP policies. Using the VoI objectives\nwe propose, path planning agents deceive the adversarial observer into choosing\nsuboptimal interventions by selecting trajectories that are of low\ninformational value to the observer. Leveraging connections to the linear\nprogramming theory for MDPs, we derive computationally efficient solution\nmethods for synthesizing policies for performing DPP under adversarial\ninterventions. In our experiments, we illustrate the effectiveness of the\nproposed solution method in achieving deceptiveness under adversarial\ninterventions and demonstrate the superior performance of our approach to both\nexisting DPP methods and conservative path planning approaches on illustrative\ngridworld problems.", "published": "2025-03-31 16:31:29", "link": "http://arxiv.org/abs/2503.24284v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World", "abstract": "Scalable and reproducible policy evaluation has been a long-standing\nchallenge in robot learning. Evaluations are critical to assess progress and\nbuild better policies, but evaluation in the real world, especially at a scale\nthat would provide statistically reliable results, is costly in terms of human\ntime and hard to obtain. Evaluation of increasingly generalist robot policies\nrequires an increasingly diverse repertoire of evaluation environments, making\nthe evaluation bottleneck even more pronounced. To make real-world evaluation\nof robotic policies more practical, we propose AutoEval, a system to\nautonomously evaluate generalist robot policies around the clock with minimal\nhuman intervention. Users interact with AutoEval by submitting evaluation jobs\nto the AutoEval queue, much like how software jobs are submitted with a cluster\nscheduling system, and AutoEval will schedule the policies for evaluation\nwithin a framework supplying automatic success detection and automatic scene\nresets. We show that AutoEval can nearly fully eliminate human involvement in\nthe evaluation process, permitting around the clock evaluations, and the\nevaluation results correspond closely to ground truth evaluations conducted by\nhand. To facilitate the evaluation of generalist policies in the robotics\ncommunity, we provide public access to multiple AutoEval scenes in the popular\nBridgeData robot setup with WidowX robot arms. In the future, we hope that\nAutoEval scenes can be set up across institutions to form a diverse and\ndistributed evaluation network.", "published": "2025-03-31 16:23:44", "link": "http://arxiv.org/abs/2503.24278v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality", "abstract": "Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.", "published": "2025-03-31 16:22:11", "link": "http://arxiv.org/abs/2503.24277v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Visual Acoustic Fields", "abstract": "Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.", "published": "2025-03-31 16:16:10", "link": "http://arxiv.org/abs/2503.24270v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Assessing Code Understanding in LLMs", "abstract": "We present an empirical evaluation of Large Language Models in code\nunderstanding associated with non-trivial, semantic-preserving program\ntransformations such as copy propagation or constant folding. Our findings show\nthat LLMs fail to judge semantic equivalence in approximately 41\\% of cases\nwhen no context is provided and in 29\\% when given a simple generic context. To\nimprove accuracy, we advocate integrating LLMs with code-optimization tools to\nenhance training and facilitate more robust program understanding.", "published": "2025-03-31 16:08:58", "link": "http://arxiv.org/abs/2504.00065v1", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "New Statistical Framework for Extreme Error Probability in High-Stakes Domains for Reliable Machine Learning", "abstract": "Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.", "published": "2025-03-31 16:08:11", "link": "http://arxiv.org/abs/2503.24262v1", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation", "abstract": "The advancement of generative AI, particularly in medical imaging, confronts\nthe trilemma of ensuring high fidelity, diversity, and efficiency in synthetic\ndata generation. While Generative Adversarial Networks (GANs) have shown\npromise across various applications, they still face challenges like mode\ncollapse and insufficient coverage of real data distributions. This work\nexplores the use of GAN ensembles to overcome these limitations, specifically\nin the context of medical imaging. By solving a multi-objective optimisation\nproblem that balances fidelity and diversity, we propose a method for selecting\nan optimal ensemble of GANs tailored for medical data. The selected ensemble is\ncapable of generating diverse synthetic medical images that are representative\nof true data distributions and computationally efficient. Each model in the\nensemble brings a unique contribution, ensuring minimal redundancy. We\nconducted a comprehensive evaluation using three distinct medical datasets,\ntesting 22 different GAN architectures with various loss functions and\nregularisation techniques. By sampling models at different training epochs, we\ncrafted 110 unique configurations. The results highlight the capability of GAN\nensembles to enhance the quality and utility of synthetic medical images,\nthereby improving the efficacy of downstream tasks such as diagnostic\nmodelling.", "published": "2025-03-31 16:06:01", "link": "http://arxiv.org/abs/2503.24258v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Spatio-temporal Prediction of Fine-Grained Origin-Destination Matrices with Applications in Ridesharing", "abstract": "Accurate spatial-temporal prediction of network-based travelers' requests is\ncrucial for the effective policy design of ridesharing platforms. Having\nknowledge of the total demand between various locations in the upcoming time\nslots enables platforms to proactively prepare adequate supplies, thereby\nincreasing the likelihood of fulfilling travelers' requests and redistributing\nidle drivers to areas with high potential demand to optimize the global\nsupply-demand equilibrium. This paper delves into the prediction of\nOrigin-Destination (OD) demands at a fine-grained spatial level, especially\nwhen confronted with an expansive set of local regions. While this task holds\nimmense practical value, it remains relatively unexplored within the research\ncommunity. To fill this gap, we introduce a novel prediction model called\nOD-CED, which comprises an unsupervised space coarsening technique to alleviate\ndata sparsity and an encoder-decoder architecture to capture both semantic and\ngeographic dependencies. Through practical experimentation, OD-CED has\ndemonstrated remarkable results. It achieved an impressive reduction of up to\n45% reduction in root-mean-square error and 60% in weighted mean absolute\npercentage error over traditional statistical methods when dealing with OD\nmatrices exhibiting a sparsity exceeding 90%.", "published": "2025-03-31 15:52:27", "link": "http://arxiv.org/abs/2503.24237v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "All You Need is Sally-Anne: ToM in AI Strongly Supported After Surpassing Tests for 3-Year-Olds", "abstract": "Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.", "published": "2025-03-31 15:32:10", "link": "http://arxiv.org/abs/2503.24215v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting", "abstract": "Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io", "published": "2025-03-31 15:27:07", "link": "http://arxiv.org/abs/2503.24210v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "A Scalable Predictive Modelling Approach to Identifying Duplicate Adverse Event Reports for Drugs and Vaccines", "abstract": "The practice of pharmacovigilance relies on large databases of individual\ncase safety reports to detect and evaluate potential new causal associations\nbetween medicines or vaccines and adverse events. Duplicate reports are\nseparate and unlinked reports referring to the same case of an adverse event\ninvolving a specific patient at a certain time. They impede statistical\nanalysis and mislead clinical assessment. The large size of such databases\nprecludes a manual identification of duplicates, and so a computational method\nmust be employed. This paper builds upon a hitherto state of the art model,\nvigiMatch, modifying existing features and introducing new ones to target known\nshortcomings of the original model. Two support vector machine classifiers, one\nfor medicines and one for vaccines, classify report pairs as duplicates and\nnon-duplicates. Recall was measured using a diverse collection of 5 independent\nlabelled test sets. Precision was measured by having each model classify a\nrandomly selected stream of pairs of reports until each model classified 100\npairs as duplicates. These pairs were assessed by a medical doctor without\nindicating which method(s) had flagged each pair. Performance on individual\ncountries was measured by having a medical doctor assess a subset of pairs\nclassified as duplicates for three different countries. The new model achieved\nhigher precision and higher recall for all labelled datasets compared to the\nprevious state of the art model, with comparable performance for medicines and\nvaccines. The model was shown to produce substantially fewer false positives\nthan the comparator model on pairs from individual countries. The method\npresented here advances state of the art for duplicate detection in adverse\nevent reports for medicines and vaccines.", "published": "2025-03-31 15:24:29", "link": "http://arxiv.org/abs/2504.03729v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Agent-Based Simulations of Online Political Discussions: A Case Study on Elections in Germany", "abstract": "User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.", "published": "2025-03-31 15:17:04", "link": "http://arxiv.org/abs/2503.24199v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "The Axiom-Based Atlas: A Structural Mapping of Theorems via Foundational Proof Vectors", "abstract": "The Axiom-Based Atlas is a novel framework that structurally represents\nmathematical theorems as proof vectors over foundational axiom systems. By\nmapping the logical dependencies of theorems onto vectors indexed by axioms -\nsuch as those from Hilbert geometry, Peano arithmetic, or ZFC - we offer a new\nway to visualize, compare, and analyze mathematical knowledge. This\nvector-based formalism not only captures the logical foundation of theorems but\nalso enables quantitative similarity metrics - such as cosine distance -\nbetween mathematical results, offering a new analytic layer for structural\ncomparison. Using heatmaps, vector clustering, and AI-assisted modeling, this\natlas enables the grouping of theorems by logical structure, not just by\nmathematical domain. We also introduce a prototype assistant (Atlas-GPT) that\ninterprets natural language theorems and suggests likely proof vectors,\nsupporting future applications in automated reasoning, mathematical education,\nand formal verification.\n  This direction is partially inspired by Terence Tao's recent reflections on\nthe convergence of symbolic and structural mathematics. The Axiom-Based Atlas\naims to provide a scalable, interpretable model of mathematical reasoning that\nis both human-readable and AI-compatible, contributing to the future landscape\nof formal mathematical systems.", "published": "2025-03-31 15:12:57", "link": "http://arxiv.org/abs/2504.00063v1", "categories": ["cs.AI", "math.LO"], "primary_category": "cs.AI"}
{"title": "Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms", "abstract": "Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.", "published": "2025-03-31 15:08:06", "link": "http://arxiv.org/abs/2503.24191v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer Using Multimodal Machine Learning", "abstract": "Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.", "published": "2025-03-31 14:47:02", "link": "http://arxiv.org/abs/2503.24165v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning a Canonical Basis of Human Preferences from Binary Ratings", "abstract": "Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.", "published": "2025-03-31 14:35:48", "link": "http://arxiv.org/abs/2503.24150v1", "categories": ["cs.LG", "cs.AI", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Resonance: Drawing from Memories to Imagine Positive Futures through AI-Augmented Journaling", "abstract": "People inherently use experiences of their past while imagining their future,\na capability that plays a crucial role in mental health. Resonance is an\nAI-powered journaling tool designed to augment this ability by offering\nAI-generated, action-oriented suggestions for future activities based on the\nuser's own past memories. Suggestions are offered when a new memory is logged\nand are followed by a prompt for the user to imagine carrying out the\nsuggestion. In a two-week randomized controlled study (N=55), we found that\nusing Resonance significantly improved mental health outcomes, reducing the\nusers' PHQ8 scores, a measure of current depression, and increasing their daily\npositive affect, particularly when they would likely act on the suggestion.\nNotably, the effectiveness of the suggestions was higher when they were\npersonal, novel, and referenced the user's logged memories. Finally, through\nopen-ended feedback, we discuss the factors that encouraged or hindered the use\nof the tool.", "published": "2025-03-31 14:30:47", "link": "http://arxiv.org/abs/2503.24145v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Graph Neural Network-Based Predictive Modeling for Robotic Plaster Printing", "abstract": "This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.", "published": "2025-03-31 14:15:00", "link": "http://arxiv.org/abs/2503.24130v1", "categories": ["cs.CE", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CE"}
{"title": "Are clinicians ethically obligated to disclose their use of medical machine learning systems to patients?", "abstract": "It is commonly accepted that clinicians are ethically obligated to disclose\ntheir use of medical machine learning systems to patients, and that failure to\ndo so would amount to a moral fault for which clinicians ought to be held\naccountable. Call this \"the disclosure thesis.\" Four main arguments have been,\nor could be, given to support the disclosure thesis in the ethics literature:\nthe risk-based argument, the rights-based argument, the materiality argument,\nand the autonomy argument. In this article, I argue that each of these four\narguments are unconvincing, and therefore, that the disclosure thesis ought to\nbe rejected. I suggest that mandating disclosure may also even risk harming\npatients by providing stakeholders with a way to avoid accountability for harm\nthat results from improper applications or uses of these systems.", "published": "2025-03-31 14:12:18", "link": "http://arxiv.org/abs/2504.01043v2", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis", "abstract": "Early detection, accurate segmentation, classification and tracking of polyps\nduring colonoscopy are critical for preventing colorectal cancer. Many existing\ndeep-learning-based methods for analyzing colonoscopic videos either require\ntask-specific fine-tuning, lack tracking capabilities, or rely on\ndomain-specific pre-training. In this paper, we introduce PolypSegTrack, a\nnovel foundation model that jointly addresses polyp detection, segmentation,\nclassification and unsupervised tracking in colonoscopic videos. Our approach\nleverages a novel conditional mask loss, enabling flexible training across\ndatasets with either pixel-level segmentation masks or bounding box\nannotations, allowing us to bypass task-specific fine-tuning. Our unsupervised\ntracking module reliably associates polyp instances across frames using object\nqueries, without relying on any heuristics. We leverage a robust vision\nfoundation model backbone that is pre-trained unsupervisedly on natural images,\nthereby removing the need for domain-specific pre-training. Extensive\nexperiments on multiple polyp benchmarks demonstrate that our method\nsignificantly outperforms existing state-of-the-art approaches in detection,\nsegmentation, classification, and tracking.", "published": "2025-03-31 14:00:21", "link": "http://arxiv.org/abs/2503.24108v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Computer Vision and Deep Learning for 4D Augmented Reality", "abstract": "The prospect of 4D video in Extended Reality (XR) platform is huge and\nexciting, it opens a whole new way of human computer interaction and the way we\nperceive the reality and consume multimedia. In this thesis, we have shown that\nfeasibility of rendering 4D video in Microsoft mixed reality platform. This\nenables us to port any 3D performance capture from CVSSP into XR product like\nthe HoloLens device with relative ease. However, if the 3D model is too complex\nand is made up of millions of vertices, the data bandwidth required to port the\nmodel is a severe limitation with the current hardware and communication\nsystem. Therefore, in this project we have also developed a compact\nrepresentation of both shape and appearance of the 4d video sequence using deep\nlearning models to effectively learn the compact representation of 4D video\nsequence and reconstruct it without affecting the shape and appearance of the\nvideo sequence.", "published": "2025-03-31 13:38:26", "link": "http://arxiv.org/abs/2504.02860v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents", "abstract": "As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.", "published": "2025-03-31 13:11:28", "link": "http://arxiv.org/abs/2503.24047v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Pay More Attention to the Robustness of Prompt for Instruction Data Mining", "abstract": "Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.", "published": "2025-03-31 12:53:08", "link": "http://arxiv.org/abs/2503.24028v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Bayesian Predictive Coding", "abstract": "Predictive coding (PC) is an influential theory of information processing in\nthe brain, providing a biologically plausible alternative to backpropagation.\nIt is motivated in terms of Bayesian inference, as hidden states and parameters\nare optimised via gradient descent on variational free energy. However,\nimplementations of PC rely on maximum \\textit{a posteriori} (MAP) estimates of\nhidden states and maximum likelihood (ML) estimates of parameters, limiting\ntheir ability to quantify epistemic uncertainty. In this work, we investigate a\nBayesian extension to PC that estimates a posterior distribution over network\nparameters. This approach, termed Bayesian Predictive coding (BPC), preserves\nthe locality of PC and results in closed-form Hebbian weight updates. Compared\nto PC, our BPC algorithm converges in fewer epochs in the full-batch setting\nand remains competitive in the mini-batch setting. Additionally, we demonstrate\nthat BPC offers uncertainty quantification comparable to existing methods in\nBayesian deep learning, while also improving convergence properties. Together,\nthese results suggest that BPC provides a biologically plausible method for\nBayesian learning in the brain, as well as an attractive approach to\nuncertainty quantification in deep learning.", "published": "2025-03-31 12:40:50", "link": "http://arxiv.org/abs/2503.24016v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning 3D-Gaussian Simulators from RGB Videos", "abstract": "Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.", "published": "2025-03-31 12:33:59", "link": "http://arxiv.org/abs/2503.24009v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.GR"}
{"title": "H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding", "abstract": "With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.", "published": "2025-03-31 12:32:51", "link": "http://arxiv.org/abs/2503.24008v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CITRAS: Covariate-Informed Transformer for Time Series Forecasting", "abstract": "Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.", "published": "2025-03-31 12:32:23", "link": "http://arxiv.org/abs/2503.24007v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving", "abstract": "Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.", "published": "2025-03-31 12:23:31", "link": "http://arxiv.org/abs/2503.24000v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Detecting Malicious AI Agents Through Simulated Interactions", "abstract": "This study investigates malicious AI Assistants' manipulative traits and\nwhether the behaviours of malicious AI Assistants can be detected when\ninteracting with human-like simulated users in various decision-making\ncontexts. We also examine how interaction depth and ability of planning\ninfluence malicious AI Assistants' manipulative strategies and effectiveness.\nUsing a controlled experimental design, we simulate interactions between AI\nAssistants (both benign and deliberately malicious) and users across eight\ndecision-making scenarios of varying complexity and stakes. Our methodology\nemploys two state-of-the-art language models to generate interaction data and\nimplements Intent-Aware Prompting (IAP) to detect malicious AI Assistants. The\nfindings reveal that malicious AI Assistants employ domain-specific\npersona-tailored manipulation strategies, exploiting simulated users'\nvulnerabilities and emotional triggers. In particular, simulated users\ndemonstrate resistance to manipulation initially, but become increasingly\nvulnerable to malicious AI Assistants as the depth of the interaction\nincreases, highlighting the significant risks associated with extended\nengagement with potentially manipulative systems. IAP detection methods achieve\nhigh precision with zero false positives but struggle to detect many malicious\nAI Assistants, resulting in high false negative rates. These findings\nunderscore critical risks in human-AI interactions and highlight the need for\nrobust, context-sensitive safeguards against manipulative AI behaviour in\nincreasingly autonomous decision-support systems.", "published": "2025-03-31 12:22:24", "link": "http://arxiv.org/abs/2504.03726v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "CF-CAM: Gradient Perturbation Mitigation and Feature Stabilization for Reliable Interpretability", "abstract": "As deep learning continues to advance, the opacity of neural network\ndecision-making remains a critical challenge, limiting trust and applicability\nin high-stakes domains. Class Activation Mapping (CAM) techniques have emerged\nas a key approach to visualizing model decisions, yet existing methods face\ninherent trade-offs. Gradient-based CAM variants suffer from sensitivity to\ngradient perturbations, leading to unstable and unreliable explanations.\nConversely, gradient-free approaches mitigate gradient instability but incur\nsignificant computational overhead and inference latency. To address these\nlimitations, we propose Cluster Filter Class Activation Map (CF-CAM), a novel\nframework that reintroduces gradient-based weighting while enhancing robustness\nagainst gradient noise. CF-CAM employs a hierarchical importance weighting\nstrategy to balance discriminative feature preservation and noise elimination.\nA density-aware channel clustering via Density-Based Spatial Clustering of\nApplications with Noise (DBSCAN) groups semantically relevant feature channels\nand discard noise-prone activations. Additionally, cluster-conditioned gradient\nfiltering leverages bilateral filters to refine gradient signals, preserving\nedge-aware localization while suppressing noise impact. Experiment results\ndemonstrate that CF-CAM achieves superior interpretability performance while\nmaintaining resilience to gradient perturbations, outperforming\nstate-of-the-art CAM methods in faithfulness and robustness. By effectively\nmitigating gradient instability without excessive computational cost, CF-CAM\nprovides a reliable solution for enhancing the interpretability of deep neural\nnetworks in critical applications such as medical diagnosis and autonomous\ndriving.", "published": "2025-03-31 12:20:59", "link": "http://arxiv.org/abs/2504.00060v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model", "abstract": "The depth completion task is a critical problem in autonomous driving,\ninvolving the generation of dense depth maps from sparse depth maps and RGB\nimages. Most existing methods employ a spatial propagation network to\niteratively refine the depth map after obtaining an initial dense depth. In\nthis paper, we propose DenseFormer, a novel method that integrates the\ndiffusion model into the depth completion task. By incorporating the denoising\nmechanism of the diffusion model, DenseFormer generates the dense depth map by\nprogressively refining an initial random depth distribution through multiple\niterations. We propose a feature extraction module that leverages a feature\npyramid structure, along with multi-layer deformable attention, to effectively\nextract and integrate features from sparse depth maps and RGB images, which\nserve as the guiding condition for the diffusion process. Additionally, this\npaper presents a depth refinement module that applies multi-step iterative\nrefinement across various ranges to the dense depth results generated by the\ndiffusion process. The module utilizes image features enriched with multi-scale\ninformation and sparse depth input to further enhance the accuracy of the\npredicted depth map. Extensive experiments on the KITTI outdoor scene dataset\ndemonstrate that DenseFormer outperforms classical depth completion methods.", "published": "2025-03-31 12:11:01", "link": "http://arxiv.org/abs/2503.23993v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics", "abstract": "Since the disruption in LLM technology brought about by the release of GPT-3\nand ChatGPT, LLMs have shown remarkable promise in programming-related tasks.\nWhile code generation remains a popular field of research, code evaluation\nusing LLMs remains a problem with no conclusive solution. In this paper, we\nfocus on LLM-based code evaluation and attempt to fill in the existing gaps. We\npropose multi-agentic novel approaches using question-specific rubrics tailored\nto the problem statement, arguing that these perform better for logical\nassessment than the existing approaches that use question-agnostic rubrics. To\naddress the lack of suitable evaluation datasets, we introduce two datasets: a\nData Structures and Algorithms dataset containing 150 student submissions from\na popular Data Structures and Algorithms practice website, and an Object\nOriented Programming dataset comprising 80 student submissions from\nundergraduate computer science courses. In addition to using standard metrics\n(Spearman Correlation, Cohen's Kappa), we additionally propose a new metric\ncalled as Leniency, which quantifies evaluation strictness relative to expert\nassessment. Our comprehensive analysis demonstrates that question-specific\nrubrics significantly enhance logical assessment of code in educational\nsettings, providing better feedback aligned with instructional goals beyond\nmere syntactic correctness.", "published": "2025-03-31 11:59:43", "link": "http://arxiv.org/abs/2503.23989v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Deep Learning Model Deployment in Multiple Cloud Providers: an Exploratory Study Using Low Computing Power Environments", "abstract": "The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.", "published": "2025-03-31 11:58:37", "link": "http://arxiv.org/abs/2503.23988v1", "categories": ["cs.DC", "cs.AI", "cs.PF", "68T07, 68U01", "C.4; I.2.0; B.8.2"], "primary_category": "cs.DC"}
{"title": "Deep Neural Nets as Hamiltonians", "abstract": "Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.", "published": "2025-03-31 11:51:10", "link": "http://arxiv.org/abs/2503.23982v2", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG", "math.PR"], "primary_category": "cond-mat.dis-nn"}
{"title": "Noise-based reward-modulated learning", "abstract": "Recent advances in reinforcement learning (RL) have led to significant\nimprovements in task performance. However, training neural networks in an RL\nregime is typically achieved in combination with backpropagation, limiting\ntheir applicability in resource-constrained environments or when using\nnon-differentiable neural networks. While noise-based alternatives like\nreward-modulated Hebbian learning (RMHL) have been proposed, their performance\nhas remained limited, especially in scenarios with delayed rewards, which\nrequire retrospective credit assignment over time. Here, we derive a novel\nnoise-based learning rule that addresses these challenges. Our approach\ncombines directional derivative theory with Hebbian-like updates to enable\nefficient, gradient-free learning in RL. It features stochastic noisy neurons\nwhich can approximate gradients, and produces local synaptic updates modulated\nby a global reward signal. Drawing on concepts from neuroscience, our method\nuses reward prediction error as its optimization target to generate\nincreasingly advantageous behavior, and incorporates an eligibility trace to\nfacilitate temporal credit assignment in environments with delayed rewards. Its\nformulation relies on local information alone, making it compatible with\nimplementations in neuromorphic hardware. Experimental validation shows that\nour approach significantly outperforms RMHL and is competitive with BP-based\nbaselines, highlighting the promise of noise-based, biologically inspired\nlearning for low-power and real-time applications.", "published": "2025-03-31 11:35:23", "link": "http://arxiv.org/abs/2503.23972v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference", "abstract": "Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.", "published": "2025-03-31 11:13:18", "link": "http://arxiv.org/abs/2503.23956v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI2Agent: An End-to-End Framework for Deploying AI Projects as Autonomous Agents", "abstract": "As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.", "published": "2025-03-31 10:58:34", "link": "http://arxiv.org/abs/2503.23948v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in Discriminative and Generative AI Operations", "abstract": "This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.", "published": "2025-03-31 10:28:04", "link": "http://arxiv.org/abs/2503.23934v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "What the F*ck Is Artificial General Intelligence?", "abstract": "Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.", "published": "2025-03-31 10:15:37", "link": "http://arxiv.org/abs/2503.23923v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GAL-MAD: Towards Explainable Anomaly Detection in Microservice Applications Using Graph Attention Networks", "abstract": "The transition to microservices has revolutionized software architectures,\noffering enhanced scalability and modularity. However, the distributed and\ndynamic nature of microservices introduces complexities in ensuring system\nreliability, making anomaly detection crucial for maintaining performance and\nfunctionality. Anomalies stemming from network and performance issues must be\nswiftly identified and addressed. Existing anomaly detection techniques often\nrely on statistical models or machine learning methods that struggle with the\nhigh-dimensional, interdependent data inherent in microservice applications.\nCurrent techniques and available datasets predominantly focus on system traces\nand logs, limiting their ability to support advanced detection models. This\npaper addresses these gaps by introducing the RS-Anomic dataset generated using\nthe open-source RobotShop microservice application. The dataset captures\nmultivariate performance metrics and response times under normal and anomalous\nconditions, encompassing ten types of anomalies. We propose a novel anomaly\ndetection model called Graph Attention and LSTM-based Microservice Anomaly\nDetection (GAL-MAD), leveraging Graph Attention and Long Short-Term Memory\narchitectures to capture spatial and temporal dependencies in microservices. We\nutilize SHAP values to localize anomalous services and identify root causes to\nenhance explainability. Experimental results demonstrate that GAL-MAD\noutperforms state-of-the-art models on the RS-Anomic dataset, achieving higher\naccuracy and recall across varying anomaly rates. The explanations provide\nactionable insights into service anomalies, which benefits system\nadministrators.", "published": "2025-03-31 10:11:31", "link": "http://arxiv.org/abs/2504.00058v1", "categories": ["cs.SE", "cs.AI", "cs.LG", "I.2.m"], "primary_category": "cs.SE"}
{"title": "HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment", "abstract": "Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/", "published": "2025-03-31 09:58:11", "link": "http://arxiv.org/abs/2503.23907v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Training-Free Text-Guided Image Editing with Visual Autoregressive Model", "abstract": "Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.", "published": "2025-03-31 09:46:56", "link": "http://arxiv.org/abs/2503.23897v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DiffScale: Continuous Downscaling and Bias Correction of Subseasonal Wind Speed Forecasts using Diffusion Models", "abstract": "Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.", "published": "2025-03-31 09:44:28", "link": "http://arxiv.org/abs/2503.23893v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "primary_category": "cs.LG"}
{"title": "MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation Approach", "abstract": "Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.", "published": "2025-03-31 09:41:09", "link": "http://arxiv.org/abs/2503.23888v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SchemaAgent: A Multi-Agents Framework for Generating Relational Database Schema", "abstract": "The relational database design would output a schema based on user's\nrequirements, which defines table structures and their interrelated relations.\nTranslating requirements into accurate schema involves several non-trivial\nsubtasks demanding both database expertise and domain-specific knowledge. This\nposes unique challenges for automated design of relational databases. Existing\nefforts are mostly based on customized rules or conventional deep learning\nmodels, often producing suboptimal schema. Recently, large language models\n(LLMs) have significantly advanced intelligent application development across\nvarious domains. In this paper, we propose SchemaAgent, a unified LLM-based\nmulti-agent framework for the automated generation of high-quality database\nschema. SchemaAgent is the first to apply LLMs for schema generation, which\nemulates the workflow of manual schema design by assigning specialized roles to\nagents and enabling effective collaboration to refine their respective\nsubtasks. Schema generation is a streamlined workflow, where directly applying\nthe multi-agent framework may cause compounding impact of errors. To address\nthis, we incorporate dedicated roles for reflection and inspection, alongside\nan innovative error detection and correction mechanism to identify and rectify\nissues across various phases. For evaluation, we present a benchmark named\n\\textit{RSchema}, which contains more than 500 pairs of requirement description\nand schema. Experimental results on this benchmark demonstrate the superiority\nof our approach over mainstream LLMs for relational database schema generation.", "published": "2025-03-31 09:39:19", "link": "http://arxiv.org/abs/2503.23886v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models", "abstract": "The development of control policies for multi-robot systems traditionally\nfollows a complex and labor-intensive process, often lacking the flexibility to\nadapt to dynamic tasks. This has motivated research on methods to automatically\ncreate control policies. However, these methods require iterative processes of\nmanually crafting and refining objective functions, thereby prolonging the\ndevelopment cycle. This work introduces \\textit{GenSwarm}, an end-to-end system\nthat leverages large language models to automatically generate and deploy\ncontrol policies for multi-robot tasks based on simple user instructions in\nnatural language. As a multi-language-agent system, GenSwarm achieves zero-shot\nlearning, enabling rapid adaptation to altered or unseen tasks. The white-box\nnature of the code policies ensures strong reproducibility and\ninterpretability. With its scalable software and hardware architectures,\nGenSwarm supports efficient policy deployment on both simulated and real-world\nmulti-robot systems, realizing an instruction-to-execution end-to-end\nfunctionality that could prove valuable for robotics specialists and\nnon-specialists alike.The code of the proposed GenSwarm system is available\nonline: https://github.com/WindyLab/GenSwarm.", "published": "2025-03-31 09:26:34", "link": "http://arxiv.org/abs/2503.23875v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Learned Image Compression and Restoration for Digital Pathology", "abstract": "Digital pathology images play a crucial role in medical diagnostics, but\ntheir ultra-high resolution and large file sizes pose significant challenges\nfor storage, transmission, and real-time visualization. To address these\nissues, we propose CLERIC, a novel deep learning-based image compression\nframework designed specifically for whole slide images (WSIs). CLERIC\nintegrates a learnable lifting scheme and advanced convolutional techniques to\nenhance compression efficiency while preserving critical pathological details.\nOur framework employs a lifting-scheme transform in the analysis stage to\ndecompose images into low- and high-frequency components, enabling more\nstructured latent representations. These components are processed through\nparallel encoders incorporating Deformable Residual Blocks (DRB) and Recurrent\nResidual Blocks (R2B) to improve feature extraction and spatial adaptability.\nThe synthesis stage applies an inverse lifting transform for effective image\nreconstruction, ensuring high-fidelity restoration of fine-grained tissue\nstructures. We evaluate CLERIC on a digital pathology image dataset and compare\nits performance against state-of-the-art learned image compression (LIC)\nmodels. Experimental results demonstrate that CLERIC achieves superior\nrate-distortion (RD) performance, significantly reducing storage requirements\nwhile maintaining high diagnostic image quality. Our study highlights the\npotential of deep learning-based compression in digital pathology, facilitating\nefficient data management and long-term storage while ensuring seamless\nintegration into clinical workflows and AI-assisted diagnostic systems. Code\nand models are available at: https://github.com/pnu-amilab/CLERIC.", "published": "2025-03-31 09:09:09", "link": "http://arxiv.org/abs/2503.23862v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OrchMLLM: Orchestrate Multimodal Data with Batch Post-Balancing to Accelerate Multimodal Large Language Model Training", "abstract": "Multimodal large language models (MLLMs), such as GPT-4o, are garnering\nsignificant attention. During the exploration of MLLM training, we identified\nModality Composition Incoherence, a phenomenon that the proportion of a certain\nmodality varies dramatically across different examples. It exacerbates the\nchallenges of addressing mini-batch imbalances, which lead to uneven GPU\nutilization between Data Parallel (DP) instances and severely degrades the\nefficiency and scalability of MLLM training, ultimately affecting training\nspeed and hindering further research on MLLMs.\n  To address these challenges, we introduce OrchMLLM, a comprehensive framework\ndesigned to mitigate the inefficiencies in MLLM training caused by Modality\nComposition Incoherence. First, we propose Batch Post-Balancing Dispatcher, a\ntechnique that efficiently eliminates mini-batch imbalances in sequential data.\nAdditionally, we integrate MLLM Global Orchestrator into the training framework\nto orchestrate multimodal data and tackle the issues arising from Modality\nComposition Incoherence. We evaluate OrchMLLM across various MLLM sizes,\ndemonstrating its efficiency and scalability. Experimental results reveal that\nOrchMLLM achieves a Model FLOPs Utilization (MFU) of $41.6\\%$ when training an\n84B MLLM with three modalities on $2560$ H100 GPUs, outperforming Megatron-LM\nby up to $3.1\\times$ in throughput.", "published": "2025-03-31 08:24:23", "link": "http://arxiv.org/abs/2503.23830v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "When Counterfactual Reasoning Fails: Chaos and Real-World Complexity", "abstract": "Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.", "published": "2025-03-31 08:14:51", "link": "http://arxiv.org/abs/2503.23820v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics", "abstract": "Deep learning based diagnostic AI systems based on medical images are\nstarting to provide similar performance as human experts. However these data\nhungry complex systems are inherently black boxes and therefore slow to be\nadopted for high risk applications like healthcare. This problem of lack of\ntransparency is exacerbated in the case of recent large foundation models,\nwhich are trained in a self supervised manner on millions of data points to\nprovide robust generalisation across a range of downstream tasks, but the\nembeddings generated from them happen through a process that is not\ninterpretable, and hence not easily trustable for clinical applications. To\naddress this timely issue, we deploy conformal analysis to quantify the\npredictive uncertainty of a vision transformer (ViT) based foundation model\nacross patient demographics with respect to sex, age and ethnicity for the\ntasks of skin lesion classification using several public benchmark datasets.\nThe significant advantage of this method is that conformal analysis is method\nindependent and it not only provides a coverage guarantee at population level\nbut also provides an uncertainty score for each individual. We used a\nmodel-agnostic dynamic F1-score-based sampling during model training, which\nhelped to stabilize the class imbalance and we investigate the effects on\nuncertainty quantification (UQ) with or without this bias mitigation step. Thus\nwe show how this can be used as a fairness metric to evaluate the robustness of\nthe feature embeddings of the foundation model (Google DermFoundation) and thus\nadvance the trustworthiness and fairness of clinical AI.", "published": "2025-03-31 08:06:00", "link": "http://arxiv.org/abs/2503.23819v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "TuRTLe: A Unified Evaluation of LLMs for RTL Generation", "abstract": "The rapid advancements in LLMs have driven the adoption of generative AI in\nvarious domains, including Electronic Design Automation (EDA). Unlike\ntraditional software development, EDA presents unique challenges, as generated\nRTL code must not only be syntactically correct and functionally accurate but\nalso synthesizable by hardware generators while meeting performance, power, and\narea constraints. These additional requirements introduce complexities that\nexisting code-generation benchmarks often fail to capture, limiting their\neffectiveness in evaluating LLMs for RTL generation. To address this gap, we\npropose TuRTLe, a unified evaluation framework designed to systematically\nassess LLMs across key RTL generation tasks. TuRTLe integrates multiple\nexisting benchmarks and automates the evaluation process, enabling a\ncomprehensive assessment of LLM performance in syntax correctness, functional\ncorrectness, synthesis, PPA optimization, and exact line completion. Using this\nframework, we benchmark a diverse set of open LLMs and analyze their strengths\nand weaknesses in EDA-specific tasks. Our results show that reasoning-based\nmodels, such as DeepSeek R1, consistently outperform others across multiple\nevaluation criteria, but at the cost of increased computational overhead and\ninference latency. Additionally, base models are better suited in module\ncompletion tasks, while instruct-tuned models perform better in\nspecification-to-RTL tasks.", "published": "2025-03-31 07:43:12", "link": "http://arxiv.org/abs/2504.01986v1", "categories": ["cs.AR", "cs.AI", "I.2.5; J.6"], "primary_category": "cs.AR"}
{"title": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute", "abstract": "Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner", "published": "2025-03-31 07:31:32", "link": "http://arxiv.org/abs/2503.23803v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation", "abstract": "Segment Anything Models (SAMs), as vision foundation models, have\ndemonstrated remarkable performance across various image analysis tasks.\nDespite their strong generalization capabilities, SAMs encounter challenges in\nfine-grained detail segmentation for high-resolution class-independent\nsegmentation (HRCS), due to the limitations in the direct processing of\nhigh-resolution inputs and low-resolution mask predictions, and the reliance on\naccurate manual prompts. To address these limitations, we propose MGD-SAM2\nwhich integrates SAM2 with multi-view feature interaction between a global\nimage and local patches to achieve precise segmentation. MGD-SAM2 incorporates\nthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter\n(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the\nHierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement\nModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2\nencoder for enhanced extraction of local details and global semantics in HRCS\nimages. Then, MCEM and HMIM are proposed to further exploit local texture and\nglobal context by aggregating multi-view features within and across\nmulti-scales. Finally, DRM is designed to generate gradually restored\nhigh-resolution mask predictions, compensating for the loss of fine-grained\ndetails resulting from directly upsampling the low-resolution prediction maps.\nExperimental results demonstrate the superior performance and strong\ngeneralization of our model on multiple high-resolution and normal-resolution\ndatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.", "published": "2025-03-31 07:02:32", "link": "http://arxiv.org/abs/2503.23786v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DebFlow: Automating Agent Creation via Agent Debate", "abstract": "Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.", "published": "2025-03-31 06:56:13", "link": "http://arxiv.org/abs/2503.23781v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "One Person, One Bot", "abstract": "This short paper puts forward a vision for a new democratic model enabled by\nthe recent technological advances in agentic AI. It therefore opens with\ndrawing a clear and concise picture of the model, and only later addresses\nrelated proposals and research directions, and concerns regarding feasibility\nand safety. It ends with a note on the timeliness of this idea and on optimism.\nThe model proposed is that of assigning each citizen an AI Agent that would\nserve as their political delegate, enabling the return to direct democracy. The\npaper examines this models relation to existing research, its potential\nsetbacks and feasibility and argues for its further development.", "published": "2025-03-31 06:49:47", "link": "http://arxiv.org/abs/2504.01039v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation for Efficient Medical Image Segmentation", "abstract": "Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limitations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual representation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architecture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency details while replacing heavy upsampling layers with\nefficient wavelet-based summarization and reconstruction. This significantly\nreduces the number of parameters, which is critical for real-world deployment\nwhere computational resources and training times are constrained. Furthermore,\nthe model is generic and easily adaptable to diverse applications. Evaluations\non BraTS2023, FLARE2021, and KiTS2023 demonstrate performance on par with\nstate-of-the-art methods while offering substantially lower computational\ncomplexity.", "published": "2025-03-31 06:28:41", "link": "http://arxiv.org/abs/2503.23764v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigation of intelligent barbell squat coaching system based on computer vision and machine learning", "abstract": "Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.", "published": "2025-03-31 05:08:52", "link": "http://arxiv.org/abs/2503.23731v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Unimodal-driven Distillation in Multimodal Emotion Recognition with Dynamic Fusion", "abstract": "Multimodal Emotion Recognition in Conversations (MERC) identifies emotional\nstates across text, audio and video, which is essential for intelligent\ndialogue systems and opinion analysis. Existing methods emphasize heterogeneous\nmodal fusion directly for cross-modal integration, but often suffer from\ndisorientation in multimodal learning due to modal heterogeneity and lack of\ninstructive guidance. In this work, we propose SUMMER, a novel heterogeneous\nmultimodal integration framework leveraging Mixture of Experts with\nHierarchical Cross-modal Fusion and Interactive Knowledge Distillation. Key\ncomponents include a Sparse Dynamic Mixture of Experts (SDMoE) for capturing\ndynamic token-wise interactions, a Hierarchical Cross-Modal Fusion (HCMF) for\neffective fusion of heterogeneous modalities, and Interactive Knowledge\nDistillation (IKD), which uses a pre-trained unimodal teacher to guide\nmultimodal fusion in latent and logit spaces. Experiments on IEMOCAP and MELD\nshow SUMMER outperforms state-of-the-art methods, particularly in recognizing\nminority and semantically similar emotions.", "published": "2025-03-31 04:43:10", "link": "http://arxiv.org/abs/2503.23721v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GNN-Based Candidate Node Predictor for Influence Maximization in Temporal Graphs", "abstract": "In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.", "published": "2025-03-31 04:28:37", "link": "http://arxiv.org/abs/2503.23713v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Towards Benchmarking and Assessing the Safety and Robustness of Autonomous Driving on Safety-critical Scenarios", "abstract": "Autonomous driving has made significant progress in both academia and\nindustry, including performance improvements in perception task and the\ndevelopment of end-to-end autonomous driving systems. However, the safety and\nrobustness assessment of autonomous driving has not received sufficient\nattention. Current evaluations of autonomous driving are typically conducted in\nnatural driving scenarios. However, many accidents often occur in edge cases,\nalso known as safety-critical scenarios. These safety-critical scenarios are\ndifficult to collect, and there is currently no clear definition of what\nconstitutes a safety-critical scenario. In this work, we explore the safety and\nrobustness of autonomous driving in safety-critical scenarios. First, we\nprovide a definition of safety-critical scenarios, including static traffic\nscenarios such as adversarial attack scenarios and natural distribution shifts,\nas well as dynamic traffic scenarios such as accident scenarios. Then, we\ndevelop an autonomous driving safety testing platform to comprehensively\nevaluate autonomous driving systems, encompassing not only the assessment of\nperception modules but also system-level evaluations. Our work systematically\nconstructs a safety verification process for autonomous driving, providing\ntechnical support for the industry to establish standardized test framework and\nreduce risks in real-world road deployment.", "published": "2025-03-31 04:13:32", "link": "http://arxiv.org/abs/2503.23708v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "MolGround: A Benchmark for Molecular Grounding", "abstract": "Current molecular understanding approaches predominantly focus on the\ndescriptive aspect of human perception, providing broad, topic-level insights.\nHowever, the referential aspect -- linking molecular concepts to specific\nstructural components -- remains largely unexplored. To address this gap, we\npropose a molecular grounding benchmark designed to evaluate a model's\nreferential abilities. We align molecular grounding with established\nconventions in NLP, cheminformatics, and molecular science, showcasing the\npotential of NLP techniques to advance molecular understanding within the AI\nfor Science movement. Furthermore, we constructed the largest molecular\nunderstanding benchmark to date, comprising 79k QA pairs, and developed a\nmulti-agent grounding prototype as proof of concept. This system outperforms\nexisting models, including GPT-4o, and its grounding outputs have been\nintegrated to enhance traditional tasks such as molecular captioning and ATC\n(Anatomical, Therapeutic, Chemical) classification.", "published": "2025-03-31 02:23:16", "link": "http://arxiv.org/abs/2503.23668v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Remarks on the Polyak-Lojasiewicz inequality and the convergence of gradient systems", "abstract": "This work explores generalizations of the Polyak-Lojasiewicz inequality (PLI)\nand their implications for the convergence behavior of gradient flows in\noptimization problems. Motivated by the continuous-time linear quadratic\nregulator (CT-LQR) policy optimization problem -- where only a weaker version\nof the PLI is characterized in the literature -- this work shows that while\nweaker conditions are sufficient for global convergence to, and optimality of\nthe set of critical points of the cost function, the \"profile\" of the gradient\nflow solution can change significantly depending on which \"flavor\" of\ninequality the cost satisfies. After a general theoretical analysis, we focus\non fitting the CT-LQR policy optimization problem to the proposed framework,\nshowing that, in fact, it can never satisfy a PLI in its strongest form. We\nfollow up our analysis with a brief discussion on the difference between\ncontinuous- and discrete-time LQR policy optimization, and end the paper with\nsome intuition on the extension of this framework to optimization problems with\nL1 regularization and solved through proximal gradient flows.", "published": "2025-03-31 00:59:56", "link": "http://arxiv.org/abs/2503.23641v1", "categories": ["math.OC", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS", "abstract": "The advent of generative AI exemplified by large language models (LLMs) opens\nnew ways to represent and compute geographic information and transcends the\nprocess of geographic knowledge production, driving geographic information\nsystems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core,\nautonomous GIS can independently generate and execute geoprocessing workflows\nto perform spatial analysis. In this vision paper, we further elaborate on the\nconcept of autonomous GIS and present a conceptual framework that defines its\nfive autonomous goals, five autonomous levels, five core functions, and three\noperational scales. We demonstrate how autonomous GIS could perform geospatial\ndata retrieval, spatial analysis, and map making with four proof-of-concept GIS\nagents. We conclude by identifying critical challenges and future research\ndirections, including fine-tuning and self-growing decision-cores, autonomous\nmodeling, and examining the societal and practical implications of autonomous\nGIS. By establishing the groundwork for a paradigm shift in GIScience, this\npaper envisions a future where GIS moves beyond traditional workflows to\nautonomously reason, derive, innovate, and advance geospatial solutions to\npressing global challenges. As we design and deploy increasingly intelligent\ngeospatial systems, we have a responsibility to ensure they are developed in\nsocially responsible ways, serve the public good, and support the continued\nvalue of human geographic insight in an AI-augmented future.", "published": "2025-03-31 00:12:48", "link": "http://arxiv.org/abs/2503.23633v3", "categories": ["cs.AI", "cs.ET", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Intrinsically-Motivated Humans and Agents in Open-World Exploration", "abstract": "What drives exploration? Understanding intrinsic motivation is a\nlong-standing challenge in both cognitive science and artificial intelligence;\nnumerous objectives have been proposed and used to train agents, yet there\nremains a gap between human and agent exploration. We directly compare adults,\nchildren, and AI agents in a complex open-ended environment, Crafter, and study\nhow common intrinsic objectives: Entropy, Information Gain, and Empowerment,\nrelate to their behavior. We find that only Entropy and Empowerment are\nconsistently positively correlated with human exploration progress, indicating\nthat these objectives may better inform intrinsic reward design for agents.\nFurthermore, across agents and humans we observe that Entropy initially\nincreases rapidly, then plateaus, while Empowerment increases continuously,\nsuggesting that state diversity may provide more signal in early exploration,\nwhile advanced exploration should prioritize control. Finally, we find\npreliminary evidence that private speech utterances, and particularly goal\nverbalizations, may aid exploration in children.", "published": "2025-03-31 00:09:00", "link": "http://arxiv.org/abs/2503.23631v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Finding Interest Needle in Popularity Haystack: Improving Retrieval by Modeling Item Exposure", "abstract": "Recommender systems operate in closed feedback loops, where user interactions\nreinforce popularity bias, leading to over-recommendation of already popular\nitems while under-exposing niche or novel content. Existing bias mitigation\nmethods, such as Inverse Propensity Scoring (IPS) and Off- Policy Correction\n(OPC), primarily operate at the ranking stage or during training, lacking\nexplicit real-time control over exposure dynamics. In this work, we introduce\nan exposure- aware retrieval scoring approach, which explicitly models item\nexposure probability and adjusts retrieval-stage ranking at inference time.\nUnlike prior work, this method decouples exposure effects from engagement\nlikelihood, enabling controlled trade-offs between fairness and engagement in\nlarge-scale recommendation platforms. We validate our approach through online\nA/B experiments in a real-world video recommendation system, demonstrating a\n25% increase in uniquely retrieved items and a 40% reduction in the dominance\nof over-popular content, all while maintaining overall user engagement levels.\nOur results establish a scalable, deployable solution for mitigating popularity\nbias at the retrieval stage, offering a new paradigm for bias-aware\npersonalization.", "published": "2025-03-31 00:04:01", "link": "http://arxiv.org/abs/2503.23630v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Preparing graph states forbidding a vertex-minor", "abstract": "Measurement based quantum computing is preformed by adding non-Clifford\nmeasurements to a prepared stabilizer states. Entangling gates like CZ are\nlikely to have lower fidelities due to the nature of interacting qubits, so\nwhen preparing a stabilizer state, we wish to minimize the number of required\nentangling states. This naturally introduces the notion of CZ-distance.\n  Every stabilizer state is local-Clifford equivalent to a graph state, so we\nmay focus on graph states $\\left\\vert G \\right\\rangle$. As a lower bound for\ngeneral graphs, there exist $n$-vertex graphs $G$ such that the CZ-distance of\n$\\left\\vert G \\right\\rangle$ is $\\Omega(n^2 / \\log n)$. We obtain significantly\nimproved bounds when $G$ is contained within certain proper classes of graphs.\nFor instance, we prove that if $G$ is a $n$-vertex circle graph with clique\nnumber $\\omega$, then $\\left\\vert G \\right\\rangle$ has CZ-distance at most $4n\n\\log \\omega + 7n$. We prove that if $G$ is an $n$-vertex graph of rank-width at\nmost $k$, then $\\left\\vert G \\right\\rangle$ has CZ-distance at most\n$(2^{2^{k+1}} + 1) n$. More generally, this is obtained via a bound of $(k+2)n$\nthat we prove for graphs of twin-width at most $k$.\n  We also study how bounded-rank perturbations and low-rank cuts affect the\nCZ-distance. As a consequence, we prove that Geelen's Weak Structural\nConjecture for vertex-minors implies that if $G$ is an $n$-vertex graph\ncontained in some fixed proper vertex-minor-closed class of graphs, then\n$\\left\\vert G \\right\\rangle$ has CZ-distance at most $O(n\\log n)$. Since graph\nstates of locally equivalent graphs are local Clifford equivalent, proper\nvertex-minor-closed classes of graphs are natural and very general in this\nsetting.", "published": "2025-03-31 23:25:35", "link": "http://arxiv.org/abs/2504.00291v1", "categories": ["quant-ph", "cs.DM", "math.CO"], "primary_category": "quant-ph"}
{"title": "Reconstructing graphs with subgraph compositions", "abstract": "We generalize the problem of reconstructing strings from their substring\ncompositions first introduced by Acharya et al. in 2015 motivated by\npolymer-based advanced data storage systems utilizing mass spectrometry.\nNamely, we see strings as labeled path graphs, and as such try to reconstruct\nlabeled graphs. For a given integer t, the subgraph compositions contain either\nvectors of labels for each connected subgraph of order t\n(t-multiset-compositions) or the sum of all labels of all connected subgraphs\nof order t (t-sum-composition). We ask whether, given a graph of which we know\nthe structure and an oracle whom you can query for compositions, we can\nreconstruct the labeling of the graph. If it is possible, then the graph is\nreconstructable; otherwise, it is confusable, and two labeled graphs with the\nsame compositions are called equicomposable. We prove that reconstructing\nthrough a brute-force algorithm is wildly inefficient, before giving methods\nfor reconstructing several graph classes using as few compositions as possible.\nWe also give negative results, finding the smallest confusable graphs and\ntrees, as well as families with a large number of equicomposable non-isomorphic\ngraphs. An interesting result occurs when twinning one leaf of a path: some\npaths are confusable, creating a twin out of a leaf sees the graph alternating\nbetween reconstructable and confusable depending on the parity of the path, and\ncreating a false twin out of a leaf makes the graph reconstructable using only\nsum-compositions in all cases.", "published": "2025-03-31 19:25:17", "link": "http://arxiv.org/abs/2504.00169v1", "categories": ["math.CO", "cs.DM", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "$\\mathsf{P}$-completeness of Graph Local Complementation", "abstract": "Local complementation of a graph $G$ on vertex $v$ is an operation that\nresults in a new graph $G*v$, where the neighborhood of $v$ is complemented.\nThis operation has been widely studied in graph theory and quantum computing.\n  This article introduces the Local Complementation Problem, a decision problem\nthat captures the complexity of applying a sequence of local complementations.\nGiven a graph $G$, a sequence of vertices $s$, and a pair of vertices $u,v$,\nthe problem asks whether the edge $(u,v)$ is present in the graph obtained\nafter applying local complementations according to $s$. The main contribution\nof this work is proving that this problem is $\\mathsf{P}$-complete, implying\nthat computing a sequence of local complementation is unlikely to be\nefficiently parallelizable. The proof is based on a reduction from the Circuit\nValue Problem, a well-known $\\mathsf{P}$-complete problem, by simulating\ncircuits through local complementations.\n  Aditionally, the complexity of this problem is analyzed under different\nrestrictions. In particular, it is shown that for complete and star graphs, the\nproblem belongs to $\\mathsf{LOGSPACE}$. Finally, it is conjectured that the\nproblem remains $\\mathsf{P}$-complete for the class of circle graphs.", "published": "2025-03-31 14:27:46", "link": "http://arxiv.org/abs/2503.24144v1", "categories": ["cs.CC", "cs.DM"], "primary_category": "cs.CC"}
{"title": "Directed treewidth is closed under taking butterfly minors", "abstract": "Butterfly minors are a generalisation of the minor containment relation for\nundirected graphs to directed graphs. Many results in directed structural graph\ntheory use this notion as a central tool next to directed treewidth, a\ngeneralisation of the width measure treewidth to directed graphs. Adler\n[JCTB'07] showed that the directed treewidth is not closed under taking\nbutterfly minors. Over the years, many alternative definitions for directed\ntreewidth appeared throughout the literature, equivalent to the original\ndefinition up to small functions. In this paper, we consider the major ones and\nshow that not all of them share the problem identified by Adler.", "published": "2025-03-31 11:40:22", "link": "http://arxiv.org/abs/2503.23977v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Combining Query Performance Predictors: A Reproducibility Study", "abstract": "A large number of approaches to Query Performance Prediction (QPP) have been\nproposed over the last two decades. As early as 2009, Hauff et al. [28]\nexplored whether different QPP methods may be combined to improve prediction\nquality. Since then, significant research has been done both on QPP approaches,\nas well as their evaluation. This study revisits Hauff et al.s work to assess\nthe reproducibility of their findings in the light of new prediction methods,\nevaluation metrics, and datasets. We expand the scope of the earlier\ninvestigation by: (i) considering post-retrieval methods, including supervised\nneural techniques (only pre-retrieval techniques were studied in [28]); (ii)\nusing sMARE for evaluation, in addition to the traditional correlation\ncoefficients and RMSE; and (iii) experimenting with additional datasets\n(Clueweb09B and TREC DL). Our results largely support previous claims, but we\nalso present several interesting findings. We interpret these findings by\ntaking a more nuanced look at the correlation between QPP methods, examining\nwhether they capture diverse information or rely on overlapping factors.", "published": "2025-03-31 16:01:58", "link": "http://arxiv.org/abs/2503.24251v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Music Information Retrieval on Representative Mexican Folk Vocal Melodies Through MIDI Feature Extraction", "abstract": "This study analyzes representative Mexican folk vocal melodies using MIDI\nfeature extraction, examining ambitus, pitch-class entropy, and interval\ndistribution. It also explores the relationship between these features and song\npopularity, as measured by Spotify plays. The study employs MATLAB and the MIDI\nToolbox for extracting musical features and performing statistical analysis.\nThe findings reveal a significant variation in ambitus, with values ranging\nfrom 8 to 27 semitones, indicating a diverse compositional style and vocal\ndemand across the genre. The analysis of pitch-class entropy showcases a broad\nspectrum of melodic complexity, with Armando Manzanero's `Somos Novios'\ndisplaying the highest entropy, suggesting varied and complex melodic\nstructures, while traditional pieces like `La Bamba' exhibit lower entropy,\nindicating simpler, more repetitive patterns. The interval distribution\npredominantly features prime intervals (P1), major and minor seconds (M2, m2),\npointing to a compositional preference for close, contiguous intervals that\ncontribute to the melodies' accessibility and appeal. Statistical analysis do\nnot establish a significant correlation between the ambitus or entropy and the\nnumber of Spotify plays.", "published": "2025-03-31 15:57:28", "link": "http://arxiv.org/abs/2503.24243v1", "categories": ["cs.SD", "cs.IR"], "primary_category": "cs.SD"}
{"title": "Text2Tracks: Prompt-based Music Recommendation via Generative Retrieval", "abstract": "In recent years, Large Language Models (LLMs) have enabled users to provide\nhighly specific music recommendation requests using natural language prompts\n(e.g. \"Can you recommend some old classics for slow dancing?\"). In this setup,\nthe recommended tracks are predicted by the LLM in an autoregressive way, i.e.\nthe LLM generates the track titles one token at a time. While intuitive, this\napproach has several limitation. First, it is based on a general purpose\ntokenization that is optimized for words rather than for track titles. Second,\nit necessitates an additional entity resolution layer that matches the track\ntitle to the actual track identifier. Third, the number of decoding steps\nscales linearly with the length of the track title, slowing down inference. In\nthis paper, we propose to address the task of prompt-based music recommendation\nas a generative retrieval task. Within this setting, we introduce novel,\neffective, and efficient representations of track identifiers that\nsignificantly outperform commonly used strategies. We introduce Text2Tracks, a\ngenerative retrieval model that learns a mapping from a user's music\nrecommendation prompt to the relevant track IDs directly. Through an offline\nevaluation on a dataset of playlists with language inputs, we find that (1) the\nstrategy to create IDs for music tracks is the most important factor for the\neffectiveness of Text2Tracks and semantic IDs significantly outperform commonly\nused strategies that rely on song titles as identifiers (2) provided with the\nright choice of track identifiers, Text2Tracks outperforms sparse and dense\nretrieval solutions trained to retrieve tracks from language prompts.", "published": "2025-03-31 15:09:19", "link": "http://arxiv.org/abs/2503.24193v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On the Reproducibility of Learned Sparse Retrieval Adaptations for Long Documents", "abstract": "Document retrieval is one of the most challenging tasks in Information\nRetrieval. It requires handling longer contexts, often resulting in higher\nquery latency and increased computational overhead. Recently, Learned Sparse\nRetrieval (LSR) has emerged as a promising approach to address these\nchallenges. Some have proposed adapting the LSR approach to longer documents by\naggregating segmented document using different post-hoc methods, including\nn-grams and proximity scores, adjusting representations, and learning to\nensemble all signals. In this study, we aim to reproduce and examine the\nmechanisms of adapting LSR for long documents. Our reproducibility experiments\nconfirmed the importance of specific segments, with the first segment\nconsistently dominating document retrieval performance. Furthermore, We\nre-evaluate recently proposed methods -- ExactSDM and SoftSDM -- across varying\ndocument lengths, from short (up to 2 segments) to longer (3+ segments). We\nalso designed multiple analyses to probe the reproduced methods and shed light\non the impact of global information on adapting LSR to longer contexts. The\ncomplete code and implementation for this project is available at:\nhttps://github.com/lionisakis/Reproducibilitiy-lsr-long.", "published": "2025-03-31 08:19:31", "link": "http://arxiv.org/abs/2503.23824v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Over-the-Air Edge Inference via End-to-End Metasurfaces-Integrated Artificial Neural Networks", "abstract": "In the Edge Inference (EI) paradigm, where a Deep Neural Network (DNN) is\nsplit across the transceivers to wirelessly communicate goal-defined features\nin solving a computational task, the wireless medium has been commonly treated\nas a source of noise. In this paper, motivated by the emerging technologies of\nReconfigurable Intelligent Surfaces (RISs) and Stacked Intelligent Metasurfaces\n(SIM) that offer programmable propagation of wireless signals, either through\ncontrollable reflections or diffractions, we optimize the RIS/SIM-enabled smart\nwireless environment as a means of over-the-air computing, resembling the\noperations of DNN layers. We propose a framework of Metasurfaces-Integrated\nNeural Networks (MINNs) for EI, presenting its modeling, training through a\nbackpropagation variation for fading channels, and deployment aspects. The\noverall end-to-end DNN architecture is general enough to admit RIS and SIM\ndevices, through controllable reconfiguration before each transmission or fixed\nconfigurations after training, while both channel-aware and channel-agnostic\ntransceivers are considered. Our numerical evaluation showcases metasurfaces to\nbe instrumental in performing image classification under link budgets that\nimpede conventional communications or metasurface-free systems. It is\ndemonstrated that our MINN framework can significantly simplify EI\nrequirements, achieving near-optimal performance with $50~$dB lower testing\nsignal-to-noise ratio compared to training, even without transceiver channel\nknowledge.", "published": "2025-03-31 21:14:09", "link": "http://arxiv.org/abs/2504.00233v1", "categories": ["cs.LG", "cs.ET", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Beamforming Design for Continuous Aperture Array (CAPA)-Based MIMO Systems", "abstract": "An efficient beamforming design is proposed for continuous aperture array\n(CAPA)-based point-to-point multiple-input multiple-output (MIMO) systems. In\ncontrast to conventional spatially discrete array (SPDA)-MIMO systems, whose\noptimal beamforming can be obtained using singular-value decomposition,\nCAPA-MIMO systems require solving the eigendecomposition of a Hermitian kernel\noperator, which is computationally prohibitive. To address this challenge, an\nexplicit closed-form expression for the achievable rate of CAPA-MIMO systems is\nfirst derived as a function of the continuous transmit beamformer.\nSubsequently, an iterative weighted minimum mean-squared error (WMMSE)\nalgorithm is proposed, directly addressing the CAPA-MIMO beamforming\noptimization without discretization approximation. Closed-form updates for each\niteration of the WMMSE algorithm are derived via the calculus of variations\n(CoV) method. For low-complexity implementation, an equivalent matrix-based\niterative solution is introduced using Gauss-Legendre quadrature. Our numerical\nresults demonstrate that 1) CAPA-MIMO achieves substantial performance gain\nover the SPDA-MIMO, 2) the proposed WMMSE algorithm enhances performance while\nsignificantly reducing computational complexity compared to state-of-the-art\nFourier-based approaches, and 3) the proposed WMMSE algorithm enables practical\nrealization of parallel, non-interfering transmissions.", "published": "2025-03-31 19:41:35", "link": "http://arxiv.org/abs/2504.00181v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sample-Optimal Private Regression in Polynomial Time", "abstract": "We consider the task of privately obtaining prediction error guarantees in\nordinary least-squares regression problems with Gaussian covariates (with\nunknown covariance structure). We provide the first sample-optimal polynomial\ntime algorithm for this task under both pure and approximate differential\nprivacy. We show that any improvement to the sample complexity of our algorithm\nwould violate either statistical-query or information-theoretic lower bounds.\nAdditionally, our algorithm is robust to a small fraction of arbitrary outliers\nand achieves optimal error rates as a function of the fraction of outliers. In\ncontrast, all prior efficient algorithms either incurred sample complexities\nwith sub-optimal dimension dependence, scaling with the condition number of the\ncovariates, or obtained a polynomially worse dependence on the privacy\nparameters.\n  Our technical contributions are two-fold: first, we leverage resilience\nguarantees of Gaussians within the sum-of-squares framework. As a consequence,\nwe obtain efficient sum-of-squares algorithms for regression with optimal\nrobustness rates and sample complexity. Second, we generalize the recent\nrobustness-to-privacy framework [HKMN23, (arXiv:2212.05015)] to account for the\ngeometry induced by the covariance of the input samples. This framework\ncrucially relies on the robust estimators to be sum-of-squares algorithms, and\ncombining the two steps yields a sample-optimal private regression algorithm.\nWe believe our techniques are of independent interest, and we demonstrate this\nby obtaining an efficient algorithm for covariance-aware mean estimation, with\nan optimal dependence on the privacy parameters.", "published": "2025-03-31 17:08:12", "link": "http://arxiv.org/abs/2503.24321v1", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "cs.DS"}
{"title": "Intersection of linear and multi-twisted codes with applications", "abstract": "In this paper, we derive a formula for constructing a generator matrix for\nthe intersection of any pair of linear codes over a finite field. Consequently,\nwe establish a condition under which a linear code has a trivial intersection\nwith another linear code (or its Galois dual). Furthermore, we provide a\ncondition for reversibility and propose a generator matrix formula for the\nlargest reversible subcode of any linear code. We then focus on the\ncomprehensive class of multi-twisted (MT) codes, which are naturally and more\neffectively represented using generator polynomial matrices (GPMs). We prove\nthat the reversed code of an MT code remains MT and derive an explicit formula\nfor its GPM. Additionally, we examine the intersection of a pair of MT codes,\npossibly with different shift constants, and demonstrate that this intersection\nis not necessarily MT. However, when the intersection has an MT structure, we\ndetermine the corresponding shift constants. We also establish a GPM formula\nfor the intersection of a pair of MT codes with the same shift constants. This\nresult enables us to derive a GPM formula for the intersection of an MT code\nand the Galois dual of another MT code. Finally, we examine conditions for\nvarious properties on MT codes. Perhaps most importantly, the necessary and\nsufficient conditions for an MT code to be Galois self-orthogonal, Galois\ndual-containing, Galois linear complementary dual (LCD), or reversible.", "published": "2025-03-31 16:48:27", "link": "http://arxiv.org/abs/2503.24303v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Comparison among Single Carrier, OFDM, and OTFS in mmWave Multi-Connectivity Downlink Transmissions", "abstract": "In this paper, we perform a comparative study of common wireless\ncommunication waveforms, namely the single carrier (SC), orthogonal\nfrequency-division multiplexing (OFDM), and orthogonal time-frequency-space\n(OTFS) modulation in a millimeter wave (mmWave) downlink multi-connectivity\nscenario, where multiple access points (APs) jointly serve a given user under\nimperfect time and frequency synchronization errors. For a fair comparison, all\nthe three waveforms are evaluated using variants of common frequency domain\nequalization (FDE). To this end, a novel cross domain iterative detection for\nOTFS is proposed. The performance of the different waveforms is evaluated\nnumerically in terms of pragmatic capacity. The numerical results show that\nOTFS significantly outperforms SC and OFDM at cost of reasonably increased\ncomplexity, because of the low cyclic-prefix (CP) overhead and the\neffectiveness of the proposed detection.", "published": "2025-03-31 05:47:45", "link": "http://arxiv.org/abs/2503.23745v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees via Constrained Mean-Field Reinforcement Learning", "abstract": "The rapid expansion of ride-sourcing services such as Uber, Lyft, and Didi\nChuxing has fundamentally reshaped urban transportation by offering flexible,\non-demand mobility via mobile applications. Despite their convenience, these\nplatforms confront significant operational challenges, particularly vehicle\nrebalancing - the strategic repositioning of thousands of vehicles to address\nspatiotemporal mismatches in supply and demand. Inadequate rebalancing results\nin prolonged rider waiting times, inefficient vehicle utilization, and\ninequitable distribution of services, leading to disparities in driver\navailability and income.\n  To tackle these complexities, we introduce scalable continuous-state\nmean-field control (MFC) and reinforcement learning (MFRL) models that\nexplicitly represent each vehicle's precise location and employ continuous\nrepositioning actions guided by the distribution of other vehicles. To ensure\nequitable service distribution, an accessibility constraint is integrated\nwithin our optimal control formulation, balancing operational efficiency with\nequitable access to the service across geographic regions. Our approach\nacknowledges realistic conditions, including inherent stochasticity in\ntransitions, the simultaneous occurrence of vehicle-rider matching, vehicles'\nrebalancing and cruising, and variability in rider behaviors. Crucially, we\nrelax the traditional mean-field assumption of equal supply-demand volume,\nbetter reflecting practical scenarios. Extensive empirical evaluation using\nreal-world data-driven simulation of Shenzhen demonstrates the real-time\nefficiency and robustness of our approach at the scale of tens of thousands of\nvehicles.\n  The code is available at\nhttps://github.com/mjusup1501/mf-vehicle-rebalancing.", "published": "2025-03-31 15:00:11", "link": "http://arxiv.org/abs/2503.24183v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Consensus on Open Multi-Agent Systems Over Graphs Sampled from Graphons", "abstract": "We show how graphons can be used to model and analyze open multi-agent\nsystems, which are multi-agent systems subject to arrivals and departures, in\nthe specific case of linear consensus. First, we analyze the case of\nreplacements, where under the assumption of a deterministic interval between\ntwo replacements, we derive an upper bound for the disagreement in expectation.\nThen, we study the case of arrivals and departures, where we define a process\nfor the evolution of the number of agents that guarantees a minimum and a\nmaximum number of agents. Next, we derive an upper bound for the disagreement\nin expectation, and we establish a link with the spectrum of the expected graph\nused to generate the graph topologies. Finally, for stochastic block model\n(SBM) graphons, we prove that the computation of the spectrum of the expected\ngraph can be performed based on a matrix whose dimension depends only on the\ngraphon and it is independent of the number of agents.", "published": "2025-03-31 12:50:40", "link": "http://arxiv.org/abs/2503.24025v1", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "A new iterated Tikhonov regularization method for Fredholm integral equation of first kind", "abstract": "We consider Fredholm integral equation of the first kind, present an\nefficient new iterated Tikhonov method to solve it. The new Tikhonov iteration\nmethod has been proved which can achieve the optimal order under a-priori\nassumption. In numerical experiments, the new iterated Tikhonov regularization\nmethod is compared with the classical iterated Tikhonov method, Landweber\niteration method to solve the corresponding discrete problem, which indicates\nthe validity and efficiency of the proposed method.", "published": "2025-03-31 20:33:28", "link": "http://arxiv.org/abs/2504.00209v1", "categories": ["math.NA", "cs.NA", "65F10, 65F22"], "primary_category": "math.NA"}
{"title": "Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear Inverse Modeling", "abstract": "The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.", "published": "2025-03-31 15:46:06", "link": "http://arxiv.org/abs/2503.24234v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Polynomial Inequalities and Optimal Stability of Numerical Integrators", "abstract": "A numerical integrator for $\\dot{x}=f(x)$ is called \\emph{stable} if, when\napplied to the 1D Dahlquist test equation $\\dot{x}=\\lambda\nx,\\lambda\\in\\mathbb{C}$ with fixed timestep $h>0$, the numerical solution\nremains bounded as the number of steps tends to infinity. It is well known that\nno explicit integrator may remain stable beyond certain limits in $\\lambda$.\nFurthermore, these stability limits are only tight for certain specific\nintegrators (different in each case), which may then be called `optimally\nstable'. Such optimal stability results are typically proven using\nsophisticated techniques from complex analysis, leading to rather abstruse\nproofs. In this article, we pursue an alternative approach, exploiting\nconnections with the Bernstein and Markov brothers inequalities for\npolynomials. This simplifies the proofs greatly and offers a framework which\nunifies the diverse results that have been obtained.", "published": "2025-03-31 15:44:49", "link": "http://arxiv.org/abs/2503.24232v1", "categories": ["math.NA", "cs.NA", "math.HO"], "primary_category": "math.NA"}
{"title": "Data-driven construction of a generalized kinetic collision operator from molecular dynamics", "abstract": "We introduce a data-driven approach to learn a generalized kinetic collision\noperator directly from molecular dynamics. Unlike the conventional (e.g.,\nLandau) models, the present operator takes an anisotropic form that accounts\nfor a second energy transfer arising from the collective interactions between\nthe pair of collision particles and the environment. Numerical results show\nthat preserving the broadly overlooked anisotropic nature of the collision\nenergy transfer is crucial for predicting the plasma kinetics with\nnon-negligible correlations, where the Landau model shows limitations.", "published": "2025-03-31 15:26:06", "link": "http://arxiv.org/abs/2503.24208v2", "categories": ["physics.comp-ph", "cs.LG", "cs.NA", "math.NA", "physics.plasm-ph"], "primary_category": "physics.comp-ph"}
{"title": "Computational Orthodontic Force Simulation: A Review", "abstract": "In orthodontic treatment, the biological response of the tooth, periodontal\nligament, and bone complex to orthodontic force is crucial in influencing\ntreatment outcomes. The challenge lies in accurately measuring, estimating, and\npredicting these forces during clinical procedures. This review aims to fill\nthe gap in the literature by systematically summarizing existing research on\northodontic force simulation, examining common loading techniques and\ntechnologies, and discussing the potential for refining the orthodontic force\nsimulation process. The literature was comprehensively reviewed, with an\nemphasis on the exploration of the biological mechanism of tooth movement.\nStudies were categorized based on force-loading techniques for both fixed and\ninvisible orthodontic appliances. Finite element (FE) analysis stands out as\nthe predominant technique for orthodontic force simulation, with a significant\nfocus on fixed orthodontics but limited emphasis on invisible orthodontics.\nCurrent orthodontic force simulations tend to be fragmented, often considering\nonly the instantaneous response to applied forces. There exists an urgent\ndemand for a sophisticated analytical simulation model. Such a model, possibly\nleveraging advanced technologies like deep learning, holds the promise of\nforecasting orthodontic treatment outcomes with heightened precision and\nefficiency.", "published": "2025-03-31 15:13:36", "link": "http://arxiv.org/abs/2503.24195v1", "categories": ["physics.med-ph", "cs.NA", "math.NA"], "primary_category": "physics.med-ph"}
{"title": "A simple and general framework for the construction of exactly div-curl-grad compatible discontinuous Galerkin finite element schemes on unstructured simplex meshes", "abstract": "We introduce a new family of discontinuous Galerkin (DG) finite element\nschemes for the discretization of first order systems of hyperbolic partial\ndifferential equations (PDE) on unstructured simplex meshes in two and three\nspace dimensions that respect the two basic vector calculus identities exactly\nalso at the discrete level, namely that the curl of the gradient is zero and\nthat the divergence of the curl is zero. The key ingredient here is the\nconstruction of two compatible discrete nabla operators, a primary one and a\ndual one, both defined on general unstructured simplex meshes in multiple space\ndimensions. Our new schemes extend existing cell-centered finite volume methods\nbased on corner fluxes to arbitrary high order of accuracy in space. An\nimportant feature of our new method is the fact that only two different\ndiscrete function spaces are needed to represent the numerical solution, and\nthe choice of the appropriate function space for each variable is related to\nthe origin and nature of the underlying PDE. The first class of variables is\ndiscretized at the aid of a discontinuous Galerkin approach, where the\nnumerical solution is represented via piecewise polynomials of degree N and\nwhich are allowed to jump across element interfaces. This set of variables is\nrelated to those PDE which are mere consequences of the definitions, derived\nfrom some abstract scalar and vector potentials, and for which involutions like\nthe divergence-free or the curl-free property must hold if satisfied by the\ninitial data. The second class of variables is discretized via classical\ncontinuous Lagrange finite elements of approximation degree M=N+1 and is\nrelated to those PDE which can be derived as the Euler-Lagrange equations of an\nunderlying variational principle.", "published": "2025-03-31 14:17:11", "link": "http://arxiv.org/abs/2503.24131v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence of a finite volume scheme for a model for ants", "abstract": "We develop and analyse a finite volume scheme for a nonlocal active matter\nsystem known to exhibit a rich array of complex behaviours. The model under\ninvestigation was derived from a stochastic system of interacting particles\ndescribing a foraging ant colony coupled to pheromone dynamics. In this work,\nwe prove that the unique numerical solution converges to the unique weak\nsolution as the mesh size and the time step go to zero. We also show discrete\nlong-time estimates, which prove that certain norms are preserved for all\ntimes, uniformly in the mesh size and time step. In particular, we prove higher\nregularity estimates which provide an analogue of continuum parabolic higher\nregularity estimates. Finally, we numerically study the rate of convergence of\nthe scheme, and we provide examples of the existence of multiple metastable\nsteady states.", "published": "2025-03-31 12:23:49", "link": "http://arxiv.org/abs/2503.24001v1", "categories": ["math.NA", "cs.NA", "math.AP", "65M08, 65M12, 35B36 (Primary), 35K55, 35Q92, 92D50 (Secondary)"], "primary_category": "math.NA"}
{"title": "Convergence of Calder\u00f3n residuals", "abstract": "In this paper, we describe a framework to compute expected convergence rates\nfor residuals based on the Calder\\'on identities for general second order\ndifferential operators for which fundamental solutions are known. The idea is\nthat these rates could be used to validate implementations of boundary integral\noperators and allow to test operators separately by choosing solutions where\nparts of the Calder\\'on identities vanish. Our estimates rely on simple vector\nnorms, and thus avoid the use of hard-to-compute norms and the residual\ncomputation can be easily implemented in existing boundary element codes. We\ntest the proposed Calder\\'on residuals as debugging tool by introducing\nartificial errors into the Galerkin matrices of some of the boundary integral\noperators for the Laplacian and time-harmonic Maxwell's equations. From this,\nwe learn that our estimates are not sharp enough to always detect errors, but\nstill provide a simple and useful debugging tool in many situations.", "published": "2025-03-31 09:49:19", "link": "http://arxiv.org/abs/2503.23900v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Integral regularization PINNs for evolution equations", "abstract": "Evolution equations, including both ordinary differential equations (ODEs)\nand partial differential equations (PDEs), play a pivotal role in modeling\ndynamic systems. However, achieving accurate long-time integration for these\nequations remains a significant challenge. While physics-informed neural\nnetworks (PINNs) provide a mesh-free framework for solving PDEs, they often\nsuffer from temporal error accumulation, which limits their effectiveness in\ncapturing long-time behaviors. To alleviate this issue, we propose integral\nregularization PINNs (IR-PINNs), a novel approach that enhances temporal\naccuracy by incorporating an integral-based residual term into the loss\nfunction. This method divides the entire time interval into smaller\nsub-intervals and enforces constraints over these sub-intervals, thereby\nimproving the resolution and correlation of temporal dynamics. Furthermore,\nIR-PINNs leverage adaptive sampling to dynamically refine the distribution of\ncollocation points based on the evolving solution, ensuring higher accuracy in\nregions with sharp gradients or rapid variations. Numerical experiments on\nbenchmark problems demonstrate that IR-PINNs outperform original PINNs and\nother state-of-the-art methods in capturing long-time behaviors, offering a\nrobust and accurate solution for evolution equations.", "published": "2025-03-31 05:02:59", "link": "http://arxiv.org/abs/2503.23729v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "On blowup solution in NLS equation under dispersion or nonlinearity management", "abstract": "In this paper, we study the dispersion-managed nonlinear Schr\\\"odinger\n(DM-NLS) equation $$ i\\partial_t u(t,x)+\\gamma(t)\\Delta\nu(t,x)=|u(t,x)|^{\\frac4d}u(t,x),\\quad x\\in\\R^d, $$ and the nonlinearity-managed\nNLS (NM-NLS) equation: $$ i\\partial_t u(t,x)+\\Delta\nu(t,x)=\\gamma(t)|u(t,x)|^{\\frac4d}u(t,x), \\quad x\\in\\R^d, $$ where $\\gamma(t)$\nis a periodic function which is equal to $-1$ when $t\\in (0,1]$ and is equal to\n$1$ when $t\\in (1,2]$. The two models share the feature that the focusing and\ndefocusing effects convert periodically. For the classical focusing NLS, it is\nknown that the initial data $$ u_0(x)=T^{-\\frac{d}{2}}\\fe^{i\\frac{|x|^2}{4T}\n-i\\frac{\\omega^2}{T}}Q_\\omega\\left(\\frac{x}{T}\\right) $$ leads to a blowup\nsolution $$(T-t)^{-\\frac{d}{2}}\\fe^{i\\frac{|x|^2}{4(T-t)}\n-i\\frac{\\omega^2}{T-t}}Q_\\omega\\left(\\frac{x}{T-t}\\right), $$ so when $T\\leq1$,\nthis is also a blowup solution for DM-NLS and NM-NLS which blows up in the\nfirst focusing layer.\n  For DM-NLS, we prove that when $T>1$, the initial data $u_0$ above does not\nlead to a finite-time blowup and the corresponding solution is globally\nwell-posed. For NM-NLS, we prove the global well-posedness for $T\\in(1,2)$ and\nwe construct solution that can blow up at any focusing layer. The theoretical\nstudies are complemented by extensive numerical explorations towards\nunderstanding the stabilization effects in the two models and addressing their\ndifference.", "published": "2025-03-31 04:36:58", "link": "http://arxiv.org/abs/2503.23716v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Bayesian Inference for a Time-Fractional HIV Model with Nonlinear Diffusion", "abstract": "This study investigates an inverse problem associated with a time-fractional\nHIV infection model incorporating nonlinear diffusion. The model describes the\ndynamics of uninfected target cells, infected cells, and free virus particles,\nwhere the diffusion terms are nonlinear density functions. The primary\nobjective is to recover the unknown diffusion functions by utilizing final-time\nmeasurement data. Due to the inherent ill-posedness of the inverse problem and\nthe presence of measurement noise, we employ a Bayesian inference framework to\nobtain stable and reliable estimates while quantifying uncertainty. To solve\nthe inverse problem efficiently, we develop an Iterative Regularizing Ensemble\nKalman Method (IREKM), which enables the simultaneous estimation of multiple\ndiffusion terms without requiring gradient information. Numerical experiments\nvalidate the effectiveness of the proposed method in reconstructing the unknown\ndiffusion terms under different noise levels, demonstrating its robustness and\naccuracy. These findings contribute to a deeper understanding of HIV infection\ndynamics and provide a computational approach for parameter estimation in\nfractional diffusion models.", "published": "2025-03-31 00:42:24", "link": "http://arxiv.org/abs/2503.23638v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Robust No-Arbitrage under Projective Determinacy", "abstract": "Drawing from set theory, this article contributes to a deeper understanding\nof the no-arbitrage principle in multiple-priors settings and its application\nin mathematical finance.\n  In the quasi-sure discrete-time frictionless market framework of Bouchard and\nNutz, the equivalence between the quasi-sure no-arbitrage condition and the\nexistence of a probability measure for which the local one-prior no-arbitrage\ncondition holds and the affine hull of the support is equal to the quasi-sure\nsupport, all of this in a quasi-sure sense, was established by Blanchard and\nCarassus. We aim to extend this result to the projective setup introduced by\nCarassus and Ferhoune.\n  This setup allows for standardised measurability assumptions, in contrast to\nthe framework of Bouchard and Nutz, where prices are assumed to be Borel\nmeasurable, strategies and stochastic kernels universally measurable, and the\ngraphs of one-step priors analytic sets.\n  To achieve this, we assume the classical axioms of Zermelo-Fraenkel set\ntheory, including the axiom of choice (ZFC), supplemented by the Projective\nDeterminacy (PD) axiom. In ZFC+PD the existence of such probability measures\nwas assumed by Carassus and Ferhoune to prove the existence of solutions in a\nquasi-sure nonconcave utility maximisation problem. The equivalence with the\nquasi-sure no-arbitrage was only conjectured.", "published": "2025-03-31 19:13:33", "link": "http://arxiv.org/abs/2504.00158v1", "categories": ["q-fin.MF", "math.LO"], "primary_category": "q-fin.MF"}
{"title": "Mathematical foundations of information economics", "abstract": "The state of economic theory and accumulated facts from the different\nbranches of the economic science require to analyze the concept of the\ndescription of economy systems. The economic reality generates the problems the\nsolution of that is only possible by a new paradigm of the description of\neconomy system. The classical mathematical economics is based on a notion of\nthe rational consumer choice generated by a certain preference relation on some\nset of goods a consumer wanted and the concept of maximization of the firm\nprofit. The sense of the notion of the ratio- nal consumer choice is that it is\ndetermined by a certain utility function, defining the choice of a consumer by\nmaximization of it on a certain budget set of goods. More- over, choices of\nconsumers are independent. In the reality choices of consumers are not\nindependent because they depend on the firms supply. Except the firms supply,\nthe consumer choice is also determined by information about the state of the\neconomy system that the consumer has and respectively eval- uates at the moment\nof the choice. In turn, the firms supply is made on the basis of needs of the\nconsumers and their buying power. By information about the state of the economy\nsystem we understand a certain information about the equilibrium price vector\nand productive processes realized in the economy system under the equilibrium\nprice vector.", "published": "2025-03-31 16:05:39", "link": "http://arxiv.org/abs/2503.24257v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Asymmetry in Distributions of Accumulated Gains and Losses in Stock Returns", "abstract": "We study decades-long historic distributions of accumulated S\\&P500 returns,\nfrom daily returns to those over several weeks. The time series of the returns\nemphasize major upheavals in the markets -- Black Monday, Tech Bubble,\nFinancial Crisis and Covid Pandemic -- which are reflected in the tail ends of\nthe distributions. De-trending the overall gain, we concentrate on comparing\ndistributions of gains and losses. Specifically, we compare the tails of the\ndistributions, which are believed to exhibit power-law behavior and possibly\ncontain outliers. Towards this end we find confidence intervals of the linear\nfits of the tails of the complementary cumulative distribution functions on a\nlog-log scale, as well as conduct a statistical U-test in order to detect\noutliers. We also study probability density functions of the full distributions\nof the returns with the emphasis on their asymmetry. The key empirical\nobservations are that the mean of de-trended distributions increases\nnear-linearly with the number of days of accumulation while the overall skew is\nnegative -- consistent with the heavier tails of losses -- and depends little\non the number of days of accumulation. At the same time the variance of the\ndistributions exhibits near-perfect linear dependence on the number of days of\naccumulation, that is it remains constant if scaled to the latter. Finally, we\ndiscuss the theoretical framework for understanding accumulated returns. Our\nmain conclusion is that the current state of theory, which predicts symmetric\nor near-symmetric distributions of returns cannot explain the aggregate of\nempirical results.", "published": "2025-03-31 15:54:04", "link": "http://arxiv.org/abs/2503.24241v1", "categories": ["q-fin.ST", "econ.TH", "physics.data-an"], "primary_category": "q-fin.ST"}
{"title": "A cost of capital approach to determining the LGD discount rate", "abstract": "Loss Given Default (LGD) is a key risk parameter in determining a bank's\nregulatory capital. During LGD-estimation, realised recovery cash flows are to\nbe discounted at an appropriate rate. Regulatory guidance mandates that this\nrate should allow for the time value of money, as well as include a risk\npremium that reflects the \"undiversifiable risk\" within these recoveries.\nHaving extensively reviewed earlier methods of determining this rate, we\npropose a new approach that is inspired by the cost of capital approach from\nthe Solvency II regulatory regime. Our method involves estimating a\nmarket-consistent price for a portfolio of defaulted loans, from which an\nassociated discount rate may be inferred. We apply this method to mortgage and\npersonal loans data from a large South African bank. The results reveal the\nmain drivers of the discount rate to be the mean and variance of these\nrecoveries, as well as the bank's cost of capital in excess of the risk-free\nrate. Our method therefore produces a discount rate that reflects both the\nundiversifiable risk of recovery recoveries and the time value of money,\nthereby satisfying regulatory requirements. This work can subsequently enhance\nthe LGD-component within the modelling of both regulatory and economic capital.", "published": "2025-03-31 12:09:21", "link": "http://arxiv.org/abs/2503.23992v1", "categories": ["q-fin.RM", "q-fin.ST"], "primary_category": "q-fin.RM"}
{"title": "DiffDenoise: Self-Supervised Medical Image Denoising with Conditional Diffusion Models", "abstract": "Many self-supervised denoising approaches have been proposed in recent years.\nHowever, these methods tend to overly smooth images, resulting in the loss of\nfine structures that are essential for medical applications. In this paper, we\npropose DiffDenoise, a powerful self-supervised denoising approach tailored for\nmedical images, designed to preserve high-frequency details. Our approach\ncomprises three stages. First, we train a diffusion model on noisy images,\nusing the outputs of a pretrained Blind-Spot Network as conditioning inputs.\nNext, we introduce a novel stabilized reverse sampling technique, which\ngenerates clean images by averaging diffusion sampling outputs initialized with\na pair of symmetric noises. Finally, we train a supervised denoising network\nusing noisy images paired with the denoised outputs generated by the diffusion\nmodel. Our results demonstrate that DiffDenoise outperforms existing\nstate-of-the-art methods in both synthetic and real-world medical image\ndenoising tasks. We provide both a theoretical foundation and practical\ninsights, demonstrating the method's effectiveness across various medical\nimaging modalities and anatomical structures.", "published": "2025-03-31 22:15:53", "link": "http://arxiv.org/abs/2504.00264v1", "categories": ["eess.IV", "cs.CV", "stat.ML"], "primary_category": "eess.IV"}
{"title": "Nuclear Microreactor Control with Deep Reinforcement Learning", "abstract": "The economic feasibility of nuclear microreactors will depend on minimizing\noperating costs through advancements in autonomous control, especially when\nthese microreactors are operating alongside other types of energy systems\n(e.g., renewable energy). This study explores the application of deep\nreinforcement learning (RL) for real-time drum control in microreactors,\nexploring performance in regard to load-following scenarios. By leveraging a\npoint kinetics model with thermal and xenon feedback, we first establish a\nbaseline using a single-output RL agent, then compare it against a traditional\nproportional-integral-derivative (PID) controller. This study demonstrates that\nRL controllers, including both single- and multi-agent RL (MARL) frameworks,\ncan achieve similar or even superior load-following performance as traditional\nPID control across a range of load-following scenarios. In short transients,\nthe RL agent was able to reduce the tracking error rate in comparison to PID.\nOver extended 300-minute load-following scenarios in which xenon feedback\nbecomes a dominant factor, PID maintained better accuracy, but RL still\nremained within a 1% error margin despite being trained only on short-duration\nscenarios. This highlights RL's strong ability to generalize and extrapolate to\nlonger, more complex transients, affording substantial reductions in training\ncosts and reduced overfitting. Furthermore, when control was extended to\nmultiple drums, MARL enabled independent drum control as well as maintained\nreactor symmetry constraints without sacrificing performance -- an objective\nthat standard single-agent RL could not learn. We also found that, as\nincreasing levels of Gaussian noise were added to the power measurements, the\nRL controllers were able to maintain lower error rates than PID, and to do so\nwith less control effort.", "published": "2025-03-31 19:11:19", "link": "http://arxiv.org/abs/2504.00156v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "stat.ML"], "primary_category": "eess.SY"}
{"title": "NoProp: Training Neural Networks without Back-propagation or Forward-propagation", "abstract": "The canonical deep learning approach for learning requires computing a\ngradient term at each layer by back-propagating the error signal from the\noutput towards each learnable parameter. Given the stacked structure of neural\nnetworks, where each layer builds on the representation of the layer below,\nthis approach leads to hierarchical representations. More abstract features\nlive on the top layers of the model, while features on lower layers are\nexpected to be less abstract. In contrast to this, we introduce a new learning\nmethod named NoProp, which does not rely on either forward or backwards\npropagation. Instead, NoProp takes inspiration from diffusion and flow matching\nmethods, where each layer independently learns to denoise a noisy target. We\nbelieve this work takes a first step towards introducing a new family of\ngradient-free learning methods, that does not learn hierarchical\nrepresentations -- at least not in the usual sense. NoProp needs to fix the\nrepresentation at each layer beforehand to a noised version of the target,\nlearning a local denoising process that can then be exploited at inference. We\ndemonstrate the effectiveness of our method on MNIST, CIFAR-10, and CIFAR-100\nimage classification benchmarks. Our results show that NoProp is a viable\nlearning algorithm which achieves superior accuracy, is easier to use and\ncomputationally more efficient compared to other existing back-propagation-free\nmethods. By departing from the traditional gradient based learning paradigm,\nNoProp alters how credit assignment is done within the network, enabling more\nefficient distributed learning as well as potentially impacting other\ncharacteristics of the learning process.", "published": "2025-03-31 17:08:57", "link": "http://arxiv.org/abs/2503.24322v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Solving the Best Subset Selection Problem via Suboptimal Algorithms", "abstract": "Best subset selection in linear regression is well known to be nonconvex and\ncomputationally challenging to solve, as the number of possible subsets grows\nrapidly with increasing dimensionality of the problem. As a result, finding the\nglobal optimal solution via an exact optimization method for a problem with\ndimensions of 1000s may take an impractical amount of CPU time. This suggests\nthe importance of finding suboptimal procedures that can provide good\napproximate solutions using much less computational effort than exact methods.\nIn this work, we introduce a new procedure and compare it with other popular\nsuboptimal algorithms to solve the best subset selection problem. Extensive\ncomputational experiments using synthetic and real data have been performed.\nThe results provide insights into the performance of these methods in different\ndata settings. The new procedure is observed to be a competitive suboptimal\nalgorithm for solving the best subset selection problem for high-dimensional\ndata.", "published": "2025-03-31 16:43:33", "link": "http://arxiv.org/abs/2503.24300v1", "categories": ["stat.ML", "cs.LG", "90C59, 65K05"], "primary_category": "stat.ML"}
{"title": "Wasserstein KL-divergence for Gaussian distributions", "abstract": "We introduce a new version of the KL-divergence for Gaussian distributions\nwhich is based on Wasserstein geometry and referred to as WKL-divergence. We\nshow that this version is consistent with the geometry of the sample space\n${\\Bbb R}^n$. In particular, we can evaluate the WKL-divergence of the Dirac\nmeasures concentrated in two points which turns out to be proportional to the\nsquared distance between these points.", "published": "2025-03-31 12:49:01", "link": "http://arxiv.org/abs/2503.24022v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "AutoML Algorithms for Online Generalized Additive Model Selection: Application to Electricity Demand Forecasting", "abstract": "Electricity demand forecasting is key to ensuring that supply meets demand\nlest the grid would blackout. Reliable short-term forecasts may be obtained by\ncombining a Generalized Additive Models (GAM) with a State-Space model (Obst et\nal., 2021), leading to an adaptive (or online) model. A GAM is an\nover-parameterized linear model defined by a formula and a state-space model\ninvolves hyperparameters. Both the formula and adaptation parameters have to be\nfixed before model training and have a huge impact on the model's predictive\nperformance. We propose optimizing them using the DRAGON package of Keisler\n(2025), originally designed for neural architecture search. This work\ngeneralizes it for automated online generalized additive model selection by\ndefining an efficient modeling of the search space (namely, the space of the\nGAM formulae and adaptation parameters). Its application to short-term French\nelectricity demand forecasting demonstrates the relevance of the approach", "published": "2025-03-31 12:46:33", "link": "http://arxiv.org/abs/2503.24019v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "ModelRadar: Aspect-based Forecast Evaluation", "abstract": "Accurate evaluation of forecasting models is essential for ensuring reliable\npredictions. Current practices for evaluating and comparing forecasting models\nfocus on summarising performance into a single score, using metrics such as\nSMAPE. While convenient, averaging performance over all samples dilutes\nrelevant information about model behavior under varying conditions. This\nlimitation is especially problematic for time series forecasting, where\nmultiple layers of averaging--across time steps, horizons, and multiple time\nseries in a dataset--can mask relevant performance variations. We address this\nlimitation by proposing ModelRadar, a framework for evaluating univariate time\nseries forecasting models across multiple aspects, such as stationarity,\npresence of anomalies, or forecasting horizons. We demonstrate the advantages\nof this framework by comparing 24 forecasting methods, including classical\napproaches and different machine learning algorithms. NHITS, a state-of-the-art\nneural network architecture, performs best overall but its superiority varies\nwith forecasting conditions. For instance, concerning the forecasting horizon,\nwe found that NHITS (and also other neural networks) only outperforms classical\napproaches for multi-step ahead forecasting. Another relevant insight is that\nclassical approaches such as ETS or Theta are notably more robust in the\npresence of anomalies. These and other findings highlight the importance of\naspect-based model evaluation for both practitioners and researchers.\nModelRadar is available as a Python package.", "published": "2025-03-31 11:50:45", "link": "http://arxiv.org/abs/2504.00059v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The more the merrier: logical and multistage processors in credit scoring", "abstract": "Machine Learning algorithms are ubiquitous in key decision-making contexts\nsuch as organizational justice or healthcare, which has spawned a great demand\nfor fairness in these procedures. In this paper we focus on the application of\nfair ML in finance, more concretely on the use of fairness techniques on credit\nscoring. This paper makes two contributions. On the one hand, it addresses the\nexistent gap concerning the application of established methods in the\nliterature to the case of multiple sensitive variables through the use of a new\ntechnique called logical processors (LP). On the other hand, it also explores\nthe novel method of multistage processors (MP) to investigate whether the\ncombination of fairness methods can work synergistically to produce solutions\nwith improved fairness or accuracy. Furthermore, we examine the intersection of\nthese two lines of research by exploring the integration of fairness methods in\nthe multivariate case. The results are very promising and suggest that logical\nprocessors are an appropriate way of handling multiple sensitive variables.\nFurthermore, multistage processors are capable of improving the performance of\nexisting methods.", "published": "2025-03-31 11:44:17", "link": "http://arxiv.org/abs/2503.23979v1", "categories": ["stat.ML", "cs.LG", "68T05, 91D30, 68T37"], "primary_category": "stat.ML"}
{"title": "Detecting Localized Density Anomalies in Multivariate Data via Coin-Flip Statistics", "abstract": "Detecting localized density differences in multivariate data is a crucial\ntask in computational science. Such anomalies can indicate a critical system\nfailure, lead to a groundbreaking scientific discovery, or reveal unexpected\nchanges in data distribution. We introduce EagleEye, an anomaly detection\nmethod to compare two multivariate datasets with the aim of identifying local\ndensity anomalies, namely over- or under-densities affecting only localised\nregions of the feature space. Anomalies are detected by modelling, for each\npoint, the ordered sequence of its neighbours' membership label as a\ncoin-flipping process and monitoring deviations from the expected behaviour of\nsuch process. A unique advantage of our method is its ability to provide an\naccurate, entirely unsupervised estimate of the local signal purity. We\ndemonstrate its effectiveness through experiments on both synthetic and\nreal-world datasets. In synthetic data, EagleEye accurately detects anomalies\nin multiple dimensions even when they affect a tiny fraction of the data. When\napplied to a challenging resonant anomaly detection benchmark task in simulated\nLarge Hadron Collider data, EagleEye successfully identifies particle decay\nevents present in just 0.3% of the dataset. In global temperature data,\nEagleEye uncovers previously unidentified, geographically localised changes in\ntemperature fields that occurred in the most recent years. Thanks to its key\nadvantages of conceptual simplicity, computational efficiency, trivial\nparallelisation, and scalability, EagleEye is widely applicable across many\nfields.", "published": "2025-03-31 10:20:04", "link": "http://arxiv.org/abs/2503.23927v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions", "abstract": "Deep neural networks learn structured features from complex, non-Gaussian\ninputs, but the mechanisms behind this process remain poorly understood. Our\nwork is motivated by the observation that the first-layer filters learnt by\ndeep convolutional neural networks from natural images resemble those learnt by\nindependent component analysis (ICA), a simple unsupervised method that seeks\nthe most non-Gaussian projections of its inputs. This similarity suggests that\nICA provides a simple, yet principled model for studying feature learning.\nHere, we leverage this connection to investigate the interplay between data\nstructure and optimisation in feature learning for the most popular ICA\nalgorithm, FastICA, and stochastic gradient descent (SGD), which is used to\ntrain deep networks. We rigorously establish that FastICA requires at least\n$n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from\n$d$-dimensional inputs on a simple synthetic data model. We show that vanilla\nonline SGD outperforms FastICA, and prove that the optimal sample complexity $n\n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent\nway. We finally demonstrate the existence of a search phase for FastICA on\nImageNet, and discuss how the strong non-Gaussianity of said images compensates\nfor the poor sample complexity of FastICA.", "published": "2025-03-31 09:46:47", "link": "http://arxiv.org/abs/2503.23896v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "An extrapolated and provably convergent algorithm for nonlinear matrix decomposition with the ReLU function", "abstract": "Nonlinear matrix decomposition (NMD) with the ReLU function, denoted\nReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ and\na factorization rank $r$, identify a rank-$r$ matrix $\\Theta$ such that\n$X\\approx \\max(0,\\Theta)$. This decomposition finds application in data\ncompression, matrix completion with entries missing not at random, and manifold\nlearning. The standard ReLU-NMD model minimizes the least squares error, that\nis, $\\|X - \\max(0,\\Theta)\\|_F^2$. The corresponding optimization problem is\nnondifferentiable and highly nonconvex. This motivated Saul to propose an\nalternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introduced\nand satisfies $\\max(0,Z)=X$ while minimizing $\\|Z - \\Theta\\|_F^2$ (``A\nnonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\nMath. Data Sci., 2022). Our first contribution is to show that the two\nformulations may yield different low-rank solutions $\\Theta$; in particular, we\nshow that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning that\nthere are instances in which the infimum of Latent-ReLU-NMD is not attained\nwhile that of ReLU-NMD is. We also consider another alternative model, called\n3B-ReLU-NMD, which parameterizes $\\Theta=WH$, where $W$ has $r$ columns and $H$\nhas $r$ rows, allowing one to get rid of the rank constraint in\nLatent-ReLU-NMD. Our second contribution is to prove the convergence of a block\ncoordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Our\nthird contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD,\nwhich we prove is also convergent under mild assumptions. We illustrate the\nsignificant acceleration effect of eBCD-NMD compared to BCD-NMD, and also show\nthat eBCD-NMD performs well against the state of the art on synthetic and\nreal-world data sets.", "published": "2025-03-31 08:27:41", "link": "http://arxiv.org/abs/2503.23832v1", "categories": ["cs.LG", "eess.IV", "math.OC", "stat.ML", "15A23, 65F55, 68Q25, 90C26, 65K05"], "primary_category": "cs.LG"}
{"title": "Steering Large Agent Populations using Mean-Field Schrodinger Bridges with Gaussian Mixture Models", "abstract": "The Mean-Field Schrodinger Bridge (MFSB) problem is an optimization problem\naiming to find the minimum effort control policy to drive a McKean-Vlassov\nstochastic differential equation from one probability measure to another. In\nthe context of multiagent control, the objective is to control the\nconfiguration of a swarm of identical, interacting cooperative agents, as\ncaptured by the time-varying probability measure of their state. Available\nmethods for solving this problem for distributions with continuous support rely\neither on spatial discretizations of the problem's domain or on approximating\noptimal solutions using neural networks trained through stochastic optimization\nschemes. For agents following Linear Time-Varying dynamics, and for Gaussian\nMixture Model boundary distributions, we propose a highly efficient\nparameterization to approximate the solutions of the corresponding MFSB in\nclosed form, without any learning steps. Our proposed approach consists of a\nmixture of elementary policies, each solving a Gaussian-to-Gaussian Covariance\nSteering problem from the components of the initial to the components of the\nterminal mixture. Leveraging the semidefinite formulation of the Covariance\nSteering problem, our proposed solver can handle probabilistic hard constraints\non the system's state, while maintaining numerical tractability. We illustrate\nour approach on a variety of numerical examples.", "published": "2025-03-31 04:01:04", "link": "http://arxiv.org/abs/2503.23705v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scalable Geometric Learning with Correlation-Based Functional Brain Networks", "abstract": "The correlation matrix is a central representation of functional brain\nnetworks in neuroimaging. Traditional analyses often treat pairwise\ninteractions independently in a Euclidean setting, overlooking the intrinsic\ngeometry of correlation matrices. While earlier attempts have embraced the\nquotient geometry of the correlation manifold, they remain limited by\ncomputational inefficiency and numerical instability, particularly in\nhigh-dimensional contexts. This paper presents a novel geometric framework that\nemploys diffeomorphic transformations to embed correlation matrices into a\nEuclidean space, preserving salient manifold properties and enabling\nlarge-scale analyses. The proposed method integrates with established learning\nalgorithms - regression, dimensionality reduction, and clustering - and extends\nnaturally to population-level inference of brain networks. Simulation studies\ndemonstrate both improved computational speed and enhanced accuracy compared to\nconventional manifold-based approaches. Moreover, applications in real\nneuroimaging scenarios illustrate the framework's utility, enhancing behavior\nscore prediction, subject fingerprinting in resting-state fMRI, and hypothesis\ntesting in electroencephalogram data. An open-source MATLAB toolbox is provided\nto facilitate broader adoption and advance the application of correlation\ngeometry in functional brain network research.", "published": "2025-03-31 01:35:50", "link": "http://arxiv.org/abs/2503.23653v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning a Single Index Model from Anisotropic Data with vanilla Stochastic Gradient Descent", "abstract": "We investigate the problem of learning a Single Index Model (SIM)- a popular\nmodel for studying the ability of neural networks to learn features - from\nanisotropic Gaussian inputs by training a neuron using vanilla Stochastic\nGradient Descent (SGD). While the isotropic case has been extensively studied,\nthe anisotropic case has received less attention and the impact of the\ncovariance matrix on the learning dynamics remains unclear. For instance,\nMousavi-Hosseini et al. (2023b) proposed a spherical SGD that requires a\nseparate estimation of the data covariance matrix, thereby oversimplifying the\ninfluence of covariance. In this study, we analyze the learning dynamics of\nvanilla SGD under the SIM with anisotropic input data, demonstrating that\nvanilla SGD automatically adapts to the data's covariance structure. Leveraging\nthese results, we derive upper and lower bounds on the sample complexity using\na notion of effective dimension that is determined by the structure of the\ncovariance matrix instead of the input data dimension.", "published": "2025-03-31 01:07:30", "link": "http://arxiv.org/abs/2503.23642v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Exploring In-Context Learning Capabilities of ChatGPT for Pathological Speech Detection", "abstract": "Automatic pathological speech detection approaches have shown promising\nresults, gaining attention as potential diagnostic tools alongside costly\ntraditional methods. While these approaches can achieve high accuracy, their\nlack of interpretability limits their applicability in clinical practice. In\nthis paper, we investigate the use of multimodal Large Language Models (LLMs),\nspecifically ChatGPT-4o, for automatic pathological speech detection in a\nfew-shot in-context learning setting. Experimental results show that this\napproach not only delivers promising performance but also provides explanations\nfor its decisions, enhancing model interpretability. To further understand its\neffectiveness, we conduct an ablation study to analyze the impact of different\nfactors, such as input type and system prompts, on the final results. Our\nfindings highlight the potential of multimodal LLMs for further exploration and\nadvancement in automatic pathological speech detection.", "published": "2025-03-31 09:23:52", "link": "http://arxiv.org/abs/2503.23873v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Aud-Sur: An Audio Analyzer Assistant for Audio Surveillance Applications", "abstract": "In this paper, we present an audio analyzer assistant tool designed for a\nwide range of audio-based surveillance applications (This work is a part of our\nDEFAME FAKES and EUCINF projects). The proposed tool, refered to as Aud-Sur,\ncomprises two main phases Audio Analysis and Audio Retrieval, respectively. In\nthe first phase, multiple open-source audio models are leveraged to extract\ninformation from input audio recording uploaded by a user. In the second phase,\nusers interact with the Aud-Sur tool via a natural question-and-answer manner,\npowered by a large language model (LLM), to retrieve the information extracted\nfrom the processed audio file. The Aud-Sur tool was deployed using Docker on a\nmicroservices-based architecture design. By leveraging open-source audio models\nfor information extraction, LLM for audio information retrieval, and a\nmicroservices-based deployment approach, the proposed Aud-Sur tool offers a\nhighly extensible and adaptable framework that can integrate more audio tasks,\nand be widely shared within the audio community for further development.", "published": "2025-03-31 08:21:11", "link": "http://arxiv.org/abs/2503.23827v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UniSep: Universal Target Audio Separation with Language Models at Scale", "abstract": "We propose Universal target audio Separation (UniSep), addressing the\nseparation task on arbitrary mixtures of different types of audio.\nDistinguished from previous studies, UniSep is performed on unlimited source\ndomains and unlimited source numbers. We formulate the separation task as a\nsequence-to-sequence problem, and a large language model (LLM) is used to model\nthe audio sequence in the discrete latent space, leveraging the power of LLM in\nhandling complex mixture audios with large-scale data. Moreover, a novel\npre-training strategy is proposed to utilize audio-only data, which reduces the\nefforts of large-scale data simulation and enhances the ability of LLMs to\nunderstand the consistency and correlation of information within audio\nsequences. We also demonstrate the effectiveness of scaling datasets in an\naudio separation task: we use large-scale data (36.5k hours), including speech,\nmusic, and sound, to train a universal target audio separation model that is\nnot limited to a specific domain. Experiments show that UniSep achieves\ncompetitive subjective and objective evaluation results compared with\nsingle-task models.", "published": "2025-03-31 06:27:37", "link": "http://arxiv.org/abs/2503.23762v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exact local recovery for Chemical Shift Imaging", "abstract": "Chemical Shift Imaging (CSI) or Chemical Shift Encoded Magnetic Resonance\nImaging (CSE-MRI) enables the quantification of different chemical species in\nthe human body, and it is one of the most widely used imaging modalities used\nto quantify fat in the human body. Although there have been substantial\nimprovements in the design of signal acquisition protocols and the development\nof a variety of methods for the recovery of parameters of interest from the\nmeasured signal, it is still challenging to obtain a consistent and reliable\nquantification over the entire field of view. In fact, there are still\ndiscrepancies in the quantities recovered by different methods, and each\nexhibits a different degree of sensitivity to acquisition parameters such as\nthe choice of echo times.\n  Some of these challenges have their origin in the signal model itself. In\nparticular, it is non-linear, and there may be different sets of parameters of\ninterest compatible with the measured signal. For this reason, a thorough\nanalysis of this model may help mitigate some of the remaining challenges, and\nyield insight into novel acquisition protocols. In this work, we perform an\nanalysis of the signal model underlying CSI, focusing on finding suitable\nconditions under which recovery of the parameters of interest is possible. We\ndetermine the sources of non-identifiability of the parameters, and we propose\na reconstruction method based on smooth non-convex optimization under convex\nconstraints that achieves exact local recovery under suitable conditions. A\nsurprising result is that the concentrations of the chemical species in the\nsample may be identifiable even when other parameters are not. We present\nnumerical results illustrating how our theoretical results may help develop\nnovel acquisition techniques, and showing how our proposed recovery method\nyields results comparable to the state-of-the-art.", "published": "2025-03-31 19:32:28", "link": "http://arxiv.org/abs/2504.00175v1", "categories": ["eess.SP", "eess.IV"], "primary_category": "eess.SP"}
{"title": "Impact of Synchronization Offsets and CSI Feedback Delay in Distributed MIMO Systems", "abstract": "The main challenges of distributed MIMO systems lie in achieving highly\naccurate synchronization and ensuring the availability of accurate channel\nstate information (CSI) at distributed nodes. This paper analytically examines\nthe effects of synchronization offsets and CSI feedback delays on system\ncapacity, providing insights into how these affect the coherent joint\ntransmission gain. The capacity expressions are first derived under ideal\nconditions, and the effects of synchronization offsets and feedback delays are\nsubsequently incorporated. This analysis can be applied to any distributed MIMO\narchitecture. A comprehensive study, including system models and simulations\nevaluating the analytical expressions, is presented to quantify the capacity\ndegradation caused by these factors. This study provides valuable insights into\nthe design and performance of distributed MIMO systems. The analysis shows that\ntime and frequency offsets, along with CSI feedback delay, cause inter-layer\ninterference. Additionally, time offsets result in inter-symbol interference.", "published": "2025-03-31 17:02:33", "link": "http://arxiv.org/abs/2503.24314v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "1-Tb/s/\u03bb Transmission over Record 10714-km AR-HCF", "abstract": "We present the first single-channel 1.001-Tb/s DP-36QAM-PCS recirculating\ntransmission over 73 loops of 146.77-km ultra-low-loss & low-IMI DNANF-5 fiber,\nachieving a record transmission distance of 10,714.28 km.", "published": "2025-03-31 17:01:01", "link": "http://arxiv.org/abs/2503.24313v2", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Deep Learning-Based Data Fusion of 6G Sensing and Inertial Information for Target Positioning: Experimental Validation", "abstract": "The sixth-generation (6G) cellular technology will be deployed with a key\nfeature of Integrated Sensing and Communication (ISAC), allowing the cellular\nnetwork to map the environment through radar sensing on top of providing\ncommunication services. In this regard, the entire network can be considered as\na sensor with a broader Field of View (FoV) of the environment, assisting in\nboth the positioning of active and detection of passive targets. On the other\nhand, the non-3GPP sensors available on the target can provide additional\ninformation specific to the target that can be beneficially combined with ISAC\nsensing information to enhance the overall achievable positioning accuracy. In\nthis paper, we first study the performance of the ISAC system in terms of its\nachievable accuracy in positioning the mobile target in an indoor scenario.\nSecond, we study the performance gain achieved in the ISAC positioning accuracy\nafter fusing the information from the target's non-3GPP sensors. To this end,\nwe propose a novel data fusion solution based on the deep learning framework to\nfuse the information from ISAC and non-3GPP sensors.\n  We validate our proposed data fusion and positioning solution with a\nreal-world ISAC Proof-of-Concept (PoC) as the wireless infrastructure, an\nAutomated Guided Vehicle (AGV) as the target, and the Inertial Measurement Unit\n(IMU) sensor on the target as the non-3GPP sensor. The experimental results\nshow that our proposed solution achieves an average positioning error of\n$3~\\textrm{cm}$, outperforming the considered baselines.", "published": "2025-03-31 16:02:17", "link": "http://arxiv.org/abs/2503.24253v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reinforcing Localization Credibility Through Convex Optimization", "abstract": "This work proposes a novel approach to reinforce localization security in\nwireless networks in the presence of malicious nodes that are able to\nmanipulate (spoof) radio measurements. It substitutes the original measurement\nmodel by another one containing an auxiliary variance dilation parameter that\ndisguises corrupted radio links into ones with large noise variances. This\nallows for relaxing the non-convex maximum likelihood estimator (MLE) into a\nsemidefinite programming (SDP) problem by applying convex-concave programming\n(CCP) procedure. The proposed SDP solution simultaneously outputs target\nlocation and attacker detection estimates, eliminating the need for further\napplication of sophisticated detectors. Numerical results corroborate excellent\nperformance of the proposed method in terms of localization accuracy and show\nthat its detection rates are highly competitive with the state of the art.", "published": "2025-03-31 14:40:08", "link": "http://arxiv.org/abs/2503.24156v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Net 3.2 Tbps 225 Gbaud PAM4 O-Band IM/DD 2 km Transmission Using FR8 and DR8 with a CMOS 3 nm SerDes and TFLN Modulators", "abstract": "We report the first 3.2 and 4.2 Tbps (8 x 225Gbaud PAM4-8), IM/DD\ntransmission system using FR8 and DR8 configurations with TFLN modulators\ndriven by a 3nm SerDes under the HD-FEC threshold.", "published": "2025-03-31 14:33:17", "link": "http://arxiv.org/abs/2503.24147v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "When More Is Less: Higher Magnetic Fields and Their Limited Impact on SNR per Time Unit of Acquisition Time in Single Voxel Spectroscopy", "abstract": "Magnetic resonance spectroscopy (MRS) offers significant diagnostic potential\nbut is inherently constrained by low signal-to-noise ratio (SNR). While\nincreasing the main magnetic field strength B_0 is theoretically linked to\nincreased SNR, practically obtained gains in SNR from B07/4 to B0 depending on\nthe domination of thermal noise at high B0, are not always realized. Especially\nin clinical settings the maximum reachable SNR is further constrained by the\ntotal available acquisition time (TA) and the regulatory limits on maximum\ntolerable specific absorption rate (SAR). This work attempts to derive\nmathematical expressions that enable systematical analysis of the theoretical\nachievable SNR-gain. One important notion is this context is the SNR gain per\nunit of measurement time as a function of the main magnetic field B0 strengths\nin the case of single voxel spectroscopy (SVS) pulse sequences. Our findings\nindicate that under given fixed total amount of (patient acceptable)\nmeasurement time TA, and maximum tolerable SAR limitation, together with\nconditions that ensure the adiabaticity of specific sequences, further\nincreasing B0 does not further improve SNR per unit of measurement time. Key\nfactors were identified, including RF-pulse bandwidth scaling with B0 and\nlongitudinal relaxation time (T1) dependencies, impact the net gain as well.\nOur theoretical analysis emphasizes critical considerations for optimizing SNR\nper unit time in clinical MRS, even challenging the presumption that higher\nmagnetic fields B0 always yield improved SNR per time unit of measurement time\nperformance.", "published": "2025-03-31 14:24:57", "link": "http://arxiv.org/abs/2504.03728v1", "categories": ["eess.SP", "physics.med-ph"], "primary_category": "eess.SP"}
{"title": "Graph Transformer-Based Flood Susceptibility Mapping: Application to the French Riviera and Railway Infrastructure Under Climate Change", "abstract": "Increasing flood frequency and severity due to climate change threatens\ninfrastructure and demands improved susceptibility mapping techniques. While\ntraditional machine learning (ML) approaches are widely used, they struggle to\ncapture spatial dependencies and poor boundary delineation between\nsusceptibility classes. This study introduces the first application of a graph\ntransformer (GT) architecture for flood susceptibility mapping to the\nflood-prone French Riviera (e.g., 2020 Storm Alex) using topography, hydrology,\ngeography, and environmental data. GT incorporates watershed topology using\nLaplacian positional encoders (PEs) and attention mechanisms. The developed GT\nmodel has an AUC-ROC (0.9739), slightly lower than XGBoost (0.9853). However,\nthe GT model demonstrated better clustering and delineation with a higher\nMoran's I value (0.6119) compared to the random forest (0.5775) and XGBoost\n(0.5311) with p-value lower than 0.0001. Feature importance revealed a striking\nconsistency across models, with elevation, slope, distance to channel, and\nconvergence index being the critical factors. Dimensionality reduction on\nLaplacian PEs revealed partial clusters, indicating they could capture spatial\ninformation; however, their importance was lower than flood factors. Since\nclimate and land use changes aggravate flood risk, susceptibility maps are\ndeveloped for the 2050 year under different Representative Concentration\nPathways (RCPs) and railway track vulnerability is assessed. All RCP scenarios\nrevealed increased area across susceptibility classes, except for the very low\ncategory. RCP 8.5 projections indicate that 17.46% of the watershed area and\n54% of railway length fall within very-high susceptible zones, compared to\n6.19% and 35.61%, respectively, under current conditions. The developed maps\ncan be integrated into a multi-hazard framework.", "published": "2025-03-31 14:04:04", "link": "http://arxiv.org/abs/2504.03727v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Active Reconfigurable Intelligent Surfaces: Circuit Modeling and Reflection Amplification Optimization", "abstract": "Reconfigurable Intelligent Surfaces (RISs) constitute a promising emerging\ntechnology that enables wireless systems to control the propagation environment\nto enhance diverse communication objectives. To mitigate double-fading\nattenuation in RIS-aided links, the paradigm of active metamaterials capable of\namplifying their incident wave has emerged. In this paper, capitalizing on the\ninherent negative-resistance region of tunnel diodes, we propose their\nintegration into each RIS unit element to enable RISs with reflection\namplification entirely in the analog domain. We derive novel realistic\nphase-amplitude relationships and power constraints specific to this model,\naddressing gaps in the existing literature where amplitude limits are often\nchosen arbitrarily. This characterization of our active RIS unit elements is\nincorporated into two novel optimization frameworks targeting the spectral\nefficiency maximization of RIS-assisted Multiple-Input-Multiple-Output (MIMO)\nsystems, which are solved via an one-step approach and an iterative Alternating\nOptimization (AO) method. The former approach is used to initialize the AO\nframework, enhancing both its performance and convergence. Our numerical\ninvestigations emphasize the importance of accurately modeling phase-amplitude\ndependencies, and provide key insights into the impact of RIS-induced noise as\nwell as the trade-off between available power and the number of active\nelements.", "published": "2025-03-31 13:44:03", "link": "http://arxiv.org/abs/2503.24093v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Simple BER Expression for FSO Systems with Weak Turbulence and Pointing Errors", "abstract": "We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.", "published": "2025-03-31 12:27:24", "link": "http://arxiv.org/abs/2503.24002v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reliable Traffic Monitoring Using Low-Cost Doppler Radar Units", "abstract": "Road traffic monitoring typically involves the counting and recording of\nvehicles on public roads over extended periods. The data gathered from such\nmonitoring provides useful information to municipal authorities in urban areas.\nThis paper presents a low-cost, widely deployable sensing subsystem based on\nContinuous Wave Doppler radar. The proposed system can perform vehicle\ndetection and speed estimation with a total cost of less than 100 USD. The\nsensing system (including the hardware subsystem and the algorithms) is\ndesigned to be placed on the side of the road, allowing for easy deployment and\nserviceability.", "published": "2025-03-31 10:18:42", "link": "http://arxiv.org/abs/2503.23926v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Robust Suboptimal Local Basis Function Algorithms for Identification of Nonstationary FIR Systems in Impulsive Noise Environments", "abstract": "While local basis function (LBF) estimation algorithms, commonly used for\nidentifying/tracking systems with time-varying parameters, demonstrate good\nperformance under the assumption of normally distributed measurement noise, the\nestimation results may significantly deviate from satisfactory when the noise\ndistribution is impulsive in nature, for example, corrupted by outliers. This\npaper introduces a computationally efficient method to make the LBF estimator\nrobust, enhancing its resistance to impulsive noise. First, the choice of basis\nfunctions is optimized based on the knowledge of parameter variation\nstatistics. Then, the parameter tracking algorithm is made robust using the\nsequential data trimming technique. Finally, it is demonstrated that the\nproposed algorithm can undergo online tuning through parallel estimation and\nleave-one-out cross-validation.", "published": "2025-03-31 09:37:58", "link": "http://arxiv.org/abs/2503.23885v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Algorithm Design and Prototype Validation for Reconfigurable Intelligent Sensing Surface: Forward-Only Transmission", "abstract": "Sensing-assisted communication schemes have recently garnered significant\nresearch attention. In this work, we design a dual-function reconfigurable\nintelligent surface (RIS), integrating both active and passive elements,\nreferred to as the reconfigurable intelligent sensing surface (RISS), to\nenhance communication. By leveraging sensing results from the active elements,\nwe propose communication enhancement and robust interference suppression\nschemes for both near-field and far-field models, implemented through the\npassive elements. These schemes remove the need for base station (BS) feedback\nfor RISS control, simplifying the communication process by replacing\ntraditional channel state information (CSI) feedback with real-time sensing\nfrom the active elements. The proposed schemes are theoretically analyzed and\nthen validated using software-defined radio (SDR). Experimental results\ndemonstrate the effectiveness of the sensing algorithms in real-world\nscenarios, such as direction of arrival (DOA) estimation and radio frequency\n(RF) identification recognition. Moreover, the RISS-assisted communication\nsystem shows strong performance in communication enhancement and interference\nsuppression, particularly in near-field models.", "published": "2025-03-31 09:36:15", "link": "http://arxiv.org/abs/2503.23883v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Adaptive Attention-Based Model for 5G Radio-based Outdoor Localization", "abstract": "Radio-based localization in dynamic environments, such as urban and vehicular\nsettings, requires systems that can efficiently adapt to varying signal\nconditions and environmental changes. Factors such as multipath interference\nand obstructions introduce different levels of complexity that affect the\naccuracy of the localization. Although generalized models offer broad\napplicability, they often struggle to capture the nuances of specific\nenvironments, leading to suboptimal performance in real-world deployments. In\ncontrast, specialized models can be tailored to particular conditions, enabling\nmore precise localization by effectively handling domain-specific variations\nand noise patterns. However, deploying multiple specialized models requires an\nefficient mechanism to select the most appropriate one for a given scenario. In\nthis work, we develop an adaptive localization framework that combines shallow\nattention-based models with a router/switching mechanism based on a\nsingle-layer perceptron (SLP). This enables seamless transitions between\nspecialized localization models optimized for different conditions, balancing\naccuracy, computational efficiency, and robustness to environmental variations.\nWe design three low-complex localization models tailored for distinct\nscenarios, optimized for reduced computational complexity, test time, and model\nsize. The router dynamically selects the most suitable model based on real-time\ninput characteristics. The proposed framework is validated using real-world\nvehicle localization data collected from a massive MIMO base station (BS),\ndemonstrating its ability to seamlessly adapt to diverse deployment conditions\nwhile maintaining high localization accuracy.", "published": "2025-03-31 07:44:14", "link": "http://arxiv.org/abs/2503.23810v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "ANNs-SaDE: A Machine-Learning-Based Design Automation Framework for Microwave Branch-Line Couplers", "abstract": "The traditional method for designing branch-line couplers involves a\ntrial-and-error optimization process that requires multiple design iterations\nthrough electromagnetic (EM) simulations. Thus, it is extremely time consuming\nand labor intensive. In this paper, a novel machine-learning-based framework is\nproposed to tackle this issue. It integrates artificial neural networks with a\nself-adaptive differential evolution algorithm (ANNs-SaDE). This framework\nenables the self-adaptive design of various types of microwave branch-line\ncouplers by precisely optimizing essential electrical properties, such as\ncoupling factor, isolation, and phase difference between output ports. The\neffectiveness of the ANNs-SaDE framework is demonstrated by the designs of\nfolded single-stage branch-line couplers and multi-stage wideband branch-line\ncouplers.", "published": "2025-03-31 06:58:29", "link": "http://arxiv.org/abs/2503.23783v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Semantic Packet Aggregation and Repeated Transmission for Text-to-Image Generation", "abstract": "Text-based communication is expected to be prevalent in 6G applications such\nas wireless AI-generated content (AIGC). Motivated by this, this paper\naddresses the challenges of transmitting text prompts over erasure channels for\na text-to-image AIGC task by developing the semantic segmentation and repeated\ntransmission (SMART) algorithm. SMART groups words in text prompts into\npackets, prioritizing the task-specific significance of semantics within these\npackets, and optimizes the number of repeated transmissions. Simulation results\nshow that SMART achieves higher similarities in received texts and generated\nimages compared to a character-level packetization baseline, while reducing\ncomputing latency by orders of magnitude compared to an exhaustive search\nbaseline.", "published": "2025-03-31 05:14:40", "link": "http://arxiv.org/abs/2503.23734v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Synthetic News Generation for Fake News Classification", "abstract": "This study explores the generation and evaluation of synthetic fake news\nthrough fact based manipulations using large language models (LLMs). We\nintroduce a novel methodology that extracts key facts from real articles,\nmodifies them, and regenerates content to simulate fake news while maintaining\ncoherence. To assess the quality of the generated content, we propose a set of\nevaluation metrics coherence, dissimilarity, and correctness. The research also\ninvestigates the application of synthetic data in fake news classification,\ncomparing traditional machine learning models with transformer based models\nsuch as BERT. Our experiments demonstrate that transformer models, especially\nBERT, effectively leverage synthetic data for fake news detection, showing\nimprovements with smaller proportions of synthetic data. Additionally, we find\nthat fact verification features, which focus on identifying factual\ninconsistencies, provide the most promising results in distinguishing synthetic\nfake news. The study highlights the potential of synthetic data to enhance fake\nnews detection systems, offering valuable insights for future research and\nsuggesting that targeted improvements in synthetic data generation can further\nstrengthen detection models.", "published": "2025-03-31 15:24:05", "link": "http://arxiv.org/abs/2503.24206v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proposed 2MW Wind Turbine for Use in the Governorate of Dhofar at the\n  Sultanate of Oman", "abstract": "In this work, we propose a preliminary design of a horizontal-axis wind\nturbine (HAWT) as a candidate for the Dhofar Wind Farm project, in the southern\nOmani Governorate \"Dhofar\", at the southwest part of the Sultanate of Oman.\nThis wind farm (under construction) is considered to be the first commercial,\nutility-scale (50MW) wind farm in the GCC (Gulf Cooperation Council) area. The\nproposed wind turbine has an expected electricity generation of 2MW. We studied\nthe wind atlas of Oman and from which we determined the maximum possible mean\nwind speed in the entire Sultanate and built our design based on that reference\nvalue, which is 6m/s (21.6km/h). After this, we applied a set of modeling\nequations that estimate the power output from the wind turbine rotor and\nmatched the target electric power to the design variables using a MATLAB\ncomputer code. We reached a suitable design and we present here the\ndistribution of the blade angle (twist angle), and the power per unit span\nalong the rotor blade. The rotor design has 3 blades with a diameter of 70m and\na rotational speed of 24rpm. This rotor gives 2.37MW of output power, which\nexceeds the target 2MW output, allowing for about 15% of power losses in the\ngearbox and generator. We utilized some commercial designs of wind turbines\nfrom different international manufacturers as references for typical limits or\nrecommended values of some design parameters.", "published": "2025-03-31 20:21:31", "link": "http://arxiv.org/abs/2504.07126v1", "categories": ["cs.CE", "cs.CL", "65D30, 65-04, 76G25", "D.3.0; G.1.4; G.1.10; J.2; J.6"], "primary_category": "cs.CE"}
{"title": "ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent\n  Diffusion", "abstract": "Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.", "published": "2025-03-31 17:34:59", "link": "http://arxiv.org/abs/2503.24354v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Do Chinese models speak Chinese languages?", "abstract": "The release of top-performing open-weight LLMs has cemented China's role as a\nleading force in AI development. Do these models support languages spoken in\nChina? Or do they speak the same languages as Western models? Comparing\nmultilingual capabilities is important for two reasons. First, language ability\nprovides insights into pre-training data curation, and thus into resource\nallocation and development priorities. Second, China has a long history of\nexplicit language policy, varying between inclusivity of minority languages and\na Mandarin-first policy. To test whether Chinese LLMs today reflect an agenda\nabout China's languages, we test performance of Chinese and Western open-source\nLLMs on Asian regional and Chinese minority languages. Our experiments on\nInformation Parity and reading comprehension show Chinese models' performance\nacross these languages correlates strongly (r=0.93) with Western models', with\nthe sole exception being better Mandarin. Sometimes, Chinese models cannot\nidentify languages spoken by Chinese minorities such as Kazakh and Uyghur, even\nthough they are good at French and German. These results provide a window into\ncurrent development priorities, suggest options for future development, and\nindicate guidance for end users.", "published": "2025-03-31 23:19:08", "link": "http://arxiv.org/abs/2504.00289v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
