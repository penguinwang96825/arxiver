{"title": "Logical Semantics and Commonsense Knowledge: Where Did we Go Wrong, and\n  How to Go Forward, Again", "abstract": "We argue that logical semantics might have faltered due to its failure in\ndistinguishing between two fundamentally very different types of concepts:\nontological concepts, that should be types in a strongly-typed ontology, and\nlogical concepts, that are predicates corresponding to properties of and\nrelations between objects of various ontological types. We will then show that\naccounting for these differences amounts to the integration of lexical and\ncompositional semantics in one coherent framework, and to an embedding in our\nlogical semantics of a strongly-typed ontology that reflects our commonsense\nview of the world and the way we talk about it in ordinary language. We will\nshow that in such a framework a number of challenges in natural language\nsemantics can be adequately and systematically treated.", "published": "2018-08-06 06:20:41", "link": "http://arxiv.org/abs/1808.01741v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Using Linguistic Cues for Analyzing Social Movements", "abstract": "With the growth of social media usage, social activists try to leverage this\nplatform to raise the awareness related to a social issue and engage the public\nworldwide. The broad use of social media platforms in recent years, made it\neasier for the people to stay up-to-date on the news related to regional and\nworldwide events. While social media, namely Twitter, assists social movements\nto connect with more people and mobilize the movement, traditional media such\nas news articles help in spreading the news related to the events in a broader\naspect. In this study, we analyze linguistic features and cues, such as\nindividualism vs. pluralism, sentiment and emotion to examine the relationship\nbetween the medium and discourse over time. We conduct this work in a specific\napplication context, the \"Black Lives Matter\" (BLM) movement, and compare\ndiscussions related to this event in social media vs. news articles.", "published": "2018-08-06 06:22:17", "link": "http://arxiv.org/abs/1808.01742v1", "categories": ["cs.CL", "cs.SI", "I.2.7; H.3.1"], "primary_category": "cs.CL"}
{"title": "An Efficient Approach to Learning Chinese Judgment Document Similarity\n  Based on Knowledge Summarization", "abstract": "A previous similar case in common law systems can be used as a reference with\nrespect to the current case such that identical situations can be treated\nsimilarly in every case. However, current approaches for judgment document\nsimilarity computation failed to capture the core semantics of judgment\ndocuments and therefore suffer from lower accuracy and higher computation\ncomplexity. In this paper, a knowledge block summarization based machine\nlearning approach is proposed to compute the semantic similarity of Chinese\njudgment documents. By utilizing domain ontologies for judgment documents, the\ncore semantics of Chinese judgment documents is summarized based on knowledge\nblocks. Then the WMD algorithm is used to calculate the similarity between\nknowledge blocks. At last, the related experiments were made to illustrate that\nour approach is very effective and efficient in achieving higher accuracy and\nfaster computation speed in comparison with the traditional approaches.", "published": "2018-08-06 12:24:19", "link": "http://arxiv.org/abs/1808.01843v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "68T35"], "primary_category": "cs.AI"}
{"title": "Residual Memory Networks: Feed-forward approach to learn long temporal\n  dependencies", "abstract": "Training deep recurrent neural network (RNN) architectures is complicated due\nto the increased network complexity. This disrupts the learning of higher order\nabstracts using deep RNN. In case of feed-forward networks training deep\nstructures is simple and faster while learning long-term temporal information\nis not possible. In this paper we propose a residual memory neural network\n(RMN) architecture to model short-time dependencies using deep feed-forward\nlayers having residual and time delayed connections. The residual connection\npaves way to construct deeper networks by enabling unhindered flow of gradients\nand the time delay units capture temporal information with shared weights. The\nnumber of layers in RMN signifies both the hierarchical processing depth and\ntemporal depth. The computational complexity in training RMN is significantly\nless when compared to deep recurrent networks. RMN is further extended as\nbi-directional RMN (BRMN) to capture both past and future information.\nExperimental analysis is done on AMI corpus to substantiate the capability of\nRMN in learning long-term information and hierarchical information. Recognition\nperformance of RMN trained with 300 hours of Switchboard corpus is compared\nwith various state-of-the-art LVCSR systems. The results indicate that RMN and\nBRMN gains 6 % and 3.8 % relative improvement over LSTM and BLSTM networks.", "published": "2018-08-06 14:00:40", "link": "http://arxiv.org/abs/1808.01916v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Audio Tagging With Connectionist Temporal Classification Model Using\n  Sequential Labelled Data", "abstract": "Audio tagging aims to predict one or several labels in an audio clip. Many\nprevious works use weakly labelled data (WLD) for audio tagging, where only\npresence or absence of sound events is known, but the order of sound events is\nunknown. To use the order information of sound events, we propose sequential\nlabelled data (SLD), where both the presence or absence and the order\ninformation of sound events are known. To utilize SLD in audio tagging, we\npropose a Convolutional Recurrent Neural Network followed by a Connectionist\nTemporal Classification (CRNN-CTC) objective function to map from an audio clip\nspectrogram to SLD. Experiments show that CRNN-CTC obtains an Area Under Curve\n(AUC) score of 0.986 in audio tagging, outperforming the baseline CRNN of 0.908\nand 0.815 with Max Pooling and Average Pooling, respectively. In addition, we\nshow CRNN-CTC has the ability to predict the order of sound events in an audio\nclip.", "published": "2018-08-06 14:40:31", "link": "http://arxiv.org/abs/1808.01935v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Paying Attention to Attention: Highlighting Influential Samples in\n  Sequential Analysis", "abstract": "In (Yang et al. 2016), a hierarchical attention network (HAN) is created for\ndocument classification. The attention layer can be used to visualize text\ninfluential in classifying the document, thereby explaining the model's\nprediction. We successfully applied HAN to a sequential analysis task in the\nform of real-time monitoring of turn taking in conversations. However, we\ndiscovered instances where the attention weights were uniform at the stopping\npoint (indicating all turns were equivalently influential to the classifier),\npreventing meaningful visualization for real-time human review or classifier\nimprovement. We observed that attention weights for turns fluctuated as the\nconversations progressed, indicating turns had varying influence based on\nconversation state. Leveraging this observation, we develop a method to create\nmore informative real-time visuals (as confirmed by human reviewers) in cases\nof uniform attention weights using the changes in turn importance as a\nconversation progresses over time.", "published": "2018-08-06 21:05:55", "link": "http://arxiv.org/abs/1808.02113v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Principles for Developing a Knowledge Graph of Interlinked Events from\n  News Headlines on Twitter", "abstract": "The ever-growing datasets published on Linked Open Data mainly contain\nencyclopedic information. However, there is a lack of quality structured and\nsemantically annotated datasets extracted from unstructured real-time sources.\nIn this paper, we present principles for developing a knowledge graph of\ninterlinked events using the case study of news headlines published on Twitter\nwhich is a real-time and eventful source of fresh information. We represent the\nessential pipeline containing the required tasks ranging from choosing\nbackground data model, event annotation (i.e., event recognition and\nclassification), entity annotation and eventually interlinking events. The\nstate-of-the-art is limited to domain-specific scenarios for recognizing and\nclassifying events, whereas this paper plays the role of a domain-agnostic\nroad-map for developing a knowledge graph of interlinked events.", "published": "2018-08-06 03:04:35", "link": "http://arxiv.org/abs/1808.02022v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
