{"title": "Categorical Metadata Representation for Customized Text Classification", "abstract": "The performance of text classification has improved tremendously using\nintelligently engineered neural-based models, especially those injecting\ncategorical metadata as additional information, e.g., using user/product\ninformation for sentiment classification. These information have been used to\nmodify parts of the model (e.g., word embeddings, attention mechanisms) such\nthat results can be customized according to the metadata. We observe that\ncurrent representation methods for categorical metadata, which are devised for\nhuman consumption, are not as effective as claimed in popular classification\nmethods, outperformed even by simple concatenation of categorical features in\nthe final layer of the sentence encoder. We conjecture that categorical\nfeatures are harder to represent for machine use, as available context only\nindirectly describes the category, and even such context is often scarce (for\ntail category). To this end, we propose to use basis vectors to effectively\nincorporate categorical metadata on various parts of a neural-based model. This\nadditionally decreases the number of parameters dramatically, especially when\nthe number of categorical features is large. Extensive experiments on various\ndatasets with different properties are performed and show that through our\nmethod, we can represent categorical metadata more effectively to customize\nparts of the model, including unexplored ones, and increase the performance of\nthe model greatly.", "published": "2019-02-14 03:07:53", "link": "http://arxiv.org/abs/1902.05196v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transfer Learning for Sequence Labeling Using Source Model and Target\n  Data", "abstract": "In this paper, we propose an approach for transferring the knowledge of a\nneural model for sequence labeling, learned from the source domain, to a new\nmodel trained on a target domain, where new label categories appear. Our\ntransfer learning (TL) techniques enable to adapt the source model using the\ntarget data and new categories, without accessing to the source data. Our\nsolution consists in adding new neurons in the output layer of the target model\nand transferring parameters from the source model, which are then fine-tuned\nwith the target data. Additionally, we propose a neural adapter to learn the\ndifference between the source and the target label distribution, which provides\nadditional important information to the target model. Our experiments on Named\nEntity Recognition show that (i) the learned knowledge in the source model can\nbe effectively transferred when the target data contains new categories and\n(ii) our neural adapter further improves such transfer.", "published": "2019-02-14 11:40:58", "link": "http://arxiv.org/abs/1902.05309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Author Profiling for Hate Speech Detection", "abstract": "The rapid growth of social media in recent years has fed into some highly\nundesirable phenomena such as proliferation of abusive and offensive language\non the Internet. Previous research suggests that such hateful content tends to\ncome from users who share a set of common stereotypes and form communities\naround them. The current state-of-the-art approaches to hate speech detection\nare oblivious to user and community information and rely entirely on textual\n(i.e., lexical and semantic) cues. In this paper, we propose a novel approach\nto this problem that incorporates community-based profiling features of Twitter\nusers. Experimenting with a dataset of 16k tweets, we show that our methods\nsignificantly outperform the current state of the art in hate speech detection.\nFurther, we conduct a qualitative analysis of model characteristics. We release\nour code, pre-trained models and all the resources used in the public domain.", "published": "2019-02-14 20:00:30", "link": "http://arxiv.org/abs/1902.06734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Actions Generation from Captions", "abstract": "Sequence transduction models have been widely explored in many natural\nlanguage processing tasks. However, the target sequence usually consists of\ndiscrete tokens which represent word indices in a given vocabulary. We barely\nsee the case where target sequence is composed of continuous vectors, where\neach vector is an element of a time series taken successively in a temporal\ndomain. In this work, we introduce a new data set, named Action Generation Data\nSet (AGDS) which is specifically designed to carry out the task of\ncaption-to-action generation. This data set contains caption-action pairs. The\ncaption is comprised of a sequence of words describing the interactive movement\nbetween two people, and the action is a captured sequence of poses representing\nthe movement. This data set is introduced to study the ability of generating\ncontinuous sequences through sequence transduction models. We also propose a\nmodel to innovatively combine Multi-Head Attention (MHA) and Generative\nAdversarial Network (GAN) together. In our model, we have one generator to\ngenerate actions from captions and three discriminators where each of them is\ndesigned to carry out a unique functionality: caption-action consistency\ndiscriminator, pose discriminator and pose transition discriminator. This novel\ndesign allowed us to achieve plausible generation performance which is\ndemonstrated in the experiments.", "published": "2019-02-14 04:37:49", "link": "http://arxiv.org/abs/1902.11109v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multimodal music information processing and retrieval: survey and future\n  challenges", "abstract": "Towards improving the performance in various music information processing\ntasks, recent studies exploit different modalities able to capture diverse\naspects of music. Such modalities include audio recordings, symbolic music\nscores, mid-level representations, motion, and gestural data, video recordings,\neditorial or cultural tags, lyrics and album cover arts. This paper critically\nreviews the various approaches adopted in Music Information Processing and\nRetrieval and highlights how multimodal algorithms can help Music Computing\napplications. First, we categorize the related literature based on the\napplication they address. Subsequently, we analyze existing information fusion\napproaches, and we conclude with the set of challenges that Music Information\nRetrieval and Sound and Music Computing research communities should focus in\nthe next years.", "published": "2019-02-14 13:36:01", "link": "http://arxiv.org/abs/1902.05347v1", "categories": ["cs.MM", "cs.IR", "cs.SD", "eess.AS", "H.5.5; H.3.3"], "primary_category": "cs.MM"}
{"title": "Theory-plus-code documentation of the DEPAM workflow for soundscape\n  description", "abstract": "In the Big Data era, the community of PAM faces strong challenges, including\nthe need for more standardized processing tools accross its different\napplications in oceanography, and for more scalable and high-performance\ncomputing systems to process more efficiently the everly growing datasets. In\nthis work we address conjointly both issues by first proposing a detailed\ntheory-plus-code document of a classical analysis workflow to describe the\ncontent of PAM data, which hopefully will be reviewed and adopted by a maximum\nof PAM experts to make it standardized. Second, we transposed this workflow\ninto the Scala language within the Spark/Hadoop frameworks so it can be\ndirectly scaled out on several node cluster.", "published": "2019-02-14 15:45:36", "link": "http://arxiv.org/abs/1902.06659v1", "categories": ["eess.AS", "astro-ph.IM", "cs.SD"], "primary_category": "eess.AS"}
