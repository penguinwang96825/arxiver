{"title": "Construction and Hedging of Equity Index Options Portfolios", "abstract": "This research presents a comprehensive evaluation of systematic index\noption-writing strategies, focusing on S&P500 index options. We compare the\nperformance of hedging strategies using the Black-Scholes-Merton (BSM) model\nand the Variance-Gamma (VG) model, emphasizing varying moneyness levels and\ndifferent sizing methods based on delta and the VIX Index. The study employs\n1-minute data of S&P500 index options and index quotes spanning from 2018 to\n2023. The analysis benchmarks hedged strategies against buy-and-hold and naked\noption-writing strategies, with a focus on risk-adjusted performance metrics\nincluding transaction costs. Portfolio delta approximations are derived using\nimplied volatility for the BSM model and market-calibrated parameters for the\nVG model. Key findings reveal that systematic option-writing strategies can\npotentially yield superior returns compared to buy-and-hold benchmarks. The BSM\nmodel generally provided better hedging outcomes than the VG model, although\nthe VG model showed profitability in certain naked strategies as a tool for\nposition sizing. In terms of rehedging frequency, we found that intraday\nhedging in 130-minute intervals provided both reliable protection against\nadverse market movements and a satisfactory returns profile.", "published": "2024-07-18 21:49:04", "link": "http://arxiv.org/abs/2407.13908v1", "categories": ["q-fin.PM", "q-fin.RM", "q-fin.TR"], "primary_category": "q-fin.PM"}
{"title": "Dynamic Pricing in Securities Lending Market: Application in Revenue Optimization for an Agent Lender Portfolio", "abstract": "Securities lending is an important part of the financial market structure,\nwhere agent lenders help long term institutional investors to lend out their\nsecurities to short sellers in exchange for a lending fee. Agent lenders within\nthe market seek to optimize revenue by lending out securities at the highest\nrate possible. Typically, this rate is set by hard-coded business rules or\nstandard supervised machine learning models. These approaches are often\ndifficult to scale and are not adaptive to changing market conditions. Unlike a\ntraditional stock exchange with a centralized limit order book, the securities\nlending market is organized similarly to an e-commerce marketplace, where agent\nlenders and borrowers can transact at any agreed price in a bilateral fashion.\nThis similarity suggests that the use of typical methods for addressing dynamic\npricing problems in e-commerce could be effective in the securities lending\nmarket. We show that existing contextual bandit frameworks can be successfully\nutilized in the securities lending market. Using offline evaluation on real\nhistorical data, we show that the contextual bandit approach can consistently\noutperform typical approaches by at least 15% in terms of total revenue\ngenerated.", "published": "2024-07-18 17:42:37", "link": "http://arxiv.org/abs/2407.13687v4", "categories": ["q-fin.TR", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "AlcLaM: Arabic Dialectal Language Model", "abstract": "Pre-trained Language Models (PLMs) are integral to many modern natural\nlanguage processing (NLP) systems. Although multilingual models cover a wide\nrange of languages, they often grapple with challenges like high inference\ncosts and a lack of diverse non-English training data. Arabic-specific PLMs are\ntrained predominantly on modern standard Arabic, which compromises their\nperformance on regional dialects. To tackle this, we construct an Arabic\ndialectal corpus comprising 3.4M sentences gathered from social media\nplatforms. We utilize this corpus to expand the vocabulary and retrain a\nBERT-based model from scratch. Named AlcLaM, our model was trained using only\n13 GB of text, which represents a fraction of the data used by existing models\nsuch as CAMeL, MARBERT, and ArBERT, compared to 7.8%, 10.2%, and 21.3%,\nrespectively. Remarkably, AlcLaM demonstrates superior performance on a variety\nof Arabic NLP tasks despite the limited training data. AlcLaM is available at\nGitHub https://github.com/amurtadha/Alclam and HuggingFace\nhttps://huggingface.co/rahbi.", "published": "2024-07-18 02:13:50", "link": "http://arxiv.org/abs/2407.13097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "abstract": "Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG update, including RAG with/without knowledge update. Then, we introduce\nRAG evaluation and benchmarking, as well as the application of RAG in\nrepresentative NLP tasks and industrial scenarios. Finally, this paper\ndiscusses RAG's future directions and challenges for promoting this field's\ndevelopment.", "published": "2024-07-18 06:06:53", "link": "http://arxiv.org/abs/2407.13193v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-based Single-Cell Language Model: A Survey", "abstract": "The transformers have achieved significant accomplishments in the natural\nlanguage processing as its outstanding parallel processing capabilities and\nhighly flexible attention mechanism. In addition, increasing studies based on\ntransformers have been proposed to model single-cell data. In this review, we\nattempt to systematically summarize the single-cell language models and\napplications based on transformers. First, we provide a detailed introduction\nabout the structure and principles of transformers. Then, we review the\nsingle-cell language models and large language models for single-cell data\nanalysis. Moreover, we explore the datasets and applications of single-cell\nlanguage models in downstream tasks such as batch correction, cell clustering,\ncell type annotation, gene regulatory network inference and perturbation\nresponse. Further, we discuss the challenges of single-cell language models and\nprovide promising research directions. We hope this review will serve as an\nup-to-date reference for researchers interested in the direction of single-cell\nlanguage models.", "published": "2024-07-18 06:43:12", "link": "http://arxiv.org/abs/2407.13205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models Capable of Generating Human-Level Narratives?", "abstract": "This paper investigates the capability of LLMs in storytelling, focusing on\nnarrative development and plot progression. We introduce a novel computational\nframework to analyze narratives through three discourse-level aspects: i) story\narcs, ii) turning points, and iii) affective dimensions, including arousal and\nvalence. By leveraging expert and automatic annotations, we uncover significant\ndiscrepancies between the LLM- and human- written stories. While human-written\nstories are suspenseful, arousing, and diverse in narrative structures, LLM\nstories are homogeneously positive and lack tension. Next, we measure narrative\nreasoning skills as a precursor to generative capacities, concluding that most\nLLMs fall short of human abilities in discourse understanding. Finally, we show\nthat explicit integration of aforementioned discourse features can enhance\nstorytelling, as is demonstrated by over 40% improvement in neural storytelling\nin terms of diversity, suspense, and arousal.", "published": "2024-07-18 08:02:49", "link": "http://arxiv.org/abs/2407.13248v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning", "abstract": "Specialized lexicons are collections of words with associated constraints\nsuch as special definitions, specific roles, and intended target audiences.\nThese constraints are necessary for content generation and documentation tasks\n(e.g., writing technical manuals or children's reading materials), where the\ngoal is to reduce the ambiguity of text content and increase its overall\nreadability for a specific group of audience. Understanding how large language\nmodels can capture these constraints can help researchers build better, more\nimpactful tools for wider use beyond the NLP community. Towards this end, we\nintroduce SpeciaLex, a benchmark for evaluating a language model's ability to\nfollow specialized lexicon-based constraints across 18 diverse subtasks with\n1,785 test instances covering core tasks of Checking, Identification,\nRewriting, and Open Generation. We present an empirical evaluation of 15 open\nand closed-source LLMs and discuss insights on how factors such as model scale,\nopenness, setup, and recency affect performance upon evaluating with the\nbenchmark.", "published": "2024-07-18 08:56:02", "link": "http://arxiv.org/abs/2407.13297v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CiteFusion: An Ensemble Framework for Citation Intent Classification\n  Harnessing Dual-Model Binary Couples and SHAP Analyses", "abstract": "Understanding the motivations underlying scholarly citations is critical for\nevaluating research impact and fostering transparent scholarly communication.\nThis study introduces CiteFusion, an ensemble framework designed to address the\nmulticlass Citation Intent Classification (CIC) task on benchmark datasets,\nSciCite and ACL-ARC. The framework decomposes the task into binary\nclassification subtasks, utilizing complementary pairs of SciBERT and XLNet\nmodels fine-tuned independently for each citation intent. These base models are\naggregated through a feedforward neural network meta-classifier, ensuring\nrobust performance in imbalanced and data-scarce scenarios. To enhance\ninterpretability, SHAP (SHapley Additive exPlanations) is employed to analyze\ntoken-level contributions and interactions among base models, providing\ntransparency into classification dynamics. We further investigate the semantic\nrole of structural context by incorporating section titles into input\nsentences, demonstrating their significant impact on classification accuracy\nand model reliability. Experimental results show that CiteFusion achieves\nstate-of-the-art performance, with Macro-F1 scores of 89.60% on SciCite and\n76.24% on ACL-ARC. The original intents from both datasets are mapped to\nCitation Typing Ontology (CiTO) object properties to ensure interoperability\nand reusability. This mapping highlights overlaps between the two datasets\nlabels, enhancing their understandability and reusability. Finally, we release\na web-based application that classifies citation intents leveraging CiteFusion\nmodels developed on SciCite.", "published": "2024-07-18 09:29:33", "link": "http://arxiv.org/abs/2407.13329v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning-From-Mistakes Prompting for Indigenous Language Translation", "abstract": "Using large language models, this paper presents techniques to improve\nextremely low-resourced indigenous language translations. Our approaches are\ngrounded in the use of (1) the presence of a datastore consisting of a limited\nnumber of parallel translation examples, (2) the inherent capabilities of LLMs\nlike GPT-3.5, and (3) a word-level translation dictionary. We harness the\npotential of LLMs and in-context learning techniques in such a setting for\nusing LLMs as universal translators for extremely low-resourced languages. Our\nmethodology hinges on utilizing LLMs as language compilers for selected\nlanguage pairs, hypothesizing that they could internalize syntactic structures\nto facilitate accurate translation. We introduce three techniques: KNNPrompting\nwith Retrieved Prompting Context, Chain-of-Thought Prompting and\nLearningfrom-Mistakes Prompting, with the last method addressing past errors.\nThe evaluation results suggest that, even with limited corpora, LLMs can\neffectively translate extremely low-resource languages when paired with proper\nprompting.", "published": "2024-07-18 09:41:20", "link": "http://arxiv.org/abs/2407.13343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fixed and Adaptive Simultaneous Machine Translation Strategies Using\n  Adapters", "abstract": "Simultaneous machine translation aims at solving the task of real-time\ntranslation by starting to translate before consuming the full input, which\nposes challenges in terms of balancing quality and latency of the translation.\nThe wait-$k$ policy offers a solution by starting to translate after consuming\n$k$ words, where the choice of the number $k$ directly affects the latency and\nquality. In applications where we seek to keep the choice over latency and\nquality at inference, the wait-$k$ policy obliges us to train more than one\nmodel. In this paper, we address the challenge of building one model that can\nfulfil multiple latency levels and we achieve this by introducing lightweight\nadapter modules into the decoder. The adapters are trained to be specialized\nfor different wait-$k$ values and compared to other techniques they offer more\nflexibility to allow for reaping the benefits of parameter sharing and\nminimizing interference. Additionally, we show that by combining with an\nadaptive strategy, we can further improve the results. Experiments on two\nlanguage directions show that our method outperforms or competes with other\nstrong baselines on most latency values.", "published": "2024-07-18 12:42:45", "link": "http://arxiv.org/abs/2407.13469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention Overflow: Language Model Input Blur during Long-Context\n  Missing Items Recommendation", "abstract": "Large language models (LLMs) can suggest missing elements from items listed\nin a prompt, which can be used for list completion or recommendations based on\nusers' history. However, their performance degrades when presented with too\nmany items, as they start to suggest items already included in the input list.\nThis occurs at around 100 items for mid-2024 flagship LLMs. We evaluate this\nphenomenon on both synthetic problems (e.g., finding missing numbers in a given\nrange of shuffled integers) and realistic movie recommendation scenarios. We\nrefer to this issue as \\textit{attention overflow}, as preventing repetition\nrequires attending to all items simultaneously. Although iterative loops can\nmitigate this problem, their costs increase with the repetition rate, affecting\nthe language models' ability to derive novelty from lengthy inputs.", "published": "2024-07-18 13:00:30", "link": "http://arxiv.org/abs/2407.13481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Open-Source LLMs Compete with Commercial Models? Exploring the\n  Few-Shot Performance of Current GPT Models in Biomedical Tasks", "abstract": "Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT\nand Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)\nbenchmarks across different domains. New competing Open-Source alternatives\nlike Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while\noften offering higher throughput and being less costly to use. Open-Source LLMs\ncan also be self-hosted, which makes them interesting for enterprise and\nclinical use cases where sensitive data should not be processed by third\nparties. We participated in the 12th BioASQ challenge, which is a retrieval\naugmented generation (RAG) setting, and explored the performance of current GPT\nmodels Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning\n(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional\nrelevant knowledge from Wikipedia added to the context-window of the LLM might\nimprove their performance. Mixtral 8x7b was competitive in the 10-shot setting,\nboth with and without fine-tuning, but failed to produce usable results in the\nzero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to\nmeasurable performance gains. Our results indicate that the performance gap\nbetween commercial and open-source models in RAG setups exists mainly in the\nzero-shot setting and can be closed by simply collecting few-shot examples for\ndomain-specific use cases. The code needed to rerun these experiments is\navailable through GitHub.", "published": "2024-07-18 13:43:01", "link": "http://arxiv.org/abs/2407.13511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Research on Tibetan Tourism Viewpoints information generation system\n  based on LLM", "abstract": "Tibet, ensconced within China's territorial expanse, is distinguished by its\nlabyrinthine and heterogeneous topography, a testament to its profound\nhistorical heritage, and the cradle of a unique religious ethos. The very\nessence of these attributes, however, has impeded the advancement of Tibet's\ntourism service infrastructure, rendering existing smart tourism services\ninadequate for the region's visitors. This study delves into the ramifications\nof informational disparities at tourist sites on Tibetan tourism and addresses\nthe challenge of establishing the Large Language Model (LLM) evaluation\ncriteria. It introduces an innovative approach, the DualGen Bridge AI system,\nemploying supervised fine-tuning techniques to bolster model functionality and\nenhance optimization processes. Furthermore, it pioneers a multi-structured\ngenerative results assessment framework. Empirical validation confirms the\nefficacy of this framework. The study also explores the application of the\nsupervised fine-tuning method within the proprietary DualGen Bridge AI, aimed\nat refining the generation of tourist site information. The study's findings\noffer valuable insights for optimizing system performance and provide support\nand inspiration for the application of LLM technology in Tibet's tourism\nservices and beyond, potentially revolutionizing the smart tourism industry\nwith advanced, tailored information generation capabilities.", "published": "2024-07-18 14:31:53", "link": "http://arxiv.org/abs/2407.13561v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "dzFinNlp at AraFinNLP: Improving Intent Detection in Financial\n  Conversational Agents", "abstract": "In this paper, we present our dzFinNlp team's contribution for intent\ndetection in financial conversational agents, as part of the AraFinNLP shared\ntask. We experimented with various models and feature configurations, including\ntraditional machine learning methods like LinearSVC with TF-IDF, as well as\ndeep learning models like Long Short-Term Memory (LSTM). Additionally, we\nexplored the use of transformer-based models for this task. Our experiments\nshow promising results, with our best model achieving a micro F1-score of\n93.02% and 67.21% on the ArBanking77 dataset, in the development and test sets,\nrespectively.", "published": "2024-07-18 14:37:20", "link": "http://arxiv.org/abs/2407.13565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Zero-Shot Multimodal Machine Translation", "abstract": "Current multimodal machine translation (MMT) systems rely on fully supervised\ndata (i.e models are trained on sentences with their translations and\naccompanying images). However, this type of data is costly to collect, limiting\nthe extension of MMT to other language pairs for which such data does not\nexist. In this work, we propose a method to bypass the need for fully\nsupervised data to train MMT systems, using multimodal English data only. Our\nmethod, called ZeroMMT, consists in adapting a strong text-only machine\ntranslation (MT) model by training it on a mixture of two objectives: visually\nconditioned masked language modelling and the Kullback-Leibler divergence\nbetween the original and new MMT outputs. We evaluate on standard MMT\nbenchmarks and the recently released CoMMuTE, a contrastive benchmark aiming to\nevaluate how well models use images to disambiguate English sentences. We\nobtain disambiguation performance close to state-of-the-art MMT models trained\nadditionally on fully supervised examples. To prove that our method generalizes\nto languages with no fully supervised training data available, we extend the\nCoMMuTE evaluation dataset to three new languages: Arabic, Russian and Chinese.\nWe further show that we can control the trade-off between disambiguation\ncapabilities and translation fidelity at inference time using classifier-free\nguidance and without any additional data. Our code, data and trained models are\npublicly accessible.", "published": "2024-07-18 15:20:31", "link": "http://arxiv.org/abs/2407.13579v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "dzStance at StanceEval2024: Arabic Stance Detection based on Sentence\n  Transformers", "abstract": "This study compares Term Frequency-Inverse Document Frequency (TF-IDF)\nfeatures with Sentence Transformers for detecting writers' stances--favorable,\nopposing, or neutral--towards three significant topics: COVID-19 vaccine,\ndigital transformation, and women empowerment. Through empirical evaluation, we\ndemonstrate that Sentence Transformers outperform TF-IDF features across\nvarious experimental setups. Our team, dzStance, participated in a stance\ndetection competition, achieving the 13th position (74.91%) among 15 teams in\nWomen Empowerment, 10th (73.43%) in COVID Vaccine, and 12th (66.97%) in Digital\nTransformation. Overall, our team's performance ranked 13th (71.77%) among all\nparticipants. Notably, our approach achieved promising F1-scores, highlighting\nits effectiveness in identifying writers' stances on diverse topics. These\nresults underscore the potential of Sentence Transformers to enhance stance\ndetection models for addressing critical societal issues.", "published": "2024-07-18 15:43:27", "link": "http://arxiv.org/abs/2407.13603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted\n  Voting and TF-IDF Features", "abstract": "This paper presents the contribution of our dzNLP team to the NADI 2024\nshared task, specifically in Subtask 1 - Multi-label Country-level Dialect\nIdentification (MLDID) (Closed Track). We explored various configurations to\naddress the challenge: in Experiment 1, we utilized a union of n-gram analyzers\n(word, character, character with word boundaries) with different n-gram values;\nin Experiment 2, we combined a weighted union of Term Frequency-Inverse\nDocument Frequency (TF-IDF) features with various weights; and in Experiment 3,\nwe implemented a weighted major voting scheme using three classifiers: Linear\nSupport Vector Classifier (LSVC), Random Forest (RF), and K-Nearest Neighbors\n(KNN).\n  Our approach, despite its simplicity and reliance on traditional machine\nlearning techniques, demonstrated competitive performance in terms of F1-score\nand precision. Notably, we achieved the highest precision score of 63.22% among\nthe participating teams. However, our overall F1 score was approximately 21%,\nsignificantly impacted by a low recall rate of 12.87%. This indicates that\nwhile our models were highly precise, they struggled to recall a broad range of\ndialect labels, highlighting a critical area for improvement in handling\ndiverse dialectal variations.", "published": "2024-07-18 15:47:42", "link": "http://arxiv.org/abs/2407.13608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FuLG: 150B Romanian Corpus for Language Model Pretraining", "abstract": "Research in the field of language models is rapidly evolving, with many open\nmodels being released to the public. Openly available pretraining corpora\nusually focus on only a handful of languages, with many others either missing\ncompletely or extremely underrepresented. In this report, we introduce FuLG, a\nhundred-fifty-billion-token Romanian corpus extracted from CommonCrawl. We\npresent our methodology for filtering FuLG and compare it via ablation studies\nagainst existing Romanian corpora.", "published": "2024-07-18 16:32:48", "link": "http://arxiv.org/abs/2407.13657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prover-Verifier Games improve legibility of LLM outputs", "abstract": "One way to increase confidence in the outputs of Large Language Models (LLMs)\nis to support them with reasoning that is clear and easy to check -- a property\nwe call legibility. We study legibility in the context of solving grade-school\nmath problems and show that optimizing chain-of-thought solutions only for\nanswer correctness can make them less legible. To mitigate the loss in\nlegibility, we propose a training algorithm inspired by Prover-Verifier Game\nfrom Anil et al. (2021). Our algorithm iteratively trains small verifiers to\npredict solution correctness, \"helpful\" provers to produce correct solutions\nthat the verifier accepts, and \"sneaky\" provers to produce incorrect solutions\nthat fool the verifier. We find that the helpful prover's accuracy and the\nverifier's robustness to adversarial attacks increase over the course of\ntraining. Furthermore, we show that legibility training transfers to\ntime-constrained humans tasked with verifying solution correctness. Over course\nof LLM training human accuracy increases when checking the helpful prover's\nsolutions, and decreases when checking the sneaky prover's solutions. Hence,\ntraining for checkability by small verifiers is a plausible technique for\nincreasing output legibility. Our results suggest legibility training against\nsmall verifiers as a practical avenue for increasing legibility of large LLMs\nto humans, and thus could help with alignment of superhuman models.", "published": "2024-07-18 16:58:18", "link": "http://arxiv.org/abs/2407.13692v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do These LLM Benchmarks Agree? Fixing Benchmark Evaluation with\n  BenchBench", "abstract": "Recent advancements in Language Models (LMs) have catalyzed the creation of\nmultiple benchmarks, designed to assess these models' general capabilities. A\ncrucial task, however, is assessing the validity of the benchmarks themselves.\nThis is most commonly done via Benchmark Agreement Testing (BAT), where new\nbenchmarks are validated against established ones using some agreement metric\n(e.g., rank correlation). Despite the crucial role of BAT for benchmark\nbuilders and consumers, there are no standardized procedures for such agreement\ntesting. This deficiency can lead to invalid conclusions, fostering mistrust in\nbenchmarks and upending the ability to properly choose the appropriate\nbenchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how\nsome overlooked methodological choices can significantly influence BAT results,\npotentially undermining the validity of conclusions. To address these\ninconsistencies, we propose a set of best practices for BAT and demonstrate how\nutilizing these methodologies greatly improves BAT robustness and validity. To\nfoster adoption and facilitate future research,, we introduce BenchBench, a\npython package for BAT, and release the BenchBench-leaderboard, a\nmeta-benchmark designed to evaluate benchmarks using their peers. Our findings\nunderscore the necessity for standardized BAT, ensuring the robustness and\nvalidity of benchmark evaluations in the evolving landscape of language model\nresearch.\n  BenchBench Package: github.com/IBM/BenchBench\n  Leaderboard: hf.co/spaces/IBM/BenchBench", "published": "2024-07-18 17:00:23", "link": "http://arxiv.org/abs/2407.13696v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free\n  Hallucination Detection", "abstract": "Research on token-level reference-free hallucination detection has\npredominantly focused on English, primarily due to the scarcity of robust\ndatasets in other languages. This has hindered systematic investigations into\nthe effectiveness of cross-lingual transfer for this important NLP application.\nTo address this gap, we introduce ANHALTEN, a new evaluation dataset that\nextends the English hallucination detection dataset to German. To the best of\nour knowledge, this is the first work that explores cross-lingual transfer for\ntoken-level reference-free hallucination detection. ANHALTEN contains gold\nannotations in German that are parallel (i.e., directly comparable to the\noriginal English instances). We benchmark several prominent cross-lingual\ntransfer approaches, demonstrating that larger context length leads to better\nhallucination detection in German, even without succeeding context.\nImportantly, we show that the sample-efficient few-shot transfer is the most\neffective approach in most setups. This highlights the practical benefits of\nminimal annotation effort in the target language for reference-free\nhallucination detection. Aiming to catalyze future research on cross-lingual\ntoken-level reference-free hallucination detection, we make ANHALTEN publicly\navailable: https://github.com/janekh24/anhalten", "published": "2024-07-18 17:01:38", "link": "http://arxiv.org/abs/2407.13702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Baba Is AI: Break the Rules to Beat the Benchmark", "abstract": "Humans solve problems by following existing rules and procedures, and also by\nleaps of creativity to redefine those rules and objectives. To probe these\nabilities, we developed a new benchmark based on the game Baba Is You where an\nagent manipulates both objects in the environment and rules, represented by\nmovable tiles with words written on them, to reach a specified goal and win the\ngame. We test three state-of-the-art multi-modal large language models (OpenAI\nGPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail\ndramatically when generalization requires that the rules of the game must be\nmanipulated and combined.", "published": "2024-07-18 17:30:48", "link": "http://arxiv.org/abs/2407.13729v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Goal-Conditioned Representations for Language Reward Models", "abstract": "Techniques that learn improved representations via offline data or\nself-supervised objectives have shown impressive results in traditional\nreinforcement learning (RL). Nevertheless, it is unclear how improved\nrepresentation learning can benefit reinforcement learning from human feedback\n(RLHF) on language models (LMs). In this work, we propose training reward\nmodels (RMs) in a contrastive, $\\textit{goal-conditioned}$ fashion by\nincreasing the representation similarity of future states along sampled\npreferred trajectories and decreasing the similarity along randomly sampled\ndispreferred trajectories. This objective significantly improves RM performance\nby up to 0.09 AUROC across challenging benchmarks, such as MATH and GSM8k.\nThese findings extend to general alignment as well -- on the Helpful-Harmless\ndataset, we observe $2.3\\%$ increase in accuracy. Beyond improving reward model\nperformance, we show this way of training RM representations enables improved\n$\\textit{steerability}$ because it allows us to evaluate the likelihood of an\naction achieving a particular goal-state (e.g., whether a solution is correct\nor helpful). Leveraging this insight, we find that we can filter up to $55\\%$\nof generated tokens during majority voting by discarding trajectories likely to\nend up in an \"incorrect\" state, which leads to significant cost savings. We\nadditionally find that these representations can perform fine-grained control\nby conditioning on desired future goal-states. For example, we show that\nsteering a Llama 3 model towards helpful generations with our approach improves\nhelpfulness by $9.6\\%$ over a supervised-fine-tuning trained baseline.\nSimilarly, steering the model towards complex generations improves complexity\nby $21.6\\%$ over the baseline. Overall, we find that training RMs in this\ncontrastive, goal-conditioned fashion significantly improves performance and\nenables model steerability.", "published": "2024-07-18 20:23:11", "link": "http://arxiv.org/abs/2407.13887v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BiasDPO: Mitigating Bias in Language Models through Direct Preference\n  Optimization", "abstract": "Large Language Models (LLMs) have become pivotal in advancing natural\nlanguage processing, yet their potential to perpetuate biases poses significant\nconcerns. This paper introduces a new framework employing Direct Preference\nOptimization (DPO) to mitigate gender, racial, and religious biases in\nLLM-generated English text. By developing a loss function that favors less\nbiased over biased completions, our approach cultivates a preference for\nrespectful and non-discriminatory language in LLMs. We also contribute a\nmanually designed dataset for training LLMs to recognize and correct biases.\nThis dataset encompasses a diverse range of prompts paired with both biased and\nunbiased completions. Implementing this approach on the Microsoft Phi-2 model,\nwe demonstrate substantial reductions in biased outputs as our model\noutperforms the baseline model on almost all bias benchmarks. Our model also\nachieves better performance compared to other open-source models on most\nbenchmarks. By reducing biases in the language generated by the model, our\nstudy marks a significant step towards developing more ethical and socially\nresponsible LLMs. We publicly release BiasDPO dataset on HuggingFace.", "published": "2024-07-18 22:32:20", "link": "http://arxiv.org/abs/2407.13928v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FANTAstic SEquences and Where to Find Them: Faithful and Efficient API\n  Call Generation through State-tracked Constrained Decoding and Reranking", "abstract": "API call generation is the cornerstone of large language models' tool-using\nability that provides access to the larger world. However, existing supervised\nand in-context learning approaches suffer from high training costs, poor data\nefficiency, and generated API calls that can be unfaithful to the API\ndocumentation and the user's request. To address these limitations, we propose\nan output-side optimization approach called FANTASE. Two of the unique\ncontributions of FANTASE are its State-Tracked Constrained Decoding (SCD) and\nReranking components. SCD dynamically incorporates appropriate API constraints\nin the form of Token Search Trie for efficient and guaranteed generation\nfaithfulness with respect to the API documentation. The Reranking component\nefficiently brings in the supervised signal by leveraging a lightweight model\nas the discriminator to rerank the beam-searched candidate generations of the\nlarge language model. We demonstrate the superior performance of FANTASE in API\ncall generation accuracy, inference efficiency, and context efficiency with\nDSTC8 and API Bank datasets.", "published": "2024-07-18 23:44:02", "link": "http://arxiv.org/abs/2407.13945v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Sentiment Analysis with Local Large Language Models using\n  Majority Voting: A Study on Factors Affecting Restaurant Evaluation", "abstract": "User-generated contents (UGCs) on online platforms allow marketing\nresearchers to understand consumer preferences for products and services. With\nthe advance of large language models (LLMs), some studies utilized the models\nfor annotation and sentiment analysis. However, the relationship between the\naccuracy and the hyper-parameters of LLMs is yet to be thoroughly examined. In\naddition, the issues of variability and reproducibility of results from each\ntrial of LLMs have rarely been considered in existing literature. Since actual\nhuman annotation uses majority voting to resolve disagreements among\nannotators, this study introduces a majority voting mechanism to a sentiment\nanalysis model using local LLMs. By a series of three analyses of online\nreviews on restaurant evaluations, we demonstrate that majority voting with\nmultiple attempts using a medium-sized model produces more robust results than\nusing a large model with a single attempt. Furthermore, we conducted further\nanalysis to investigate the effect of each aspect on the overall evaluation.", "published": "2024-07-18 00:28:04", "link": "http://arxiv.org/abs/2407.13069v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for\n  Fact-Checking", "abstract": "Fact-checking real-world claims often requires reviewing multiple multimodal\ndocuments to assess a claim's truthfulness, which is a highly laborious and\ntime-consuming task. In this paper, we present a summarization model designed\nto generate claim-specific summaries useful for fact-checking from multimodal,\nmulti-document datasets. The model takes inputs in the form of documents,\nimages, and a claim, with the objective of assisting in fact-checking tasks. We\nintroduce a dynamic perceiver-based model that can handle inputs from multiple\nmodalities of arbitrary lengths. To train our model, we leverage a novel\nreinforcement learning-based entailment objective to generate summaries that\nprovide evidence distinguishing between different truthfulness labels. To\nassess the efficacy of our approach, we conduct experiments on both an existing\nbenchmark and a new dataset of multi-document claims that we contribute. Our\napproach outperforms the SOTA approach by 4.6% in the claim verification task\non the MOCHEG dataset and demonstrates strong performance on our new\nMulti-News-Fact-Checking dataset.", "published": "2024-07-18 01:33:20", "link": "http://arxiv.org/abs/2407.13089v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with\n  an Iterative Approach", "abstract": "Multi-hop question answering is a challenging task with distinct industrial\nrelevance, and Retrieval-Augmented Generation (RAG) methods based on large\nlanguage models (LLMs) have become a popular approach to tackle this task.\nOwing to the potential inability to retrieve all necessary information in a\nsingle iteration, a series of iterative RAG methods has been recently\ndeveloped, showing significant performance improvements. However, existing\nmethods still face two critical challenges: context overload resulting from\nmultiple rounds of retrieval, and over-planning and repetitive planning due to\nthe lack of a recorded retrieval trajectory. In this paper, we propose a novel\niterative RAG method called ReSP, equipped with a dual-function summarizer.\nThis summarizer compresses information from retrieved documents, targeting both\nthe overarching question and the current sub-question concurrently.\nExperimental results on the multi-hop question-answering datasets HotpotQA and\n2WikiMultihopQA demonstrate that our method significantly outperforms the\nstate-of-the-art, and exhibits excellent robustness concerning context length.", "published": "2024-07-18 02:19:00", "link": "http://arxiv.org/abs/2407.13101v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep &\n  Cross Network and Large Language Models", "abstract": "Clinical trials need to recruit a sufficient number of volunteer patients to\ndemonstrate the statistical power of the treatment (e.g., a new drug) in curing\na certain disease. Clinical trial recruitment has a significant impact on trial\nsuccess. Forecasting whether the recruitment process would be successful before\nwe run the trial would save many resources and time. This paper develops a\nnovel deep & cross network with large language model (LLM)-augmented text\nfeature that learns semantic information from trial eligibility criteria and\npredicts enrollment success. The proposed method enables interpretability by\nunderstanding which sentence/word in eligibility criteria contributes heavily\nto prediction. We also demonstrate the empirical superiority of the proposed\nmethod (0.7002 PR-AUC) over a bunch of well-established machine learning\nmethods. The code and curated dataset are publicly available at\nhttps://anonymous.4open.science/r/TrialEnroll-7E12.", "published": "2024-07-18 02:50:40", "link": "http://arxiv.org/abs/2407.13115v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Translate-and-Revise: Boosting Large Language Models for Constrained\n  Translation", "abstract": "Imposing constraints on machine translation systems presents a challenging\nissue because these systems are not trained to make use of constraints in\ngenerating adequate, fluent translations. In this paper, we leverage the\ncapabilities of large language models (LLMs) for constrained translation, given\nthat LLMs can easily adapt to this task by taking translation instructions and\nconstraints as prompts. However, LLMs cannot always guarantee the adequacy of\ntranslation, and, in some cases, ignore the given constraints. This is in part\nbecause LLMs might be overly confident in their predictions, overriding the\ninfluence of the constraints. To overcome this overiding behaviour, we propose\nto add a revision process that encourages LLMs to correct the outputs by\nprompting them about the constraints that have not yet been met. We evaluate\nour approach on four constrained translation tasks, encompassing both lexical\nand structural constraints in multiple constraint domains. Experiments show\n15\\% improvement in constraint-based translation accuracy over standard LLMs\nand the approach also significantly outperforms neural machine translation\n(NMT) state-of-the-art methods.", "published": "2024-07-18 05:08:09", "link": "http://arxiv.org/abs/2407.13164v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SciCode: A Research Coding Benchmark Curated by Scientists", "abstract": "Since language models (LMs) now outperform average humans on many challenging\ntasks, it has become increasingly difficult to develop challenging,\nhigh-quality, and realistic evaluations. We address this issue by examining\nLMs' capabilities to generate code for solving real scientific research\nproblems. Incorporating input from scientists and AI researchers in 16 diverse\nnatural science sub-fields, including mathematics, physics, chemistry, biology,\nand materials science, we created a scientist-curated coding benchmark,\nSciCode. The problems in SciCode naturally factorize into multiple subproblems,\neach involving knowledge recall, reasoning, and code synthesis. In total,\nSciCode contains 338 subproblems decomposed from 80 challenging main problems.\nIt offers optional descriptions specifying useful scientific background\ninformation and scientist-annotated gold-standard solutions and test cases for\nevaluation. Claude3.5-Sonnet, the best-performing model among those tested, can\nsolve only 4.6% of the problems in the most realistic setting. We believe that\nSciCode demonstrates both contemporary LMs' progress towards becoming helpful\nscientific assistants and sheds light on the development and evaluation of\nscientific AI in the future.", "published": "2024-07-18 05:15:24", "link": "http://arxiv.org/abs/2407.13168v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining\n  Tasks", "abstract": "Large Language Models (LLMs) have the potential to semi-automate some process\nmining (PM) analyses. While commercial models are already adequate for many\nanalytics tasks, the competitive level of open-source LLMs in PM tasks is\nunknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive\nbenchmark for PM focusing on domain knowledge (process-mining-specific and\nprocess-specific) and on different implementation strategies. We focus also on\nthe challenges in creating such a benchmark, related to the public availability\nof the data and on evaluation biases by the LLMs. Overall, we observe that most\nof the considered LLMs can perform some process mining tasks at a satisfactory\nlevel, but tiny models that would run on edge devices are still inadequate. We\nalso conclude that while the proposed benchmark is useful for identifying LLMs\nthat are adequate for process mining tasks, further research is needed to\novercome the evaluation biases and perform a more thorough ranking of the\ncompetitive LLMs.", "published": "2024-07-18 07:57:31", "link": "http://arxiv.org/abs/2407.13244v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Robust ASR Error Correction with Conservative Data Filtering", "abstract": "Error correction (EC) based on large language models is an emerging\ntechnology to enhance the performance of automatic speech recognition (ASR)\nsystems. Generally, training data for EC are collected by automatically pairing\na large set of ASR hypotheses (as sources) and their gold references (as\ntargets). However, the quality of such pairs is not guaranteed, and we observed\nvarious types of noise which can make the EC models brittle, e.g. inducing\novercorrection in out-of-domain (OOD) settings. In this work, we propose two\nfundamental criteria that EC training data should satisfy: namely, EC targets\nshould (1) improve linguistic acceptability over sources and (2) be inferable\nfrom the available context (e.g. source phonemes). Through these criteria, we\nidentify low-quality EC pairs and train the models not to make any correction\nin such cases, the process we refer to as conservative data filtering. In our\nexperiments, we focus on Japanese ASR using a strong Conformer-CTC as the\nbaseline and finetune Japanese LLMs for EC. Through our evaluation on a suite\nof 21 internal benchmarks, we demonstrate that our approach can significantly\nreduce overcorrection and improve both the accuracy and quality of ASR results\nin the challenging OOD settings.", "published": "2024-07-18 09:05:49", "link": "http://arxiv.org/abs/2407.13300v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Capturing Style in Author and Document Representation", "abstract": "A wide range of Deep Natural Language Processing (NLP) models integrates\ncontinuous and low dimensional representations of words and documents.\nSurprisingly, very few models study representation learning for authors. These\nrepresentations can be used for many NLP tasks, such as author identification\nand classification, or in recommendation systems. A strong limitation of\nexisting works is that they do not explicitly capture writing style, making\nthem hardly applicable to literary data. We therefore propose a new\narchitecture based on Variational Information Bottleneck (VIB) that learns\nembeddings for both authors and documents with a stylistic constraint. Our\nmodel fine-tunes a pre-trained document encoder. We stimulate the detection of\nwriting style by adding predefined stylistic features making the representation\naxis interpretable with respect to writing style indicators. We evaluate our\nmethod on three datasets: a literary corpus extracted from the Gutenberg\nProject, the Blog Authorship Corpus and IMDb62, for which we show that it\nmatches or outperforms strong/recent baselines in authorship attribution while\ncapturing much more accurately the authors stylistic aspects.", "published": "2024-07-18 10:01:09", "link": "http://arxiv.org/abs/2407.13358v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in\n  Vision-language Models", "abstract": "Vision language models (VLMs) perceive the world through a combination of a\nvisual encoder and a large language model (LLM). The visual encoder,\npre-trained on large-scale vision-text datasets, provides zero-shot\ngeneralization to visual data, and the LLM endows its high reasoning ability to\nVLMs. It leads VLMs to achieve high performance on wide benchmarks without\nfine-tuning, exhibiting zero or few-shot capability. However, recent studies\nshow that VLMs are vulnerable to hallucination. This undesirable behavior\ndegrades reliability and credibility, thereby making users unable to fully\ntrust the output from VLMs. To enhance trustworthiness and better tackle the\nhallucination of VLMs, we curate a new evaluation dataset, called the\nBEfore-AFter hallucination dataset (BEAF), and introduce new metrics: True\nUnderstanding (TU), IGnorance (IG), StuBbornness (SB), and InDecision (ID).\nUnlike prior works that focus only on constructing questions and answers, the\nkey idea of our benchmark is to manipulate visual scene information by image\nediting models and to design the metrics based on scene changes. This allows us\nto clearly assess whether VLMs correctly understand a given scene by observing\nthe ability to perceive changes. We also visualize image-wise object\nrelationship by virtue of our two-axis view: vision and text. Upon evaluating\nVLMs with our dataset, we observed that our metrics reveal different aspects of\nVLM hallucination that have not been reported before. Project page:\n\\url{https://beafbench.github.io/}", "published": "2024-07-18 12:11:12", "link": "http://arxiv.org/abs/2407.13442v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "End-To-End Clinical Trial Matching with Large Language Models", "abstract": "Matching cancer patients to clinical trials is essential for advancing\ntreatment and patient care. However, the inconsistent format of medical free\ntext documents and complex trial eligibility criteria make this process\nextremely challenging and time-consuming for physicians. We investigated\nwhether the entire trial matching process - from identifying relevant trials\namong 105,600 oncology-related clinical trials on clinicaltrials.gov to\ngenerating criterion-level eligibility matches - could be automated using Large\nLanguage Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic\nHealth Records (EHRs), we demonstrate that our approach identifies relevant\ncandidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%\nwhen matching patient-level information at the criterion level against a\nbaseline defined by human experts. Utilizing LLM feedback reveals that 39.3%\ncriteria that were initially considered incorrect are either ambiguous or\ninaccurately annotated, leading to a total model accuracy of 92.7% after\nrefining our human baseline. In summary, we present an end-to-end pipeline for\nclinical trial matching using LLMs, demonstrating high precision in screening\nand matching trials to individual patients, even outperforming the performance\nof qualified medical doctors. Our fully end-to-end pipeline can operate\nautonomously or with human supervision and is not restricted to oncology,\noffering a scalable solution for enhancing patient-trial matching in real-world\nsettings.", "published": "2024-07-18 12:36:26", "link": "http://arxiv.org/abs/2407.13463v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Combining Constraint Programming Reasoning with Large Language Model\n  Predictions", "abstract": "Constraint Programming (CP) and Machine Learning (ML) face challenges in text\ngeneration due to CP's struggle with implementing \"meaning'' and ML's\ndifficulty with structural constraints. This paper proposes a solution by\ncombining both approaches and embedding a Large Language Model (LLM) in CP. The\nLLM handles word generation and meaning, while CP manages structural\nconstraints. This approach builds on GenCP, an improved version of On-the-fly\nConstraint Programming Search (OTFS) using LLM-generated domains. Compared to\nBeam Search (BS), a standard NLP method, this combined approach (GenCP with\nLLM) is faster and produces better results, ensuring all constraints are\nsatisfied. This fusion of CP and ML presents new possibilities for enhancing\ntext generation under constraints.", "published": "2024-07-18 13:15:55", "link": "http://arxiv.org/abs/2407.13490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source\n  Framework Applied on Rett Syndrome and Alzheimer's Disease", "abstract": "The ever-growing volume of biomedical publications creates a critical need\nfor efficient knowledge discovery. In this context, we introduce an open-source\nend-to-end framework designed to construct knowledge around specific diseases\ndirectly from raw text. To facilitate research in disease-related knowledge\ndiscovery, we create two annotated datasets focused on Rett syndrome and\nAlzheimer's disease, enabling the identification of semantic relations between\nbiomedical entities. Extensive benchmarking explores various ways to represent\nrelations and entity representations, offering insights into optimal modeling\nstrategies for semantic relation detection and highlighting language models'\ncompetence in knowledge discovery. We also conduct probing experiments using\ndifferent layer representations and attention scores to explore transformers'\nability to capture semantic relations.", "published": "2024-07-18 13:20:53", "link": "http://arxiv.org/abs/2407.13492v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "New Capability to Look Up an ASL Sign from a Video Example", "abstract": "Looking up an unknown sign in an ASL dictionary can be difficult. Most ASL\ndictionaries are organized based on English glosses, despite the fact that (1)\nthere is no convention for assigning English-based glosses to ASL signs; and\n(2) there is no 1-1 correspondence between ASL signs and English words.\nFurthermore, what if the user does not know either the meaning of the target\nsign or its possible English translation(s)? Some ASL dictionaries enable\nsearching through specification of articulatory properties, such as handshapes,\nlocations, movement properties, etc. However, this is a cumbersome process and\ndoes not always result in successful lookup. Here we describe a new system,\npublicly shared on the Web, to enable lookup of a video of an ASL sign (e.g., a\nwebcam recording or a clip from a continuous signing video). The user submits a\nvideo for analysis and is presented with the five most likely sign matches, in\ndecreasing order of likelihood, so that the user can confirm the selection and\nthen be taken to our ASLLRP Sign Bank entry for that sign. Furthermore, this\nvideo lookup is also integrated into our newest version of SignStream(R)\nsoftware to facilitate linguistic annotation of ASL video data, enabling the\nuser to directly look up a sign in the video being annotated, and, upon\nconfirmation of the match, to directly enter into the annotation the gloss and\nfeatures of that sign, greatly increasing the efficiency and consistency of\nlinguistic annotations of ASL video data.", "published": "2024-07-18 15:14:35", "link": "http://arxiv.org/abs/2407.13571v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "How Reliable are LLMs as Knowledge Bases? Re-thinking Facutality and\n  Consistency", "abstract": "Large Language Models (LLMs) are increasingly explored as knowledge bases\n(KBs), yet current evaluation methods focus too narrowly on knowledge\nretention, overlooking other crucial criteria for reliable performance. In this\nwork, we rethink the requirements for evaluating reliable LLM-as-KB usage and\nhighlight two essential factors: factuality, ensuring accurate responses to\nseen and unseen knowledge, and consistency, maintaining stable answers to\nquestions about the same knowledge. We introduce UnseenQA, a dataset designed\nto assess LLM performance on unseen knowledge, and propose new criteria and\nmetrics to quantify factuality and consistency, leading to a final reliability\nscore. Our experiments on 26 LLMs reveal several challenges regarding their use\nas KBs, underscoring the need for more principled and comprehensive evaluation.", "published": "2024-07-18 15:20:18", "link": "http://arxiv.org/abs/2407.13578v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like\n  (PL) Tasks", "abstract": "Text summarization is a well-studied problem that deals with deriving\ninsights from unstructured text consumed by humans, and it has found extensive\nbusiness applications. However, many real-life tasks involve generating a\nseries of actions to achieve specific goals, such as workflows, recipes,\ndialogs, and travel plans. We refer to them as planning-like (PL) tasks noting\nthat the main commonality they share is control flow information. which may be\npartially specified. Their structure presents an opportunity to create more\npractical summaries to help users make quick decisions. We investigate this\nobservation by introducing a novel plan summarization problem, presenting a\ndataset, and providing a baseline method for generating PL summaries. Using\nquantitative metrics and qualitative user studies to establish baselines, we\nevaluate the plan summaries from our method and large language models. We\nbelieve the novel problem and dataset can reinvigorate research in\nsummarization, which some consider as a solved problem.", "published": "2024-07-18 15:36:02", "link": "http://arxiv.org/abs/2407.13597v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies", "abstract": "Research on scaling large language models (LLMs) has primarily focused on\nmodel parameters and training data size, overlooking the role of vocabulary\nsize. We investigate how vocabulary size impacts LLM scaling laws by training\nmodels ranging from 33M to 3B parameters on up to 500B characters with various\nvocabulary configurations. We propose three complementary approaches for\npredicting the compute-optimal vocabulary size: IsoFLOPs analysis, derivative\nestimation, and parametric fit of the loss function. Our approaches converge on\nthe conclusion that the optimal vocabulary size depends on the compute budget,\nwith larger models requiring larger vocabularies. Most LLMs, however, use\ninsufficient vocabulary sizes. For example, we predict that the optimal\nvocabulary size of Llama2-70B should have been at least 216K, 7 times larger\nthan its vocabulary of 32K. We validate our predictions empirically by training\nmodels with 3B parameters across different FLOPs budgets. Adopting our\npredicted optimal vocabulary size consistently improves downstream performance\nover commonly used vocabulary sizes. By increasing the vocabulary size from the\nconventional 32K to 43K, we improve performance on ARC-Challenge from 29.1 to\n32.0 with the same 2.3e21 FLOPs. Our work highlights the importance of jointly\nconsidering tokenization and model scaling for efficient pre-training. The code\nand demo are available at https://github.com/sail-sg/scaling-with-vocab and\nhttps://hf.co/spaces/sail/scaling-with-vocab-demo.", "published": "2024-07-18 15:58:54", "link": "http://arxiv.org/abs/2407.13623v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparative Study on Automatic Coding of Medical Letters with\n  Explainability", "abstract": "This study aims to explore the implementation of Natural Language Processing\n(NLP) and machine learning (ML) techniques to automate the coding of medical\nletters with visualised explainability and light-weighted local computer\nsettings. Currently in clinical settings, coding is a manual process that\ninvolves assigning codes to each condition, procedure, and medication in a\npatient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There\nare preliminary research on automatic coding in this field using\nstate-of-the-art ML models; however, due to the complexity and size of the\nmodels, the real-world deployment is not achieved. To further facilitate the\npossibility of automatic coding practice, we explore some solutions in a local\ncomputer setting; in addition, we explore the function of explainability for\ntransparency of AI models. We used the publicly available MIMIC-III database\nand the HAN/HLAN network models for ICD code prediction purposes. We also\nexperimented with the mapping between ICD and SNOMED CT knowledge bases. In our\nexperiments, the models provided useful information for 97.98\\% of codes. The\nresult of this investigation can shed some light on implementing automatic\nclinical coding in practice, such as in hospital settings, on the local\ncomputers used by clinicians , project page\n\\url{https://github.com/Glenj01/Medical-Coding}.", "published": "2024-07-18 16:12:47", "link": "http://arxiv.org/abs/2407.13638v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Weak-to-Strong Reasoning", "abstract": "When large language models (LLMs) exceed human-level capabilities, it becomes\nincreasingly challenging to provide full-scale and accurate supervision for\nthese models. Weak-to-strong learning, which leverages a less capable model to\nunlock the latent abilities of a stronger model, proves valuable in this\ncontext. Yet, the efficacy of this approach for complex reasoning tasks is\nstill untested. Furthermore, tackling reasoning tasks under the weak-to-strong\nsetting currently lacks efficient methods to avoid blindly imitating the weak\nsupervisor including its errors. In this paper, we introduce a progressive\nlearning framework that enables the strong model to autonomously refine its\ntraining data, without requiring input from either a more advanced model or\nhuman-annotated data. This framework begins with supervised fine-tuning on a\nselective small but high-quality dataset, followed by preference optimization\non contrastive samples identified by the strong model itself. Extensive\nexperiments on the GSM8K and MATH datasets demonstrate that our method\nsignificantly enhances the reasoning capabilities of Llama2-70b using three\nseparate weak models. This method is further validated in a forward-looking\nexperimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b\non the highly challenging OlympicArena dataset. This work paves the way for a\nmore scalable and sophisticated strategy to enhance AI reasoning powers. All\nrelevant code and resources are available in\n\\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.", "published": "2024-07-18 16:25:17", "link": "http://arxiv.org/abs/2407.13647v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Reference Policies in Direct Preference Optimization", "abstract": "Direct Preference Optimization (DPO) has become a widely used training method\nfor the instruction fine-tuning of large language models (LLMs). In this work,\nwe explore an under-investigated aspect of DPO - its dependency on the\nreference model or policy. Such reference policies, typically instantiated as\nthe model to be further fine-tuned, are important since they can impose an\nupper limit on DPO's effectiveness. Therefore, we address three related\nresearch questions in this work. First, we explore the optimal strength of the\nKL divergence constraint in DPO, which penalizes deviations from the reference\npolicy, and find that DPO is sensitive to this strength. Next, we examine the\nnecessity of the KL-constraint from the reference policies in DPO by providing\nboth theoretical and empirical comparisons between DPO and related learning\nobjectives, demonstrating DPO's superiority in this controlled setting.\nAdditionally, we investigate whether DPO benefits from stronger reference\npolicies, finding that a stronger reference policy can lead to improved\nperformance, but only when it is similar to the model being fine-tuned. Our\nfindings highlight the confounding role of reference policies in DPO and offer\ninsights for best practices, while also identifying open research questions for\nfuture studies.", "published": "2024-07-18 17:08:10", "link": "http://arxiv.org/abs/2407.13709v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs as Function Approximators: Terminology, Taxonomy, and Questions for\n  Evaluation", "abstract": "Natural Language Processing has moved rather quickly from modelling specific\ntasks to taking more general pre-trained models and fine-tuning them for\nspecific tasks, to a point where we now have what appear to be inherently\ngeneralist models. This paper argues that the resultant loss of clarity on what\nthese models model leads to metaphors like \"artificial general intelligences\"\nthat are not helpful for evaluating their strengths and weaknesses. The\nproposal is to see their generality, and their potential value, in their\nability to approximate specialist function, based on a natural language\nspecification. This framing brings to the fore questions of the quality of the\napproximation, but beyond that, also questions of discoverability, stability,\nand protectability of these functions. As the paper will show, this framing\nhence brings together in one conceptual framework various aspects of\nevaluation, both from a practical and a theoretical perspective, as well as\nquestions often relegated to a secondary status (such as \"prompt injection\" and\n\"jailbreaking\").", "published": "2024-07-18 17:49:56", "link": "http://arxiv.org/abs/2407.13744v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Latent Causal Probing: A Formal Perspective on Probing with Causal\n  Models of Data", "abstract": "As language models (LMs) deliver increasing performance on a range of NLP\ntasks, probing classifiers have become an indispensable technique in the effort\nto better understand their inner workings. A typical setup involves (1)\ndefining an auxiliary task consisting of a dataset of text annotated with\nlabels, then (2) supervising small classifiers to predict the labels from the\nrepresentations of a pretrained LM as it processed the dataset. A high probing\naccuracy is interpreted as evidence that the LM has learned to perform the\nauxiliary task as an unsupervised byproduct of its original pretraining\nobjective. Despite the widespread usage of probes, however, the robust design\nand analysis of probing experiments remains a challenge. We develop a formal\nperspective on probing using structural causal models (SCM). Specifically,\ngiven an SCM which explains the distribution of tokens observed during\ntraining, we frame the central hypothesis as whether the LM has learned to\nrepresent the latent variables of the SCM. Empirically, we extend a recent\nstudy of LMs in the context of a synthetic grid-world navigation task, where\nhaving an exact model of the underlying causal structure allows us to draw\nstrong inferences from the result of probing experiments. Our techniques\nprovide robust empirical evidence for the ability of LMs to induce the latent\nconcepts underlying text.", "published": "2024-07-18 17:59:27", "link": "http://arxiv.org/abs/2407.13765v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\"\n  Cycle", "abstract": "Recent innovations in language model training have demonstrated that it is\npossible to create highly performant models that are small enough to run on a\nsmartphone. As these models are deployed in an increasing number of domains, it\nis critical to ensure that they are aligned with human preferences and safety\nconsiderations. In this report, we present our methodology for safety aligning\nthe Phi-3 series of language models. We utilized a \"break-fix\" cycle,\nperforming multiple rounds of dataset curation, safety post-training,\nbenchmarking, red teaming, and vulnerability identification to cover a variety\nof harm areas in both single and multi-turn scenarios. Our results indicate\nthat this approach iteratively improved the performance of the Phi-3 models\nacross a wide range of responsible AI benchmarks. Finally, we include\nadditional red teaming strategies and evaluations that were used to test the\nsafety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for\nmultilingual capabilities.", "published": "2024-07-18 18:06:59", "link": "http://arxiv.org/abs/2407.13833v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "High Risk of Political Bias in Black Box Emotion Inference Models", "abstract": "This paper investigates the presence of political bias in emotion inference\nmodels used for sentiment analysis (SA) in social science research. Machine\nlearning models often reflect biases in their training data, impacting the\nvalidity of their outcomes. While previous research has highlighted gender and\nrace biases, our study focuses on political bias - an underexplored yet\npervasive issue that can skew the interpretation of text data across a wide\narray of studies. We conducted a bias audit on a Polish sentiment analysis\nmodel developed in our lab. By analyzing valence predictions for names and\nsentences involving Polish politicians, we uncovered systematic differences\ninfluenced by political affiliations. Our findings indicate that annotations by\nhuman raters propagate political biases into the model's predictions. To\nmitigate this, we pruned the training dataset of texts mentioning these\npoliticians and observed a reduction in bias, though not its complete\nelimination. Given the significant implications of political bias in SA, our\nstudy emphasizes caution in employing these models for social science research.\nWe recommend a critical examination of SA results and propose using\nlexicon-based systems as a more ideologically neutral alternative. This paper\nunderscores the necessity for ongoing scrutiny and methodological adjustments\nto ensure the reliability and impartiality of the use of machine learning in\nacademic and applied contexts.", "published": "2024-07-18 20:31:07", "link": "http://arxiv.org/abs/2407.13891v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction", "abstract": "This paper introduces Werewolf Arena, a novel framework for evaluating large\nlanguage models (LLMs) through the lens of the classic social deduction game,\nWerewolf. In Werewolf Arena, LLMs compete against each other, navigating the\ngame's complex dynamics of deception, deduction, and persuasion. The framework\nintroduces a dynamic turn-taking system based on bidding, mirroring real-world\ndiscussions where individuals strategically choose when to speak. We\ndemonstrate the framework's utility through an arena-style tournament featuring\nGemini and GPT models. Our results reveal distinct strengths and weaknesses in\nthe models' strategic reasoning and communication. These findings highlight\nWerewolf Arena's potential as a challenging and scalable LLM benchmark.", "published": "2024-07-18 23:41:05", "link": "http://arxiv.org/abs/2407.13943v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thought-Like-Pro: Enhancing Reasoning of Large Language Models through\n  Self-Driven Prolog-based Chain-of-Thought", "abstract": "Large language models (LLMs) have shown exceptional performance as\ngeneral-purpose assistants, excelling across a variety of reasoning tasks. This\nachievement represents a significant step toward achieving artificial general\nintelligence (AGI). Despite these advancements, the effectiveness of LLMs often\nhinges on the specific prompting strategies employed, and there remains a lack\nof a robust framework to facilitate learning and generalization across diverse\nreasoning tasks. To address these challenges, we introduce a novel learning\nframework, THOUGHT-LIKE-PRO In this framework, we utilize imitation learning to\nimitate the Chain-of-Thought (CoT) process which is verified and translated\nfrom reasoning trajectories generated by a symbolic Prolog logic engine. This\nframework proceeds in a self-driven manner, that enables LLMs to formulate\nrules and statements from given instructions and leverage the symbolic Prolog\nengine to derive results. Subsequently, LLMs convert Prolog-derived successive\nreasoning trajectories into natural language CoT for imitation learning. Our\nempirical findings indicate that our proposed approach substantially enhances\nthe reasoning abilities of LLMs and demonstrates robust generalization across\nout-of-distribution reasoning tasks.", "published": "2024-07-18 18:52:10", "link": "http://arxiv.org/abs/2407.14562v2", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "An Application of Large Language Models to Coding Negotiation\n  Transcripts", "abstract": "In recent years, Large Language Models (LLM) have demonstrated impressive\ncapabilities in the field of natural language processing (NLP). This paper\nexplores the application of LLMs in negotiation transcript analysis by the\nVanderbilt AI Negotiation Lab. Starting in September 2022, we applied multiple\nstrategies using LLMs from zero shot learning to fine tuning models to\nin-context learning). The final strategy we developed is explained, along with\nhow to access and use the model. This study provides a sense of both the\nopportunities and roadblocks for the implementation of LLMs in real life\napplications and offers a model for how LLMs can be applied to coding in other\nfields.", "published": "2024-07-18 17:05:59", "link": "http://arxiv.org/abs/2407.21037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A light-weight and efficient punctuation and word casing prediction\n  model for on-device streaming ASR", "abstract": "Punctuation and word casing prediction are necessary for automatic speech\nrecognition (ASR). With the popularity of on-device end-to-end streaming ASR\nsystems, the on-device punctuation and word casing prediction become a\nnecessity while we found little discussion on this. With the emergence of\nTransformer, Transformer based models have been explored for this scenario.\nHowever, Transformer based models are too large for on-device ASR systems. In\nthis paper, we propose a light-weight and efficient model that jointly predicts\npunctuation and word casing in real time. The model is based on Convolutional\nNeural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).\nExperimental results on the IWSLT2011 test set show that the proposed model\nobtains 9% relative improvement compared to the best of non-Transformer models\non overall F1-score. Compared to the representative of Transformer based\nmodels, the proposed model achieves comparable results to the representative\nmodel while being only one-fortieth its size and 2.5 times faster in terms of\ninference time. It is suitable for on-device streaming ASR systems. Our code is\npublicly available.", "published": "2024-07-18 04:01:12", "link": "http://arxiv.org/abs/2407.13142v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models for Anxiety and Depression\n  Classification using Counseling and Psychotherapy Transcripts", "abstract": "We aim to evaluate the efficacy of traditional machine learning and large\nlanguage models (LLMs) in classifying anxiety and depression from long\nconversational transcripts. We fine-tune both established transformer models\n(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained\na Support Vector Machine with feature engineering, and assessed GPT models\nthrough prompting. We observe that state-of-the-art models fail to enhance\nclassification outcomes compared to traditional machine learning methods.", "published": "2024-07-18 07:26:09", "link": "http://arxiv.org/abs/2407.13228v1", "categories": ["cs.CL", "cs.CY", "cs.ET", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-Resourced Speech Recognition for Iu Mien Language via\n  Weakly-Supervised Phoneme-based Multilingual Pre-training", "abstract": "The mainstream automatic speech recognition (ASR) technology usually requires\nhundreds to thousands of hours of annotated speech data. Three approaches to\nlow-resourced ASR are phoneme or subword based supervised pre-training, and\nself-supervised pre-training over multilingual data. The Iu Mien language is\nthe main ethnic language of the Yao ethnic group in China and is low-resourced\nin the sense that the annotated speech is very limited. With less than 10 hours\nof transcribed Iu Mien language, this paper investigates and compares the three\napproaches for Iu Mien speech recognition. Our experiments are based on the\nrecently released, three backbone models pretrained over the 10 languages from\nthe CommonVoice dataset (CV-Lang10), which correspond to the three approaches\nfor low-resourced ASR. It is found that phoneme supervision can achieve better\nresults compared to subword supervision and self-supervision, thereby providing\nhigher data-efficiency. Particularly, the Whistle models, i.e., obtained by the\nweakly-supervised phoneme-based multilingual pre-training, obtain the most\ncompetitive results.", "published": "2024-07-18 08:46:47", "link": "http://arxiv.org/abs/2407.13292v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis", "abstract": "The field of medical diagnosis has undergone a significant transformation\nwith the advent of large language models (LLMs), yet the challenges of\ninterpretability within these models remain largely unaddressed. This study\nintroduces Chain-of-Diagnosis (CoD) to enhance the interpretability of\nLLM-based medical diagnostics. CoD transforms the diagnostic process into a\ndiagnostic chain that mirrors a physician's thought process, providing a\ntransparent reasoning pathway. Additionally, CoD outputs the disease confidence\ndistribution to ensure transparency in decision-making. This interpretability\nmakes model diagnostics controllable and aids in identifying critical symptoms\nfor inquiry through the entropy reduction of confidences. With CoD, we\ndeveloped DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental\nresults demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic\nbenchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring\ncontrollability in diagnostic rigor.", "published": "2024-07-18 09:06:27", "link": "http://arxiv.org/abs/2407.13301v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Linear-Complexity Self-Supervised Learning for Speech Processing", "abstract": "Self-supervised learning (SSL) models usually require weeks of pre-training\nwith dozens of high-end GPUs. These models typically have a multi-headed\nself-attention (MHSA) context encoder. However, MHSA takes quadratic time and\nspace in the input length, contributing to the high pre-training cost.\nLinear-complexity alternatives to MHSA have been proposed. For instance, in\nsupervised training, the SummaryMixing model is the first to outperform MHSA\nacross multiple speech processing tasks. However, these cheaper alternatives\nhave not been explored for SSL yet. This paper studies a linear-complexity\ncontext encoder for SSL for the first time. With better or equivalent\nperformance for the downstream tasks of the MP3S benchmark, SummaryMixing\nreduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by\n23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model\nfinished within one week with 4 Tesla A100 GPUs. Code is available at\nhttps://github.com/SamsungLabs/SummaryMixing.", "published": "2024-07-18 10:34:33", "link": "http://arxiv.org/abs/2407.13377v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Correcting the Mythos of KL-Regularization: Direct Alignment without\n  Overoptimization via Chi-Squared Preference Optimization", "abstract": "Language model alignment methods such as reinforcement learning from human\nfeedback (RLHF) have led to impressive advances in language model capabilities,\nbut are limited by a widely observed phenomenon known as overoptimization,\nwhere the quality of the language model degrades over the course of the\nalignment process. As the model optimizes performance with respect to an\noffline reward model, it overfits to inaccuracies and drifts away from\npreferred responses covered by the data. To discourage such distribution shift,\nKL-regularization is widely employed in existing offline alignment methods, but\noveroptimization continues to harm performance. Lending theoretical insight\ninto the source of these empirical observations, we first show that the\nKL-regularization is too weak to prevent overfitting, then raise the following\nquestion: is it possible to design an efficient algorithm that is provably\nrobust to overoptimization?\n  We address this question with a new algorithm for offline alignment,\n$\\chi^2$-Preference Optimization ($\\chi$PO). $\\chi$PO is a one-line change to\nDirect Preference Optimization (DPO; Rafailov et al., 2023), which only\ninvolves modifying the logarithmic link function in the DPO objective. Despite\nthis minimal change, $\\chi$PO implicitly implements the principle of pessimism\nin the face of uncertainty via regularization with the $\\chi^2$-divergence --\nwhich quantifies uncertainty more effectively than KL-regularization -- and\nprovably alleviates overoptimization, achieving sample-complexity guarantees\nbased on single-policy concentrability -- the gold standard in offline\nreinforcement learning. $\\chi$PO's simplicity and strong guarantees make it the\nfirst practical and general-purpose offline alignment algorithm that is\nprovably robust to overoptimization.", "published": "2024-07-18 11:08:40", "link": "http://arxiv.org/abs/2407.13399v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "From Words to Worlds: Compositionality for Cognitive Architectures", "abstract": "Large language models (LLMs) are very performant connectionist systems, but\ndo they exhibit more compositionality? More importantly, is that part of why\nthey perform so well? We present empirical analyses across four LLM families\n(12 models) and three task categories, including a novel task introduced below.\nOur findings reveal a nuanced relationship in learning of compositional\nstrategies by LLMs -- while scaling enhances compositional abilities,\ninstruction tuning often has a reverse effect. Such disparity brings forth some\nopen issues regarding the development and improvement of large language models\nin alignment with human cognitive capacities.", "published": "2024-07-18 11:42:13", "link": "http://arxiv.org/abs/2407.13419v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for\n  Practical Applications through Low-Effort Data Strategies", "abstract": "Publicly available TTS datasets for low-resource languages like Hindi and\nTamil typically contain 10-20 hours of data, leading to poor vocabulary\ncoverage. This limitation becomes evident in downstream applications where\ndomain-specific vocabulary coupled with frequent code-mixing with English,\nresults in many OOV words. To highlight this problem, we create a benchmark\ncontaining OOV words from several real-world applications. Indeed,\nstate-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV\nbenchmark, as indicated by intelligibility tests. To improve the model's OOV\nperformance, we propose a low-effort and economically viable strategy to obtain\nmore training data. Specifically, we propose using volunteers as opposed to\nhigh quality voice artists to record words containing character bigrams unseen\nin the training data. We show that using such inexpensive data, the model's\nperformance improves on OOV words, while not affecting voice quality and\nin-domain performance.", "published": "2024-07-18 12:03:14", "link": "http://arxiv.org/abs/2407.13435v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous\n  Behaviors Based on Language Models", "abstract": "Spontaneous style speech synthesis, which aims to generate human-like speech,\noften encounters challenges due to the scarcity of high-quality data and\nlimitations in model capabilities. Recent language model-based TTS systems can\nbe trained on large, diverse, and low-quality speech datasets, resulting in\nhighly natural synthesized speech. However, they are limited by the difficulty\nof simulating various spontaneous behaviors and capturing prosody variations in\nspontaneous speech. In this paper, we propose a novel spontaneous speech\nsynthesis system based on language models. We systematically categorize and\nuniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody\nmodeling is introduced to enhance the model's ability to capture subtle prosody\nvariations in spontaneous speech.Experimental results show that our proposed\nmethod significantly outperforms the baseline methods in terms of prosody\nnaturalness and spontaneous behavior naturalness.", "published": "2024-07-18 13:42:38", "link": "http://arxiv.org/abs/2407.13509v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting\n  Recognition", "abstract": "Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)\npose unique challenges due to the cursive and context-sensitive nature of the\nArabic script. This study introduces Qalam, a novel foundation model designed\nfor Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder\narchitecture. Our model significantly outperforms existing methods, achieving a\nWord Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We\ntrain Qalam on a diverse dataset, including over 4.5 million images from Arabic\nmanuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,\nQalam demonstrates exceptional handling of Arabic diacritics, a critical\nfeature in Arabic scripts. Furthermore, it shows a remarkable ability to\nprocess high-resolution inputs, addressing a common limitation in current OCR\nsystems. These advancements underscore Qalam's potential as a leading solution\nfor Arabic script recognition, offering a significant leap in accuracy and\nefficiency.", "published": "2024-07-18 14:31:09", "link": "http://arxiv.org/abs/2407.13559v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Scaling Granite Code Models to 128K Context", "abstract": "This paper introduces long-context Granite code models that support effective\ncontext windows of up to 128K tokens. Our solution for scaling context length\nof Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight\ncontinual pretraining by gradually increasing its RoPE base frequency with\nrepository-level file packing and length-upsampled long-context data.\nAdditionally, we also release instruction-tuned models with long-context\nsupport which are derived by further finetuning the long context base models on\na mix of permissively licensed short and long-context instruction-response\npairs. While comparing to the original short-context Granite code models, our\nlong-context models achieve significant improvements on long-context tasks\nwithout any noticeable performance degradation on regular code completion\nbenchmarks (e.g., HumanEval). We release all our long-context Granite code\nmodels under an Apache 2.0 license for both research and commercial use.", "published": "2024-07-18 17:46:02", "link": "http://arxiv.org/abs/2407.13739v1", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation\n  of Large Language Models", "abstract": "Retrieval-Augmented Generation (RAG) is applied to solve hallucination\nproblems and real-time constraints of large language models, but it also\ninduces vulnerabilities against retrieval corruption attacks. Existing research\nmainly explores the unreliability of RAG in white-box and closed-domain QA\ntasks. In this paper, we aim to reveal the vulnerabilities of\nRetrieval-Enhanced Generative (RAG) models when faced with black-box attacks\nfor opinion manipulation. We explore the impact of such attacks on user\ncognition and decision-making, providing new insight to enhance the reliability\nand security of RAG models. We manipulate the ranking results of the retrieval\nmodel in RAG with instruction and use these results as data to train a\nsurrogate model. By employing adversarial retrieval attack methods to the\nsurrogate model, black-box transfer attacks on RAG are further realized.\nExperiments conducted on opinion datasets across multiple topics show that the\nproposed attack strategy can significantly alter the opinion polarity of the\ncontent generated by RAG. This demonstrates the model's vulnerability and, more\nimportantly, reveals the potential negative impact on user cognition and\ndecision-making, making it easier to mislead users into accepting incorrect or\nbiased information.", "published": "2024-07-18 17:55:55", "link": "http://arxiv.org/abs/2407.13757v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Crafting Efficient Fine-Tuning Strategies for Large Language Models", "abstract": "This paper addresses the challenges of efficiently fine-tuning large language\nmodels (LLMs) by exploring data efficiency and hyperparameter optimization. We\ninvestigate the minimum data required for effective fine-tuning and propose a\nnovel hyperparameter optimization method that leverages early-stage model\nperformance. Our experiments demonstrate that fine-tuning with as few as 200\nsamples can improve model accuracy from 70\\% to 88\\% in a product attribute\nextraction task. We identify a saturation point of approximately 6,500 samples,\nbeyond which additional data yields diminishing returns. Our proposed bayesian\nhyperparameter optimization method, which evaluates models at 20\\% of total\ntraining time, correlates strongly with final model performance, with 4 out of\n5 top early-stage models remaining in the top 5 at completion. This approach\nled to a 2\\% improvement in accuracy over baseline models when evaluated on an\nindependent test set. These findings offer actionable insights for\npractitioners, potentially reducing computational load and dependency on\nextensive datasets while enhancing overall performance of fine-tuned LLMs.", "published": "2024-07-18 21:36:00", "link": "http://arxiv.org/abs/2407.13906v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mechanical Self-replication", "abstract": "This study presents a theoretical model for a self-replicating mechanical\nsystem inspired by biological processes within living cells and supported by\ncomputer simulations. The model decomposes self-replication into core\ncomponents, each of which is executed by a single machine constructed from a\nset of basic block types. Key functionalities such as sorting, copying, and\nbuilding, are demonstrated. The model provides valuable insights into the\nconstraints of self-replicating systems. The discussion also addresses the\nspatial and timing behavior of the system, as well as its efficiency and\ncomplexity. This work provides a foundational framework for future studies on\nself-replicating mechanisms and their information-processing applications.", "published": "2024-07-18 09:49:50", "link": "http://arxiv.org/abs/2407.14556v2", "categories": ["q-bio.OT", "cs.CL", "physics.bio-ph"], "primary_category": "q-bio.OT"}
{"title": "Handling Numeric Expressions in Automatic Speech Recognition", "abstract": "This paper addresses the problem of correctly formatting numeric expressions\nin automatic speech recognition (ASR) transcripts. This is challenging since\nthe expected transcript format depends on the context, e.g., 1945 (year) vs.\n19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize\nand format numeric expression, such as years, timestamps, currency amounts, and\nquantities. For the end-to-end approach we employed a data generation strategy\nusing a large language model (LLM) together with a text to speech (TTS) model\nto generate adaptation data. The results on our test dataset show that while\napproaches based on LLMs perform well on recognizing formatted numeric\nexpressions, adapted end-to-end models offer competitive performance with the\nadvantage of lower latency and inference cost.", "published": "2024-07-18 09:46:19", "link": "http://arxiv.org/abs/2408.00004v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation\n  Systems", "abstract": "In recent years, there has been increased demand for speech-to-speech\ntranslation (S2ST) systems in industry settings. Although successfully\ncommercialized, cloning-based S2ST systems expose their distributors to\nliabilities when misused by individuals and can infringe on personality rights\nwhen exploited by media organizations. This work proposes a regulated S2ST\nframework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice\ncloning in S2ST by first matching the input voice to a similar prior consenting\nspeaker voice in the target-language. With this separation, PVM avoids cloning\nthe input speaker, ensuring PVM systems comply with regulations and reduce risk\nof misuse. Our results demonstrate PVM can significantly improve S2ST system\nrun-time in multi-speaker settings and the naturalness of S2ST synthesized\nspeech. To our knowledge, PVM is the first explicitly regulated S2ST framework\nleveraging similarly-matched preset-voices for dynamic S2ST tasks.", "published": "2024-07-18 04:42:01", "link": "http://arxiv.org/abs/2407.13153v1", "categories": ["cs.CL", "cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Framework for Curating Speech Datasets and Evaluating ASR Systems: A\n  Case Study for Polish", "abstract": "Speech datasets available in the public domain are often underutilized\nbecause of challenges in discoverability and interoperability. A comprehensive\nframework has been designed to survey, catalog, and curate available speech\ndatasets, which allows replicable evaluation of automatic speech recognition\n(ASR) systems. A case study focused on the Polish language was conducted; the\nframework was applied to curate more than 24 datasets and evaluate 25\ncombinations of ASR systems and models. This research constitutes the most\nextensive comparison to date of both commercial and free ASR systems for the\nPolish language. It draws insights from 600 system-model-test set evaluations,\nmarking a significant advancement in both scale and comprehensiveness. The\nresults of surveys and performance comparisons are available as interactive\ndashboards (https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard) along\nwith curated datasets (https://huggingface.co/datasets/amu-cai/pl-asr-bigos-v2,\nhttps://huggingface.co/datasets/pelcra/pl-asr-pelcra-for-bigos) and the open\nchallenge call (https://poleval.pl/tasks/task3). Tools used for evaluation are\nopen-sourced (https://github.com/goodmike31/pl-asr-bigos-tools), facilitating\nreplication and adaptation for other languages, as well as continuous expansion\nwith new datasets and systems.", "published": "2024-07-18 21:32:12", "link": "http://arxiv.org/abs/2408.00005v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Semi-Supervised Contrastive Learning of Musical Representations", "abstract": "Despite the success of contrastive learning in Music Information Retrieval,\nthe inherent ambiguity of contrastive self-supervision presents a challenge.\nRelying solely on augmentation chains and self-supervised positive sampling\nstrategies can lead to a pretraining objective that does not capture key\nmusical information for downstream tasks. We introduce semi-supervised\ncontrastive learning (SemiSupCon), a simple method for leveraging musically\ninformed labeled data (supervision signals) in the contrastive learning of\nmusical representations. Our approach introduces musically relevant supervision\nsignals into self-supervised contrastive learning by combining supervised and\nself-supervised contrastive objectives in a simpler framework than previous\napproaches. This framework improves downstream performance and robustness to\naudio corruptions on a range of downstream MIR tasks with moderate amounts of\nlabeled data. Our approach enables shaping the learned similarity metric\nthrough the choice of labeled data that (1) infuses the representations with\nmusical domain knowledge and (2) improves out-of-domain performance with\nminimal general downstream performance loss. We show strong transfer learning\nperformance on musically related yet not trivially similar tasks - such as\npitch and key estimation. Additionally, our approach shows performance\nimprovement on automatic tagging over self-supervised approaches with only 5\\%\nof available labels included in pretraining.", "published": "2024-07-18 18:21:40", "link": "http://arxiv.org/abs/2407.13840v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving the Robustness and Clinical Applicability of Automatic\n  Respiratory Sound Classification Using Deep Learning-Based Audio Enhancement:\n  Algorithm Development and Validation", "abstract": "Deep learning techniques have shown promising results in the automatic\nclassification of respiratory sounds. However, accurately distinguishing these\nsounds in real-world noisy conditions remains challenging for clinical\ndeployment. In addition, predicting signals with only background noise may\nreduce user trust in the system. This study explores the feasibility and\neffectiveness of incorporating a deep learning-based audio enhancement step\ninto automatic respiratory sound classification systems to improve robustness\nand clinical applicability. We conducted extensive experiments using various\naudio enhancement model architectures, including time-domain and\ntime-frequency-domain approaches, combined with multiple classification models\nto evaluate the module's effectiveness. The classification performance was\ncompared against the noise injection data augmentation method. These\nexperiments were carried out on two datasets: the ICBHI respiratory sound\ndataset and the FABS dataset. Furthermore, a physician validation study\nassessed the system's clinical utility. Integrating the audio enhancement\nmodule resulted in a 21.9% increase in the ICBHI classification score and a\n4.1% improvement on the FABS dataset in multi-class noisy scenarios.\nQuantitative analysis revealed efficiency gains, higher diagnostic confidence,\nand increased trust, with workflows using enhanced audio improving diagnostic\nsensitivity by 11.6% and enabling high-confidence diagnoses. Incorporating an\naudio enhancement algorithm boosts the robustness and clinical utility of\nautomatic respiratory sound classification systems, enhancing performance in\nnoisy environments and fostering greater trust among medical professionals.", "published": "2024-07-18 20:48:33", "link": "http://arxiv.org/abs/2407.13895v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DiveSound: LLM-Assisted Automatic Taxonomy Construction for Diverse\n  Audio Generation", "abstract": "Audio generation has attracted significant attention. Despite remarkable\nenhancement in audio quality, existing models overlook diversity evaluation.\nThis is partially due to the lack of a systematic sound class diversity\nframework and a matching dataset. To address these issues, we propose\nDiveSound, a novel framework for constructing multimodal datasets with in-class\ndiversified taxonomy, assisted by large language models. As both textual and\nvisual information can be utilized to guide diverse generation, DiveSound\nleverages multimodal contrastive representations in data construction. Our\nframework is highly autonomous and can be easily scaled up. We provide a\ntextaudio-image aligned diversity dataset whose sound event class tags have an\naverage of 2.42 subcategories. Text-to-audio experiments on the constructed\ndataset show a substantial increase of diversity with the help of the guidance\nof visual information.", "published": "2024-07-18 06:23:34", "link": "http://arxiv.org/abs/2407.13198v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MEDIC: Zero-shot Music Editing with Disentangled Inversion Control", "abstract": "Text-guided diffusion models make a paradigm shift in audio generation,\nfacilitating the adaptability of source audio to conform to specific textual\nprompts. Recent works introduce inversion techniques, like DDIM inversion, to\nzero-shot editing, exploiting pretrained diffusion models for audio\nmodification. Nonetheless, our investigation exposes that DDIM inversion\nsuffers from an accumulation of errors across each diffusion step, undermining\nits efficacy. Moreover, existing editing methods fail to achieve effective\ncomplex non-rigid music editing while maintaining essential content\npreservation and high editing fidelity. To counteract these issues, we\nintroduce the Disentangled Inversion technique to disentangle the diffusion\nprocess into triple branches, rectifying the deviated path of the source branch\ncaused by DDIM inversion. In addition, we propose the Harmonized Attention\nControl framework, which unifies the mutual self-attention control and\ncross-attention control with an intermediate Harmonic Branch to progressively\nachieve the desired harmonic and melodic information in the target music.\nCollectively, these innovations comprise the Disentangled Inversion Control\n(DIC) framework, enabling accurate music editing while safeguarding content\nintegrity. To benchmark audio editing efficacy, we introduce ZoME-Bench, a\ncomprehensive music editing benchmark hosting 1,100 samples spread across ten\ndistinct editing categories. This facilitates both zero-shot and\ninstruction-based music editing tasks. Our method achieves unparalleled\nperformance in edit fidelity and essential content preservation, outperforming\ncontemporary state-of-the-art inversion techniques.", "published": "2024-07-18 07:05:43", "link": "http://arxiv.org/abs/2407.13220v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fade-in Reverberation in Multi-room Environments Using the Common-Slope\n  Model", "abstract": "In multi-room environments, modelling the sound propagation is complex due to\nthe coupling of rooms and diverse source-receiver positions. A common scenario\nis when the source and the receiver are in different rooms without a clear line\nof sight. For such source-receiver configurations, an initial increase in\nenergy is observed, referred to as the \"fade-in\" of reverberation. Based on\nrecent work of representing inhomogeneous and anisotropic reverberation with\ncommon decay times, this work proposes an extended parametric model that\nenables the modelling of the fade-in phenomenon. The method performs fitting on\nthe envelopes, instead of energy decay functions, and allows negative\namplitudes of decaying exponentials. We evaluate the method on simulated and\nmeasured multi-room environments, where we show that the proposed approach can\nnow model the fade-ins that were unrealisable with the previous method.", "published": "2024-07-18 07:51:11", "link": "http://arxiv.org/abs/2407.13242v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Using Speech Foundational Models in Loss Functions for Hearing Aid\n  Speech Enhancement", "abstract": "Machine learning techniques are an active area of research for speech\nenhancement for hearing aids, with one particular focus on improving the\nintelligibility of a noisy speech signal. Recent work has shown that feature\nencodings from self-supervised speech representation models can effectively\ncapture speech intelligibility. In this work, it is shown that the distance\nbetween self-supervised speech representations of clean and noisy speech\ncorrelates more strongly with human intelligibility ratings than other\nsignal-based metrics. Experiments show that training a speech enhancement model\nusing this distance as part of a loss function improves the performance over\nusing an SNR-based loss function, demonstrated by an increase in HASPI, STOI,\nPESQ and SI-SNR scores. This method takes inference of a high parameter count\nmodel only at training time, meaning the speech enhancement model can remain\nsmaller, as is required for hearing aids.", "published": "2024-07-18 09:32:57", "link": "http://arxiv.org/abs/2407.13333v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Accurate Mapping of RNNs on Neuromorphic Hardware with Adaptive Spiking\n  Neurons", "abstract": "Thanks to their parallel and sparse activity features, recurrent neural\nnetworks (RNNs) are well-suited for hardware implementation in low-power\nneuromorphic hardware. However, mapping rate-based RNNs to hardware-compatible\nspiking neural networks (SNNs) remains challenging. Here, we present a\n${\\Sigma}{\\Delta}$-low-pass RNN (lpRNN): an RNN architecture employing an\nadaptive spiking neuron model that encodes signals using\n${\\Sigma}{\\Delta}$-modulation and enables precise mapping. The\n${\\Sigma}{\\Delta}$-neuron communicates analog values using spike timing, and\nthe dynamics of the lpRNN are set to match typical timescales for processing\nnatural signals, such as speech. Our approach integrates rate and temporal\ncoding, offering a robust solution for the efficient and accurate conversion of\nRNNs to SNNs. We demonstrate the implementation of the lpRNN on Intel's\nneuromorphic research chip Loihi, achieving state-of-the-art classification\nresults on audio benchmarks using 3-bit weights. These results call for a\ndeeper investigation of recurrency and adaptation in event-based systems, which\nmay lead to insights for edge computing applications where power-efficient\nreal-time inference is required.", "published": "2024-07-18 14:06:07", "link": "http://arxiv.org/abs/2407.13534v1", "categories": ["cs.NE", "eess.AS"], "primary_category": "cs.NE"}
{"title": "Modeling and Driving Human Body Soundfields through Acoustic Primitives", "abstract": "While rendering and animation of photorealistic 3D human body models have\nmatured and reached an impressive quality over the past years, modeling the\nspatial audio associated with such full body models has been largely ignored so\nfar. In this work, we present a framework that allows for high-quality spatial\naudio generation, capable of rendering the full 3D soundfield generated by a\nhuman body, including speech, footsteps, hand-body interactions, and others.\nGiven a basic audio-visual representation of the body in form of 3D body pose\nand audio from a head-mounted microphone, we demonstrate that we can render the\nfull acoustic scene at any point in 3D space efficiently and accurately. To\nenable near-field and realtime rendering of sound, we borrow the idea of\nvolumetric primitives from graphical neural rendering and transfer them into\nthe acoustic domain. Our acoustic primitives result in an order of magnitude\nsmaller soundfield representations and overcome deficiencies in near-field\nrendering compared to previous approaches.", "published": "2024-07-18 01:05:13", "link": "http://arxiv.org/abs/2407.13083v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the\n  State-of-the-art", "abstract": "This paper comprehensively reviews recent advances in underwater acoustic\nsignal denoising, an area critical for improving the reliability and clarity of\nunderwater communication and monitoring systems. Despite significant progress\nin the field, the complex nature of underwater environments poses unique\nchallenges that complicate the denoising process. We begin by outlining the\nfundamental challenges associated with underwater acoustic signal processing,\nincluding signal attenuation, noise variability, and the impact of\nenvironmental factors. The review then systematically categorizes and discusses\nvarious denoising algorithms, such as conventional, decomposition-based, and\nlearning-based techniques, highlighting their applications, advantages, and\nlimitations. Evaluation metrics and experimental datasets are also reviewed.\nThe paper concludes with a list of open questions and recommendations for\nfuture research directions, emphasizing the need for developing more robust\ndenoising techniques that can adapt to the dynamic underwater acoustic\nenvironment.", "published": "2024-07-18 08:14:59", "link": "http://arxiv.org/abs/2407.13264v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "How Private is Low-Frequency Speech Audio in the Wild? An Analysis of\n  Verbal Intelligibility by Humans and Machines", "abstract": "Low-frequency audio has been proposed as a promising privacy-preserving\nmodality to study social dynamics in real-world settings. To this end,\nresearchers have developed wearable devices that can record audio at\nfrequencies as low as 1250 Hz to mitigate the automatic extraction of the\nverbal content of speech that may contain private details. This paper\ninvestigates the validity of this hypothesis, examining the degree to which\nlow-frequency speech ensures verbal privacy. It includes simulating a potential\nprivacy attack in various noise environments. Further, it explores the\ntrade-off between the performance of voice activity detection, which is\nfundamental for understanding social behavior, and privacy-preservation. The\nevaluation incorporates subjective human intelligibility and automatic speech\nrecognition performance, comprehensively analyzing the delicate balance between\neffective social behavior analysis and preserving verbal privacy.", "published": "2024-07-18 08:16:56", "link": "http://arxiv.org/abs/2407.13266v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reducing Barriers to the Use of Marginalised Music Genres in AI", "abstract": "AI systems for high quality music generation typically rely on extremely\nlarge musical datasets to train the AI models. This creates barriers to\ngenerating music beyond the genres represented in dominant datasets such as\nWestern Classical music or pop music. We undertook a 4 month international\nresearch project summarised in this paper to explore the eXplainable AI (XAI)\nchallenges and opportunities associated with reducing barriers to using\nmarginalised genres of music with AI models. XAI opportunities identified\nincluded topics of improving transparency and control of AI models, explaining\nthe ethics and bias of AI models, fine tuning large models with small datasets\nto reduce bias, and explaining style-transfer opportunities with AI models.\nParticipants in the research emphasised that whilst it is hard to work with\nsmall datasets such as marginalised music and AI, such approaches strengthen\ncultural representation of underrepresented cultures and contribute to\naddressing issues of bias of deep learning models. We are now building on this\nproject to bring together a global International Responsible AI Music community\nand invite people to join our network.", "published": "2024-07-18 12:10:04", "link": "http://arxiv.org/abs/2407.13439v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CogniVoice: Multimodal and Multilingual Fusion Networks for Mild\n  Cognitive Impairment Assessment from Spontaneous Speech", "abstract": "Mild Cognitive Impairment (MCI) is a medical condition characterized by\nnoticeable declines in memory and cognitive abilities, potentially affecting\nindividual's daily activities. In this paper, we introduce CogniVoice, a novel\nmultilingual and multimodal framework to detect MCI and estimate Mini-Mental\nState Examination (MMSE) scores by analyzing speech data and its textual\ntranscriptions. The key component of CogniVoice is an ensemble multimodal and\nmultilingual network based on ``Product of Experts'' that mitigates reliance on\nshortcut solutions. Using a comprehensive dataset containing both English and\nChinese languages from TAUKADIAL challenge, CogniVoice outperforms the best\nperforming baseline model on MCI classification and MMSE regression tasks by\n2.8 and 4.1 points in F1 and RMSE respectively, and can effectively reduce the\nperformance gap across different language groups by 0.7 points in F1.", "published": "2024-07-18 16:38:24", "link": "http://arxiv.org/abs/2407.13660v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Aligning Sight and Sound: Advanced Sound Source Localization Through\n  Audio-Visual Alignment", "abstract": "Recent studies on learning-based sound source localization have mainly\nfocused on the localization performance perspective. However, prior work and\nexisting benchmarks overlook a crucial aspect: cross-modal interaction, which\nis essential for interactive sound source localization. Cross-modal interaction\nis vital for understanding semantically matched or mismatched audio-visual\nevents, such as silent objects or off-screen sounds. In this paper, we first\ncomprehensively examine the cross-modal interaction of existing methods,\nbenchmarks, evaluation metrics, and cross-modal understanding tasks. Then, we\nidentify the limitations of previous studies and make several contributions to\novercome the limitations. First, we introduce a new synthetic benchmark for\ninteractive sound source localization. Second, we introduce new evaluation\nmetrics to rigorously assess sound source localization methods, focusing on\naccurately evaluating both localization performance and cross-modal interaction\nability. Third, we propose a learning framework with a cross-modal alignment\nstrategy to enhance cross-modal interaction. Lastly, we evaluate both\ninteractive sound source localization and auxiliary cross-modal retrieval tasks\ntogether to thoroughly assess cross-modal interaction capabilities and\nbenchmark competing methods. Our new benchmarks and evaluation metrics reveal\npreviously overlooked issues in sound source localization studies. Our proposed\nnovel method, with enhanced cross-modal alignment, shows superior sound source\nlocalization performance. This work provides the most comprehensive analysis of\nsound source localization to date, with extensive validation of competing\nmethods on both existing and new benchmarks using new and standard evaluation\nmetrics.", "published": "2024-07-18 16:51:15", "link": "http://arxiv.org/abs/2407.13676v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Audio-visual Generalized Zero-shot Learning the Easy Way", "abstract": "Audio-visual generalized zero-shot learning is a rapidly advancing domain\nthat seeks to understand the intricate relations between audio and visual cues\nwithin videos. The overarching goal is to leverage insights from seen classes\nto identify instances from previously unseen ones. Prior approaches primarily\nutilized synchronized auto-encoders to reconstruct audio-visual attributes,\nwhich were informed by cross-attention transformers and projected text\nembeddings. However, these methods fell short of effectively capturing the\nintricate relationship between cross-modal features and class-label embeddings\ninherent in pre-trained language-aligned embeddings. To circumvent these\nbottlenecks, we introduce a simple yet effective framework for Easy\nAudio-Visual Generalized Zero-shot Learning, named EZ-AVGZL, that aligns\naudio-visual embeddings with transformed text representations. It utilizes a\nsingle supervised text audio-visual contrastive loss to learn an alignment\nbetween audio-visual and textual modalities, moving away from the conventional\napproach of reconstructing cross-modal features and text embeddings. Our key\ninsight is that while class name embeddings are well aligned with\nlanguage-based audio-visual features, they don't provide sufficient class\nseparation to be useful for zero-shot learning. To address this, our method\nleverages differential optimization to transform class embeddings into a more\ndiscriminative space while preserving the semantic structure of language\nrepresentations. We conduct extensive experiments on VGGSound-GZSL, UCF-GZSL,\nand ActivityNet-GZSL benchmarks. Our results demonstrate that our EZ-AVGZL\nachieves state-of-the-art performance in audio-visual generalized zero-shot\nlearning.", "published": "2024-07-18 01:57:16", "link": "http://arxiv.org/abs/2407.13095v1", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
