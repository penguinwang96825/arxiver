{"title": "Logic Mill -- A Knowledge Navigation System", "abstract": "Logic Mill is a scalable and openly accessible software system that\nidentifies semantically similar documents within either one domain-specific\ncorpus or multi-domain corpora. It uses advanced Natural Language Processing\n(NLP) techniques to generate numerical representations of documents. Currently\nit leverages a large pre-trained language model to generate these document\nrepresentations. The system focuses on scientific publications and patent\ndocuments and contains more than 200 million documents. It is easily accessible\nvia a simple Application Programming Interface (API) or via a web interface.\nMoreover, it is continuously being updated and can be extended to text corpora\nfrom other domains. We see this system as a general-purpose tool for future\nresearch applications in the social sciences and other domains.", "published": "2022-12-31 13:46:50", "link": "http://arxiv.org/abs/2301.00200v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on In-context Learning", "abstract": "With the increasing capabilities of large language models (LLMs), in-context\nlearning (ICL) has emerged as a new paradigm for natural language processing\n(NLP), where LLMs make predictions based on contexts augmented with a few\nexamples. It has been a significant trend to explore ICL to evaluate and\nextrapolate the ability of LLMs. In this paper, we aim to survey and summarize\nthe progress and challenges of ICL. We first present a formal definition of ICL\nand clarify its correlation to related studies. Then, we organize and discuss\nadvanced techniques, including training strategies, prompt designing\nstrategies, and related analysis. Additionally, we explore various ICL\napplication scenarios, such as data engineering and knowledge updating.\nFinally, we address the challenges of ICL and suggest potential directions for\nfurther research. We hope that our work can encourage more research on\nuncovering how ICL works and improving ICL.", "published": "2022-12-31 15:57:09", "link": "http://arxiv.org/abs/2301.00234v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking with Retrieval: Faithful Large Language Model Inference", "abstract": "Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs.", "published": "2022-12-31 22:35:34", "link": "http://arxiv.org/abs/2301.00303v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Proactively Forecasting Sentence-Specific Information Popularity\n  within Online News Documents", "abstract": "Multiple studies have focused on predicting the prospective popularity of an\nonline document as a whole, without paying attention to the contributions of\nits individual parts. We introduce the task of proactively forecasting\npopularities of sentences within online news documents solely utilizing their\nnatural language content. We model sentence-specific popularity forecasting as\na sequence regression task. For training our models, we curate InfoPop, the\nfirst dataset containing popularity labels for over 1.7 million sentences from\nover 50,000 online news documents. To the best of our knowledge, this is the\nfirst dataset automatically created using streams of incoming search engine\nqueries to generate sentence-level popularity annotations. We propose a novel\ntransfer learning approach involving sentence salience prediction as an\nauxiliary task. Our proposed technique coupled with a BERT-based neural model\nexceeds nDCG values of 0.8 for proactive sentence-specific popularity\nforecasting. Notably, our study presents a non-trivial takeaway: though\npopularity and salience are different concepts, transfer learning from salience\nprediction enhances popularity forecasting. We release InfoPop and make our\ncode publicly available: https://github.com/sayarghoshroy/InfoPopularity", "published": "2022-12-31 08:40:08", "link": "http://arxiv.org/abs/2301.00152v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sample-Efficient Unsupervised Domain Adaptation of Speech Recognition\n  Systems A case study for Modern Greek", "abstract": "Modern speech recognition systems exhibits rapid performance degradation\nunder domain shift. This issue is especially prevalent in data-scarce settings,\nsuch as low-resource languages, where diversity of training data is limited. In\nthis work we propose M2DS2, a simple and sample-efficient finetuning strategy\nfor large pretrained speech models, based on mixed source and target domain\nself-supervision. We find that including source domain self-supervision\nstabilizes training and avoids mode collapse of the latent representations. For\nevaluation, we collect HParl, a $120$ hour speech corpus for Greek, consisting\nof plenary sessions in the Greek Parliament. We merge HParl with two popular\nGreek corpora to create GREC-MD, a test-bed for multi-domain evaluation of\nGreek ASR systems. In our experiments we find that, while other Unsupervised\nDomain Adaptation baselines fail in this resource-constrained environment,\nM2DS2 yields significant improvements for cross-domain adaptation, even when a\nonly a few hours of in-domain audio are available. When we relax the problem in\na weakly supervised setting, we find that independent adaptation for audio\nusing M2DS2 and language using simple LM augmentation techniques is\nparticularly effective, yielding word error rates comparable to the fully\nsupervised baselines.", "published": "2022-12-31 22:57:30", "link": "http://arxiv.org/abs/2301.00304v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Computational Charisma -- A Brick by Brick Blueprint for Building\n  Charismatic Artificial Intelligence", "abstract": "Charisma is considered as one's ability to attract and potentially also\ninfluence others. Clearly, there can be considerable interest from an\nartificial intelligence's (AI) perspective to provide it with such skill.\nBeyond, a plethora of use cases opens up for computational measurement of human\ncharisma, such as for tutoring humans in the acquisition of charisma, mediating\nhuman-to-human conversation, or identifying charismatic individuals in big\nsocial data. A number of models exist that base charisma on various dimensions,\noften following the idea that charisma is given if someone could and would help\nothers. Examples include influence (could help) and affability (would help) in\nscientific studies or power (could help), presence, and warmth (both would\nhelp) as a popular concept. Modelling high levels in these dimensions for\nhumanoid robots or virtual agents, seems accomplishable. Beyond, also automatic\nmeasurement appears quite feasible with the recent advances in the related\nfields of Affective Computing and Social Signal Processing. Here, we,\nthereforem present a blueprint for building machines that can appear\ncharismatic, but also analyse the charisma of others. To this end, we first\nprovide the psychological perspective including different models of charisma\nand behavioural cues of it. We then switch to conversational charisma in spoken\nlanguage as an exemplary modality that is essential for human-human and\nhuman-computer conversations. The computational perspective then deals with the\nrecognition and generation of charismatic behaviour by AI. This includes an\noverview of the state of play in the field and the aforementioned blueprint. We\nthen name exemplary use cases of computational charismatic skills before\nswitching to ethical aspects and concluding this overview and perspective on\nbuilding charisma-enabled AI.", "published": "2022-12-31 07:27:01", "link": "http://arxiv.org/abs/2301.00142v1", "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.LG", "cs.SD", "eess.AS", "A.1"], "primary_category": "cs.HC"}
