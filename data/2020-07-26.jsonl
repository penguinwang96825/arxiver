{"title": "Reed at SemEval-2020 Task 9: Fine-Tuning and Bag-of-Words Approaches to\n  Code-Mixed Sentiment Analysis", "abstract": "We explore the task of sentiment analysis on Hinglish (code-mixed\nHindi-English) tweets as participants of Task 9 of the SemEval-2020\ncompetition, known as the SentiMix task. We had two main approaches: 1)\napplying transfer learning by fine-tuning pre-trained BERT models and 2)\ntraining feedforward neural networks on bag-of-words representations. During\nthe evaluation phase of the competition, we obtained an F-score of 71.3% with\nour best model, which placed $4^{th}$ out of 62 entries in the official system\nrankings.", "published": "2020-07-26 05:48:46", "link": "http://arxiv.org/abs/2007.13061v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KUISAIL at SemEval-2020 Task 12: BERT-CNN for Offensive Speech\n  Identification in Social Media", "abstract": "In this paper, we describe our approach to utilize pre-trained BERT models\nwith Convolutional Neural Networks for sub-task A of the Multilingual Offensive\nLanguage Identification shared task (OffensEval 2020), which is a part of the\nSemEval 2020. We show that combining CNN with BERT is better than using BERT on\nits own, and we emphasize the importance of utilizing pre-trained language\nmodels for downstream tasks. Our system, ranked 4th with macro averaged\nF1-Score of 0.897 in Arabic, 4th with score of 0.843 in Greek, and 3rd with\nscore of 0.814 in Turkish. Additionally, we present ArabicBERT, a set of\npre-trained transformer language models for Arabic that we share with the\ncommunity.", "published": "2020-07-26 17:26:20", "link": "http://arxiv.org/abs/2007.13184v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Survey on Complex Question Answering over Knowledge Base: Recent\n  Advances and Challenges", "abstract": "Question Answering (QA) over Knowledge Base (KB) aims to automatically answer\nnatural language questions via well-structured relation information between\nentities stored in knowledge bases. In order to make KBQA more applicable in\nactual scenarios, researchers have shifted their attention from simple\nquestions to complex questions, which require more KB triples and constraint\ninference. In this paper, we introduce the recent advances in complex QA.\nBesides traditional methods relying on templates and rules, the research is\ncategorized into a taxonomy that contains two main branches, namely Information\nRetrieval-based and Neural Semantic Parsing-based. After describing the methods\nof these branches, we analyze directions for future research and introduce the\nmodels proposed by the Alime team.", "published": "2020-07-26 07:13:32", "link": "http://arxiv.org/abs/2007.13069v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "To BERT or Not To BERT: Comparing Speech and Language-based Approaches\n  for Alzheimer's Disease Detection", "abstract": "Research related to automatically detecting Alzheimer's disease (AD) is\nimportant, given the high prevalence of AD and the high cost of traditional\nmethods. Since AD significantly affects the content and acoustics of\nspontaneous speech, natural language processing and machine learning provide\npromising techniques for reliably detecting AD. We compare and contrast the\nperformance of two such approaches for AD detection on the recent ADReSS\nchallenge dataset: 1) using domain knowledge-based hand-crafted features that\ncapture linguistic and acoustic phenomena, and 2) fine-tuning Bidirectional\nEncoder Representations from Transformer (BERT)-based sequence classification\nmodels. We also compare multiple feature-based regression models for a\nneuropsychological score task in the challenge. We observe that fine-tuned BERT\nmodels, given the relative importance of linguistics in cognitive impairment\ndetection, outperform feature-based approaches on the AD detection task.", "published": "2020-07-26 04:50:47", "link": "http://arxiv.org/abs/2008.01551v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do recommender systems function in the health domain: a system review", "abstract": "Recommender systems have fulfilled an important role in everyday life.\nRecommendations such as news by Google, videos by Netflix, goods by e-commerce\nproviders, etc. have heavily changed everyones lifestyle. Health domains\ncontain similar decision-making problems such as what to eat, how to exercise,\nand what is the proper medicine for a patient. Recently, studies focused on\nrecommender systems to solve health problems have attracted attention. In this\npaper, we review aspects of health recommender systems including interests,\nmethods, evaluation, future challenges and trend issues. We find that 1) health\nrecommender systems have their own health concern limitations that cause them\nto focus on less-risky recommendations such as diet recommendation; 2)\ntraditional recommender methods such as content-based and collaborative\nfiltering methods can hardly handle health constraints, but knowledge-based\nmethods function more than ever; 3) evaluating a health recommendation is more\ncomplicated than evaluating a commercial one because multiple dimensions in\naddition to accuracy should be considered. Recommender systems can function\nwell in the health domain after the solution of several key problems. Our work\nis a systematic review of health recommender system studies, we show current\nconditions and future directions. It is believed that this review will help\ndomain researchers and promote health recommender systems to the next step.", "published": "2020-07-26 04:58:47", "link": "http://arxiv.org/abs/2007.13058v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "68U35", "H.4.0"], "primary_category": "cs.IR"}
{"title": "End-to-end spoofing detection with raw waveform CLDNNs", "abstract": "Albeit recent progress in speaker verification generates powerful models,\nmalicious attacks in the form of spoofed speech, are generally not coped with.\nRecent results in ASVSpoof2015 and BTAS2016 challenges indicate that\nspoof-aware features are a possible solution to this problem. Most successful\nmethods in both challenges focus on spoof-aware features, rather than focusing\non a powerful classifier. In this paper we present a novel raw waveform based\ndeep model for spoofing detection, which jointly acts as a feature extractor\nand classifier, thus allowing it to directly classify speech signals. This\napproach can be considered as an end-to-end classifier, which removes the need\nfor any pre- or post-processing on the data, making training and evaluation a\nstreamlined process, consuming less time than other neural-network based\napproaches. The experiments on the BTAS2016 dataset show that the system\nperformance is significantly improved by the proposed raw waveform\nconvolutional long short term neural network (CLDNN), from the previous best\npublished 1.26\\% half total error rate (HTER) to the current 0.82\\% HTER.\nMoreover it shows that the proposed system also performs well under the unknown\n(RE-PH2-PH3,RE-LPPH2-PH3) conditions.", "published": "2020-07-26 05:48:35", "link": "http://arxiv.org/abs/2007.13060v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Double Multi-Head Attention for Speaker Verification", "abstract": "Most state-of-the-art Deep Learning systems for speaker verification are\nbased on speaker embedding extractors. These architectures are commonly\ncomposed of a feature extractor front-end together with a pooling layer to\nencode variable-length utterances into fixed-length speaker vectors. In this\npaper we present Double Multi-Head Attention pooling, which extends our\nprevious approach based on Self Multi-Head Attention. An additional self\nattention layer is added to the pooling layer that summarizes the context\nvectors produced by Multi-Head Attention into a unique speaker representation.\nThis method enhances the pooling mechanism by giving weights to the information\ncaptured for each head and it results in creating more discriminative speaker\nembeddings. We have evaluated our approach with the VoxCeleb2 dataset. Our\nresults show 6.09% and 5.23% relative improvement in terms of EER compared to\nSelf Attention pooling and Self Multi-Head Attention, respectively. According\nto the obtained results, Double Multi-Head Attention has shown to be an\nexcellent approach to efficiently select the most relevant features captured by\nthe CNN-based front-ends from the speech signal.", "published": "2020-07-26 19:18:53", "link": "http://arxiv.org/abs/2007.13199v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-Expressing Autoencoders for Unsupervised Spoken Term Discovery", "abstract": "Unsupervised spoken term discovery consists of two tasks: finding the\nacoustic segment boundaries and labeling acoustically similar segments with the\nsame labels. We perform segmentation based on the assumption that the frame\nfeature vectors are more similar within a segment than across the segments.\nTherefore, for strong segmentation performance, it is crucial that the features\nrepresent the phonetic properties of a frame more than other factors of\nvariability. We achieve this via a self-expressing autoencoder framework. It\nconsists of a single encoder and two decoders with shared weights. The encoder\nprojects the input features into a latent representation. One of the decoders\ntries to reconstruct the input from these latent representations and the other\nfrom the self-expressed version of them. We use the obtained features to\nsegment and cluster the speech data. We evaluate the performance of the\nproposed method in the Zero Resource 2020 challenge unit discovery task. The\nproposed system consistently outperforms the baseline, demonstrating the\nusefulness of the method in learning representations.", "published": "2020-07-26 00:04:17", "link": "http://arxiv.org/abs/2007.13033v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "UIAI System for Short-Duration Speaker Verification Challenge 2020", "abstract": "In this work, we present the system description of the UIAI entry for the\nshort-duration speaker verification (SdSV) challenge 2020. Our focus is on Task\n1 dedicated to text-dependent speaker verification. We investigate different\nfeature extraction and modeling approaches for automatic speaker verification\n(ASV) and utterance verification (UV). We have also studied different fusion\nstrategies for combining UV and ASV modules. Our primary submission to the\nchallenge is the fusion of seven subsystems which yields a normalized minimum\ndetection cost function (minDCF) of 0.072 and an equal error rate (EER) of\n2.14% on the evaluation set. The single system consisting of a pass-phrase\nidentification based model with phone-discriminative bottleneck features gives\na normalized minDCF of 0.118 and achieves 19% relative improvement over the\nstate-of-the-art challenge baseline.", "published": "2020-07-26 12:32:34", "link": "http://arxiv.org/abs/2007.13118v1", "categories": ["eess.AS", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tag2Risk: Harnessing Social Music Tags for Characterizing Depression\n  Risk", "abstract": "Musical preferences have been considered a mirror of the self. In this age of\nBig Data, online music streaming services allow us to capture ecologically\nvalid music listening behavior and provide a rich source of information to\nidentify several user-specific aspects. Studies have shown musical engagement\nto be an indirect representation of internal states including internalized\nsymptomatology and depression. The current study aims at unearthing patterns\nand trends in the individuals at risk for depression as it manifests in\nnaturally occurring music listening behavior. Mental well-being scores, musical\nengagement measures, and listening histories of Last.fm users (N=541) were\nacquired. Social tags associated with each listener's most popular tracks were\nanalyzed to unearth the mood/emotions and genres associated with the users.\nResults revealed that social tags prevalent in the users at risk for depression\nwere predominantly related to emotions depicting Sadness associated with genre\ntags representing neo-psychedelic-, avant garde-, dream-pop. This study will\nopen up avenues for an MIR-based approach to characterizing and predicting risk\nfor depression which can be helpful in early detection and additionally provide\nbases for designing music recommendations accordingly.", "published": "2020-07-26 16:02:10", "link": "http://arxiv.org/abs/2007.13159v1", "categories": ["cs.IR", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
