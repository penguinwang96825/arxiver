{"title": "Perceptual Structure in the Absence of Grounding for LLMs: The Impact of\n  Abstractedness and Subjectivity in Color Language", "abstract": "The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.", "published": "2023-11-22 02:12:36", "link": "http://arxiv.org/abs/2311.13105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper", "abstract": "This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.", "published": "2023-11-22 03:28:34", "link": "http://arxiv.org/abs/2311.13126v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Calibration of Large Language Models and Alignment", "abstract": "As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.", "published": "2023-11-22 08:57:55", "link": "http://arxiv.org/abs/2311.13240v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM\n  Instruction Tuning", "abstract": "Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative. To\nensure the high quality of LLM-generated instruction datasets, several\napproaches have been proposed. Nevertheless, existing methods either compromise\ndataset integrity by filtering a large proportion of samples, or are unsuitable\nfor industrial applications. In this paper, instead of discarding low-quality\nsamples, we propose CoachLM, a novel approach to enhance the quality of\ninstruction datasets through automatic revisions on samples in the dataset.\nCoachLM is trained from the samples revised by human experts and significantly\nincreases the proportion of high-quality samples in the dataset from 17.7% to\n78.9%. The effectiveness of CoachLM is further assessed on various real-world\ninstruction test sets. The results show that CoachLM improves the\ninstruction-following capabilities of the instruction-tuned LLM by an average\nof 29.9%, which even surpasses larger LLMs with nearly twice the number of\nparameters. Furthermore, CoachLM is successfully deployed in a data management\nsystem for LLMs at Huawei, resulting in an efficiency improvement of up to 20%\nin the cleaning of 40k real-world instruction pairs. We release various assets\nof CoachLM, including the training data, code and test set\n(https://github.com/lunyiliu/CoachLM).", "published": "2023-11-22 09:04:57", "link": "http://arxiv.org/abs/2311.13246v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Experimentation of Accuracy Metrics in Automated Medical\n  Reporting: The Case of Otitis Consultations", "abstract": "Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.", "published": "2023-11-22 09:51:43", "link": "http://arxiv.org/abs/2311.13273v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Summarization Performance through Transformer-Based Prompt\n  Engineering in Automated Medical Reporting", "abstract": "Customized medical prompts enable Large Language Models (LLM) to effectively\naddress medical dialogue summarization. The process of medical reporting is\noften time-consuming for healthcare professionals. Implementing medical\ndialogue summarization techniques presents a viable solution to alleviate this\ntime constraint by generating automated medical reports. The effectiveness of\nLLMs in this process is significantly influenced by the formulation of the\nprompt, which plays a crucial role in determining the quality and relevance of\nthe generated reports. In this research, we used a combination of two distinct\nprompting strategies, known as shot prompting and pattern prompting to enhance\nthe performance of automated medical reporting. The evaluation of the automated\nmedical reports is carried out using the ROUGE score and a human evaluation\nwith the help of an expert panel. The two-shot prompting approach in\ncombination with scope and domain context outperforms other methods and\nachieves the highest score when compared to the human reference set by a\ngeneral practitioner. However, the automated reports are approximately twice as\nlong as the human references, due to the addition of both redundant and\nrelevant statements that are added to the report.", "published": "2023-11-22 09:51:53", "link": "http://arxiv.org/abs/2311.13274v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Large Language Model Hallucinations via Autonomous Knowledge\n  Graph-based Retrofitting", "abstract": "Incorporating factual knowledge in knowledge graph is regarded as a promising\napproach for mitigating the hallucination of large language models (LLMs).\nExisting methods usually only use the user's input to query the knowledge\ngraph, thus failing to address the factual hallucination generated by LLMs\nduring its reasoning process. To address this problem, this paper proposes\nKnowledge Graph-based Retrofitting (KGR), a new framework that incorporates\nLLMs with KGs to mitigate factual hallucination during the reasoning process by\nretrofitting the initial draft responses of LLMs based on the factual knowledge\nstored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,\nand retrofit factual statements within the model-generated responses, which\nenables an autonomous knowledge verifying and refining procedure without any\nadditional manual efforts. Experiments show that KGR can significantly improve\nthe performance of LLMs on factual QA benchmarks especially when involving\ncomplex reasoning processes, which demonstrates the necessity and effectiveness\nof KGR in mitigating hallucination and enhancing the reliability of LLMs.", "published": "2023-11-22 11:08:38", "link": "http://arxiv.org/abs/2311.13314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PaSS: Parallel Speculative Sampling", "abstract": "Scaling the size of language models to tens of billions of parameters has led\nto impressive performance on a wide range of tasks. At generation, these models\nare used auto-regressively, requiring a forward pass for each generated token,\nand thus reading the full set of parameters from memory. This memory access\nforms the primary bottleneck for generation and it worsens as the model size\nincreases. Moreover, executing a forward pass for multiple tokens in parallel\noften takes nearly the same time as it does for just one token. These two\nobservations lead to the development of speculative sampling, where a second\nsmaller model is used to draft a few tokens, that are then validated or\nrejected using a single forward pass of the large model. Unfortunately, this\nmethod requires two models that share the same tokenizer and thus limits its\nadoption. As an alternative, we propose to use parallel decoding as a way to\ndraft multiple tokens from a single model with no computational cost, nor the\nneed for a second model. Our approach only requires an additional input token\nthat marks the words that will be generated simultaneously. We show promising\nperformance (up to $30\\%$ speed-up) while requiring only as few as $O(d_{emb})$\nadditional parameters.", "published": "2023-11-22 18:37:27", "link": "http://arxiv.org/abs/2311.13581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Fault Analysis in Substations Based on Knowledge Graphs", "abstract": "To address the challenge of identifying hidden danger in substations from\nunstructured text, a novel dynamic analysis method is proposed. We first\nextract relevant information from the unstructured text, and then leverages a\nflexible distributed search engine built on Elastic-Search to handle the data.\nFollowing this, the hidden Markov model is employed to train the data within\nthe engine. The Viterbi algorithm is integrated to decipher the hidden state\nsequences, facilitating the segmentation and labeling of entities related to\nhidden dangers. The final step involves using the Neo4j graph database to\ndynamically create a knowledge graph that visualizes hidden dangers in the\nsubstation. The effectiveness of the proposed method is demonstrated through a\ncase analysis from a specific substation with hidden dangers revealed in the\ntext records.", "published": "2023-11-22 21:59:46", "link": "http://arxiv.org/abs/2311.13708v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparison of pipeline, sequence-to-sequence, and GPT models for\n  end-to-end relation extraction: experiments with the rare disease use-case", "abstract": "End-to-end relation extraction (E2ERE) is an important and realistic\napplication of natural language processing (NLP) in biomedicine. In this paper,\nwe aim to compare three prevailing paradigms for E2ERE using a complex dataset\nfocused on rare diseases involving discontinuous and nested entities. We use\nthe RareDis information extraction dataset to evaluate three competing\napproaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to\nsequence models, and generative pre-trained transformer (GPT) models. We use\ncomparable state-of-the-art models and best practices for each of these\napproaches and conduct error analyses to assess their failure modes. Our\nfindings reveal that pipeline models are still the best, while\nsequence-to-sequence models are not far behind; GPT models with eight times as\nmany parameters are worse than even sequence-to-sequence models and lose to\npipeline models by over 10 F1 points. Partial matches and discontinuous\nentities caused many NER errors contributing to lower overall E2E performances.\nWe also verify these findings on a second E2ERE dataset for chemical-protein\ninteractions. Although generative LM-based methods are more suitable for\nzero-shot settings, when training data is available, our results show that it\nis better to work with more conventional models trained and tailored for E2ERE.\nMore innovative methods are needed to marry the best of the both worlds from\nsmaller encoder-decoder pipeline models and the larger GPT models to improve\nE2ERE. As of now, we see that well designed pipeline models offer substantial\nperformance gains at a lower cost and carbon footprint for E2ERE. Our\ncontribution is also the first to conduct E2ERE for the RareDis dataset.", "published": "2023-11-22 22:52:00", "link": "http://arxiv.org/abs/2311.13729v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Surpassing GPT-4 Medical Coding with a Two-Stage Approach", "abstract": "Recent advances in large language models (LLMs) show potential for clinical\napplications, such as clinical decision support and trial recommendations.\nHowever, the GPT-4 LLM predicts an excessive number of ICD codes for medical\ncoding tasks, leading to high recall but low precision. To tackle this\nchallenge, we introduce LLM-codex, a two-stage approach to predict ICD codes\nthat first generates evidence proposals using an LLM and then employs an\nLSTM-based verification stage. The LSTM learns from both the LLM's high recall\nand human expert's high precision, using a custom loss function. Our model is\nthe only approach that simultaneously achieves state-of-the-art results in\nmedical coding accuracy, accuracy on rare codes, and sentence-level evidence\nidentification to support coding decisions without training on human-annotated\nevidence according to experiments on the MIMIC dataset.", "published": "2023-11-22 23:35:13", "link": "http://arxiv.org/abs/2311.13735v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoKG: Efficient Automated Knowledge Graph Generation for Language\n  Models", "abstract": "Traditional methods of linking large language models (LLMs) to knowledge\nbases via the semantic similarity search often fall short of capturing complex\nrelational dynamics. To address these limitations, we introduce AutoKG, a\nlightweight and efficient approach for automated knowledge graph (KG)\nconstruction. For a given knowledge base consisting of text blocks, AutoKG\nfirst extracts keywords using a LLM and then evaluates the relationship weight\nbetween each pair of keywords using graph Laplace learning. We employ a hybrid\nsearch scheme combining vector similarity and graph-based associations to\nenrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a\nmore comprehensive and interconnected knowledge retrieval mechanism compared to\nthe semantic similarity search, thereby enhancing the capabilities of LLMs in\ngenerating more insightful and relevant outputs.", "published": "2023-11-22 08:58:25", "link": "http://arxiv.org/abs/2311.14740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications", "abstract": "Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.", "published": "2023-11-22 01:51:50", "link": "http://arxiv.org/abs/2311.13095v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive\n  Algorithm Representation", "abstract": "Algorithm selection, a critical process of automated machine learning, aims\nto identify the most suitable algorithm for solving a specific problem prior to\nexecution. Mainstream algorithm selection techniques heavily rely on problem\nfeatures, while the role of algorithm features remains largely unexplored. Due\nto the intrinsic complexity of algorithms, effective methods for universally\nextracting algorithm information are lacking. This paper takes a significant\nstep towards bridging this gap by introducing Large Language Models (LLMs) into\nalgorithm selection for the first time. By comprehending the code text, LLM not\nonly captures the structural and semantic aspects of the algorithm, but also\ndemonstrates contextual awareness and library function understanding. The\nhigh-dimensional algorithm representation extracted by LLM, after undergoing a\nfeature selection module, is combined with the problem representation and\npassed to the similarity calculation module. The selected algorithm is\ndetermined by the matching degree between a given problem and different\nalgorithms. Extensive experiments validate the performance superiority of the\nproposed model and the efficacy of each key module. Furthermore, we present a\ntheoretical upper bound on model complexity, showcasing the influence of\nalgorithm representation and feature selection modules. This provides valuable\ntheoretical guidance for the practical implementation of our method.", "published": "2023-11-22 06:23:18", "link": "http://arxiv.org/abs/2311.13184v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus", "abstract": "Large Language Models (LLMs) have gained significant popularity for their\nimpressive performance across diverse fields. However, LLMs are prone to\nhallucinate untruthful or nonsensical outputs that fail to meet user\nexpectations in many real-world applications. Existing works for detecting\nhallucinations in LLMs either rely on external knowledge for reference\nretrieval or require sampling multiple responses from the LLM for consistency\nverification, making these methods costly and inefficient. In this paper, we\npropose a novel reference-free, uncertainty-based method for detecting\nhallucinations in LLMs. Our approach imitates human focus in factuality\nchecking from three aspects: 1) focus on the most informative and important\nkeywords in the given text; 2) focus on the unreliable tokens in historical\ncontext which may lead to a cascade of hallucinations; and 3) focus on the\ntoken properties such as token type and token frequency. Experimental results\non relevant datasets demonstrate the effectiveness of our proposed method,\nwhich achieves state-of-the-art performance across all the evaluation metrics\nand eliminates the need for additional information.", "published": "2023-11-22 08:39:17", "link": "http://arxiv.org/abs/2311.13230v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Intention and Context Elicitation with Large Language Models in the\n  Legal Aid Intake Process", "abstract": "Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.", "published": "2023-11-22 10:04:29", "link": "http://arxiv.org/abs/2311.13281v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Generation of Explanations for Logic Reasoning", "abstract": "This thesis delves into a fortiori arguments in deductive reasoning,\nunderscoring their relevance in various domains such as law, philosophy, and\nartificial intelligence. The research is centred on employing GPT-3.5-turbo to\nautomate the analysis of these arguments, with a focus on understanding\nintricate reasoning processes, generating clear and coherent explanations, and\ncreating novel arguments. The methodology encompasses a series of tasks\nincluding detailed reasoning, interpretation, and the augmentation of a\nfortiori arguments. It involves meticulously identifying these arguments in\ndiverse contexts, differentiating comparative elements, and categorizing them\nbased on their logical structure.\n  Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in\naccurately detecting and classifying a fortiori arguments. Nevertheless, the\nmodel demonstrates a performance that rivals specialized models, particularly\nin extracting key components and interpreting underlying properties. The\nintegration of external information into the model's processing significantly\nelevates the quality of the generated explanations. Additionally, the model\nexhibits a noteworthy capability in augmenting arguments, thus contributing to\nthe enrichment of the data set.\n  Despite facing certain limitations, this thesis makes significant\ncontributions to the fields of artificial intelligence and logical reasoning.\nIt introduces novel methodologies, establishes a rigorous evaluation framework,\nand provides deep insights that set the stage for future advancements in\nautomated logical reasoning. The findings and methodologies presented herein\nnot only underscore the potential of AI in complex reasoning tasks but also\nhighlight areas for future research and development.", "published": "2023-11-22 15:22:04", "link": "http://arxiv.org/abs/2311.13455v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Complexity-Guided Curriculum Learning for Text Graphs", "abstract": "Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.", "published": "2023-11-22 15:40:57", "link": "http://arxiv.org/abs/2311.13472v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Model Inversion", "abstract": "Language models produce a distribution over the next token; can we use this\ninformation to recover the prompt tokens? We consider the problem of language\nmodel inversion and show that next-token probabilities contain a surprising\namount of information about the preceding text. Often we can recover the text\nin cases where it is hidden from the user, motivating a method for recovering\nunknown prompts given only the model's current distribution output. We consider\na variety of model access scenarios, and show how even without predictions for\nevery token in the vocabulary we can recover the probability vector through\nsearch. On Llama-2 7b, our inversion method reconstructs prompts with a BLEU of\n$59$ and token-level F1 of $78$ and recovers $27\\%$ of prompts exactly. Code\nfor reproducing all experiments is available at\nhttp://github.com/jxmorris12/vec2text.", "published": "2023-11-22 19:04:04", "link": "http://arxiv.org/abs/2311.13647v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Transformer Knowledge Distillation: A Performance Review", "abstract": "As pretrained transformer language models continue to achieve\nstate-of-the-art performance, the Natural Language Processing community has\npushed for advances in model compression and efficient attention mechanisms to\naddress high computational requirements and limited input sequence length.\nDespite these separate efforts, no investigation has been done into the\nintersection of these two fields. In this work, we provide an evaluation of\nmodel compression via knowledge distillation on efficient attention\ntransformers. We provide cost-performance trade-offs for the compression of\nstate-of-the-art efficient attention architectures and the gains made in\nperformance in comparison to their full attention counterparts. Furthermore, we\nintroduce a new long-context Named Entity Recognition dataset, GONERD, to train\nand test the performance of NER models on long sequences. We find that\ndistilled efficient attention transformers can preserve a significant amount of\noriginal model performance, preserving up to 98.6% across short-context tasks\n(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context\nQuestion-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on\nlong-context Named Entity Recognition (GONERD), while decreasing inference\ntimes by up to 57.8%. We find that, for most models on most tasks, performing\nknowledge distillation is an effective method to yield high-performing\nefficient attention models with low costs.", "published": "2023-11-22 19:19:37", "link": "http://arxiv.org/abs/2311.13657v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Co-guiding for Multi-intent Spoken Language Understanding", "abstract": "Recent graph-based models for multi-intent SLU have obtained promising\nresults through modeling the guidance from the prediction of intents to the\ndecoding of slot filling. However, existing methods (1) only model the\nunidirectional guidance from intent to slot, while there are bidirectional\ninter-correlations between intent and slot; (2) adopt homogeneous graphs to\nmodel the interactions between the slot semantics nodes and intent label nodes,\nwhich limit the performance. In this paper, we propose a novel model termed\nCo-guiding Net, which implements a two-stage framework achieving the mutual\nguidances between the two tasks. In the first stage, the initial estimated\nlabels of both tasks are produced, and then they are leveraged in the second\nstage to model the mutual guidances. Specifically, we propose two heterogeneous\ngraph attention networks working on the proposed two heterogeneous semantics\nlabel graphs, which effectively represent the relations among the semantics\nnodes and label nodes. Besides, we further propose Co-guiding-SCL Net, which\nexploits the single-task and dual-task semantics contrastive relations. For the\nfirst stage, we propose single-task supervised contrastive learning, and for\nthe second stage, we propose co-guiding supervised contrastive learning, which\nconsiders the two tasks' mutual guidances in the contrastive learning\nprocedure. Experiment results on multi-intent SLU show that our model\noutperforms existing models by a large margin, obtaining a relative improvement\nof 21.3% over the previous best model on MixATIS dataset in overall accuracy.\nWe also evaluate our model on the zero-shot cross-lingual scenario and the\nresults show that our model can relatively improve the state-of-the-art model\nby 33.5% on average in terms of overall accuracy for the total 9 languages.", "published": "2023-11-22 08:06:22", "link": "http://arxiv.org/abs/2312.03716v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Functional Analytics for Document Ordering for Curriculum Development\n  and Comprehension", "abstract": "We propose multiple techniques for automatic document order generation for\n(1) curriculum development and for (2) creation of optimal reading order for\nuse in learning, training, and other content-sequencing applications. Such\ntechniques could potentially be used to improve comprehension, identify areas\nthat need expounding, generate curricula, and improve search engine results. We\nadvance two main techniques: The first uses document similarities through\nvarious methods. The second uses entropy against the backdrop of topics\ngenerated through Latent Dirichlet Allocation (LDA). In addition, we try the\nsame methods on the summarized documents and compare them against the results\nobtained using the complete documents. Our results showed that while the\ndocument orders for our control document sets (biographies, novels, and\nWikipedia articles) could not be predicted using our methods, our test\ndocuments (textbooks, courses, journal papers, dissertations) provided more\nreliability. We also demonstrated that summarized documents were good stand-ins\nfor the complete documents for the purposes of ordering.", "published": "2023-11-22 02:13:27", "link": "http://arxiv.org/abs/2312.09457v1", "categories": ["cs.CL", "cs.IR", "K.3.2"], "primary_category": "cs.CL"}
{"title": "Detecting out-of-distribution text using topological features of\n  transformer-based language models", "abstract": "To safeguard machine learning systems that operate on textual data against\nout-of-distribution (OOD) inputs that could cause unpredictable behaviour, we\nexplore the use of topological features of self-attention maps from\ntransformer-based language models to detect when input text is out of\ndistribution. Self-attention forms the core of transformer-based language\nmodels, dynamically assigning vectors to words based on context, thus in theory\nour methodology is applicable to any transformer-based language model with\nmultihead self-attention. We evaluate our approach on BERT and compare it to a\ntraditional OOD approach using CLS embeddings. Our results show that our\napproach outperforms CLS embeddings in distinguishing in-distribution samples\nfrom far-out-of-domain samples, but struggles with near or same-domain\ndatasets.", "published": "2023-11-22 02:04:35", "link": "http://arxiv.org/abs/2311.13102v2", "categories": ["cs.CL", "cs.LG", "math.AT"], "primary_category": "cs.CL"}
{"title": "White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?", "abstract": "In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .", "published": "2023-11-22 02:23:32", "link": "http://arxiv.org/abs/2311.13110v4", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms", "abstract": "Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.", "published": "2023-11-22 03:37:01", "link": "http://arxiv.org/abs/2311.13133v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization", "abstract": "Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.", "published": "2023-11-22 05:28:59", "link": "http://arxiv.org/abs/2311.13171v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation", "abstract": "State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.", "published": "2023-11-22 09:23:34", "link": "http://arxiv.org/abs/2311.13258v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Rethinking Radiology Report Generation via Causal Inspired\n  Counterfactual Augmentation", "abstract": "Radiology Report Generation (RRG) draws attention as a vision-and-language\ninteraction of biomedical fields. Previous works inherited the ideology of\ntraditional language generation tasks, aiming to generate paragraphs with high\nreadability as reports. Despite significant progress, the independence between\ndiseases-a specific property of RRG-was neglected, yielding the models being\nconfused by the co-occurrence of diseases brought on by the biased data\ndistribution, thus generating inaccurate reports. In this paper, to rethink\nthis issue, we first model the causal effects between the variables from a\ncausal perspective, through which we prove that the co-occurrence relationships\nbetween diseases on the biased distribution function as confounders, confusing\nthe accuracy through two backdoor paths, i.e. the Joint Vision Coupling and the\nConditional Sequential Coupling. Then, we proposed a novel model-agnostic\ncounterfactual augmentation method that contains two strategies, i.e. the\nPrototype-based Counterfactual Sample Synthesis (P-CSS) and the Magic-Cube-like\nCounterfactual Report Reconstruction (Cube), to intervene the backdoor paths,\nthus enhancing the accuracy and generalization of RRG models. Experimental\nresults on the widely used MIMIC-CXR dataset demonstrate the effectiveness of\nour proposed method. Additionally, a generalization performance is evaluated on\nIU X-Ray dataset, which verifies our work can effectively reduce the impact of\nco-occurrences caused by different distributions on the results.", "published": "2023-11-22 10:55:36", "link": "http://arxiv.org/abs/2311.13307v3", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Fact-based Court Judgment Prediction", "abstract": "This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.", "published": "2023-11-22 12:39:28", "link": "http://arxiv.org/abs/2311.13350v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Machine Translation to Control Formality Features in the Target Language", "abstract": "Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.", "published": "2023-11-22 15:42:51", "link": "http://arxiv.org/abs/2311.13475v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Current Topological and Machine Learning Applications for Bias Detection\n  in Text", "abstract": "Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.", "published": "2023-11-22 16:12:42", "link": "http://arxiv.org/abs/2311.13495v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "LM-Cocktail: Resilient Tuning of Language Models via Model Merging", "abstract": "The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose LM-Cocktail which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging, where the fine-tuned language model is merged with the\npre-trained base model or the peer models from other domains through weighted\naverage. Despite simplicity, LM-Cocktail is surprisingly effective: the\nresulted model is able to achieve a strong empirical performance in the whole\nscope of general tasks while preserving a superior capacity in its targeted\ndomain. We conduct comprehensive experiments with LLama and BGE model on\npopular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail.", "published": "2023-11-22 17:14:54", "link": "http://arxiv.org/abs/2311.13534v4", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering", "abstract": "We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.", "published": "2023-11-22 18:22:56", "link": "http://arxiv.org/abs/2311.13565v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of\n  Large Language Models", "abstract": "The recent explosion in the capabilities of large language models has led to\na wave of interest in how best to prompt a model to perform a given task. While\nit may be tempting to simply choose a prompt based on average performance on a\nvalidation set, this can lead to a deployment where unexpectedly poor responses\nare generated, especially for the worst-off users. To mitigate this prospect,\nwe propose Prompt Risk Control, a lightweight framework for selecting a prompt\nbased on rigorous upper bounds on families of informative risk measures. We\noffer methods for producing bounds on a diverse set of metrics, including\nquantities that measure worst-case responses and disparities in generation\nquality across the population of users. In addition, we extend the underlying\nstatistical bounding techniques to accommodate the possibility of distribution\nshifts in deployment. Experiments on applications such as open-ended chat,\nmedical question summarization, and code generation highlight how such a\nframework can foster responsible deployment by reducing the risk of the worst\noutcomes.", "published": "2023-11-22 18:50:47", "link": "http://arxiv.org/abs/2311.13628v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MAIRA-1: A specialised large multimodal model for radiology report\n  generation", "abstract": "We present a radiology-specific multimodal model for the task for generating\nradiological reports from chest X-rays (CXRs). Our work builds on the idea that\nlarge language model(s) can be equipped with multimodal capabilities through\nalignment with pre-trained vision encoders. On natural images, this has been\nshown to allow multimodal models to gain image understanding and description\ncapabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image\nencoder in conjunction with a fine-tuned large language model based on\nVicuna-7B, and text-based data augmentation, to produce reports with\nstate-of-the-art quality. In particular, MAIRA-1 significantly improves on the\nradiologist-aligned RadCliQ metric and across all lexical metrics considered.\nManual review of model outputs demonstrates promising fluency and accuracy of\ngenerated reports while uncovering failure modes not captured by existing\nevaluation practices. More information and resources can be found on the\nproject website: https://aka.ms/maira.", "published": "2023-11-22 19:45:40", "link": "http://arxiv.org/abs/2311.13668v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Positional Description Matters for Transformers Arithmetic", "abstract": "Transformers, central to the successes in modern Natural Language Processing,\noften falter on arithmetic tasks despite their vast capabilities --which\nparadoxically include remarkable coding abilities. We observe that a crucial\nchallenge is their naive reliance on positional information to solve arithmetic\nproblems with a small number of digits, leading to poor performance on larger\nnumbers. Herein, we delve deeper into the role of positional encoding, and\npropose several ways to fix the issue, either by modifying the positional\nencoding directly, or by modifying the representation of the arithmetic task to\nleverage standard positional encoding differently. We investigate the value of\nthese modifications for three tasks: (i) classical multiplication, (ii) length\nextrapolation in addition, and (iii) addition in natural language context. For\n(i) we train a small model on a small dataset (100M parameters and 300k\nsamples) with remarkable aptitude in (direct, no scratchpad) 15 digits\nmultiplication and essentially perfect up to 12 digits, while usual training in\nthis context would give a model failing at 4 digits multiplication. In the\nexperiments on addition, we use a mere 120k samples to demonstrate: for (ii)\nextrapolation from 10 digits to testing on 12 digits numbers while usual\ntraining would have no extrapolation, and for (iii) almost perfect accuracy up\nto 5 digits while usual training would be correct only up to 3 digits (which is\nessentially memorization with a training set of 120k samples).", "published": "2023-11-22 00:31:01", "link": "http://arxiv.org/abs/2311.14737v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "@ve: A Chatbot for Latin", "abstract": "Dead, extinct, and endangered languages have been preserved primarily through\naudio conservation and the collection and digitization of scripts and have been\npromoted through targeted language acquisition efforts. Another possibility\nwould be to build conversational agents that can master these languages. This\nwould provide an artificial, active conversational partner which has knowledge\nof the vocabulary and grammar, and one learns with it in a different way. The\nchatbot @ve, with which one can communicate in Latin, was developed in\n2022/2023 based on GPT-3.0. It was additionally equipped with a manually\ncreated knowledge base. After conceptual groundwork, this paper presents the\npreparation and implementation of the project. In addition, it summarizes the\ntest that a Latin expert conducted with the chatbot. A critical discussion\nelaborates advantages and disadvantages. @ve could be a new tool for teaching\nLatin in a memorable and entertaining way through dialogue. However, the\npresent implementation is still too prone to glitches for stand-alone use -\ni.e., without the accompaniment of a teacher. The use of GPT-4 could be a\nsolution as well as the extension of the knowledge base. In conclusion, it can\nbe argued that conversational agents are an innovative approach to promoting\nand preserving languages.", "published": "2023-11-22 09:06:11", "link": "http://arxiv.org/abs/2311.14741v1", "categories": ["cs.CL", "cs.AI", "cs.RO", "I.2; K.3"], "primary_category": "cs.CL"}
{"title": "Conditions for Length Generalization in Learning Reasoning Skills", "abstract": "Reasoning is a fundamental capability of AI agents. Recently, large language\nmodels (LLMs) have shown remarkable abilities to perform reasoning tasks.\nHowever, numerous evaluations of the reasoning capabilities of LLMs have also\nshowed some limitations. An outstanding limitation is length generalization,\nmeaning that when trained on reasoning problems of smaller lengths or sizes,\nthe resulting models struggle with problems of larger sizes or lengths. This\npotentially indicates some theoretical limitations of generalization in\nlearning reasoning skills. These evaluations and their observations motivated\nus to perform a theoretical study of the length generalization problem. This\nwork focuses on reasoning tasks that can be formulated as Markov dynamic\nprocesses (MDPs) and/or directed acyclic graphs (DAGs). It identifies and\nproves conditions that decide whether the length generalization problem can be\nsolved or not for a reasoning task in a particular representation. Experiments\nare also conducted to verify the theoretical results.", "published": "2023-11-22 03:36:18", "link": "http://arxiv.org/abs/2311.16173v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Turbocharge Speech Understanding with Pilot Inference", "abstract": "Modern speech understanding (SU) runs a sophisticated pipeline: ingesting\nstreaming voice input, the pipeline executes encoder-decoder based deep neural\nnetworks repeatedly; by doing so, the pipeline generates tentative outputs\n(called hypotheses), and periodically scores the hypotheses. This paper sets to\naccelerate SU on resource-constrained edge devices. It takes a hybrid approach:\nto speed up on-device execution; to offload inputs that are beyond the device's\ncapacity. While the approach is well-known, we address SU's unique challenges\nwith novel techniques: (1) late contextualization, which executes a model's\nattentive encoder in parallel to the input ingestion; (2) pilot inference,\nwhich mitigates the SU pipeline's temporal load imbalance; (3) autoregression\nofframps, which evaluate offloading decisions based on pilot inferences and\nhypotheses. Our techniques are compatible with existing speech models,\npipelines, and frameworks; they can be applied independently or in combination.\nOur prototype, called PASU, is tested on Arm platforms with 6 - 8 cores: it\ndelivers SOTA accuracy; it reduces the end-to-end latency by 2x and reduces the\noffloading needs by 2x.", "published": "2023-11-22 17:14:18", "link": "http://arxiv.org/abs/2311.17065v3", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements", "abstract": "This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.", "published": "2023-11-22 02:45:01", "link": "http://arxiv.org/abs/2311.13118v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.SI", "68T50, 62H30, 91C99, 68T068T50, 62H30, 91C99, 68T01", "I.2.7; I.5.4; K.4.1; K.4.2"], "primary_category": "cs.LG"}
{"title": "Deep Audio Zooming: Beamwidth-Controllable Neural Beamformer", "abstract": "Audio zooming, a signal processing technique, enables selective focusing and\nenhancement of sound signals from a specified region, attenuating others. While\ntraditional beamforming and neural beamforming techniques, centered on creating\na directional array, necessitate the designation of a singular target\ndirection, they often overlook the concept of a field of view (FOV), that\ndefines an angular area. In this paper, we proposed a simple yet effective FOV\nfeature, amalgamating all directional attributes within the user-defined field.\nIn conjunction, we've introduced a counter FOV feature capturing directional\naspects outside the desired field. Such advancements ensure refined sound\ncapture, particularly emphasizing the FOV's boundaries, and guarantee the\nenhanced capture of all desired sound sources inside the user-defined field.\nThe results from the experiment demonstrate the efficacy of the introduced\nangular FOV feature and its seamless incorporation into a low-power subband\nmodel suited for real-time applica?tions.", "published": "2023-11-22 00:38:06", "link": "http://arxiv.org/abs/2311.13075v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Performance Analysis Of Binaural Signal Matching (BSM) in the\n  Time-Frequency Domain", "abstract": "The capture and reproduction of spatial audio is becoming increasingly\npopular, with the mushrooming of applications in teleconferencing,\nentertainment and virtual reality. Many binaural reproduction methods have been\ndeveloped and studied extensively for spherical and other specially designed\narrays. However, the recent increased popularity of wearable and mobile arrays\nrequires the development of binaural reproduction methods for these arrays. One\nsuch method is binaural signal matching (BSM). However, to date this method has\nonly been investigated with fixed matched filters designed for long audio\nrecordings. With the aim of making the BSM method more adaptive to dynamic\nenvironments, this paper analyzes BSM with a parameterized sound-field in the\ntime-frequency domain. The paper presents results of implementing the BSM\nmethod on a sound-field that was decomposed into its direct and reverberant\ncomponents, and compares this implementation with the BSM computed for the\nentire sound-field, to compare performance for binaural reproduction of\nreverberant speech in a simulated environment.", "published": "2023-11-22 13:38:37", "link": "http://arxiv.org/abs/2311.13390v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Sparsity-Driven EEG Channel Selection for Brain-Assisted Speech\n  Enhancement", "abstract": "Speech enhancement is widely used as a front-end to improve the speech\nquality in many audio systems, while it is hard to extract the target speech in\nmulti-talker conditions without prior information on the speaker identity. It\nwas shown that the auditory attention on the target speaker can be decoded from\nthe electroencephalogram (EEG) of the listener implicitly. In this work, we\ntherefore propose a novel end-to-end brain-assisted speech enhancement network\n(BASEN), which incorporates the listeners' EEG signals and adopts a temporal\nconvolutional network together with a convolutional multi-layer cross attention\nmodule to fuse EEG-audio features. Considering that an EEG cap with sparse\nchannels exhibits multiple benefits and in practice many electrodes might\ncontribute marginally, we further propose two channel selection methods, called\nresidual Gumbel selection and convolutional regularization selection. They are\ndedicated to tackling training instability and duplicated channel selections,\nrespectively. Experimental results on a public dataset show the superiority of\nthe proposed BASEN over existing approaches. The proposed channel selection\nmethods can significantly reduce the amount of informative EEG channels with a\nnegligible impact on the performance.", "published": "2023-11-22 14:50:11", "link": "http://arxiv.org/abs/2311.13436v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "End-to-end transfer learning for speaker-independent cross-language and\n  cross-corpus speech emotion recognition", "abstract": "Data-driven models achieve successful results in Speech Emotion Recognition\n(SER). However, these models, which are often based on general acoustic\nfeatures or end-to-end approaches, show poor performance when the testing set\nhas a different language than the training set or when these sets are taken\nfrom different datasets. To alleviate these problems, this paper presents an\nend-to-end Deep Neural Network (DNN) model based on transfer learning for\ncross-language and cross-corpus SER. We use the wav2vec 2.0 pre-trained model\nto transform audio time-domain waveforms from different languages, different\nspeakers and different recording conditions into a feature space shared by\nmultiple languages, thereby reducing the language variabilities in the speech\nembeddings. Next, we propose a new Deep-Within-Class Covariance Normalisation\n(Deep-WCCN) layer that can be inserted into the DNN model and aims to reduce\nother variabilities including speaker variability, channel variability and so\non. The entire model is fine-tuned in an end-to-end manner on a combined loss\nand is validated on datasets from three languages (i.e. English, German,\nChinese). Experimental results show that our proposed method outperforms the\nbaseline model that is based on common acoustic feature sets for SER in the\nwithin-language setting and the cross-language setting. In addition, we also\nexperimentally validate the effectiveness of Deep-WCCN, which can further\nimprove the model performance. Next, we show that the proposed transfer\nlearning method has good data efficiency when merging target language data into\nthe fine-tuning process. The model speaker-independent SER performance\nincreases with up to 15.6% when only 160s of target language data is used.\nFinally, our proposed model shows significantly better performance than other\nstate-of-the-art models in cross-language SER.", "published": "2023-11-22 20:11:16", "link": "http://arxiv.org/abs/2311.13678v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Spatial Audio and Individualized HRTFs using a Convolutional Neural\n  Network (CNN)", "abstract": "Spatial audio and 3-Dimensional sound rendering techniques play a pivotal and\nessential role in immersive audio experiences. Head-Related Transfer Functions\n(HRTFs) are acoustic filters which represent how sound interacts with an\nindividual's unique head and ears anatomy. The use of HRTFs compliant to the\nsubjects anatomical traits is crucial to ensure a personalized and unique\nspatial experience. This work proposes the implementation of an HRTF\nindividualization method based on anthropometric features automatically\nextracted from ear images using a Convolutional Neural Network (CNN). Firstly,\na CNN is implemented and tested to assess the performance of machine learning\non positioning landmarks on ear images. The I-BUG dataset, containing ear\nimages with corresponding 55 landmarks, was used to train and test the neural\nnetwork. Subsequently, 12 relevant landmarks were selected to correspond to 7\nspecific anthropometric measurements established by the HUTUBS database. These\nlandmarks serve as a reference for distance computation in pixels in order to\nretrieve the anthropometric measurements from the ear images. Once the 7\ndistances in pixels are extracted from the ear image, they are converted in\ncentimetres using conversion factors, a best match method vector is implemented\ncomputing the Euclidean distance for each set in a database of 116 ears with\ntheir corresponding 7 anthropometric measurements provided by the HUTUBS\ndatabase. The closest match of anthropometry can be identified and the\ncorresponding set of HRTFs can be obtained for personnalized use. The method is\nevaluated in its validity instead of the accuracy of the results. The\nconceptual scope of each stage has been verified and substantiated to function\ncorrectly. The various steps and the available elements in the process are\nreviewed and challenged to define a greater algorithm entity designed for the\ndesired task.", "published": "2023-11-22 13:52:51", "link": "http://arxiv.org/abs/2311.13397v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts", "abstract": "In the heart of \"rhythm games\" - games where players must perform actions in\nsync with a piece of music - are \"charts\", the directives to be given to\nplayers. We newly formulate chart generation as a sequence generation task and\ntrain a Transformer using a large dataset. We also introduce tempo-informed\npreprocessing and training procedures, some of which are suggested to be\nintegral for a successful training. Our model is found to outperform the\nbaselines on a large dataset, and is also found to benefit from pretraining and\nfinetuning.", "published": "2023-11-22 20:47:52", "link": "http://arxiv.org/abs/2311.13687v1", "categories": ["cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
