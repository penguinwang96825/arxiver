{"title": "Bridging Background Knowledge Gaps in Translation with Automatic\n  Explicitation", "abstract": "Translations help people understand content written in another language.\nHowever, even correct literal translations do not fulfill that goal when people\nlack the necessary background to understand them. Professional translators\nincorporate explicitations to explain the missing context by considering\ncultural differences between source and target audiences. Despite its potential\nto help users, NLP research on explicitation is limited because of the dearth\nof adequate evaluation methods. This work introduces techniques for\nautomatically generating explicitations, motivated by WikiExpl: a dataset that\nwe collect from Wikipedia and annotate with human translators. The resulting\nexplicitations are useful as they help answer questions more accurately in a\nmultilingual question answering framework.", "published": "2023-12-03 07:24:12", "link": "http://arxiv.org/abs/2312.01308v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark\n  Dataset for Generative Language Models in Norwegian", "abstract": "Norwegian, spoken by only 5 million population, is under-representative\nwithin the most impressive breakthroughs in NLP tasks. To the best of our\nknowledge, there has not yet been a comprehensive evaluation of the existing\nlanguage models (LMs) on Norwegian generation tasks during the article writing\nprocess. To fill this gap, we 1) compiled the existing Norwegian dataset and\npre-trained 4 Norwegian Open Language Models varied from parameter scales and\narchitectures, collectively called NorGLM; 2) introduced a comprehensive\nbenchmark, NLEBench, for evaluating natural language generation capabilities in\nNorwegian, encompassing translation and human annotation. Based on the\ninvestigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5\nhas limited capability in understanding the Norwegian context; 2) the increase\nin model parameter scales demonstrates limited impact on the performance of\ndownstream tasks when the pre-training dataset is constrained in size; 3)\nsmaller models also demonstrate the reasoning capability through\nChain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be\nused to verify the generalizability of LLMs on natural language understanding\nand, meanwhile, test the interconnectedness of these NLP tasks. We share our\nresources and code for reproducibility under a CC BY-NC 4.0 license.", "published": "2023-12-03 08:09:45", "link": "http://arxiv.org/abs/2312.01314v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CEScore: Simple and Efficient Confidence Estimation Model for Evaluating\n  Split and Rephrase", "abstract": "The split and rephrase (SR) task aims to divide a long, complex sentence into\na set of shorter, simpler sentences that convey the same meaning. This\nchallenging problem in NLP has gained increased attention recently because of\nits benefits as a pre-processing step in other NLP tasks. Evaluating quality of\nSR is challenging, as there no automatic metric fit to evaluate this task. In\nthis work, we introduce CEScore, as novel statistical model to automatically\nevaluate SR task. By mimicking the way humans evaluate SR, CEScore provides 4\nmetrics (Sscore, Gscore, Mscore, and CEscore) to assess simplicity,\ngrammaticality, meaning preservation, and overall quality, respectively. In\nexperiments with 26 models, CEScore correlates strongly with human evaluations,\nachieving 0.98 in Spearman correlations at model-level. This underscores the\npotential of CEScore as a simple and effective metric for assessing the overall\nquality of SR models.", "published": "2023-12-03 11:36:23", "link": "http://arxiv.org/abs/2312.01356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Approach to Evaluate Sentence-Level Fluency: Do We Really\n  Need Reference?", "abstract": "Fluency is a crucial goal of all Natural Language Generation (NLG) systems.\nWidely used automatic evaluation metrics fall short in capturing the fluency of\nmachine-generated text. Assessing the fluency of NLG systems poses a challenge\nsince these models are not limited to simply reusing words from the input but\nmay also generate abstractions. Existing reference-based fluency evaluations,\nsuch as word overlap measures, often exhibit weak correlations with human\njudgments. This paper adapts an existing unsupervised technique for measuring\ntext fluency without the need for any reference. Our approach leverages various\nword embeddings and trains language models using Recurrent Neural Network (RNN)\narchitectures. We also experiment with other available multilingual Language\nModels (LMs). To assess the performance of the models, we conduct a comparative\nanalysis across 10 Indic languages, correlating the obtained fluency scores\nwith human judgments. Our code and human-annotated benchmark test-set for\nfluency is available at\nhttps://github.com/AnanyaCoder/TextFluencyForIndicLanaguges.", "published": "2023-12-03 20:09:23", "link": "http://arxiv.org/abs/2312.01500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward best research practices in AI Psychology", "abstract": "Language models have become an essential part of the burgeoning field of AI\nPsychology. I discuss 14 methodological considerations that can help design\nmore robust, generalizable studies evaluating the cognitive abilities of\nlanguage-based AI systems, as well as to accurately interpret the results of\nthese studies.", "published": "2023-12-03 04:28:19", "link": "http://arxiv.org/abs/2312.01276v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On Significance of Subword tokenization for Low Resource and Efficient\n  Named Entity Recognition: A case study in Marathi", "abstract": "Named Entity Recognition (NER) systems play a vital role in NLP applications\nsuch as machine translation, summarization, and question-answering. These\nsystems identify named entities, which encompass real-world concepts like\nlocations, persons, and organizations. Despite extensive research on NER\nsystems for the English language, they have not received adequate attention in\nthe context of low resource languages. In this work, we focus on NER for\nlow-resource language and present our case study in the context of the Indian\nlanguage Marathi. The advancement of NLP research revolves around the\nutilization of pre-trained transformer models such as BERT for the development\nof NER models. However, we focus on improving the performance of shallow models\nbased on CNN, and LSTM by combining the best of both worlds. In the era of\ntransformers, these traditional deep learning models are still relevant because\nof their high computational efficiency. We propose a hybrid approach for\nefficient NER by integrating a BERT-based subword tokenizer into vanilla\nCNN/LSTM models. We show that this simple approach of replacing a traditional\nword-based tokenizer with a BERT-tokenizer brings the accuracy of vanilla\nsingle-layer models closer to that of deep pre-trained models like BERT. We\nshow the importance of using sub-word tokenization for NER and present our\nstudy toward building efficient NLP systems. The evaluation is performed on\nL3Cube-MahaNER dataset using tokenizers from MahaBERT, MahaGPT, IndicBERT, and\nmBERT.", "published": "2023-12-03 06:53:53", "link": "http://arxiv.org/abs/2312.01306v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational\n  Applications", "abstract": "This paper presents the first Arabic crossword puzzle generator driven by\nadvanced AI technology. Leveraging cutting-edge large language models including\nGPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system\ngenerates distinctive and challenging clues. Based on a dataset comprising over\n50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot\nlearning strategies, and rigorous quality-checking protocols to enforce the\ngeneration of high-quality clue-answer pairs. Importantly, educational\ncrosswords contribute to enhancing memory, expanding vocabulary, and promoting\nproblem-solving skills, thereby augmenting the learning experience through a\nfun and engaging approach, reshaping the landscape of traditional learning\nmethods. The overall system can be exploited as a powerful educational tool\nthat amalgamates AI and innovative learning techniques, heralding a\ntransformative era for Arabic crossword puzzles and the intersection of\ntechnology and education.", "published": "2023-12-03 10:03:50", "link": "http://arxiv.org/abs/2312.01339v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise", "abstract": "In this paper, we introduce a novel fine-tuning technique for language\nmodels, which involves incorporating symmetric noise into the embedding\nprocess. This method aims to enhance the model's function by more stringently\nregulating its local curvature, demonstrating superior performance over the\ncurrent method, NEFTune. When fine-tuning the LLaMA-2-7B model using Alpaca,\nstandard techniques yield a 29.79% score on AlpacaEval. However, our approach,\nSymNoise, increases this score significantly to 69.04%, using symmetric noisy\nembeddings. This is a 6.7% improvement over the state-of-the-art method,\nNEFTune~(64.69%). Furthermore, when tested on various models and stronger\nbaseline instruction datasets, such as Evol-Instruct, ShareGPT, OpenPlatypus,\nSymNoise consistently outperforms NEFTune. The current literature, including\nNEFTune, has underscored the importance of more in-depth research into the\napplication of noise-based strategies in the fine-tuning of language models.\nOur approach, SymNoise, is another significant step towards this direction,\nshowing notable improvement over the existing state-of-the-art method.", "published": "2023-12-03 22:44:58", "link": "http://arxiv.org/abs/2312.01523v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Large Language Models to Accelerate Communication for Users with\n  Severe Motor Impairments", "abstract": "Finding ways to accelerate text input for individuals with profound motor\nimpairments has been a long-standing area of research. Closing the speed gap\nfor augmentative and alternative communication (AAC) devices such as\neye-tracking keyboards is important for improving the quality of life for such\nindividuals. Recent advances in neural networks of natural language pose new\nopportunities for re-thinking strategies and user interfaces for enhanced\ntext-entry for AAC users. In this paper, we present SpeakFaster, consisting of\nlarge language models (LLMs) and a co-designed user interface for text entry in\na highly-abbreviated form, allowing saving 57% more motor actions than\ntraditional predictive keyboards in offline simulation. A pilot study with 19\nnon-AAC participants typing on a mobile device by hand demonstrated gains in\nmotor savings in line with the offline simulation, while introducing relatively\nsmall effects on overall typing speed. Lab and field testing on two eye-gaze\ntyping users with amyotrophic lateral sclerosis (ALS) demonstrated text-entry\nrates 29-60% faster than traditional baselines, due to significant saving of\nexpensive keystrokes achieved through phrase and word predictions from\ncontext-aware LLMs. These findings provide a strong foundation for further\nexploration of substantially-accelerated text communication for motor-impaired\nusers and demonstrate a direction for applying LLMs to text-based user\ninterfaces.", "published": "2023-12-03 23:12:49", "link": "http://arxiv.org/abs/2312.01532v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Behind the Magic, MERLIM: Multi-modal Evaluation Benchmark for Large\n  Image-Language Models", "abstract": "Large Vision and Language Models have enabled significant advances in fully\nsupervised and zero-shot visual tasks. These large architectures serve as the\nbaseline to what is currently known as Instruction Tuning Large Vision and\nLanguage models (IT-LVLMs). IT-LVLMs are general-purpose multi-modal assistants\nwhose responses are modulated by natural language instructions and visual data.\nDespite this versatility, IT-LVLM effectiveness in fundamental computer vision\nproblems remains unclear, primarily due to the absence of a standardized\nevaluation benchmark. This paper introduces a Multi-modal Evaluation Benchmark\nnamed MERLIM, a scalable test-bed to assess the capabilities of IT-LVLMs on\nfundamental computer vision tasks. MERLIM contains over 300K image-question\npairs and has a strong focus on detecting cross-modal \"hallucination\" events in\nIT-LVLMs. Our results bring important insights on the performance of\nstate-of-the-art IT-LVMLs including limitations at identifying fine-grained\nvisual concepts, object hallucinations across tasks, and biases towards the\nlanguage query. Our findings also suggest that these models have weak visual\ngrounding, but manage to make adequate guesses from global visual patterns or\nlanguage biases contained in the LLM component.", "published": "2023-12-03 16:39:36", "link": "http://arxiv.org/abs/2312.02219v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long\n  Documents", "abstract": "Large language models (LLMs) have attracted huge interest in practical\napplications given their increasingly accurate responses and coherent reasoning\nabilities. Given their nature as black-boxes using complex reasoning processes\non their inputs, it is inevitable that the demand for scalable and faithful\nexplanations for LLMs' generated content will continue to grow. There have been\nmajor developments in the explainability of neural network models over the past\ndecade. Among them, post-hoc explainability methods, especially Shapley values,\nhave proven effective for interpreting deep learning models. However, there are\nmajor challenges in scaling up Shapley values for LLMs, particularly when\ndealing with long input contexts containing thousands of tokens and\nautoregressively generated output sequences. Furthermore, it is often unclear\nhow to effectively utilize generated explanations to improve the performance of\nLLMs. In this paper, we introduce TextGenSHAP, an efficient post-hoc\nexplanation method incorporating LM-specific techniques. We demonstrate that\nthis leads to significant increases in speed compared to conventional Shapley\nvalue computations, reducing processing times from hours to minutes for\ntoken-level explanations, and to just seconds for document-level explanations.\nIn addition, we demonstrate how real-time Shapley values can be utilized in two\nimportant scenarios, providing better understanding of long-document question\nanswering by localizing important words and sentences; and improving existing\ndocument retrieval systems through enhancing the accuracy of selected passages\nand ultimately the final responses.", "published": "2023-12-03 04:35:04", "link": "http://arxiv.org/abs/2312.01279v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal\n  Stakeholder's Perspective", "abstract": "Commercial contracts are known to be a valuable source for deriving\nproject-specific requirements. However, contract negotiations mainly occur\namong the legal counsel of the parties involved. The participation of non-legal\nstakeholders, including requirement analysts, engineers, and solution\narchitects, whose primary responsibility lies in ensuring the seamless\nimplementation of contractual terms, is often indirect and inadequate.\nConsequently, a significant number of sentences in contractual clauses, though\nlegally accurate, can appear unfair from an implementation perspective to\nnon-legal stakeholders. This perception poses a problem since requirements\nindicated in the clauses are obligatory and can involve punitive measures and\npenalties if not implemented as committed in the contract. Therefore, the\nidentification of potentially unfair clauses in contracts becomes crucial. In\nthis work, we conduct an empirical study to analyze the perspectives of\ndifferent stakeholders regarding contractual fairness. We then investigate the\nability of Pre-trained Language Models (PLMs) to identify unfairness in\ncontractual sentences by comparing chain of thought prompting and\nsemi-supervised fine-tuning approaches. Using BERT-based fine-tuning, we\nachieved an accuracy of 84% on a dataset consisting of proprietary contracts.\nIt outperformed chain of thought prompting using Vicuna-13B by a margin of 9%.", "published": "2023-12-03 13:52:32", "link": "http://arxiv.org/abs/2312.01398v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformers are uninterpretable with myopic methods: a case study with\n  bounded Dyck grammars", "abstract": "Interpretability methods aim to understand the algorithm implemented by a\ntrained model (e.g., a Transofmer) by examining various aspects of the model,\nsuch as the weight matrices or the attention patterns. In this work, through a\ncombination of theoretical results and carefully controlled experiments on\nsynthetic data, we take a critical view of methods that exclusively focus on\nindividual parts of the model, rather than consider the network as a whole. We\nconsider a simple synthetic setup of learning a (bounded) Dyck language.\nTheoretically, we show that the set of models that (exactly or approximately)\nsolve this task satisfy a structural characterization derived from ideas in\nformal languages (the pumping lemma). We use this characterization to show that\nthe set of optima is qualitatively rich; in particular, the attention pattern\nof a single layer can be ``nearly randomized'', while preserving the\nfunctionality of the network. We also show via extensive experiments that these\nconstructions are not merely a theoretical artifact: even after severely\nconstraining the architecture of the model, vastly different solutions can be\nreached via standard training. Thus, interpretability claims based on\ninspecting individual heads or weight matrices in the Transformer can be\nmisleading.", "published": "2023-12-03 15:34:46", "link": "http://arxiv.org/abs/2312.01429v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "D-Bot: Database Diagnosis System using Large Language Models", "abstract": "Database administrators (DBAs) play an important role in managing,\nmaintaining and optimizing database systems. However, it is hard and tedious\nfor DBAs to manage a large number of databases and give timely response\n(waiting for hours is intolerable in many online cases). In addition, existing\nempirical methods only support limited diagnosis scenarios, which are also\nlabor-intensive to update the diagnosis rules for database version updates.\nRecently large language models (LLMs) have shown great potential in various\nfields. Thus, we propose D-Bot, an LLM-based database diagnosis system that can\nautomatically acquire knowledge from diagnosis documents, and generate\nreasonable and well-founded diagnosis report (i.e., identifying the root causes\nand solutions) within acceptable time (e.g., under 10 minutes compared to hours\nby a DBA). The techniques in D-Bot include (i) offline knowledge extraction\nfrom documents, (ii) automatic prompt generation (e.g., knowledge matching,\ntool retrieval), (iii) root cause analysis using tree search algorithm, and\n(iv) collaborative mechanism for complex anomalies with multiple root causes.\nWe verify D-Bot on real benchmarks (including 539 anomalies of six typical\napplications), and the results show that D-Bot can effectively analyze the root\ncauses of unseen anomalies and significantly outperforms traditional methods\nand vanilla models like GPT-4.", "published": "2023-12-03 16:58:10", "link": "http://arxiv.org/abs/2312.01454v2", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Effectively Fine-tune to Improve Large Multimodal Models for Radiology\n  Report Generation", "abstract": "Writing radiology reports from medical images requires a high level of domain\nexpertise. It is time-consuming even for trained radiologists and can be\nerror-prone for inexperienced radiologists. It would be appealing to automate\nthis task by leveraging generative AI, which has shown drastic progress in\nvision and language understanding. In particular, Large Language Models (LLM)\nhave demonstrated impressive capabilities recently and continued to set new\nstate-of-the-art performance on almost all natural language tasks. While many\nhave proposed architectures to combine vision models with LLMs for multimodal\ntasks, few have explored practical fine-tuning strategies. In this work, we\nproposed a simple yet effective two-stage fine-tuning protocol to align visual\nfeatures to LLM's text embedding space as soft visual prompts. Our framework\nwith OpenLLaMA-7B achieved state-of-the-art level performance without\ndomain-specific pretraining. Moreover, we provide detailed analyses of soft\nvisual prompts and attention mechanisms, shedding light on future research\ndirections.", "published": "2023-12-03 20:42:38", "link": "http://arxiv.org/abs/2312.01504v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Tackling Bias in Pre-trained Language Models: Current Trends and\n  Under-represented Societies", "abstract": "The benefits and capabilities of pre-trained language models (LLMs) in\ncurrent and future innovations are vital to any society. However, introducing\nand using LLMs comes with biases and discrimination, resulting in concerns\nabout equality, diversity and fairness, and must be addressed. While\nunderstanding and acknowledging bias in LLMs and developing mitigation\nstrategies are crucial, the generalised assumptions towards societal needs can\nresult in disadvantages towards under-represented societies and indigenous\npopulations. Furthermore, the ongoing changes to actual and proposed amendments\nto regulations and laws worldwide also impact research capabilities in tackling\nthe bias problem. This research presents a comprehensive survey synthesising\nthe current trends and limitations in techniques used for identifying and\nmitigating bias in LLMs, where the overview of methods for tackling bias are\ngrouped into metrics, benchmark datasets, and mitigation strategies. The\nimportance and novelty of this survey are that it explores the perspective of\nunder-represented societies. We argue that current practices tackling the bias\nproblem cannot simply be 'plugged in' to address the needs of under-represented\nsocieties. We use examples from New Zealand to present requirements for\nadopting existing techniques to under-represented societies.", "published": "2023-12-03 21:25:10", "link": "http://arxiv.org/abs/2312.01509v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Bigger is not Always Better: The Effect of Context Size on Speech\n  Pre-Training", "abstract": "It has been generally assumed in the automatic speech recognition (ASR)\nliterature that it is better for models to have access to wider context\nwindows. Yet, many of the potential reasons this might be true in the\nsupervised setting do not necessarily transfer over to the case of unsupervised\nlearning. We investigate how much context is necessary to achieve high-quality\npre-trained acoustic models using self-supervised learning. We principally\ninvestigate contrastive predictive coding (CPC), which we adapt to be able to\nprecisely control the amount of context visible to the model during training\nand inference. We find that phone discriminability in the resulting model\nrepresentations peaks at around 40~ms of preceding context, and that having too\nmuch context (beyond around 320 ms) substantially degrades the quality of the\nrepresentations. Surprisingly, we find that this pattern also transfers to\nsupervised ASR when the pre-trained representations are used as frozen input\nfeatures. Our results point to potential changes in the design of current\nupstream architectures to better facilitate a variety of downstream tasks.", "published": "2023-12-03 22:08:54", "link": "http://arxiv.org/abs/2312.01515v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.CL"}
{"title": "T3D: Advancing 3D Medical Vision-Language Pre-training by Learning\n  Multi-View Visual Consistency", "abstract": "While 3D visual self-supervised learning (vSSL) shows promising results in\ncapturing visual representations, it overlooks the clinical knowledge from\nradiology reports. Meanwhile, 3D medical vision-language pre-training (MedVLP)\nremains underexplored due to the lack of a large-scale, publicly available 3D\nmedical image-report dataset. To bridge this gap, we introduce **CT-3DVLP**,\nthe first and largest **public** 3D volume-report dataset, establishing a\ncomprehensive benchmark for 3D MedVLP research. Meanwhile, we propose the\n**T3D** framework, which enhances 3D MedVLP beyond naive CLIP-style alignment\nthat directly pairs volumes with reports but neglects local visual\nrepresentations. Instead, we introduce **Text-informed Multi-view Alignment\n(TMA)**, a novel approach that clusters volumetric data while enforcing\nconsistency across different views of the same volume-report pair. TMA\nintegrates textual features into fine-grained visual representations, ensuring\ncontextual coherence across views. We evaluate T3D across multiple downstream\ntasks in both unimodal and cross-modal settings, including zero-shot and\nfine-tuned classification, cross-modal retrieval, report generation, and\nsemantic segmentation. Our results show that T3D consistently outperforms\nexisting vSSL and multimodal methods, demonstrating superior zero-shot and\nfine-tuning capabilities and setting a new benchmark for 3D medical image\nunderstanding.", "published": "2023-12-03 23:03:22", "link": "http://arxiv.org/abs/2312.01529v3", "categories": ["cs.CV", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "OpenVoice: Versatile Instant Voice Cloning", "abstract": "We introduce OpenVoice, a versatile voice cloning approach that requires only\na short audio clip from the reference speaker to replicate their voice and\ngenerate speech in multiple languages. OpenVoice represents a significant\nadvancement in addressing the following open challenges in the field: 1)\nFlexible Voice Style Control. OpenVoice enables granular control over voice\nstyles, including emotion, accent, rhythm, pauses, and intonation, in addition\nto replicating the tone color of the reference speaker. The voice styles are\nnot directly copied from and constrained by the style of the reference speaker.\nPrevious approaches lacked the ability to flexibly manipulate voice styles\nafter cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves\nzero-shot cross-lingual voice cloning for languages not included in the\nmassive-speaker training set. Unlike previous approaches, which typically\nrequire extensive massive-speaker multi-lingual (MSML) dataset for all\nlanguages, OpenVoice can clone voices into a new language without any\nmassive-speaker training data for that language. OpenVoice is also\ncomputationally efficient, costing tens of times less than commercially\navailable APIs that offer even inferior performance. To foster further research\nin the field, we have made the source code and trained model publicly\naccessible. We also provide qualitative results in our demo website. OpenVoice\nhas been used by more than 2M users worldwide as the voice engine of MyShell.ai", "published": "2023-12-03 18:41:54", "link": "http://arxiv.org/abs/2312.01479v6", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Livestock feeding behaviour: A review on automated systems for ruminant\n  monitoring", "abstract": "Livestock feeding behaviour is an influential research area for those\ninvolved in animal husbandry and agriculture. In recent years, there has been a\ngrowing interest in automated systems for monitoring the behaviour of\nruminants. Despite the developments accomplished in the last decade, there is\nstill much to do and learn about the methods for measuring and analysing\nlivestock feeding behaviour. Automated monitoring systems mainly use motion,\nacoustic, and image sensors to collect animal behavioural data. The performance\nevaluation of existing methods is a complex task and direct comparisons between\nstudies are difficult. Several factors prevent a direct comparison, starting\nfrom the diversity of data and performance metrics used in the experiments. To\nthe best of our knowledge, this work represents the first tutorial-style review\non the analysis of the feeding behaviour of ruminants, emphasising the\nrelationship between sensing methodologies, signal processing, and\ncomputational intelligence methods. It assesses the main sensing methodologies\n(i.e. based on movement, sound, images/videos, and pressure) and the main\ntechniques to measure and analyse the signals associated with feeding\nbehaviour, evaluating their use in different settings and situations. It also\nhighlights the potentiality of automated monitoring systems to provide valuable\ninformation that improves our understanding of livestock feeding behaviour. The\nrelevance of these systems is increasingly important due to their impact on\nproduction systems and research. Finally, the paper closes by discussing future\nchallenges and opportunities in livestock feeding behaviour monitoring.", "published": "2023-12-03 13:42:55", "link": "http://arxiv.org/abs/2312.09259v3", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "eess.SP"}
