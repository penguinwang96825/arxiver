{"title": "A corpus of precise natural textual entailment problems", "abstract": "In this paper, we present a new corpus of entailment problems. This corpus\ncombines the following characteristics: 1. it is precise (does not leave out\nimplicit hypotheses) 2. it is based on \"real-world\" texts (i.e. most of the\npremises were written for purposes other than testing textual entailment). 3.\nits size is 150. The corpus was constructed by taking problems from the Real\nText Entailment and discovering missing hypotheses using a crowd of experts. We\nbelieve that this corpus constitutes a first step towards wide-coverage testing\nof precise natural-language inference systems.", "published": "2018-12-14 08:09:29", "link": "http://arxiv.org/abs/1812.05813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Reliable Novel Word Senses: A Network-Centric Approach", "abstract": "In this era of Big Data, due to expeditious exchange of information on the\nweb, words are being used to denote newer meanings, causing linguistic shift.\nWith the recent availability of large amounts of digitized texts, an automated\nanalysis of the evolution of language has become possible. Our study mainly\nfocuses on improving the detection of new word senses. This paper presents a\nunique proposal based on network features to improve the precision of new word\nsense detection. For a candidate word where a new sense (birth) has been\ndetected by comparing the sense clusters induced at two different time points,\nwe further compare the network properties of the subgraphs induced from novel\nsense cluster across these two time points. Using the mean fractional change in\nedge density, structural similarity and average path length as features in an\nSVM classifier, manual evaluation gives precision values of 0.86 and 0.74 for\nthe task of new sense detection, when tested on 2 distinct time-point pairs, in\ncomparison to the precision values in the range of 0.23-0.32, when the proposed\nscheme is not used. The outlined method can therefore be used as a new post-hoc\nstep to improve the precision of novel word sense detection in a robust and\nreliable way where the underlying framework uses a graph structure. Another\nimportant observation is that even though our proposal is a post-hoc step, it\ncan be used in isolation and that itself results in a very decent performance\nachieving a precision of 0.54-0.62. Finally, we show that our method is able to\ndetect the well-known historical shifts in 80% cases.", "published": "2018-12-14 13:57:43", "link": "http://arxiv.org/abs/1812.05936v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Similarity: Computationally Reproducing the Scholar's\n  Interests", "abstract": "Computerized document classification already orders the news articles that\nApple's \"News\" app or Google's \"personalized search\" feature groups together to\nmatch a reader's interests. The invisible and therefore illegible decisions\nthat go into these tailored searches have been the subject of a critique by\nscholars who emphasize that our intelligence about documents is only as good as\nour ability to understand the criteria of search. This article will attempt to\nunpack the procedures used in computational classification of texts,\ntranslating them into term legible to humanists, and examining opportunities to\nrender the computational text classification process subject to expert critique\nand improvement.", "published": "2018-12-14 15:39:34", "link": "http://arxiv.org/abs/1812.05984v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational Intent Understanding for Passengers in Autonomous\n  Vehicles", "abstract": "Understanding passenger intents and extracting relevant slots are important\nbuilding blocks towards developing a contextual dialogue system responsible for\nhandling certain vehicle-passenger interactions in autonomous vehicles (AV).\nWhen the passengers give instructions to AMIE (Automated-vehicle Multimodal\nIn-cabin Experience), the agent should parse such commands properly and trigger\nthe appropriate functionality of the AV system. In our AMIE scenarios, we\ndescribe usages and support various natural commands for interacting with the\nvehicle. We collected a multimodal in-cabin data-set with multi-turn dialogues\nbetween the passengers and AMIE using a Wizard-of-Oz scheme. We explored\nvarious recent Recurrent Neural Networks (RNN) based techniques and built our\nown hierarchical models to recognize passenger intents along with relevant\nslots associated with the action to be performed in AV scenarios. Our\nexperimental results achieved F1-score of 0.91 on utterance-level intent\nrecognition and 0.96 on slot extraction models.", "published": "2018-12-14 00:43:58", "link": "http://arxiv.org/abs/1901.04899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Classify, Translate: Multi-Level E-Commerce Product Categorization\n  Via Machine Translation", "abstract": "E-commerce platforms categorize their products into a multi-level taxonomy\ntree with thousands of leaf categories. Conventional methods for product\ncategorization are typically based on machine learning classification\nalgorithms. These algorithms take product information as input (e.g., titles\nand descriptions) to classify a product into a leaf category. In this paper, we\npropose a new paradigm based on machine translation. In our approach, we\ntranslate a product's natural language description into a sequence of tokens\nrepresenting a root-to-leaf path in a product taxonomy. In our experiments on\ntwo large real-world datasets, we show that our approach achieves better\npredictive accuracy than a state-of-the-art classification system for product\ncategorization. In addition, we demonstrate that our machine translation models\ncan propose meaningful new paths between previously unconnected nodes in a\ntaxonomy tree, thereby transforming the taxonomy into a directed acyclic graph\n(DAG). We discuss how the resultant taxonomy DAG promotes user-friendly\nnavigation, and how it is more adaptable to new products.", "published": "2018-12-14 04:12:02", "link": "http://arxiv.org/abs/1812.05774v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Neural Multi-Task Learning Framework to Jointly Model Medical Named\n  Entity Recognition and Normalization", "abstract": "State-of-the-art studies have demonstrated the superiority of joint modelling\nover pipeline implementation for medical named entity recognition and\nnormalization due to the mutual benefits between the two processes. To exploit\nthese benefits in a more sophisticated way, we propose a novel deep neural\nmulti-task learning framework with explicit feedback strategies to jointly\nmodel recognition and normalization. On one hand, our method benefits from the\ngeneral representations of both tasks provided by multi-task learning. On the\nother hand, our method successfully converts hierarchical tasks into a parallel\nmulti-task setting while maintaining the mutual supports between tasks. Both of\nthese aspects improve the model performance. Experimental results demonstrate\nthat our method performs significantly better than state-of-the-art approaches\non two publicly available medical literature datasets.", "published": "2018-12-14 18:59:41", "link": "http://arxiv.org/abs/1812.06081v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Conversational Agents With Weak Supervision", "abstract": "Many conversational agents in the market today follow a standard bot\ndevelopment framework which requires training intent classifiers to recognize\nuser input. The need to create a proper set of training examples is often the\nbottleneck in the development process. In many occasions agent developers have\naccess to historical chat logs that can provide a good quantity as well as\ncoverage of training examples. However, the cost of labeling them with tens to\nhundreds of intents often prohibits taking full advantage of these chat logs.\nIn this paper, we present a framework called \\textit{search, label, and\npropagate} (SLP) for bootstrapping intents from existing chat logs using weak\nsupervision. The framework reduces hours to days of labeling effort down to\nminutes of work by using a search engine to find examples, then relies on a\ndata programming approach to automatically expand the labels. We report on a\nuser study that shows positive user feedback for this new approach to build\nconversational agents, and demonstrates the effectiveness of using data\nprogramming for auto-labeling. While the system is developed for training\nconversational agents, the framework has broader application in significantly\nreducing labeling effort for training text classifiers.", "published": "2018-12-14 21:32:40", "link": "http://arxiv.org/abs/1812.06176v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Inferring the size of the causal universe: features and fusion of causal\n  attribution networks", "abstract": "Cause-and-effect reasoning, the attribution of effects to causes, is one of\nthe most powerful and unique skills humans possess. Multiple surveys are\nmapping out causal attributions as networks, but it is unclear how well these\nefforts can be combined. Further, the total size of the collective causal\nattribution network held by humans is currently unknown, making it challenging\nto assess the progress of these surveys. Here we study three causal attribution\nnetworks to determine how well they can be combined into a single network.\nCombining these networks requires dealing with ambiguous nodes, as nodes\nrepresent written descriptions of causes and effects and different descriptions\nmay exist for the same concept. We introduce NetFUSES, a method for combining\nnetworks with ambiguous nodes. Crucially, treating the different causal\nattributions networks as independent samples allows us to use their overlap to\nestimate the total size of the collective causal attribution network. We find\nthat existing surveys capture 5.77% $\\pm$ 0.781% of the $\\approx$293 000 causes\nand effects estimated to exist, and 0.198% $\\pm$ 0.174% of the $\\approx$10 200\n000 attributed cause-effect relationships.", "published": "2018-12-14 17:28:20", "link": "http://arxiv.org/abs/1812.06038v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "stat.AP"], "primary_category": "cs.SI"}
{"title": "Few-shot classification in Named Entity Recognition Task", "abstract": "For many natural language processing (NLP) tasks the amount of annotated data\nis limited. This urges a need to apply semi-supervised learning techniques,\nsuch as transfer learning or meta-learning. In this work we tackle Named Entity\nRecognition (NER) task using Prototypical Network - a metric learning\ntechnique. It learns intermediate representations of words which cluster well\ninto named entity classes. This property of the model allows classifying words\nwith extremely limited number of training examples, and can potentially be used\nas a zero-shot learning method. By coupling this technique with transfer\nlearning we achieve well-performing classifiers trained on only 20 instances of\na target class.", "published": "2018-12-14 20:39:47", "link": "http://arxiv.org/abs/1812.06158v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Inter-sentence Relation Extraction for Associating Biological Context\n  with Events in Biomedical Texts", "abstract": "We present an analysis of the problem of identifying biological context and\nassociating it with biochemical events in biomedical texts. This constitutes a\nnon-trivial, inter-sentential relation extraction task. We focus on biological\ncontext as descriptions of the species, tissue type and cell type that are\nassociated with biochemical events. We describe the properties of an annotated\ncorpus of context-event relations and present and evaluate several classifiers\nfor context-event association trained on syntactic, distance and frequency\nfeatures.", "published": "2018-12-14 23:03:41", "link": "http://arxiv.org/abs/1812.06199v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Parameterization of Sequence of MFCCs for DNN-based voice disorder\n  detection", "abstract": "In this article a DNN-based system for detection of three common voice\ndisorders (vocal nodules, polyps and cysts; laryngeal neoplasm; unilateral\nvocal paralysis) is presented. The input to the algorithm is (at least 3-second\nlong) audio recording of sustained vowel sound /a:/. The algorithm was\ndeveloped as part of the \"2018 FEMH Voice Data Challenge\" organized by Far\nEastern Memorial Hospital and obtained score value (defined in the challenge\nspecification) of 77.44. This was the second best result before final\nsubmission. Final challenge results are not yet known during writing of this\ndocument. The document also reports changes that were made for the final\nsubmission which improved the score value in cross-validation by 0.6% points.", "published": "2018-12-14 12:44:21", "link": "http://arxiv.org/abs/1812.05888v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluation of an open-source implementation of the SRP-PHAT algorithm\n  within the 2018 LOCATA challenge", "abstract": "This short paper presents an efficient, flexible implementation of the\nSRP-PHAT multichannel sound source localization method. The method is evaluated\non the single-source tasks of the LOCATA 2018 development dataset, and an\nassociated Matlab toolbox is made available online.", "published": "2018-12-14 13:15:45", "link": "http://arxiv.org/abs/1812.05901v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AdaFlow: Domain-Adaptive Density Estimator with Application to Anomaly\n  Detection and Unpaired Cross-Domain Translation", "abstract": "We tackle unsupervised anomaly detection (UAD), a problem of detecting data\nthat significantly differ from normal data. UAD is typically solved by using\ndensity estimation. Recently, deep neural network (DNN)-based density\nestimators, such as Normalizing Flows, have been attracting attention. However,\none of their drawbacks is the difficulty in adapting them to the change in the\nnormal data's distribution. To address this difficulty, we propose AdaFlow, a\nnew DNN-based density estimator that can be easily adapted to the change of the\ndistribution. AdaFlow is a unified model of a Normalizing Flow and Adaptive\nBatch-Normalizations, a module that enables DNNs to adapt to new distributions.\nAdaFlow can be adapted to a new distribution by just conducting forward\npropagation once per sample; hence, it can be used on devices that have limited\ncomputational resources. We have confirmed the effectiveness of the proposed\nmodel through an anomaly detection in a sound task. We also propose a method of\napplying AdaFlow to the unpaired cross-domain translation problem, in which one\nhas to train a cross-domain translation model with only unpaired samples. We\nhave confirmed that our model can be used for the cross-domain translation\nproblem through experiments on image datasets.", "published": "2018-12-14 06:40:02", "link": "http://arxiv.org/abs/1812.05796v2", "categories": ["stat.ML", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "stat.ML"}
{"title": "Semi-Supervised Monaural Singing Voice Separation With a Masking Network\n  Trained on Synthetic Mixtures", "abstract": "We study the problem of semi-supervised singing voice separation, in which\nthe training data contains a set of samples of mixed music (singing and\ninstrumental) and an unmatched set of instrumental music. Our solution employs\na single mapping function g, which, applied to a mixed sample, recovers the\nunderlying instrumental music, and, applied to an instrumental sample, returns\nthe same sample. The network g is trained using purely instrumental samples, as\nwell as on synthetic mixed samples that are created by mixing reconstructed\nsinging voices with random instrumental samples. Our results indicate that we\nare on a par with or better than fully supervised methods, which are also\nprovided with training samples of unmixed singing voices, and are better than\nother recent semi-supervised methods.", "published": "2018-12-14 08:17:24", "link": "http://arxiv.org/abs/1812.06087v3", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Towards Unsupervised Single-Channel Blind Source Separation using\n  Adversarial Pair Unmix-and-Remix", "abstract": "Blind single-channel source separation is a long standing signal processing\nchallenge. Many methods were proposed to solve this task utilizing multiple\nsignal priors such as low rank, sparsity, temporal continuity etc. The recent\nadvance of generative adversarial models presented new opportunities in signal\nregression tasks. The power of adversarial training however has not yet been\nrealized for blind source separation tasks. In this work, we propose a novel\nmethod for blind source separation (BSS) using adversarial methods. We rely on\nthe independence of sources for creating adversarial constraints on pairs of\napproximately separated sources, which ensure good separation. Experiments are\ncarried out on image sources validating the good performance of our approach,\nand presenting our method as a promising approach for solving BSS for general\nsignals.", "published": "2018-12-14 09:27:29", "link": "http://arxiv.org/abs/1812.07504v2", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "eess.SP"}
