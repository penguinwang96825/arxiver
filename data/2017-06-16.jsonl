{"title": "An Automatic Approach for Document-level Topic Model Evaluation", "abstract": "Topic models jointly learn topics and document-level topic distribution.\nExtrinsic evaluation of topic models tends to focus exclusively on topic-level\nevaluation, e.g. by assessing the coherence of topics. We demonstrate that\nthere can be large discrepancies between topic- and document-level model\nquality, and that basing model evaluation on topic-level analysis can be highly\nmisleading. We propose a method for automatically predicting topic model\nquality based on analysis of document-level topic allocations, and provide\nempirical evidence for its robustness.", "published": "2017-06-16 03:53:38", "link": "http://arxiv.org/abs/1706.05140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deal or No Deal? End-to-End Learning for Negotiation Dialogues", "abstract": "Much of human dialogue occurs in semi-cooperative settings, where agents with\ndifferent goals attempt to agree on common decisions. Negotiations require\ncomplex communication and reasoning skills, but success is easy to measure,\nmaking this an interesting task for AI. We gather a large dataset of\nhuman-human negotiations on a multi-issue bargaining task, where agents who\ncannot observe each other's reward functions must reach an agreement (or a\ndeal) via natural language dialogue. For the first time, we show it is possible\nto train end-to-end models for negotiation, which must learn both linguistic\nand reasoning skills with no annotated dialogue states. We also introduce\ndialogue rollouts, in which the model plans ahead by simulating possible\ncomplete continuations of the conversation, and find that this technique\ndramatically improves performance. Our code and dataset are publicly available\n(https://github.com/facebookresearch/end-to-end-negotiator).", "published": "2017-06-16 01:26:09", "link": "http://arxiv.org/abs/1706.05125v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Active learning in annotating micro-blogs dealing with e-reputation", "abstract": "Elections unleash strong political views on Twitter, but what do people\nreally think about politics? Opinion and trend mining on micro blogs dealing\nwith politics has recently attracted researchers in several fields including\nInformation Retrieval and Machine Learning (ML). Since the performance of ML\nand Natural Language Processing (NLP) approaches are limited by the amount and\nquality of data available, one promising alternative for some tasks is the\nautomatic propagation of expert annotations. This paper intends to develop a\nso-called active learning process for automatically annotating French language\ntweets that deal with the image (i.e., representation, web reputation) of\npoliticians. Our main focus is on the methodology followed to build an original\nannotated dataset expressing opinion from two French politicians over time. We\ntherefore review state of the art NLP-based ML algorithms to automatically\nannotate tweets using a manual initiation step as bootstrap. This paper focuses\non key issues about active learning while building a large annotated data set\nfrom noise. This will be introduced by human annotators, abundance of data and\nthe label distribution across data and entities. In turn, we show that Twitter\ncharacteristics such as the author's name or hashtags can be considered as the\nbearing point to not only improve automatic systems for Opinion Mining (OM) and\nTopic Classification but also to reduce noise in human annotations. However, a\nlater thorough analysis shows that reducing noise might induce the loss of\ncrucial information.", "published": "2017-06-16 17:07:24", "link": "http://arxiv.org/abs/1706.05349v4", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Bib2vec: An Embedding-based Search System for Bibliographic Information", "abstract": "We propose a novel embedding model that represents relationships among\nseveral elements in bibliographic information with high representation ability\nand flexibility. Based on this model, we present a novel search system that\nshows the relationships among the elements in the ACL Anthology Reference\nCorpus. The evaluation results show that our model can achieve a high\nprediction ability and produce reasonable search results.", "published": "2017-06-16 00:53:28", "link": "http://arxiv.org/abs/1706.05122v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "An online sequence-to-sequence model for noisy speech recognition", "abstract": "Generative models have long been the dominant approach for speech\nrecognition. The success of these models however relies on the use of\nsophisticated recipes and complicated machinery that is not easily accessible\nto non-practitioners. Recent innovations in Deep Learning have given rise to an\nalternative - discriminative models called Sequence-to-Sequence models, that\ncan almost match the accuracy of state of the art generative models. While\nthese models are easy to train as they can be trained end-to-end in a single\nstep, they have a practical limitation that they can only be used for offline\nrecognition. This is because the models require that the entirety of the input\nsequence be available at the beginning of inference, an assumption that is not\nvalid for instantaneous speech recognition. To address this problem, online\nsequence-to-sequence models were recently introduced. These models are able to\nstart producing outputs as data arrives, and the model feels confident enough\nto output partial transcripts. These models, like sequence-to-sequence are\ncausal - the output produced by the model until any time, $t$, affects the\nfeatures that are computed subsequently. This makes the model inherently more\npowerful than generative models that are unable to change features that are\ncomputed from the data. This paper highlights two main contributions - an\nimprovement to online sequence-to-sequence model training, and its application\nto noisy settings with mixed speech from two speakers.", "published": "2017-06-16 20:58:43", "link": "http://arxiv.org/abs/1706.06428v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
