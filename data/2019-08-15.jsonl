{"title": "Multi-Task Self-Supervised Learning for Disfluency Detection", "abstract": "Most existing approaches to disfluency detection heavily rely on\nhuman-annotated data, which is expensive to obtain in practice. To tackle the\ntraining data bottleneck, we investigate methods for combining multiple\nself-supervised tasks-i.e., supervised tasks where data can be collected\nwithout manual labeling. First, we construct large-scale pseudo training data\nby randomly adding or deleting words from unlabeled news data, and propose two\nself-supervised pre-training tasks: (i) tagging task to detect the added noisy\nwords. (ii) sentence classification to distinguish original sentences from\ngrammatically-incorrect sentences. We then combine these two tasks to jointly\ntrain a network. The pre-trained network is then fine-tuned using\nhuman-annotated disfluency detection training data. Experimental results on the\ncommonly used English Switchboard test set show that our approach can achieve\ncompetitive performance compared to the previous systems (trained using the\nfull dataset) by using less than 1% (1000 sentences) of the training data. Our\nmethod trained on the full dataset significantly outperforms previous methods,\nreducing the error by 21% on English Switchboard.", "published": "2019-08-15 00:22:38", "link": "http://arxiv.org/abs/1908.05378v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards End-to-End Learning for Efficient Dialogue Agent by Modeling\n  Looking-ahead Ability", "abstract": "Learning an efficient manager of dialogue agent from data with little manual\nintervention is important, especially for goal-oriented dialogues. However,\nexisting methods either take too many manual efforts (e.g. reinforcement\nlearning methods) or cannot guarantee the dialogue efficiency (e.g.\nsequence-to-sequence methods). In this paper, we address this problem by\nproposing a novel end-to-end learning model to train a dialogue agent that can\nlook ahead for several future turns and generate an optimal response to make\nthe dialogue efficient. Our method is data-driven and does not require too much\nmanual work for intervention during system design. We evaluate our method on\ntwo datasets of different scenarios and the experimental results demonstrate\nthe efficiency of our model.", "published": "2019-08-15 03:50:53", "link": "http://arxiv.org/abs/1908.05408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XCMRC: Evaluating Cross-lingual Machine Reading Comprehension", "abstract": "We present XCMRC, the first public cross-lingual language understanding (XLU)\nbenchmark which aims to test machines on their cross-lingual reading\ncomprehension ability. To be specific, XCMRC is a Cross-lingual Cloze-style\nMachine Reading Comprehension task which requires the reader to fill in a\nmissing word (we additionally provide ten noun candidates) in a sentence\nwritten in target language (English / Chinese) by reading a given passage\nwritten in source language (Chinese / English). Chinese and English are\nrich-resource language pairs, in order to study low-resource cross-lingual\nmachine reading comprehension (XMRC), besides defining the common XCMRC task\nwhich has no restrictions on use of external language resources, we also define\nthe pseudo low-resource XCMRC task by limiting the language resources to be\nused. In addition, we provide two baselines for common XCMRC task and two for\npseudo XCMRC task respectively. We also provide an upper bound baseline for\nboth tasks. We found that for common XCMRC task, translation-based method and\nmultilingual sentence encoder-based method can obtain reasonable performance\nbut still have much room for improvement. As for pseudo low-resource XCMRC\ntask, due to strict restrictions on the use of language resources, our two\napproaches are far below the upper bound so there are many challenges ahead.", "published": "2019-08-15 04:40:27", "link": "http://arxiv.org/abs/1908.05416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's Wrong with Hebrew NLP? And How to Make it Right", "abstract": "For languages with simple morphology, such as English, automatic annotation\npipelines such as spaCy or Stanford's CoreNLP successfully serve projects in\nacademia and the industry. For many morphologically-rich languages (MRLs),\nsimilar pipelines show sub-optimal performance that limits their applicability\nfor text analysis in research and the industry.The sub-optimal performance is\nmainly due to errors in early morphological disambiguation decisions, which\ncannot be recovered later in the pipeline, yielding incoherent annotations on\nthe whole. In this paper we describe the design and use of the Onlp suite, a\njoint morpho-syntactic parsing framework for processing Modern Hebrew texts.\nThe joint inference over morphology and syntax substantially limits error\npropagation, and leads to high accuracy. Onlp provides rich and expressive\noutput which already serves diverse academic and commercial needs. Its\naccompanying online demo further serves educational activities, introducing\nHebrew NLP intricacies to researchers and non-researchers alike.", "published": "2019-08-15 08:09:52", "link": "http://arxiv.org/abs/1908.05453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Type Multi-Span Network for Reading Comprehension that Requires\n  Discrete Reasoning", "abstract": "Rapid progress has been made in the field of reading comprehension and\nquestion answering, where several systems have achieved human parity in some\nsimplified settings. However, the performance of these models degrades\nsignificantly when they are applied to more realistic scenarios, such as\nanswers involve various types, multiple text strings are correct answers, or\ndiscrete reasoning abilities are required. In this paper, we introduce the\nMulti-Type Multi-Span Network (MTMSN), a neural reading comprehension model\nthat combines a multi-type answer predictor designed to support various answer\ntypes (e.g., span, count, negation, and arithmetic expression) with a\nmulti-span extraction method for dynamically producing one or multiple text\nspans. In addition, an arithmetic expression reranking mechanism is proposed to\nrank expression candidates for further confirming the prediction. Experiments\nshow that our model achieves 79.9 F1 on the DROP hidden test set, creating new\nstate-of-the-art results. Source\ncode\\footnote{\\url{https://github.com/huminghao16/MTMSN}} is released to\nfacilitate future work.", "published": "2019-08-15 12:32:52", "link": "http://arxiv.org/abs/1908.05514v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Multi-Word Entity Recognition for Biomedical Texts", "abstract": "Biomedical Named Entity Recognition (BioNER) is a crucial step for analyzing\nBiomedical texts, which aims at extracting biomedical named entities from a\ngiven text. Different supervised machine learning algorithms have been applied\nfor BioNER by various researchers. The main requirement of these approaches is\nan annotated dataset used for learning the parameters of machine learning\nalgorithms. Segment Representation (SR) models comprise of different tag sets\nused for representing the annotated data, such as IOB2, IOE2 and IOBES. In this\npaper, we propose an extension of IOBES model to improve the performance of\nBioNER. The proposed SR model, FROBES, improves the representation of\nmulti-word entities. We used Bidirectional Long Short-Term Memory (BiLSTM)\nnetwork; an instance of Recurrent Neural Networks (RNN), to design a baseline\nsystem for BioNER and evaluated the new SR model on two datasets, i2b2/VA 2010\nchallenge dataset and JNLPBA 2004 shared task dataset. The proposed SR model\noutperforms other models for multi-word entities with length greater than two.\nFurther, the outputs of different SR models have been combined using majority\nvoting ensemble method which outperforms the baseline models performance.", "published": "2019-08-15 18:04:39", "link": "http://arxiv.org/abs/1908.05691v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple and Effective Noisy Channel Modeling for Neural Machine\n  Translation", "abstract": "Previous work on neural noisy channel modeling relied on latent variable\nmodels that incrementally process the source and target sentence. This makes\ndecoding decisions based on partial source prefixes even though the full source\nis available. We pursue an alternative approach based on standard sequence to\nsequence models which utilize the entire source. These models perform\nremarkably well as channel models, even though they have neither been trained\non, nor designed to factor over incomplete target sentences. Experiments with\nneural language models trained on billions of words show that noisy channel\nmodels can outperform a direct model by up to 3.2 BLEU on WMT'17 German-English\ntranslation. We evaluate on four language-pairs and our channel models\nconsistently outperform strong alternatives such right-to-left reranking models\nand ensembles of direct models.", "published": "2019-08-15 19:54:23", "link": "http://arxiv.org/abs/1908.05731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abductive Commonsense Reasoning", "abstract": "Abductive reasoning is inference to the most plausible explanation. For\nexample, if Jenny finds her house in a mess when she returns from work, and\nremembers that she left a window open, she can hypothesize that a thief broke\ninto her house and caused the mess, as the most plausible explanation. While\nabduction has long been considered to be at the core of how people interpret\nand read between the lines in natural language (Hobbs et al., 1988), there has\nbeen relatively little research in support of abductive natural language\ninference and generation. We present the first study that investigates the\nviability of language-based abductive reasoning. We introduce a challenge\ndataset, ART, that consists of over 20k commonsense narrative contexts and 200k\nexplanations. Based on this dataset, we conceptualize two new tasks -- (i)\nAbductive NLI: a multiple-choice question answering task for choosing the more\nlikely explanation, and (ii) Abductive NLG: a conditional generation task for\nexplaining given observations in natural language. On Abductive NLI, the best\nmodel achieves 68.9% accuracy, well below human performance of 91.4%. On\nAbductive NLG, the current best language generators struggle even more, as they\nlack reasoning capabilities that are trivial for humans. Our analysis leads to\nnew insights into the types of reasoning that deep pre-trained language models\nfail to perform--despite their strong performance on the related but more\nnarrowly defined task of entailment NLI--pointing to interesting avenues for\nfuture research.", "published": "2019-08-15 20:03:10", "link": "http://arxiv.org/abs/1908.05739v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unpaired Cross-lingual Image Caption Generation with Self-Supervised\n  Rewards", "abstract": "Generating image descriptions in different languages is essential to satisfy\nusers worldwide. However, it is prohibitively expensive to collect large-scale\npaired image-caption dataset for every target language which is critical for\ntraining descent image captioning models. Previous works tackle the unpaired\ncross-lingual image captioning problem through a pivot language, which is with\nthe help of paired image-caption data in the pivot language and pivot-to-target\nmachine translation models. However, such language-pivoted approach suffers\nfrom inaccuracy brought by the pivot-to-target translation, including\ndisfluency and visual irrelevancy errors. In this paper, we propose to generate\ncross-lingual image captions with self-supervised rewards in the reinforcement\nlearning framework to alleviate these two types of errors. We employ\nself-supervision from mono-lingual corpus in the target language to provide\nfluency reward, and propose a multi-level visual semantic matching model to\nprovide both sentence-level and concept-level visual relevancy rewards. We\nconduct extensive experiments for unpaired cross-lingual image captioning in\nboth English and Chinese respectively on two widely used image caption corpora.\nThe proposed approach achieves significant performance improvement over\nstate-of-the-art methods.", "published": "2019-08-15 03:50:18", "link": "http://arxiv.org/abs/1908.05407v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multi-class Hierarchical Question Classification for Multiple Choice\n  Science Exams", "abstract": "Prior work has demonstrated that question classification (QC), recognizing\nthe problem domain of a question, can help answer it more accurately. However,\ndeveloping strong QC algorithms has been hindered by the limited size and\ncomplexity of annotated data available. To address this, we present the largest\nchallenge dataset for QC, containing 7,787 science exam questions paired with\ndetailed classification labels from a fine-grained hierarchical taxonomy of 406\nproblem domains. We then show that a BERT-based model trained on this dataset\nachieves a large (+0.12 MAP) gain compared with previous methods, while also\nachieving state-of-the-art performance on benchmark open-domain and biomedical\nQC datasets. Finally, we show that using this model's predictions of question\ntopic significantly improves the accuracy of a question answering system by\n+1.7% P@1, with substantial future gains possible as QC performance improves.", "published": "2019-08-15 07:00:16", "link": "http://arxiv.org/abs/1908.05441v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multivariate Model for Representing Semantic Non-compositionality", "abstract": "Semantically non-compositional phrases constitute an intriguing research\ntopic in Natural Language Processing. Semantic non-compositionality --the\nsituation when the meaning of a phrase cannot be derived from the meaning of\nits components, is the main characteristic of such phrases, however, they bear\nother characteristics such as high statistical association and\nnon-substitutability. In this work, we present a model for identifying\nnon-compositional phrases that takes into account all of these characteristics.\nWe show that the presented model remarkably outperforms the existing models of\nidentifying non-compositional phrases that mostly focus only on one of these\ncharacteristics.", "published": "2019-08-15 10:58:57", "link": "http://arxiv.org/abs/1908.05490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Vector spaces as Kripke frames", "abstract": "In recent years, the compositional distributional approach in computational\nlinguistics has opened the way for an integration of the \\emph{lexical} aspects\nof meaning into Lambek's type-logical grammar program. This approach is based\non the observation that a sound semantics for the associative, commutative and\nunital Lambek calculus can be based on vector spaces by interpreting fusion as\nthe tensor product of vector spaces.\n  In this paper, we build on this observation and extend it to a `vector space\nsemantics' for the \\emph{general} Lambek calculus, based on \\emph{algebras over\na field} $\\mathbb{K}$ (or $\\mathbb{K}$-algebras), i.e. vector spaces endowed\nwith a bilinear binary product. Such structures are well known in algebraic\ngeometry and algebraic topology, since they are important instances of Lie\nalgebras and Hopf algebras. Applying results and insights from duality and\nrepresentation theory for the algebraic semantics of nonclassical logics, we\nregard $\\mathbb{K}$-algebras as `Kripke frames' the complex algebras of which\nare complete residuated lattices.\n  This perspective makes it possible to establish a systematic connection\nbetween vector space semantics and the standard Routley-Meyer semantics of\n(modal) substructural logics.", "published": "2019-08-15 13:26:44", "link": "http://arxiv.org/abs/1908.05528v4", "categories": ["cs.LO", "cs.CL"], "primary_category": "cs.LO"}
{"title": "Visualizing and Understanding the Effectiveness of BERT", "abstract": "Language model pre-training, such as BERT, has achieved remarkable results in\nmany NLP tasks. However, it is unclear why the pre-training-then-fine-tuning\nparadigm can improve performance and generalization capability across different\ntasks. In this paper, we propose to visualize loss landscapes and optimization\ntrajectories of fine-tuning BERT on specific datasets. First, we find that\npre-training reaches a good initial point across downstream tasks, which leads\nto wider optima and easier optimization compared with training from scratch. We\nalso demonstrate that the fine-tuning procedure is robust to overfitting, even\nthough BERT is highly over-parameterized for downstream tasks. Second, the\nvisualization results indicate that fine-tuning BERT tends to generalize better\nbecause of the flat and wide optima, and the consistency between the training\nloss surface and the generalization error surface. Third, the lower layers of\nBERT are more invariant during fine-tuning, which suggests that the layers that\nare close to input learn more transferable representations of language.", "published": "2019-08-15 16:11:45", "link": "http://arxiv.org/abs/1908.05620v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SenseBERT: Driving Some Sense into BERT", "abstract": "The ability to learn from large unlabeled corpora has allowed neural language\nmodels to advance the frontier in natural language understanding. However,\nexisting self-supervision techniques operate at the word form level, which\nserves as a surrogate for the underlying semantic content. This paper proposes\na method to employ weak-supervision directly at the word sense level. Our\nmodel, named SenseBERT, is pre-trained to predict not only the masked words but\nalso their WordNet supersenses. Accordingly, we attain a lexical-semantic level\nlanguage model, without the use of human annotation. SenseBERT achieves\nsignificantly improved lexical understanding, as we demonstrate by\nexperimenting on SemEval Word Sense Disambiguation, and by attaining a state of\nthe art result on the Word in Context task.", "published": "2019-08-15 17:20:20", "link": "http://arxiv.org/abs/1908.05646v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Making the Most of BERT in Neural Machine Translation", "abstract": "GPT-2 and BERT demonstrate the effectiveness of using pre-trained language\nmodels (LMs) on various natural language processing tasks. However, LM\nfine-tuning often suffers from catastrophic forgetting when applied to\nresource-rich tasks. In this work, we introduce a concerted training framework\n(CTNMT) that is the key to integrate the pre-trained LMs to neural machine\ntranslation (NMT). Our proposed CTNMT consists of three techniques: a)\nasymptotic distillation to ensure that the NMT model can retain the previous\npre-trained knowledge; b) a dynamic switching gate to avoid catastrophic\nforgetting of pre-trained knowledge; and c) a strategy to adjust the learning\npaces according to a scheduled policy. Our experiments in machine translation\nshow CTNMT gains of up to 3 BLEU score on the WMT14 English-German language\npair which even surpasses the previous state-of-the-art pre-training aided NMT\nby 1.4 BLEU score. While for the large WMT14 English-French task with 40\nmillions of sentence-pairs, our base model still significantly improves upon\nthe state-of-the-art Transformer big model by more than 1 BLEU score. The code\nand model can be downloaded from https://github.com/bytedance/neurst/\ntree/master/examples/ctnmt.", "published": "2019-08-15 03:33:50", "link": "http://arxiv.org/abs/1908.05672v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer-based Automatic Post-Editing with a Context-Aware Encoding\n  Approach for Multi-Source Inputs", "abstract": "Recent approaches to the Automatic Post-Editing (APE) research have shown\nthat better results are obtained by multi-source models, which jointly encode\nboth source (src) and machine translation output (mt) to produce post-edited\nsentence (pe). Along this trend, we present a new multi-source APE model based\non the Transformer. To construct effective joint representations, our model\ninternally learns to incorporate src context into mt representation. With this\napproach, we achieve a significant improvement over baseline systems, as well\nas the state-of-the-art multi-source APE model. Moreover, to demonstrate the\ncapability of our model to incorporate src context, we show that the word\nalignment of the unknown MT system is successfully captured in our encoding\nresults.", "published": "2019-08-15 14:08:24", "link": "http://arxiv.org/abs/1908.05679v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Source Code Search: A Study of the Past and a Glimpse at the\n  Future", "abstract": "With the recent explosion in the size and complexity of source codebases and\nsoftware projects, the need for efficient source code search engines has\nincreased dramatically. Unfortunately, existing information retrieval-based\nmethods fail to capture the query semantics and perform well only when the\nquery contains syntax-based keywords. Consequently, such methods will perform\npoorly when given high-level natural language queries. In this paper, we review\nexisting methods for building code search engines. We also outline the open\nresearch directions and the various obstacles that stand in the way of having a\nuniversal source code search engine.", "published": "2019-08-15 12:50:51", "link": "http://arxiv.org/abs/1908.06738v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Towards Knowledge-Based Recommender Dialog System", "abstract": "In this paper, we propose a novel end-to-end framework called KBRD, which\nstands for Knowledge-Based Recommender Dialog System. It integrates the\nrecommender system and the dialog generation system. The dialog system can\nenhance the performance of the recommendation system by introducing\nknowledge-grounded information about users' preferences, and the recommender\nsystem can improve that of the dialog generation system by providing\nrecommendation-aware vocabulary bias. Experimental results demonstrate that our\nproposed model has significant advantages over the baselines in both the\nevaluation of dialog generation and recommendation. A series of analyses show\nthat the two systems can bring mutual benefits to each other, and the\nintroduced knowledge contributes to both their performances.", "published": "2019-08-15 01:49:19", "link": "http://arxiv.org/abs/1908.05391v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Feature-Less End-to-End Nested Term Extraction", "abstract": "In this paper, we proposed a deep learning-based end-to-end method on the\ndomain specified automatic term extraction (ATE), it considers possible term\nspans within a fixed length in the sentence and predicts them whether they can\nbe conceptual terms. In comparison with current ATE methods, the model supports\nnested term extraction and does not crucially need extra (extracted) features.\nResults show that it can achieve high recall and a comparable precision on term\nextraction task with inputting segmented raw text.", "published": "2019-08-15 05:38:14", "link": "http://arxiv.org/abs/1908.05426v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Sex Trafficking Detection with Ordinal Regression Neural Networks", "abstract": "Sex trafficking is a global epidemic. Escort websites are a primary vehicle\nfor selling the services of such trafficking victims and thus a major driver of\ntrafficker revenue. Many law enforcement agencies do not have the resources to\nmanually identify leads from the millions of escort ads posted across dozens of\npublic websites. We propose an ordinal regression neural network to identify\nescort ads that are likely linked to sex trafficking. Our model uses a modified\ncost function to mitigate inconsistencies in predictions often associated with\nnonparametric ordinal regression and leverages recent advancements in deep\nlearning to improve prediction accuracy. The proposed method significantly\nimproves on the previous state-of-the-art on Trafficking-10K, an\nexpert-annotated dataset of escort ads. Additionally, because traffickers use\nacronyms, deliberate typographical errors, and emojis to replace explicit\nkeywords, we demonstrate how to expand the lexicon of trafficking flags through\nword embeddings and t-SNE.", "published": "2019-08-15 06:25:46", "link": "http://arxiv.org/abs/1908.05434v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Hamming Sentence Embeddings for Information Retrieval", "abstract": "In retrieval applications, binary hashes are known to offer significant\nimprovements in terms of both memory and speed. We investigate the compression\nof sentence embeddings using a neural encoder-decoder architecture, which is\ntrained by minimizing reconstruction error. Instead of employing the original\nreal-valued embeddings, we use latent representations in Hamming space produced\nby the encoder for similarity calculations.\n  In quantitative experiments on several benchmarks for semantic similarity\ntasks, we show that our compressed hamming embeddings yield a comparable\nperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at\ncompression ratios of up to 256:1. We further demonstrate that our model\nstrongly decorrelates input features, and that the compressor generalizes well\nwhen pre-trained on Wikipedia sentences. We publish the source code on Github\nand all experimental results.", "published": "2019-08-15 13:51:12", "link": "http://arxiv.org/abs/1908.05541v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Natural Language Processing of Clinical Notes on Chronic Diseases:\n  Systematic Review", "abstract": "Of the 2652 articles considered, 106 met the inclusion criteria. Review of\nthe included papers resulted in identification of 43 chronic diseases, which\nwere then further classified into 10 disease categories using ICD-10. The\nmajority of studies focused on diseases of the circulatory system (n=38) while\nendocrine and metabolic diseases were fewest (n=14). This was due to the\nstructure of clinical records related to metabolic diseases, which typically\ncontain much more structured data, compared with medical records for diseases\nof the circulatory system, which focus more on unstructured data and\nconsequently have seen a stronger focus of NLP. The review has shown that there\nis a significant increase in the use of machine learning methods compared to\nrule-based approaches; however, deep learning methods remain emergent (n=3).\nConsequently, the majority of works focus on classification of disease\nphenotype with only a handful of papers addressing extraction of comorbidities\nfrom the free text or integration of clinical notes with structured data. There\nis a notable use of relatively simple methods, such as shallow classifiers (or\ncombination with rule-based methods), due to the interpretability of\npredictions, which still represents a significant issue for more complex\nmethods. Finally, scarcity of publicly available data may also have contributed\nto insufficient development of more advanced methods, such as extraction of\nword embeddings from clinical notes. Further efforts are still required to\nimprove (1) progression of clinical NLP methods from extraction toward\nunderstanding; (2) recognition of relations among entities rather than entities\nin isolation; (3) temporal extraction to understand past, current, and future\nclinical events; (4) exploitation of alternative sources of clinical knowledge;\nand (5) availability of large-scale, de-identified clinical corpora.", "published": "2019-08-15 21:54:06", "link": "http://arxiv.org/abs/1908.05780v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CY"}
{"title": "Integrating Multimodal Information in Large Pretrained Transformers", "abstract": "Recent Transformer-based contextual word representations, including BERT and\nXLNet, have shown state-of-the-art performance in multiple disciplines within\nNLP. Fine-tuning the trained contextual models on task-specific datasets has\nbeen the key to achieving superior performance downstream. While fine-tuning\nthese pre-trained models is straightforward for lexical applications\n(applications with only language modality), it is not trivial for multimodal\nlanguage (a growing area in NLP focused on modeling face-to-face\ncommunication). Pre-trained models don't have the necessary components to\naccept two extra modalities of vision and acoustic. In this paper, we proposed\nan attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG\nallows BERT and XLNet to accept multimodal nonverbal data during fine-tuning.\nIt does so by generating a shift to internal representation of BERT and XLNet;\na shift that is conditioned on the visual and acoustic modalities. In our\nexperiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for\nmultimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly\nboosts the sentiment analysis performance over previous baselines as well as\nlanguage-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet\nachieves human-level multimodal sentiment analysis performance for the first\ntime in the NLP community.", "published": "2019-08-15 22:51:21", "link": "http://arxiv.org/abs/1908.05787v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Multi-Turn Emotionally Engaging Dialog Model", "abstract": "Open-domain dialog systems (also known as chatbots) have increasingly drawn\nattention in natural language processing. Some of the recent work aims at\nincorporating affect information into sequence-to-sequence neural dialog\nmodeling, making the response emotionally richer, while others use hand-crafted\nrules to determine the desired emotion response. However, they do not\nexplicitly learn the subtle emotional interactions captured in human dialogs.\nIn this paper, we propose a multi-turn dialog system aimed at learning and\ngenerating emotional responses that so far only humans know how to do. Compared\nwith two baseline models, offline experiments show that our method performs the\nbest in perplexity scores. Further human evaluations confirm that our chatbot\ncan keep track of the conversation context and generate emotionally more\nappropriate responses while performing equally well on grammar.", "published": "2019-08-15 12:52:53", "link": "http://arxiv.org/abs/1908.07816v3", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Disentangling Latent Emotions of Word Embeddings on Complex Emotional\n  Narratives", "abstract": "Word embedding models such as GloVe are widely used in natural language\nprocessing (NLP) research to convert words into vectors. Here, we provide a\npreliminary guide to probe latent emotions in text through GloVe word vectors.\nFirst, we trained a neural network model to predict continuous emotion valence\nratings by taking linguistic inputs from Stanford Emotional Narratives Dataset\n(SEND). After interpreting the weights in the model, we found that only a few\ndimensions of the word vectors contributed to expressing emotions in text, and\nwords were clustered on the basis of their emotional polarities. Furthermore,\nwe performed a linear transformation that projected high dimensional embedded\nvectors into an emotion space. Based on NRC Emotion Lexicon (EmoLex), we\nvisualized the entanglement of emotions in the lexicon by using both projected\nand raw GloVe word vectors. We showed that, in the proposed emotion space, we\nwere able to better disentangle emotions than using raw GloVe vectors alone. In\naddition, we found that the sum vectors of different pairs of emotion words\nsuccessfully captured expressed human feelings in the EmoLex. For example, the\nsum of two embedded word vectors expressing Joy and Trust which express Love\nshared high similarity (similarity score .62) with the embedded vector\nexpressing Optimism. On the contrary, this sum vector was dissimilar\n(similarity score -.19) with the the embedded vector expressing Remorse. In\nthis paper, we argue that through the proposed emotion space, arithmetic of\nemotions is preserved in the word vectors. The affective representation\nuncovered in emotion vector space could shed some light on how to help machines\nto disentangle emotion expressed in word embeddings.", "published": "2019-08-15 11:05:45", "link": "http://arxiv.org/abs/1908.07817v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Replication of the Keyword Extraction part of the paper \"'Without the\n  Clutter of Unimportant Words': Descriptive Keyphrases for Text Visualization\"", "abstract": "\"Keyword Extraction\" refers to the task of automatically identifying the most\nrelevant and informative phrases in natural language text. As we are deluged\nwith large amounts of text data in many different forms and content - emails,\nblogs, tweets, Facebook posts, academic papers, news articles - the task of\n\"making sense\" of all this text by somehow summarizing them into a coherent\nstructure assumes paramount importance. Keyword extraction - a well-established\nproblem in Natural Language Processing - can help us here. In this report, we\nconstruct and test three different hypotheses (all related to the task of\nkeyword extraction) that take us one step closer to understanding how to\nmeaningfully identify and extract \"descriptive\" keyphrases. The work reported\nhere was done as part of replicating the study by Chuang et al. [3].", "published": "2019-08-15 04:09:12", "link": "http://arxiv.org/abs/1908.07818v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Speaker Verification Using Simple Temporal Features and Pitch\n  Synchronous Cepstral Coefficients", "abstract": "Speaker verification is the process by which a speakers claim of identity is\ntested against a claimed speaker by his or her voice. Speaker verification is\ndone by the use of some parameters (features) from the speakers voice which can\nbe used to differentiate among many speakers. The efficiency of speaker\nverification system mainly depends on the feature set providing high\ninter-speaker variability and low intra-speaker variability. There are many\nmethods used for speaker verification. Some systems use Mel Frequency Cepstral\nCoefficients as features (MFCCs), while others use Hidden Markov Models (HMM)\nbased speaker recognition, Support Vector Machines (SVM), GMMs . In this paper\nsimple intra-pitch temporal information in conjunction with pitch synchronous\ncepstral coefficients forms the feature set. The distinct feature of a speaker\nis determined from the steady state part of five cardinal spoken English\nvowels. The performance was found to be average when these features were used\nindependently. But very encouraging results were observed when both features\nwere combined to form a decision for speaker verification. For a database of\ntwenty speakers of 100 utterances per speaker, an accuracy of 91.04% has been\nobserved. The analysis of speakers whose recognition was incorrect is conducted\nand discussed .", "published": "2019-08-15 14:05:48", "link": "http://arxiv.org/abs/1908.05553v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Conditional LSTM-GAN for Melody Generation from Lyrics", "abstract": "Melody generation from lyrics has been a challenging research issue in the\nfield of artificial intelligence and music, which enables to learn and discover\nlatent relationship between interesting lyrics and accompanying melody.\nUnfortunately, the limited availability of paired lyrics-melody dataset with\nalignment information has hindered the research progress. To address this\nproblem, we create a large dataset consisting of 12,197 MIDI songs each with\npaired lyrics and melody alignment through leveraging different music sources\nwhere alignment relationship between syllables and music attributes is\nextracted. Most importantly, we propose a novel deep generative model,\nconditional Long Short-Term Memory - Generative Adversarial Network (LSTM-GAN)\nfor melody generation from lyrics, which contains a deep LSTM generator and a\ndeep LSTM discriminator both conditioned on lyrics. In particular,\nlyrics-conditioned melody and alignment relationship between syllables of given\nlyrics and notes of predicted melody are generated simultaneously. Experimental\nresults have proved the effectiveness of our proposed lyrics-to-melody\ngenerative model, where plausible and tuneful sequences can be inferred from\nlyrics.", "published": "2019-08-15 14:03:58", "link": "http://arxiv.org/abs/1908.05551v2", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
