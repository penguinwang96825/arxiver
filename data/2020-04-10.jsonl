{"title": "Probing Neural Language Models for Human Tacit Assumptions", "abstract": "Humans carry stereotypic tacit assumptions (STAs) (Prince, 1978), or\npropositional beliefs about generic concepts. Such associations are crucial for\nunderstanding natural language. We construct a diagnostic set of word\nprediction prompts to evaluate whether recent neural contextualized language\nmodels trained on large text corpora capture STAs. Our prompts are based on\nhuman responses in a psychological study of conceptual associations. We find\nmodels to be profoundly effective at retrieving concepts given associated\nproperties. Our results demonstrate empirical evidence that stereotypic\nconceptual representations are captured in neural models derived from\nsemi-supervised linguistic exposure.", "published": "2020-04-10 01:48:50", "link": "http://arxiv.org/abs/2004.04877v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dense Passage Retrieval for Open-Domain Question Answering", "abstract": "Open-domain question answering relies on efficient passage retrieval to\nselect candidate contexts, where traditional sparse vector space models, such\nas TF-IDF or BM25, are the de facto method. In this work, we show that\nretrieval can be practically implemented using dense representations alone,\nwhere embeddings are learned from a small number of questions and passages by a\nsimple dual-encoder framework. When evaluated on a wide range of open-domain QA\ndatasets, our dense retriever outperforms a strong Lucene-BM25 system largely\nby 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our\nend-to-end QA system establish new state-of-the-art on multiple open-domain QA\nbenchmarks.", "published": "2020-04-10 04:53:17", "link": "http://arxiv.org/abs/2004.04906v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Designing Precise and Robust Dialogue Response Evaluators", "abstract": "Automatic dialogue response evaluator has been proposed as an alternative to\nautomated metrics and human evaluation. However, existing automatic evaluators\nachieve only moderate correlation with human judgement and they are not robust.\nIn this work, we propose to build a reference-free evaluator and exploit the\npower of semi-supervised training and pretrained (masked) language models.\nExperimental results demonstrate that the proposed evaluator achieves a strong\ncorrelation (> 0.6) with human judgement and generalizes robustly to diverse\nresponses and corpora. We open-source the code and data in\nhttps://github.com/ZHAOTING/dialog-processing.", "published": "2020-04-10 04:59:37", "link": "http://arxiv.org/abs/2004.04908v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scalable Multilingual Frontend for TTS", "abstract": "This paper describes progress towards making a Neural Text-to-Speech (TTS)\nFrontend that works for many languages and can be easily extended to new\nlanguages. We take a Machine Translation (MT) inspired approach to constructing\nthe frontend, and model both text normalization and pronunciation on a sentence\nlevel by building and using sequence-to-sequence (S2S) models. We experimented\nwith training normalization and pronunciation as separate S2S models and with\ntraining a single S2S model combining both functions.\n  For our language-independent approach to pronunciation we do not use a\nlexicon. Instead all pronunciations, including context-based pronunciations,\nare captured in the S2S model. We also present a language-independent chunking\nand splicing technique that allows us to process arbitrary-length sentences.\nModels for 18 languages were trained and evaluated. Many of the accuracy\nmeasurements are above 99%. We also evaluated the models in the context of\nend-to-end synthesis against our current production system.", "published": "2020-04-10 08:00:40", "link": "http://arxiv.org/abs/2004.04934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Spelling Correction for Clinical Text Mining in Russian", "abstract": "The main goal of this paper is to develop a spell checker module for clinical\ntext in Russian. The described approach combines string distance measure\nalgorithms with technics of machine learning embedding methods. Our overall\nprecision is 0.86, lexical precision - 0.975 and error precision is 0.74. We\ndevelop spell checker as a part of medical text mining tool regarding the\nproblems of misspelling, negation, experiencer and temporality detection.", "published": "2020-04-10 10:59:44", "link": "http://arxiv.org/abs/2004.04987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Minimum Latency Training Strategies for Streaming Sequence-to-Sequence\n  ASR", "abstract": "Recently, a few novel streaming attention-based sequence-to-sequence (S2S)\nmodels have been proposed to perform online speech recognition with linear-time\ndecoding complexity. However, in these models, the decisions to generate tokens\nare delayed compared to the actual acoustic boundaries since their\nunidirectional encoders lack future information. This leads to an inevitable\nlatency during inference. To alleviate this issue and reduce latency, we\npropose several strategies during training by leveraging external hard\nalignments extracted from the hybrid model. We investigate to utilize the\nalignments in both the encoder and the decoder. On the encoder side, (1)\nmulti-task learning and (2) pre-training with the framewise classification task\nare studied. On the decoder side, we (3) remove inappropriate alignment paths\nbeyond an acceptable latency during the alignment marginalization, and (4)\ndirectly minimize the differentiable expected latency loss. Experiments on the\nCortana voice search task demonstrate that our proposed methods can\nsignificantly reduce the latency, and even improve the recognition accuracy in\ncertain cases on the decoder side. We also present some analysis to understand\nthe behaviors of streaming S2S models.", "published": "2020-04-10 12:24:49", "link": "http://arxiv.org/abs/2004.05009v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Dataset for Natural Language Inference from Code-mixed\n  Conversations", "abstract": "Natural Language Inference (NLI) is the task of inferring the logical\nrelationship, typically entailment or contradiction, between a premise and\nhypothesis. Code-mixing is the use of more than one language in the same\nconversation or utterance, and is prevalent in multilingual communities all\nover the world. In this paper, we present the first dataset for code-mixed NLI,\nin which both the premises and hypotheses are in code-mixed Hindi-English. We\nuse data from Hindi movies (Bollywood) as premises, and crowd-source hypotheses\nfrom Hindi-English bilinguals. We conduct a pilot annotation study and describe\nthe final annotation protocol based on observations from the pilot. Currently,\nthe data collected consists of 400 premises in the form of code-mixed\nconversation snippets and 2240 code-mixed hypotheses. We conduct an extensive\nanalysis to infer the linguistic phenomena commonly observed in the dataset\nobtained. We evaluate the dataset using a standard mBERT-based pipeline for NLI\nand report results.", "published": "2020-04-10 14:32:01", "link": "http://arxiv.org/abs/2004.05051v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overestimation of Syntactic Representationin Neural Language Models", "abstract": "With the advent of powerful neural language models over the last few years,\nresearch attention has increasingly focused on what aspects of language they\nrepresent that make them so successful. Several testing methodologies have been\ndeveloped to probe models' syntactic representations. One popular method for\ndetermining a model's ability to induce syntactic structure trains a model on\nstrings generated according to a template then tests the model's ability to\ndistinguish such strings from superficially similar ones with different syntax.\nWe illustrate a fundamental problem with this approach by reproducing positive\nresults from a recent paper with two non-syntactic baseline language models: an\nn-gram model and an LSTM model trained on scrambled inputs.", "published": "2020-04-10 15:13:03", "link": "http://arxiv.org/abs/2004.05067v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Molweni: A Challenge Multiparty Dialogues-based Machine Reading\n  Comprehension Dataset with Discourse Structure", "abstract": "Research into the area of multiparty dialog has grown considerably over\nrecent years. We present the Molweni dataset, a machine reading comprehension\n(MRC) dataset with discourse structure built over multiparty dialog. Molweni's\nsource samples from the Ubuntu Chat Corpus, including 10,000 dialogs comprising\n88,303 utterances. We annotate 30,066 questions on this corpus, including both\nanswerable and unanswerable questions. Molweni also uniquely contributes\ndiscourse dependency annotations in a modified Segmented Discourse\nRepresentation Theory (SDRT; Asher et al., 2016) style for all of its\nmultiparty dialogs, contributing large-scale (78,245 annotated discourse\nrelations) data to bear on the task of multiparty dialog discourse parsing. Our\nexperiments show that Molweni is a challenging dataset for current MRC models:\nBERT-wwm, a current, strong SQuAD 2.0 performer, achieves only 67.7% F1 on\nMolweni's questions, a 20+% significant drop as compared against its SQuAD 2.0\nperformance.", "published": "2020-04-10 15:52:08", "link": "http://arxiv.org/abs/2004.05080v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Automatic Generation of Questions from Long Answers", "abstract": "Automatic question generation (AQG) has broad applicability in domains such\nas tutoring systems, conversational agents, healthcare literacy, and\ninformation retrieval. Existing efforts at AQG have been limited to short\nanswer lengths of up to two or three sentences. However, several real-world\napplications require question generation from answers that span several\nsentences. Therefore, we propose a novel evaluation benchmark to assess the\nperformance of existing AQG systems for long-text answers. We leverage the\nlarge-scale open-source Google Natural Questions dataset to create the\naforementioned long-answer AQG benchmark. We empirically demonstrate that the\nperformance of existing AQG methods significantly degrades as the length of the\nanswer increases. Transformer-based methods outperform other existing AQG\nmethods on long answers in terms of automatic as well as human evaluation.\nHowever, we still observe degradation in the performance of our best performing\nmodels with increasing sentence length, suggesting that long answer QA is a\nchallenging benchmark task for future research.", "published": "2020-04-10 16:45:08", "link": "http://arxiv.org/abs/2004.05109v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer", "abstract": "Fine-tuning (FT) pre-trained sentence embedding models on small datasets has\nbeen shown to have limitations. In this paper we show that concatenating the\nembeddings from the pre-trained model with those from a simple sentence\nembedding model trained only on the target data, can improve over the\nperformance of FT for few-sample tasks. To this end, a linear classifier is\ntrained on the combined embeddings, either by freezing the embedding model\nweights or training the classifier and embedding models end-to-end. We perform\nevaluation on seven small datasets from NLP tasks and show that our approach\nwith end-to-end training outperforms FT with negligible computational overhead.\nFurther, we also show that sophisticated combination techniques like CCA and\nKCCA do not work as well in practice as concatenation. We provide theoretical\nanalysis to explain this empirical observation.", "published": "2020-04-10 16:57:06", "link": "http://arxiv.org/abs/2004.05119v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Model to Recognize Them All: Marginal Distillation from NER Models\n  with Different Tag Sets", "abstract": "Named entity recognition (NER) is a fundamental component in the modern\nlanguage understanding pipeline. Public NER resources such as annotated data\nand model services are available in many domains. However, given a particular\ndownstream application, there is often no single NER resource that supports all\nthe desired entity types, so users must leverage multiple resources with\ndifferent tag sets. This paper presents a marginal distillation (MARDI)\napproach for training a unified NER model from resources with disjoint or\nheterogeneous tag sets. In contrast to recent works, MARDI merely requires\naccess to pre-trained models rather than the original training datasets. This\nflexibility makes it easier to work with sensitive domains like healthcare and\nfinance. Furthermore, our approach is general enough to integrate with\ndifferent NER architectures, including local models (e.g., BiLSTM) and global\nmodels (e.g., CRF). Experiments on two benchmark datasets show that MARDI\nperforms on par with a strong marginal CRF baseline, while being more flexible\nin the form of required NER resources. MARDI also sets a new state of the art\non the progressive NER task. MARDI significantly outperforms the\nstart-of-the-art model on the task of progressive NER.", "published": "2020-04-10 17:36:27", "link": "http://arxiv.org/abs/2004.05140v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Longformer: The Long-Document Transformer", "abstract": "Transformer-based models are unable to process long sequences due to their\nself-attention operation, which scales quadratically with the sequence length.\nTo address this limitation, we introduce the Longformer with an attention\nmechanism that scales linearly with sequence length, making it easy to process\ndocuments of thousands of tokens or longer. Longformer's attention mechanism is\na drop-in replacement for the standard self-attention and combines a local\nwindowed attention with a task motivated global attention. Following prior work\non long-sequence transformers, we evaluate Longformer on character-level\nlanguage modeling and achieve state-of-the-art results on text8 and enwik8. In\ncontrast to most prior work, we also pretrain Longformer and finetune it on a\nvariety of downstream tasks. Our pretrained Longformer consistently outperforms\nRoBERTa on long document tasks and sets new state-of-the-art results on WikiHop\nand TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a\nLongformer variant for supporting long document generative sequence-to-sequence\ntasks, and demonstrate its effectiveness on the arXiv summarization dataset.", "published": "2020-04-10 17:54:09", "link": "http://arxiv.org/abs/2004.05150v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Natural Language Processing Pipeline of Chinese Free-text Radiology\n  Reports for Liver Cancer Diagnosis", "abstract": "Despite the rapid development of natural language processing (NLP)\nimplementation in electronic medical records (EMRs), Chinese EMRs processing\nremains challenging due to the limited corpus and specific grammatical\ncharacteristics, especially for radiology reports. In this study, we designed\nan NLP pipeline for the direct extraction of clinically relevant features from\nChinese radiology reports, which is the first key step in computer-aided\nradiologic diagnosis. The pipeline was comprised of named entity recognition,\nsynonyms normalization, and relationship extraction to finally derive the\nradiological features composed of one or more terms. In named entity\nrecognition, we incorporated lexicon into deep learning model bidirectional\nlong short-term memory-conditional random field (BiLSTM-CRF), and the model\nfinally achieved an F1 score of 93.00%. With the extracted radiological\nfeatures, least absolute shrinkage and selection operator and machine learning\nmethods (support vector machine, random forest, decision tree, and logistic\nregression) were used to build the classifiers for liver cancer prediction. For\nliver cancer diagnosis, random forest had the highest predictive performance in\nliver cancer diagnosis (F1 score 86.97%, precision 87.71%, and recall 86.25%).\nThis work was a comprehensive NLP study focusing on Chinese radiology reports\nand the application of NLP in cancer risk prediction. The proposed NLP pipeline\nfor the radiological feature extraction could be easily implemented in other\nkinds of Chinese clinical texts and other disease predictive tasks.", "published": "2020-04-10 09:32:07", "link": "http://arxiv.org/abs/2004.13848v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Distributional Perspective Differences from Colingual Groups", "abstract": "Perspective differences exist among different cultures or languages. A lack\nof mutual understanding among different groups about their perspectives on\nspecific values or events may lead to uninformed decisions or biased opinions.\nAutomatically understanding the group perspectives can provide essential\nbackground for many downstream applications of natural language processing\ntechniques. In this paper, we study colingual groups and use language corpora\nas a proxy to identify their distributional perspectives. We present a novel\ncomputational approach to learn shared understandings, and benchmark our method\nby building culturally-aware models for the English, Chinese, and Japanese\nlanguages. On a held out set of diverse topics including marriage, corruption,\ndemocracy, our model achieves high correlation with human judgements regarding\nintra-group values and inter-group differences.", "published": "2020-04-10 08:13:07", "link": "http://arxiv.org/abs/2004.04938v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Effect of Sociocultural Variables on Sarcasm Communication Online", "abstract": "Online social networks (OSN) play an essential role for connecting people and\nallowing them to communicate online. OSN users share their thoughts, moments,\nand news with their network. The messages they share online can include\nsarcastic posts, where the intended meaning expressed by the written text is\ndifferent from the literal one. This could result in miscommunication. Previous\nresearch in psycholinguistics has studied the sociocultural factors the might\nlead to sarcasm misunderstanding between speakers and listeners. However, there\nis a lack of such studies in the context of OSN. In this paper we fill this gap\nby performing a quantitative analysis on the influence of sociocultural\nvariables, including gender, age, country, and English language nativeness, on\nthe effectiveness of sarcastic communication online. We collect examples of\nsarcastic tweets directly from the authors who posted them. Further, we ask\nthird-party annotators of different sociocultural backgrounds to label these\ntweets for sarcasm. Our analysis indicates that age, English language\nnativeness, and country are significantly influential and should be considered\nin the design of future social analysis tools that either study sarcasm\ndirectly, or look at related phenomena where sarcasm may have an influence. We\nalso make observations about the social ecology surrounding sarcastic exchanges\non OSNs. We conclude by suggesting ways in which our findings can be included\nin future work.", "published": "2020-04-10 08:30:50", "link": "http://arxiv.org/abs/2004.04945v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Negation Detection for Clinical Text Mining in Russian", "abstract": "Developing predictive modeling in medicine requires additional features from\nunstructured clinical texts. In Russia, there are no instruments for natural\nlanguage processing to cope with problems of medical records. This paper is\ndevoted to a module of negation detection. The corpus-free machine learning\nmethod is based on gradient boosting classifier is used to detect whether a\ndisease is denied, not mentioned or presented in the text. The detector\nclassifies negations for five diseases and shows average F-score from 0.81 to\n0.93. The benefits of negation detection have been demonstrated by predicting\nthe presence of surgery for patients with the acute coronary syndrome.", "published": "2020-04-10 10:38:33", "link": "http://arxiv.org/abs/2004.04980v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Telling BERT's full story: from Local Attention to Global Aggregation", "abstract": "We take a deep look into the behavior of self-attention heads in the\ntransformer architecture. In light of recent work discouraging the use of\nattention distributions for explaining a model's behavior, we show that\nattention distributions can nevertheless provide insights into the local\nbehavior of attention heads. This way, we propose a distinction between local\npatterns revealed by attention and global patterns that refer back to the\ninput, and analyze BERT from both angles. We use gradient attribution to\nanalyze how the output of an attention attention head depends on the input\ntokens, effectively extending the local attention-based analysis to account for\nthe mixing of information throughout the transformer layers. We find that there\nis a significant discrepancy between attention and attribution distributions,\ncaused by the mixing of context inside the model. We quantify this discrepancy\nand observe that interestingly, there are some patterns that persist across all\nlayers despite the mixing.", "published": "2020-04-10 01:36:41", "link": "http://arxiv.org/abs/2004.05916v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An In-depth Walkthrough on Evolution of Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) methodologies have burgeoned from using\nsimple feed-forward architectures to the state of the art; viz. BERT model. The\nuse cases of NMT models have been broadened from just language translations to\nconversational agents (chatbots), abstractive text summarization, image\ncaptioning, etc. which have proved to be a gem in their respective\napplications. This paper aims to study the major trends in Neural Machine\nTranslation, the state of the art models in the domain and a high level\ncomparison between them.", "published": "2020-04-10 04:21:05", "link": "http://arxiv.org/abs/2004.04902v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Multimodal Categorization of Crisis Events in Social Media", "abstract": "Recent developments in image classification and natural language processing,\ncoupled with the rapid growth in social media usage, have enabled fundamental\nadvances in detecting breaking events around the world in real-time. Emergency\nresponse is one such area that stands to gain from these advances. By\nprocessing billions of texts and images a minute, events can be automatically\ndetected to enable emergency response workers to better assess rapidly evolving\nsituations and deploy resources accordingly. To date, most event detection\ntechniques in this area have focused on image-only or text-only approaches,\nlimiting detection performance and impacting the quality of information\ndelivered to crisis response teams. In this paper, we present a new multimodal\nfusion method that leverages both images and texts as input. In particular, we\nintroduce a cross-attention module that can filter uninformative and misleading\ncomponents from weak modalities on a sample by sample basis. In addition, we\nemploy a multimodal graph-based approach to stochastically transition between\nembeddings of different multimodal pairs during training to better regularize\nthe learning process as well as dealing with limited training data by\nconstructing new matched pairs from different samples. We show that our method\noutperforms the unimodal approaches and strong multimodal baselines by a large\nmargin on three crisis-related tasks.", "published": "2020-04-10 06:31:30", "link": "http://arxiv.org/abs/2004.04917v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "I.5.4"], "primary_category": "cs.LG"}
{"title": "Generating Multilingual Voices Using Speaker Space Translation Based on\n  Bilingual Speaker Data", "abstract": "We present progress towards bilingual Text-to-Speech which is able to\ntransform a monolingual voice to speak a second language while preserving\nspeaker voice quality. We demonstrate that a bilingual speaker embedding space\ncontains a separate distribution for each language and that a simple transform\nin speaker space generated by the speaker embedding can be used to control the\ndegree of accent of a synthetic voice in a language. The same transform can be\napplied even to monolingual speakers.\n  In our experiments speaker data from an English-Spanish (Mexican) bilingual\nspeaker was used, and the goal was to enable English speakers to speak Spanish\nand Spanish speakers to speak English. We found that the simple transform was\nsufficient to convert a voice from one language to the other with a high degree\nof naturalness. In one case the transformed voice outperformed a native\nlanguage voice in listening tests. Experiments further indicated that the\ntransform preserved many of the characteristics of the original voice. The\ndegree of accent present can be controlled and naturalness is relatively\nconsistent across a range of accent values.", "published": "2020-04-10 10:01:53", "link": "http://arxiv.org/abs/2004.04972v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic\n  Similarity Metric", "abstract": "The rapid development of such natural language processing tasks as style\ntransfer, paraphrase, and machine translation often calls for the use of\nsemantic similarity metrics. In recent years a lot of methods to measure the\nsemantic similarity of two short texts were developed. This paper provides a\ncomprehensive analysis for more than a dozen of such methods. Using a new\ndataset of fourteen thousand sentence pairs human-labeled according to their\nsemantic similarity, we demonstrate that none of the metrics widely used in the\nliterature is close enough to human judgment in these tasks. A number of\nrecently proposed metrics provide comparable results, yet Word Mover Distance\nis shown to be the most reasonable solution to measure semantic similarity in\nreformulated texts at the moment.", "published": "2020-04-10 11:52:06", "link": "http://arxiv.org/abs/2004.05001v3", "categories": ["cs.CL", "cs.IR", "cs.LG", "68Q55", "H.1.1; E.4"], "primary_category": "cs.CL"}
{"title": "Rapidly Deploying a Neural Search Engine for the COVID-19 Open Research\n  Dataset: Preliminary Thoughts and Lessons Learned", "abstract": "We present the Neural Covidex, a search engine that exploits the latest\nneural ranking architectures to provide information access to the COVID-19 Open\nResearch Dataset curated by the Allen Institute for AI. This web application\nexists as part of a suite of tools that we have developed over the past few\nweeks to help domain experts tackle the ongoing global pandemic. We hope that\nimproved information access capabilities to the scientific literature can\ninform evidence-based decision making and insight generation. This paper\ndescribes our initial efforts and offers a few thoughts about lessons we have\nlearned along the way.", "published": "2020-04-10 17:12:29", "link": "http://arxiv.org/abs/2004.05125v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Joint translation and unit conversion for end-to-end localization", "abstract": "A variety of natural language tasks require processing of textual data which\ncontains a mix of natural language and formal languages such as mathematical\nexpressions. In this paper, we take unit conversions as an example and propose\na data augmentation technique which leads to models learning both translation\nand conversion tasks as well as how to adequately switch between them for\nend-to-end localization.", "published": "2020-04-10 20:18:43", "link": "http://arxiv.org/abs/2004.05219v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple Approach to Learning Unsupervised Multilingual Embeddings", "abstract": "Recent progress on unsupervised learning of cross-lingual embeddings in\nbilingual setting has given impetus to learning a shared embedding space for\nseveral languages without any supervision. A popular framework to solve the\nlatter problem is to jointly solve the following two sub-problems: 1) learning\nunsupervised word alignment between several pairs of languages, and 2) learning\nhow to map the monolingual embeddings of every language to a shared\nmultilingual space. In contrast, we propose a simple, two-stage framework in\nwhich we decouple the above two sub-problems and solve them separately using\nexisting techniques. The proposed approach obtains surprisingly good\nperformance in various tasks such as bilingual lexicon induction, cross-lingual\nword similarity, multilingual document classification, and multilingual\ndependency parsing. When distant languages are involved, the proposed solution\nillustrates robustness and outperforms existing unsupervised multilingual word\nembedding approaches. Overall, our experimental results encourage development\nof multi-stage models for such challenging problems.", "published": "2020-04-10 05:54:10", "link": "http://arxiv.org/abs/2004.05991v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
