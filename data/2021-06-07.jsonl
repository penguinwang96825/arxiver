{"title": "On the Language Coverage Bias for Neural Machine Translation", "abstract": "Language coverage bias, which indicates the content-dependent differences\nbetween sentence pairs originating from the source and target languages, is\nimportant for neural machine translation (NMT) because the target-original\ntraining data is not well exploited in current practice. By carefully designing\nexperiments, we provide comprehensive analyses of the language coverage bias in\nthe training data, and find that using only the source-original data achieves\ncomparable performance with using full training data. Based on these\nobservations, we further propose two simple and effective approaches to\nalleviate the language coverage bias problem through explicitly distinguishing\nbetween the source- and target-original training data, which consistently\nimprove the performance over strong baselines on six WMT20 translation tasks.\nComplementary to the translationese effect, language coverage bias provides\nanother explanation for the performance drop caused by back-translation. We\nalso apply our approach to both back- and forward-translation and find that\nmitigating the language coverage bias can improve the performance of both the\ntwo representative data augmentation methods and their tagged variants.", "published": "2021-06-07 01:55:34", "link": "http://arxiv.org/abs/2106.03297v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic and Syntactic Enhanced Aspect Sentiment Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract triplets from\nsentences, where each triplet includes an entity, its associated sentiment, and\nthe opinion span explaining the reason for the sentiment. Most existing\nresearch addresses this problem in a multi-stage pipeline manner, which\nneglects the mutual information between such three elements and has the problem\nof error propagation. In this paper, we propose a Semantic and Syntactic\nEnhanced aspect Sentiment triplet Extraction model (S3E2) to fully exploit the\nsyntactic and semantic relationships between the triplet elements and jointly\nextract them. Specifically, we design a Graph-Sequence duel representation and\nmodeling paradigm for the task of ASTE: we represent the semantic and syntactic\nrelationships between word pairs in a sentence by graph and encode it by Graph\nNeural Networks (GNNs), as well as modeling the original sentence by LSTM to\npreserve the sequential information. Under this setting, we further apply a\nmore efficient inference strategy for the extraction of triplets. Extensive\nevaluations on four benchmark datasets show that S3E2 significantly outperforms\nexisting approaches, which proves our S3E2's superiority and flexibility in an\nend-to-end fashion.", "published": "2021-06-07 03:16:51", "link": "http://arxiv.org/abs/2106.03315v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summary Grounded Conversation Generation", "abstract": "Many conversation datasets have been constructed in the recent years using\ncrowdsourcing. However, the data collection process can be time consuming and\npresents many challenges to ensure data quality. Since language generation has\nimproved immensely in recent years with the advancement of pre-trained language\nmodels, we investigate how such models can be utilized to generate entire\nconversations, given only a summary of a conversation as the input. We explore\nthree approaches to generate summary grounded conversations, and evaluate the\ngenerated conversations using automatic measures and human judgements. We also\nshow that the accuracy of conversation summarization can be improved by\naugmenting a conversation summarization dataset with generated conversations.", "published": "2021-06-07 04:46:31", "link": "http://arxiv.org/abs/2106.03337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Joint Model for Dropped Pronoun Recovery and Conversational Discourse\n  Parsing in Chinese Conversational Speech", "abstract": "In this paper, we present a neural model for joint dropped pronoun recovery\n(DPR) and conversational discourse parsing (CDP) in Chinese conversational\nspeech. We show that DPR and CDP are closely related, and a joint model\nbenefits both tasks. We refer to our model as DiscProReco, and it first encodes\nthe tokens in each utterance in a conversation with a directed Graph\nConvolutional Network (GCN). The token states for an utterance are then\naggregated to produce a single state for each utterance. The utterance states\nare then fed into a biaffine classifier to construct a conversational discourse\ngraph. A second (multi-relational) GCN is then applied to the utterance states\nto produce a discourse relation-augmented representation for the utterances,\nwhich are then fused together with token states in each utterance as input to a\ndropped pronoun recovery layer. The joint model is trained and evaluated on a\nnew Structure Parsing-enhanced Dropped Pronoun Recovery (SPDPR) dataset that we\nannotated with both two types of information. Experimental results on the SPDPR\ndataset and other benchmarks show that DiscProReco significantly outperforms\nthe state-of-the-art baselines of both tasks.", "published": "2021-06-07 05:22:37", "link": "http://arxiv.org/abs/2106.03345v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Globally Normalized Neural Model for Semantic Parsing", "abstract": "In this paper, we propose a globally normalized model for context-free\ngrammar (CFG)-based semantic parsing. Instead of predicting a probability, our\nmodel predicts a real-valued score at each step and does not suffer from the\nlabel bias problem. Experiments show that our approach outperforms locally\nnormalized models on small datasets, but it does not yield improvement on a\nlarge dataset.", "published": "2021-06-07 07:06:36", "link": "http://arxiv.org/abs/2106.03376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Never guess what I heard... Rumor Detection in Finnish News: a Dataset\n  and a Baseline", "abstract": "This study presents a new dataset on rumor detection in Finnish language news\nheadlines. We have evaluated two different LSTM based models and two different\nBERT models, and have found very significant differences in the results. A\nfine-tuned FinBERT reaches the best overall accuracy of 94.3% and rumor label\naccuracy of 96.0% of the time. However, a model fine-tuned on Multilingual BERT\nreaches the best factual label accuracy of 97.2%. Our results suggest that the\nperformance difference is due to a difference in the original training data.\nFurthermore, we find that a regular LSTM model works better than one trained\nwith a pretrained word2vec model. These findings suggest that more work needs\nto be done for pretrained models in Finnish language as they have been trained\non small and biased corpora.", "published": "2021-06-07 07:36:36", "link": "http://arxiv.org/abs/2106.03389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Apurin\u00e3 Universal Dependencies Treebank", "abstract": "This paper presents and discusses the first Universal Dependencies treebank\nfor the Apurin\\~a language. The treebank contains 76 fully annotated sentences,\napplies 14 parts-of-speech, as well as seven augmented or new features - some\nof which are unique to Apurin\\~a. The construction of the treebank has also\nserved as an opportunity to develop finite-state description of the language\nand facilitate the transfer of open-source infrastructure possibilities to an\nendangered language of the Amazon. The source materials used in the initial\ntreebank represent fieldwork practices where not all tokens of all sentences\nare equally annotated. For this reason, establishing regular annotation\npractices for the entire Apurin\\~a treebank is an ongoing project.", "published": "2021-06-07 07:42:00", "link": "http://arxiv.org/abs/2106.03391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Relevant and Coherent Dialogue Responses using Self-separated\n  Conditional Variational AutoEncoders", "abstract": "Conditional Variational AutoEncoder (CVAE) effectively increases the\ndiversity and informativeness of responses in open-ended dialogue generation\ntasks through enriching the context vector with sampled latent variables.\nHowever, due to the inherent one-to-many and many-to-one phenomena in human\ndialogues, the sampled latent variables may not correctly reflect the contexts'\nsemantics, leading to irrelevant and incoherent generated responses. To resolve\nthis problem, we propose Self-separated Conditional Variational AutoEncoder\n(abbreviated as SepaCVAE) that introduces group information to regularize the\nlatent variables, which enhances CVAE by improving the responses' relevance and\ncoherence while maintaining their diversity and informativeness. SepaCVAE\nactively divides the input data into groups, and then widens the absolute\ndifference between data pairs from distinct groups, while narrowing the\nrelative distance between data pairs in the same group. Empirical results from\nautomatic evaluation and detailed analysis demonstrate that SepaCVAE can\nsignificantly boost responses in well-established open-domain dialogue\ndatasets.", "published": "2021-06-07 08:19:31", "link": "http://arxiv.org/abs/2106.03410v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention Temperature Matters in Abstractive Summarization Distillation", "abstract": "Recent progress of abstractive text summarization largely relies on large\npre-trained sequence-to-sequence Transformer models, which are computationally\nexpensive. This paper aims to distill these large models into smaller ones for\nfaster inference and minimal performance loss. Pseudo-labeling based methods\nare popular in sequence-to-sequence model distillation. In this paper, we find\nsimply manipulating attention temperatures in Transformers can make pseudo\nlabels easier to learn for student models. Our experiments on three\nsummarization datasets show our proposed method consistently improves over\nvanilla pseudo-labeling based methods. We also find that both the pseudo labels\nand summaries produced by our students are shorter and more abstractive. Our\ncode is available at \\url{https://github.com/Shengqiang-Zhang/plate}.", "published": "2021-06-07 09:18:21", "link": "http://arxiv.org/abs/2106.03441v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Neural Semantic Parsing for Low-Resourced Languages", "abstract": "Multilingual semantic parsing is a cost-effective method that allows a single\nmodel to understand different languages. However, researchers face a great\nimbalance of availability of training data, with English being resource rich,\nand other languages having much less data. To tackle the data limitation\nproblem, we propose using machine translation to bootstrap multilingual\ntraining data from the more abundant English data. To compensate for the data\nquality of machine translated training data, we utilize transfer learning from\npretrained multilingual encoders to further improve the model. To evaluate our\nmultilingual models on human-written sentences as opposed to machine translated\nones, we introduce a new multilingual semantic parsing dataset in English,\nItalian and Japanese based on the Facebook Task Oriented Parsing (TOP) dataset.\nWe show that joint multilingual training with pretrained encoders substantially\noutperforms our baselines on the TOP dataset and outperforms the\nstate-of-the-art model on the public NLMaps dataset. We also establish a new\nbaseline for zero-shot learning on the TOP dataset. We find that a semantic\nparser trained only on English data achieves a zero-shot performance of 44.9%\nexact-match accuracy on Italian sentences.", "published": "2021-06-07 09:53:02", "link": "http://arxiv.org/abs/2106.03469v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERTGEN: Multi-task Generation through BERT", "abstract": "We present BERTGEN, a novel generative, decoder-only model which extends BERT\nby fusing multimodal and multilingual pretrained models VL-BERT and M-BERT,\nrespectively. BERTGEN is auto-regressively trained for language generation\ntasks, namely image captioning, machine translation and multimodal machine\ntranslation, under a multitask setting. With a comprehensive set of\nevaluations, we show that BERTGEN outperforms many strong baselines across the\ntasks explored. We also show BERTGEN's ability for zero-shot language\ngeneration, where it exhibits competitive performance to supervised\ncounterparts. Finally, we conduct ablation studies which demonstrate that\nBERTGEN substantially benefits from multi-tasking and effectively transfers\nrelevant inductive biases from the pre-trained models.", "published": "2021-06-07 10:17:45", "link": "http://arxiv.org/abs/2106.03484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of\n  Conversational Language Models", "abstract": "Text representation models are prone to exhibit a range of societal biases,\nreflecting the non-controlled and biased nature of the underlying pretraining\ndata, which consequently leads to severe ethical issues and even bias\namplification. Recent work has predominantly focused on measuring and\nmitigating bias in pretrained language models. Surprisingly, the landscape of\nbias measurements and mitigation resources and methods for conversational\nlanguage models is still very scarce: it is limited to only a few types of\nbias, artificially constructed resources, and completely ignores the impact\nthat debiasing methods may have on the final performance in dialog tasks, e.g.,\nconversational response generation. In this work, we present RedditBias, the\nfirst conversational data set grounded in the actual human conversations from\nReddit, allowing for bias measurement and mitigation across four important bias\ndimensions: gender, race, religion, and queerness. Further, we develop an\nevaluation framework which simultaneously 1) measures bias on the developed\nRedditBias resource, and 2) evaluates model capability in dialog tasks after\nmodel debiasing. We use the evaluation framework to benchmark the widely used\nconversational DialoGPT model along with the adaptations of four debiasing\nmethods. Our results indicate that DialoGPT is biased with respect to religious\ngroups and that some debiasing techniques can remove this bias while preserving\ndownstream task performance.", "published": "2021-06-07 11:22:39", "link": "http://arxiv.org/abs/2106.03521v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on\n  Synthetic Datasets", "abstract": "To highlight the challenges of achieving representation disentanglement for\ntext domain in an unsupervised setting, in this paper we select a\nrepresentative set of successfully applied models from the image domain. We\nevaluate these models on 6 disentanglement metrics, as well as on downstream\nclassification tasks and homotopy. To facilitate the evaluation, we propose two\nsynthetic datasets with known generative factors. Our experiments highlight the\nexisting gap in the text domain and illustrate that certain elements such as\nrepresentation sparsity (as an inductive bias), or representation coupling with\nthe decoder could impact disentanglement. To the best of our knowledge, our\nwork is the first attempt on the intersection of unsupervised representation\ndisentanglement and text, and provides the experimental framework and datasets\nfor examining future developments in this direction.", "published": "2021-06-07 14:04:32", "link": "http://arxiv.org/abs/2106.03631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PROST: Physical Reasoning of Objects through Space and Time", "abstract": "We present a new probing dataset named PROST: Physical Reasoning about\nObjects Through Space and Time. This dataset contains 18,736 multiple-choice\nquestions made from 14 manually curated templates, covering 10 physical\nreasoning concepts. All questions are designed to probe both causal and masked\nlanguage models in a zero-shot setting. We conduct an extensive analysis which\ndemonstrates that state-of-the-art pretrained models are inadequate at physical\nreasoning: they are influenced by the order in which answer options are\npresented to them, they struggle when the superlative in a question is inverted\n(e.g., most <-> least), and increasing the amount of pretraining data and\nparameters only yields minimal improvements. These results provide support for\nthe hypothesis that current pretrained models' ability to reason about physical\ninteractions is inherently limited by a lack of real world experience. By\nhighlighting these limitations, we hope to motivate the development of models\nwith a human-like understanding of the physical world.", "published": "2021-06-07 14:06:20", "link": "http://arxiv.org/abs/2106.03634v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diverse Pretrained Context Encodings Improve Document Translation", "abstract": "We propose a new architecture for adapting a sentence-level\nsequence-to-sequence transformer by incorporating multiple pretrained document\ncontext signals and assess the impact on translation performance of (1)\ndifferent pretraining approaches for generating these signals, (2) the quantity\nof parallel data for which document context is available, and (3) conditioning\non source, target, or source and target contexts. Experiments on the NIST\nChinese-English, and IWSLT and WMT English-German tasks support four general\nconclusions: that using pretrained context representations markedly improves\nsample efficiency, that adequate parallel data resources are crucial for\nlearning to use document context, that jointly conditioning on multiple context\nrepresentations outperforms any single representation, and that source context\nis more valuable for translation performance than target side context. Our best\nmulti-context model consistently outperforms the best existing context-aware\ntransformers.", "published": "2021-06-07 15:28:01", "link": "http://arxiv.org/abs/2106.03717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COVID-Fact: Fact Extraction and Verification of Real-World Claims on\n  COVID-19 Pandemic", "abstract": "We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the\nCOVID-19 pandemic. The dataset contains claims, evidence for the claims, and\ncontradictory claims refuted by the evidence. Unlike previous approaches, we\nautomatically detect true claims and their source articles and then generate\ncounter-claims using automatic methods rather than employing human annotators.\nAlong with our constructed resource, we formally present the task of\nidentifying relevant evidence for the claims and verifying whether the evidence\nrefutes or supports a given claim. In addition to scientific claims, our data\ncontains simplified general claims from media sources, making it better suited\nfor detecting general misinformation regarding COVID-19. Our experiments\nindicate that COVID-Fact will provide a challenging testbed for the development\nof new systems and our approach will reduce the costs of building\ndomain-specific datasets for detecting misinformation.", "published": "2021-06-07 16:59:46", "link": "http://arxiv.org/abs/2106.03794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple Recipe for Multilingual Grammatical Error Correction", "abstract": "This paper presents a simple recipe to train state-of-the-art multilingual\nGrammatical Error Correction (GEC) models. We achieve this by first proposing a\nlanguage-agnostic method to generate a large number of synthetic examples. The\nsecond ingredient is to use large-scale multilingual language models (up to 11B\nparameters). Once fine-tuned on language-specific supervised sets we surpass\nthe previous state-of-the-art results on GEC benchmarks in four languages:\nEnglish, Czech, German and Russian. Having established a new set of baselines\nfor GEC, we make our results easily reproducible and accessible by releasing a\ncLang-8 dataset. It is produced by using our best model, which we call gT5, to\nclean the targets of a widely used yet noisy lang-8 dataset. cLang-8 greatly\nsimplifies typical GEC training pipelines composed of multiple fine-tuning\nstages -- we demonstrate that performing a single fine-tuning step on cLang-8\nwith the off-the-shelf language models yields further accuracy improvements\nover an already top-performing gT5 model for English.", "published": "2021-06-07 17:47:04", "link": "http://arxiv.org/abs/2106.03830v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Conversational Uptake: A Case Study on Student-Teacher\n  Interactions", "abstract": "In conversation, uptake happens when a speaker builds on the contribution of\ntheir interlocutor by, for example, acknowledging, repeating or reformulating\nwhat they have said. In education, teachers' uptake of student contributions\nhas been linked to higher student achievement. Yet measuring and improving\nteachers' uptake at scale is challenging, as existing methods require expensive\nannotation by experts. We propose a framework for computationally measuring\nuptake, by (1) releasing a dataset of student-teacher exchanges extracted from\nUS math classroom transcripts annotated for uptake by experts; (2) formalizing\nuptake as pointwise Jensen-Shannon Divergence (pJSD), estimated via next\nutterance classification; (3) conducting a linguistically-motivated comparison\nof different unsupervised measures and (4) correlating these measures with\neducational outcomes. We find that although repetition captures a significant\npart of uptake, pJSD outperforms repetition-based baselines, as it is capable\nof identifying a wider range of uptake phenomena like question answering and\nreformulation. We apply our uptake measure to three different educational\ndatasets with outcome indicators. Unlike baseline measures, pJSD correlates\nsignificantly with instruction quality in all three, providing evidence for its\ngeneralizability and for its potential to serve as an automated professional\ndevelopment tool for teachers.", "published": "2021-06-07 18:00:06", "link": "http://arxiv.org/abs/2106.03873v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Different Types of Subtle Toxicity in Unhealthy Online\n  Conversations", "abstract": "This paper investigates the use of machine learning models for the\nclassification of unhealthy online conversations containing one or more forms\nof subtler abuse, such as hostility, sarcasm, and generalization. We leveraged\na public dataset of 44K online comments containing healthy and unhealthy\ncomments labeled with seven forms of subtle toxicity. We were able to\ndistinguish between these comments with a top micro F1-score, macro F1-score,\nand ROC-AUC of 88.76%, 67.98%, and 0.71, respectively. Hostile comments were\neasier to detect than other types of unhealthy comments. We also conducted a\nsentiment analysis which revealed that most types of unhealthy comments were\nassociated with a slight negative sentiment, with hostile comments being the\nmost negative ones.", "published": "2021-06-07 20:32:42", "link": "http://arxiv.org/abs/2106.03952v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Language Relatedness for Low Web-Resource Language Model\n  Adaptation: An Indic Languages Study", "abstract": "Recent research in multilingual language models (LM) has demonstrated their\nability to effectively handle multiple languages in a single model. This holds\npromise for low web-resource languages (LRL) as multilingual models can enable\ntransfer of supervision from high resource languages to LRLs. However,\nincorporating a new language in an LM still remains a challenge, particularly\nfor languages with limited corpora and in unseen scripts. In this paper we\nargue that relatedness among languages in a language family may be exploited to\novercome some of the corpora limitations of LRLs, and propose RelateLM. We\nfocus on Indian languages, and exploit relatedness along two dimensions: (1)\nscript (since many Indic scripts originated from the Brahmic script), and (2)\nsentence structure. RelateLM uses transliteration to convert the unseen script\nof limited LRL text into the script of a Related Prominent Language (RPL)\n(Hindi in our case). While exploiting similar sentence structures, RelateLM\nutilizes readily available bilingual dictionaries to pseudo translate RPL text\ninto LRL corpora. Experiments on multiple real-world benchmark datasets provide\nvalidation to our hypothesis that using a related language as pivot, along with\ntransliteration and pseudo translation based data augmentation, can be an\neffective way to adapt LMs for LRLs, rather than direct training or pivoting\nthrough English.", "published": "2021-06-07 20:43:02", "link": "http://arxiv.org/abs/2106.03958v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expressivity of Emergent Language is a Trade-off between Contextual\n  Complexity and Unpredictability", "abstract": "Researchers are using deep learning models to explore the emergence of\nlanguage in various language games, where agents interact and develop an\nemergent language to solve tasks. We focus on the factors that determine the\nexpressivity of emergent languages, which reflects the amount of information\nabout input spaces those languages are capable of encoding. We measure the\nexpressivity of emergent languages based on the generalisation performance\nacross different games, and demonstrate that the expressivity of emergent\nlanguages is a trade-off between the complexity and unpredictability of the\ncontext those languages emerged from. Another contribution of this work is the\ndiscovery of message type collapse, i.e. the number of unique messages is lower\nthan that of inputs. We also show that using the contrastive loss proposed by\nChen et al. (2020) can alleviate this problem.", "published": "2021-06-07 21:57:11", "link": "http://arxiv.org/abs/2106.03982v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SelfDoc: Self-Supervised Document Representation Learning", "abstract": "We propose SelfDoc, a task-agnostic pre-training framework for document image\nunderstanding. Because documents are multimodal and are intended for sequential\nreading, our framework exploits the positional, textual, and visual information\nof every semantically meaningful component in a document, and it models the\ncontextualization between each block of content. Unlike existing document\npre-training models, our model is coarse-grained instead of treating individual\nwords as input, therefore avoiding an overly fine-grained with excessive\ncontextualization. Beyond that, we introduce cross-modal learning in the model\npre-training phase to fully leverage multimodal information from unlabeled\ndocuments. For downstream usage, we propose a novel modality-adaptive attention\nmechanism for multimodal feature fusion by adaptively emphasizing language and\nvision signals. Our framework benefits from self-supervised pre-training on\ndocuments without requiring annotations by a feature masking training strategy.\nIt achieves superior performance on multiple downstream tasks with\nsignificantly fewer document images used in the pre-training stage compared to\nprevious works.", "published": "2021-06-07 04:19:49", "link": "http://arxiv.org/abs/2106.03331v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LAWDR: Language-Agnostic Weighted Document Representations from\n  Pre-trained Models", "abstract": "Cross-lingual document representations enable language understanding in\nmultilingual contexts and allow transfer learning from high-resource to\nlow-resource languages at the document level. Recently large pre-trained\nlanguage models such as BERT, XLM and XLM-RoBERTa have achieved great success\nwhen fine-tuned on sentence-level downstream tasks. It is tempting to apply\nthese cross-lingual models to document representation learning. However, there\nare two challenges: (1) these models impose high costs on long document\nprocessing and thus many of them have strict length limit; (2) model\nfine-tuning requires extra data and computational resources, which is not\npractical in resource-limited settings. In this work, we address these\nchallenges by proposing unsupervised Language-Agnostic Weighted Document\nRepresentations (LAWDR). We study the geometry of pre-trained sentence\nembeddings and leverage it to derive document representations without\nfine-tuning. Evaluated on cross-lingual document alignment, LAWDR demonstrates\ncomparable performance to state-of-the-art models on benchmark datasets.", "published": "2021-06-07 07:14:00", "link": "http://arxiv.org/abs/2106.03379v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hierarchical Task Learning from Language Instructions with Unified\n  Transformers and Self-Monitoring", "abstract": "Despite recent progress, learning new tasks through language instructions\nremains an extremely challenging problem. On the ALFRED benchmark for task\nlearning, the published state-of-the-art system only achieves a task success\nrate of less than 10% in an unseen environment, compared to the human\nperformance of over 90%. To address this issue, this paper takes a closer look\nat task learning. In a departure from a widely applied end-to-end architecture,\nwe decomposed task learning into three sub-problems: sub-goal planning, scene\nnavigation, and object manipulation; and developed a model HiTUT (stands for\nHierarchical Tasks via Unified Transformers) that addresses each sub-problem in\na unified manner to learn a hierarchical task structure. On the ALFRED\nbenchmark, HiTUT has achieved the best performance with a remarkably higher\ngeneralization ability. In the unseen environment, HiTUT achieves over 160%\nperformance gain in success rate compared to the previous state of the art. The\nexplicit representation of task structures also enables an in-depth\nunderstanding of the nature of the problem and the ability of the agent, which\nprovides insight for future benchmark development and evaluation.", "published": "2021-06-07 08:48:44", "link": "http://arxiv.org/abs/2106.03427v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Relative Importance in Sentence Processing", "abstract": "Determining the relative importance of the elements in a sentence is a key\nfactor for effortless natural language understanding. For human language\nprocessing, we can approximate patterns of relative importance by measuring\nreading fixations using eye-tracking technology. In neural language models,\ngradient-based saliency methods indicate the relative importance of a token for\nthe target objective. In this work, we compare patterns of relative importance\nin English language processing by humans and models and analyze the underlying\nlinguistic patterns. We find that human processing patterns in English\ncorrelate strongly with saliency-based importance in language models and not\nwith attention-based importance. Our results indicate that saliency could be a\ncognitively more plausible metric for interpreting neural language models. The\ncode is available on GitHub: https://github.com/beinborn/relative_importance", "published": "2021-06-07 09:56:18", "link": "http://arxiv.org/abs/2106.03471v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion\n  Cause Extraction", "abstract": "The Emotion Cause Extraction (ECE)} task aims to identify clauses which\ncontain emotion-evoking information for a particular emotion expressed in text.\nWe observe that a widely-used ECE dataset exhibits a bias that the majority of\nannotated cause clauses are either directly before their associated emotion\nclauses or are the emotion clauses themselves. Existing models for ECE tend to\nexplore such relative position information and suffer from the dataset bias. To\ninvestigate the degree of reliance of existing ECE models on clause relative\npositions, we propose a novel strategy to generate adversarial examples in\nwhich the relative position information is no longer the indicative feature of\ncause clauses. We test the performance of existing models on such adversarial\nexamples and observe a significant performance drop. To address the dataset\nbias, we propose a novel graph-based method to explicitly model the emotion\ntriggering paths by leveraging the commonsense knowledge to enhance the\nsemantic dependencies between a candidate clause and an emotion clause.\nExperimental results show that our proposed approach performs on par with the\nexisting state-of-the-art methods on the original ECE dataset, and is more\nrobust against adversarial attacks compared to existing models.", "published": "2021-06-07 11:14:58", "link": "http://arxiv.org/abs/2106.03518v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CAiRE in DialDoc21: Data Augmentation for Information-Seeking Dialogue\n  System", "abstract": "Information-seeking dialogue systems, including knowledge identification and\nresponse generation, aim to respond to users with fluent, coherent, and\ninformative responses based on users' needs, which. To tackle this challenge,\nwe utilize data augmentation methods and several training techniques with the\npre-trained language models to learn a general pattern of the task and thus\nachieve promising performance. In DialDoc21 competition, our system achieved\n74.95 F1 score and 60.74 Exact Match score in subtask 1, and 37.72 SacreBLEU\nscore in subtask 2. Empirical analysis is provided to explain the effectiveness\nof our approaches.", "published": "2021-06-07 11:40:55", "link": "http://arxiv.org/abs/2106.03530v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Assessment of Dialog Evaluation Metrics", "abstract": "Automatic evaluation metrics are a crucial component of dialog systems\nresearch. Standard language evaluation metrics are known to be ineffective for\nevaluating dialog. As such, recent research has proposed a number of novel,\ndialog-specific metrics that correlate better with human judgements. Due to the\nfast pace of research, many of these metrics have been assessed on different\ndatasets and there has as yet been no time for a systematic comparison between\nthem. To this end, this paper provides a comprehensive assessment of recently\nproposed dialog evaluation metrics on a number of datasets. In this paper, 23\ndifferent automatic evaluation metrics are evaluated on 10 different datasets.\nFurthermore, the metrics are assessed in different settings, to better qualify\ntheir respective strengths and weaknesses. Metrics are assessed (1) on both the\nturn level and the dialog level, (2) for different dialog lengths, (3) for\ndifferent dialog qualities (e.g., coherence, engaging), (4) for different types\nof response generation models (i.e., generative, retrieval, simple models and\nstate-of-the-art models), (5) taking into account the similarity of different\nmetrics and (6) exploring combinations of different metrics. This comprehensive\nassessment offers several takeaways pertaining to dialog evaluation metrics in\ngeneral. It also suggests how to best assess evaluation metrics and indicates\npromising directions for future work.", "published": "2021-06-07 15:17:03", "link": "http://arxiv.org/abs/2106.03706v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Encouraging Neural Machine Translation to Satisfy Terminology\n  Constraints", "abstract": "We present a new approach to encourage neural machine translation to satisfy\nlexical constraints. Our method acts at the training step and thereby avoiding\nthe introduction of any extra computational overhead at inference step. The\nproposed method combines three main ingredients. The first one consists in\naugmenting the training data to specify the constraints. Intuitively, this\nencourages the model to learn a copy behavior when it encounters constraint\nterms. Compared to previous work, we use a simplified augmentation strategy\nwithout source factors. The second ingredient is constraint token masking,\nwhich makes it even easier for the model to learn the copy behavior and\ngeneralize better. The third one, is a modification of the standard cross\nentropy loss to bias the model towards assigning high probabilities to\nconstraint words. Empirical results show that our method improves upon related\nbaselines in terms of both BLEU score and the percentage of generated\nconstraint terms.", "published": "2021-06-07 15:46:07", "link": "http://arxiv.org/abs/2106.03730v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "X2Parser: Cross-Lingual and Cross-Domain Framework for Task-Oriented\n  Compositional Semantic Parsing", "abstract": "Task-oriented compositional semantic parsing (TCSP) handles complex nested\nuser queries and serves as an essential component of virtual assistants.\nCurrent TCSP models rely on numerous training data to achieve decent\nperformance but fail to generalize to low-resource target languages or domains.\nIn this paper, we present X2Parser, a transferable Cross-lingual and\nCross-domain Parser for TCSP. Unlike previous models that learn to generate the\nhierarchical representations for nested intents and slots, we propose to\npredict flattened intents and slots representations separately and cast both\nprediction tasks into sequence labeling problems. After that, we further\npropose a fertility-based slot predictor that first learns to dynamically\ndetect the number of labels for each token, and then predicts the slot types.\nExperimental results illustrate that our model can significantly outperform\nexisting strong baselines in cross-lingual and cross-domain settings, and our\nmodel can also achieve a good generalization ability on target languages of\ntarget domains. Furthermore, our model tackles the problem in an efficient\nnon-autoregressive way that reduces the latency by up to 66% compared to the\ngenerative model.", "published": "2021-06-07 16:40:05", "link": "http://arxiv.org/abs/2106.03777v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Context- and Relation-Aware Learning for Aspect-based Sentiment\n  Analysis", "abstract": "Existing works for aspect-based sentiment analysis (ABSA) have adopted a\nunified approach, which allows the interactive relations among subtasks.\nHowever, we observe that these methods tend to predict polarities based on the\nliteral meaning of aspect and opinion terms and mainly consider relations\nimplicitly among subtasks at the word level. In addition, identifying multiple\naspect-opinion pairs with their polarities is much more challenging. Therefore,\na comprehensive understanding of contextual information w.r.t. the aspect and\nopinion are further required in ABSA. In this paper, we propose Deep\nContextualized Relation-Aware Network (DCRAN), which allows interactive\nrelations among subtasks with deep contextual information based on two modules\n(i.e., Aspect and Opinion Propagation and Explicit Self-Supervised Strategies).\nEspecially, we design novel self-supervised strategies for ABSA, which have\nstrengths in dealing with multiple aspects. Experimental results show that\nDCRAN significantly outperforms previous state-of-the-art methods by large\nmargins on three widely used benchmarks.", "published": "2021-06-07 17:16:15", "link": "http://arxiv.org/abs/2106.03806v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Narrative Question Answering with Cutting-Edge Open-Domain QA\n  Techniques: A Comprehensive Study", "abstract": "Recent advancements in open-domain question answering (ODQA), i.e., finding\nanswers from large open-domain corpus like Wikipedia, have led to human-level\nperformance on many datasets. However, progress in QA over book stories (Book\nQA) lags behind despite its similar task formulation to ODQA. This work\nprovides a comprehensive and quantitative analysis about the difficulty of Book\nQA: (1) We benchmark the research on the NarrativeQA dataset with extensive\nexperiments with cutting-edge ODQA techniques. This quantifies the challenges\nBook QA poses, as well as advances the published state-of-the-art with a\n$\\sim$7\\% absolute improvement on Rouge-L. (2) We further analyze the detailed\nchallenges in Book QA through human\nstudies.\\footnote{\\url{https://github.com/gorov/BookQA}.} Our findings indicate\nthat the event-centric questions dominate this task, which exemplifies the\ninability of existing QA models to handle event-oriented scenarios.", "published": "2021-06-07 17:46:09", "link": "http://arxiv.org/abs/2106.03826v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Abstractive Unsupervised Summarization of Online News Discussions", "abstract": "Summarization has usually relied on gold standard summaries to train\nextractive or abstractive models. Social media brings a hurdle to summarization\ntechniques since it requires addressing a multi-document multi-author approach.\nWe address this challenging task by introducing a novel method that generates\nabstractive summaries of online news discussions. Our method extends a\nBERT-based architecture, including an attention encoding that fed comments'\nlikes during the training stage. To train our model, we define a task which\nconsists of reconstructing high impact comments based on popularity (likes).\nAccordingly, our model learns to summarize online discussions based on their\nmost relevant comments. Our novel approach provides a summary that represents\nthe most relevant aspects of a news item that users comment on, incorporating\nthe social context as a source of information to summarize texts in online\nsocial networks. Our model is evaluated using ROUGE scores between the\ngenerated summary and each comment on the thread. Our model, including the\nsocial attention encoding, significantly outperforms both extractive and\nabstractive summarization methods based on such evaluation.", "published": "2021-06-07 20:33:51", "link": "http://arxiv.org/abs/2106.03953v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Hypothetical Events for Abductive Inference", "abstract": "Abductive reasoning starts from some observations and aims at finding the\nmost plausible explanation for these observations. To perform abduction, humans\noften make use of temporal and causal inferences, and knowledge about how some\nhypothetical situation can result in different outcomes. This work offers the\nfirst study of how such knowledge impacts the Abductive NLI task -- which\nconsists in choosing the more likely explanation for given observations. We\ntrain a specialized language model LMI that is tasked to generate what could\nhappen next from a hypothetical scenario that evolves from a given event. We\nthen propose a multi-task model MTL to solve the Abductive NLI task, which\npredicts a plausible explanation by a) considering different possible events\nemerging from candidate hypotheses -- events generated by LMI -- and b)\nselecting the one that is most similar to the observed outcome. We show that\nour MTL model improves over prior vanilla pre-trained LMs fine-tuned on\nAbductive NLI. Our manual evaluation and analysis suggest that learning about\npossible next events from different hypothetical scenarios supports abductive\ninference.", "published": "2021-06-07 21:34:11", "link": "http://arxiv.org/abs/2106.03973v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Transfer Learning in Multilingual Pre-trained Language\n  Models through Chinese Natural Language Inference", "abstract": "Multilingual transformers (XLM, mT5) have been shown to have remarkable\ntransfer skills in zero-shot settings. Most transfer studies, however, rely on\nautomatically translated resources (XNLI, XQuAD), making it hard to discern the\nparticular linguistic knowledge that is being transferred, and the role of\nexpert annotated monolingual datasets when developing task-specific models. We\ninvestigate the cross-lingual transfer abilities of XLM-R for Chinese and\nEnglish natural language inference (NLI), with a focus on the recent\nlarge-scale Chinese dataset OCNLI. To better understand linguistic transfer, we\ncreated 4 categories of challenge and adversarial tasks (totaling 17 new\ndatasets) for Chinese that build on several well-known resources for English\n(e.g., HANS, NLI stress-tests). We find that cross-lingual models trained on\nEnglish NLI do transfer well across our Chinese tasks (e.g., in 3/4 of our\nchallenge categories, they perform as well/better than the best monolingual\nmodels, even on 3/5 uniquely Chinese linguistic phenomena such as idioms, pro\ndrop). These results, however, come with important caveats: cross-lingual\nmodels often perform best when trained on a mixture of English and high-quality\nmonolingual NLI data (OCNLI), and are often hindered by automatically\ntranslated resources (XNLI-zh). For many phenomena, all models continue to\nstruggle, highlighting the need for our new diagnostics to help benchmark\nChinese and cross-lingual models. All new datasets/code are released at\nhttps://github.com/huhailinguist/ChineseNLIProbing.", "published": "2021-06-07 22:00:18", "link": "http://arxiv.org/abs/2106.03983v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lexicon Learning for Few-Shot Neural Sequence Modeling", "abstract": "Sequence-to-sequence transduction is the core problem in language processing\napplications as diverse as semantic parsing, machine translation, and\ninstruction following. The neural network models that provide the dominant\nsolution to these problems are brittle, especially in low-resource settings:\nthey fail to generalize correctly or systematically from small datasets. Past\nwork has shown that many failures of systematic generalization arise from\nneural models' inability to disentangle lexical phenomena from syntactic ones.\nTo address this, we augment neural decoders with a lexical translation\nmechanism that generalizes existing copy mechanisms to incorporate learned,\ndecontextualized, token-level translation rules. We describe how to initialize\nthis mechanism using a variety of lexicon learning algorithms, and show that it\nimproves systematic generalization on a diverse set of sequence modeling tasks\ndrawn from cognitive science, formal semantics, and machine translation.", "published": "2021-06-07 22:35:04", "link": "http://arxiv.org/abs/2106.03993v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Progressive Open-Domain Response Generation with Multiple Controllable\n  Attributes", "abstract": "It is desirable to include more controllable attributes to enhance the\ndiversity of generated responses in open-domain dialogue systems. However,\nexisting methods can generate responses with only one controllable attribute or\nlack a flexible way to generate them with multiple controllable attributes. In\nthis paper, we propose a Progressively trained Hierarchical Encoder-Decoder\n(PHED) to tackle this task. More specifically, PHED deploys Conditional\nVariational AutoEncoder (CVAE) on Transformer to include one aspect of\nattributes at one stage. A vital characteristic of the CVAE is to separate the\nlatent variables at each stage into two types: a global variable capturing the\ncommon semantic features and a specific variable absorbing the attribute\ninformation at that stage. PHED then couples the CVAE latent variables with the\nTransformer encoder and is trained by minimizing a newly derived ELBO and\ncontrolled losses to produce the next stage's input and produce responses as\nrequired. Finally, we conduct extensive evaluations to show that PHED\nsignificantly outperforms the state-of-the-art neural generation models and\nproduces more diverse responses as expected.", "published": "2021-06-07 08:48:39", "link": "http://arxiv.org/abs/2106.14614v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Free-Choice Nets With Home Clusters Are Lucent", "abstract": "A marked Petri net is lucent if there are no two different reachable markings\nenabling the same set of transitions, i.e., states are fully characterized by\nthe transitions they enable. Characterizing the class of systems that are\nlucent is a foundational and also challenging question. However, little\nresearch has been done on the topic. In this paper, it is shown that all\nfree-choice nets having a home cluster are lucent. These nets have a so-called\nhome marking such that it is always possible to reach this marking again. Such\na home marking can serve as a regeneration point or as an end-point. The result\nis highly relevant because in many applications, we want the system to be\nlucent and many well-behaved process models fall into the class identified in\nthis paper. Unlike previous work, we do not require the marked Petri net to be\nlive and strongly connected. Most of the analysis techniques for free-choice\nnets are tailored towards well-formed nets. The approach presented in this\npaper provides a novel perspective enabling new analysis techniques for\nfree-choice nets that do not need to be well-formed. Therefore, we can also\nmodel systems and processes that are terminating and/or have an initialization\nphase.", "published": "2021-06-07 12:34:29", "link": "http://arxiv.org/abs/2106.03554v1", "categories": ["cs.FL", "cs.CL", "cs.SY", "eess.SY", "D.2.2; F.1.1; F.1.2"], "primary_category": "cs.FL"}
{"title": "RoSearch: Search for Robust Student Architectures When Distilling\n  Pre-trained Language Models", "abstract": "Pre-trained language models achieve outstanding performance in NLP tasks.\nVarious knowledge distillation methods have been proposed to reduce the heavy\ncomputation and storage requirements of pre-trained language models. However,\nfrom our observations, student models acquired by knowledge distillation suffer\nfrom adversarial attacks, which limits their usage in security sensitive\nscenarios. In order to overcome these security problems, RoSearch is proposed\nas a comprehensive framework to search the student models with better\nadversarial robustness when performing knowledge distillation. A directed\nacyclic graph based search space is built and an evolutionary search strategy\nis utilized to guide the searching approach. Each searched architecture is\ntrained by knowledge distillation on pre-trained language model and then\nevaluated under a robustness-, accuracy- and efficiency-aware metric as\nenvironmental fitness. Experimental results show that RoSearch can improve\nrobustness of student models from 7%~18% up to 45.8%~47.8% on different\ndatasets with comparable weight compression ratio to existing distillation\nmethods (4.6$\\times$~6.5$\\times$ improvement from teacher model BERT_BASE) and\nlow accuracy drop. In addition, we summarize the relationship between student\narchitecture and robustness through statistics of searched models.", "published": "2021-06-07 13:38:16", "link": "http://arxiv.org/abs/2106.03613v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GTM: A Generative Triple-Wise Model for Conversational Question\n  Generation", "abstract": "Generating some appealing questions in open-domain conversations is an\neffective way to improve human-machine interactions and lead the topic to a\nbroader or deeper direction. To avoid dull or deviated questions, some\nresearchers tried to utilize answer, the \"future\" information, to guide\nquestion generation. However, they separate a post-question-answer (PQA) triple\ninto two parts: post-question (PQ) and question-answer (QA) pairs, which may\nhurt the overall coherence. Besides, the QA relationship is modeled as a\none-to-one mapping that is not reasonable in open-domain conversations. To\ntackle these problems, we propose a generative triple-wise model with\nhierarchical variations for open-domain conversational question generation\n(CQG). Latent variables in three hierarchies are used to represent the shared\nbackground of a triple and one-to-many semantic mappings in both PQ and QA\npairs. Experimental results on a large-scale CQG dataset show that our method\nsignificantly improves the quality of questions in terms of fluency, coherence\nand diversity over competitive baselines.", "published": "2021-06-07 14:07:07", "link": "http://arxiv.org/abs/2106.03635v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diversity driven Query Rewriting in Search Advertising", "abstract": "Retrieving keywords (bidwords) with the same intent as query, referred to as\nclose variant keywords, is of prime importance for effective targeted search\nadvertising. For head and torso search queries, sponsored search engines use a\nhuge repository of same intent queries and keywords, mined ahead of time.\nOnline, this repository is used to rewrite the query and then lookup the\nrewrite in a repository of bid keywords contributing to significant revenue.\nRecently generative retrieval models have been shown to be effective at the\ntask of generating such query rewrites. We observe two main limitations of such\ngenerative models. First, rewrites generated by these models exhibit low\nlexical diversity, and hence the rewrites fail to retrieve relevant keywords\nthat have diverse linguistic variations. Second, there is a misalignment\nbetween the training objective - the likelihood of training data, v/s what we\ndesire - improved quality and coverage of rewrites. In this work, we introduce\nCLOVER, a framework to generate both high-quality and diverse rewrites by\noptimizing for human assessment of rewrite quality using our diversity-driven\nreinforcement learning algorithm. We use an evaluation model, trained to\npredict human judgments, as the reward function to finetune the generation\npolicy. We empirically show the effectiveness of our proposed approach through\noffline experiments on search queries across geographies spanning three major\nlanguages. We also perform online A/B experiments on Bing, a large commercial\nsearch engine, which shows (i) better user engagement with an average increase\nin clicks by 12.83% accompanied with an average defect reduction by 13.97%, and\n(ii) improved revenue by 21.29%.", "published": "2021-06-07 17:30:45", "link": "http://arxiv.org/abs/2106.03816v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Active Speaker Detection as a Multi-Objective Optimization with\n  Uncertainty-based Multimodal Fusion", "abstract": "It is now well established from a variety of studies that there is a\nsignificant benefit from combining video and audio data in detecting active\nspeakers. However, either of the modalities can potentially mislead audiovisual\nfusion by inducing unreliable or deceptive information. This paper outlines\nactive speaker detection as a multi-objective learning problem to leverage best\nof each modalities using a novel self-attention, uncertainty-based multimodal\nfusion scheme. Results obtained show that the proposed multi-objective learning\narchitecture outperforms traditional approaches in improving both mAP and AUC\nscores. We further demonstrate that our fusion strategy surpasses, in active\nspeaker detection, other modality fusion methods reported in various\ndisciplines. We finally show that the proposed method significantly improves\nthe state-of-the-art on the AVA-ActiveSpeaker dataset.", "published": "2021-06-07 17:38:55", "link": "http://arxiv.org/abs/2106.03821v2", "categories": ["cs.SD", "cs.CL", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Counterfactual Maximum Likelihood Estimation for Training Deep Networks", "abstract": "Although deep learning models have driven state-of-the-art performance on a\nwide array of tasks, they are prone to spurious correlations that should not be\nlearned as predictive clues. To mitigate this problem, we propose a\ncausality-based training framework to reduce the spurious correlations caused\nby observed confounders. We give theoretical analysis on the underlying general\nStructural Causal Model (SCM) and propose to perform Maximum Likelihood\nEstimation (MLE) on the interventional distribution instead of the\nobservational distribution, namely Counterfactual Maximum Likelihood Estimation\n(CMLE). As the interventional distribution, in general, is hidden from the\nobservational data, we then derive two different upper bounds of the expected\nnegative log-likelihood and propose two general algorithms, Implicit CMLE and\nExplicit CMLE, for causal predictions of deep learning models using\nobservational data. We conduct experiments on both simulated data and two\nreal-world tasks: Natural Language Inference (NLI) and Image Captioning. The\nresults show that CMLE methods outperform the regular MLE method in terms of\nout-of-domain generalization performance and reducing spurious correlations,\nwhile maintaining comparable performance on the regular evaluations.", "published": "2021-06-07 17:47:16", "link": "http://arxiv.org/abs/2106.03831v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SIGTYP 2021 Shared Task: Robust Spoken Language Identification", "abstract": "While language identification is a fundamental speech and language processing\ntask, for many languages and language families it remains a challenging task.\nFor many low-resource and endangered languages this is in part due to resource\navailability: where larger datasets exist, they may be single-speaker or have\ndifferent domains than desired application scenarios, demanding a need for\ndomain and speaker-invariant language identification systems. This year's\nshared task on robust spoken language identification sought to investigate just\nthis scenario: systems were to be trained on largely single-speaker speech from\none domain, but evaluated on data in other domains recorded from speakers under\ndifferent recording circumstances, mimicking realistic low-resource scenarios.\nWe see that domain and speaker mismatch proves very challenging for current\nmethods which can perform above 95% accuracy in-domain, which domain adaptation\ncan address to some degree, but that these conditions merit further\ninvestigation to make spoken language identification accessible in many\nscenarios.", "published": "2021-06-07 18:12:27", "link": "http://arxiv.org/abs/2106.03895v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Measuring and Improving BERT's Mathematical Abilities by Predicting the\n  Order of Reasoning", "abstract": "Imagine you are in a supermarket. You have two bananas in your basket and\nwant to buy four apples. How many fruits do you have in total? This seemingly\nstraightforward question can be challenging for data-driven language models,\neven if trained at scale. However, we would expect such generic language models\nto possess some mathematical abilities in addition to typical linguistic\ncompetence. Towards this goal, we investigate if a commonly used language\nmodel, BERT, possesses such mathematical abilities and, if so, to what degree.\nFor that, we fine-tune BERT on a popular dataset for word math problems,\nAQuA-RAT, and conduct several tests to understand learned representations\nbetter. Since we teach models trained on natural language to do formal\nmathematics, we hypothesize that such models would benefit from training on\nsemi-formal steps that explain how math results are derived. To better\naccommodate such training, we also propose new pretext tasks for learning\nmathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or\nNROP). With this new model, we achieve significantly better outcomes than\ndata-driven baselines and even on-par with more tailored models. We also show\nhow to reduce positional bias in such models.", "published": "2021-06-07 19:08:29", "link": "http://arxiv.org/abs/2106.03921v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Document-level Relation Extraction as Semantic Segmentation", "abstract": "Document-level relation extraction aims to extract relations among multiple\nentity pairs from a document. Previously proposed graph-based or\ntransformer-based models utilize the entities independently, regardless of\nglobal information among relational triples. This paper approaches the problem\nby predicting an entity-level relation matrix to capture local and global\ninformation, parallel to the semantic segmentation task in computer vision.\nHerein, we propose a Document U-shaped Network for document-level relation\nextraction. Specifically, we leverage an encoder module to capture the context\ninformation of entities and a U-shaped segmentation module over the image-style\nfeature map to capture global interdependency among triples. Experimental\nresults show that our approach can obtain state-of-the-art performance on three\nbenchmark datasets DocRED, CDR, and GDA.", "published": "2021-06-07 13:44:44", "link": "http://arxiv.org/abs/2106.03618v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Augmentation Methods for End-to-end Speech Recognition on\n  Distant-Talk Scenarios", "abstract": "Although end-to-end automatic speech recognition (E2E ASR) has achieved great\nperformance in tasks that have numerous paired data, it is still challenging to\nmake E2E ASR robust against noisy and low-resource conditions. In this study,\nwe investigated data augmentation methods for E2E ASR in distant-talk\nscenarios. E2E ASR models are trained on the series of CHiME challenge\ndatasets, which are suitable tasks for studying robustness against noisy and\nspontaneous speech. We propose to use three augmentation methods and thier\ncombinations: 1) data augmentation using text-to-speech (TTS) data, 2)\ncycle-consistent generative adversarial network (Cycle-GAN) augmentation\ntrained to map two different audio characteristics, the one of clean speech and\nof noisy recordings, to match the testing condition, and 3) pseudo-label\naugmentation provided by the pretrained ASR module for smoothing label\ndistributions. Experimental results using the CHiME-6/CHiME-4 datasets show\nthat each augmentation method individually improves the accuracy on top of the\nconventional SpecAugment; further improvements are obtained by combining these\napproaches. We achieved 4.3\\% word error rate (WER) reduction, which was more\nsignificant than that of the SpecAugment, when we combine all three\naugmentations for the CHiME-6 task.", "published": "2021-06-07 08:36:26", "link": "http://arxiv.org/abs/2106.03419v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Empirical Bayesian Independent Deeply Learned Matrix Analysis For\n  Multichannel Audio Source Separation", "abstract": "Independent deeply learned matrix analysis (IDLMA) is one of the\nstate-of-the-art supervised multichannel audio source separation methods. It\nblindly estimates the demixing filters on the basis of source independence,\nusing the source model estimated by the deep neural network (DNN). However,\nsince the ratios of the source to interferer signals vary widely among\ntime-frequency (TF) slots, it is difficult to obtain reliable estimated power\nspectrograms of sources at all TF slots. In this paper, we propose an IDLMA\nextension, empirical Bayesian IDLMA (EB-IDLMA), by introducing a prior\ndistribution of source power spectrograms and treating the source power\nspectrograms as latent random variables. This treatment allows us to implicitly\nconsider the reliability of the estimated source power spectrograms for the\nestimation of demixing filters through the hyperparameters of the prior\ndistribution estimated by the DNN. Experimental evaluations show the\neffectiveness of EB-IDLMA and the importance of introducing the reliability of\nthe estimated source power spectrograms.", "published": "2021-06-07 10:26:02", "link": "http://arxiv.org/abs/2106.03492v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weakly-supervised word-level pronunciation error detection in non-native\n  English speech", "abstract": "We propose a weakly-supervised model for word-level mispronunciation\ndetection in non-native (L2) English speech. To train this model, phonetically\ntranscribed L2 speech is not required and we only need to mark mispronounced\nwords. The lack of phonetic transcriptions for L2 speech means that the model\nhas to learn only from a weak signal of word-level mispronunciations. Because\nof that and due to the limited amount of mispronounced L2 speech, the model is\nmore likely to overfit. To limit this risk, we train it in a multi-task setup.\nIn the first task, we estimate the probabilities of word-level\nmispronunciation. For the second task, we use a phoneme recognizer trained on\nphonetically transcribed L1 speech that is easily accessible and can be\nautomatically annotated. Compared to state-of-the-art approaches, we improve\nthe accuracy of detecting word-level pronunciation errors in AUC metric by 30%\non the GUT Isle Corpus of L2 Polish speakers, and by 21.5% on the Isle Corpus\nof L2 German and Italian speakers.", "published": "2021-06-07 10:31:53", "link": "http://arxiv.org/abs/2106.03494v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Unsupervised Clustered Federated Learning in Complex Multi-source\n  Acoustic Environments", "abstract": "In this paper we introduce a realistic and challenging, multi-source and\nmulti-room acoustic environment and an improved algorithm for the estimation of\nsource-dominated microphone clusters in acoustic sensor networks. Our proposed\nclustering method is based on a single microphone per node and on unsupervised\nclustered federated learning which employs a light-weight autoencoder model. We\npresent an improved clustering control strategy that takes into account the\nvariability of the acoustic scene and allows the estimation of a dynamic range\nof clusters using reduced amounts of training data. The proposed approach is\noptimized using clustering-based measures and validated via a network-wide\nclassification task.", "published": "2021-06-07 14:51:39", "link": "http://arxiv.org/abs/2106.03671v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "PANACEA cough sound-based diagnosis of COVID-19 for the DiCOVA 2021\n  Challenge", "abstract": "The COVID-19 pandemic has led to the saturation of public health services\nworldwide. In this scenario, the early diagnosis of SARS-Cov-2 infections can\nhelp to stop or slow the spread of the virus and to manage the demand upon\nhealth services. This is especially important when resources are also being\nstretched by heightened demand linked to other seasonal diseases, such as the\nflu. In this context, the organisers of the DiCOVA 2021 challenge have\ncollected a database with the aim of diagnosing COVID-19 through the use of\ncoughing audio samples. This work presents the details of the automatic system\nfor COVID-19 detection from cough recordings presented by team PANACEA. This\nteam consists of researchers from two European academic institutions and one\ncompany: EURECOM (France), University of Granada (Spain), and Biometric Vox\nS.L. (Spain). We developed several systems based on established signal\nprocessing and machine learning methods. Our best system employs a Teager\nenergy operator cepstral coefficients (TECCs) based frontend and Light gradient\nboosting machine (LightGBM) backend. The AUC obtained by this system on the\ntest set is 76.31% which corresponds to a 10% improvement over the official\nbaseline.", "published": "2021-06-07 09:09:32", "link": "http://arxiv.org/abs/2106.04423v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PILOT: Introducing Transformers for Probabilistic Sound Event\n  Localization", "abstract": "Sound event localization aims at estimating the positions of sound sources in\nthe environment with respect to an acoustic receiver (e.g. a microphone array).\nRecent advances in this domain most prominently focused on utilizing deep\nrecurrent neural networks. Inspired by the success of transformer architectures\nas a suitable alternative to classical recurrent neural networks, this paper\nintroduces a novel transformer-based sound event localization framework, where\ntemporal dependencies in the received multi-channel audio signals are captured\nvia self-attention mechanisms. Additionally, the estimated sound event\npositions are represented as multivariate Gaussian variables, yielding an\nadditional notion of uncertainty, which many previously proposed deep\nlearning-based systems designed for this application do not provide. The\nframework is evaluated on three publicly available multi-source sound event\nlocalization datasets and compared against state-of-the-art methods in terms of\nlocalization error and event detection accuracy. It outperforms all competing\nsystems on all datasets with statistical significant differences in\nperformance.", "published": "2021-06-07 18:29:19", "link": "http://arxiv.org/abs/2106.03903v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "How to Design a Three-Stage Architecture for Audio-Visual Active Speaker\n  Detection in the Wild", "abstract": "Successful active speaker detection requires a three-stage pipeline: (i)\naudio-visual encoding for all speakers in the clip, (ii) inter-speaker relation\nmodeling between a reference speaker and the background speakers within each\nframe, and (iii) temporal modeling for the reference speaker. Each stage of\nthis pipeline plays an important role for the final performance of the created\narchitecture. Based on a series of controlled experiments, this work presents\nseveral practical guidelines for audio-visual active speaker detection.\nCorrespondingly, we present a new architecture called ASDNet, which achieves a\nnew state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5%\noutperforming the second best with a large margin of 4.7%. Our code and\npretrained models are publicly available.", "published": "2021-06-07 19:44:56", "link": "http://arxiv.org/abs/2106.03932v2", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
