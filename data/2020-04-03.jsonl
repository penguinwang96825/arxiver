{"title": "XGLUE: A New Benchmark Dataset for Cross-lingual Pre-training,\n  Understanding and Generation", "abstract": "In this paper, we introduce XGLUE, a new benchmark dataset that can be used\nto train large-scale cross-lingual pre-trained models using multilingual and\nbilingual corpora and evaluate their performance across a diverse set of\ncross-lingual tasks. Comparing to GLUE(Wang et al., 2019), which is labeled in\nEnglish for natural language understanding tasks only, XGLUE has two main\nadvantages: (1) it provides 11 diversified tasks that cover both natural\nlanguage understanding and generation scenarios; (2) for each task, it provides\nlabeled data in multiple languages. We extend a recent cross-lingual\npre-trained model Unicoder(Huang et al., 2019) to cover both understanding and\ngeneration tasks, which is evaluated on XGLUE as a strong baseline. We also\nevaluate the base versions (12-layer) of Multilingual BERT, XLM and XLM-R for\ncomparison.", "published": "2020-04-03 07:03:12", "link": "http://arxiv.org/abs/2004.01401v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing autoencoder-based acoustic word embeddings", "abstract": "Recent studies have introduced methods for learning acoustic word embeddings\n(AWEs)---fixed-size vector representations of words which encode their acoustic\nfeatures. Despite the widespread use of AWEs in speech processing research,\nthey have only been evaluated quantitatively in their ability to discriminate\nbetween whole word tokens. To better understand the applications of AWEs in\nvarious downstream tasks and in cognitive modeling, we need to analyze the\nrepresentation spaces of AWEs. Here we analyze basic properties of AWE spaces\nlearned by a sequence-to-sequence encoder-decoder model in six typologically\ndiverse languages. We first show that these AWEs preserve some information\nabout words' absolute duration and speaker. At the same time, the\nrepresentation space of these AWEs is organized such that the distance between\nwords' embeddings increases with those words' phonetic dissimilarity. Finally,\nthe AWEs exhibit a word onset bias, similar to patterns reported in various\nstudies on human speech processing and lexical access. We argue this is a\npromising result and encourage further evaluation of AWEs as a potentially\nuseful tool in cognitive science, which could provide a link between speech\nprocessing and lexical memory.", "published": "2020-04-03 16:11:57", "link": "http://arxiv.org/abs/2004.01647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Directions in Abusive Language Training Data: Garbage In, Garbage Out", "abstract": "Data-driven analysis and detection of abusive online content covers many\ndifferent tasks, phenomena, contexts, and methodologies. This paper\nsystematically reviews abusive language dataset creation and content in\nconjunction with an open website for cataloguing abusive language data. This\ncollection of knowledge leads to a synthesis providing evidence-based\nrecommendations for practitioners working with this complex and highly diverse\ndata.", "published": "2020-04-03 16:51:33", "link": "http://arxiv.org/abs/2004.01670v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning synchronous context-free grammars with multiple specialised\n  non-terminals for hierarchical phrase-based translation", "abstract": "Translation models based on hierarchical phrase-based statistical machine\ntranslation (HSMT) have shown better performances than the non-hierarchical\nphrase-based counterparts for some language pairs. The standard approach to\nHSMT learns and apply a synchronous context-free grammar with a single\nnon-terminal. The hypothesis behind the grammar refinement algorithm presented\nin this work is that this single non-terminal is overloaded, and insufficiently\ndiscriminative, and therefore, an adequate split of it into more specialised\nsymbols could lead to improved models. This paper presents a method to learn\nsynchronous context-free grammars with a huge number of initial non-terminals,\nwhich are then grouped via a clustering algorithm. Our experiments show that\nthe resulting smaller set of non-terminals correctly capture the contextual\ninformation that makes it possible to statistically significantly improve the\nBLEU score of the standard HSMT approach.", "published": "2020-04-03 08:09:07", "link": "http://arxiv.org/abs/2004.01422v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Set of Recommendations for Assessing Human-Machine Parity in Language\n  Translation", "abstract": "The quality of machine translation has increased remarkably over the past\nyears, to the degree that it was found to be indistinguishable from\nprofessional human translation in a number of empirical investigations. We\nreassess Hassan et al.'s 2018 investigation into Chinese to English news\ntranslation, showing that the finding of human-machine parity was owed to\nweaknesses in the evaluation design - which is currently considered best\npractice in the field. We show that the professional human translations\ncontained significantly fewer errors, and that perceived quality in human\nevaluation depends on the choice of raters, the availability of linguistic\ncontext, and the creation of reference translations. Our results call for\nrevisiting current best practices to assess strong machine translation systems\nin general and human-machine parity in particular, for which we offer a set of\nrecommendations based on our empirical findings.", "published": "2020-04-03 17:49:56", "link": "http://arxiv.org/abs/2004.01694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Finding Black Cat in a Coal Cellar -- Keyphrase Extraction &\n  Keyphrase-Rubric Relationship Classification from Complex Assignments", "abstract": "Diversity in content and open-ended questions are inherent in complex\nassignments across online graduate programs. The natural scale of these\nprograms poses a variety of challenges across both peer and expert feedback\nincluding rogue reviews. While the identification of relevant content and\nassociating it to predefined rubrics would simplify and improve the grading\nprocess, the research to date is still in a nascent stage. As such in this\npaper we aim to quantify the effectiveness of supervised and unsupervised\napproaches for the task for keyphrase extraction and generic/specific\nkeyphrase-rubric relationship extraction. Through this study, we find that (i)\nunsupervised MultiPartiteRank produces the best result for keyphrase extraction\n(ii) supervised SVM classifier with BERT features that offer the best\nperformance for both generic and specific keyphrase-rubric relationship\nclassification. We finally present a comprehensive analysis and derive useful\nobservations for those interested in these tasks for the future. The source\ncode is released in \\url{https://github.com/manikandan-ravikiran/cs6460-proj}.", "published": "2020-04-03 13:18:02", "link": "http://arxiv.org/abs/2004.01549v3", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Aligned Cross Entropy for Non-Autoregressive Machine Translation", "abstract": "Non-autoregressive machine translation models significantly speed up decoding\nby allowing for parallel prediction of the entire target sequence. However,\nmodeling word order is more challenging due to the lack of autoregressive\nfactors in the model. This difficultly is compounded during training with cross\nentropy loss, which can highly penalize small shifts in word order. In this\npaper, we propose aligned cross entropy (AXE) as an alternative loss function\nfor training of non-autoregressive models. AXE uses a differentiable dynamic\nprogram to assign loss based on the best possible monotonic alignment between\ntarget tokens and model predictions. AXE-based training of conditional masked\nlanguage models (CMLMs) substantially improves performance on major WMT\nbenchmarks, while setting a new state of the art for non-autoregressive models.", "published": "2020-04-03 16:24:47", "link": "http://arxiv.org/abs/2004.01655v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Testing pre-trained Transformer models for Lithuanian news clustering", "abstract": "A recent introduction of Transformer deep learning architecture made\nbreakthroughs in various natural language processing tasks. However,\nnon-English languages could not leverage such new opportunities with the\nEnglish text pre-trained models. This changed with research focusing on\nmultilingual models, where less-spoken languages are the main beneficiaries. We\ncompare pre-trained multilingual BERT, XLM-R, and older learned text\nrepresentation methods as encodings for the task of Lithuanian news clustering.\nOur results indicate that publicly available pre-trained multilingual\nTransformer models can be fine-tuned to surpass word vectors but still score\nmuch lower than specially trained doc2vec embeddings.", "published": "2020-04-03 14:41:54", "link": "http://arxiv.org/abs/2004.03461v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "68T05", "I.2.6"], "primary_category": "cs.IR"}
{"title": "Template-based Question Answering using Recursive Neural Networks", "abstract": "We propose a neural network-based approach to automatically learn and\nclassify natural language questions into its corresponding template using\nrecursive neural networks. An obvious advantage of using neural networks is the\nelimination of the need for laborious feature engineering that can be\ncumbersome and error-prone. The input question is encoded into a vector\nrepresentation. The model is trained and evaluated on the LC-QuAD dataset\n(Large-scale Complex Question Answering Dataset). The LC-QuAD queries are\nannotated based on 38 unique templates that the model attempts to classify. The\nresulting model is evaluated against both the LC-QuAD dataset and the 7th\nQuestion Answering Over Linked Data (QALD-7) dataset. The recursive neural\nnetwork achieves template classification accuracy of 0.828 on the LC-QuAD\ndataset and an accuracy of 0.618 on the QALD-7 dataset. When the top-2 most\nlikely templates were considered the model achieves an accuracy of 0.945 on the\nLC-QuAD dataset and 0.786 on the QALD-7 dataset. After slot filling, the\noverall system achieves a macro F-score 0.419 on the LC-QuAD dataset and a\nmacro F-score of 0.417 on the QALD-7 dataset.", "published": "2020-04-03 18:14:39", "link": "http://arxiv.org/abs/2004.13843v3", "categories": ["cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural i-vectors", "abstract": "Deep speaker embeddings have been demonstrated to outperform their generative\ncounterparts, i-vectors, in recent speaker verification evaluations. To combine\nthe benefits of high performance and generative interpretation, we investigate\nthe use of deep embedding extractor and i-vector extractor in succession. To\nbundle the deep embedding extractor with an i-vector extractor, we adopt\naggregation layers inspired by the Gaussian mixture model (GMM) to the\nembedding extractor networks. The inclusion of GMM-like layer allows the\ndiscriminatively trained network to be used as a provider of sufficient\nstatistics for the i-vector extractor to extract what we call neural i-vectors.\nWe compare the deep embeddings to the proposed neural i-vectors on the Speakers\nin the Wild (SITW) and the Speaker Recognition Evaluation (SRE) 2018 and 2019\ndatasets. On the core-core condition of SITW, our deep embeddings obtain\nperformance comparative to the state-of-the-art. The neural i-vectors obtain\nabout 50% worse performance than the deep embeddings, but on the other hand\noutperform the previous i-vector approaches reported in the literature by a\nclear margin.", "published": "2020-04-03 13:29:31", "link": "http://arxiv.org/abs/2004.01559v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
