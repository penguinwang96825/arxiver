{"title": "Predicting Discharge Medications at Admission Time Based on Deep\n  Learning", "abstract": "Predicting discharge medications right after a patient being admitted is an\nimportant clinical decision, which provides physicians with guidance on what\ntype of medication regimen to plan for and what possible changes on initial\nmedication may occur during an inpatient stay. It also facilitates medication\nreconciliation process with easy detection of medication discrepancy at\ndischarge time to improve patient safety. However, since the information\navailable upon admission is limited and patients' condition may evolve during\nan inpatient stay, these predictions could be a difficult decision for\nphysicians to make. In this work, we investigate how to leverage deep learning\ntechnologies to assist physicians in predicting discharge medications based on\ninformation documented in the admission note. We build a convolutional neural\nnetwork which takes an admission note as input and predicts the medications\nplaced on the patient at discharge time. Our method is able to distill semantic\npatterns from unstructured and noisy texts, and is capable of capturing the\npharmacological correlations among medications. We evaluate our method on 25K\npatient visits and compare with 4 strong baselines. Our methods demonstrate a\n20% increase in macro-averaged F1 score than the best baseline.", "published": "2017-11-04 03:04:40", "link": "http://arxiv.org/abs/1711.01386v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Stacking Networks for Low-Resource Chinese Word Segmentation with\n  Transfer Learning", "abstract": "In recent years, neural networks have proven to be effective in Chinese word\nsegmentation. However, this promising performance relies on large-scale\ntraining data. Neural networks with conventional architectures cannot achieve\nthe desired results in low-resource datasets due to the lack of labelled\ntraining data. In this paper, we propose a deep stacking framework to improve\nthe performance on word segmentation tasks with insufficient data by\nintegrating datasets from diverse domains. Our framework consists of two parts,\ndomain-based models and deep stacking networks. The domain-based models are\nused to learn knowledge from different datasets. The deep stacking networks are\ndesigned to integrate domain-based models. To reduce model conflicts, we\ninnovatively add communication paths among models and design various structures\nof deep stacking networks, including Gaussian-based Stacking Networks,\nConcatenate-based Stacking Networks, Sequence-based Stacking Networks and\nTree-based Stacking Networks. We conduct experiments on six low-resource\ndatasets from various domains. Our proposed framework shows significant\nperformance improvements on all datasets compared with several strong\nbaselines.", "published": "2017-11-04 12:24:26", "link": "http://arxiv.org/abs/1711.01427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Linguistically Generalizable NLP Systems: A Workshop and Shared\n  Task", "abstract": "This paper presents a summary of the first Workshop on Building\nLinguistically Generalizable Natural Language Processing Systems, and the\nassociated Build It Break It, The Language Edition shared task. The goal of\nthis workshop was to bring together researchers in NLP and linguistics with a\nshared task aimed at testing the generalizability of NLP systems beyond the\ndistributions of their training data. We describe the motivation, setup, and\nparticipation of the shared task, provide discussion of some highlighted\nresults, and discuss lessons learned.", "published": "2017-11-04 22:46:54", "link": "http://arxiv.org/abs/1711.01505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language as a matrix product state", "abstract": "We propose a statistical model for natural language that begins by\nconsidering language as a monoid, then representing it in complex matrices with\na compatible translation invariant probability measure. We interpret the\nprobability measure as arising via the Born rule from a translation invariant\nmatrix product state.", "published": "2017-11-04 09:11:18", "link": "http://arxiv.org/abs/1711.01416v1", "categories": ["cs.CL", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Monaural Singing Voice Separation with Skip-Filtering Connections and\n  Recurrent Inference of Time-Frequency Mask", "abstract": "Singing voice separation based on deep learning relies on the usage of\ntime-frequency masking. In many cases the masking process is not a learnable\nfunction or is not encapsulated into the deep learning optimization.\nConsequently, most of the existing methods rely on a post processing step using\nthe generalized Wiener filtering. This work proposes a method that learns and\noptimizes (during training) a source-dependent mask and does not need the\naforementioned post processing step. We introduce a recurrent inference\nalgorithm, a sparse transformation step to improve the mask generation process,\nand a learned denoising filter. Obtained results show an increase of 0.49 dB\nfor the signal to distortion ratio and 0.30 dB for the signal to interference\nratio, compared to previous state-of-the-art approaches for monaural singing\nvoice separation.", "published": "2017-11-04 13:46:10", "link": "http://arxiv.org/abs/1711.01437v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Knowledge Transfer from Weakly Labeled Audio using Convolutional Neural\n  Network for Sound Events and Scenes", "abstract": "In this work we propose approaches to effectively transfer knowledge from\nweakly labeled web audio data. We first describe a convolutional neural network\n(CNN) based framework for sound event detection and classification using weakly\nlabeled audio data. Our model trains efficiently from audios of variable\nlengths; hence, it is well suited for transfer learning. We then propose\nmethods to learn representations using this model which can be effectively used\nfor solving the target task. We study both transductive and inductive transfer\nlearning tasks, showing the effectiveness of our methods for both domain and\ntask adaptation. We show that the learned representations using the proposed\nCNN model generalizes well enough to reach human level accuracy on ESC-50 sound\nevents dataset and set state of art results on this dataset. We further use\nthem for acoustic scene classification task and once again show that our\nproposed approaches suit well for this task as well. We also show that our\nmethods are helpful in capturing semantic meanings and relations as well.\nMoreover, in this process we also set state-of-art results on Audioset dataset,\nrelying on balanced training set.", "published": "2017-11-04 00:22:23", "link": "http://arxiv.org/abs/1711.01369v4", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
