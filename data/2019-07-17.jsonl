{"title": "Learning Representation Mapping for Relation Detection in Knowledge Base\n  Question Answering", "abstract": "Relation detection is a core step in many natural language process\napplications including knowledge base question answering. Previous efforts show\nthat single-fact questions could be answered with high accuracy. However, one\ncritical problem is that current approaches only get high accuracy for\nquestions whose relations have been seen in the training data. But for unseen\nrelations, the performance will drop rapidly. The main reason for this problem\nis that the representations for unseen relations are missing. In this paper, we\npropose a simple mapping method, named representation adapter, to learn the\nrepresentation mapping for both seen and unseen relations based on previously\nlearned relation embedding. We employ the adversarial objective and the\nreconstruction objective to improve the mapping performance. We re-organize the\npopular SimpleQuestion dataset to reveal and evaluate the problem of detecting\nunseen relations. Experiments show that our method can greatly improve the\nperformance of unseen relations while the performance for those seen part is\nkept comparable to the state-of-the-art. Our code and data are available at\nhttps://github.com/wudapeng268/KBQA-Adapter.", "published": "2019-07-17 04:29:27", "link": "http://arxiv.org/abs/1907.07328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fake News Detection as Natural Language Inference", "abstract": "This report describes the entry by the Intelligent Knowledge Management (IKM)\nLab in the WSDM 2019 Fake News Classification challenge. We treat the task as\nnatural language inference (NLI). We individually train a number of the\nstrongest NLI models as well as BERT. We ensemble these results and retrain\nwith noisy labels in two stages. We analyze transitivity relations in the train\nand test sets and determine a set of test cases that can be reliably classified\non this basis. The remainder of test cases are classified by our ensemble. Our\nentry achieves test set accuracy of 88.063% for 3rd place in the competition.", "published": "2019-07-17 06:03:17", "link": "http://arxiv.org/abs/1907.07347v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Neural Network Comprehension of Natural Language Arguments", "abstract": "We are surprised to find that BERT's peak performance of 77% on the Argument\nReasoning Comprehension Task reaches just three points below the average\nuntrained human baseline. However, we show that this result is entirely\naccounted for by exploitation of spurious statistical cues in the dataset. We\nanalyze the nature of these cues and demonstrate that a range of models all\nexploit them. This analysis informs the construction of an adversarial dataset\non which all models achieve random accuracy. Our adversarial dataset provides a\nmore robust assessment of argument comprehension and should be adopted as the\nstandard in future work.", "published": "2019-07-17 06:26:20", "link": "http://arxiv.org/abs/1907.07355v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Differentiable Disentanglement Filter: an Application Agnostic Core\n  Concept Discovery Probe", "abstract": "It has long been speculated that deep neural networks function by discovering\na hierarchical set of domain-specific core concepts or patterns, which are\nfurther combined to recognize even more elaborate concepts for the\nclassification or other machine learning tasks. Meanwhile disentangling the\nactual core concepts engrained in the word embeddings (like word2vec or BERT)\nor deep convolutional image recognition neural networks (like PG-GAN) is\ndifficult and some success there has been achieved only recently. In this paper\nwe propose a novel neural network nonlinearity named Differentiable\nDisentanglement Filter (DDF) which can be transparently inserted into any\nexisting neural network layer to automatically disentangle the core concepts\nused by that layer. The DDF probe is inspired by the obscure properties of the\nhyper-dimensional computing theory. The DDF proof-of-concept implementation is\nshown to disentangle concepts within the neural 3D scene representation - a\ntask vital for visual grounding of natural language narratives.", "published": "2019-07-17 13:31:31", "link": "http://arxiv.org/abs/1907.07507v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Almawave-SLU: A new dataset for SLU in Italian", "abstract": "The widespread use of conversational and question answering systems made it\nnecessary to improve the performances of speaker intent detection and\nunderstanding of related semantic slots, i.e., Spoken Language Understanding\n(SLU). Often, these tasks are approached with supervised learning methods,\nwhich needs considerable labeled datasets. This paper presents the first\nItalian dataset for SLU. It is derived through a semi-automatic procedure and\nis used as a benchmark of various open source and commercial systems.", "published": "2019-07-17 13:52:54", "link": "http://arxiv.org/abs/1907.07526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Linguistic Characteristics for Bipolar Disorder Recognition\n  with Gender Differences", "abstract": "Most previous studies on automatic recognition model for bipolar disorder\n(BD) were based on both social media and linguistic features. The present study\ninvestigates the possibility of adopting only language-based features, namely\nthe syntax and morpheme collocation. We also examine the effect of gender on\nthe results considering gender has long been recognized as an important\nmodulating factor for mental disorders, yet it received little attention in\nprevious linguistic models. The present study collects Twitter posts 3 months\nprior to the self-disclosure by 349 BD users (231 female, 118 male). We\nconstruct a set of syntactic patterns in terms of the word usage based on graph\npattern construction and pattern attention mechanism. The factors examined are\ngender differences, syntactic patterns, and bipolar recognition performance.\nThe performance indicates our F1 scores reach over 91% and outperform several\nbaselines, including those using TF-IDF, LIWC and pre-trained language models\n(ELMO and BERT). The contributions of the present study are: (1) The features\nare contextualized, domain-agnostic, and purely linguistic. (2) The performance\nof BD recognition is improved by gender-enriched linguistic pattern features,\nwhich are constructed with gender differences in language usage.", "published": "2019-07-17 07:37:13", "link": "http://arxiv.org/abs/1907.07366v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SUMBT: Slot-Utterance Matching for Universal and Scalable Belief\n  Tracking", "abstract": "In goal-oriented dialog systems, belief trackers estimate the probability\ndistribution of slot-values at every dialog turn. Previous neural approaches\nhave modeled domain- and slot-dependent belief trackers, and have difficulty in\nadding new slot-values, resulting in lack of flexibility of domain ontology\nconfigurations. In this paper, we propose a new approach to universal and\nscalable belief tracker, called slot-utterance matching belief tracker (SUMBT).\nThe model learns the relations between domain-slot-types and slot-values\nappearing in utterances through attention mechanisms based on contextual\nsemantic vectors. Furthermore, the model predicts slot-value labels in a\nnon-parametric way. From our experiments on two dialog corpora, WOZ 2.0 and\nMultiWOZ, the proposed model showed performance improvement in comparison with\nslot-dependent methods and achieved the state-of-the-art joint accuracy.", "published": "2019-07-17 10:03:38", "link": "http://arxiv.org/abs/1907.07421v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning End-to-End Goal-Oriented Dialog with Maximal User Task Success\n  and Minimal Human Agent Use", "abstract": "Neural end-to-end goal-oriented dialog systems showed promise to reduce the\nworkload of human agents for customer service, as well as reduce wait time for\nusers. However, their inability to handle new user behavior at deployment has\nlimited their usage in real world. In this work, we propose an end-to-end\ntrainable method for neural goal-oriented dialog systems which handles new user\nbehaviors at deployment by transferring the dialog to a human agent\nintelligently. The proposed method has three goals: 1) maximize user's task\nsuccess by transferring to human agents, 2) minimize the load on the human\nagents by transferring to them only when it is essential and 3) learn online\nfrom the human agent's responses to reduce human agents load further. We\nevaluate our proposed method on a modified-bAbI dialog task that simulates the\nscenario of new user behaviors occurring at test time. Experimental results\nshow that our proposed method is effective in achieving the desired goals.", "published": "2019-07-17 16:50:16", "link": "http://arxiv.org/abs/1907.07638v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gated Recurrent Neural Network Approach for Multilabel Emotion Detection\n  in Microblogs", "abstract": "People express their opinions and emotions freely in social media posts and\nonline reviews that contain valuable feedback for multiple stakeholders such as\nbusinesses and political campaigns. Manually extracting opinions and emotions\nfrom large volumes of such posts is an impossible task. Therefore, automated\nprocessing of these posts to extract opinions and emotions is an important\nresearch problem. However, human emotion detection is a challenging task due to\nthe complexity and nuanced nature. To overcome these barriers, researchers have\nextensively used techniques such as deep learning, distant supervision, and\ntransfer learning. In this paper, we propose a novel Pyramid Attention Network\n(PAN) based model for emotion detection in microblogs. The main advantage of\nour approach is that PAN has the capability to evaluate sentences in different\nperspectives to capture multiple emotions existing in a single text. The\nproposed model was evaluated on a recently released dataset and the results\nachieved the state-of-the-art accuracy of 58.9%.", "published": "2019-07-17 17:33:13", "link": "http://arxiv.org/abs/1907.07653v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoding the Style and Bias of Song Lyrics", "abstract": "The central idea of this paper is to gain a deeper understanding of song\nlyrics computationally. We focus on two aspects: style and biases of song\nlyrics. All prior works to understand these two aspects are limited to manual\nanalysis of a small corpus of song lyrics. In contrast, we analyzed more than\nhalf a million songs spread over five decades. We characterize the lyrics style\nin terms of vocabulary, length, repetitiveness, speed, and readability. We have\nobserved that the style of popular songs significantly differs from other\nsongs. We have used distributed representation methods and WEAT test to measure\nvarious gender and racial biases in the song lyrics. We have observed that\nbiases in song lyrics correlate with prior results on human subjects. This\ncorrelation indicates that song lyrics reflect the biases that exist in\nsociety. Increasing consumption of music and the effect of lyrics on human\nemotions makes this analysis important.", "published": "2019-07-17 23:57:46", "link": "http://arxiv.org/abs/1907.07818v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Analysis of Word Embeddings Using Fuzzy Clustering", "abstract": "In data dominated systems and applications, a concept of representing words\nin a numerical format has gained a lot of attention. There are a few approaches\nused to generate such a representation. An interesting issue that should be\nconsidered is the ability of such representations - called embeddings - to\nimitate human-based semantic similarity between words. In this study, we\nperform a fuzzy-based analysis of vector representations of words, i.e., word\nembeddings. We use two popular fuzzy clustering algorithms on count-based word\nembeddings, known as GloVe, of different dimensionality. Words from\nWordSim-353, called the gold standard, are represented as vectors and\nclustered. The results indicate that fuzzy clustering algorithms are very\nsensitive to high-dimensional data, and parameter tuning can dramatically\nchange their performance. We show that by adjusting the value of the fuzzifier\nparameter, fuzzy clustering can be successfully applied to vectors of high - up\nto one hundred - dimensions. Additionally, we illustrate that fuzzy clustering\nallows to provide interesting results regarding membership of words to\ndifferent clusters.", "published": "2019-07-17 23:40:46", "link": "http://arxiv.org/abs/1907.07672v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OmniNet: A unified architecture for multi-modal multi-task learning", "abstract": "Transformer is a popularly used neural network architecture, especially for\nlanguage understanding. We introduce an extended and unified architecture that\ncan be used for tasks involving a variety of modalities like image, text,\nvideos, etc. We propose a spatio-temporal cache mechanism that enables learning\nspatial dimension of the input in addition to the hidden states corresponding\nto the temporal input sequence. The proposed architecture further enables a\nsingle model to support tasks with multiple input modalities as well as\nasynchronous multi-task learning, thus we refer to it as OmniNet. For example,\na single instance of OmniNet can concurrently learn to perform the tasks of\npart-of-speech tagging, image captioning, visual question answering and video\nactivity recognition. We demonstrate that training these four tasks together\nresults in about three times compressed model while retaining the performance\nin comparison to training them individually. We also show that using this\nneural network pre-trained on some modalities assists in learning unseen tasks\nsuch as video captioning and video question answering. This illustrates the\ngeneralization capacity of the self-attention mechanism on the spatio-temporal\ncache present in OmniNet.", "published": "2019-07-17 22:59:56", "link": "http://arxiv.org/abs/1907.07804v2", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "HODGEPODGE: Sound event detection based on ensemble of semi-supervised\n  learning methods", "abstract": "In this paper, we present a method called HODGEPODGE\\footnotemark[1] for\nlarge-scale detection of sound events using weakly labeled, synthetic, and\nunlabeled data proposed in the Detection and Classification of Acoustic Scenes\nand Events (DCASE) 2019 challenge Task 4: Sound event detection in domestic\nenvironments. To perform this task, we adopted the convolutional recurrent\nneural networks (CRNN) as our backbone network. In order to deal with a small\namount of tagged data and a large amounts of unlabeled in-domain data, we aim\nto focus primarily on how to apply semi-supervise learning methods efficiently\nto make full use of limited data. Three semi-supervised learning principles\nhave been used in our system, including: 1) Consistency regularization applies\ndata augmentation; 2) MixUp regularizer requiring that the predictions for a\ninterpolation of two inputs is close to the interpolation of the prediction for\neach individual input; 3) MixUp regularization applies to interpolation between\ndata augmentations. We also tried an ensemble of various models, which are\ntrained by using different semi-supervised learning principles. Our proposed\napproach significantly improved the performance of the baseline, achieving the\nevent-based f-measure of 42.0\\% compared to 25.8\\% event-based f-measure of the\nbaseline in the provided official evaluation dataset. Our submissions ranked\nthird among 18 teams in the task 4.", "published": "2019-07-17 08:55:51", "link": "http://arxiv.org/abs/1907.07398v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
