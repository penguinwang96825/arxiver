{"title": "Women in ISIS Propaganda: A Natural Language Processing Analysis of\n  Topics and Emotions in a Comparison with Mainstream Religious Group", "abstract": "Online propaganda is central to the recruitment strategies of extremist\ngroups and in recent years these efforts have increasingly extended to women.\nTo investigate ISIS' approach to targeting women in their online propaganda and\nuncover implications for counterterrorism, we rely on text mining and natural\nlanguage processing (NLP). Specifically, we extract articles published in Dabiq\nand Rumiyah (ISIS's online English language publications) to identify prominent\ntopics. To identify similarities or differences between these texts and those\nproduced by non-violent religious groups, we extend the analysis to articles\nfrom a Catholic forum dedicated to women. We also perform an emotional analysis\nof both of these resources to better understand the emotional components of\npropaganda. We rely on Depechemood (a lexical-base emotion analysis method) to\ndetect emotions most likely to be evoked in readers of these materials. The\nfindings indicate that the emotional appeal of ISIS and Catholic materials are\nsimilar", "published": "2019-12-09 01:11:59", "link": "http://arxiv.org/abs/1912.03804v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Effective Attention Modeling for Neural Relation Extraction", "abstract": "Relation extraction is the task of determining the relation between two\nentities in a sentence. Distantly-supervised models are popular for this task.\nHowever, sentences can be long and two entities can be located far from each\nother in a sentence. The pieces of evidence supporting the presence of a\nrelation between two entities may not be very direct, since the entities may be\nconnected via some indirect links such as a third entity or via co-reference.\nRelation extraction in such scenarios becomes more challenging as we need to\ncapture the long-distance interactions among the entities and other words in\nthe sentence. Also, the words in a sentence do not contribute equally in\nidentifying the relation between the two entities. To address this issue, we\npropose a novel and effective attention model which incorporates syntactic\ninformation of the sentence and a multi-factor attention mechanism. Experiments\non the New York Times corpus show that our proposed model outperforms prior\nstate-of-the-art models.", "published": "2019-12-09 03:38:16", "link": "http://arxiv.org/abs/1912.03832v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AI2D-RST: A multimodal corpus of 1000 primary school science diagrams", "abstract": "This article introduces AI2D-RST, a multimodal corpus of 1000\nEnglish-language diagrams that represent topics in primary school natural\nsciences, such as food webs, life cycles, moon phases and human physiology. The\ncorpus is based on the Allen Institute for Artificial Intelligence Diagrams\n(AI2D) dataset, a collection of diagrams with crowd-sourced descriptions, which\nwas originally developed to support research on automatic diagram understanding\nand visual question answering. Building on the segmentation of diagram layouts\nin AI2D, the AI2D-RST corpus presents a new multi-layer annotation schema that\nprovides a rich description of their multimodal structure. Annotated by trained\nexperts, the layers describe (1) the grouping of diagram elements into\nperceptual units, (2) the connections set up by diagrammatic elements such as\narrows and lines, and (3) the discourse relations between diagram elements,\nwhich are described using Rhetorical Structure Theory (RST). Each annotation\nlayer in AI2D-RST is represented using a graph. The corpus is freely available\nfor research and teaching.", "published": "2019-12-09 07:22:54", "link": "http://arxiv.org/abs/1912.03879v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Analysis of the Ethiopic Twitter Dataset for Abusive Speech in Amharic", "abstract": "In this paper, we present an analysis of the first Ethiopic Twitter Dataset\nfor the Amharic language targeted for recognizing abusive speech. The dataset\nhas been collected since 2014 that is written in Fidel script. Since several\nlanguages can be written using the Fidel script, we have used the existing\nAmharic, Tigrinya and Ge'ez corpora to retain only the Amharic tweets. We have\nanalyzed the tweets for abusive speech content with the following targets:\nAnalyze the distribution and tendency of abusive speech content over time and\ncompare the abusive speech content between a Twitter and general reference\nAmharic corpus.", "published": "2019-12-09 23:18:13", "link": "http://arxiv.org/abs/1912.04419v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "MITAS: A Compressed Time-Domain Audio Separation Network with Parameter\n  Sharing", "abstract": "Deep learning methods have brought substantial advancements in speech\nseparation (SS). Nevertheless, it remains challenging to deploy\ndeep-learning-based models on edge devices. Thus, identifying an effective way\nto compress these large models without hurting SS performance has become an\nimportant research topic. Recently, TasNet and Conv-TasNet have been proposed.\nThey achieved state-of-the-art results on several standardized SS tasks.\nMoreover, their low latency natures make them definitely suitable for real-time\non-device applications. In this study, we propose two parameter-sharing schemes\nto lower the memory consumption on TasNet and Conv-TasNet. Accordingly, we\nderive a novel so-called MiTAS (Mini TasNet). Our experimental results first\nconfirmed the robustness of our MiTAS on two types of perturbations in mixed\naudio. We also designed a series of ablation experiments to analyze the\nrelation between SS performance and the amount of parameters in the model. The\nresults show that MiTAS is able to reduce the model size by a factor of four\nwhile maintaining comparable SS performance with improved stability as compared\nto TasNet and Conv-TasNet. This suggests that MiTAS is more suitable for\nreal-time low latency applications.", "published": "2019-12-09 07:44:32", "link": "http://arxiv.org/abs/1912.03884v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeepMUSIC: Multiple Signal Classification via Deep Learning", "abstract": "This letter introduces a deep learning (DL) framework for\ndirection-of-arrival (DOA) estimation. Previous works in DL context mostly\nconsider a single or two target scenario which is a strong limitation in\npractice. Hence, in this work, we propose a DL framework for multiple signal\nclassification (DeepMUSIC). We design multiple deep convolutional neural\nnetworks (CNNs), each of which is dedicated to a subregion of the angular\nspectrum. In particular, each CNN is fed with the array covariance matrix and\nit learns the MUSIC spectra of the corresponding angular subregion. We have\nshown, through simulations, that the proposed DeepMUSIC framework has superior\nestimation accuracy and exhibits less computational complexity in comparison\nwith both DL and non-DL based techniques.", "published": "2019-12-09 20:18:59", "link": "http://arxiv.org/abs/1912.04357v3", "categories": ["eess.SP", "cs.LG", "eess.AS"], "primary_category": "eess.SP"}
