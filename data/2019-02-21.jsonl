{"title": "Pretrained language model transfer on neural named entity recognition in\n  Indonesian conversational texts", "abstract": "Named entity recognition (NER) is an important task in NLP, which is all the\nmore challenging in conversational domain with their noisy facets. Moreover,\nconversational texts are often available in limited amount, making supervised\ntasks infeasible. To learn from small data, strong inductive biases are\nrequired. Previous work relied on hand-crafted features to encode these biases\nuntil transfer learning emerges. Here, we explore a transfer learning method,\nnamely language model pretraining, on NER task in Indonesian conversational\ntexts. We utilize large unlabeled data (generic domain) to be transferred to\nconversational texts, enabling supervised training on limited in-domain data.\nWe report two transfer learning variants, namely supervised model fine-tuning\nand unsupervised pretrained LM fine-tuning. Our experiments show that both\nvariants outperform baseline neural models when trained on small data (100\nsentences), yielding an absolute improvement of 32 points of test F1 score.\nFurthermore, we find that the pretrained LM encodes part-of-speech information\nwhich is a strong predictor for NER.", "published": "2019-02-21 09:53:04", "link": "http://arxiv.org/abs/1902.07938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Short Text Classification with Knowledge Powered Attention", "abstract": "Short text classification is one of important tasks in Natural Language\nProcessing (NLP). Unlike paragraphs or documents, short texts are more\nambiguous since they have not enough contextual information, which poses a\ngreat challenge for classification. In this paper, we retrieve knowledge from\nexternal knowledge source to enhance the semantic representation of short\ntexts. We take conceptual information as a kind of knowledge and incorporate it\ninto deep neural networks. For the purpose of measuring the importance of\nknowledge, we introduce attention mechanisms and propose deep Short Text\nClassification with Knowledge powered Attention (STCKA). We utilize Concept\ntowards Short Text (C- ST) attention and Concept towards Concept Set (C-CS)\nattention to acquire the weight of concepts from two aspects. And we classify a\nshort text with the help of conceptual information. Unlike traditional\napproaches, our model acts like a human being who has intrinsic ability to make\ndecisions based on observation (i.e., training data for machines) and pays more\nattention to important knowledge. We also conduct extensive experiments on four\npublic datasets for different tasks. The experimental results and case studies\nshow that our model outperforms the state-of-the-art methods, justifying the\neffectiveness of knowledge powered attention.", "published": "2019-02-21 13:50:56", "link": "http://arxiv.org/abs/1902.08050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Development of a classifiers/quantifiers dictionary towards\n  French-Japanese MT", "abstract": "Although classifiers/quantifiers (CQs) expressions appear frequently in\neveryday communications or written documents, they are described neither in\nclassical bilingual paper dictionaries , nor in machine-readable dictionaries.\nThe paper describes a CQs dictionary, edited from the corpus we have annotated,\nand its usage in the framework of French-Japanese machine translation (MT). CQs\ntreatment in MT often causes problems of lexical ambiguity, polylexical phrase\nrecognition difficulties in analysis and doubtful output in\ntransfer-generation, in particular for distant languages pairs like French and\nJapanese. Our basic treatment of CQs is to annotate the corpus by UNL-UWs\n(Universal Networking Language-Universal words) 1 , and then to produce a\nbilingual or multilingual dictionary of CQs, based on synonymy through identity\nof UWs.", "published": "2019-02-21 14:19:00", "link": "http://arxiv.org/abs/1902.08061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting ConceptNet Path Quality Using Crowdsourced Assessments of\n  Naturalness", "abstract": "In many applications, it is important to characterize the way in which two\nconcepts are semantically related. Knowledge graphs such as ConceptNet provide\na rich source of information for such characterizations by encoding relations\nbetween concepts as edges in a graph. When two concepts are not directly\nconnected by an edge, their relationship can still be described in terms of the\npaths that connect them. Unfortunately, many of these paths are uninformative\nand noisy, which means that the success of applications that use such path\nfeatures crucially relies on their ability to select high-quality paths. In\nexisting applications, this path selection process is based on relatively\nsimple heuristics. In this paper we instead propose to learn to predict path\nquality from crowdsourced human assessments. Since we are interested in a\ngeneric task-independent notion of quality, we simply ask human participants to\nrank paths according to their subjective assessment of the paths' naturalness,\nwithout attempting to define naturalness or steering the participants towards\nparticular indicators of quality. We show that a neural network model trained\non these assessments is able to predict human judgments on unseen paths with\nnear optimal performance. Most notably, we find that the resulting path\nselection method is substantially better than the current heuristic approaches\nat identifying meaningful paths.", "published": "2019-02-21 01:12:07", "link": "http://arxiv.org/abs/1902.07831v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Speaker Embedding Learning with Multi-Level Pooling for\n  Text-Independent Speaker Verification", "abstract": "This paper aims to improve the widely used deep speaker embedding x-vector\nmodel. We propose the following improvements: (1) a hybrid neural network\nstructure using both time delay neural network (TDNN) and long short-term\nmemory neural networks (LSTM) to generate complementary speaker information at\ndifferent levels; (2) a multi-level pooling strategy to collect speaker\ninformation from both TDNN and LSTM layers; (3) a regularization scheme on the\nspeaker embedding extraction layer to make the extracted embeddings suitable\nfor the following fusion step. The synergy of these improvements are shown on\nthe NIST SRE 2016 eval test (with a 19% EER reduction) and SRE 2018 dev test\n(with a 9% EER reduction), as well as more than 10% DCF scores reduction on\nthese two test sets over the x-vector baseline.", "published": "2019-02-21 00:36:24", "link": "http://arxiv.org/abs/1902.07821v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ntuer at SemEval-2019 Task 3: Emotion Classification with Word and\n  Sentence Representations in RCNN", "abstract": "In this paper we present our model on the task of emotion detection in\ntextual conversations in SemEval-2019. Our model extends the Recurrent\nConvolutional Neural Network (RCNN) by using external fine-tuned word\nrepresentations and DeepMoji sentence representations. We also explored several\nother competitive pre-trained word and sentence representations including ELMo,\nBERT and InferSent but found inferior performance. In addition, we conducted\nextensive sensitivity analysis, which empirically shows that our model is\nrelatively robust to hyper-parameters. Our model requires no handcrafted\nfeatures or emotion lexicons but achieved good performance with a micro-F1\nscore of 0.7463.", "published": "2019-02-21 05:16:45", "link": "http://arxiv.org/abs/1902.07867v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Visually Grounded Sub-Word Speech Unit Discovery", "abstract": "In this paper, we investigate the manner in which interpretable sub-word\nspeech units emerge within a convolutional neural network model trained to\nassociate raw speech waveforms with semantically related natural image scenes.\nWe show how diphone boundaries can be superficially extracted from the\nactivation patterns of intermediate layers of the model, suggesting that the\nmodel may be leveraging these events for the purpose of word recognition. We\npresent a series of experiments investigating the information encoded by these\nevents.", "published": "2019-02-21 19:00:30", "link": "http://arxiv.org/abs/1902.08213v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Incremental Transfer Learning in Two-pass Information Bottleneck based\n  Speaker Diarization System for Meetings", "abstract": "The two-pass information bottleneck (TPIB) based speaker diarization system\noperates independently on different conversational recordings. TPIB system does\nnot consider previously learned speaker discriminative information while\ndiarizing new conversations. Hence, the real time factor (RTF) of TPIB system\nis high owing to the training time required for the artificial neural network\n(ANN). This paper attempts to improve the RTF of the TPIB system using an\nincremental transfer learning approach where the parameters learned by the ANN\nfrom other conversations are updated using current conversation rather than\nlearning parameters from scratch. This reduces the RTF significantly. The\neffectiveness of the proposed approach compared to the baseline IB and the TPIB\nsystems is demonstrated on standard NIST and AMI conversational meeting\ndatasets. With a minor degradation in performance, the proposed system shows a\nsignificant improvement of 33.07% and 24.45% in RTF with respect to TPIB system\non the NIST RT-04Eval and AMI-1 datasets, respectively.", "published": "2019-02-21 13:55:51", "link": "http://arxiv.org/abs/1902.08051v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "All-neural online source separation, counting, and diarization for\n  meeting analysis", "abstract": "Automatic meeting analysis comprises the tasks of speaker counting, speaker\ndiarization, and the separation of overlapped speech, followed by automatic\nspeech recognition. This all has to be carried out on arbitrarily long sessions\nand, ideally, in an online or block-online manner. While significant progress\nhas been made on individual tasks, this paper presents for the first time an\nall-neural approach to simultaneous speaker counting, diarization and source\nseparation. The NN-based estimator operates in a block-online fashion and\ntracks speakers even if they remain silent for a number of time blocks, thus\nlearning a stable output order for the separated sources. The neural network is\nrecurrent over time as well as over the number of sources. The simulation\nexperiments show that state of the art separation performance is achieved,\nwhile at the same time delivering good diarization and source counting results.\nIt even generalizes well to an unseen large number of blocks.", "published": "2019-02-21 06:32:21", "link": "http://arxiv.org/abs/1902.07881v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The NIGENS General Sound Events Database", "abstract": "Computational auditory scene analysis is gaining interest in the last years.\nTrailing behind the more mature field of speech recognition, it is particularly\ngeneral sound event detection that is attracting increasing attention. Crucial\nfor training and testing reasonable models is having available enough suitable\ndata -- until recently, general sound event databases were hardly found. We\nrelease and present a database with 714 wav files containing isolated high\nquality sound events of 14 different types, plus 303 `general' wav files of\nanything else but these 14 types. All sound events are strongly labeled with\nperceptual on- and offset times, paying attention to omitting in-between\nsilences. The amount of isolated sound events, the quality of annotations, and\nthe particular general sound class distinguish NIGENS from other databases.", "published": "2019-02-21 23:51:59", "link": "http://arxiv.org/abs/1902.08314v4", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
