{"title": "End-to-end Story Plot Generator", "abstract": "Story plots, while short, carry most of the essential information of a full\nstory that may contain tens of thousands of words. We study the problem of\nautomatic generation of story plots, which includes story premise, character\ndescriptions, plot outlines, etc. To generate a single engaging plot, existing\nplot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands\nof calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot,\nwhich is costly and takes at least several minutes. Moreover, the hard-wired\nnature of the method makes the pipeline non-differentiable, blocking fast\nspecialization and personalization of the plot generator. In this paper, we\npropose three models, $\\texttt{OpenPlot}$, $\\texttt{E2EPlot}$ and\n$\\texttt{RLPlot}$, to address these challenges. $\\texttt{OpenPlot}$ replaces\nexpensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful\nprompt designs, which leads to inexpensive generation of high-quality training\ndatasets of story plots. We then train an end-to-end story plot generator,\n$\\texttt{E2EPlot}$, by supervised fine-tuning (SFT) using approximately 13000\nstory plots generated by $\\texttt{OpenPlot}$. $\\texttt{E2EPlot}$ generates\nstory plots of comparable quality to $\\texttt{OpenPlot}$, and is > 10$\\times$\nfaster (1k tokens in only 30 seconds on average). Finally, we obtain\n$\\texttt{RLPlot}$ that is further fine-tuned with RLHF on several different\nreward models for different aspects of story quality, which yields 60.0$\\%$\nwinning rate against $\\texttt{E2EPlot}$ along the aspect of suspense and\nsurprise.", "published": "2023-10-13 00:49:59", "link": "http://arxiv.org/abs/2310.08796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding AMR Parsing with Reverse Graph Linearization", "abstract": "Abstract Meaning Representation (AMR) parsing aims to extract an abstract\nsemantic graph from a given sentence. The sequence-to-sequence approaches,\nwhich linearize the semantic graph into a sequence of nodes and edges and\ngenerate the linearized graph directly, have achieved good performance.\nHowever, we observed that these approaches suffer from structure loss\naccumulation during the decoding process, leading to a much lower F1-score for\nnodes and edges decoded later compared to those decoded earlier. To address\nthis issue, we propose a novel Reverse Graph Linearization (RGL) enhanced\nframework. RGL defines both default and reverse linearization orders of an AMR\ngraph, where most structures at the back part of the default order appear at\nthe front part of the reversed order and vice versa. RGL incorporates the\nreversed linearization to the original AMR parser through a two-pass\nself-distillation mechanism, which guides the model when generating the default\nlinearizations. Our analysis shows that our proposed method significantly\nmitigates the problem of structure loss accumulation, outperforming the\npreviously best AMR parsing model by 0.8 and 0.5 Smatch scores on the AMR 2.0\nand AMR 3.0 dataset, respectively. The code are available at\nhttps://github.com/pkunlp-icler/AMR_reverse_graph_linearization.", "published": "2023-10-13 05:03:13", "link": "http://arxiv.org/abs/2310.08860v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue\n  System", "abstract": "Developing an efficient retriever to retrieve knowledge from a large-scale\nknowledge base (KB) is critical for task-oriented dialogue systems to\neffectively handle localized and specialized tasks. However, widely used\ngenerative models such as T5 and ChatGPT often struggle to differentiate subtle\ndifferences among the retrieved KB records when generating responses, resulting\nin suboptimal quality of generated responses. In this paper, we propose the\napplication of maximal marginal likelihood to train a perceptive retriever by\nutilizing signals from response generation for supervision. In addition, our\napproach goes beyond considering solely retrieved entities and incorporates\nvarious meta knowledge to guide the generator, thus improving the utilization\nof knowledge. We evaluate our approach on three task-oriented dialogue datasets\nusing T5 and ChatGPT as the backbone models. The results demonstrate that when\ncombined with meta knowledge, the response generator can effectively leverage\nhigh-quality knowledge records from the retriever and enhance the quality of\ngenerated responses. The codes and models of this paper are available at\nhttps://github.com/shenwzh3/MK-TOD.", "published": "2023-10-13 06:03:47", "link": "http://arxiv.org/abs/2310.08877v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InstructTODS: Large Language Models for End-to-End Task-Oriented\n  Dialogue Systems", "abstract": "Large language models (LLMs) have been used for diverse tasks in natural\nlanguage processing (NLP), yet remain under-explored for task-oriented dialogue\nsystems (TODS), especially for end-to-end TODS. We present InstructTODS, a\nnovel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue\nsystems that can adapt to diverse domains without fine-tuning. By leveraging\nLLMs, InstructTODS generates a proxy belief state that seamlessly translates\nuser intentions into dynamic queries for efficient interaction with any KB. Our\nextensive experiments demonstrate that InstructTODS achieves comparable\nperformance to fully fine-tuned TODS in guiding dialogues to successful\ncompletion without prior knowledge or task-specific data. Furthermore, a\nrigorous human evaluation of end-to-end TODS shows that InstructTODS produces\ndialogue responses that notably outperform both the gold responses and the\nstate-of-the-art TODS in terms of helpfulness, informativeness, and humanness.\nMoreover, the effectiveness of LLMs in TODS is further supported by our\ncomprehensive evaluations on TODS subtasks: dialogue state tracking, intent\nclassification, and response generation. Code and implementations could be\nfound here https://github.com/WillyHC22/InstructTODS/", "published": "2023-10-13 06:36:26", "link": "http://arxiv.org/abs/2310.08885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP", "abstract": "With the rapid development of neural network applications in NLP, model\nrobustness problem is gaining more attention. Different from computer vision,\nthe discrete nature of texts makes it more challenging to explore robustness in\nNLP. Therefore, in this paper, we aim to connect discrete perturbations with\ncontinuous perturbations, therefore we can use such connections as a bridge to\nhelp understand discrete perturbations in NLP models. Specifically, we first\nexplore how to connect and measure the correlation between discrete\nperturbations and continuous perturbations. Then we design a regression task as\na PerturbScore to learn the correlation automatically. Through experimental\nresults, we find that we can build a connection between discrete and continuous\nperturbations and use the proposed PerturbScore to learn such correlation,\nsurpassing previous methods used in discrete perturbation measuring. Further,\nthe proposed PerturbScore can be well generalized to different datasets,\nperturbation methods, indicating that we can use it as a powerful tool to study\nmodel robustness in NLP.", "published": "2023-10-13 06:50:15", "link": "http://arxiv.org/abs/2310.08889v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploration with Principles for Diverse AI Supervision", "abstract": "Training large transformers using next-token prediction has given rise to\ngroundbreaking advancements in AI. While this generative AI approach has\nproduced impressive results, it heavily leans on human supervision. Even\nstate-of-the-art AI models like ChatGPT depend on fine-tuning through human\ndemonstrations, demanding extensive human input and domain expertise. This\nstrong reliance on human oversight poses a significant hurdle to the\nadvancement of AI innovation. To address this limitation, we propose a novel\nparadigm termed Exploratory AI (EAI) aimed at autonomously generating\nhigh-quality training data. Drawing inspiration from unsupervised reinforcement\nlearning (RL) pretraining, EAI achieves exploration within the natural language\nspace. We accomplish this by harnessing large language models to assess the\nnovelty of generated content. Our approach employs two key components: an actor\nthat generates novel content following exploration principles and a critic that\nevaluates the generated content, offering critiques to guide the actor.\nEmpirical evaluations demonstrate that EAI significantly boosts model\nperformance on complex reasoning tasks, addressing the limitations of\nhuman-intensive supervision.", "published": "2023-10-13 07:03:39", "link": "http://arxiv.org/abs/2310.08899v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeqXGPT: Sentence-Level AI-Generated Text Detection", "abstract": "Widely applied large language models (LLMs) can generate human-like content,\nraising concerns about the abuse of LLMs. Therefore, it is important to build\nstrong AI-generated text (AIGT) detectors. Current works only consider\ndocument-level AIGT detection, therefore, in this paper, we first introduce a\nsentence-level detection challenge by synthesizing a dataset that contains\ndocuments that are polished with LLMs, that is, the documents contain sentences\nwritten by humans and sentences modified by LLMs. Then we propose\n\\textbf{Seq}uence \\textbf{X} (Check) \\textbf{GPT}, a novel method that utilizes\nlog probability lists from white-box LLMs as features for sentence-level AIGT\ndetection. These features are composed like \\textit{waves} in speech processing\nand cannot be studied by LLMs. Therefore, we build SeqXGPT based on convolution\nand self-attention networks. We test it in both sentence and document-level\ndetection challenges. Experimental results show that previous methods struggle\nin solving sentence-level AIGT detection, while our method not only\nsignificantly surpasses baseline methods in both sentence and document-level\ndetection challenges but also exhibits strong generalization capabilities.", "published": "2023-10-13 07:18:53", "link": "http://arxiv.org/abs/2310.08903v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human-in-the-loop Machine Translation with Large Language Model", "abstract": "The large language model (LLM) has garnered significant attention due to its\nin-context learning mechanisms and emergent capabilities. The research\ncommunity has conducted several pilot studies to apply LLMs to machine\ntranslation tasks and evaluate their performance from diverse perspectives.\nHowever, previous research has primarily focused on the LLM itself and has not\nexplored human intervention in the inference process of LLM. The\ncharacteristics of LLM, such as in-context learning and prompt engineering,\nclosely mirror human cognitive abilities in language tasks, offering an\nintuitive solution for human-in-the-loop generation. In this study, we propose\na human-in-the-loop pipeline that guides LLMs to produce customized outputs\nwith revision instructions. The pipeline initiates by prompting the LLM to\nproduce a draft translation, followed by the utilization of automatic retrieval\nor human feedback as supervision signals to enhance the LLM's translation\nthrough in-context learning. The human-machine interactions generated in this\npipeline are also stored in an external database to expand the in-context\nretrieval database, enabling us to leverage human supervision in an offline\nsetting. We evaluate the proposed pipeline using GPT-3.5-turbo API on five\ndomain-specific benchmarks for German-English translation. The results\ndemonstrate the effectiveness of the pipeline in tailoring in-domain\ntranslations and improving translation performance compared to direct\ntranslation. Additionally, we discuss the results from the following\nperspectives: 1) the effectiveness of different in-context retrieval methods;\n2) the construction of a retrieval database under low-resource scenarios; 3)\nthe observed domains differences; 4) the quantitative analysis of linguistic\nstatistics; and 5) the qualitative analysis of translation cases. The code and\ndata are available at https://github.com/NLP2CT/HIL-MT/.", "published": "2023-10-13 07:30:27", "link": "http://arxiv.org/abs/2310.08908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Informative Few-Shot Prompt with Maximum Information Gain for\n  In-Context Learning", "abstract": "Large Language models (LLMs) possess the capability to engage In-context\nLearning (ICL) by leveraging a few demonstrations pertaining to a new\ndownstream task as conditions. However, this particular learning paradigm\nsuffers from high instability stemming from substantial variances induced by\nfactors such as the input distribution of selected examples, their ordering,\nand prompt formats. In this work, we demonstrate that even when all these\nfactors are held constant, the random selection of examples still results in\nhigh variance. Consequently, we aim to explore the informative ability of data\nexamples by quantifying the Information Gain (IG) obtained in prediction after\nobserving a given example candidate. Then we propose to sample those with\nmaximum IG. Additionally, we identify the presence of template bias, which can\nlead to unfair evaluations of IG during the sampling process. To mitigate this\nbias, we introduce Calibration Before Sampling strategy. The experimental\nresults illustrate that our proposed method can yield an average relative\nimprovement of 14.3% across six classification tasks using three LLMs.", "published": "2023-10-13 07:49:11", "link": "http://arxiv.org/abs/2310.08923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-level Adaptive Contrastive Learning for Knowledge Internalization\n  in Dialogue Generation", "abstract": "Knowledge-grounded dialogue generation aims to mitigate the issue of text\ndegeneration by incorporating external knowledge to supplement the context.\nHowever, the model often fails to internalize this information into responses\nin a human-like manner. Instead, it simply inserts segments of the provided\nknowledge into generic responses. As a result, the generated responses tend to\nbe tedious, incoherent, and in lack of interactivity which means the\ndegeneration problem is still unsolved. In this work, we first find that such\ncopying-style degeneration is primarily due to the weak likelihood objective,\nwhich allows the model to \"cheat\" the objective by merely duplicating knowledge\nsegments in a superficial pattern matching based on overlap. To overcome this\nchallenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL)\nframework that dynamically samples negative examples and subsequently penalizes\ndegeneration behaviors at both the token-level and sequence-level. Extensive\nexperiments on the WoW dataset demonstrate the effectiveness of our approach\nacross various pre-trained models.", "published": "2023-10-13 08:16:27", "link": "http://arxiv.org/abs/2310.08943v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Textual Analysis of ICALEPCS and IPAC Conference Proceedings: Revealing\n  Research Trends, Topics, and Collaborations for Future Insights and Advanced\n  Search", "abstract": "In this paper, we show a textual analysis of past ICALEPCS and IPAC\nconference proceedings to gain insights into the research trends and topics\ndiscussed in the field. We use natural language processing techniques to\nextract meaningful information from the abstracts and papers of past conference\nproceedings. We extract topics to visualize and identify trends, analyze their\nevolution to identify emerging research directions, and highlight interesting\npublications based solely on their content with an analysis of their network.\nAdditionally, we will provide an advanced search tool to better search the\nexisting papers to prevent duplication and easier reference findings. Our\nanalysis provides a comprehensive overview of the research landscape in the\nfield and helps researchers and practitioners to better understand the\nstate-of-the-art and identify areas for future research.", "published": "2023-10-13 08:55:19", "link": "http://arxiv.org/abs/2310.08954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark", "abstract": "Recent advancements in reference-free learned metrics for open-domain\ndialogue evaluation have been driven by the progress in pre-trained language\nmodels and the availability of dialogue data with high-quality human\nannotations. However, current studies predominantly concentrate on English\ndialogues, and the generalization of these metrics to other languages has not\nbeen fully examined. This is largely due to the absence of a multilingual\ndialogue evaluation benchmark. To address the issue, we introduce xDial-Eval,\nbuilt on top of open-source English dialogue evaluation datasets. xDial-Eval\nincludes 12 turn-level and 6 dialogue-level English datasets, comprising 14930\nannotated turns and 8691 annotated dialogues respectively. The English dialogue\ndata are extended to nine other languages with commercial machine translation\nsystems. On xDial-Eval, we conduct comprehensive analyses of previous\nBERT-based metrics and the recently-emerged large language models. Lastly, we\nestablish strong self-supervised and multilingual baselines. In terms of\naverage Pearson correlations over all datasets and languages, the best baseline\noutperforms OpenAI's ChatGPT by absolute improvements of 6.5% and 4.6% at the\nturn and dialogue levels respectively, albeit with much fewer parameters. The\ndata and code are publicly available at https://github.com/e0397123/xDial-Eval.", "published": "2023-10-13 09:07:13", "link": "http://arxiv.org/abs/2310.08958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Example-Based NMT with Multi-Levenshtein Transformers", "abstract": "Retrieval-Augmented Machine Translation (RAMT) is attracting growing\nattention. This is because RAMT not only improves translation metrics, but is\nalso assumed to implement some form of domain adaptation. In this contribution,\nwe study another salient trait of RAMT, its ability to make translation\ndecisions more transparent by allowing users to go back to examples that\ncontributed to these decisions.\n  For this, we propose a novel architecture aiming to increase this\ntransparency. This model adapts a retrieval-augmented version of the\nLevenshtein Transformer and makes it amenable to simultaneously edit multiple\nfuzzy matches found in memory. We discuss how to perform training and inference\nin this model, based on multi-way alignment algorithms and imitation learning.\nOur experiments show that editing several examples positively impacts\ntranslation scores, notably increasing the number of target spans that are\ncopied from existing instances.", "published": "2023-10-13 09:18:57", "link": "http://arxiv.org/abs/2310.08967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dont Add, dont Miss: Effective Content Preserving Generation from\n  Pre-Selected Text Spans", "abstract": "The recently introduced Controlled Text Reduction (CTR) task isolates the\ntext generation step within typical summarization-style tasks. It does so by\nchallenging models to generate coherent text conforming to pre-selected content\nwithin the input text (``highlights''). This framing enables increased\nmodularity in summarization-like tasks, allowing to couple a single CTR model\nwith various content-selection setups and modules. However, there are currently\nno reliable CTR models, while the performance of the existing baseline for the\ntask is mediocre, falling short of practical utility. Here, we address this gap\nby introducing a high-quality, open-source CTR model that tackles two prior key\nlimitations: inadequate enforcement of the content-preservation constraint, and\nsuboptimal silver training data. Addressing these, we amplify the\ncontent-preservation constraint in both training, via RL, and inference, via a\ncontrolled decoding strategy. Further, we substantially improve the silver\ntraining data quality via GPT-4 distillation. Overall, pairing the distilled\ndataset with the highlight-adherence strategies yields marked gains over the\ncurrent baseline, of up to 30 ROUGE-L points, providing a reliable CTR model\nfor downstream use.", "published": "2023-10-13 11:28:02", "link": "http://arxiv.org/abs/2310.09017v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large\n  Language Model", "abstract": "Integrating large language models (LLMs) into healthcare holds great\npotential but faces challenges. Pre-training LLMs from scratch for domains like\nmedicine is resource-heavy and often unfeasible. On the other hand, sole\nreliance on Supervised Fine-tuning (SFT) can result in overconfident\npredictions and may not tap into domain-specific insights. In response, we\npresent a multi-stage training method combining Domain-specific Continued\nPre-training (DCPT), SFT, and Direct Preference Optimization (DPO). In\naddition, we publish a 3Gb Chinese Medicine (ChiMed) dataset, encompassing\nmedical question answering, plain texts, knowledge graphs, and dialogues,\nsegmented into three training stages. The medical LLM trained with our\npipeline, Qilin-Med, shows substantial performance improvement. In the CPT and\nSFT phases, Qilin-Med achieved 38.4% and 40.0% accuracy on the CMExam test set,\nrespectively. It outperformed the basemodel Baichuan-7B (accuracy: 33.5%), by\n7.5%. In the DPO phase, it scored 16.66 in BLEU-1 and 27.44 in ROUGE-1 on the\nHuatuo-26M test set, bringing further improvement to the SFT phase (12.69 in\nBLEU-1 and 24.21 in ROUGE-1). Additionally, we have further enhanced the\nmodel's performance through the Retrieval Augmented Generation (RAG) approach.\nExperiments demonstrate that Qilin-Med-RAG achieves an accuracy rate of 42.8%\non CMExam. These results highlight the contribution of our novel training\napproach in building LLMs for medical applications.", "published": "2023-10-13 13:17:03", "link": "http://arxiv.org/abs/2310.09089v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for\n  Chinese Spelling Check", "abstract": "In recent years, Chinese Spelling Check (CSC) has been greatly improved by\ndesigning task-specific pre-training methods or introducing auxiliary tasks,\nwhich mostly solve this task in an end-to-end fashion. In this paper, we\npropose to decompose the CSC workflow into detection, reasoning, and searching\nsubtasks so that the rich external knowledge about the Chinese language can be\nleveraged more directly and efficiently. Specifically, we design a\nplug-and-play detection-and-reasoning module that is compatible with existing\nSOTA non-autoregressive CSC models to further boost their performance. We find\nthat the detection-and-reasoning module trained for one model can also benefit\nother models. We also study the primary interpretability provided by the task\ndecomposition. Extensive experiments and detailed analyses demonstrate the\neffectiveness and competitiveness of the proposed module.", "published": "2023-10-13 14:03:01", "link": "http://arxiv.org/abs/2310.09119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PuoBERTa: Training and evaluation of a curated language model for\n  Setswana", "abstract": "Natural language processing (NLP) has made significant progress for\nwell-resourced languages such as English but lagged behind for low-resource\nlanguages like Setswana. This paper addresses this gap by presenting PuoBERTa,\na customised masked language model trained specifically for Setswana. We cover\nhow we collected, curated, and prepared diverse monolingual texts to generate a\nhigh-quality corpus for PuoBERTa's training. Building upon previous efforts in\ncreating monolingual resources for Setswana, we evaluated PuoBERTa across\nseveral NLP tasks, including part-of-speech (POS) tagging, named entity\nrecognition (NER), and news categorisation. Additionally, we introduced a new\nSetswana news categorisation dataset and provided the initial benchmarks using\nPuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP\ncapabilities for understudied languages like Setswana and paves the way for\nfuture research directions.", "published": "2023-10-13 14:33:02", "link": "http://arxiv.org/abs/2310.09141v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BibRank: Automatic Keyphrase Extraction Platform Using~Metadata", "abstract": "Automatic Keyphrase Extraction involves identifying essential phrases in a\ndocument. These keyphrases are crucial in various tasks such as document\nclassification, clustering, recommendation, indexing, searching, summarization,\nand text simplification. This paper introduces a platform that integrates\nkeyphrase datasets and facilitates the evaluation of keyphrase extraction\nalgorithms. The platform includes BibRank, an automatic keyphrase extraction\nalgorithm that leverages a rich dataset obtained by parsing bibliographic data\nin BibTeX format. BibRank combines innovative weighting techniques with\npositional, statistical, and word co-occurrence information to extract\nkeyphrases from documents. The platform proves valuable for researchers and\ndevelopers seeking to enhance their keyphrase extraction algorithms and advance\nthe field of natural language processing.", "published": "2023-10-13 14:44:34", "link": "http://arxiv.org/abs/2310.09151v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing a Natural Language Understanding Model to Characterize Cable\n  News Bias", "abstract": "Media bias has been extensively studied by both social and computational\nsciences. However, current work still has a large reliance on human input and\nsubjective assessment to label biases. This is especially true for cable news\nresearch. To address these issues, we develop an unsupervised machine learning\nmethod to characterize the bias of cable news programs without any human input.\nThis method relies on the analysis of what topics are mentioned through Named\nEntity Recognition and how those topics are discussed through Stance Analysis\nin order to cluster programs with similar biases together. Applying our method\nto 2020 cable news transcripts, we find that program clusters are consistent\nover time and roughly correspond to the cable news network of the program. This\nmethod reveals the potential for future tools to objectively assess media bias\nand characterize unfamiliar media environments.", "published": "2023-10-13 15:01:17", "link": "http://arxiv.org/abs/2310.09166v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through\n  Active Exploration", "abstract": "Instruction-tuning can be substantially optimized through enhanced diversity,\nresulting in models capable of handling a broader spectrum of tasks. However,\nexisting data employed for such tuning often exhibit an inadequate coverage of\nindividual domains, limiting the scope for nuanced comprehension and\ninteractions within these areas. To address this deficiency, we propose\nExplore-Instruct, a novel approach to enhance the data coverage to be used in\ndomain-specific instruction-tuning through active exploration via Large\nLanguage Models (LLMs). Built upon representative domain use cases,\nExplore-Instruct explores a multitude of variations or possibilities by\nimplementing a search algorithm to obtain diversified and domain-focused\ninstruction-tuning data. Our data-centric analysis validates the effectiveness\nof this proposed approach in improving domain-specific instruction coverage.\nMoreover, our model's performance demonstrates considerable advancements over\nmultiple baselines, including those utilizing domain-specific data enhancement.\nOur findings offer a promising opportunity to improve instruction coverage,\nespecially in domain-specific contexts, thereby advancing the development of\nadaptable language models. Our code, model weights, and data are public at\n\\url{https://github.com/fanqiwan/Explore-Instruct}.", "published": "2023-10-13 15:03:15", "link": "http://arxiv.org/abs/2310.09168v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models\n  for Sentiment Analysis of Bangla Social Media Posts", "abstract": "Bangla is the 7th most widely spoken language globally, with a staggering 234\nmillion native speakers primarily hailing from India and Bangladesh. This\nmorphologically rich language boasts a rich literary tradition, encompassing\ndiverse dialects and language-specific challenges. Despite its linguistic\nrichness and history, Bangla remains categorized as a low-resource language\nwithin the natural language processing (NLP) and speech community. This paper\npresents our submission to Task 2 (Sentiment Analysis of Bangla Social Media\nPosts) of the BLP Workshop. We experiment with various Transformer-based\narchitectures to solve this task. Our quantitative results show that transfer\nlearning really helps in better learning of the models in this low-resource\nlanguage scenario. This becomes evident when we further finetune a model which\nhas already been finetuned on twitter data for sentiment analysis task and that\nfinetuned model performs the best among all other models. We also perform a\ndetailed error analysis where we find some instances where ground truth labels\nneed to be relooked at. We obtain a micro-F1 of 67.02\\% on the test set and our\nperformance in this shared task is ranked at 21 in the leaderboard.", "published": "2023-10-13 16:46:38", "link": "http://arxiv.org/abs/2310.09238v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model\n  Collaboration", "abstract": "Legal Judgment Prediction (LJP) has become an increasingly crucial task in\nLegal AI, i.e., predicting the judgment of the case in terms of case fact\ndescription. Precedents are the previous legal cases with similar facts, which\nare the basis for the judgment of the subsequent case in national legal\nsystems. Thus, it is worthwhile to explore the utilization of precedents in the\nLJP. Recent advances in deep learning have enabled a variety of techniques to\nbe used to solve the LJP task. These can be broken down into two categories:\nlarge language models (LLMs) and domain-specific models. LLMs are capable of\ninterpreting and generating complex natural language, while domain models are\nefficient in learning task-specific information. In this paper, we propose the\nprecedent-enhanced LJP framework (PLJP), a system that leverages the strength\nof both LLM and domain models in the context of precedents. Specifically, the\ndomain models are designed to provide candidate labels and find the proper\nprecedents efficiently, and the large models will make the final prediction\nwith an in-context precedents comprehension. Experiments on the real-world\ndataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a\npromising direction for LLM and domain-model collaboration that can be\ngeneralized to other vertical domains.", "published": "2023-10-13 16:47:20", "link": "http://arxiv.org/abs/2310.09241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Political claim identification and categorization in a multilingual\n  setting: First experiments", "abstract": "The identification and classification of political claims is an important\nstep in the analysis of political newspaper reports; however, resources for\nthis task are few and far between. This paper explores different strategies for\nthe cross-lingual projection of political claims analysis. We conduct\nexperiments on a German dataset, DebateNet2.0, covering the policy debate\nsparked by the 2015 refugee crisis. Our evaluation involves two tasks (claim\nidentification and categorization), three languages (German, English, and\nFrench) and two methods (machine translation -- the best method in our\nexperiments -- and multilingual embeddings).", "published": "2023-10-13 17:13:00", "link": "http://arxiv.org/abs/2310.09256v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Computational Approach to Style in American Poetry", "abstract": "We develop a quantitative method to assess the style of American poems and to\nvisualize a collection of poems in relation to one another. Qualitative poetry\ncriticism helped guide our development of metrics that analyze various\northographic, syntactic, and phonemic features. These features are used to\ndiscover comprehensive stylistic information from a poem's multi-layered latent\nstructure, and to compute distances between poems in this space. Visualizations\nprovide ready access to the analytical components. We demonstrate our method on\nseveral collections of poetry, showing that it better delineates poetry style\nthan the traditional word-occurrence features that are used in typical text\nanalysis algorithms. Our method has potential applications to academic research\nof texts, to research of the intuitive personal response to poetry, and to\nmaking recommendations to readers based on their favorite poems.", "published": "2023-10-13 18:49:14", "link": "http://arxiv.org/abs/2310.09357v1", "categories": ["cs.CL", "J.5; I.2.7"], "primary_category": "cs.CL"}
{"title": "\"Im not Racist but...\": Discovering Bias in the Internal Knowledge of\n  Large Language Models", "abstract": "Large language models (LLMs) have garnered significant attention for their\nremarkable performance in a continuously expanding set of natural language\nprocessing tasks. However, these models have been shown to harbor inherent\nsocietal biases, or stereotypes, which can adversely affect their performance\nin their many downstream applications. In this paper, we introduce a novel,\npurely prompt-based approach to uncover hidden stereotypes within any arbitrary\nLLM. Our approach dynamically generates a knowledge representation of internal\nstereotypes, enabling the identification of biases encoded within the LLM's\ninternal knowledge. By illuminating the biases present in LLMs and offering a\nsystematic methodology for their analysis, our work contributes to advancing\ntransparency and promoting fairness in natural language processing systems.", "published": "2023-10-13 00:03:37", "link": "http://arxiv.org/abs/2310.08780v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Task-Agnostic Distillation Methods for\n  Compressing Transformer Language Models", "abstract": "Large language models have become a vital component in modern NLP, achieving\nstate of the art performance in a variety of tasks. However, they are often\ninefficient for real-world deployment due to their expensive inference costs.\nKnowledge distillation is a promising technique to improve their efficiency\nwhile retaining most of their effectiveness. In this paper, we reproduce,\ncompare and analyze several representative methods for task-agnostic\n(general-purpose) distillation of Transformer language models. Our target of\nstudy includes Output Distribution (OD) transfer, Hidden State (HS) transfer\nwith various layer mapping strategies, and Multi-Head Attention (MHA) transfer\nbased on MiniLMv2. Through our extensive experiments, we study the\neffectiveness of each method for various student architectures in both\nmonolingual (English) and multilingual settings. Overall, we show that MHA\ntransfer based on MiniLMv2 is generally the best option for distillation and\nexplain the potential reasons behind its success. Moreover, we show that HS\ntransfer remains as a competitive baseline, especially under a sophisticated\nlayer mapping strategy, while OD transfer consistently lags behind other\napproaches. Findings from this study helped us deploy efficient yet effective\nstudent models for latency-critical applications.", "published": "2023-10-13 01:00:15", "link": "http://arxiv.org/abs/2310.08797v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Source Planner for Personalized\n  Knowledge-grounded Dialogue", "abstract": "Open-domain dialogue system usually requires different sources of knowledge\nto generate more informative and evidential responses. However, existing\nknowledge-grounded dialogue systems either focus on a single knowledge source\nor overlook the dependency between multiple sources of knowledge, which may\nresult in generating inconsistent or even paradoxical responses. To incorporate\nmultiple knowledge sources and dependencies between them, we propose SAFARI, a\nnovel framework that leverages the exceptional capabilities of large language\nmodels (LLMs) in planning, understanding, and incorporating under both\nsupervised and unsupervised settings. Specifically, SAFARI decouples the\nknowledge grounding into multiple sources and response generation, which allows\neasy extension to various knowledge sources including the possibility of not\nusing any sources. To study the problem, we construct a personalized\nknowledge-grounded dialogue dataset \\textit{\\textbf{K}nowledge \\textbf{B}ehind\n\\textbf{P}ersona}~(\\textbf{KBP}), which is the first to consider the dependency\nbetween persona and implicit knowledge. Experimental results on the KBP dataset\ndemonstrate that the SAFARI framework can effectively produce\npersona-consistent and knowledge-enhanced responses.", "published": "2023-10-13 03:38:38", "link": "http://arxiv.org/abs/2310.08840v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Confidence-based Acquisition Model for Self-supervised Active Learning\n  and Label Correction", "abstract": "Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present CAMEL (Confidence-based Acquisition Model for Efficient\nself-supervised active Learning), a pool-based active learning framework\ntailored to sequential multi-output problems. CAMEL possesses two core\nfeatures: (1) it requires expert annotators to label only a fraction of a\nchosen sequence, and (2) it facilitates self-supervision for the remainder of\nthe sequence. By deploying a label correction mechanism, CAMEL can also be\nutilised for data cleaning. We evaluate CAMEL on two sequential tasks, with a\nspecial emphasis on dialogue belief tracking, a task plagued by the constraints\nof limited and noisy datasets. Our experiments demonstrate that CAMEL\nsignificantly outperforms the baselines in terms of efficiency. Furthermore,\nthe data corrections suggested by our method contribute to an overall\nimprovement in the quality of the resulting datasets.", "published": "2023-10-13 08:19:31", "link": "http://arxiv.org/abs/2310.08944v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question\n  Answering with Fine-tuned Large Language Models", "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions over large-scale knowledge bases (KBs), which can be summarized into\ntwo crucial steps: knowledge retrieval and semantic parsing. However, three\ncore challenges remain: inefficient knowledge retrieval, mistakes of retrieval\nadversely impacting semantic parsing, and the complexity of previous KBQA\nmethods. To tackle these challenges, we introduce ChatKBQA, a novel and simple\ngenerate-then-retrieve KBQA framework, which proposes first generating the\nlogical form with fine-tuned LLMs, then retrieving and replacing entities and\nrelations with an unsupervised retrieval method, to improve both generation and\nretrieval more directly. Experimental results show that ChatKBQA achieves new\nstate-of-the-art performance on standard KBQA datasets, WebQSP, and CWQ. This\nwork can also be regarded as a new paradigm for combining LLMs with knowledge\ngraphs (KGs) for interpretable and knowledge-required question answering. Our\ncode is publicly available.", "published": "2023-10-13 09:45:14", "link": "http://arxiv.org/abs/2310.08975v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MM-BigBench: Evaluating Multimodal Models on Multimodal Content\n  Comprehension Tasks", "abstract": "The popularity of multimodal large language models (MLLMs) has triggered a\nrecent surge in research efforts dedicated to evaluating these models.\nNevertheless, existing evaluation studies of MLLMs primarily focus on the\ncomprehension and reasoning of unimodal (vision) content, neglecting\nperformance evaluations in the domain of multimodal (vision-language) content\nunderstanding. Beyond multimodal reasoning, tasks related to multimodal content\ncomprehension necessitate a profound understanding of multimodal contexts,\nachieved through the multimodal interaction to obtain a final answer. In this\npaper, we introduce a comprehensive assessment framework called MM-BigBench,\nwhich incorporates a diverse range of metrics to offer an extensive evaluation\nof the performance of various models and instructions across a wide spectrum of\ndiverse multimodal content comprehension tasks. Consequently, our work\ncomplements research on the performance of MLLMs in multimodal comprehension\ntasks, achieving a more comprehensive and holistic evaluation of MLLMs. To\nbegin, we employ the Best Performance metric to ascertain each model's\nperformance upper bound on different datasets. Subsequently, the Mean Relative\nGain metric offers an assessment of the overall performance of various models\nand instructions, while the Stability metric measures their sensitivity.\nFurthermore, previous research centers on evaluating models independently or\nsolely assessing instructions, neglecting the adaptability between models and\ninstructions. We propose the Adaptability metric to quantify the adaptability\nbetween models and instructions. Our paper evaluates a total of 20 language\nmodels (14 MLLMs) on 14 multimodal datasets spanning 6 tasks, with 10\ninstructions for each task, and derives novel insights. Our code will be\nreleased at https://github.com/declare-lab/MM-BigBench.", "published": "2023-10-13 11:57:04", "link": "http://arxiv.org/abs/2310.09036v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Dialect Transfer for Swiss German Speech Translation", "abstract": "This paper investigates the challenges in building Swiss German speech\ntranslation systems, specifically focusing on the impact of dialect diversity\nand differences between Swiss German and Standard German. Swiss German is a\nspoken language with no formal writing system, it comprises many diverse\ndialects and is a low-resource language with only around 5 million speakers.\nThe study is guided by two key research questions: how does the inclusion and\nexclusion of dialects during the training of speech translation models for\nSwiss German impact the performance on specific dialects, and how do the\ndifferences between Swiss German and Standard German impact the performance of\nthe systems? We show that dialect diversity and linguistic differences pose\nsignificant challenges to Swiss German speech translation, which is in line\nwith linguistic hypotheses derived from empirical investigations.", "published": "2023-10-13 13:16:57", "link": "http://arxiv.org/abs/2310.09088v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GLoRE: Evaluating Logical Reasoning of Large Language Models", "abstract": "Recently, large language models (LLMs), including notable models such as\nGPT-4 and burgeoning community models, have showcased significant general\nlanguage understanding abilities. However, there has been a scarcity of\nattempts to assess the logical reasoning capacities of these LLMs, an essential\nfacet of natural language understanding. To encourage further investigation in\nthis area, we introduce GLoRE, a meticulously assembled General Logical\nReasoning Evaluation benchmark comprised of 12 datasets that span three\ndifferent types of tasks. Our experimental results show that compared to the\nperformance of human and supervised fine-tuning, the logical reasoning\ncapabilities of open LLM models necessitate additional improvement; ChatGPT and\nGPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing\nChatGPT by a large margin. We propose a self-consistency probing method to\nenhance the accuracy of ChatGPT and a fine-tuned method to boost the\nperformance of an open LLM. We release the datasets and evaluation programs to\nfacilitate future research.", "published": "2023-10-13 13:52:15", "link": "http://arxiv.org/abs/2310.09107v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework\n  for Cross-Domain Zero-Shot Slot Filling", "abstract": "In task-oriented dialogue scenarios, cross-domain zero-shot slot filling\nplays a vital role in leveraging source domain knowledge to learn a model with\nhigh generalization ability in unknown target domain where annotated data is\nunavailable. However, the existing state-of-the-art zero-shot slot filling\nmethods have limited generalization ability in target domain, they only show\neffective knowledge transfer on seen slots and perform poorly on unseen slots.\nTo alleviate this issue, we present a novel Hierarchical Contrastive Learning\nFramework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse-\nto fine-grained contrastive learning based on Gaussian-distributed embedding to\nlearn the generalized deep semantic relations between utterance-tokens, by\noptimizing inter- and intra-token distribution distance. This encourages HiCL\nto generalize to the slot types unseen at training phase. Furthermore, we\npresent a new iterative label set semantics inference method to unbiasedly and\nseparately evaluate the performance of unseen slot types which entangled with\ntheir counterparts (i.e., seen slot types) in the previous zero-shot slot\nfilling evaluation methods. The extensive empirical experiments on four\ndatasets demonstrate that the proposed method achieves comparable or even\nbetter performance than the current state-of-the-art zero-shot slot filling\napproaches.", "published": "2023-10-13 14:23:33", "link": "http://arxiv.org/abs/2310.09135v2", "categories": ["cs.AI", "cs.CL", "I.2; I.2.7"], "primary_category": "cs.AI"}
{"title": "\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in\n  LLM-Generated Reference Letters", "abstract": "Large Language Models (LLMs) have recently emerged as an effective tool to\nassist individuals in writing various types of content, including professional\ndocuments such as recommendation letters. Though bringing convenience, this\napplication also introduces unprecedented fairness concerns. Model-generated\nreference letters might be directly used by users in professional scenarios. If\nunderlying biases exist in these model-constructed letters, using them without\nscrutinization could lead to direct societal harms, such as sabotaging\napplication success rates for female applicants. In light of this pressing\nissue, it is imminent and necessary to comprehensively study fairness issues\nand associated harms in this real-world use case. In this paper, we critically\nexamine gender biases in LLM-generated reference letters. Drawing inspiration\nfrom social science findings, we design evaluation methods to manifest biases\nthrough 2 dimensions: (1) biases in language style and (2) biases in lexical\ncontent. We further investigate the extent of bias propagation by analyzing the\nhallucination bias of models, a term that we define to be bias exacerbation in\nmodel-hallucinated contents. Through benchmarking evaluation on 2 popular LLMs-\nChatGPT and Alpaca, we reveal significant gender biases in LLM-generated\nrecommendation letters. Our findings not only warn against using LLMs for this\napplication without scrutinization, but also illuminate the importance of\nthoroughly studying hidden biases and harms in LLM-generated professional\ndocuments.", "published": "2023-10-13 16:12:57", "link": "http://arxiv.org/abs/2310.09219v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AgentCF: Collaborative Learning with Autonomous Language Agents for\n  Recommender Systems", "abstract": "Recently, there has been an emergence of employing LLM-powered agents as\nbelievable human proxies, based on their remarkable decision-making capability.\nHowever, existing studies mainly focus on simulating human dialogue. Human\nnon-verbal behaviors, such as item clicking in recommender systems, although\nimplicitly exhibiting user preferences and could enhance the modeling of users,\nhave not been deeply explored. The main reasons lie in the gap between language\nmodeling and behavior modeling, as well as the incomprehension of LLMs about\nuser-item relations.\n  To address this issue, we propose AgentCF for simulating user-item\ninteractions in recommender systems through agent-based collaborative\nfiltering. We creatively consider not only users but also items as agents, and\ndevelop a collaborative learning approach that optimizes both kinds of agents\ntogether. Specifically, at each time step, we first prompt the user and item\nagents to interact autonomously. Then, based on the disparities between the\nagents' decisions and real-world interaction records, user and item agents are\nprompted to reflect on and adjust the misleading simulations collaboratively,\nthereby modeling their two-sided relations. The optimized agents can also\npropagate their preferences to other agents in subsequent interactions,\nimplicitly capturing the collaborative filtering idea. Overall, the optimized\nagents exhibit diverse interaction behaviors within our framework, including\nuser-item, user-user, item-item, and collective interactions. The results show\nthat these agents can demonstrate personalized behaviors akin to those of\nreal-world individuals, sparking the development of next-generation user\nbehavior simulation.", "published": "2023-10-13 16:37:14", "link": "http://arxiv.org/abs/2310.09233v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "PromptRE: Weakly-Supervised Document-Level Relation Extraction via\n  Prompting-Based Data Programming", "abstract": "Relation extraction aims to classify the relationships between two entities\ninto pre-defined categories. While previous research has mainly focused on\nsentence-level relation extraction, recent studies have expanded the scope to\ndocument-level relation extraction. Traditional relation extraction methods\nheavily rely on human-annotated training data, which is time-consuming and\nlabor-intensive. To mitigate the need for manual annotation, recent\nweakly-supervised approaches have been developed for sentence-level relation\nextraction while limited work has been done on document-level relation\nextraction. Weakly-supervised document-level relation extraction faces\nsignificant challenges due to an imbalanced number \"no relation\" instances and\nthe failure of directly probing pretrained large language models for document\nrelation extraction. To address these challenges, we propose PromptRE, a novel\nweakly-supervised document-level relation extraction method that combines\nprompting-based techniques with data programming. Furthermore, PromptRE\nincorporates the label distribution and entity types as prior knowledge to\nimprove the performance. By leveraging the strengths of both prompting and data\nprogramming, PromptRE achieves improved performance in relation classification\nand effectively handles the \"no relation\" problem. Experimental results on\nReDocRED, a benchmark dataset for document-level relation extraction,\ndemonstrate the superiority of PromptRE over baseline approaches.", "published": "2023-10-13 17:23:17", "link": "http://arxiv.org/abs/2310.09265v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dialogue Chain-of-Thought Distillation for Commonsense-aware\n  Conversational Agents", "abstract": "Human-like chatbots necessitate the use of commonsense reasoning in order to\neffectively comprehend and respond to implicit information present within\nconversations. Achieving such coherence and informativeness in responses,\nhowever, is a non-trivial task. Even for large language models (LLMs), the task\nof identifying and aggregating key evidence within a single hop presents a\nsubstantial challenge. This complexity arises because such evidence is\nscattered across multiple turns in a conversation, thus necessitating\nintegration over multiple hops. Hence, our focus is to facilitate such\nmulti-hop reasoning over a dialogue context, namely dialogue chain-of-thought\n(CoT) reasoning. To this end, we propose a knowledge distillation framework\nthat leverages LLMs as unreliable teachers and selectively distills consistent\nand helpful rationales via alignment filters. We further present DOCTOR, a\nDialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for\nresponse generation. We conduct extensive experiments to show that enhancing\ndialogue agents with high-quality rationales from DOCTOR significantly improves\nthe quality of their responses.", "published": "2023-10-13 18:17:23", "link": "http://arxiv.org/abs/2310.09343v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Domain Adaption for Neural Information Retrieval", "abstract": "Neural information retrieval requires costly annotated data for each target\ndomain to be competitive. Synthetic annotation by query generation using Large\nLanguage Models or rule-based string manipulation has been proposed as an\nalternative, but their relative merits have not been analysed. In this paper,\nwe compare both methods head-to-head using the same neural IR architecture. We\nfocus on the BEIR benchmark, which includes test datasets from several domains\nwith no training data, and explore two scenarios: zero-shot, where the\nsupervised system is trained in a large out-of-domain dataset (MS-MARCO); and\nunsupervised domain adaptation, where, in addition to MS-MARCO, the system is\nfine-tuned in synthetic data from the target domain. Our results indicate that\nLarge Language Models outperform rule-based methods in all scenarios by a large\nmargin, and, more importantly, that unsupervised domain adaptation is effective\ncompared to applying a supervised IR system in a zero-shot fashion. In addition\nwe explore several sizes of open Large Language Models to generate synthetic\ndata and find that a medium-sized model suffices. Code and models are publicly\navailable for reproducibility.", "published": "2023-10-13 18:27:33", "link": "http://arxiv.org/abs/2310.09350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing and Enhancing the Robustness of Large Language Models with\n  Task Structure Variations for Logical Reasoning", "abstract": "Large language models (LLMs), such as LLaMA, Alpaca, Vicuna, GPT-3.5 and\nGPT-4, have advanced the performance of AI systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness when performing logical reasoning has not been sufficiently\nassessed. To comprehensively evaluate this ability, we develop three new\nlogical reasoning datasets named \"ReClor-plus\", \"LogiQA-plus\" and\n\"LogiQAv2-plus\" that extend standard logical reasoning datasets to evaluate the\nrobustness of the LLM's reasoning. For each, we create three subsets: the first\nwith randomly shuffled options, the second with the correct choices replaced by\n\"none of the other options is correct\", and the third with a combination of\nshuffling and substitution. Experiments on these datasets show that these\nsimple augmentations greatly hinder the models' performance. Despite their high\nperformance on the original publicly available datasets, we find that all\nmodels perform poorly on these newly constructed datasets. We also demonstrate\nthat introducing task variations into the training set can markedly improve the\nmodel's performance on both the original and our developed datasets. Finally,\nwe show that applying logic-driven data augmentation for fine-tuning and\nprompting can enhance generalisation in both discriminative and generative\nmodels, offering a path to improving their robustness for tasks involving\nlogical reasoning. Source code and data are made publicly available at\nhttps://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning.", "published": "2023-10-13 22:29:15", "link": "http://arxiv.org/abs/2310.09430v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Bias for Question Answering Models by Tracking Bias Influence", "abstract": "Models of various NLP tasks have been shown to exhibit stereotypes, and the\nbias in the question answering (QA) models is especially harmful as the output\nanswers might be directly consumed by the end users. There have been datasets\nto evaluate bias in QA models, while bias mitigation technique for the QA\nmodels is still under-explored. In this work, we propose BMBI, an approach to\nmitigate the bias of multiple-choice QA models. Based on the intuition that a\nmodel would lean to be more biased if it learns from a biased example, we\nmeasure the bias level of a query instance by observing its influence on\nanother instance. If the influenced instance is more biased, we derive that the\nquery instance is biased. We then use the bias level detected as an\noptimization objective to form a multi-task learning setting in addition to the\noriginal QA task. We further introduce a new bias evaluation metric to quantify\nbias in a comprehensive and sensitive way. We show that our method could be\napplied to multiple QA formulations across multiple bias categories. It can\nsignificantly reduce the bias level in all 9 bias categories in the BBQ dataset\nwhile maintaining comparable QA accuracy.", "published": "2023-10-13 00:49:09", "link": "http://arxiv.org/abs/2310.08795v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Welfare Diplomacy: Benchmarking Language Model Cooperation", "abstract": "The growing capabilities and increasingly widespread deployment of AI systems\nnecessitate robust benchmarks for measuring their cooperative capabilities.\nUnfortunately, most multi-agent benchmarks are either zero-sum or purely\ncooperative, providing limited opportunities for such measurements. We\nintroduce a general-sum variant of the zero-sum board game Diplomacy -- called\nWelfare Diplomacy -- in which players must balance investing in military\nconquest and domestic welfare. We argue that Welfare Diplomacy facilitates both\na clearer assessment of and stronger training incentives for cooperative\ncapabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules\nand implementing them via an open-source Diplomacy engine; (2) constructing\nbaseline agents using zero-shot prompted language models; and (3) conducting\nexperiments where we find that baselines using state-of-the-art models attain\nhigh social welfare but are exploitable. Our work aims to promote societal\nsafety by aiding researchers in developing and assessing multi-agent AI\nsystems. Code to evaluate Welfare Diplomacy and reproduce our experiments is\navailable at https://github.com/mukobi/welfare-diplomacy.", "published": "2023-10-13 07:15:32", "link": "http://arxiv.org/abs/2310.08901v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Relation-aware Ensemble Learning for Knowledge Graph Embedding", "abstract": "Knowledge graph (KG) embedding is a fundamental task in natural language\nprocessing, and various methods have been proposed to explore semantic patterns\nin distinctive ways. In this paper, we propose to learn an ensemble by\nleveraging existing methods in a relation-aware manner. However, exploring\nthese semantics using relation-aware ensemble leads to a much larger search\nspace than general ensemble methods. To address this issue, we propose a\ndivide-search-combine algorithm RelEns-DSC that searches the relation-wise\nensemble weights independently. This algorithm has the same computation cost as\ngeneral ensemble methods but with much better performance. Experimental results\non benchmark datasets demonstrate the effectiveness of the proposed method in\nefficiently searching relation-aware ensemble weights and achieving\nstate-of-the-art embedding performance. The code is public at\nhttps://github.com/LARS-research/RelEns.", "published": "2023-10-13 07:40:12", "link": "http://arxiv.org/abs/2310.08917v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs", "abstract": "We present EasyGen, an efficient model designed to enhance multimodal\nunderstanding and generation by harnessing the capabilities of diffusion models\nand large language models (LLMs), Unlike existing multimodal models that\npredominately depend on encoders like CLIP or ImageBind and need ample amounts\nof training data to bridge modalities,EasyGen leverages BiDiffuser,a\nbidirectional conditional diffusion model, to foster more efficient modality\ninteractions. Easygen achieves text generation by training a projection layer\nlinking BiDiffuser and an LLM, and facilities image generation by training an\nadapter to align the LLM's text space with the BiDiffuser's image space,\nComprehensive quantitative and qualitative experiments show that EasyGen excels\nin data-efficient training, high-quality image generation, and extendibility,\neffectively addressing the challenges in multimodal generation. The source code\nis available at https://github.com/zxy556677/EasyGen.", "published": "2023-10-13 08:38:56", "link": "http://arxiv.org/abs/2310.08949v3", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules", "abstract": "Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.", "published": "2023-10-13 10:17:48", "link": "http://arxiv.org/abs/2310.08992v3", "categories": ["cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.AI"}
{"title": "KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level\n  Hallucination Detection", "abstract": "Large Language Models (LLMs) have demonstrated remarkable human-level natural\nlanguage generation capabilities. However, their potential to generate\nmisinformation, often called the hallucination problem, poses a significant\nrisk to their deployment. A common approach to address this issue is to\nretrieve relevant knowledge and fine-tune the LLM with the knowledge in its\ninput. Unfortunately, this method incurs high training costs and may cause\ncatastrophic forgetting for multi-tasking models. To overcome these\nlimitations, we propose a knowledge-constrained decoding method called KCTS\n(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text\naligned with the reference knowledge at each decoding step using a knowledge\nclassifier score and MCTS (Monte-Carlo Tree Search). To adapt the\nsequence-level knowledge classifier to token-level guidance, we also propose a\nnovel token-level hallucination detection method called RIPA (Reward Inflection\nPoint Approximation). Our empirical results on knowledge-grounded dialogue and\nabstractive summarization demonstrate the strength of KCTS as a plug-and-play,\nmodel-agnostic decoding method that can effectively reduce hallucinations in\nnatural language generation.", "published": "2023-10-13 12:12:34", "link": "http://arxiv.org/abs/2310.09044v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Consensus Game: Language Model Generation via Equilibrium Search", "abstract": "When applied to question answering and other text generation tasks, language\nmodels (LMs) may be queried generatively (by sampling answers from their output\ndistribution) or discriminatively (by using them to score or rank a set of\ncandidate outputs). These procedures sometimes yield very different\npredictions. How do we reconcile mutually incompatible scoring procedures to\nobtain coherent LM predictions? We introduce a new, a training-free,\ngame-theoretic procedure for language model decoding. Our approach casts\nlanguage model decoding as a regularized imperfect-information sequential\nsignaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks\nto communicate an abstract correctness parameter using natural language\nsentences to a DISCRIMINATOR. We develop computational procedures for finding\napproximate equilibria of this game, resulting in a decoding algorithm we call\nEQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading\ncomprehension, commonsense reasoning, mathematical problem-solving, and\ndialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,\nimproves performance over existing LM decoding procedures - on multiple\nbenchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B\noutperforms the much larger LLaMA-65B and PaLM-540B models. These results\nhighlight the promise of game-theoretic tools for addressing fundamental\nchallenges of truthfulness and consistency in LMs.", "published": "2023-10-13 14:27:21", "link": "http://arxiv.org/abs/2310.09139v1", "categories": ["cs.GT", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Automated Claim Matching with Large Language Models: Empowering\n  Fact-Checkers in the Fight Against Misinformation", "abstract": "In today's digital era, the rapid spread of misinformation poses threats to\npublic well-being and societal trust. As online misinformation proliferates,\nmanual verification by fact checkers becomes increasingly challenging. We\nintroduce FACT-GPT (Fact-checking Augmentation with Claim matching\nTask-oriented Generative Pre-trained Transformer), a framework designed to\nautomate the claim matching phase of fact-checking using Large Language Models\n(LLMs). This framework identifies new social media content that either supports\nor contradicts claims previously debunked by fact-checkers. Our approach\nemploys GPT-4 to generate a labeled dataset consisting of simulated social\nmedia posts. This data set serves as a training ground for fine-tuning more\nspecialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media\ncontent related to public health. The results indicate that our fine-tuned LLMs\nrival the performance of larger pre-trained LLMs in claim matching tasks,\naligning closely with human annotations. This study achieves three key\nmilestones: it provides an automated framework for enhanced fact-checking;\ndemonstrates the potential of LLMs to complement human expertise; offers public\nresources, including datasets and models, to further research and applications\nin the fact-checking domain.", "published": "2023-10-13 16:21:07", "link": "http://arxiv.org/abs/2310.09223v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet\n  Hierarchy", "abstract": "Text-to-image synthesis has recently attracted widespread attention due to\nrapidly improving quality and numerous practical applications. However, the\nlanguage understanding capabilities of text-to-image models are still poorly\nunderstood, which makes it difficult to reason about prompt formulations that a\ngiven model would understand well. In this work, we measure the capability of\npopular text-to-image models to understand $\\textit{hypernymy}$, or the \"is-a\"\nrelation between words. We design two automatic metrics based on the WordNet\nsemantic hierarchy and existing image classifiers pretrained on ImageNet. These\nmetrics both enable broad quantitative comparison of linguistic capabilities\nfor text-to-image models and offer a way of finding fine-grained qualitative\ndifferences, such as words that are unknown to models and thus are difficult\nfor them to draw. We comprehensively evaluate popular text-to-image models,\nincluding GLIDE, Latent Diffusion, and Stable Diffusion, showing how our\nmetrics can provide a better understanding of the individual strengths and\nweaknesses of these models.", "published": "2023-10-13 16:53:25", "link": "http://arxiv.org/abs/2310.09247v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Table-GPT: Table-tuned GPT for Diverse Table Tasks", "abstract": "Language models, such as GPT-3.5 and ChatGPT, demonstrate remarkable\nabilities to follow diverse human instructions and perform a wide range of\ntasks. However, when probing language models using a range of basic\ntable-understanding tasks, we observe that today's language models are still\nsub-optimal in many table-related tasks, likely because they are pre-trained\npredominantly on \\emph{one-dimensional} natural-language texts, whereas\nrelational tables are \\emph{two-dimensional} objects.\n  In this work, we propose a new \"\\emph{table-tuning}\" paradigm, where we\ncontinue to train/fine-tune language models like GPT-3.5 and ChatGPT, using\ndiverse table-tasks synthesized from real tables as training data, with the\ngoal of enhancing language models' ability to understand tables and perform\ntable tasks. We show that our resulting Table-GPT models demonstrate (1) better\n\\emph{table-understanding} capabilities, by consistently outperforming the\nvanilla GPT-3.5 and ChatGPT, on a wide-range of table tasks, including holdout\nunseen tasks, and (2) strong \\emph{generalizability}, in its ability to respond\nto diverse human instructions to perform new table-tasks, in a manner similar\nto GPT-3.5 and ChatGPT.", "published": "2023-10-13 17:20:56", "link": "http://arxiv.org/abs/2310.09263v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "User Inference Attacks on Large Language Models", "abstract": "Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\nconsider a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We design attacks\nfor performing user inference that require only black-box access to the\nfine-tuned LLM and a few samples from a user which need not be from the\nfine-tuning dataset. We find that LLMs are susceptible to user inference across\na variety of fine-tuning datasets, at times with near perfect attack success\nrates. Further, we theoretically and empirically investigate the properties\nthat make users vulnerable to user inference, finding that outlier users, users\nwith identifiable shared features between examples, and users that contribute a\nlarge fraction of the fine-tuning data are most susceptible to attack. Based on\nthese findings, we identify several methods for mitigating user inference\nincluding training with example-level differential privacy, removing\nwithin-user duplicate examples, and reducing a user's contribution to the\ntraining data. While these techniques provide partial mitigation of user\ninference, we highlight the need to develop methods to fully protect fine-tuned\nLLMs against this privacy risk.", "published": "2023-10-13 17:24:52", "link": "http://arxiv.org/abs/2310.09266v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Ranking LLM-Generated Loop Invariants for Program Verification", "abstract": "Synthesizing inductive loop invariants is fundamental to automating program\nverification. In this work, we observe that Large Language Models (such as\ngpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of\nprograms in a 0-shot setting, yet require several samples to generate the\ncorrect invariants. This can lead to a large number of calls to a program\nverifier to establish an invariant. To address this issue, we propose a {\\it\nre-ranking} approach for the generated results of LLMs. We have designed a\nranker that can distinguish between correct inductive invariants and incorrect\nattempts based on the problem definition. The ranker is optimized as a\ncontrastive ranker. Experimental results demonstrate that this re-ranking\nmechanism significantly improves the ranking of correct invariants among the\ngenerated candidates, leading to a notable reduction in the number of calls to\na verifier. The source code and the experimental data for this paper are\navailable in \\url{https://github.com/microsoft/NeuralInvariantRanker}.", "published": "2023-10-13 18:13:52", "link": "http://arxiv.org/abs/2310.09342v3", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.PL"}
{"title": "Surveying the Landscape of Text Summarization with Deep Learning: A\n  Comprehensive Review", "abstract": "In recent years, deep learning has revolutionized natural language processing\n(NLP) by enabling the development of models that can learn complex\nrepresentations of language data, leading to significant improvements in\nperformance across a wide range of NLP tasks. Deep learning models for NLP\ntypically use large amounts of data to train deep neural networks, allowing\nthem to learn the patterns and relationships in language data. This is in\ncontrast to traditional NLP approaches, which rely on hand-engineered features\nand rules to perform NLP tasks. The ability of deep neural networks to learn\nhierarchical representations of language data, handle variable-length input\nsequences, and perform well on large datasets makes them well-suited for NLP\napplications. Driven by the exponential growth of textual data and the\nincreasing demand for condensed, coherent, and informative summaries, text\nsummarization has been a critical research area in the field of NLP. Applying\ndeep learning to text summarization refers to the use of deep neural networks\nto perform text summarization tasks. In this survey, we begin with a review of\nfashionable text summarization tasks in recent years, including extractive,\nabstractive, multi-document, and so on. Next, we discuss most deep\nlearning-based models and their experimental results on these tasks. The paper\nalso covers datasets and data representation for summarization tasks. Finally,\nwe delve into the opportunities and challenges associated with summarization\ntasks and their corresponding methodologies, aiming to inspire future research\nefforts to advance the field further. A goal of our survey is to explain how\nthese methods differ in their requirements as understanding them is essential\nfor choosing a technique suited for a specific setting.", "published": "2023-10-13 21:24:37", "link": "http://arxiv.org/abs/2310.09411v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SALM: Speech-augmented Language Model with In-context Learning for\n  Speech Recognition and Translation", "abstract": "We present a novel Speech Augmented Language Model (SALM) with {\\em\nmultitask} and {\\em in-context} learning capabilities. SALM comprises a frozen\ntext LLM, a audio encoder, a modality adapter module, and LoRA layers to\naccommodate speech input and associated task instructions. The unified SALM not\nonly achieves performance on par with task-specific Conformer baselines for\nAutomatic Speech Recognition (ASR) and Speech Translation (AST), but also\nexhibits zero-shot in-context learning capabilities, demonstrated through\nkeyword-boosting task for ASR and AST. Moreover, {\\em speech supervised\nin-context training} is proposed to bridge the gap between LLM training and\ndownstream speech tasks, which further boosts the in-context learning ability\nof speech-to-text models. Proposed model is open-sourced via NeMo toolkit.", "published": "2023-10-13 22:07:33", "link": "http://arxiv.org/abs/2310.09424v1", "categories": ["cs.CL", "cs.HC", "cs.SD", "eess.AS", "68T10", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Enhancing BERT-Based Visual Question Answering through Keyword-Driven\n  Sentence Selection", "abstract": "The Document-based Visual Question Answering competition addresses the\nautomatic detection of parent-child relationships between elements in\nmulti-page documents. The goal is to identify the document elements that answer\na specific question posed in natural language. This paper describes the\nPoliTo's approach to addressing this task, in particular, our best solution\nexplores a text-only approach, leveraging an ad hoc sampling strategy.\nSpecifically, our approach leverages the Masked Language Modeling technique to\nfine-tune a BERT model, focusing on sentences containing sensitive keywords\nthat also occur in the questions, such as references to tables or images.\nThanks to the effectiveness of this approach, we are able to achieve high\nperformance compared to baselines, demonstrating how our solution contributes\npositively to this task.", "published": "2023-10-13 22:43:55", "link": "http://arxiv.org/abs/2310.09432v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sub-network Discovery and Soft-masking for Continual Learning of Mixed\n  Tasks", "abstract": "Continual learning (CL) has two main objectives: preventing catastrophic\nforgetting (CF) and encouraging knowledge transfer (KT). The existing\nliterature mainly focused on overcoming CF. Some work has also been done on KT\nwhen the tasks are similar. To our knowledge, only one method has been proposed\nto learn a sequence of mixed tasks. However, these techniques still suffer from\nCF and/or limited KT. This paper proposes a new CL method to achieve both. It\novercomes CF by isolating the knowledge of each task via discovering a\nsubnetwork for it. A soft-masking mechanism is also proposed to preserve the\nprevious knowledge and to enable the new task to leverage the past knowledge to\nachieve KT. Experiments using classification, generation, information\nextraction, and their mixture (i.e., heterogeneous tasks) show that the\nproposed method consistently outperforms strong baselines.", "published": "2023-10-13 23:00:39", "link": "http://arxiv.org/abs/2310.09436v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in\n  Bangla with Multi-Feature and Multi-Modal Analysis", "abstract": "This study presents a large multi-modal Bangla YouTube clickbait dataset\nconsisting of 253,070 data points collected through an automated process using\nthe YouTube API and Python web automation frameworks. The dataset contains 18\ndiverse features categorized into metadata, primary content, engagement\nstatistics, and labels for individual videos from 58 Bangla YouTube channels. A\nrigorous preprocessing step has been applied to denoise, deduplicate, and\nremove bias from the features, ensuring unbiased and reliable analysis. As the\nlargest and most robust clickbait corpus in Bangla to date, this dataset\nprovides significant value for natural language processing and data science\nresearchers seeking to advance modeling of clickbait phenomena in low-resource\nlanguages. Its multi-modal nature allows for comprehensive analyses of\nclickbait across content, user interactions, and linguistic dimensions to\ndevelop more sophisticated detection methods with cross-linguistic\napplications.", "published": "2023-10-13 13:25:16", "link": "http://arxiv.org/abs/2310.11465v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Speaking rate attention-based duration prediction for speed control TTS", "abstract": "With the advent of high-quality speech synthesis, there is a lot of interest\nin controlling various prosodic attributes of speech. Speaking rate is an\nessential attribute towards modelling the expressivity of speech. In this work,\nwe propose a novel approach to control the speaking rate for non-autoregressive\nTTS. We achieve this by conditioning the speaking rate inside the duration\npredictor, allowing implicit speaking rate control. We show the benefits of\nthis approach by synthesising audio at various speaking rate factors and\nmeasuring the quality of speaking rate-controlled synthesised speech. Further,\nwe study the effect of the speaking rate distribution of the training data\ntowards effective rate control. Finally, we fine-tune a baseline pretrained TTS\nmodel to obtain speaking rate control TTS. We provide various analyses to\nshowcase the benefits of using this proposed approach, along with objective as\nwell as subjective metrics. We find that the proposed methods have higher\nsubjective scores and lower speaker rate errors across many speaking rate\nfactors over the baseline.", "published": "2023-10-13 04:13:26", "link": "http://arxiv.org/abs/2310.08846v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Protecting Voice-Controlled Devices against LASER Injection Attacks", "abstract": "Voice-Controllable Devices (VCDs) have seen an increasing trend towards their\nadoption due to the small form factor of the MEMS microphones and their easy\nintegration into modern gadgets. Recent studies have revealed that MEMS\nmicrophones are vulnerable to audio-modulated laser injection attacks. This\npaper aims to develop countermeasures to detect and prevent laser injection\nattacks on MEMS microphones. A time-frequency decomposition based on discrete\nwavelet transform (DWT) is employed to decompose microphone output audio signal\ninto n + 1 frequency subbands to capture photo-acoustic related artifacts.\nHigher-order statistical features consisting of the first four moments of\nsubband audio signals, e.g., variance, skew, and kurtosis are used to\ndistinguish between acoustic and photo-acoustic responses. An SVM classifier is\nused to learn the underlying model that differentiates between an acoustic- and\nlaser-induced (photo-acoustic) response in the MEMS microphone. The proposed\nframework is evaluated on a data set of 190 audios, consisting of 19 speakers.\nThe experimental results indicate that the proposed framework is able to\ncorrectly classify $98\\%$ of the acoustic- and laser-induced audio in a random\ndata partition setting and $100\\%$ of the audio in speaker-independent and\ntext-independent data partition settings.", "published": "2023-10-13 21:09:38", "link": "http://arxiv.org/abs/2310.09404v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Dual-Branch Knowledge Distillation for Noise-Robust Synthetic Speech\n  Detection", "abstract": "Most research in synthetic speech detection (SSD) focuses on improving\nperformance on standard noise-free datasets. However, in actual situations,\nnoise interference is usually present, causing significant performance\ndegradation in SSD systems. To improve noise robustness, this paper proposes a\ndual-branch knowledge distillation synthetic speech detection (DKDSSD) method.\nSpecifically, a parallel data flow of the clean teacher branch and the noisy\nstudent branch is designed, and interactive fusion module and response-based\nteacher-student paradigms are proposed to guide the training of noisy data from\nboth the data distribution and decision-making perspectives. In the noisy\nstudent branch, speech enhancement is introduced initially for denoising,\naiming to reduce the interference of strong noise. The proposed interactive\nfusion combines denoised features and noisy features to mitigate the impact of\nspeech distortion and ensure consistency with the data distribution of the\nclean branch. The teacher-student paradigm maps the student's decision space to\nthe teacher's decision space, enabling noisy speech to behave similarly to\nclean speech. Additionally, a joint training method is employed to optimize\nboth branches for achieving global optimality. Experimental results based on\nmultiple datasets demonstrate that the proposed method performs effectively in\nnoisy environments and maintains its performance in cross-dataset experiments.\nSource code is available at https://github.com/fchest/DKDSSD.", "published": "2023-10-13 05:37:29", "link": "http://arxiv.org/abs/2310.08869v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Transformer-based Autoencoder with ID Constraint for Unsupervised\n  Anomalous Sound Detection", "abstract": "Unsupervised anomalous sound detection (ASD) aims to detect unknown anomalous\nsounds of devices when only normal sound data is available. The autoencoder\n(AE) and self-supervised learning based methods are two mainstream methods.\nHowever, the AE-based methods could be limited as the feature learned from\nnormal sounds can also fit with anomalous sounds, reducing the ability of the\nmodel in detecting anomalies from sound. The self-supervised methods are not\nalways stable and perform differently, even for machines of the same type. In\naddition, the anomalous sound may be short-lived, making it even harder to\ndistinguish from normal sound. This paper proposes an ID constrained\nTransformer-based autoencoder (IDC-TransAE) architecture with weighted anomaly\nscore computation for unsupervised ASD. Machine ID is employed to constrain the\nlatent space of the Transformer-based autoencoder (TransAE) by introducing a\nsimple ID classifier to learn the difference in the distribution for the same\nmachine type and enhance the ability of the model in distinguishing anomalous\nsound. Moreover, weighted anomaly score computation is introduced to highlight\nthe anomaly scores of anomalous events that only appear for a short time.\nExperiments performed on DCASE 2020 Challenge Task2 development dataset\ndemonstrate the effectiveness and superiority of our proposed method.", "published": "2023-10-13 08:49:17", "link": "http://arxiv.org/abs/2310.08950v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Differential Evolution Algorithm based Hyper-Parameters Selection of\n  Convolutional Neural Network for Speech Command Recognition", "abstract": "Speech Command Recognition (SCR), which deals with identification of short\nuttered speech commands, is crucial for various applications, including IoT\ndevices and assistive technology. Despite the promise shown by Convolutional\nNeural Networks (CNNs) in SCR tasks, their efficacy relies heavily on\nhyper-parameter selection, which is typically laborious and time-consuming when\ndone manually. This paper introduces a hyper-parameter selection method for\nCNNs based on the Differential Evolution (DE) algorithm, aiming to enhance\nperformance in SCR tasks. Training and testing with the Google Speech Command\n(GSC) dataset, the proposed approach showed effectiveness in classifying speech\ncommands. Moreover, a comparative analysis with Genetic Algorithm based\nselections and other deep CNN (DCNN) models highlighted the efficiency of the\nproposed DE algorithm in hyper-parameter selection for CNNs in SCR tasks.", "published": "2023-10-13 07:38:03", "link": "http://arxiv.org/abs/2310.08914v1", "categories": ["cs.SD", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-latency Speech Enhancement via Speech Token Generation", "abstract": "Existing deep learning based speech enhancement mainly employ a data-driven\napproach, which leverage large amounts of data with a variety of noise types to\nachieve noise removal from noisy signal. However, the high dependence on the\ndata limits its generalization on the unseen complex noises in real-life\nenvironment. In this paper, we focus on the low-latency scenario and regard\nspeech enhancement as a speech generation problem conditioned on the noisy\nsignal, where we generate clean speech instead of identifying and removing\nnoises. Specifically, we propose a conditional generative framework for speech\nenhancement, which models clean speech by acoustic codes of a neural speech\ncodec and generates the speech codes conditioned on past noisy frames in an\nauto-regressive way. Moreover, we propose an explicit-alignment approach to\nalign noisy frames with the generated speech tokens to improve the robustness\nand scalability to different input lengths. Different from other methods that\nleverage multiple stages to generate speech codes, we leverage a single-stage\nspeech generation approach based on the TF-Codec neural codec to achieve high\nspeech quality with low latency. Extensive results on both synthetic and\nreal-recorded test set show its superiority over data-driven approaches in\nterms of noise robustness and temporal speech coherence.", "published": "2023-10-13 09:57:09", "link": "http://arxiv.org/abs/2310.08981v3", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CORN: Co-Trained Full- And No-Reference Speech Quality Assessment", "abstract": "Perceptual evaluation constitutes a crucial aspect of various\naudio-processing tasks. Full reference (FR) or similarity-based metrics rely on\nhigh-quality reference recordings, to which lower-quality or corrupted versions\nof the recording may be compared for evaluation. In contrast, no-reference (NR)\nmetrics evaluate a recording without relying on a reference. Both the FR and NR\napproaches exhibit advantages and drawbacks relative to each other. In this\npaper, we present a novel framework called CORN that amalgamates these dual\napproaches, concurrently training both FR and NR models together. After\ntraining, the models can be applied independently. We evaluate CORN by\npredicting several common objective metrics and across two different\narchitectures. The NR model trained using CORN has access to a reference\nrecording during training, and thus, as one would expect, it consistently\noutperforms baseline NR models trained independently. Perhaps even more\nremarkable is that the CORN FR model also outperforms its baseline counterpart,\neven though it relies on the same training data and the same model\narchitecture. Thus, a single training regime produces two independently useful\nmodels, each outperforming independently trained models", "published": "2023-10-13 20:17:44", "link": "http://arxiv.org/abs/2310.09388v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
