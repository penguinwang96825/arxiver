{"title": "SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection", "abstract": "Deception is the intentional practice of twisting information. It is a\nnuanced societal practice deeply intertwined with human societal evolution,\ncharacterized by a multitude of facets. This research explores the problem of\ndeception through the lens of psychology, employing a framework that\ncategorizes deception into three forms: lies of omission, lies of commission,\nand lies of influence. The primary focus of this study is specifically on\ninvestigating only lies of omission. We propose a novel framework for deception\ndetection leveraging NLP techniques. We curated an annotated dataset of 876,784\nsamples by amalgamating a popular large-scale fake news dataset and scraped\nnews headlines from the Twitter handle of Times of India, a well-known Indian\nnews media house. Each sample has been labeled with four layers, namely: (i)\nthe type of omission (speculation, bias, distortion, sounds factual, and\nopinion), (ii) colors of lies(black, white, etc), and (iii) the intention of\nsuch lies (to influence, etc) (iv) topic of lies (political, educational,\nreligious, etc). We present a novel multi-task learning pipeline that leverages\nthe dataless merging of fine-tuned language models to address the deception\ndetection task mentioned earlier. Our proposed model achieved an F1 score of\n0.87, demonstrating strong performance across all layers including the type,\ncolor, intent, and topic aspects of deceptive content. Finally, our research\nexplores the relationship between lies of omission and propaganda techniques.\nTo accomplish this, we conducted an in-depth analysis, uncovering compelling\nfindings. For instance, our analysis revealed a significant correlation between\nloaded language and opinion, shedding light on their interconnectedness. To\nencourage further research in this field, we will be making the models and\ndataset available with the MIT License, making it favorable for open-source\nresearch.", "published": "2023-12-01 02:13:25", "link": "http://arxiv.org/abs/2312.00292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PsyAttention: Psychological Attention Model for Personality Detection", "abstract": "Work on personality detection has tended to incorporate psychological\nfeatures from different personality models, such as BigFive and MBTI. There are\nmore than 900 psychological features, each of which is helpful for personality\ndetection. However, when used in combination, the application of different\ncalculation standards among these features may result in interference between\nfeatures calculated using distinct systems, thereby introducing noise and\nreducing performance. This paper adapts different psychological models in the\nproposed PsyAttention for personality detection, which can effectively encode\npsychological features, reducing their number by 85%. In experiments on the\nBigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and\n86.30%, respectively, outperforming state-of-the-art methods, indicating that\nit is effective at encoding psychological features.", "published": "2023-12-01 02:13:34", "link": "http://arxiv.org/abs/2312.00293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient\n  Way", "abstract": "Large language models (LLMs) are increasingly pivotal in a wide range of\nnatural language processing tasks. Access to pre-trained models, courtesy of\nthe open-source community, has made it possible to adapt these models to\nspecific applications for enhanced performance. However, the substantial\nresources required for training these models necessitate efficient solutions.\nThis paper introduces CoLLiE, an efficient library that facilitates\ncollaborative training of large language models using 3D parallelism,\nparameter-efficient fine-tuning (PEFT) methods, and optimizers such as Lion,\nAdan, Sophia, LOMO and AdaLomo. With its modular design and comprehensive\nfunctionality, CoLLiE offers a balanced blend of efficiency, ease of use, and\ncustomization. CoLLiE has proven superior training efficiency in comparison\nwith prevalent solutions in pre-training and fine-tuning scenarios.\nFurthermore, we provide an empirical evaluation of the correlation between\nmodel size and GPU memory consumption under different optimization methods, as\nwell as an analysis of the throughput. Lastly, we carry out a comprehensive\ncomparison of various optimizers and PEFT methods within the instruction-tuning\ncontext. CoLLiE is available at https://github.com/OpenLMLab/collie.", "published": "2023-12-01 08:02:16", "link": "http://arxiv.org/abs/2312.00407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summarization-based Data Augmentation for Document Classification", "abstract": "Despite the prevalence of pretrained language models in natural language\nunderstanding tasks, understanding lengthy text such as document is still\nchallenging due to the data sparseness problem. Inspired by that humans develop\ntheir ability of understanding lengthy text from reading shorter text, we\npropose a simple yet effective summarization-based data augmentation, SUMMaug,\nfor document classification. We first obtain easy-to-learn examples for the\ntarget document classification task by summarizing the input of the original\ntraining examples, while optionally merging the original labels to conform to\nthe summarized input. We then use the generated pseudo examples to perform\ncurriculum learning. Experimental results on two datasets confirmed the\nadvantage of our method compared to existing baseline methods in terms of\nrobustness and accuracy. We release our code and data at\nhttps://github.com/etsurin/summaug.", "published": "2023-12-01 11:34:37", "link": "http://arxiv.org/abs/2312.00513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trained MT Metrics Learn to Cope with Machine-translated References", "abstract": "Neural metrics trained on human evaluations of MT tend to correlate well with\nhuman judgments, but their behavior is not fully understood. In this paper, we\nperform a controlled experiment and compare a baseline metric that has not been\ntrained on human evaluations (Prism) to a trained version of the same metric\n(Prism+FT). Surprisingly, we find that Prism+FT becomes more robust to\nmachine-translated references, which are a notorious problem in MT evaluation.\nThis suggests that the effects of metric training go beyond the intended effect\nof improving overall correlation with human judgments.", "published": "2023-12-01 12:15:58", "link": "http://arxiv.org/abs/2312.00536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Unsupervised Relation Extraction by Augmenting Diverse\n  Sentence Pairs", "abstract": "Unsupervised relation extraction (URE) aims to extract relations between\nnamed entities from raw text without requiring manual annotations or\npre-existing knowledge bases. In recent studies of URE, researchers put a\nnotable emphasis on contrastive learning strategies for acquiring relation\nrepresentations. However, these studies often overlook two important aspects:\nthe inclusion of diverse positive pairs for contrastive learning and the\nexploration of appropriate loss functions. In this paper, we propose AugURE\nwith both within-sentence pairs augmentation and augmentation through\ncross-sentence pairs extraction to increase the diversity of positive pairs and\nstrengthen the discriminative power of contrastive learning. We also identify\nthe limitation of noise-contrastive estimation (NCE) loss for relation\nrepresentation learning and propose to apply margin loss for sentence pairs.\nExperiments on NYT-FB and TACRED datasets demonstrate that the proposed\nrelation representation learning and a simple K-Means clustering achieves\nstate-of-the-art performance.", "published": "2023-12-01 12:59:32", "link": "http://arxiv.org/abs/2312.00552v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explanatory Argument Extraction of Correct Answers in Resident Medical\n  Exams", "abstract": "Developing the required technology to assist medical experts in their\neveryday activities is currently a hot topic in the Artificial Intelligence\nresearch field. Thus, a number of large language models (LLMs) and automated\nbenchmarks have recently been proposed with the aim of facilitating information\nextraction in Evidence-Based Medicine (EBM) using natural language as a tool\nfor mediating in human-AI interaction. The most representative benchmarks are\nlimited to either multiple-choice or long-form answers and are available only\nin English. In order to address these shortcomings, in this paper we present a\nnew dataset which, unlike previous work: (i) includes not only explanatory\narguments for the correct answer, but also arguments to reason why the\nincorrect answers are not correct; (ii) the explanations are written originally\nby medical doctors to answer questions from the Spanish Residency Medical\nExams. Furthermore, this new benchmark allows us to setup a novel extractive\ntask which consists of identifying the explanation of the correct answer\nwritten by medical doctors. An additional benefit of our setting is that we can\nleverage the extractive QA paradigm to automatically evaluate performance of\nLLMs without resorting to costly manual evaluation by medical experts.\nComprehensive experimentation with language models for Spanish shows that\nsometimes multilingual models fare better than monolingual ones, even\noutperforming models which have been adapted to the medical domain.\nFurthermore, results across the monolingual models are mixed, with supposedly\nsmaller and inferior models performing competitively. In any case, the obtained\nresults show that our novel dataset and approach can be an effective technique\nto help medical practitioners in identifying relevant evidence-based\nexplanations for medical questions.", "published": "2023-12-01 13:22:35", "link": "http://arxiv.org/abs/2312.00567v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction-tuning Aligns LLMs to the Human Brain", "abstract": "Instruction-tuning is a widely adopted finetuning method that enables large\nlanguage models (LLMs) to generate output that more closely resembles human\nresponses. However, no studies have shown that instruction-tuning actually\nteaches LLMs to process language in a similar manner as humans. We investigate\nthe effect of instruction-tuning on aligning LLM and human language processing\nmechanisms in two ways: (1) brain alignment, the similarity of LLM internal\nrepresentations to neural activity in the human language system, and (2)\nbehavioral alignment, the similarity of LLM and human behavior on a reading\ntask. We assess 25 vanilla and instruction-tuned LLMs on three datasets\ninvolving humans reading naturalistic stories and sentences, and find that\ninstruction-tuning generally enhances brain alignment (~6%), but has no similar\neffect on behavioral alignment. To identify factors underlying this improvement\nin brain alignment, we compute correlations between brain alignment and various\nLLM properties, such as model size, problem-solving, and world knowledge\nunderstanding. Notably, we find a strong positive correlation between brain\nalignment and model size (r = 0.95), as well as performance on tasks requiring\nworld knowledge (r = 0.81). Our results demonstrate that instruction-tuning\nLLMs improves both world knowledge representations and brain alignment,\nsuggesting that the mechanisms that encode world knowledge in LLMs also improve\nrepresentational alignment to the human brain.", "published": "2023-12-01 13:31:02", "link": "http://arxiv.org/abs/2312.00575v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey", "abstract": "The rapid growth of Large Language Models (LLMs) has been a driving force in\ntransforming various domains, reshaping the artificial general intelligence\nlandscape. However, the increasing computational and memory demands of these\nmodels present substantial challenges, hindering both academic research and\npractical applications. To address these issues, a wide array of methods,\nincluding both algorithmic and hardware solutions, have been developed to\nenhance the efficiency of LLMs. This survey delivers a comprehensive review of\nalgorithmic advancements aimed at improving LLM efficiency. Unlike other\nsurveys that typically focus on specific areas such as training or model\ncompression, this paper examines the multi-faceted dimensions of efficiency\nessential for the end-to-end algorithmic development of LLMs. Specifically, it\ncovers various topics related to efficiency, including scaling laws, data\nutilization, architectural innovations, training and tuning strategies, and\ninference techniques. This paper aims to serve as a valuable resource for\nresearchers and practitioners, laying the groundwork for future innovations in\nthis critical research area. Our repository of relevant references is\nmaintained at url{https://github.com/tding1/Efficient-LLM-Survey}.", "published": "2023-12-01 16:00:25", "link": "http://arxiv.org/abs/2312.00678v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualized word senses: from attention to compositionality", "abstract": "The neural architectures of language models are becoming increasingly\ncomplex, especially that of Transformers, based on the attention mechanism.\nAlthough their application to numerous natural language processing tasks has\nproven to be very fruitful, they continue to be models with little or no\ninterpretability and explainability. One of the tasks for which they are best\nsuited is the encoding of the contextual sense of words using contextualized\nembeddings. In this paper we propose a transparent, interpretable, and\nlinguistically motivated strategy for encoding the contextual sense of words by\nmodeling semantic compositionality. Particular attention is given to dependency\nrelations and semantic notions such as selection preferences and paradigmatic\nclasses. A partial implementation of the proposed model is carried out and\ncompared with Transformer-based architectures for a given semantic task, namely\nthe similarity calculation of word senses in context. The results obtained show\nthat it is possible to be competitive with linguistically motivated models\ninstead of using the black boxes underlying complex neural architectures.", "published": "2023-12-01 16:04:00", "link": "http://arxiv.org/abs/2312.00680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeaLLMs -- Large Language Models for Southeast Asia", "abstract": "Despite the remarkable achievements of large language models (LLMs) in\nvarious tasks, there remains a linguistic bias that favors high-resource\nlanguages, such as English, often at the expense of low-resource and regional\nlanguages. To address this imbalance, we introduce SeaLLMs, an innovative\nseries of language models that specifically focuses on Southeast Asian (SEA)\nlanguages. SeaLLMs are built upon the Llama-2 model and further advanced\nthrough continued pre-training with an extended vocabulary, specialized\ninstruction and alignment tuning to better capture the intricacies of regional\nlanguages. This allows them to respect and reflect local cultural norms,\ncustoms, stylistic preferences, and legal considerations. Our comprehensive\nevaluation demonstrates that SeaLLM-13b models exhibit superior performance\nacross a wide spectrum of linguistic tasks and assistant-style\ninstruction-following capabilities relative to comparable open-source models.\nMoreover, they outperform ChatGPT-3.5 in non-Latin languages, such as Thai,\nKhmer, Lao, and Burmese, by large margins while remaining lightweight and\ncost-effective to operate.", "published": "2023-12-01 17:17:56", "link": "http://arxiv.org/abs/2312.00738v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs\n  in Language Pretraining", "abstract": "The knowledge graph is a structure to store and represent knowledge, and\nrecent studies have discussed its capability to assist language models for\nvarious applications. Some variations of knowledge graphs aim to record\narguments and their relations for computational argumentation tasks. However,\nmany must simplify semantic types to fit specific schemas, thus losing\nflexibility and expression ability. In this paper, we propose the Hierarchical\nArgumentation Graph (Hi-ArG), a new structure to organize arguments. We also\nintroduce two approaches to exploit Hi-ArG, including a text-graph multi-modal\nmodel GreaseArG and a new pre-training framework augmented with graph\ninformation. Experiments on two argumentation tasks have shown that after\nfurther pre-training and fine-tuning, GreaseArG supersedes same-scale language\nmodels on these tasks, while incorporating graph information during further\npre-training can also improve the performance of vanilla language models. Code\nfor this paper is available at https://github.com/ljcleo/Hi-ArG .", "published": "2023-12-01 19:03:38", "link": "http://arxiv.org/abs/2312.00874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing the Impact of Fake News on the Anticipated Outcome of the 2024\n  Election Ahead of Time", "abstract": "Despite increasing awareness and research around fake news, there is still a\nsignificant need for datasets that specifically target racial slurs and biases\nwithin North American political speeches. This is particulary important in the\ncontext of upcoming North American elections. This study introduces a\ncomprehensive dataset that illuminates these critical aspects of\nmisinformation. To develop this fake news dataset, we scraped and built a\ncorpus of 40,000 news articles about political discourses in North America. A\nportion of this dataset (4000) was then carefully annotated, using a blend of\nadvanced language models and human verification methods. We have made both\nthese datasets openly available to the research community and have conducted\nbenchmarking on the annotated data to demonstrate its utility. We release the\nbest-performing language model along with data. We encourage researchers and\ndevelopers to make use of this dataset and contribute to this ongoing\ninitiative.", "published": "2023-12-01 20:14:16", "link": "http://arxiv.org/abs/2312.03750v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rule-Guided Joint Embedding Learning over Knowledge Graphs", "abstract": "Recent studies focus on embedding learning over knowledge graphs, which map\nentities and relations in knowledge graphs into low-dimensional vector spaces.\nWhile existing models mainly consider the aspect of graph structure, there\nexists a wealth of contextual and literal information that can be utilized for\nmore effective embedding learning. This paper introduces a novel model that\nincorporates both contextual and literal information into entity and relation\nembeddings by utilizing graph convolutional networks. Specifically, for\ncontextual information, we assess its significance through confidence and\nrelatedness metrics. In addition, a unique rule-based method is developed to\ncalculate the confidence metric, and the relatedness metric is derived from the\nliteral information's representations. We validate our model performance with\nthorough experiments on two established benchmark datasets.", "published": "2023-12-01 19:58:31", "link": "http://arxiv.org/abs/2401.02968v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing for Question Answering over Knowledge Graphs", "abstract": "In this paper, we introduce a novel method with graph-to-segment mapping for\nquestion answering over knowledge graphs, which helps understanding question\nutterances. This method centers on semantic parsing, a key approach for\ninterpreting these utterances. The challenges lie in comprehending implicit\nentities, relationships, and complex constraints like time, ordinality, and\naggregation within questions, contextualized by the knowledge graph. Our\nframework employs a combination of rule-based and neural-based techniques to\nparse and construct highly accurate and comprehensive semantic segment\nsequences. These sequences form semantic query graphs, effectively representing\nquestion utterances. We approach question semantic parsing as a sequence\ngeneration task, utilizing an encoder-decoder neural network to transform\nnatural language questions into semantic segments. Moreover, to enhance the\nparsing of implicit entities and relations, we incorporate a graph neural\nnetwork that leverages the context of the knowledge graph to better understand\nquestion representations. Our experimental evaluations on two datasets\ndemonstrate the effectiveness and superior performance of our model in semantic\nparsing for question answering.", "published": "2023-12-01 20:45:06", "link": "http://arxiv.org/abs/2401.06772v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Attribute Control via Closed-Loop Disentanglement", "abstract": "Changing an attribute of a text without changing the content usually requires\nto first disentangle the text into irrelevant attributes and content\nrepresentations. After that, in the inference phase, the representation of one\nattribute is tuned to a different value, expecting that the corresponding\nattribute of the text can also be changed accordingly. The usual way of\ndisentanglement is to add some constraints on the latent space of an\nencoder-decoder architecture, including adversarial-based constraints and\nmutual-information-based constraints. However, the previous semi-supervised\nprocesses of attribute change are usually not enough to guarantee the success\nof attribute change and content preservation. In this paper, we propose a novel\napproach to achieve a robust control of attributes while enhancing content\npreservation. In this approach, we use a semi-supervised contrastive learning\nmethod to encourage the disentanglement of attributes in latent spaces.\nDifferently from previous works, we re-disentangle the reconstructed sentence\nand compare the re-disentangled latent space with the original latent space,\nwhich makes a closed-loop disentanglement process. This also helps content\npreservation. In addition, the contrastive learning method is also able to\nreplace the role of minimizing mutual information and adversarial training in\nthe disentanglement process, which alleviates the computation cost. We\nconducted experiments on three text datasets, including the Yelp Service review\ndataset, the Amazon Product review dataset, and the GoEmotions dataset. The\nexperimental results show the effectiveness of our model.", "published": "2023-12-01 01:26:38", "link": "http://arxiv.org/abs/2312.00277v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific\n  Progress in NLP", "abstract": "I propose a paradigm for scientific progress in NLP centered around\ndeveloping scalable, data-driven theories of linguistic structure. The idea is\nto collect data in tightly scoped, carefully defined ways which allow for\nexhaustive annotation of behavioral phenomena of interest, and then use machine\nlearning to construct explanatory theories of these phenomena which can form\nbuilding blocks for intelligible AI systems. After laying some conceptual\ngroundwork, I describe several investigations into data-driven theories of\nshallow semantic structure using Question-Answer driven Semantic Role Labeling\n(QA-SRL), a schema for annotating verbal predicate-argument relations using\nhighly constrained question-answer pairs. While this only scratches the surface\nof the complex language behaviors of interest in AI, I outline principles for\ndata collection and theoretical modeling which can inform future scientific\nprogress. This note summarizes and draws heavily on my PhD thesis.", "published": "2023-12-01 04:55:29", "link": "http://arxiv.org/abs/2312.00349v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "On Exploring the Reasoning Capability of Large Language Models with\n  Knowledge Graphs", "abstract": "This paper examines the capacity of LLMs to reason with knowledge graphs\nusing their internal knowledge graph, i.e., the knowledge graph they learned\nduring pre-training. Two research questions are formulated to investigate the\naccuracy of LLMs in recalling information from pre-training knowledge graphs\nand their ability to infer knowledge graph relations from context. To address\nthese questions, we employ LLMs to perform four distinct knowledge graph\nreasoning tasks. Furthermore, we identify two types of hallucinations that may\noccur during knowledge reasoning with LLMs: content and ontology hallucination.\nOur experimental results demonstrate that LLMs can successfully tackle both\nsimple and complex knowledge graph reasoning tasks from their own memory, as\nwell as infer from input context.", "published": "2023-12-01 05:08:47", "link": "http://arxiv.org/abs/2312.00353v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Event-driven Real-time Retrieval in Web Search", "abstract": "Information retrieval in real-time search presents unique challenges distinct\nfrom those encountered in classical web search. These challenges are\nparticularly pronounced due to the rapid change of user search intent, which is\ninfluenced by the occurrence and evolution of breaking news events, such as\nearthquakes, elections, and wars. Previous dense retrieval methods, which\nprimarily focused on static semantic representation, lack the capacity to\ncapture immediate search intent, leading to inferior performance in retrieving\nthe most recent event-related documents in time-sensitive scenarios. To address\nthis issue, this paper expands the query with event information that represents\nreal-time search intent. The Event information is then integrated with the\nquery through a cross-attention mechanism, resulting in a time-context query\nrepresentation. We further enhance the model's capacity for event\nrepresentation through multi-task training. Since publicly available datasets\nsuch as MS-MARCO do not contain any event information on the query side and\nhave few time-sensitive queries, we design an automatic data collection and\nannotation pipeline to address this issue, which includes ModelZoo-based Coarse\nAnnotation and LLM-driven Fine Annotation processes. In addition, we share the\ntraining tricks such as two-stage training and hard negative sampling. Finally,\nwe conduct a set of offline experiments on a million-scale production dataset\nto evaluate our approach and deploy an A/B testing in a real online system to\nverify the performance. Extensive experimental results demonstrate that our\nproposed approach significantly outperforms existing state-of-the-art baseline\nmethods.", "published": "2023-12-01 06:30:31", "link": "http://arxiv.org/abs/2312.00372v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Japanese Tort-case Dataset for Rationale-supported Legal Judgment\n  Prediction", "abstract": "This paper presents the first dataset for Japanese Legal Judgment Prediction\n(LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort\nprediction and its rationale extraction. The rationale extraction task\nidentifies the court's accepting arguments from alleged arguments by plaintiffs\nand defendants, which is a novel task in the field. JTD is constructed based on\nannotated 3,477 Japanese Civil Code judgments by 41 legal experts, resulting in\n7,978 instances with 59,697 of their alleged arguments from the involved\nparties. Our baseline experiments show the feasibility of the proposed two\ntasks, and our error analysis by legal experts identifies sources of errors and\nsuggests future directions of the LJP research.", "published": "2023-12-01 10:23:15", "link": "http://arxiv.org/abs/2312.00480v2", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "SurreyAI 2023 Submission for the Quality Estimation Shared Task", "abstract": "Quality Estimation (QE) systems are important in situations where it is\nnecessary to assess the quality of translations, but there is no reference\navailable. This paper describes the approach adopted by the SurreyAI team for\naddressing the Sentence-Level Direct Assessment shared task in WMT23. The\nproposed approach builds upon the TransQuest framework, exploring various\nautoencoder pre-trained language models within the MonoTransQuest architecture\nusing single and ensemble settings. The autoencoder pre-trained language models\nemployed in the proposed systems are XLMV, InfoXLM-large, and XLMR-large. The\nevaluation utilizes Spearman and Pearson correlation coefficients, assessing\nthe relationship between machine-predicted quality scores and human judgments\nfor 5 language pairs (English-Gujarati, English-Hindi, English-Marathi,\nEnglish-Tamil and English-Telugu). The MonoTQ-InfoXLM-large approach emerges as\na robust strategy, surpassing all other individual models proposed in this\nstudy by significantly improving over the baseline for the majority of the\nlanguage pairs.", "published": "2023-12-01 12:01:04", "link": "http://arxiv.org/abs/2312.00525v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Questioning Biases in Case Judgment Summaries: Legal Datasets or Large\n  Language Models?", "abstract": "The evolution of legal datasets and the advent of large language models\n(LLMs) have significantly transformed the legal field, particularly in the\ngeneration of case judgment summaries. However, a critical concern arises\nregarding the potential biases embedded within these summaries. This study\nscrutinizes the biases present in case judgment summaries produced by legal\ndatasets and large language models. The research aims to analyze the impact of\nbiases on legal decision making. By interrogating the accuracy, fairness, and\nimplications of biases in these summaries, this study contributes to a better\nunderstanding of the role of technology in legal contexts and the implications\nfor justice systems worldwide. In this study, we investigate biases wrt\nGender-related keywords, Race-related keywords, Keywords related to crime\nagainst women, Country names and religious keywords. The study shows\ninteresting evidences of biases in the outputs generated by the large language\nmodels and pre-trained abstractive summarization models. The reasoning behind\nthese biases needs further studies.", "published": "2023-12-01 13:00:45", "link": "http://arxiv.org/abs/2312.00554v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Ethics of Automating Legal Actors", "abstract": "The introduction of large public legal datasets has brought about a\nrenaissance in legal NLP. Many of these datasets are comprised of legal\njudgements - the product of judges deciding cases. This fact, together with the\nway machine learning works, means that several legal NLP models are models of\njudges. While some have argued for the automation of judges, in this position\npiece, we argue that automating the role of the judge raises difficult ethical\nchallenges, in particular for common law legal systems. Our argument follows\nfrom the social role of the judge in actively shaping the law, rather than\nmerely applying it. Since current NLP models come nowhere close to having the\nfacilities necessary for this task, they should not be used to automate judges.\nFurthermore, even in the case the models could achieve human-level\ncapabilities, there would still be remaining ethical concerns inherent in the\nautomation of the legal process.", "published": "2023-12-01 13:48:46", "link": "http://arxiv.org/abs/2312.00584v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Nonparametric Variational Regularisation of Pretrained Transformers", "abstract": "The current paradigm of large-scale pre-training and fine-tuning Transformer\nlarge language models has lead to significant improvements across the board in\nnatural language processing. However, such large models are susceptible to\noverfitting to their training data, and as a result the models perform poorly\nwhen the domain changes. Also, due to the model's scale, the cost of\nfine-tuning the model to the new domain is large. Nonparametric Variational\nInformation Bottleneck (NVIB) has been proposed as a regulariser for training\ncross-attention in Transformers, potentially addressing the overfitting\nproblem. We extend the NVIB framework to replace all types of attention\nfunctions in Transformers, and show that existing pretrained Transformers can\nbe reinterpreted as Nonparametric Variational (NV) models using a proposed\nidentity initialisation. We then show that changing the initialisation\nintroduces a novel, information-theoretic post-training regularisation in the\nattention mechanism, which improves out-of-domain generalisation without any\ntraining. This success supports the hypothesis that pretrained Transformers are\nimplicitly NV Bayesian models.", "published": "2023-12-01 15:40:30", "link": "http://arxiv.org/abs/2312.00662v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal\n  Functionals", "abstract": "Transformers have achieved remarkable success in a wide range of natural\nlanguage processing and computer vision applications. However, the\nrepresentation capacity of a deep transformer model is degraded due to the\nover-smoothing issue in which the token representations become identical when\nthe model's depth grows. In this work, we show that self-attention layers in\ntransformers minimize a functional which promotes smoothness, thereby causing\ntoken uniformity. We then propose a novel regularizer that penalizes the norm\nof the difference between the smooth output tokens from self-attention and the\ninput tokens to preserve the fidelity of the tokens. Minimizing the resulting\nregularized energy functional, we derive the Neural Transformer with a\nRegularized Nonlocal Functional (NeuTRENO), a novel class of transformer models\nthat can mitigate the over-smoothing issue. We empirically demonstrate the\nadvantages of NeuTRENO over the baseline transformers and state-of-the-art\nmethods in reducing the over-smoothing of token representations on various\npractical tasks, including object classification, image segmentation, and\nlanguage modeling.", "published": "2023-12-01 17:52:47", "link": "http://arxiv.org/abs/2312.00751v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from\n  Fine-grained Correctional Human Feedback", "abstract": "Multimodal Large Language Models (MLLMs) have recently demonstrated\nimpressive capabilities in multimodal understanding, reasoning, and\ninteraction. However, existing MLLMs prevalently suffer from serious\nhallucination problems, generating text that is not factually grounded in\nassociated images. The problem makes existing MLLMs untrustworthy and thus\nimpractical in real-world (especially high-stakes) applications. To address the\nchallenge, we present RLHF-V, which enhances MLLM trustworthiness via behavior\nalignment from fine-grained correctional human feedback. Specifically, RLHF-V\ncollects human preference in the form of segment-level corrections on\nhallucinations, and performs dense direct preference optimization over the\nhuman feedback. Comprehensive experiments on five benchmarks in both automatic\nand human evaluation show that, RLHF-V can enable substantially more\ntrustworthy MLLM behaviors with promising data and computation efficiency.\nRemarkably, using 1.4k annotated data samples, RLHF-V significantly reduces the\nhallucination rate of the base MLLM by 34.8%, outperforming the concurrent\nLLaVA-RLHF trained on 10k annotated data. The final model achieves\nstate-of-the-art performance in trustworthiness among open-source MLLMs, and\nshows better robustness than GPT-4V in preventing hallucinations aroused from\nover-generalization. We open-source our code, model, and data at\nhttps://github.com/RLHF-V/RLHF-V.", "published": "2023-12-01 11:36:08", "link": "http://arxiv.org/abs/2312.00849v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Hyperparameter Optimization for Large Language Model Instruction-Tuning", "abstract": "The fine-tuning of Large Language Models (LLMs) has enabled them to recently\nachieve milestones in natural language processing applications. The emergence\nof ever larger LLMs has paved the way for more efficient fine-tuning methods.\nAmong these, the Low-Rank Adaptation (LoRA) method keeps most of the weights of\nthe pre-trained LLM frozen while introducing a low-rank decomposition of the\nweight matrix, enabling the tuning of only a very small proportion of the\nnetwork. The performance on downstream tasks of models fine-tuned with LoRA\nheavily relies on a set of hyperparameters including the rank of the\ndecomposition. In this work, we investigate the choice of these hyperparameters\nthrough two main blackbox optimization (BBO) techniques. We examine the whole\npipeline of performing fine-tuning and validation on a pre-trained LLM as a\nblackbox and efficiently explore the space of hyperparameters with the \\nomad\nalgorithm, achieving a boost in performance and human alignment of the tuned\nmodel.", "published": "2023-12-01 22:03:12", "link": "http://arxiv.org/abs/2312.00949v2", "categories": ["cs.CL", "math.OC"], "primary_category": "cs.CL"}
{"title": "Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of\n  Low-rank Experts", "abstract": "Large multi-modal models (LMMs) exhibit remarkable performance across\nnumerous tasks. However, generalist LMMs often suffer from performance\ndegradation when tuned over a large collection of tasks. Recent research\nsuggests that Mixture of Experts (MoE) architectures are useful for instruction\ntuning, but for LMMs of parameter size around O(50-100B), the prohibitive cost\nof replicating and storing the expert models severely limits the number of\nexperts we can use. We propose Omni-SMoLA, an architecture that uses the Soft\nMoE approach to (softly) mix many multimodal low rank experts, and avoids\nintroducing a significant number of new parameters compared to conventional MoE\nmodels. The core intuition here is that the large model provides a foundational\nbackbone, while different lightweight experts residually learn specialized\nknowledge, either per-modality or multimodally. Extensive experiments\ndemonstrate that the SMoLA approach helps improve the generalist performance\nacross a broad range of generative vision-and-language tasks, achieving new\nSoTA generalist performance that often matches or outperforms single\nspecialized LMM baselines, as well as new SoTA specialist performance.", "published": "2023-12-01 23:04:27", "link": "http://arxiv.org/abs/2312.00968v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Knowledge Graph Driven Recommendation System Algorithm", "abstract": "In this paper, we propose a novel graph neural network-based recommendation\nmodel called KGLN, which leverages Knowledge Graph (KG) information to enhance\nthe accuracy and effectiveness of personalized recommendations. We first use a\nsingle-layer neural network to merge individual node features in the graph, and\nthen adjust the aggregation weights of neighboring entities by incorporating\ninfluence factors. The model evolves from a single layer to multiple layers\nthrough iteration, enabling entities to access extensive multi-order associated\nentity information. The final step involves integrating features of entities\nand users to produce a recommendation score. The model performance was\nevaluated by comparing its effects on various aggregation methods and influence\nfactors. In tests over the MovieLen-1M and Book-Crossing datasets, KGLN shows\nan Area Under the ROC curve (AUC) improvement of 0.3% to 5.9% and 1.1% to 8.2%,\nrespectively, which is better than existing benchmark methods like LibFM,\nDeepFM, Wide&Deep, and RippleNet.", "published": "2023-12-01 21:50:43", "link": "http://arxiv.org/abs/2401.10244v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Location Sensitive Embedding for Knowledge Graph Reasoning", "abstract": "Embedding methods transform the knowledge graph into a continuous,\nlow-dimensional space, facilitating inference and completion tasks. Existing\nmethods are mainly divided into two types: translational distance models and\nsemantic matching models. A key challenge in translational distance models is\ntheir inability to effectively differentiate between 'head' and 'tail' entities\nin graphs. To address this problem, a novel location-sensitive embedding (LSE)\nmethod has been developed. LSE innovatively modifies the head entity using\nrelation-specific mappings, conceptualizing relations as linear transformations\nrather than mere translations. The theoretical foundations of LSE, including\nits representational capabilities and its connections to existing models, have\nbeen thoroughly examined. A more streamlined variant, LSEd, which employs a\ndiagonal matrix for transformations to enhance practical efficiency, is also\nproposed. Experiments conducted on four large-scale KG datasets for link\nprediction show that LSEd either outperforms or is competitive with\nstate-of-the-art related works.", "published": "2023-12-01 22:35:19", "link": "http://arxiv.org/abs/2401.10893v4", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Mark My Words: Analyzing and Evaluating Language Model Watermarks", "abstract": "The capabilities of large language models have grown significantly in recent\nyears and so too have concerns about their misuse. It is important to be able\nto distinguish machine-generated text from human-authored content. Prior works\nhave proposed numerous schemes to watermark text, which would benefit from a\nsystematic evaluation framework. This work focuses on LLM output watermarking\ntechniques - as opposed to image or model watermarks - and proposes Mark My\nWords, a comprehensive benchmark for them under different natural language\ntasks. We focus on three main metrics: quality, size (i.e., the number of\ntokens needed to detect a watermark), and tamper resistance (i.e., the ability\nto detect a watermark after perturbing marked text). Current watermarking\ntechniques are nearly practical enough for real-world use: Kirchenbauer et al.\n[33]'s scheme can watermark models like Llama 2 7B-chat or Mistral-7B-Instruct\nwith no perceivable loss in quality on natural language tasks, the watermark\ncan be detected with fewer than 100 tokens, and their scheme offers good tamper\nresistance to simple perturbations. However, they struggle to efficiently\nwatermark code generations. We publicly release our benchmark\n(https://github.com/wagner-group/MarkMyWords).", "published": "2023-12-01 01:22:46", "link": "http://arxiv.org/abs/2312.00273v3", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Agent-OM: Leveraging LLM Agents for Ontology Matching", "abstract": "Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM agents have\nrevolutionised data engineering and have been applied creatively in many\ndomains, their potential for OM remains underexplored. This study introduces a\nnovel agent-powered LLM-based design paradigm for OM systems. With\nconsideration of several specific challenges in leveraging LLM agents for OM,\nwe propose a generic framework, namely Agent-OM (Agent for Ontology Matching),\nconsisting of two Siamese agents for retrieval and matching, with a set of OM\ntools. Our framework is implemented in a proof-of-concept system. Evaluations\nof three Ontology Alignment Evaluation Initiative (OAEI) tracks over\nstate-of-the-art OM systems show that our system can achieve results very close\nto the long-standing best performance on simple OM tasks and can significantly\nimprove the performance on complex and few-shot OM tasks.", "published": "2023-12-01 03:44:54", "link": "http://arxiv.org/abs/2312.00326v10", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "RTQ: Rethinking Video-language Understanding Based on Image-text Model", "abstract": "Recent advancements in video-language understanding have been established on\nthe foundation of image-text models, resulting in promising outcomes due to the\nshared knowledge between images and videos. However, video-language\nunderstanding presents unique challenges due to the inclusion of highly complex\nsemantic details, which result in information redundancy, temporal dependency,\nand scene complexity. Current techniques have only partially tackled these\nissues, and our quantitative analysis indicates that some of these methods are\ncomplementary. In light of this, we propose a novel framework called RTQ\n(Refine, Temporal model, and Query), which addresses these challenges\nsimultaneously. The approach involves refining redundant information within\nframes, modeling temporal relations among frames, and querying task-specific\ninformation from the videos. Remarkably, our model demonstrates outstanding\nperformance even in the absence of video-language pre-training, and the results\nare comparable with or superior to those achieved by state-of-the-art\npre-training methods. Code is available at\nhttps://github.com/SCZwangxiao/RTQ-MM2023.", "published": "2023-12-01 04:51:01", "link": "http://arxiv.org/abs/2312.00347v2", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Abstract Syntax Tree for Programming Language Understanding and\n  Representation: How Far Are We?", "abstract": "Programming language understanding and representation (a.k.a code\nrepresentation learning) has always been a hot and challenging task in software\nengineering. It aims to apply deep learning techniques to produce numerical\nrepresentations of the source code features while preserving its semantics.\nThese representations can be used for facilitating subsequent code-related\ntasks. The abstract syntax tree (AST), a fundamental code feature, illustrates\nthe syntactic information of the source code and has been widely used in code\nrepresentation learning. However, there is still a lack of systematic and\nquantitative evaluation of how well AST-based code representation facilitates\nsubsequent code-related tasks. In this paper, we first conduct a comprehensive\nempirical study to explore the effectiveness of the AST-based code\nrepresentation in facilitating follow-up code-related tasks. To do so, we\ncompare the performance of models trained with code token sequence (Token for\nshort) based code representation and AST-based code representation on three\npopular types of code-related tasks. Surprisingly, the overall quantitative\nstatistical results demonstrate that models trained with AST-based code\nrepresentation consistently perform worse across all three tasks compared to\nmodels trained with Token-based code representation. Our further quantitative\nanalysis reveals that models trained with AST-based code representation\noutperform models trained with Token-based code representation in certain\nsubsets of samples across all three tasks. We also conduct comprehensive\nexperiments to evaluate and reveal the impact of the choice of AST\nparsing/preprocessing/encoding methods on AST-based code representation and\nsubsequent code-related tasks. Our study provides future researchers with\ndetailed guidance on how to select solutions at each stage to fully exploit\nAST.", "published": "2023-12-01 08:37:27", "link": "http://arxiv.org/abs/2312.00413v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL", "68-04, 68T30", "D.2.3; I.2.2; I.2.4"], "primary_category": "cs.SE"}
{"title": "Towards Transparency in Coreference Resolution: A Quantum-Inspired\n  Approach", "abstract": "Guided by grammatical structure, words compose to form sentences, and guided\nby discourse structure, sentences compose to form dialogues and documents. The\ncompositional aspect of sentence and discourse units is often overlooked by\nmachine learning algorithms. A recent initiative called Quantum Natural\nLanguage Processing (QNLP) learns word meanings as points in a Hilbert space\nand acts on them via a translation of grammatical structure into Parametrised\nQuantum Circuits (PQCs). Previous work extended the QNLP translation to\ndiscourse structure using points in a closure of Hilbert spaces. In this paper,\nwe evaluate this translation on a Winograd-style pronoun resolution task. We\ntrain a Variational Quantum Classifier (VQC) for binary classification and\nimplement an end-to-end pronoun resolution system. The simulations executed on\nIBMQ software converged with an F1 score of 87.20%. The model outperformed two\nout of three classical coreference resolution systems and neared\nstate-of-the-art SpanBERT. A mixed quantum-classical model yet improved these\nresults with an F1 score increase of around 6%.", "published": "2023-12-01 16:11:38", "link": "http://arxiv.org/abs/2312.00688v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized\n  Model Responses", "abstract": "Large language model (LLM) powered chatbots are primarily text-based today,\nand impose a large interactional cognitive load, especially for exploratory or\nsensemaking tasks such as planning a trip or learning about a new city. Because\nthe interaction is textual, users have little scaffolding in the way of\nstructure, informational \"scent\", or ability to specify high-level preferences\nor goals. We introduce ExploreLLM that allows users to structure thoughts, help\nexplore different options, navigate through the choices and recommendations,\nand to more easily steer models to generate more personalized responses. We\nconduct a user study and show that users find it helpful to use ExploreLLM for\nexploratory or planning tasks, because it provides a useful schema-like\nstructure to the task, and guides users in planning. The study also suggests\nthat users can more easily personalize responses with high-level preferences\nwith ExploreLLM. Together, ExploreLLM points to a future where users interact\nwith LLMs beyond the form of chatbots, and instead designed to support complex\nuser tasks with a tighter integration between natural language and graphical\nuser interfaces.", "published": "2023-12-01 18:31:28", "link": "http://arxiv.org/abs/2312.00763v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Context Retrieval via Normalized Contextual Latent Interaction for\n  Conversational Agent", "abstract": "Conversational agents leveraging AI, particularly deep learning, are emerging\nin both academic research and real-world applications. However, these\napplications still face challenges, including disrespecting knowledge and\nfacts, not personalizing to user preferences, and enormous demand for\ncomputational resources during training and inference. Recent research efforts\nhave been focused on addressing these challenges from various aspects,\nincluding supplementing various types of auxiliary information to the\nconversational agents. However, existing methods are still not able to\neffectively and efficiently exploit relevant information from these auxiliary\nsupplements to further unleash the power of the conversational agents and the\nlanguage models they use. In this paper, we present a novel method, PK-NCLI,\nthat is able to accurately and efficiently identify relevant auxiliary\ninformation to improve the quality of conversational responses by learning the\nrelevance among persona, chat history, and knowledge background through\nlow-level normalized contextual latent interaction. Our experimental results\nindicate that PK-NCLI outperforms the state-of-the-art method, PK-FoCus, by\n47.80%/30.61%/24.14% in terms of perplexity, knowledge grounding, and training\nefficiency, respectively, and maintained the same level of persona grounding\nperformance. We also provide a detailed analysis of how different factors,\nincluding language model choices and trade-offs on training weights, would\naffect the performance of PK-NCLI.", "published": "2023-12-01 18:53:51", "link": "http://arxiv.org/abs/2312.00774v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual\n  Prompts", "abstract": "While existing large vision-language multimodal models focus on whole image\nunderstanding, there is a prominent gap in achieving region-specific\ncomprehension. Current approaches that use textual coordinates or spatial\nencodings often fail to provide a user-friendly interface for visual prompting.\nTo address this challenge, we introduce a novel multimodal model capable of\ndecoding arbitrary visual prompts. This allows users to intuitively mark images\nand interact with the model using natural cues like a \"red bounding box\" or\n\"pointed arrow\". Our simple design directly overlays visual markers onto the\nRGB image, eliminating the need for complex region encodings, yet achieves\nstate-of-the-art performance on region-understanding tasks like Visual7W,\nPointQA, and Visual Commonsense Reasoning benchmark. Furthermore, we present\nViP-Bench, a comprehensive benchmark to assess the capability of models in\nunderstanding visual prompts across multiple dimensions, enabling future\nresearch in this domain. Code, data, and model are publicly available.", "published": "2023-12-01 18:59:56", "link": "http://arxiv.org/abs/2312.00784v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Quick Back-Translation for Unsupervised Machine Translation", "abstract": "The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.", "published": "2023-12-01 20:27:42", "link": "http://arxiv.org/abs/2312.00912v1", "categories": ["cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "The Cost of Compression: Investigating the Impact of Compression on\n  Parametric Knowledge in Language Models", "abstract": "Compressing large language models (LLMs), often consisting of billions of\nparameters, provides faster inference, smaller memory footprints, and enables\nlocal deployment. Two standard compression techniques are pruning and\nquantization, with the former eliminating redundant connections in model layers\nand the latter representing model parameters with fewer bits. The key tradeoff\nis between the degree of compression and the impact on the quality of the\ncompressed model. Existing research on LLM compression primarily focuses on\nperformance in terms of general metrics like perplexity or downstream task\naccuracy. More fine-grained metrics, such as those measuring parametric\nknowledge, remain significantly underexplored. To help bridge this gap, we\npresent a comprehensive analysis across multiple model families (ENCODER,\nENCODER-DECODER, and DECODER) using the LAMA and LM-HARNESS benchmarks in order\nto systematically quantify the effect of commonly employed compression\ntechniques on model performance. A particular focus is on tradeoffs involving\nparametric knowledge, with the goal of providing practitioners with practical\ninsights to help make informed decisions on compression. We release our\ncodebase1 to enable further research.", "published": "2023-12-01 22:27:12", "link": "http://arxiv.org/abs/2312.00960v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Video Summarization: Towards Entity-Aware Captions", "abstract": "Existing popular video captioning benchmarks and models deal with generic\ncaptions devoid of specific person, place or organization named entities. In\ncontrast, news videos present a challenging setting where the caption requires\nsuch named entities for meaningful summarization. As such, we propose the task\nof summarizing news video directly to entity-aware captions. We also release a\nlarge-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.\nFurther, we propose a method that augments visual information from videos with\ncontext retrieved from external world knowledge to generate entity-aware\ncaptions. We demonstrate the effectiveness of our approach on three video\ncaptioning models. We also show that our approach generalizes to existing news\nimage captions dataset. With all the extensive experiments and insights, we\nbelieve we establish a solid basis for future research on this challenging\ntask.", "published": "2023-12-01 23:56:00", "link": "http://arxiv.org/abs/2312.02188v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Conceptual Engineering Using Large Language Models", "abstract": "We describe a method, based on Jennifer Nado's proposal for classification\nprocedures as targets of conceptual engineering, that implements such\nprocedures by prompting a large language model. We apply this method, using\ndata from the Wikidata knowledge graph, to evaluate stipulative definitions\nrelated to two paradigmatic conceptual engineering projects: the International\nAstronomical Union's redefinition of PLANET and Haslanger's ameliorative\nanalysis of WOMAN. Our results show that classification procedures built using\nour approach can exhibit good classification performance and, through the\ngeneration of rationales for their classifications, can contribute to the\nidentification of issues in either the definitions or the data against which\nthey are being evaluated. We consider objections to this method, and discuss\nimplications of this work for three aspects of theory and practice of\nconceptual engineering: the definition of its targets, empirical methods for\ntheir investigation, and their practical roles. The data and code used for our\nexperiments, together with the experimental results, are available in a Github\nrepository.", "published": "2023-12-01 01:58:16", "link": "http://arxiv.org/abs/2312.03749v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "Towards a Psychological Generalist AI: A Survey of Current Applications\n  of Large Language Models and Future Prospects", "abstract": "The complexity of psychological principles underscore a significant societal\nchallenge, given the vast social implications of psychological problems.\nBridging the gap between understanding these principles and their actual\nclinical and real-world applications demands rigorous exploration and adept\nimplementation. In recent times, the swift advancement of highly adaptive and\nreusable artificial intelligence (AI) models has emerged as a promising way to\nunlock unprecedented capabilities in the realm of psychology. This paper\nemphasizes the importance of performance validation for these large-scale AI\nmodels, emphasizing the need to offer a comprehensive assessment of their\nverification from diverse perspectives. Moreover, we review the cutting-edge\nadvancements and practical implementations of these expansive models in\npsychology, highlighting pivotal work spanning areas such as social media\nanalytics, clinical nursing insights, vigilant community monitoring, and the\nnuanced exploration of psychological theories. Based on our review, we project\nan acceleration in the progress of psychological fields, driven by these\nlarge-scale AI models. These future generalist AI models harbor the potential\nto substantially curtail labor costs and alleviate social stress. However, this\nforward momentum will not be without its set of challenges, especially when\nconsidering the paradigm changes and upgrades required for medical\ninstrumentation and related applications.", "published": "2023-12-01 08:35:18", "link": "http://arxiv.org/abs/2312.04578v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SPIRE-SIES: A Spontaneous Indian English Speech Corpus", "abstract": "In this paper, we present a 170.83 hour Indian English spontaneous speech\ndataset. Lack of Indian English speech data is one of the major hindrances in\ndeveloping robust speech systems which are adapted to the Indian speech style.\nMoreover this scarcity is even more for spontaneous speech. This corpus is\ncrowd sourced over varied Indian nativities, genders and age groups.\nTraditional spontaneous speech collection strategies involve capturing of\nspeech during interviewing or conversations. In this study, we use images as\nstimuli to induce spontaneity in speech. Transcripts for 23 hours is generated\nand validated which can serve as a spontaneous speech ASR benchmark. Quality of\nthe corpus is validated with voice activity detection based segmentation,\ngender verification and image semantic correlation. Which determines a\nrelationship between image stimulus and recorded speech using caption keywords\nderived from Image2Text model and high occurring words derived from whisper ASR\ngenerated transcripts.", "published": "2023-12-01 16:29:50", "link": "http://arxiv.org/abs/2312.00698v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Self-Supervised Learning of Spatial Acoustic Representation with\n  Cross-Channel Signal Reconstruction and Multi-Channel Conformer", "abstract": "Supervised learning methods have shown effectiveness in estimating spatial\nacoustic parameters such as time difference of arrival, direct-to-reverberant\nratio and reverberation time. However, they still suffer from the\nsimulation-to-reality generalization problem due to the mismatch between\nsimulated and real-world acoustic characteristics and the deficiency of\nannotated real-world data. To this end, this work proposes a self-supervised\nmethod that takes full advantage of unlabeled data for spatial acoustic\nparameter estimation. First, a new pretext task, i.e. cross-channel signal\nreconstruction (CCSR), is designed to learn a universal spatial acoustic\nrepresentation from unlabeled multi-channel microphone signals. We mask partial\nsignals of one channel and ask the model to reconstruct them, which makes it\npossible to learn spatial acoustic information from unmasked signals and\nextract source information from the other microphone channel. An\nencoder-decoder structure is used to disentangle the two kinds of information.\nBy fine-tuning the pre-trained spatial encoder with a small annotated dataset,\nthis encoder can be used to estimate spatial acoustic parameters. Second, a\nnovel multi-channel audio Conformer (MC-Conformer) is adopted as the encoder\nmodel architecture, which is suitable for both the pretext and downstream\ntasks. It is carefully designed to be able to capture the local and global\ncharacteristics of spatial acoustics exhibited in the time-frequency domain.\nExperimental results of five acoustic parameter estimation tasks on both\nsimulated and real-world data show the effectiveness of the proposed method. To\nthe best of our knowledge, this is the first self-supervised learning method in\nthe field of spatial acoustic representation learning and multi-channel audio\nsignal processing.", "published": "2023-12-01 10:16:02", "link": "http://arxiv.org/abs/2312.00476v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Which Augmentation Should I Use? An Empirical Investigation of\n  Augmentations for Self-Supervised Phonocardiogram Representation Learning", "abstract": "Despite recent advancements in deep learning, its application in real-world\nmedical settings, such as phonocardiogram (PCG) classification, remains\nlimited. A significant barrier is the lack of high-quality annotated datasets,\nwhich hampers the development of robust, generalizable models that can perform\nwell on newly collected, out-of-distribution (OOD) data. Self-Supervised\nLearning (SSL) contrastive learning, has shown promise in mitigating the issue\nof data scarcity by using unlabeled data to enhance model robustness. Even\nthough SSL methods have been proposed and researched in other domains, works\nfocusing on the impact of data augmentations on model robustness for PCG\nclassification are limited. In particular, while augmentations are a key\ncomponent in SSL, selecting the most suitable policy during training is highly\nchallenging. Improper augmentations can lead to substantial performance\ndegradation and even hinder a network's ability to learn meaningful\nrepresentations. Addressing this gap, our research aims to explore and evaluate\na wide range of audio-based augmentations and uncover combinations that enhance\nSSL model performance in PCG classification. We conduct a comprehensive\ncomparative analysis across multiple datasets, assessing the impact of various\naugmentations on model performance. Our findings reveal that depending on the\ntraining distribution, augmentation choice significantly influences model\nrobustness, with fully-supervised models experiencing up to a 32\\% drop in\neffectiveness when evaluated on unseen data, while SSL models demonstrate\ngreater resilience, losing only 10\\% or even improving in some cases. This\nstudy also highlights the most promising and appropriate augmentations for PCG\nsignal processing, by calculating their effect size on training. These insights\nequip researchers with valuable guidelines for developing reliable models in\nPCG signal processing.", "published": "2023-12-01 11:06:00", "link": "http://arxiv.org/abs/2312.00502v6", "categories": ["cs.LG", "cs.SD", "eess.AS", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "aoip.ai: An Open-Source P2P SDK", "abstract": "This white paper introduces aoip.ai, a groundbreaking open-source SDK\nincorporating peer-to-peer technology and advanced AI integration to transform\nVoIP and IoT applications. It addresses key market challenges by enhancing data\nsecurity, elevating communication quality, and providing greater flexibility\nfor developers and users. Developed in collaboration with Carnegie Mellon\nUniversity, aoip.ai sets a new standard for decentralized and democratized\ncommunication solutions.", "published": "2023-12-01 23:28:06", "link": "http://arxiv.org/abs/2312.14934v1", "categories": ["cs.NI", "cs.AI", "cs.CY", "cs.SD", "eess.AS"], "primary_category": "cs.NI"}
