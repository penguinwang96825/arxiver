{"title": "Multi-Level Matching and Aggregation Network for Few-Shot Relation\n  Classification", "abstract": "This paper presents a multi-level matching and aggregation network (MLMAN)\nfor few-shot relation classification. Previous studies on this topic adopt\nprototypical networks, which calculate the embedding vector of a query instance\nand the prototype vector of each support set independently. In contrast, our\nproposed MLMAN model encodes the query instance and each support set in an\ninteractive way by considering their matching information at both local and\ninstance levels. The final class prototype for each support set is obtained by\nattentive aggregation over the representations of its support instances, where\nthe weights are calculated using the query instance. Experimental results\ndemonstrate the effectiveness of our proposed methods, which achieve a new\nstate-of-the-art performance on the FewRel dataset.", "published": "2019-06-16 13:10:33", "link": "http://arxiv.org/abs/1906.06678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Automatically Extracted Minimum Spans to Disentangle Coreference\n  Evaluation from Boundary Detection", "abstract": "The common practice in coreference resolution is to identify and evaluate the\nmaximum span of mentions. The use of maximum spans tangles coreference\nevaluation with the challenges of mention boundary detection like prepositional\nphrase attachment. To address this problem, minimum spans are manually\nannotated in smaller corpora. However, this additional annotation is costly and\ntherefore, this solution does not scale to large corpora. In this paper, we\npropose the MINA algorithm for automatically extracting minimum spans to\nbenefit from minimum span evaluation in all corpora. We show that the extracted\nminimum spans by MINA are consistent with those that are manually annotated by\nexperts. Our experiments show that using minimum spans is in particular\nimportant in cross-dataset coreference evaluation, in which detected mention\nboundaries are noisier due to domain shift. We will integrate MINA into\nhttps://github.com/ns-moosavi/coval for reporting standard coreference scores\nbased on both maximum and automatically detected minimum spans.", "published": "2019-06-16 14:33:45", "link": "http://arxiv.org/abs/1906.06703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B", "abstract": "In this paper we propose a novel neural approach for automatic decipherment\nof lost languages. To compensate for the lack of strong supervision signal, our\nmodel design is informed by patterns in language change documented in\nhistorical linguistics. The model utilizes an expressive sequence-to-sequence\nmodel to capture character-level correspondences between cognates. To\neffectively train the model in an unsupervised manner, we innovate the training\nprocedure by formalizing it as a minimum-cost flow problem. When applied to the\ndecipherment of Ugaritic, we achieve a 5.5% absolute improvement over\nstate-of-the-art results. We also report the first automatic results in\ndeciphering Linear B, a syllabic language related to ancient Greek, where our\nmodel correctly translates 67.3% of cognates.", "published": "2019-06-16 15:37:54", "link": "http://arxiv.org/abs/1906.06718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Background Based Conversation with Context-aware Knowledge\n  Pre-selection", "abstract": "Background Based Conversations (BBCs) have been developed to make dialogue\nsystems generate more informative and natural responses by leveraging\nbackground knowledge. Existing methods for BBCs can be grouped into two\ncategories: extraction-based methods and generation-based methods. The former\nextract spans frombackground material as responses that are not necessarily\nnatural. The latter generate responses thatare natural but not necessarily\neffective in leveraging background knowledge. In this paper, we focus on\ngeneration-based methods and propose a model, namely Context-aware Knowledge\nPre-selection (CaKe), which introduces a pre-selection process that uses\ndynamic bi-directional attention to improve knowledge selection by using the\nutterance history context as prior information to select the most relevant\nbackground material. Experimental results show that our model is superior to\ncurrent state-of-the-art baselines, indicating that it benefits from the\npre-selection process, thus improving in-formativeness and fluency.", "published": "2019-06-16 13:33:55", "link": "http://arxiv.org/abs/1906.06685v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dispersed Exponential Family Mixture VAEs for Interpretable Text\n  Generation", "abstract": "Deep generative models are commonly used for generating images and text.\nInterpretability of these models is one important pursuit, other than the\ngeneration quality. Variational auto-encoder (VAE) with Gaussian distribution\nas prior has been successfully applied in text generation, but it is hard to\ninterpret the meaning of the latent variable. To enhance the controllability\nand interpretability, one can replace the Gaussian prior with a mixture of\nGaussian distributions (GM-VAE), whose mixture components could be related to\nhidden semantic aspects of data. In this paper, we generalize the practice and\nintroduce DEM-VAE, a class of models for text generation using VAEs with a\nmixture distribution of exponential family. Unfortunately, a standard\nvariational training algorithm fails due to the mode-collapse problem. We\ntheoretically identify the root cause of the problem and propose an effective\nalgorithm to train DEM-VAE. Our method penalizes the training with an extra\ndispersion term to induce a well-structured latent space. Experimental results\nshow that our approach does obtain a meaningful space, and it outperforms\nstrong baselines in text generation benchmarks. The code is available at\nhttps://github.com/wenxianxian/demvae.", "published": "2019-06-16 15:41:07", "link": "http://arxiv.org/abs/1906.06719v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Persuasion for Good: Towards a Personalized Persuasive Dialogue System\n  for Social Good", "abstract": "Developing intelligent persuasive conversational agents to change people's\nopinions and actions for social good is the frontier in advancing the ethical\ndevelopment of automated dialogue systems. To do so, the first step is to\nunderstand the intricate organization of strategic disclosures and appeals\nemployed in human persuasion conversations. We designed an online persuasion\ntask where one participant was asked to persuade the other to donate to a\nspecific charity. We collected a large dataset with 1,017 dialogues and\nannotated emerging persuasion strategies from a subset. Based on the\nannotation, we built a baseline classifier with context information and\nsentence-level features to predict the 10 persuasion strategies used in the\ncorpus. Furthermore, to develop an understanding of personalized persuasion\nprocesses, we analyzed the relationships between individuals' demographic and\npsychological backgrounds including personality, morality, value systems, and\ntheir willingness for donation. Then, we analyzed which types of persuasion\nstrategies led to a greater amount of donation depending on the individuals'\npersonal backgrounds. This work lays the ground for developing a personalized\npersuasive dialogue system.", "published": "2019-06-16 16:43:02", "link": "http://arxiv.org/abs/1906.06725v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Theoretical Limitations of Self-Attention in Neural Sequence Models", "abstract": "Transformers are emerging as the new workhorse of NLP, showing great success\nacross tasks. Unlike LSTMs, transformers process input sequences entirely\nthrough self-attention. Previous work has suggested that the computational\ncapabilities of self-attention to process hierarchical structures are limited.\nIn this work, we mathematically investigate the computational power of\nself-attention to model formal languages. Across both soft and hard attention,\nwe show strong theoretical limitations of the computational abilities of\nself-attention, finding that it cannot model periodic finite-state languages,\nnor hierarchical structure, unless the number of layers or heads increases with\ninput length. These limitations seem surprising given the practical success of\nself-attention and the prominent role assigned to hierarchical structure in\nlinguistics, suggesting that natural language can be approximated well with\nmodels that are too weak for the formal languages typically assumed in\ntheoretical linguistics.", "published": "2019-06-16 19:19:49", "link": "http://arxiv.org/abs/1906.06755v2", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SEntNet: Source-aware Recurrent Entity Network for Dialogue Response\n  Selection", "abstract": "Dialogue response selection is an important part of Task-oriented Dialogue\nSystems (TDSs); it aims to predict an appropriate response given a dialogue\ncontext. Obtaining key information from a complex, long dialogue context is\nchallenging, especially when different sources of information are available,\ne.g., the user's utterances, the system's responses, and results retrieved from\na knowledge base (KB). Previous work ignores the type of information source and\nmerges sources for response selection. However, accounting for the source type\nmay lead to remarkable differences in the quality of response selection. We\npropose the Source-aware Recurrent Entity Network (SEntNet), which is aware of\ndifferent information sources for the response selection process. SEntNet\nachieves this by employing source-specific memories to exploit differences in\nthe usage of words and syntactic structure from different information sources\n(user, system, and KB). Experimental results show that SEntNet obtains 91.0%\naccuracy on the Dialog bAbI dataset, outperforming prior work by 4.7%. On the\nDSTC2 dataset, SEntNet obtains an accuracy of 41.2%, beating source unaware\nrecurrent entity networks by 2.4%.", "published": "2019-06-16 22:36:33", "link": "http://arxiv.org/abs/1906.06788v4", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Audio Transport: A Generalized Portamento via Optimal Transport", "abstract": "This paper proposes a new method to interpolate between two audio signals. As\nan interpolation parameter is changed, the pitches in one signal slide to the\npitches in the other, producing a portamento, or musical glide. The assignment\nof pitches in one sound to pitches in the other is accomplished by solving a\n1-dimensional optimal transport problem. In addition, we introduce several\ntechniques that preserve the audio fidelity over this highly non-linear\ntransformation.\n  A portamento is a natural way for a musician to transition between notes, but\ntraditionally it has only been possible for instruments with a continuously\nvariable pitch like the human voice or the violin. Audio transport extends the\nportamento to any instrument, even polyphonic ones. Moreover, the effect can be\nused to transition between different instruments, groups of instruments, or\nreally any transient-less audio signals. The audio transport effect operates in\nreal-time; we open-source implementation is provided. In experiments with\nsinusoidal inputs, the interpolating effect is indistinguishable from ideal\nsine sweeps. In general, the effect produces clear, musical results for a wide\nvariety of inputs.", "published": "2019-06-16 20:18:07", "link": "http://arxiv.org/abs/1906.06763v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-scale Embedded CNN for Music Tagging (MsE-CNN)", "abstract": "Convolutional neural networks (CNN) recently gained notable attraction in a\nvariety of machine learning tasks: including music classification and style\ntagging. In this work, we propose implementing intermediate connections to the\nCNN architecture to facilitate the transfer of multi-scale/level knowledge\nbetween different layers. Our novel model for music tagging shows significant\nimprovement in comparison to the proposed approaches in the literature, due to\nits ability to carry low-level timbral features to the last layer.", "published": "2019-06-16 18:16:21", "link": "http://arxiv.org/abs/1906.06746v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Parametric Resynthesis with neural vocoders", "abstract": "Noise suppression systems generally produce output speech with compromised\nquality. We propose to utilize the high quality speech generation capability of\nneural vocoders for noise suppression. We use a neural network to predict clean\nmel-spectrogram features from noisy speech and then compare two neural\nvocoders, WaveNet and WaveGlow, for synthesizing clean speech from the\npredicted mel spectrogram. Both WaveNet and WaveGlow achieve better subjective\nand objective quality scores than the source separation model Chimera++.\nFurther, WaveNet and WaveGlow also achieve significantly better subjective\nquality ratings than the oracle Wiener mask. Moreover, we observe that between\nWaveNet and WaveGlow, WaveNet achieves the best subjective quality scores,\nalthough at the cost of much slower waveform generation.", "published": "2019-06-16 20:17:23", "link": "http://arxiv.org/abs/1906.06762v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
