{"title": "Mining Scientific Papers for Bibliometrics: a (very) Brief Survey of\n  Methods and Tools", "abstract": "The Open Access movement in scientific publishing and search engines like\nGoogle Scholar have made scientific articles more broadly accessible. During\nthe last decade, the availability of scientific papers in full text has become\nmore and more widespread thanks to the growing number of publications on online\nplatforms such as ArXiv and CiteSeer. The efforts to provide articles in\nmachine-readable formats and the rise of Open Access publishing have resulted\nin a number of standardized formats for scientific papers (such as NLM-JATS,\nTEI, DocBook). Our aim is to stimulate research at the intersection of\nBibliometrics and Computational Linguistics in order to study the ways\nBibliometrics can benefit from large-scale text analytics and sense mining of\nscientific papers, thus exploring the interdisciplinarity of Bibliometrics and\nNatural Language Processing.", "published": "2015-05-06 15:18:04", "link": "http://arxiv.org/abs/1505.01393v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "A Fixed-Size Encoding Method for Variable-Length Sequences with its\n  Application to Neural Network Language Models", "abstract": "In this paper, we propose the new fixed-size ordinally-forgetting encoding\n(FOFE) method, which can almost uniquely encode any variable-length sequence of\nwords into a fixed-size representation. FOFE can model the word order in a\nsequence using a simple ordinally-forgetting mechanism according to the\npositions of words. In this work, we have applied FOFE to feedforward neural\nnetwork language models (FNN-LMs). Experimental results have shown that without\nusing any recurrent feedbacks, FOFE based FNN-LMs can significantly outperform\nnot only the standard fixed-input FNN-LMs but also the popular RNN-LMs.", "published": "2015-05-06 20:14:25", "link": "http://arxiv.org/abs/1505.01504v2", "categories": ["cs.NE", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
