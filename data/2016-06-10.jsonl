{"title": "PSDVec: a Toolbox for Incremental and Scalable Word Embedding", "abstract": "PSDVec is a Python/Perl toolbox that learns word embeddings, i.e. the mapping\nof words in a natural language to continuous vectors which encode the\nsemantic/syntactic regularities between the words. PSDVec implements a word\nembedding learning method based on a weighted low-rank positive semidefinite\napproximation. To scale up the learning process, we implement a blockwise\nonline learning algorithm to learn the embeddings incrementally. This strategy\ngreatly reduces the learning time of word embeddings on a large vocabulary, and\ncan learn the embeddings of new words without re-learning the whole vocabulary.\nOn 9 word similarity/analogy benchmark sets and 2 Natural Language Processing\n(NLP) tasks, PSDVec produces embeddings that has the best average performance\namong popular word embedding tools. PSDVec provides a new option for NLP\npractitioners.", "published": "2016-06-10 05:55:58", "link": "http://arxiv.org/abs/1606.03192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Question Answering by Attentive Convolutional Neural Network", "abstract": "This work focuses on answering single-relation factoid questions over\nFreebase. Each question can acquire the answer from a single fact of form\n(subject, predicate, object) in Freebase. This task, simple question answering\n(SimpleQA), can be addressed via a two-step pipeline: entity linking and fact\nselection. In fact selection, we match the subject entity in a fact candidate\nwith the entity mention in the question by a character-level convolutional\nneural network (char-CNN), and match the predicate in that fact with the\nquestion by a word-level CNN (word-CNN). This work makes two main\ncontributions. (i) A simple and effective entity linker over Freebase is\nproposed. Our entity linker outperforms the state-of-the-art entity linker over\nSimpleQA task. (ii) A novel attentive maxpooling is stacked over word-CNN, so\nthat the predicate representation can be matched with the predicate-focused\nquestion representation more effectively. Experiments show that our system sets\nnew state-of-the-art in this task.", "published": "2016-06-10 16:54:51", "link": "http://arxiv.org/abs/1606.03391v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Distantly Supervised IE using Joint Learning and Small\n  Well-structured Corpora", "abstract": "We propose a framework to improve performance of distantly-supervised\nrelation extraction, by jointly learning to solve two related tasks:\nconcept-instance extraction and relation extraction. We combine this with a\nnovel use of document structure: in some small, well-structured corpora,\nsections can be identified that correspond to relation arguments, and\ndistantly-labeled examples from such sections tend to have good precision.\nUsing these as seeds we extract additional relation examples by applying label\npropagation on a graph composed of noisy examples extracted from a large\nunstructured testing corpus. Combined with the soft constraint that concept\nexamples should have the same type as the second argument of the relation, we\nget significant improvements over several state-of-the-art approaches to\ndistantly-supervised relation extraction.", "published": "2016-06-10 17:14:11", "link": "http://arxiv.org/abs/1606.03398v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Policy Networks with Two-Stage Training for Dialogue Systems", "abstract": "In this paper, we propose to use deep policy networks which are trained with\nan advantage actor-critic method for statistically optimised dialogue systems.\nFirst, we show that, on summary state and action spaces, deep Reinforcement\nLearning (RL) outperforms Gaussian Processes methods. Summary state and action\nspaces lead to good performance but require pre-engineering effort, RL\nknowledge, and domain expertise. In order to remove the need to define such\nsummary spaces, we show that deep RL can also be trained efficiently on the\noriginal state and action spaces. Dialogue systems based on partially\nobservable Markov decision processes are known to require many dialogues to\ntrain, which makes them unappealing for practical deployment. We show that a\ndeep RL method based on an actor-critic architecture can exploit a small amount\nof data very efficiently. Indeed, with only a few hundred dialogues collected\nwith a handcrafted policy, the actor-critic deep learner is considerably\nbootstrapped from a combination of supervised and batch RL. In addition,\nconvergence to an optimal policy is significantly sped up compared to other\ndeep RL methods initialized on the data with batch RL. All experiments are\nperformed on a restaurant domain derived from the Dialogue State Tracking\nChallenge 2 (DSTC2) dataset.", "published": "2016-06-10 01:02:19", "link": "http://arxiv.org/abs/1606.03152v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning of Word-Sequence Representations from Scratch via\n  Convolutional Tensor Decomposition", "abstract": "Unsupervised text embeddings extraction is crucial for text understanding in\nmachine learning. Word2Vec and its variants have received substantial success\nin mapping words with similar syntactic or semantic meaning to vectors close to\neach other. However, extracting context-aware word-sequence embedding remains a\nchallenging task. Training over large corpus is difficult as labels are\ndifficult to get. More importantly, it is challenging for pre-trained models to\nobtain word-sequence embeddings that are universally good for all downstream\ntasks or for any new datasets. We propose a two-phased ConvDic+DeconvDec\nframework to solve the problem by combining a word-sequence dictionary learning\nmodel with a word-sequence embedding decode model. We propose a convolutional\ntensor decomposition mechanism to learn good word-sequence phrase dictionary in\nthe learning phase. It is proved to be more accurate and much more efficient\nthan the popular alternating minimization method. In the decode phase, we\nintroduce a deconvolution framework that is immune to the problem of varying\nsentence lengths. The word-sequence embeddings we extracted using\nConvDic+DeconvDec are universally good for a few downstream tasks we test on.\nThe framework requires neither pre-training nor prior/outside information.", "published": "2016-06-10 01:22:32", "link": "http://arxiv.org/abs/1606.03153v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation enhances human decision-making with\n  uncertain information", "abstract": "Decision-making is often dependent on uncertain data, e.g. data associated\nwith confidence scores or probabilities. We present a comparison of different\ninformation presentations for uncertain data and, for the first time, measure\ntheir effects on human decision-making. We show that the use of Natural\nLanguage Generation (NLG) improves decision-making under uncertainty, compared\nto state-of-the-art graphical-based representation methods. In a task-based\nstudy with 442 adults, we found that presentations using NLG lead to 24% better\ndecision-making on average than the graphical presentations, and to 44% better\ndecision-making when NLG is combined with graphics. We also show that women\nachieve significantly better results when presented with NLG output (an 87%\nincrease on average compared to graphical presentations).", "published": "2016-06-10 10:12:13", "link": "http://arxiv.org/abs/1606.03254v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Length bias in Encoder Decoder Models and a Case for Global Conditioning", "abstract": "Encoder-decoder networks are popular for modeling sequences probabilistically\nin many applications. These models use the power of the Long Short-Term Memory\n(LSTM) architecture to capture the full dependence among variables, unlike\nearlier models like CRFs that typically assumed conditional independence among\nnon-adjacent variables. However in practice encoder-decoder models exhibit a\nbias towards short sequences that surprisingly gets worse with increasing beam\nsize.\n  In this paper we show that such phenomenon is due to a discrepancy between\nthe full sequence margin and the per-element margin enforced by the locally\nconditioned training objective of a encoder-decoder model. The discrepancy more\nadversely impacts long sequences, explaining the bias towards predicting short\nsequences.\n  For the case where the predicted sequences come from a closed set, we show\nthat a globally conditioned model alleviates the above problems of\nencoder-decoder models. From a practical point of view, our proposed model also\neliminates the need for a beam-search during inference, which reduces to an\nefficient dot-product based search in a vector-space.", "published": "2016-06-10 17:30:46", "link": "http://arxiv.org/abs/1606.03402v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Deep CNNs along the Time Axis with Intermap Pooling for Robustness to\n  Spectral Variations", "abstract": "Convolutional neural networks (CNNs) with convolutional and pooling\noperations along the frequency axis have been proposed to attain invariance to\nfrequency shifts of features. However, this is inappropriate with regard to the\nfact that acoustic features vary in frequency. In this paper, we contend that\nconvolution along the time axis is more effective. We also propose the addition\nof an intermap pooling (IMP) layer to deep CNNs. In this layer, filters in each\ngroup extract common but spectrally variant features, then the layer pools the\nfeature maps of each group. As a result, the proposed IMP CNN can achieve\ninsensitivity to spectral variations characteristic of different speakers and\nutterances. The effectiveness of the IMP CNN architecture is demonstrated on\nseveral LVCSR tasks. Even without speaker adaptation techniques, the\narchitecture achieved a WER of 12.7% on the SWB part of the Hub5'2000\nevaluation test set, which is competitive with other state-of-the-art methods.", "published": "2016-06-10 06:44:21", "link": "http://arxiv.org/abs/1606.03207v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Automatic Genre and Show Identification of Broadcast Media", "abstract": "Huge amounts of digital videos are being produced and broadcast every day,\nleading to giant media archives. Effective techniques are needed to make such\ndata accessible further. Automatic meta-data labelling of broadcast media is an\nessential task for multimedia indexing, where it is standard to use multi-modal\ninput for such purposes. This paper describes a novel method for automatic\ndetection of media genre and show identities using acoustic features, textual\nfeatures or a combination thereof. Furthermore the inclusion of available\nmeta-data, such as time of broadcast, is shown to lead to very high\nperformance. Latent Dirichlet Allocation is used to model both acoustics and\ntext, yielding fixed dimensional representations of media recordings that can\nthen be used in Support Vector Machines based classification. Experiments are\nconducted on more than 1200 hours of TV broadcasts from the British\nBroadcasting Corporation (BBC), where the task is to categorise the broadcasts\ninto 8 genres or 133 show identities. On a 200-hour test set, accuracies of\n98.6% and 85.7% were achieved for genre and show identification respectively,\nusing a combination of acoustic and textual features with meta-data.", "published": "2016-06-10 14:09:32", "link": "http://arxiv.org/abs/1606.03333v1", "categories": ["cs.MM", "cs.CL", "cs.IR"], "primary_category": "cs.MM"}
{"title": "WordNet2Vec: Corpora Agnostic Word Vectorization Method", "abstract": "A complex nature of big data resources demands new methods for structuring\nespecially for textual content. WordNet is a good knowledge source for\ncomprehensive abstraction of natural language as its good implementations exist\nfor many languages. Since WordNet embeds natural language in the form of a\ncomplex network, a transformation mechanism WordNet2Vec is proposed in the\npaper. It creates vectors for each word from WordNet. These vectors encapsulate\ngeneral position - role of a given word towards all other words in the natural\nlanguage. Any list or set of such vectors contains knowledge about the context\nof its component within the whole language. Such word representation can be\neasily applied to many analytic tasks like classification or clustering. The\nusefulness of the WordNet2Vec method was demonstrated in sentiment analysis,\ni.e. classification with transfer learning for the real Amazon opinion textual\ndataset.", "published": "2016-06-10 14:12:47", "link": "http://arxiv.org/abs/1606.03335v1", "categories": ["cs.CL", "cs.AI", "cs.DC"], "primary_category": "cs.CL"}
{"title": "Conditional Generation and Snapshot Learning in Neural Dialogue Systems", "abstract": "Recently a variety of LSTM-based conditional language models (LM) have been\napplied across a range of language generation tasks. In this work we study\nvarious model architectures and different ways to represent and aggregate the\nsource information in an end-to-end neural dialogue system framework. A method\ncalled snapshot learning is also proposed to facilitate learning from\nsupervised sequential signals by applying a companion cross-entropy objective\nfunction to the conditioning vector. The experimental and analytical results\ndemonstrate firstly that competition occurs between the conditioning vector and\nthe LM, and the differing architectures provide different trade-offs between\nthe two. Secondly, the discriminative power and transparency of the\nconditioning vector is key to providing both model interpretability and better\nperformance. Thirdly, snapshot learning leads to consistent performance\nimprovements independent of which architecture is used.", "published": "2016-06-10 14:56:19", "link": "http://arxiv.org/abs/1606.03352v1", "categories": ["cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "De-identification of Patient Notes with Recurrent Neural Networks", "abstract": "Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.", "published": "2016-06-10 20:45:30", "link": "http://arxiv.org/abs/1606.03475v1", "categories": ["cs.CL", "cs.AI", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
