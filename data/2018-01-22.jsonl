{"title": "BiographyNet: Extracting Relations Between People and Events", "abstract": "This paper describes BiographyNet, a digital humanities project (2012-2016)\nthat brings together researchers from history, computational linguistics and\ncomputer science. The project uses data from the Biography Portal of the\nNetherlands (BPN), which contains approximately 125,000 biographies from a\nvariety of Dutch biographical dictionaries from the eighteenth century until\nnow, describing around 76,000 individuals. BiographyNet's aim is to strengthen\nthe value of the portal and comparable biographical datasets for historical\nresearch, by improving the search options and the presentation of its outcome,\nwith a historically justified NLP pipeline that works through a user evaluated\ndemonstrator. The project's main target group are professional historians. The\nproject therefore worked with two key concepts: \"provenance\" -understood as a\nterm allowing for both historical source criticism and for references to\ndata-management and programming interventions in digitized sources; and\n\"perspective\" interpreted as inherent uncertainty concerning the interpretation\nof historical results.", "published": "2018-01-22 13:00:02", "link": "http://arxiv.org/abs/1801.07073v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Open Relation Extraction", "abstract": "We explore methods to extract relations between named entities from free text\nin an unsupervised setting. In addition to standard feature extraction, we\ndevelop a novel method to re-weight word embeddings. We alleviate the problem\nof features sparsity using an individual feature reduction. Our approach\nexhibits a significant improvement by 5.8% over the state-of-the-art relation\nclustering scoring a F1-score of 0.416 on the NYT-FB dataset.", "published": "2018-01-22 16:19:12", "link": "http://arxiv.org/abs/1801.07174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Siamese Neural Networks with Random Forest for detecting duplicate\n  question pairs", "abstract": "Determining whether two given questions are semantically similar is a fairly\nchallenging task given the different structures and forms that the questions\ncan take. In this paper, we use Gated Recurrent Units(GRU) in combination with\nother highly used machine learning algorithms like Random Forest, Adaboost and\nSVM for the similarity prediction task on a dataset released by Quora,\nconsisting of about 400k labeled question pairs. We got the best result by\nusing the Siamese adaptation of a Bidirectional GRU with a Random Forest\nclassifier, which landed us among the top 24% in the competition Quora Question\nPairs hosted on Kaggle.", "published": "2018-01-22 19:27:31", "link": "http://arxiv.org/abs/1801.07288v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?", "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.", "published": "2018-01-22 18:58:18", "link": "http://arxiv.org/abs/1801.07243v5", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Early Detection of Social Media Hoaxes at Scale", "abstract": "The unmoderated nature of social media enables the diffusion of hoaxes, which\nin turn jeopardises the credibility of information gathered from social media\nplatforms. Existing research on automated detection of hoaxes has the\nlimitation of using relatively small datasets, owing to the difficulty of\ngetting labelled data. This in turn has limited research exploring early\ndetection of hoaxes as well as exploring other factors such as the effect of\nthe size of the training data or the use of sliding windows. To mitigate this\nproblem, we introduce a semi-automated method that leverages the Wikidata\nknowledge base to build large-scale datasets for veracity classification,\nfocusing on celebrity death reports. This enables us to create a dataset with\n4,007 reports including over 13 million tweets, 15% of which are fake.\nExperiments using class-specific representations of word embeddings show that\nwe can achieve F1 scores nearing 72% within 10 minutes of the first tweet being\nposted when we expand the size of the training data following our\nsemi-automated means. Our dataset represents a realistic scenario with a real\ndistribution of true, commemorative and false stories, which we release for\nfurther use as a benchmark in future research.", "published": "2018-01-22 20:41:50", "link": "http://arxiv.org/abs/1801.07311v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Adversarial Texts with Gradient Methods", "abstract": "Adversarial samples for images have been extensively studied in the\nliterature. Among many of the attacking methods, gradient-based methods are\nboth effective and easy to compute. In this work, we propose a framework to\nadapt the gradient attacking methods on images to text domain. The main\ndifficulties for generating adversarial texts with gradient methods are i) the\ninput space is discrete, which makes it difficult to accumulate small noise\ndirectly in the inputs, and ii) the measurement of the quality of the\nadversarial texts is difficult. We tackle the first problem by searching for\nadversarials in the embedding space and then reconstruct the adversarial texts\nvia nearest neighbor search. For the latter problem, we employ the Word Mover's\nDistance (WMD) to quantify the quality of adversarial texts. Through extensive\nexperiments on three datasets, IMDB movie reviews, Reuters-2 and Reuters-5\nnewswires, we show that our framework can leverage gradient attacking methods\nto generate very high-quality adversarial texts that are only a few words\ndifferent from the original texts. There are many cases where we can change one\nword to alter the label of the whole piece of text. We successfully incorporate\nFGM and DeepFool into our framework. In addition, we empirically show that WMD\nis closely related to the quality of adversarial texts.", "published": "2018-01-22 16:19:52", "link": "http://arxiv.org/abs/1801.07175v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
