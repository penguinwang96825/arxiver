{"title": "A Deep Cascade Model for Multi-Document Reading Comprehension", "abstract": "A fundamental trade-off between effectiveness and efficiency needs to be\nbalanced when designing an online question answering system. Effectiveness\ncomes from sophisticated functions such as extractive machine reading\ncomprehension (MRC), while efficiency is obtained from improvements in\npreliminary retrieval components such as candidate document selection and\nparagraph ranking. Given the complexity of the real-world multi-document MRC\nscenario, it is difficult to jointly optimize both in an end-to-end system. To\naddress this problem, we develop a novel deep cascade learning model, which\nprogressively evolves from the document-level and paragraph-level ranking of\ncandidate texts to more precise answer extraction with machine reading\ncomprehension. Specifically, irrelevant documents and paragraphs are first\nfiltered out with simple functions for efficiency consideration. Then we\njointly train three modules on the remaining texts for better tracking the\nanswer: the document extraction, the paragraph extraction and the answer\nextraction. Experiment results show that the proposed method outperforms the\nprevious state-of-the-art methods on two large-scale multi-document benchmark\ndatasets, i.e., TriviaQA and DuReader. In addition, our online system can\nstably serve typical scenarios with millions of daily requests in less than\n50ms.", "published": "2018-11-28 03:48:34", "link": "http://arxiv.org/abs/1811.11374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Dialog Re-Ranking for Task-Oriented Dialog Systems", "abstract": "Dialog response ranking is used to rank response candidates by considering\ntheir relation to the dialog history. Although researchers have addressed this\nconcept for open-domain dialogs, little attention has been focused on\ntask-oriented dialogs. Furthermore, no previous studies have analyzed whether\nresponse ranking can improve the performance of existing dialog systems in real\nhuman-computer dialogs with speech recognition errors. In this paper, we\npropose a context-aware dialog response re-ranking system. Our system reranks\nresponses in two steps: (1) it calculates matching scores for each candidate\nresponse and the current dialog context; (2) it combines the matching scores\nand a probability distribution of the candidates from an existing dialog system\nfor response re-ranking. By using neural word embedding-based models and\nhandcrafted or logistic regression-based ensemble models, we have improved the\nperformance of a recently proposed end-to-end task-oriented dialog system on\nreal dialogs with speech recognition errors.", "published": "2018-11-28 07:58:16", "link": "http://arxiv.org/abs/1811.11430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Multi-modal Neural Machine Translation", "abstract": "Unsupervised neural machine translation (UNMT) has recently achieved\nremarkable results with only large monolingual corpora in each language.\nHowever, the uncertainty of associating target with source sentences makes UNMT\ntheoretically an ill-posed problem. This work investigates the possibility of\nutilizing images for disambiguation to improve the performance of UNMT. Our\nassumption is intuitively based on the invariant property of image, i.e., the\ndescription of the same visual content by different languages should be\napproximately similar. We propose an unsupervised multi-modal machine\ntranslation (UMNMT) framework based on the language translation cycle\nconsistency loss conditional on the image, targeting to learn the bidirectional\nmulti-modal translation simultaneously. Through an alternate training between\nmulti-modal and uni-modal, our inference model can translate with or without\nthe image. On the widely used Multi30K dataset, the experimental results of our\napproach are significantly better than those of the text-only UNMT on the 2016\ntest dataset.", "published": "2018-11-28 02:48:25", "link": "http://arxiv.org/abs/1811.11365v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Sequence Learning with RNNs for Medical Concept Normalization in\n  User-Generated Texts", "abstract": "In this work, we consider the medical concept normalization problem, i.e.,\nthe problem of mapping a disease mention in free-form text to a concept in a\ncontrolled vocabulary, usually to the standard thesaurus in the Unified Medical\nLanguage System (UMLS). This task is challenging since medical terminology is\nvery different when coming from health care professionals or from the general\npublic in the form of social media texts. We approach it as a sequence learning\nproblem, with recurrent neural networks trained to obtain semantic\nrepresentations of one- and multi-word expressions. We develop end-to-end\nneural architectures tailored specifically to medical concept normalization,\nincluding bidirectional LSTM and GRU with an attention mechanism and additional\nsemantic similarity features based on UMLS. Our evaluation over a standard\nbenchmark shows that our model improves over a state of the art baseline for\nclassification based on CNNs.", "published": "2018-11-28 12:42:57", "link": "http://arxiv.org/abs/1811.11523v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Few-Shot Generalization Across Dialogue Tasks", "abstract": "Machine-learning based dialogue managers are able to learn complex behaviors\nin order to complete a task, but it is not straightforward to extend their\ncapabilities to new domains. We investigate different policies' ability to\nhandle uncooperative user behavior, and how well expertise in completing one\ntask (such as restaurant reservations) can be reapplied when learning a new one\n(e.g. booking a hotel). We introduce the Recurrent Embedding Dialogue Policy\n(REDP), which embeds system actions and dialogue states in the same vector\nspace. REDP contains a memory component and attention mechanism based on a\nmodified Neural Turing Machine, and significantly outperforms a baseline LSTM\nclassifier on this task. We also show that both our architecture and baseline\nsolve the bAbI dialogue task, achieving 100% test accuracy.", "published": "2018-11-28 17:51:39", "link": "http://arxiv.org/abs/1811.11707v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Indus Script and Economics. A Role for Indus Seals and Tablets in\n  Rationing and Administration of Labor", "abstract": "The Indus script remains one of the last major undeciphered scripts of the\nancient world. We focus here on Indus inscriptions on a group of miniature\ntablets discovered by Meadow and Kenoyer in Harappa in 1997. By drawing\nparallels with proto-Elamite and proto-Cuneiform inscriptions, we explore how\nthese miniature tablets may have been used to record rations allocated to\nporters or laborers. We then show that similar inscriptions are found on stamp\nseals, leading to the potentially provocative conclusion that rather than\nsimply indicating ownership of property, Indus seals may have been used for\ngenerating tokens, tablets and sealings for repetitive economic transactions\nsuch as rations and exchange of canonical amounts of goods, grains, animals,\nand labor in a barter-based economy.", "published": "2018-11-28 23:34:06", "link": "http://arxiv.org/abs/1812.00049v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "On the Inductive Bias of Word-Character-Level Multi-Task Learning for\n  Speech Recognition", "abstract": "End-to-end automatic speech recognition (ASR) commonly transcribes audio\nsignals into sequences of characters while its performance is evaluated by\nmeasuring the word-error rate (WER). This suggests that predicting sequences of\nwords directly may be helpful instead. However, training with word-level\nsupervision can be more difficult due to the sparsity of examples per label\nclass. In this paper we analyze an end-to-end ASR model that combines a\nword-and-character representation in a multi-task learning (MTL) framework. We\nshow that it improves on the WER and study how the word-level model can benefit\nfrom character-level supervision by analyzing the learned inductive preference\nbias of each model component empirically. We find that by adding\ncharacter-level supervision, the MTL model interpolates between recognizing\nmore frequent words (preferred by the word-level model) and shorter words\n(preferred by the character-level model).", "published": "2018-11-28 10:37:24", "link": "http://arxiv.org/abs/1812.02308v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "GIRNet: Interleaved Multi-Task Recurrent State Sequence Models", "abstract": "In several natural language tasks, labeled sequences are available in\nseparate domains (say, languages), but the goal is to label sequences with\nmixed domain (such as code-switched text). Or, we may have available models for\nlabeling whole passages (say, with sentiments), which we would like to exploit\ntoward better position-specific label inference (say, target-dependent\nsentiment annotation). A key characteristic shared across such tasks is that\ndifferent positions in a primary instance can benefit from different `experts'\ntrained from auxiliary data, but labeled primary instances are scarce, and\nlabeling the best expert for each position entails unacceptable cognitive\nburden. We propose GITNet, a unified position-sensitive multi-task recurrent\nneural network (RNN) architecture for such applications. Auxiliary and primary\ntasks need not share training instances. Auxiliary RNNs are trained over\nauxiliary instances. A primary instance is also submitted to each auxiliary\nRNN, but their state sequences are gated and merged into a novel composite\nstate sequence tailored to the primary inference task. Our approach is in sharp\ncontrast to recent multi-task networks like the cross-stitch and sluice\nnetwork, which do not control state transfer at such fine granularity. We\ndemonstrate the superiority of GIRNet using three applications: sentiment\nclassification of code-switched passages, part-of-speech tagging of\ncode-switched text, and target position-sensitive annotation of sentiment in\nmonolingual passages. In all cases, we establish new state-of-the-art\nperformance beyond recent competitive baselines.", "published": "2018-11-28 09:20:13", "link": "http://arxiv.org/abs/1811.11456v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding", "abstract": "We address the problem of phrase grounding by lear ing a multi-level common\nsemantic space shared by the textual and visual modalities. We exploit multiple\nlevels of feature maps of a Deep Convolutional Neural Network, as well as\ncontextualized word and sentence embeddings extracted from a character-based\nlanguage model. Following dedicated non-linear mappings for visual features at\neach level, word, and sentence embeddings, we obtain multiple instantiations of\nour common semantic space in which comparisons between any target text and the\nvisual content is performed with cosine similarity. We guide the model by a\nmulti-level multimodal attention mechanism which outputs attended visual\nfeatures at each level. The best level is chosen to be compared with text\ncontent for maximizing the pertinence scores of image-sentence pairs of the\nground truth. Experiments conducted on three publicly available datasets show\nsignificant performance gains (20%-60% relative) over the state-of-the-art in\nphrase localization and set a new performance record on those datasets. We\nprovide a detailed ablation study to show the contribution of each element of\nour approach and release our code on GitHub.", "published": "2018-11-28 17:05:27", "link": "http://arxiv.org/abs/1811.11683v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "The MeSH-gram Neural Network Model: Extending Word Embedding Vectors\n  with MeSH Concepts for UMLS Semantic Similarity and Relatedness in the\n  Biomedical Domain", "abstract": "Eliciting semantic similarity between concepts in the biomedical domain\nremains a challenging task. Recent approaches founded on embedding vectors have\ngained in popularity as they risen to efficiently capture semantic\nrelationships The underlying idea is that two words that have close meaning\ngather similar contexts. In this study, we propose a new neural network model\nnamed MeSH-gram which relies on a straighforward approach that extends the\nskip-gram neural network model by considering MeSH (Medical Subject Headings)\ndescriptors instead words. Trained on publicly available corpus PubMed MEDLINE,\nMeSH-gram is evaluated on reference standards manually annotated for semantic\nsimilarity. MeSH-gram is first compared to skip-gram with vectors of size 300\nand at several windows contexts. A deeper comparison is performed with tewenty\nexisting models. All the obtained results of Spearman's rank correlations\nbetween human scores and computed similarities show that MeSH-gram outperforms\nthe skip-gram model, and is comparable to the best methods but that need more\ncomputation and external resources.", "published": "2018-11-28 07:48:27", "link": "http://arxiv.org/abs/1812.02309v1", "categories": ["cs.CL", "cs.DL", "cs.IR", "cs.LG", "stat.ML", "I.2.6; H.3.1"], "primary_category": "cs.CL"}
{"title": "Acoustics-guided evaluation (AGE): a new measure for estimating\n  performance of speech enhancement algorithms for robust ASR", "abstract": "One challenging problem of robust automatic speech recognition (ASR) is how\nto measure the goodness of a speech enhancement algorithm (SEA) without\ncalculating the word error rate (WER) due to the high costs of manual\ntranscriptions, language modeling and decoding process. Traditional measures\nlike PESQ and STOI for evaluating the speech quality and intelligibility were\nverified to have relatively low correlations with WER. In this study, a novel\nacoustics-guided evaluation (AGE) measure is proposed for estimating\nperformance of SEAs for robust ASR. AGE consists of three consecutive steps,\nnamely the low-level representations via the feature extraction, high-level\nrepresentations via the nonlinear mapping with the acoustic model (AM), and the\nfinal AGE calculation between the representations of clean speech and degraded\nspeech. Specifically, state posterior probabilities from neural network based\nAM are adopted for the high-level representations and the cross-entropy\ncriterion is used to calculate AGE. Experiments demonstrate AGE could yield\nconsistently highest correlations with WER and give the most accurate\nestimation of ASR performance compared with PESQ, STOI, and acoustic confidence\nmeasure using Entropy. Potentially, AGE could be adopted to guide the parameter\noptimization of deep learning based SEAs to further improve the recognition\nperformance.", "published": "2018-11-28 12:13:23", "link": "http://arxiv.org/abs/1811.11517v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multiple source direction of arrival estimation using subspace\n  pseudointensity vectors", "abstract": "The recently proposed subspace pseudointensity method for direction of\narrival estimation is applied in the context of Tasks 1 and 2 of the LOCATA\nChallenge using the Eigenmike recordings. Specific implementation details are\ndescribed and results reported for the development dataset, for which the\nground truth source directions are available. For both single and multiple\nsource scenarios, the average absolute error angle is about 9 degrees.", "published": "2018-11-28 16:43:56", "link": "http://arxiv.org/abs/1811.11663v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "UFANS: U-shaped Fully-Parallel Acoustic Neural Structure For Statistical\n  Parametric Speech Synthesis With 20X Faster", "abstract": "Neural networks with Auto-regressive structures, such as Recurrent Neural\nNetworks (RNNs), have become the most appealing structures for acoustic\nmodeling of parametric text to speech synthesis (TTS) in ecent studies. Despite\nthe prominent capacity to capture long-term dependency, these models consist of\nmassive sequential computations that cannot be fully parallel. In this paper,\nwe propose a U-shaped Fully-parallel Acoustic Neural Structure (UFANS), which\nis a deconvolutional alternative of RNNs for Statistical Parametric Speech\nSynthesis (SPSS). The experiments verify that our proposed model is over 20\ntimes faster than RNN based acoustic model, both training and inference on GPU\nwith comparable speech quality. Furthermore, We also investigate that how long\ninformation dependence really matters to synthesized speech quality.", "published": "2018-11-28 03:53:20", "link": "http://arxiv.org/abs/1811.12208v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Play as You Like: Timbre-enhanced Multi-modal Music Style Transfer", "abstract": "Style transfer of polyphonic music recordings is a challenging task when\nconsidering the modeling of diverse, imaginative, and reasonable music pieces\nin the style different from their original one. To achieve this, learning\nstable multi-modal representations for both domain-variant (i.e., style) and\ndomain-invariant (i.e., content) information of music in an unsupervised manner\nis critical. In this paper, we propose an unsupervised music style transfer\nmethod without the need for parallel data. Besides, to characterize the\nmulti-modal distribution of music pieces, we employ the Multi-modal\nUnsupervised Image-to-Image Translation (MUNIT) framework in the proposed\nsystem. This allows one to generate diverse outputs from the learned latent\ndistributions representing contents and styles. Moreover, to better capture the\ngranularity of sound, such as the perceptual dimensions of timbre and the\nnuance in instrument-specific performance, cognitively plausible features\nincluding mel-frequency cepstral coefficients (MFCC), spectral difference, and\nspectral envelope, are combined with the widely-used mel-spectrogram into a\ntimber-enhanced multi-channel input representation. The Relativistic average\nGenerative Adversarial Networks (RaGAN) is also utilized to achieve fast\nconvergence and high stability. We conduct experiments on bilateral style\ntransfer tasks among three different genres, namely piano solo, guitar solo,\nand string quartet. Results demonstrate the advantages of the proposed method\nin music style transfer with improved sound quality and in allowing users to\nmanipulate the output.", "published": "2018-11-28 18:42:50", "link": "http://arxiv.org/abs/1811.12214v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SVD-PHAT: A Fast Sound Source Localization Method", "abstract": "This paper introduces a new localization method called SVD-PHAT. The SVD-PHAT\nmethod relies on Singular Value Decomposition of the SRP-PHAT projection\nmatrix. A k-d tree is also proposed to speed up the search for the most likely\ndirection of arrival of sound. We show that this method performs as accurately\nas SRP-PHAT, while reducing significantly the amount of computation required.", "published": "2018-11-28 19:06:55", "link": "http://arxiv.org/abs/1811.11785v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A Study of the Complexity and Accuracy of Direction of Arrival\n  Estimation Methods Based on GCC-PHAT for a Pair of Close Microphones", "abstract": "This paper investigates the accuracy of various Generalized Cross-Correlation\nwith Phase Transform (GCC-PHAT) methods for a close pair of microphones. We\ninvestigate interpolation-based methods and also propose another approach based\non Singular Value Decomposition (SVD). All investigated methods are implemented\nin C code, and the execution time is measured to determine which approach is\nthe most appealing for real-time applications on low-cost embedded hardware.", "published": "2018-11-28 19:11:57", "link": "http://arxiv.org/abs/1811.11787v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
