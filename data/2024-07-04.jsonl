{"title": "Core: Robust Factual Precision with Informative Sub-Claim Identification", "abstract": "Hallucinations pose a challenge to the application of large language models\n(LLMs) thereby motivating the development of metrics to evaluate factual\nprecision. We observe that popular metrics using the Decompose-Then-Verify\nframework, such as \\FActScore, can be manipulated by adding obvious or\nrepetitive subclaims to artificially inflate scores. This observation motivates\nour new customizable plug-and-play subclaim selection component called Core,\nwhich filters down individual subclaims according to their uniqueness and\ninformativeness. We show that many popular factual precision metrics augmented\nby Core are substantially more robust on a wide range of knowledge domains. We\nrelease an evaluation framework supporting easy and modular use of Core and\nvarious decomposition strategies, which we recommend adoption by the community.\nWe also release an expansion of the FActScore biography dataset to facilitate\nfurther studies of decomposition-based factual precision evaluation.", "published": "2024-07-04 01:51:38", "link": "http://arxiv.org/abs/2407.03572v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and\n  Information Retrieval", "abstract": "Persuasion plays a pivotal role in a wide range of applications from health\nintervention to the promotion of social good. Persuasive chatbots employed\nresponsibly for social good can be an enabler of positive individual and social\nchange. Existing methods rely on fine-tuning persuasive chatbots with\ntask-specific training data which is costly, if not infeasible, to collect.\nFurthermore, they employ only a handful of pre-defined persuasion strategies.\nWe propose PersuaBot, a zero-shot chatbot based on Large Language Models (LLMs)\nthat is factual and more persuasive by leveraging many more nuanced strategies.\nPersuaBot uses an LLM to first generate natural responses, from which the\nstrategies used are extracted. To combat hallucination of LLMs, Persuabot\nreplace any unsubstantiated claims in the response with retrieved facts\nsupporting the extracted strategies. We applied our chatbot, PersuaBot, to\nthree significantly different domains needing persuasion skills: donation\nsolicitation, recommendations, and health intervention. Our experiments on\nsimulated and human conversations show that our zero-shot approach is more\npersuasive than prior work, while achieving factual accuracy surpassing\nstate-of-the-art knowledge-oriented chatbots.", "published": "2024-07-04 02:28:21", "link": "http://arxiv.org/abs/2407.03585v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought Augmentation with Logit Contrast for Enhanced Reasoning\n  in Language Models", "abstract": "Rapidly increasing model scales coupled with steering methods such as\nchain-of-thought prompting have led to drastic improvements in language model\nreasoning. At the same time, models struggle with compositional generalization\nand are far from human performance on many reasoning-based benchmarks.\nLeveraging the success of chain-of-thought prompting, and also taking\ninspiration from context-aware decoding (CAD), we explore input-based\ncontrasting methods to further encourage the type of reasoning induced by\nchain-of-thought prompting. While work remains to stabilize these results\nacross datasets and models, the improvements we find warrant further\ninvestigation into input-based steering methods for context-aware reasoning.", "published": "2024-07-04 03:20:31", "link": "http://arxiv.org/abs/2407.03600v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visualizing Dialogues: Enhancing Image Selection through Dialogue\n  Understanding with Large Language Models", "abstract": "Recent advancements in dialogue systems have highlighted the significance of\nintegrating multimodal responses, which enable conveying ideas through diverse\nmodalities rather than solely relying on text-based interactions. This\nenrichment not only improves overall communicative efficacy but also enhances\nthe quality of conversational experiences. However, existing methods for\ndialogue-to-image retrieval face limitations due to the constraints of\npre-trained vision language models (VLMs) in comprehending complex dialogues\naccurately. To address this, we present a novel approach leveraging the robust\nreasoning capabilities of large language models (LLMs) to generate precise\ndialogue-associated visual descriptors, facilitating seamless connection with\nimages. Extensive experiments conducted on benchmark data validate the\neffectiveness of our proposed approach in deriving concise and accurate visual\ndescriptors, leading to significant enhancements in dialogue-to-image retrieval\nperformance. Furthermore, our findings demonstrate the method's\ngeneralizability across diverse visual cues, various LLMs, and different\ndatasets, underscoring its practicality and potential impact in real-world\napplications.", "published": "2024-07-04 03:50:30", "link": "http://arxiv.org/abs/2407.03615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Mysterious Case of Neuron 1512: Injectable Realignment Architectures\n  Reveal Internal Characteristics of Meta's Llama 2 Model", "abstract": "Large Language Models (LLMs) have an unrivaled and invaluable ability to\n\"align\" their output to a diverse range of human preferences, by mirroring them\nin the text they generate. The internal characteristics of such models,\nhowever, remain largely opaque. This work presents the Injectable Realignment\nModel (IRM) as a novel approach to language model interpretability and\nexplainability. Inspired by earlier work on Neural Programming Interfaces, we\nconstruct and train a small network -- the IRM -- to induce emotion-based\nalignments within a 7B parameter LLM architecture. The IRM outputs are injected\nvia layerwise addition at various points during the LLM's forward pass, thus\nmodulating its behavior without changing the weights of the original model.\nThis isolates the alignment behavior from the complex mechanisms of the\ntransformer model. Analysis of the trained IRM's outputs reveals a curious\npattern. Across more than 24 training runs and multiple alignment datasets,\npatterns of IRM activations align themselves in striations associated with a\nneuron's index within each transformer layer, rather than being associated with\nthe layers themselves. Further, a single neuron index (1512) is strongly\ncorrelated with all tested alignments. This result, although initially\ncounterintuitive, is directly attributable to design choices present within\nalmost all commercially available transformer architectures, and highlights a\npotential weak point in Meta's pretrained Llama 2 models. It also demonstrates\nthe value of the IRM architecture for language model analysis and\ninterpretability. Our code and datasets are available at\nhttps://github.com/DRAGNLabs/injectable-alignment-model", "published": "2024-07-04 04:05:19", "link": "http://arxiv.org/abs/2407.03621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question-Analysis Prompting Improves LLM Performance in Reasoning Tasks", "abstract": "Although LLMs have the potential to transform many fields, they still\nunderperform humans in reasoning tasks. Existing methods induce the model to\nproduce step-by-step calculations, but this research explores the question:\nDoes making the LLM analyze the question improve its performance? We propose a\nnovel prompting strategy called Question Analysis Prompting (QAP), in which the\nmodel is prompted to explain the question in $n$ words before solving. The\nvalue of $n$ influences the length of response generated by the model. QAP is\nevaluated on GPT 3.5 Turbo and GPT 4 Turbo on arithmetic datasets GSM8K, AQuA,\nand SAT and commonsense dataset StrategyQA. QAP is compared with other\nstate-of-the-art prompts including Chain-of-Thought (CoT), Plan and Solve\nPrompting (PS+) and Take A Deep Breath (TADB). QAP outperforms all\nstate-of-the-art prompts on AQuA and SAT datasets on both GPT3.5 and GPT4. QAP\nconsistently ranks among the top-2 prompts on 75\\% of the tests. A key factor\nof QAP performance can be attributed to response length, where detailed\nresponses are beneficial when answering harder questions, but can negatively\naffect easy questions.", "published": "2024-07-04 04:19:50", "link": "http://arxiv.org/abs/2407.03624v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSLR: Document Refinement with Sentence-Level Re-ranking and\n  Reconstruction to Enhance Retrieval-Augmented Generation", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their performance across various Natural Language Processing (NLP)\ntasks. However, LLMs still struggle with generating non-factual responses due\nto limitations in their parametric memory. Retrieval-Augmented Generation (RAG)\nsystems address this issue by incorporating external knowledge with a retrieval\nmodule. Despite their successes, however, current RAG systems face challenges\nwith retrieval failures and the limited ability of LLMs to filter out\nirrelevant information. Therefore, in this work, we propose DSLR (Document\nRefinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised\nframework that decomposes retrieved documents into sentences, filters out\nirrelevant sentences, and reconstructs them again into coherent passages. We\nexperimentally validate DSLR on multiple open-domain QA datasets and the\nresults demonstrate that DSLR significantly enhances the RAG performance over\nconventional fixed-size passage. Furthermore, our DSLR enhances performance in\nspecific, yet realistic scenarios without the need for additional training,\nproviding an effective and efficient solution for refining retrieved documents\nin RAG systems.", "published": "2024-07-04 04:30:04", "link": "http://arxiv.org/abs/2407.03627v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPT-4 vs. Human Translators: A Comprehensive Evaluation of Translation\n  Quality Across Languages, Domains, and Expertise Levels", "abstract": "This study comprehensively evaluates the translation quality of Large\nLanguage Models (LLMs), specifically GPT-4, against human translators of\nvarying expertise levels across multiple language pairs and domains. Through\ncarefully designed annotation rounds, we find that GPT-4 performs comparably to\njunior translators in terms of total errors made but lags behind medium and\nsenior translators. We also observe the imbalanced performance across different\nlanguages and domains, with GPT-4's translation capability gradually weakening\nfrom resource-rich to resource-poor directions. In addition, we qualitatively\nstudy the translation given by GPT-4 and human translators, and find that GPT-4\ntranslator suffers from literal translations, but human translators sometimes\noverthink the background information. To our knowledge, this study is the first\nto evaluate LLMs against human translators and analyze the systematic\ndifferences between their outputs, providing valuable insights into the current\nstate of LLM-based translation and its potential limitations.", "published": "2024-07-04 05:58:04", "link": "http://arxiv.org/abs/2407.03658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M5 -- A Diverse Benchmark to Assess the Performance of Large Multimodal\n  Models Across Multilingual and Multicultural Vision-Language Tasks", "abstract": "Since the release of ChatGPT, the field of Natural Language Processing has\nexperienced rapid advancements, particularly in Large Language Models (LLMs)\nand their multimodal counterparts, Large Multimodal Models (LMMs). Despite\ntheir impressive capabilities, LLMs often exhibit significant performance\ndisparities across different languages and cultural contexts, as demonstrated\nby various text-only benchmarks. However, current research lacks such\nbenchmarks for multimodal visio-linguistic settings. This work fills this gap\nby introducing M5, the first comprehensive benchmark designed to evaluate LMMs\non diverse vision-language tasks within a multilingual and multicultural\ncontext. M5 includes eight datasets covering five tasks and $41$ languages,\nwith a focus on underrepresented languages and culturally diverse images.\nFurthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including a\nnew Visio-Linguistic Outlier Detection task, in which all evaluated open-source\nmodels fail to significantly surpass the random baseline. Through extensive\nevaluation and analyses, we highlight substantial task-agnostic performance\ndisparities between high- and low-resource languages. Moreover, we show that\nlarger models do not necessarily outperform smaller ones in a multilingual\nsetting.", "published": "2024-07-04 09:55:04", "link": "http://arxiv.org/abs/2407.03791v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cognitive Modeling with Scaffolded LLMs: A Case Study of Referential\n  Expression Generation", "abstract": "To what extent can LLMs be used as part of a cognitive model of language\ngeneration? In this paper, we approach this question by exploring a\nneuro-symbolic implementation of an algorithmic cognitive model of referential\nexpression generation by Dale & Reiter (1995). The symbolic task analysis\nimplements the generation as an iterative procedure that scaffolds symbolic and\ngpt-3.5-turbo-based modules. We compare this implementation to an ablated model\nand a one-shot LLM-only baseline on the A3DS dataset (Tsvilodub & Franke,\n2023). We find that our hybrid approach is cognitively plausible and performs\nwell in complex contexts, while allowing for more open-ended modeling of\nlanguage generation in a larger domain.", "published": "2024-07-04 10:28:48", "link": "http://arxiv.org/abs/2407.03805v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConText at WASSA 2024 Empathy and Personality Shared Task:\n  History-Dependent Embedding Utterance Representations for Empathy and Emotion\n  Prediction in Conversations", "abstract": "Empathy and emotion prediction are key components in the development of\neffective and empathetic agents, amongst several other applications. The WASSA\nshared task on empathy and emotion prediction in interactions presents an\nopportunity to benchmark approaches to these tasks. Appropriately selecting and\nrepresenting the historical context is crucial in the modelling of empathy and\nemotion in conversations. In our submissions, we model empathy, emotion\npolarity and emotion intensity of each utterance in a conversation by feeding\nthe utterance to be classified together with its conversational context, i.e.,\na certain number of previous conversational turns, as input to an encoder\nPre-trained Language Model, to which we append a regression head for\nprediction. We also model perceived counterparty empathy of each interlocutor\nby feeding all utterances from the conversation and a token identifying the\ninterlocutor for which we are predicting the empathy. Our system officially\nranked $1^{st}$ at the CONV-turn track and $2^{nd}$ at the CONV-dialog track.", "published": "2024-07-04 10:44:59", "link": "http://arxiv.org/abs/2407.03818v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Benchmarking of LLMs for Open-Domain Dialogue Evaluation", "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities in\nvarious Natural Language Processing tasks. For automatic open-domain dialogue\nevaluation in particular, LLMs have been seamlessly integrated into evaluation\nframeworks, and together with human evaluation, compose the backbone of most\nevaluations. However, existing evaluation benchmarks often rely on outdated\ndatasets and evaluate aspects like Fluency and Relevance, which fail to\nadequately capture the capabilities and limitations of state-of-the-art chatbot\nmodels.\n  This paper critically examines current evaluation benchmarks, highlighting\nthat the use of older response generators and quality aspects fail to\naccurately reflect modern chatbot capabilities. A small annotation experiment\non a recent LLM-generated dataset (SODA) reveals that LLM evaluators such as\nGPT-4 struggle to detect actual deficiencies in dialogues generated by current\nLLM chatbots.", "published": "2024-07-04 11:14:47", "link": "http://arxiv.org/abs/2407.03841v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anthropocentric bias and the possibility of artificial cognition", "abstract": "Evaluating the cognitive capacities of large language models (LLMs) requires\novercoming not only anthropomorphic but also anthropocentric biases. This\narticle identifies two types of anthropocentric bias that have been neglected:\noverlooking how auxiliary factors can impede LLM performance despite competence\n(Type-I), and dismissing LLM mechanistic strategies that differ from those of\nhumans as not genuinely competent (Type-II). Mitigating these biases\nnecessitates an empirically-driven, iterative approach to mapping cognitive\ntasks to LLM-specific capacities and mechanisms, which can be done by\nsupplementing carefully designed behavioral experiments with mechanistic\nstudies.", "published": "2024-07-04 11:44:28", "link": "http://arxiv.org/abs/2407.03859v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TartuNLP @ AXOLOTL-24: Leveraging Classifier Output for New Sense\n  Detection in Lexical Semantics", "abstract": "We present our submission to the AXOLOTL-24 shared task. The shared task\ncomprises two subtasks: identifying new senses that words gain with time (when\ncomparing newer and older time periods) and producing the definitions for the\nidentified new senses. We implemented a conceptually simple and computationally\ninexpensive solution to both subtasks. We trained adapter-based binary\nclassification models to match glosses with usage examples and leveraged the\nprobability output of the models to identify novel senses. The same models were\nused to match examples of novel sense usages with Wiktionary definitions. Our\nsubmission attained third place on the first subtask and the first place on the\nsecond subtask.", "published": "2024-07-04 11:46:39", "link": "http://arxiv.org/abs/2407.03861v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scoping Review of Active Learning Strategies and their Evaluation\n  Environments for Entity Recognition Tasks", "abstract": "We conducted a scoping review for active learning in the domain of natural\nlanguage processing (NLP), which we summarize in accordance with the PRISMA-ScR\nguidelines as follows:\n  Objective: Identify active learning strategies that were proposed for entity\nrecognition and their evaluation environments (datasets, metrics, hardware,\nexecution time). Design: We used Scopus and ACM as our search engines. We\ncompared the results with two literature surveys to assess the search quality.\nWe included peer-reviewed English publications introducing or comparing active\nlearning strategies for entity recognition. Results: We analyzed 62 relevant\npapers and identified 106 active learning strategies. We grouped them into\nthree categories: exploitation-based (60x), exploration-based (14x), and hybrid\nstrategies (32x). We found that all studies used the F1-score as an evaluation\nmetric. Information about hardware (6x) and execution time (13x) was only\noccasionally included. The 62 papers used 57 different datasets to evaluate\ntheir respective strategies. Most datasets contained newspaper articles or\nbiomedical/medical data. Our analysis revealed that 26 out of 57 datasets are\npublicly accessible.\n  Conclusion: Numerous active learning strategies have been identified, along\nwith significant open questions that still need to be addressed. Researchers\nand practitioners face difficulties when making data-driven decisions about\nwhich active learning strategy to adopt. Conducting comprehensive empirical\ncomparisons using the evaluation environment proposed in this study could help\nestablish best practices in the domain.", "published": "2024-07-04 12:40:35", "link": "http://arxiv.org/abs/2407.03895v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity-Level Sentiment: More than the Sum of Its Parts", "abstract": "In sentiment analysis of longer texts, there may be a variety of topics\ndiscussed, of entities mentioned, and of sentiments expressed regarding each\nentity. We find a lack of studies exploring how such texts express their\nsentiment towards each entity of interest, and how these sentiments can be\nmodelled. In order to better understand how sentiment regarding persons and\norganizations (each entity in our scope) is expressed in longer texts, we have\ncollected a dataset of expert annotations where the overall sentiment regarding\neach entity is identified, together with the sentence-level sentiment for these\nentities separately. We show that the reader's perceived sentiment regarding an\nentity often differs from an arithmetic aggregation of sentiments at the\nsentence level. Only 70\\% of the positive and 55\\% of the negative entities\nreceive a correct overall sentiment label when we aggregate the\n(human-annotated) sentiment labels for the sentences where the entity is\nmentioned. Our dataset reveals the complexity of entity-specific sentiment in\nlonger texts, and allows for more precise modelling and evaluation of such\nsentiment expressions.", "published": "2024-07-04 13:21:07", "link": "http://arxiv.org/abs/2407.03916v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TongGu: Mastering Classical Chinese Understanding with\n  Knowledge-Grounded Large Language Models", "abstract": "Classical Chinese is a gateway to the rich heritage and wisdom of ancient\nChina, yet its complexities pose formidable comprehension barriers for most\nmodern people without specialized knowledge. While Large Language Models (LLMs)\nhave shown remarkable capabilities in Natural Language Processing (NLP), they\nstruggle with Classical Chinese Understanding (CCU), especially in\ndata-demanding and knowledge-intensive tasks. In response to this dilemma, we\npropose \\textbf{TongGu} (mean understanding ancient and modern), the first\nCCU-specific LLM, underpinned by three core contributions. First, we construct\na two-stage instruction-tuning dataset ACCN-INS derived from rich classical\nChinese corpora, aiming to unlock the full CCU potential of LLMs. Second, we\npropose Redundancy-Aware Tuning (RAT) to prevent catastrophic forgetting,\nenabling TongGu to acquire new capabilities while preserving its foundational\nknowledge. Third, we present a CCU Retrieval-Augmented Generation (CCU-RAG)\ntechnique to reduce hallucinations based on knowledge-grounding. Extensive\nexperiments across 24 diverse CCU tasks validate TongGu's superior ability,\nunderscoring the effectiveness of RAT and CCU-RAG. The model and dataset are\navailable at \\url{https://github.com/SCUT-DLVCLab/TongGu-LLM}.", "published": "2024-07-04 13:52:23", "link": "http://arxiv.org/abs/2407.03937v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A framework for annotating and modelling intentions behind metaphor use", "abstract": "Metaphors are part of everyday language and shape the way in which we\nconceptualize the world. Moreover, they play a multifaceted role in\ncommunication, making their understanding and generation a challenging task for\nlanguage models (LMs). While there has been extensive work in the literature\nlinking metaphor to the fulfilment of individual intentions, no comprehensive\ntaxonomy of such intentions, suitable for natural language processing (NLP)\napplications, is available to present day. In this paper, we propose a novel\ntaxonomy of intentions commonly attributed to metaphor, which comprises 9\ncategories. We also release the first dataset annotated for intentions behind\nmetaphor use. Finally, we use this dataset to test the capability of large\nlanguage models (LLMs) in inferring the intentions behind metaphor use, in\nzero- and in-context few-shot settings. Our experiments show that this is still\na challenge for LLMs.", "published": "2024-07-04 14:13:57", "link": "http://arxiv.org/abs/2407.03952v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta-prompting Optimized Retrieval-augmented Generation", "abstract": "Retrieval-augmented generation resorts to content retrieved from external\nsources in order to leverage the performance of large language models in\ndownstream tasks. The excessive volume of retrieved content, the possible\ndispersion of its parts, or their out of focus range may happen nevertheless to\neventually have a detrimental rather than an incremental effect. To mitigate\nthis issue and improve retrieval-augmented generation, we propose a method to\nrefine the retrieved content before it is included in the prompt by resorting\nto meta-prompting optimization. Put to empirical test with the demanding\nmulti-hop question answering task from the StrategyQA dataset, the evaluation\nresults indicate that this method outperforms a similar retrieval-augmented\nsystem but without this method by over 30%.", "published": "2024-07-04 14:20:12", "link": "http://arxiv.org/abs/2407.03955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Roleplay: Simulating Human-Chatbot Interaction", "abstract": "The development of chatbots requires collecting a large number of\nhuman-chatbot dialogues to reflect the breadth of users' sociodemographic\nbackgrounds and conversational goals. However, the resource requirements to\nconduct the respective user studies can be prohibitively high and often only\nallow for a narrow analysis of specific dialogue goals and participant\ndemographics. In this paper, we propose LLM Roleplay: a goal-oriented,\npersona-based method to automatically generate diverse multi-turn dialogues\nsimulating human-chatbot interaction. LLM Roleplay can be applied to generate\ndialogues with any type of chatbot and uses large language models (LLMs) to\nplay the role of textually described personas. To validate our method, we\ncollect natural human-chatbot dialogues from different sociodemographic groups\nand conduct a user study to compare these with our generated dialogues. We\nevaluate the capabilities of state-of-the-art LLMs in maintaining a\nconversation during their embodiment of a specific persona and find that our\nmethod can simulate human-chatbot dialogues with a high indistinguishability\nrate.", "published": "2024-07-04 14:49:46", "link": "http://arxiv.org/abs/2407.03974v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Natural Language Counterfactual Generation", "abstract": "Natural language counterfactual generation aims to minimally modify a given\ntext such that the modified text will be classified into a different class. The\ngenerated counterfactuals provide insight into the reasoning behind a model's\npredictions by highlighting which words significantly influence the outcomes.\nAdditionally, they can be used to detect model fairness issues and augment the\ntraining data to enhance the model's robustness. A substantial amount of\nresearch has been conducted to generate counterfactuals for various NLP tasks,\nemploying different models and methodologies. With the rapid growth of studies\nin this field, a systematic review is crucial to guide future researchers and\ndevelopers. To bridge this gap, this survey provides a comprehensive overview\nof textual counterfactual generation methods, particularly those based on Large\nLanguage Models. We propose a new taxonomy that systematically categorizes the\ngeneration methods into four groups and summarizes the metrics for evaluating\nthe generation quality. Finally, we discuss ongoing research challenges and\noutline promising directions for future work.", "published": "2024-07-04 15:13:59", "link": "http://arxiv.org/abs/2407.03993v2", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Exploring Diachronic and Diatopic Changes in Dialect Continua: Tasks,\n  Datasets and Challenges", "abstract": "Everlasting contact between language communities leads to constant changes in\nlanguages over time, and gives rise to language varieties and dialects.\nHowever, the communities speaking non-standard language are often overlooked by\nnon-inclusive NLP technologies. Recently, there has been a surge of interest in\nstudying diatopic and diachronic changes in dialect NLP, but there is currently\nno research exploring the intersection of both. Our work aims to fill this gap\nby systematically reviewing diachronic and diatopic papers from a unified\nperspective. In this work, we critically assess nine tasks and datasets across\nfive dialects from three language families (Slavic, Romance, and Germanic) in\nboth spoken and written modalities. The tasks covered are diverse, including\ncorpus construction, dialect distance estimation, and dialect geolocation\nprediction, among others. Moreover, we outline five open challenges regarding\nchanges in dialect use over time, the reliability of dialect datasets, the\nimportance of speaker characteristics, limited coverage of dialects, and\nethical considerations in data collection. We hope that our work sheds light on\nfuture research towards inclusive computational methods and datasets for\nlanguage varieties and dialects.", "published": "2024-07-04 15:38:38", "link": "http://arxiv.org/abs/2407.04010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMAEL: Large Language Models are Good Context Augmenters for Entity\n  Linking", "abstract": "Entity Linking (EL) models are well-trained at mapping mentions to their\ncorresponding entities according to a given context. However, EL models\nstruggle to disambiguate long-tail entities due to their limited training data.\nMeanwhile, large language models (LLMs) are more robust at interpreting\nuncommon mentions. Yet, due to a lack of specialized training, LLMs suffer at\ngenerating correct entity IDs. Furthermore, training an LLM to perform EL is\ncost-intensive. Building upon these insights, we introduce LLM-Augmented Entity\nLinking LLMAEL, a plug-and-play approach to enhance entity linking through LLM\ndata augmentation. We leverage LLMs as knowledgeable context augmenters,\ngenerating mention-centered descriptions as additional input, while preserving\ntraditional EL models for task specific processing. Experiments on 6 standard\ndatasets show that the vanilla LLMAEL outperforms baseline EL models in most\ncases, while the fine-tuned LLMAEL set the new state-of-the-art results across\nall 6 benchmarks.", "published": "2024-07-04 15:55:13", "link": "http://arxiv.org/abs/2407.04020v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematic Task Exploration with LLMs: A Study in Citation Text\n  Generation", "abstract": "Large language models (LLMs) bring unprecedented flexibility in defining and\nexecuting complex, creative natural language generation (NLG) tasks. Yet, this\nflexibility brings new challenges, as it introduces new degrees of freedom in\nformulating the task inputs and instructions and in evaluating model\nperformance. To facilitate the exploration of creative NLG tasks, we propose a\nthree-component research framework that consists of systematic input\nmanipulation, reference data, and output measurement. We use this framework to\nexplore citation text generation -- a popular scholarly NLP task that lacks\nconsensus on the task definition and evaluation metric and has not yet been\ntackled within the LLM paradigm. Our results highlight the importance of\nsystematically investigating both task instruction and input configuration when\nprompting LLMs, and reveal non-trivial relationships between different\nevaluation metrics used for citation text generation. Additional human\ngeneration and human evaluation experiments provide new qualitative insights\ninto the task to guide future research in citation text generation. We make our\ncode and data publicly available.", "published": "2024-07-04 16:41:08", "link": "http://arxiv.org/abs/2407.04046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Graphs for Syntactic Simplification: A Revisit from the Age of\n  LLM", "abstract": "Symbolic sentence meaning representations, such as AMR (Abstract Meaning\nRepresentation) provide expressive and structured semantic graphs that act as\nintermediates that simplify downstream NLP tasks. However, the\ninstruction-following capability of large language models (LLMs) offers a\nshortcut to effectively solve NLP tasks, questioning the utility of semantic\ngraphs. Meanwhile, recent work has also shown the difficulty of using meaning\nrepresentations merely as a helpful auxiliary for LLMs. We revisit the position\nof semantic graphs in syntactic simplification, the task of simplifying\nsentence structures while preserving their meaning, which requires semantic\nunderstanding, and evaluate it on a new complex and natural dataset. The\nAMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art\nmeaning representations can lead to easy-to-implement simplification methods\nwith competitive performance and unique advantages in cost, interpretability,\nand generalization. With AMRS$^3$ as an anchor, we discover that syntactic\nsimplification is a task where semantic graphs are helpful in LLM prompting. We\npropose AMRCoC prompting that guides LLMs to emulate graph algorithms for\nexplicit symbolic reasoning on AMR graphs, and show its potential for improving\nLLM on semantic-centered tasks like syntactic simplification.", "published": "2024-07-04 17:13:38", "link": "http://arxiv.org/abs/2407.04067v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AXOLOTL'24 Shared Task on Multilingual Explainable Semantic Change\n  Modeling", "abstract": "This paper describes the organization and findings of AXOLOTL'24, the first\nmultilingual explainable semantic change modeling shared task. We present new\nsense-annotated diachronic semantic change datasets for Finnish and Russian\nwhich were employed in the shared task, along with a surprise test-only German\ndataset borrowed from an existing source. The setup of AXOLOTL'24 is new to the\nsemantic change modeling field, and involves subtasks of identifying unknown\n(novel) senses and providing dictionary-like definitions to these senses. The\nmethods of the winning teams are described and compared, thus paving a path\ntowards explainability in computational approaches to historical change of\nmeaning.", "published": "2024-07-04 17:41:32", "link": "http://arxiv.org/abs/2407.04079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in\n  Social Conversations", "abstract": "In the rapidly evolving field of natural language processing, dialogue\nsystems primarily employ a single-step dialogue paradigm. Although this\nparadigm is efficient, it lacks the depth and fluidity of human interactions\nand does not appear natural. We introduce a novel \\textbf{Step}-by-Step\nDialogue Paradigm (Stephanie), designed to mimic the ongoing dynamic nature of\nhuman conversations. By employing a dual learning strategy and a further-split\npost-editing method, we generated and utilized a high-quality step-by-step\ndialogue dataset to fine-tune existing large language models, enabling them to\nperform step-by-step dialogues. We thoroughly present Stephanie. Tailored\nautomatic and human evaluations are conducted to assess its effectiveness\ncompared to the traditional single-step dialogue paradigm. We will release\ncode, Stephanie datasets, and Stephanie LLMs to facilitate the future of\nchatbot eras.", "published": "2024-07-04 17:59:41", "link": "http://arxiv.org/abs/2407.04093v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Automating Text Annotation: A Case Study on Semantic Proximity\n  Annotation using GPT-4", "abstract": "This paper explores using GPT-3.5 and GPT-4 to automate the data annotation\nprocess with automatic prompting techniques. The main aim of this paper is to\nreuse human annotation guidelines along with some annotated data to design\nautomatic prompts for LLMs, focusing on the semantic proximity annotation task.\nAutomatic prompts are compared to customized prompts. We further implement the\nprompting strategies into an open-source text annotation tool, enabling easy\nonline use via the OpenAI API. Our study reveals the crucial role of accurate\nprompt design and suggests that prompting GPT-4 with human-like instructions is\nnot straightforwardly possible for the semantic proximity task. We show that\nsmall modifications to the human guidelines already improve the performance,\nsuggesting possible ways for future research.", "published": "2024-07-04 19:16:44", "link": "http://arxiv.org/abs/2407.04130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELCC: the Emergent Language Corpus Collection", "abstract": "We introduce the Emergent Language Corpus Collection (ELCC): a collection of\ncorpora generated from open source implementations of emergent communication\nsystems across the literature. These systems include a variety of signalling\ngame environments as well as more complex environments like a social deduction\ngame and embodied navigation. Each corpus is annotated with metadata describing\nthe characteristics of the source system as well as a suite of analyses of the\ncorpus (e.g., size, entropy, average message length, performance as transfer\nlearning data). Currently, research studying emergent languages requires\ndirectly running different systems which takes time away from actual analyses\nof such languages, makes studies which compare diverse emergent languages rare,\nand presents a barrier to entry for researchers without a background in deep\nlearning. The availability of a substantial collection of well-documented\nemergent language corpora, then, will enable research which can analyze a wider\nvariety of emergent languages, which more effectively uncovers general\nprinciples in emergent communication rather than artifacts of particular\nenvironments. We provide some quantitative and qualitative analyses with ELCC\nto demonstrate potential use cases of the resource in this vein.", "published": "2024-07-04 21:23:18", "link": "http://arxiv.org/abs/2407.04158v2", "categories": ["cs.CL", "I.2.7; I.6.m"], "primary_category": "cs.CL"}
{"title": "Defense Against Syntactic Textual Backdoor Attacks with Token\n  Substitution", "abstract": "Textual backdoor attacks present a substantial security risk to Large\nLanguage Models (LLM). It embeds carefully chosen triggers into a victim model\nat the training stage, and makes the model erroneously predict inputs\ncontaining the same triggers as a certain class. Prior backdoor defense methods\nprimarily target special token-based triggers, leaving syntax-based triggers\ninsufficiently addressed. To fill this gap, this paper proposes a novel online\ndefense algorithm that effectively counters syntax-based as well as special\ntoken-based backdoor attacks. The algorithm replaces semantically meaningful\nwords in sentences with entirely different ones but preserves the syntactic\ntemplates or special tokens, and then compares the predicted labels before and\nafter the substitution to determine whether a sentence contains triggers.\nExperimental results confirm the algorithm's performance against these two\ntypes of triggers, offering a comprehensive defense strategy for model\nintegrity.", "published": "2024-07-04 22:48:57", "link": "http://arxiv.org/abs/2407.04179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HAF-RM: A Hybrid Alignment Framework for Reward Model Training", "abstract": "The reward model has become increasingly important in alignment, assessment,\nand data construction for large language models (LLMs). Most existing\nresearchers focus on enhancing reward models through data improvements,\nfollowing the conventional training framework for reward models that directly\noptimizes the predicted rewards. In this paper, we propose a hybrid alignment\nframework HaF-RM for reward model training by introducing an additional\nconstraint on token-level policy probabilities in addition to the reward score.\nIt can simultaneously supervise the internal preference model at the token\nlevel and optimize the mapping layer of the reward model at the sequence level.\nExperiment results on five datasets sufficiently show the validity and\neffectiveness of our proposed hybrid framework for training a high-quality\nreward model. By decoupling the reward modeling procedure and incorporating\nhybrid supervision, our HaF-RM framework offers a principled and effective\napproach to enhancing the performance and alignment of reward models, a\ncritical component in the responsible development of powerful language models.\nWe release our code at https://haf-rm.github.io.", "published": "2024-07-04 23:26:56", "link": "http://arxiv.org/abs/2407.04185v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Randomness in Large Language Models: A Linear Congruential\n  Generator Approach for Generating Clinically Relevant Content", "abstract": "Generating diverse, high-quality outputs from language models is crucial for\napplications in education and content creation. Achieving true randomness and\navoiding repetition remains a significant challenge. This study uses the Linear\nCongruential Generator method for systematic fact selection, combined with\nAI-powered content generation. We ensured unique combinations of\ngastrointestinal physiology and pathology facts across multiple rounds,\nintegrating these facts into prompts for GPT-4o to create clinically relevant,\nvignette-style outputs. Over 14 rounds, 98 unique outputs were generated,\ndemonstrating LCG's effectiveness in producing diverse and high-quality\ncontent. This method addresses key issues of randomness and repetition,\nenhancing the quality and efficiency of language model-generated content for\nvarious applications.", "published": "2024-07-04 02:21:47", "link": "http://arxiv.org/abs/2407.03582v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lateralization LoRA: Interleaved Instruction Tuning with\n  Modality-Specialized Adaptations", "abstract": "Recent advancements in Vision-Language Models (VLMs) have led to the\ndevelopment of Vision-Language Generalists (VLGs) capable of understanding and\ngenerating interleaved images and text. Despite these advances, VLGs still\nstruggle to follow user instructions for interleaved text and image generation.\nTo address this issue, we introduce LeafInstruct, the first open-sourced\ninterleaved instruction tuning data with over 30,000 high-quality instances\nacross more than 10 domains. Due to the extensive size of existing VLGs, we opt\nfor parameter-efficient tuning. However, we observe that VLGs tuned with a\nstandard LoRA typically exhibit inferior performance in interleaved text-image\ngeneration. We attribute this problem to modality interference and the lack of\nmodality-specialized adaptation design. Hence, we propose Lateralization LoRA,\na novel modality-specialized adaptation method inspired by the concept of brain\nlateralization. Lateralization LoRA employs a hybrid approach, combining the\ntraditional linear LoRA and a Convolutional LoRA for generating text and\nimages, enabling the generation of high-quality text and images by leveraging\nmodality-specific structures and parameter sets. We perform instruction tuning\nof the VLG (i.e., EMU2) using Lateralization LoRA on the LeafInstruct dataset.\nExtensive experiments demonstrate that EMU2 tuned with Lateralization LoRA\nachieve state-of-the-art performance, significantly surpassing baseline models\nin complex interleaved tasks.", "published": "2024-07-04 03:28:22", "link": "http://arxiv.org/abs/2407.03604v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "BM25S: Orders of magnitude faster lexical search via eager sparse\n  scoring", "abstract": "We introduce BM25S, an efficient Python-based implementation of BM25 that\nonly depends on Numpy and Scipy. BM25S achieves up to a 500x speedup compared\nto the most popular Python-based framework by eagerly computing BM25 scores\nduring indexing and storing them into sparse matrices. It also achieves\nconsiderable speedups compared to highly optimized Java-based implementations,\nwhich are used by popular commercial products. Finally, BM25S reproduces the\nexact implementation of five BM25 variants based on Kamphuis et al. (2020) by\nextending eager scoring to non-sparse variants using a novel score shifting\nmethod. The code can be found at https://github.com/xhluca/bm25s", "published": "2024-07-04 04:01:05", "link": "http://arxiv.org/abs/2407.03618v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "QET: Enhancing Quantized LLM Parameters and KV cache Compression through\n  Element Substitution and Residual Clustering", "abstract": "The matrix quantization entails representing matrix elements in a more\nspace-efficient form to reduce storage usage, with dequantization restoring the\noriginal matrix for use. We formulate the Quantization Error Minimization (QEM)\nproblem as minimizing the distance between a matrix before and after\nquantization, under the condition that the quantized matrix occupies the same\nmemory space. Matrix quantization is crucial in various applications, including\nLarge Language Models (LLMs) weight quantization, vector databases, KV cache\nquantization, graph compression, and image compression. Recent advancements in\nLLMs, such as GPT-4 and BERT, have highlighted the importance of matrix\ncompression due to the large size of parameters and KV cache, which are stored\nas matrices.\n  We propose Quantum Entanglement Trees (QET) to address the QEM problem by\nleveraging the local orderliness of matrix elements, involving iterative\nelement swapping to form a locally ordered matrix. This matrix is then grouped\nand quantized by columns. To enhance QET, we introduce two optimizations:\nfurther quantizing residuals to reduce MSE, and using masking and batch\nprocessing to accelerate the algorithm.\n  Experimental results demonstrate that QET can effectively reduce MSE to\n5.05%, 13.33%, and 11.89% of the current best method on the LLM dataset, K\ncache, and V cache, respectively. Our contributions include the abstraction of\nthe QEM problem, the design of the QET algorithm, and the proposal of two\noptimizations to improve accuracy and speed.", "published": "2024-07-04 05:13:58", "link": "http://arxiv.org/abs/2407.03637v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Differentiating between human-written and AI-generated texts using\n  linguistic features automatically extracted from an online computational tool", "abstract": "While extensive research has focused on ChatGPT in recent years, very few\nstudies have systematically quantified and compared linguistic features between\nhuman-written and Artificial Intelligence (AI)-generated language. This study\naims to investigate how various linguistic components are represented in both\ntypes of texts, assessing the ability of AI to emulate human writing. Using\nhuman-authored essays as a benchmark, we prompted ChatGPT to generate essays of\nequivalent length. These texts were analyzed using Open Brain AI, an online\ncomputational tool, to extract measures of phonological, morphological,\nsyntactic, and lexical constituents. Despite AI-generated texts appearing to\nmimic human speech, the results revealed significant differences across\nmultiple linguistic features such as consonants, word stress, nouns, verbs,\npronouns, direct objects, prepositional modifiers, and use of difficult words\namong others. These findings underscore the importance of integrating automated\ntools for efficient language assessment, reducing time and effort in data\nanalysis. Moreover, they emphasize the necessity for enhanced training\nmethodologies to improve the capacity of AI for producing more human-like text.", "published": "2024-07-04 05:37:09", "link": "http://arxiv.org/abs/2407.03646v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Language Model Context Windows: A \"Working Memory\" Test and\n  Inference-time Correction", "abstract": "Large language models are prominently used in real-world applications, often\ntasked with reasoning over large volumes of documents. An exciting development\nin this space is models boasting extended context capabilities, with some\naccommodating over 2 million tokens. Such long context model capabilities\nremain uncertain in production systems, motivating the need to benchmark their\nperformance on real world use cases. We address this challenge by proposing\nSWiM, an evaluation framework that addresses the limitations of standard tests.\nTesting the framework on eight long context models, we find that even strong\nmodels such as GPT-4 and Claude 3 Opus degrade in performance when information\nis present in the middle of the context window (lost-in-the-middle effect).\nNext, in addition to our benchmark, we propose medoid voting, a simple, but\neffective training-free approach that helps alleviate this effect, by\ngenerating responses a few times, each time randomly permuting documents in the\ncontext, and selecting the medoid answer. We evaluate medoid voting on single\ndocument QA tasks, achieving up to a 24% lift in accuracy. Our code is\navailable at https://github.com/snorkel-ai/long-context-eval.", "published": "2024-07-04 05:46:20", "link": "http://arxiv.org/abs/2407.03651v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Self Consistency in LLMs through Probabilistic Tokenization", "abstract": "Prior research has demonstrated noticeable performance gains through the use\nof probabilistic tokenizations, an approach that involves employing multiple\ntokenizations of the same input string during the training phase of a language\nmodel. Despite these promising findings, modern large language models (LLMs)\nhave yet to be trained using probabilistic tokenizations. Interestingly, while\nthe tokenizers of these contemporary LLMs have the capability to generate\nmultiple tokenizations, this property remains underutilized.\n  In this work, we propose a novel method to leverage the multiple tokenization\ncapabilities of modern LLM tokenizers, aiming to enhance the self-consistency\nof LLMs in reasoning tasks. Our experiments indicate that when utilizing\nprobabilistic tokenizations, LLMs generate logically diverse reasoning paths,\nmoving beyond mere surface-level linguistic diversity.We carefully study\nprobabilistic tokenization and offer insights to explain the self consistency\nimprovements it brings through extensive experimentation on 5 LLM families and\n4 reasoning benchmarks.", "published": "2024-07-04 06:52:48", "link": "http://arxiv.org/abs/2407.03678v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for\n  Complex Reasoning in Multi-Hop Question Answering", "abstract": "Multi-hop question answering (MHQA) requires a model to retrieve and\nintegrate information from multiple passages to answer a complex question.\nRecent systems leverage the power of large language models and integrate\nevidence retrieval with reasoning prompts (e.g., chain-of-thought reasoning)\nfor the MHQA task. However, the complexities in the question types (bridge v.s.\ncomparison questions) and the reasoning types (sequential v.s. parallel\nreasonings) require more novel and fine-grained prompting methods to enhance\nthe performance of MHQA under the zero-shot setting. In this paper, we propose\nSTOC-TOT, a stochastic tree-of-thought reasoning prompting method with\nconstrained decoding for MHQA and conduct a detailed comparison with other\nreasoning prompts on different question types and reasoning types.\nSpecifically, we construct a tree-like reasoning structure by prompting the\nmodel to break down the original question into smaller sub-questions to form\ndifferent reasoning paths. In addition, we prompt the model to provide a\nprobability estimation for each reasoning path at each reasoning step. At\nanswer time, we conduct constrained decoding on the model to generate more\ngrounded answers and reduce hallucination. Experiments comparing STOC-TOT with\ntwo MHQA datasets and five large language models showed that our framework\noutperforms other reasoning prompts by a significant margin.", "published": "2024-07-04 07:17:53", "link": "http://arxiv.org/abs/2407.03687v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Query-oriented Data Augmentation for Session Search", "abstract": "Modeling contextual information in a search session has drawn more and more\nattention when understanding complex user intents. Recent methods are all\ndata-driven, i.e., they train different models on large-scale search log data\nto identify the relevance between search contexts and candidate documents. The\ncommon training paradigm is to pair the search context with different candidate\ndocuments and train the model to rank the clicked documents higher than the\nunclicked ones. However, this paradigm neglects the symmetric nature of the\nrelevance between the session context and document, i.e., the clicked documents\ncan also be paired with different search contexts when training. In this work,\nwe propose query-oriented data augmentation to enrich search logs and empower\nthe modeling. We generate supplemental training pairs by altering the most\nimportant part of a search context, i.e., the current query, and train our\nmodel to rank the generated sequence along with the original sequence. This\napproach enables models to learn that the relevance of a document may vary as\nthe session context changes, leading to a better understanding of users' search\npatterns. We develop several strategies to alter the current query, resulting\nin new training data with varying degrees of difficulty. Through\nexperimentation on two extensive public search logs, we have successfully\ndemonstrated the effectiveness of our model.", "published": "2024-07-04 08:08:33", "link": "http://arxiv.org/abs/2407.03720v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Argument Mining in Data Scarce Settings: Cross-lingual Transfer and\n  Few-shot Techniques", "abstract": "Recent research on sequence labelling has been exploring different strategies\nto mitigate the lack of manually annotated data for the large majority of the\nworld languages. Among others, the most successful approaches have been based\non (i) the cross-lingual transfer capabilities of multilingual pre-trained\nlanguage models (model-transfer), (ii) data translation and label projection\n(data-transfer) and (iii), prompt-based learning by reusing the mask objective\nto exploit the few-shot capabilities of pre-trained language models (few-shot).\nPrevious work seems to conclude that model-transfer outperforms data-transfer\nmethods and that few-shot techniques based on prompting are superior to\nupdating the model's weights via fine-tuning. In this paper, we empirically\ndemonstrate that, for Argument Mining, a sequence labelling task which requires\nthe detection of long and complex discourse structures, previous insights on\ncross-lingual transfer or few-shot learning do not apply. Contrary to previous\nwork, we show that for Argument Mining data transfer obtains better results\nthan model-transfer and that fine-tuning outperforms few-shot methods.\nRegarding the former, the domain of the dataset used for data-transfer seems to\nbe a deciding factor, while, for few-shot, the type of task (length and\ncomplexity of the sequence spans) and sampling method prove to be crucial.", "published": "2024-07-04 08:59:17", "link": "http://arxiv.org/abs/2407.03748v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HYBRINFOX at CheckThat! 2024 -- Task 2: Enriching BERT Models with the\n  Expert System VAGO for Subjectivity Detection", "abstract": "This paper presents the HYBRINFOX method used to solve Task 2 of Subjectivity\ndetection of the CLEF 2024 CheckThat! competition. The specificity of the\nmethod is to use a hybrid system, combining a RoBERTa model, fine-tuned for\nsubjectivity detection, a frozen sentence-BERT (sBERT) model to capture\nsemantics, and several scores calculated by the English version of the expert\nsystem VAGO, developed independently of this task to measure vagueness and\nsubjectivity in texts based on the lexicon. In English, the HYBRINFOX method\nranked 1st with a macro F1 score of 0.7442 on the evaluation data. For the\nother languages, the method used a translation step into English, producing\nmore mixed results (ranking 1st in Multilingual and 2nd in Italian over the\nbaseline, but under the baseline in Bulgarian, German, and Arabic). We explain\nthe principles of our hybrid approach, and outline ways in which the method\ncould be improved for other languages besides English.", "published": "2024-07-04 09:29:19", "link": "http://arxiv.org/abs/2407.03770v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Functional Faithfulness in the Wild: Circuit Discovery with\n  Differentiable Computation Graph Pruning", "abstract": "In this paper, we introduce a comprehensive reformulation of the task known\nas Circuit Discovery, along with DiscoGP, a novel and effective algorithm based\non differentiable masking for discovering circuits. Circuit discovery is the\ntask of interpreting the computational mechanisms of language models (LMs) by\ndissecting their functions and capabilities into sparse subnetworks (circuits).\nWe identified two major limitations in existing circuit discovery efforts: (1)\na dichotomy between weight-based and connection-edge-based approaches forces\nresearchers to choose between pruning connections or weights, thereby limiting\nthe scope of mechanistic interpretation of LMs; (2) algorithms based on\nactivation patching tend to identify circuits that are neither functionally\nfaithful nor complete. The performance of these identified circuits is\nsubstantially reduced, often resulting in near-random performance in isolation.\nFurthermore, the complement of the circuit -- i.e., the original LM with the\nidentified circuit removed -- still retains adequate performance, indicating\nthat essential components of a complete circuits are missed by existing\nmethods.\n  DiscoGP successfully addresses the two aforementioned issues and demonstrates\nstate-of-the-art faithfulness, completeness, and sparsity. The effectiveness of\nthe algorithm and its novel structure open up new avenues of gathering new\ninsights into the internal workings of generative AI.", "published": "2024-07-04 09:42:25", "link": "http://arxiv.org/abs/2407.03779v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MAMA: Meta-optimized Angular Margin Contrastive Framework for\n  Video-Language Representation Learning", "abstract": "Data quality stands at the forefront of deciding the effectiveness of\nvideo-language representation learning. However, video-text pairs in previous\ndata typically do not align perfectly with each other, which might lead to\nvideo-language representations that do not accurately reflect cross-modal\nsemantics. Moreover, previous data also possess an uneven distribution of\nconcepts, thereby hampering the downstream performance across unpopular\nsubjects. To address these problems, we propose MAMA, a new approach to\nlearning video-language representations by utilizing a contrastive objective\nwith a subtractive angular margin to regularize cross-modal representations in\ntheir effort to reach perfect similarity. Furthermore, to adapt to the\nnon-uniform concept distribution, MAMA utilizes a multi-layer perceptron\n(MLP)-parameterized weighting function that maps loss values to sample weights\nwhich enable dynamic adjustment of the model's focus throughout the training.\nWith the training guided by a small amount of unbiased meta-data and augmented\nby video-text data generated by large vision-language model, MAMA improves\nvideo-language representations and achieve superior performances on commonly\nused video question answering and text-video retrieval datasets. The code,\nmodel, and data have been made available at\nhttps://nguyentthong.github.io/MAMA.", "published": "2024-07-04 09:52:17", "link": "http://arxiv.org/abs/2407.03788v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Finetuning End-to-End Models for Estonian Conversational Spoken Language\n  Translation", "abstract": "This paper investigates the finetuning of end-to-end models for bidirectional\nEstonian-English and Estonian-Russian conversational speech-to-text\ntranslation. Due to the limited availability of speech translation data for\nEstonian, we created additional training data by web scraping and synthesizing\ndata from speech recognition datasets using machine translation. We evaluated\nthree publicly available end-to-end models: Whisper, OWSM 3.1, and SeamlessM4T.\nOur results indicate that fine-tuning with synthetic data enhances translation\naccuracy by a large margin, with SeamlessM4T matching or surpassing cascaded\nspeech translation systems that use state-of-the-art speech recognition and\nmachine translation models.", "published": "2024-07-04 10:33:12", "link": "http://arxiv.org/abs/2407.03809v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "HYBRINFOX at CheckThat! 2024 -- Task 1: Enhancing Language Models with\n  Structured Information for Check-Worthiness Estimation", "abstract": "This paper summarizes the experiments and results of the HYBRINFOX team for\nthe CheckThat! 2024 - Task 1 competition. We propose an approach enriching\nLanguage Models such as RoBERTa with embeddings produced by triples (subject ;\npredicate ; object) extracted from the text sentences. Our analysis of the\ndevelopmental data shows that this method improves the performance of Language\nModels alone. On the evaluation data, its best performance was in English,\nwhere it achieved an F1 score of 71.1 and ranked 12th out of 27 candidates. On\nthe other languages (Dutch and Arabic), it obtained more mixed results. Future\nresearch tracks are identified toward adapting this processing pipeline to more\nrecent Large Language Models.", "published": "2024-07-04 11:33:54", "link": "http://arxiv.org/abs/2407.03850v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Progressive Red Teaming", "abstract": "Ensuring the safety of large language models (LLMs) is paramount, yet\nidentifying potential vulnerabilities is challenging. While manual red teaming\nis effective, it is time-consuming, costly and lacks scalability. Automated red\nteaming (ART) offers a more cost-effective alternative, automatically\ngenerating adversarial prompts to expose LLM vulnerabilities. However, in\ncurrent ART efforts, a robust framework is absent, which explicitly frames red\nteaming as an effectively learnable task. To address this gap, we propose\nAutomated Progressive Red Teaming (APRT) as an effectively learnable framework.\nAPRT leverages three core modules: an Intention Expanding LLM that generates\ndiverse initial attack samples, an Intention Hiding LLM that crafts deceptive\nprompts, and an Evil Maker to manage prompt diversity and filter ineffective\nsamples. The three modules collectively and progressively explore and exploit\nLLM vulnerabilities through multi-round interactions. In addition to the\nframework, we further propose a novel indicator, Attack Effectiveness Rate\n(AER) to mitigate the limitations of existing evaluation metrics. By measuring\nthe likelihood of eliciting unsafe but seemingly helpful responses, AER aligns\nclosely with human evaluations. Extensive experiments with both automatic and\nhuman evaluations, demonstrate the effectiveness of ARPT across both open- and\nclosed-source LLMs. Specifically, APRT effectively elicits 54% unsafe yet\nuseful responses from Meta's Llama-3-8B-Instruct, 50% from GPT-4o (API access),\nand 39% from Claude-3.5 (API access), showcasing its robust attack capability\nand transferability across LLMs (especially from open-source LLMs to\nclosed-source LLMs).", "published": "2024-07-04 12:14:27", "link": "http://arxiv.org/abs/2407.03876v3", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM\n  Dialogue Agents", "abstract": "Dialogue agents powered by Large Language Models (LLMs) show superior\nperformance in various tasks. Despite the better user understanding and\nhuman-like responses, their lack of controllability remains a key challenge,\noften leading to unfocused conversations or task failure. To address this, we\nintroduce Standard Operating Procedure (SOP) to regulate dialogue flow.\nSpecifically, we propose ChatSOP, a novel SOP-guided Monte Carlo Tree Search\n(MCTS) planning framework designed to enhance the controllability of LLM-driven\ndialogue agents. To enable this, we curate a dataset comprising SOP-annotated\nmulti-scenario dialogues, generated using a semi-automated role-playing system\nwith GPT-4o and validated through strict manual quality control. Additionally,\nwe propose a novel method that integrates Chain of Thought reasoning with\nsupervised fine-tuning for SOP prediction and utilizes SOP-guided Monte Carlo\nTree Search for optimal action planning during dialogues. Experimental results\ndemonstrate the effectiveness of our method, such as achieving a 27.95%\nimprovement in action accuracy compared to baseline models based on GPT-3.5 and\nalso showing notable gains for open-source models. Dataset and codes are\npublicly available.", "published": "2024-07-04 12:23:02", "link": "http://arxiv.org/abs/2407.03884v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems", "abstract": "Prior research has enhanced the ability of Large Language Models (LLMs) to\nsolve logic puzzles using techniques such as chain-of-thought prompting or\nintroducing a symbolic representation. These frameworks are still usually\ninsufficient to solve complicated logical problems, such as Zebra puzzles, due\nto the inherent complexity of translating natural language clues into logical\nstatements. We introduce a multi-agent system, ZPS, that integrates LLMs with\nan off the shelf theorem prover. This system tackles the complex puzzle-solving\ntask by breaking down the problem into smaller, manageable parts, generating\nSMT (Satisfiability Modulo Theories) code to solve them with a theorem prover,\nand using feedback between the agents to repeatedly improve their answers. We\nalso introduce an automated grid puzzle grader to assess the correctness of our\npuzzle solutions and show that the automated grader is reliable by evaluating\nit in a user-study. Our approach shows improvement in all three LLMs we tested,\nwith GPT-4 showing 166% improvement in the number of fully correct solutions.", "published": "2024-07-04 14:22:25", "link": "http://arxiv.org/abs/2407.03956v2", "categories": ["cs.MA", "cs.CL", "68T01, 68T20, 68T27,", "I.2.3; I.2.6; I.2.7; I.2.11"], "primary_category": "cs.MA"}
{"title": "Stark: Social Long-Term Multi-Modal Conversation with Persona\n  Commonsense Knowledge", "abstract": "Humans share a wide variety of images related to their personal experiences\nwithin conversations via instant messaging tools. However, existing works focus\non (1) image-sharing behavior in singular sessions, leading to limited\nlong-term social interaction, and (2) a lack of personalized image-sharing\nbehavior. In this work, we introduce Stark, a large-scale long-term multi-modal\nconversation dataset that covers a wide range of social personas in a\nmulti-modality format, time intervals, and images. To construct Stark\nautomatically, we propose a novel multi-modal contextualization framework, Mcu,\nthat generates long-term multi-modal dialogue distilled from ChatGPT and our\nproposed Plan-and-Execute image aligner. Using our Stark, we train a\nmulti-modal conversation model, Ultron 7B, which demonstrates impressive visual\nimagination ability. Furthermore, we demonstrate the effectiveness of our\ndataset in human evaluation. We make our source code and dataset publicly\navailable.", "published": "2024-07-04 14:26:49", "link": "http://arxiv.org/abs/2407.03958v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LLM-jp: A Cross-organizational Project for the Research and Development\n  of Fully Open Japanese LLMs", "abstract": "This paper introduces LLM-jp, a cross-organizational project for the research\nand development of Japanese large language models (LLMs). LLM-jp aims to\ndevelop open-source and strong Japanese LLMs, and as of this writing, more than\n1,500 participants from academia and industry are working together for this\npurpose. This paper presents the background of the establishment of LLM-jp,\nsummaries of its activities, and technical reports on the LLMs developed by\nLLM-jp. For the latest activities, visit https://llm-jp.nii.ac.jp/en/.", "published": "2024-07-04 14:33:03", "link": "http://arxiv.org/abs/2407.03963v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Sample Efficiency of Reinforcement Learning with Background\n  Knowledge from Large Language Models", "abstract": "Low sample efficiency is an enduring challenge of reinforcement learning\n(RL). With the advent of versatile large language models (LLMs), recent works\nimpart common-sense knowledge to accelerate policy learning for RL processes.\nHowever, we note that such guidance is often tailored for one specific task but\nloses generalizability. In this paper, we introduce a framework that harnesses\nLLMs to extract background knowledge of an environment, which contains general\nunderstandings of the entire environment, making various downstream RL tasks\nbenefit from one-time knowledge representation. We ground LLMs by feeding a few\npre-collected experiences and requesting them to delineate background knowledge\nof the environment. Afterward, we represent the output knowledge as potential\nfunctions for potential-based reward shaping, which has a good property for\nmaintaining policy optimality from task rewards. We instantiate three variants\nto prompt LLMs for background knowledge, including writing code, annotating\npreferences, and assigning goals. Our experiments show that these methods\nachieve significant sample efficiency improvements in a spectrum of downstream\ntasks from Minigrid and Crafter domains.", "published": "2024-07-04 14:33:47", "link": "http://arxiv.org/abs/2407.03964v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Benchmarking Complex Instruction-Following with Multiple Constraints\n  Composition", "abstract": "Instruction following is one of the fundamental capabilities of large\nlanguage models (LLMs). As the ability of LLMs is constantly improving, they\nhave been increasingly applied to deal with complex human instructions in\nreal-world scenarios. Therefore, how to evaluate the ability of complex\ninstruction-following of LLMs has become a critical research problem. Existing\nbenchmarks mainly focus on modeling different types of constraints in human\ninstructions while neglecting the composition of different constraints, which\nis an indispensable constituent in complex instructions. To this end, we\npropose ComplexBench, a benchmark for comprehensively evaluating the ability of\nLLMs to follow complex instructions composed of multiple constraints. We\npropose a hierarchical taxonomy for complex instructions, including 4\nconstraint types, 19 constraint dimensions, and 4 composition types, and\nmanually collect a high-quality dataset accordingly. To make the evaluation\nreliable, we augment LLM-based evaluators with rules to effectively verify\nwhether generated texts can satisfy each constraint and composition.\nFurthermore, we obtain the final evaluation score based on the dependency\nstructure determined by different composition types. ComplexBench identifies\nsignificant deficiencies in existing LLMs when dealing with complex\ninstructions with multiple constraints composition.", "published": "2024-07-04 14:50:45", "link": "http://arxiv.org/abs/2407.03978v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unlocking the Potential of Model Merging for Low-Resource Languages", "abstract": "Adapting large language models (LLMs) to new languages typically involves\ncontinual pre-training (CT) followed by supervised fine-tuning (SFT). However,\nthis CT-then-SFT approach struggles with limited data in the context of\nlow-resource languages, failing to balance language modeling and task-solving\ncapabilities. We thus propose model merging as an alternative for low-resource\nlanguages, combining models with distinct capabilities into a single model\nwithout additional training. We use model merging to develop task-solving LLMs\nfor low-resource languages without SFT data in the target languages. Our\nexperiments based on Llama-2-7B demonstrate that model merging effectively\nendows LLMs for low-resource languages with task-solving abilities,\noutperforming CT-then-SFT in scenarios with extremely scarce data. Observing\nperformance saturation in model merging with more training tokens, we further\nanalyze the merging process and introduce a slack variable to the model merging\nalgorithm to mitigate the loss of important parameters, thereby enhancing\nperformance. We hope that model merging can benefit more human languages\nsuffering from data scarcity with its higher data efficiency.", "published": "2024-07-04 15:14:17", "link": "http://arxiv.org/abs/2407.03994v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Content Understanding Toward Entity and Aspect Target Sentiment\n  Analysis on Foundation Models", "abstract": "Introducing Entity-Aspect Sentiment Triplet Extraction (EASTE), a novel\nAspect-Based Sentiment Analysis (ABSA) task which extends\nTarget-Aspect-Sentiment Detection (TASD) by separating aspect categories (e.g.,\nfood#quality) into pre-defined entities (e.g., meal, drink) and aspects (e.g.,\ntaste, freshness) which add a fine-gainer level of complexity, yet help\nexposing true sentiment of chained aspect to its entity. We explore the task of\nEASTE solving capabilities of language models based on transformers\narchitecture from our proposed unified-loss approach via token classification\ntask using BERT architecture to text generative models such as Flan-T5,\nFlan-Ul2 to Llama2, Llama3 and Mixtral employing different alignment techniques\nsuch as zero/few-shot learning, Parameter Efficient Fine Tuning (PEFT) such as\nLow-Rank Adaptation (LoRA). The model performances are evaluated on the\nSamEval-2016 benchmark dataset representing the fair comparison to existing\nworks. Our research not only aims to achieve high performance on the EASTE task\nbut also investigates the impact of model size, type, and adaptation techniques\non task performance. Ultimately, we provide detailed insights and achieving\nstate-of-the-art results in complex sentiment analysis.", "published": "2024-07-04 16:48:14", "link": "http://arxiv.org/abs/2407.04050v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Pre-trained Language Models Understand Chinese Humor?", "abstract": "Humor understanding is an important and challenging research in natural\nlanguage processing. As the popularity of pre-trained language models (PLMs),\nsome recent work makes preliminary attempts to adopt PLMs for humor recognition\nand generation. However, these simple attempts do not substantially answer the\nquestion: {\\em whether PLMs are capable of humor understanding?} This paper is\nthe first work that systematically investigates the humor understanding ability\nof PLMs. For this purpose, a comprehensive framework with three evaluation\nsteps and four evaluation tasks is designed. We also construct a comprehensive\nChinese humor dataset, which can fully meet all the data requirements of the\nproposed evaluation framework. Our empirical study on the Chinese humor dataset\nyields some valuable observations, which are of great guiding value for future\noptimization of PLMs in humor understanding and generation.", "published": "2024-07-04 18:13:38", "link": "http://arxiv.org/abs/2407.04105v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MAPO: Boosting Large Language Model Performance with Model-Adaptive\n  Prompt Optimization", "abstract": "Prompt engineering, as an efficient and effective way to leverage Large\nLanguage Models (LLM), has drawn a lot of attention from the research\ncommunity. The existing research primarily emphasizes the importance of\nadapting prompts to specific tasks, rather than specific LLMs. However, a good\nprompt is not solely defined by its wording, but also binds to the nature of\nthe LLM in question. In this work, we first quantitatively demonstrate that\ndifferent prompts should be adapted to different LLMs to enhance their\ncapabilities across various downstream tasks in NLP. Then we novelly propose a\nmodel-adaptive prompt optimizer (MAPO) method that optimizes the original\nprompts for each specific LLM in downstream tasks. Extensive experiments\nindicate that the proposed method can effectively refine prompts for an LLM,\nleading to significant improvements over various downstream tasks.", "published": "2024-07-04 18:39:59", "link": "http://arxiv.org/abs/2407.04118v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hallucination Detection: Robustly Discerning Reliable Answers in Large\n  Language Models", "abstract": "Large Language Models (LLMs) have gained widespread adoption in various\nnatural language processing tasks, including question answering and dialogue\nsystems. However, a major drawback of LLMs is the issue of hallucination, where\nthey generate unfaithful or inconsistent content that deviates from the input\nsource, leading to severe consequences. In this paper, we propose a robust\ndiscriminator named RelD to effectively detect hallucination in LLMs' generated\nanswers. RelD is trained on the constructed RelQA, a bilingual\nquestion-answering dialogue dataset along with answers generated by LLMs and a\ncomprehensive set of metrics. Our experimental results demonstrate that the\nproposed RelD successfully detects hallucination in the answers generated by\ndiverse LLMs. Moreover, it performs well in distinguishing hallucination in\nLLMs' generated answers from both in-distribution and out-of-distribution\ndatasets. Additionally, we also conduct a thorough analysis of the types of\nhallucinations that occur and present valuable insights. This research\nsignificantly contributes to the detection of reliable answers generated by\nLLMs and holds noteworthy implications for mitigating hallucination in the\nfuture work.", "published": "2024-07-04 18:47:42", "link": "http://arxiv.org/abs/2407.04121v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Orchestrating LLMs with Different Personalizations", "abstract": "This paper presents a novel approach to aligning large language models (LLMs)\nwith individual human preferences, sometimes referred to as Reinforcement\nLearning from \\textit{Personalized} Human Feedback (RLPHF). Given stated\npreferences along multiple dimensions, such as helpfulness, conciseness, or\nhumor, the goal is to create an LLM without re-training that best adheres to\nthis specification. Starting from specialized expert LLMs, each trained for one\nsuch particular preference dimension, we propose a black-box method that merges\ntheir outputs on a per-token level. We train a lightweight Preference Control\nModel (PCM) that dynamically translates the preference description and current\ncontext into next-token prediction weights. By combining the expert models'\noutputs at the token level, our approach dynamically generates text that\noptimizes the given preference. Empirical tests show that our method matches or\nsurpasses existing preference merging techniques, providing a scalable,\nefficient alternative to fine-tuning LLMs for individual personalization.", "published": "2024-07-04 22:55:02", "link": "http://arxiv.org/abs/2407.04181v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hadamard Adapter: An Extreme Parameter-Efficient Adapter Tuning Method\n  for Pre-trained Language Models", "abstract": "Recent years, Pre-trained Language models (PLMs) have swept into various\nfields of artificial intelligence and achieved great success. However, most\nPLMs, such as T5 and GPT3, have a huge amount of parameters, fine-tuning them\nis often expensive and time consuming, and storing them takes up a lot of\nspace. Therefore, it is necessary to adopt a parameter-efficient approach to\nreduce parameters of PLMs in fine-tuning without compromising their performance\nin downstream tasks. In this paper, we design a novel adapter which only acts\non self-attention outputs in PLMs. This adapter adopts element-wise linear\ntransformation using Hadamard product, hence named as Hadamard adapter,\nrequires the fewest parameters compared to previous parameter-efficient\nadapters. In addition, we also summarize some tuning patterns for Hadamard\nadapter shared by various downstream tasks, expecting to provide some guidance\nfor further parameter reduction with shared adapters in future studies. The\nexperiments conducted on the widely-used GLUE benchmark with several SOTA PLMs\nprove that the Hadamard adapter achieves competitive performance with only\n0.033\\% parameters compared with full fine-tuning, and it has the fewest\nparameters compared with other adapters. Moreover, we further find that there\nis also some redundant layers in the Hadamard adapter which can be removed to\nachieve more parameter efficiency with only 0.022\\% parameters.", "published": "2024-07-04 18:21:28", "link": "http://arxiv.org/abs/2407.11033v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Historical Ink: 19th Century Latin American Spanish Newspaper Corpus\n  with LLM OCR Correction", "abstract": "This paper presents two significant contributions: First, it introduces a\nnovel dataset of 19th-century Latin American newspaper texts, addressing a\ncritical gap in specialized corpora for historical and linguistic analysis in\nthis region. Second, it develops a flexible framework that utilizes a Large\nLanguage Model for OCR error correction and linguistic surface form detection\nin digitized corpora. This semi-automated framework is adaptable to various\ncontexts and datasets and is applied to the newly created dataset.", "published": "2024-07-04 02:10:18", "link": "http://arxiv.org/abs/2407.12838v2", "categories": ["cs.CL", "cs.DL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Black-box Model Ensembling for Textual and Visual Question Answering via\n  Information Fusion", "abstract": "A diverse range of large language models (LLMs), e.g., ChatGPT, and visual\nquestion answering (VQA) models, e.g., BLIP, have been developed for solving\ntextual and visual question answering tasks. However, fine-tuning these models\nis either difficult, as it requires access via APIs, rendering them as\nblack-boxes, or costly due to the need of tuning a large number of parameters.\nTo address this, we introduce InfoSel, a data-efficient ensemble method that\nlearns to dynamically pick the winner from existing black-box models for\npredictions on both textual and multimodal visual question answering tasks.\nUnlike traditional ensemble models, InfoSel does not rely on prediction\nprobabilities or confidences, which typically are not available in black-box\nmodels. Experimental results on four datasets demonstrate that our approach\nachieves an absolute increase of up to +5.19\\% in the F1-score compared to\nstandalone LLMs using only 1K training instances.", "published": "2024-07-04 12:59:10", "link": "http://arxiv.org/abs/2407.12841v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MS2SL: Multimodal Spoken Data-Driven Continuous Sign Language Production", "abstract": "Sign language understanding has made significant strides; however, there is\nstill no viable solution for generating sign sequences directly from entire\nspoken content, e.g., text or speech. In this paper, we propose a unified\nframework for continuous sign language production, easing communication between\nsign and non-sign language users. In particular, a sequence diffusion model,\nutilizing embeddings extracted from text or speech, is crafted to generate sign\npredictions step by step. Moreover, by creating a joint embedding space for\ntext, audio, and sign, we bind these modalities and leverage the semantic\nconsistency among them to provide informative feedback for the model training.\nThis embedding-consistency learning strategy minimizes the reliance on sign\ntriplets and ensures continuous model refinement, even with a missing audio\nmodality. Experiments on How2Sign and PHOENIX14T datasets demonstrate that our\nmodel achieves competitive performance in sign language production.", "published": "2024-07-04 13:53:50", "link": "http://arxiv.org/abs/2407.12842v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NutriBench: A Dataset for Evaluating Large Language Models on Nutrition\n  Estimation from Meal Descriptions", "abstract": "Accurate nutrition estimation helps people make informed dietary choices and\nis essential in the prevention of serious health complications. We present\nNutriBench, the first publicly available natural language meal description\nnutrition benchmark. NutriBench consists of 11,857 meal descriptions generated\nfrom real-world global dietary intake data. The data is human-verified and\nannotated with macro-nutrient labels, including carbohydrates, proteins, fats,\nand calories. We conduct an extensive evaluation of NutriBench on the task of\ncarbohydrate estimation, testing twelve leading Large Language Models (LLMs),\nincluding GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using\nstandard, Chain-of-Thought and Retrieval-Augmented Generation strategies.\nAdditionally, we present a study involving professional nutritionists, finding\nthat LLMs can provide comparable but significantly faster estimates. Finally,\nwe perform a real-world risk assessment by simulating the effect of\ncarbohydrate predictions on the blood glucose levels of individuals with\ndiabetes. Our work highlights the opportunities and challenges of using LLMs\nfor nutrition estimation, demonstrating their potential to aid professionals\nand laypersons and improve health outcomes. Our benchmark is publicly available\nat: https://mehak126.github.io/nutribench.html", "published": "2024-07-04 15:10:51", "link": "http://arxiv.org/abs/2407.12843v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unveiling Scoring Processes: Dissecting the Differences between LLMs and\n  Human Graders in Automatic Scoring", "abstract": "Large language models (LLMs) have demonstrated strong potential in performing\nautomatic scoring for constructed response assessments. While constructed\nresponses graded by humans are usually based on given grading rubrics, the\nmethods by which LLMs assign scores remain largely unclear. It is also\nuncertain how closely AI's scoring process mirrors that of humans or if it\nadheres to the same grading criteria. To address this gap, this paper uncovers\nthe grading rubrics that LLMs used to score students' written responses to\nscience tasks and their alignment with human scores. We also examine whether\nenhancing the alignments can improve scoring accuracy. Specifically, we prompt\nLLMs to generate analytic rubrics that they use to assign scores and study the\nalignment gap with human grading rubrics. Based on a series of experiments with\nvarious configurations of LLM settings, we reveal a notable alignment gap\nbetween human and LLM graders. While LLMs can adapt quickly to scoring tasks,\nthey often resort to shortcuts, bypassing deeper logical reasoning expected in\nhuman grading. We found that incorporating high-quality analytical rubrics\ndesigned to reflect human grading logic can mitigate this gap and enhance LLMs'\nscoring accuracy. These results underscore the need for a nuanced approach when\napplying LLMs in science education and highlight the importance of aligning LLM\noutputs with human expectations to ensure efficient and accurate automatic\nscoring.", "published": "2024-07-04 22:26:20", "link": "http://arxiv.org/abs/2407.18328v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Feelings about Bodies: Emotions on Diet and Fitness Forums Reveal\n  Gendered Stereotypes and Body Image Concerns", "abstract": "The gendered expectations about ideal body types can lead to body image\nconcerns, dissatisfaction, and in extreme cases, disordered eating and other\npsychopathologies across the gender spectrum. While research has focused on\npro-anorexia online communities that glorify the 'thin ideal', less attention\nhas been given to the broader spectrum of body image concerns or how emerging\ndisorders like muscle dysmorphia ('bigorexia') present in online discussions.\nTo address these gaps, we analyze 46 Reddit discussion forums related to diet,\nfitness, and associated mental health challenges. Using membership structure\nanalysis and transformer-based language models, we project these communities\nalong gender and body ideal axes, revealing complex interactions between\ngender, body ideals, and emotional expression. Our findings show that\nfeminine-oriented communities generally express more negative emotions,\nparticularly in thinness-promoting forums. Conversely, communities focused on\nthe muscular ideal exhibit less negativity, regardless of gender orientation.\nWe also uncover a gendered pattern in emotional indicators of mental health\nchallenges, with communities discussing serious issues aligning more closely\nwith thinness-oriented, predominantly feminine-leaning communities. By\nrevealing the gendered emotional dynamics of online communities, our findings\ncan inform the development of more effective content moderation approaches that\nfacilitate supportive interactions, while minimizing exposure to potentially\nharmful content.", "published": "2024-07-04 00:11:27", "link": "http://arxiv.org/abs/2407.03551v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "Learning Video Temporal Dynamics with Cross-Modal Attention for Robust\n  Audio-Visual Speech Recognition", "abstract": "Audio-visual speech recognition (AVSR) aims to transcribe human speech using\nboth audio and video modalities. In practical environments with noise-corrupted\naudio, the role of video information becomes crucial. However, prior works have\nprimarily focused on enhancing audio features in AVSR, overlooking the\nimportance of video features. In this study, we strengthen the video features\nby learning three temporal dynamics in video data: context order, playback\ndirection, and the speed of video frames. Cross-modal attention modules are\nintroduced to enrich video features with audio information so that speech\nvariability can be taken into account when training on the video temporal\ndynamics. Based on our approach, we achieve the state-of-the-art performance on\nthe LRS2 and LRS3 AVSR benchmarks for the noise-dominant settings. Our approach\nexcels in scenarios especially for babble and speech noise, indicating the\nability to distinguish the speech signal that should be recognized from lip\nmovements in the video modality. We support the validity of our methodology by\noffering the ablation experiments for the temporal dynamics losses and the\ncross-modal attention architecture design.", "published": "2024-07-04 01:25:20", "link": "http://arxiv.org/abs/2407.03563v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Generative Technology for Human Emotion Recognition: A Scope Review", "abstract": "Affective computing stands at the forefront of artificial intelligence (AI),\nseeking to imbue machines with the ability to comprehend and respond to human\nemotions. Central to this field is emotion recognition, which endeavors to\nidentify and interpret human emotional states from different modalities, such\nas speech, facial images, text, and physiological signals. In recent years,\nimportant progress has been made in generative models, including Autoencoder,\nGenerative Adversarial Network, Diffusion Model, and Large Language Model.\nThese models, with their powerful data generation capabilities, emerge as\npivotal tools in advancing emotion recognition. However, up to now, there\nremains a paucity of systematic efforts that review generative technology for\nemotion recognition. This survey aims to bridge the gaps in the existing\nliterature by conducting a comprehensive analysis of over 320 research papers\nuntil June 2024. Specifically, this survey will firstly introduce the\nmathematical principles of different generative models and the commonly used\ndatasets. Subsequently, through a taxonomy, it will provide an in-depth\nanalysis of how generative techniques address emotion recognition based on\ndifferent modalities in several aspects, including data augmentation, feature\nextraction, semi-supervised learning, cross-domain, etc. Finally, the review\nwill outline future research directions, emphasizing the potential of\ngenerative models to advance the field of emotion recognition and enhance the\nemotional intelligence of AI systems.", "published": "2024-07-04 05:22:55", "link": "http://arxiv.org/abs/2407.03640v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Continual Learning Optimizations for Auto-regressive Decoder of\n  Multilingual ASR systems", "abstract": "Continual Learning (CL) involves fine-tuning pre-trained models with new data\nwhile maintaining the performance on the pre-trained data. This is particularly\nrelevant for expanding multilingual ASR (MASR) capabilities. However, existing\nCL methods, mainly designed for computer vision and reinforcement learning\ntasks, often yield sub-optimal results when directly applied to MASR. We\nhypothesise that this is because CL of the auto-regressive decoder in the MASR\nmodel is difficult. To verify this, we propose four optimizations on the\ndecoder. They include decoder-layer gradient surgery, freezing unused token\nembeddings, suppressing output of newly added tokens, and learning rate\nre-scaling. Our experiments on adapting Whisper to 10 unseen languages from the\nCommon Voice dataset demonstrate that these optimizations reduce the Average\nWord Error Rate (AWER) of pretrained languages from 14.2% to 12.4% compared\nwith Experience Replay, without compromising the AWER of new languages.", "published": "2024-07-04 05:35:47", "link": "http://arxiv.org/abs/2407.03645v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Text2TimeSeries: Enhancing Financial Forecasting through Time Series\n  Prediction Updates with Event-Driven Insights from Large Language Models", "abstract": "Time series models, typically trained on numerical data, are designed to\nforecast future values. These models often rely on weighted averaging\ntechniques over time intervals. However, real-world time series data is seldom\nisolated and is frequently influenced by non-numeric factors. For instance,\nstock price fluctuations are impacted by daily random events in the broader\nworld, with each event exerting a unique influence on price signals.\nPreviously, forecasts in financial markets have been approached in two main\nways: either as time-series problems over price sequence or sentiment analysis\ntasks. The sentiment analysis tasks aim to determine whether news events will\nhave a positive or negative impact on stock prices, often categorizing them\ninto discrete labels. Recognizing the need for a more comprehensive approach to\naccurately model time series prediction, we propose a collaborative modeling\nframework that incorporates textual information about relevant events for\npredictions. Specifically, we leverage the intuition of large language models\nabout future changes to update real number time series predictions. We\nevaluated the effectiveness of our approach on financial market data.", "published": "2024-07-04 07:21:38", "link": "http://arxiv.org/abs/2407.03689v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Convolutional vs Large Language Models for Software Log Classification\n  in Edge-Deployable Cellular Network Testing", "abstract": "Software logs generated by sophisticated network emulators in the\ntelecommunications industry, such as VIAVI TM500, are extremely complex, often\ncomprising tens of thousands of text lines with minimal resemblance to natural\nlanguage. Only specialised expert engineers can decipher such logs and\ntroubleshoot defects in test runs. While AI offers a promising solution for\nautomating defect triage, potentially leading to massive revenue savings for\ncompanies, state-of-the-art large language models (LLMs) suffer from\nsignificant drawbacks in this specialised domain. These include a constrained\ncontext window, limited applicability to text beyond natural language, and high\ninference costs. To address these limitations, we propose a compact\nconvolutional neural network (CNN) architecture that offers a context window\nspanning up to 200,000 characters and achieves over 96% accuracy (F1>0.9) in\nclassifying multifaceted software logs into various layers in the\ntelecommunications protocol stack. Specifically, the proposed model is capable\nof identifying defects in test runs and triaging them to the relevant\ndepartment, formerly a manual engineering process that required expert\nknowledge. We evaluate several LLMs; LLaMA2-7B, Mixtral 8x7B, Flan-T5, BERT and\nBigBird, and experimentally demonstrate their shortcomings in our specialized\napplication. Despite being lightweight, our CNN significantly outperforms\nLLM-based approaches in telecommunications log classification while minimizing\nthe cost of production. Our defect triaging AI model is deployable on edge\ndevices without dedicated hardware and widely applicable across software logs\nin various industries.", "published": "2024-07-04 09:12:08", "link": "http://arxiv.org/abs/2407.03759v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "cs.CL"}
{"title": "From Data to Commonsense Reasoning: The Use of Large Language Models for\n  Explainable AI", "abstract": "Commonsense reasoning is a difficult task for a computer, but a critical\nskill for an artificial intelligence (AI). It can enhance the explainability of\nAI models by enabling them to provide intuitive and human-like explanations for\ntheir decisions. This is necessary in many areas especially in question\nanswering (QA), which is one of the most important tasks of natural language\nprocessing (NLP). Over time, a multitude of methods have emerged for solving\ncommonsense reasoning problems such as knowledge-based approaches using formal\nlogic or linguistic analysis. In this paper, we investigate the effectiveness\nof large language models (LLMs) on different QA tasks with a focus on their\nabilities in reasoning and explainability. We study three LLMs: GPT-3.5, Gemma\nand Llama 3. We further evaluate the LLM results by means of a questionnaire.\nWe demonstrate the ability of LLMs to reason with commonsense as the models\noutperform humans on different datasets. While GPT-3.5's accuracy ranges from\n56% to 93% on various QA benchmarks, Llama 3 achieved a mean accuracy of 90% on\nall eleven datasets. Thereby Llama 3 is outperforming humans on all datasets\nwith an average 21% higher accuracy over ten datasets. Furthermore, we can\nappraise that, in the sense of explainable artificial intelligence (XAI),\nGPT-3.5 provides good explanations for its decisions. Our questionnaire\nrevealed that 66% of participants rated GPT-3.5's explanations as either \"good\"\nor \"excellent\". Taken together, these findings enrich our understanding of\ncurrent LLMs and pave the way for future investigations of reasoning and\nexplainability.", "published": "2024-07-04 09:38:49", "link": "http://arxiv.org/abs/2407.03778v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Narrow Transformer: StarCoder-Based Java-LM For Desktop", "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language\nmodel built on StarCoderBase-1.1B, designed for coding tasks in Java\nprogramming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its\nbase model and majority of other models of similar size on MultiPL-E Java code\nbenchmark. While there have been studies on extending large, generic\npre-trained models to improve proficiency in specific programming languages\nlike Python, similar investigations on small code models for other programming\nlanguages are lacking. Large code models require specialized hardware like GPUs\nfor inference, highlighting the need for research into building small code\nmodels that can be deployed on developer desktops. This paper addresses this\nresearch gap by focusing on the development of a small Java code model,\nNT-Java-1.1B, and its quantized versions, which performs comparably to open\nmodels around 1.1B on MultiPL-E Java code benchmarks, making them ideal for\ndesktop deployment. This paper establishes the foundation for specialized\nmodels across languages and sizes for a family of NT Models.", "published": "2024-07-04 13:54:24", "link": "http://arxiv.org/abs/2407.03941v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.SE"}
{"title": "Diverse and Fine-Grained Instruction-Following Ability Exploration with\n  Synthetic Data", "abstract": "Instruction-following is particularly crucial for large language models\n(LLMs) to support diverse user requests. While existing work has made progress\nin aligning LLMs with human preferences, evaluating their capabilities on\ninstruction following remains a challenge due to complexity and diversity of\nreal-world user instructions. While existing evaluation methods focus on\ngeneral skills, they suffer from two main shortcomings, i.e., lack of\nfine-grained task-level evaluation and reliance on singular instruction\nexpression. To address these problems, this paper introduces DINGO, a\nfine-grained and diverse instruction-following evaluation dataset that has two\nmain advantages: (1) DINGO is based on a manual annotated, fine-grained and\nmulti-level category tree with 130 nodes derived from real-world user requests;\n(2) DINGO includes diverse instructions, generated by both GPT-4 and human\nexperts. Through extensive experiments, we demonstrate that DINGO can not only\nprovide more challenging and comprehensive evaluation for LLMs, but also\nprovide task-level fine-grained directions to further improve LLMs.", "published": "2024-07-04 13:54:41", "link": "http://arxiv.org/abs/2407.03942v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Investigating the Role of Instruction Variety and Task Difficulty in\n  Robotic Manipulation Tasks", "abstract": "Evaluating the generalisation capabilities of multimodal models based solely\non their performance on out-of-distribution data fails to capture their true\nrobustness. This work introduces a comprehensive evaluation framework that\nsystematically examines the role of instructions and inputs in the\ngeneralisation abilities of such models, considering architectural design,\ninput perturbations across language and vision modalities, and increased task\ncomplexity. The proposed framework uncovers the resilience of multimodal models\nto extreme instruction perturbations and their vulnerability to observational\nchanges, raising concerns about overfitting to spurious correlations. By\nemploying this evaluation framework on current Transformer-based multimodal\nmodels for robotic manipulation tasks, we uncover limitations and suggest\nfuture advancements should focus on architectural and training innovations that\nbetter integrate multimodal inputs, enhancing a model's generalisation prowess\nby prioritising sensitivity to input content over incidental correlations.", "published": "2024-07-04 14:36:49", "link": "http://arxiv.org/abs/2407.03967v2", "categories": ["cs.CL", "cs.AI", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Improving Accented Speech Recognition using Data Augmentation based on\n  Unsupervised Text-to-Speech Synthesis", "abstract": "This paper investigates the use of unsupervised text-to-speech synthesis\n(TTS) as a data augmentation method to improve accented speech recognition. TTS\nsystems are trained with a small amount of accented speech training data and\ntheir pseudo-labels rather than manual transcriptions, and hence unsupervised.\nThis approach enables the use of accented speech data without manual\ntranscriptions to perform data augmentation for accented speech recognition.\nSynthetic accented speech data, generated from text prompts by using the TTS\nsystems, are then combined with available non-accented speech data to train\nautomatic speech recognition (ASR) systems. ASR experiments are performed in a\nself-supervised learning framework using a Wav2vec2.0 model which was\npre-trained on large amount of unsupervised accented speech data. The accented\nspeech data for training the unsupervised TTS are read speech, selected from\nL2-ARCTIC and British Isles corpora, while spontaneous conversational speech\nfrom the Edinburgh international accents of English corpus are used as the\nevaluation data. Experimental results show that Wav2vec2.0 models which are\nfine-tuned to downstream ASR task with synthetic accented speech data,\ngenerated by the unsupervised TTS, yield up to 6.1% relative word error rate\nreductions compared to a Wav2vec2.0 baseline which is fine-tuned with the\nnon-accented speech data from Librispeech corpus.", "published": "2024-07-04 16:42:24", "link": "http://arxiv.org/abs/2407.04047v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Systematic Survey and Critical Review on Evaluating Large Language\n  Models: Challenges, Limitations, and Recommendations", "abstract": "Large Language Models (LLMs) have recently gained significant attention due\nto their remarkable capabilities in performing diverse tasks across various\ndomains. However, a thorough evaluation of these models is crucial before\ndeploying them in real-world applications to ensure they produce reliable\nperformance. Despite the well-established importance of evaluating LLMs in the\ncommunity, the complexity of the evaluation process has led to varied\nevaluation setups, causing inconsistencies in findings and interpretations. To\naddress this, we systematically review the primary challenges and limitations\ncausing these inconsistencies and unreliable evaluations in various steps of\nLLM evaluation. Based on our critical review, we present our perspectives and\nrecommendations to ensure LLM evaluations are reproducible, reliable, and\nrobust.", "published": "2024-07-04 17:15:37", "link": "http://arxiv.org/abs/2407.04069v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DotaMath: Decomposition of Thought with Code Assistance and\n  Self-correction for Mathematical Reasoning", "abstract": "Large language models (LLMs) have made impressive progress in handling simple\nmath problems, yet they still struggle with more challenging and complex\nmathematical tasks. In this paper, we introduce a series of LLMs that employs\nthe Decomposition of thought with code assistance and self-correction for\nmathematical reasoning, dubbed as DotaMath. DotaMath models tackle complex\nmathematical tasks by decomposing them into simpler logical subtasks,\nleveraging code to solve these subtasks, obtaining fine-grained feedback from\nthe code interpreter, and engaging in self-reflection and correction. By\nannotating diverse interactive tool-use trajectories and employing query\nevolution on GSM8K and MATH datasets, we generate an instruction fine-tuning\ndataset called DotaMathQA with 574K query-response pairs. We train a series of\nbase LLMs using imitation learning on DotaMathQA, resulting in DotaMath models\nthat achieve remarkable performance compared to open-source LLMs across various\nin-domain and out-of-domain benchmarks. Notably, DotaMath-deepseek-7B showcases\nan outstanding performance of 64.8% on the competitive MATH dataset and 86.7%\non GSM8K. Besides, DotaMath-deepseek-7B maintains strong competitiveness on a\nseries of in-domain and out-of-domain benchmarks (Avg. 80.1%). Looking forward,\nwe anticipate that the DotaMath paradigm will open new pathways for addressing\nintricate mathematical problems. Our code is publicly available at\nhttps://github.com/ChengpengLi1003/DotaMath.", "published": "2024-07-04 17:39:16", "link": "http://arxiv.org/abs/2407.04078v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MiniGPT-Med: Large Language Model as a General Interface for Radiology\n  Diagnosis", "abstract": "Recent advancements in artificial intelligence (AI) have precipitated\nsignificant breakthroughs in healthcare, particularly in refining diagnostic\nprocedures. However, previous studies have often been constrained to limited\nfunctionalities. This study introduces MiniGPT-Med, a vision-language model\nderived from large-scale language models and tailored for medical applications.\nMiniGPT-Med demonstrates remarkable versatility across various imaging\nmodalities, including X-rays, CT scans, and MRIs, enhancing its utility. The\nmodel is capable of performing tasks such as medical report generation, visual\nquestion answering (VQA), and disease identification within medical imagery.\nIts integrated processing of both image and textual clinical data markedly\nimproves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's\nsuperior performance in disease grounding, medical report generation, and VQA\nbenchmarks, representing a significant step towards reducing the gap in\nassisting radiology practice. Furthermore, it achieves state-of-the-art\nperformance on medical report generation, higher than the previous best model\nby 19\\% accuracy. MiniGPT-Med promises to become a general interface for\nradiology diagnoses, enhancing diagnostic efficiency across a wide range of\nmedical imaging applications.", "published": "2024-07-04 18:21:10", "link": "http://arxiv.org/abs/2407.04106v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Future Events as Backdoor Triggers: Investigating Temporal\n  Vulnerabilities in LLMs", "abstract": "Backdoors are hidden behaviors that are only triggered once an AI system has\nbeen deployed. Bad actors looking to create successful backdoors must design\nthem to avoid activation during training and evaluation. Since data used in\nthese stages often only contains information about events that have already\noccurred, a component of a simple backdoor trigger could be a model recognizing\ndata that is in the future relative to when it was trained. Through prompting\nexperiments and by probing internal activations, we show that current large\nlanguage models (LLMs) can distinguish past from future events, with probes on\nmodel activations achieving 90% accuracy. We train models with backdoors\ntriggered by a temporal distributional shift; they activate when the model is\nexposed to news headlines beyond their training cut-off dates. Fine-tuning on\nhelpful, harmless and honest (HHH) data does not work well for removing simpler\nbackdoor triggers but is effective on our backdoored models, although this\ndistinction is smaller for the larger-scale model we tested. We also find that\nan activation-steering vector representing a model's internal representation of\nthe date influences the rate of backdoor activation. We take these results as\ninitial evidence that, at least for models at the modest scale we test,\nstandard safety measures are enough to remove these backdoors.", "published": "2024-07-04 18:24:09", "link": "http://arxiv.org/abs/2407.04108v3", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Query-Guided Self-Supervised Summarization of Nursing Notes", "abstract": "Nursing notes, an important part of Electronic Health Records (EHRs), track a\npatient's health during a care episode. Summarizing key information in nursing\nnotes can help clinicians quickly understand patients' conditions. However,\nexisting summarization methods in the clinical setting, especially abstractive\nmethods, have overlooked nursing notes and require reference summaries for\ntraining. We introduce QGSumm, a novel query-guided self-supervised domain\nadaptation approach for abstractive nursing note summarization. The method uses\npatient-related clinical queries for guidance, and hence does not need\nreference summaries for training. Through automatic experiments and manual\nevaluation by an expert clinician, we study our approach and other\nstate-of-the-art Large Language Models (LLMs) for nursing note summarization.\nOur experiments show: 1) GPT-4 is competitive in maintaining information in the\noriginal nursing notes, 2) QGSumm can generate high-quality summaries with a\ngood balance between recall of the original content and hallucination rate\nlower than other top methods. Ultimately, our work offers a new perspective on\nconditional text summarization, tailored to clinical applications.", "published": "2024-07-04 18:54:30", "link": "http://arxiv.org/abs/2407.04125v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Securing Multi-turn Conversational Language Models From Distributed\n  Backdoor Triggers", "abstract": "Large language models (LLMs) have acquired the ability to handle longer\ncontext lengths and understand nuances in text, expanding their dialogue\ncapabilities beyond a single utterance. A popular user-facing application of\nLLMs is the multi-turn chat setting. Though longer chat memory and better\nunderstanding may seemingly benefit users, our paper exposes a vulnerability\nthat leverages the multi-turn feature and strong learning ability of LLMs to\nharm the end-user: the backdoor. We demonstrate that LLMs can capture the\ncombinational backdoor representation. Only upon presentation of triggers\ntogether does the backdoor activate. We also verify empirically that this\nrepresentation is invariant to the position of the trigger utterance.\nSubsequently, inserting a single extra token into two utterances of 5%of the\ndata can cause over 99% Attack Success Rate (ASR). Our results with 3 triggers\ndemonstrate that this framework is generalizable, compatible with any trigger\nin an adversary's toolbox in a plug-and-play manner. Defending the backdoor can\nbe challenging in the chat setting because of the large input and output space.\nOur analysis indicates that the distributed backdoor exacerbates the current\nchallenges by polynomially increasing the dimension of the attacked input\nspace. Canonical textual defenses like ONION and BKI leverage auxiliary model\nforward passes over individual tokens, scaling exponentially with the input\nsequence length and struggling to maintain computational feasibility. To this\nend, we propose a decoding time defense - decayed contrastive decoding - that\nscales linearly with assistant response sequence length and reduces the\nbackdoor to as low as 0.35%.", "published": "2024-07-04 20:57:06", "link": "http://arxiv.org/abs/2407.04151v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild", "abstract": "Given the ubiquity of charts as a data analysis, visualization, and\ndecision-making tool across industries and sciences, there has been a growing\ninterest in developing pre-trained foundation models as well as general purpose\ninstruction-tuned models for chart understanding and reasoning. However,\nexisting methods suffer crucial drawbacks across two critical axes affecting\nthe performance of chart representation models: they are trained on data\ngenerated from underlying data tables of the charts, ignoring the visual trends\nand patterns in chart images, and use weakly aligned vision-language backbone\nmodels for domain-specific training, limiting their generalizability when\nencountering charts in the wild. We address these important drawbacks and\nintroduce ChartGemma, a novel chart understanding and reasoning model developed\nover PaliGemma. Rather than relying on underlying data tables, ChartGemma is\ntrained on instruction-tuning data generated directly from chart images, thus\ncapturing both high-level trends and low-level visual information from a\ndiverse set of charts. Our simple approach achieves state-of-the-art results\nacross $5$ benchmarks spanning chart summarization, question answering, and\nfact-checking, and our elaborate qualitative studies on real-world charts show\nthat ChartGemma generates more realistic and factually correct summaries\ncompared to its contemporaries. We release the code, model checkpoints,\ndataset, and demos at https://github.com/vis-nlp/ChartGemma.", "published": "2024-07-04 22:16:40", "link": "http://arxiv.org/abs/2407.04172v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality\n  Norms", "abstract": "Large language models (LLMs) are trained on broad corpora and then used in\ncommunities with specialized norms. Is providing LLMs with community rules\nenough for models to follow these norms? We evaluate LLMs' capacity to detect\n(Task 1) and correct (Task 2) biased Wikipedia edits according to Wikipedia's\nNeutral Point of View (NPOV) policy. LLMs struggled with bias detection,\nachieving only 64% accuracy on a balanced dataset. Models exhibited contrasting\nbiases (some under- and others over-predicted bias), suggesting distinct priors\nabout neutrality. LLMs performed better at generation, removing 79% of words\nremoved by Wikipedia editors. However, LLMs made additional changes beyond\nWikipedia editors' simpler neutralizations, resulting in high-recall but\nlow-precision editing. Interestingly, crowdworkers rated AI rewrites as more\nneutral (70%) and fluent (61%) than Wikipedia-editor rewrites. Qualitative\nanalysis found LLMs sometimes applied NPOV more comprehensively than Wikipedia\neditors but often made extraneous non-NPOV-related changes (such as grammar).\nLLMs may apply rules in ways that resonate with the public but diverge from\ncommunity experts. While potentially effective for generation, LLMs may reduce\neditor agency and increase moderation workload (e.g., verifying additions).\nEven when rules are easy to articulate, having LLMs apply them like community\nmembers may still be difficult.", "published": "2024-07-04 23:05:58", "link": "http://arxiv.org/abs/2407.04183v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "metabench -- A Sparse Benchmark of Reasoning and Knowledge in Large\n  Language Models", "abstract": "Large Language Models (LLMs) vary in their abilities on a range of tasks.\nInitiatives such as the Open LLM Leaderboard aim to quantify these differences\nwith several large benchmarks (sets of test items to which an LLM can respond\neither correctly or incorrectly). However, high correlations within and between\nbenchmark scores suggest that (1) there exists a small set of common underlying\nabilities that these benchmarks measure, and (2) items tap into redundant\ninformation and the benchmarks may thus be considerably compressed. We use data\nfrom n > 5000 LLMs to identify the most informative items of six benchmarks,\nARC, GSM8K, HellaSwag, MMLU, TruthfulQA and WinoGrande (with d = 28,632 items\nin total). From them we distill a sparse benchmark, metabench, that has less\nthan 3% of the original size of all six benchmarks combined. This new sparse\nbenchmark goes beyond point scores by yielding estimators of the underlying\nbenchmark-specific abilities. We show that these estimators (1) can be used to\nreconstruct each original individual benchmark score with, on average, 1.24%\nroot mean square error (RMSE), (2) reconstruct the original total score with\n0.58% RMSE, and (3) have a single underlying common factor whose Spearman\ncorrelation with the total score is r = 0.94.", "published": "2024-07-04 17:57:38", "link": "http://arxiv.org/abs/2407.12844v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The Price of Prompting: Profiling Energy Use in Large Language Models\n  Inference", "abstract": "In the rapidly evolving realm of artificial intelligence, deploying large\nlanguage models (LLMs) poses increasingly pressing computational and\nenvironmental challenges. This paper introduces MELODI - Monitoring Energy\nLevels and Optimization for Data-driven Inference - a multifaceted framework\ncrafted to monitor and analyze the energy consumed during LLM inference\nprocesses. MELODI enables detailed observations of power consumption dynamics\nand facilitates the creation of a comprehensive dataset reflective of energy\nefficiency across varied deployment scenarios. The dataset, generated using\nMELODI, encompasses a broad spectrum of LLM deployment frameworks, multiple\nlanguage models, and extensive prompt datasets, enabling a comparative analysis\nof energy use. Using the dataset, we investigate how prompt attributes,\nincluding length and complexity, correlate with energy expenditure. Our\nfindings indicate substantial disparities in energy efficiency, suggesting\nample scope for optimization and adoption of sustainable measures in LLM\ndeployment. Our contribution lies not only in the MELODI framework but also in\nthe novel dataset, a resource that can be expanded by other researchers. Thus,\nMELODI is a foundational tool and dataset for advancing research into\nenergy-conscious LLM deployment, steering the field toward a more sustainable\nfuture.", "published": "2024-07-04 12:16:28", "link": "http://arxiv.org/abs/2407.16893v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Multi-Convformer: Extending Conformer with Multiple Convolution Kernels", "abstract": "Convolutions have become essential in state-of-the-art end-to-end Automatic\nSpeech Recognition~(ASR) systems due to their efficient modelling of local\ncontext. Notably, its use in Conformers has led to superior performance\ncompared to vanilla Transformer-based ASR systems. While components other than\nthe convolution module in the Conformer have been reexamined, altering the\nconvolution module itself has been far less explored. Towards this, we\nintroduce Multi-Convformer that uses multiple convolution kernels within the\nconvolution module of the Conformer in conjunction with gating. This helps in\nimproved modeling of local dependencies at varying granularities. Our model\nrivals existing Conformer variants such as CgMLP and E-Branchformer in\nperformance, while being more parameter efficient. We empirically compare our\napproach with Conformer and its variants across four different datasets and\nthree different modelling paradigms and show up to 8% relative word error\nrate~(WER) improvements.", "published": "2024-07-04 08:08:12", "link": "http://arxiv.org/abs/2407.03718v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Improving Self-supervised Pre-training using Accent-Specific Codebooks", "abstract": "Speech accents present a serious challenge to the performance of\nstate-of-the-art end-to-end Automatic Speech Recognition (ASR) systems. Even\nwith self-supervised learning and pre-training of ASR models, accent invariance\nis seldom achieved. In this work, we propose an accent-aware adaptation\ntechnique for self-supervised learning that introduces a trainable set of\naccent-specific codebooks to the self-supervised architecture. These learnable\ncodebooks enable the model to capture accent specific information during\npre-training, that is further refined during ASR finetuning. On the Mozilla\nCommon Voice dataset, our proposed approach outperforms all other\naccent-adaptation approaches on both seen and unseen English accents, with up\nto 9% relative reduction in word error rate (WER).", "published": "2024-07-04 08:33:52", "link": "http://arxiv.org/abs/2407.03734v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Mixstyle based Domain Generalization for Sound Event Detection with\n  Heterogeneous Training Data", "abstract": "This work explores domain generalization (DG) for sound event detection\n(SED), advancing adaptability towards real-world scenarios. Our approach\nemploys a mean-teacher framework with domain generalization to integrate\nheterogeneous training data, while preserving the SED model performance across\nthe datasets. Specifically, we first apply mixstyle to the frequency dimension\nto adapt the mel-spectrograms from different domains. Next, we use the adaptive\nresidual normalization method to generalize features across multiple domains by\napplying instance normalization in the frequency dimension. Lastly, we use the\nsound event bounding boxes method for post-processing. Our approach integrates\nfeatures from bidirectional encoder representations from audio transformers and\na convolutional recurrent neural network. We evaluate the proposed approach on\nDCASE 2024 Challenge Task 4 dataset, measuring polyphonic SED score (PSDS) on\nthe DESED dataset and macro-average pAUC on the MAESTRO dataset. The results\nindicate that the proposed DG-based method improves both PSDS and macro-average\npAUC compared to the challenge baseline.", "published": "2024-07-04 05:50:40", "link": "http://arxiv.org/abs/2407.03654v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Optimizing a-DCF for Spoofing-Robust Speaker Verification", "abstract": "Automatic speaker verification (ASV) systems are vulnerable to spoofing\nattacks. We propose a spoofing-robust ASV system optimized directly for the\nrecently introduced architecture-agnostic detection cost function (a-DCF),\nwhich allows targeting a desired trade-off between the contradicting aims of\nuser convenience and robustness to spoofing. We combine a-DCF and binary\ncross-entropy (BCE) with a novel straightforward threshold optimization\ntechnique. Our results with an embedding fusion system on ASVspoof2019 data\ndemonstrate relative improvement of $13\\%$ over a system trained using BCE only\n(from minimum a-DCF of $0.1445$ to $0.1254$). Using an alternative non-linear\nscore fusion approach provides relative improvement of $43\\%$ (from minimum\na-DCF of $0.0508$ to $0.0289$).", "published": "2024-07-04 16:20:01", "link": "http://arxiv.org/abs/2407.04034v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DASS: Distilled Audio State Space Models Are Stronger and More\n  Duration-Scalable Learners", "abstract": "State-space models (SSMs) have emerged as an alternative to Transformers for\naudio modeling due to their high computational efficiency with long inputs.\nWhile recent efforts on Audio SSMs have reported encouraging results, two main\nlimitations remain: First, in 10-second short audio tagging tasks, Audio SSMs\nstill underperform compared to Transformer-based models such as Audio\nSpectrogram Transformer (AST). Second, although Audio SSMs theoretically\nsupport long audio inputs, their actual performance with long audio has not\nbeen thoroughly evaluated. To address these limitations, in this paper, 1) We\napplied knowledge distillation in audio space model training, resulting in a\nmodel called Knowledge Distilled Audio SSM (DASS). To the best of our\nknowledge, it is the first SSM that outperforms the Transformers on AudioSet\nand achieves an mAP of 47.6; and 2) We designed a new test called Audio Needle\nIn A Haystack (Audio NIAH). We find that DASS, trained with only 10-second\naudio clips, can retrieve sound events in audio recordings up to 2.5 hours\nlong, while the AST model fails when the input is just 50 seconds,\ndemonstrating SSMs are indeed more duration scalable.", "published": "2024-07-04 17:46:19", "link": "http://arxiv.org/abs/2407.04082v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "High Fidelity Text-Guided Music Editing via Single-Stage Flow Matching", "abstract": "We introduce MelodyFlow, an efficient text-controllable high-fidelity music\ngeneration and editing model. It operates on continuous latent representations\nfrom a low frame rate 48 kHz stereo variational auto encoder codec. Based on a\ndiffusion transformer architecture trained on a flow-matching objective the\nmodel can edit diverse high quality stereo samples of variable duration, with\nsimple text descriptions. We adapt the ReNoise latent inversion method to flow\nmatching and compare it with the original implementation and naive denoising\ndiffusion implicit model (DDIM) inversion on a variety of music editing\nprompts. Our results indicate that our latent inversion outperforms both\nReNoise and DDIM for zero-shot test-time text-guided editing on several\nobjective metrics. Subjective evaluations exhibit a substantial improvement\nover previous state of the art for music editing. Code and model weights will\nbe publicly made available. Samples are available at\nhttps://melodyflow.github.io.", "published": "2024-07-04 05:38:49", "link": "http://arxiv.org/abs/2407.03648v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound\n  Event Detection System", "abstract": "This work aims to advance sound event detection (SED) research by presenting\na new large language model (LLM)-powered dataset namely wild domestic\nenvironment sound event detection (WildDESED). It is crafted as an extension to\nthe original DESED dataset to reflect diverse acoustic variability and complex\nnoises in home settings. We leveraged LLMs to generate eight different domestic\nscenarios based on target sound categories of the DESED dataset. Then we\nenriched the scenarios with a carefully tailored mixture of noises selected\nfrom AudioSet and ensured no overlap with target sound. We consider widely\npopular convolutional neural recurrent network to study WildDESED dataset,\nwhich depicts its challenging nature. We then apply curriculum learning by\ngradually increasing noise complexity to enhance the model's generalization\ncapabilities across various noise levels. Our results with this approach show\nimprovements within the noisy environment, validating the effectiveness on the\nWildDESED dataset promoting noise-robust SED advancements.", "published": "2024-07-04 05:54:19", "link": "http://arxiv.org/abs/2407.03656v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "UCIL: An Unsupervised Class Incremental Learning Approach for Sound\n  Event Detection", "abstract": "This work explores class-incremental learning (CIL) for sound event detection\n(SED), advancing adaptability towards real-world scenarios. CIL's success in\ndomains like computer vision inspired our SED-tailored method, addressing the\nunique challenges of diverse and complex audio environments. Our approach\nemploys an independent unsupervised learning framework with a distillation loss\nfunction to integrate new sound classes while preserving the SED model\nconsistency across incremental tasks. We further enhance this framework with a\nsample selection strategy for unlabeled data and a balanced exemplar update\nmechanism, ensuring varied and illustrative sound representations. Evaluating\nvarious continual learning methods on the DCASE 2023 Task 4 dataset, we find\nthat our research offers insights into each method's applicability for\nreal-world SED systems that can have newly added sound classes. The findings\nalso delineate future directions of CIL in dynamic audio settings.", "published": "2024-07-04 05:57:30", "link": "http://arxiv.org/abs/2407.03657v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Where's That Voice Coming? Continual Learning for Sound Source\n  Localization", "abstract": "Sound source localization (SSL) is essential for many speech-processing\napplications. Deep learning models have achieved high performance, but often\nfail when the training and inference environments differ. Adapting SSL models\nto dynamic acoustic conditions faces a major challenge: catastrophic\nforgetting. In this work, we propose an exemplar-free continual learning\nstrategy for SSL (CL-SSL) to address such a forgetting phenomenon. CL-SSL\napplies task-specific sub-networks to adapt across diverse acoustic\nenvironments while retaining previously learned knowledge. It also uses a\nscaling mechanism to limit parameter growth, ensuring consistent performance\nacross incremental tasks. We evaluated CL-SSL on simulated data with varying\nmicrophone distances and real-world data with different noise levels. The\nresults demonstrate CL-SSL's ability to maintain high accuracy with minimal\nparameter increase, offering an efficient solution for SSL applications.", "published": "2024-07-04 06:02:52", "link": "http://arxiv.org/abs/2407.03661v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unsupervised speech enhancement with spectral kurtosis and double deep\n  priors", "abstract": "This paper proposes an unsupervised DNN-based speech enhancement approach\nfounded on deep priors (DPs). Here, DP signifies that DNNs are more inclined to\nproduce clean speech signals than noises. Conventional methods based on DP\ntypically involve training on a noisy speech signal using a random noise\nfeature as input, stopping training only a clean speech signal is generated.\nHowever, such conventional approaches encounter challenges in determining the\noptimal stop timing, experience performance degradation due to environmental\nbackground noise, and suffer a trade-off between distortion of the clean speech\nsignal and noise reduction performance. To address these challenges, we utilize\ntwo DNNs: one to generate a clean speech signal and the other to generate\nnoise. The combined output of these networks closely approximates the noisy\nspeech signal, with a loss term based on spectral kurtosis utilized to separate\nthe noisy speech signal into a clean speech signal and noise. The key advantage\nof this method lies in its ability to circumvent trade-offs and early stopping\nproblems, as the signal is decomposed by enough steps. Through evaluation\nexperiments, we demonstrate that the proposed method outperforms conventional\nmethods in the case of white Gaussian and environmental noise while effectively\nmitigating early stopping problems.", "published": "2024-07-04 12:25:13", "link": "http://arxiv.org/abs/2407.03887v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Effectiveness of Acoustic BPE in Decoder-Only TTS", "abstract": "Discretizing speech into tokens and generating them by a decoder-only model\nhave been a promising direction for text-to-speech (TTS) and spoken language\nmodeling (SLM). To shorten the sequence length of speech tokens, acoustic\nbyte-pair encoding (BPE) has emerged in SLM that treats speech tokens from\nself-supervised semantic representations as characters to further compress the\ntoken sequence. But the gain in TTS has not been fully investigated, and the\nproper choice of acoustic BPE remains unclear. In this work, we conduct a\ncomprehensive study on various settings of acoustic BPE to explore its\neffectiveness in decoder-only TTS models with semantic speech tokens.\nExperiments on LibriTTS verify that acoustic BPE uniformly increases the\nintelligibility and diversity of synthesized speech, while showing different\nfeatures across BPE settings. Hence, acoustic BPE is a favorable tool for\ndecoder-only TTS.", "published": "2024-07-04 12:35:32", "link": "http://arxiv.org/abs/2407.03892v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Serialized Output Training by Learned Dominance", "abstract": "Serialized Output Training (SOT) has showcased state-of-the-art performance\nin multi-talker speech recognition by sequentially decoding the speech of\nindividual speakers. To address the challenging label-permutation issue, prior\nmethods have relied on either the Permutation Invariant Training (PIT) or the\ntime-based First-In-First-Out (FIFO) rule. This study presents a model-based\nserialization strategy that incorporates an auxiliary module into the Attention\nEncoder-Decoder architecture, autonomously identifying the crucial factors to\norder the output sequence of the speech components in multi-talker speech.\nExperiments conducted on the LibriSpeech and LibriMix databases reveal that our\napproach significantly outperforms the PIT and FIFO baselines in both 2-mix and\n3-mix scenarios. Further analysis shows that the serialization module\nidentifies dominant speech components in a mixture by factors including\nloudness and gender, and orders speech components based on the dominance score.", "published": "2024-07-04 14:36:02", "link": "http://arxiv.org/abs/2407.03966v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FunAudioLLM: Voice Understanding and Generation Foundation Models for\n  Natural Interaction Between Humans and LLMs", "abstract": "This report introduces FunAudioLLM, a model family designed to enhance\nnatural voice interactions between humans and large language models (LLMs). At\nits core are two innovative models: SenseVoice, which handles multilingual\nspeech recognition, emotion recognition, and audio event detection; and\nCosyVoice, which facilitates natural speech generation with control over\nmultiple languages, timbre, speaking style, and speaker identity.\nSenseVoice-Small delivers exceptionally low-latency ASR for 5 languages, and\nSenseVoice-Large supports high-precision ASR for over 50 languages, while\nCosyVoice excels in multi-lingual voice generation, zero-shot in-context\nlearning, cross-lingual voice cloning, and instruction-following capabilities.\nThe models related to SenseVoice and CosyVoice have been open-sourced on\nModelscope and Huggingface, along with the corresponding training, inference,\nand fine-tuning codes released on GitHub. By integrating these models with\nLLMs, FunAudioLLM enables applications such as speech-to-speech translation,\nemotional voice chat, interactive podcasts, and expressive audiobook narration,\nthereby pushing the boundaries of voice interaction technology. Demos are\navailable at https://fun-audio-llm.github.io, and the code can be accessed at\nhttps://github.com/FunAudioLLM.", "published": "2024-07-04 16:49:02", "link": "http://arxiv.org/abs/2407.04051v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semantic Grouping Network for Audio Source Separation", "abstract": "Recently, audio-visual separation approaches have taken advantage of the\nnatural synchronization between the two modalities to boost audio source\nseparation performance. They extracted high-level semantics from visual inputs\nas the guidance to help disentangle sound representation for individual\nsources. Can we directly learn to disentangle the individual semantics from the\nsound itself? The dilemma is that multiple sound sources are mixed together in\nthe original space. To tackle the difficulty, in this paper, we present a novel\nSemantic Grouping Network, termed as SGN, that can directly disentangle sound\nrepresentations and extract high-level semantic information for each source\nfrom input audio mixture. Specifically, SGN aggregates category-wise source\nfeatures through learnable class tokens of sounds. Then, the aggregated\nsemantic features can be used as the guidance to separate the corresponding\naudio sources from the mixture. We conducted extensive experiments on\nmusic-only and universal sound separation benchmarks: MUSIC, FUSS, MUSDB18, and\nVGG-Sound. The results demonstrate that our SGN significantly outperforms\nprevious audio-only methods and audio-visual models without utilizing\nadditional visual cues.", "published": "2024-07-04 08:37:47", "link": "http://arxiv.org/abs/2407.03736v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
