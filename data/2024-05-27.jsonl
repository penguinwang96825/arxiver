{"title": "Performance evaluation of Reddit Comments using Machine Learning and\n  Natural Language Processing methods in Sentiment Analysis", "abstract": "Sentiment analysis, an increasingly vital field in both academia and\nindustry, plays a pivotal role in machine learning applications, particularly\non social media platforms like Reddit. However, the efficacy of sentiment\nanalysis models is hindered by the lack of expansive and fine-grained emotion\ndatasets. To address this gap, our study leverages the GoEmotions dataset,\ncomprising a diverse range of emotions, to evaluate sentiment analysis methods\nacross a substantial corpus of 58,000 comments. Distinguished from prior\nstudies by the Google team, which limited their analysis to only two models,\nour research expands the scope by evaluating a diverse array of models. We\ninvestigate the performance of traditional classifiers such as Naive Bayes and\nSupport Vector Machines (SVM), as well as state-of-the-art transformer-based\nmodels including BERT, RoBERTa, and GPT. Furthermore, our evaluation criteria\nextend beyond accuracy to encompass nuanced assessments, including hierarchical\nclassification based on varying levels of granularity in emotion\ncategorization. Additionally, considerations such as computational efficiency\nare incorporated to provide a comprehensive evaluation framework. Our findings\nreveal that the RoBERTa model consistently outperforms the baseline models,\ndemonstrating superior accuracy in fine-grained sentiment classification tasks.\nThis underscores the substantial potential and significance of the RoBERTa\nmodel in advancing sentiment analysis capabilities.", "published": "2024-05-27 03:59:28", "link": "http://arxiv.org/abs/2405.16810v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Perturbation-Restrained Sequential Model Editing", "abstract": "Model editing is an emerging field that focuses on updating the knowledge\nembedded within large language models (LLMs) without extensive retraining.\nHowever, current model editing methods significantly compromise the general\nabilities of LLMs as the number of edits increases, and this trade-off poses a\nsubstantial challenge to the continual learning of LLMs. In this paper, we\nfirst theoretically analyze that the factor affecting the general abilities in\nsequential model editing lies in the condition number of the edited matrix. The\ncondition number of a matrix represents its numerical sensitivity, and\ntherefore can be used to indicate the extent to which the original knowledge\nassociations stored in LLMs are perturbed after editing. Subsequently,\nstatistical findings demonstrate that the value of this factor becomes larger\nas the number of edits increases, thereby exacerbating the deterioration of\ngeneral abilities. To this end, a framework termed Perturbation Restraint on\nUpper bouNd for Editing (PRUNE) is proposed, which applies the condition number\nrestraints in sequential editing. These restraints can lower the upper bound on\nperturbation to edited models, thus preserving the general abilities.\nSystematically, we conduct experiments employing three editing methods on three\nLLMs across four downstream tasks. The results show that PRUNE can preserve\ngeneral abilities while maintaining the editing performance effectively in\nsequential model editing. The code are available at\nhttps://github.com/mjy1111/PRUNE.", "published": "2024-05-27 04:40:56", "link": "http://arxiv.org/abs/2405.16821v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can We Trust LLMs? Mitigate Overconfidence Bias in LLMs through\n  Knowledge Transfer", "abstract": "The study explores mitigating overconfidence bias in LLMs to improve their\nreliability. We introduce a knowledge transfer (KT) method utilizing chain of\nthoughts, where \"big\" LLMs impart knowledge to \"small\" LLMs via detailed,\nsequential reasoning paths. This method uses advanced reasoning of larger\nmodels to fine-tune smaller models, enabling them to produce more accurate\npredictions with calibrated confidence. Experimental evaluation using\nmultiple-choice questions and sentiment analysis across diverse datasets\ndemonstrated the KT method's superiority over the vanilla and question-answer\npair (QA) fine-tuning methods. The most significant improvement in three key\nmetrics, where the KT method outperformed the vanilla and QA methods by an\naverage of 55.3% and 43.1%, respectively. These findings underscore the KT\nmethod's potential in enhancing model trustworthiness and accuracy, offering\nprecise outputs with well-matched confidence levels across various contexts.", "published": "2024-05-27 06:06:36", "link": "http://arxiv.org/abs/2405.16856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty\n  in Words?", "abstract": "We posit that large language models (LLMs) should be capable of expressing\ntheir intrinsic uncertainty in natural language. For example, if the LLM is\nequally likely to output two contradicting answers to the same question, then\nits generated response should reflect this uncertainty by hedging its answer\n(e.g., \"I'm not sure, but I think...\"). We formalize faithful response\nuncertainty based on the gap between the model's intrinsic confidence in the\nassertions it makes and the decisiveness by which they are conveyed. This\nexample-level metric reliably indicates whether the model reflects its\nuncertainty, as it penalizes both excessive and insufficient hedging. We\nevaluate a variety of aligned LLMs at faithfully communicating uncertainty on\nseveral knowledge-intensive question answering tasks. Our results provide\nstrong evidence that modern LLMs are poor at faithfully conveying their\nuncertainty, and that better alignment is necessary to improve their\ntrustworthiness.", "published": "2024-05-27 07:56:23", "link": "http://arxiv.org/abs/2405.16908v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SelfCP: Compressing Over-Limit Prompt via the Frozen Large Language\n  Model Itself", "abstract": "Long prompt leads to huge hardware costs when using transformer-based Large\nLanguage Models (LLMs). Unfortunately, many tasks, such as summarization,\ninevitably introduce long documents, and the wide application of in-context\nlearning easily makes the prompt length explode. This paper proposes a\nSelf-Compressor (SelfCP), which employs the target LLM itself to compress\nover-limit prompts into dense vectors while keeping the allowed prompts\nunmodified. Dense vectors are then projected into dense tokens via a learnable\nconnector to make the same LLM unburden to understand. The connector is\nsupervised-tuned under the language modeling objective of the LLM on relatively\nlong texts selected from publicly accessed datasets, involving an instruction\ndataset to make SelfCP respond to various prompts, while the target LLM keeps\nfrozen during training. We build the lightweight SelfCP upon 2 different\nbackbones with merely 17M learnable parameters originating from the connector\nand a learnable embedding. Evaluation on both English and Chinese benchmarks\ndemonstrate that SelfCP effectively substitutes 12$\\times$ over-limit prompts\nwith dense tokens to reduce memory costs and booster inference throughputs, yet\nimproving response quality. The outstanding performance brings an efficient\nsolution for LLMs to tackle long prompts without training LLMs from scratch.", "published": "2024-05-27 11:14:55", "link": "http://arxiv.org/abs/2405.17052v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Demonstration Selection and Compression for In-Context Learning", "abstract": "In-context learning (ICL) facilitates large language models (LLMs) exhibiting\nspectacular emergent capabilities in various scenarios. Unfortunately,\nintroducing demonstrations easily makes the prompt length explode, bringing a\nsignificant burden to hardware. In addition, random demonstrations usually\nachieve limited improvements in ICL, necessitating demonstration selection\namong accessible candidates. Previous studies introduce extra modules to\nperform demonstration compression or selection independently. In this paper, we\npropose an ICL framework UniICL, which Unifies demonstration selection and\ncompression, and final response generation via a single frozen LLM.\nSpecifically, UniICL first projects actual demonstrations and inference text\ninputs into short virtual tokens, respectively. Then, virtual tokens are\napplied to select suitable demonstrations by measuring semantic similarity\nwithin latent space among candidate demonstrations and inference input.\nFinally, inference text inputs together with selected virtual demonstrations\nare fed into the same frozen LLM for response generation. Notably, UniICL is a\nparameter-efficient framework that only contains 17M trainable parameters\noriginating from the projection layer. We conduct experiments and analysis over\nin- and out-domain datasets of both generative and understanding tasks,\nencompassing ICL scenarios with plentiful and limited demonstration candidates.\nResults show that UniICL effectively unifies $12 \\times$ compression,\ndemonstration selection, and response generation, efficiently scaling up the\nbaseline from 4-shot to 64-shot ICL in IMDb with 24 GB CUDA allocation", "published": "2024-05-27 11:31:58", "link": "http://arxiv.org/abs/2405.17062v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness", "abstract": "Traditional feedback learning for hallucination reduction relies on\nlabor-intensive manual labeling or expensive proprietary models. This leaves\nthe community without foundational knowledge about how to build high-quality\nfeedback with open-source MLLMs. In this work, we introduce RLAIF-V, a novel\nframework that aligns MLLMs in a fully open-source paradigm. RLAIF-V maximally\nexplores open-source MLLMs from two perspectives, including high-quality\nfeedback data generation for preference learning and self-feedback guidance for\ninference-time scaling. Extensive experiments on six benchmarks in both\nautomatic and human evaluation show that RLAIF-V substantially enhances the\ntrustworthiness of models at both preference learning and inference time.\nRLAIF-V 7B reduces object hallucination by 80.7\\% and overall hallucination by\n33.7\\%. Remarkably, RLAIF-V 12B further reveals the self-alignment potential of\nopen-source MLLMs, where the model can learn from feedback of itself to achieve\nsuper GPT-4V trustworthiness.", "published": "2024-05-27 14:37:01", "link": "http://arxiv.org/abs/2405.17220v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Library for Automatic Natural Language Generation of Spanish Texts", "abstract": "In this article we present a novel system for natural language generation\n(NLG) of Spanish sentences from a minimum set of meaningful words (such as\nnouns, verbs and adjectives) which, unlike other state-of-the-art solutions,\nperforms the NLG task in a fully automatic way, exploiting both knowledge-based\nand statistical approaches. Relying on its linguistic knowledge of vocabulary\nand grammar, the system is able to generate complete, coherent and correctly\nspelled sentences from the main word sets presented by the user. The system,\nwhich was designed to be integrable, portable and efficient, can be easily\nadapted to other languages by design and can feasibly be integrated in a wide\nrange of digital devices. During its development we also created a\nsupplementary lexicon for Spanish, aLexiS, with wide coverage and high\nprecision, as well as syntactic trees from a freely available definite-clause\ngrammar. The resulting NLG library has been evaluated both automatically and\nmanually (annotation). The system can potentially be used in different\napplication domains such as augmentative communication and automatic generation\nof administrative reports or news.", "published": "2024-05-27 15:44:06", "link": "http://arxiv.org/abs/2405.17280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XFormParser: A Simple and Effective Multimodal Multilingual\n  Semi-structured Form Parser", "abstract": "In the domain of Document AI, parsing semi-structured image form is a crucial\nKey Information Extraction (KIE) task. The advent of pre-trained multimodal\nmodels significantly empowers Document AI frameworks to extract key information\nfrom form documents in different formats such as PDF, Word, and images.\nNonetheless, form parsing is still encumbered by notable challenges like subpar\ncapabilities in multilingual parsing and diminished recall in industrial\ncontexts in rich text and rich visuals. In this work, we introduce a simple but\neffective \\textbf{M}ultimodal and \\textbf{M}ultilingual semi-structured\n\\textbf{FORM} \\textbf{PARSER} (\\textbf{XFormParser}), which anchored on a\ncomprehensive Transformer-based pre-trained language model and innovatively\namalgamates semantic entity recognition (SER) and relation extraction (RE) into\na unified framework. Combined with Bi-LSTM, the performance of multilingual\nparsing is significantly improved. Furthermore, we develop InDFormSFT, a\npioneering supervised fine-tuning (SFT) industrial dataset that specifically\naddresses the parsing needs of forms in various industrial contexts.\nXFormParser has demonstrated its unparalleled effectiveness and robustness\nthrough rigorous testing on established benchmarks. Compared to existing\nstate-of-the-art (SOTA) models, XFormParser notably achieves up to 1.79\\% F1\nscore improvement on RE tasks in language-specific settings. It also exhibits\nexceptional cross-task performance improvements in multilingual and zero-shot\nsettings. The codes, datasets, and pre-trained models are publicly available at\nhttps://github.com/zhbuaa0/xformparser.", "published": "2024-05-27 16:37:17", "link": "http://arxiv.org/abs/2405.17336v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank\n  Distribution", "abstract": "Fine-tuning large-scale pre-trained models is inherently a resource-intensive\ntask. While it can enhance the capabilities of the model, it also incurs\nsubstantial computational costs, posing challenges to the practical application\nof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods\nsuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the\ndifferential parameter budget requirements across weight matrices, which may\nlead to suboptimal fine-tuning outcomes. To address this issue, we introduce\nthe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRA\nlayers into structured single-rank components, allowing for dynamic pruning of\nparameter budget based on their importance to specific tasks during training,\nwhich makes the most of the limited parameter budget. Experimental results\ndemonstrate that DoRA can achieve competitive performance compared with LoRA\nand full model fine-tuning, and outperform various strong baselines with the\nsame storage parameter budget. Our code is available at\nhttps://github.com/MIkumikumi0116/DoRA", "published": "2024-05-27 17:02:27", "link": "http://arxiv.org/abs/2405.17357v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an\n  Application to Certified Robustness", "abstract": "This paper reveals a key insight that a one-layer decoder-only Transformer is\nequivalent to a two-layer Recurrent Neural Network (RNN). Building on this\ninsight, we propose ARC-Tran, a novel approach for verifying the robustness of\ndecoder-only Transformers against arbitrary perturbation spaces. Compared to\nARC-Tran, current robustness verification techniques are limited either to\nspecific and length-preserving perturbations like word substitutions or to\nrecursive models like LSTMs. ARC-Tran addresses these limitations by\nmeticulously managing position encoding to prevent mismatches and by utilizing\nour key insight to achieve precise and scalable verification. Our evaluation\nshows that ARC-Tran (1) trains models more robust to arbitrary perturbation\nspaces than those produced by existing techniques and (2) shows high\ncertification accuracy of the resulting models.", "published": "2024-05-27 17:10:04", "link": "http://arxiv.org/abs/2405.17361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Federating Dynamic Models using Early-Exit Architectures for Automatic\n  Speech Recognition on Heterogeneous Clients", "abstract": "Automatic speech recognition models require large amounts of speech\nrecordings for training. However, the collection of such data often is\ncumbersome and leads to privacy concerns. Federated learning has been widely\nused as an effective decentralized technique that collaboratively learns a\nshared prediction model while keeping the data local on different clients.\nUnfortunately, client devices often feature limited computation and\ncommunication resources leading to practical difficulties for large models. In\naddition, the heterogeneity that characterizes edge devices makes it\nsub-optimal to generate a single model that fits all of them. Differently from\nthe recent literature, where multiple models with different architectures are\nused, in this work, we propose using dynamical architectures which, employing\nearly-exit solutions, can adapt their processing (i.e. traversed layers)\ndepending on the input and on the operation conditions. This solution falls in\nthe realm of partial training methods and brings two benefits: a single model\nis used on a variety of devices; federating the models after local training is\nstraightforward. Experiments on public datasets show that our proposed approach\nis effective and can be combined with basic federated learning strategies.", "published": "2024-05-27 17:32:37", "link": "http://arxiv.org/abs/2405.17376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Various Lengths, Constant Speed: Efficient Language Modeling with\n  Lightning Attention", "abstract": "We present Lightning Attention, the first linear attention implementation\nthat maintains a constant training speed for various sequence lengths under\nfixed memory consumption. Due to the issue with cumulative summation operations\n(cumsum), previous linear attention implementations cannot achieve their\ntheoretical advantage in a casual setting. However, this issue can be\neffectively solved by utilizing different attention calculation strategies to\ncompute the different parts of attention. Specifically, we split the attention\ncalculation into intra-blocks and inter-blocks and use conventional attention\ncomputation for intra-blocks and linear attention kernel tricks for\ninter-blocks. This eliminates the need for cumsum in the linear attention\ncalculation. Furthermore, a tiling technique is adopted through both forward\nand backward procedures to take full advantage of the GPU hardware. To enhance\naccuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a new\narchitecture that is tailored to our lightning attention. We conduct rigorous\ntesting on standard and self-collected datasets with varying model sizes and\nsequence lengths. TNL is notably more efficient than other language models. In\naddition, benchmark results indicate that TNL performs on par with\nstate-of-the-art LLMs utilizing conventional transformer structures. The source\ncode is released at github.com/OpenNLPLab/TransnormerLLM.", "published": "2024-05-27 17:38:13", "link": "http://arxiv.org/abs/2405.17381v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlocking the Secrets of Linear Complexity Sequence Model from A Unified\n  Perspective", "abstract": "We present the Linear Complexity Sequence Model (LCSM), a comprehensive\nsolution that unites various sequence modeling techniques with linear\ncomplexity, including linear attention, state space model, long convolution,\nand linear RNN, within a single framework. The goal is to enhance comprehension\nof these models by analyzing the impact of each component from a cohesive and\nstreamlined viewpoint. Specifically, we segment the modeling processes of these\nmodels into three distinct stages: Expand, Oscillation, and Shrink (EOS), with\neach model having its own specific settings. The Expand stage involves\nprojecting the input signal onto a high-dimensional memory state. This is\nfollowed by recursive operations performed on the memory state in the\nOscillation stage. Finally, the memory state is projected back to a\nlow-dimensional space in the Shrink stage. We perform comprehensive experiments\nto analyze the impact of different stage settings on language modeling and\nretrieval tasks. Our results show that data-driven methods are crucial for the\neffectiveness of the three stages in language modeling, whereas hand-crafted\nmethods yield better performance in retrieval tasks.", "published": "2024-05-27 17:38:55", "link": "http://arxiv.org/abs/2405.17383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "THREAD: Thinking Deeper with Recursive Spawning", "abstract": "Large language models (LLMs) have shown impressive capabilities across\ndiverse settings, but still struggle as the length and complexity of the\ncontext increases. To address this challenge, we propose Thinking Recursively\nand Dynamically (ThReaD). THREAD frames model generation as a thread of\nexecution that, based on the context, can run to completion or dynamically\nspawn new threads. By spawning, threads can offload work (e.g., thinking,\nretrieving information) to child threads, which only return tokens needed for\nthe parent thread to do its work. In effect, this enables the model to adapt,\nas needed, the amount of intermediate work used to produce tokens. We apply\nTHREAD in the settings of LLM task solving and question answering, where the\ndynamic threading allows the model to recursively decompose the given task or\nquestion into progressively simpler sub-problems that can be solved by separate\nchild threads. We test THREAD, implemented using a few-shot learning approach,\non diverse benchmarks for agent tasks and data-grounded question answering.\nTHREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these\nbenchmarks, including ALFWorld, TextCraft, and WebShop, along with two new\nbenchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD\noutperforms existing frameworks by 10% to 50% absolute points with smaller\nmodels, including Llama-3-8b and CodeLlama-7b.", "published": "2024-05-27 17:51:24", "link": "http://arxiv.org/abs/2405.17402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal\n  Stories with LLMs", "abstract": "Empathy serves as a cornerstone in enabling prosocial behaviors, and can be\nevoked through sharing of personal experiences in stories. While empathy is\ninfluenced by narrative content, intuitively, people respond to the way a story\nis told as well, through narrative style. Yet the relationship between empathy\nand narrative style is not fully understood. In this work, we empirically\nexamine and quantify this relationship between style and empathy using LLMs and\nlarge-scale crowdsourcing studies. We introduce a novel, theory-based taxonomy,\nHEART (Human Empathy and Narrative Taxonomy) that delineates elements of\nnarrative style that can lead to empathy with the narrator of a story. We\nestablish the performance of LLMs in extracting narrative elements from HEART,\nshowing that prompting with our taxonomy leads to reasonable, human-level\nannotations beyond what prior lexicon-based methods can do. To show empirical\nuse of our taxonomy, we collect a dataset of empathy judgments of stories via a\nlarge-scale crowdsourcing study with N=2,624 participants. We show that\nnarrative elements extracted via LLMs, in particular, vividness of emotions and\nplot volume, can elucidate the pathways by which narrative style cultivates\nempathy towards personal stories. Our work suggests that such models can be\nused for narrative analyses that lead to human-centered social and behavioral\ninsights.", "published": "2024-05-27 20:00:38", "link": "http://arxiv.org/abs/2405.17633v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Ready Are Generative Pre-trained Large Language Models for\n  Explaining Bengali Grammatical Errors?", "abstract": "Grammatical error correction (GEC) tools, powered by advanced generative\nartificial intelligence (AI), competently correct linguistic inaccuracies in\nuser input. However, they often fall short in providing essential natural\nlanguage explanations, which are crucial for learning languages and gaining a\ndeeper understanding of the grammatical rules. There is limited exploration of\nthese tools in low-resource languages such as Bengali. In such languages,\ngrammatical error explanation (GEE) systems should not only correct sentences\nbut also provide explanations for errors. This comprehensive approach can help\nlanguage learners in their quest for proficiency. Our work introduces a\nreal-world, multi-domain dataset sourced from Bengali speakers of varying\nproficiency levels and linguistic complexities. This dataset serves as an\nevaluation benchmark for GEE systems, allowing them to use context information\nto generate meaningful explanations and high-quality corrections. Various\ngenerative pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, Text-davinci-003, Text-babbage-001, Text-curie-001,\nText-ada-001, Llama-2-7b, Llama-2-13b, and Llama-2-70b, are assessed against\nhuman experts for performance comparison. Our research underscores the\nlimitations in the automatic deployment of current state-of-the-art generative\npre-trained LLMs for Bengali GEE. Advocating for human intervention, our\nfindings propose incorporating manual checks to address grammatical errors and\nimprove feedback quality. This approach presents a more suitable strategy to\nrefine the GEC tools in Bengali, emphasizing the educational aspect of language\nlearning.", "published": "2024-05-27 15:56:45", "link": "http://arxiv.org/abs/2406.00039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unveiling Themes in Judicial Proceedings: A Cross-Country Study Using\n  Topic Modeling on Legal Documents from India and the UK", "abstract": "Legal documents are indispensable in every country for legal practices and\nserve as the primary source of information regarding previous cases and\nemployed statutes. In today's world, with an increasing number of judicial\ncases, it is crucial to systematically categorize past cases into subgroups,\nwhich can then be utilized for upcoming cases and practices. Our primary focus\nin this endeavor was to annotate cases using topic modeling algorithms such as\nLatent Dirichlet Allocation, Non-Negative Matrix Factorization, and Bertopic\nfor a collection of lengthy legal documents from India and the UK. This step is\ncrucial for distinguishing the generated labels between the two countries,\nhighlighting the differences in the types of cases that arise in each\njurisdiction. Furthermore, an analysis of the timeline of cases from India was\nconducted to discern the evolution of dominant topics over the years.", "published": "2024-05-27 16:26:50", "link": "http://arxiv.org/abs/2406.00040v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QUB-Cirdan at \"Discharge Me!\": Zero shot discharge letter generation by\n  open-source LLM", "abstract": "The BioNLP ACL'24 Shared Task on Streamlining Discharge Documentation aims to\nreduce the administrative burden on clinicians by automating the creation of\ncritical sections of patient discharge letters. This paper presents our\napproach using the Llama3 8B quantized model to generate the \"Brief Hospital\nCourse\" and \"Discharge Instructions\" sections. We employ a zero-shot method\ncombined with Retrieval-Augmented Generation (RAG) to produce concise,\ncontextually accurate summaries. Our contributions include the development of a\ncurated template-based approach to ensure reliability and consistency, as well\nas the integration of RAG for word count prediction. We also describe several\nunsuccessful experiments to provide insights into our pathway for the\ncompetition. Our results demonstrate the effectiveness and efficiency of our\napproach, achieving high scores across multiple evaluation metrics.", "published": "2024-05-27 17:55:36", "link": "http://arxiv.org/abs/2406.00041v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoPSV: Automated Process-Supervised Verifier", "abstract": "In this work, we propose a novel method named \\textbf{Auto}mated\n\\textbf{P}rocess-\\textbf{S}upervised \\textbf{V}erifier\n(\\textbf{\\textsc{AutoPSV}}) to enhance the reasoning capabilities of large\nlanguage models (LLMs) by automatically annotating the reasoning steps.\n\\textsc{AutoPSV} begins by training a verification model on the correctness of\nfinal answers, enabling it to generate automatic process annotations. This\nverification model assigns a confidence score to each reasoning step,\nindicating the probability of arriving at the correct final answer from that\npoint onward. We detect relative changes in the verification's confidence\nscores across reasoning steps to automatically annotate the reasoning process,\nenabling error detection even in scenarios where ground truth answers are\nunavailable. This alleviates the need for numerous manual annotations or the\nhigh computational costs associated with model-induced annotation approaches.\nWe experimentally validate that the step-level confidence changes learned by\nthe verification model trained on the final answer correctness can effectively\nidentify errors in the reasoning steps. We demonstrate that the verification\nmodel, when trained on process annotations generated by \\textsc{AutoPSV},\nexhibits improved performance in selecting correct answers from multiple\nLLM-generated outputs. Notably, we achieve substantial improvements across five\ndatasets in mathematics and commonsense reasoning. The source code of\n\\textsc{AutoPSV} is available at \\url{https://github.com/rookie-joe/AutoPSV}.", "published": "2024-05-27 03:44:24", "link": "http://arxiv.org/abs/2405.16802v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entity Alignment with Noisy Annotations from Large Language Models", "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. While existing methods heavily rely on human-generated\nlabels, it is prohibitively expensive to incorporate cross-domain experts for\nannotation in real-world scenarios. The advent of Large Language Models (LLMs)\npresents new avenues for automating EA with annotations, inspired by their\ncomprehensive capability to process semantic information. However, it is\nnontrivial to directly apply LLMs for EA since the annotation space in\nreal-world KGs is large. LLMs could also generate noisy labels that may mislead\nthe alignment. To this end, we propose a unified framework, LLM4EA, to\neffectively leverage LLMs for EA. Specifically, we design a novel active\nlearning policy to significantly reduce the annotation space by prioritizing\nthe most valuable entities based on the entire inter-KG and intra-KG structure.\nMoreover, we introduce an unsupervised label refiner to continuously enhance\nlabel accuracy through in-depth probabilistic reasoning. We iteratively\noptimize the policy based on the feedback from a base EA model. Extensive\nexperiments demonstrate the advantages of LLM4EA on four benchmark datasets in\nterms of effectiveness, robustness, and efficiency. Codes are available via\nhttps://github.com/chensyCN/llm4ea_official.", "published": "2024-05-27 03:52:55", "link": "http://arxiv.org/abs/2405.16806v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multiple Heads are Better than One: Mixture of Modality Knowledge\n  Experts for Entity Representation Learning", "abstract": "Learning high-quality multi-modal entity representations is an important goal\nof multi-modal knowledge graph (MMKG) representation learning, which can\nenhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The\nmain challenge is to collaboratively model the structural information concealed\nin massive triples and the multi-modal features of the entities. Existing\nmethods focus on crafting elegant entity-wise multi-modal fusion strategies,\nyet they overlook the utilization of multi-perspective features concealed\nwithin the modalities under diverse relational contexts. To address this issue,\nwe introduce a novel framework with Mixture of Modality Knowledge experts\n(MoMoK for short) to learn adaptive multi-modal entity representations for\nbetter MMKGC. We design relation-guided modality knowledge experts to acquire\nrelation-aware modality embeddings and integrate the predictions from\nmulti-modalities to achieve joint decisions. Additionally, we disentangle the\nexperts by minimizing their mutual information. Experiments on four public MMKG\nbenchmarks demonstrate the outstanding performance of MoMoK under complex\nscenarios.", "published": "2024-05-27 06:36:17", "link": "http://arxiv.org/abs/2405.16869v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Match, Compare, or Select? An Investigation of Large Language Models for\n  Entity Matching", "abstract": "Entity matching (EM) is a critical step in entity resolution (ER). Recently,\nentity matching based on large language models (LLMs) has shown great promise.\nHowever, current LLM-based entity matching approaches typically follow a binary\nmatching paradigm that ignores the global consistency among record\nrelationships. In this paper, we investigate various methodologies for\nLLM-based entity matching that incorporate record interactions from different\nperspectives. Specifically, we comprehensively compare three representative\nstrategies: matching, comparing, and selecting, and analyze their respective\nadvantages and challenges in diverse scenarios. Based on our findings, we\nfurther design a compound entity matching framework (ComEM) that leverages the\ncomposition of multiple strategies and LLMs. ComEM benefits from the advantages\nof different sides and achieves improvements in both effectiveness and\nefficiency. Experimental results on 8 ER datasets and 10 LLMs verify the\nsuperiority of incorporating record interactions through the selecting\nstrategy, as well as the further cost-effectiveness brought by ComEM.", "published": "2024-05-27 07:05:27", "link": "http://arxiv.org/abs/2405.16884v3", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Empowering Large Language Models to Set up a Knowledge Retrieval Indexer\n  via Self-Learning", "abstract": "Retrieval-Augmented Generation (RAG) offers a cost-effective approach to\ninjecting real-time knowledge into large language models (LLMs). Nevertheless,\nconstructing and validating high-quality knowledge repositories require\nconsiderable effort. We propose a pre-retrieval framework named Pseudo-Graph\nRetrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students\nby providing them with abundant raw reading materials and encouraging them to\nengage in autonomous reading to record factual information in their own words.\nThe resulting concise, well-organized mental indices are interconnected through\ncommon topics or complementary facts to form a pseudo-graph database. During\nthe retrieval phase, PG-RAG mimics the human behavior in flipping through\nnotes, identifying fact paths and subsequently exploring the related contexts.\nAdhering to the principle of the path taken by many is the best, it integrates\nhighly corroborated fact paths to provide a structured and refined sub-graph\nassisting LLMs. We validated PG-RAG on three specialized question-answering\ndatasets. In single-document tasks, PG-RAG significantly outperformed the\ncurrent best baseline, KGP-LLaMA, across all key evaluation metrics, with an\naverage overall performance improvement of 11.6%. Specifically, its BLEU score\nincreased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In\nmulti-document scenarios, the average metrics of PG-RAG were at least 2.35%\nhigher than the best baseline. Notably, the BLEU score and QE-F1 metric showed\nstable improvements of around 7.55% and 12.75%, respectively. Our code:\nhttps://github.com/IAAR-Shanghai/PGRAG.", "published": "2024-05-27 08:26:45", "link": "http://arxiv.org/abs/2405.16933v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Exploring the LLM Journey from Cognition to Expression with Linear\n  Representations", "abstract": "This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.", "published": "2024-05-27 08:57:04", "link": "http://arxiv.org/abs/2405.16964v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Multi-Range Theory of Translation Quality Measurement: MQM scoring\n  models and Statistical Quality Control", "abstract": "The year 2024 marks the 10th anniversary of the Multidimensional Quality\nMetrics (MQM) framework for analytic translation quality evaluation. The MQM\nerror typology has been widely used by practitioners in the translation and\nlocalization industry and has served as the basis for many derivative projects.\nThe annual Conference on Machine Translation (WMT) shared tasks on both human\nand automatic translation quality evaluations used the MQM error typology.\n  The metric stands on two pillars: error typology and the scoring model. The\nscoring model calculates the quality score from annotation data, detailing how\nto convert error type and severity counts into numeric scores to determine if\nthe content meets specifications. Previously, only the raw scoring model had\nbeen published. This April, the MQM Council published the Linear Calibrated\nScoring Model, officially presented herein, along with the Non-Linear Scoring\nModel, which had not been published before.\n  This paper details the latest MQM developments and presents a universal\napproach to translation quality measurement across three sample size ranges. It\nalso explains why Statistical Quality Control should be used for very small\nsample sizes, starting from a single sentence.", "published": "2024-05-27 09:06:24", "link": "http://arxiv.org/abs/2405.16969v5", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for\n  Controllable Language Generation", "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural\nlanguage processing, yet their limited controllability poses a significant\nchallenge for downstream applications. We aim to address this by drawing\ninspiration from the neural mechanisms of the human brain, specifically Broca's\nand Wernicke's areas, which are crucial for language generation and\ncomprehension, respectively. In particular, Broca's area receives cognitive\ndecision signals from Wernicke's area, treating the language generation as an\nintricate decision-making process, which differs from the fully auto-regressive\nlanguage generation of existing LLMs. In a similar vein, our proposed system,\nthe BWArea model, conceptualizes language generation as a decision-making task.\nThis model has three components: a language world model, an inverse dynamics\nmodel, and a cognitive policy. Like Wernicke's area, the inverse dynamics model\nis designed to deduce the underlying cognitive intentions, or latent actions,\nbehind each token. The BWArea model is amenable to both pre-training and\nfine-tuning like existing LLMs. With 30B clean pre-training tokens, we have\ntrained a BWArea model, which achieves competitive performance with LLMs of\nequal size (1B parameters). Unlike fully auto-regressive LLMs, its pre-training\nperformance does not degenerate if dirty data unintentionally appears. This\nshows the advantage of a decomposed structure of BWArea model in reducing\nefforts in laborious data selection and labeling. Finally, we reveal that the\nBWArea model offers enhanced controllability via fine-tuning the cognitive\npolicy with downstream reward metrics, thereby facilitating alignment with\ngreater simplicity. On 9 out of 10 tasks from two suites, TextWorld and\nBigBench Hard, our method shows superior performance to auto-regressive LLMs.", "published": "2024-05-27 10:45:49", "link": "http://arxiv.org/abs/2405.17039v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off\n  Code Generation", "abstract": "Code generation plays a crucial role in various tasks, such as code\nauto-completion and mathematical reasoning. Previous work has proposed numerous\nmethods to enhance code generation performance, including integrating feedback\nfrom the compiler. Inspired by this, we present ReflectionCoder, a novel\napproach that effectively leverages reflection sequences constructed by\nintegrating compiler feedback to improve one-off code generation performance.\nFurthermore, we propose reflection self-distillation and dynamically masked\ndistillation to effectively utilize these reflection sequences. Extensive\nexperiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,\ndemonstrate that models fine-tuned with our method achieve state-of-the-art\nperformance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9\n(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo\nand Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we\nbelieve this approach can benefit other domains that focus on final results and\nrequire long reasoning paths. Code and data are available at\nhttps://github.com/SenseLLM/ReflectionCoder.", "published": "2024-05-27 11:27:00", "link": "http://arxiv.org/abs/2405.17057v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tokenization Matters! Degrading Large Language Models through\n  Challenging Their Tokenization", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. Nonetheless, it was also witnessed that LLMs tend\nto produce inaccurate responses to specific queries. This deficiency can be\ntraced to the tokenization step LLMs must undergo, which is an inevitable\nlimitation inherent to all LLMs. In fact, incorrect tokenization is the\ncritical point that hinders LLMs in understanding the input precisely, thus\nleading to unsatisfactory output. To demonstrate this flaw of LLMs, we\nconstruct an adversarial dataset, named as $\\textbf{ADT (Adversarial Dataset\nfor Tokenizer)}$, which draws upon the vocabularies of various open-source LLMs\nto challenge LLMs' tokenization. ADT consists of two subsets: the manually\nconstructed ADT-Human and the automatically generated ADT-Auto. Our empirical\nresults reveal that our ADT is highly effective on challenging the tokenization\nof leading LLMs, including GPT-4o, Llama-3, Qwen2.5-max and so on, thus\ndegrading these LLMs' capabilities. Moreover, our method of automatic data\ngeneration has been proven efficient and robust, which can be applied to any\nopen-source LLMs. To the best of our knowledge, our study is the first to\ninvestigating LLMs' vulnerability in terms of challenging their token\nsegmentation, which will shed light on the subsequent research of improving\nLLMs' capabilities through optimizing their tokenization process and\nalgorithms.", "published": "2024-05-27 11:39:59", "link": "http://arxiv.org/abs/2405.17067v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering Character-level Text Infilling by Eliminating Sub-Tokens", "abstract": "In infilling tasks, sub-tokens, representing instances where a complete token\nis segmented into two parts, often emerge at the boundaries of prefixes,\nmiddles, and suffixes. Traditional methods focused on training models at the\ntoken level, leading to sub-optimal performance in character-level infilling\ntasks during the inference stage. Alternately, some approaches considered\ncharacter-level infilling, but they relied on predicting sub-tokens in\ninference, yet this strategy diminished ability in character-level infilling\ntasks due to the large perplexity of the model on sub-tokens. In this paper, we\nintroduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and\nEnding character constraints. The proposed method addresses character-level\ninfilling tasks by utilizing a line-level format to avoid predicting any\nsub-token in inference. In addition, we incorporate two special tokens to\nsignify the rest of the incomplete lines, thereby enhancing generation\nguidance. Extensive experiments demonstrate that our proposed approach\nsurpasses previous methods, offering a significant advantage. Code is available\nat https://github.com/SenseLLM/FIM-SE.", "published": "2024-05-27 12:21:48", "link": "http://arxiv.org/abs/2405.17103v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TEII: Think, Explain, Interact and Iterate with Large Language Models to\n  Solve Cross-lingual Emotion Detection", "abstract": "Cross-lingual emotion detection allows us to analyze global trends, public\nopinion, and social phenomena at scale. We participated in the Explainability\nof Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score\nof 0.6046 on the evaluation set for the emotion detection sub-task. Our system\noutperformed the baseline by more than 0.16 F1-score absolute, and ranked\nsecond amongst competing systems. We conducted experiments using fine-tuning,\nzero-shot learning, and few-shot learning for Large Language Model (LLM)-based\nmodels as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.\nAdditionally, we introduced two novel methods: the Multi-Iteration Agentic\nWorkflow and the Multi-Binary-Classifier Agentic Workflow. We found that\nLLM-based approaches provided good performance on multilingual emotion\ndetection. Furthermore, ensembles combining all our experimented models yielded\nhigher F1-scores than any single approach alone.", "published": "2024-05-27 12:47:40", "link": "http://arxiv.org/abs/2405.17129v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploiting the Layered Intrinsic Dimensionality of Deep Models for\n  Practical Adversarial Training", "abstract": "Despite being a heavily researched topic, Adversarial Training (AT) is\nrarely, if ever, deployed in practical AI systems for two primary reasons: (i)\nthe gained robustness is frequently accompanied by a drop in generalization and\n(ii) generating adversarial examples (AEs) is computationally prohibitively\nexpensive. To address these limitations, we propose SMAAT, a new AT algorithm\nthat leverages the manifold conjecture, stating that off-manifold AEs lead to\nbetter robustness while on-manifold AEs result in better generalization.\nSpecifically, SMAAT aims at generating a higher proportion of off-manifold AEs\nby perturbing the intermediate deepnet layer with the lowest intrinsic\ndimension. This systematically results in better scalability compared to\nclassical AT as it reduces the PGD chains length required for generating the\nAEs. Additionally, our study provides, to the best of our knowledge, the first\nexplanation for the difference in the generalization and robustness trends\nbetween vision and language models, ie., AT results in a drop in generalization\nin vision models whereas, in encoder-based language models, generalization\neither improves or remains unchanged. We show that vision transformers and\ndecoder-based models tend to have low intrinsic dimensionality in the earlier\nlayers of the network (more off-manifold AEs), while encoder-based models have\nlow intrinsic dimensionality in the later layers. We demonstrate the efficacy\nof SMAAT; on several tasks, including robustifying (i) sentiment classifiers,\n(ii) safety filters in decoder-based models, and (iii) retrievers in RAG\nsetups. SMAAT requires only 25-33% of the GPU time compared to standard AT,\nwhile significantly improving robustness across all applications and\nmaintaining comparable generalization.", "published": "2024-05-27 12:48:30", "link": "http://arxiv.org/abs/2405.17130v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Collage is the New Writing: Exploring the Fragmentation of Text and User\n  Interfaces in AI Tools", "abstract": "This essay proposes and explores the concept of Collage for the design of AI\nwriting tools, transferred from avant-garde literature with four facets: 1)\nfragmenting text in writing interfaces, 2) juxtaposing voices (content vs\ncommand), 3) integrating material from multiple sources (e.g. text\nsuggestions), and 4) shifting from manual writing to editorial and\ncompositional decision-making, such as selecting and arranging snippets. The\nessay then employs Collage as an analytical lens to analyse the user interface\ndesign of recent AI writing tools, and as a constructive lens to inspire new\ndesign directions. Finally, a critical perspective relates the concerns that\nwriters historically expressed through literary collage to AI writing tools. In\na broad view, this essay explores how literary concepts can help advance design\ntheory around AI writing tools. It encourages creators of future writing tools\nto engage not only with new technological possibilities, but also with past\nwriting innovations.", "published": "2024-05-27 14:35:17", "link": "http://arxiv.org/abs/2405.17217v1", "categories": ["cs.HC", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Assessing LLMs Suitability for Knowledge Graph Completion", "abstract": "Recent work has shown the capability of Large Language Models (LLMs) to solve\ntasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in\nZero- or Few-Shot paradigms. However, they are known to hallucinate answers, or\noutput results in a non-deterministic manner, thus leading to wrongly reasoned\nresponses, even if they satisfy the user's demands. To highlight opportunities\nand challenges in knowledge graphs-related tasks, we experiment with three\ndistinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and\nGPT-4o, on Knowledge Graph Completion for static knowledge graphs, using\nprompts constructed following the TELeR taxonomy, in Zero- and One-Shot\ncontexts, on a Task-Oriented Dialogue system use case. When evaluated using\nboth strict and flexible metrics measurement manners, our results show that\nLLMs could be fit for such a task if prompts encapsulate sufficient information\nand relevant examples.", "published": "2024-05-27 15:04:50", "link": "http://arxiv.org/abs/2405.17249v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Noise Robustness of In-Context Learning for Text Generation", "abstract": "Large language models (LLMs) have shown impressive performance on downstream\ntasks by in-context learning (ICL), which heavily relies on the quality of\ndemonstrations selected from a large set of annotated examples. Recent works\nclaim that in-context learning is robust to noisy demonstrations in text\nclassification. In this work, we show that, on text generation tasks, noisy\nannotations significantly hurt the performance of in-context learning. To\ncircumvent the issue, we propose a simple and effective approach called Local\nPerplexity Ranking (LPR), which replaces the \"noisy\" candidates with their\nnearest neighbors that are more likely to be clean. Our method is motivated by\nanalyzing the perplexity deviation caused by noisy labels and decomposing\nperplexity into inherent perplexity and matching perplexity. Our key idea\nbehind LPR is thus to decouple the matching perplexity by performing the\nranking among the neighbors in semantic space. Our approach can prevent the\nselected demonstrations from including mismatched input-label pairs while\npreserving the effectiveness of the original selection methods. Extensive\nexperiments demonstrate the effectiveness of LPR, improving the EM score by up\nto 18.75 on common benchmarks with noisy annotations. Our code is available at\nhttps://github.com/ml-stat-Sustech/Local-Perplexity-Ranking.", "published": "2024-05-27 15:22:58", "link": "http://arxiv.org/abs/2405.17264v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An NLP Crosswalk Between the Common Core State Standards and NAEP Item\n  Specifications", "abstract": "Natural language processing (NLP) is rapidly developing for applications in\neducational assessment. In this paper, I describe an NLP-based procedure that\ncan be used to support subject matter experts in establishing a crosswalk\nbetween item specifications and content standards. This paper extends recent\nwork by proposing and demonstrating the use of multivariate similarity based on\nembedding vectors for sentences or texts. In particular, a hybrid regression\nprocedure is demonstrated for establishing the match of each content standard\nto multiple item specifications. The procedure is used to evaluate the match of\nthe Common Core State Standards (CCSS) for mathematics at grade 4 to the\ncorresponding item specifications for the 2026 National Assessment of\nEducational Progress (NAEP).", "published": "2024-05-27 15:47:46", "link": "http://arxiv.org/abs/2405.17284v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cost-efficient Knowledge-based Question Answering with Large Language\n  Models", "abstract": "Knowledge-based question answering (KBQA) is widely used in many scenarios\nthat necessitate domain knowledge. Large language models (LLMs) bring\nopportunities to KBQA, while their costs are significantly higher and absence\nof domain-specific knowledge during pre-training. We are motivated to combine\nLLMs and prior small models on knowledge graphs (KGMs) for both inferential\naccuracy and cost saving. However, it remains challenging since accuracy and\ncost are not readily combined in the optimization as two distinct metrics. It\nis also laborious for model selection since different models excel in diverse\nknowledge. To this end, we propose Coke, a novel cost-efficient strategy for\nKBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize\ncalls to LLMs within limited budgets. We first formulate the accuracy\nexpectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A\ncontext-aware policy is optimized to further distinguish the expert model\nsubject to the question semantics. The overall decision is bounded by the cost\nregret according to historical expenditure on failures. Extensive experiments\nshowcase the superior performance of Coke, which moves the Pareto frontier with\nup to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on\nthe benchmark datasets.", "published": "2024-05-27 16:37:34", "link": "http://arxiv.org/abs/2405.17337v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring and steering the moral compass of Large Language Models", "abstract": "Large Language Models (LLMs) have become central to advancing automation and\ndecision-making across various sectors, raising significant ethical questions.\nThis study proposes a comprehensive comparative analysis of the most advanced\nLLMs to assess their moral profiles. We subjected several state-of-the-art\nmodels to a selection of ethical dilemmas and found that all the proprietary\nones are mostly utilitarian and all of the open-weights ones align mostly with\nvalues-based ethics. Furthermore, when using the Moral Foundations\nQuestionnaire, all models we probed - except for Llama 2-7B - displayed a\nstrong liberal bias. Lastly, in order to causally intervene in one of the\nstudied models, we propose a novel similarity-specific activation steering\ntechnique. Using this method, we were able to reliably steer the model's moral\ncompass to different ethical schools. All of these results showcase that there\nis an ethical dimension in already deployed LLMs, an aspect that is generally\noverlooked.", "published": "2024-05-27 16:49:22", "link": "http://arxiv.org/abs/2405.17345v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ReMoDetect: Reward Models Recognize Aligned LLM's Generations", "abstract": "The remarkable capabilities and easy accessibility of large language models\n(LLMs) have significantly increased societal risks (e.g., fake news\ngeneration), necessitating the development of LLM-generated text (LGT)\ndetection methods for safe usage. However, detecting LGTs is challenging due to\nthe vast number of LLMs, making it impractical to account for each LLM\nindividually; hence, it is crucial to identify the common characteristics\nshared by these models. In this paper, we draw attention to a common feature of\nrecent powerful LLMs, namely the alignment training, i.e., training LLMs to\ngenerate human-preferable texts. Our key finding is that as these aligned LLMs\nare trained to maximize the human preferences, they generate texts with higher\nestimated preferences even than human-written texts; thus, such texts are\neasily detected by using the reward model (i.e., an LLM trained to model human\npreference distribution). Based on this finding, we propose two training\nschemes to further improve the detection ability of the reward model, namely\n(i) continual preference fine-tuning to make the reward model prefer aligned\nLGTs even further and (ii) reward modeling of Human/LLM mixed texts (a\nrephrased texts from human-written texts using aligned LLMs), which serves as a\nmedian preference text corpus between LGTs and human-written texts to learn the\ndecision boundary better. We provide an extensive evaluation by considering six\ntext domains across twelve aligned LLMs, where our method demonstrates\nstate-of-the-art results. Code is available at\nhttps://github.com/hyunseoklee-ai/ReMoDetect.", "published": "2024-05-27 17:38:33", "link": "http://arxiv.org/abs/2405.17382v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MindMerger: Efficient Boosting LLM Reasoning in non-English Languages", "abstract": "Reasoning capabilities are crucial for Large Language Models (LLMs), yet a\nnotable gap exists between English and non-English languages. To bridge this\ndisparity, some works fine-tune LLMs to relearn reasoning capabilities in\nnon-English languages, while others replace non-English inputs with an external\nmodel's outputs such as English translation text to circumvent the challenge of\nLLM understanding non-English. Unfortunately, these methods often underutilize\nthe built-in skilled reasoning and useful language understanding capabilities\nof LLMs. In order to better utilize the minds of reasoning and language\nunderstanding in LLMs, we propose a new method, namely MindMerger, which merges\nLLMs with the external language understanding capabilities from multilingual\nmodels to boost the multilingual reasoning performance. Furthermore, a two-step\ntraining scheme is introduced to first train to embeded the external\ncapabilities into LLMs and then train the collaborative utilization of the\nexternal capabilities and the built-in capabilities in LLMs. Experiments on\nthree multilingual reasoning datasets and a language understanding dataset\ndemonstrate that MindMerger consistently outperforms all baselines, especially\nin low-resource languages. Without updating the parameters of LLMs, the average\naccuracy improved by 6.7% and 8.0% across all languages and low-resource\nlanguages on the MGSM dataset, respectively.", "published": "2024-05-27 17:41:54", "link": "http://arxiv.org/abs/2405.17386v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KSW: Khmer Stop Word based Dictionary for Keyword Extraction", "abstract": "This paper introduces KSW, a Khmer-specific approach to keyword extraction\nthat leverages a specialized stop word dictionary. Due to the limited\navailability of natural language processing resources for the Khmer language,\neffective keyword extraction has been a significant challenge. KSW addresses\nthis by developing a tailored stop word dictionary and implementing a\npreprocessing methodology to remove stop words, thereby enhancing the\nextraction of meaningful keywords. Our experiments demonstrate that KSW\nachieves substantial improvements in accuracy and relevance compared to\nprevious methods, highlighting its potential to advance Khmer text processing\nand information retrieval. The KSW resources, including the stop word\ndictionary, are available at the following GitHub repository:\n(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git).", "published": "2024-05-27 17:42:54", "link": "http://arxiv.org/abs/2405.17390v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Privacy-Aware Visual Language Models", "abstract": "This paper aims to advance our understanding of how Visual Language Models\n(VLMs) handle privacy-sensitive information, a crucial concern as these\ntechnologies become integral to everyday life. To this end, we introduce a new\nbenchmark PrivBench, which contains images from 8 sensitive categories such as\npassports, or fingerprints. We evaluate 10 state-of-the-art VLMs on this\nbenchmark and observe a generally limited understanding of privacy,\nhighlighting a significant area for model improvement. Based on this we\nintroduce PrivTune, a new instruction-tuning dataset aimed at equipping VLMs\nwith knowledge about visual privacy. By tuning two pretrained VLMs, TinyLLaVa\nand MiniGPT-v2, on this small dataset, we achieve strong gains in their ability\nto recognize sensitive content, outperforming even GPT4-V. At the same time, we\nshow that privacy-tuning only minimally affects the VLMs performance on\nstandard benchmarks such as VQA. Overall, this paper lays out a crucial\nchallenge for making VLMs effective in handling real-world data safely and\nprovides a simple recipe that takes the first step towards building\nprivacy-aware VLMs.", "published": "2024-05-27 17:59:25", "link": "http://arxiv.org/abs/2405.17423v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generative Query Reformulation Using Ensemble Prompting, Document\n  Fusion, and Relevance Feedback", "abstract": "Query Reformulation (QR) is a set of techniques used to transform a user's\noriginal search query to a text that better aligns with the user's intent and\nimproves their search experience. Recently, zero-shot QR has been a promising\napproach due to its ability to exploit knowledge inherent in large language\nmodels. Inspired by the success of ensemble prompting strategies which have\nbenefited other tasks, we investigate if they can improve query reformulation.\nIn this context, we propose two ensemble-based prompting techniques,\nGenQREnsemble and GenQRFusion which leverage paraphrases of a zero-shot\ninstruction to generate multiple sets of keywords to improve retrieval\nperformance ultimately. We further introduce their post-retrieval variants to\nincorporate relevance feedback from a variety of sources, including an oracle\nsimulating a human user and a \"critic\" LLM. We demonstrate that an ensemble of\nquery reformulations can improve retrieval effectiveness by up to 18% on\nnDCG@10 in pre-retrieval settings and 9% on post-retrieval settings on multiple\nbenchmarks, outperforming all previously reported SOTA results. We perform\nsubsequent analyses to investigate the effects of feedback documents,\nincorporate domain-specific instructions, filter reformulations, and generate\nfluent reformulations that might be more beneficial to human searchers.\nTogether, the techniques and the results presented in this paper establish a\nnew state of the art in automated query reformulation for retrieval and suggest\npromising directions for future research.", "published": "2024-05-27 21:03:26", "link": "http://arxiv.org/abs/2405.17658v1", "categories": ["cs.IR", "cs.CL", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Mechanistic Interpretability of Binary and Ternary Transformers", "abstract": "Recent research (arXiv:2310.11453, arXiv:2402.17764) has proposed binary and\nternary transformer networks as a way to significantly reduce memory and\nimprove inference speed in Large Language Models (LLMs) while maintaining\naccuracy. In this work, we apply techniques from mechanistic interpretability\nto investigate whether such networks learn distinctly different or similar\nalgorithms when compared to full-precision transformer networks. In particular,\nwe reverse engineer the algorithms learned for the toy problem of modular\naddition where we find that binary and ternary networks learn similar\nalgorithms as full precision networks. This provides evidence against the\npossibility of using binary and ternary networks as a more interpretable\nalternative in the LLM setting.", "published": "2024-05-27 23:22:23", "link": "http://arxiv.org/abs/2405.17703v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Aligning LLMs through Multi-perspective User Preference Ranking-based\n  Feedback for Programming Question Answering", "abstract": "Code Community Question Answering (CCQA) seeks to tackle programming-related\nissues, thereby boosting productivity in both software engineering and academic\nresearch. Recent advancements in Reinforcement Learning from Human Feedback\n(RLHF) have transformed the fine-tuning process of Large Language Models (LLMs)\nto produce responses that closely mimic human behavior. Leveraging LLMs with\nRLHF for practical CCQA applications has thus emerged as a promising area of\nstudy. Unlike standard code question-answering tasks, CCQA involves multiple\npossible answers, with varying user preferences for each response.\nAdditionally, code communities often show a preference for new APIs. These\nchallenges prevent LLMs from generating responses that cater to the diverse\npreferences of users in CCQA tasks. To address these issues, we propose a novel\nframework called Aligning LLMs through Multi-perspective User Preference\nRanking-based Feedback for Programming Question Answering (ALMupQA) to create\nuser-focused responses. Our approach starts with Multi-perspective Preference\nRanking Alignment (MPRA), which synthesizes varied user preferences based on\nthe characteristics of answers from code communities. We then introduce a\nRetrieval-augmented In-context Learning (RIL) module to mitigate the problem of\noutdated answers by retrieving responses to similar questions from a question\nbank. Due to the limited availability of high-quality, multi-answer CCQA\ndatasets, we also developed a dataset named StaCCQA from real code communities.\nExtensive experiments demonstrated the effectiveness of the ALMupQA framework\nin terms of accuracy and user preference. Compared to the base model, ALMupQA\nshowed nearly an 11% improvement in BLEU, with increases of 20% and 17.5% in\nBERTScore and CodeBERTScore, respectively.", "published": "2024-05-27 14:21:31", "link": "http://arxiv.org/abs/2406.00037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ViSpeR: Multilingual Audio-Visual Speech Recognition", "abstract": "This work presents an extensive and detailed study on Audio-Visual Speech\nRecognition (AVSR) for five widely spoken languages: Chinese, Spanish, English,\nArabic, and French. We have collected large-scale datasets for each language\nexcept for English, and have engaged in the training of supervised learning\nmodels. Our model, ViSpeR, is trained in a multi-lingual setting, resulting in\ncompetitive performance on newly established benchmarks for each language. The\ndatasets and models are released to the community with an aim to serve as a\nfoundation for triggering and feeding further research work and exploration on\nAudio-Visual Speech Recognition, an increasingly important area of research.\nCode available at\n\\href{https://github.com/YasserdahouML/visper}{https://github.com/YasserdahouML/visper}.", "published": "2024-05-27 14:48:51", "link": "http://arxiv.org/abs/2406.00038v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative\n  Language Agents using Information Relevance and Relative Proximity", "abstract": "We address the challenge of multi-agent cooperation, where agents achieve a\ncommon goal by cooperating with decentralized agents under complex partial\nobservations. Existing cooperative agent systems often struggle with\nefficiently processing continuously accumulating information, managing globally\nsuboptimal planning due to lack of consideration of collaborators, and\naddressing false planning caused by environmental changes introduced by other\ncollaborators. To overcome these challenges, we propose the RElevance,\nProximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel\ncognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory\nmanagement, optimal planning, and cost-effective prevention of false planning\nby leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based\nValidation. Extensive experimental results demonstrate REVECA's superiority\nover existing methods across various benchmarks, while a user study reveals its\npotential for achieving trustworthy human-AI cooperation.", "published": "2024-05-27 01:47:14", "link": "http://arxiv.org/abs/2405.16751v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "primary_category": "cs.AI"}
{"title": "On Mesa-Optimization in Autoregressively Trained Transformers: Emergence\n  and Capability", "abstract": "Autoregressively trained transformers have brought a profound revolution to\nthe world, especially with their in-context learning (ICL) ability to address\ndownstream tasks. Recently, several studies suggest that transformers learn a\nmesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely,\nthe forward pass of the trained transformer is equivalent to optimizing an\ninner objective function in-context. However, whether the practical non-convex\ntraining dynamics will converge to the ideal mesa-optimizer is still unclear.\nTowards filling this gap, we investigate the non-convex dynamics of a one-layer\nlinear causal self-attention model autoregressively trained by gradient flow,\nwhere the sequences are generated by an AR process $x_{t+1} = W x_t$. First,\nunder a certain condition of data distribution, we prove that an\nautoregressively trained transformer learns $W$ by implementing one step of\ngradient descent to minimize an ordinary least squares (OLS) problem\nin-context. It then applies the learned $\\widehat{W}$ for next-token\nprediction, thereby verifying the mesa-optimization hypothesis. Next, under the\nsame data conditions, we explore the capability limitations of the obtained\nmesa-optimizer. We show that a stronger assumption related to the moments of\ndata is the sufficient and necessary condition that the learned mesa-optimizer\nrecovers the distribution. Besides, we conduct exploratory analyses beyond the\nfirst data condition and prove that generally, the trained transformer will not\nperform vanilla gradient descent for the OLS problem. Finally, our simulation\nresults verify the theoretical results.", "published": "2024-05-27 05:41:06", "link": "http://arxiv.org/abs/2405.16845v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large\n  Multi-Modal Models", "abstract": "While large multi-modal models (LMMs) have exhibited impressive capabilities\nacross diverse tasks, their effectiveness in handling complex tasks has been\nlimited by the prevailing single-step reasoning paradigm. To this end, this\npaper proposes VoCoT, a multi-step Visually grounded object-centric\nChain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is\ncharacterized by two key features: (1) object-centric reasoning paths that\nrevolve around cross-modal shared object-level information, and (2) visually\ngrounded representation of object concepts in a multi-modal interleaved and\naligned manner, which effectively bridges the modality gap within LMMs during\nlong-term generation. To adapt LMMs in reasoning with VoCoT, we further\nconstruct an instruction-tuning dataset. By combining VoCoT with the prevalent\nopen-source LMM architectures, we develop a VoCoT-based model, VolCano. With\nonly 7B parameters and limited input image resolution, VolCano demonstrates\nexcellent performance across various scenarios. In benchmarks like CLEVR and\nEmbSpatial, which highly require complex reasoning capabilities, VolCano\noutperforms SOTA models, including powerful GPT-4V. Related code, data and\nmodels are released in https://github.com/RupertLuo/VoCoT.", "published": "2024-05-27 08:12:00", "link": "http://arxiv.org/abs/2405.16919v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Vision-and-Language Navigation Generative Pretrained Transformer", "abstract": "In the Vision-and-Language Navigation (VLN) field, agents are tasked with\nnavigating real-world scenes guided by linguistic instructions. Enabling the\nagent to adhere to instructions throughout the process of navigation represents\na significant challenge within the domain of VLN. To address this challenge,\ncommon approaches often rely on encoders to explicitly record past locations\nand actions, increasing model complexity and resource consumption. Our\nproposal, the Vision-and-Language Navigation Generative Pretrained Transformer\n(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory\nsequence dependencies, bypassing the need for historical encoding modules. This\nmethod allows for direct historical information access through trajectory\nsequence, enhancing efficiency. Furthermore, our model separates the training\nprocess into offline pre-training with imitation learning and online\nfine-tuning with reinforcement learning. This distinction allows for more\nfocused training objectives and improved performance. Performance assessments\non the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art\nencoder-based models.", "published": "2024-05-27 09:42:04", "link": "http://arxiv.org/abs/2405.16994v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Interesting Scientific Idea Generation using Knowledge Graphs and LLMs:\n  Evaluations with 100 Research Group Leaders", "abstract": "The rapid growth of scientific literature makes it challenging for\nresearchers to identify novel and impactful ideas, especially across\ndisciplines. Modern artificial intelligence (AI) systems offer new approaches,\npotentially inspiring ideas not conceived by humans alone. But how compelling\nare these AI-generated ideas, and how can we improve their quality? Here, we\nintroduce SciMuse, which uses 58 million research papers and a large-language\nmodel to generate research ideas. We conduct a large-scale evaluation in which\nover 100 research group leaders -- from natural sciences to humanities --\nranked more than 4,400 personalized ideas based on their interest. This data\nallows us to predict research interest using (1) supervised neural networks\ntrained on human evaluations, and (2) unsupervised zero-shot ranking with\nlarge-language models. Our results demonstrate how future systems can help\ngenerating compelling research ideas and foster unforeseen interdisciplinary\ncollaborations.", "published": "2024-05-27 11:00:51", "link": "http://arxiv.org/abs/2405.17044v3", "categories": ["cs.AI", "cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Leveraging small language models for Text2SPARQL tasks to improve the\n  resilience of AI assistance", "abstract": "In this work we will show that language models with less than one billion\nparameters can be used to translate natural language to SPARQL queries after\nfine-tuning. Using three different datasets ranging from academic to real\nworld, we identify prerequisites that the training data must fulfill in order\nfor the training to be successful. The goal is to empower users of semantic web\ntechnology to use AI assistance with affordable commodity hardware, making them\nmore resilient against external factors.", "published": "2024-05-27 11:47:21", "link": "http://arxiv.org/abs/2405.17076v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Phase Transitions in the Output Distribution of Large Language Models", "abstract": "In a physical system, changing parameters such as temperature can induce a\nphase transition: an abrupt change from one state of matter to another.\nAnalogous phenomena have recently been observed in large language models.\nTypically, the task of identifying phase transitions requires human analysis\nand some prior understanding of the system to narrow down which low-dimensional\nproperties to monitor and analyze. Statistical methods for the automated\ndetection of phase transitions from data have recently been proposed within the\nphysics community. These methods are largely system agnostic and, as shown\nhere, can be adapted to study the behavior of large language models. In\nparticular, we quantify distributional changes in the generated output via\nstatistical distances, which can be efficiently estimated with access to the\nprobability distribution over next-tokens. This versatile approach is capable\nof discovering new phases of behavior and unexplored transitions -- an ability\nthat is particularly exciting in light of the rapid development of language\nmodels and their emergent capabilities.", "published": "2024-05-27 12:04:36", "link": "http://arxiv.org/abs/2405.17088v1", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-Optic: Unveiling the Capabilities of Large Language Models for\n  Universal Visual Grounding", "abstract": "Visual grounding is an essential tool that links user-provided text queries\nwith query-specific regions within an image. Despite advancements in visual\ngrounding models, their ability to comprehend complex queries remains limited.\nTo overcome this limitation, we introduce LLM-Optic, an innovative method that\nutilizes Large Language Models (LLMs) as an optical lens to enhance existing\nvisual grounding models in comprehending complex text queries involving\nintricate text structures, multiple objects, or object spatial relationships,\nsituations that current models struggle with. LLM-Optic first employs an LLM as\na Text Grounder to interpret complex text queries and accurately identify\nobjects the user intends to locate. Then a pre-trained visual grounding model\nis used to generate candidate bounding boxes given the refined query by the\nText Grounder. After that, LLM-Optic annotates the candidate bounding boxes\nwith numerical marks to establish a connection between text and specific image\nregions, thereby linking two distinct modalities. Finally, it employs a Large\nMultimodal Model (LMM) as a Visual Grounder to select the marked candidate\nobjects that best correspond to the original text query. Through LLM-Optic, we\nhave achieved universal visual grounding, which allows for the detection of\narbitrary objects specified by arbitrary human language input. Importantly, our\nmethod achieves this enhancement without requiring additional training or\nfine-tuning. Extensive experiments across various challenging benchmarks\ndemonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding\ncapabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.", "published": "2024-05-27 12:23:08", "link": "http://arxiv.org/abs/2405.17104v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Mixtures of Unsupervised Lexicon Classification", "abstract": "This paper presents a mixture version of the method-of-moment unsupervised\nlexicon classification by an incorporation of a Dirichlet process.", "published": "2024-05-27 12:33:47", "link": "http://arxiv.org/abs/2405.17116v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stop! In the Name of Flaws: Disentangling Personal Names and\n  Sociodemographic Attributes in NLP", "abstract": "Personal names simultaneously differentiate individuals and categorize them\nin ways that are important in a given society. While the natural language\nprocessing community has thus associated personal names with sociodemographic\ncharacteristics in a variety of tasks, researchers have engaged to varying\ndegrees with the established methodological problems in doing so. To guide\nfuture work that uses names and sociodemographic characteristics, we provide an\noverview of relevant research: first, we present an interdisciplinary\nbackground on names and naming. We then survey the issues inherent to\nassociating names with sociodemographic attributes, covering problems of\nvalidity (e.g., systematic error, construct validity), as well as ethical\nconcerns (e.g., harms, differential impact, cultural insensitivity). Finally,\nwe provide guiding questions along with normative recommendations to avoid\nvalidity and ethical pitfalls when dealing with names and sociodemographic\ncharacteristics in natural language processing.", "published": "2024-05-27 13:33:29", "link": "http://arxiv.org/abs/2405.17159v2", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Efficient multi-prompt evaluation of LLMs", "abstract": "Most popular benchmarks for comparing LLMs rely on a limited set of prompt\ntemplates, which may not fully capture the LLMs' abilities and can affect the\nreproducibility of results on leaderboards. Many recent works empirically\nverify prompt sensitivity and advocate for changes in LLM evaluation. In this\npaper, we consider the problem of estimating the performance distribution\nacross many prompt variants instead of finding a single prompt to evaluate\nwith. We introduce PromptEval, a method for estimating performance across a\nlarge set of prompts borrowing strength across prompts and examples to produce\naccurate estimates under practical evaluation budgets. The resulting\ndistribution can be used to obtain performance quantiles to construct various\nrobust performance metrics (e.g., top 95% quantile or median). We prove that\nPromptEval consistently estimates the performance distribution and demonstrate\nits efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench\nHard, and LMentry; for example, PromptEval can accurately estimate performance\nquantiles across 100 prompt templates on MMLU with a budget equivalent to two\nsingle-prompt evaluations. Moreover, we show how PromptEval can be useful in\nLLM-as-a-judge and best prompt identification applications.", "published": "2024-05-27 14:24:47", "link": "http://arxiv.org/abs/2405.17202v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The Expressive Capacity of State Space Models: A Formal Language\n  Perspective", "abstract": "Recently, recurrent models based on linear state space models (SSMs) have\nshown promising performance in language modeling (LM), competititve with\ntransformers. However, there is little understanding of the in-principle\nabilities of such models, which could provide useful guidance to the search for\nbetter LM architectures. We present a comprehensive theoretical study of the\ncapacity of such SSMs as it compares to that of transformers and traditional\nRNNs. We find that SSMs and transformers have overlapping but distinct\nstrengths. In star-free state tracking, SSMs implement straightforward and\nexact solutions to problems that transformers struggle to represent exactly.\nThey can also model bounded hierarchical structure with optimal memory even\nwithout simulating a stack. On the other hand, we identify a design choice in\ncurrent SSMs that limits their expressive power. We discuss implications for\nSSM and LM research, and verify results empirically on a recent SSM, Mamba.", "published": "2024-05-27 17:46:57", "link": "http://arxiv.org/abs/2405.17394v2", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding\n  Models", "abstract": "Decoder-only LLM-based embedding models are beginning to outperform BERT or\nT5-based embedding models in general-purpose text embedding tasks, including\ndense vector-based retrieval. In this work, we introduce NV-Embed,\nincorporating architectural designs, training procedures, and curated datasets\nto significantly enhance the performance of LLM as a versatile embedding model,\nwhile maintaining its simplicity and reproducibility. For model architecture,\nwe propose a latent attention layer to obtain pooled embeddings, which\nconsistently improves retrieval and downstream task accuracy compared to mean\npooling or using the last <EOS> token embedding from LLMs. To enhance\nrepresentation learning, we remove the causal attention mask of LLMs during\ncontrastive training. For training algorithm, we introduce a two-stage\ncontrastive instruction-tuning method. It first applies contrastive training\nwith instructions on retrieval datasets, utilizing in-batch negatives and\ncurated hard negative examples. At stage-2, it blends various non-retrieval\ninto instruction tuning, which not only enhances non-retrieval task accuracy\nbut also improves retrieval performance. For training data, we utilize the\nhard-negative mining, synthetic data generation and existing public available\ndatasets to boost the performance of embedding model. By combining these\ntechniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position\non the MTEB leaderboard (as of May 24 and August 30, 2024, respectively) across\n56 tasks, demonstrating the sustained effectiveness of the proposed methods\nover time. It also achieved the highest scores in the Long Doc section and the\nsecond-highest scores in the QA section of the AIR Benchmark, which covers a\nrange of out-of-domain information retrieval topics beyond those in MTEB. We\nfurther provide the analysis of model compression techniques for generalist\nembedding models.", "published": "2024-05-27 17:59:45", "link": "http://arxiv.org/abs/2405.17428v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Matryoshka Multimodal Models", "abstract": "Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in\nvisual-linguistic reasoning. These models first embed images into a fixed large\nnumber of visual tokens and then feed them into a Large Language Model (LLM).\nHowever, this design causes an excessive number of tokens for dense visual\nscenarios such as high-resolution images and videos, leading to great\ninefficiency. While token pruning/merging methods do exist, they produce a\nsingle length output for each image and do not afford flexibility in trading\noff information density v.s. efficiency. Inspired by the concept of Matryoshka\nDolls, we propose M3: Matryoshka Multimodal Models, which learns to represent\nvisual content as nested sets of visual tokens that capture information across\nmultiple coarse-to-fine granularities. Our approach offers several unique\nbenefits for LMMs: (1) One can explicitly control the visual granularity per\ntest instance during inference, e.g. , adjusting the number of tokens used to\nrepresent an image based on the anticipated complexity or simplicity of the\ncontent; (2) M3 provides a framework for analyzing the granularity needed for\nexisting datasets, where we find that COCO-style benchmarks only need around ~9\nvisual tokens to obtain accuracy similar to that of using all 576 tokens; (3)\nOur approach provides a foundation to explore the best trade-off between\nperformance and visual token length at sample level, where our investigation\nreveals that a large gap exists between the oracle upper bound and current\nfixed-scale representations.", "published": "2024-05-27 17:59:56", "link": "http://arxiv.org/abs/2405.17430v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale", "abstract": "Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for taxonomic classification\nof photographic images and DNA separately, in this work, we introduce a\nmultimodal approach combining both, using CLIP-style contrastive learning to\nalign images, barcode DNA, and text-based representations of taxonomic labels\nin a unified embedding space. This allows for accurate classification of both\nknown and unknown insect species without task-specific fine-tuning, leveraging\ncontrastive learning for the first time to fuse barcode DNA and image data. Our\nmethod surpasses previous single-modality approaches in accuracy by over 8% on\nzero-shot learning tasks, showcasing its effectiveness in biodiversity studies.", "published": "2024-05-27 17:57:48", "link": "http://arxiv.org/abs/2405.17537v4", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "RAGSys: Item-Cold-Start Recommender as RAG System", "abstract": "Large Language Models (LLM) hold immense promise for real-world applications,\nbut their generic knowledge often falls short of domain-specific needs.\nFine-tuning, a common approach, can suffer from catastrophic forgetting and\nhinder generalizability. In-Context Learning (ICL) offers an alternative, which\ncan leverage Retrieval-Augmented Generation (RAG) to provide LLMs with relevant\ndemonstrations for few-shot learning tasks. This paper explores the desired\nqualities of a demonstration retrieval system for ICL. We argue that ICL\nretrieval in this context resembles item-cold-start recommender systems,\nprioritizing discovery and maximizing information gain over strict relevance.\nWe propose a novel evaluation method that measures the LLM's subsequent\nperformance on NLP tasks, eliminating the need for subjective diversity scores.\nOur findings demonstrate the critical role of diversity and quality bias in\nretrieved demonstrations for effective ICL, and highlight the potential of\nrecommender system techniques in this domain.", "published": "2024-05-27 18:40:49", "link": "http://arxiv.org/abs/2405.17587v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters", "abstract": "The rapid expansion of large language models (LLMs) has underscored the need\nfor parameter-efficient fine-tuning methods, with LoRA (Low-Rank Adaptation)\nemerging as a popular solution. Although LoRA reduces the number of trainable\nparameters, serving multiple (task or user-specific) LoRA modules on top of a\nbase model still creates significant storage challenges. To address this, using\ntheoretical derivation, we introduce LoRA-XS (Low-Rank Adaptation with\neXtremely Small number of parameters), a novel low-rank adaptation method that\nconsiderably reduces the trainable parameters while showing superior or\ncompetitive performance. LoRA-XS achieves this by inserting a small, trainable\nr x r weight matrix between frozen low-rank matrices, which are constructed by\nSingular Value Decomposition (SVD) of the original weight matrix. This\nlightweight matrix enables fine-tuning with drastically reduced storage\nrequirements, making it feasible to deploy millions of personalized models\nwhile minimizing memory overhead. For instance, LoRA-XS achieves a remarkable\nreduction of trainable parameters by over 100x in 7B models compared to LoRA.\nOur evaluations across various benchmarks (including GLUE, GSM8K, MATH, and\neight commonsense reasoning datasets) demonstrate that LoRA-XS performs\ncompetitively or better than LoRA and other recent methods like VeRA while\nbeing significantly more parameter efficient. We also provide an extensive\nablation study on the importance of singular vectors in transformer weights,\nshedding light on the underlying mechanisms driving LoRA-XS's enhanced\nefficiency. These findings suggest that LoRA-XS is not only a storage-efficient\nalternative, but also a powerful tool for scaling and personalizing LLMs at\nunprecedented scales.", "published": "2024-05-27 19:07:13", "link": "http://arxiv.org/abs/2405.17604v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Explainable machine learning multi-label classification of Spanish legal\n  judgements", "abstract": "Artificial Intelligence techniques such as Machine Learning (ML) have not\nbeen exploited to their maximum potential in the legal domain. This has been\npartially due to the insufficient explanations they provided about their\ndecisions. Automatic expert systems with explanatory capabilities can be\nspecially useful when legal practitioners search jurisprudence to gather\ncontextual knowledge for their cases. Therefore, we propose a hybrid system\nthat applies ML for multi-label classification of judgements (sentences) and\nvisual and natural language descriptions for explanation purposes, boosted by\nNatural Language Processing techniques and deep legal reasoning to identify the\nentities, such as the parties, involved. We are not aware of any prior work on\nautomatic multi-label classification of legal judgements also providing natural\nlanguage explanations to the end-users with comparable overall quality. Our\nsolution achieves over 85 % micro precision on a labelled data set annotated by\nlegal experts. This endorses its interest to relieve human experts from\nmonotonous labour-intensive legal classification tasks.", "published": "2024-05-27 19:16:42", "link": "http://arxiv.org/abs/2405.17610v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Jointly Modeling Inter- & Intra-Modality Dependencies for Multi-modal\n  Learning", "abstract": "Supervised multi-modal learning involves mapping multiple modalities to a\ntarget label. Previous studies in this field have concentrated on capturing in\nisolation either the inter-modality dependencies (the relationships between\ndifferent modalities and the label) or the intra-modality dependencies (the\nrelationships within a single modality and the label). We argue that these\nconventional approaches that rely solely on either inter- or intra-modality\ndependencies may not be optimal in general. We view the multi-modal learning\nproblem from the lens of generative models where we consider the target as a\nsource of multiple modalities and the interaction between them. Towards that\nend, we propose inter- & intra-modality modeling (I2M2) framework, which\ncaptures and integrates both the inter- and intra-modality dependencies,\nleading to more accurate predictions. We evaluate our approach using real-world\nhealthcare and vision-and-language datasets with state-of-the-art models,\ndemonstrating superior performance over traditional methods focusing only on\none type of modality dependency.", "published": "2024-05-27 19:22:41", "link": "http://arxiv.org/abs/2405.17613v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "InversionView: A General-Purpose Method for Reading Information from\n  Neural Activations", "abstract": "The inner workings of neural networks can be better understood if we can\nfully decipher the information encoded in neural activations. In this paper, we\nargue that this information is embodied by the subset of inputs that give rise\nto similar activations. We propose InversionView, which allows us to\npractically inspect this subset by sampling from a trained decoder model\nconditioned on activations. This helps uncover the information content of\nactivation vectors, and facilitates understanding of the algorithms implemented\nby transformer models. We present four case studies where we investigate models\nranging from small transformers to GPT-2. In these studies, we show that\nInversionView can reveal clear information contained in activations, including\nbasic information about tokens appearing in the context, as well as more\ncomplex information, such as the count of certain tokens, their relative\npositions, and abstract knowledge about the subject. We also provide causally\nverified circuits to confirm the decoded information.", "published": "2024-05-27 20:53:22", "link": "http://arxiv.org/abs/2405.17653v4", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EMERGE: Enhancing Multimodal Electronic Health Records Predictive\n  Modeling with Retrieval-Augmented Generation", "abstract": "The integration of multimodal Electronic Health Records (EHR) data has\nsignificantly advanced clinical predictive capabilities. Existing models, which\nutilize clinical notes and multivariate time-series EHR data, often fall short\nof incorporating the necessary medical context for accurate clinical tasks,\nwhile previous approaches with knowledge graphs (KGs) primarily focus on\nstructured knowledge extraction. In response, we propose EMERGE, a\nRetrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR\npredictive modeling. We extract entities from both time-series data and\nclinical notes by prompting Large Language Models (LLMs) and align them with\nprofessional PrimeKG, ensuring consistency. In addition to triplet\nrelationships, we incorporate entities' definitions and descriptions for richer\nsemantics. The extracted knowledge is then used to generate task-relevant\nsummaries of patients' health statuses. Finally, we fuse the summary with other\nmodalities using an adaptive multimodal fusion network with cross-attention.\nExtensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital\nmortality and 30-day readmission tasks demonstrate the superior performance of\nthe EMERGE framework over baseline models. Comprehensive ablation studies and\nanalysis highlight the efficacy of each designed module and robustness to data\nsparsity. EMERGE contributes to refining the utilization of multimodal EHR data\nin healthcare, bridging the gap with nuanced medical contexts essential for\ninformed clinical predictions. We have publicly released the code at\nhttps://github.com/yhzhu99/EMERGE.", "published": "2024-05-27 10:53:15", "link": "http://arxiv.org/abs/2406.00036v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recent advances in text embedding: A Comprehensive Review of\n  Top-Performing Methods on the MTEB Benchmark", "abstract": "Text embedding methods have become increasingly popular in both industrial\nand academic fields due to their critical role in a variety of natural language\nprocessing tasks. The significance of universal text embeddings has been\nfurther highlighted with the rise of Large Language Models (LLMs) applications\nsuch as Retrieval-Augmented Systems (RAGs). While previous models have\nattempted to be general-purpose, they often struggle to generalize across tasks\nand domains. However, recent advancements in training data quantity, quality\nand diversity; synthetic data generation from LLMs as well as using LLMs as\nbackbones encourage great improvements in pursuing universal text embeddings.\nIn this paper, we provide an overview of the recent advances in universal text\nembedding models with a focus on the top performing text embeddings on Massive\nText Embedding Benchmark (MTEB). Through detailed comparison and analysis, we\nhighlight the key contributions and limitations in this area, and propose\npotentially inspiring future research directions.", "published": "2024-05-27 09:52:54", "link": "http://arxiv.org/abs/2406.01607v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Detecting Deceptive Dark Patterns in E-commerce Platforms", "abstract": "Dark patterns are deceptive user interfaces employed by e-commerce websites\nto manipulate user's behavior in a way that benefits the website, often\nunethically. This study investigates the detection of such dark patterns.\nExisting solutions include UIGuard, which uses computer vision and natural\nlanguage processing, and approaches that categorize dark patterns based on\ndetectability or utilize machine learning models trained on datasets. We\npropose combining web scraping techniques with fine-tuned BERT language models\nand generative capabilities to identify dark patterns, including outliers. The\napproach scrapes textual content, feeds it into the BERT model for detection,\nand leverages BERT's bidirectional analysis and generation abilities. The study\nbuilds upon research on automatically detecting and explaining dark patterns,\naiming to raise awareness and protect consumers.", "published": "2024-05-27 16:32:40", "link": "http://arxiv.org/abs/2406.01608v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Cross-Modal Safety Alignment: Is textual unlearning all you need?", "abstract": "Recent studies reveal that integrating new modalities into Large Language\nModels (LLMs), such as Vision-Language Models (VLMs), creates a new attack\nsurface that bypasses existing safety training techniques like Supervised\nFine-tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF). While\nfurther SFT and RLHF-based safety training can be conducted in multi-modal\nsettings, collecting multi-modal training datasets poses a significant\nchallenge. Inspired by the structural design of recent multi-modal models,\nwhere, regardless of the combination of input modalities, all inputs are\nultimately fused into the language space, we aim to explore whether unlearning\nsolely in the textual domain can be effective for cross-modality safety\nalignment. Our evaluation across six datasets empirically demonstrates the\ntransferability -- textual unlearning in VLMs significantly reduces the Attack\nSuccess Rate (ASR) to less than 8\\% and in some cases, even as low as nearly\n2\\% for both text-based and vision-text-based attacks, alongside preserving the\nutility. Moreover, our experiments show that unlearning with a multi-modal\ndataset offers no potential benefits but incurs significantly increased\ncomputational demands, possibly up to 6 times higher.", "published": "2024-05-27 20:29:13", "link": "http://arxiv.org/abs/2406.02575v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech enhancement deep-learning architecture for efficient edge\n  processing", "abstract": "Deep learning has become a de facto method of choice for speech enhancement\ntasks with significant improvements in speech quality. However, real-time\nprocessing with reduced size and computations for low-power edge devices\ndrastically degrades speech quality. Recently, transformer-based architectures\nhave greatly reduced the memory requirements and provided ways to improve the\nmodel performance through local and global contexts. However, the transformer\noperations remain computationally heavy. In this work, we introduce WaveUNet\nsqueeze-excitation Res2 (WSR)-based metric generative adversarial network\n(WSR-MGAN) architecture that can be efficiently implemented on low-power edge\ndevices for noise suppression tasks while maintaining speech quality. We\nutilize multi-scale features using Res2Net blocks that can be related to\nspectral content used in speech-processing tasks. In the generator, we\nintegrate squeeze-excitation blocks (SEB) with multi-scale features for\nmaintaining local and global contexts along with gated recurrent units (GRUs).\nThe proposed approach is optimized through a combined loss function calculated\nover raw waveform, multi-resolution magnitude spectrogram, and objective\nmetrics using a metric discriminator. Experimental results in terms of various\nobjective metrics on VoiceBank+DEMAND and DNS-2020 challenge datasets\ndemonstrate that the proposed speech enhancement (SE) approach outperforms the\nbaselines and achieves state-of-the-art (SOTA) performance in the time domain.", "published": "2024-05-27 05:04:09", "link": "http://arxiv.org/abs/2405.16834v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Variance-Preserving Interpolation Approach for Diffusion Models with\n  Applications to Single Channel Speech Enhancement and Recognition", "abstract": "In this paper, we propose a variance-preserving interpolation framework to\nimprove diffusion models for single-channel speech enhancement (SE) and\nautomatic speech recognition (ASR). This new variance-preserving interpolation\ndiffusion model (VPIDM) approach requires only 25 iterative steps and obviates\nthe need for a corrector, an essential element in the existing\nvariance-exploding interpolation diffusion model (VEIDM). Two notable\ndistinctions between VPIDM and VEIDM are the scaling function of the mean of\nstate variables and the constraint imposed on the variance relative to the\nmean's scale. We conduct a systematic exploration of the theoretical mechanism\nunderlying VPIDM and develop insights regarding VPIDM's applications in SE and\nASR using VPIDM as a frontend. Our proposed approach, evaluated on two distinct\ndata sets, demonstrates VPIDM's superior performances over conventional\ndiscriminative SE algorithms. Furthermore, we assess the performance of the\nproposed model under varying signal-to-noise ratio (SNR) levels. The\ninvestigation reveals VPIDM's improved robustness in target noise elimination\nwhen compared to VEIDM. Furthermore, utilizing the mid-outputs of both VPIDM\nand VEIDM results in enhanced ASR accuracies, thereby highlighting the\npractical efficacy of our proposed approach.", "published": "2024-05-27 08:44:19", "link": "http://arxiv.org/abs/2405.16952v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speech Loudness in Broadcasting and Streaming", "abstract": "The introduction and regulation of loudness in broadcasting and streaming\nbrought clear benefits to the audience, e.g., a level of uniformity across\nprograms and channels. Yet, speech loudness is frequently reported as being too\nlow in certain passages, which can hinder the full understanding and enjoyment\nof movies and TV programs. This paper proposes expanding the set of\nloudness-based measures typically used in the industry. We focus on speech\nloudness, and we show that, when clean speech is not available, Deep Neural\nNetworks (DNNs) can be used to isolate the speech signal and so to accurately\nestimate speech loudness, providing a more precise estimate compared to\nspeech-gated loudness. Moreover, we define critical passages, i.e., passages in\nwhich speech is likely to be hard to understand. Critical passages are defined\nbased on the local Speech Loudness Deviation (SLD) and the local\nSpeech-to-Background Loudness Difference (SBLD), as SLD and SBLD significantly\ncontribute to intelligibility and listening effort. In contrast to other more\ncomprehensive measures of intelligibility and listening effort, SLD and SBLD\ncan be straightforwardly measured, are intuitive, and, most importantly, can be\neasily controlled by adjusting the speech level in the mix or by enabling\npersonalization at the user's end. Finally, examples are provided that show how\nthe detection of critical passages can support the evaluation and control of\nthe speech signal during and after content production.", "published": "2024-05-27 17:14:45", "link": "http://arxiv.org/abs/2405.17364v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "RSET: Remapping-based Sorting Method for Emotion Transfer Speech\n  Synthesis", "abstract": "Although current Text-To-Speech (TTS) models are able to generate\nhigh-quality speech samples, there are still challenges in developing emotion\nintensity controllable TTS. Most existing TTS models achieve emotion intensity\ncontrol by extracting intensity information from reference speeches.\nUnfortunately, limited by the lack of modeling for intra-class emotion\nintensity and the model's information decoupling capability, the generated\nspeech cannot achieve fine-grained emotion intensity control and suffers from\ninformation leakage issues. In this paper, we propose an emotion transfer TTS\nmodel, which defines a remapping-based sorting method to model intra-class\nrelative intensity information, combined with Mutual Information (MI) to\ndecouple speaker and emotion information, and synthesizes expressive speeches\nwith perceptible intensity differences. Experiments show that our model\nachieves fine-grained emotion control while preserving speaker information.", "published": "2024-05-27 10:30:54", "link": "http://arxiv.org/abs/2405.17028v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Real-Time Voice Activity Detection Based On Lightweight Neural", "abstract": "Voice activity detection (VAD) is the task of detecting speech in an audio\nstream, which is challenging due to numerous unseen noises and low\nsignal-to-noise ratios in real environments. Recently, neural network-based\nVADs have alleviated the degradation of performance to some extent. However,\nthe majority of existing studies have employed excessively large models and\nincorporated future context, while neglecting to evaluate the operational\nefficiency and latency of the models. In this paper, we propose a lightweight\nand real-time neural network called MagicNet, which utilizes casual and depth\nseparable 1-D convolutions and GRU. Without relying on future features as\ninput, our proposed model is compared with two state-of-the-art algorithms on\nsynthesized in-domain and out-domain test datasets. The evaluation results\ndemonstrate that MagicNet can achieve improved performance and robustness with\nfewer parameter costs.", "published": "2024-05-27 03:31:16", "link": "http://arxiv.org/abs/2405.16797v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sok: Comprehensive Security Overview, Challenges, and Future Directions\n  of Voice-Controlled Systems", "abstract": "The integration of Voice Control Systems (VCS) into smart devices and their\ngrowing presence in daily life accentuate the importance of their security.\nCurrent research has uncovered numerous vulnerabilities in VCS, presenting\nsignificant risks to user privacy and security. However, a cohesive and\nsystematic examination of these vulnerabilities and the corresponding solutions\nis still absent. This lack of comprehensive analysis presents a challenge for\nVCS designers in fully understanding and mitigating the security issues within\nthese systems.\n  Addressing this gap, our study introduces a hierarchical model structure for\nVCS, providing a novel lens for categorizing and analyzing existing literature\nin a systematic manner. We classify attacks based on their technical principles\nand thoroughly evaluate various attributes, such as their methods, targets,\nvectors, and behaviors. Furthermore, we consolidate and assess the defense\nmechanisms proposed in current research, offering actionable recommendations\nfor enhancing VCS security. Our work makes a significant contribution by\nsimplifying the complexity inherent in VCS security, aiding designers in\neffectively identifying and countering potential threats, and setting a\nfoundation for future advancements in VCS security research.", "published": "2024-05-27 12:18:46", "link": "http://arxiv.org/abs/2405.17100v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Enhancing Music Genre Classification through Multi-Algorithm Analysis\n  and User-Friendly Visualization", "abstract": "The aim of this study is to teach an algorithm how to recognize different\ntypes of music. Users will submit songs for analysis. Since the algorithm\nhasn't heard these songs before, it needs to figure out what makes each song\nunique. It does this by breaking down the songs into different parts and\nstudying things like rhythm, melody, and tone via supervised learning because\nthe program learns from examples that are already labelled. One important thing\nto consider when classifying music is its genre, which can be quite complex. To\nensure accuracy, we use five different algorithms, each working independently,\nto analyze the songs. This helps us get a more complete understanding of each\nsong's characteristics. Therefore, our goal is to correctly identify the genre\nof each submitted song. Once the analysis is done, the results are presented\nusing a graphing tool, making it easy for users to understand and provide\nfeedback.", "published": "2024-05-27 17:57:20", "link": "http://arxiv.org/abs/2405.17413v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discriminant audio properties in deep learning based respiratory\n  insufficiency detection in Brazilian Portuguese", "abstract": "This work investigates Artificial Intelligence (AI) systems that detect\nrespiratory insufficiency (RI) by analyzing speech audios, thus treating speech\nas a RI biomarker. Previous works collected RI data (P1) from COVID-19 patients\nduring the first phase of the pandemic and trained modern AI models, such as\nCNNs and Transformers, which achieved $96.5\\%$ accuracy, showing the\nfeasibility of RI detection via AI. Here, we collect RI patient data (P2) with\nseveral causes besides COVID-19, aiming at extending AI-based RI detection. We\nalso collected control data from hospital patients without RI. We show that the\nconsidered models, when trained on P1, do not generalize to P2, indicating that\nCOVID-19 RI has features that may not be found in all RI types.", "published": "2024-05-27 18:04:49", "link": "http://arxiv.org/abs/2405.17569v1", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Listenable Maps for Zero-Shot Audio Classifiers", "abstract": "Interpreting the decisions of deep learning models, including audio\nclassifiers, is crucial for ensuring the transparency and trustworthiness of\nthis technology. In this paper, we introduce LMAC-ZS (Listenable Maps for Audio\nClassifiers in the Zero-Shot context), which, to the best of our knowledge, is\nthe first decoder-based post-hoc interpretation method for explaining the\ndecisions of zero-shot audio classifiers. The proposed method utilizes a novel\nloss function that maximizes the faithfulness to the original similarity\nbetween a given text-and-audio pair. We provide an extensive evaluation using\nthe Contrastive Language-Audio Pretraining (CLAP) model to showcase that our\ninterpreter remains faithful to the decisions in a zero-shot classification\ncontext. Moreover, we qualitatively show that our method produces meaningful\nexplanations that correlate well with different text prompts.", "published": "2024-05-27 19:25:42", "link": "http://arxiv.org/abs/2405.17615v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
