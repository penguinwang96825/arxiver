{"title": "Controllable Summarization with Constrained Markov Decision Process", "abstract": "We study controllable text summarization which allows users to gain control\non a particular attribute (e.g., length limit) of the generated summaries. In\nthis work, we propose a novel training framework based on Constrained Markov\nDecision Process (CMDP), which conveniently includes a reward function along\nwith a set of constraints, to facilitate better summarization control. The\nreward function encourages the generation to resemble the human-written\nreference, while the constraints are used to explicitly prevent the generated\nsummaries from violating user-imposed requirements. Our framework can be\napplied to control important attributes of summarization, including length,\ncovered entities, and abstractiveness, as we devise specific constraints for\neach of these aspects. Extensive experiments on popular benchmarks show that\nour CMDP framework helps generate informative summaries while complying with a\ngiven attribute's requirement.", "published": "2021-08-07 09:12:53", "link": "http://arxiv.org/abs/2108.03405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning GPT-3 for Russian Text Summarization", "abstract": "Automatic summarization techniques aim to shorten and generalize information\ngiven in the text while preserving its core message and the most relevant\nideas. This task can be approached and treated with a variety of methods,\nhowever, not many attempts have been made to produce solutions specifically for\nthe Russian language despite existing localizations of the state-of-the-art\nmodels. In this paper, we aim to showcase ruGPT3 ability to summarize texts,\nfine-tuning it on the corpora of Russian news with their corresponding\nhuman-generated summaries. Additionally, we employ hyperparameter tuning so\nthat the model's output becomes less random and more tied to the original text.\nWe evaluate the resulting texts with a set of metrics, showing that our\nsolution can surpass the state-of-the-art model's performance without\nadditional changes in architecture or loss function. Despite being able to\nproduce sensible summaries, our model still suffers from a number of flaws,\nnamely, it is prone to altering Named Entities present in the original text\n(such as surnames, places, dates), deviating from facts stated in the given\ndocument, and repeating the information in the summary.", "published": "2021-08-07 19:01:40", "link": "http://arxiv.org/abs/2108.03502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Generalization in Multilingual Semantic Parsing over\n  Wikidata", "abstract": "Semantic parsing (SP) allows humans to leverage vast knowledge resources\nthrough natural interaction. However, parsers are mostly designed for and\nevaluated on English resources, such as CFQ (Keysers et al., 2020), the current\nstandard benchmark based on English data generated from grammar rules and\noriented towards Freebase, an outdated knowledge base. We propose a method for\ncreating a multilingual, parallel dataset of question-query pairs, grounded in\nWikidata. We introduce such a dataset, which we call Multilingual Compositional\nWikidata Questions (MCWQ), and use it to analyze the compositional\ngeneralization of semantic parsers in Hebrew, Kannada, Chinese and English.\nWhile within-language generalization is comparable across languages,\nexperiments on zero-shot cross-lingual transfer demonstrate that cross-lingual\ncompositional generalization fails, even with state-of-the-art pretrained\nmultilingual encoders. Furthermore, our methodology, dataset and results will\nfacilitate future research on SP in more realistic and diverse settings than\nhas been possible with existing resources.", "published": "2021-08-07 19:40:38", "link": "http://arxiv.org/abs/2108.03509v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Measures of Biases and Harms in NLP", "abstract": "Recent studies show that Natural Language Processing (NLP) technologies\npropagate societal biases about demographic groups associated with attributes\nsuch as gender, race, and nationality. To create interventions and mitigate\nthese biases and associated harms, it is vital to be able to detect and measure\nsuch biases. While existing works propose bias evaluation and mitigation\nmethods for various tasks, there remains a need to cohesively understand the\nbiases and the specific harms they measure, and how different measures compare\nwith each other. To address this gap, this work presents a practical framework\nof harms and a series of questions that practitioners can answer to guide the\ndevelopment of bias measures. As a validation of our framework and\ndocumentation questions, we also present several case studies of how existing\nbias measures in NLP -- both intrinsic measures of bias in representations and\nextrinsic measures of bias of downstream applications -- can be aligned with\ndifferent harms and how our proposed documentation questions facilitates more\nholistic understanding of what bias measures are measuring.", "published": "2021-08-07 04:08:47", "link": "http://arxiv.org/abs/2108.03362v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Generating Personalized Dialogue via Multi-Task Meta-Learning", "abstract": "Conventional approaches to personalized dialogue generation typically require\na large corpus, as well as predefined persona information. However, in a\nreal-world setting, neither a large corpus of training data nor persona\ninformation are readily available. To address these practical limitations, we\npropose a novel multi-task meta-learning approach which involves training a\nmodel to adapt to new personas without relying on a large corpus, or on any\npredefined persona information. Instead, the model is tasked with generating\npersonalized responses based on only the dialogue context. Unlike prior work,\nour approach leverages on the provided persona information only during training\nvia the introduction of an auxiliary persona reconstruction task. In this\npaper, we introduce 2 frameworks that adopt the proposed multi-task\nmeta-learning approach: the Multi-Task Meta-Learning (MTML) framework, and the\nAlternating Multi-Task Meta-Learning (AMTML) framework. Experimental results\nshow that utilizing MTML and AMTML results in dialogue responses with greater\npersona consistency.", "published": "2021-08-07 06:38:35", "link": "http://arxiv.org/abs/2108.03377v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Similar Language Translation With Transfer Learning", "abstract": "We investigate transfer learning based on pre-trained neural machine\ntranslation models to translate between (low-resource) similar languages. This\nwork is part of our contribution to the WMT 2021 Similar Languages Translation\nShared Task where we submitted models for different language pairs, including\nFrench-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions. Our\nmodels for Catalan-Spanish ($82.79$ BLEU) and Portuguese-Spanish ($87.11$ BLEU)\nrank top 1 in the official shared task evaluation, and we are the only team to\nsubmit models for the French-Bambara pairs.", "published": "2021-08-07 22:25:46", "link": "http://arxiv.org/abs/2108.03533v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Tiny Neural Models for Seq2Seq", "abstract": "Semantic parsing models with applications in task oriented dialog systems\nrequire efficient sequence to sequence (seq2seq) architectures to be run\non-device. To this end, we propose a projection based encoder-decoder model\nreferred to as pQRNN-MAtt. Studies based on projection methods were restricted\nto encoder-only models, and we believe this is the first study extending it to\nseq2seq architectures. The resulting quantized models are less than 3.5MB in\nsize and are well suited for on-device latency critical applications. We show\nthat on MTOP, a challenging multilingual semantic parsing dataset, the average\nmodel performance surpasses LSTM based seq2seq model that uses pre-trained\nembeddings despite being 85x smaller. Furthermore, the model can be an\neffective student for distilling large pre-trained models such as T5/BERT.", "published": "2021-08-07 00:39:42", "link": "http://arxiv.org/abs/2108.03340v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An empirical assessment of deep learning approaches to task-oriented\n  dialog management", "abstract": "Deep learning is providing very positive results in areas related to\nconversational interfaces, such as speech recognition, but its potential\nbenefit for dialog management has still not been fully studied. In this paper,\nwe perform an assessment of different configurations for deep-learned dialog\nmanagement with three dialog corpora from different application domains and\nvarying in size, dimensionality and possible system responses. Our results have\nallowed us to identify several aspects that can have an impact on accuracy,\nincluding the approaches used for feature extraction, input representation,\ncontext consideration and the hyper-parameters of the deep neural networks\nemployed.", "published": "2021-08-07 16:05:48", "link": "http://arxiv.org/abs/2108.03478v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Propaganda Techniques in Memes", "abstract": "Propaganda can be defined as a form of communication that aims to influence\nthe opinions or the actions of people towards a specific goal; this is achieved\nby means of well-defined rhetorical and psychological devices. Propaganda, in\nthe form we know it today, can be dated back to the beginning of the 17th\ncentury. However, it is with the advent of the Internet and the social media\nthat it has started to spread on a much larger scale than before, thus becoming\nmajor societal and political issue. Nowadays, a large fraction of propaganda in\nsocial media is multimodal, mixing textual with visual content. With this in\nmind, here we propose a new multi-label multimodal task: detecting the type of\npropaganda techniques used in memes. We further create and release a new corpus\nof 950 memes, carefully annotated with 22 propaganda techniques, which can\nappear in the text, in the image, or in both. Our analysis of the corpus shows\nthat understanding both modalities together is essential for detecting these\ntechniques. This is further confirmed in our experiments with several\nstate-of-the-art multimodal models.", "published": "2021-08-07 11:56:52", "link": "http://arxiv.org/abs/2109.08013v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM", "68T50", "I.2.7"], "primary_category": "cs.CV"}
{"title": "Target-speaker Voice Activity Detection with Improved I-Vector\n  Estimation for Unknown Number of Speaker", "abstract": "Target-speaker voice activity detection (TS-VAD) has recently shown promising\nresults for speaker diarization on highly overlapped speech. However, the\noriginal model requires a fixed (and known) number of speakers, which limits\nits application to real conversations. In this paper, we extend TS-VAD to\nspeaker diarization with unknown numbers of speakers. This is achieved by two\nsteps: first, an initial diarization system is applied for speaker number\nestimation, followed by TS-VAD network output masking according to this\nestimate. We further investigate different diarization methods, including\nclustering-based and region proposal networks, for estimating the initial\ni-vectors. Since these systems have complementary strengths, we propose a\nfusion-based method to combine frame-level decisions from the systems for an\nimproved initialization. We demonstrate through experiments on variants of the\nLibriCSS meeting corpus that our proposed approach can improve the DER by up to\n50\\% relative across varying numbers of speakers. This improvement also results\nin better downstream ASR performance approaching that using oracle segments.", "published": "2021-08-07 01:29:37", "link": "http://arxiv.org/abs/2108.03342v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Unified Model for Zero-shot Music Source Separation, Transcription and\n  Synthesis", "abstract": "We propose a unified model for three inter-related tasks: 1) to\n\\textit{separate} individual sound sources from a mixed music audio, 2) to\n\\textit{transcribe} each sound source to MIDI notes, and 3) to\\textit{\nsynthesize} new pieces based on the timbre of separated sources. The model is\ninspired by the fact that when humans listen to music, our minds can not only\nseparate the sounds of different instruments, but also at the same time\nperceive high-level representations such as score and timbre. To mirror such\ncapability computationally, we designed a pitch-timbre disentanglement module\nbased on a popular encoder-decoder neural architecture for source separation.\nThe key inductive biases are vector-quantization for pitch representation and\npitch-transformation invariant for timbre representation. In addition, we\nadopted a query-by-example method to achieve \\textit{zero-shot} learning, i.e.,\nthe model is capable of doing source separation, transcription, and synthesis\nfor \\textit{unseen} instruments. The current design focuses on audio mixtures\nof two monophonic instruments. Experimental results show that our model\noutperforms existing multi-task baselines, and the transcribed score serves as\na powerful auxiliary for separation tasks.", "published": "2021-08-07 14:28:21", "link": "http://arxiv.org/abs/2108.03456v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "W2v-BERT: Combining Contrastive Learning and Masked Language Modeling\n  for Self-Supervised Speech Pre-Training", "abstract": "Motivated by the success of masked language modeling~(MLM) in pre-training\nnatural language processing models, we propose w2v-BERT that explores MLM for\nself-supervised speech representation learning. w2v-BERT is a framework that\ncombines contrastive learning and MLM, where the former trains the model to\ndiscretize input continuous speech signals into a finite set of discriminative\nspeech tokens, and the latter trains the model to learn contextualized speech\nrepresentations via solving a masked prediction task consuming the discretized\ntokens. In contrast to existing MLM-based speech pre-training frameworks such\nas HuBERT, which relies on an iterative re-clustering and re-training process,\nor vq-wav2vec, which concatenates two separately trained modules, w2v-BERT can\nbe optimized in an end-to-end fashion by solving the two self-supervised\ntasks~(the contrastive task and MLM) simultaneously. Our experiments show that\nw2v-BERT achieves competitive results compared to current state-of-the-art\npre-trained models on the LibriSpeech benchmarks when using the Libri-Light~60k\ncorpus as the unsupervised data. In particular, when compared to published\nmodels such as conformer-based wav2vec~2.0 and HuBERT, our model shows~5\\%\nto~10\\% relative WER reduction on the test-clean and test-other subsets. When\napplied to the Google's Voice Search traffic dataset, w2v-BERT outperforms our\ninternal conformer-based wav2vec~2.0 by more than~30\\% relatively.", "published": "2021-08-07 06:29:36", "link": "http://arxiv.org/abs/2108.06209v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
